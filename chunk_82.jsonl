{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(env, account_id, origin_id):\n\n    manager = SoftLayer.CDNManager(env.client)\n    manager.remove_origin(account_id, origin_id)", "response": "Remove an origin pull mapping."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all CDN accounts.", "response": "def cli(env, sortby):\n    \"\"\"List all CDN accounts.\"\"\"\n\n    manager = SoftLayer.CDNManager(env.client)\n    accounts = manager.list_accounts()\n\n    table = formatting.Table(['id',\n                              'account_name',\n                              'type',\n                              'created',\n                              'notes'])\n    for account in accounts:\n        table.add_row([\n            account['id'],\n            account['cdnAccountName'],\n            account['cdnSolutionName'],\n            account['createDate'],\n            account.get('cdnAccountNote', formatting.blank())\n        ])\n\n    table.sortby = sortby\n    env.fout(table)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(env, volume_id, sortby, columns):\n    file_manager = SoftLayer.FileStorageManager(env.client)\n    snapshots = file_manager.get_file_volume_snapshot_list(\n        volume_id,\n        mask=columns.mask()\n    )\n\n    table = formatting.Table(columns.columns)\n    table.sortby = sortby\n\n    for snapshot in snapshots:\n        table.add_row([value or formatting.blank()\n                       for value in columns.row(snapshot)])\n\n    env.fout(table)", "response": "List file storage snapshots."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a list of all virtual servers on the account.", "response": "def list_instances(self, hourly=True, monthly=True, tags=None, cpus=None,\n                       memory=None, hostname=None, domain=None,\n                       local_disk=None, datacenter=None, nic_speed=None,\n                       public_ip=None, private_ip=None, **kwargs):\n        \"\"\"Retrieve a list of all virtual servers on the account.\n\n        Example::\n\n            # Print out a list of hourly instances in the DAL05 data center.\n\n            for vsi in mgr.list_instances(hourly=True, datacenter='dal05'):\n               print vsi['fullyQualifiedDomainName'], vsi['primaryIpAddress']\n\n            # Using a custom object-mask. Will get ONLY what is specified\n            object_mask = \"mask[hostname,monitoringRobot[robotStatus]]\"\n            for vsi in mgr.list_instances(mask=object_mask,hourly=True):\n                print vsi\n\n        :param boolean hourly: include hourly instances\n        :param boolean monthly: include monthly instances\n        :param list tags: filter based on list of tags\n        :param integer cpus: filter based on number of CPUS\n        :param integer memory: filter based on amount of memory\n        :param string hostname: filter based on hostname\n        :param string domain: filter based on domain\n        :param string local_disk: filter based on local_disk\n        :param string datacenter: filter based on datacenter\n        :param integer nic_speed: filter based on network speed (in MBPS)\n        :param string public_ip: filter based on public ip address\n        :param string private_ip: filter based on private ip address\n        :param dict \\\\*\\\\*kwargs: response-level options (mask, limit, etc.)\n        :returns: Returns a list of dictionaries representing the matching\n                  virtual servers\n        \"\"\"\n        if 'mask' not in kwargs:\n            items = [\n                'id',\n                'globalIdentifier',\n                'hostname',\n                'domain',\n                'fullyQualifiedDomainName',\n                'primaryBackendIpAddress',\n                'primaryIpAddress',\n                'lastKnownPowerState.name',\n                'powerState',\n                'maxCpu',\n                'maxMemory',\n                'datacenter',\n                'activeTransaction.transactionStatus[friendlyName,name]',\n                'status',\n            ]\n            kwargs['mask'] = \"mask[%s]\" % ','.join(items)\n\n        call = 'getVirtualGuests'\n        if not all([hourly, monthly]):\n            if hourly:\n                call = 'getHourlyVirtualGuests'\n            elif monthly:\n                call = 'getMonthlyVirtualGuests'\n\n        _filter = utils.NestedDict(kwargs.get('filter') or {})\n        if tags:\n            _filter['virtualGuests']['tagReferences']['tag']['name'] = {\n                'operation': 'in',\n                'options': [{'name': 'data', 'value': tags}],\n            }\n\n        if cpus:\n            _filter['virtualGuests']['maxCpu'] = utils.query_filter(cpus)\n\n        if memory:\n            _filter['virtualGuests']['maxMemory'] = utils.query_filter(memory)\n\n        if hostname:\n            _filter['virtualGuests']['hostname'] = utils.query_filter(hostname)\n\n        if domain:\n            _filter['virtualGuests']['domain'] = utils.query_filter(domain)\n\n        if local_disk is not None:\n            _filter['virtualGuests']['localDiskFlag'] = (\n                utils.query_filter(bool(local_disk)))\n\n        if datacenter:\n            _filter['virtualGuests']['datacenter']['name'] = (\n                utils.query_filter(datacenter))\n\n        if nic_speed:\n            _filter['virtualGuests']['networkComponents']['maxSpeed'] = (\n                utils.query_filter(nic_speed))\n\n        if public_ip:\n            _filter['virtualGuests']['primaryIpAddress'] = (\n                utils.query_filter(public_ip))\n\n        if private_ip:\n            _filter['virtualGuests']['primaryBackendIpAddress'] = (\n                utils.query_filter(private_ip))\n\n        kwargs['filter'] = _filter.to_dict()\n        kwargs['iter'] = True\n        return self.client.call('Account', call, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_instance(self, instance_id, **kwargs):\n\n        if 'mask' not in kwargs:\n            kwargs['mask'] = (\n                'id,'\n                'globalIdentifier,'\n                'fullyQualifiedDomainName,'\n                'hostname,'\n                'domain,'\n                'createDate,'\n                'modifyDate,'\n                'provisionDate,'\n                'notes,'\n                'dedicatedAccountHostOnlyFlag,'\n                'privateNetworkOnlyFlag,'\n                'primaryBackendIpAddress,'\n                'primaryIpAddress,'\n                '''networkComponents[id, status, speed, maxSpeed, name,\n                                     macAddress, primaryIpAddress, port,\n                                     primarySubnet[addressSpace],\n                                     securityGroupBindings[\n                                        securityGroup[id, name]]],'''\n                'lastKnownPowerState.name,'\n                'powerState,'\n                'status,'\n                'maxCpu,'\n                'maxMemory,'\n                'datacenter,'\n                'activeTransaction[id, transactionStatus[friendlyName,name]],'\n                'lastTransaction[transactionStatus],'\n                'lastOperatingSystemReload.id,'\n                'blockDevices,'\n                'blockDeviceTemplateGroup[id, name, globalIdentifier],'\n                'postInstallScriptUri,'\n                '''operatingSystem[passwords[username,password],\n                                   softwareLicense.softwareDescription[\n                                       manufacturer,name,version,\n                                       referenceCode]],'''\n                '''softwareComponents[\n                    passwords[username,password,notes],\n                    softwareLicense[softwareDescription[\n                                        manufacturer,name,version,\n                                        referenceCode]]],'''\n                'hourlyBillingFlag,'\n                'userData,'\n                '''billingItem[id,nextInvoiceTotalRecurringAmount,\n                               package[id,keyName],\n                               children[categoryCode,nextInvoiceTotalRecurringAmount],\n                               orderItem[id,\n                                         order.userRecord[username],\n                                         preset.keyName]],'''\n                'tagReferences[id,tag[name,id]],'\n                'networkVlans[id,vlanNumber,networkSpace],'\n                'dedicatedHost.id,'\n                'placementGroupId'\n            )\n\n        return self.guest.getObject(id=instance_id, **kwargs)", "response": "Get details about a virtual server instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reload_instance(self, instance_id,\n                        post_uri=None,\n                        ssh_keys=None,\n                        image_id=None):\n        \"\"\"Perform an OS reload of an instance.\n\n        :param integer instance_id: the instance ID to reload\n        :param string post_url: The URI of the post-install script to run\n                                after reload\n        :param list ssh_keys: The SSH keys to add to the root user\n        :param int image_id: The GUID of the image to load onto the server\n\n        .. warning::\n            This will reformat the primary drive.\n            Post-provision script MUST be HTTPS for it to be executed.\n\n        Example::\n\n           # Reload instance ID 12345 then run a custom post-provision script.\n           # Post-provision script MUST be HTTPS for it to be executed.\n           post_uri = 'https://somehost.com/bootstrap.sh'\n           vsi = mgr.reload_instance(12345, post_uri=post_url)\n\n        \"\"\"\n        config = {}\n\n        if post_uri:\n            config['customProvisionScriptUri'] = post_uri\n\n        if ssh_keys:\n            config['sshKeyIds'] = [key_id for key_id in ssh_keys]\n\n        if image_id:\n            config['imageTemplateId'] = image_id\n\n        return self.client.call('Virtual_Guest', 'reloadOperatingSystem',\n                                'FORCE', config, id=instance_id)", "response": "Perform an OS reload of an instance.\n\n        :param integer instance_id: the instance ID to reload\n        :param string post_url: The URI of the post-install script to run\n                                after reload\n        :param list ssh_keys: The SSH keys to add to the root user\n        :param int image_id: The GUID of the image to load onto the server\n\n        .. warning::\n            This will reformat the primary drive.\n            Post-provision script MUST be HTTPS for it to be executed.\n\n        Example::\n\n           # Reload instance ID 12345 then run a custom post-provision script.\n           # Post-provision script MUST be HTTPS for it to be executed.\n           post_uri = 'https://somehost.com/bootstrap.sh'\n           vsi = mgr.reload_instance(12345, post_uri=post_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a dict that can be passed into Virtual_Guest. createObject.", "response": "def _generate_create_dict(\n            self, cpus=None, memory=None, hourly=True,\n            hostname=None, domain=None, local_disk=True,\n            datacenter=None, os_code=None, image_id=None,\n            dedicated=False, public_vlan=None, private_vlan=None,\n            private_subnet=None, public_subnet=None,\n            userdata=None, nic_speed=None, disks=None, post_uri=None,\n            private=False, ssh_keys=None, public_security_groups=None,\n            private_security_groups=None, boot_mode=None, **kwargs):\n        \"\"\"Returns a dict appropriate to pass into Virtual_Guest::createObject\n\n            See :func:`create_instance` for a list of available options.\n        \"\"\"\n        required = [hostname, domain]\n\n        flavor = kwargs.get('flavor', None)\n        host_id = kwargs.get('host_id', None)\n\n        mutually_exclusive = [\n            {'os_code': os_code, 'image_id': image_id},\n            {'cpu': cpus, 'flavor': flavor},\n            {'memory': memory, 'flavor': flavor},\n            {'flavor': flavor, 'dedicated': dedicated},\n            {'flavor': flavor, 'host_id': host_id}\n        ]\n\n        if not all(required):\n            raise ValueError(\"hostname, and domain are required\")\n\n        for mu_ex in mutually_exclusive:\n            if all(mu_ex.values()):\n                raise ValueError(\n                    'Can only specify one of: %s' % (','.join(mu_ex.keys())))\n\n        data = {\n            \"startCpus\": cpus,\n            \"maxMemory\": memory,\n            \"hostname\": hostname,\n            \"domain\": domain,\n            \"localDiskFlag\": local_disk,\n            \"hourlyBillingFlag\": hourly,\n            \"supplementalCreateObjectOptions\": {\n                \"bootMode\": boot_mode\n            }\n        }\n\n        if flavor:\n            data[\"supplementalCreateObjectOptions\"][\"flavorKeyName\"] = flavor\n\n        if dedicated and not host_id:\n            data[\"dedicatedAccountHostOnlyFlag\"] = dedicated\n\n        if host_id:\n            data[\"dedicatedHost\"] = {\"id\": host_id}\n\n        if private:\n            data['privateNetworkOnlyFlag'] = private\n\n        if image_id:\n            data[\"blockDeviceTemplateGroup\"] = {\"globalIdentifier\": image_id}\n        elif os_code:\n            data[\"operatingSystemReferenceCode\"] = os_code\n\n        if datacenter:\n            data[\"datacenter\"] = {\"name\": datacenter}\n\n        if private_vlan or public_vlan or private_subnet or public_subnet:\n            network_components = self._create_network_components(public_vlan, private_vlan,\n                                                                 private_subnet, public_subnet)\n            data.update(network_components)\n\n        if public_security_groups:\n            secgroups = [{'securityGroup': {'id': int(sg)}}\n                         for sg in public_security_groups]\n            pnc = data.get('primaryNetworkComponent', {})\n            pnc['securityGroupBindings'] = secgroups\n            data.update({'primaryNetworkComponent': pnc})\n\n        if private_security_groups:\n            secgroups = [{'securityGroup': {'id': int(sg)}}\n                         for sg in private_security_groups]\n            pbnc = data.get('primaryBackendNetworkComponent', {})\n            pbnc['securityGroupBindings'] = secgroups\n            data.update({'primaryBackendNetworkComponent': pbnc})\n\n        if userdata:\n            data['userData'] = [{'value': userdata}]\n\n        if nic_speed:\n            data['networkComponents'] = [{'maxSpeed': nic_speed}]\n\n        if disks:\n            data['blockDevices'] = [\n                {\"device\": \"0\", \"diskImage\": {\"capacity\": disks[0]}}\n            ]\n\n            for dev_id, disk in enumerate(disks[1:], start=2):\n                data['blockDevices'].append(\n                    {\n                        \"device\": str(dev_id),\n                        \"diskImage\": {\"capacity\": disk}\n                    }\n                )\n\n        if post_uri:\n            data['postInstallScriptUri'] = post_uri\n\n        if ssh_keys:\n            data['sshKeys'] = [{'id': key_id} for key_id in ssh_keys]\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting on a VS transaction for the specified amount of time.", "response": "def wait_for_transaction(self, instance_id, limit, delay=10):\n        \"\"\"Waits on a VS transaction for the specified amount of time.\n\n        This is really just a wrapper for wait_for_ready(pending=True).\n        Provided for backwards compatibility.\n\n        :param int instance_id: The instance ID with the pending transaction\n        :param int limit: The maximum amount of time to wait.\n        :param int delay: The number of seconds to sleep before checks. Defaults to 10.\n        \"\"\"\n\n        return self.wait_for_ready(instance_id, limit, delay=delay, pending=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_create_instance(self, **kwargs):\n        kwargs.pop('tags', None)\n        create_options = self._generate_create_dict(**kwargs)\n        return self.guest.generateOrderTemplate(create_options)", "response": "Verifies an instance creation command."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new virtual server instance.", "response": "def create_instance(self, **kwargs):\n        \"\"\"Creates a new virtual server instance.\n\n        .. warning::\n\n            This will add charges to your account\n\n        Example::\n\n            new_vsi = {\n                'domain': u'test01.labs.sftlyr.ws',\n                'hostname': u'minion05',\n                'datacenter': u'hkg02',\n                'flavor': 'BL1_1X2X100'\n                'dedicated': False,\n                'private': False,\n                'os_code' : u'UBUNTU_LATEST',\n                'hourly': True,\n                'ssh_keys': [1234],\n                'disks': ('100','25'),\n                'local_disk': True,\n                'tags': 'test, pleaseCancel',\n                'public_security_groups': [12, 15]\n            }\n\n            vsi = mgr.create_instance(**new_vsi)\n            # vsi will have the newly created vsi details if done properly.\n            print vsi\n\n        :param int cpus: The number of virtual CPUs to include in the instance.\n        :param int memory: The amount of RAM to order.\n        :param bool hourly: Flag to indicate if this server should be billed hourly (default) or monthly.\n        :param string hostname: The hostname to use for the new server.\n        :param string domain: The domain to use for the new server.\n        :param bool local_disk: Flag to indicate if this should be a local disk (default) or a SAN disk.\n        :param string datacenter: The short name of the data center in which the VS should reside.\n        :param string os_code: The operating system to use. Cannot be specified  if image_id is specified.\n        :param int image_id: The GUID of the image to load onto the server. Cannot be specified if os_code is specified.\n        :param bool dedicated: Flag to indicate if this should be housed on adedicated or shared host (default).\n                               This will incur a fee on your account.\n        :param int public_vlan: The ID of the public VLAN on which you want this VS placed.\n        :param list public_security_groups: The list of security group IDs to apply to the public interface\n        :param list private_security_groups: The list of security group IDs to apply to the private interface\n        :param int private_vlan: The ID of the private VLAN on which you want  this VS placed.\n        :param list disks: A list of disk capacities for this server.\n        :param string post_uri: The URI of the post-install script to run  after reload\n        :param bool private: If true, the VS will be provisioned only with access to the private network.\n                             Defaults to false\n        :param list ssh_keys: The SSH keys to add to the root user\n        :param int nic_speed: The port speed to set\n        :param string tags: tags to set on the VS as a comma separated list\n        :param string flavor: The key name of the public virtual server flavor being ordered.\n        :param int host_id: The host id of a dedicated host to provision a dedicated host virtual server on.\n        \"\"\"\n        tags = kwargs.pop('tags', None)\n        inst = self.guest.createObject(self._generate_create_dict(**kwargs))\n        if tags is not None:\n            self.set_tags(tags, guest_id=inst['id'])\n        return inst"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates multiple virtual server instances. This will create a single instance and add charges to your account.", "response": "def create_instances(self, config_list):\n        \"\"\"Creates multiple virtual server instances.\n\n        This takes a list of dictionaries using the same arguments as\n        create_instance().\n\n        .. warning::\n\n            This will add charges to your account\n\n        Example::\n\n            # Define the instance we want to create.\n            new_vsi = {\n                'domain': u'test01.labs.sftlyr.ws',\n                'hostname': u'minion05',\n                'datacenter': u'hkg02',\n                'flavor': 'BL1_1X2X100'\n                'dedicated': False,\n                'private': False,\n                'os_code' : u'UBUNTU_LATEST',\n                'hourly': True,\n                'ssh_keys': [1234],\n                'disks': ('100','25'),\n                'local_disk': True,\n                'tags': 'test, pleaseCancel',\n                'public_security_groups': [12, 15]\n            }\n\n            # using .copy() so we can make changes to individual nodes\n            instances = [new_vsi.copy(), new_vsi.copy(), new_vsi.copy()]\n\n            # give each its own hostname, not required.\n            instances[0]['hostname'] = \"multi-test01\"\n            instances[1]['hostname'] = \"multi-test02\"\n            instances[2]['hostname'] = \"multi-test03\"\n\n            vsi = mgr.create_instances(config_list=instances)\n            #vsi will be a dictionary of all the new virtual servers\n            print vsi\n        \"\"\"\n        tags = [conf.pop('tags', None) for conf in config_list]\n\n        resp = self.guest.createObjects([self._generate_create_dict(**kwargs)\n                                         for kwargs in config_list])\n\n        for instance, tag in zip(resp, tags):\n            if tag is not None:\n                self.set_tags(tag, guest_id=instance['id'])\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nallowing you to change the port speed of a virtual server s NICs.", "response": "def change_port_speed(self, instance_id, public, speed):\n        \"\"\"Allows you to change the port speed of a virtual server's NICs.\n\n        Example::\n\n            #change the Public interface to 10Mbps on instance 12345\n            result = mgr.change_port_speed(instance_id=12345,\n                                        public=True, speed=10)\n            # result will be True or an Exception\n\n        :param int instance_id: The ID of the VS\n        :param bool public: Flag to indicate which interface to change.\n                            True (default) means the public interface.\n                            False indicates the private interface.\n        :param int speed: The port speed to set.\n\n        .. warning::\n            A port speed of 0 will disable the interface.\n        \"\"\"\n        if public:\n            return self.client.call('Virtual_Guest', 'setPublicNetworkInterfaceSpeed',\n                                    speed, id=instance_id)\n        else:\n            return self.client.call('Virtual_Guest', 'setPrivateNetworkInterfaceSpeed',\n                                    speed, id=instance_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting VS ids which match the given hostname.", "response": "def _get_ids_from_hostname(self, hostname):\n        \"\"\"List VS ids which match the given hostname.\"\"\"\n        results = self.list_instances(hostname=hostname, mask=\"id\")\n        return [result['id'] for result in results]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_ids_from_ip(self, ip_address):  # pylint: disable=inconsistent-return-statements\n        try:\n            # Does it look like an ip address?\n            socket.inet_aton(ip_address)\n        except socket.error:\n            return []\n\n        # Find the VS via ip address. First try public ip, then private\n        results = self.list_instances(public_ip=ip_address, mask=\"id\")\n        if results:\n            return [result['id'] for result in results]\n\n        results = self.list_instances(private_ip=ip_address, mask=\"id\")\n        if results:\n            return [result['id'] for result in results]", "response": "List VS ids which match the given ip address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits the hostname domain name notes and user data on a VS.", "response": "def edit(self, instance_id, userdata=None, hostname=None, domain=None,\n             notes=None, tags=None):\n        \"\"\"Edit hostname, domain name, notes, and/or the user data of a VS.\n\n        Parameters set to None will be ignored and not attempted to be updated.\n\n        :param integer instance_id: the instance ID to edit\n        :param string userdata: user data on VS to edit.\n                                If none exist it will be created\n        :param string hostname: valid hostname\n        :param string domain: valid domain namem\n        :param string notes: notes about this particular VS\n        :param string tags: tags to set on the VS as a comma separated list.\n                            Use the empty string to remove all tags.\n        :returns: bool -- True or an Exception\n\n        Example::\n            # Change the hostname on instance 12345 to 'something'\n            result = mgr.edit(instance_id=12345 , hostname=\"something\")\n            #result will be True or an Exception\n        \"\"\"\n\n        obj = {}\n        if userdata:\n            self.guest.setUserMetadata([userdata], id=instance_id)\n\n        if tags is not None:\n            self.set_tags(tags, guest_id=instance_id)\n\n        if hostname:\n            obj['hostname'] = hostname\n\n        if domain:\n            obj['domain'] = domain\n\n        if notes:\n            obj['notes'] = notes\n\n        if not obj:\n            return True\n\n        return self.guest.editObject(obj, id=instance_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaptures one or all disks from a VS to a SoftLayer image.", "response": "def capture(self, instance_id, name, additional_disks=False, notes=None):\n        \"\"\"Capture one or all disks from a VS to a SoftLayer image.\n\n        Parameters set to None will be ignored and not attempted to be updated.\n\n        :param integer instance_id: the instance ID to edit\n        :param string name: name assigned to the image\n        :param bool additional_disks: set to true to include all additional\n                                        attached storage devices\n        :param string notes: notes about this particular image\n\n        :returns: dictionary -- information about the capture transaction.\n\n        Example::\n            name = \"Testing Images\"\n            notes = \"Some notes about this image\"\n            result = mgr.capture(instance_id=12345, name=name, notes=notes)\n        \"\"\"\n\n        vsi = self.client.call(\n            'Virtual_Guest',\n            'getObject',\n            id=instance_id,\n            mask=\"\"\"id,\n            blockDevices[id,device,mountType,\n            diskImage[id,metadataFlag,type[keyName]]]\"\"\")\n\n        disks_to_capture = []\n        for block_device in vsi['blockDevices']:\n\n            # We never want metadata disks\n            if utils.lookup(block_device, 'diskImage', 'metadataFlag'):\n                continue\n\n            # We never want swap devices\n            type_name = utils.lookup(block_device, 'diskImage', 'type', 'keyName')\n            if type_name == 'SWAP':\n                continue\n\n            # We never want CD images\n            if block_device['mountType'] == 'CD':\n                continue\n\n            # Only use the first block device if we don't want additional disks\n            if not additional_disks and str(block_device['device']) != '0':\n                continue\n\n            disks_to_capture.append(block_device)\n\n        return self.guest.createArchiveTransaction(\n            name, disks_to_capture, notes, id=instance_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupgrade a VS instance to a new version.", "response": "def upgrade(self, instance_id, cpus=None, memory=None, nic_speed=None, public=True, preset=None):\n        \"\"\"Upgrades a VS instance.\n\n        Example::\n\n           # Upgrade instance 12345 to 4 CPUs and 4 GB of memory\n           import SoftLayer\n           client = SoftLayer.create_client_from_env()\n           mgr = SoftLayer.VSManager(client)\n           mgr.upgrade(12345, cpus=4, memory=4)\n\n        :param int instance_id: Instance id of the VS to be upgraded\n        :param int cpus: The number of virtual CPUs to upgrade to\n                            of a VS instance.\n        :param string preset: preset assigned to the vsi\n        :param int memory: RAM of the VS to be upgraded to.\n        :param int nic_speed: The port speed to set\n        :param bool public: CPU will be in Private/Public Node.\n\n        :returns: bool\n        \"\"\"\n        upgrade_prices = self._get_upgrade_prices(instance_id)\n        prices = []\n\n        data = {'nic_speed': nic_speed}\n\n        if cpus is not None and preset is not None:\n            raise ValueError(\"Do not use cpu, private and memory if you are using flavors\")\n        data['cpus'] = cpus\n\n        if memory is not None and preset is not None:\n            raise ValueError(\"Do not use memory, private or cpu if you are using flavors\")\n        data['memory'] = memory\n\n        maintenance_window = datetime.datetime.now(utils.UTC())\n        order = {\n            'complexType': 'SoftLayer_Container_Product_Order_Virtual_Guest_Upgrade',\n            'properties': [{\n                'name': 'MAINTENANCE_WINDOW',\n                'value': maintenance_window.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n            }],\n            'virtualGuests': [{'id': int(instance_id)}],\n        }\n\n        for option, value in data.items():\n            if not value:\n                continue\n            price_id = self._get_price_id_for_upgrade_option(upgrade_prices,\n                                                             option,\n                                                             value,\n                                                             public)\n            if not price_id:\n                # Every option provided is expected to have a price\n                raise exceptions.SoftLayerError(\n                    \"Unable to find %s option with value %s\" % (option, value))\n\n            prices.append({'id': price_id})\n        order['prices'] = prices\n\n        if preset is not None:\n            vs_object = self.get_instance(instance_id)['billingItem']['package']\n            order['presetId'] = self.ordering_manager.get_preset_by_key(vs_object['keyName'], preset)['id']\n\n        if prices or preset:\n            self.client['Product_Order'].placeOrder(order)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef order_guest(self, guest_object, test=False):\n        tags = guest_object.pop('tags', None)\n        template = self.verify_create_instance(**guest_object)\n\n        if guest_object.get('ipv6'):\n            ipv6_price = self.ordering_manager.get_price_id_list('PUBLIC_CLOUD_SERVER', ['1_IPV6_ADDRESS'])\n            template['prices'].append({'id': ipv6_price[0]})\n\n        # Notice this is `userdata` from the cli, but we send it in as `userData`\n        if guest_object.get('userdata'):\n            # SL_Virtual_Guest::generateOrderTemplate() doesn't respect userData, so we need to add it ourself\n            template['virtualGuests'][0]['userData'] = [{\"value\": guest_object.get('userdata')}]\n        if guest_object.get('host_id'):\n            template['hostId'] = guest_object.get('host_id')\n        if guest_object.get('placement_id'):\n            template['virtualGuests'][0]['placementGroupId'] = guest_object.get('placement_id')\n\n        if test:\n            result = self.client.call('Product_Order', 'verifyOrder', template)\n        else:\n            result = self.client.call('Product_Order', 'placeOrder', template)\n            if tags is not None:\n                virtual_guests = utils.lookup(result, 'orderDetails', 'virtualGuests')\n                for guest in virtual_guests:\n                    self.set_tags(tags, guest_id=guest['id'])\n        return result", "response": "Uses Product_Order. placeOrder to create a virtual guest."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_package_items(self):\n        warnings.warn(\"use _get_upgrade_prices() instead\",\n                      DeprecationWarning)\n        mask = [\n            'description',\n            'capacity',\n            'units',\n            'prices[id,locationGroupId,categories[name,id,categoryCode]]'\n        ]\n        mask = \"mask[%s]\" % ','.join(mask)\n\n        package_keyname = \"CLOUD_SERVER\"\n        package = self.ordering_manager.get_package_by_key(package_keyname)\n\n        package_service = self.client['Product_Package']\n        return package_service.getItems(id=package['id'], mask=mask)", "response": "Gets all the items related to VS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_upgrade_prices(self, instance_id, include_downgrade_options=True):\n        mask = [\n            'id',\n            'locationGroupId',\n            'categories[name,id,categoryCode]',\n            'item[description,capacity,units]'\n        ]\n        mask = \"mask[%s]\" % ','.join(mask)\n        return self.guest.getUpgradeItemPrices(include_downgrade_options, id=instance_id, mask=mask)", "response": "Gets all the price ids related to upgrading a VS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_price_id_for_upgrade_option(self, upgrade_prices, option, value, public=True):\n        option_category = {\n            'memory': 'ram',\n            'cpus': 'guest_core',\n            'nic_speed': 'port_speed'\n        }\n        category_code = option_category.get(option)\n        for price in upgrade_prices:\n            if price.get('categories') is None or price.get('item') is None:\n                continue\n\n            product = price.get('item')\n            is_private = (product.get('units') == 'PRIVATE_CORE'\n                          or product.get('units') == 'DEDICATED_CORE')\n\n            for category in price.get('categories'):\n                if not (category.get('categoryCode') == category_code\n                        and str(product.get('capacity')) == str(value)):\n                    continue\n\n                if option == 'cpus':\n                    # Public upgrade and public guest_core price\n                    if public and not is_private:\n                        return price.get('id')\n                    # Private upgrade and private guest_core price\n                    elif not public and is_private:\n                        return price.get('id')\n                elif option == 'nic_speed':\n                    if 'Public' in product.get('description'):\n                        return price.get('id')\n                else:\n                    return price.get('id')", "response": "Find the price id for the option and value to upgrade."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the price id for the option and value to upgrade.", "response": "def _get_price_id_for_upgrade(self, package_items, option, value, public=True):\n        \"\"\"Find the price id for the option and value to upgrade.\n\n        Deprecated in favor of _get_price_id_for_upgrade_option()\n\n        :param list package_items: Contains all the items related to an VS\n        :param string option: Describes type of parameter to be upgraded\n        :param int value: The value of the parameter to be upgraded\n        :param bool public: CPU will be in Private/Public Node.\n        \"\"\"\n        warnings.warn(\"use _get_price_id_for_upgrade_option() instead\",\n                      DeprecationWarning)\n        option_category = {\n            'memory': 'ram',\n            'cpus': 'guest_core',\n            'nic_speed': 'port_speed'\n        }\n        category_code = option_category[option]\n        for item in package_items:\n            is_private = (item.get('units') == 'PRIVATE_CORE')\n            for price in item['prices']:\n                if 'locationGroupId' in price and price['locationGroupId']:\n                    # Skip location based prices\n                    continue\n\n                if 'categories' not in price:\n                    continue\n\n                categories = price['categories']\n                for category in categories:\n                    if not (category['categoryCode'] == category_code\n                            and str(item['capacity']) == str(value)):\n                        continue\n                    if option == 'cpus':\n                        if public and not is_private:\n                            return price['id']\n                        elif not public and is_private:\n                            return price['id']\n                    elif option == 'nic_speed':\n                        if 'Public' in item['description']:\n                            return price['id']\n                    else:\n                        return price['id']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef interface_list(env, securitygroup_id, sortby):\n    mgr = SoftLayer.NetworkManager(env.client)\n\n    table = formatting.Table(COLUMNS)\n    table.sortby = sortby\n\n    mask = (\n        '''networkComponentBindings[\n            networkComponentId,\n            networkComponent[\n                id,\n                port,\n                guest[\n                    id,\n                    hostname,\n                    primaryBackendIpAddress,\n                    primaryIpAddress\n                ]\n            ]\n        ]'''\n    )\n\n    secgroup = mgr.get_securitygroup(securitygroup_id, mask=mask)\n    for binding in secgroup.get('networkComponentBindings', []):\n        interface_id = binding['networkComponentId']\n        try:\n            interface = binding['networkComponent']\n            vsi = interface['guest']\n            vsi_id = vsi['id']\n            hostname = vsi['hostname']\n            priv_pub = 'PRIVATE' if interface['port'] == 0 else 'PUBLIC'\n            ip_address = (vsi['primaryBackendIpAddress']\n                          if interface['port'] == 0\n                          else vsi['primaryIpAddress'])\n        except KeyError:\n            vsi_id = \"N/A\"\n            hostname = \"Not enough permission to view\"\n            priv_pub = \"N/A\"\n            ip_address = \"N/A\"\n\n        table.add_row([\n            interface_id,\n            vsi_id,\n            hostname,\n            priv_pub,\n            ip_address\n        ])\n\n    env.fout(table)", "response": "List interfaces associated with security groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(env, securitygroup_id, network_component, server, interface):\n    _validate_args(network_component, server, interface)\n\n    mgr = SoftLayer.NetworkManager(env.client)\n    component_id = _get_component_id(env, network_component, server, interface)\n\n    ret = mgr.attach_securitygroup_component(securitygroup_id,\n                                             component_id)\n    if not ret:\n        raise exceptions.CLIAbort(\"Could not attach network component\")\n\n    table = formatting.Table(REQUEST_COLUMNS)\n    table.add_row([ret['requestId']])\n\n    env.fout(table)", "response": "Attach an interface to a security group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default_select(identifier, all_entry_points):  # pylint: disable=inconsistent-return-statements\n\n    if len(all_entry_points) == 0:\n        raise PluginMissingError(identifier)\n\n    elif len(all_entry_points) == 1:\n        return all_entry_points[0]\n\n    elif len(all_entry_points) > 1:\n        raise AmbiguousPluginError(all_entry_points)", "response": "Raise an exception when we have ambiguous entry points."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the object from the given entry_point and set the object s the attribute plugin_name on the loaded object.", "response": "def _load_class_entry_point(cls, entry_point):\n        \"\"\"\n        Load `entry_point`, and set the `entry_point.name` as the\n        attribute `plugin_name` on the loaded object\n        \"\"\"\n        class_ = entry_point.load()\n        setattr(class_, 'plugin_name', entry_point.name)\n        return class_"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a single class specified by identifier.", "response": "def load_class(cls, identifier, default=None, select=None):\n        \"\"\"Load a single class specified by identifier.\n\n        If `identifier` specifies more than a single class, and `select` is not None,\n        then call `select` on the list of entry_points. Otherwise, choose\n        the first one and log a warning.\n\n        If `default` is provided, return it if no entry_point matching\n        `identifier` is found. Otherwise, will raise a PluginMissingError\n\n        If `select` is provided, it should be a callable of the form::\n\n            def select(identifier, all_entry_points):\n                # ...\n                return an_entry_point\n\n        The `all_entry_points` argument will be a list of all entry_points matching `identifier`\n        that were found, and `select` should return one of those entry_points to be\n        loaded. `select` should raise `PluginMissingError` if no plugin is found, or `AmbiguousPluginError`\n        if too many plugins are found\n        \"\"\"\n        identifier = identifier.lower()\n        key = (cls.entry_point, identifier)\n        if key not in PLUGIN_CACHE:\n\n            if select is None:\n                select = default_select\n\n            all_entry_points = list(pkg_resources.iter_entry_points(cls.entry_point, name=identifier))\n            for extra_identifier, extra_entry_point in cls.extra_entry_points:\n                if identifier == extra_identifier:\n                    all_entry_points.append(extra_entry_point)\n\n            try:\n                selected_entry_point = select(identifier, all_entry_points)\n            except PluginMissingError:\n                if default is not None:\n                    return default\n                raise\n\n            PLUGIN_CACHE[key] = cls._load_class_entry_point(selected_entry_point)\n\n        return PLUGIN_CACHE[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_classes(cls, fail_silently=True):\n        all_classes = itertools.chain(\n            pkg_resources.iter_entry_points(cls.entry_point),\n            (entry_point for identifier, entry_point in cls.extra_entry_points),\n        )\n        for class_ in all_classes:\n            try:\n                yield (class_.name, cls._load_class_entry_point(class_))\n            except Exception:  # pylint: disable=broad-except\n                if fail_silently:\n                    log.warning('Unable to load %s %r', cls.__name__, class_.name, exc_info=True)\n                else:\n                    raise", "response": "Load all the classes for a specific plugin."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecorates a function to run with a temporary plugin available. Use it like this in tests:: @register_temp_plugin(MyXBlockClass): def test_the_thing(): # Here I can load MyXBlockClass by name.", "response": "def register_temp_plugin(cls, class_, identifier=None, dist='xblock'):\n        \"\"\"Decorate a function to run with a temporary plugin available.\n\n        Use it like this in tests::\n\n            @register_temp_plugin(MyXBlockClass):\n            def test_the_thing():\n                # Here I can load MyXBlockClass by name.\n\n        \"\"\"\n        from mock import Mock\n\n        if identifier is None:\n            identifier = class_.__name__.lower()\n\n        entry_point = Mock(\n            dist=Mock(key=dist),\n            load=Mock(return_value=class_),\n        )\n        entry_point.name = identifier\n\n        def _decorator(func):                           # pylint: disable=C0111\n            @functools.wraps(func)\n            def _inner(*args, **kwargs):                # pylint: disable=C0111\n                global PLUGIN_CACHE  # pylint: disable=global-statement\n\n                old = list(cls.extra_entry_points)\n                old_cache = PLUGIN_CACHE\n\n                cls.extra_entry_points.append((identifier, entry_point))\n                PLUGIN_CACHE = {}\n\n                try:\n                    return func(*args, **kwargs)\n                finally:\n                    cls.extra_entry_points = old\n                    PLUGIN_CACHE = old_cache\n            return _inner\n        return _decorator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a django response to the webob_response", "response": "def webob_to_django_response(webob_response):\n    \"\"\"Returns a django response to the `webob_response`\"\"\"\n    from django.http import HttpResponse\n    django_response = HttpResponse(\n        webob_response.app_iter,\n        content_type=webob_response.content_type,\n        status=webob_response.status_code,\n    )\n    for name, value in webob_response.headerlist:\n        django_response[name] = value\n    return django_response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new webob. MultiDict from a django. http. QueryDict.", "response": "def querydict_to_multidict(query_dict, wrap=None):\n    \"\"\"\n    Returns a new `webob.MultiDict` from a `django.http.QueryDict`.\n\n    If `wrap` is provided, it's used to wrap the values.\n\n    \"\"\"\n    wrap = wrap or (lambda val: val)\n    return MultiDict(chain.from_iterable(\n        six.moves.zip(repeat(key), (wrap(v) for v in vals))\n        for key, vals in six.iterlists(query_dict)\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntranslating HTTP header names to the format used by Django request objects.", "response": "def _meta_name(self, name):\n        \"\"\"\n        Translate HTTP header names to the format used by Django request objects.\n\n        See https://docs.djangoproject.com/en/1.4/ref/request-response/#django.http.HttpRequest.META\n        \"\"\"\n        name = name.upper().replace('-', '_')\n        if name not in self.UNPREFIXED_HEADERS:\n            name = 'HTTP_' + name\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _un_meta_name(self, name):\n        if name.startswith('HTTP_'):\n            name = name[5:]\n        return name.replace('_', '-').title()", "response": "Un - format the name of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef environ(self):\n        environ = dict(self._request.META)\n\n        environ['PATH_INFO'] = self._request.path_info\n\n        return environ", "response": "Return the environ dictionary for the current request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getfield(self, block, name):\n\n        # First, get the field from the class, if defined\n        block_field = getattr(block.__class__, name, None)\n        if block_field is not None and isinstance(block_field, Field):\n            return block_field\n\n        # Not in the class, so name\n        # really doesn't name a field\n        raise KeyError(name)", "response": "Get the field with the given name from the given block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresolving the name to a key in the following form", "response": "def _key(self, block, name):\n        \"\"\"\n        Resolves `name` to a key, in the following form:\n\n        KeyValueStore.Key(\n            scope=field.scope,\n            user_id=student_id,\n            block_scope_id=block_id,\n            field_name=name,\n            block_family=block.entry_point,\n        )\n        \"\"\"\n        field = self._getfield(block, name)\n        if field.scope in (Scope.children, Scope.parent):\n            block_id = block.scope_ids.usage_id\n            user_id = None\n        else:\n            block_scope = field.scope.block\n\n            if block_scope == BlockScope.ALL:\n                block_id = None\n            elif block_scope == BlockScope.USAGE:\n                block_id = block.scope_ids.usage_id\n            elif block_scope == BlockScope.DEFINITION:\n                block_id = block.scope_ids.def_id\n            elif block_scope == BlockScope.TYPE:\n                block_id = block.scope_ids.block_type\n\n            if field.scope.user == UserScope.ONE:\n                user_id = block.scope_ids.user_id\n            else:\n                user_id = None\n\n        key = KeyValueStore.Key(\n            scope=field.scope,\n            user_id=user_id,\n            block_scope_id=block_id,\n            field_name=name,\n            block_family=block.entry_point,\n        )\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, block, name):\n        return self._kvs.get(self._key(block, name))", "response": "Retrieve the value for the field named name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, block, name, value):\n        self._kvs.set(self._key(block, name), value)", "response": "Set the value of the named name to value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, block, name):\n        self._kvs.delete(self._key(block, name))", "response": "Delete the value of the named key in the specified block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has(self, block, name):\n        try:\n            return self._kvs.has(self._key(block, name))\n        except KeyError:\n            return False", "response": "Return whether or not the field named name has a non - default value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_many(self, block, update_dict):\n        updated_dict = {}\n\n        # Generate a new dict with the correct mappings.\n        for (key, value) in six.iteritems(update_dict):\n            updated_dict[self._key(block, key)] = value\n\n        self._kvs.set_many(updated_dict)", "response": "Update the underlying model with the correct values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasks the kvs for the default value for the given field.", "response": "def default(self, block, name):\n        \"\"\"\n        Ask the kvs for the default (default implementation which other classes may override).\n\n        :param block: block containing field to default\n        :type block: :class:`~xblock.core.XBlock`\n        :param name: name of the field to default\n        \"\"\"\n        return self._kvs.default(self._key(block, name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a usage and store its definition id.", "response": "def create_usage(self, def_id):\n        \"\"\"Make a usage, storing its definition id.\"\"\"\n        usage_id = self._next_id(\"u\")\n        self._usages[usage_id] = def_id\n        return usage_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a definition_id by its usage id.", "response": "def get_definition_id(self, usage_id):\n        \"\"\"Get a definition_id by its usage id.\"\"\"\n        try:\n            return self._usages[usage_id]\n        except KeyError:\n            raise NoSuchUsage(repr(usage_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_definition(self, block_type, slug=None):\n        prefix = \"d\"\n        if slug:\n            prefix += \"_\" + slug\n        def_id = self._next_id(prefix)\n        self._definitions[def_id] = block_type\n        return def_id", "response": "Make a definition storing its block type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a block type by its definition id.", "response": "def get_block_type(self, def_id):\n        \"\"\"Get a block_type by its definition id.\"\"\"\n        try:\n            return self._definitions[def_id]\n        except KeyError:\n            try:\n                return def_id.aside_type\n            except AttributeError:\n                raise NoSuchDefinition(repr(def_id))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndeprecate in favor of a field - data service.", "response": "def field_data(self, field_data):\n        \"\"\"\n        Set field_data.\n\n        Deprecated in favor of a 'field-data' service.\n        \"\"\"\n        warnings.warn(\"Runtime.field_data is deprecated\", FieldDataDeprecationWarning, stacklevel=2)\n        self._deprecated_per_instance_field_data = field_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a subclass of XBlock that corresponds to the specified block_type.", "response": "def load_block_type(self, block_type):\n        \"\"\"\n        Returns a subclass of :class:`.XBlock` that corresponds to the specified `block_type`.\n        \"\"\"\n        return XBlock.load_class(block_type, self.default_class, self.select)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing a new xblock of type cls mixing in the mixins defined for this application.", "response": "def construct_xblock_from_class(self, cls, scope_ids, field_data=None, *args, **kwargs):\n        \"\"\"\n        Construct a new xblock of type cls, mixing in the mixins\n        defined for this application.\n        \"\"\"\n        return self.mixologist.mix(cls)(\n            runtime=self,\n            field_data=field_data,\n            scope_ids=scope_ids,\n            *args, **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_block(self, usage_id, for_parent=None):\n        def_id = self.id_reader.get_definition_id(usage_id)\n        try:\n            block_type = self.id_reader.get_block_type(def_id)\n        except NoSuchDefinition:\n            raise NoSuchUsage(repr(usage_id))\n        keys = ScopeIds(self.user_id, block_type, def_id, usage_id)\n        block = self.construct_xblock(block_type, keys, for_parent=for_parent)\n        return block", "response": "Create an XBlock instance in this runtime."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_aside(self, aside_usage_id):\n        aside_type = self.id_reader.get_aside_type_from_usage(aside_usage_id)\n        xblock_usage = self.id_reader.get_usage_id_from_aside(aside_usage_id)\n        xblock_def = self.id_reader.get_definition_id(xblock_usage)\n        aside_def_id, aside_usage_id = self.id_generator.create_aside(xblock_def, xblock_usage, aside_type)\n\n        keys = ScopeIds(self.user_id, aside_type, aside_def_id, aside_usage_id)\n        block = self.create_aside(aside_type, keys)\n        return block", "response": "Create an XBlockAside in this runtime."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a string of XML returning a usage id.", "response": "def parse_xml_string(self, xml, id_generator=None):\n        \"\"\"Parse a string of XML, returning a usage id.\"\"\"\n        if id_generator is not None:\n            warnings.warn(\n                \"Passing an id_generator directly is deprecated \"\n                \"in favor of constructing the Runtime with the id_generator\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n        id_generator = id_generator or self.id_generator\n        if isinstance(xml, six.binary_type):\n            io_type = BytesIO\n        else:\n            io_type = StringIO\n        return self.parse_xml_file(io_type(xml), id_generator)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing an open XML file returning a usage id.", "response": "def parse_xml_file(self, fileobj, id_generator=None):\n        \"\"\"Parse an open XML file, returning a usage id.\"\"\"\n        root = etree.parse(fileobj).getroot()\n        usage_id = self._usage_id_from_node(root, None, id_generator)\n        return usage_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _usage_id_from_node(self, node, parent_id, id_generator=None):\n        if id_generator is not None:\n            warnings.warn(\n                \"Passing an id_generator directly is deprecated \"\n                \"in favor of constructing the Runtime with the id_generator\",\n                DeprecationWarning,\n                stacklevel=3,\n            )\n\n        id_generator = id_generator or self.id_generator\n\n        block_type = node.tag\n        # remove xblock-family from elements\n        node.attrib.pop('xblock-family', None)\n        # TODO: a way for this node to be a usage to an existing definition?\n        def_id = id_generator.create_definition(block_type)\n        usage_id = id_generator.create_usage(def_id)\n        keys = ScopeIds(None, block_type, def_id, usage_id)\n        block_class = self.mixologist.mix(self.load_block_type(block_type))\n        # pull the asides out of the xml payload\n        aside_children = []\n        for child in node.iterchildren():\n            # get xblock-family from node\n            xblock_family = child.attrib.pop('xblock-family', None)\n            if xblock_family:\n                xblock_family = self._family_id_to_superclass(xblock_family)\n                if issubclass(xblock_family, XBlockAside):\n                    aside_children.append(child)\n        # now process them & remove them from the xml payload\n        for child in aside_children:\n            self._aside_from_xml(child, def_id, usage_id, id_generator)\n            node.remove(child)\n        block = block_class.parse_xml(node, self, keys, id_generator)\n        block.parent = parent_id\n        block.save()\n        return usage_id", "response": "Create a new usage id from an XML dom node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an aside from the xml and attach it to the given block_def_id and block_usage_id", "response": "def _aside_from_xml(self, node, block_def_id, block_usage_id, id_generator):\n        \"\"\"\n        Create an aside from the xml and attach it to the given block\n        \"\"\"\n        id_generator = id_generator or self.id_generator\n\n        aside_type = node.tag\n        aside_class = self.load_aside_type(aside_type)\n        aside_def_id, aside_usage_id = id_generator.create_aside(block_def_id, block_usage_id, aside_type)\n        keys = ScopeIds(None, aside_type, aside_def_id, aside_usage_id)\n        aside = aside_class.parse_xml(node, self, keys, id_generator)\n        aside.save()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_node_as_child(self, block, node, id_generator=None):\n        usage_id = self._usage_id_from_node(node, block.scope_ids.usage_id, id_generator)\n        block.children.append(usage_id)", "response": "Adds a node as a child of the given block."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports the block to XML writing the XML to xmlfile.", "response": "def export_to_xml(self, block, xmlfile):\n        \"\"\"\n        Export the block to XML, writing the XML to `xmlfile`.\n        \"\"\"\n        root = etree.Element(\"unknown_root\", nsmap=XML_NAMESPACES)\n        tree = etree.ElementTree(root)\n        block.add_xml_to_node(root)\n        # write asides as children\n        for aside in self.get_asides(block):\n            if aside.needs_serialization():\n                aside_node = etree.Element(\"unknown_root\", nsmap=XML_NAMESPACES)\n                aside.add_xml_to_node(aside_node)\n                block.append(aside_node)\n        tree.write(xmlfile, xml_declaration=True, pretty_print=True, encoding='utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a node to the block as a child node of node.", "response": "def add_block_as_child_node(self, block, node):\n        \"\"\"\n        Export `block` as a child node of `node`.\n        \"\"\"\n        child = etree.SubElement(node, \"unknown\")\n        block.add_xml_to_node(child)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, block, view_name, context=None):\n        # Set the active view so that :function:`render_child` can use it\n        # as a default\n        old_view_name = self._view_name\n        self._view_name = view_name\n        try:\n\n            view_fn = getattr(block, view_name, None)\n            if view_fn is None:\n                view_fn = getattr(block, \"fallback_view\", None)\n                if view_fn is None:\n                    raise NoSuchViewError(block, view_name)\n                view_fn = functools.partial(view_fn, view_name)\n\n            frag = view_fn(context)\n\n            # Explicitly save because render action may have changed state\n            block.save()\n            updated_frag = self.wrap_xblock(block, view_name, frag, context)\n            return self.render_asides(block, view_name, updated_frag, context)\n        finally:\n            # Reset the active view to what it was before entering this method\n            self._view_name = old_view_name", "response": "Render a block by invoking its view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_child(self, child, view_name=None, context=None):\n        return child.render(view_name or self._view_name, context)", "response": "A shortcut to render a child block."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_children(self, block, view_name=None, context=None):\n        results = []\n        for child_id in block.children:\n            child = self.get_block(child_id)\n            result = self.render_child(child, view_name, context)\n            results.append(result)\n        return results", "response": "Render a block s children returning a list of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps the xblock into a div", "response": "def wrap_xblock(self, block, view, frag, context):  # pylint: disable=W0613\n        \"\"\"\n        Creates a div which identifies the xblock and writes out the json_init_args into a script tag.\n\n        If there's a `wrap_child` method, it calls that with a deprecation warning.\n\n        The default implementation creates a frag to wraps frag w/ a div identifying the xblock. If you have\n        javascript, you'll need to override this impl\n        \"\"\"\n        if hasattr(self, 'wrap_child'):\n            log.warning(\"wrap_child is deprecated in favor of wrap_xblock and wrap_aside %s\", self.__class__)\n            return self.wrap_child(block, view, frag, context)  # pylint: disable=no-member\n\n        extra_data = {'name': block.name} if block.name else {}\n        return self._wrap_ele(block, view, frag, extra_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_aside(self, block, aside, view, frag, context):  # pylint: disable=unused-argument\n        return self._wrap_ele(\n            aside, view, frag, {\n                'block_id': block.scope_ids.usage_id,\n                'url_selector': 'asideBaseUrl',\n            })", "response": "Creates a div which identifies the aside and writes out the json_init_args into a script tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps an element in a fragment.", "response": "def _wrap_ele(self, block, view, frag, extra_data=None):\n        \"\"\"\n        Does the guts of the wrapping the same way for both xblocks and asides. Their\n        wrappers provide other info in extra_data which gets put into the dom data- attrs.\n        \"\"\"\n        wrapped = Fragment()\n        data = {\n            'usage': block.scope_ids.usage_id,\n            'block-type': block.scope_ids.block_type,\n        }\n        data.update(extra_data)\n\n        if frag.js_init_fn:\n            data['init'] = frag.js_init_fn\n            data['runtime-version'] = frag.js_init_version\n\n        json_init = \"\"\n        # TODO/Note: We eventually want to remove: hasattr(frag, 'json_init_args')\n        # However, I'd like to maintain backwards-compatibility with older XBlock\n        # for at least a little while so as not to adversely effect developers.\n        # pmitros/Jun 28, 2014.\n        if hasattr(frag, 'json_init_args') and frag.json_init_args is not None:\n            json_init = (\n                '<script type=\"json/xblock-args\" class=\"xblock_json_init_args\">'\n                '{data}</script>'\n            ).format(data=json.dumps(frag.json_init_args))\n\n        block_css_entrypoint = block.entry_point.replace('.', '-')\n        css_classes = [\n            block_css_entrypoint,\n            '{}-{}'.format(block_css_entrypoint, view),\n        ]\n\n        html = \"<div class='{}'{properties}>{body}{js}</div>\".format(\n            markupsafe.escape(' '.join(css_classes)),\n            properties=\"\".join(\" data-%s='%s'\" % item for item in list(data.items())),\n            body=frag.body_html(),\n            js=json_init)\n\n        wrapped.add_content(html)\n        wrapped.add_fragment_resources(frag)\n        return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_aside(self, block_type, keys):\n        aside_cls = XBlockAside.load_class(block_type)\n        return aside_cls(runtime=self, scope_ids=keys)", "response": "Create an aside instance of the given block type and keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all of the asides that will decorate this block.", "response": "def get_asides(self, block):\n        \"\"\"\n        Return instances for all of the asides that will decorate this `block`.\n\n        Arguments:\n            block (:class:`.XBlock`): The block to render retrieve asides for.\n\n        Returns:\n            List of XBlockAside instances\n        \"\"\"\n        aside_instances = [\n            self.get_aside_of_type(block, aside_type)\n            for aside_type in self.applicable_aside_types(block)\n        ]\n        return [\n            aside_instance for aside_instance in aside_instances\n            if aside_instance.should_apply_to_block(block)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the aside of the given aside_type which might be decorating this block.", "response": "def get_aside_of_type(self, block, aside_type):\n        \"\"\"\n        Return the aside of the given aside_type which might be decorating this `block`.\n\n        Arguments:\n            block (:class:`.XBlock`): The block to retrieve asides for.\n            aside_type (`str`): the type of the aside\n        \"\"\"\n        # TODO: This function will need to be extended if we want to allow:\n        #   a) XBlockAsides to statically indicated which types of blocks they can comment on\n        #   b) XBlockRuntimes to limit the selection of asides to a subset of the installed asides\n        #   c) Optimize by only loading asides that actually decorate a particular view\n\n        if self.id_generator is None:\n            raise Exception(\"Runtimes must be supplied with an IdGenerator to load XBlockAsides.\")\n\n        usage_id = block.scope_ids.usage_id\n\n        aside_cls = self.load_aside_type(aside_type)\n        definition_id = self.id_reader.get_definition_id(usage_id)\n        aside_def_id, aside_usage_id = self.id_generator.create_aside(definition_id, usage_id, aside_type)\n        scope_ids = ScopeIds(self.user_id, aside_type, aside_def_id, aside_usage_id)\n        return aside_cls(runtime=self, scope_ids=scope_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_asides(self, block, view_name, frag, context):\n        aside_frag_fns = []\n        for aside in self.get_asides(block):\n            aside_view_fn = aside.aside_view_declaration(view_name)\n            if aside_view_fn is not None:\n                aside_frag_fns.append((aside, aside_view_fn))\n        if aside_frag_fns:\n            # layout (overideable by other runtimes)\n            return self.layout_asides(block, context, frag, view_name, aside_frag_fns)\n        return frag", "response": "Render all of the asides in the block into the frag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting and layout the asides wrt the block s frag.", "response": "def layout_asides(self, block, context, frag, view_name, aside_frag_fns):\n        \"\"\"\n        Execute and layout the aside_frags wrt the block's frag. Runtimes should feel free to override this\n        method to control execution, place, and style the asides appropriately for their application\n\n        This default method appends the aside_frags after frag. If you override this, you must\n        call wrap_aside around each aside as per this function.\n\n        Args:\n            block (XBlock): the block being rendered\n            frag (html): The result from rendering the block\n            aside_frag_fns list((aside, aside_fn)): The asides and closures for rendering to call\n        \"\"\"\n        result = Fragment(frag.content)\n        result.add_fragment_resources(frag)\n\n        for aside, aside_fn in aside_frag_fns:\n            aside_frag = self.wrap_aside(block, aside, view_name, aside_fn(block, context), context)\n            aside.save()\n            result.add_content(aside_frag.content)\n            result.add_fragment_resources(aside_frag)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle(self, block, handler_name, request, suffix=''):\n        handler = getattr(block, handler_name, None)\n        if handler and getattr(handler, '_is_xblock_handler', False):\n            # Cache results of the handler call for later saving\n            results = handler(request, suffix)\n        else:\n            fallback_handler = getattr(block, \"fallback_handler\", None)\n            if fallback_handler and getattr(fallback_handler, '_is_xblock_handler', False):\n                # Cache results of the handler call for later saving\n                results = fallback_handler(handler_name, request, suffix)\n            else:\n                raise NoSuchHandlerError(\"Couldn't find handler %r for %r\" % (handler_name, block))\n\n        # Write out dirty fields\n        block.save()\n        return results", "response": "Handles any calls to the specified handler_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a service object for the given service name.", "response": "def service(self, block, service_name):\n        \"\"\"Return a service, or None.\n\n        Services are objects implementing arbitrary other interfaces.  They are\n        requested by agreed-upon names, see [XXX TODO] for a list of possible\n        services.  The object returned depends on the service requested.\n\n        XBlocks must announce their intention to request services with the\n        `XBlock.needs` or `XBlock.wants` decorators.  Use `needs` if you assume\n        that the service is available, or `wants` if your code is flexible and\n        can accept a None from this method.\n\n        Runtimes can override this method if they have different techniques for\n        finding and delivering services.\n\n        Arguments:\n            block (XBlock): this block's class will be examined for service\n                decorators.\n            service_name (str): the name of the service requested.\n\n        Returns:\n            An object implementing the requested service, or None.\n\n        \"\"\"\n        declaration = block.service_declaration(service_name)\n        if declaration is None:\n            raise NoSuchServiceError(\"Service {!r} was not requested.\".format(service_name))\n        service = self._services.get(service_name)\n        if service is None and declaration == \"need\":\n            raise NoSuchServiceError(\"Service {!r} is not available.\".format(service_name))\n        return service"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying the block for the given path.", "response": "def querypath(self, block, path):\n        \"\"\"An XPath-like interface to `query`.\"\"\"\n        class BadPath(Exception):\n            \"\"\"Bad path exception thrown when path cannot be found.\"\"\"\n            pass\n        results = self.query(block)\n        ROOT, SEP, WORD, FINAL = six.moves.range(4)               # pylint: disable=C0103\n        state = ROOT\n        lexer = RegexLexer(\n            (\"dotdot\", r\"\\.\\.\"),\n            (\"dot\", r\"\\.\"),\n            (\"slashslash\", r\"//\"),\n            (\"slash\", r\"/\"),\n            (\"atword\", r\"@\\w+\"),\n            (\"word\", r\"\\w+\"),\n            (\"err\", r\".\"),\n        )\n        for tokname, toktext in lexer.lex(path):\n            if state == FINAL:\n                # Shouldn't be any tokens after a last token.\n                raise BadPath()\n            if tokname == \"dotdot\":\n                # .. (parent)\n                if state == WORD:\n                    raise BadPath()\n                results = results.parent()\n                state = WORD\n            elif tokname == \"dot\":\n                # . (current node)\n                if state == WORD:\n                    raise BadPath()\n                state = WORD\n            elif tokname == \"slashslash\":\n                # // (descendants)\n                if state == SEP:\n                    raise BadPath()\n                if state == ROOT:\n                    raise NotImplementedError()\n                results = results.descendants()\n                state = SEP\n            elif tokname == \"slash\":\n                # / (here)\n                if state == SEP:\n                    raise BadPath()\n                if state == ROOT:\n                    raise NotImplementedError()\n                state = SEP\n            elif tokname == \"atword\":\n                # @xxx (attribute access)\n                if state != SEP:\n                    raise BadPath()\n                results = results.attr(toktext[1:])\n                state = FINAL\n            elif tokname == \"word\":\n                # xxx (tag selection)\n                if state != SEP:\n                    raise BadPath()\n                results = results.children().tagged(toktext)\n                state = WORD\n            else:\n                raise BadPath(\"Invalid thing: %r\" % toktext)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _family_id_to_superclass(self, family_id):\n        for family in [XBlock, XBlockAside]:\n            if family_id == family.entry_point:\n                return family\n        raise ValueError('No such family: {}'.format(family_id))", "response": "Temporary hardcoded mapping from serialized family id to class XBlock."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _object_with_attr(self, name):\n        for obj in self._objects:\n            if hasattr(obj, name):\n                return obj\n\n        raise AttributeError(\"No object has attribute {!r}\".format(name))", "response": "Returns the first object that has the attribute name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mix(self, cls):\n\n        if hasattr(cls, 'unmixed_class'):\n            base_class = cls.unmixed_class\n            old_mixins = cls.__bases__[1:]  # Skip the original unmixed class\n            mixins = old_mixins + tuple(\n                mixin\n                for mixin in self._mixins\n                if mixin not in old_mixins\n            )\n        else:\n            base_class = cls\n            mixins = self._mixins\n\n        mixin_key = (base_class, mixins)\n\n        if mixin_key not in _CLASS_CACHE:\n            # Only lock if we're about to make a new class\n            with _CLASS_CACHE_LOCK:\n                # Use setdefault so that if someone else has already\n                # created a class before we got the lock, we don't\n                # overwrite it\n                return _CLASS_CACHE.setdefault(mixin_key, type(\n                    base_class.__name__ + str('WithMixins'),  # type() requires native str\n                    (base_class, ) + mixins,\n                    {'unmixed_class': base_class}\n                ))\n        else:\n            return _CLASS_CACHE[mixin_key]", "response": "Returns a subclass of cls mixed with self. mixins."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lex(self, text):\n        for match in self.regex.finditer(text):\n            name = match.lastgroup\n            yield (name, match.group(name))", "response": "Iterator that tokenizes text and yields up tokens as they are found"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strftime(self, dtime, format):      # pylint: disable=redefined-builtin\n        format = self.STRFTIME_FORMATS.get(format + \"_FORMAT\", format)\n        if six.PY2 and isinstance(format, six.text_type):\n            format = format.encode(\"utf8\")\n        timestring = dtime.strftime(format)\n        if six.PY2:\n            timestring = timestring.decode(\"utf8\")\n        return timestring", "response": "Locale - aware strftime with format short - cuts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch to the appropriate gettext method to handle text objects.", "response": "def ugettext(self):\n        \"\"\"\n        Dispatch to the appropriate gettext method to handle text objects.\n\n        Note that under python 3, this uses `gettext()`, while under python 2,\n        it uses `ugettext()`.  This should not be used with bytestrings.\n        \"\"\"\n        # pylint: disable=no-member\n        if six.PY2:\n            return self._translations.ugettext\n        else:\n            return self._translations.gettext"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndispatch to the appropriate ungettext method to handle text objects.", "response": "def ungettext(self):\n        \"\"\"\n        Dispatch to the appropriate ngettext method to handle text objects.\n\n        Note that under python 3, this uses `ngettext()`, while under python 2,\n        it uses `ungettext()`.  This should not be used with bytestrings.\n        \"\"\"\n        # pylint: disable=no-member\n        if six.PY2:\n            return self._translations.ungettext\n        else:\n            return self._translations.ngettext"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the object from the cache.", "response": "def load(self, instance, xblock):\n        \"\"\"\n        Get the filesystem for the field specified in 'instance' and the\n        xblock in 'xblock' It is locally scoped.\n        \"\"\"\n\n        # TODO: Get xblock from context, once the plumbing is piped through\n        if djpyfs:\n            return djpyfs.get_filesystem(scope_key(instance, xblock))\n        else:\n            # The reference implementation relies on djpyfs\n            # https://github.com/edx/django-pyfs\n            # For Django runtimes, you may use this reference\n            # implementation. Otherwise, you will need to\n            # patch pyfilesystem yourself to implement get_url.\n            raise NotImplementedError(\"djpyfs not available\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef emit_completion(self, completion_percent):\n        completion_mode = XBlockCompletionMode.get_mode(self)\n        if not self.has_custom_completion or completion_mode != XBlockCompletionMode.COMPLETABLE:\n            raise AttributeError(\n                \"Using `emit_completion` requires `has_custom_completion == True` (was {}) \"\n                \"and `completion_mode == 'completable'` (was {})\".format(\n                    self.has_custom_completion, completion_mode,\n                )\n            )\n\n        if completion_percent is None or not 0.0 <= completion_percent <= 1.0:\n            raise ValueError(\"Completion percent must be in [0.0; 1.0] interval, {} given\".format(completion_percent))\n\n        self.runtime.publish(\n            self,\n            'completion',\n            {'completion': completion_percent},\n        )", "response": "Emits completion event through the completion API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has(self, block, name):\n        try:\n            self.get(block, name)\n            return True\n        except KeyError:\n            return False", "response": "Return whether or not the field named name has a non - default value for the XBlock block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate many fields on an XBlock simultaneously.", "response": "def set_many(self, block, update_dict):\n        \"\"\"\n        Update many fields on an XBlock simultaneously.\n\n        :param block: the block to update\n        :type block: :class:`~xblock.core.XBlock`\n        :param update_dict: A map of field names to their new values\n        :type update_dict: dict\n        \"\"\"\n        for key, value in six.iteritems(update_dict):\n            self.set(block, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _field_data(self, block, name):\n        scope = block.fields[name].scope\n\n        if scope not in self._scope_mappings:\n            raise InvalidScopeError(scope)\n\n        return self._scope_mappings[scope]", "response": "Return the field data for the field name on the block."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_response(self, **kwargs):\n        return Response(\n            json.dumps({\"error\": self.message}),  # pylint: disable=exception-message-attribute\n            status_code=self.status_code,\n            content_type=\"application/json\",\n            charset=\"utf-8\",\n            **kwargs\n        )", "response": "Returns a Response object containing this object s status code and a\n            JSON object containing the key error and the value of this object s\n            error message in the body."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json_handler(cls, func):\n        @cls.handler\n        @functools.wraps(func)\n        def wrapper(self, request, suffix=''):\n            \"\"\"The wrapper function `json_handler` returns.\"\"\"\n            if request.method != \"POST\":\n                return JsonHandlerError(405, \"Method must be POST\").get_response(allow=[\"POST\"])\n            try:\n                request_json = json.loads(request.body)\n            except ValueError:\n                return JsonHandlerError(400, \"Invalid JSON\").get_response()\n            try:\n                response = func(self, request_json, suffix)\n            except JsonHandlerError as err:\n                return err.get_response()\n            if isinstance(response, Response):\n                return response\n            else:\n                return Response(json.dumps(response), content_type='application/json', charset='utf8')\n        return wrapper", "response": "A decorator that wraps a function to consume and produce JSON."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle request with this block s runtime.", "response": "def handle(self, handler_name, request, suffix=''):\n        \"\"\"Handle `request` with this block's runtime.\"\"\"\n        return self.runtime.handle(self, handler_name, request, suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _combined_services(cls):  # pylint: disable=no-self-argument\n        # The class declares what services it desires. To deal with subclasses,\n        # especially mixins, properly, we have to walk up the inheritance\n        # hierarchy, and combine all the declared services into one dictionary.\n        combined = {}\n        for parent in reversed(cls.mro()):\n            combined.update(getattr(parent, \"_services_requested\", {}))\n        return combined", "response": "A dictionary that collects all _services_requested by all ancestors of this class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parent(self):\n        if not self.has_cached_parent:\n            if self.parent is not None:\n                self._parent_block = self.runtime.get_block(self.parent)\n            else:\n                self._parent_block = None\n            self._parent_block_id = self.parent\n        return self._parent_block", "response": "Return the parent block of this block or None if there isn t one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_child(self, usage_id):\n        if usage_id in self._child_cache:\n            return self._child_cache[usage_id]\n\n        child_block = self.runtime.get_block(usage_id, for_parent=self)\n        self._child_cache[usage_id] = child_block\n        return child_block", "response": "Return the child identified by usage_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns instantiated XBlocks for each of this blocks s children.", "response": "def get_children(self, usage_id_filter=None):\n        \"\"\"\n        Return instantiated XBlocks for each of this blocks ``children``.\n        \"\"\"\n        if not self.has_children:\n            return []\n\n        return [\n            self.get_child(usage_id)\n            for usage_id in self.children\n            if usage_id_filter is None or usage_id_filter(usage_id)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding children to node.", "response": "def add_children_to_node(self, node):\n        \"\"\"\n        Add children to etree.Element `node`.\n        \"\"\"\n        if self.has_children:\n            for child_id in self.children:\n                child = self.runtime.get_block(child_id)\n                self.runtime.add_block_as_child_node(child, node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse an xml node into an xblock.", "response": "def parse_xml(cls, node, runtime, keys, id_generator):\n        \"\"\"\n        Use `node` to construct a new block.\n\n        Arguments:\n            node (:class:`~xml.etree.ElementTree.Element`): The xml node to parse into an xblock.\n\n            runtime (:class:`.Runtime`): The runtime to use while parsing.\n\n            keys (:class:`.ScopeIds`): The keys identifying where this block\n                will store its data.\n\n            id_generator (:class:`.IdGenerator`): An object that will allow the\n                runtime to generate correct definition and usage ids for\n                children of this block.\n\n        \"\"\"\n        block = runtime.construct_xblock_from_class(cls, keys)\n\n        # The base implementation: child nodes become child blocks.\n        # Or fields, if they belong to the right namespace.\n        for child in node:\n            if child.tag is etree.Comment:\n                continue\n            qname = etree.QName(child)\n            tag = qname.localname\n            namespace = qname.namespace\n\n            if namespace == XML_NAMESPACES[\"option\"]:\n                cls._set_field_if_present(block, tag, child.text, child.attrib)\n            else:\n                block.runtime.add_node_as_child(block, child, id_generator)\n\n        # Attributes become fields.\n        for name, value in node.items():  # lxml has no iteritems\n            cls._set_field_if_present(block, name, value, {})\n\n        # Text content becomes \"content\", if such a field exists.\n        if \"content\" in block.fields and block.fields[\"content\"].scope == Scope.content:\n            text = node.text\n            if text:\n                text = text.strip()\n                if text:\n                    block.content = text\n\n        return block"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_field_if_present(cls, block, name, value, attrs):\n        if name in block.fields:\n            value = (block.fields[name]).from_string(value)\n            if \"none\" in attrs and attrs[\"none\"] == \"true\":\n                setattr(block, name, None)\n            else:\n                setattr(block, name, value)\n        else:\n            logging.warning(\"XBlock %s does not contain field %s\", type(block), name)", "response": "Sets the field block. name if block have such a field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the field to the node.", "response": "def _add_field(self, node, field_name, field):\n        \"\"\"\n        Add xml representation of field to node.\n\n        Depending on settings, it either stores the value of field\n        as an xml attribute or creates a separate child node.\n        \"\"\"\n        value = field.to_string(field.read_from(self))\n        text_value = \"\" if value is None else value\n\n        # Is the field type supposed to serialize the fact that the value is None to XML?\n        save_none_as_xml_attr = field.none_to_xml and value is None\n        field_attrs = {\"none\": \"true\"} if save_none_as_xml_attr else {}\n\n        if save_none_as_xml_attr or field.xml_node:\n            # Field will be output to XML as an separate element.\n            tag = etree.QName(XML_NAMESPACES[\"option\"], field_name)\n            elem = etree.SubElement(node, tag, field_attrs)\n            if field.xml_node:\n                # Only set the value if forced via xml_node;\n                # in all other cases, the value is None.\n                # Avoids an unnecessary XML end tag.\n                elem.text = text_value\n        else:\n            # Field will be output to XML as an attribute on the node.\n            node.set(field_name, text_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rescore(self, only_if_higher):\n\n        _ = self.runtime.service(self, 'i18n').ugettext\n\n        if not self.allows_rescore():\n            raise TypeError(_('Problem does not support rescoring: {}').format(self.location))\n\n        if not self.has_submitted_answer():\n            raise ValueError(_('Cannot rescore unanswered problem: {}').format(self.location))\n\n        new_score = self.calculate_score()\n        self._publish_grade(new_score, only_if_higher)", "response": "Rescore the assessment of the current state of the user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _publish_grade(self, score, only_if_higher=None):\n        grade_dict = {\n            'value': score.raw_earned,\n            'max_value': score.raw_possible,\n            'only_if_higher': only_if_higher,\n        }\n        self.runtime.publish(self, 'grade', grade_dict)", "response": "Publish a grade to the runtime."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a unique key for a given scope.", "response": "def scope_key(instance, xblock):\n    \"\"\"Generate a unique key for a scope that can be used as a\n    filename, in a URL, or in a KVS.\n\n    Our goal is to have a pretty, human-readable 1:1 encoding.\n\n    This encoding is as good as we can do. It's reversible, but not\n    trivial to reverse.\n\n    Encoding scheme:\n    Posix allows [A-Z][a-z][0-9]._-\n    We'd like to have a _concise_ representation for common punctuation\n    We're okay with a _non-concise_ representation for repeated or uncommon characters\n    We keep [A-z][a-z][0-9] as is.\n    We encode other common punctuation as pairs of ._-. This gives a total of 3*3=9 combinations.\n    We're pretty careful to keep this nice. Where possible, we double characters. The most common\n    other character (' ' and ':') are encoded as _- and -_\n    We separate field portions with /. This gives a natural directory\n    tree. This is nice in URLs and filenames (although not so nice in\n    urls.py)\n    If a field starts with punctuatation, we prefix a _. This prevents hidden files.\n\n    Uncommon characters, we encode as their ordinal value, surrounded by -.\n    For example, tilde would be -126-.\n\n    If a field is not used, we call it NONE.NONE. This does not\n    conflict with fields with the same name, since they are escaped to\n    NONE..NONE.\n\n    Sample keys:\n\n    Settings scope:\n      animationxblock..animation..d0..u0/settings__fs/NONE.NONE\n    User summary scope:\n      animationxblock..animation..d0..u0/uss__fs/NONE.NONE\n    User preferences, username is Aan.!a\n      animation/pref__fs/Aan.._33_a\n\n    \"\"\"\n    scope_key_dict = {}\n    scope_key_dict['name'] = instance.name\n    if instance.scope.user == UserScope.NONE or instance.scope.user == UserScope.ALL:\n        pass\n    elif instance.scope.user == UserScope.ONE:\n        scope_key_dict['user'] = six.text_type(xblock.scope_ids.user_id)\n    else:\n        raise NotImplementedError()\n\n    if instance.scope.block == BlockScope.TYPE:\n        scope_key_dict['block'] = six.text_type(xblock.scope_ids.block_type)\n    elif instance.scope.block == BlockScope.USAGE:\n        scope_key_dict['block'] = six.text_type(xblock.scope_ids.usage_id)\n    elif instance.scope.block == BlockScope.DEFINITION:\n        scope_key_dict['block'] = six.text_type(xblock.scope_ids.def_id)\n    elif instance.scope.block == BlockScope.ALL:\n        pass\n    else:\n        raise NotImplementedError()\n\n    replacements = itertools.product(\"._-\", \"._-\")\n    substitution_list = dict(six.moves.zip(\"./\\\\,_ +:-\", (\"\".join(x) for x in replacements)))\n    # Above runs in 4.7us, and generates a list of common substitutions:\n    # {' ': '_-', '+': '-.', '-': '--', ',': '_.', '/': '._', '.': '..', ':': '-_', '\\\\': '.-', '_': '__'}\n\n    key_list = []\n\n    def encode(char):\n        \"\"\"\n        Replace all non-alphanumeric characters with -n- where n\n        is their Unicode codepoint.\n        TODO: Test for UTF8 which is not ASCII\n        \"\"\"\n        if char.isalnum():\n            return char\n        elif char in substitution_list:\n            return substitution_list[char]\n        else:\n            return \"_{}_\".format(ord(char))\n\n    for item in ['block', 'name', 'user']:\n        if item in scope_key_dict:\n            field = scope_key_dict[item]\n            # Prevent injection of \"..\", hidden files, or similar.\n            # First part adds a prefix. Second part guarantees\n            # continued uniqueness.\n            if field.startswith(\".\") or field.startswith(\"_\"):\n                field = \"_\" + field\n            field = \"\".join(encode(char) for char in field)\n        else:\n            field = \"NONE.NONE\"\n        key_list.append(field)\n\n    key = \"/\".join(key_list)\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scopes(cls):\n        # Why do we need this? This should either\n        # * Be bubbled to the places where it is used (AcidXBlock).\n        # * Be automatic. Look for all members of a type.\n        return [cls.USAGE, cls.DEFINITION, cls.TYPE, cls.ALL]", "response": "Return a list of valid and understood class scopes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef default(self):\n        if self.MUTABLE:\n            return copy.deepcopy(self._default)\n        else:\n            return self._default", "response": "Returns the static value that this defaults to."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_cached_value(self, xblock, value):\n        # pylint: disable=protected-access\n        if not hasattr(xblock, '_field_data_cache'):\n            xblock._field_data_cache = {}\n        xblock._field_data_cache[self.name] = value", "response": "Store a value in the xblock s cache creating the cache if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _del_cached_value(self, xblock):\n        # pylint: disable=protected-access\n        if hasattr(xblock, '_field_data_cache') and self.name in xblock._field_data_cache:\n            del xblock._field_data_cache[self.name]", "response": "Remove a value from the xblock s cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting this field to dirty on the xblock.", "response": "def _mark_dirty(self, xblock, value):\n        \"\"\"Set this field to dirty on the xblock.\"\"\"\n        # pylint: disable=protected-access\n\n        # Deep copy the value being marked as dirty, so that there\n        # is a baseline to check against when saving later\n        if self not in xblock._dirty_fields:\n            xblock._dirty_fields[self] = copy.deepcopy(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether this field should be saved when xblock. save is called.", "response": "def _is_dirty(self, xblock):\n        \"\"\"\n        Return whether this field should be saved when xblock.save() is called\n        \"\"\"\n        # pylint: disable=protected-access\n        if self not in xblock._dirty_fields:\n            return False\n\n        baseline = xblock._dirty_fields[self]\n        return baseline is EXPLICITLY_SET or xblock._field_data_cache[self.name] != baseline"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_or_enforce_type(self, value):\n        if self._enable_enforce_type:\n            return self.enforce_type(value)\n\n        try:\n            new_value = self.enforce_type(value)\n        except:  # pylint: disable=bare-except\n            message = \"The value {!r} could not be enforced ({})\".format(\n                value, traceback.format_exc().splitlines()[-1])\n            warnings.warn(message, FailingEnforceTypeWarning, stacklevel=3)\n        else:\n            try:\n                equal = value == new_value\n            except TypeError:\n                equal = False\n            if not equal:\n                message = \"The value {!r} would be enforced to {!r}\".format(\n                    value, new_value)\n                warnings.warn(message, ModifyingEnforceTypeWarning, stacklevel=3)\n\n        return value", "response": "Check if the value is enforced and return the result or call it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calculate_unique_id(self, xblock):\n        key = scope_key(self, xblock)\n        return hashlib.sha1(key.encode('utf-8')).hexdigest()", "response": "Calculates the unique ID for the given field in the given scope."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the default value for caching.", "response": "def _get_default_value_to_cache(self, xblock):\n        \"\"\"\n        Perform special logic to provide a field's default value for caching.\n        \"\"\"\n        try:\n            # pylint: disable=protected-access\n            return self.from_json(xblock._field_data.default(xblock, self.name))\n        except KeyError:\n            if self._default is UNIQUE_ID:\n                return self._check_or_enforce_type(self._calculate_unique_id(xblock))\n            else:\n                return self.default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a JSON serialized string representation of the value.", "response": "def to_string(self, value):\n        \"\"\"\n        Return a JSON serialized string representation of the value.\n        \"\"\"\n        self._warn_deprecated_outside_JSONField()\n        value = json.dumps(\n            self.to_json(value),\n            indent=2,\n            sort_keys=True,\n            separators=(',', ': '),\n        )\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a native value from a YAML serialized string representation.", "response": "def from_string(self, serialized):\n        \"\"\"\n        Returns a native value from a YAML serialized string representation.\n        Since YAML is a superset of JSON, this is the inverse of to_string.)\n        \"\"\"\n        self._warn_deprecated_outside_JSONField()\n        value = yaml.safe_load(serialized)\n        return self.enforce_type(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the serialized value for this field from the specified xblock.", "response": "def read_json(self, xblock):\n        \"\"\"\n        Retrieve the serialized value for this field from the specified xblock\n        \"\"\"\n        self._warn_deprecated_outside_JSONField()\n        return self.to_json(self.read_from(xblock))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether this field has a non - default value on the supplied xblock.", "response": "def is_set_on(self, xblock):\n        \"\"\"\n        Return whether this field has a non-default value on the supplied xblock\n        \"\"\"\n        # pylint: disable=protected-access\n        return self._is_dirty(xblock) or xblock._field_data.has(xblock, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the object to a string.", "response": "def to_string(self, value):\n        \"\"\"\n        In python3, json.dumps() cannot sort keys of different types,\n        so preconvert None to 'null'.\n        \"\"\"\n        self.enforce_type(value)\n        if isinstance(value, dict) and None in value:\n            value = value.copy()\n            value['null'] = value[None]\n            del value[None]\n        return super(Dict, self).to_string(value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sanitize(self, value):\n        if isinstance(value, six.binary_type):\n            value = value.decode('utf-8')\n        if isinstance(value, six.text_type):\n            new_value = ''.join(ch for ch in value if self._valid_char(ch))\n        else:\n            return value\n        # The new string will be equivalent to the original string if no control characters are present.\n        # If equivalent, return the original string - some tests check for object equality instead of string equality.\n        return value if value == new_value else new_value", "response": "Sanitize the value for the attribute name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstringing gets serialized and deserialized without quote marks.", "response": "def to_string(self, value):\n        \"\"\"String gets serialized and deserialized without quote marks.\"\"\"\n        if isinstance(value, six.binary_type):\n            value = value.decode('utf-8')\n        return self.to_json(value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_json(self, value):\n        if self._enable_enforce_type:\n            value = self.enforce_type(value)\n        return super(XMLString, self).to_json(value)", "response": "Serialize the data ensuring that it is a basestring and that it is valid XML."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the ISO - formatted date string or None.", "response": "def from_json(self, value):\n        \"\"\"\n        Parse the date from an ISO-formatted date string, or None.\n        \"\"\"\n        if value is None:\n            return None\n\n        if isinstance(value, six.binary_type):\n            value = value.decode('utf-8')\n\n        if isinstance(value, six.text_type):\n            # Parser interprets empty string as now by default\n            if value == \"\":\n                return None\n            try:\n                value = dateutil.parser.parse(value)\n            except (TypeError, ValueError):\n                raise ValueError(\"Could not parse {} as a date\".format(value))\n\n        if not isinstance(value, datetime.datetime):\n            raise TypeError(\n                \"Value should be loaded from a string, a datetime object or None, not {}\".format(type(value))\n            )\n\n        if value.tzinfo is not None:  # pylint: disable=maybe-no-member\n            return value.astimezone(pytz.utc)  # pylint: disable=maybe-no-member\n        else:\n            return value.replace(tzinfo=pytz.utc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nserialize the date as an ISO - formatted date string or None.", "response": "def to_json(self, value):\n        \"\"\"\n        Serialize the date as an ISO-formatted date string, or None.\n        \"\"\"\n        if isinstance(value, datetime.datetime):\n            return value.strftime(self.DATETIME_FORMAT)\n        if value is None:\n            return None\n        raise TypeError(\"Value stored must be a datetime object, not {}\".format(type(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_script(pycode):\n    # Fix up the whitespace in pycode.\n    if pycode[0] == \"\\n\":\n        pycode = pycode[1:]\n    pycode.rstrip()\n    pycode = textwrap.dedent(pycode)\n\n    # execute it.\n    globs = {}\n    six.exec_(pycode, globs, globs)  # pylint: disable=W0122\n\n    return globs", "response": "Run the Python in pycode and return a dict of the resulting globals."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen a local resource.", "response": "def open_local_resource(cls, uri):\n        \"\"\"\n        Open a local resource.\n\n        The container calls this method when it receives a request for a\n        resource on a URL which was generated by Runtime.local_resource_url().\n        It will pass the URI from the original call to local_resource_url()\n        back to this method. The XBlock must parse this URI and return an open\n        file-like object for the resource.\n\n        For security reasons, the default implementation will return only a\n        very restricted set of file types, which must be located in a folder\n        that defaults to \"public\".  The location used for public resources can\n        be changed on a per-XBlock basis. XBlock authors who want to override\n        this behavior will need to take care to ensure that the method only\n        serves legitimate public resources. At the least, the URI should be\n        matched against a whitelist regex to ensure that you do not serve an\n        unauthorized resource.\n        \"\"\"\n\n        if isinstance(uri, six.binary_type):\n            uri = uri.decode('utf-8')\n\n        # If no resources_dir is set, then this XBlock cannot serve local resources.\n        if cls.resources_dir is None:\n            raise DisallowedFileError(\"This XBlock is not configured to serve local resources\")\n\n        # Make sure the path starts with whatever public_dir is set to.\n        if not uri.startswith(cls.public_dir + '/'):\n            raise DisallowedFileError(\"Only files from %r/ are allowed: %r\" % (cls.public_dir, uri))\n\n        # Disalow paths that have a '/.' component, as `/./` is a no-op and `/../`\n        # can be used to recurse back past the entry point of this XBlock.\n        if \"/.\" in uri:\n            raise DisallowedFileError(\"Only safe file names are allowed: %r\" % uri)\n\n        return pkg_resources.resource_stream(cls.__module__, os.path.join(cls.resources_dir, uri))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _class_tags(cls):  # pylint: disable=no-self-argument\n        class_tags = set()\n\n        for base in cls.mro()[1:]:  # pylint: disable=no-member\n            class_tags.update(getattr(base, '_class_tags', set()))\n\n        return class_tags", "response": "Collect the tags from all base classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a function that adds the words in tags as class tags to this class.", "response": "def tag(tags):\n        \"\"\"Returns a function that adds the words in `tags` as class tags to this class.\"\"\"\n        def dec(cls):\n            \"\"\"Add the words in `tags` as class tags to this class.\"\"\"\n            # Add in this class's tags\n            cls._class_tags.update(tags.replace(\",\", \" \").split())  # pylint: disable=protected-access\n            return cls\n        return dec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading all XBlock classes tagged with tag.", "response": "def load_tagged_classes(cls, tag, fail_silently=True):\n        \"\"\"\n        Produce a sequence of all XBlock classes tagged with `tag`.\n\n        fail_silently causes the code to simply log warnings if a\n        plugin cannot import. The goal is to be able to use part of\n        libraries from an XBlock (and thus have it installed), even if\n        the overall XBlock cannot be used (e.g. depends on Django in a\n        non-Django application). There is diagreement about whether\n        this is a good idea, or whether we should see failures early\n        (e.g. on startup or first page load), and in what\n        contexts. Hence, the flag.\n        \"\"\"\n        # Allow this method to access the `_class_tags`\n        # pylint: disable=W0212\n        for name, class_ in cls.load_classes(fail_silently):\n            if tag in class_._class_tags:\n                yield name, class_"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, view, context=None):\n        return self.runtime.render(self, view, context)", "response": "Render view with this block s runtime and the supplied context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ugettext(self, text):\n        runtime_service = self.runtime.service(self, \"i18n\")\n        runtime_ugettext = runtime_service.ugettext\n        return runtime_ugettext(text)", "response": "Translate a message or text into unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_xml_to_node(self, node):\n        super(XBlock, self).add_xml_to_node(node)\n        # Add children for each of our children.\n        self.add_children_to_node(node)", "response": "Add XML data to node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _combined_asides(cls):  # pylint: disable=no-self-argument\n        # The method declares what views it decorates. We rely on `dir`\n        # to handle subclasses and overrides.\n        combined_asides = defaultdict(None)\n        for _view_name, view_func in inspect.getmembers(cls, lambda attr: hasattr(attr, '_aside_for')):\n            aside_for = getattr(view_func, '_aside_for', [])\n            for view in aside_for:\n                combined_asides[view] = view_func.__name__\n        return combined_asides", "response": "A dictionary mapping XBlock view names to the aside methods that have been decorated with the specified view."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind and return a function object if one is an aside_view for the given view_name", "response": "def aside_view_declaration(self, view_name):\n        \"\"\"\n        Find and return a function object if one is an aside_view for the given view_name\n\n        Aside methods declare their view provision via @XBlockAside.aside_for(view_name)\n        This function finds those declarations for a block.\n\n        Arguments:\n            view_name (string): the name of the view requested.\n\n        Returns:\n            either the function or None\n        \"\"\"\n        if view_name in self._combined_asides:  # pylint: disable=unsupported-membership-test\n            return getattr(self, self._combined_asides[view_name])  # pylint: disable=unsubscriptable-object\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef needs_serialization(self):\n        return any(field.is_set_on(self) for field in six.itervalues(self.fields))", "response": "Return True if the aside has any data to serialize to XML at all."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, message):\n        if not isinstance(message, ValidationMessage):\n            raise TypeError(\"Argument must of type ValidationMessage\")\n        self.messages.append(message)", "response": "Adds a new validation message to this instance s list of messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_messages(self, validation):\n        if not isinstance(validation, Validation):\n            raise TypeError(\"Argument must be of type Validation\")\n\n        self.messages.extend(validation.messages)", "response": "Adds all the messages in the specified Validation object to this instance s messages array."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts to a json - serializable representation.", "response": "def to_json(self):\n        \"\"\"\n        Convert to a json-serializable representation.\n\n        Returns:\n            dict: A dict representation that is json-serializable.\n        \"\"\"\n        return {\n            \"xblock_id\": six.text_type(self.xblock_id),\n            \"messages\": [message.to_json() for message in self.messages],\n            \"empty\": self.empty\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requireCompatibleAPI():\n        if 'PyQt4.QtCore' in sys.modules:\n            import sip\n            for api in ('QVariant', 'QString'):\n                if sip.getapi(api) != 2:\n                    raise RuntimeError('%s API already set to V%d, but should be 2' % (api, sip.getapi(api)))", "response": "Check that PyQt4 s API is compatible with PySide s\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef byte_view(qimage, byteorder = 'little'):\n    raw = _qimage_or_filename_view(qimage)\n    result = raw.view(_np.uint8).reshape(raw.shape + (-1, ))\n    if byteorder and byteorder != _sys.byteorder:\n        result = result[...,::-1]\n    return result", "response": "Returns raw 3D view of the given QImage_s memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a 3D numpy. uint8 array of a given 32 - bit color QImage_ s memory.", "response": "def rgb_view(qimage, byteorder = 'big'):\n    \"\"\"Returns RGB view of a given 32-bit color QImage_'s memory.\n    Similarly to byte_view(), the result is a 3D numpy.uint8 array,\n    but reduced to the rgb dimensions (without alpha), and reordered\n    (using negative strides in the last dimension) to have the usual\n    [R,G,B] order.  The image must have 32 bit pixel size, i.e. be\n    RGB32, ARGB32, or ARGB32_Premultiplied.  (Note that in the latter\n    case, the values are of course premultiplied with alpha.)\n\n    The order of channels in the last axis depends on the `byteorder`,\n    which defaults to 'big', i.e. RGB order.  You may set the argument\n    `byteorder` to 'little' to get BGR, or use None which means\n    sys.byteorder here, i.e. return native order for the machine the\n    code is running on.\n\n    For your convenience, `qimage` may also be a filename, see\n    `Loading and Saving Images`_ in the documentation.\n\n    :param qimage: image whose memory shall be accessed via NumPy\n    :type qimage: QImage_ with 32-bit pixel type\n    :param byteorder: specify order of channels in last axis\n    :rtype: numpy.ndarray_ with shape (height, width, 3) and dtype uint8\"\"\"\n    if byteorder is None:\n        byteorder = _sys.byteorder\n    bytes = byte_view(qimage, byteorder)\n    if bytes.shape[2] != 4:\n        raise ValueError(\"For rgb_view, the image must have 32 bit pixel size (use RGB32, ARGB32, or ARGB32_Premultiplied)\")\n\n    if byteorder == 'little':\n        return bytes[...,:3] # strip A off BGRA\n    else:\n        return bytes[...,1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef alpha_view(qimage):\n    bytes = byte_view(qimage, byteorder = None)\n    if bytes.shape[2] != 4:\n        raise ValueError(\"For alpha_view, the image must have 32 bit pixel size (use RGB32, ARGB32, or ARGB32_Premultiplied)\")\n    return bytes[...,_bgra[3]]", "response": "Returns an alpha view of a given 32 - bit color QImage_ s memory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning recarray_ view of a given 32 - bit color QImage_s memory.", "response": "def recarray_view(qimage):\n    \"\"\"Returns recarray_ view of a given 32-bit color QImage_'s\n    memory.\n\n    The result is a 2D array with a complex record dtype, offering the\n    named fields 'r','g','b', and 'a' and corresponding long names.\n    Thus, each color components can be accessed either via string\n    indexing or via attribute lookup (through numpy.recarray_):\n\n    For your convenience, `qimage` may also be a filename, see\n    `Loading and Saving Images`_ in the documentation.\n\n    >>> from PyQt4.QtGui import QImage, qRgb\n    >>> qimg = QImage(320, 240, QImage.Format_ARGB32)\n    >>> qimg.fill(qRgb(12,34,56))\n    >>>\n    >>> import qimage2ndarray\n    >>> v = qimage2ndarray.recarray_view(qimg)\n    >>>\n    >>> red = v[\"r\"]\n    >>> red[10,10]\n    12\n    >>> pixel = v[10,10]\n    >>> pixel[\"r\"]\n    12\n    >>> (v.g == v[\"g\"]).all()\n    True\n    >>> (v.alpha == 255).all()\n    True\n\n    :param qimage: image whose memory shall be accessed via NumPy\n    :type qimage: QImage_ with 32-bit pixel type\n    :rtype: numpy.ndarray_ with shape (height, width) and dtype :data:`bgra_dtype`\"\"\"\n    raw = _qimage_or_filename_view(qimage)\n    if raw.itemsize != 4:\n        raise ValueError(\"For rgb_view, the image must have 32 bit pixel size (use RGB32, ARGB32, or ARGB32_Premultiplied)\")\n    return raw.view(bgra_dtype, _np.recarray)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a 2D numpy array gray into a 32 - bit indexed QImage_ object.", "response": "def gray2qimage(gray, normalize = False):\n    \"\"\"Convert the 2D numpy array `gray` into a 8-bit, indexed QImage_\n    with a gray colormap.  The first dimension represents the vertical\n    image axis.\n\n    The parameter `normalize` can be used to normalize an image's\n    value range to 0..255:\n\n    `normalize` = (nmin, nmax):\n      scale & clip image values from nmin..nmax to 0..255\n\n    `normalize` = nmax:\n      lets nmin default to zero, i.e. scale & clip the range 0..nmax\n      to 0..255\n\n    `normalize` = True:\n      scale image values to 0..255 (same as passing (gray.min(),\n      gray.max()))\n\n    If the source array `gray` contains masked values, the result will\n    have only 255 shades of gray, and one color map entry will be used\n    to make the corresponding pixels transparent.\n\n    A full alpha channel cannot be supported with indexed images;\n    instead, use `array2qimage` to convert into a 32-bit QImage.\n\n    :param gray: image data which should be converted (copied) into a QImage_\n    :type gray: 2D or 3D numpy.ndarray_ or `numpy.ma.array <masked arrays>`_\n    :param normalize: normalization parameter (see above, default: no value changing)\n    :type normalize: bool, scalar, or pair\n    :rtype: QImage_ with RGB32 or ARGB32 format\"\"\"\n    if _np.ndim(gray) != 2:\n        raise ValueError(\"gray2QImage can only convert 2D arrays\" +\n                         \" (try using array2qimage)\" if _np.ndim(gray) == 3 else \"\")\n\n    h, w = gray.shape\n    result = _qt.QImage(w, h, _qt.QImage.Format_Indexed8)\n\n    if not _np.ma.is_masked(gray):\n        for i in range(256):\n            result.setColor(i, _qt.qRgb(i,i,i))\n\n        _qimageview(result)[:] = _normalize255(gray, normalize)\n    else:\n        # map gray value 1 to gray value 0, in order to make room for\n        # transparent colormap entry:\n        result.setColor(0, _qt.qRgb(0,0,0))\n        for i in range(2, 256):\n            result.setColor(i-1, _qt.qRgb(i,i,i))\n\n        _qimageview(result)[:] = _normalize255(gray, normalize, clip = (1, 255)) - 1\n\n        result.setColor(255, 0)\n        _qimageview(result)[gray.mask] = 255\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a 2D numpy array into a 32 - bit QImage_.", "response": "def array2qimage(array, normalize = False):\n    \"\"\"Convert a 2D or 3D numpy array into a 32-bit QImage_.  The\n    first dimension represents the vertical image axis; the optional\n    third dimension is supposed to contain 1-4 channels:\n\n    ========= ===================\n    #channels interpretation\n    ========= ===================\n            1 scalar/gray\n            2 scalar/gray + alpha\n            3 RGB\n            4 RGB + alpha\n    ========= ===================\n\n    Scalar data will be converted into corresponding gray RGB triples;\n    if you want to convert to an (indexed) 8-bit image instead, use\n    `gray2qimage` (which cannot support an alpha channel though).\n\n    The parameter `normalize` can be used to normalize an image's\n    value range to 0..255:\n\n    `normalize` = (nmin, nmax):\n      scale & clip image values from nmin..nmax to 0..255\n\n    `normalize` = nmax:\n      lets nmin default to zero, i.e. scale & clip the range 0..nmax\n      to 0..255\n\n    `normalize` = True:\n      scale image values to 0..255 (same as passing (array.min(),\n      array.max()))\n\n    If `array` contains masked values, the corresponding pixels will\n    be transparent in the result.  Thus, the result will be of\n    QImage.Format_ARGB32 if the input already contains an alpha\n    channel (i.e. has shape (H,W,4)) or if there are masked pixels,\n    and QImage.Format_RGB32 otherwise.\n\n    :param array: image data which should be converted (copied) into a QImage_\n    :type array: 2D or 3D numpy.ndarray_ or `numpy.ma.array <masked arrays>`_\n    :param normalize: normalization parameter (see above, default: no value changing)\n    :type normalize: bool, scalar, or pair\n    :rtype: QImage_ with RGB32 or ARGB32 format\"\"\"\n    if _np.ndim(array) == 2:\n        array = array[...,None]\n    elif _np.ndim(array) != 3:\n        raise ValueError(\"array2qimage can only convert 2D or 3D arrays (got %d dimensions)\" % _np.ndim(array))\n    if array.shape[2] not in (1, 2, 3, 4):\n        raise ValueError(\"array2qimage expects the last dimension to contain exactly one (scalar/gray), two (gray+alpha), three (R,G,B), or four (R,G,B,A) channels\")\n\n    h, w, channels = array.shape\n\n    hasAlpha = _np.ma.is_masked(array) or channels in (2, 4)\n    fmt = _qt.QImage.Format_ARGB32 if hasAlpha else _qt.QImage.Format_RGB32\n\n    result = _qt.QImage(w, h, fmt)\n\n    array = _normalize255(array, normalize)\n\n    if channels >= 3:\n        rgb_view(result)[:] = array[...,:3]\n    else:\n        rgb_view(result)[:] = array[...,:1] # scalar data\n\n    alpha = alpha_view(result)\n\n    if channels in (2, 4):\n        alpha[:] = array[...,-1]\n    else:\n        alpha[:] = 255\n\n    if _np.ma.is_masked(array):\n        alpha[:]  *= _np.logical_not(_np.any(array.mask, axis = -1))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imread(filename, masked = False):\n    qImage = _qt.QImage(filename)\n\n    if qImage.isNull():\n        raise IOError('loading %r failed' % filename)\n\n    isGray = qImage.isGrayscale()\n    if isGray and qImage.depth() == 8:\n        return byte_view(qImage)[...,0]\n\n    hasAlpha = qImage.hasAlphaChannel()\n\n    if hasAlpha:\n        targetFormat = _qt.QImage.Format_ARGB32\n    else:\n        targetFormat = _qt.QImage.Format_RGB32\n    if qImage.format() != targetFormat:\n        qImage = qImage.convertToFormat(targetFormat)\n\n    result = rgb_view(qImage)\n    if isGray:\n        result = result[...,0]\n    if hasAlpha:\n        if masked:\n            mask = (alpha_view(qImage) == 0)\n            if _np.ndim(result) == 3:\n                mask = _np.repeat(mask[...,None], 3, axis = 2)\n            result = _np.ma.masked_array(result, mask)\n        else:\n            result = _np.dstack((result, alpha_view(qImage)))\n    return result", "response": "Convenience function that uses the QImage_ constructor to read an anisotropic image from the given file and return an rgb_view of the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getData(self, *statements):\n        # FIXME: only works for the first statement.\n        return lock_and_call(\n            lambda: DataFrame._fromDataFrameRef(\n                self._impl.getData(list(statements), len(statements))\n            ),\n            self._lock\n        )", "response": "Get the data corresponding to the display statements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getEntity(self, name):\n        return lock_and_call(\n            lambda: Entity(self._impl.getEntity(name)),\n            self._lock\n        )", "response": "Returns the AMPL entity with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getVariable(self, name):\n        return lock_and_call(\n            lambda: Variable(self._impl.getVariable(name)),\n            self._lock\n        )", "response": "Returns the variable with the corresponding name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getConstraint(self, name):\n        return lock_and_call(\n            lambda: Constraint(self._impl.getConstraint(name)),\n            self._lock\n        )", "response": "Returns the constraint with the corresponding name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getObjective(self, name):\n        return lock_and_call(\n            lambda: Objective(self._impl.getObjective(name)),\n            self._lock\n        )", "response": "Returns the objective with the corresponding name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the set with the corresponding name.", "response": "def getSet(self, name):\n        \"\"\"\n        Get the set with the corresponding name.\n\n        Args:\n            name: Name of the set to be found.\n\n        Raises:\n            TypeError: if the specified set does not exist.\n        \"\"\"\n        return lock_and_call(\n            lambda: Set(self._impl.getSet(name)),\n            self._lock\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getParameter(self, name):\n        return lock_and_call(\n            lambda: Parameter(self._impl.getParameter(name)),\n            self._lock\n        )", "response": "Returns the parameter with the corresponding name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eval(self, amplstatements, **kwargs):\n        if self._langext is not None:\n            amplstatements = self._langext.translate(amplstatements, **kwargs)\n        lock_and_call(\n            lambda: self._impl.eval(amplstatements),\n            self._lock\n        )\n        self._errorhandler_wrapper.check()", "response": "Parses AMPL code and evaluates it as a possibly empty sequence of AMPL declarations and statements and returns the result of the interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isBusy(self):\n        # return self._impl.isBusy()\n        if self._lock.acquire(False):\n            self._lock.release()\n            return False\n        else:\n            return True", "response": "Returns true if the underlying engine is doing an async operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readAsync(self, fileName, callback, **kwargs):\n        if self._langext is not None:\n            with open(fileName, 'r') as fin:\n                newmodel = self._langext.translate(fin.read(), **kwargs)\n                with open(fileName+'.translated', 'w') as fout:\n                    fout.write(newmodel)\n                    fileName += '.translated'\n\n        def async_call():\n            self._lock.acquire()\n            try:\n                self._impl.read(fileName)\n                self._errorhandler_wrapper.check()\n            except Exception:\n                self._lock.release()\n                raise\n            else:\n                self._lock.release()\n                callback.run()\n        Thread(target=async_call).start()", "response": "Interprets the specified file asynchronously interpreting it as a\n            model or script file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninterpreting the specified data file asynchronously.", "response": "def readDataAsync(self, fileName, callback):\n        \"\"\"\n        Interprets the specified data file asynchronously. When interpreting is\n        over, the specified callback is called. The file is interpreted as\n        data. As a side effect, it invalidates all entities (as the passed file\n        can contain any arbitrary command); the lists of entities will be\n        re-populated lazily (at first access)\n\n        Args:\n            fileName: Full path to the file.\n\n            callback: Callback to be executed when the file has been\n            interpreted.\n        \"\"\"\n        def async_call():\n            self._lock.acquire()\n            try:\n                self._impl.readData(fileName)\n                self._errorhandler_wrapper.check()\n            except Exception:\n                self._lock.release()\n                raise\n            else:\n                self._lock.release()\n                callback.run()\n        Thread(target=async_call).start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evalAsync(self, amplstatements, callback, **kwargs):\n        if self._langext is not None:\n            amplstatements = self._langext.translate(amplstatements, **kwargs)\n\n        def async_call():\n            self._lock.acquire()\n            try:\n                self._impl.eval(amplstatements)\n                self._errorhandler_wrapper.check()\n            except Exception:\n                self._lock.release()\n                raise\n            else:\n                self._lock.release()\n                callback.run()\n        Thread(target=async_call).start()", "response": "Interprets the given AMPL statement asynchronously and runs the callback when the statement has been successfully interpreted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solveAsync(self, callback):\n        def async_call():\n            self._lock.acquire()\n            try:\n                self._impl.solve()\n            except Exception:\n                self._lock.release()\n                raise\n            else:\n                self._lock.release()\n                callback.run()\n        Thread(target=async_call).start()", "response": "Solve the current model asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cd(self, path=None):\n        if path is None:\n            return lock_and_call(\n                lambda: self._impl.cd(),\n                self._lock\n            )\n        else:\n            return lock_and_call(\n                lambda: self._impl.cd(path),\n                self._lock\n            )", "response": "Get or set the current working directory from the underlying\n            interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setOption(self, name, value):\n        if isinstance(value, bool):\n            lock_and_call(\n                lambda: self._impl.setBoolOption(name, value),\n                self._lock\n            )\n        elif isinstance(value, int):\n            lock_and_call(\n                lambda: self._impl.setIntOption(name, value),\n                self._lock\n            )\n        elif isinstance(value, float):\n            lock_and_call(\n                lambda: self._impl.setDblOption(name, value),\n                self._lock\n            )\n        elif isinstance(value, basestring):\n            lock_and_call(\n                lambda: self._impl.setOption(name, value),\n                self._lock\n            )\n        else:\n            raise TypeError", "response": "Sets an AMPL option to a specified value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getOption(self, name):\n        try:\n            value = lock_and_call(\n                lambda: self._impl.getOption(name).value(),\n                self._lock\n            )\n        except RuntimeError:\n            return None\n        else:\n            try:\n                return int(value)\n            except ValueError:\n                try:\n                    return float(value)\n                except ValueError:\n                    return value", "response": "Returns the current value of the specified option."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, fileName, **kwargs):\n        if self._langext is not None:\n            with open(fileName, 'r') as fin:\n                newmodel = self._langext.translate(fin.read(), **kwargs)\n                with open(fileName+'.translated', 'w') as fout:\n                    fout.write(newmodel)\n                    fileName += '.translated'\n        lock_and_call(\n            lambda: self._impl.read(fileName),\n            self._lock\n        )\n        self._errorhandler_wrapper.check()", "response": "Reads the specified file and returns the set of entities that were translated."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninterpreting the specified file as an AMPL data file.", "response": "def readData(self, fileName):\n        \"\"\"\n        Interprets the specified file as an AMPL data file. As a side effect,\n        it invalidates all entities (as the passed file can contain any\n        arbitrary command); the lists of entities will be re-populated lazily\n        (at first access). After reading the file, the interpreter is put back\n        to \"model\" mode.\n\n        Args:\n            fileName: Full path to the file.\n\n        Raises:\n            RuntimeError: in case the file does not exist.\n        \"\"\"\n        lock_and_call(\n            lambda: self._impl.readData(fileName),\n            self._lock\n        )\n        self._errorhandler_wrapper.check()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a scalar value from the underlying AMPL interpreter as a double or a string.", "response": "def getValue(self, scalarExpression):\n        \"\"\"\n        Get a scalar value from the underlying AMPL interpreter, as a double or\n        a string.\n\n        Args:\n            scalarExpression: An AMPL expression which evaluates to a scalar\n            value.\n\n        Returns:\n            The value of the expression.\n        \"\"\"\n        return lock_and_call(\n            lambda: Utils.castVariant(self._impl.getValue(scalarExpression)),\n            self._lock\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setData(self, data, setName=None):\n        if not isinstance(data, DataFrame):\n            if pd is not None and isinstance(data, pd.DataFrame):\n                data = DataFrame.fromPandas(data)\n        if setName is None:\n            lock_and_call(\n                lambda: self._impl.setData(data._impl),\n                self._lock\n            )\n        else:\n            lock_and_call(\n                lambda: self._impl.setData(data._impl, setName),\n                self._lock\n            )", "response": "Assign the data in the dataframe to the AMPL entities with the names\n            corresponding to the column names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readTable(self, tableName):\n        lock_and_call(\n            lambda: self._impl.readTable(tableName),\n            self._lock\n        )", "response": "Reads the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef writeTable(self, tableName):\n        lock_and_call(\n            lambda: self._impl.writeTable(tableName),\n            self._lock\n        )", "response": "Writes the specified table name to the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display(self, *amplExpressions):\n        exprs = list(map(str, amplExpressions))\n        lock_and_call(\n            lambda: self._impl.displayLst(exprs, len(exprs)),\n            self._lock\n        )", "response": "Writes on the current OutputHandler the outcome of the AMPL statement."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setOutputHandler(self, outputhandler):\n        class OutputHandlerInternal(amplpython.OutputHandler):\n            def output(self, kind, msg):\n                outputhandler.output(kind, msg)\n\n        self._outputhandler = outputhandler\n        self._outputhandler_internal = OutputHandlerInternal()\n        lock_and_call(\n            lambda: self._impl.setOutputHandler(\n                self._outputhandler_internal\n            ),\n            self._lock\n        )", "response": "Sets a new output handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setErrorHandler(self, errorhandler):\n        class ErrorHandlerWrapper(ErrorHandler):\n            def __init__(self, errorhandler):\n                self.errorhandler = errorhandler\n                self.last_exception = None\n\n            def error(self, exception):\n                if isinstance(exception, amplpython.AMPLException):\n                    exception = AMPLException(exception)\n                try:\n                    self.errorhandler.error(exception)\n                except Exception as e:\n                    self.last_exception = e\n\n            def warning(self, exception):\n                if isinstance(exception, amplpython.AMPLException):\n                    exception = AMPLException(exception)\n                try:\n                    self.errorhandler.warning(exception)\n                except Exception as e:\n                    self.last_exception = e\n\n            def check(self):\n                if self.last_exception is not None:\n                    e, self.last_exception = self.last_exception, None\n                    raise e\n\n        errorhandler_wrapper = ErrorHandlerWrapper(errorhandler)\n\n        class InnerErrorHandler(amplpython.ErrorHandler):\n            def error(self, exception):\n                errorhandler_wrapper.error(exception)\n\n            def warning(self, exception):\n                errorhandler_wrapper.warning(exception)\n\n        self._errorhandler = errorhandler\n        self._errorhandler_inner = InnerErrorHandler()\n        self._errorhandler_wrapper = errorhandler_wrapper\n        lock_and_call(\n            lambda: self._impl.setErrorHandler(self._errorhandler_inner),\n            self._lock\n        )", "response": "Sets a new error handler for the AMPL error and warning."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getVariables(self):\n        variables = lock_and_call(\n            lambda: self._impl.getVariables(),\n            self._lock\n        )\n        return EntityMap(variables, Variable)", "response": "Get all the variables declared."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getConstraints(self):\n        constraints = lock_and_call(\n            lambda: self._impl.getConstraints(),\n            self._lock\n        )\n        return EntityMap(constraints, Constraint)", "response": "Get all the constraints declared."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all the objectives declared in this object.", "response": "def getObjectives(self):\n        \"\"\"\n        Get all the objectives declared.\n        \"\"\"\n        objectives = lock_and_call(\n            lambda: self._impl.getObjectives(),\n            self._lock\n        )\n        return EntityMap(objectives, Objective)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSets(self):\n        sets = lock_and_call(\n            lambda: self._impl.getSets(),\n            self._lock\n        )\n        return EntityMap(sets, Set)", "response": "Get all the sets declared in this instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all the parameters declared.", "response": "def getParameters(self):\n        \"\"\"\n        Get all the parameters declared.\n        \"\"\"\n        parameters = lock_and_call(\n            lambda: self._impl.getParameters(),\n            self._lock\n        )\n        return EntityMap(parameters, Parameter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getCurrentObjective(self):\n        name = self._impl.getCurrentObjectiveName()\n        if name == '':\n            return None\n        else:\n            return self.getObjective(name)", "response": "Returns the current objective. Returns None if no objective is set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a variable that is a subset of the current object.", "response": "def _var(self):\n        \"\"\"\n        Get/Set a variable.\n        \"\"\"\n        class Variables(object):\n            def __getitem__(_self, name):\n                return self.getVariable(name)\n\n            def __setitem__(_self, name, value):\n                self.getVariable(name).setValue(value)\n\n            def __iter__(_self):\n                return self.getVariables()\n\n        return Variables()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _con(self):\n        class Constraints(object):\n            def __getitem__(_self, name):\n                return self.getConstraint(name)\n\n            def __setitem__(_self, name, value):\n                self.getConstraint(name).setDual(value)\n\n            def __iter__(_self):\n                return self.getConstraints()\n\n        return Constraints()", "response": "Returns a class that can be used to access the constraints of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set(self):\n        class Sets(object):\n            def __getitem__(_self, name):\n                return self.getSet(name)\n\n            def __setitem__(_self, name, values):\n                self.getSet(name).setValues(values)\n\n            def __iter__(_self):\n                return self.getSets()\n\n        return Sets()", "response": "Return a new object that represents the set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a class that can be used to access the parameters of the current object.", "response": "def _param(self):\n        \"\"\"\n        Get/Set a parameter.\n        \"\"\"\n        class Parameters(object):\n            def __getitem__(_self, name):\n                return self.getParameter(name)\n\n            def __setitem__(_self, name, value):\n                if isinstance(value, (float, int, basestring)):\n                    self.getParameter(name).set(value)\n                else:\n                    self.getParameter(name).setValues(value)\n\n            def __iter__(_self):\n                return self.getParameters()\n\n        return Parameters()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _option(self):\n        class Options(object):\n            def __getitem__(_self, name):\n                return self.getOption(name)\n\n            def __setitem__(_self, name, value):\n                self.setOption(name, value)\n\n        return Options()", "response": "Return an object that represents an option."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exportData(self, datfile):\n\n        def ampl_set(name, values):\n            def format_entry(e):\n                return repr(e).replace(' ', '')\n\n            return 'set {0} := {1};'.format(\n                name, ','.join(format_entry(e) for e in values)\n            )\n\n        def ampl_param(name, values):\n            def format_entry(k, v):\n                k = repr(k).strip('()').replace(' ', '')\n                if v == inf:\n                    v = \"Infinity\"\n                elif v == -inf:\n                    v = \"-Infinity\"\n                else:\n                    v = repr(v).strip('()').replace(' ', '')\n                return '[{0}]{1}'.format(k, v)\n\n            return 'param {0} := {1};'.format(\n                name, ''.join(format_entry(k, v) for k, v in values.items())\n            )\n\n        with open(datfile, 'w') as f:\n            for name, entity in self.getSets():\n                values = entity.getValues().toList()\n                print(ampl_set(name, values), file=f)\n            for name, entity in self.getParameters():\n                if entity.isScalar():\n                    print(\n                        'param {} := {};'.format(name, entity.value()),\n                        file=f\n                    )\n                else:\n                    values = entity.getValues().toDict()\n                    print(ampl_param(name, values), file=f)", "response": "Create a. dat file with the data that has been loaded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport the model to Gurobi.", "response": "def exportGurobiModel(self, gurobiDriver='gurobi', verbose=False):\n        \"\"\"\n        Export the model to Gurobi as a gurobipy.Model object.\n\n        Args:\n            gurobiDriver: The name or the path of the Gurobi solver driver.\n            verbose: Whether should generate verbose output.\n\n        Returns:\n            A :class:`gurobipy.Model` object with the model loaded.\n        \"\"\"\n        from gurobipy import GRB, read\n        from tempfile import mkdtemp\n        from shutil import rmtree\n        from os import path\n        import sys\n        if (sys.version_info > (3, 0)):\n            from io import StringIO\n        else:\n            from io import BytesIO as StringIO\n        tmp_dir = mkdtemp()\n        model_file = path.join(tmp_dir, 'model.mps')\n\n        previous = {\n            'solver': self.getOption('solver') or '',\n            'gurobi_auxfiles': self.getOption('auxfiles') or '',\n            'gurobi_options': self.getOption('gurobi_options') or '',\n        }\n        temporary = {\n            'solver': gurobiDriver,\n            'gurobi_auxfiles': 'rc',\n            'gurobi_options': '''\n                writeprob={}\n                timelim=0\n                presolve=0\n                heurfrac=0\n                outlev=0\n            '''.format(model_file)\n        }\n\n        for option in temporary:\n            self.setOption(option, temporary[option])\n\n        output = self.getOutput('solve;')\n        if not path.isfile(model_file):\n            raise RuntimeError(output)\n\n        for option in previous:\n            self.setOption(option, previous[option])\n\n        text_trap = StringIO()\n        stdout = sys.stdout\n        sys.stdout = text_trap\n        model = read(model_file)\n        sys.stdout = stdout\n        if verbose:\n            print(text_trap.getvalue())\n        if model_file.endswith('.mps'):\n            if not self.getCurrentObjective().minimization():\n                model.ModelSense = GRB.MAXIMIZE\n                model.setObjective(- model.getObjective())\n        model.update()\n        rmtree(tmp_dir)\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimports the solution from a gurobipy. Model object.", "response": "def importGurobiSolution(self, grbmodel):\n        \"\"\"\n        Import the solution from a gurobipy.Model object.\n\n        Args:\n            grbmodel: A :class:`gurobipy.Model` object with the model solved.\n        \"\"\"\n        self.eval(''.join(\n            'let {} := {};'.format(var.VarName, var.X)\n            for var in grbmodel.getVars()\n            if '$' not in var.VarName\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _startRecording(self, filename):\n        self.setOption('_log_file_name', filename)\n        self.setOption('_log_input_only', True)\n        self.setOption('_log', True)", "response": "Start recording the session to a file for debug purposes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a recorded session.", "response": "def _loadSession(self, filename):\n        \"\"\"\n        Load a recorded session.\n        \"\"\"\n        try:\n            self.eval(open(filename).read())\n        except RuntimeError as e:\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, *index):\n        assert self.wrapFunction is not None\n        if len(index) == 1 and isinstance(index[0], (tuple, list)):\n            index = index[0]\n        if len(index) == 0:\n            return self.wrapFunction(self._impl.get())\n        else:\n            return self.wrapFunction(self._impl.get(Tuple(index)._impl))", "response": "Get the corresponding instance with the specified index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching the current entity for an instance with the specified index.", "response": "def find(self, *index):\n        \"\"\"\n        Searches the current entity for an instance with the specified index.\n\n        Returns:\n            The wanted instance if found, otherwise it returns `None`.\n        \"\"\"\n        assert self.wrapFunction is not None\n        if len(index) == 1 and isinstance(index[0], (tuple, list)):\n            index = index[0]\n        it = self._impl.find(Tuple(index)._impl)\n        if it == self._impl.end():\n            return None\n        else:\n            return self.wrapFunction(it)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getValues(self, suffixes=None):\n        if suffixes is None:\n            return DataFrame._fromDataFrameRef(self._impl.getValues())\n        else:\n            suffixes = list(map(str, suffixes))\n            return DataFrame._fromDataFrameRef(\n                self._impl.getValuesLst(suffixes, len(suffixes))\n            )", "response": "Returns the values for all the keys in the set. If a list of suffixes is provided get the values for all the instances of this set. Otherwise get all the values for all the instances of this set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the values of this entity to the correponding values of a DataFrame.", "response": "def setValues(self, data):\n        \"\"\"\n        Set the values of this entiy to the correponding values of a\n        DataFrame indexed over the same sets (or a subset).\n        This function assigns the values in the first data column of\n        the passed dataframe to the entity the function is called from.\n        In particular, the statement:\n\n        .. code-block:: python\n\n            x.setValues(y.getValues())\n\n        is semantically equivalent to the AMPL statement:\n\n        .. code-block:: ampl\n\n            let {s in S} x[s] := y[s];\n\n        Args:\n            data: The data to set the entity to.\n        \"\"\"\n        if isinstance(data, DataFrame):\n            self._impl.setValuesDf(data._impl)\n        else:\n            if pd is not None and isinstance(data, (pd.DataFrame, pd.Series)):\n                df = DataFrame.fromPandas(data)\n                self._impl.setValuesDf(df._impl)\n                return\n            raise TypeError"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addRow(self, *value):\n        if len(value) == 1 and isinstance(value[0], (tuple, list)):\n            value = value[0]\n        assert len(value) == self.getNumCols()\n        self._impl.addRow(Tuple(value)._impl)", "response": "Adds a row to the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addColumn(self, header, values=[]):\n        if len(values) == 0:\n            self._impl.addColumn(header)\n        else:\n            assert len(values) == self.getNumRows()\n            if any(isinstance(value, basestring) for value in values):\n                values = list(map(str, values))\n                self._impl.addColumnStr(header, values)\n            elif all(isinstance(value, Real) for value in values):\n                values = list(map(float, values))\n                self._impl.addColumnDbl(header, values)\n            else:\n                raise NotImplementedError", "response": "Add a new column with the corresponding header and values to the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setColumn(self, header, values):\n        if any(isinstance(value, basestring) for value in values):\n            values = list(map(str, values))\n            self._impl.setColumnStr(header, values, len(values))\n        elif all(isinstance(value, Real) for value in values):\n            values = list(map(float, values))\n            self._impl.setColumnDbl(header, values, len(values))\n        else:\n            print(values)\n            raise NotImplementedError", "response": "Sets the values of a column."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getRow(self, key):\n        return Row(self._impl.getRow(Tuple(key)._impl))", "response": "Get a row by value of the indexing columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getRowByIndex(self, index):\n        assert isinstance(index, int)\n        return Row(self._impl.getRowByIndex(index))", "response": "Returns a row by numeric index."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the headers of this DataFrame.", "response": "def getHeaders(self):\n        \"\"\"\n         Get the headers of this DataFrame.\n\n         Returns:\n            The headers of this DataFrame.\n        \"\"\"\n        headers = self._impl.getHeaders()\n        return tuple(\n            headers.getIndex(i) for i in range(self._impl.getNumCols())\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setValues(self, values):\n        ncols = self.getNumCols()\n        nindices = self.getNumIndices()\n        for key, value in values.items():\n            key = Utils.convToList(key)\n            assert len(key) == nindices\n            value = Utils.convToList(value)\n            assert len(value) == ncols-nindices\n            self.addRow(key + value)", "response": "Set the values of a DataFrame from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toDict(self):\n        d = {}\n        nindices = self.getNumIndices()\n        for i in range(self.getNumRows()):\n            row = list(self.getRowByIndex(i))\n            if nindices > 1:\n                key = tuple(row[:nindices])\n            elif nindices == 1:\n                key = row[0]\n            else:\n                key = None\n            if len(row) - nindices == 0:\n                d[key] = None\n            elif len(row) - nindices == 1:\n                d[key] = row[nindices]\n            else:\n                d[key] = tuple(row[nindices:])\n        return d", "response": "Return a dictionary with the DataFrame data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef toList(self):\n        if self.getNumCols() > 1:\n            return [\n                tuple(self.getRowByIndex(i))\n                for i in range(self.getNumRows())\n            ]\n        else:\n            return [\n                self.getRowByIndex(i)[0]\n                for i in range(self.getNumRows())\n            ]", "response": "Return a list with the DataFrame data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a pandas DataFrame with the DataFrame data.", "response": "def toPandas(self):\n        \"\"\"\n        Return a pandas DataFrame with the DataFrame data.\n        \"\"\"\n        assert pd is not None\n        nindices = self.getNumIndices()\n        headers = self.getHeaders()\n        columns = {\n            header: list(self.getColumn(header))\n            for header in headers[nindices:]\n        }\n        index = zip(*[\n            list(self.getColumn(header))\n            for header in headers[:nindices]\n        ])\n        index = [key if len(key) > 1 else key[0] for key in index]\n        if index == []:\n            return pd.DataFrame(columns, index=None)\n        else:\n            return pd.DataFrame(columns, index=index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a : class ~amplpy. DataFrame from a pandas DataFrame.", "response": "def fromPandas(cls, df):\n        \"\"\"\n        Create a :class:`~amplpy.DataFrame` from a pandas DataFrame.\n        \"\"\"\n        assert pd is not None\n        if isinstance(df, pd.Series):\n            df = pd.DataFrame(df)\n        else:\n            assert isinstance(df, pd.DataFrame)\n        keys = [\n            key if isinstance(key, tuple) else (key,)\n            for key in df.index.tolist()\n        ]\n        index = [\n            ('index{}'.format(i), cindex)\n            for i, cindex in enumerate(zip(*keys))\n        ]\n        columns = [\n            (str(cname), df[cname].tolist())\n            for cname in df.columns.tolist()\n        ]\n        return cls(index=index, columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromNumpy(cls, data):\n        assert np is not None\n        if isinstance(data, np.ndarray):\n            index = []\n            if len(data.shape) == 1:\n                columns = [('value', data.tolist())]\n            elif len(data.shape) == 2:\n                columns = [\n                    ('c{}'.format(i), col)\n                    for i, col in enumerate(zip(*data.tolist()))\n                ]\n            else:\n                raise TypeError\n        else:\n            raise TypeError\n        return cls(index=index, columns=columns)", "response": "Create a : class ~amplpy. DataFrame from a numpy array or matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, *args):\n        assert len(args) in (1, 2)\n        if len(args) == 1:\n            value = args[0]\n            self._impl.set(value)\n        else:\n            index, value = args\n            if isinstance(value, Real):\n                self._impl.setTplDbl(Tuple(index)._impl, value)\n            elif isinstance(value, basestring):\n                self._impl.setTplStr(Tuple(index)._impl, value)\n            else:\n                raise TypeError", "response": "Set the value of the attribute in the underlying AMPL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns the values to the parameter instances with the specified indices equivalent to the AMPL code.", "response": "def setValues(self, values):\n        \"\"\"\n        Assign the values (string or float) to the parameter instances with the\n        specified indices, equivalent to the AMPL code:\n\n        .. code-block:: ampl\n\n            let {i in indices} par[i] := values[i];\n\n        Args:\n            values: list, dictionary or :class:`~amplpy.DataFrame` with the\n            indices and the values to be set.\n\n        Raises:\n            TypeError: If called on a scalar parameter.\n        \"\"\"\n        if isinstance(values, dict):\n            indices, values = list(zip(*values.items()))\n            indices = Utils.toTupleArray(indices)\n            if any(isinstance(value, basestring) for value in values):\n                values = list(map(str, values))\n                self._impl.setValuesTaStr(indices, values, len(values))\n            elif all(isinstance(value, Real) for value in values):\n                values = list(map(float, values))\n                self._impl.setValuesTaDbl(indices, values, len(values))\n            else:\n                raise TypeError\n        elif isinstance(values, (list, tuple)):\n            if any(isinstance(value, basestring) for value in values):\n                values = list(map(str, values))\n                self._impl.setValuesStr(values, len(values))\n            elif all(isinstance(value, Real) for value in values):\n                values = list(map(float, values))\n                self._impl.setValuesDbl(values, len(values))\n            else:\n                raise TypeError\n        else:\n            if np is not None and isinstance(values, np.ndarray):\n                self.setValues(DataFrame.fromNumpy(values).toList())\n                return\n            Entity.setValues(self, values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setValues(self, values):\n        if isinstance(values, (list, set)):\n            if any(isinstance(value, basestring) for value in values):\n                values = list(map(str, values))\n                self._impl.setValuesStr(values, len(values))\n            elif all(isinstance(value, Real) for value in values):\n                values = list(map(float, values))\n                self._impl.setValuesDbl(values, len(values))\n            elif all(isinstance(value, tuple) for value in values):\n                self._impl.setValues(Utils.toTupleArray(values), len(values))\n            else:\n                raise TypeError\n        else:\n            if np is not None and isinstance(values, np.ndarray):\n                self.setValues(DataFrame.fromNumpy(values).toList())\n                return\n            Entity.setValues(self, values)", "response": "Sets the values of the internal data structures in this set. Valid only for non - indexed sets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreceiving notification of an error.", "response": "def error(self, amplexception):\n        \"\"\"\n        Receives notification of an error.\n        \"\"\"\n        msg = '\\t'+str(amplexception).replace('\\n', '\\n\\t')\n        print('Error:\\n{:s}'.format(msg))\n        raise amplexception"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs a warning message.", "response": "def warning(self, amplexception):\n        \"\"\"\n        Receives notification of a warning.\n        \"\"\"\n        msg = '\\t'+str(amplexception).replace('\\n', '\\n\\t')\n        print('Warning:\\n{:s}'.format(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering jupyter notebook magics and ampl_eval cells.", "response": "def register_magics(store_name='_ampl_cells', ampl_object=None):\n    \"\"\"\n    Register jupyter notebook magics ``%%ampl`` and ``%%ampl_eval``.\n\n    Args:\n        store_name: Name of the store where ``%%ampl cells`` will be stored.\n        ampl_object: Object used to evaluate ``%%ampl_eval`` cells.\n    \"\"\"\n    from IPython.core.magic import  (\n        Magics, magics_class, cell_magic, line_magic\n    )\n\n    @magics_class\n    class StoreAMPL(Magics):\n        def __init__(self, shell=None,  **kwargs):\n            Magics.__init__(self, shell=shell, **kwargs)\n            self._store = []\n            shell.user_ns[store_name] = self._store\n\n        @cell_magic\n        def ampl(self, line, cell):\n            \"\"\"Store the cell in the store\"\"\"\n            self._store.append(cell)\n\n        @cell_magic\n        def ampl_eval(self, line, cell):\n            \"\"\"Evaluate the cell\"\"\"\n            ampl_object.eval(cell)\n\n        @line_magic\n        def get_ampl(self, line):\n            \"\"\"Retrieve the store\"\"\"\n            return self._store\n\n    get_ipython().register_magics(StoreAMPL)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfix all instances of this variable to a value if provided or to their current value otherwise.", "response": "def fix(self, value=None):\n        \"\"\"\n        Fix all instances of this variable to a value if provided or to\n        their current value otherwise.\n\n        Args:\n            value: value to be set.\n        \"\"\"\n\n        if value is None:\n            self._impl.fix()\n        else:\n            self._impl.fix(value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef toVName(name, stripNum=0, upper=False):\n    if upper:\n        name = name.upper()\n    if stripNum != 0:\n        name = name[:-stripNum]\n    return name.replace('_', '-')", "response": "Turn a Python name into an iCalendar style name optionally uppercase and with characters stripped off."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses parameters in a string", "response": "def parseParams(string):\n    \"\"\"\n    Parse parameters\n    \"\"\"\n    all = params_re.findall(string)\n    allParameters = []\n    for tup in all:\n        paramList = [tup[0]]  # tup looks like (name, valuesString)\n        for pair in param_values_re.findall(tup[1]):\n            # pair looks like ('', value) or (value, '')\n            if pair[0] != '':\n                paramList.append(pair[0])\n            else:\n                paramList.append(pair[1])\n        allParameters.append(paramList)\n    return allParameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a line of a sequence of parameters and values.", "response": "def parseLine(line, lineNumber=None):\n    \"\"\"\n    Parse line\n    \"\"\"\n    match = line_re.match(line)\n    if match is None:\n        raise ParseError(\"Failed to parse line: {0!s}\".format(line), lineNumber)\n    # Underscores are replaced with dash to work around Lotus Notes\n    return (match.group('name').replace('_', '-'),\n            parseParams(match.group('params')),\n            match.group('value'), match.group('group'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nescapes double quotes in parameter values.", "response": "def dquoteEscape(param):\n    \"\"\"\n    Return param, or \"param\" if ',' or ';' or ':' is in param.\n    \"\"\"\n    if param.find('\"') >= 0:\n        raise VObjectError(\"Double quotes aren't allowed in parameter values.\")\n    for char in ',;:':\n        if param.find(char) >= 0:\n            return '\"' + param + '\"'\n    return param"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a sequence of components from a file or string.", "response": "def readComponents(streamOrString, validate=False, transform=True,\n                   ignoreUnreadable=False, allowQP=False):\n    \"\"\"\n    Generate one Component at a time from a stream.\n    \"\"\"\n    if isinstance(streamOrString, basestring):\n        stream = six.StringIO(streamOrString)\n    else:\n        stream = streamOrString\n\n    try:\n        stack = Stack()\n        versionLine = None\n        n = 0\n        for line, n in getLogicalLines(stream, allowQP):\n            if ignoreUnreadable:\n                try:\n                    vline = textLineToContentLine(line, n)\n                except VObjectError as e:\n                    if e.lineNumber is not None:\n                        msg = \"Skipped line {lineNumber}, message: {msg}\"\n                    else:\n                        msg = \"Skipped a line, message: {msg}\"\n                    logger.error(msg.format(**{'lineNumber': e.lineNumber, 'msg': str(e)}))\n                    continue\n            else:\n                vline = textLineToContentLine(line, n)\n            if vline.name == \"VERSION\":\n                versionLine = vline\n                stack.modifyTop(vline)\n            elif vline.name == \"BEGIN\":\n                stack.push(Component(vline.value, group=vline.group))\n            elif vline.name == \"PROFILE\":\n                if not stack.top():\n                    stack.push(Component())\n                stack.top().setProfile(vline.value)\n            elif vline.name == \"END\":\n                if len(stack) == 0:\n                    err = \"Attempted to end the {0} component but it was never opened\"\n                    raise ParseError(err.format(vline.value), n)\n\n                if vline.value.upper() == stack.topName():  # START matches END\n                    if len(stack) == 1:\n                        component = stack.pop()\n                        if versionLine is not None:\n                            component.setBehaviorFromVersionLine(versionLine)\n                        else:\n                            behavior = getBehavior(component.name)\n                            if behavior:\n                                component.setBehavior(behavior)\n                        if validate:\n                            component.validate(raiseException=True)\n                        if transform:\n                            component.transformChildrenToNative()\n                        yield component  # EXIT POINT\n                    else:\n                        stack.modifyTop(stack.pop())\n                else:\n                    err = \"{0} component wasn't closed\"\n                    raise ParseError(err.format(stack.topName()), n)\n            else:\n                stack.modifyTop(vline)  # not a START or END line\n        if stack.top():\n            if stack.topName() is None:\n                logger.warning(\"Top level component was never named\")\n            elif stack.top().useBegin:\n                raise ParseError(\"Component {0!s} was never closed\".format(\n                                 (stack.topName())), n)\n            yield stack.pop()\n\n    except ParseError as e:\n        e.input = streamOrString\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread one element from a stream.", "response": "def readOne(stream, validate=False, transform=True, ignoreUnreadable=False,\n            allowQP=False):\n    \"\"\"\n    Return the first component from stream.\n    \"\"\"\n    return next(readComponents(stream, validate, transform, ignoreUnreadable,\n                               allowQP))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registerBehavior(behavior, name=None, default=False, id=None):\n    if not name:\n        name = behavior.name.upper()\n    if id is None:\n        id = behavior.versionString\n    if name in __behaviorRegistry:\n        if default:\n            __behaviorRegistry[name].insert(0, (id, behavior))\n        else:\n            __behaviorRegistry[name].append((id, behavior))\n    else:\n        __behaviorRegistry[name] = [(id, behavior)]", "response": "Register the given behavior.\n\n    If default is True (or if this is the first version registered with this\n    name), the version will be the default if no id is given."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a matching behavior if it exists or None.", "response": "def getBehavior(name, id=None):\n    \"\"\"\n    Return a matching behavior if it exists, or None.\n\n    If id is None, return the default for name.\n    \"\"\"\n    name = name.upper()\n    if name in __behaviorRegistry:\n        if id:\n            for n, behavior in __behaviorRegistry[name]:\n                if n == id:\n                    return behavior\n\n        return __behaviorRegistry[name][0][1]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling the behavior's validate method, or return True.", "response": "def validate(self, *args, **kwds):\n        \"\"\"\n        Call the behavior's validate method, or return True.\n        \"\"\"\n        if self.behavior:\n            return self.behavior.validate(self, *args, **kwds)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autoBehavior(self, cascade=False):\n        parentBehavior = self.parentBehavior\n        if parentBehavior is not None:\n            knownChildTup = parentBehavior.knownChildren.get(self.name, None)\n            if knownChildTup is not None:\n                behavior = getBehavior(self.name, knownChildTup[2])\n                if behavior is not None:\n                    self.setBehavior(behavior, cascade)\n                    if isinstance(self, ContentLine) and self.encoded:\n                        self.behavior.decode(self)\n            elif isinstance(self, ContentLine):\n                self.behavior = parentBehavior.defaultBehavior\n                if self.encoded and self.behavior:\n                    self.behavior.decode(self)", "response": "Set behavior if name is in self. parentBehavior. knownChildren and cascade is True then recalculate behavior and parentBehavior for all\n        descendants."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the behavior of the current object.", "response": "def setBehavior(self, behavior, cascade=True):\n        \"\"\"\n        Set behavior. If cascade is True, autoBehavior all descendants.\n        \"\"\"\n        self.behavior = behavior\n        if cascade:\n            for obj in self.getChildren():\n                obj.parentBehavior = behavior\n                obj.autoBehavior(True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms this object into a custom VBase subclass.", "response": "def transformToNative(self):\n        \"\"\"\n        Transform this object into a custom VBase subclass.\n\n        transformToNative should always return a representation of this object.\n        It may do so by modifying self in place then returning self, or by\n        creating a new object.\n        \"\"\"\n        if self.isNative or not self.behavior or not self.behavior.hasNative:\n            return self\n        else:\n            self_orig = copy.copy(self)\n            try:\n                return self.behavior.transformToNative(self)\n            except Exception as e:\n                # wrap errors in transformation in a ParseError\n                lineNumber = getattr(self, 'lineNumber', None)\n\n                if isinstance(e, ParseError):\n                    if lineNumber is not None:\n                        e.lineNumber = lineNumber\n                    raise\n                else:\n                    msg = \"In transformToNative, unhandled exception on line {0}: {1}: {2}\"\n                    msg = msg.format(lineNumber, sys.exc_info()[0], sys.exc_info()[1])\n                    msg = msg + \" (\" + str(self_orig) + \")\"\n                    raise ParseError(msg, lineNumber)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing to buf if it exists otherwise return a string.", "response": "def serialize(self, buf=None, lineLength=75, validate=True, behavior=None):\n        \"\"\"\n        Serialize to buf if it exists, otherwise return a string.\n\n        Use self.behavior.serialize if behavior exists.\n        \"\"\"\n        if not behavior:\n            behavior = self.behavior\n\n        if behavior:\n            if DEBUG:\n                logger.debug(\"serializing {0!s} with behavior {1!s}\".format(self.name, behavior))\n            return behavior.serialize(self, buf, lineLength, validate)\n        else:\n            if DEBUG:\n                logger.debug(\"serializing {0!s} without behavior\".format(self.name))\n            return defaultSerialize(self, buf, lineLength)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform the representation of the value according to the behavior.", "response": "def valueRepr(self):\n        \"\"\"\n        Transform the representation of the value\n        according to the behavior, if any.\n        \"\"\"\n        v = self.value\n        if self.behavior:\n            v = self.behavior.valueRepr(self)\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setProfile(self, name):\n        if self.name or self.useBegin:\n            if self.name == name:\n                return\n            raise VObjectError(\"This component already has a PROFILE or \"\n                               \"uses BEGIN.\")\n        self.name = name.upper()", "response": "Assign a PROFILE to this unnamed component."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a child s value.", "response": "def getChildValue(self, childName, default=None, childNumber=0):\n        \"\"\"\n        Return a child's value (the first, by default), or None.\n        \"\"\"\n        child = self.contents.get(toVName(childName))\n        if child is None:\n            return default\n        else:\n            return child[childNumber].value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding objOrName to contents set behavior if it can be inferred.", "response": "def add(self, objOrName, group=None):\n        \"\"\"\n        Add objOrName to contents, set behavior if it can be inferred.\n\n        If objOrName is a string, create an empty component or line based on\n        behavior. If no behavior is found for the object, add a ContentLine.\n\n        group is an optional prefix to the name of the object (see RFC 2425).\n        \"\"\"\n        if isinstance(objOrName, VBase):\n            obj = objOrName\n            if self.behavior:\n                obj.parentBehavior = self.behavior\n                obj.autoBehavior(True)\n        else:\n            name = objOrName.upper()\n            try:\n                id = self.behavior.knownChildren[name][2]\n                behavior = getBehavior(name, id)\n                if behavior.isComponent:\n                    obj = Component(name)\n                else:\n                    obj = ContentLine(name, [], '', group)\n                obj.parentBehavior = self.behavior\n                obj.behavior = behavior\n                obj = obj.transformToNative()\n            except (KeyError, AttributeError):\n                obj = ContentLine(objOrName, [], '', group)\n            if obj.behavior is None and self.behavior is not None:\n                if isinstance(obj, ContentLine):\n                    obj.behavior = self.behavior.defaultBehavior\n        self.contents.setdefault(obj.name.lower(), []).append(obj)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an object from the contents.", "response": "def remove(self, obj):\n        \"\"\"\n        Remove obj from contents.\n        \"\"\"\n        named = self.contents.get(obj.name.lower())\n        if named:\n            try:\n                named.remove(obj)\n                if len(named) == 0:\n                    del self.contents[obj.name.lower()]\n            except ValueError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting behavior if one matches name and value.", "response": "def setBehaviorFromVersionLine(self, versionLine):\n        \"\"\"\n        Set behavior if one matches name, versionLine.value.\n        \"\"\"\n        v = getBehavior(self.name, versionLine.value)\n        if v:\n            self.setBehavior(v)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transformChildrenFromNative(self, clearBehavior=True):\n        for childArray in self.contents.values():\n            for child in childArray:\n                child = child.transformFromNative()\n                child.transformChildrenFromNative(clearBehavior)\n                if clearBehavior:\n                    child.behavior = None\n                    child.parentBehavior = None", "response": "Recursively transform native children to vanilla representations."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes iCalendar object to HTML using the iCalendar microformat.", "response": "def serialize(cls, obj, buf=None, lineLength=None, validate=True):\n        \"\"\"\n        Serialize iCalendar to HTML using the hCalendar microformat (http://microformats.org/wiki/hcalendar)\n        \"\"\"\n\n        outbuf = buf or six.StringIO()\n        level = 0  # holds current indentation level\n        tabwidth = 3\n\n        def indent():\n            return ' ' * level * tabwidth\n\n        def out(s):\n            outbuf.write(indent())\n            outbuf.write(s)\n\n        # not serializing optional vcalendar wrapper\n\n        vevents = obj.vevent_list\n\n        for event in vevents:\n            out('<span class=\"vevent\">' + CRLF)\n            level += 1\n\n            # URL\n            url = event.getChildValue(\"url\")\n            if url:\n                out('<a class=\"url\" href=\"' + url + '\">' + CRLF)\n                level += 1\n            # SUMMARY\n            summary = event.getChildValue(\"summary\")\n            if summary:\n                out('<span class=\"summary\">' + summary + '</span>:' + CRLF)\n\n            # DTSTART\n            dtstart = event.getChildValue(\"dtstart\")\n            if dtstart:\n                if type(dtstart) == date:\n                    timeformat = \"%A, %B %e\"\n                    machine = \"%Y%m%d\"\n                elif type(dtstart) == datetime:\n                    timeformat = \"%A, %B %e, %H:%M\"\n                    machine = \"%Y%m%dT%H%M%S%z\"\n\n                #TODO: Handle non-datetime formats?\n                #TODO: Spec says we should handle when dtstart isn't included\n\n                out('<abbr class=\"dtstart\", title=\"{0!s}\">{1!s}</abbr>\\r\\n'\n                    .format(dtstart.strftime(machine),\n                            dtstart.strftime(timeformat)))\n\n                # DTEND\n                dtend = event.getChildValue(\"dtend\")\n                if not dtend:\n                    duration = event.getChildValue(\"duration\")\n                    if duration:\n                        dtend = duration + dtstart\n                   # TODO: If lacking dtend & duration?\n\n                if dtend:\n                    human = dtend\n                    # TODO: Human readable part could be smarter, excluding repeated data\n                    if type(dtend) == date:\n                        human = dtend - timedelta(days=1)\n\n                    out('- <abbr class=\"dtend\", title=\"{0!s}\">{1!s}</abbr>\\r\\n'\n                        .format(dtend.strftime(machine),\n                                human.strftime(timeformat)))\n\n            # LOCATION\n            location = event.getChildValue(\"location\")\n            if location:\n                out('at <span class=\"location\">' + location + '</span>' + CRLF)\n\n            description = event.getChildValue(\"description\")\n            if description:\n                out('<div class=\"description\">' + description + '</div>' + CRLF)\n\n            if url:\n                level -= 1\n                out('</a>' + CRLF)\n\n            level -= 1\n            out('</span>' + CRLF)  # close vevent\n\n        return buf or outbuf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the timezone of the specified component.", "response": "def change_tz(cal, new_timezone, default, utc_only=False, utc_tz=icalendar.utc):\n    \"\"\"\n    Change the timezone of the specified component.\n\n    Args:\n        cal (Component): the component to change\n        new_timezone (tzinfo): the timezone to change to\n        default (tzinfo): a timezone to assume if the dtstart or dtend in cal \n            doesn't have an existing timezone\n        utc_only (bool): only convert dates that are in utc\n        utc_tz (tzinfo): the tzinfo to compare to for UTC when processing \n            utc_only=True\n    \"\"\"\n\n    for vevent in getattr(cal, 'vevent_list', []):\n        start = getattr(vevent, 'dtstart', None)\n        end   = getattr(vevent, 'dtend',   None)\n        for node in (start, end):\n            if node:\n                dt = node.value\n                if (isinstance(dt, datetime) and\n                        (not utc_only or dt.tzinfo == utc_tz)):\n                    if dt.tzinfo is None:\n                        dt = dt.replace(tzinfo = default)\n                    node.value = dt.astimezone(new_timezone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfolds one line of a single - byte utf - 8 sequence into a single line of text.", "response": "def foldOneLine(outbuf, input, lineLength = 75):\n    \"\"\"\n    Folding line procedure that ensures multi-byte utf-8 sequences are not\n    broken across lines\n\n    TO-DO: This all seems odd. Is it still needed, especially in python3?\n    \"\"\"\n    if len(input) < lineLength:\n        # Optimize for unfolded line case\n        try:\n            outbuf.write(bytes(input, 'UTF-8'))\n        except Exception:\n            # fall back on py2 syntax\n            outbuf.write(str_(input))\n\n    else:\n        # Look for valid utf8 range and write that out\n        start = 0\n        written = 0\n        counter = 0  # counts line size in bytes\n        decoded = to_unicode(input)\n        length = len(to_basestring(input))\n        while written < length:\n            s = decoded[start]  # take one char\n            size = len(to_basestring(s))  # calculate it's size in bytes\n            if counter + size > lineLength:\n                try:\n                    outbuf.write(bytes(\"\\r\\n \", 'UTF-8'))\n                except Exception:\n                    # fall back on py2 syntax\n                    outbuf.write(\"\\r\\n \")\n\n                counter = 1  # one for space\n\n            if str is unicode_type:\n                outbuf.write(to_unicode(s))\n            else:\n                # fall back on py2 syntax\n                outbuf.write(s.encode('utf-8'))\n\n            written += size\n            counter += size\n            start += 1\n    try:\n        outbuf.write(bytes(\"\\r\\n\", 'UTF-8'))\n    except Exception:\n        # fall back on py2 syntax\n        outbuf.write(\"\\r\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef defaultSerialize(obj, buf, lineLength):\n    outbuf = buf or six.StringIO()\n\n    if isinstance(obj, Component):\n        if obj.group is None:\n            groupString = ''\n        else:\n            groupString = obj.group + '.'\n        if obj.useBegin:\n            foldOneLine(outbuf, \"{0}BEGIN:{1}\".format(groupString, obj.name),\n                        lineLength)\n        for child in obj.getSortedChildren():\n            # validate is recursive, we only need to validate once\n            child.serialize(outbuf, lineLength, validate=False)\n        if obj.useBegin:\n            foldOneLine(outbuf, \"{0}END:{1}\".format(groupString, obj.name),\n                        lineLength)\n\n    elif isinstance(obj, ContentLine):\n        startedEncoded = obj.encoded\n        if obj.behavior and not startedEncoded:\n            obj.behavior.encode(obj)\n\n        s = six.StringIO()\n\n        if obj.group is not None:\n            s.write(obj.group + '.')\n        s.write(obj.name.upper())\n        keys = sorted(obj.params.keys())\n        for key in keys:\n            paramstr = ','.join(dquoteEscape(p) for p in obj.params[key])\n            s.write(\";{0}={1}\".format(key, paramstr))\n        s.write(\":{0}\".format(str_(obj.value)))\n        if obj.behavior and not startedEncoded:\n            obj.behavior.decode(obj)\n        foldOneLine(outbuf, s.getvalue(), lineLength)\n\n    return buf or outbuf.getvalue()", "response": "Default serialize method for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning a string or unicode into unicode", "response": "def toUnicode(s):\n    \"\"\"\n    Take a string or unicode, turn it into unicode, decoding as utf-8\n    \"\"\"\n    if isinstance(s, six.binary_type):\n        s = s.decode('utf-8')\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef numToDigits(num, places):\n    s = str(num)\n    if len(s) < places:\n        return (\"0\" * (places - len(s))) + s\n    elif len(s) > places:\n        return s[len(s)-places: ]\n    else:\n        return s", "response": "Helper for converting numbers to textual digits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert timedelta to an ical DURATION.", "response": "def timedeltaToString(delta):\n    \"\"\"\n    Convert timedelta to an ical DURATION.\n    \"\"\"\n    if delta.days == 0:\n        sign = 1\n    else:\n        sign = delta.days / abs(delta.days)\n    delta = abs(delta)\n    days = delta.days\n    hours = int(delta.seconds / 3600)\n    minutes = int((delta.seconds % 3600) / 60)\n    seconds = int(delta.seconds % 60)\n\n    output = ''\n    if sign == -1:\n        output += '-'\n    output += 'P'\n    if days:\n        output += '{}D'.format(days)\n    if hours or minutes or seconds:\n        output += 'T'\n    elif not days:  # Deal with zero duration\n        output += 'T0S'\n    if hours:\n        output += '{}H'.format(hours)\n    if minutes:\n        output += '{}M'.format(minutes)\n    if seconds:\n        output += '{}S'.format(seconds)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stringToTextValues(s, listSeparator=',', charList=None, strict=False):\n    if charList is None:\n        charList = escapableCharList\n\n    def escapableChar (c):\n        return c in charList\n\n    def error(msg):\n        if strict:\n            raise ParseError(msg)\n        else:\n            logging.error(msg)\n\n    # vars which control state machine\n    charIterator = enumerate(s)\n    state        = \"read normal\"\n\n    current = []\n    results = []\n\n    while True:\n        try:\n            charIndex, char = next(charIterator)\n        except:\n            char = \"eof\"\n\n        if state == \"read normal\":\n            if char == '\\\\':\n                state = \"read escaped char\"\n            elif char == listSeparator:\n                state = \"read normal\"\n                current = \"\".join(current)\n                results.append(current)\n                current = []\n            elif char == \"eof\":\n                state = \"end\"\n            else:\n                state = \"read normal\"\n                current.append(char)\n\n        elif state == \"read escaped char\":\n            if escapableChar(char):\n                state = \"read normal\"\n                if char in 'nN':\n                    current.append('\\n')\n                else:\n                    current.append(char)\n            else:\n                state = \"read normal\"\n                # leave unrecognized escaped characters for later passes\n                current.append('\\\\' + char)\n\n        elif state == \"end\":  # an end state\n            if len(current) or len(results) == 0:\n                current = \"\".join(current)\n                results.append(current)\n            return results\n\n        elif state == \"error\":  # an end state\n            return results\n\n        else:\n            state = \"error\"\n            error(\"unknown state: '{0!s}' reached in {1!s}\".format(state, s))", "response": "Returns a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stringToDurations(s, strict=False):\n    def makeTimedelta(sign, week, day, hour, minute, sec):\n        if sign == \"-\": sign = -1\n        else: sign = 1\n        week = int(week)\n        day = int(day)\n        hour = int(hour)\n        minute = int(minute)\n        sec = int(sec)\n        return sign * datetime.timedelta(weeks=week, days=day, hours=hour,\n                                         minutes=minute, seconds=sec)\n\n    def error(msg):\n        if strict:\n            raise ParseError(msg)\n        else:\n            raise ParseError(msg)\n\n    # vars which control state machine\n    charIterator = enumerate(s)\n    state  = \"start\"\n\n    durations = []\n    current = \"\"\n    sign = None\n    week = 0\n    day = 0\n    hour = 0\n    minute = 0\n    sec = 0\n\n    while True:\n        try:\n            charIndex, char = next(charIterator)\n        except:\n            char = \"eof\"\n\n        if state == \"start\":\n            if char == '+':\n                state = \"start\"\n                sign = char\n            elif char == '-':\n                state = \"start\"\n                sign = char\n            elif char.upper() == 'P':\n                state = \"read field\"\n            elif char == \"eof\":\n                state = \"error\"\n                error(\"got end-of-line while reading in duration: \" + s)\n            elif char in string.digits:\n                state = \"read field\"\n                current = current + char  # update this part when updating \"read field\"\n            else:\n                state = \"error\"\n                error(\"got unexpected character {0} reading in duration: {1}\"\n                      .format(char, s))\n\n        elif state == \"read field\":\n            if (char in string.digits):\n                state = \"read field\"\n                current = current + char  # update part above when updating \"read field\"\n            elif char.upper() == 'T':\n                state = \"read field\"\n            elif char.upper() == 'W':\n                state = \"read field\"\n                week    = current\n                current = \"\"\n            elif char.upper() == 'D':\n                state = \"read field\"\n                day     = current\n                current = \"\"\n            elif char.upper() == 'H':\n                state = \"read field\"\n                hour    = current\n                current = \"\"\n            elif char.upper() == 'M':\n                state = \"read field\"\n                minute  = current\n                current = \"\"\n            elif char.upper() == 'S':\n                state = \"read field\"\n                sec     = current\n                current = \"\"\n            elif char == \",\":\n                state = \"start\"\n                durations.append(makeTimedelta(sign, week, day, hour, minute,\n                                               sec))\n                current = \"\"\n                sign = None\n                week = None\n                day = None\n                hour = None\n                minute = None\n                sec = None\n            elif char == \"eof\":\n                state = \"end\"\n            else:\n                state = \"error\"\n                error(\"got unexpected character reading in duration: \" + s)\n\n        elif state == \"end\":  # an end state\n            if (sign or week or day or hour or minute or sec):\n                durations.append(makeTimedelta(sign, week, day, hour, minute,\n                                               sec))\n            return durations\n\n        elif state == \"error\":  # an end state\n            error(\"in error state\")\n            return durations\n\n        else:\n            state = \"error\"\n            error(\"unknown state: '{0!s}' reached in {1!s}\".format(state, s))", "response": "Returns a list of timedelta objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseDtstart(contentline, allowSignatureMismatch=False):\n    tzinfo = getTzid(getattr(contentline, 'tzid_param', None))\n    valueParam = getattr(contentline, 'value_param', 'DATE-TIME').upper()\n    if valueParam == \"DATE\":\n        return stringToDate(contentline.value)\n    elif valueParam == \"DATE-TIME\":\n        try:\n            return stringToDateTime(contentline.value, tzinfo)\n        except:\n            if allowSignatureMismatch:\n                return stringToDate(contentline.value)\n            else:\n                raise", "response": "Parses a contentline s value into a date or date - time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getTransition(transitionTo, year, tzinfo):\n    def firstTransition(iterDates, test):\n        \"\"\"\n        Return the last date not matching test, or None if all tests matched.\n        \"\"\"\n        success = None\n        for dt in iterDates:\n            if not test(dt):\n                success = dt\n            else:\n                if success is not None:\n                    return success\n        return success # may be None\n\n    def generateDates(year, month=None, day=None):\n        \"\"\"\n        Iterate over possible dates with unspecified values.\n        \"\"\"\n        months = range(1, 13)\n        days   = range(1, 32)\n        hours  = range(0, 24)\n        if month is None:\n            for month in months:\n                yield datetime.datetime(year, month, 1)\n        elif day is None:\n            for day in days:\n                try:\n                    yield datetime.datetime(year, month, day)\n                except ValueError:\n                    pass\n        else:\n            for hour in hours:\n                yield datetime.datetime(year, month, day, hour)\n\n    assert transitionTo in ('daylight', 'standard')\n    if transitionTo == 'daylight':\n        def test(dt):\n            try:\n                return tzinfo.dst(dt) != zeroDelta\n            except pytz.NonExistentTimeError:\n                return True  # entering daylight time\n            except pytz.AmbiguousTimeError:\n                return False  # entering standard time\n    elif transitionTo == 'standard':\n        def test(dt):\n            try:\n                return tzinfo.dst(dt) == zeroDelta\n            except pytz.NonExistentTimeError:\n                return False  # entering daylight time\n            except pytz.AmbiguousTimeError:\n                return True  # entering standard time\n    newyear = datetime.datetime(year, 1, 1)\n    monthDt = firstTransition(generateDates(year), test)\n    if monthDt is None:\n        return newyear\n    elif monthDt.month == 12:\n        return None\n    else:\n        # there was a good transition somewhere in a non-December month\n        month = monthDt.month\n        day         = firstTransition(generateDates(year, month), test).day\n        uncorrected = firstTransition(generateDates(year, month, day), test)\n        if transitionTo == 'standard':\n            # assuming tzinfo.dst returns a new offset for the first\n            # possible hour, we need to add one hour for the offset change\n            # and another hour because firstTransition returns the hour\n            # before the transition\n            return uncorrected + datetime.timedelta(hours=2)\n        else:\n            return uncorrected + datetime.timedelta(hours=1)", "response": "Returns the datetime of the transition to or None if no transition is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompares offsets and DST transitions from startYear to endYear.", "response": "def tzinfo_eq(tzinfo1, tzinfo2, startYear = 2000, endYear=2020):\n    \"\"\"\n    Compare offsets and DST transitions from startYear to endYear.\n    \"\"\"\n    if tzinfo1 == tzinfo2:\n        return True\n    elif tzinfo1 is None or tzinfo2 is None:\n        return False\n\n    def dt_test(dt):\n        if dt is None:\n            return True\n        return tzinfo1.utcoffset(dt) == tzinfo2.utcoffset(dt)\n\n    if not dt_test(datetime.datetime(startYear, 1, 1)):\n        return False\n    for year in range(startYear, endYear):\n        for transitionTo in 'daylight', 'standard':\n            t1=getTransition(transitionTo, year, tzinfo1)\n            t2=getTransition(transitionTo, year, tzinfo2)\n            if t1 != t2 or not dt_test(t1):\n                return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registerTzinfo(obj, tzinfo):\n        tzid = obj.pickTzid(tzinfo)\n        if tzid and not getTzid(tzid, False):\n            registerTzid(tzid, tzinfo)\n        return tzid", "response": "Register tzinfo if it s not already registered return its tzid."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the timezone information for the current time range.", "response": "def settzinfo(self, tzinfo, start=2000, end=2030):\n        \"\"\"\n        Create appropriate objects in self to represent tzinfo.\n\n        Collapse DST transitions to rrules as much as possible.\n\n        Assumptions:\n        - DST <-> Standard transitions occur on the hour\n        - never within a month of one another\n        - twice or fewer times a year\n        - never in the month of December\n        - DST always moves offset exactly one hour later\n        - tzinfo classes dst method always treats times that could be in either\n          offset as being in the later regime\n        \"\"\"\n        def fromLastWeek(dt):\n            \"\"\"\n            How many weeks from the end of the month dt is, starting from 1.\n            \"\"\"\n            weekDelta = datetime.timedelta(weeks=1)\n            n = 1\n            current = dt + weekDelta\n            while current.month == dt.month:\n                n += 1\n                current += weekDelta\n            return n\n\n        # lists of dictionaries defining rules which are no longer in effect\n        completed = {'daylight' : [], 'standard' : []}\n\n        # dictionary defining rules which are currently in effect\n        working   = {'daylight' : None, 'standard' : None}\n\n        # rule may be based on nth week of the month or the nth from the last\n        for year in range(start, end + 1):\n            newyear = datetime.datetime(year, 1, 1)\n            for transitionTo in 'daylight', 'standard':\n                transition = getTransition(transitionTo, year, tzinfo)\n                oldrule = working[transitionTo]\n\n                if transition == newyear:\n                    # transitionTo is in effect for the whole year\n                    rule = {'end'        : None,\n                            'start'      : newyear,\n                            'month'      : 1,\n                            'weekday'    : None,\n                            'hour'       : None,\n                            'plus'       : None,\n                            'minus'      : None,\n                            'name'       : tzinfo.tzname(newyear),\n                            'offset'     : tzinfo.utcoffset(newyear),\n                            'offsetfrom' : tzinfo.utcoffset(newyear)}\n                    if oldrule is None:\n                        # transitionTo was not yet in effect\n                        working[transitionTo] = rule\n                    else:\n                        # transitionTo was already in effect\n                        if (oldrule['offset'] !=\n                            tzinfo.utcoffset(newyear)):\n                            # old rule was different, it shouldn't continue\n                            oldrule['end'] = year - 1\n                            completed[transitionTo].append(oldrule)\n                            working[transitionTo] = rule\n                elif transition is None:\n                    # transitionTo is not in effect\n                    if oldrule is not None:\n                        # transitionTo used to be in effect\n                        oldrule['end'] = year - 1\n                        completed[transitionTo].append(oldrule)\n                        working[transitionTo] = None\n                else:\n                    # an offset transition was found\n                    try:\n                        old_offset = tzinfo.utcoffset(transition - twoHours)\n                        name = tzinfo.tzname(transition)\n                        offset = tzinfo.utcoffset(transition)\n                    except (pytz.AmbiguousTimeError, pytz.NonExistentTimeError):\n                        # guaranteed that tzinfo is a pytz timezone\n                        is_dst = (transitionTo == \"daylight\")\n                        old_offset = tzinfo.utcoffset(transition - twoHours, is_dst=is_dst)\n                        name = tzinfo.tzname(transition, is_dst=is_dst)\n                        offset = tzinfo.utcoffset(transition, is_dst=is_dst)\n                    rule = {'end'     : None,  # None, or an integer year\n                            'start'   : transition,  # the datetime of transition\n                            'month'   : transition.month,\n                            'weekday' : transition.weekday(),\n                            'hour'    : transition.hour,\n                            'name'    : name,\n                            'plus'    : int(\n                                (transition.day - 1)/ 7 + 1),  # nth week of the month\n                            'minus'   : fromLastWeek(transition),  # nth from last week\n                            'offset'  : offset,\n                            'offsetfrom' : old_offset}\n\n                    if oldrule is None:\n                        working[transitionTo] = rule\n                    else:\n                        plusMatch  = rule['plus']  == oldrule['plus']\n                        minusMatch = rule['minus'] == oldrule['minus']\n                        truth = plusMatch or minusMatch\n                        for key in 'month', 'weekday', 'hour', 'offset':\n                            truth = truth and rule[key] == oldrule[key]\n                        if truth:\n                            # the old rule is still true, limit to plus or minus\n                            if not plusMatch:\n                                oldrule['plus'] = None\n                            if not minusMatch:\n                                oldrule['minus'] = None\n                        else:\n                            # the new rule did not match the old\n                            oldrule['end'] = year - 1\n                            completed[transitionTo].append(oldrule)\n                            working[transitionTo] = rule\n\n        for transitionTo in 'daylight', 'standard':\n            if working[transitionTo] is not None:\n                completed[transitionTo].append(working[transitionTo])\n\n        self.tzid = []\n        self.daylight = []\n        self.standard = []\n\n        self.add('tzid').value = self.pickTzid(tzinfo, True)\n\n        # old = None # unused?\n        for transitionTo in 'daylight', 'standard':\n            for rule in completed[transitionTo]:\n                comp = self.add(transitionTo)\n                dtstart = comp.add('dtstart')\n                dtstart.value = rule['start']\n                if rule['name'] is not None:\n                    comp.add('tzname').value  = rule['name']\n                line = comp.add('tzoffsetto')\n                line.value = deltaToOffset(rule['offset'])\n                line = comp.add('tzoffsetfrom')\n                line.value = deltaToOffset(rule['offsetfrom'])\n\n                if rule['plus'] is not None:\n                    num = rule['plus']\n                elif rule['minus'] is not None:\n                    num = -1 * rule['minus']\n                else:\n                    num = None\n                if num is not None:\n                    dayString = \";BYDAY=\" + str(num) + WEEKDAYS[rule['weekday']]\n                else:\n                    dayString = \"\"\n                if rule['end'] is not None:\n                    if rule['hour'] is None:\n                        # all year offset, with no rule\n                        endDate = datetime.datetime(rule['end'], 1, 1)\n                    else:\n                        weekday = rrule.weekday(rule['weekday'], num)\n                        du_rule = rrule.rrule(rrule.YEARLY,\n                                   bymonth = rule['month'],byweekday = weekday,\n                                   dtstart = datetime.datetime(\n                                       rule['end'], 1, 1, rule['hour'])\n                                  )\n                        endDate = du_rule[0]\n                    endDate = endDate.replace(tzinfo = utc) - rule['offsetfrom']\n                    endString = \";UNTIL=\"+ dateTimeToString(endDate)\n                else:\n                    endString = ''\n                new_rule = \"FREQ=YEARLY{0!s};BYMONTH={1!s}{2!s}\"\\\n                    .format(dayString, rule['month'], endString)\n\n                comp.add('rrule').value = new_rule"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pickTzid(tzinfo, allowUTC=False):\n        if tzinfo is None or (not allowUTC and tzinfo_eq(tzinfo, utc)):\n            # If tzinfo is UTC, we don't need a TZID\n            return None\n        # try PyICU's tzid key\n        if hasattr(tzinfo, 'tzid'):\n            return toUnicode(tzinfo.tzid)\n\n        # try pytz zone key\n        if hasattr(tzinfo, 'zone'):\n            return toUnicode(tzinfo.zone)\n\n        # try tzical's tzid key\n        elif hasattr(tzinfo, '_tzid'):\n            return toUnicode(tzinfo._tzid)\n        else:\n            # return tzname for standard (non-DST) time\n            notDST = datetime.timedelta(0)\n            for month in range(1, 13):\n                dt = datetime.datetime(2000, month, 1)\n                if tzinfo.dst(dt) == notDST:\n                    return toUnicode(tzinfo.tzname(dt))\n        # there was no standard time in 2000!\n        raise VObjectError(\"Unable to guess TZID for tzinfo {0!s}\"\n                           .format(tzinfo))", "response": "Given a tzinfo class pick a TZID from known APIs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode(cls, line):\n        if line.encoded:\n            encoding = getattr(line, 'encoding_param', None)\n            if encoding and encoding.upper() == cls.base64string:\n                line.value = codecs.decode(self.value.encode(\"utf-8\"), \"base64\").decode(encoding)\n            else:\n                line.value = stringToTextValues(line.value)[0]\n            line.encoded=False", "response": "Decode the value of a single line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nturn a recurring Component into a RecurringComponent.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn a recurring Component into a RecurringComponent.\n        \"\"\"\n        if not obj.isNative:\n            object.__setattr__(obj, '__class__', RecurringComponent)\n            obj.isNative = True\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generateImplicitParameters(obj):\n        if not hasattr(obj, 'uid'):\n            rand = int(random.random() * 100000)\n            now = datetime.datetime.now(utc)\n            now = dateTimeToString(now)\n            host = socket.gethostname()\n            obj.add(ContentLine('UID', [], \"{0} - {1}@{2}\".format(now, rand,\n                                                                  host)))", "response": "Generate a UID if one does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns obj. value into a date or datetime.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn obj.value into a date or datetime.\n        \"\"\"\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        if obj.value == '':\n            return obj\n        obj.value=obj.value\n        obj.value=parseDtstart(obj, allowSignatureMismatch=True)\n        if getattr(obj, 'value_param', 'DATE-TIME').upper() == 'DATE-TIME':\n            if hasattr(obj, 'tzid_param'):\n                # Keep a copy of the original TZID around\n                obj.params['X-VOBJ-ORIGINAL-TZID'] = [obj.tzid_param]\n                del obj.tzid_param\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform the ISO 8601 date or datetime in obj. value with an ISO 8601 string.", "response": "def transformFromNative(obj):\n        \"\"\"\n        Replace the date or datetime in obj.value with an ISO 8601 string.\n        \"\"\"\n        if type(obj.value) == datetime.date:\n            obj.isNative = False\n            obj.value_param = 'DATE'\n            obj.value = dateToString(obj.value)\n            return obj\n        else:\n            return DateTimeBehavior.transformFromNative(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nturn obj. value into a list of dates datetimes or timedelta tuples.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn obj.value into a list of dates, datetimes, or\n        (datetime, timedelta) tuples.\n        \"\"\"\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        if obj.value == '':\n            obj.value = []\n            return obj\n        tzinfo = getTzid(getattr(obj, 'tzid_param', None))\n        valueParam = getattr(obj, 'value_param', \"DATE-TIME\").upper()\n        valTexts = obj.value.split(\",\")\n        if valueParam == \"DATE\":\n            obj.value = [stringToDate(x) for x in valTexts]\n        elif valueParam == \"DATE-TIME\":\n            obj.value = [stringToDateTime(x, tzinfo) for x in valTexts]\n        elif valueParam == \"PERIOD\":\n            obj.value = [stringToPeriod(x, tzinfo) for x in valTexts]\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transformFromNative(obj):\n        if obj.value and type(obj.value[0]) == datetime.date:\n            obj.isNative = False\n            obj.value_param = 'DATE'\n            obj.value = ','.join([dateToString(val) for val in obj.value])\n            return obj\n        # Fixme: handle PERIOD case\n        else:\n            if obj.isNative:\n                obj.isNative = False\n                transformed = []\n                tzid = None\n                for val in obj.value:\n                    if tzid is None and type(val) == datetime.datetime:\n                        tzid = TimezoneComponent.registerTzinfo(val.tzinfo)\n                        if tzid is not None:\n                            obj.tzid_param = tzid\n                    transformed.append(dateTimeToString(val))\n                obj.value = ','.join(transformed)\n            return obj", "response": "Replace the date datetime or period tuples in obj. value with the appropriate strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode a single entry from a line.", "response": "def decode(cls, line):\n        \"\"\"\n        Remove backslash escaping from line.value, then split on commas.\n        \"\"\"\n        if line.encoded:\n            line.value = stringToTextValues(line.value,\n                listSeparator=cls.listSeparator)\n            line.encoded=False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode(cls, line):\n        if not line.encoded:\n            line.value = cls.listSeparator.join(backslashEscape(val)\n                                                for val in line.value)\n            line.encoded=True", "response": "Encode the value of a resource item into a list of ISO - 8601 values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates implicit parameters for a content line.", "response": "def generateImplicitParameters(cls, obj):\n        \"\"\"\n        Create PRODID, VERSION, and VTIMEZONEs if needed.\n\n        VTIMEZONEs will need to exist whenever TZID parameters exist or when\n        datetimes with tzinfo exist.\n        \"\"\"\n        for comp in obj.components():\n            if comp.behavior is not None:\n                comp.behavior.generateImplicitParameters(comp)\n        if not hasattr(obj, 'prodid'):\n            obj.add(ContentLine('PRODID', [], PRODID))\n        if not hasattr(obj, 'version'):\n            obj.add(ContentLine('VERSION', [], cls.versionString))\n        tzidsUsed = {}\n\n        def findTzids(obj, table):\n            if isinstance(obj, ContentLine) and (obj.behavior is None or\n                                                 not obj.behavior.forceUTC):\n                if getattr(obj, 'tzid_param', None):\n                    table[obj.tzid_param] = 1\n                else:\n                    if type(obj.value) == list:\n                        for item in obj.value:\n                            tzinfo = getattr(obj.value, 'tzinfo', None)\n                            tzid = TimezoneComponent.registerTzinfo(tzinfo)\n                            if tzid:\n                                table[tzid] = 1\n                    else:\n                        tzinfo = getattr(obj.value, 'tzinfo', None)\n                        tzid = TimezoneComponent.registerTzinfo(tzinfo)\n                        if tzid:\n                            table[tzid] = 1\n            for child in obj.getChildren():\n                if obj.name != 'VTIMEZONE':\n                    findTzids(child, table)\n\n        findTzids(obj, tzidsUsed)\n        oldtzids = [toUnicode(x.tzid.value) for x in getattr(obj, 'vtimezone_list', [])]\n        for tzid in tzidsUsed.keys():\n            tzid = toUnicode(tzid)\n            if tzid != u'UTC' and tzid not in oldtzids:\n                obj.add(TimezoneComponent(tzinfo=getTzid(tzid)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating implicit parameters for a single object.", "response": "def generateImplicitParameters(obj):\n        \"\"\"\n        Create default ACTION and TRIGGER if they're not set.\n        \"\"\"\n        try:\n            obj.action\n        except AttributeError:\n            obj.add('action').value = 'AUDIO'\n        try:\n            obj.trigger\n        except AttributeError:\n            obj.add('trigger').value = datetime.timedelta(0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns obj. value into a datetime. timedelta.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn obj.value into a datetime.timedelta.\n        \"\"\"\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        obj.value=obj.value\n        if obj.value == '':\n            return obj\n        else:\n            deltalist=stringToDurations(obj.value)\n            # When can DURATION have multiple durations?  For now:\n            if len(deltalist) == 1:\n                obj.value = deltalist[0]\n                return obj\n            else:\n                raise ParseError(\"DURATION must have a single duration string.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformFromNative(obj):\n        if not obj.isNative:\n            return obj\n        obj.isNative = False\n        obj.value = timedeltaToString(obj.value)\n        return obj", "response": "Replace the datetime. timedelta in obj. value with an RFC 2445 string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nturns obj. value into a timedelta or datetime.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn obj.value into a timedelta or datetime.\n        \"\"\"\n        if obj.isNative:\n            return obj\n        value = getattr(obj, 'value_param', 'DURATION').upper()\n        if hasattr(obj, 'value_param'):\n            del obj.value_param\n        if obj.value == '':\n            obj.isNative = True\n            return obj\n        elif value  == 'DURATION':\n            try:\n                return Duration.transformToNative(obj)\n            except ParseError:\n                logger.warning(\"TRIGGER not recognized as DURATION, trying \"\n                             \"DATE-TIME, because iCal sometimes exports \"\n                             \"DATE-TIMEs without setting VALUE=DATE-TIME\")\n                try:\n                    obj.isNative = False\n                    dt = DateTimeBehavior.transformToNative(obj)\n                    return dt\n                except:\n                    msg = \"TRIGGER with no VALUE not recognized as DURATION \" \\\n                          \"or as DATE-TIME\"\n                    raise ParseError(msg)\n        elif value == 'DATE-TIME':\n            # TRIGGERs with DATE-TIME values must be in UTC, we could validate\n            # that fact, for now we take it on faith.\n            return DateTimeBehavior.transformToNative(obj)\n        else:\n            raise ParseError(\"VALUE must be DURATION or DATE-TIME\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transformToNative(obj):\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        if obj.value == '':\n            obj.value = []\n            return obj\n        tzinfo = getTzid(getattr(obj, 'tzid_param', None))\n        obj.value = [stringToPeriod(x, tzinfo) for x in obj.value.split(\",\")]\n        return obj", "response": "Convert comma separated periods into tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the list of tuples in obj. value to strings.", "response": "def transformFromNative(cls, obj):\n        \"\"\"\n        Convert the list of tuples in obj.value to strings.\n        \"\"\"\n        if obj.isNative:\n            obj.isNative = False\n            transformed = []\n            for tup in obj.value:\n                transformed.append(periodToString(tup, cls.forceUTC))\n            if len(transformed) > 0:\n                tzid = TimezoneComponent.registerTzinfo(tup[0].tzinfo)\n                if not cls.forceUTC and tzid is not None:\n                    obj.tzid_param = tzid\n\n            obj.value = ','.join(transformed)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serializeFields(obj, order=None):\n    fields = []\n    if order is None:\n        fields = [backslashEscape(val) for val in obj]\n    else:\n        for field in order:\n            escapedValueList = [backslashEscape(val) for val in\n                                toList(getattr(obj, field))]\n            fields.append(','.join(escapedValueList))\n    return ';'.join(fields)", "response": "Turn an object s fields into a ';' and ',' seperated string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn a string or array value into a string.", "response": "def toString(val, join_char='\\n'):\n        \"\"\"\n        Turn a string or array value into a string.\n        \"\"\"\n        if type(val) in (list, tuple):\n            return join_char.join(val)\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode(cls, line):\n        if not line.encoded:\n            encoding = getattr(line, 'encoding_param', None)\n            if encoding and encoding.upper() == cls.base64string:\n                if isinstance(line.value, bytes):\n                    line.value = codecs.encode(line.value, \"base64\").decode(\"utf-8\").replace('\\n', '')\n                else:\n                    line.value = codecs.encode(line.value.encode(encoding), \"base64\").decode(\"utf-8\")\n            else:\n                line.value = backslashEscape(line.value)\n            line.encoded = True", "response": "Encode the value of a single line."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generateImplicitParameters(cls, obj):\n        if not hasattr(obj, 'version'):\n            obj.add(ContentLine('VERSION', [], cls.versionString))", "response": "Generate implicit parameters for the TZID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(cls, obj, buf, lineLength, validate):\n        if wacky_apple_photo_serialize:\n            lineLength = REALLY_LARGE\n        VCardTextBehavior.serialize(obj, buf, lineLength, validate)", "response": "Serialize the object into a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn obj. value into a Name.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn obj.value into a Name.\n        \"\"\"\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        obj.value = Name(**dict(zip(NAME_ORDER, splitFields(obj.value))))\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing the Name in obj. value with a string.", "response": "def transformFromNative(obj):\n        \"\"\"\n        Replace the Name in obj.value with a string.\n        \"\"\"\n        obj.isNative = False\n        obj.value = serializeFields(obj.value, NAME_ORDER)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transformToNative(obj):\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        obj.value = Address(**dict(zip(ADDRESS_ORDER, splitFields(obj.value))))\n        return obj", "response": "Turn obj. value into an Address."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns obj. value into a list.", "response": "def transformToNative(obj):\n        \"\"\"\n        Turn obj.value into a list.\n        \"\"\"\n        if obj.isNative:\n            return obj\n        obj.isNative = True\n        obj.value = splitFields(obj.value)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding the value of a line.", "response": "def decode(cls, line):\n        \"\"\"\n        Remove backslash escaping from line.valueDecode line, either to remove\n        backslash espacing, or to decode base64 encoding. The content line should\n        contain a ENCODING=b for base64 encoding, but Apple Addressbook seems to\n        export a singleton parameter of 'BASE64', which does not match the 3.0\n        vCard spec. If we encouter that, then we transform the parameter to\n        ENCODING=b\n        \"\"\"\n        if line.encoded:\n            if 'BASE64' in line.singletonparams:\n                line.singletonparams.remove('BASE64')\n                line.encoding_param = cls.base64string\n            encoding = getattr(line, 'encoding_param', None)\n            if encoding:\n                line.value = codecs.decode(line.value.encode(\"utf-8\"), \"base64\")\n            else:\n                line.value = stringToTextValues(line.value)[0]\n            line.encoded=False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(cls, obj, raiseException=False, complainUnrecognized=False):\n        if not cls.allowGroup and obj.group is not None:\n            err = \"{0} has a group, but this object doesn't support groups\".format(obj)\n            raise base.VObjectError(err)\n        if isinstance(obj, base.ContentLine):\n            return cls.lineValidate(obj, raiseException, complainUnrecognized)\n        elif isinstance(obj, base.Component):\n            count = {}\n            for child in obj.getChildren():\n                if not child.validate(raiseException, complainUnrecognized):\n                    return False\n                name = child.name.upper()\n                count[name] = count.get(name, 0) + 1\n            for key, val in cls.knownChildren.items():\n                if count.get(key, 0) < val[0]:\n                    if raiseException:\n                        m = \"{0} components must contain at least {1} {2}\"\n                        raise base.ValidateError(m .format(cls.name, val[0], key))\n                    return False\n                if val[1] and count.get(key, 0) > val[1]:\n                    if raiseException:\n                        m = \"{0} components cannot contain more than {1} {2}\"\n                        raise base.ValidateError(m.format(cls.name, val[1], key))\n                    return False\n            return True\n        else:\n            err = \"{0} is not a Component or Contentline\".format(obj)\n            raise base.VObjectError(err)", "response": "Check if the object satisfies this behavior s requirements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(cls, obj, buf, lineLength, validate=True):\n\n        cls.generateImplicitParameters(obj)\n        if validate:\n            cls.validate(obj, raiseException=True)\n\n        if obj.isNative:\n            transformed = obj.transformFromNative()\n            undoTransform = True\n        else:\n            transformed = obj\n            undoTransform = False\n\n        out = base.defaultSerialize(transformed, buf, lineLength)\n        if undoTransform:\n            obj.transformToNative()\n        return out", "response": "Serialize a single object into a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_timezones():\n    l = []\n    for i in xrange(parentsize):\n        l.append(_winreg.EnumKey(tzparent, i))\n    return l", "response": "Return a list of all time zones known to the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npick the nth weekday in the sequence of weekdays", "response": "def pickNthWeekday(year, month, dayofweek, hour, minute, whichweek):\n    \"\"\"dayofweek == 0 means Sunday, whichweek > 4 means last instance\"\"\"\n    first = datetime.datetime(year=year, month=month, hour=hour, minute=minute,\n                              day=1)\n    weekdayone = first.replace(day=((dayofweek - first.isoweekday()) % 7 + 1))\n    for n in xrange(whichweek - 1, -1, -1):\n        dt = weekdayone + n * WEEKS\n        if dt.month == month:\n            return dt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef valuesToDict(key):\n    d = {}\n    size = _winreg.QueryInfoKey(key)[1]\n    for i in xrange(size):\n        d[_winreg.EnumValue(key, i)[0]] = _winreg.EnumValue(key, i)[1]\n    return d", "response": "Convert a registry key s values to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of objects that are not in the same order as the given ones.", "response": "def diff(left, right):\n    \"\"\"\n    Take two VCALENDAR components, compare VEVENTs and VTODOs in them,\n    return a list of object pairs containing just UID and the bits\n    that didn't match, using None for objects that weren't present in one\n    version or the other.\n\n    When there are multiple ContentLines in one VEVENT, for instance many\n    DESCRIPTION lines, such lines original order is assumed to be\n    meaningful.  Order is also preserved when comparing (the unlikely case\n    of) multiple parameters of the same type in a ContentLine\n\n    \"\"\"\n\n    def processComponentLists(leftList, rightList):\n        output = []\n        rightIndex = 0\n        rightListSize = len(rightList)\n\n        for comp in leftList:\n            if rightIndex >= rightListSize:\n                output.append((comp, None))\n            else:\n                leftKey  = getSortKey(comp)\n                rightComp = rightList[rightIndex]\n                rightKey = getSortKey(rightComp)\n                while leftKey > rightKey:\n                    output.append((None, rightComp))\n                    rightIndex += 1\n                    if rightIndex >= rightListSize:\n                        output.append((comp, None))\n                        break\n                    else:\n                        rightComp = rightList[rightIndex]\n                        rightKey = getSortKey(rightComp)\n\n                if leftKey < rightKey:\n                    output.append((comp, None))\n                elif leftKey == rightKey:\n                    rightIndex += 1\n                    matchResult = processComponentPair(comp, rightComp)\n                    if matchResult is not None:\n                        output.append(matchResult)\n\n        return output\n\n    def newComponent(name, body):\n        if body is None:\n            return None\n        else:\n            c = Component(name)\n            c.behavior = getBehavior(name)\n            c.isNative = True\n            return c\n\n    def processComponentPair(leftComp, rightComp):\n        \"\"\"\n        Return None if a match, or a pair of components including UIDs and\n        any differing children.\n\n        \"\"\"\n        leftChildKeys = leftComp.contents.keys()\n        rightChildKeys = rightComp.contents.keys()\n\n        differentContentLines = []\n        differentComponents = {}\n\n        for key in leftChildKeys:\n            rightList = rightComp.contents.get(key, [])\n            if isinstance(leftComp.contents[key][0], Component):\n                compDifference = processComponentLists(leftComp.contents[key],\n                                                       rightList)\n                if len(compDifference) > 0:\n                    differentComponents[key] = compDifference\n\n            elif leftComp.contents[key] != rightList:\n                differentContentLines.append((leftComp.contents[key],\n                                              rightList))\n\n        for key in rightChildKeys:\n            if key not in leftChildKeys:\n                if isinstance(rightComp.contents[key][0], Component):\n                    differentComponents[key] = ([], rightComp.contents[key])\n                else:\n                    differentContentLines.append(([], rightComp.contents[key]))\n\n        if len(differentContentLines) == 0 and len(differentComponents) == 0:\n            return None\n        else:\n            left  = newFromBehavior(leftComp.name)\n            right = newFromBehavior(leftComp.name)\n            # add a UID, if one existed, despite the fact that they'll always be\n            # the same\n            uid = leftComp.getChildValue('uid')\n            if uid is not None:\n                left.add( 'uid').value = uid\n                right.add('uid').value = uid\n\n            for name, childPairList in differentComponents.items():\n                leftComponents, rightComponents = zip(*childPairList)\n                if len(leftComponents) > 0:\n                    # filter out None\n                    left.contents[name] = filter(None, leftComponents)\n                if len(rightComponents) > 0:\n                    # filter out None\n                    right.contents[name] = filter(None, rightComponents)\n\n            for leftChildLine, rightChildLine in differentContentLines:\n                nonEmpty = leftChildLine or rightChildLine\n                name = nonEmpty[0].name\n                if leftChildLine is not None:\n                    left.contents[name] = leftChildLine\n                if rightChildLine is not None:\n                    right.contents[name] = rightChildLine\n\n            return left, right\n\n\n    vevents = processComponentLists(sortByUID(getattr(left, 'vevent_list', [])),\n                                    sortByUID(getattr(right, 'vevent_list', [])))\n\n    vtodos = processComponentLists(sortByUID(getattr(left, 'vtodo_list', [])),\n                                   sortByUID(getattr(right, 'vtodo_list', [])))\n\n    return vevents + vtodos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stringToDateTime(s, tzinfo=None):\n    try:\n        year = int(s[0:4])\n        month = int(s[4:6])\n        day = int(s[6:8])\n        hour = int(s[9:11])\n        minute = int(s[11:13])\n        second = int(s[13:15])\n        if len(s) > 15:\n            if s[15] == 'Z':\n                tzinfo = getTzid('UTC')\n    except:\n        raise ParseError(\"'{0!s}' is not a valid DATE-TIME\".format(s))\n    year = year and year or 2000\n    if tzinfo is not None and hasattr(tzinfo,'localize'):  # PyTZ case\n        return tzinfo.localize(datetime.datetime(year, month, day, hour, minute, second))\n    return datetime.datetime(year, month, day, hour, minute, second, 0, tzinfo)", "response": "Converts a string representation of a date - time to a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize(cls, obj, buf, lineLength, validate=True):\n\n        cls.generateImplicitParameters(obj)\n        if validate:\n            cls.validate(obj, raiseException=True)\n        if obj.isNative:\n            transformed = obj.transformFromNative()\n            undoTransform = True\n        else:\n            transformed = obj\n            undoTransform = False\n        out = None\n        outbuf = buf or six.StringIO()\n        if obj.group is None:\n            groupString = ''\n        else:\n            groupString = obj.group + '.'\n        if obj.useBegin:\n            foldOneLine(outbuf, \"{0}BEGIN:{1}\".format(groupString, obj.name),\n                        lineLength)\n\n        try:\n            first_props = [s for s in cls.sortFirst if s in obj.contents \\\n                                    and not isinstance(obj.contents[s][0], Component)]\n            first_components = [s for s in cls.sortFirst if s in obj.contents \\\n                                    and isinstance(obj.contents[s][0], Component)]\n        except Exception:\n            first_props = first_components = []\n            # first_components = []\n\n        prop_keys = sorted(list(k for k in obj.contents.keys() if k not in first_props \\\n                                         and not isinstance(obj.contents[k][0], Component)))\n        comp_keys = sorted(list(k for k in obj.contents.keys() if k not in first_components \\\n                                        and isinstance(obj.contents[k][0], Component)))\n\n        sorted_keys = first_props + prop_keys + first_components + comp_keys\n        children = [o for k in sorted_keys for o in obj.contents[k]]\n\n        for child in children:\n            # validate is recursive, we only need to validate once\n            child.serialize(outbuf, lineLength, validate=False)\n        if obj.useBegin:\n            foldOneLine(outbuf, \"{0}END:{1}\".format(groupString, obj.name),\n                        lineLength)\n        out = buf or outbuf.getvalue()\n        if undoTransform:\n            obj.transformToNative()\n        return out", "response": "Serializes the object into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfills a new data stream with historical data for a given thermostat.", "response": "def fillPelicanHole(site, username, password, tstat_name, start_time, end_time):\n    \"\"\"Fill a hole in a Pelican thermostat's data stream.\n\n    Arguments:\n        site -- The thermostat's Pelican site name\n        username -- The Pelican username for the site\n        password -- The Pelican password for the site\n        tstat_name -- The name of the thermostat, as identified by Pelican\n        start_time -- The start of the data hole in UTC, e.g. \"2018-01-29 15:00:00\"\n        end_time -- The end of the data hole in UTC, e.g. \"2018-01-29 16:00:00\"\n\n    Returns:\n        A Pandas dataframe with historical Pelican data that falls between the\n        specified start and end times.\n\n    Note that this function assumes the Pelican thermostat's local time zone is\n    US/Pacific. It will properly handle PST vs. PDT.\n    \"\"\"\n\n    start = datetime.strptime(start_time, _INPUT_TIME_FORMAT).replace(tzinfo=pytz.utc).astimezone(_pelican_time)\n    end = datetime.strptime(end_time, _INPUT_TIME_FORMAT).replace(tzinfo=pytz.utc).astimezone(_pelican_time)\n\n    heat_needs_fan = _lookupHeatNeedsFan(site, username, password, tstat_name)\n    if heat_needs_fan is None:\n        return None\n\n    # Pelican's API only allows a query covering a time range of up to 1 month\n    # So we may need run multiple requests for historical data\n    history_blocks = []\n    while start < end:\n        block_start = start\n        block_end = min(start + timedelta(days=30), end)\n        blocks = _lookupHistoricalData(site, username, password, tstat_name, block_start, block_end)\n        if blocks is None:\n            return None\n        history_blocks.extend(blocks)\n        start += timedelta(days=30, minutes=1)\n\n    output_rows = []\n    for block in history_blocks:\n        runStatus = block.find(\"runStatus\").text\n        if runStatus.startswith(\"Heat\"):\n            fanState = (heatNeedsFan == \"Yes\")\n        else:\n            fanState = (runStatus != \"Off\")\n\n        api_time = datetime.strptime(block.find(\"timestamp\").text, \"%Y-%m-%dT%H:%M\").replace(tzinfo=_pelican_time)\n        # Need to convert seconds to nanoseconds\n        timestamp = int(api_time.timestamp() * 10**9)\n\n        output_rows.append({\n            \"temperature\": float(block.find(\"temperature\").text),\n            \"relative_humidity\": float(block.find(\"humidity\").text),\n            \"heating_setpoint\": float(block.find(\"heatSetting\").text),\n            \"cooling_setpoint\": float(block.find(\"coolSetting\").text),\n            # Driver explicitly uses \"Schedule\" field, but we don't have this in history\n            \"override\": block.find(\"setBy\").text != \"Schedule\",\n            \"fan\": fanState,\n            \"mode\": _mode_name_mappings[block.find(\"system\").text],\n            \"state\": _state_mappings.get(runStatus, 0),\n            \"time\": timestamp,\n        })\n    df = pd.DataFrame(output_rows)\n    df.drop_duplicates(subset=\"time\", keep=\"first\", inplace=True)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_degree_days(self, col='OAT', hdh_cpoint=65, cdh_cpoint=65):\n\n        if self.preprocessed_data.empty:\n            data = self.original_data\n        else:\n            data = self.preprocessed_data\n\n        # Calculate hdh\n        data['hdh'] = data[col]\n        over_hdh = data.loc[:, col] > hdh_cpoint\n        data.loc[over_hdh, 'hdh'] = 0\n        data.loc[~over_hdh, 'hdh'] = hdh_cpoint - data.loc[~over_hdh, col]\n\n        # Calculate cdh\n        data['cdh'] = data[col]\n        under_cdh = data.loc[:, col] < cdh_cpoint\n        data.loc[under_cdh, 'cdh'] = 0\n        data.loc[~under_cdh, 'cdh'] = data.loc[~under_cdh, col] - cdh_cpoint\n\n        self.preprocessed_data = data", "response": "Adds Heating & Cooling Degree Hours to the internal data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_col_features(self, col=None, degree=None):\n\n        if not col and not degree:\n            return\n\n        else:\n            if isinstance(col, list) and isinstance(degree, list):\n                if len(col) != len(degree):\n                    print('col len: ', len(col))\n                    print('degree len: ', len(degree))\n                    raise ValueError('col and degree should have equal length.')\n                else:\n                    if self.preprocessed_data.empty:\n                        data = self.original_data\n                    else:\n                        data = self.preprocessed_data\n\n                    for i in range(len(col)):\n                        data.loc[:,col[i]+str(degree[i])] = pow(data.loc[:,col[i]],degree[i]) / pow(10,degree[i]-1)\n                    \n                    self.preprocessed_data = data\n            else:\n                raise TypeError('col and degree should be lists.')", "response": "Adds features to the dataframe."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds time features to the dataframe.", "response": "def add_time_features(self, year=False, month=False, week=True, tod=True, dow=True):\n        \"\"\" Add time features to dataframe.\n\n        Parameters\n        ----------\n        year    : bool\n            Year.\n        month   : bool\n            Month.\n        week    : bool\n            Week.\n        tod    : bool\n            Time of Day.\n        dow    : bool\n            Day of Week.\n\n        \"\"\"\n\n        var_to_expand = []\n\n        if self.preprocessed_data.empty:\n            data = self.original_data\n        else:\n            data = self.preprocessed_data\n\n        if year:\n            data[\"year\"] = data.index.year\n            var_to_expand.append(\"year\")\n        if month:\n            data[\"month\"] = data.index.month\n            var_to_expand.append(\"month\")\n        if week:\n            data[\"week\"] = data.index.week\n            var_to_expand.append(\"week\")\n        if tod:\n            data[\"tod\"] = data.index.hour\n            var_to_expand.append(\"tod\")\n        if dow:\n            data[\"dow\"] = data.index.weekday\n            var_to_expand.append(\"dow\")\n\n        # One-hot encode the time features\n        for var in var_to_expand:\n                \n                add_var = pd.get_dummies(data[var], prefix=var, drop_first=True)\n                \n                # Add all the columns to the model data\n                data = data.join(add_var)\n\n                # Drop the original column that was expanded\n                data.drop(columns=[var], inplace=True)\n\n        self.preprocessed_data = data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_data(self):\n\n        try:\n            # Extract data ranging in time_period1\n            time_period1 = (slice(self.baseline_period[0], self.baseline_period[1]))\n            self.baseline_in = self.original_data.loc[time_period1, self.input_col]\n            self.baseline_out = self.original_data.loc[time_period1, self.output_col]\n\n            if self.exclude_time_period:\n                for i in range(0, len(self.exclude_time_period), 2):\n                    # Drop data ranging in exclude_time_period1\n                    exclude_time_period1 = (slice(self.exclude_time_period[i], self.exclude_time_period[i+1]))\n                    self.baseline_in.drop(self.baseline_in.loc[exclude_time_period1].index, axis=0, inplace=True)\n                    self.baseline_out.drop(self.baseline_out.loc[exclude_time_period1].index, axis=0, inplace=True)\n        except Exception as e:\n            raise e\n\n        # CHECK: Can optimize this part\n        # Error checking to ensure time_period values are valid\n        if self.projection_period:\n            for i in range(0, len(self.projection_period), 2):\n                period = (slice(self.projection_period[i], self.projection_period[i+1]))\n                try:\n                    self.original_data.loc[period, self.input_col]\n                    self.original_data.loc[period, self.output_col]\n                except Exception as e:\n                    raise e", "response": "Splits the data according to baseline and projection time period values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef linear_regression(self):\n\n        model = LinearRegression()\n        scores = []\n\n        kfold = KFold(n_splits=self.cv, shuffle=True, random_state=42)\n        for i, (train, test) in enumerate(kfold.split(self.baseline_in, self.baseline_out)):\n            model.fit(self.baseline_in.iloc[train], self.baseline_out.iloc[train])\n            scores.append(model.score(self.baseline_in.iloc[test], self.baseline_out.iloc[test]))\n\n        mean_score = sum(scores) / len(scores)\n        \n        self.models.append(model)\n        self.model_names.append('Linear Regression')\n        self.max_scores.append(mean_score)\n\n        self.metrics['Linear Regression'] = {}\n        self.metrics['Linear Regression']['R2'] = mean_score\n        self.metrics['Linear Regression']['Adj R2'] = self.adj_r2(mean_score, self.baseline_in.shape[0], self.baseline_in.shape[1])", "response": "This function runs a linear regression on the current set of resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lasso_regression(self):\n\n        score_list = []\n        max_score = float('-inf')\n        best_alpha = None\n\n        for alpha in self.alphas:\n            # model = Lasso(normalize=True, alpha=alpha, max_iter=5000)\n            model = Lasso(alpha=alpha, max_iter=5000)\n            model.fit(self.baseline_in, self.baseline_out.values.ravel())\n\n            scores = []\n            kfold = KFold(n_splits=self.cv, shuffle=True, random_state=42)\n            for i, (train, test) in enumerate(kfold.split(self.baseline_in, self.baseline_out)):\n                model.fit(self.baseline_in.iloc[train], self.baseline_out.iloc[train])\n                scores.append(model.score(self.baseline_in.iloc[test], self.baseline_out.iloc[test]))\n            mean_score = np.mean(scores)\n\n            score_list.append(mean_score)\n            \n            if mean_score > max_score:\n                max_score = mean_score\n                best_alpha = alpha\n\n        # self.models.append(Lasso(normalize=True, alpha=best_alpha, max_iter=5000))\n        self.models.append(Lasso(alpha=best_alpha, max_iter=5000))\n        self.model_names.append('Lasso Regression')\n        self.max_scores.append(max_score)\n        \n        self.metrics['Lasso Regression'] = {}\n        self.metrics['Lasso Regression']['R2'] = max_score\n        self.metrics['Lasso Regression']['Adj R2'] = self.adj_r2(max_score, self.baseline_in.shape[0], self.baseline_in.shape[1])", "response": "This function runs the lasso regression and stores the results in self. models and self. max_scores."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_models(self):\n\n        self.linear_regression()\n        self.lasso_regression()\n        self.ridge_regression()\n        self.elastic_net_regression()\n        self.random_forest()\n        self.ann()\n\n        # Index of the model with max score\n        best_model_index = self.max_scores.index(max(self.max_scores))\n\n        # Store name of the optimal model\n        self.best_model_name = self.model_names[best_model_index]\n\n        # Store optimal model\n        self.best_model = self.models[best_model_index]\n\n        return self.metrics", "response": "Run all models and return a dict of the models with the best scores."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef custom_model(self, func):\n\n        y_pred = func(self.baseline_in, self.baseline_out)\n\n        self.custom_metrics = {}\n        self.custom_metrics['r2'] = r2_score(self.baseline_out, y_pred)\n        self.custom_metrics['mse'] = mean_squared_error(self.baseline_out, y_pred)\n        self.custom_metrics['rmse'] = math.sqrt(self.custom_metrics['mse'])\n        self.custom_metrics['adj_r2'] = self.adj_r2(self.custom_metrics['r2'], self.baseline_in.shape[0], self.baseline_in.shape[1])\n\n        return self.custom_metrics", "response": "Run custom model provided by user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfits data to optimal model and return its metrics.", "response": "def best_model_fit(self):\n        \"\"\" Fit data to optimal model and return its metrics.\n\n        Returns\n        -------\n        dict\n            Best model's metrics\n\n        \"\"\"\n\n        self.best_model.fit(self.baseline_in, self.baseline_out)\n\n        self.y_true = self.baseline_out                             # Pandas Series\n        self.y_pred = self.best_model.predict(self.baseline_in)     # numpy.ndarray\n\n        # Set all negative values to zero since energy > 0\n        self.y_pred[self.y_pred < 0] = 0\n\n        # n and k values for adj r2 score\n        self.n_test = self.baseline_in.shape[0]   # Number of points in data sample\n        self.k_test = self.baseline_in.shape[1]   # Number of variables in model, excluding the constant\n\n        # Store best model's metrics\n        self.best_metrics['name']   = self.best_model_name\n        self.best_metrics['r2']     = r2_score(self.y_true, self.y_pred)\n        self.best_metrics['mse']    = mean_squared_error(self.y_true, self.y_pred)\n        self.best_metrics['rmse']   = math.sqrt(self.best_metrics['mse'])\n        self.best_metrics['adj_r2'] = self.adj_r2(self.best_metrics['r2'], self.n_test, self.k_test)\n\n        # Normalized Mean Bias Error\n        numerator = sum(self.y_true - self.y_pred)\n        denominator = (self.n_test - self.k_test) * (sum(self.y_true) / len(self.y_true))\n        self.best_metrics['nmbe']   = numerator / denominator\n\n        # MAPE can't have 0 values in baseline_out -> divide by zero error\n        self.baseline_out_copy  = self.baseline_out[self.baseline_out != 0]\n        self.baseline_in_copy   = self.baseline_in[self.baseline_in.index.isin(self.baseline_out_copy.index)]\n        self.y_true_copy = self.baseline_out_copy                             # Pandas Series\n        self.y_pred_copy = self.best_model.predict(self.baseline_in_copy)     # numpy.ndarray\n        self.best_metrics['mape']   = np.mean(np.abs((self.y_true_copy - self.y_pred_copy) / self.y_true_copy)) * 100\n\n        return self.best_metrics"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating heatmap of Pearson s correlation coefficient.", "response": "def correlation_plot(self, data):\n        \"\"\" Create heatmap of Pearson's correlation coefficient.\n\n        Parameters\n        ----------\n        data    : pd.DataFrame()\n            Data to display.\n\n        Returns\n        -------\n        matplotlib.figure\n            Heatmap.\n\n        \"\"\"\n\n        # CHECK: Add saved filename in result.json\n        fig = plt.figure(Plot_Data.count)\n        corr = data.corr()\n        ax = sns.heatmap(corr)\n\n        Plot_Data.count += 1\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating baseline and projection plots.", "response": "def baseline_projection_plot(self, y_true, y_pred, \n                                baseline_period, projection_period,\n                                model_name, adj_r2,\n                                data, input_col, output_col, model,\n                                site):\n        \"\"\" Create baseline and projection plots.\n\n        Parameters\n        ----------\n        y_true              : pd.Series()\n            Actual y values.\n        y_pred              : np.ndarray\n            Predicted y values.\n        baseline_period     : list(str)\n            Baseline period.\n        projection_period   : list(str)\n            Projection periods.\n        model_name          : str\n            Optimal model's name.\n        adj_r2              : float\n            Adjusted R2 score of optimal model.\n        data                : pd.Dataframe()\n            Data containing real values.\n        input_col           : list(str)\n            Predictor column(s).\n        output_col          : str\n            Target column.\n        model               : func\n            Optimal model.\n\n        Returns\n        -------\n        matplotlib.figure\n            Baseline plot\n\n        \"\"\"\n\n        # Baseline and projection plots\n        fig = plt.figure(Plot_Data.count)\n        \n        # Number of plots to display\n        if projection_period:\n            nrows = len(baseline_period) + len(projection_period) / 2\n        else:\n            nrows = len(baseline_period) / 2\n        \n        # Plot 1 - Baseline\n        base_df = pd.DataFrame()\n        base_df['y_true'] = y_true\n        base_df['y_pred'] = y_pred\n        ax1 = fig.add_subplot(nrows, 1, 1)\n        base_df.plot(ax=ax1, figsize=self.figsize,\n            title='Baseline Period ({}-{}). \\nBest Model: {}. \\nBaseline Adj R2: {}. \\nSite: {}.'.format(baseline_period[0], baseline_period[1], \n                                                                                                            model_name, adj_r2, site))\n\n        if projection_period:\n            # Display projection plots\n            num_plot = 2\n            for i in range(0, len(projection_period), 2):\n                ax = fig.add_subplot(nrows, 1, num_plot)\n                period = (slice(projection_period[i], projection_period[i+1]))\n                project_df = pd.DataFrame()\n                \n                try:    \n                    project_df['y_true'] = data.loc[period, output_col]\n                    project_df['y_pred'] = model.predict(data.loc[period, input_col])\n\n                    # Set all negative values to zero since energy > 0\n                    project_df['y_pred'][project_df['y_pred'] < 0] = 0\n\n                    project_df.plot(ax=ax, figsize=self.figsize, title='Projection Period ({}-{})'.format(projection_period[i], \n                                                                                                        projection_period[i+1]))\n                    num_plot += 1\n                    fig.tight_layout()\n\n                    Plot_Data.count += 1\n                    return fig, project_df['y_true'], project_df['y_pred']\n                except:\n                    raise TypeError(\"If projecting into the future, please specify project_ind_col that has data available \\\n                                        in the future time period requested.\")\n           \n        return fig, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_thermostat_meter_data(zone):\n    meter_uri = zone2meter.get(zone, \"None\")\n    data = []\n    def cb(msg):\n        for po in msg.payload_objects:\n            if po.type_dotted == (2,0,9,1):\n                m = msgpack.unpackb(po.content)\n                data.append(m['current_demand'])\n    handle = c.subscribe(meter_uri+\"/signal/meter\", cb)\n\n    def stop():\n        c.unsubscribe(handle)\n        return data\n    return stop", "response": "This method subscribes to the output of the meter for the given zone and returns a handler to call when you want to stop subscribing data over that time period."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_heat(tstat):\n    current_hsp, current_csp = tstat.heating_setpoint, tstat.cooling_setpoint\n    current_temp = tstat.temperature\n    tstat.write({\n        'heating_setpoint': current_temp+10,\n        'cooling_setpoint': current_temp+20,\n        'mode': HEAT,\n    })\n\n    def restore():\n        tstat.write({\n            'heating_setpoint': current_hsp,\n            'cooling_setpoint': current_csp,\n            'mode': AUTO,\n        })\n    return restore", "response": "Returns a function that can be used to reset the thermostat\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that can be used to reset the thermostat.", "response": "def call_cool(tstat):\n    \"\"\"\n    Adjusts the temperature setpoints in order to call for cooling. Returns\n    a handler to call when you want to reset the thermostat\n    \"\"\"\n    current_hsp, current_csp = tstat.heating_setpoint, tstat.cooling_setpoint\n    current_temp = tstat.temperature\n    tstat.write({\n        'heating_setpoint': current_temp-20,\n        'cooling_setpoint': current_temp-10,\n        'mode': COOL,\n    })\n\n    def restore():\n        tstat.write({\n            'heating_setpoint': current_hsp,\n            'cooling_setpoint': current_csp,\n            'mode': AUTO,\n        })\n    return restore"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function that can be used to toggle the fan state", "response": "def call_fan(tstat):\n    \"\"\"\n    Toggles the fan\n    \"\"\"\n    old_fan = tstat.fan\n\n    tstat.write({\n        'fan': not old_fan,\n    })\n\n    def restore():\n        tstat.write({\n            'fan': old_fan,\n        })\n    return restore"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_csv(self, file_name='*', folder_name='.', head_row=0, index_col=0, convert_col=True, concat_files=False):\n\n        # Import a specific or all csv files in folder\n        if isinstance(file_name, str) and isinstance(folder_name, str):\n            try:\n                self.data = self._load_csv(file_name, folder_name, head_row, index_col, convert_col, concat_files)\n            except Exception as e:\n                raise e\n\n        # Import multiple csv files in a particular folder.\n        elif isinstance(file_name, list) and isinstance(folder_name, str):\n\n            for i, file in enumerate(file_name):\n                if isinstance(head_row, list):\n                    _head_row = head_row[i]\n                else:\n                    _head_row = head_row\n\n                if isinstance(index_col, list):\n                    _index_col = index_col[i]\n                else:\n                    _index_col = index_col\n\n                try:\n                    data_tmp = self._load_csv(file, folder_name, _head_row, _index_col, convert_col, concat_files)\n                    if concat_files:\n                        self.data = self.data.append(data_tmp, ignore_index=False, verify_integrity=False)\n                    else:\n                        self.data = self.data.join(data_tmp, how=\"outer\")\n                except Exception as e:\n                    raise e\n\n        else:\n            # Current implementation can't accept,\n            # 1. file_name of type str and folder_name of type list(str)\n            # 2. file_name and folder_name both of type list(str)\n            raise NotImplementedError(\"Filename and Folder name can't both be of type list.\")", "response": "Imports a CSV file and stores the result in self. data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_csv(self, file_name, folder_name, head_row, index_col, convert_col, concat_files):\n\n        # Denotes all csv files\n        if file_name == \"*\":\n\n            if not os.path.isdir(folder_name):\n                raise OSError('Folder does not exist.')\n            else:\n                file_name_list = sorted(glob.glob(folder_name + '*.csv'))\n\n                if not file_name_list:\n                    raise OSError('Either the folder does not contain any csv files or invalid folder provided.')\n                else:\n                    # Call previous function again with parameters changed (file_name=file_name_list, folder_name=None)\n                    # Done to reduce redundancy of code\n                    self.import_csv(file_name=file_name_list, head_row=head_row, index_col=index_col,\n                                    convert_col=convert_col, concat_files=concat_files)\n                    return self.data\n\n        else:\n            if not os.path.isdir(folder_name):\n                raise OSError('Folder does not exist.')\n            else:\n                path = os.path.join(folder_name, file_name)\n\n                if head_row > 0:\n                    data = pd.read_csv(path, index_col=index_col, skiprows=[i for i in range(head_row-1)])\n                else:\n                    data = pd.read_csv(path, index_col=index_col)\n\n                # Convert time into datetime format\n                try:\n                    # Special case format 1/4/14 21:30\n                    data.index = pd.to_datetime(data.index, format='%m/%d/%y %H:%M')\n                except:\n                    data.index = pd.to_datetime(data.index, dayfirst=False, infer_datetime_format=True)\n\n        # Convert all columns to numeric type\n        if convert_col:\n            # Check columns in dataframe to see if they are numeric\n            for col in data.columns:\n                # If particular column is not numeric, then convert to numeric type\n                if data[col].dtype != np.number:\n                    data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n\n        return data", "response": "Loads a single csv file into a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert time to UTC.", "response": "def convert_to_utc(time):\n        \"\"\" Convert time to UTC\n\n        Parameters\n        ----------\n        time    : str\n            Time to convert. Has to be of the format '2016-01-01T00:00:00-08:00'.\n\n        Returns\n        -------\n        str\n            UTC timestamp.\n\n        \"\"\"\n\n        # time is already in UTC\n        if 'Z' in time:\n            return time\n        else:\n            time_formatted = time[:-3] + time[-2:]\n            dt = datetime.strptime(time_formatted, '%Y-%m-%dT%H:%M:%S%z')\n            dt = dt.astimezone(timezone('UTC'))\n            return dt.strftime('%Y-%m-%dT%H:%M:%SZ')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget meter data from MDAL.", "response": "def get_meter(self, site, start, end, point_type='Green_Button_Meter',\n                  var=\"meter\", agg='MEAN', window='24h', aligned=True, return_names=True):\n        \"\"\" Get meter data from MDAL.\n\n        Parameters\n        ----------\n        site            : str\n            Building name.\n        start           : str\n            Start date - 'YYYY-MM-DDTHH:MM:SSZ'\n        end             : str\n            End date - 'YYYY-MM-DDTHH:MM:SSZ'\n        point_type      : str\n            Type of data, i.e. Green_Button_Meter, Building_Electric_Meter...\n        var             : str\n            Variable - \"meter\", \"weather\"...\n        agg             : str\n            Aggregation - MEAN, SUM, RAW...\n        window          : str\n            Size of the moving window.\n        aligned         : bool\n            ???\n        return_names    : bool\n            ???\n\n        Returns\n        -------\n        (df, mapping, context)\n            ???\n\n        \"\"\"\n\n        # Convert time to UTC\n        start = self.convert_to_utc(start)\n        end = self.convert_to_utc(end)\n    \n        request = self.compose_MDAL_dic(point_type=point_type, site=site, start=start, end=end,\n                                        var=var, agg=agg, window=window, aligned=aligned)\n        resp = self.m.query(request)\n        \n        if return_names:\n            resp = self.replace_uuid_w_names(resp)\n        \n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tstat(self, site, start, end, var=\"tstat_temp\", agg='MEAN', window='24h', aligned=True, return_names=True):\n\n        # Convert time to UTC\n        start = self.convert_to_utc(start)\n        end = self.convert_to_utc(end)\n    \n        point_map = {\n            \"tstat_state\" : \"Thermostat_Status\", \n            \"tstat_hsp\" : \"Supply_Air_Temperature_Heating_Setpoint\", \n            \"tstat_csp\" : \"Supply_Air_Temperature_Cooling_Setpoint\", \n            \"tstat_temp\": \"Temperature_Sensor\" \n        }\n        \n        if isinstance(var,list):\n            point_type = [point_map[point_type] for point_type in var] # list of all the point names using BRICK classes\n        else:\n            point_type = point_map[var] # single value using BRICK classes\n        \n        request = self.compose_MDAL_dic(point_type=point_type, site=site, start=start, end=end,\n                                        var=var, agg=agg, window=window, aligned=aligned)\n        resp = self.m.query(request)\n        \n        if return_names:\n            resp = self.replace_uuid_w_names(resp)\n\n        return resp", "response": "Get thermostat data from MDAL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a dictionary for MDAL request.", "response": "def compose_MDAL_dic(self, site, point_type, \n                        start, end,  var, agg, window, aligned, points=None, return_names=False):\n        \"\"\" Create dictionary for MDAL request.\n\n        Parameters\n        ----------\n        site            : str\n            Building name.\n        start           : str\n            Start date - 'YYYY-MM-DDTHH:MM:SSZ'\n        end             : str\n            End date - 'YYYY-MM-DDTHH:MM:SSZ'\n        point_type      : str\n            Type of data, i.e. Green_Button_Meter, Building_Electric_Meter...\n        var             : str\n            Variable - \"meter\", \"weather\"...\n        agg             : str\n            Aggregation - MEAN, SUM, RAW...\n        window          : str\n            Size of the moving window.\n        aligned         : bool\n            ???\n        return_names    : bool\n            ???\n\n        Returns\n        -------\n        (df, mapping, context)\n            ???\n\n        \"\"\"\n\n        # Convert time to UTC\n        start = self.convert_to_utc(start)\n        end = self.convert_to_utc(end)\n    \n        request = {} \n        \n        # Add Time Details - single set for one or multiple series\n        request['Time'] = {\n            'Start': start,\n            'End': end,\n            'Window': window,\n            'Aligned': aligned\n                           }\n        # Define Variables \n        request[\"Variables\"] = {}\n        request['Composition'] = []\n        request['Aggregation'] = {}\n        \n        if isinstance(point_type, str): # if point_type is a string -> single type of point requested\n            request[\"Variables\"][var] =  self.compose_BRICK_query(point_type=point_type,site=site) # pass one point type at the time\n            request['Composition'] = [var]\n            request['Aggregation'][var] = [agg]\n            \n        elif isinstance(point_type, list): # loop through all the point_types and create one section of the brick query at the time\n\n            for idx, point in enumerate(point_type): \n                request[\"Variables\"][var[idx]] =  self.compose_BRICK_query(point_type=point,site=site) # pass one point type at the time\n                request['Composition'].append(var[idx])\n                \n                if isinstance(agg, str): # if agg is a string -> single type of aggregation requested\n                    request['Aggregation'][var[idx]] = [agg]\n                elif isinstance(agg, list): # if agg is a list -> expected one agg per point\n                    request['Aggregation'][var[idx]] = [agg[idx]]\n        \n        return request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_point_name(self, context):\n        \n        metadata_table = self.parse_context(context)\n        return metadata_table.apply(self.strip_point_name, axis=1)", "response": "Get point name.\n\n        Parameters\n        ----------\n        context     : ???\n            ???\n\n        Returns\n        -------\n        ???\n            ???"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_uuid_w_names(self, resp):\n        \n        col_mapper = self.get_point_name(resp.context)[\"?point\"].to_dict()\n        resp.df.rename(columns=col_mapper, inplace=True)\n        return resp", "response": "Replace the uuid s with names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_weather_power_tstat(self, site, start, end, data_type=['weather', 'power']):\n\n        m = dataclient.MDALClient(\"corbusier.cs.berkeley.edu:8088\")\n\n        request = {\n            \"Variables\": {\n                \"greenbutton\": {\n                    \"Definition\": \"\"\"SELECT ?meter ?meter_uuid FROM %s WHERE {\n                        ?meter rdf:type brick:Green_Button_Meter .\n                        ?meter bf:uuid ?meter_uuid\n                    };\"\"\" % site,\n                },\n                \"weather\": {\n                    \"Definition\": \"\"\"SELECT ?t ?t_uuid FROM %s WHERE {\n                        ?t rdf:type/rdfs:subClassOf* brick:Weather_Temperature_Sensor .\n                        ?t bf:uuid ?t_uuid\n                    };\"\"\" % site,\n                },\n                \"tstat_state\": {\n                    \"Definition\": \"\"\"SELECT ?t ?t_uuid ?tstat FROM %s WHERE {\n                        ?t rdf:type/rdfs:subClassOf* brick:Thermostat_Status .\n                        ?t bf:uuid ?t_uuid\n                        ?t bf:isPointOf ?tstat .\n                        ?tstat rdf:type brick:Thermostat\n                    };\"\"\" % site,\n                },\n                \"tstat_hsp\": {\n                    \"Definition\": \"\"\"SELECT ?t ?t_uuid ?tstat FROM %s WHERE {\n                        ?t rdf:type/rdfs:subClassOf* brick:Supply_Air_Temperature_Heating_Setpoint .\n                        ?t bf:uuid ?t_uuid .\n                        ?t bf:isPointOf ?tstat .\n                        ?tstat rdf:type brick:Thermostat\n                    };\"\"\" % site,\n                },\n                \"tstat_csp\": {\n                    \"Definition\": \"\"\"SELECT ?t ?t_uuid ?tstat FROM %s WHERE {\n                        ?t rdf:type/rdfs:subClassOf* brick:Supply_Air_Temperature_Cooling_Setpoint .\n                        ?t bf:uuid ?t_uuid .\n                        ?t bf:isPointOf ?tstat .\n                        ?tstat rdf:type brick:Thermostat\n                    };\"\"\" % site,\n                },\n                \"tstat_temp\": {\n                    \"Definition\": \"\"\"SELECT ?t ?t_uuid ?tstat FROM %s WHERE {\n                        ?t rdf:type/rdfs:subClassOf* brick:Temperature_Sensor .\n                        ?t bf:uuid ?t_uuid .\n                        ?t bf:isPointOf ?tstat .\n                        ?tstat rdf:type brick:Thermostat\n                    };\"\"\" % site,\n                },\n            },\n        }\n\n        # outside air temp\n        request['Composition'] = ['weather']\n        request['Aggregation'] = {'weather': ['MEAN']}\n        request['Time'] = {\n            'Start': start,\n            'End': end,\n            'Window': '15m',\n            'Aligned': True\n        }\n        resp_weather = m.query(request)\n        self.weather_data = resp_weather.df\n\n        # power\n        request['Composition'] = ['greenbutton']\n        request['Aggregation'] = {'greenbutton': ['MEAN']}\n        resp_power = m.query(request)\n        self.power_data = resp_power.df\n\n        # tstat temperature\n        request['Composition'] = ['tstat_temp', 'tstat_hsp', 'tstat_csp']\n        request['Aggregation'] = {'tstat_temp': ['MEAN']}\n        resp_temp  = m.query(request)\n        self.temp_data = resp_temp\n\n        # tstat heat setpoint\n        request['Composition'] = ['tstat_hsp']\n        request['Aggregation'] = {'tstat_hsp': ['MAX']}\n        resp_hsp = m.query(request)\n        self.hsp_data = resp_hsp\n\n        # tstat cool setpoint\n        request['Composition'] = ['tstat_csp']\n        request['Aggregation'] = {'tstat_csp': ['MAX']}\n        resp_csp = m.query(request)\n        self.csp_data = resp_csp\n\n        mapping = {\n            'weather': resp_weather,\n            'power': resp_power,\n            'temperature': resp_temp, \n            'hsp': resp_hsp,\n            'csp': resp_csp\n        }\n\n        first = True\n        for dat in data_type:\n            if first:\n                try:\n                    self.data = mapping[dat].df\n                    first = False\n                except:\n                    raise SystemError('Undefined data_type (Make sure all characters are lowercase)')\n            else:\n                try:\n                    self.data = self.data.join(mapping[dat].df)\n                except:\n                    raise SystemError('Undefined data_type (Make sure all characters are lowercase)')\n\n        return mapping", "response": "Get weather and power data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndropping columns in dataframe.", "response": "def drop_columns(self, col):\n        \"\"\" Drop columns in dataframe.\n        \n        Parameters\n        ----------\n        col     : str\n            Column to drop.\n\n        \"\"\"\n        try:\n            self.cleaned_data.drop(col, axis=1, inplace=True)\n        except Exception as e:\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rename_columns(self, col):\n        try:\n            self.cleaned_data.columns = col\n        except Exception as e:\n            raise e", "response": "Rename columns of dataframe.\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninterpolates dataframe. Parameters ---------- data : pd.DataFrame() Dataframe to interpolate limit : int Interpolation limit. method : str Interpolation method. Returns ------- pd.DataFrame() Dataframe containing interpolated data", "response": "def interpolate_data(self, data, limit, method):\n        \"\"\" Interpolate dataframe.\n\n        Parameters\n        ----------\n        data    : pd.DataFrame()\n            Dataframe to interpolate\n        limit   : int\n            Interpolation limit.\n        method  : str\n            Interpolation method.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe containing interpolated data\n\n        \"\"\"\n        data = data.interpolate(how=\"index\", limit=limit, method=method)        \n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_na(self, data, remove_na_how):\n        data = data.dropna(how=remove_na_how)        \n        return data", "response": "Remove NA from dataframe."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove outliers from a dataframe.", "response": "def remove_outlier(self, data, sd_val):\n        \"\"\" Remove outliers from dataframe.\n\n        Note\n        ----\n        1. This function excludes all lines with NA in all columns.\n\n        Parameters\n        ----------\n        data    : pd.DataFrame()\n            Dataframe to remove outliers from.\n        sd_val  : int\n            Standard Deviation Value (specifices how many SDs away is a point considered an outlier)\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe with outliers removed.\n\n        \"\"\"\n        data = data.dropna()\n        data = data[(np.abs(stats.zscore(data)) < float(sd_val)).all(axis=1)]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving out of bounds datapoints from a dataframe.", "response": "def remove_out_of_bounds(self, data, low_bound, high_bound):\n        \"\"\" Remove out of bound datapoints from dataframe.\n\n        This function removes all points < low_bound and > high_bound.\n\n        To Do,\n        1. Add a different boundary for each column.\n\n        Parameters\n        ----------\n        data        : pd.DataFrame()\n            Dataframe to remove bounds from.\n        low_bound   : int\n            Low bound of the data.\n        high_bound  : int\n            High bound of the data.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe with out of bounds removed.\n\n        \"\"\"\n        data = data.dropna()\n        data = data[(data > low_bound).all(axis=1) & (data < high_bound).all(axis=1)]        \n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_TS_index(self, data):\n        \n        # Set index\n        data.index = pd.to_datetime(data.index, error= \"ignore\")\n\n        # Format types to numeric\n        for col in data.columns:\n            data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n\n        return data", "response": "Convert index to datetime and all other columns to numeric"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadjusts index of dataframe according to local timezone.", "response": "def _utc_to_local(self, data, local_zone=\"America/Los_Angeles\"):\n        \"\"\" Adjust index of dataframe according to timezone that is requested by user.\n\n        Parameters\n        ----------\n        data        : pd.DataFrame()\n            Pandas dataframe of json timeseries response from server.\n\n        local_zone  : str\n            pytz.timezone string of specified local timezone to change index to.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Pandas dataframe with timestamp index adjusted for local timezone.\n        \"\"\"\n\n        # Accounts for localtime shift\n        data.index = data.index.tz_localize(pytz.utc).tz_convert(local_zone)\n        \n        # Gets rid of extra offset information so can compare with csv data\n        data.index = data.index.tz_localize(None)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _local_to_utc(self, timestamp, local_zone=\"America/Los_Angeles\"):\n\n        timestamp_new = pd.to_datetime(timestamp, infer_datetime_format=True, errors='coerce')\n        timestamp_new = timestamp_new.tz_localize(local_zone).tz_convert(pytz.utc)\n        timestamp_new = timestamp_new.strftime('%Y-%m-%d %H:%M:%S')\n        return timestamp_new", "response": "Convert local timestamp to UTC."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove start NaN from a dataframe.", "response": "def remove_start_NaN(self, data, var=None):\n        \"\"\" Remove start NaN.\n        \n        CHECK: Note issue with multi-column df.\n        \n        Parameters\n        ----------\n        data    : pd.DataFrame()\n            Input dataframe.\n        var     : list(str)\n            List that specifies specific columns of dataframe.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe starting from its first valid index.\n       \n        \"\"\"\n\n        # Limit to one or some variables\n        if var:\n            start_ok_data = data[var].first_valid_index()\n        else:\n            start_ok_data = data.first_valid_index()\n      \n        data = data.loc[start_ok_data:, :]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove end NaN. CHECK: Note issue with multi-column df. Parameters ---------- data : pd.DataFrame() Input dataframe. var : list(str) List that specifies specific columns of dataframe. Returns ------- pd.DataFrame() Dataframe starting from its last valid index.", "response": "def remove_end_NaN(self, data, var=None):\n        \"\"\" Remove end NaN.\n        \n        CHECK: Note issue with multi-column df.\n        \n        Parameters\n        ----------\n        data    : pd.DataFrame()\n            Input dataframe.\n        var     : list(str)\n            List that specifies specific columns of dataframe.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe starting from its last valid index.\n       \n        \"\"\"\n        \n        # Limit to one or some variables\n        if var:\n            end_ok_data = data[var].last_valid_index()\n        else:\n            end_ok_data = data.last_valid_index()\n\n        data = data.loc[:end_ok_data, :]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_missing(self, data, return_bool=False):\n\n        # This returns the full table with True where the condition is true\n        if return_bool == False:\n            data = self._find_missing_return_frame(data)\n            return data\n\n        # This returns a bool selector if any of the column is True\n        elif return_bool == \"any\":\n            bool_sel = self._find_missing_return_frame(data).any(axis=0)\n            return bool_sel\n\n        # This returns a bool selector if all of the column are True\n        elif return_bool == \"all\":\n            bool_sel = self._find_missing_return_frame(data).all(axis=0)\n            return bool_sel\n        \n        else:\n            print(\"error in multi_col_how input\")", "response": "This function returns a dataframe with the missing entries in the table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef display_missing(self, data, return_bool=\"any\"):\n\n        if return_bool == \"any\":\n            bool_sel = self._find_missing(data, return_bool=\"any\")\n\n        elif return_bool == \"all\":\n            bool_sel = self._find_missing(data, return_bool=\"all\")\n\n        return data[bool_sel]", "response": "Display missing entries in the dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts missing entries in a dataframe.", "response": "def count_missing(self, data, output=\"number\"):\n        \"\"\" ???\n        \n        Parameters\n        ----------\n        data    : pd.DataFrame()\n            Input dataframe.\n        output  : str\n            Sting indicating the output of function (number or percent)\n\n        Returns\n        -------\n        int/float\n            Count of missing data (int or float)\n\n        \"\"\"\n\n        count = self._find_missing(data,return_bool=False).sum()\n\n        if output == \"number\":\n            return count\n        elif output == \"percent\":\n            return ((count / (data.shape[0])) * 100)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove missing entries from a dataframe.", "response": "def remove_missing(self, data, return_bool=\"any\"):\n        \"\"\" ??? \n        \n        Parameters\n        ----------\n        data            : pd.DataFrame()\n            Input dataframe.\n        return_bool     : bool\n            ???\n\n        Returns\n        -------\n        pd.DataFrame()\n            ???\n\n        \"\"\"\n\n        if return_bool == \"any\":\n            bool_sel = self._find_missing(data,return_bool=\"any\")\n        elif return_bool == \"all\":\n            bool_sel = self._find_missing(data,return_bool=\"all\")\n\n        return data[~bool_sel]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmask for selecting data that is out of bounds.", "response": "def _find_outOfBound(self, data, lowBound, highBound):\n        \"\"\" Mask for selecting data that is out of bounds. \n        \n        Parameters\n        ----------\n        data        : pd.DataFrame()\n            Input dataframe.\n        lowBound    : float\n            Lower bound for dataframe.\n        highBound   : float\n            Higher bound for dataframe.\n\n        Returns\n        -------\n        ???   \n\n        \"\"\"\n\n        data = ((data < lowBound) | (data > highBound))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef display_outOfBound(self, data, lowBound, highBound):\n\n        data = data[self._find_outOfBound(data, lowBound, highBound).any(axis=1)]\n        return data", "response": "Display data that is out of bound."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count_outOfBound(self, data, lowBound, highBound, output):\n\n        count = self._find_outOfBound(data, lowBound, highBound).sum()\n        \n        if output == \"number\":\n            return count\n        elif output == \"percent\":\n            return count / (data.shape[0]) * 1.0 * 100", "response": "Counts the number of out of bounds data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_outOfBound(self, data, lowBound, highBound):\n\n        data = data[~self._find_outOfBound(data, lowBound, highBound).any(axis=1)]\n        return data", "response": "Remove out of bounds data from input dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _calc_outliers_bounds(self, data, method, coeff, window):\n       \n        if method == \"std\":\n            lowBound = (data.mean(axis=0) - coeff * data.std(axis=0)).values[0]\n            highBound = (data.mean(axis=0) + coeff * data.std(axis=0)).values[0]\n\n        elif method == \"rstd\":\n            rl_mean=data.rolling(window=window).mean(how=any)\n            rl_std = data.rolling(window=window).std(how=any).fillna(method='bfill').fillna(method='ffill')\n            \n            lowBound = rl_mean - coeff * rl_std\n            highBound = rl_mean + coeff * rl_std\n\n        elif method == \"rmedian\":\n            rl_med = data.rolling(window=window, center=True).median().fillna(\n                method='bfill').fillna(method='ffill')\n\n            lowBound =  rl_med - coeff\n            highBound = rl_med + coeff\n\n        # Coeff is multip for std and IQR or threshold for rolling median\n        elif method == \"iqr\":\n            Q1 = data.quantile(.25) # Coeff is multip for std or % of quartile\n            Q3 = data.quantile(.75)\n            IQR = Q3 - Q1\n\n            lowBound = Q1 - coeff * IQR\n            highBound = Q3 + coeff * IQR\n\n        elif method == \"qtl\":\n            lowBound = data.quantile(.005)\n            highBound = data.quantile(.995)\n\n        else:\n            print (\"Method chosen does not exist\")\n            lowBound = None\n            highBound = None\n\n        return lowBound, highBound", "response": "Calculates the lower and higher bound for detection outliers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying outliers in a dataframe.", "response": "def display_outliers(self, data, method, coeff, window=10):\n        \"\"\" Returns dataframe with outliers.\n        \n        Parameters\n        ----------\n        data        : pd.DataFrame()\n            Input dataframe.\n        method      : str\n            Method to use for calculating the lower and higher bounds.\n        coeff       : int\n            Coefficient to use in calculation.\n        window      : int\n            Size of the moving window.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe containing outliers.\n\n        \"\"\"\n        \n        lowBound, highBound = self._calc_outliers_bounds(data, method, coeff, window)\n        data = self.display_outOfBound(data, lowBound, highBound)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_outliers(self, data, method, coeff, output, window=10):\n        \n        lowBound, highBound = self._calc_outliers_bounds(data, method, coeff, window)\n        count = self.count_outOfBound(data, lowBound, highBound, output=output)\n        return count", "response": "Counts the number of outliers in dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_outliers(self, data, method, coeff, window=10):\n        \n        lowBound, highBound = self._calc_outliers_bounds(data, method, coeff, window)\n        data = self.remove_outOfBound(data, lowBound, highBound)\n        return data", "response": "Remove outliers in dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of values that match the condition.", "response": "def count_if(self, data, condition, val, output=\"number\"):\n        \"\"\" Count the number of values that match the condition.\n        \n        Parameters\n        ----------\n        data        : pd.DataFrame()\n            Input dataframe.\n        condition   : str\n            Condition to match.\n        val         : float\n            Value to compare against.\n        output      : str\n            Sting indicating the output of function (number or percent)\n\n        Returns\n        -------\n        int/float\n            Count of values that match the condition (int or float)\n\n        \"\"\" \n        \n        if condition == \"=\":\n            count = self._find_equal_to_values(data,val).sum()\n        elif condition == \">\":\n            count = self._find_greater_than_values(data,val).sum()\n        elif condition == \"<\":\n            count = self._find_less_than_values(data,val).sum()\n        elif condition == \">=\":\n            count = self._find_greater_than_or_equal_to_values(data,val).sum()\n        elif condition == \"<=\":\n            count = self._find_less_than_or_equal_to_values(data,val).sum()\n        elif condition == \"!=\":\n            count = self._find_different_from_values(data,val).sum()\n        \n        if output == \"number\":\n            return count\n        elif output == \"percent\":\n            return count/data.shape[0]*1.0*100\n\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_uuid(self, obj, column_name):\n\n        keys = obj.context.keys()\n\n        for i in keys:\n            if column_name in obj.context[i]['?point']:\n                uuid = i\n\n        return i", "response": "Find the uuid that corresponds with the input point"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef identify_missing(self, df, check_start=True):\n\n        # Check start changes the first value of df to 1, when the data stream is initially missing\n        # This allows the diff function to acknowledge the missing data\n        data_missing = df.isnull() * 1\n        col_name = str(data_missing.columns[0])\n\n        # When there is no data stream at the beginning we change it to 1\n        if check_start & data_missing[col_name][0] == 1:\n            data_missing[col_name][0] = 0\n\n        return data_missing, col_name", "response": "Identify missing data.\n\n        Parameters\n        ----------\n        df              : pd.DataFrame()\n            Dataframe to check for missing data.\n        check_start     : bool\n            turns 0 to 1 for the first observation, to display the start of the data\n        as the beginning of the missing data event\n\n        Returns\n        -------\n        pd.DataFrame(), str\n            dataframe where 1 indicates missing data and 0 indicates reported data,\n        returns the column name generated from the MDAL Query"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diff_boolean(self, df, column_name=None, uuid=None, duration=True, min_event_filter='3 hours'):\n\n        if uuid == None:\n            uuid = 'End'\n\n        data_gaps = df[(df.diff() == 1) | (df.diff() == -1)].dropna()\n        data_gaps[\"duration\"] = abs(data_gaps.index.to_series().diff(periods=-1))\n\n        data_gaps[uuid] = data_gaps.index + (data_gaps[\"duration\"])\n\n        data_gaps = data_gaps[data_gaps[\"duration\"] > pd.Timedelta(min_event_filter)]\n        data_gaps = data_gaps[data_gaps[column_name] == 1]\n        data_gaps.pop(column_name)\n        if not duration:\n            data_gaps.pop('duration')\n        data_gaps.index = data_gaps.index.strftime(date_format=\"%Y-%m-%d %H:%M:%S\")\n        data_gaps[uuid] = data_gaps[uuid].dt.strftime(date_format=\"%Y-%m-%d %H:%M:%S\")\n\n        return data_gaps", "response": "Takes a dataframe of missing values and returns a dataframe that indicates the number of events that have been continuously missing."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nanalyze the quality table of the data for each column of the object.", "response": "def analyze_quality_table(self, obj,low_bound=None, high_bound=None):\n        \"\"\" Takes in an the object returned by the MDAL query, and analyzes the quality \n        of the data for each column in the df. Returns a df of data quality metrics\n\n        To Do\n        -----\n        Need to make it specific for varying meters and label it for each type,\n        Either separate functions or make the function broader\n\n        Parameters\n        ----------\n        obj             : ???\n            the object returned by the MDAL Query\n\n        low_bound       : float\n            all data equal to or below this value will be interpreted as missing data\n        high_bound      : float\n            all data above this value will be interpreted as missing\n\n        Returns\n        -------\n        pd.DataFrame()\n          returns data frame with % missing data, average duration of missing data \n        event and standard deviation of that duration for each column of data\n\n        \"\"\"\n\n        data = obj.df\n        N_rows = 3\n        N_cols = data.shape[1]\n        d = pd.DataFrame(np.zeros((N_rows, N_cols)),\n                         index=['% Missing', 'AVG Length Missing', 'Std dev. Missing'],\n                         columns=[data.columns])\n\n        \n        if low_bound:\n            data = data.where(data >= low_bound)\n        if high_bound:\n            data=data.where(data < high_bound)\n\n\n        for i in range(N_cols):\n\n            data_per_meter = data.iloc[:, [i]]\n\n            data_missing, meter = self.identify_missing(data_per_meter)\n            percentage = data_missing.sum() / (data.shape[0]) * 100\n            data_gaps = self.diff_boolean(data_missing, column_name=meter)\n\n            missing_mean = data_gaps.mean()\n            std_dev = data_gaps.std()\n            d.loc[\"% Missing\", meter] = percentage[meter]\n            d.loc[\"AVG Length Missing\", meter] = missing_mean['duration']\n            d.loc[\"Std dev. Missing\", meter] = std_dev['duration']\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nanalyzes the quality of the object returned by the MDAL query and returns a list of graphs each containing the number of missing data events over time and the number of missing data frequency during each hour of the day of the missing data.", "response": "def analyze_quality_graph(self, obj):\n        \"\"\" Takes in an the object returned by the MDAL query, and analyzes the quality \n        of the data for each column in the df in the form of graphs. The Graphs returned\n        show missing data events over time, and missing data frequency during each hour\n        of the day\n\n        To Do\n        -----\n        Need to make it specific for varying meters and label it for each type,\n        Either separate functions or make the function broader\n\n        Parameters\n        ----------\n        obj             : ???\n            the object returned by the MDAL Query\n\n        \"\"\"\n\n        data = obj.df\n\n        for i in range(data.shape[1]):\n\n            data_per_meter = data.iloc[:, [i]]  # need to make this work or change the structure\n\n            data_missing, meter = self.identify_missing(data_per_meter)\n            percentage = data_missing.sum() / (data.shape[0]) * 100\n\n            print('Percentage Missing of ' + meter + ' data: ' + str(int(percentage)) + '%')\n            data_missing.plot(figsize=(18, 5), x_compat=True, title=meter + \" Missing Data over the Time interval\")\n            data_gaps = self.diff_boolean(data_missing, column_name=meter)\n\n            data_missing['Hour'] = data_missing.index.hour\n            ymax = int(data_missing.groupby('Hour').sum().max() + 10)\n            data_missing.groupby('Hour').sum().plot(ylim=(0, ymax), figsize=(18, 5),\n                                                    title=meter + \" Time of Day of Missing Data\")\n\n            print(data_gaps)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking in an object and returns a dictionary with the missing data events for each column in the object", "response": "def event_duration(self, obj, dictionary, low_bound=None, high_bound=None):\n        \"\"\" Takes in an object and returns a dictionary with the missing data events (start and end)\n        for each column in the inputted object (will map to a uuid)\n\n        To Do\n        -----\n        Need to make it specific for varying meters and label it for each type,\n        Either separate functions or make the function broader\n\n        Parameters\n        ----------\n        obj             : ???\n            the object returned by the MDAL Query\n        dictionary      : dict\n            name of the dictionary\n        low_bound       : float\n             all data equal to or below this value will be interpreted as missing data\n        high_bound      : float\n             all data above this value will be interpreted as missing data\n\n        Returns\n        -------\n        dict\n            dictionary with the format:\n            {uuid:{start of event 1: end of event 1, start of event 2: end of event 2, ...}, uuid:{..}}\n\n        \"\"\"\n\n        data = obj.df\n        N_cols = data.shape[1]\n\n        if low_bound:\n            data = data.where(data >= low_bound)\n        if high_bound:\n            data=data.where(data < high_bound)\n\n        for i in range(N_cols):\n\n            data_per_meter = data.iloc[:, [i]]\n\n            data_missing, meter = self.identify_missing(data_per_meter)\n            uuid = self.find_uuid(obj, column_name=meter)\n            data_gaps = self.diff_boolean(data_missing, meter, uuid)\n\n            dictionary_solo = data_gaps.to_dict()\n            dictionary[uuid] = dictionary_solo[uuid]\n            # dictionary[uuid]=data_gaps # uncomment to get a dictionary of dfs\n\n        return dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_data(self, resample=True, freq='h', resampler='mean',\n                    interpolate=True, limit=1, method='linear',\n                    remove_na=True, remove_na_how='any', \n                    remove_outliers=True, sd_val=3, \n                    remove_out_of_bounds=True, low_bound=0, high_bound=9998):\n        \"\"\" Clean dataframe.\n\n        Parameters\n        ----------\n        resample                : bool\n            Indicates whether to resample data or not.\n        freq                    : str\n            Resampling frequency i.e. d, h, 15T...\n        resampler               : str\n            Resampling type i.e. mean, max.\n        interpolate             : bool\n            Indicates whether to interpolate data or not.\n        limit                   : int\n            Interpolation limit.\n        method                  : str\n            Interpolation method.\n        remove_na               : bool\n            Indicates whether to remove NAs or not.\n        remove_na_how           : str\n            Specificies how to remove NA i.e. all, any...\n        remove_outliers         : bool\n            Indicates whether to remove outliers or not.\n        sd_val                  : int\n            Standard Deviation Value (specifices how many SDs away is a point considered an outlier)\n        remove_out_of_bounds    : bool\n            Indicates whether to remove out of bounds datapoints or not.\n        low_bound               : int\n            Low bound of the data.\n        high_bound              : int\n            High bound of the data.\n\n        \"\"\"\n\n        # Store copy of the original data\n        data = self.original_data\n\n        if resample:\n            try:\n                data = self.resample_data(data, freq, resampler)\n            except Exception as e:\n                raise e\n\n        if interpolate:\n            try:\n                data = self.interpolate_data(data, limit=limit, method=method)\n            except Exception as e:\n                raise e\n        \n        if remove_na:\n            try:\n                data = self.remove_na(data, remove_na_how)\n            except Exception as e:\n                raise e\n\n        if remove_outliers:\n            try:\n                data = self.remove_outliers(data, sd_val)\n            except Exception as e:\n                raise e\n\n        if remove_out_of_bounds:\n            try:\n                data = self.remove_out_of_bounds(data, low_bound, high_bound)\n            except Exception as e:\n                raise e\n\n        self.cleaned_data = data", "response": "Clean the data for a specific entry in the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of json files in the results directory and dump them in new file", "response": "def get_global_count(self):\n        \"\"\" Return global count (used for naming of .json and .png files) \n\n        Returns\n        -------\n        int\n            Global count\n\n        \"\"\"\n        \n        # Check current number of json files in results directory and dump current json in new file\n        path_to_json = self.results_folder_name + '/'\n        json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n        Wrapper.global_count = len(json_files) + 1\n        return Wrapper.global_count"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_json(self):\n\n        with open(self.results_folder_name + '/results-' + str(self.get_global_count()) + '.json', 'a') as f:\n            json.dump(self.result, f)", "response": "Dump data into json file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsummarizing site data into a single table. folder_name : str Folder where all site data resides. site_event_mapping : dic Dictionary of site name to date of installation. end_date : str End date of data collected.", "response": "def site_analysis(self, folder_name, site_install_mapping, end_date):\n        \"\"\" Summarize site data into a single table.\n\n        folder_name         : str\n            Folder where all site data resides.\n        site_event_mapping  : dic\n            Dictionary of site name to date of installation.\n        end_date            : str\n            End date of data collected.\n\n        \"\"\"\n\n        def count_number_of_days(site, end_date):\n            \"\"\" Counts the number of days between two dates.\n\n            Parameters\n            ----------\n            site        : str\n                Key to a dic containing site_name -> pelican installation date.\n            end_date    : str\n                End date.\n\n            Returns\n            -------\n            int\n                Number of days\n\n            \"\"\"\n            \n            start_date = site_install_mapping[site]\n            start_date = start_date.split('-')\n            start = date(int(start_date[0]), int(start_date[1]), int(start_date[2]))\n            \n            end_date = end_date.split('-')\n            end = date(int(end_date[0]), int(end_date[1]), int(end_date[2]))\n            \n            delta = end - start\n            return delta.days\n\n\n        if not folder_name or not isinstance(folder_name, str):\n            raise TypeError(\"folder_name should be type string\")\n        else:\n            list_json_files = []\n            df      = pd.DataFrame()\n            temp_df = pd.DataFrame()\n            json_files = [f for f in os.listdir(folder_name) if f.endswith('.json')]\n            \n            for json_file in json_files:\n                \n                with open(folder_name + json_file) as f:\n                    js = json.load(f)\n                    num_days = count_number_of_days(js['Site'], end_date)\n                \n                    e_abs_sav = round(js['Energy Savings (absolute)'] / 1000, 2) # Energy Absolute Savings\n                    e_perc_sav = round(js['Energy Savings (%)'], 2) # Energy Percent Savings\n                    ann_e_abs_sav = (e_abs_sav / num_days) * 365 # Annualized Energy Absolute Savings\n                    \n                    d_abs_sav = round(js['User Comments']['Dollar Savings (absolute)'], 2) # Dollar Absolute Savings\n                    d_perc_sav = round(js['User Comments']['Dollar Savings (%)'], 2) # Dollar Percent Savings\n                    ann_d_abs_sav = (d_abs_sav / num_days) * 365 # Annualized Dollar Absolute Savings\n\n                    temp_df = pd.DataFrame({\n                        'Site': js['Site'],\n                        '#Days since Pelican Installation': num_days,\n\n                        'Energy Savings (%)': e_perc_sav,\n                        'Energy Savings (kWh)': e_abs_sav,\n                        'Annualized Energy Savings (kWh)': ann_e_abs_sav,\n                        \n                        'Dollar Savings (%)': d_perc_sav,\n                        'Dollar Savings ($)': d_abs_sav,\n                        'Annualized Dollar Savings ($)': ann_d_abs_sav,\n                        \n                        'Best Model': js['Model']['Optimal Model\\'s Metrics']['name'],\n                        'Adj R2': round(js['Model']['Optimal Model\\'s Metrics']['adj_cross_val_score'], 2),\n                        \n                        'RMSE': round(js['Model']['Optimal Model\\'s Metrics']['rmse'], 2),\n                        'MAPE': js['Model']['Optimal Model\\'s Metrics']['mape'],\n                        'Uncertainity': js['Uncertainity'],\n                    }, index=[0])\n                \n                df = df.append(temp_df)\n\n            df.set_index('Site', inplace=True)\n            return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a json file and returns a Pandas Dataframe containing the data.", "response": "def read_json(self, file_name=None, input_json=None, imported_data=pd.DataFrame()):\n        \"\"\" Read input json file.\n\n        Notes\n        -----\n        The input json file should include ALL parameters.\n\n        Parameters\n        ----------\n        file_name   : str\n            Filename to be read.\n        input_json  : dict\n            JSON object to be read.\n        imported_data   : pd.DataFrame()\n            Pandas Dataframe containing data.\n\n        \"\"\"\n\n        if not file_name and not input_json or file_name and input_json:\n            raise TypeError('Provide either json file or json object to read.')\n        \n        # Read json file\n        if file_name:\n            if not isinstance(file_name, str) or not file_name.endswith('.json') or not os.path.isfile('./'+file_name):\n                raise TypeError('File name should be a valid .json file residing in current directory.')\n            else:\n                f = open(file_name)\n                input_json = json.load(f)\n\n        if imported_data.empty:\n            import_json = input_json['Import']\n            imported_data = self.import_data(file_name=import_json['File Name'], folder_name=import_json['Folder Name'],\n                                            head_row=import_json['Head Row'], index_col=import_json['Index Col'],\n                                            convert_col=import_json['Convert Col'], concat_files=import_json['Concat Files'],\n                                            save_file=import_json['Save File'])\n\n        clean_json = input_json['Clean']\n        cleaned_data = self.clean_data(imported_data, rename_col=clean_json['Rename Col'], drop_col=clean_json['Drop Col'],\n                                        resample=clean_json['Resample'], freq=clean_json['Frequency'], resampler=clean_json['Resampler'],\n                                        interpolate=clean_json['Interpolate'], limit=clean_json['Limit'],\n                                        method=clean_json['Method'], remove_na=clean_json['Remove NA'],\n                                        remove_na_how=clean_json['Remove NA How'], remove_outliers=clean_json['Remove Outliers'],\n                                        sd_val=clean_json['SD Val'], remove_out_of_bounds=clean_json['Remove Out of Bounds'],\n                                        low_bound=clean_json['Low Bound'], high_bound=clean_json['High Bound'],\n                                        save_file=clean_json['Save File'])\n\n        preproc_json = input_json['Preprocess']\n        preprocessed_data = self.preprocess_data(cleaned_data, cdh_cpoint=preproc_json['CDH CPoint'],\n                                                hdh_cpoint=preproc_json['HDH CPoint'], col_hdh_cdh=preproc_json['HDH CDH Calc Col'],\n                                                col_degree=preproc_json['Col Degree'], degree=preproc_json['Degree'],\n                                                standardize=preproc_json['Standardize'], normalize=preproc_json['Normalize'],\n                                                year=preproc_json['Year'], month=preproc_json['Month'], week=preproc_json['Week'],\n                                                tod=preproc_json['Time of Day'], dow=preproc_json['Day of Week'],\n                                                save_file=preproc_json['Save File'])\n\n        model_json = input_json['Model']\n        model_data = self.model(preprocessed_data, ind_col=model_json['Independent Col'], dep_col=model_json['Dependent Col'],\n                                project_ind_col=model_json['Projection Independent Col'],\n                                baseline_period=model_json['Baseline Period'], projection_period=model_json['Projection Period'],\n                                exclude_time_period=model_json['Exclude Time Period'],\n                                alphas=model_json['Alphas'], cv=model_json['CV'], plot=model_json['Plot'], figsize=model_json['Fig Size'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns models on different data configurations.", "response": "def search(self, file_name, imported_data=None):\n        \"\"\" Run models on different data configurations.\n\n        Note\n        ----\n        The input json file should include ALL parameters.\n\n        Parameters\n        ----------\n        file_name       : str\n            Optional json file to read parameters.\n        imported_data   : pd.DataFrame()\n            Pandas Dataframe containing data.\n\n        \"\"\"\n\n        resample_freq=['15T', 'h', 'd']\n        time_freq = {\n            'year'  :   [True,  False,  False,  False,  False],\n            'month' :   [False, True,   False,  False,  False],\n            'week'  :   [False, False,  True,   False,  False],\n            'tod'   :   [False, False,  False,  True,   False],\n            'dow'   :   [False, False,  False,  False,  True],\n        }\n        \n        optimal_score = float('-inf')\n        optimal_model = None\n\n        # CSV Files\n        if not imported_data:\n            with open(file_name) as f:\n                input_json = json.load(f)\n                import_json = input_json['Import']\n                imported_data = self.import_data(file_name=import_json['File Name'], folder_name=import_json['Folder Name'],\n                                                head_row=import_json['Head Row'], index_col=import_json['Index Col'],\n                                                convert_col=import_json['Convert Col'], concat_files=import_json['Concat Files'],\n                                                save_file=import_json['Save File'])\n\n        with open(file_name) as f:\n            input_json = json.load(f)\n\n            for x in resample_freq: # Resample data interval\n                input_json['Clean']['Frequency'] = x\n\n                for i in range(len(time_freq.items())): # Add time features\n                    input_json['Preprocess']['Year']        = time_freq['year'][i]\n                    input_json['Preprocess']['Month']       = time_freq['month'][i]\n                    input_json['Preprocess']['Week']        = time_freq['week'][i]\n                    input_json['Preprocess']['Time of Day'] = time_freq['tod'][i]\n                    input_json['Preprocess']['Day of Week'] = time_freq['dow'][i]\n\n                    # Putting comment in json file to indicate which parameters have been changed\n                    time_feature = None\n                    for key in time_freq:\n                        if time_freq[key][i]:\n                            time_feature = key\n                    self.result['Comment'] = 'Freq: ' + x + ', ' + 'Time Feature: ' + time_feature\n\n                    # Read parameters in input_json\n                    self.read_json(file_name=None, input_json=input_json, imported_data=imported_data)\n                    \n                    # Keep track of highest adj_r2 score\n                    if self.result['Model']['Optimal Model\\'s Metrics']['adj_r2'] > optimal_score:\n                        optimal_score = self.result['Model']['Optimal Model\\'s Metrics']['adj_r2']\n                        optimal_model_file_name = self.results_folder_name + '/results-' + str(self.get_global_count()) + '.json'\n\n                    # Wrapper.global_count += 1\n\n        print('Most optimal model: ', optimal_model_file_name)\n        freq = self.result['Comment'].split(' ')[1][:-1]\n        time_feat = self.result['Comment'].split(' ')[-1]\n        print('Freq: ', freq, 'Time Feature: ', time_feat)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_data(self, file_name='*', folder_name='.', head_row=0, index_col=0,\n                    convert_col=True, concat_files=False, save_file=True):\n        \"\"\" Imports csv file(s) and stores the result in self.imported_data.\n            \n        Note\n        ----\n        1. If folder exists out of current directory, folder_name should contain correct regex\n        2. Assuming there's no file called \"\\*.csv\"\n\n        Parameters\n        ----------\n        file_name       : str\n            CSV file to be imported. Defaults to '\\*' - all csv files in the folder.\n        folder_name     : str\n            Folder where file resides. Defaults to '.' - current directory.\n        head_row        : int\n            Skips all rows from 0 to head_row-1\n        index_col       : int\n            Skips all columns from 0 to index_col-1\n        convert_col     : bool\n            Convert columns to numeric type\n        concat_files    : bool\n            Appends data from files to result dataframe\n        save_file       : bool\n            Specifies whether to save file or not. Defaults to True.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe containing imported data.\n\n        \"\"\"\n        \n        # Create instance and import the data\n        import_data_obj = Import_Data()\n        import_data_obj.import_csv(file_name=file_name, folder_name=folder_name, \n                                head_row=head_row, index_col=index_col, \n                                convert_col=convert_col, concat_files=concat_files)\n        \n        # Store imported data in wrapper class\n        self.imported_data = import_data_obj.data\n\n        # Logging\n        self.result['Import'] = {\n            'File Name': file_name,\n            'Folder Name': folder_name,\n            'Head Row': head_row,\n            'Index Col': index_col,\n            'Convert Col': convert_col,\n            'Concat Files': concat_files,\n            'Save File': save_file\n        }\n        \n        if save_file:\n            f = self.results_folder_name + '/imported_data-' + str(self.get_global_count()) + '.csv'\n            self.imported_data.to_csv(f)\n            self.result['Import']['Saved File'] = f\n        else:\n            self.result['Import']['Saved File'] = ''\n\n        return self.imported_data", "response": "Imports the CSV file and stores the imported data in self. imported_data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_data(self, data, rename_col=None, drop_col=None,\n                    resample=True, freq='h', resampler='mean',\n                    interpolate=True, limit=1, method='linear',\n                    remove_na=True, remove_na_how='any',\n                    remove_outliers=True, sd_val=3,\n                    remove_out_of_bounds=True, low_bound=0, high_bound=float('inf'),\n                    save_file=True):\n        \"\"\" Cleans dataframe according to user specifications and stores result in self.cleaned_data.\n\n        Parameters\n        ----------\n        data                    : pd.DataFrame()\n            Dataframe to be cleaned.\n        rename_col              : list(str)\n            List of new column names.\n        drop_col                : list(str)\n            Columns to be dropped.\n        resample                : bool\n            Indicates whether to resample data or not.\n        freq                    : str\n            Resampling frequency i.e. d, h, 15T... \n        resampler               : str\n            Resampling type i.e. mean, max.\n        interpolate             : bool\n            Indicates whether to interpolate data or not.\n        limit                   : int\n            Interpolation limit.\n        method                  : str\n            Interpolation method.\n        remove_na               : bool\n            Indicates whether to remove NAs or not.\n        remove_na_how           : str\n            Specificies how to remove NA i.e. all, any...\n        remove_outliers         : bool\n            Indicates whether to remove outliers or not.\n        sd_val                  : int\n            Standard Deviation Value (specifices how many SDs away is a point considered an outlier)\n        remove_out_of_bounds    : bool\n            Indicates whether to remove out of bounds datapoints or not.\n        low_bound               : int\n            Low bound of the data.\n        high_bound              : int\n            High bound of the data.\n        save_file       : bool\n            Specifies whether to save file or not. Defaults to True.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe containing cleaned data.\n\n        \"\"\"\n\n        # Check to ensure data is a pandas dataframe\n        if not isinstance(data, pd.DataFrame):\n            raise TypeError('data has to be a pandas dataframe.')\n        \n        # Create instance and clean the data\n        clean_data_obj = Clean_Data(data)\n        clean_data_obj.clean_data(resample=resample, freq=freq, resampler=resampler,\n                                interpolate=interpolate, limit=limit, method=method,\n                                remove_na=remove_na, remove_na_how=remove_na_how,\n                                remove_outliers=remove_outliers, sd_val=sd_val,\n                                remove_out_of_bounds=remove_out_of_bounds, low_bound=low_bound, high_bound=high_bound)\n\n        # Correlation plot\n        # fig = self.plot_data_obj.correlation_plot(clean_data_obj.cleaned_data)\n        # fig.savefig(self.results_folder_name + '/correlation_plot-' + str(Wrapper.global_count) + '.png')\n\n        if rename_col:  # Rename columns of dataframe\n            clean_data_obj.rename_columns(rename_col)\n        if drop_col:    # Drop columns of dataframe\n            clean_data_obj.drop_columns(drop_col)\n\n        # Store cleaned data in wrapper class\n        self.cleaned_data = clean_data_obj.cleaned_data\n\n        # Logging\n        self.result['Clean'] = {\n            'Rename Col': rename_col,\n            'Drop Col': drop_col,\n            'Resample': resample,\n            'Frequency': freq,\n            'Resampler': resampler,\n            'Interpolate': interpolate,\n            'Limit': limit,\n            'Method': method,\n            'Remove NA': remove_na,\n            'Remove NA How': remove_na_how,\n            'Remove Outliers': remove_outliers,\n            'SD Val': sd_val,\n            'Remove Out of Bounds': remove_out_of_bounds,\n            'Low Bound': low_bound,\n            'High Bound': str(high_bound) if high_bound == float('inf') else high_bound,\n            'Save File': save_file\n        }\n\n        if save_file:\n            f = self.results_folder_name + '/cleaned_data-' + str(self.get_global_count()) + '.csv'\n            self.cleaned_data.to_csv(f)\n            self.result['Clean']['Saved File'] = f\n        else:\n            self.result['Clean']['Saved File'] = ''\n\n        return self.cleaned_data", "response": "Cleans the data and stores result in self. cleaned_data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uncertainity_equation(self, model_data_obj, E_measured, E_predicted, confidence_level):\n        \n        # Number of rows in baseline period\n        n = model_data_obj.baseline_in.shape[0]\n\n        # Number of columns in baseline period\n        p = model_data_obj.baseline_in.shape[1]\n        \n        # Number of rows in post period\n        m = E_measured.count()\n        \n        # t-stats value\n        # CHECK: degrees of freedom = E_predicted.count() - 1?\n        t = stats.t.ppf(confidence_level, E_predicted.count() - 1)\n\n        # Rho - Autocorrelation coefficient\n        residuals = E_measured - E_predicted \n        auto_corr = residuals.autocorr(lag=1)\n        rho = pow(auto_corr, 0.5)\n\n        # Effective number of points after accounting for autocorrelation\n        n_prime = n * ((1 - rho) / (1 + rho))\n        \n        # Coefficient of variation of RMSE\n        # CHECK: Is the denominator correct?\n        cv_rmse = pow(sum(pow(E_measured - E_predicted, 2) / (n - p)), 0.5) / (sum(E_measured) / E_measured.count())\n        \n        # Bracket in the numerator - refer to page 20\n        numerator_bracket = pow((n / n_prime) * (1 + (2 / n_prime)) * (1 / m), 0.5)\n        \n        # Esave should be absolute value? \n        f = abs(sum(E_measured - E_predicted) / sum(model_data_obj.y_true))\n           \n        # Main equation \n        uncertainity = t * ((1.26 * cv_rmse * numerator_bracket) / f)\n        \n        return uncertainity", "response": "This function calculates the uncertainity of the model data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_query(self, query, timeout=DEFAULT_TIMEOUT, tz=pytz.timezone(\"US/Pacific\")):\n        nonce = str(random.randint(0, 2**32))\n        query['Nonce'] = nonce\n        ev = threading.Event()\n        response = {}\n        def _handleresult(msg):\n            got_response = False\n            for po in msg.payload_objects:\n                if po.type_dotted != (2,0,10,4): continue\n                data = msgpack.unpackb(po.content)\n                if data['Nonce'] != query['Nonce']: continue\n\n                if 'error' in data:\n                    response['error'] = data['error']\n                    response['df'] = None\n                    got_response=True\n                    continue\n\n                uuids = [str(uuid.UUID(bytes=x)) for x in data['Rows']]\n                data = data_capnp.StreamCollection.from_bytes_packed(data['Data'])\n                if hasattr(data, 'times') and len(data.times):\n                    times = list(data.times)\n                    if len(times) == 0:\n                        response['df'] = pd.DataFrame(columns=uuids)\n                        got_response = True\n                        break\n                    df = pd.DataFrame(index=pd.to_datetime(times, unit='ns', utc=False))\n                    for idx, s in enumerate(data.streams):\n                        if len(s.values) == 0:\n                            df[uuids[idx]] = None\n                        else:\n                            df[uuids[idx]] = s.values\n                    df.index = df.index.tz_localize(pytz.utc).tz_convert(tz)\n                    response['df'] = df\n                    got_response = True\n                else:\n                    df = pd.DataFrame()\n                    for idx, s in enumerate(data.streams):\n                        if hasattr(s, 'times'):\n                            newdf = pd.DataFrame(list(s.values), index=list(s.times), columns=[uuids[idx]])\n                            newdf.index = pd.to_datetime(newdf.index, unit='ns').tz_localize(pytz.utc).tz_convert(tz)\n                            df = df.join(newdf, how='outer')\n                        else:\n                            raise Exception(\"Does this ever happen? Tell gabe!\")\n                    response['df'] = df\n                    got_response = True\n            df = response.get('df')\n            if df is not None:\n                response['df'] = df#[df.index.duplicated(keep='first')]\n            if got_response:\n                ev.set()\n        h = self.c.subscribe(\"{0}/s.mdal/_/i.mdal/signal/{1}\".format(self.url, self.vk[:-1]), _handleresult)\n        po = PayloadObject((2,0,10,3), None, msgpack.packb(query))\n        self.c.publish(\"{0}/s.mdal/_/i.mdal/slot/query\".format(self.url), payload_objects=(po,))\n        ev.wait(timeout)\n        self.c.unsubscribe(h)\n        if 'error' in response:\n            raise Exception(response['error'])\n        return response", "response": "Query the system for the given resource names and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget historical occupancy up until last.", "response": "def get_occupancy(last, bucketsize):\n    \"\"\"\n    We deliver historical occupancy up until \"now\". If the building has occupancy sensors, we pull that data\n    and aggregate it by zone. Take mean occupancy per zone (across all sensors). \n\n    If building does *not* have occupancy sensors, then we need to read the results from some occupancy file.\n    \"\"\"\n    if last not in ['hour','day','week']:\n        return \"Must be hour, day, week\"\n    start_date = get_start(last)\n\n    zones = defaultdict(list)\n    prediction_start = datetime.now(config.TZ)\n\n    md = config.HOD.do_query(occupancy_query)\n    if md['Rows'] is not None:\n        for row in md['Rows']:\n            zones[row['?zone']].append(row['?occ_uuid'])\n        q = occupancy_data_query.copy()\n        q[\"Time\"] = {\n            \"T0\": start_date.strftime(\"%Y-%m-%d %H:%M:%S %Z\"),\n            \"T1\": prediction_start.strftime(\"%Y-%m-%d %H:%M:%S %Z\"),\n            \"WindowSize\": bucketsize,\n            \"Aligned\": True,\n        }\n        resp = config.MDAL.do_query(q, timeout=120)\n        if 'error' in resp:\n            print 'ERROR', resp\n            return\n        df = resp['df'].fillna(method='ffill')\n\n        for zone, uuidlist in zones.items():\n            if len(uuidlist) > 0:\n                zones[zone] = json.loads(df[uuidlist].mean(axis=1).to_json())\n            else:\n                zones[zone] = {}\n\n        # get predicted output\n        prediction_end = get_tomorrow() \n        predicted = list(rrule.rrule(freq=rrule.HOURLY, dtstart=prediction_start, until=prediction_end))\n        for zone, occdict in zones.items():\n            for date in predicted:\n                occdict[int(int(date.strftime('%s'))*1000)] = 'predicted' # prediction\n            zones[zone] = occdict\n    else:\n        md = config.HOD.do_query(zone_query)\n        zonenames = [x['?zone'].lower() for x in md['Rows']]\n        conn = sqlite3.connect('occupancy_schedule.db')\n        sql = conn.cursor()\n        for zone in zonenames:\n            query = \"SELECT * FROM schedules WHERE site='{0}' and zone='{1}' and dayofweek='{2}'\".format(config.SITE, zone, prediction_start.strftime('%A').lower())\n            res = sql.execute(query).fetchall()\n            records = {'time': [], 'occ': [], 'zone': []}\n            for sqlrow in res:\n                hour, minute = sqlrow[3].split(':')\n                time = datetime(year=prediction_start.year, month=prediction_start.month, day=prediction_start.day, hour=int(hour), minute=int(minute), tzinfo=prediction_start.tzinfo)\n                occ = sqlrow[5]\n                zone = sqlrow[1]\n                records['time'].append(time)\n                records['occ'].append(occ)\n                records['zone'].append(zone)\n            df = pd.DataFrame.from_records(records)\n            df = df.set_index(df.pop('time'))\n            if len(df) ==0:\n                continue\n            sched = df.resample(bucketsize.replace('m','T')).ffill()\n            zones[zone] = json.loads(sched['occ'].to_json())\n        conn.close()\n\n    return zones"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_service(prediction_fxn, namespace, prediction_type, block=False):\n    subscribe = '{0}/s.predictions/+/i.{1}/slot/request'.format(namespace, prediction_type)\n    if block:\n        print 'Blocking is True! This will loop forever and program will not exit until killed'\n    else:\n        print 'Blocking is False! This will run in background until program exits or is killed'\n    print 'Subscribe on', subscribe\n    def run():\n        c = get_client(config.AGENT, config.ENTITY)\n        def cb(msg):\n            po = msgpack.unpackb(msg.payload_objects[0].content)\n            if not isinstance(po, dict): return\n            client_id = msg.uri.split('/')[2]\n            start = po.get('predstart')\n            start = parse(start) if start else get_today()\n            end = po.get('predend')\n            end = parse(end) if end else get_today()+datetime.timedelta(days=1)\n            resolution = po.get('resolution', '1h')\n            result = prediction_fxn(start, end, resolution)\n            po = PayloadObject((2,0,0,0), None, msgpack.packb(result))\n            publish = '{0}/s.predictions/{1}/i.{2}/signal/response'.format(namespace, client_id, prediction_type)\n            print \"Respond on\", publish\n            c.publish(publish, payload_objects=(po,))\n        c.subscribe(subscribe, cb)\n        while True:\n            time.sleep(10)\n    t = threading.Thread(target=run)\n    t.daemon = True\n    t.start()\n    while block:\n        time.sleep(10)\n    return t", "response": "Runs the prediction_fxn on the specified namespace and prediction_type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prevmonday(num):\n    today = get_today()\n    lastmonday = today - timedelta(days=today.weekday(), weeks=num)\n    return lastmonday", "response": "Return unix SECOND timestamp of num mondays ago"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef med_filt(x, k=201):\n    if x.ndim > 1:\n        x = np.squeeze(x)\n    med = np.median(x)\n    assert k % 2 == 1, \"Median filter length must be odd.\"\n    assert x.ndim == 1, \"Input must be one-dimensional.\"\n    k2 = (k - 1) // 2\n    y = np.zeros((len(x), k), dtype=x.dtype)\n    y[:, k2] = x\n    for i in range(k2):\n        j = k2 - i\n        y[j:, i] = x[:-j]\n        y[:j, i] = x[0]\n        y[:-j, -(i + 1)] = x[j:]\n        y[-j:, -(i + 1)] = med\n    return np.median(y, axis=1)", "response": "Apply a length - k median filter to a 1D array x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the k days that are similar to the given time.", "response": "def find_similar_days(training_data, now, observation_length, k, method=hamming_distance):\n\tmin_time = training_data.index[0] + timedelta(minutes=observation_length)\n\t# Find moments in our dataset that have the same hour/minute and is_weekend() == weekend.\n\n\tselector = ((training_data.index.minute == now.minute) &\n\t\t\t\t(training_data.index.hour == now.hour) &\n\t\t\t\t(training_data.index > min_time))\n\n\t\"\"\"\n\tif now.weekday() < 5:\n\t\tselector = (\n\t\t\t(training_data.index.minute == now.minute) &\n\t\t\t(training_data.index.hour == now.hour) &\n\t\t\t(training_data.index > min_time) &\n\t\t\t(training_data.index.weekday < 5)\n\t\t)\n\telse:\n\t\tselector = (\n\t\t\t(training_data.index.minute == now.minute) &\n\t\t\t(training_data.index.hour == now.hour) &\n\t\t\t(training_data.index > min_time) &\n\t\t\t(training_data.index.weekday >= 5)\n\t\t)\n\t\"\"\"\n\n\tsimilar_moments = training_data[selector][:-1]\n\n\tobs_td = timedelta(minutes=observation_length)\n\n\tsimilar_moments['Similarity'] = [\n\t\tmethod(\n\t\t\ttraining_data[(training_data.index >= now - obs_td) &\n\t\t\t\t\t\t\t(training_data.index <= now)].get_values(),\n\t\t\ttraining_data[(training_data.index >= i - obs_td) &\n\t\t\t\t\t\t\t(training_data.index <= i)].get_values()\n\t\t) for i in similar_moments.index\n\t\t]\n\n\tindexes = (similar_moments.sort_values('Similarity', ascending=True)\n\t\t\t\t.head(k).index)\n\treturn indexes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef preprocess_data(self, data,\n                        hdh_cpoint=65, cdh_cpoint=65, col_hdh_cdh=None,\n                        col_degree=None, degree=None,\n                        standardize=False, normalize=False,\n                        year=False, month=False, week=False, tod=False, dow=False,\n                        save_file=True):\n        \"\"\" Preprocesses dataframe according to user specifications and stores result in self.preprocessed_data.\n\n        Parameters\n        ----------\n        data            : pd.DataFrame()\n            Dataframe to be preprocessed.\n        hdh_cpoint      : int\n            Heating degree hours. Defaults to 65.\n        cdh_cpoint      : int\n            Cooling degree hours. Defaults to 65.\n        col_hdh_cdh     : str\n            Column name which contains the outdoor air temperature.\n        col_degree      : list(str)\n            Column to exponentiate.\n        degree          : list(str)\n            Exponentiation degree.\n        standardize     : bool\n            Standardize data.\n        normalize       : bool\n            Normalize data.\n        year            : bool\n            Year.\n        month           : bool\n            Month.\n        week            : bool\n            Week.\n        tod             : bool\n            Time of Day.\n        dow             : bool\n            Day of Week.\n        save_file       : bool\n            Specifies whether to save file or not. Defaults to True.\n\n        Returns\n        -------\n        pd.DataFrame()\n            Dataframe containing preprocessed data.\n\n        \"\"\"\n\n        # Check to ensure data is a pandas dataframe\n        if not isinstance(data, pd.DataFrame):\n            raise SystemError('data has to be a pandas dataframe.')\n        \n        # Create instance\n        preprocess_data_obj = Preprocess_Data(data)\n        if col_hdh_cdh:\n            preprocess_data_obj.add_degree_days(col=col_hdh_cdh, hdh_cpoint=hdh_cpoint, cdh_cpoint=cdh_cpoint)\n        preprocess_data_obj.add_col_features(col=col_degree, degree=degree)\n\n        if standardize:\n            preprocess_data_obj.standardize()\n        if normalize:\n            preprocess_data_obj.normalize()\n\n        preprocess_data_obj.add_time_features(year=year, month=month, week=week, tod=tod, dow=dow)\n        \n        # Store preprocessed data in wrapper class\n        self.preprocessed_data = preprocess_data_obj.preprocessed_data\n\n        # Logging\n        self.result['Preprocess'] = {\n            'HDH CPoint': hdh_cpoint,\n            'CDH CPoint': cdh_cpoint,\n            'HDH CDH Calc Col': col_hdh_cdh,\n            'Col Degree': col_degree,\n            'Degree': degree,\n            'Standardize': standardize,\n            'Normalize': normalize,\n            'Year': year,\n            'Month': month,\n            'Week': week,\n            'Time of Day': tod,\n            'Day of Week': dow,\n            'Save File': save_file\n        }\n\n        if save_file:\n            f = self.results_folder_name + '/preprocessed_data-' + str(self.get_global_count()) + '.csv'\n            self.preprocessed_data.to_csv(f)\n            self.result['Preprocess']['Saved File'] = f\n        else:\n            self.result['Preprocess']['Saved File'] = ''\n\n        return self.preprocessed_data", "response": "Preprocesses data according to user specifications and stores result in self. preprocessed_data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef model(self, data,\n            ind_col=None, dep_col=None,\n            project_ind_col=None,\n            baseline_period=[None, None], projection_period=None, exclude_time_period=None,\n            alphas=np.logspace(-4,1,30),\n            cv=3, plot=True, figsize=None,\n            custom_model_func=None):\n        \"\"\" Split data into baseline and projection periods, run models on them and display metrics & plots.\n\n        Parameters\n        ----------\n        data                    : pd.DataFrame()\n            Dataframe to model.\n        ind_col                 : list(str)\n            Independent column(s) of dataframe. Defaults to all columns except the last.\n        dep_col                 : str\n            Dependent column of dataframe.\n        project_ind_col         : list(str)\n            Independent column(s) to use for projection. If none, use ind_col.\n        baseline_period         : list(str)\n            List of time periods to split the data into baseline periods. It needs to have a start and an end date.\n        projection_period       : list(str)\n            List of time periods to split the data into projection periods. It needs to have a start and an end date.\n        exclude_time_period     : list(str)\n            List of time periods to exclude for modeling.\n        alphas                  : list(int)\n            List of alphas to run regression on.\n        cv                      : int\n            Number of folds for cross-validation.\n        plot                    : bool\n            Specifies whether to save plots or not.\n        figsize                 : tuple\n            Size of the plots.\n        custom_model_func       : function\n            Model with specific hyper-parameters provided by user.\n\n        Returns\n        -------\n        dict\n            Metrics of the optimal/best model.\n\n        \"\"\"\n\n        # Check to ensure data is a pandas dataframe\n        if not isinstance(data, pd.DataFrame):\n            raise SystemError('data has to be a pandas dataframe.')\n        \n        # Create instance\n        model_data_obj = Model_Data(data, ind_col, dep_col, alphas, cv, exclude_time_period, baseline_period, projection_period)\n\n        # Split data into baseline and projection\n        model_data_obj.split_data()\n\n        # Logging\n        self.result['Model'] = {\n            'Independent Col': ind_col,\n            'Dependent Col': dep_col,\n            'Projection Independent Col': project_ind_col,\n            'Baseline Period': baseline_period,\n            'Projection Period': projection_period,\n            'Exclude Time Period': exclude_time_period,\n            'Alphas': list(alphas),\n            'CV': cv,\n            'Plot': plot,\n            'Fig Size': figsize\n        }\n\n        # Runs all models on the data and returns optimal model\n        all_metrics = model_data_obj.run_models()\n        self.result['Model']['All Model\\'s Metrics'] = all_metrics\n\n        # CHECK: Define custom model's parameter and return types in documentation.\n        if custom_model_func:\n            self.result['Model']['Custom Model\\'s Metrics'] = model_data_obj.custom_model(custom_model_func)\n\n        # Fit optimal model to data\n        self.result['Model']['Optimal Model\\'s Metrics'] = model_data_obj.best_model_fit()\n\n        if plot:\n\n            # Use project_ind_col if projecting into the future (no input data other than weather data)\n            input_col = model_data_obj.input_col if not project_ind_col else project_ind_col\n            fig, y_true, y_pred = self.plot_data_obj.baseline_projection_plot(model_data_obj.y_true, model_data_obj.y_pred, \n                                                            model_data_obj.baseline_period, model_data_obj.projection_period,\n                                                            model_data_obj.best_model_name, model_data_obj.best_metrics['adj_r2'],\n                                                            model_data_obj.original_data,\n                                                            input_col, model_data_obj.output_col,\n                                                            model_data_obj.best_model,\n                                                            self.result['Site'])\n\n            fig.savefig(self.results_folder_name + '/baseline_projection_plot-' + str(self.get_global_count()) + '.png')\n            \n            if not y_true.empty and not y_pred.empty:\n                saving_absolute = (y_pred - y_true).sum()\n                saving_perc = (saving_absolute / y_pred.sum()) * 100\n                self.result['Energy Savings (%)'] = float(saving_perc)\n                self.result['Energy Savings (absolute)'] = saving_absolute\n\n                # Temporary\n                self.project_df['true'] = y_true\n                self.project_df['pred'] = y_pred\n\n                # Calculate uncertainity of savings\n                self.result['Uncertainity'] = self.uncertainity_equation(model_data_obj, y_true, y_pred, 0.9)\n            \n            else:\n                print('y_true: ', y_true)\n                print('y_pred: ', y_pred)\n                print('Error: y_true and y_pred are empty. Default to -1.0 savings.')\n                self.result['Energy Savings (%)'] = float(-1.0)\n                self.result['Energy Savings (absolute)'] = float(-1.0)\n        \n        return self.best_metrics", "response": "Function to run models on the data and return a dict of model metrics and plots."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning the results of one of the data API calls into a pandas dataframe", "response": "def make_dataframe(result):\n    \"\"\"\n    Turns the results of one of the data API calls into a pandas dataframe\n    \"\"\"\n    import pandas as pd\n    ret = {}\n    if isinstance(result,dict):\n        if 'timeseries' in result:\n            result = result['timeseries']\n    for uuid, data in result.items():\n        df = pd.DataFrame(data)\n        if len(df.columns) == 5: # statistical data\n            df.columns = ['time','min','mean','max','count']\n        else:\n            df.columns = ['time','value']\n        df['time'] = pd.to_datetime(df['time'],unit='ns')\n        df = df.set_index(df.pop('time'))\n        ret[uuid] = df\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_dfs(dfs, resample=None, do_mean=False, do_sum=False, do_min=False, do_max=False):\n    if len(dfs) == 0:\n        raise Exception(\"No dataframes provided\")\n    df = dfs.values()[0]\n    name = dfs.keys()[0]\n    df.columns = map(lambda x: name+\"_\"+x if not x.startswith(name) else x, df.columns)\n    if resample is not None:\n        df = df.resample(resample)\n        if do_mean: df = df.mean()\n        elif do_sum: df = df.sum()\n        elif do_min: df = df.min()\n        elif do_max: df = df.max()\n        else: df = df.mean()\n    if len(dfs) > 1:\n        for name, newdf in dfs.items()[1:]:\n            if resample is not None:\n                newdf = newdf.resample(resample)\n                if do_mean: newdf = newdf.mean()\n                elif do_sum: newdf = newdf.sum()\n                elif do_min: newdf = newdf.min()\n                elif do_max: newdf = newdf.max()\n                else: newdf = newdf.mean()\n            newdf.columns = map(lambda x: name+\"_\"+x if not x.startswith(name) else x, newdf.columns)\n            df = df.merge(newdf, left_index=True, right_index=True, how='outer')\n    return df", "response": "Merge the dataframes in the order of the order they appear in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query(self, query, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        if archiver == \"\":\n            archiver = self.archivers[0]\n\n        nonce = random.randint(0, 2**32)\n        ev = threading.Event()\n        response = {}\n        def _handleresult(msg):\n            # decode, throw away if not correct nonce\n            got_response = False\n            error = getError(nonce, msg)\n            if error is not None:\n                got_response = True\n                response[\"error\"] = error\n\n            metadata = getMetadata(nonce, msg)\n            if metadata is not None:\n                got_response = True\n                response[\"metadata\"] = metadata\n\n            timeseries = getTimeseries(nonce, msg)\n            if timeseries is not None:\n                got_response = True\n                response[\"timeseries\"] = timeseries\n\n            if got_response:\n                ev.set()\n\n        vk = self.vk[:-1] # remove last part of VK because archiver doesn't expect it\n\n        # set up receiving\n        self.c.subscribe(\"{0}/s.giles/_/i.archiver/signal/{1},queries\".format(archiver, vk), _handleresult)\n\n        # execute query\n        q_struct = msgpack.packb({\"Query\": query, \"Nonce\": nonce})\n        po = PayloadObject((2,0,8,1), None, q_struct)\n        self.c.publish(\"{0}/s.giles/_/i.archiver/slot/query\".format(archiver), payload_objects=(po,))\n\n        ev.wait(timeout)\n        if len(response) == 0: # no results\n            raise TimeoutException(\"Query of {0} timed out\".format(query))\n        return response", "response": "Runs a pundat query and returns the results as a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uuids(self, where, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        resp = self.query(\"select uuid where {0}\".format(where), archiver, timeout)\n        uuids = []\n        for r in resp[\"metadata\"]:\n            uuids.append(r[\"uuid\"])\n        return uuids", "response": "Returns a list of UUIDs that match the given where clause"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all streams matching the given WHERE clause", "response": "def tags(self, where, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        \"\"\"\n        Retrieves tags for all streams matching the given WHERE clause\n\n        Arguments:\n        [where]: the where clause (e.g. 'path like \"keti\"', 'SourceName = \"TED Main\"')\n        [archiver]: if specified, this is the archiver to use. Else, it will run on the first archiver passed\n                    into the constructor for the client\n        [timeout]: time in seconds to wait for a response from the archiver\n        \"\"\"\n        return self.query(\"select * where {0}\".format(where), archiver, timeout).get('metadata',{})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve all tags for all streams with the provided UUIDs", "response": "def tags_uuids(self, uuids, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        \"\"\"\n        Retrieves tags for all streams with the provided UUIDs\n\n        Arguments:\n        [uuids]: list of UUIDs\n        [archiver]: if specified, this is the archiver to use. Else, it will run on the first archiver passed\n                    into the constructor for the client\n        [timeout]: time in seconds to wait for a response from the archiver\n        \"\"\"\n        if not isinstance(uuids, list):\n            uuids = [uuids]\n        where = \" or \".join(['uuid = \"{0}\"'.format(uuid) for uuid in uuids])\n        return self.query(\"select * where {0}\".format(where), archiver, timeout).get('metadata',{})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all RAW data between the given timestamps", "response": "def data(self, where, start, end, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        \"\"\"\n        With the given WHERE clause, retrieves all RAW data between the 2 given timestamps\n\n        Arguments:\n        [where]: the where clause (e.g. 'path like \"keti\"', 'SourceName = \"TED Main\"')\n        [start, end]: time references:\n        [archiver]: if specified, this is the archiver to use. Else, it will run on the first archiver passed\n                    into the constructor for the client\n        [timeout]: time in seconds to wait for a response from the archiver\n        \"\"\"\n        return self.query(\"select data in ({0}, {1}) where {2}\".format(start, end, where), archiver, timeout).get('timeseries',{})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_uuids(self, uuids, start, end, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        if not isinstance(uuids, list):\n            uuids = [uuids]\n        where = \" or \".join(['uuid = \"{0}\"'.format(uuid) for uuid in uuids])\n        return self.query(\"select data in ({0}, {1}) where {2}\".format(start, end, where), archiver, timeout).get('timeseries',{})", "response": "This function retrieves all RAW data between the given timestamps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stats(self, where, start, end, pw, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        return self.query(\"select statistical({3}) data in ({0}, {1}) where {2}\".format(start, end, where, pw), archiver, timeout).get('timeseries',{})", "response": "Returns all statistical data between the 2 given timestamps"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all statistical data between the given timestamps", "response": "def window(self, where, start, end, width, archiver=\"\", timeout=DEFAULT_TIMEOUT):\n        \"\"\"\n        With the given WHERE clause, retrieves all statistical data between the 2 given timestamps, using the given window size\n\n        Arguments:\n        [where]: the where clause (e.g. 'path like \"keti\"', 'SourceName = \"TED Main\"')\n        [start, end]: time references:\n        [width]: a time expression for the window size, e.g. \"5s\", \"365d\"\n        [archiver]: if specified, this is the archiver to use. Else, it will run on the first archiver passed\n                    into the constructor for the client\n        [timeout]: time in seconds to wait for a response from the archiver\n        \"\"\"\n        return self.query(\"select window({3}) data in ({0}, {1}) where {2}\".format(start, end, where, width), archiver, timeout).get('timeseries',{})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef brightness(self):\n        if self.mode == \"ww\":\n            return int(self.raw_state[9])\n        else:\n            _, _, v = colorsys.rgb_to_hsv(*self.getRgb())\n            return v", "response": "Return current brightness 0 - 255."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode(var, encoding):\n    if PY2:\n        if isinstance(var, unicode):\n            ret = var\n        elif isinstance(var, str):\n            if encoding:\n                ret = var.decode(encoding)\n            else:\n                ret = unicode(var)\n        else:\n            ret = unicode(var)\n    else:\n        ret = str(var)\n    return ret", "response": "Decode a string or unicode object into a unicode object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the cfitsio version as a string.", "response": "def cfitsio_version(asfloat=False):\n    \"\"\"\n    Return the cfitsio version as a string.\n    \"\"\"\n    # use string version to avoid roundoffs\n    ver = '%0.3f' % _fitsio_wrap.cfitsio_version()\n    if asfloat:\n        return float(ver)\n    else:\n        return ver"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_little_endian(array):\n    if numpy.little_endian:\n        machine_little = True\n    else:\n        machine_little = False\n\n    byteorder = array.dtype.base.byteorder\n    return (byteorder == '<') or (machine_little and byteorder == '=')", "response": "Returns True if array is little endian False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert an array to the native byte order.", "response": "def array_to_native(array, inplace=False):\n    \"\"\"\n    Convert an array to the native byte order.\n\n    NOTE: the inplace keyword argument is not currently used.\n    \"\"\"\n    if numpy.little_endian:\n        machine_little = True\n    else:\n        machine_little = False\n\n    data_little = False\n    if array.dtype.names is None:\n\n        if array.dtype.base.byteorder == '|':\n            # strings and 1 byte integers\n            return array\n\n        data_little = is_little_endian(array)\n    else:\n        # assume all are same byte order: we only need to find one with\n        # little endian\n        for fname in array.dtype.names:\n            if is_little_endian(array[fname]):\n                data_little = True\n                break\n\n    if ((machine_little and not data_little)\n            or (not machine_little and data_little)):\n        output = array.byteswap(inplace)\n    else:\n        output = array\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes sure the value is a string paying mind to python3 vs 2", "response": "def mks(val):\n    \"\"\"\n    make sure the value is a string, paying mind to python3 vs 2\n    \"\"\"\n    if sys.version_info > (3, 0, 0):\n        if isinstance(val, bytes):\n            sval = str(val, 'utf-8')\n        else:\n            sval = str(val)\n    else:\n        sval = str(val)\n\n    return sval"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_vararray_max(tform):\n    first = tform.find('(')\n    last = tform.rfind(')')\n\n    if first == -1 or last == -1:\n        # no max length specified\n        return -1\n\n    maxnum = int(tform[first+1:last])\n    return maxnum", "response": "Extract max length specified by PX"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_col_dimstr(tdim, is_string=False):\n    dimstr = ''\n    if tdim is None:\n        dimstr = 'array[bad TDIM]'\n    else:\n        if is_string:\n            if len(tdim) > 1:\n                dimstr = [str(d) for d in tdim[1:]]\n        else:\n            if len(tdim) > 1 or tdim[0] > 1:\n                dimstr = [str(d) for d in tdim]\n        if dimstr != '':\n            dimstr = ','.join(dimstr)\n            dimstr = 'array[%s]' % dimstr\n\n    return dimstr", "response": "Returns a string representation of the column dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a NPY array to FITS.", "response": "def _npy2fits(d, table_type='binary', write_bitcols=False):\n    \"\"\"\n    d is the full element from the descr\n    \"\"\"\n    npy_dtype = d[1][1:]\n    if npy_dtype[0] == 'S' or npy_dtype[0] == 'U':\n        name, form, dim = _npy_string2fits(d, table_type=table_type)\n    else:\n        name, form, dim = _npy_num2fits(\n            d, table_type=table_type, write_bitcols=write_bitcols)\n\n    return name, form, dim"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert numpy array columns to FITS strings.", "response": "def _npy_num2fits(d, table_type='binary', write_bitcols=False):\n    \"\"\"\n    d is the full element from the descr\n\n    For vector,array columns the form is the total counts\n    followed by the code.\n\n    For array columns with dimension greater than 1, the dim is set to\n        (dim1, dim2, ...)\n    So it is treated like an extra dimension\n\n    \"\"\"\n\n    dim = None\n\n    name = d[0]\n\n    npy_dtype = d[1][1:]\n    if npy_dtype[0] == 'S' or npy_dtype[0] == 'U':\n        raise ValueError(\"got S or U type: use _npy_string2fits\")\n\n    if npy_dtype not in _table_npy2fits_form:\n        raise ValueError(\"unsupported type '%s'\" % npy_dtype)\n\n    if table_type == 'binary':\n        form = _table_npy2fits_form[npy_dtype]\n    else:\n        form = _table_npy2fits_form_ascii[npy_dtype]\n\n    # now the dimensions\n    if len(d) > 2:\n        if table_type == 'ascii':\n            raise ValueError(\n                \"Ascii table columns must be scalar, got %s\" % str(d))\n\n        if write_bitcols and npy_dtype == 'b1':\n            # multi-dimensional boolean\n            form = 'X'\n\n        # Note, depending on numpy version, even 1-d can be a tuple\n        if isinstance(d[2], tuple):\n            count = reduce(lambda x, y: x*y, d[2])\n            form = '%d%s' % (count, form)\n\n            if len(d[2]) > 1:\n                # this is multi-dimensional array column.  the form\n                # should be total elements followed by A\n                dim = list(reversed(d[2]))\n                dim = [str(e) for e in dim]\n                dim = '(' + ','.join(dim)+')'\n        else:\n            # this is a vector (1d array) column\n            count = d[2]\n            form = '%d%s' % (count, form)\n\n    return name, form, dim"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a NPY string to FITS.", "response": "def _npy_string2fits(d, table_type='binary'):\n    \"\"\"\n    d is the full element from the descr\n\n    form for strings is the total number of bytes followed by A.  Thus\n    for vector or array columns it is the size of the string times the\n    total number of elements in the array.\n\n    Then the dim is set to\n        (sizeofeachstring, dim1, dim2, ...)\n    So it is treated like an extra dimension\n\n    \"\"\"\n\n    dim = None\n\n    name = d[0]\n\n    npy_dtype = d[1][1:]\n    if npy_dtype[0] != 'S' and npy_dtype[0] != 'U':\n        raise ValueError(\"expected S or U type, got %s\" % npy_dtype[0])\n\n    # get the size of each string\n    string_size_str = npy_dtype[1:]\n    string_size = int(string_size_str)\n\n    if string_size <= 0:\n        raise ValueError('string sizes must be > 0, '\n                         'got %s for field %s' % (npy_dtype, name))\n\n    # now the dimensions\n    if len(d) == 2:\n        if table_type == 'ascii':\n            form = 'A'+string_size_str\n        else:\n            form = string_size_str+'A'\n    else:\n        if table_type == 'ascii':\n            raise ValueError(\n                \"Ascii table columns must be scalar, got %s\" % str(d))\n        if isinstance(d[2], tuple):\n            # this is an array column.  the form\n            # should be total elements followed by A\n            # count = 1\n            # count = [count*el for el in d[2]]\n            count = reduce(lambda x, y: x*y, d[2])\n            count = string_size*count\n            form = '%dA' % count\n\n            # will have to do tests to see if this is the right order\n            dim = list(reversed(d[2]))\n            # dim = d[2]\n            dim = [string_size_str] + [str(e) for e in dim]\n            dim = '(' + ','.join(dim)+')'\n        else:\n            # this is a vector (1d array) column\n            count = string_size*d[2]\n            form = '%dA' % count\n\n            # will have to do tests to see if this is the right order\n            dim = [string_size_str, str(d[2])]\n            dim = '(' + ','.join(dim)+')'\n\n    return name, form, dim"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the name associated with the given column number.", "response": "def get_colname(self, colnum):\n        \"\"\"\n        Get the name associated with the given column number\n\n        parameters\n        ----------\n        colnum: integer\n            The number for the column, zero offset\n        \"\"\"\n        if colnum < 0 or colnum > (len(self._colnames)-1):\n            raise ValueError(\n                \"colnum out of range [0,%s-1]\" % (0, len(self._colnames)))\n        return self._colnames[colnum]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, data, **keys):\n\n        slow = keys.get('slow', False)\n\n        isrec = False\n        if isinstance(data, (list, dict)):\n            if isinstance(data, list):\n                data_list = data\n                columns_all = keys.get('columns', None)\n                if columns_all is None:\n                    columns_all = keys.get('names', None)\n                    if columns_all is None:\n                        raise ValueError(\n                            \"you must send columns with a list of arrays\")\n\n            else:\n                columns_all = list(data.keys())\n                data_list = [data[n] for n in columns_all]\n\n            colnums_all = [self._extract_colnum(c) for c in columns_all]\n            names = [self.get_colname(c) for c in colnums_all]\n\n            isobj = numpy.zeros(len(data_list), dtype=numpy.bool)\n            for i in xrange(len(data_list)):\n                isobj[i] = is_object(data_list[i])\n\n        else:\n            if data.dtype.fields is None:\n                raise ValueError(\"You are writing to a table, so I expected \"\n                                 \"an array with fields as input. If you want \"\n                                 \"to write a simple array, you should use \"\n                                 \"write_column to write to a single column, \"\n                                 \"or instead write to an image hdu\")\n\n            if data.shape is ():\n                raise ValueError(\"cannot write data with shape ()\")\n\n            isrec = True\n            names = data.dtype.names\n            # only write object types (variable-length columns) after\n            # writing the main table\n            isobj = fields_are_object(data)\n\n            data_list = []\n            colnums_all = []\n            for i, name in enumerate(names):\n                colnum = self._extract_colnum(name)\n                data_list.append(data[name])\n                colnums_all.append(colnum)\n\n        if slow:\n            for i, name in enumerate(names):\n                if not isobj[i]:\n                    self.write_column(name, data_list[i], **keys)\n        else:\n\n            nonobj_colnums = []\n            nonobj_arrays = []\n            for i in xrange(len(data_list)):\n                if not isobj[i]:\n                    nonobj_colnums.append(colnums_all[i])\n                    if isrec:\n                        # this still leaves possibility of f-order sub-arrays..\n                        colref = array_to_native(data_list[i], inplace=False)\n                    else:\n                        colref = array_to_native_c(data_list[i], inplace=False)\n\n                    if IS_PY3 and colref.dtype.char == 'U':\n                        # for python3, we convert unicode to ascii\n                        # this will error if the character is not in ascii\n                        colref = colref.astype('S', copy=False)\n\n                    nonobj_arrays.append(colref)\n\n            for tcolnum, tdata in zip(nonobj_colnums, nonobj_arrays):\n                self._verify_column_data(tcolnum, tdata)\n\n            if len(nonobj_arrays) > 0:\n                firstrow = keys.get('firstrow', 0)\n                self._FITS.write_columns(\n                    self._ext+1, nonobj_colnums, nonobj_arrays,\n                    firstrow=firstrow+1, write_bitcols=self.write_bitcols)\n\n        # writing the object arrays always occurs the same way\n        # need to make sure this works for array fields\n        for i, name in enumerate(names):\n            if isobj[i]:\n                self.write_var_column(name, data_list[i], **keys)\n\n        self._update_info()", "response": "Writes data into this HDU."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting data to a column in this HDU.", "response": "def write_column(self, column, data, **keys):\n        \"\"\"\n        Write data to a column in this HDU\n\n        This HDU must be a table HDU.\n\n        parameters\n        ----------\n        column: scalar string/integer\n            The column in which to write.  Can be the name or number (0 offset)\n        column: ndarray\n            Numerical python array to write.  This should match the\n            shape of the column.  You are probably better using\n            fits.write_table() to be sure.\n        firstrow: integer, optional\n            At which row you should begin writing.  Be sure you know what you\n            are doing!  For appending see the append() method.  Default 0.\n        \"\"\"\n\n        firstrow = keys.get('firstrow', 0)\n\n        colnum = self._extract_colnum(column)\n\n        # need it to be contiguous and native byte order.  For now, make a\n        # copy.  but we may be able to avoid this with some care.\n\n        if not data.flags['C_CONTIGUOUS']:\n            # this always makes a copy\n            data_send = numpy.ascontiguousarray(data)\n            # this is a copy, we can make sure it is native\n            # and modify in place if needed\n            array_to_native(data_send, inplace=True)\n        else:\n            # we can avoid the copy with a try-finally block and\n            # some logic\n            data_send = array_to_native(data, inplace=False)\n\n        if IS_PY3 and data_send.dtype.char == 'U':\n            # for python3, we convert unicode to ascii\n            # this will error if the character is not in ascii\n            data_send = data_send.astype('S', copy=False)\n\n        self._verify_column_data(colnum, data_send)\n\n        self._FITS.write_column(\n            self._ext+1, colnum+1, data_send,\n            firstrow=firstrow+1, write_bitcols=self.write_bitcols)\n        del data_send\n        self._update_info()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify the input data is of the correct type and shape", "response": "def _verify_column_data(self, colnum, data):\n        \"\"\"\n        verify the input data is of the correct type and shape\n        \"\"\"\n        this_dt = data.dtype.descr[0]\n\n        if len(data.shape) > 2:\n            this_shape = data.shape[1:]\n        elif len(data.shape) == 2 and data.shape[1] > 1:\n            this_shape = data.shape[1:]\n        else:\n            this_shape = ()\n\n        this_npy_type = this_dt[1][1:]\n\n        npy_type, isvar, istbit = self._get_tbl_numpy_dtype(colnum)\n        info = self._info['colinfo'][colnum]\n\n        if npy_type[0] in ['>', '<', '|']:\n            npy_type = npy_type[1:]\n\n        col_name = info['name']\n        col_tdim = info['tdim']\n        col_shape = _tdim2shape(\n            col_tdim, col_name, is_string=(npy_type[0] == 'S'))\n\n        if col_shape is None:\n            if this_shape == ():\n                this_shape = None\n\n        if col_shape is not None and not isinstance(col_shape, tuple):\n            col_shape = (col_shape,)\n\n        \"\"\"\n        print('column name:',col_name)\n        print(data.shape)\n        print('col tdim', info['tdim'])\n        print('column dtype:',npy_type)\n        print('input dtype:',this_npy_type)\n        print('column shape:',col_shape)\n        print('input shape:',this_shape)\n        print()\n        \"\"\"\n\n        # this mismatch is OK\n        if npy_type == 'i1' and this_npy_type == 'b1':\n            this_npy_type = 'i1'\n\n        if isinstance(self, AsciiTableHDU):\n            # we don't enforce types exact for ascii\n            if npy_type == 'i8' and this_npy_type in ['i2', 'i4']:\n                this_npy_type = 'i8'\n            elif npy_type == 'f8' and this_npy_type == 'f4':\n                this_npy_type = 'f8'\n\n        if this_npy_type != npy_type:\n            raise ValueError(\n                \"bad input data for column '%s': \"\n                \"expected '%s', got '%s'\" % (\n                    col_name, npy_type, this_npy_type))\n\n        if this_shape != col_shape:\n            raise ValueError(\n                \"bad input shape for column '%s': \"\n                \"expected '%s', got '%s'\" % (col_name, col_shape, this_shape))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_var_column(self, column, data, firstrow=0, **keys):\n\n        if not is_object(data):\n            raise ValueError(\"Only object fields can be written to \"\n                             \"variable-length arrays\")\n        colnum = self._extract_colnum(column)\n\n        self._FITS.write_var_column(self._ext+1, colnum+1, data,\n                                    firstrow=firstrow+1)\n        self._update_info()", "response": "Write data to a variable - length column in this HDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts a new column into the table.", "response": "def insert_column(self, name, data, colnum=None):\n        \"\"\"\n        Insert a new column.\n\n        parameters\n        ----------\n        name: string\n            The column name\n        data:\n            The data to write into the new column.\n        colnum: int, optional\n            The column number for the new column, zero-offset.  Default\n            is to add the new column after the existing ones.\n\n        Notes\n        -----\n        This method is used un-modified by ascii tables as well.\n        \"\"\"\n\n        if name in self._colnames:\n            raise ValueError(\"column '%s' already exists\" % name)\n\n        if IS_PY3 and data.dtype.char == 'U':\n            # fast dtype conversion using an empty array\n            # we could hack at the actual text description, but using\n            # the numpy API is probably safer\n            # this also avoids doing a dtype conversion on every array\n            # element which could b expensive\n            descr = numpy.empty(1).astype(data.dtype).astype('S').dtype.descr\n        else:\n            descr = data.dtype.descr\n\n        if len(descr) > 1:\n            raise ValueError(\"you can only insert a single column, \"\n                             \"requested: %s\" % descr)\n\n        this_descr = descr[0]\n        this_descr = [name, this_descr[1]]\n        if len(data.shape) > 1:\n            this_descr += [data.shape[1:]]\n        this_descr = tuple(this_descr)\n\n        name, fmt, dims = _npy2fits(\n            this_descr,\n            table_type=self._table_type_str)\n        if dims is not None:\n            dims = [dims]\n\n        if colnum is None:\n            new_colnum = len(self._info['colinfo']) + 1\n        else:\n            new_colnum = colnum+1\n        self._FITS.insert_col(self._ext+1, new_colnum, name, fmt, tdim=dims)\n        self._update_info()\n\n        self.write_column(name, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append(self, data, **keys):\n\n        firstrow = self._info['nrows']\n\n        keys['firstrow'] = firstrow\n        self.write(data, **keys)", "response": "Append new rows to a table HDU"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes rows from the table and return the new version of the table.", "response": "def delete_rows(self, rows):\n        \"\"\"\n        Delete rows from the table\n\n        parameters\n        ----------\n        rows: sequence or slice\n            The exact rows to delete as a sequence, or a slice.\n\n        examples\n        --------\n            # delete a range of rows\n            with fitsio.FITS(fname,'rw') as fits:\n                fits['mytable'].delete_rows(slice(3,20))\n\n            # delete specific rows\n            with fitsio.FITS(fname,'rw') as fits:\n                rows2delete = [3,88,76]\n                fits['mytable'].delete_rows(rows2delete)\n        \"\"\"\n\n        if rows is None:\n            return\n\n        # extract and convert to 1-offset for C routine\n        if isinstance(rows, slice):\n            rows = self._process_slice(rows)\n            if rows.step is not None and rows.step != 1:\n                rows = numpy.arange(\n                    rows.start+1,\n                    rows.stop+1,\n                    rows.step,\n                )\n            else:\n                # rows must be 1-offset\n                rows = slice(rows.start+1, rows.stop+1)\n        else:\n            rows = self._extract_rows(rows)\n            # rows must be 1-offset\n            rows += 1\n\n        if isinstance(rows, slice):\n            self._FITS.delete_row_range(self._ext+1, rows.start, rows.stop)\n        else:\n            if rows.size == 0:\n                return\n\n            self._FITS.delete_rows(self._ext+1, rows)\n\n        self._update_info()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize(self, nrows, front=False):\n\n        nrows_current = self.get_nrows()\n        if nrows == nrows_current:\n            return\n\n        if nrows < nrows_current:\n            rowdiff = nrows_current - nrows\n            if front:\n                # delete from the front\n                start = 0\n                stop = rowdiff\n            else:\n                # delete from the back\n                start = nrows\n                stop = nrows_current\n\n            self.delete_rows(slice(start, stop))\n        else:\n            rowdiff = nrows - nrows_current\n            if front:\n                # in this case zero is what we want, since the code inserts\n                firstrow = 0\n            else:\n                firstrow = nrows_current\n            self._FITS.insert_rows(self._ext+1, firstrow, rowdiff)\n\n        self._update_info()", "response": "Resize the table to the given size removing or adding rows from the front or adding rows from the back."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading data from this HDU and return as a list of tuples.", "response": "def read(self, **keys):\n        \"\"\"\n        read data from this HDU\n\n        By default, all data are read.\n\n        send columns= and rows= to select subsets of the data.\n        Table data are read into a recarray; use read_column() to get a single\n        column as an ordinary array.  You can alternatively use slice notation\n            fits=fitsio.FITS(filename)\n            fits[ext][:]\n            fits[ext][2:5]\n            fits[ext][200:235:2]\n            fits[ext][rows]\n            fits[ext][cols][rows]\n\n        parameters\n        ----------\n        columns: optional\n            An optional set of columns to read from table HDUs.  Default is to\n            read all.  Can be string or number.  If a sequence, a recarray\n            is always returned.  If a scalar, an ordinary array is returned.\n        rows: optional\n            An optional list of rows to read from table HDUS.  Default is to\n            read all.\n        vstorage: string, optional\n            Over-ride the default method to store variable length columns.  Can\n            be 'fixed' or 'object'.  See docs on fitsio.FITS for details.\n        \"\"\"\n\n        columns = keys.get('columns', None)\n        rows = keys.get('rows', None)\n\n        if columns is not None:\n            if 'columns' in keys:\n                del keys['columns']\n            data = self.read_columns(columns, **keys)\n        elif rows is not None:\n            if 'rows' in keys:\n                del keys['rows']\n            data = self.read_rows(rows, **keys)\n        else:\n            data = self._read_all(**keys)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_all(self, **keys):\n\n        dtype, offsets, isvar = self.get_rec_dtype(**keys)\n\n        w, = numpy.where(isvar == True)  # noqa\n        has_tbit = self._check_tbit()\n\n        if w.size > 0:\n            vstorage = keys.get('vstorage', self._vstorage)\n            colnums = self._extract_colnums()\n            rows = None\n            array = self._read_rec_with_var(colnums, rows, dtype,\n                                            offsets, isvar, vstorage)\n        elif has_tbit:\n            # drop down to read_columns since we can't stuff into a\n            # contiguous array\n            colnums = self._extract_colnums()\n            array = self.read_columns(colnums, **keys)\n        else:\n\n            firstrow = 1  # noqa - not used?\n            nrows = self._info['nrows']\n            array = numpy.zeros(nrows, dtype=dtype)\n\n            self._FITS.read_as_rec(self._ext+1, 1, nrows, array)\n\n            array = self._maybe_decode_fits_ascii_strings_to_unicode_py3(array)\n\n            for colnum, name in enumerate(array.dtype.names):\n                self._rescale_and_convert_field_inplace(\n                    array,\n                    name,\n                    self._info['colinfo'][colnum]['tscale'],\n                    self._info['colinfo'][colnum]['tzero'])\n        lower = keys.get('lower', False)\n        upper = keys.get('upper', False)\n        if self.lower or lower:\n            _names_to_lower_if_recarray(array)\n        elif self.upper or upper:\n            _names_to_upper_if_recarray(array)\n\n        self._maybe_trim_strings(array, **keys)\n        return array", "response": "Read all data in the HDU."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the specified column from the FITS file.", "response": "def read_column(self, col, **keys):\n        \"\"\"\n        Read the specified column\n\n        Alternatively, you can use slice notation\n            fits=fitsio.FITS(filename)\n            fits[ext][colname][:]\n            fits[ext][colname][2:5]\n            fits[ext][colname][200:235:2]\n            fits[ext][colname][rows]\n\n        Note, if reading multiple columns, it is more efficient to use\n        read(columns=) or slice notation with a list of column names.\n\n        parameters\n        ----------\n        col: string/int,  required\n            The column name or number.\n        rows: optional\n            An optional set of row numbers to read.\n        vstorage: string, optional\n            Over-ride the default method to store variable length columns.  Can\n            be 'fixed' or 'object'.  See docs on fitsio.FITS for details.\n        \"\"\"\n\n        res = self.read_columns([col], **keys)\n        colname = res.dtype.names[0]\n        data = res[colname]\n\n        self._maybe_trim_strings(data, **keys)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_rows(self, rows, **keys):\n        if rows is None:\n            # we actually want all rows!\n            return self._read_all()\n\n        if self._info['hdutype'] == ASCII_TBL:\n            keys['rows'] = rows\n            return self.read(**keys)\n\n        rows = self._extract_rows(rows)\n        dtype, offsets, isvar = self.get_rec_dtype(**keys)\n\n        w, = numpy.where(isvar == True)  # noqa\n        if w.size > 0:\n            vstorage = keys.get('vstorage', self._vstorage)\n            colnums = self._extract_colnums()\n            return self._read_rec_with_var(\n                colnums, rows, dtype, offsets, isvar, vstorage)\n        else:\n            array = numpy.zeros(rows.size, dtype=dtype)\n            self._FITS.read_rows_as_rec(self._ext+1, array, rows)\n\n            array = self._maybe_decode_fits_ascii_strings_to_unicode_py3(array)\n\n            for colnum, name in enumerate(array.dtype.names):\n                self._rescale_and_convert_field_inplace(\n                    array,\n                    name,\n                    self._info['colinfo'][colnum]['tscale'],\n                    self._info['colinfo'][colnum]['tzero'])\n\n        lower = keys.get('lower', False)\n        upper = keys.get('upper', False)\n        if self.lower or lower:\n            _names_to_lower_if_recarray(array)\n        elif self.upper or upper:\n            _names_to_upper_if_recarray(array)\n\n        self._maybe_trim_strings(array, **keys)\n\n        return array", "response": "Read the specified rows."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_columns(self, columns, **keys):\n\n        if self._info['hdutype'] == ASCII_TBL:\n            keys['columns'] = columns\n            return self.read(**keys)\n\n        rows = keys.get('rows', None)\n\n        # if columns is None, returns all.  Guaranteed to be unique and sorted\n        colnums = self._extract_colnums(columns)\n        if isinstance(colnums, int):\n            # scalar sent, don't read as a recarray\n            return self.read_column(columns, **keys)\n\n        # if rows is None still returns None, and is correctly interpreted\n        # by the reader to mean all\n        rows = self._extract_rows(rows)\n\n        # this is the full dtype for all columns\n        dtype, offsets, isvar = self.get_rec_dtype(colnums=colnums, **keys)\n\n        w, = numpy.where(isvar == True)  # noqa\n        if w.size > 0:\n            vstorage = keys.get('vstorage', self._vstorage)\n            array = self._read_rec_with_var(\n                colnums, rows, dtype, offsets, isvar, vstorage)\n        else:\n\n            if rows is None:\n                nrows = self._info['nrows']\n            else:\n                nrows = rows.size\n            array = numpy.zeros(nrows, dtype=dtype)\n\n            colnumsp = colnums[:].copy()\n            colnumsp[:] += 1\n            self._FITS.read_columns_as_rec(self._ext+1, colnumsp, array, rows)\n\n            array = self._maybe_decode_fits_ascii_strings_to_unicode_py3(array)\n\n            for i in xrange(colnums.size):\n                colnum = int(colnums[i])\n                name = array.dtype.names[i]\n                self._rescale_and_convert_field_inplace(\n                    array,\n                    name,\n                    self._info['colinfo'][colnum]['tscale'],\n                    self._info['colinfo'][colnum]['tzero'])\n\n        if (self._check_tbit(colnums=colnums)):\n            array = self._fix_tbit_dtype(array, colnums)\n\n        lower = keys.get('lower', False)\n        upper = keys.get('upper', False)\n        if self.lower or lower:\n            _names_to_lower_if_recarray(array)\n        elif self.upper or upper:\n            _names_to_upper_if_recarray(array)\n\n        self._maybe_trim_strings(array, **keys)\n\n        return array", "response": "read a subset of columns from this binary table HDU and return a recarray."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_slice(self, firstrow, lastrow, step=1, **keys):\n\n        if self._info['hdutype'] == ASCII_TBL:\n            rows = numpy.arange(firstrow, lastrow, step, dtype='i8')\n            keys['rows'] = rows\n            return self.read_ascii(**keys)\n\n        step = keys.get('step', 1)\n        if self._info['hdutype'] == IMAGE_HDU:\n            raise ValueError(\"slices currently only supported for tables\")\n\n        maxrow = self._info['nrows']\n        if firstrow < 0 or lastrow > maxrow:\n            raise ValueError(\n                \"slice must specify a sub-range of [%d,%d]\" % (0, maxrow))\n\n        dtype, offsets, isvar = self.get_rec_dtype(**keys)\n\n        w, = numpy.where(isvar == True)  # noqa\n        if w.size > 0:\n            vstorage = keys.get('vstorage', self._vstorage)\n            rows = numpy.arange(firstrow, lastrow, step, dtype='i8')\n            colnums = self._extract_colnums()\n            array = self._read_rec_with_var(\n                colnums, rows, dtype, offsets, isvar, vstorage)\n        else:\n            if step != 1:\n                rows = numpy.arange(firstrow, lastrow, step, dtype='i8')\n                array = self.read(rows=rows)\n            else:\n                # no +1 because lastrow is non-inclusive\n                nrows = lastrow - firstrow\n                array = numpy.zeros(nrows, dtype=dtype)\n\n                # only first needs to be +1.  This is becuase the c code is\n                # inclusive\n                self._FITS.read_as_rec(self._ext+1, firstrow+1, lastrow, array)\n\n                array = self._maybe_decode_fits_ascii_strings_to_unicode_py3(\n                    array)\n\n                for colnum, name in enumerate(array.dtype.names):\n                    self._rescale_and_convert_field_inplace(\n                        array,\n                        name,\n                        self._info['colinfo'][colnum]['tscale'],\n                        self._info['colinfo'][colnum]['tzero'])\n\n        lower = keys.get('lower', False)\n        upper = keys.get('upper', False)\n        if self.lower or lower:\n            _names_to_lower_if_recarray(array)\n        elif self.upper or upper:\n            _names_to_upper_if_recarray(array)\n\n        self._maybe_trim_strings(array, **keys)\n\n        return array", "response": "Read the specified row slice from a table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_rec_dtype(self, **keys):\n        colnums = keys.get('colnums', None)\n        vstorage = keys.get('vstorage', self._vstorage)\n\n        if colnums is None:\n            colnums = self._extract_colnums()\n\n        descr = []\n        isvararray = numpy.zeros(len(colnums), dtype=numpy.bool)\n        for i, colnum in enumerate(colnums):\n            dt, isvar = self.get_rec_column_descr(colnum, vstorage)\n            descr.append(dt)\n            isvararray[i] = isvar\n        dtype = numpy.dtype(descr)\n\n        offsets = numpy.zeros(len(colnums), dtype='i8')\n        for i, n in enumerate(dtype.names):\n            offsets[i] = dtype.fields[n][1]\n        return dtype, offsets, isvararray", "response": "Get the dtype and offsets for the specified columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if one of the columns is a TBIT column.", "response": "def _check_tbit(self, **keys):\n        \"\"\"\n        Check if one of the columns is a TBIT column\n\n        parameters\n        ----------\n        colnums: integer array, optional\n        \"\"\"\n        colnums = keys.get('colnums', None)\n\n        if colnums is None:\n            colnums = self._extract_colnums()\n\n        has_tbit = False\n        for i, colnum in enumerate(colnums):\n            npy_type, isvar, istbit = self._get_tbl_numpy_dtype(colnum)\n            if (istbit):\n                has_tbit = True\n                break\n\n        return has_tbit"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_simple_dtype_and_shape(self, colnum, rows=None):\n\n        # basic datatype\n        npy_type, isvar, istbit = self._get_tbl_numpy_dtype(colnum)\n        info = self._info['colinfo'][colnum]\n        name = info['name']\n\n        if rows is None:\n            nrows = self._info['nrows']\n        else:\n            nrows = rows.size\n\n        shape = None\n        tdim = info['tdim']\n\n        shape = _tdim2shape(tdim, name, is_string=(npy_type[0] == 'S'))\n        if shape is not None:\n            if nrows > 1:\n                if not isinstance(shape, tuple):\n                    # vector\n                    shape = (nrows, shape)\n                else:\n                    # multi-dimensional\n                    shape = tuple([nrows] + list(shape))\n        else:\n            # scalar\n            shape = nrows\n        return npy_type, shape", "response": "Get the numpy dtype and shape of the array entry for a single column."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_rec_column_descr(self, colnum, vstorage):\n        npy_type, isvar, istbit = self._get_tbl_numpy_dtype(colnum)\n        name = self._info['colinfo'][colnum]['name']\n\n        if isvar:\n            if vstorage == 'object':\n                descr = (name, 'O')\n            else:\n                tform = self._info['colinfo'][colnum]['tform']\n                max_size = _extract_vararray_max(tform)\n\n                if max_size <= 0:\n                    name = self._info['colinfo'][colnum]['name']\n                    mess = 'Will read as an object field'\n                    if max_size < 0:\n                        mess = \"Column '%s': No maximum size: '%s'. %s\"\n                        mess = mess % (name, tform, mess)\n                        warnings.warn(mess, FITSRuntimeWarning)\n                    else:\n                        mess = \"Column '%s': Max size is zero: '%s'. %s\"\n                        mess = mess % (name, tform, mess)\n                        warnings.warn(mess, FITSRuntimeWarning)\n\n                    # we are forced to read this as an object array\n                    return self.get_rec_column_descr(colnum, 'object')\n\n                if npy_type[0] == 'S':\n                    # variable length string columns cannot\n                    # themselves be arrays I don't think\n                    npy_type = 'S%d' % max_size\n                    descr = (name, npy_type)\n                elif npy_type[0] == 'U':\n                    # variable length string columns cannot\n                    # themselves be arrays I don't think\n                    npy_type = 'U%d' % max_size\n                    descr = (name, npy_type)\n                else:\n                    descr = (name, npy_type, max_size)\n        else:\n            tdim = self._info['colinfo'][colnum]['tdim']\n            shape = _tdim2shape(\n                tdim, name,\n                is_string=(npy_type[0] == 'S' or npy_type[0] == 'U'))\n            if shape is not None:\n                descr = (name, npy_type, shape)\n            else:\n                descr = (name, npy_type)\n        return descr, isvar", "response": "Get a descriptor entry for the specified column."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_rec_with_var(\n            self, colnums, rows, dtype, offsets, isvar, vstorage):\n        \"\"\"\n        Read columns from a table into a rec array, including variable length\n        columns.  This is special because, for efficiency, it involves reading\n        from the main table as normal but skipping the columns in the array\n        that are variable.  Then reading the variable length columns, with\n        accounting for strides appropriately.\n\n        row and column numbers should be checked before calling this function\n        \"\"\"\n\n        colnumsp = colnums+1\n        if rows is None:\n            nrows = self._info['nrows']\n        else:\n            nrows = rows.size\n        array = numpy.zeros(nrows, dtype=dtype)\n\n        # read from the main table first\n        wnotvar, = numpy.where(isvar == False)  # noqa\n        if wnotvar.size > 0:\n            # this will be contiguous (not true for slices)\n            thesecol = colnumsp[wnotvar]\n            theseoff = offsets[wnotvar]\n            self._FITS.read_columns_as_rec_byoffset(self._ext+1,\n                                                    thesecol,\n                                                    theseoff,\n                                                    array,\n                                                    rows)\n            for i in xrange(thesecol.size):\n\n                name = array.dtype.names[wnotvar[i]]\n                colnum = thesecol[i]-1\n                self._rescale_and_convert_field_inplace(\n                    array,\n                    name,\n                    self._info['colinfo'][colnum]['tscale'],\n                    self._info['colinfo'][colnum]['tzero'])\n\n        array = self._maybe_decode_fits_ascii_strings_to_unicode_py3(array)\n\n        # now read the variable length arrays we may be able to speed this up\n        # by storing directly instead of reading first into a list\n        wvar, = numpy.where(isvar == True)  # noqa\n        if wvar.size > 0:\n            # this will be contiguous (not true for slices)\n            thesecol = colnumsp[wvar]\n            for i in xrange(thesecol.size):\n                colnump = thesecol[i]\n                name = array.dtype.names[wvar[i]]\n                dlist = self._FITS.read_var_column_as_list(\n                    self._ext+1, colnump, rows)\n\n                if (isinstance(dlist[0], str) or\n                        (IS_PY3 and isinstance(dlist[0], bytes))):\n                    is_string = True\n                else:\n                    is_string = False\n\n                if array[name].dtype.descr[0][1][1] == 'O':\n                    # storing in object array\n                    # get references to each, no copy made\n                    for irow, item in enumerate(dlist):\n                        if IS_PY3 and isinstance(item, bytes):\n                            item = item.decode('ascii')\n                        array[name][irow] = item\n                else:\n                    for irow, item in enumerate(dlist):\n                        if IS_PY3 and isinstance(item, bytes):\n                            item = item.decode('ascii')\n\n                        if is_string:\n                            array[name][irow] = item\n                        else:\n                            ncopy = len(item)\n\n                            if IS_PY3:\n                                ts = array[name].dtype.descr[0][1][1]\n                                if ts != 'S' and ts != 'U':\n                                    array[name][irow][0:ncopy] = item[:]\n                                else:\n                                    array[name][irow] = item\n                            else:\n                                array[name][irow][0:ncopy] = item[:]\n\n        return array", "response": "Read columns from a main table into a rec array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extract_rows(self, rows):\n        if rows is not None:\n            rows = numpy.array(rows, ndmin=1, copy=False, dtype='i8')\n            # returns unique, sorted\n            rows = numpy.unique(rows)\n\n            maxrow = self._info['nrows']-1\n            if rows[0] < 0 or rows[-1] > maxrow:\n                raise ValueError(\"rows must be in [%d,%d]\" % (0, maxrow))\n        return rows", "response": "Extract an array of rows from an input scalar or sequence\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_slice(self, arg):\n        start = arg.start\n        stop = arg.stop\n        step = arg.step\n\n        nrows = self._info['nrows']\n        if step is None:\n            step = 1\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = nrows\n\n        if start < 0:\n            start = nrows + start\n            if start < 0:\n                raise IndexError(\"Index out of bounds\")\n\n        if stop < 0:\n            stop = nrows + start + 1\n\n        if stop < start:\n            # will return an empty struct\n            stop = start\n\n        if stop > nrows:\n            stop = nrows\n        return slice(start, stop, step)", "response": "process the input slice for use calling the C code\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _slice2rows(self, start, stop, step=None):\n        nrows = self._info['nrows']\n        if start is None:\n            start = 0\n        if stop is None:\n            stop = nrows\n        if step is None:\n            step = 1\n\n        tstart = self._fix_range(start)\n        tstop = self._fix_range(stop)\n        if tstart == 0 and tstop == nrows:\n            # this is faster: if all fields are also requested, then a\n            # single fread will be done\n            return None\n        if stop < start:\n            raise ValueError(\"start is greater than stop in slice\")\n        return numpy.arange(tstart, tstop, step, dtype='i8')", "response": "Convert a slice to an array of rows."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure the input is within the range.", "response": "def _fix_range(self, num, isslice=True):\n        \"\"\"\n        Ensure the input is within range.\n\n        If el=True, then don't treat as a slice element\n        \"\"\"\n\n        nrows = self._info['nrows']\n        if isslice:\n            # include the end\n            if num < 0:\n                num = nrows + (1+num)\n            elif num > nrows:\n                num = nrows\n        else:\n            # single element\n            if num < 0:\n                num = nrows + num\n            elif num > (nrows-1):\n                num = nrows-1\n\n        return num"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies fits scalings. Also, convert bool to proper numpy boolean values", "response": "def _rescale_and_convert_field_inplace(self, array, name, scale, zero):\n        \"\"\"\n        Apply fits scalings.  Also, convert bool to proper\n        numpy boolean values\n        \"\"\"\n        self._rescale_array(array[name], scale, zero)\n        if array[name].dtype == numpy.bool:\n            array[name] = self._convert_bool_array(array[name])\n        return array"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _rescale_array(self, array, scale, zero):\n        if scale != 1.0:\n            sval = numpy.array(scale, dtype=array.dtype)\n            array *= sval\n        if zero != 0.0:\n            zval = numpy.array(zero, dtype=array.dtype)\n            array += zval", "response": "Rescale the input array to the desired scale and zero values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _maybe_trim_strings(self, array, **keys):\n        trim_strings = keys.get('trim_strings', False)\n        if self.trim_strings or trim_strings:\n            _trim_strings(array)", "response": "Trim trailing white space from all string fields in the input array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_bool_array(self, array):\n\n        output = (array.view(numpy.int8) == ord('T')).astype(numpy.bool)\n        return output", "response": "Convert a numpy array into a real bool"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_tbl_numpy_dtype(self, colnum, include_endianness=True):\n        table_type = self._info['hdutype']\n        table_type_string = _hdu_type_map[table_type]\n        try:\n            ftype = self._info['colinfo'][colnum]['eqtype']\n            if table_type == ASCII_TBL:\n                npy_type = _table_fits2npy_ascii[abs(ftype)]\n            else:\n                npy_type = _table_fits2npy[abs(ftype)]\n        except KeyError:\n            raise KeyError(\"unsupported %s fits data \"\n                           \"type: %d\" % (table_type_string, ftype))\n\n        istbit = False\n        if (ftype == 1):\n            istbit = True\n\n        isvar = False\n        if ftype < 0:\n            isvar = True\n        if include_endianness:\n            # if binary we will read the big endian bytes directly,\n            # if ascii we read into native byte order\n            if table_type == ASCII_TBL:\n                addstr = ''\n            else:\n                addstr = '>'\n            if npy_type not in ['u1', 'i1', 'S', 'U']:\n                npy_type = addstr+npy_type\n\n        if npy_type == 'S':\n            width = self._info['colinfo'][colnum]['width']\n            npy_type = 'S%d' % width\n        elif npy_type == 'U':\n            width = self._info['colinfo'][colnum]['width']\n            npy_type = 'U%d' % width\n\n        return npy_type, isvar, istbit", "response": "Get numpy dtype for the input column."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the args to get the correct type of data.", "response": "def _process_args_as_rows_or_columns(self, arg, unpack=False):\n        \"\"\"\n        We must be able to interpret the args as as either a column name or\n        row number, or sequences thereof.  Numpy arrays and slices are also\n        fine.\n\n        Examples:\n            'field'\n            35\n            [35,55,86]\n            ['f1',f2',...]\n        Can also be tuples or arrays.\n        \"\"\"\n\n        flags = set()\n        #\n        if isinstance(arg, (tuple, list, numpy.ndarray)):\n            # a sequence was entered\n            if isstring(arg[0]):\n                result = arg\n            else:\n                result = arg\n                flags.add('isrows')\n        elif isstring(arg):\n            # a single string was entered\n            result = arg\n        elif isinstance(arg, slice):\n            if unpack:\n                flags.add('isrows')\n                result = self._slice2rows(arg.start, arg.stop, arg.step)\n            else:\n                flags.add('isrows')\n                flags.add('isslice')\n                result = self._process_slice(arg)\n        else:\n            # a single object was entered.\n            # Probably should apply some more checking on this\n            result = arg\n            flags.add('isrows')\n            if numpy.ndim(arg) == 0:\n                flags.add('isscalar')\n\n        return result, flags"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts an array of column numbers from the input", "response": "def _extract_colnums(self, columns=None):\n        \"\"\"\n        Extract an array of columns from the input\n        \"\"\"\n        if columns is None:\n            return numpy.arange(self._ncol, dtype='i8')\n\n        if not isinstance(columns, (tuple, list, numpy.ndarray)):\n            # is a scalar\n            return self._extract_colnum(columns)\n\n        colnums = numpy.zeros(len(columns), dtype='i8')\n        for i in xrange(colnums.size):\n            colnums[i] = self._extract_colnum(columns[i])\n\n        # returns unique sorted\n        colnums = numpy.unique(colnums)\n        return colnums"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _extract_colnum(self, col):\n        if isinteger(col):\n            colnum = col\n\n            if (colnum < 0) or (colnum > (self._ncol-1)):\n                raise ValueError(\n                    \"column number should be in [0,%d]\" % (0, self._ncol-1))\n        else:\n            colstr = mks(col)\n            try:\n                if self.case_sensitive:\n                    mess = \"column name '%s' not found (case sensitive)\" % col\n                    colnum = self._colnames.index(colstr)\n                else:\n                    mess \\\n                        = \"column name '%s' not found (case insensitive)\" % col\n                    colnum = self._colnames_lower.index(colstr.lower())\n            except ValueError:\n                raise ValueError(mess)\n        return int(colnum)", "response": "Extract the column number for the input column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the internal info of the a .", "response": "def _update_info(self):\n        \"\"\"\n        Call parent method and make sure this is in fact a\n        table HDU.  Set some convenience data.\n        \"\"\"\n        super(TableHDU, self)._update_info()\n        if self._info['hdutype'] == IMAGE_HDU:\n            mess = \"Extension %s is not a Table HDU\" % self.ext\n            raise ValueError(mess)\n        if 'colinfo' in self._info:\n            self._colnames = [i['name'] for i in self._info['colinfo']]\n            self._colnames_lower = [\n                i['name'].lower() for i in self._info['colinfo']]\n            self._ncol = len(self._colnames)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the next buffered row for iteration.", "response": "def _get_next_buffered_row(self):\n        \"\"\"\n        Get the next row for iteration.\n        \"\"\"\n        if self._iter_row == self._iter_nrows:\n            raise StopIteration\n\n        if self._row_buffer_index >= self._iter_row_buffer:\n            self._buffer_iter_rows(self._iter_row)\n\n        data = self._row_buffer[self._row_buffer_index]\n        self._iter_row += 1\n        self._row_buffer_index += 1\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading in the buffer for iteration", "response": "def _buffer_iter_rows(self, start):\n        \"\"\"\n        Read in the buffer for iteration\n        \"\"\"\n        self._row_buffer = self[start:start+self._iter_row_buffer]\n\n        # start back at the front of the buffer\n        self._row_buffer_index = 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, **keys):\n\n        rows = keys.get('rows', None)\n        columns = keys.get('columns', None)\n\n        # if columns is None, returns all.  Guaranteed to be unique and sorted\n        colnums = self._extract_colnums(columns)\n        if isinstance(colnums, int):\n            # scalar sent, don't read as a recarray\n            return self.read_column(columns, **keys)\n\n        rows = self._extract_rows(rows)\n        if rows is None:\n            nrows = self._info['nrows']\n        else:\n            nrows = rows.size\n\n        # if rows is None still returns None, and is correctly interpreted\n        # by the reader to mean all\n        rows = self._extract_rows(rows)\n\n        # this is the full dtype for all columns\n        dtype, offsets, isvar = self.get_rec_dtype(colnums=colnums, **keys)\n        array = numpy.zeros(nrows, dtype=dtype)\n\n        # note reading into existing data\n        wnotvar, = numpy.where(isvar == False)  # noqa\n        if wnotvar.size > 0:\n            for i in wnotvar:\n                colnum = colnums[i]\n                name = array.dtype.names[i]\n                a = array[name].copy()\n                self._FITS.read_column(self._ext+1, colnum+1, a, rows)\n                array[name] = a\n                del a\n\n        array = self._maybe_decode_fits_ascii_strings_to_unicode_py3(array)\n\n        wvar, = numpy.where(isvar == True)  # noqa\n        if wvar.size > 0:\n            for i in wvar:\n                colnum = colnums[i]\n                name = array.dtype.names[i]\n                dlist = self._FITS.read_var_column_as_list(\n                    self._ext+1, colnum+1, rows)\n                if (isinstance(dlist[0], str) or\n                        (IS_PY3 and isinstance(dlist[0], bytes))):\n                    is_string = True\n                else:\n                    is_string = False\n\n                if array[name].dtype.descr[0][1][1] == 'O':\n                    # storing in object array\n                    # get references to each, no copy made\n                    for irow, item in enumerate(dlist):\n                        if IS_PY3 and isinstance(item, bytes):\n                            item = item.decode('ascii')\n                        array[name][irow] = item\n                else:\n                    for irow, item in enumerate(dlist):\n                        if IS_PY3 and isinstance(item, bytes):\n                            item = item.decode('ascii')\n                        if is_string:\n                            array[name][irow] = item\n                        else:\n                            ncopy = len(item)\n                            array[name][irow][0:ncopy] = item[:]\n\n        lower = keys.get('lower', False)\n        upper = keys.get('upper', False)\n        if self.lower or lower:\n            _names_to_lower_if_recarray(array)\n        elif self.upper or upper:\n            _names_to_upper_if_recarray(array)\n\n        self._maybe_trim_strings(array, **keys)\n\n        return array", "response": "read a data from an ascii table HDU and return a recarray of the data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the data from disk and return as a numpy array.", "response": "def read(self, **keys):\n        \"\"\"\n        Read the data from disk and return as a numpy array\n        \"\"\"\n\n        if self.is_scalar:\n            data = self.fitshdu.read_column(self.columns, **keys)\n        else:\n            c = keys.get('columns', None)\n            if c is None:\n                keys['columns'] = self.columns\n            data = self.fitshdu.read(**keys)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading data from a FITS file into a FITS record array.", "response": "def read(filename, ext=None, extver=None, **keys):\n    \"\"\"\n    Convenience function to read data from the specified FITS HDU\n\n    By default, all data are read.  For tables, send columns= and rows= to\n    select subsets of the data.  Table data are read into a recarray; use a\n    FITS object and read_column() to get a single column as an ordinary array.\n    For images, create a FITS object and use slice notation to read subsets.\n\n    Under the hood, a FITS object is constructed and data are read using\n    an associated FITSHDU object.\n\n    parameters\n    ----------\n    filename: string\n        A filename.\n    ext: number or string, optional\n        The extension.  Either the numerical extension from zero\n        or a string extension name. If not sent, data is read from\n        the first HDU that has data.\n    extver: integer, optional\n        FITS allows multiple extensions to have the same name (extname).  These\n        extensions can optionally specify an EXTVER version number in the\n        header.  Send extver= to select a particular version.  If extver is not\n        sent, the first one will be selected.  If ext is an integer, the extver\n        is ignored.\n    columns: list or array, optional\n        An optional set of columns to read from table HDUs.  Default is to\n        read all.  Can be string or number.\n    rows: optional\n        An optional list of rows to read from table HDUS.  Default is to\n        read all.\n    header: bool, optional\n        If True, read the FITS header and return a tuple (data,header)\n        Default is False.\n    case_sensitive: bool, optional\n        Match column names and extension names with case-sensitivity.  Default\n        is False.\n    lower: bool, optional\n        If True, force all columns names to lower case in output\n    upper: bool, optional\n        If True, force all columns names to upper case in output\n    vstorage: string, optional\n        Set the default method to store variable length columns.  Can be\n        'fixed' or 'object'.  See docs on fitsio.FITS for details.\n    \"\"\"\n\n    with FITS(filename, **keys) as fits:\n\n        header = keys.pop('header', False)\n\n        if ext is None:\n            for i in xrange(len(fits)):\n                if fits[i].has_data():\n                    ext = i\n                    break\n            if ext is None:\n                raise IOError(\"No extensions have data\")\n\n        item = _make_item(ext, extver=extver)\n\n        data = fits[item].read(**keys)\n        if header:\n            h = fits[item].read_header()\n            return data, h\n        else:\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the header from a FITS file.", "response": "def read_header(filename, ext=0, extver=None, case_sensitive=False, **keys):\n    \"\"\"\n    Convenience function to read the header from the specified FITS HDU\n\n    The FITSHDR allows access to the values and comments by name and\n    number.\n\n    parameters\n    ----------\n    filename: string\n        A filename.\n    ext: number or string, optional\n        The extension.  Either the numerical extension from zero\n        or a string extension name. Default read primary header.\n    extver: integer, optional\n        FITS allows multiple extensions to have the same name (extname).  These\n        extensions can optionally specify an EXTVER version number in the\n        header.  Send extver= to select a particular version.  If extver is not\n        sent, the first one will be selected.  If ext is an integer, the extver\n        is ignored.\n    case_sensitive: bool, optional\n        Match extension names with case-sensitivity.  Default is False.\n    \"\"\"\n\n    dont_create = 0\n    try:\n        hdunum = ext+1\n    except TypeError:\n        hdunum = None\n\n    _fits = _fitsio_wrap.FITS(filename, READONLY, dont_create)\n\n    if hdunum is None:\n        extname = mks(ext)\n        if extver is None:\n            extver_num = 0\n        else:\n            extver_num = extver\n\n        if not case_sensitive:\n            # the builtin movnam_hdu is not case sensitive\n            hdunum = _fits.movnam_hdu(ANY_HDU, extname, extver_num)\n        else:\n            # for case sensitivity we'll need to run through\n            # all the hdus\n            found = False\n            current_ext = 0\n            while True:\n                hdunum = current_ext+1\n                try:\n                    hdu_type = _fits.movabs_hdu(hdunum)  # noqa - not used\n                    name, vers = _fits.get_hdu_name_version(hdunum)\n                    if name == extname:\n                        if extver is None:\n                            # take the first match\n                            found = True\n                            break\n                        else:\n                            if extver_num == vers:\n                                found = True\n                                break\n                except OSError:\n                    break\n\n                current_ext += 1\n\n            if not found:\n                raise IOError(\n                    'hdu not found: %s (extver %s)' % (extname, extver))\n\n    return FITSHDR(_fits.read_header(hdunum))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_scamp_head(fname, header=None):\n\n    with open(fname) as fobj:\n        lines = fobj.readlines()\n\n    lines = [l.strip() for l in lines if l[0:3] != 'END']\n\n    # if header is None an empty FITSHDR is created\n    hdr = FITSHDR(header)\n\n    for l in lines:\n        hdr.add_record(l)\n\n    return hdr", "response": "Reads a SCAMP. head file and returns a FITSHDR object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting numpy array to tabledef.", "response": "def array2tabledef(data, table_type='binary', write_bitcols=False):\n    \"\"\"\n    Similar to descr2tabledef but if there are object columns a type\n    and max length will be extracted and used for the tabledef\n    \"\"\"\n    is_ascii = (table_type == 'ascii')\n\n    if data.dtype.fields is None:\n        raise ValueError(\"data must have fields\")\n    names = []\n    names_nocase = {}\n    formats = []\n    dims = []\n\n    descr = data.dtype.descr\n    for d in descr:\n        # these have the form '<f4' or '|S25', etc.  Extract the pure type\n        npy_dtype = d[1][1:]\n        if is_ascii:\n            if npy_dtype in ['u1', 'i1']:\n                raise ValueError(\n                    \"1-byte integers are not supported for \"\n                    \"ascii tables: '%s'\" % npy_dtype)\n            if npy_dtype in ['u2']:\n                raise ValueError(\n                    \"unsigned 2-byte integers are not supported for \"\n                    \"ascii tables: '%s'\" % npy_dtype)\n\n        if npy_dtype[0] == 'O':\n            # this will be a variable length column 1Pt(len) where t is the\n            # type and len is max length.  Each element must be convertible to\n            # the same type as the first\n            name = d[0]\n            form, dim = npy_obj2fits(data, name)\n        elif npy_dtype[0] == \"V\":\n            continue\n        else:\n            name, form, dim = _npy2fits(\n                d, table_type=table_type, write_bitcols=write_bitcols)\n\n        if name == '':\n            raise ValueError(\"field name is an empty string\")\n\n        \"\"\"\n        if is_ascii:\n            if dim is not None:\n                raise ValueError(\"array columns are not supported for \"\n                                 \"ascii tables\")\n        \"\"\"\n        name_nocase = name.upper()\n        if name_nocase in names_nocase:\n            raise ValueError(\n                \"duplicate column name found: '%s'.  Note \"\n                \"FITS column names are not case sensitive\" % name_nocase)\n\n        names.append(name)\n        names_nocase[name_nocase] = name_nocase\n\n        formats.append(form)\n        dims.append(dim)\n\n    return names, formats, dims"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a numpy recarray type descriptor to a FITS table def.", "response": "def descr2tabledef(descr, table_type='binary', write_bitcols=False):\n    \"\"\"\n    Create a FITS table def from the input numpy descriptor.\n\n    parameters\n    ----------\n    descr: list\n        A numpy recarray type descriptor  array.dtype.descr\n\n    returns\n    -------\n    names, formats, dims: tuple of lists\n        These are the ttyp, tform and tdim header entries\n        for each field.  dim entries may be None\n    \"\"\"\n    names = []\n    formats = []\n    dims = []\n\n    for d in descr:\n\n        \"\"\"\n        npy_dtype = d[1][1:]\n        if is_ascii and npy_dtype in ['u1','i1']:\n            raise ValueError(\"1-byte integers are not supported for \"\n                             \"ascii tables\")\n        \"\"\"\n\n        if d[1][1] == 'O':\n            raise ValueError(\n                'cannot automatically declare a var column without '\n                'some data to determine max len')\n\n        name, form, dim = _npy2fits(\n            d, table_type=table_type, write_bitcols=write_bitcols)\n\n        if name == '':\n            raise ValueError(\"field name is an empty string\")\n\n        \"\"\"\n        if is_ascii:\n            if dim is not None:\n                raise ValueError(\"array columns are not supported \"\n                                 \"for ascii tables\")\n        \"\"\"\n\n        names.append(name)\n        formats.append(form)\n        dims.append(dim)\n\n    return names, formats, dims"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tile_dims(tile_dims, imshape):\n\n    if tile_dims is None:\n        td = None\n    else:\n        td = numpy.array(tile_dims, dtype='i8')\n        nd = len(imshape)\n        if td.size != nd:\n            msg = \"expected tile_dims to have %d dims, got %d\" % (td.size, nd)\n            raise ValueError(msg)\n\n    return td", "response": "Return the tile dims as numpy array."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the table type from the given type string.", "response": "def _extract_table_type(type):\n    \"\"\"\n    Get the numerical table type\n    \"\"\"\n    if isinstance(type, str):\n        type = type.lower()\n        if type[0:7] == 'binary':\n            table_type = BINARY_TBL\n        elif type[0:6] == 'ascii':\n            table_type = ASCII_TBL\n        else:\n            raise ValueError(\n                \"table type string should begin with 'binary' or 'ascii' \"\n                \"(case insensitive)\")\n    else:\n        type = int(type)\n        if type not in [BINARY_TBL, ASCII_TBL]:\n            raise ValueError(\n                \"table type num should be BINARY_TBL (%d) or \"\n                \"ASCII_TBL (%d)\" % (BINARY_TBL, ASCII_TBL))\n        table_type = type\n\n    return table_type"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if hasattr(self, '_FITS'):\n            if self._FITS is not None:\n                self._FITS.close()\n                self._FITS = None\n        self._filename = None\n        self.mode = None\n        self.charmode = None\n        self.intmode = None\n        self.hdu_list = None\n        self.hdu_map = None", "response": "Close the fits file and set relevant metadata to None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves to the indicated HDU by name.", "response": "def movnam_hdu(self, extname, hdutype=ANY_HDU, extver=0):\n        \"\"\"\n        Move to the indicated HDU by name\n\n        In general, it is not necessary to use this method explicitly.\n\n        returns the one-offset extension number\n        \"\"\"\n        extname = mks(extname)\n        hdu = self._FITS.movnam_hdu(hdutype, extname, extver)\n        return hdu"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses and reopen the fits file with the same mode", "response": "def reopen(self):\n        \"\"\"\n        close and reopen the fits file with the same mode\n        \"\"\"\n        self._FITS.close()\n        del self._FITS\n        self._FITS = _fitsio_wrap.FITS(self._filename, self.intmode, 0)\n        self.update_hdu_list()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, data, units=None, extname=None, extver=None,\n              compress=None, tile_dims=None,\n              header=None,\n              names=None,\n              table_type='binary', write_bitcols=False, **keys):\n        \"\"\"\n        Write the data to a new HDU.\n\n        This method is a wrapper.  If this is an IMAGE_HDU, write_image is\n        called, otherwise write_table is called.\n\n        parameters\n        ----------\n        data: ndarray\n            An n-dimensional image or an array with fields.\n        extname: string, optional\n            An optional extension name.\n        extver: integer, optional\n            FITS allows multiple extensions to have the same name (extname).\n            These extensions can optionally specify an EXTVER version number in\n            the header.  Send extver= to set a particular version, which will\n            be represented in the header with keyname EXTVER.  The extver must\n            be an integer > 0.  If extver is not sent, the first one will be\n            selected.  If ext is an integer, the extver is ignored.\n        header: FITSHDR, list, dict, optional\n            A set of header keys to write. Can be one of these:\n                - FITSHDR object\n                - list of dictionaries containing 'name','value' and optionally\n                  a 'comment' field; the order is preserved.\n                - a dictionary of keyword-value pairs; no comments are written\n                  in this case, and the order is arbitrary.\n            Note required keywords such as NAXIS, XTENSION, etc are cleaed out.\n\n        Image-only keywords:\n            compress: string, optional\n                A string representing the compression algorithm for images,\n                default None.\n                Can be one of\n                    'RICE'\n                    'GZIP'\n                    'GZIP_2'\n                    'PLIO' (no unsigned or negative integers)\n                    'HCOMPRESS'\n                (case-insensitive) See the cfitsio manual for details.\n\n        Table-only keywords:\n            units: list/dec, optional:\n                A list of strings with units for each column.\n            table_type: string, optional\n                Either 'binary' or 'ascii', default 'binary'\n                Matching is case-insensitive\n            write_bitcols: bool, optional\n                Write boolean arrays in the FITS bitcols format, default False\n\n\n        restrictions\n        ------------\n        The File must be opened READWRITE\n        \"\"\"\n\n        isimage = False\n        if data is None:\n            isimage = True\n        elif isinstance(data, numpy.ndarray):\n            if data.dtype.fields == None:  # noqa - probably should be is None\n                isimage = True\n\n        if isimage:\n            self.write_image(data, extname=extname, extver=extver,\n                             compress=compress, tile_dims=tile_dims,\n                             header=header)\n        else:\n            self.write_table(data, units=units,\n                             extname=extname, extver=extver, header=header,\n                             names=names,\n                             table_type=table_type,\n                             write_bitcols=write_bitcols)", "response": "This method writes the data to a new HDU."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new image extension and write the data.", "response": "def write_image(self, img, extname=None, extver=None,\n                    compress=None, tile_dims=None, header=None):\n        \"\"\"\n        Create a new image extension and write the data.\n\n        parameters\n        ----------\n        img: ndarray\n            An n-dimensional image.\n        extname: string, optional\n            An optional extension name.\n        extver: integer, optional\n            FITS allows multiple extensions to have the same name (extname).\n            These extensions can optionally specify an EXTVER version number in\n            the header.  Send extver= to set a particular version, which will\n            be represented in the header with keyname EXTVER.  The extver must\n            be an integer > 0.  If extver is not sent, the first one will be\n            selected.  If ext is an integer, the extver is ignored.\n        compress: string, optional\n            A string representing the compression algorithm for images,\n            default None.\n            Can be one of\n                'RICE'\n                'GZIP'\n                'GZIP_2'\n                'PLIO' (no unsigned or negative integers)\n                'HCOMPRESS'\n            (case-insensitive) See the cfitsio manual for details.\n        header: FITSHDR, list, dict, optional\n            A set of header keys to write. Can be one of these:\n                - FITSHDR object\n                - list of dictionaries containing 'name','value' and optionally\n                  a 'comment' field; the order is preserved.\n                - a dictionary of keyword-value pairs; no comments are written\n                  in this case, and the order is arbitrary.\n            Note required keywords such as NAXIS, XTENSION, etc are cleaed out.\n\n\n        restrictions\n        ------------\n        The File must be opened READWRITE\n        \"\"\"\n\n        self.create_image_hdu(img,\n                              header=header,\n                              extname=extname, extver=extver,\n                              compress=compress, tile_dims=tile_dims)\n\n        if header is not None:\n            self[-1].write_keys(header)\n            self[-1]._update_info()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new image HDU in the current directory.", "response": "def create_image_hdu(self,\n                         img=None,\n                         dims=None,\n                         dtype=None,\n                         extname=None,\n                         extver=None,\n                         compress=None,\n                         tile_dims=None,\n                         header=None):\n        \"\"\"\n        Create a new, empty image HDU and reload the hdu list.  Either\n        create from an input image or from input dims and dtype\n\n            fits.create_image_hdu(image, ...)\n            fits.create_image_hdu(dims=dims, dtype=dtype)\n\n        If an image is sent, the data are also written.\n\n        You can write data into the new extension using\n            fits[extension].write(image)\n\n        Alternatively you can skip calling this function and instead just use\n\n            fits.write(image)\n            or\n            fits.write_image(image)\n\n        which will create the new image extension for you with the appropriate\n        structure, and write the data.\n\n        parameters\n        ----------\n        img: ndarray, optional\n            An image with which to determine the properties of the HDU. The\n            data will be written.\n        dims: sequence, optional\n            A sequence describing the dimensions of the image to be created\n            on disk.  You must also send a dtype=\n        dtype: numpy data type\n            When sending dims= also send the data type.  Can be of the\n            various numpy data type declaration styles, e.g. 'f8',\n            numpy.float64.\n        extname: string, optional\n            An optional extension name.\n        extver: integer, optional\n            FITS allows multiple extensions to have the same name (extname).\n            These extensions can optionally specify an EXTVER version number in\n            the header.  Send extver= to set a particular version, which will\n            be represented in the header with keyname EXTVER.  The extver must\n            be an integer > 0.  If extver is not sent, the first one will be\n            selected.  If ext is an integer, the extver is ignored.\n        compress: string, optional\n            A string representing the compression algorithm for images,\n            default None.\n            Can be one of\n                'RICE'\n                'GZIP'\n                'GZIP_2'\n                'PLIO' (no unsigned or negative integers)\n                'HCOMPRESS'\n            (case-insensitive) See the cfitsio manual for details.\n\n        header: FITSHDR, list, dict, optional\n            This is only used to determine how many slots to reserve for\n            header keywords\n\n        restrictions\n        ------------\n        The File must be opened READWRITE\n        \"\"\"\n\n        if (img is not None) or (img is None and dims is None):\n            from_image = True\n        elif dims is not None:\n            from_image = False\n\n        if from_image:\n            img2send = img\n            if img is not None:\n                dims = img.shape\n                dtstr = img.dtype.descr[0][1][1:]\n                if img.size == 0:\n                    raise ValueError(\"data must have at least 1 row\")\n\n                # data must be c-contiguous and native byte order\n                if not img.flags['C_CONTIGUOUS']:\n                    # this always makes a copy\n                    img2send = numpy.ascontiguousarray(img)\n                    array_to_native(img2send, inplace=True)\n                else:\n                    img2send = array_to_native(img, inplace=False)\n\n                if IS_PY3 and img2send.dtype.char == 'U':\n                    # for python3, we convert unicode to ascii\n                    # this will error if the character is not in ascii\n                    img2send = img2send.astype('S', copy=False)\n\n            else:\n                self._ensure_empty_image_ok()\n                compress = None\n                tile_dims = None\n\n            # we get dims from the input image\n            dims2send = None\n        else:\n            # img was None and dims was sent\n            if dtype is None:\n                raise ValueError(\"send dtype= with dims=\")\n\n            # this must work!\n            dtype = numpy.dtype(dtype)\n            dtstr = dtype.descr[0][1][1:]\n            # use the example image to build the type in C\n            img2send = numpy.zeros(1, dtype=dtype)\n\n            # sending an array simplifies access\n            dims2send = numpy.array(dims, dtype='i8', ndmin=1)\n\n        if img2send is not None:\n            if img2send.dtype.fields is not None:\n                raise ValueError(\n                    \"got record data type, expected regular ndarray\")\n\n        if extname is None:\n            # will be ignored\n            extname = \"\"\n        else:\n            if not isstring(extname):\n                raise ValueError(\"extension name must be a string\")\n            extname = mks(extname)\n\n        if extname is not None and extver is not None:\n            extver = check_extver(extver)\n\n        if extver is None:\n            # will be ignored\n            extver = 0\n\n        comptype = get_compress_type(compress)\n        tile_dims = get_tile_dims(tile_dims, dims)\n\n        if img2send is not None:\n            check_comptype_img(comptype, dtstr)\n\n        if header is not None:\n            nkeys = len(header)\n        else:\n            nkeys = 0\n\n        self._FITS.create_image_hdu(img2send,\n                                    nkeys,\n                                    dims=dims2send,\n                                    comptype=comptype,\n                                    tile_dims=tile_dims,\n                                    extname=extname,\n                                    extver=extver)\n\n        # don't rebuild the whole list unless this is the first hdu\n        # to be created\n        self.update_hdu_list(rebuild=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that empty image is not written to the file.", "response": "def _ensure_empty_image_ok(self):\n        \"\"\"\n        If ignore_empty was not set to True, we only allow empty HDU for first\n        HDU and if there is no data there already\n        \"\"\"\n        if self.ignore_empty:\n            return\n\n        if len(self) > 1:\n            raise RuntimeError(\n                \"Cannot write None image at extension %d\" % len(self))\n        if 'ndims' in self[0]._info:\n            raise RuntimeError(\"Can only write None images to extension zero, \"\n                               \"which already exists\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_table(self, data, table_type='binary',\n                    names=None, formats=None, units=None,\n                    extname=None, extver=None, header=None,\n                    write_bitcols=False):\n        \"\"\"\n        Create a new table extension and write the data.\n\n        The table definition is taken from the fields in the input array.  If\n        you want to append new rows to the table, access the HDU directly and\n        use the write() function, e.g.\n\n            fits[extension].append(data)\n\n        parameters\n        ----------\n        data: recarray\n            A numpy array with fields.  The table definition will be\n            determined from this array.\n        table_type: string, optional\n            Either 'binary' or 'ascii', default 'binary'\n            Matching is case-insensitive\n        extname: string, optional\n            An optional string for the extension name.\n        extver: integer, optional\n            FITS allows multiple extensions to have the same name (extname).\n            These extensions can optionally specify an EXTVER version number in\n            the header.  Send extver= to set a particular version, which will\n            be represented in the header with keyname EXTVER.  The extver must\n            be an integer > 0.  If extver is not sent, the first one will be\n            selected.  If ext is an integer, the extver is ignored.\n        units: list/dec, optional:\n            A list of strings with units for each column.\n        header: FITSHDR, list, dict, optional\n            A set of header keys to write. The keys are written before the data\n            is written to the table, preventing a resizing of the table area.\n\n            Can be one of these:\n                - FITSHDR object\n                - list of dictionaries containing 'name','value' and optionally\n                  a 'comment' field; the order is preserved.\n                - a dictionary of keyword-value pairs; no comments are written\n                  in this case, and the order is arbitrary.\n            Note required keywords such as NAXIS, XTENSION, etc are cleaed out.\n        write_bitcols: boolean, optional\n            Write boolean arrays in the FITS bitcols format, default False\n\n        restrictions\n        ------------\n        The File must be opened READWRITE\n        \"\"\"\n\n        \"\"\"\n        if data.dtype.fields == None:\n            raise ValueError(\"data must have fields\")\n        if data.size == 0:\n            raise ValueError(\"data must have at least 1 row\")\n        \"\"\"\n\n        self.create_table_hdu(data=data,\n                              header=header,\n                              names=names,\n                              units=units,\n                              extname=extname,\n                              extver=extver,\n                              table_type=table_type,\n                              write_bitcols=write_bitcols)\n\n        if header is not None:\n            self[-1].write_keys(header)\n            self[-1]._update_info()\n\n        self[-1].write(data, names=names)", "response": "Write the data to the table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new table extension for the object containing the key - value pairs.", "response": "def create_table_hdu(self, data=None, dtype=None,\n                         header=None,\n                         names=None, formats=None,\n                         units=None, dims=None, extname=None, extver=None,\n                         table_type='binary', write_bitcols=False):\n        \"\"\"\n        Create a new, empty table extension and reload the hdu list.\n\n        There are three ways to do it:\n            1) send a numpy dtype, from which the formats in the fits file will\n               be determined.\n            2) Send an array in data= keyword.  this is required if you have\n                object fields for writing to variable length columns.\n            3) send the names,formats and dims yourself\n\n        You can then write data into the new extension using\n            fits[extension].write(array)\n        If you want to write to a single column\n            fits[extension].write_column(array)\n        But be careful as the other columns will be left zeroed.\n\n        Often you will instead just use write_table to do this all\n        atomically.\n\n            fits.write_table(recarray)\n\n        write_table will create the new table extension for you with the\n        appropriate fields.\n\n        parameters\n        ----------\n        dtype: numpy dtype or descriptor, optional\n            If you have an array with fields, you can just send arr.dtype.  You\n            can also use a list of tuples, e.g. [('x','f8'),('index','i4')] or\n            a dictionary representation.\n        data: a numpy array with fields, optional\n              or a dictionary\n\n            An array or dict from which to determine the table definition.  You\n            must use this instead of sending a descriptor if you have object\n            array fields, as this is the only way to determine the type and max\n            size.\n\n        names: list of strings, optional\n            The list of field names\n        formats: list of strings, optional\n            The TFORM format strings for each field.\n        dims: list of strings, optional\n            An optional list of dimension strings for each field.  Should\n            match the repeat count for the formats fields. Be careful of\n            the order since FITS is more like fortran. See the descr2tabledef\n            function.\n\n        table_type: string, optional\n            Either 'binary' or 'ascii', default 'binary'\n            Matching is case-insensitive\n        units: list of strings, optional\n            An optional list of unit strings for each field.\n        extname: string, optional\n            An optional extension name.\n        extver: integer, optional\n            FITS allows multiple extensions to have the same name (extname).\n            These extensions can optionally specify an EXTVER version number in\n            the header.  Send extver= to set a particular version, which will\n            be represented in the header with keyname EXTVER.  The extver must\n            be an integer > 0.  If extver is not sent, the first one will be\n            selected.  If ext is an integer, the extver is ignored.\n        write_bitcols: bool, optional\n            Write boolean arrays in the FITS bitcols format, default False\n\n        header: FITSHDR, list, dict, optional\n            This is only used to determine how many slots to reserve for\n            header keywords\n\n\n        restrictions\n        ------------\n        The File must be opened READWRITE\n        \"\"\"\n\n        # record this for the TableHDU object\n        self.keys['write_bitcols'] = write_bitcols\n\n        # can leave as turn\n        table_type_int = _extract_table_type(table_type)\n\n        if data is not None:\n            if isinstance(data, numpy.ndarray):\n                names, formats, dims = array2tabledef(\n                    data, table_type=table_type, write_bitcols=write_bitcols)\n            elif isinstance(data, (list, dict)):\n                names, formats, dims = collection2tabledef(\n                    data, names=names, table_type=table_type,\n                    write_bitcols=write_bitcols)\n            else:\n                raise ValueError(\n                    \"data must be an ndarray with fields or a dict\")\n        elif dtype is not None:\n            dtype = numpy.dtype(dtype)\n            names, formats, dims = descr2tabledef(\n                dtype.\n                descr,\n                write_bitcols=write_bitcols,\n                table_type=table_type,\n            )\n        else:\n            if names is None or formats is None:\n                raise ValueError(\n                    \"send either dtype=, data=, or names= and formats=\")\n\n            if not isinstance(names, list) or not isinstance(formats, list):\n                raise ValueError(\"names and formats should be lists\")\n            if len(names) != len(formats):\n                raise ValueError(\"names and formats must be same length\")\n\n            if dims is not None:\n                if not isinstance(dims, list):\n                    raise ValueError(\"dims should be a list\")\n                if len(dims) != len(names):\n                    raise ValueError(\"names and dims must be same length\")\n\n        if units is not None:\n            if not isinstance(units, list):\n                raise ValueError(\"units should be a list\")\n            if len(units) != len(names):\n                raise ValueError(\"names and units must be same length\")\n\n        if extname is None:\n            # will be ignored\n            extname = \"\"\n        else:\n            if not isstring(extname):\n                raise ValueError(\"extension name must be a string\")\n            extname = mks(extname)\n\n        if extname is not None and extver is not None:\n            extver = check_extver(extver)\n        if extver is None:\n            # will be ignored\n            extver = 0\n        if extname is None:\n            # will be ignored\n            extname = \"\"\n\n        if header is not None:\n            nkeys = len(header)\n        else:\n            nkeys = 0\n\n        # note we can create extname in the c code for tables, but not images\n        self._FITS.create_table_hdu(table_type_int, nkeys,\n                                    names, formats, tunit=units, tdim=dims,\n                                    extname=extname, extver=extver)\n\n        # don't rebuild the whole list unless this is the first hdu\n        # to be created\n        self.update_hdu_list(rebuild=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_hdu_list(self, rebuild=True):\n        if not hasattr(self, 'hdu_list'):\n            rebuild = True\n\n        if rebuild:\n            self.hdu_list = []\n            self.hdu_map = {}\n\n            # we don't know how many hdus there are, so iterate\n            # until we can't open any more\n            ext_start = 0\n        else:\n            # start from last\n            ext_start = len(self)\n\n        ext = ext_start\n        while True:\n            try:\n                self._append_hdu_info(ext)\n            except IOError:\n                break\n            except RuntimeError:\n                break\n\n            ext = ext + 1", "response": "Update the list of HDU entries in the current HDU object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _append_hdu_info(self, ext):\n\n        # raised IOError if not found\n        hdu_type = self._FITS.movabs_hdu(ext+1)\n\n        if hdu_type == IMAGE_HDU:\n            hdu = ImageHDU(self._FITS, ext, **self.keys)\n        elif hdu_type == BINARY_TBL:\n            hdu = TableHDU(self._FITS, ext, **self.keys)\n        elif hdu_type == ASCII_TBL:\n            hdu = AsciiTableHDU(self._FITS, ext, **self.keys)\n        else:\n            mess = (\"extension %s is of unknown type %s \"\n                    \"this is probably a bug\")\n            mess = mess % (ext, hdu_type)\n            raise IOError(mess)\n\n        self.hdu_list.append(hdu)\n        self.hdu_map[ext] = hdu\n\n        extname = hdu.get_extname()\n        if not self.case_sensitive:\n            extname = extname.lower()\n        if extname != '':\n            # this will guarantee we default to *first* version,\n            # if version is not requested, using __getitem__\n            if extname not in self.hdu_map:\n                self.hdu_map[extname] = hdu\n\n            ver = hdu.get_extver()\n            if ver > 0:\n                key = '%s-%s' % (extname, ver)\n                self.hdu_map[key] = hdu", "response": "internal routine to append info for indiciated extension"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self):\n        if self._iter_index == len(self.hdu_list):\n            raise StopIteration\n        hdu = self.hdu_list[self._iter_index]\n        self._iter_index += 1\n        return hdu", "response": "Move to the next HDU in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_item(self, item):\n        ver = 0\n        if isinstance(item, tuple):\n            ver_sent = True\n            nitem = len(item)\n            if nitem == 1:\n                ext = item[0]\n            elif nitem == 2:\n                ext, ver = item\n        else:\n            ver_sent = False\n            ext = item\n        return ext, ver, ver_sent", "response": "helper function to extract an item from the item list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_info(self):\n        super(ImageHDU, self)._update_info()\n\n        if self._info['hdutype'] != IMAGE_HDU:\n            mess = \"Extension %s is not a Image HDU\" % self.ext\n            raise ValueError(mess)\n\n        # convert to c order\n        if 'dims' in self._info:\n            self._info['dims'] = list(reversed(self._info['dims']))", "response": "Update the internal info of the a\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reshape(self, dims):\n\n        adims = numpy.array(dims, ndmin=1, dtype='i8')\n        self._FITS.reshape_image(self._ext+1, adims)", "response": "reshape an existing image to the requested dimensions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the image into this HDU.", "response": "def write(self, img, start=0, **keys):\n        \"\"\"\n        Write the image into this HDU\n\n        If data already exist in this HDU, they will be overwritten.  If the\n        image to write is larger than the image on disk, or if the start\n        position is such that the write would extend beyond the existing\n        dimensions, the on-disk image is expanded.\n\n        parameters\n        ----------\n        img: ndarray\n            A simple numpy ndarray\n        start: integer or sequence\n            Where to start writing data.  Can be an integer offset\n            into the entire array, or a sequence determining where\n            in N-dimensional space to start.\n        \"\"\"\n\n        dims = self.get_dims()\n\n        if img.dtype.fields is not None:\n            raise ValueError(\"got recarray, expected regular ndarray\")\n        if img.size == 0:\n            raise ValueError(\"data must have at least 1 row\")\n\n        # data must be c-contiguous and native byte order\n        if not img.flags['C_CONTIGUOUS']:\n            # this always makes a copy\n            img_send = numpy.ascontiguousarray(img)\n            array_to_native(img_send, inplace=True)\n        else:\n            img_send = array_to_native(img, inplace=False)\n\n        if IS_PY3 and img_send.dtype.char == 'U':\n            # for python3, we convert unicode to ascii\n            # this will error if the character is not in ascii\n            img_send = img_send.astype('S', copy=False)\n\n        if not numpy.isscalar(start):\n            # convert to scalar offset\n            # note we use the on-disk data type to get itemsize\n\n            offset = _convert_full_start_to_offset(dims, start)\n        else:\n            offset = start\n\n        # see if we need to resize the image\n        if self.has_data():\n            self._expand_if_needed(dims, img.shape, start, offset)\n\n        self._FITS.write_image(self._ext+1, img_send, offset+1)\n        self._update_info()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, **keys):\n        if not self.has_data():\n            return None\n\n        dtype, shape = self._get_dtype_and_shape()\n        array = numpy.zeros(shape, dtype=dtype)\n        self._FITS.read_image(self._ext+1, array)\n        return array", "response": "Read the image.\n\n        If the HDU is an IMAGE_HDU, read the corresponding image.  Compression\n        and scaling are dealt with properly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the numpy dtype and shape for image", "response": "def _get_dtype_and_shape(self):\n        \"\"\"\n        Get the numpy dtype and shape for image\n        \"\"\"\n        npy_dtype = self._get_image_numpy_dtype()\n\n        if self._info['ndims'] != 0:\n            shape = self._info['dims']\n        else:\n            raise IOError(\"no image present in HDU\")\n\n        return npy_dtype, shape"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the numpy dtype for the image", "response": "def _get_image_numpy_dtype(self):\n        \"\"\"\n        Get the numpy dtype for the image\n        \"\"\"\n        try:\n            ftype = self._info['img_equiv_type']\n            npy_type = _image_bitpix2npy[ftype]\n        except KeyError:\n            raise KeyError(\"unsupported fits data type: %d\" % ftype)\n\n        return npy_type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a slice of the image.", "response": "def _read_image_slice(self, arg):\n        \"\"\"\n        workhorse to read a slice\n        \"\"\"\n        if 'ndims' not in self._info:\n            raise ValueError(\"Attempt to slice empty extension\")\n\n        if isinstance(arg, slice):\n            # one-dimensional, e.g. 2:20\n            return self._read_image_slice((arg,))\n\n        if not isinstance(arg, tuple):\n            raise ValueError(\"arguments must be slices, one for each \"\n                             \"dimension, e.g. [2:5] or [2:5,8:25] etc.\")\n\n        # should be a tuple of slices, one for each dimension\n        # e.g. [2:3, 8:100]\n        nd = len(arg)\n        if nd != self._info['ndims']:\n            raise ValueError(\"Got slice dimensions %d, \"\n                             \"expected %d\" % (nd, self._info['ndims']))\n\n        targ = arg\n        arg = []\n        for a in targ:\n            if isinstance(a, slice):\n                arg.append(a)\n            elif isinstance(a, int):\n                arg.append(slice(a, a+1, 1))\n            else:\n                raise ValueError(\"arguments must be slices, e.g. 2:12\")\n\n        dims = self._info['dims']\n        arrdims = []\n        first = []\n        last = []\n        steps = []\n\n        # check the args and reverse dimensions since\n        # fits is backwards from numpy\n        dim = 0\n        for slc in arg:\n            start = slc.start\n            stop = slc.stop\n            step = slc.step\n\n            if start is None:\n                start = 0\n            if stop is None:\n                stop = dims[dim]\n            if step is None:\n                step = 1\n            if step < 1:\n                raise ValueError(\"slice steps must be >= 1\")\n\n            if start < 0:\n                start = dims[dim] + start\n                if start < 0:\n                    raise IndexError(\"Index out of bounds\")\n\n            if stop < 0:\n                stop = dims[dim] + start + 1\n\n            # move to 1-offset\n            start = start + 1\n\n            if stop < start:\n                raise ValueError(\"python slices but include at least one \"\n                                 \"element, got %s\" % slc)\n            if stop > dims[dim]:\n                stop = dims[dim]\n\n            first.append(start)\n            last.append(stop)\n            steps.append(step)\n            arrdims.append(stop-start+1)\n\n            dim += 1\n\n        first.reverse()\n        last.reverse()\n        steps.reverse()\n        first = numpy.array(first, dtype='i8')\n        last = numpy.array(last, dtype='i8')\n        steps = numpy.array(steps, dtype='i8')\n\n        npy_dtype = self._get_image_numpy_dtype()\n        array = numpy.zeros(arrdims, dtype=npy_dtype)\n        self._FITS.read_image_slice(self._ext+1, first, last, steps, array)\n        return array"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexpand the on - disk image if needed.", "response": "def _expand_if_needed(self, dims, write_dims, start, offset):\n        \"\"\"\n        expand the on-disk image if the indended write will extend\n        beyond the existing dimensions\n        \"\"\"\n        from operator import mul\n\n        if numpy.isscalar(start):\n            start_is_scalar = True\n        else:\n            start_is_scalar = False\n\n        existing_size = reduce(mul, dims, 1)\n        required_size = offset + reduce(mul, write_dims, 1)\n\n        if required_size > existing_size:\n            print(\n                \"    required size:\", required_size,\n                \"existing size:\", existing_size)\n            # we need to expand the image\n            ndim = len(dims)\n            idim = len(write_dims)\n\n            if start_is_scalar:\n                if start == 0:\n                    start = [0]*ndim\n                else:\n                    raise ValueError(\n                        \"When expanding \"\n                        \"an existing image while writing, the start keyword \"\n                        \"must have the same number of dimensions \"\n                        \"as the image or be exactly 0, got %s \" % start)\n\n            if idim != ndim:\n                raise ValueError(\n                    \"When expanding \"\n                    \"an existing image while writing, the input image \"\n                    \"must have the same number of dimensions \"\n                    \"as the original.  \"\n                    \"Got %d instead of %d\" % (idim, ndim))\n            new_dims = []\n            for i in xrange(ndim):\n                required_dim = start[i] + write_dims[i]\n\n                if required_dim < dims[i]:\n                    # careful not to shrink the image!\n                    dimsize = dims[i]\n                else:\n                    dimsize = required_dim\n\n                new_dims.append(dimsize)\n\n            print(\"    reshaping image to:\", new_dims)\n            self.reshape(new_dims)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_extname(self):\n        name = self._info['extname']\n        if name.strip() == '':\n            name = self._info['hduname']\n        return name.strip()", "response": "Get the name of the extension"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_extver(self):\n        ver = self._info['extver']\n        if ver == 0:\n            ver = self._info['hduver']\n        return ver", "response": "Get the version of this extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_exttype(self, num=False):\n        if num:\n            return self._info['hdutype']\n        else:\n            name = _hdu_type_map[self._info['hdutype']]\n            return name", "response": "Get the extension type of the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_offsets(self):\n        return dict(\n            header_start=self._info['header_start'],\n            data_start=self._info['data_start'],\n            data_end=self._info['data_end'],\n        )", "response": "Returns a dictionary with these entries in the file as keys and values as values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_checksum(self):\n        res = self._FITS.verify_checksum(self._ext+1)\n        if res['dataok'] != 1:\n            raise ValueError(\"data checksum failed\")\n        if res['hduok'] != 1:\n            raise ValueError(\"hdu checksum failed\")", "response": "Verify the checksum in the header for this HDU."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_comment(self, comment):\n        self._FITS.write_comment(self._ext+1, str(comment))", "response": "Write a comment into the header\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_history(self, history):\n        self._FITS.write_history(self._ext+1, str(history))", "response": "Writes the history text into the header of the log file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_continue(self, value):\n        self._FITS.write_continue(self._ext+1, str(value))", "response": "Writes a continue bit into the header."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_key(self, name, value, comment=\"\"):\n\n        if value is None:\n            self._FITS.write_undefined_key(self._ext+1,\n                                           str(name),\n                                           str(comment))\n\n        elif isinstance(value, bool):\n            if value:\n                v = 1\n            else:\n                v = 0\n            self._FITS.write_logical_key(self._ext+1,\n                                         str(name),\n                                         v,\n                                         str(comment))\n        elif isinstance(value, _stypes):\n            self._FITS.write_string_key(self._ext+1,\n                                        str(name),\n                                        str(value),\n                                        str(comment))\n        elif isinstance(value, _ftypes):\n            self._FITS.write_double_key(self._ext+1,\n                                        str(name),\n                                        float(value),\n                                        str(comment))\n        elif isinstance(value, _itypes):\n            self._FITS.write_long_key(self._ext+1,\n                                      str(name),\n                                      int(value),\n                                      str(comment))\n        elif isinstance(value, (tuple, list)):\n            vl = [str(el) for el in value]\n            sval = ','.join(vl)\n            self._FITS.write_string_key(self._ext+1,\n                                        str(name),\n                                        sval,\n                                        str(comment))\n        else:\n            sval = str(value)\n            mess = (\n                \"warning, keyword '%s' has non-standard \"\n                \"value type %s, \"\n                \"Converting to string: '%s'\")\n            warnings.warn(mess % (name, type(value), sval), FITSRuntimeWarning)\n            self._FITS.write_string_key(self._ext+1,\n                                        str(name),\n                                        sval,\n                                        str(comment))", "response": "Writes the input value to the header and returns the header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the keys of the current object to the header.", "response": "def write_keys(self, records_in, clean=True):\n        \"\"\"\n        Write the keywords to the header.\n\n        parameters\n        ----------\n        records: FITSHDR or list or dict\n            Can be one of these:\n                - FITSHDR object\n                - list of dictionaries containing 'name','value' and optionally\n                  a 'comment' field; the order is preserved.\n                - a dictionary of keyword-value pairs; no comments are written\n                  in this case, and the order is arbitrary.\n        clean: boolean\n            If True, trim out the standard fits header keywords that are\n            created on HDU creation, such as EXTEND, SIMPLE, STTYPE, TFORM,\n            TDIM, XTENSION, BITPIX, NAXIS, etc.\n\n        Notes\n        -----\n        Input keys named COMMENT and HISTORY are written using the\n        write_comment and write_history methods.\n        \"\"\"\n\n        if isinstance(records_in, FITSHDR):\n            hdr = records_in\n        else:\n            hdr = FITSHDR(records_in)\n\n        if clean:\n            is_table = hasattr(self, '_table_type_str')\n            # is_table = isinstance(self, TableHDU)\n            hdr.clean(is_table=is_table)\n\n        for r in hdr.records():\n            name = r['name'].upper()\n            value = r['value']\n\n            if name == 'COMMENT':\n                self.write_comment(value)\n            elif name == 'HISTORY':\n                self.write_history(value)\n            elif name == 'CONTINUE':\n                self._write_continue(value)\n            else:\n                comment = r.get('comment', '')\n                self.write_key(name, value, comment=comment)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_info(self):\n        try:\n            self._FITS.movabs_hdu(self._ext+1)\n        except IOError:\n            raise RuntimeError(\"no such hdu\")\n\n        self._info = self._FITS.get_hdu_info(self._ext+1)", "response": "Update info for this HDU."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_repr_list(self):\n        spacing = ' '*2\n        text = ['']\n        text.append(\"%sfile: %s\" % (spacing, self._filename))\n        text.append(\"%sextension: %d\" % (spacing, self._info['hdunum']-1))\n        text.append(\n            \"%stype: %s\" % (spacing, _hdu_type_map[self._info['hdutype']]))\n\n        extname = self.get_extname()\n        if extname != \"\":\n            text.append(\"%sextname: %s\" % (spacing, extname))\n        extver = self.get_extver()\n        if extver != 0:\n            text.append(\"%sextver: %s\" % (spacing, extver))\n\n        return text, spacing", "response": "Get some representation data common to all HDU types and return a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_record(self, record_in):\n        if (isinstance(record_in, dict) and\n                'name' in record_in and 'value' in record_in):\n            record = {}\n            record.update(record_in)\n        else:\n            record = FITSRecord(record_in)\n\n        # only append when this name already exists if it is\n        # a comment or history field, otherwise simply over-write\n        key = record['name'].upper()\n\n        key_exists = key in self._record_map\n\n        if not key_exists or key in ('COMMENT', 'HISTORY', 'CONTINUE'):\n            # append new record\n            self._record_list.append(record)\n            index = len(self._record_list)-1\n            self._index_map[key] = index\n        else:\n            # over-write existing\n            index = self._index_map[key]\n            self._record_list[index] = record\n\n        self._record_map[key] = record", "response": "Adds a new record to the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the comment for the requested entry", "response": "def get_comment(self, item):\n        \"\"\"\n        Get the comment for the requested entry\n        \"\"\"\n        key = item.upper()\n        if key not in self._record_map:\n            raise KeyError(\"unknown record: %s\" % key)\n\n        if 'comment' not in self._record_map[key]:\n            return None\n        else:\n            return self._record_map[key]['comment']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, name):\n        if isinstance(name, (list, tuple)):\n            for xx in name:\n                self.delete(xx)\n        else:\n            if name in self._record_map:\n                del self._record_map[name]\n                self._record_list = [\n                    r for r in self._record_list if r['name'] != name]", "response": "Delete the specified entry if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean(self, is_table=False):\n\n        rmnames = [\n            'SIMPLE', 'EXTEND', 'XTENSION', 'BITPIX', 'PCOUNT', 'GCOUNT',\n            'THEAP',\n            'EXTNAME',\n            'BLANK',\n            'ZQUANTIZ', 'ZDITHER0', 'ZIMAGE', 'ZCMPTYPE',\n            'ZSIMPLE', 'ZTENSION', 'ZPCOUNT', 'ZGCOUNT',\n            'ZBITPIX', 'ZEXTEND',\n            # 'FZTILELN','FZALGOR',\n            'CHECKSUM', 'DATASUM']\n\n        if is_table:\n            # these are not allowed in tables\n            rmnames += [\n                'BUNIT', 'BSCALE', 'BZERO',\n            ]\n\n        self.delete(rmnames)\n\n        r = self._record_map.get('NAXIS', None)\n        if r is not None:\n            naxis = int(r['value'])\n            self.delete('NAXIS')\n\n            rmnames = ['NAXIS%d' % i for i in xrange(1, naxis+1)]\n            self.delete(rmnames)\n\n        r = self._record_map.get('ZNAXIS', None)\n        self.delete('ZNAXIS')\n        if r is not None:\n\n            znaxis = int(r['value'])\n\n            rmnames = ['ZNAXIS%d' % i for i in xrange(1, znaxis+1)]\n            self.delete(rmnames)\n            rmnames = ['ZTILE%d' % i for i in xrange(1, znaxis+1)]\n            self.delete(rmnames)\n            rmnames = ['ZNAME%d' % i for i in xrange(1, znaxis+1)]\n            self.delete(rmnames)\n            rmnames = ['ZVAL%d' % i for i in xrange(1, znaxis+1)]\n            self.delete(rmnames)\n\n        r = self._record_map.get('TFIELDS', None)\n        if r is not None:\n            tfields = int(r['value'])\n            self.delete('TFIELDS')\n\n            if tfields > 0:\n\n                nbase = [\n                    'TFORM', 'TTYPE', 'TDIM', 'TUNIT', 'TSCAL', 'TZERO',\n                    'TNULL', 'TDISP', 'TDMIN', 'TDMAX', 'TDESC', 'TROTA',\n                    'TRPIX', 'TRVAL', 'TDELT', 'TCUNI',\n                    # 'FZALG'\n                ]\n                for i in xrange(1, tfields+1):\n                    names = ['%s%d' % (n, i) for n in nbase]\n                    self.delete(names)", "response": "Removes reserved keywords from the header and data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the requested header entry by keyword name.", "response": "def get(self, item, default_value=None):\n        \"\"\"\n        Get the requested header entry by keyword name\n        \"\"\"\n\n        found, name = self._contains_and_name(item)\n        if found:\n            return self._record_map[name]['value']\n        else:\n            return default_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self):\n        if self._current < len(self._record_list):\n            rec = self._record_list[self._current]\n            key = rec['name']\n            self._current += 1\n            return key\n        else:\n            raise StopIteration", "response": "Returns the next key in the record list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a record into a card string.", "response": "def _record2card(self, record):\n        \"\"\"\n        when we add new records they don't have a card,\n        this sort of fakes it up similar to what cfitsio\n        does, just for display purposes.  e.g.\n\n            DBL     =            23.299843\n            LNG     =              3423432\n            KEYSNC  = 'hello   '\n            KEYSC   = 'hello   '           / a comment for string\n            KEYDC   =     3.14159265358979 / a comment for pi\n            KEYLC   =            323423432 / a comment for long\n\n        basically,\n            - 8 chars, left aligned, for the keyword name\n            - a space\n            - 20 chars for value, left aligned for strings, right aligned for\n              numbers\n            - if there is a comment, one space followed by / then another space\n              then the comment out to 80 chars\n\n        \"\"\"\n        name = record['name']\n        value = record['value']\n\n        v_isstring = isstring(value)\n\n        if name == 'COMMENT':\n            # card = 'COMMENT   %s' % value\n            card = 'COMMENT %s' % value\n        elif name == 'CONTINUE':\n            card = 'CONTINUE   %s' % value\n        elif name == 'HISTORY':\n            card = 'HISTORY   %s' % value\n        else:\n            if len(name) > 8:\n                card = 'HIERARCH %s= ' % name\n            else:\n                card = '%-8s= ' % name[0:8]\n\n            # these may be string representations of data, or actual strings\n            if v_isstring:\n                value = str(value)\n                if len(value) > 0:\n                    if value[0] != \"'\":\n                        # this is a string representing a string header field\n                        # make it look like it will look in the header\n                        value = \"'\" + value + \"'\"\n                        vstr = '%-20s' % value\n                    else:\n                        vstr = \"%20s\" % value\n                else:\n                    vstr = \"''\"\n            else:\n                vstr = '%20s' % value\n\n            card += vstr\n\n            if 'comment' in record:\n                card += ' / %s' % record['comment']\n\n        if v_isstring and len(card) > 80:\n            card = card[0:79] + \"'\"\n        else:\n            card = card[0:80]\n\n        return card"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the record in the object", "response": "def set_record(self, record, **kw):\n        \"\"\"\n        check the record is valid and set keys in the dict\n\n        parameters\n        ----------\n        record: string\n            Dict representing a record or a string representing a FITS header\n            card\n        \"\"\"\n\n        if isstring(record):\n            card = FITSCard(record)\n            self.update(card)\n\n            self.verify()\n\n        else:\n\n            if isinstance(record, FITSRecord):\n                self.update(record)\n            elif isinstance(record, dict):\n                if 'name' in record and 'value' in record:\n                    self.update(record)\n\n                elif 'card_string' in record:\n                    self.set_record(record['card_string'])\n\n                else:\n                    raise ValueError('record must have name,value fields '\n                                     'or a card_string field')\n            else:\n                raise ValueError(\"record must be a string card or \"\n                                 \"dictionary or FITSRecord\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck for = in position 9 set attribute _has_equals", "response": "def _check_equals(self):\n        \"\"\"\n        check for = in position 8, set attribute _has_equals\n        \"\"\"\n        card_string = self['card_string']\n        if len(card_string) < 9:\n            self._has_equals = False\n        elif card_string[8] == '=':\n            self._has_equals = True\n        else:\n            self._has_equals = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts value_orig to value_orig", "response": "def _convert_value(self, value_orig):\n        \"\"\"\n        things like 6 and 1.25 are converted with ast.literal_value\n\n        Things like 'hello' are stripped of quotes\n        \"\"\"\n        import ast\n        if value_orig is None:\n            return value_orig\n\n        if value_orig.startswith(\"'\") and value_orig.endswith(\"'\"):\n            value = value_orig[1:-1]\n        else:\n\n            try:\n                avalue = ast.parse(value_orig).body[0].value\n                if isinstance(avalue, ast.BinOp):\n                    # this is probably a string that happens to look like\n                    # a binary operation, e.g. '25-3'\n                    value = value_orig\n                else:\n                    value = ast.literal_eval(value_orig)\n            except Exception:\n                value = self._convert_string(value_orig)\n\n            if isinstance(value, int) and '_' in value_orig:\n                value = value_orig\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates available threads count post - construction.", "response": "def _update_threads(self):\n        \"\"\"Update available thread count post-construction.\n        To be called any number of times from run() method\"\"\"\n        if self.remaining_clusters is not None:\n            self.threads = max(1,self.threads_total//self.remaining_clusters.value)\n        #otherwise just keep the current (initial) value\n        print(\"{} detected {} threads available to it\".format(self.name,self.threads), file = self.log_fh)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _report_completion(self):\n        rem_clust = self.remaining_clusters\n        if rem_clust is not None:\n            # -= is non-atomic, need to acquire a lock\n            with self.remaining_clusters_lock:\n                rem_clust.value -= 1\n            # we do not need this object anymore\n            self.remaining_clusters = None\n            print(\"{} reported completion\".format(self.name), file=self.log_fh)", "response": "Report that we have finished with this cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_reads_for_assembly(number_of_wanted_reads, total_reads, reads_in1, reads_in2, reads_out1, reads_out2, random_seed=None):\n        '''Makes fastq files that are random subset of input files. Returns total number of reads in output files.\n           If the number of wanted reads is >= total reads, then just makes symlinks instead of making\n           new copies of the input files.'''\n        random.seed(random_seed)\n\n        if number_of_wanted_reads < total_reads:\n            reads_written = 0\n            percent_wanted = 100 * number_of_wanted_reads / total_reads\n            file_reader1 = pyfastaq.sequences.file_reader(reads_in1)\n            file_reader2 = pyfastaq.sequences.file_reader(reads_in2)\n            out1 = pyfastaq.utils.open_file_write(reads_out1)\n            out2 = pyfastaq.utils.open_file_write(reads_out2)\n\n            for read1 in file_reader1:\n                try:\n                    read2 = next(file_reader2)\n                except StopIteration:\n                    pyfastaq.utils.close(out1)\n                    pyfastaq.utils.close(out2)\n                    raise Error('Error subsetting reads. No mate found for read ' + read1.id)\n\n                if random.randint(0, 100) <= percent_wanted:\n                    print(read1, file=out1)\n                    print(read2, file=out2)\n                    reads_written += 2\n\n            pyfastaq.utils.close(out1)\n            pyfastaq.utils.close(out2)\n            return reads_written\n        else:\n            os.symlink(reads_in1, reads_out1)\n            os.symlink(reads_in2, reads_out2)\n            return total_reads", "response": "Makes fastq files that are random subset of input files. Returns total number of reads in output files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef genbank_to_gene_coords(infile, genes):\n    '''Input file in genbank format. genes = list of gene names to find.\n    Returns dict of gene name -> {start: x, end: y}, where x and y are\n    zero-based. x<y iff gene is on forwards strand'''\n    coords = {}\n\n    for seq_record in SeqIO.parse(infile, \"genbank\"):\n        for feature in seq_record.features:\n            if feature.type == 'gene':\n                gene_name = feature.qualifiers.get('gene', [None])[0]\n                if gene_name not in genes:\n                    continue\n\n                if feature.location.strand == 1:\n                    coords[gene_name] = {'start': int(feature.location.start), 'end': int(feature.location.end) - 1}\n                else:\n                    coords[gene_name] = {'end': int(feature.location.start), 'start': int(feature.location.end) - 1}\n\n    return coords", "response": "Input file in genbank format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_mutations(gene_coords, mutation_to_drug_json, variants_txt, upstream_before=100):\n    '''Load mutations from \"mykrobe-style\" files. mutation_to_drug_json is json file\n    of mutation -> list of drugs. variants_txt is text file of variants used my mykrobe's\n    make probes. gene_coords should be dict of gene coords made by the function\n    genbank_to_gene_coords'''\n    with open(mutation_to_drug_json) as f:\n        drug_data = json.load(f)\n\n    mutations = []\n    genes_with_indels = set()\n    genes_need_upstream = set()\n    genes_non_upstream = set()\n\n    with open(variants_txt) as f:\n        for line in f:\n            gene, variant, d_or_p = line.rstrip().split('\\t')\n            coding = 0 if gene == 'rrs' else 1\n            d = {'gene': gene, 'var': variant, 'coding': coding, 'upstream': False}\n            drug_data_key = d['gene'] + '_' + d['var']\n            if drug_data_key not in drug_data:\n                print('KEY', drug_data_key, 'NOT FOUND', file=sys.stderr)\n            else:\n                d['drugs'] = ','.join(sorted(drug_data[drug_data_key]))\n\n            if d_or_p == 'DNA' and gene != 'rrs':\n                assert gene != 'rrs'\n                re_match = re.match('([ACGT]+)(-?[0-9]+)([ACGTX]+)', d['var'])\n                try:\n                    ref, pos, alt = re_match.groups()\n                except:\n                    print('regex error:', d['var'], file=sys.stderr)\n                    continue\n\n                pos = int(pos)\n                if len(ref) != len(alt):\n                    genes_with_indels.add(d['gene'])\n                    continue\n                elif pos > 0:\n                    #print('ignoring synonymous change (not implemented):', d['gene'], d['var'], d['drugs'], file=sys.stderr)\n                    continue\n                elif pos < 0:\n                    this_gene_coords = gene_coords[d['gene']]\n                    d['upstream'] = True\n                    if this_gene_coords['start'] < this_gene_coords['end']:\n                        variant_pos_in_output_seq = upstream_before + pos + 1\n                    else:\n                        variant_pos_in_output_seq = upstream_before + pos + 1\n                    assert variant_pos_in_output_seq > 0\n                    d['var'] = ref + str(variant_pos_in_output_seq) + alt\n                    d['original_mutation'] = variant\n                    genes_need_upstream.add(d['gene'])\n                elif pos == 0:\n                    print('Zero coord!', d, file=sys.stderr)\n                    continue\n                else:\n                    print('deal with?', d, file=sys.stderr)\n                    continue\n\n            mutations.append(d)\n            if not d['upstream']:\n                genes_non_upstream.add(d['gene'])\n\n    return mutations, genes_with_indels, genes_need_upstream, genes_non_upstream", "response": "Load mutations from mykrobe - style files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a FASTA file to be used with - f option of prepareref", "response": "def write_prepareref_fasta_file(outfile, gene_coords, genes_need_upstream, genes_non_upstream, upstream_before=100, upstream_after=100):\n    '''Writes fasta file to be used with -f option of prepareref'''\n    tmp_dict = {}\n    fasta_in = os.path.join(data_dir, 'NC_000962.3.fa.gz')\n    pyfastaq.tasks.file_to_dict(fasta_in, tmp_dict)\n    ref_seq = tmp_dict['NC_000962.3']\n\n    with open(outfile, 'w') as f:\n        for gene in genes_non_upstream:\n            start = gene_coords[gene]['start']\n            end = gene_coords[gene]['end']\n            if start < end:\n                gene_fa = pyfastaq.sequences.Fasta(gene, ref_seq[start:end+1])\n            else:\n                gene_fa = pyfastaq.sequences.Fasta(gene, ref_seq[end:start+1])\n                gene_fa.revcomp()\n\n            print(gene_fa, file=f)\n\n        for gene in genes_need_upstream:\n            start = gene_coords[gene]['start']\n            end = gene_coords[gene]['end']\n            if start < end:\n                gene_fa = pyfastaq.sequences.Fasta(gene, ref_seq[start - upstream_before:start + upstream_after])\n            else:\n                gene_fa = pyfastaq.sequences.Fasta(gene, ref_seq[start - upstream_after + 1:start + upstream_before + 1])\n                gene_fa.revcomp()\n\n            gene_fa.id += '_upstream'\n            print(gene_fa, file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_known_noncoding_het_snp(data_dict):\n        '''If ref is coding, return None. If the data dict has a known snp, and\n           samtools made a call, then return the string ref_name_change and the\n           % of reads supporting the variant type. If noncoding, but no\n           samtools call, then return None'''\n        if data_dict['gene'] == '1':\n            return None\n\n        if data_dict['known_var'] == '1' and data_dict['ref_ctg_effect'] == 'SNP' \\\n          and data_dict['smtls_nts'] != '.' and ';' not in data_dict['smtls_nts']:\n            nucleotides = data_dict['smtls_nts'].split(',')\n            depths = data_dict['smtls_nts_depth'].split(',')\n\n            if len(nucleotides) != len(depths):\n                raise Error('Mismatch in number of inferred nucleotides from ctg_nt, smtls_nts, smtls_nts_depth columns. Cannot continue\\n' + str(data_dict))\n\n            try:\n                var_nucleotide = data_dict['known_var_change'][-1]\n                depths = [int(x) for x in depths]\n                nuc_to_depth = dict(zip(nucleotides, depths))\n                total_depth = sum(depths)\n                var_depth = nuc_to_depth.get(var_nucleotide, 0)\n                percent_depth = round(100 * var_depth / total_depth, 1)\n            except:\n                return None\n\n            return data_dict['known_var_change'], percent_depth\n        else:\n            return None", "response": "Return the string ref_name_change and the\n           percent of reads supporting the variant type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_nonsynonymous_var(data_dict):\n        '''if data_dict has a non synonymous variant, return string:\n        ref_name.change. Otherwise return None'''\n        has_nonsyn = SummaryCluster._has_nonsynonymous(data_dict)\n\n        if has_nonsyn == 'no':\n            return None\n        elif data_dict['known_var_change'] == data_dict['ref_ctg_change'] == '.' == data_dict['ref_ctg_effect']:\n            raise Error('Unexpected data in ariba summary... \\n' + str(data_dict) + '\\n... known_var_change, ref_ctg_change, ref_ctg_effect all equal to \".\", but has a non synonymous change. Something is inconsistent. Cannot continue')\n        else:\n            if '.' not in [data_dict['known_var_change'], data_dict['ref_ctg_change']] and \\\n              data_dict['known_var_change'] != data_dict['ref_ctg_change']:\n                raise Error('Unexpected data in ariba summary... \\n' + str(data_dict) + '\\n... known_var_change != ref_ctg_change. Cannot continue')\n\n            var_group = 'novel', None\n\n            if data_dict['known_var'] == '1' and data_dict['known_var_change'] != '.':\n                var_change = data_dict['known_var_change']\n                if data_dict['var_group'] == '.':\n                    var_group = 'ungrouped', None\n                else:\n                    var_group = 'grouped', data_dict['var_group']\n            elif data_dict['ref_ctg_change'] != '.':\n                var_change = data_dict['ref_ctg_change']\n            else:\n                var_change = data_dict['ref_ctg_effect']\n\n            return (data_dict['ref_name'], var_change) + var_group", "response": "Returns the non synonymous variant of the current class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns yes or no depending on whether the assembled_summary matches the known_synonymous_var_only flag.", "response": "def _has_match(self, assembled_summary):\n        '''assembled_summary should be output of _to_cluster_summary_assembled'''\n        if assembled_summary.startswith('yes'):\n            if self.data[0]['var_only'] == '0' or self._to_cluster_summary_has_known_nonsynonymous(assembled_summary) == 'yes':\n                return 'yes'\n            else:\n                return 'no'\n        else:\n            return 'no'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a set of the variant group ids that this cluster has", "response": "def has_var_groups(self):\n        '''Returns a set of the variant group ids that this cluster has'''\n        ids = set()\n        for d in self.data:\n            if self._has_known_variant(d) != 'no' and d['var_group'] != '.':\n                ids.add(d['var_group'])\n        return ids"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of column name - > value for cluster - level results", "response": "def column_summary_data(self):\n        '''Returns a dictionary of column name -> value, for cluster-level results'''\n        assembled_summary = self._to_cluster_summary_assembled()\n        pct_id, read_depth = self._pc_id_and_read_depth_of_longest()\n\n        columns = {\n            'assembled': self._to_cluster_summary_assembled(),\n            'match': self._has_match(assembled_summary),\n            'ref_seq': self.ref_name,\n            'pct_id': str(pct_id),\n            'ctg_cov': str(read_depth),\n            'known_var': self._to_cluster_summary_has_known_nonsynonymous(assembled_summary),\n            'novel_var': self._to_cluster_summary_has_novel_nonsynonymous(assembled_summary)\n        }\n\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncatting all files in list infiles into outfile", "response": "def cat_files(infiles, outfile):\n    '''Cats all files in list infiles into outfile'''\n    f_out = pyfastaq.utils.open_file_write(outfile)\n\n    for filename in infiles:\n        if os.path.exists(filename):\n            f_in = pyfastaq.utils.open_file_read(filename)\n            for line in f_in:\n                print(line, end='', file=f_out)\n            pyfastaq.utils.close(f_in)\n\n    pyfastaq.utils.close(f_out)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if SPAdes can fail with a strange error. Stop everything if this happens.", "response": "def _check_spades_log_file(logfile):\n        '''SPAdes can fail with a strange error. Stop everything if this happens'''\n        f = pyfastaq.utils.open_file_read(logfile)\n\n        for line in f:\n            if line.startswith('== Error ==  system call for:') and line.rstrip().endswith('finished abnormally, err code: -7'):\n                pyfastaq.utils.close(f)\n                print('Error running SPAdes. Cannot continue. This is the error from the log file', logfile, '...', file=sys.stderr)\n                print(line, file=sys.stderr)\n                raise Error('Fatal error (\"err code: -7\") running spades. Cannot continue')\n\n        pyfastaq.utils.close(f)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fix_contig_orientation(contigs_fa, ref_fa, outfile, min_id=90, min_length=20, breaklen=200):\n        '''Changes orientation of each contig to match the reference, when possible.\n           Returns a set of names of contigs that had hits in both orientations to the reference'''\n        if not os.path.exists(contigs_fa):\n            raise Error('Cannot fix orientation of assembly contigs because file not found: ' + contigs_fa)\n\n        tmp_coords = os.path.join(outfile + '.tmp.rename.coords')\n        pymummer.nucmer.Runner(\n            ref_fa,\n            contigs_fa,\n            tmp_coords,\n            min_id=min_id,\n            min_length=min_length,\n            breaklen=breaklen,\n            maxmatch=True,\n        ).run()\n\n        to_revcomp = set()\n        not_revcomp = set()\n        file_reader = pymummer.coords_file.reader(tmp_coords)\n        for hit in file_reader:\n            if hit.on_same_strand():\n                not_revcomp.add(hit.qry_name)\n            else:\n                to_revcomp.add(hit.qry_name)\n\n        os.unlink(tmp_coords)\n        in_both = to_revcomp.intersection(not_revcomp)\n\n        f = pyfastaq.utils.open_file_write(outfile)\n        seq_reader = pyfastaq.sequences.file_reader(contigs_fa)\n        for seq in seq_reader:\n            if seq.id in to_revcomp and seq.id not in in_both:\n                seq.revcomp()\n            print(seq, file=f)\n        pyfastaq.utils.close(f)\n\n        return in_both", "response": "Changes the orientation of each contig to match the reference when possible. Returns a set of names of contigs that had hits in both orientations to the reference."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_nucmer_coords_file(coords_file, ref_name):\n        '''Input is coords file made by self._run_nucmer. Reference should have one sequence only.\n           ref_name is name fo the reference sequence, to sanity check the coords file.\n           Returns dictionary. Key = assembly contig name. Value = list of nucmer hits to that contig'''\n        file_reader = pymummer.coords_file.reader(coords_file)\n        nucmer_hits = {}\n        for hit in file_reader:\n            assert hit.ref_name == ref_name\n            contig = hit.qry_name\n            if contig not in nucmer_hits:\n                nucmer_hits[contig] = []\n            nucmer_hits[contig].append(copy.copy(hit))\n\n        return nucmer_hits", "response": "Input is coords file made by self. _run_nucmer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninput is hits made by self. _parse_nucmer_coords_file. nucmer_coords_file. nucmer_hits Returns dictionary. key = contig name. Value = percent identity of hits to that contig", "response": "def _nucmer_hits_to_percent_identity(nucmer_hits):\n        '''Input is hits made by self._parse_nucmer_coords_file.\n           Returns dictionary. key = contig name. Value = percent identity of hits to that contig'''\n        percent_identities = {}\n        max_lengths = {}\n\n        for contig in nucmer_hits:\n            max_length = -1\n            percent_identity = 0\n            for hit in nucmer_hits[contig]:\n                if hit.hit_length_qry > max_length:\n                    max_length = hit.hit_length_qry\n                    percent_identity = hit.percent_identity\n            percent_identities[contig] = percent_identity\n\n        return percent_identities"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _nucmer_hits_to_assembly_coords(nucmer_hits):\n        '''Input is hits made by self._parse_nucmer_coords_file.\n           Returns dictionary. key = contig name. Value = list of coords that match\n           to the reference gene'''\n        coords = {}\n        for l in nucmer_hits.values():\n            for hit in l:\n                if hit.qry_name not in coords:\n                    coords[hit.qry_name] = []\n                coords[hit.qry_name].append(hit.qry_coords())\n\n        for scaff in coords:\n            pyfastaq.intervals.merge_overlapping_in_list(coords[scaff])\n\n        return coords", "response": "Input is hits made by self. _parse_nucmer_coords_file. nucmer_coords_file. n"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nucmer_hits_to_ref_coords(cls, nucmer_hits, contig=None):\n        '''Input is hits made by self._parse_nucmer_coords_file.\n           Returns dictionary. Key = contig name. Value = list of coords in the\n           reference sequence for that contig.\n           if contig=contig_name, then just gets the ref coords from that contig,\n           instead of using all the contigs'''\n        coords = []\n        if contig is None:\n            coords = {key: [] for key in nucmer_hits.keys()}\n        else:\n            coords = {contig: []}\n\n        for key in coords:\n            coords[key] = [hit.ref_coords() for hit in nucmer_hits[key]]\n            pyfastaq.intervals.merge_overlapping_in_list(coords[key])\n\n        return coords", "response": "Input is hits made by self. _parse_nucmer_coords_file. nucmer_coords_file. nucmer_coords Returns dictionary. Key = contig name Value = list of coords in the\n           reference sequence for that contig."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninputting is hits made by self. _parse_nucmer_coords_file. nucmer_hits Returns dictionary. key = contig name. Value = number of bases that match to the reference sequence.", "response": "def ref_cov_per_contig(nucmer_hits):\n        '''Input is hits made by self._parse_nucmer_coords_file.\n           Returns dictionary. key = contig name. Value = number of bases that\n           match to the reference sequence.'''\n        coords = AssemblyCompare.nucmer_hits_to_ref_coords(nucmer_hits)\n        return {x: pyfastaq.intervals.length_sum_from_list(coords[x]) for x in coords}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_assembled_reference_sequences(nucmer_hits, ref_sequence, assembly):\n        '''nucmer_hits =  hits made by self._parse_nucmer_coords_file.\n           ref_gene = reference sequence (pyfastaq.sequences.Fasta object)\n           assembly = dictionary of contig name -> contig.\n           Makes a set of Fasta objects of each piece of assembly that\n           corresponds to the reference sequeunce.'''\n        sequences = {}\n\n        for contig in sorted(nucmer_hits):\n            for hit in nucmer_hits[contig]:\n                qry_coords = hit.qry_coords()\n                fa = assembly[hit.qry_name].subseq(qry_coords.start, qry_coords.end + 1)\n                if hit.on_same_strand():\n                    strand = '+'\n                else:\n                    fa.revcomp()\n                    strand = '-'\n                ref_coords = hit.ref_coords()\n                fa.id = '.'.join([\n                    ref_sequence.id,\n                    str(ref_coords.start + 1),\n                    str(ref_coords.end + 1),\n                    contig,\n                    str(qry_coords.start + 1),\n                    str(qry_coords.end + 1),\n                    strand\n                ])\n\n                if hit.hit_length_ref == hit.ref_length:\n                    fa.id += '.complete'\n\n                sequences[fa.id] = fa\n\n        return sequences", "response": "Returns a dictionary of all the assembled reference sequences."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns true iff the reference sequence is covered by nucmer hits.", "response": "def _whole_gene_covered_by_nucmer_hits(nucmer_hits, ref_seq, percent_threshold, max_nt_extend):\n        '''Returns true iff the reference sequence is covered by nucmer hits.\n           nucmer_hits = hits made by self._parse_nucmer_coords_file.\n           Counts as covered if (total ref bases covered) / len(ref_seq) >= threshold'''\n        coords = AssemblyCompare.nucmer_hits_to_ref_coords(nucmer_hits)\n        covered = []\n        for coords_list in coords.values():\n            covered.extend(coords_list)\n        pyfastaq.intervals.merge_overlapping_in_list(covered)\n        return (2 * max_nt_extend + pyfastaq.intervals.length_sum_from_list(covered)) / len(ref_seq) >= percent_threshold"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ref_has_region_assembled_twice(nucmer_hits, ref_seq, threshold):\n        '''Returns true iff there is a part of the reference that is assembled\n           more than once (ie covered by >1 nucmer hit).\n           Needs a minimum proportin of the ref to be assembled more than once,\n           determined by threshold.\n           nucmer_hits = hits made by self._parse_nucmer_coords_file.'''\n        coords = AssemblyCompare.nucmer_hits_to_ref_coords(nucmer_hits)\n        covered = []\n        for coords_list in coords.values():\n            covered.extend(coords_list)\n        covered.sort()\n\n        if len(covered) <= 1:\n            return False\n\n        coverage = {}\n        for i in covered:\n            for j in range(i.start, i.end + 1):\n                coverage[j] = coverage.get(j, 0) + 1\n\n        bases_depth_at_least_two = len([1 for x in coverage.values() if x > 1])\n        return bases_depth_at_least_two / len(ref_seq) >= threshold", "response": "Returns true iff there is a part of the reference that is assembled more than once."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ref_covered_by_at_least_one_full_length_contig(nucmer_hits, percent_threshold, max_nt_extend):\n        '''Returns true iff there exists a contig that completely\n           covers the reference sequence\n           nucmer_hits = hits made by self._parse_nucmer_coords_file.'''\n        for l in nucmer_hits.values():\n            for hit in l:\n                if ( (2 * max_nt_extend) + len(hit.ref_coords()) ) / hit.ref_length >= percent_threshold:\n                    return True\n        return False", "response": "Returns true iff there exists a contig that completely\n           covers the reference sequence\n          ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the first nucmer match found that contains the given reference location.", "response": "def nucmer_hit_containing_reference_position(nucmer_hits, ref_name, ref_position, qry_name=None):\n        '''Returns the first nucmer match found that contains the given\n           reference location. nucmer_hits = hits made by self._parse_nucmer_coords_file.\n           Returns None if no matching hit found'''\n        for contig_name in nucmer_hits:\n            for hit in nucmer_hits[contig_name]:\n                if hit.ref_name == ref_name and (qry_name is None or qry_name == hit.qry_name) and hit.ref_coords().distance_to_point(ref_position) == 0:\n                    return hit\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_exe(prog):\n        '''Given a program name, return what we expect its exectuable to be called'''\n        if prog in prog_to_env_var:\n            env_var = prog_to_env_var[prog]\n            if env_var in os.environ:\n                return os.environ[env_var]\n\n        return prog_to_default[prog]", "response": "Given a program name return what we expect its exectuable to be called"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_version(prog, path):\n        '''Given a program name and expected path, tries to determine its version.\n           Returns tuple (bool, version). First element True iff found version ok.\n           Second element is version string (if found), otherwise an error message'''\n        assert prog in prog_to_version_cmd\n        args, regex = prog_to_version_cmd[prog]\n        cmd = path + ' ' + args\n        if prog == 'spades':\n            cmd_output = subprocess.Popen(['python3', path, args], shell=False, stdout=subprocess.PIPE,\n                                          stderr=subprocess.PIPE).communicate()\n        else:\n            cmd_output = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n\n        cmd_output = common.decode(cmd_output[0]).split('\\n')[:-1] + common.decode(cmd_output[1]).split('\\n')[:-1]\n\n        for line in cmd_output:\n            hits = regex.search(line)\n            if hits:\n                return True, hits.group(1)\n\n        return False, 'I tried to get the version of ' + prog + ' with: \"' + cmd + '\" and the output didn\\'t match this regular expression: \"' + regex.pattern + '\"'", "response": "Given a program name and expected path tries to determine its version. Returns tuple ( bool version )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns total read depth and depth of reads supporting alternative ( if present )", "response": "def _get_read_depths(cls, read_depths_file, sequence_name, position):\n        '''Returns total read depth and depth of reads supporting alternative (if present)'''\n        assert os.path.exists(read_depths_file)\n        assert os.path.exists(read_depths_file + '.tbi')\n        tbx = pysam.TabixFile(read_depths_file)\n        try:\n            rows = [x for x in tbx.fetch(sequence_name, position, position + 1)]\n        except:\n            return None\n\n        if len(rows) > 1: # which happens with indels, mutiple lines for same base of reference\n            test_rows = [x for x in rows if x.rstrip().split()[3] != '.']\n            if len(test_rows) != 1:\n                rows = [rows[-1]]\n            else:\n                rows = test_rows\n\n        if len(rows) == 1:\n            r, p, ref_base, alt_base, ref_counts, alt_counts = rows[0].rstrip().split()\n            bases = ref_base if alt_base == '.' else ref_base + ',' + alt_base\n            return bases, int(ref_counts), alt_counts\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fake_run(self):\n        '''Doesn't actually run cd-hit. Instead, puts each input sequence into its own cluster. So it's as if cdhit was run, but didn't cluster anything'''\n        clusters = {}\n        used_names = set()\n        seq_reader = pyfastaq.sequences.file_reader(self.infile)\n\n        for seq in seq_reader:\n            if seq.id in used_names:\n                raise Error('Sequence name \"' + seq.id + '\" not unique. Cannot continue')\n\n            clusters[str(len(clusters) + self.min_cluster_number)] = {seq.id}\n            used_names.add(seq.id)\n\n        return clusters", "response": "Doesn t actually run cd - hit. Instead it puts each input sequence into its own cluster. So it s as if cdhit was run but didn t cluster anything."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_get_clusters_from_file(self, clusters_infile, all_ref_seqs, rename_dict=None):\n        '''Instead of running cdhit, gets the clusters info from the input file.'''\n        if rename_dict is None:\n            rename_dict = {}\n\n        # check that every sequence in the clusters file can be\n        # found in the fasta file\n        seq_reader = pyfastaq.sequences.file_reader(self.infile)\n        names_list_from_fasta_file = [seq.id for seq in seq_reader]\n        names_set_from_fasta_file = set(names_list_from_fasta_file)\n\n        clusters = self._load_user_clusters_file(clusters_infile, all_ref_seqs, rename_dict=rename_dict)\n\n        if len(names_set_from_fasta_file) != len(names_list_from_fasta_file):\n            raise Error('At least one duplicate name in fasta file ' + self.infile + '. Cannot continue')\n\n        names_from_clusters_file = set()\n        for new_names in clusters.values():\n            names_from_clusters_file.update(new_names)\n\n        if not names_set_from_fasta_file.issubset(names_from_clusters_file):\n            raise Error('Some names in fasta file \"' + self.infile + '\" not given in cluster file. Cannot continue')\n\n        return clusters", "response": "Instead of running cdhit gets the clusters info from the input file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_total_alignment_score(bam):\n    '''Returns total of AS: tags in the input BAM'''\n    sam_reader = pysam.Samfile(bam, \"rb\")\n    total = 0\n    for sam in sam_reader.fetch(until_eof=True):\n        try:\n            total += sam.opt('AS')\n        except:\n            pass\n    return total", "response": "Returns total of AS tags in the input BAM"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a pysam alignment returns the sequence a Fastq object.", "response": "def sam_to_fastq(sam):\n    '''Given a pysam alignment, returns the sequence a Fastq object.\n       Reverse complements as required and add suffix /1 or /2 as appropriate from the flag'''\n    name = sam.qname\n    if sam.is_read1:\n        name += '/1'\n    elif sam.is_read2:\n        name += '/2'\n    else:\n        raise Error('Read ' + name + ' must be first or second of pair according to flag. Cannot continue')\n\n    seq = pyfastaq.sequences.Fastq(name, common.decode(sam.seq), common.decode(sam.qual))\n    if sam.is_reverse:\n        seq.revcomp()\n\n    return seq"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns insert size from pair of sam records as long as their orientation is innies. Otherwise returns None.", "response": "def sam_pair_to_insert(s1, s2):\n    '''Returns insert size from pair of sam records, as long as their orientation is \"innies\".\n       Otherwise returns None.'''\n    if s1.is_unmapped or s2.is_unmapped or (s1.tid != s2.tid) or (s1.is_reverse == s2.is_reverse):\n        return None\n\n    # If here, reads are both mapped to the same ref, and in opposite orientations\n    if s1.is_reverse:\n        end = s1.reference_end - 1\n        start = s2.reference_start\n    else:\n        end = s2.reference_end - 1\n        start = s1.reference_start\n\n    if start < end:\n        return end - start + 1\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_from_sam(self, sam, sam_reader):\n        '''Updates graph info from a pysam.AlignedSegment object'''\n        if sam.is_unmapped \\\n          or sam.mate_is_unmapped \\\n          or (sam.reference_id == sam.next_reference_id):\n            return\n\n        new_link = link.Link(sam, sam_reader, self.ref_lengths)\n        read_name = sam.query_name\n\n        if read_name in self.partial_links:\n            new_link.merge(self.partial_links[read_name])\n            del self.partial_links[read_name]\n            key = tuple(sorted((new_link.refnames[0], new_link.refnames[1])))\n            if key not in self.links:\n                self.links[key] = []\n            new_link.sort()\n            self.links[key].append(new_link)\n        else:\n            self.partial_links[read_name] = new_link", "response": "Updates the internal representation of the internal representation of a pysam. AlignedSegment object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_graph(self, max_insert):\n        '''helper function to construct graph from current state of object'''\n        if len(self.partial_links) != 0:\n            raise Error('Error in _make_graph(). Cannot continue because there are partial links')\n        \n        self.contig_links = {}\n        for key in self.links:\n            for l in self.links[key]:\n                insert_size = l.insert_size()\n                if insert_size <= max_insert:\n                    if key not in self.contig_links:\n                        self.contig_links[key] = {}\n                    dirs = ''.join(l.dirs)\n                    self.contig_links[key][dirs] = self.contig_links[key].get(dirs, 0) + 1", "response": "helper function to construct graph from current state of object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nucleotide_range(self):\n        '''Returns the nucleotide (start, end) positions inclusive of this variant.\n           start==end if it's an amino acid variant, otherwise start+2==end'''\n        if self.variant_type == 'p':\n            return 3 * self.position, 3 * self.position + 2\n        else:\n            return self.position, self.position", "response": "Returns the nucleotide start and end positions inclusive of this variant."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns tuple of whether or not the left and right end of the mapped read in the sam record is soft - clipped", "response": "def _sam_to_soft_clipped(self, sam):\n        '''Returns tuple of whether or not the left and right end of the mapped read in the sam record is soft-clipped'''\n        if sam.is_unmapped:\n            raise Error('Cannot get soft clip info from an unmapped read')\n\n        if sam.cigar is None or len(sam.cigar) == 0:\n            return False, False\n        return (sam.cigar[0][0] == 4, sam.cigar[-1][0] == 4)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking report line string as input. Returns a dict of column name -> value in line", "response": "def _report_line_to_dict(cls, line):\n        '''Takes report line string as input. Returns a dict of column name -> value in line'''\n        data = line.split('\\t')\n        if len(data) != len(report.columns):\n            return None\n\n        d = dict(zip(report.columns, data))\n        for key in report.int_columns:\n            try:\n                d[key] = int(d[key])\n            except:\n                assert d[key] == '.'\n\n        for key in report.float_columns:\n            try:\n                d[key] = float(d[key])\n            except:\n                assert d[key] == '.'\n\n        d['flag'] = flag.Flag(int(d['flag']))\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dict_to_report_line(cls, report_dict):\n        '''Takes a report_dict as input and returns a report line'''\n        return '\\t'.join([str(report_dict[x]) for x in report.columns])", "response": "Takes a report_dict as input and returns a report line"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a report file into a dictionary. Key = reference name. Value = list of report lines for that reference", "response": "def _load_report(infile):\n        '''Loads report file into a dictionary. Key=reference name.\n        Value = list of report lines for that reference'''\n        report_dict = {}\n        f = pyfastaq.utils.open_file_read(infile)\n        first_line = True\n\n        for line in f:\n            line = line.rstrip()\n\n            if first_line:\n                expected_first_line = '#' + '\\t'.join(report.columns)\n                if line != expected_first_line:\n                    pyfastaq.utils.close(f)\n                    raise Error('Error reading report file. Expected first line of file is\\n' + expected_first_line + '\\nbut got:\\n' + line)\n                first_line = False\n            else:\n                line_dict = ReportFilter._report_line_to_dict(line)\n                if line_dict is None:\n                    pyfastaq.utils.close(f)\n                    raise Error('Error reading report file at this line:\\n' + line)\n                ref_name = line_dict['ref_name']\n                ctg_name = line_dict['ctg']\n                if ref_name not in report_dict:\n                    report_dict[ref_name] = {}\n                if ctg_name not in report_dict[ref_name]:\n                    report_dict[ref_name][ctg_name] = []\n\n                report_dict[ref_name][ctg_name].append(line_dict)\n\n        pyfastaq.utils.close(f)\n        return report_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _filter_dicts(self):\n        '''Filters out all the report_dicts that do not pass the cutoffs. If any ref sequence\n           loses all of its report_dicts, then it is completely removed.'''\n        keys_to_remove = set()\n\n        for ref_name in self.report:\n            for ctg_name in self.report[ref_name]:\n                self.report[ref_name][ctg_name] = self._filter_list_of_dicts(self.report[ref_name][ctg_name])\n                if len(self.report[ref_name][ctg_name]) == 0:\n                    keys_to_remove.add((ref_name, ctg_name))\n\n        refs_to_remove = set()\n\n        for ref_name, ctg_name in keys_to_remove:\n            del self.report[ref_name][ctg_name]\n            if len(self.report[ref_name]) == 0:\n                refs_to_remove.add(ref_name)\n\n        for ref_name in refs_to_remove:\n            del self.report[ref_name]", "response": "Filters out all the report_dicts that do not pass the cutoffs. If any ref sequence\n           loses all of its report_dicts then it is completely removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(self, other):\n        '''Merge another link into this one. Expected that each link was created from each mate from a pair. We only know both distances to contig ends when we have read info from both mappings in a BAM file. All other info should be the same.'''\n        assert self.refnames == other.refnames\n        assert self.dirs == other.dirs\n        assert self.lengths == other.lengths\n\n        for i in range(2):\n            if self.pos[i] is None:\n                if other.pos[i] is None:\n                   raise Error('Error merging these two links:\\n' + str(self) + '\\n' + str(other))\n                self.pos[i] = other.pos[i]\n            else:\n                if other.pos[i] is not None:\n                   raise Error('Error merging these two links:\\n' + str(self) + '\\n' + str(other))", "response": "Merge another link into this one. Expected that each link was created from each mate from each pair."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns insert size defined as distance from outer edges of reads and assumes gap length of zero", "response": "def insert_size(self):\n        '''Returns insert size, defined as distance from outer edges of reads (and assumes gap length of zero)'''\n        try:\n            distances = self._distance_to_contig_ends()\n        except:\n            raise Error('Error getting insert size from Link:\\n' + str(self))\n\n        return sum(distances)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_fofn(cls, fofn):\n        '''Returns dictionary of filename -> short name. Value is None\n        whenever short name is not provided'''\n        filenames = {}\n        f = pyfastaq.utils.open_file_read(fofn)\n        for line in f:\n            fields = line.rstrip().split()\n            if len(fields) == 1:\n                filenames[fields[0]] = None\n            elif len(fields) == 2:\n                filenames[fields[0]] = fields[1]\n            else:\n                raise Error('Error at the following line of file ' + fofn + '. Expected at most 2 fields.\\n' + line)\n\n        pyfastaq.utils.close(f)\n        return filenames", "response": "Returns dictionary of filename -> short name. Value is None whenever short name is not provided"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _filter_matrix_rows(cls, matrix):\n        '''matrix = output from _to_matrix'''\n        indexes_to_keep = []\n\n        for i in range(len(matrix)):\n            keep_row = False\n            for element in matrix[i]:\n                if element not in {'NA', 'no'}:\n                    keep_row = True\n                    break\n            if keep_row:\n                indexes_to_keep.append(i)\n\n        return [matrix[i] for i in indexes_to_keep]", "response": "Filter the rows of the matrix to only contain the rows that are not NA no or NA."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter out the columns in the matrix.", "response": "def _filter_matrix_columns(cls, matrix, phandango_header, csv_header):\n        '''phandango_header, csv_header, matrix = output from _to_matrix'''\n        indexes_to_keep = set()\n\n        for row in matrix:\n            for i in range(len(row)):\n                if row[i] not in {'NA', 'no'}:\n                    indexes_to_keep.add(i)\n\n        indexes_to_keep = sorted(list(indexes_to_keep))\n\n        for i in range(len(matrix)):\n            matrix[i] = [matrix[i][j] for j in indexes_to_keep]\n\n        phandango_header = [phandango_header[i] for i in indexes_to_keep]\n        csv_header = [csv_header[i] for i in indexes_to_keep]\n        return phandango_header, csv_header, matrix"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_variant_effect(cls, variants, ref_sequence):\n        '''variants = list of variants in the same codon.\n           returns type of variant (cannot handle more than one indel in the same codon).'''\n        assert len(variants) != 0\n\n        var_types = [x.var_type for x in variants]\n        if len(set(var_types)) != 1:\n            return 'MULTIPLE', '.', '.'\n\n        var_type = var_types[0]\n\n        assert set([x.ref_name for x in variants]) == set([ref_sequence.id])\n        codon_starts = [AssemblyVariants._get_codon_start(0, x.ref_start) for x in variants]\n        assert len(set(codon_starts)) == 1\n        codon_start = codon_starts[0]\n        aa_start = codon_start // 3\n        ref_codon = pyfastaq.sequences.Fasta('codon', ref_sequence[codon_start:codon_start+3])\n        ref_aa = ref_codon.translate()\n\n        if var_type == pymummer.variant.SNP:\n            new_codon = list(ref_codon.seq)\n            for v in variants:\n                new_codon[v.ref_start - codon_start] = v.qry_base\n            new_codon = pyfastaq.sequences.Fasta('new', ''.join(new_codon))\n            qry_aa = new_codon.translate()\n\n            if ref_aa.seq == qry_aa.seq:\n                return ('SYN', '.', aa_start)\n            elif qry_aa.seq == '*':\n                return ('TRUNC', ref_aa.seq + str(aa_start + 1) + 'trunc', aa_start)\n            else:\n                return ('NONSYN', ref_aa.seq + str(aa_start + 1) + qry_aa.seq, aa_start)\n        elif var_type in [pymummer.variant.INS, pymummer.variant.DEL]:\n            if len(variants) > 1:\n                return 'INDELS', '.', aa_start\n\n            var = variants[0]\n\n            if var_type == pymummer.variant.INS:\n                new_seq = pyfastaq.sequences.Fasta('seq', var.qry_base)\n            else:\n                new_seq = pyfastaq.sequences.Fasta('seq', var.ref_base)\n\n            if len(new_seq) % 3 != 0:\n                return ('FSHIFT', ref_aa.seq + str(aa_start + 1) + 'fs', aa_start)\n\n            new_seq_aa = new_seq.translate()\n            if '*' in new_seq_aa.seq:\n                return ('TRUNC', ref_aa.seq + str(aa_start + 1) + 'trunc', aa_start)\n            elif var_type == pymummer.variant.INS:\n                ref_codon_after_ins = pyfastaq.sequences.Fasta('codon', ref_sequence[codon_start+3:codon_start+6])\n                aa_after_ins = ref_codon_after_ins.translate()\n                return ('INS', ref_aa.seq + str(aa_start + 1) + '_' + aa_after_ins.seq + str(aa_start + 2) + 'ins' + new_seq_aa.seq , aa_start)\n            else:\n                if len(new_seq) == 3:\n                    return ('DEL', ref_aa.seq + str(aa_start + 1) + 'del', aa_start)\n                else:\n                    assert len(new_seq) % 3 == 0\n                    ref_codon_after_ins = pyfastaq.sequences.Fasta('codon', ref_sequence[codon_start+3:codon_start+6])\n                    aa_after_ins = ref_codon_after_ins.translate()\n                    return ('DEL', ref_aa.seq + str(aa_start + 1)+ '_' + aa_after_ins.seq + str(aa_start + 2) + 'del', aa_start)\n\n        else:\n            return ('UNKNOWN', '.', aa_start)", "response": "Returns the variant effect string for the current codon."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_remaining_known_ref_variants(known_ref_variants, used_ref_variants, nucmer_coords):\n        '''Finds variants where ref has the variant and so does the contig. Which means\n           that there was no mummer call to flag it up so need to look through the known\n           ref variants. Also need to check that the variant is in a nucmer match to an\n           assembly contig.'''\n        variants = []\n\n        for ref_variant_pos, ref_variants_set in sorted(known_ref_variants.items()):\n            for known_ref_variant in ref_variants_set:\n                if known_ref_variant not in used_ref_variants:\n                    variant_pos_matches_contig = False\n                    pos = known_ref_variant.variant.position\n\n                    if known_ref_variant.seq_type == 'n':\n                        ref_interval = intervals.Interval(pos, pos)\n                    elif known_ref_variant.seq_type == 'p':\n                        ref_interval = intervals.Interval(3 * pos, 3 * pos + 2)\n                    else:\n                        raise Error('Unexpected variant type \"' + known_ref_variant.variant_type + '\" in _get_remaining_known_ref_variants. Cannot continue')\n\n                    for interval in nucmer_coords:\n                        if ref_interval.intersects(interval):\n                            variant_pos_matches_contig = True\n                            break\n\n                    if variant_pos_matches_contig:\n                        variants.append((None, known_ref_variant.seq_type, None, None, None, {known_ref_variant}, set()))\n\n        return variants", "response": "Finds variants where ref has the variant and so does the contig."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_variants(self, ref_sequence_name, allowed_ctg_coords, allowed_ref_coords, nucmer_matches=None):\n        '''Nucmr coords = dict. Key=contig name. Value = list of intervals of ref coords that match the contig.\n           Made by assembly_compare.AssemblyCompare.nucmer_hits_to_ref_coords\n           Returns dictionary. Key=contig name. Value = list of variants. Each variant\n           is a tuple: (\n               0 = position,\n               1 = type in ['n', 'p']\n               2 = Variant string, eg 'D2E',\n               3 = variant effect (as returned by _get_variant_effect)\n               4 = list of pymummer.variant.Variant that made up this variant (could be more than one because of\n                   variants in the same codon)\n               5 = set {matching known variants from metadata (=sequence_metadata.SequenceMetadata)}\n               6 = set {known ref metadata (=sequence_metadata.SequenceMetadata)  at same position as SNP}, excluding those from 4\n           )\n        '''\n        mummer_variants = self._get_mummer_variants(self.nucmer_snp_file)\n        variants = {}\n        seq_type, is_variant_only = self.refdata.sequence_type(ref_sequence_name)\n        ref_sequence = self.refdata.sequence(ref_sequence_name)\n\n        if ref_sequence_name in self.refdata.metadata:\n            refdata_var_dict = self.refdata.metadata[ref_sequence_name]\n        else:\n            refdata_var_dict = None\n\n        known_non_wild_variants_in_ref = self.refdata.all_non_wild_type_variants(ref_sequence_name)\n\n        for contig in allowed_ctg_coords:\n            if contig not in allowed_ref_coords:\n                continue\n\n            used_known_variants = set()\n            variants[contig] = []\n\n            if contig in mummer_variants:\n                for mummer_variant_list in mummer_variants[contig]:\n                    ref_start = min([x.ref_start for x in mummer_variant_list])\n                    ref_end = max([x.ref_end for x in mummer_variant_list])\n                    ctg_start = min([x.qry_start for x in mummer_variant_list])\n                    ctg_end = min([x.qry_end for x in mummer_variant_list])\n                    ref_interval = intervals.Interval(ref_start, ref_end)\n                    ctg_interval = intervals.Interval(ctg_start, ctg_end)\n                    ref_ok = True in {x.intersects(ref_interval) for x in allowed_ref_coords[contig]}\n                    qry_ok = True in {x.intersects(ctg_interval) for x in allowed_ctg_coords[contig]}\n\n                    if not (ref_ok and qry_ok):\n                        continue\n\n                    if seq_type == 'p':\n                        new_variant, used_variants = self._get_one_variant_for_one_contig_coding(ref_sequence, refdata_var_dict, mummer_variant_list)\n                    else:\n                        for mummer_variant in mummer_variant_list:\n                            new_variant, used_variants = self._get_one_variant_for_one_contig_non_coding(refdata_var_dict, mummer_variant)\n\n                    if new_variant is not None:\n                            variants[contig].append(new_variant)\n                    used_known_variants.update(used_variants)\n\n            # for this contig, need to know all the ref sequence and coords it maps to.\n            # Then report just the unused known variants, as the contig also has these variants\n            if seq_type == 'p':\n                new_variants = self._get_remaining_known_ref_variants(known_non_wild_variants_in_ref['p'], used_known_variants, allowed_ref_coords[contig])\n\n            else:\n                new_variants = self._get_remaining_known_ref_variants(known_non_wild_variants_in_ref['n'], used_known_variants, allowed_ref_coords[contig])\n\n            if is_variant_only:\n                new_variants = [x for x in new_variants if len(x[5]) > 0]\n\n            variants[contig].extend(new_variants)\n            if len(variants[contig]) == 0:\n                del variants[contig]\n\n        return variants", "response": "Get all the variants that are in the reference sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _fix_virulencefinder_fasta_file(cls, infile, outfile):\n        '''Some line breaks are missing in the FASTA files from\n        viruslence finder. Which means there are lines like this:\n        AAGATCCAATAACTGAAGATGTTGAACAAACAATTCATAATATTTATGGTCAATATGCTATTTTCGTTGA\n        AGGTGTTGCGCATTTACCTGGACATCTCTCTCCATTATTAAAAAAATTACTACTTAAATCTTTATAA>coa:1:BA000018.3\n        ATGAAAAAGCAAATAATTTCGCTAGGCGCATTAGCAGTTGCATCTAGCTTATTTACATGGGATAACAAAG\n        and therefore the sequences are messed up when we parse them. Also\n        one has a > at the end, then the seq name on the next line.\n        This function fixes the file by adding line breaks'''\n        with open(infile) as f_in, open(outfile, 'w') as f_out:\n            for line in f_in:\n                if line.startswith('>') or '>' not in line:\n                    print(line, end='', file=f_out)\n                elif line.endswith('>\\n'):\n                    print('WARNING: found line with \">\" at the end! Fixing. Line:' + line.rstrip() + ' in file ' + infile, file=sys.stderr)\n                    print(line.rstrip('>\\n'), file=f_out)\n                    print('>', end='', file=f_out)\n                else:\n                    print('WARNING: found line with \">\" not at the start! Fixing. Line:' + line.rstrip() + ' in file ' + infile, file=sys.stderr)\n                    line1, line2 = line.split('>')\n                    print(line1, file=f_out)\n                    print('>', line2, sep='', end='', file=f_out)", "response": "This function fixes the line breaks in the file from\n        virulence finder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninputting is a known variants as sequence_metadata object. The list of variants is a list of pymummer. variant. Variant objects that are contained in the sequence_meta. variant. Variant objects that are not wild type.", "response": "def _samtools_depths_at_known_snps_all_wild(sequence_meta, contig_name, cluster, variant_list):\n    '''Input is a known variants, as sequence_metadata object. The\n       assumption is that both the reference and the assembly have the\n       variant type, not wild type. The list variant_list should be a list\n       of pymummer.variant.Variant objects, only contaning variants to the\n       relevant query contig'''\n    ref_nuc_range = sequence_meta.variant.nucleotide_range()\n\n    if ref_nuc_range is None:\n        return None\n\n    bases = []\n    ctg_nts = []\n    ref_nts = []\n    smtls_total_depths = []\n    smtls_nts = []\n    smtls_depths = []\n    contig_positions = []\n\n    for ref_position in range(ref_nuc_range[0], ref_nuc_range[1]+1, 1):\n        nucmer_match = cluster.assembly_compare.nucmer_hit_containing_reference_position(cluster.assembly_compare.nucmer_hits, cluster.ref_sequence.id, ref_position, qry_name=contig_name)\n\n        if nucmer_match is not None:\n            # work out contig position. Needs indels variants to correct the position\n            ref_nts.append(cluster.ref_sequence[ref_position])\n            contig_position, in_indel = nucmer_match.qry_coords_from_ref_coord(ref_position, variant_list)\n            contig_positions.append(contig_position)\n            bases, total_depth, base_depths = cluster.samtools_vars.get_depths_at_position(contig_name, contig_position)\n            ctg_nts.append(cluster.assembly.sequences[contig_name][contig_position])\n            smtls_nts.append(bases)\n            smtls_total_depths.append(total_depth)\n            smtls_depths.append(base_depths)\n\n    ctg_nts = ';'.join(ctg_nts) if len(ctg_nts) else '.'\n    ref_nts = ';'.join(ref_nts) if len(ref_nts) else '.'\n    smtls_nts = ';'.join(smtls_nts) if len(smtls_nts) else '.'\n    smtls_total_depths = ';'.join([str(x)for x in smtls_total_depths]) if len(smtls_total_depths) else '.'\n    smtls_depths = ';'.join([str(x)for x in smtls_depths]) if len(smtls_depths) else '.'\n    ctg_start = str(min(contig_positions) + 1) if contig_positions is not None else '.'\n    ctg_end = str(max(contig_positions) + 1) if contig_positions is not None else '.'\n\n    return [str(x) for x in [\n        ref_nuc_range[0] + 1,\n        ref_nuc_range[1] + 1,\n        ref_nts,\n        ctg_start,\n        ctg_end,\n        ctg_nts,\n        smtls_total_depths,\n        smtls_nts,\n        smtls_depths\n    ]]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef abbr(value: Any, limit: int=20) -> str:\n    rep = repr(value)\n\n    if len(rep) > limit:\n        if limit < 3:\n            raise ValueError('Abbreviation limit may not be less than 3')\n\n        rep = rep[:limit - 3] + '...'\n\n    return rep", "response": "Converts a value into its string representation and abbreviates that string representation based on the given length limit."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising an exception for when a value is not encodable by an encoder.", "response": "def invalidate_value(\n        cls,\n        value: Any,\n        exc: Type[Exception]=EncodingTypeError,\n        msg: Optional[str]=None,\n    ) -> None:\n        \"\"\"\n        Throws a standard exception for when a value is not encodable by an\n        encoder.\n        \"\"\"\n        raise exc(\n            \"Value `{rep}` of type {typ} cannot be encoded by {cls}{msg}\".format(\n                rep=abbr(value),\n                typ=type(value),\n                cls=cls.__name__,\n                msg=\"\" if msg is None else (\": \" + msg),\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse by BaseCoder subclasses as a convenience for implementing the ``from_type_str`` method required by ``ABIRegistry``. Useful if normalizing then parsing a type string with an (optional) expected base is required in that method.", "response": "def parse_type_str(expected_base=None, with_arrlist=False):\n    \"\"\"\n    Used by BaseCoder subclasses as a convenience for implementing the\n    ``from_type_str`` method required by ``ABIRegistry``.  Useful if normalizing\n    then parsing a type string with an (optional) expected base is required in\n    that method.\n    \"\"\"\n    def decorator(old_from_type_str):\n        @functools.wraps(old_from_type_str)\n        def new_from_type_str(cls, type_str, registry):\n            normalized_type_str = normalize(type_str)\n            abi_type = parse(normalized_type_str)\n\n            type_str_repr = repr(type_str)\n            if type_str != normalized_type_str:\n                type_str_repr = '{} (normalized to {})'.format(\n                    type_str_repr,\n                    repr(normalized_type_str),\n                )\n\n            if expected_base is not None:\n                if not isinstance(abi_type, BasicType):\n                    raise ValueError(\n                        'Cannot create {} for non-basic type {}'.format(\n                            cls.__name__,\n                            type_str_repr,\n                        )\n                    )\n                if abi_type.base != expected_base:\n                    raise ValueError(\n                        'Cannot create {} for type {}: expected type with '\n                        \"base '{}'\".format(\n                            cls.__name__,\n                            type_str_repr,\n                            expected_base,\n                        )\n                    )\n\n            if not with_arrlist and abi_type.arrlist is not None:\n                raise ValueError(\n                    'Cannot create {} for type {}: expected type with '\n                    'no array dimension list'.format(\n                        cls.__name__,\n                        type_str_repr,\n                    )\n                )\n            if with_arrlist and abi_type.arrlist is None:\n                raise ValueError(\n                    'Cannot create {} for type {}: expected type with '\n                    'array dimension list'.format(\n                        cls.__name__,\n                        type_str_repr,\n                    )\n                )\n\n            # Perform general validation of default solidity types\n            abi_type.validate()\n\n            return old_from_type_str(cls, abi_type, registry)\n\n        return classmethod(new_from_type_str)\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_tuple_type_str(old_from_type_str):\n    @functools.wraps(old_from_type_str)\n    def new_from_type_str(cls, type_str, registry):\n        normalized_type_str = normalize(type_str)\n        abi_type = parse(normalized_type_str)\n\n        type_str_repr = repr(type_str)\n        if type_str != normalized_type_str:\n            type_str_repr = '{} (normalized to {})'.format(\n                type_str_repr,\n                repr(normalized_type_str),\n            )\n\n        if not isinstance(abi_type, TupleType):\n            raise ValueError(\n                'Cannot create {} for non-tuple type {}'.format(\n                    cls.__name__,\n                    type_str_repr,\n                )\n            )\n\n        abi_type.validate()\n\n        return old_from_type_str(cls, abi_type, registry)\n\n    return classmethod(new_from_type_str)", "response": "A convenience method for implementing the\n    from_type_str method required by BaseCoder classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nseeks to the specified position in the current contextual frame.", "response": "def seek_in_frame(self, pos, *args, **kwargs):\n        \"\"\"\n        Seeks relative to the total offset of the current contextual frames.\n        \"\"\"\n        super().seek(self._total_offset + pos, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push_frame(self, offset):\n        self._frames.append((offset, self.tell()))\n        self._total_offset += offset\n\n        self.seek_in_frame(0)", "response": "Pushes a new contextual frame onto the stack with the given offset and returns the current cursor position and the total offset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop the current contextual frame off of the stack and returns the frame s cursor.", "response": "def pop_frame(self):\n        \"\"\"\n        Pops the current contextual frame off of the stack and returns the\n        cursor to the frame's return position.\n        \"\"\"\n        try:\n            offset, return_pos = self._frames.pop()\n        except IndexError:\n            raise IndexError('no frames to pop')\n        self._total_offset -= offset\n\n        self.seek(return_pos)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_arrlist(type_str):\n    try:\n        abi_type = grammar.parse(type_str)\n    except exceptions.ParseError:\n        return False\n\n    return abi_type.arrlist is not None", "response": "A predicate that matches a type string with an array dimension list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_encoder(self, lookup: Lookup, encoder: Encoder, label: str=None) -> None:\n        self._register_coder(self._encoders, lookup, encoder, label=label)", "response": "Registers the given encoder under the given lookup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_decoder(self, lookup: Lookup, decoder: Decoder, label: str=None) -> None:\n        self._register_coder(self._decoders, lookup, decoder, label=label)", "response": "Registers the given decoder under the given lookup."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister the given encoder and decoder under the given unique string label.", "response": "def register(self, lookup: Lookup, encoder: Encoder, decoder: Decoder, label: str=None) -> None:\n        \"\"\"\n        Registers the given ``encoder`` and ``decoder`` under the given\n        ``lookup``.  A unique string label may be optionally provided that can\n        be used to refer to the registration by name.\n\n        :param lookup: A type string or type string matcher function\n            (predicate).  When the registry is queried with a type string\n            ``query`` to determine which encoder or decoder to use, ``query``\n            will be checked against every registration in the registry.  If a\n            registration was created with a type string for ``lookup``, it will\n            be considered a match if ``lookup == query``.  If a registration\n            was created with a matcher function for ``lookup``, it will be\n            considered a match if ``lookup(query) is True``.  If more than one\n            registration is found to be a match, then an exception is raised.\n\n        :param encoder: An encoder callable or class to use if ``lookup``\n            matches a query.  If ``encoder`` is a callable, it must accept a\n            python value and return a ``bytes`` value.  If ``encoder`` is a\n            class, it must be a valid subclass of :any:`encoding.BaseEncoder`\n            and must also implement the :any:`from_type_str` method on\n            :any:`base.BaseCoder`.\n\n        :param decoder: A decoder callable or class to use if ``lookup``\n            matches a query.  If ``decoder`` is a callable, it must accept a\n            stream-like object of bytes and return a python value.  If\n            ``decoder`` is a class, it must be a valid subclass of\n            :any:`decoding.BaseDecoder` and must also implement the\n            :any:`from_type_str` method on :any:`base.BaseCoder`.\n\n        :param label: An optional label that can be used to refer to this\n            registration by name.  This label can be used to unregister an\n            entry in the registry via the :any:`unregister` method and its\n            variants.\n        \"\"\"\n        self.register_encoder(lookup, encoder, label=label)\n        self.register_decoder(lookup, decoder, label=label)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_encoder(self, type_str: abi.TypeStr) -> bool:\n        try:\n            self.get_encoder(type_str)\n        except NoEntriesFound:\n            return False\n        else:\n            return True", "response": "Returns True if an encoder is found for the given type string\n        otherwise returns False."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the current registry.", "response": "def copy(self):\n        \"\"\"\n        Copies a registry such that new registrations can be made or existing\n        registrations can be unregistered without affecting any instance from\n        which a copy was obtained.  This is useful if an existing registry\n        fulfills most of a user's needs but requires one or two modifications.\n        In that case, a copy of that registry can be obtained and the necessary\n        changes made without affecting the original registry.\n        \"\"\"\n        cpy = type(self)()\n\n        cpy._encoders = copy.copy(self._encoders)\n        cpy._decoders = copy.copy(self._decoders)\n\n        return cpy"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencoding the python value arg as a binary value of the type typ.", "response": "def encode_single(self, typ: TypeStr, arg: Any) -> bytes:\n        \"\"\"\n        Encodes the python value ``arg`` as a binary value of the ABI type\n        ``typ``.\n\n        :param typ: The string representation of the ABI type that will be used\n            for encoding e.g. ``'uint256'``, ``'bytes[]'``, ``'(int,int)'``,\n            etc.\n        :param arg: The python value to be encoded.\n\n        :returns: The binary representation of the python value ``arg`` as a\n            value of the ABI type ``typ``.\n        \"\"\"\n        encoder = self._registry.get_encoder(typ)\n\n        return encoder(arg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode_abi(self, types: Iterable[TypeStr], args: Iterable[Any]) -> bytes:\n        encoders = [\n            self._registry.get_encoder(type_str)\n            for type_str in types\n        ]\n\n        encoder = TupleEncoder(encoders=encoders)\n\n        return encoder(args)", "response": "Encodes the python values in args as a sequence of binary values of the ABI types in types."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_encodable(self, typ: TypeStr, arg: Any) -> bool:\n        encoder = self._registry.get_encoder(typ)\n\n        try:\n            encoder.validate_value(arg)\n        except EncodingError:\n            return False\n        except AttributeError:\n            try:\n                encoder(arg)\n            except EncodingError:\n                return False\n\n        return True", "response": "Determines if the python value arg is encodable as a value of the type typ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding the binary value data of the ABI type typ into its equivalent python value.", "response": "def decode_single(self, typ: TypeStr, data: Decodable) -> Any:\n        \"\"\"\n        Decodes the binary value ``data`` of the ABI type ``typ`` into its\n        equivalent python value.\n\n        :param typ: The string representation of the ABI type that will be used for\n            decoding e.g. ``'uint256'``, ``'bytes[]'``, ``'(int,int)'``, etc.\n        :param data: The binary value to be decoded.\n\n        :returns: The equivalent python value of the ABI value represented in\n            ``data``.\n        \"\"\"\n        if not is_bytes(data):\n            raise TypeError(\"The `data` value must be of bytes type.  Got {0}\".format(type(data)))\n\n        decoder = self._registry.get_decoder(typ)\n        stream = ContextFramesBytesIO(data)\n\n        return decoder(stream)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecoding the binary value data as a sequence of equivalent python values for the ABI types that are in types.", "response": "def decode_abi(self, types: Iterable[TypeStr], data: Decodable) -> Tuple[Any, ...]:\n        \"\"\"\n        Decodes the binary value ``data`` as a sequence of values of the ABI types\n        in ``types`` via the head-tail mechanism into a tuple of equivalent python\n        values.\n\n        :param types: An iterable of string representations of the ABI types that\n            will be used for decoding e.g. ``('uint256', 'bytes[]', '(int,int)')``\n        :param data: The binary value to be decoded.\n\n        :returns: A tuple of equivalent python values for the ABI values\n            represented in ``data``.\n        \"\"\"\n        if not is_bytes(data):\n            raise TypeError(\"The `data` value must be of bytes type.  Got {0}\".format(type(data)))\n\n        decoders = [\n            self._registry.get_decoder(type_str)\n            for type_str in types\n        ]\n\n        decoder = TupleDecoder(decoders=decoders)\n        stream = ContextFramesBytesIO(data)\n\n        return decoder(stream)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a type string into an appropriate instance of .", "response": "def parse(self, type_str):\n        \"\"\"\n        Parses a type string into an appropriate instance of\n        :class:`~eth_abi.grammar.ABIType`.  If a type string cannot be parsed,\n        throws :class:`~eth_abi.exceptions.ParseError`.\n\n        :param type_str: The type string to be parsed.\n        :returns: An instance of :class:`~eth_abi.grammar.ABIType` containing\n            information about the parsed type string.\n        \"\"\"\n        if not isinstance(type_str, str):\n            raise TypeError('Can only parse string values: got {}'.format(type(type_str)))\n\n        try:\n            return super().parse(type_str)\n        except parsimonious.ParseError as e:\n            raise ParseError(e.text, e.pos, e.expr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def create_turn_endpoint(protocol_factory, server_addr, username, password,\n                               lifetime=600, ssl=False, transport='udp'):\n    \"\"\"\n    Create datagram connection relayed over TURN.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    if transport == 'tcp':\n        _, inner_protocol = await loop.create_connection(\n            lambda: TurnClientTcpProtocol(server_addr,\n                                          username=username,\n                                          password=password,\n                                          lifetime=lifetime),\n            host=server_addr[0],\n            port=server_addr[1],\n            ssl=ssl)\n    else:\n        _, inner_protocol = await loop.create_datagram_endpoint(\n            lambda: TurnClientUdpProtocol(server_addr,\n                                          username=username,\n                                          password=password,\n                                          lifetime=lifetime),\n            remote_addr=server_addr)\n\n    protocol = protocol_factory()\n    transport = TurnTransport(protocol, inner_protocol)\n    await transport._connect()\n\n    return transport, protocol", "response": "Create a datagram connection relayed over TURN."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def connect(self):\n        request = stun.Message(message_method=stun.Method.ALLOCATE,\n                               message_class=stun.Class.REQUEST)\n        request.attributes['LIFETIME'] = self.lifetime\n        request.attributes['REQUESTED-TRANSPORT'] = UDP_TRANSPORT\n\n        try:\n            response, _ = await self.request(request)\n        except exceptions.TransactionFailed as e:\n            response = e.response\n            if response.attributes['ERROR-CODE'][0] == 401:\n                # update long-term credentials\n                self.nonce = response.attributes['NONCE']\n                self.realm = response.attributes['REALM']\n                self.integrity_key = make_integrity_key(self.username, self.realm, self.password)\n\n                # retry request with authentication\n                request.transaction_id = random_transaction_id()\n                response, _ = await self.request(request)\n\n        self.relayed_address = response.attributes['XOR-RELAYED-ADDRESS']\n        logger.info('TURN allocation created %s', self.relayed_address)\n\n        # periodically refresh allocation\n        self.refresh_handle = asyncio.ensure_future(self.refresh())\n\n        return self.relayed_address", "response": "Create a TURN allocation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def delete(self):\n        if self.refresh_handle:\n            self.refresh_handle.cancel()\n            self.refresh_handle = None\n\n        request = stun.Message(message_method=stun.Method.REFRESH,\n                               message_class=stun.Class.REQUEST)\n        request.attributes['LIFETIME'] = 0\n        await self.request(request)\n\n        logger.info('TURN allocation deleted %s', self.relayed_address)\n        if self.receiver:\n            self.receiver.connection_lost(None)", "response": "Delete the TURN allocation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def refresh(self):\n        while True:\n            await asyncio.sleep(5/6 * self.lifetime)\n\n            request = stun.Message(message_method=stun.Method.REFRESH,\n                                   message_class=stun.Class.REQUEST)\n            request.attributes['LIFETIME'] = self.lifetime\n            await self.request(request)\n\n            logger.info('TURN allocation refreshed %s', self.relayed_address)", "response": "Refresh the TURN allocation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a STUN transaction and return the response.", "response": "async def request(self, request):\n        \"\"\"\n        Execute a STUN transaction and return the response.\n        \"\"\"\n        assert request.transaction_id not in self.transactions\n\n        if self.integrity_key:\n            self.__add_authentication(request)\n\n        transaction = stun.Transaction(request, self.server, self)\n        self.transactions[request.transaction_id] = transaction\n        try:\n            return await transaction.run()\n        finally:\n            del self.transactions[request.transaction_id]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def send_data(self, data, addr):\n        channel = self.peer_to_channel.get(addr)\n        if channel is None:\n            channel = self.channel_number\n            self.channel_number += 1\n            self.channel_to_peer[channel] = addr\n            self.peer_to_channel[addr] = channel\n\n            # bind channel\n            await self.channel_bind(channel, addr)\n\n        header = struct.pack('!HH', channel, len(data))\n        self._send(header + data)", "response": "Send data to a remote host via the TURN server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_stun(self, message, addr):\n        logger.debug('%s > %s %s', self, addr, message)\n        self._send(bytes(message))", "response": "Send a STUN message to the TURN server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_extra_info(self, name, default=None):\n        if name == 'related_address':\n            return self.__inner_protocol.transport.get_extra_info('sockname')\n        elif name == 'sockname':\n            return self.__relayed_address\n        return default", "response": "Return optional transport information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sendto(self, data, addr):\n        asyncio.ensure_future(self.__inner_protocol.send_data(data, addr))", "response": "Send the data bytes to the remote peer given addr."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef candidate_foundation(candidate_type, candidate_transport, base_address):\n    key = '%s|%s|%s' % (candidate_type, candidate_transport, base_address)\n    return hashlib.md5(key.encode('ascii')).hexdigest()", "response": "Compute a candidate foundation key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef candidate_priority(candidate_component, candidate_type, local_pref=65535):\n    if candidate_type == 'host':\n        type_pref = 126\n    elif candidate_type == 'prflx':\n        type_pref = 110\n    elif candidate_type == 'srflx':\n        type_pref = 100\n    else:\n        type_pref = 0\n\n    return (1 << 24) * type_pref + \\\n           (1 << 8) * local_pref + \\\n           (256 - candidate_component)", "response": "Return the priority of a candidate component based on the candidate type and local_pref."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_sdp(cls, sdp):\n        bits = sdp.split()\n        if len(bits) < 8:\n            raise ValueError('SDP does not have enough properties')\n\n        kwargs = {\n            'foundation': bits[0],\n            'component': int(bits[1]),\n            'transport': bits[2],\n            'priority': int(bits[3]),\n            'host': bits[4],\n            'port': int(bits[5]),\n            'type': bits[7],\n        }\n\n        for i in range(8, len(bits) - 1, 2):\n            if bits[i] == 'raddr':\n                kwargs['related_address'] = bits[i + 1]\n            elif bits[i] == 'rport':\n                kwargs['related_port'] = int(bits[i + 1])\n            elif bits[i] == 'tcptype':\n                kwargs['tcptype'] = bits[i + 1]\n            elif bits[i] == 'generation':\n                kwargs['generation'] = int(bits[i + 1])\n\n        return Candidate(**kwargs)", "response": "Parse a Candidate from a SDP string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string representation suitable for SDP.", "response": "def to_sdp(self):\n        \"\"\"\n        Return a string representation suitable for SDP.\n        \"\"\"\n        sdp = '%s %d %s %d %s %d typ %s' % (\n            self.foundation,\n            self.component,\n            self.transport,\n            self.priority,\n            self.host,\n            self.port,\n            self.type)\n        if self.related_address is not None:\n            sdp += ' raddr %s' % self.related_address\n        if self.related_port is not None:\n            sdp += ' rport %s' % self.related_port\n        if self.tcptype is not None:\n            sdp += ' tcptype %s' % self.tcptype\n        if self.generation is not None:\n            sdp += ' generation %d' % self.generation\n        return sdp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef can_pair_with(self, other):\n        a = ipaddress.ip_address(self.host)\n        b = ipaddress.ip_address(other.host)\n        return (\n            self.component == other.component and\n            self.transport.lower() == other.transport.lower() and\n            a.version == b.version\n        )", "response": "Returns True if this instance can be paired with another instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef candidate_pair_priority(local, remote, ice_controlling):\n    G = ice_controlling and local.priority or remote.priority\n    D = ice_controlling and remote.priority or local.priority\n    return (1 << 32) * min(G, D) + 2 * max(G, D) + (G > D and 1 or 0)", "response": "Return the candidate pair priority."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_host_addresses(use_ipv4, use_ipv6):\n    addresses = []\n    for interface in netifaces.interfaces():\n        ifaddresses = netifaces.ifaddresses(interface)\n        for address in ifaddresses.get(socket.AF_INET, []):\n            if use_ipv4 and address['addr'] != '127.0.0.1':\n                addresses.append(address['addr'])\n        for address in ifaddresses.get(socket.AF_INET6, []):\n            if use_ipv6 and address['addr'] != '::1' and '%' not in address['addr']:\n                addresses.append(address['addr'])\n    return addresses", "response": "Get local IP addresses."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def server_reflexive_candidate(protocol, stun_server):\n    # lookup address\n    loop = asyncio.get_event_loop()\n    stun_server = (\n        await loop.run_in_executor(None, socket.gethostbyname, stun_server[0]),\n        stun_server[1])\n\n    # perform STUN query\n    request = stun.Message(message_method=stun.Method.BINDING,\n                           message_class=stun.Class.REQUEST)\n    response, _ = await protocol.request(request, stun_server)\n\n    local_candidate = protocol.local_candidate\n    return Candidate(\n        foundation=candidate_foundation('srflx', 'udp', local_candidate.host),\n        component=local_candidate.component,\n        transport=local_candidate.transport,\n        priority=candidate_priority(local_candidate.component, 'srflx'),\n        host=response.attributes['XOR-MAPPED-ADDRESS'][0],\n        port=response.attributes['XOR-MAPPED-ADDRESS'][1],\n        type='srflx',\n        related_address=local_candidate.host,\n        related_port=local_candidate.port)", "response": "Query STUN server to obtain a server - reflexive candidate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_candidate_pairs(pairs, ice_controlling):\n    def pair_priority(pair):\n        return -candidate_pair_priority(pair.local_candidate,\n                                        pair.remote_candidate,\n                                        ice_controlling)\n\n    pairs.sort(key=pair_priority)", "response": "Sort a list of candidate pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def request(self, request, addr, integrity_key=None, retransmissions=None):\n        assert request.transaction_id not in self.transactions\n\n        if integrity_key is not None:\n            request.add_message_integrity(integrity_key)\n            request.add_fingerprint()\n\n        transaction = stun.Transaction(request, addr, self, retransmissions=retransmissions)\n        transaction.integrity_key = integrity_key\n        self.transactions[request.transaction_id] = transaction\n        try:\n            return await transaction.run()\n        finally:\n            del self.transactions[request.transaction_id]", "response": "Execute a STUN transaction and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_stun(self, message, addr):\n        self.__log_debug('> %s %s', addr, message)\n        self.transport.sendto(bytes(message), addr)", "response": "Send a STUN message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a remote candidate or signal end - of - candidates.", "response": "def add_remote_candidate(self, remote_candidate):\n        \"\"\"\n        Add a remote candidate or signal end-of-candidates.\n\n        To signal end-of-candidates, pass `None`.\n        \"\"\"\n        if self._remote_candidates_end:\n            raise ValueError('Cannot add remote candidate after end-of-candidates.')\n\n        if remote_candidate is None:\n            self._prune_components()\n            self._remote_candidates_end = True\n            return\n\n        self._remote_candidates.append(remote_candidate)\n        for protocol in self._protocols:\n            if (protocol.local_candidate.can_pair_with(remote_candidate) and\n               not self._find_pair(protocol, remote_candidate)):\n                pair = CandidatePair(protocol, remote_candidate)\n                self._check_list.append(pair)\n        self.sort_check_list()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngather local candidates. You **must** call this coroutine before calling :meth:`connect`.", "response": "async def gather_candidates(self):\n        \"\"\"\n        Gather local candidates.\n\n        You **must** call this coroutine before calling :meth:`connect`.\n        \"\"\"\n        if not self._local_candidates_start:\n            self._local_candidates_start = True\n            addresses = get_host_addresses(use_ipv4=self._use_ipv4, use_ipv6=self._use_ipv6)\n            for component in self._components:\n                self._local_candidates += await self.get_component_candidates(\n                    component=component,\n                    addresses=addresses)\n            self._local_candidates_end = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the default local candidate for the specified component.", "response": "def get_default_candidate(self, component):\n        \"\"\"\n        Gets the default local candidate for the specified component.\n        \"\"\"\n        for candidate in sorted(self._local_candidates, key=lambda x: x.priority):\n            if candidate.component == component:\n                return candidate"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def connect(self):\n        if not self._local_candidates_end:\n            raise ConnectionError('Local candidates gathering was not performed')\n\n        if (self.remote_username is None or\n           self.remote_password is None):\n            raise ConnectionError('Remote username or password is missing')\n\n        # 5.7.1. Forming Candidate Pairs\n        for remote_candidate in self._remote_candidates:\n            for protocol in self._protocols:\n                if (protocol.local_candidate.can_pair_with(remote_candidate) and\n                   not self._find_pair(protocol, remote_candidate)):\n                    pair = CandidatePair(protocol, remote_candidate)\n                    self._check_list.append(pair)\n        self.sort_check_list()\n\n        self._unfreeze_initial()\n\n        # handle early checks\n        for check in self._early_checks:\n            self.check_incoming(*check)\n        self._early_checks = []\n\n        # perform checks\n        while True:\n            if not self.check_periodic():\n                break\n            await asyncio.sleep(0.02)\n\n        # wait for completion\n        if self._check_list:\n            res = await self._check_list_state.get()\n        else:\n            res = ICE_FAILED\n\n        # cancel remaining checks\n        for check in self._check_list:\n            if check.handle:\n                check.handle.cancel()\n\n        if res != ICE_COMPLETED:\n            raise ConnectionError('ICE negotiation failed')\n\n        # start consent freshness tests\n        self._query_consent_handle = asyncio.ensure_future(self.query_consent())", "response": "Perform ICE handshake and return the local and remote candidate set names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def recvfrom(self):\n        if not len(self._nominated):\n            raise ConnectionError('Cannot receive data, not connected')\n\n        result = await self._queue.get()\n        if result[0] is None:\n            raise ConnectionError('Connection lost while receiving data')\n        return result", "response": "Receive the next datagram from the queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def sendto(self, data, component):\n        active_pair = self._nominated.get(component)\n        if active_pair:\n            await active_pair.protocol.send_data(data, active_pair.remote_addr)\n        else:\n            raise ConnectionError('Cannot send data, not connected')", "response": "Send a datagram to the specified component."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_selected_pair(self, component, local_foundation, remote_foundation):\n        # find local candidate\n        protocol = None\n        for p in self._protocols:\n            if (p.local_candidate.component == component and\n               p.local_candidate.foundation == local_foundation):\n                protocol = p\n                break\n\n        # find remote candidate\n        remote_candidate = None\n        for c in self._remote_candidates:\n            if c.component == component and c.foundation == remote_foundation:\n                remote_candidate = c\n\n        assert (protocol and remote_candidate)\n        self._nominated[component] = CandidatePair(protocol, remote_candidate)", "response": "Set the selected candidate pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a succesful incoming check.", "response": "def check_incoming(self, message, addr, protocol):\n        \"\"\"\n        Handle a succesful incoming check.\n        \"\"\"\n        component = protocol.local_candidate.component\n\n        # find remote candidate\n        remote_candidate = None\n        for c in self._remote_candidates:\n            if c.host == addr[0] and c.port == addr[1]:\n                remote_candidate = c\n                assert remote_candidate.component == component\n                break\n        if remote_candidate is None:\n            # 7.2.1.3. Learning Peer Reflexive Candidates\n            remote_candidate = Candidate(\n                foundation=random_string(10),\n                component=component,\n                transport='udp',\n                priority=message.attributes['PRIORITY'],\n                host=addr[0],\n                port=addr[1],\n                type='prflx')\n            self._remote_candidates.append(remote_candidate)\n            self.__log_info('Discovered peer reflexive candidate %s', remote_candidate)\n\n        # find pair\n        pair = self._find_pair(protocol, remote_candidate)\n        if pair is None:\n            pair = CandidatePair(protocol, remote_candidate)\n            pair.state = CandidatePair.State.WAITING\n            self._check_list.append(pair)\n            self.sort_check_list()\n\n        # triggered check\n        if pair.state in [CandidatePair.State.WAITING, CandidatePair.State.FAILED]:\n            pair.handle = asyncio.ensure_future(self.check_start(pair))\n\n        # 7.2.1.5. Updating the Nominated Flag\n        if 'USE-CANDIDATE' in message.attributes and not self.ice_controlling:\n            pair.remote_nominated = True\n\n            if pair.state == CandidatePair.State.SUCCEEDED:\n                pair.nominated = True\n                self.check_complete(pair)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_state(self, pair, state):\n        self.__log_info('Check %s %s -> %s', pair, pair.state, state)\n        pair.state = state", "response": "Updates the state of a check."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_pair(self, protocol, remote_candidate):\n        for pair in self._check_list:\n            if (pair.protocol == protocol and pair.remote_candidate == remote_candidate):\n                return pair\n        return None", "response": "Find a candidate pair in the check list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove components for which the remote party did not provide any candidates.", "response": "def _prune_components(self):\n        \"\"\"\n        Remove components for which the remote party did not provide any candidates.\n\n        This can only be determined after end-of-candidates.\n        \"\"\"\n        seen_components = set(map(lambda x: x.component, self._remote_candidates))\n        missing_components = self._components - seen_components\n        if missing_components:\n            self.__log_info('Components %s have no candidate pairs' % missing_components)\n            self._components = seen_components"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def query_consent(self):\n        failures = 0\n        while True:\n            # randomize between 0.8 and 1.2 times CONSENT_INTERVAL\n            await asyncio.sleep(CONSENT_INTERVAL * (0.8 + 0.4 * random.random()))\n\n            for pair in self._nominated.values():\n                request = self.build_request(pair)\n                try:\n                    await pair.protocol.request(\n                        request, pair.remote_addr,\n                        integrity_key=self.remote_password.encode('utf8'),\n                        retransmissions=0)\n                    failures = 0\n                except exceptions.TransactionError:\n                    failures += 1\n                if failures >= CONSENT_FAILURES:\n                    self.__log_info('Consent to send expired')\n                    self._query_consent_handle = None\n                    return await self.close()", "response": "Query consent for a specific user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a STUN message and returns a Message object.", "response": "def parse_message(data, integrity_key=None):\n    \"\"\"\n    Parses a STUN message.\n\n    If the ``integrity_key`` parameter is given, the message's HMAC will be verified.\n    \"\"\"\n    if len(data) < HEADER_LENGTH:\n        raise ValueError('STUN message length is less than 20 bytes')\n    message_type, length, cookie, transaction_id = unpack('!HHI12s', data[0:HEADER_LENGTH])\n    if len(data) != HEADER_LENGTH + length:\n        raise ValueError('STUN message length does not match')\n\n    attributes = OrderedDict()\n    pos = HEADER_LENGTH\n    while pos <= len(data) - 4:\n        attr_type, attr_len = unpack('!HH', data[pos:pos + 4])\n        v = data[pos + 4:pos + 4 + attr_len]\n        pad_len = 4 * ((attr_len + 3) // 4) - attr_len\n        if attr_type in ATTRIBUTES_BY_TYPE:\n            _, attr_name, attr_pack, attr_unpack = ATTRIBUTES_BY_TYPE[attr_type]\n            if attr_unpack == unpack_xor_address:\n                attributes[attr_name] = attr_unpack(v, transaction_id=transaction_id)\n            else:\n                attributes[attr_name] = attr_unpack(v)\n\n            if attr_name == 'FINGERPRINT':\n                if attributes[attr_name] != message_fingerprint(data[0:pos]):\n                    raise ValueError('STUN message fingerprint does not match')\n            elif attr_name == 'MESSAGE-INTEGRITY':\n                if (integrity_key is not None and\n                   attributes[attr_name] != message_integrity(data[0:pos], integrity_key)):\n                    raise ValueError('STUN message integrity does not match')\n\n        pos += 4 + attr_len + pad_len\n    return Message(\n        message_method=message_type & 0x3eef,\n        message_class=message_type & 0x0110,\n        transaction_id=transaction_id,\n        attributes=attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling by the asyncio library when a connection is made.", "response": "def connection_made(self, transport: asyncio.BaseTransport) -> None:\n        \"\"\"\n        Modified ``connection_made`` that supports upgrading our transport in\n        place using STARTTLS.\n\n        We set the _transport directly on the StreamReader, rather than calling\n        set_transport (which will raise an AssertionError on upgrade).\n        \"\"\"\n        if self._stream_reader is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        self._stream_reader._transport = transport  # type: ignore\n        self._over_ssl = transport.get_extra_info(\"sslcontext\") is not None\n        self._stream_writer = asyncio.StreamWriter(\n            transport, self, self._stream_reader, self._loop\n        )\n        self._client_connected_cb(  # type: ignore\n            self._stream_reader, self._stream_writer\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupgrades our transport to TLS in place.", "response": "def upgrade_transport(\n        self,\n        context: ssl.SSLContext,\n        server_hostname: str = None,\n        waiter: Awaitable = None,\n    ) -> SSLProtocol:\n        \"\"\"\n        Upgrade our transport to TLS in place.\n        \"\"\"\n        if self._over_ssl:\n            raise RuntimeError(\"Already using TLS.\")\n\n        if self._stream_reader is None or self._stream_writer is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        transport = self._stream_reader._transport  # type: ignore\n\n        tls_protocol = SSLProtocol(\n            self._loop,\n            self,\n            context,\n            waiter,\n            server_side=False,\n            server_hostname=server_hostname,\n        )\n\n        app_transport = tls_protocol._app_transport\n        # Use set_protocol if we can\n        if hasattr(transport, \"set_protocol\"):\n            transport.set_protocol(tls_protocol)\n        else:\n            transport._protocol = tls_protocol\n\n        self._stream_reader._transport = app_transport  # type: ignore\n        self._stream_writer._transport = app_transport  # type: ignore\n\n        tls_protocol.connection_made(transport)\n        self._over_ssl = True  # type: bool\n\n        return tls_protocol"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a status response from the server.", "response": "async def read_response(self, timeout: NumType = None) -> SMTPResponse:\n        \"\"\"\n        Get a status reponse from the server.\n\n        Returns an SMTPResponse namedtuple consisting of:\n          - server response code (e.g. 250, or such, if all goes well)\n          - server response string corresponding to response code (multiline\n            responses are converted to a single, multiline string).\n        \"\"\"\n        if self._stream_reader is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        code = None\n        response_lines = []\n\n        while True:\n            async with self._io_lock:\n                line = await self._readline(timeout=timeout)\n            try:\n                code = int(line[:3])\n            except ValueError:\n                pass\n\n            message = line[4:].strip(b\" \\t\\r\\n\").decode(\"utf-8\", \"surrogateescape\")\n            response_lines.append(message)\n\n            if line[3:4] != b\"-\":\n                break\n\n        full_message = \"\\n\".join(response_lines)\n\n        if code is None:\n            raise SMTPResponseException(\n                SMTPStatus.invalid_response.value,\n                \"Malformed SMTP response: {}\".format(full_message),\n            )\n\n        return SMTPResponse(code, full_message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def write_and_drain(self, data: bytes, timeout: NumType = None) -> None:\n        if self._stream_writer is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        self._stream_writer.write(data)\n\n        async with self._io_lock:\n            await self._drain_writer(timeout)", "response": "Write data to the server and drain the writer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencodes and write email message data.", "response": "async def write_message_data(self, data: bytes, timeout: NumType = None) -> None:\n        \"\"\"\n        Encode and write email message data.\n\n        Automatically quotes lines beginning with a period per RFC821.\n        Lone \\\\\\\\r and \\\\\\\\n characters are converted to \\\\\\\\r\\\\\\\\n\n        characters.\n        \"\"\"\n        data = LINE_ENDINGS_REGEX.sub(b\"\\r\\n\", data)\n        data = PERIOD_REGEX.sub(b\"..\", data)\n        if not data.endswith(b\"\\r\\n\"):\n            data += b\"\\r\\n\"\n        data += b\".\\r\\n\"\n\n        await self.write_and_drain(data, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend an SMTP command along with any args to the server and returns the response.", "response": "async def execute_command(\n        self, *args: bytes, timeout: NumType = None\n    ) -> SMTPResponse:\n        \"\"\"\n        Sends an SMTP command along with any args to the server, and returns\n        a response.\n        \"\"\"\n        command = b\" \".join(args) + b\"\\r\\n\"\n\n        await self.write_and_drain(command, timeout=timeout)\n        response = await self.read_response(timeout=timeout)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the connection to the server into TLS mode.", "response": "async def starttls(\n        self,\n        tls_context: ssl.SSLContext,\n        server_hostname: str = None,\n        timeout: NumType = None,\n    ) -> StartTLSResponse:\n        \"\"\"\n        Puts the connection to the SMTP server into TLS mode.\n        \"\"\"\n        if self._stream_reader is None or self._stream_writer is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        response = await self.execute_command(b\"STARTTLS\", timeout=timeout)\n\n        if response.code != SMTPStatus.ready:\n            raise SMTPResponseException(response.code, response.message)\n\n        await self._drain_writer(timeout)\n\n        waiter = asyncio.Future(loop=self._loop)  # type: asyncio.Future\n\n        tls_protocol = self.upgrade_transport(\n            tls_context, server_hostname=server_hostname, waiter=waiter\n        )\n\n        try:\n            await asyncio.wait_for(waiter, timeout=timeout, loop=self._loop)\n        except asyncio.TimeoutError as exc:\n            raise SMTPTimeoutError(str(exc))\n\n        return response, tls_protocol"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps writer.drain() with error handling.", "response": "async def _drain_writer(self, timeout: NumType = None) -> None:\n        \"\"\"\n        Wraps writer.drain() with error handling.\n        \"\"\"\n        if self._stream_writer is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        # Wrapping drain in a task makes mypy happy\n        drain_task = asyncio.Task(self._stream_writer.drain(), loop=self._loop)\n        try:\n            await asyncio.wait_for(drain_task, timeout, loop=self._loop)\n        except ConnectionError as exc:\n            raise SMTPServerDisconnected(str(exc))\n        except asyncio.TimeoutError as exc:\n            raise SMTPTimeoutError(str(exc))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a single line from the stream.", "response": "async def _readline(self, timeout: NumType = None):\n        \"\"\"\n        Wraps reader.readuntil() with error handling.\n        \"\"\"\n        if self._stream_reader is None or self._stream_writer is None:\n            raise SMTPServerDisconnected(\"Client not connected\")\n\n        read_task = asyncio.Task(\n            self._stream_reader.readuntil(separator=b\"\\n\"), loop=self._loop\n        )\n        try:\n            line = await asyncio.wait_for(\n                read_task, timeout, loop=self._loop\n            )  # type: bytes\n        except asyncio.LimitOverrunError:\n            raise SMTPResponseException(\n                SMTPStatus.unrecognized_command, \"Line too long.\"\n            )\n        except asyncio.TimeoutError as exc:\n            raise SMTPTimeoutError(str(exc))\n        except asyncio.IncompleteReadError as exc:\n            if exc.partial == b\"\":\n                # if we got only an EOF, raise SMTPServerDisconnected\n                raise SMTPServerDisconnected(\"Unexpected EOF received\")\n            else:\n                # otherwise, close our connection but try to parse the\n                # response anyways\n                self._stream_writer.close()\n                line = exc.partial\n\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses an EHLO response into a dict of extensions and auth types.", "response": "def parse_esmtp_extensions(message: str) -> Tuple[Dict[str, str], List[str]]:\n    \"\"\"\n    Parse an EHLO response from the server into a dict of {extension: params}\n    and a list of auth method names.\n\n    It might look something like:\n\n         220 size.does.matter.af.MIL (More ESMTP than Crappysoft!)\n         EHLO heaven.af.mil\n         250-size.does.matter.af.MIL offers FIFTEEN extensions:\n         250-8BITMIME\n         250-PIPELINING\n         250-DSN\n         250-ENHANCEDSTATUSCODES\n         250-EXPN\n         250-HELP\n         250-SAML\n         250-SEND\n         250-SOML\n         250-TURN\n         250-XADR\n         250-XSTA\n         250-ETRN\n         250-XGEN\n         250 SIZE 51200000\n    \"\"\"\n    esmtp_extensions = {}\n    auth_types = []  # type: List[str]\n\n    response_lines = message.split(\"\\n\")\n\n    # ignore the first line\n    for line in response_lines[1:]:\n        # To be able to communicate with as many SMTP servers as possible,\n        # we have to take the old-style auth advertisement into account,\n        # because:\n        # 1) Else our SMTP feature parser gets confused.\n        # 2) There are some servers that only advertise the auth methods we\n        #    support using the old style.\n        auth_match = OLDSTYLE_AUTH_REGEX.match(line)\n        if auth_match is not None:\n            auth_type = auth_match.group(\"auth\")\n            auth_types.append(auth_type.lower().strip())\n\n        # RFC 1869 requires a space between ehlo keyword and parameters.\n        # It's actually stricter, in that only spaces are allowed between\n        # parameters, but were not going to check for that here.  Note\n        # that the space isn't present if there are no parameters.\n        extensions = EXTENSIONS_REGEX.match(line)\n        if extensions is not None:\n            extension = extensions.group(\"ext\").lower()\n            params = extensions.string[extensions.end(\"ext\") :].strip()\n            esmtp_extensions[extension] = params\n\n            if extension == \"auth\":\n                auth_types.extend([param.strip().lower() for param in params.split()])\n\n    return esmtp_extensions, auth_types"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the last EHLO response.", "response": "def last_ehlo_response(self, response: SMTPResponse) -> None:\n        \"\"\"\n        When setting the last EHLO response, parse the message for supported\n        extensions and auth methods.\n        \"\"\"\n        extensions, auth_methods = parse_esmtp_extensions(response.message)\n        self._last_ehlo_response = response\n        self.esmtp_extensions = extensions\n        self.server_auth_methods = auth_methods\n        self.supports_esmtp = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def helo(\n        self, hostname: str = None, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Send the SMTP HELO command.\n        Hostname to send for this command defaults to the FQDN of the local\n        host.\n\n        :raises SMTPHeloError: on unexpected server response code\n        \"\"\"\n        if hostname is None:\n            hostname = self.source_address\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"HELO\", hostname.encode(\"ascii\"), timeout=timeout\n            )\n        self.last_helo_response = response\n\n        if response.code != SMTPStatus.completed:\n            raise SMTPHeloError(response.code, response.message)\n\n        return response", "response": "Send the SMTP HELO command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def help(self, timeout: DefaultNumType = _default) -> str:\n        await self._ehlo_or_helo_if_needed()\n\n        async with self._command_lock:\n            response = await self.execute_command(b\"HELP\", timeout=timeout)\n        success_codes = (\n            SMTPStatus.system_status_ok,\n            SMTPStatus.help_message,\n            SMTPStatus.completed,\n        )\n        if response.code not in success_codes:\n            raise SMTPResponseException(response.code, response.message)\n\n        return response.message", "response": "Send the SMTP HELP command which responds with help text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an SMTP RSET command which resets the server s envelope containing the sender recipient and mail data.", "response": "async def rset(self, timeout: DefaultNumType = _default) -> SMTPResponse:\n        \"\"\"\n        Send an SMTP RSET command, which resets the server's envelope\n        (the envelope contains the sender, recipient, and mail data).\n\n        :raises SMTPResponseException: on unexpected server response code\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n\n        async with self._command_lock:\n            response = await self.execute_command(b\"RSET\", timeout=timeout)\n        if response.code != SMTPStatus.completed:\n            raise SMTPResponseException(response.code, response.message)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def noop(self, timeout: DefaultNumType = _default) -> SMTPResponse:\n        await self._ehlo_or_helo_if_needed()\n\n        async with self._command_lock:\n            response = await self.execute_command(b\"NOOP\", timeout=timeout)\n        if response.code != SMTPStatus.completed:\n            raise SMTPResponseException(response.code, response.message)\n\n        return response", "response": "Send an SMTP NOOP command which does nothing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an SMTP VRFY command which tests an address for validity.", "response": "async def vrfy(\n        self, address: str, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Send an SMTP VRFY command, which tests an address for validity.\n        Not many servers support this command.\n\n        :raises SMTPResponseException: on unexpected server response code\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n\n        parsed_address = parse_address(address)\n\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"VRFY\", parsed_address.encode(\"ascii\"), timeout=timeout\n            )\n\n        success_codes = (\n            SMTPStatus.completed,\n            SMTPStatus.will_forward,\n            SMTPStatus.cannot_vrfy,\n        )\n\n        if response.code not in success_codes:\n            raise SMTPResponseException(response.code, response.message)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an SMTP EXPN command which expands a mailing list.", "response": "async def expn(\n        self, address: str, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Send an SMTP EXPN command, which expands a mailing list.\n        Not many servers support this command.\n\n        :raises SMTPResponseException: on unexpected server response code\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n\n        parsed_address = parse_address(address)\n\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"EXPN\", parsed_address.encode(\"ascii\"), timeout=timeout\n            )\n\n        if response.code != SMTPStatus.completed:\n            raise SMTPResponseException(response.code, response.message)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a SMTP QUIT command which closes the connection and closes the connection from our side.", "response": "async def quit(self, timeout: DefaultNumType = _default) -> SMTPResponse:\n        \"\"\"\n        Send the SMTP QUIT command, which closes the connection.\n        Also closes the connection from our side after a response is received.\n\n        :raises SMTPResponseException: on unexpected server response code\n        \"\"\"\n        # Can't quit without HELO/EHLO\n        await self._ehlo_or_helo_if_needed()\n\n        async with self._command_lock:\n            response = await self.execute_command(b\"QUIT\", timeout=timeout)\n        if response.code != SMTPStatus.closing:\n            raise SMTPResponseException(response.code, response.message)\n\n        self.close()\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an SMTP MAIL command.", "response": "async def mail(\n        self,\n        sender: str,\n        options: Iterable[str] = None,\n        timeout: DefaultNumType = _default,\n    ) -> SMTPResponse:\n        \"\"\"\n        Send an SMTP MAIL command, which specifies the message sender and\n        begins a new mail transfer session (\"envelope\").\n\n        :raises SMTPSenderRefused: on unexpected server response code\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n\n        if options is None:\n            options = []\n\n        options_bytes = [option.encode(\"ascii\") for option in options]\n        from_string = b\"FROM:\" + quote_address(sender).encode(\"ascii\")\n\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"MAIL\", from_string, *options_bytes, timeout=timeout\n            )\n\n        if response.code != SMTPStatus.completed:\n            raise SMTPSenderRefused(response.code, response.message, sender)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def rcpt(\n        self,\n        recipient: str,\n        options: Iterable[str] = None,\n        timeout: DefaultNumType = _default,\n    ) -> SMTPResponse:\n        \"\"\"\n        Send an SMTP RCPT command, which specifies a single recipient for\n        the message. This command is sent once per recipient and must be\n        preceded by 'MAIL'.\n\n        :raises SMTPRecipientRefused: on unexpected server response code\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n\n        if options is None:\n            options = []\n\n        options_bytes = [option.encode(\"ascii\") for option in options]\n        to = b\"TO:\" + quote_address(recipient).encode(\"ascii\")\n\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"RCPT\", to, *options_bytes, timeout=timeout\n            )\n\n        success_codes = (SMTPStatus.completed, SMTPStatus.will_forward)\n        if response.code not in success_codes:\n            raise SMTPRecipientRefused(response.code, response.message, recipient)\n\n        return response", "response": "Sends an SMTP RCPT command to set the message s recipient and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def data(\n        self, message: Union[str, bytes], timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Send an SMTP DATA command, followed by the message given.\n        This method transfers the actual email content to the server.\n\n        :raises SMTPDataError: on unexpected server response code\n        :raises SMTPServerDisconnected: connection lost\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n        # As data accesses protocol directly, some handling is required\n        self._raise_error_if_disconnected()\n\n        if timeout is _default:\n            timeout = self.timeout  # type: ignore\n\n        if isinstance(message, str):\n            message = message.encode(\"ascii\")\n\n        async with self._command_lock:\n            start_response = await self.execute_command(b\"DATA\", timeout=timeout)\n\n            if start_response.code != SMTPStatus.start_input:\n                raise SMTPDataError(start_response.code, start_response.message)\n\n            try:\n                await self.protocol.write_message_data(  # type: ignore\n                    message, timeout=timeout\n                )\n                response = await self.protocol.read_response(  # type: ignore\n                    timeout=timeout\n                )\n            except SMTPServerDisconnected as exc:\n                self.close()\n                raise exc\n\n        if response.code != SMTPStatus.completed:\n            raise SMTPDataError(response.code, response.message)\n\n        return response", "response": "Send an SMTP DATA command followed by the message given."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend an SMTP EHLO command.", "response": "async def ehlo(\n        self, hostname: str = None, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Send the SMTP EHLO command.\n        Hostname to send for this command defaults to the FQDN of the local\n        host.\n\n        :raises SMTPHeloError: on unexpected server response code\n        \"\"\"\n        if hostname is None:\n            hostname = self.source_address\n\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"EHLO\", hostname.encode(\"ascii\"), timeout=timeout\n            )\n        self.last_ehlo_response = response\n\n        if response.code != SMTPStatus.completed:\n            raise SMTPHeloError(response.code, response.message)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls self. ehlo and self. helo if needed.", "response": "async def _ehlo_or_helo_if_needed(self) -> None:\n        \"\"\"\n        Call self.ehlo() and/or self.helo() if needed.\n\n        If there has been no previous EHLO or HELO command this session, this\n        method tries ESMTP EHLO first.\n        \"\"\"\n        async with self._ehlo_or_helo_lock:\n            if self.is_ehlo_or_helo_needed:\n                try:\n                    await self.ehlo()\n                except SMTPHeloError as exc:\n                    if self.is_connected:\n                        await self.helo()\n                    else:\n                        raise exc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear the server state.", "response": "def _reset_server_state(self) -> None:\n        \"\"\"\n        Clear stored information about the server.\n        \"\"\"\n        self.last_helo_response = None\n        self._last_ehlo_response = None\n        self.esmtp_extensions = {}\n        self.supports_esmtp = False\n        self.server_auth_methods = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def starttls(\n        self,\n        server_hostname: str = None,\n        validate_certs: bool = None,\n        client_cert: DefaultStrType = _default,\n        client_key: DefaultStrType = _default,\n        cert_bundle: DefaultStrType = _default,\n        tls_context: DefaultSSLContextType = _default,\n        timeout: DefaultNumType = _default,\n    ) -> SMTPResponse:\n        \"\"\"\n        Puts the connection to the SMTP server into TLS mode.\n\n        If there has been no previous EHLO or HELO command this session, this\n        method tries ESMTP EHLO first.\n\n        If the server supports TLS, this will encrypt the rest of the SMTP\n        session. If you provide the keyfile and certfile parameters,\n        the identity of the SMTP server and client can be checked (if\n        validate_certs is True). You can also provide a custom SSLContext\n        object. If no certs or SSLContext is given, and TLS config was\n        provided when initializing the class, STARTTLS will use to that,\n        otherwise it will use the Python defaults.\n\n        :raises SMTPException: server does not support STARTTLS\n        :raises SMTPServerDisconnected: connection lost\n        :raises ValueError: invalid options provided\n        \"\"\"\n        self._raise_error_if_disconnected()\n        await self._ehlo_or_helo_if_needed()\n\n        if validate_certs is not None:\n            self.validate_certs = validate_certs\n        if timeout is _default:\n            timeout = self.timeout  # type: ignore\n        if client_cert is not _default:\n            self.client_cert = client_cert  # type: ignore\n        if client_key is not _default:\n            self.client_key = client_key  # type: ignore\n        if cert_bundle is not _default:\n            self.cert_bundle = cert_bundle  # type: ignore\n        if tls_context is not _default:\n            self.tls_context = tls_context  # type: ignore\n\n        if self.tls_context is not None and self.client_cert is not None:\n            raise ValueError(\n                \"Either a TLS context or a certificate/key must be provided\"\n            )\n\n        if server_hostname is None:\n            server_hostname = self.hostname\n\n        tls_context = self._get_tls_context()\n\n        if not self.supports_extension(\"starttls\"):\n            raise SMTPException(\"SMTP STARTTLS extension not supported by server.\")\n\n        async with self._command_lock:\n            try:\n                response, protocol = await self.protocol.starttls(  # type: ignore\n                    tls_context, server_hostname=server_hostname, timeout=timeout\n                )\n            except SMTPServerDisconnected:\n                self.close()\n                raise\n\n        self.transport = protocol._app_transport\n\n        # RFC 3207 part 4.2:\n        # The client MUST discard any knowledge obtained from the server, such\n        # as the list of SMTP service extensions, which was not obtained from\n        # the TLS negotiation itself.\n        self._reset_server_state()\n\n        return response", "response": "Starts the SMTP server in TLS mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef supported_auth_methods(self) -> List[str]:\n        return [auth for auth in self.AUTH_METHODS if auth in self.server_auth_methods]", "response": "Get all AUTH methods supported by both server and us."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattempts to login with supported auth methods.", "response": "async def login(\n        self, username: str, password: str, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Tries to login with supported auth methods.\n\n        Some servers advertise authentication methods they don't really\n        support, so if authentication fails, we continue until we've tried\n        all methods.\n        \"\"\"\n        await self._ehlo_or_helo_if_needed()\n\n        if not self.supports_extension(\"auth\"):\n            raise SMTPException(\"SMTP AUTH extension not supported by server.\")\n\n        response = None  # type: Optional[SMTPResponse]\n        exception = None  # type: Optional[SMTPAuthenticationError]\n        for auth_name in self.supported_auth_methods:\n            method_name = \"auth_{}\".format(auth_name.replace(\"-\", \"\"))\n            try:\n                auth_method = getattr(self, method_name)\n            except AttributeError:\n                raise RuntimeError(\n                    \"Missing handler for auth method {}\".format(auth_name)\n                )\n            try:\n                response = await auth_method(username, password, timeout=timeout)\n            except SMTPAuthenticationError as exc:\n                exception = exc\n            else:\n                # No exception means we're good\n                break\n\n        if response is None:\n            raise exception or SMTPException(\"No suitable authentication method found.\")\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nauthenticates the user with the server s CRAM - MD5 password.", "response": "async def auth_crammd5(\n        self, username: str, password: str, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        CRAM-MD5 auth uses the password as a shared secret to MD5 the server's\n        response.\n\n        Example::\n\n            250 AUTH CRAM-MD5\n            auth cram-md5\n            334 PDI0NjA5LjEwNDc5MTQwNDZAcG9wbWFpbC5TcGFjZS5OZXQ+\n            dGltIGI5MTNhNjAyYzdlZGE3YTQ5NWI0ZTZlNzMzNGQzODkw\n\n        \"\"\"\n        async with self._command_lock:\n            initial_response = await self.execute_command(\n                b\"AUTH\", b\"CRAM-MD5\", timeout=timeout\n            )\n\n            if initial_response.code != SMTPStatus.auth_continue:\n                raise SMTPAuthenticationError(\n                    initial_response.code, initial_response.message\n                )\n\n            password_bytes = password.encode(\"ascii\")\n            username_bytes = username.encode(\"ascii\")\n            response_bytes = initial_response.message.encode(\"ascii\")\n\n            verification_bytes = crammd5_verify(\n                username_bytes, password_bytes, response_bytes\n            )\n\n            response = await self.execute_command(verification_bytes)\n\n        if response.code != SMTPStatus.auth_successful:\n            raise SMTPAuthenticationError(response.code, response.message)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def auth_plain(\n        self, username: str, password: str, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        PLAIN auth encodes the username and password in one Base64 encoded\n        string. No verification message is required.\n\n        Example::\n\n            220-esmtp.example.com\n            AUTH PLAIN dGVzdAB0ZXN0AHRlc3RwYXNz\n            235 ok, go ahead (#2.0.0)\n\n        \"\"\"\n        username_bytes = username.encode(\"ascii\")\n        password_bytes = password.encode(\"ascii\")\n        username_and_password = b\"\\0\" + username_bytes + b\"\\0\" + password_bytes\n        encoded = base64.b64encode(username_and_password)\n\n        async with self._command_lock:\n            response = await self.execute_command(\n                b\"AUTH\", b\"PLAIN\", encoded, timeout=timeout\n            )\n\n        if response.code != SMTPStatus.auth_successful:\n            raise SMTPAuthenticationError(response.code, response.message)\n\n        return response", "response": "Authenticate the user with plain password."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an AUTH LOGIN command to get the current user s ID and password.", "response": "async def auth_login(\n        self, username: str, password: str, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        LOGIN auth sends the Base64 encoded username and password in sequence.\n\n        Example::\n\n            250 AUTH LOGIN PLAIN CRAM-MD5\n            auth login avlsdkfj\n            334 UGFzc3dvcmQ6\n            avlsdkfj\n\n        Note that there is an alternate version sends the username\n        as a separate command::\n\n            250 AUTH LOGIN PLAIN CRAM-MD5\n            auth login\n            334 VXNlcm5hbWU6\n            avlsdkfj\n            334 UGFzc3dvcmQ6\n            avlsdkfj\n\n        However, since most servers seem to support both, we send the username\n        with the initial request.\n        \"\"\"\n        encoded_username = base64.b64encode(username.encode(\"ascii\"))\n        encoded_password = base64.b64encode(password.encode(\"ascii\"))\n\n        async with self._command_lock:\n            initial_response = await self.execute_command(\n                b\"AUTH\", b\"LOGIN\", encoded_username, timeout=timeout\n            )\n\n            if initial_response.code != SMTPStatus.auth_continue:\n                raise SMTPAuthenticationError(\n                    initial_response.code, initial_response.message\n                )\n\n            response = await self.execute_command(encoded_password, timeout=timeout)\n\n        if response.code != SMTPStatus.auth_successful:\n            raise SMTPAuthenticationError(response.code, response.message)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_address(address: str) -> str:\n    display_name, parsed_address = email.utils.parseaddr(address)\n\n    return parsed_address or address", "response": "Parses an email address falling back to the raw string given."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquoting an email address in the current language.", "response": "def quote_address(address: str) -> str:\n    \"\"\"\n    Quote a subset of the email addresses defined by RFC 821.\n\n    Should be able to handle anything email.utils.parseaddr can handle.\n    \"\"\"\n    display_name, parsed_address = email.utils.parseaddr(address)\n    if parsed_address:\n        quoted_address = \"<{}>\".format(parsed_address)\n    # parseaddr couldn't parse it, use it as is and hope for the best.\n    else:\n        quoted_address = \"<{}>\".format(address.strip())\n\n    return quoted_address"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_sender(\n    message: Message, resent_dates: List[Union[str, Header]] = None\n) -> str:\n    \"\"\"\n    Extract the sender from the message object given.\n    \"\"\"\n    if resent_dates:\n        sender_header = \"Resent-Sender\"\n        from_header = \"Resent-From\"\n    else:\n        sender_header = \"Sender\"\n        from_header = \"From\"\n\n    # Prefer the sender field per RFC 2822:3.6.2.\n    if sender_header in message:\n        sender = message[sender_header]\n    else:\n        sender = message[from_header]\n\n    return str(sender) if sender else \"\"", "response": "Extract the sender from the message object given."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the recipients from the message object given.", "response": "def _extract_recipients(\n    message: Message, resent_dates: List[Union[str, Header]] = None\n) -> List[str]:\n    \"\"\"\n    Extract the recipients from the message object given.\n    \"\"\"\n    recipients = []  # type: List[str]\n\n    if resent_dates:\n        recipient_headers = (\"Resent-To\", \"Resent-Cc\", \"Resent-Bcc\")\n    else:\n        recipient_headers = (\"To\", \"Cc\", \"Bcc\")\n\n    for header in recipient_headers:\n        recipients.extend(message.get_all(header, []))  # type: ignore\n\n    parsed_recipients = [\n        str(email.utils.formataddr(address))\n        for address in email.utils.getaddresses(recipients)\n    ]\n\n    return parsed_recipients"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef source_address(self) -> str:\n        if self._source_address is None:\n            self._source_address = socket.getfqdn()\n\n        return self._source_address", "response": "Returns the system hostname of the SMTP server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the server and returns an SMTPResponse object.", "response": "async def connect(\n        self,\n        hostname: str = None,\n        port: int = None,\n        source_address: DefaultStrType = _default,\n        timeout: DefaultNumType = _default,\n        loop: asyncio.AbstractEventLoop = None,\n        use_tls: bool = None,\n        validate_certs: bool = None,\n        client_cert: DefaultStrType = _default,\n        client_key: DefaultStrType = _default,\n        tls_context: DefaultSSLContextType = _default,\n        cert_bundle: DefaultStrType = _default,\n    ) -> SMTPResponse:\n        \"\"\"\n        Initialize a connection to the server. Options provided to\n        :meth:`.connect` take precedence over those used to initialize the\n        class.\n\n        :keyword hostname:  Server name (or IP) to connect to\n        :keyword port: Server port. Defaults to 25 if ``use_tls`` is\n            False, 465 if ``use_tls`` is True.\n        :keyword source_address: The hostname of the client. Defaults to the\n            result of :func:`socket.getfqdn`. Note that this call blocks.\n        :keyword timeout: Default timeout value for the connection, in seconds.\n            Defaults to 60.\n        :keyword loop: event loop to run on. If not set, uses\n            :func:`asyncio.get_event_loop()`.\n        :keyword use_tls: If True, make the initial connection to the server\n            over TLS/SSL. Note that if the server supports STARTTLS only, this\n            should be False.\n        :keyword validate_certs: Determines if server certificates are\n            validated. Defaults to True.\n        :keyword client_cert: Path to client side certificate, for TLS.\n        :keyword client_key: Path to client side key, for TLS.\n        :keyword tls_context: An existing :class:`ssl.SSLContext`, for TLS.\n            Mutually exclusive with ``client_cert``/``client_key``.\n        :keyword cert_bundle: Path to certificate bundle, for TLS verification.\n\n        :raises ValueError: mutually exclusive options provided\n        \"\"\"\n        await self._connect_lock.acquire()\n\n        if hostname is not None:\n            self.hostname = hostname\n        if loop is not None:\n            self.loop = loop\n        if use_tls is not None:\n            self.use_tls = use_tls\n        if validate_certs is not None:\n            self.validate_certs = validate_certs\n\n        if port is not None:\n            self.port = port\n\n        if self.port is None:\n            self.port = SMTP_TLS_PORT if self.use_tls else SMTP_PORT\n\n        if timeout is not _default:\n            self.timeout = timeout  # type: ignore\n        if source_address is not _default:\n            self._source_address = source_address  # type: ignore\n        if client_cert is not _default:\n            self.client_cert = client_cert  # type: ignore\n        if client_key is not _default:\n            self.client_key = client_key  # type: ignore\n        if tls_context is not _default:\n            self.tls_context = tls_context  # type: ignore\n        if cert_bundle is not _default:\n            self.cert_bundle = cert_bundle  # type: ignore\n\n        if self.tls_context is not None and self.client_cert is not None:\n            raise ValueError(\n                \"Either a TLS context or a certificate/key must be provided\"\n            )\n\n        response = await self._create_connection()\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a command on the server.", "response": "async def execute_command(\n        self, *args: bytes, timeout: DefaultNumType = _default\n    ) -> SMTPResponse:\n        \"\"\"\n        Check that we're connected, if we got a timeout value, and then\n        pass the command to the protocol.\n\n        :raises SMTPServerDisconnected: connection lost\n        \"\"\"\n        if timeout is _default:\n            timeout = self.timeout  # type: ignore\n\n        self._raise_error_if_disconnected()\n\n        try:\n            response = await self.protocol.execute_command(  # type: ignore\n                *args, timeout=timeout\n            )\n        except SMTPServerDisconnected:\n            # On disconnect, clean up the connection.\n            self.close()\n            raise\n\n        # If the server is unavailable, be nice and close the connection\n        if response.code == SMTPStatus.domain_unavailable:\n            self.close()\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds an SSLContext object from the options we ve been given.", "response": "def _get_tls_context(self) -> ssl.SSLContext:\n        \"\"\"\n        Build an SSLContext object from the options we've been given.\n        \"\"\"\n        if self.tls_context is not None:\n            context = self.tls_context\n        else:\n            # SERVER_AUTH is what we want for a client side socket\n            context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n            context.check_hostname = bool(self.validate_certs)\n            if self.validate_certs:\n                context.verify_mode = ssl.CERT_REQUIRED\n            else:\n                context.verify_mode = ssl.CERT_NONE\n\n            if self.cert_bundle is not None:\n                context.load_verify_locations(cafile=self.cert_bundle)\n\n            if self.client_cert is not None:\n                context.load_cert_chain(self.client_cert, keyfile=self.client_key)\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _raise_error_if_disconnected(self) -> None:\n        if (\n            self.transport is None\n            or self.protocol is None\n            or self.transport.is_closing()\n        ):\n            self.close()\n            raise SMTPServerDisconnected(\"Disconnected from SMTP server\")", "response": "Raise an error if we re still connected."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget extra info from the transport.", "response": "def get_transport_info(self, key: str) -> Any:\n        \"\"\"\n        Get extra info from the transport.\n        Supported keys:\n\n            - ``peername``\n            - ``socket``\n            - ``sockname``\n            - ``compression``\n            - ``cipher``\n            - ``peercert``\n            - ``sslcontext``\n            - ``sslobject``\n\n        :raises SMTPServerDisconnected: connection lost\n        \"\"\"\n        self._raise_error_if_disconnected()\n\n        return self.transport.get_extra_info(key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def sendmail(\n        self,\n        sender: str,\n        recipients: RecipientsType,\n        message: Union[str, bytes],\n        mail_options: Iterable[str] = None,\n        rcpt_options: Iterable[str] = None,\n        timeout: DefaultNumType = _default,\n    ) -> SendmailResponseType:\n        \"\"\"\n        This command performs an entire mail transaction.\n\n        The arguments are:\n            - sender: The address sending this mail.\n            - recipients: A list of addresses to send this mail to.  A bare\n                string will be treated as a list with 1 address.\n            - message: The message string to send.\n            - mail_options: List of options (such as ESMTP 8bitmime) for the\n                MAIL command.\n            - rcpt_options: List of options (such as DSN commands) for all the\n                RCPT commands.\n\n        message must be a string containing characters in the ASCII range.\n        The string is encoded to bytes using the ascii codec, and lone \\\\\\\\r\n        and \\\\\\\\n characters are converted to \\\\\\\\r\\\\\\\\n characters.\n\n        If there has been no previous HELO or EHLO command this session, this\n        method tries EHLO first.\n\n        This method will return normally if the mail is accepted for at least\n        one recipient.  It returns a tuple consisting of:\n\n            - an error dictionary, with one entry for each recipient that was\n                refused.  Each entry contains a tuple of the SMTP error code\n                and the accompanying error message sent by the server.\n            - the message sent by the server in response to the DATA command\n                (often containing a message id)\n\n        Example:\n\n             >>> loop = asyncio.get_event_loop()\n             >>> smtp = aiosmtplib.SMTP(hostname=\"127.0.0.1\", port=1025)\n             >>> loop.run_until_complete(smtp.connect())\n             (220, ...)\n             >>> recipients = [\"one@one.org\", \"two@two.org\", \"3@three.org\"]\n             >>> message = \"From: Me@my.org\\\\nSubject: testing\\\\nHello World\"\n             >>> send_coro = smtp.sendmail(\"me@my.org\", recipients, message)\n             >>> loop.run_until_complete(send_coro)\n             ({}, 'OK')\n             >>> loop.run_until_complete(smtp.quit())\n             (221, Bye)\n\n        In the above example, the message was accepted for delivery for all\n        three addresses. If delivery had been only successful to two\n        of the three addresses, and one was rejected, the response would look\n        something like::\n\n            (\n                {\"nobody@three.org\": (550, \"User unknown\")},\n                \"Written safely to disk. #902487694.289148.12219.\",\n            )\n\n\n        If delivery is not successful to any addresses,\n        :exc:`.SMTPRecipientsRefused` is raised.\n\n        If :exc:`.SMTPResponseException` is raised by this method, we try to\n        send an RSET command to reset the server envelope automatically for\n        the next attempt.\n\n        :raises SMTPRecipientsRefused: delivery to all recipients failed\n        :raises SMTPResponseException: on invalid response\n        \"\"\"\n        if isinstance(recipients, str):\n            recipients = [recipients]\n        else:\n            recipients = list(recipients)\n\n        if mail_options is None:\n            mail_options = []\n        else:\n            mail_options = list(mail_options)\n\n        if rcpt_options is None:\n            rcpt_options = []\n        else:\n            rcpt_options = list(rcpt_options)\n\n        async with self._sendmail_lock:\n            if self.supports_extension(\"size\"):\n                size_option = \"size={}\".format(len(message))\n                mail_options.append(size_option)\n\n            try:\n                await self.mail(sender, options=mail_options, timeout=timeout)\n                recipient_errors = await self._send_recipients(\n                    recipients, options=rcpt_options, timeout=timeout\n                )\n                response = await self.data(message, timeout=timeout)\n            except (SMTPResponseException, SMTPRecipientsRefused) as exc:\n                # If we got an error, reset the envelope.\n                try:\n                    await self.rset(timeout=timeout)\n                except (ConnectionError, SMTPResponseException):\n                    # If we're disconnected on the reset, or we get a bad\n                    # status, don't raise that as it's confusing\n                    pass\n                raise exc\n\n        return recipient_errors, response.message", "response": "This command sends an email to the specified recipients and message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _send_recipients(\n        self,\n        recipients: List[str],\n        options: List[str] = None,\n        timeout: DefaultNumType = _default,\n    ) -> RecipientErrorsType:\n        \"\"\"\n        Send the recipients given to the server. Used as part of\n        :meth:`.sendmail`.\n        \"\"\"\n        recipient_errors = []\n        for address in recipients:\n            try:\n                await self.rcpt(address, timeout=timeout)\n            except SMTPRecipientRefused as exc:\n                recipient_errors.append(exc)\n\n        if len(recipient_errors) == len(recipients):\n            raise SMTPRecipientsRefused(recipient_errors)\n\n        formatted_errors = {\n            err.recipient: SMTPResponse(err.code, err.message)\n            for err in recipient_errors\n        }\n\n        return formatted_errors", "response": "Send the recipients given to the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _run_sync(self, method: Callable, *args, **kwargs) -> Any:\n        if self.loop.is_running():\n            raise RuntimeError(\"Event loop is already running.\")\n\n        if not self.is_connected:\n            self.loop.run_until_complete(self.connect())\n\n        task = asyncio.Task(method(*args, **kwargs), loop=self.loop)\n        result = self.loop.run_until_complete(task)\n\n        self.loop.run_until_complete(self.quit())\n\n        return result", "response": "Utility method to run commands synchronously for testing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_message_sync(\n        self,\n        message: Message,\n        sender: str = None,\n        recipients: RecipientsType = None,\n        mail_options: Iterable[str] = None,\n        rcpt_options: Iterable[str] = None,\n        timeout: DefaultNumType = _default,\n    ) -> SendmailResponseType:\n        \"\"\"\n        Synchronous version of :meth:`.send_message`. This method\n        starts the event loop to connect, send the message, and disconnect.\n        \"\"\"\n        return self._run_sync(\n            self.send_message,\n            message,\n            sender=sender,\n            recipients=recipients,\n            mail_options=mail_options,\n            rcpt_options=rcpt_options,\n            timeout=timeout,\n        )", "response": "Synchronous version of send_message. This method is synchronous and will block until the message is sent or the timeout expires."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking for any announcements from cs50. me raise Error if so.", "response": "def check_announcements():\n    \"\"\"Check for any announcements from cs50.me, raise Error if so.\"\"\"\n    res = requests.get(\"https://cs50.me/status/submit50\")  # TODO change this to submit50.io!\n    if res.status_code == 200 and res.text.strip():\n        raise Error(res.text.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_version():\n    # Retrieve version info\n    res = requests.get(\"https://cs50.me/versions/submit50\")  # TODO change this to submit50.io!\n    if res.status_code != 200:\n        raise Error(_(\"You have an unknown version of submit50. \"\n                      \"Email sysadmins@cs50.harvard.edu!\"))\n\n    # Check that latest version == version installed\n    required_required = pkg_resources.parse_version(res.text.strip())", "response": "Check that submit50 is the latest version according to submit50. io."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cprint(text=\"\", color=None, on_color=None, attrs=None, **kwargs):\n    # Assume 80 in case not running in a terminal\n    columns, lines = shutil.get_terminal_size()\n    if columns == 0:\n        columns = 80  # Because get_terminal_size's default fallback doesn't work in pipes\n\n    # Print text\n    termcolor.cprint(textwrap.fill(text, columns, drop_whitespace=False),\n                     color=color, on_color=on_color, attrs=attrs, **kwargs)", "response": "Colorizes text and wraps to terminal s width."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of all plugin classes registered as a list of tuples", "response": "def list_plugins():\n    \"\"\"Return list of all plugin classes registered as a list of tuples:\n\n        [(name, plugin_class)]\n    \"\"\"\n    plugin_eps = pkg_resources.iter_entry_points('ofxstatement')\n    return sorted((ep.name, ep.load()) for ep in plugin_eps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_transaction_id(stmt_line):\n    return str(abs(hash((stmt_line.date,\n                         stmt_line.memo,\n                         stmt_line.amount))))", "response": "Generate pseudo - unique id for given statement line."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recalculate_balance(stmt):\n\n    total_amount = sum(sl.amount for sl in stmt.lines)\n\n    stmt.start_balance = stmt.start_balance or D(0)\n    stmt.end_balance = stmt.start_balance + total_amount\n    stmt.start_date = min(sl.date for sl in stmt.lines)\n    stmt.end_date = max(sl.date for sl in stmt.lines)", "response": "Recalculate statement starting and ending dates and balances."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assert_valid(self):\n        assert self.trntype in TRANSACTION_TYPES, \\\n            \"trntype must be one of %s\" % TRANSACTION_TYPES\n\n        if self.bank_account_to:\n            self.bank_account_to.assert_valid()", "response": "Ensure that the fields have valid values\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self):\n        reader = self.split_records()\n        for line in reader:\n            self.cur_record += 1\n            if not line:\n                continue\n            stmt_line = self.parse_record(line)\n            if stmt_line:\n                stmt_line.assert_valid()\n                self.statement.lines.append(stmt_line)\n        return self.statement", "response": "Read and parse statement\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nacquire an auth token from the CAS server.", "response": "def acquire_auth_token_ticket(self, headers=None):\n        '''\n        Acquire an auth token from the CAS server.\n        '''\n        logging.debug('[CAS] Acquiring Auth token ticket')\n        url = self._get_auth_token_tickets_url()\n        text = self._perform_post(url, headers=headers)\n        auth_token_ticket = json.loads(text)['ticket']\n        logging.debug('[CAS] Acquire Auth token ticket: {}'.format(\n            auth_token_ticket))\n        return auth_token_ticket"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a session record from a service ticket.", "response": "def create_session(self, ticket, payload=None, expires=None):\n        '''\n        Create a session record from a service ticket.\n        '''\n        assert isinstance(self.session_storage_adapter, CASSessionAdapter)\n        logging.debug('[CAS] Creating session for ticket {}'.format(ticket))\n        self.session_storage_adapter.create(\n            ticket,\n            payload=payload,\n            expires=expires,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_session(self, ticket):\n        '''\n        Delete a session record associated with a service ticket.\n        '''\n        assert isinstance(self.session_storage_adapter, CASSessionAdapter)\n        logging.debug('[CAS] Deleting session for ticket {}'.format(ticket))\n        self.session_storage_adapter.delete(ticket)", "response": "Delete a session record associated with a service ticket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_api_url(\n        self,\n        api_resource,\n        auth_token_ticket,\n        authenticator,\n        private_key,\n        service_url=None,\n        **kwargs\n    ):\n        '''\n        Build an auth-token-protected CAS API url.\n        '''\n        auth_token, auth_token_signature = self._build_auth_token_data(\n            auth_token_ticket,\n            authenticator,\n            private_key,\n            **kwargs\n            )\n        params = {\n            'at': auth_token,\n            'ats': auth_token_signature,\n            }\n        if service_url is not None:\n            params['service'] = service_url\n        url = '{}?{}'.format(\n            self._get_api_url(api_resource),\n            urlencode(params),\n            )\n        return url", "response": "Builds an auth - token - protected CAS API url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_auth_token_login_url(\n        self,\n        auth_token_ticket,\n        authenticator,\n        private_key,\n        service_url,\n        username,\n    ):\n        '''\n        Build an auth token login URL.\n\n        See https://github.com/rbCAS/CASino/wiki/Auth-Token-Login for details.\n        '''\n        auth_token, auth_token_signature = self._build_auth_token_data(\n            auth_token_ticket,\n            authenticator,\n            private_key,\n            username=username,\n            )\n        logging.debug('[CAS] AuthToken: {}'.format(auth_token))\n        url = self._get_auth_token_login_url(\n            auth_token=auth_token,\n            auth_token_signature=auth_token_signature,\n            service_url=service_url,\n            )\n        logging.debug('[CAS] AuthToken Login URL: {}'.format(url))\n        return url", "response": "Build an auth token login URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_destroy_other_sessions_url(self, service_url=None):\n        '''\n        Get the URL for a remote CAS `destroy-other-sessions` endpoint.\n        ::\n\n            >>> from cas_client import CASClient\n            >>> client = CASClient('https://logmein.com')\n            >>> service_url = 'http://myservice.net'\n            >>> client.get_destroy_other_sessions_url(service_url)\n            'https://logmein.com/cas/destroy-other-sessions?service=http://myservice.net'\n\n        '''\n        template = '{server_url}{auth_prefix}/destroy-other-sessions?service={service_url}'\n        url = template.format(\n            server_url=self.server_url,\n            auth_prefix=self.auth_prefix,\n            service_url=service_url or self.service_url,\n        )\n\n        logging.debug('[CAS] Destroy Sessions URL: {}'.format(url))\n        return url", "response": "Get the URL for a remote CAS destroy - other - sessions endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_logout_request(self, message_text):\n        '''\n        Parse the contents of a CAS `LogoutRequest` XML message.\n\n        ::\n\n            >>> from cas_client import CASClient\n            >>> client = CASClient('https://logmein.com')\n            >>> message_text = \"\"\"\n            ... <samlp:LogoutRequest\n            ...     xmlns:samlp=\"urn:oasis:names:tc:SAML:2.0:protocol\"\n            ...     xmlns:saml=\"urn:oasis:names:tc:SAML:2.0:assertion\"\n            ...     ID=\"935a2d0c-4026-481e-be3d-20a1b2cdd553\"\n            ...     Version=\"2.0\"\n            ...     IssueInstant=\"2016-04-08 00:40:55 +0000\">\n            ...     <saml:NameID>@NOT_USED@</saml:NameID>\n            ...     <samlp:SessionIndex>ST-14600760351898-0B3lSFt2jOWSbgQ377B4CtbD9uq0MXR9kG23vAuH</samlp:SessionIndex>\n            ... </samlp:LogoutRequest>\n            ... \"\"\"\n            >>> parsed_message = client.parse_logout_request(message_text)\n            >>> import pprint\n            >>> pprint.pprint(parsed_message)\n            {'ID': '935a2d0c-4026-481e-be3d-20a1b2cdd553',\n             'IssueInstant': '2016-04-08 00:40:55 +0000',\n             'Version': '2.0',\n             'session_index': 'ST-14600760351898-0B3lSFt2jOWSbgQ377B4CtbD9uq0MXR9kG23vAuH',\n             'xmlns:saml': 'urn:oasis:names:tc:SAML:2.0:assertion',\n             'xmlns:samlp': 'urn:oasis:names:tc:SAML:2.0:protocol'}\n\n        '''\n        result = {}\n        xml_document = parseString(message_text)\n        for node in xml_document.getElementsByTagName('saml:NameId'):\n            for child in node.childNodes:\n                if child.nodeType == child.TEXT_NODE:\n                    result['name_id'] = child.nodeValue.strip()\n        for node in xml_document.getElementsByTagName('samlp:SessionIndex'):\n            for child in node.childNodes:\n                if child.nodeType == child.TEXT_NODE:\n                    result['session_index'] = str(child.nodeValue.strip())\n        for key in xml_document.documentElement.attributes.keys():\n            result[str(key)] = str(xml_document.documentElement.getAttribute(key))\n        logging.debug('[CAS] LogoutRequest:\\n{}'.format(\n            json.dumps(result, sort_keys=True, indent=4, separators=[',', ': ']),\n            ))\n        return result", "response": "Parse the contents of a CAS LogoutRequest XML message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform an auth - token - protected request against a CAS API endpoint.", "response": "def perform_api_request(\n        self,\n        url,\n        method='POST',\n        headers=None,\n        body=None,\n        **kwargs\n    ):\n        '''\n        Perform an auth-token-protected request against a CAS API endpoint.\n        '''\n        assert method in ('GET', 'POST')\n        if method == 'GET':\n            response = self._perform_get(url, headers=headers, **kwargs)\n        elif method == 'POST':\n            response = self._perform_post(url, headers=headers, data=body, **kwargs)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a CAS proxy call.", "response": "def perform_proxy(self, proxy_ticket, headers=None):\n        '''\n        Fetch a response from the remote CAS `proxy` endpoint.\n        '''\n        url = self._get_proxy_url(ticket=proxy_ticket)\n        logging.debug('[CAS] Proxy URL: {}'.format(url))\n        return self._perform_cas_call(\n            url,\n            ticket=proxy_ticket,\n            headers=headers,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a remote CAS ProxyValidate request.", "response": "def perform_proxy_validate(self, proxied_service_ticket, headers=None):\n        '''\n        Fetch a response from the remote CAS `proxyValidate` endpoint.\n        '''\n        url = self._get_proxy_validate_url(ticket=proxied_service_ticket)\n        logging.debug('[CAS] ProxyValidate URL: {}'.format(url))\n        return self._perform_cas_call(\n            url,\n            ticket=proxied_service_ticket,\n            headers=headers,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a remote CAS serviceValidate call.", "response": "def perform_service_validate(\n        self,\n        ticket=None,\n        service_url=None,\n        headers=None,\n        ):\n        '''\n        Fetch a response from the remote CAS `serviceValidate` endpoint.\n        '''\n        url = self._get_service_validate_url(ticket, service_url=service_url)\n        logging.debug('[CAS] ServiceValidate URL: {}'.format(url))\n        return self._perform_cas_call(url, ticket=ticket, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntest if a session record exists for a service ticket.", "response": "def session_exists(self, ticket):\n        '''\n        Test if a session records exists for a service ticket.\n        '''\n        assert isinstance(self.session_storage_adapter, CASSessionAdapter)\n        exists = self.session_storage_adapter.exists(ticket)\n        logging.debug('[CAS] Session [{}] exists: {}'.format(ticket, exists))\n        return exists"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a session identifier in memcache associated with ticket.", "response": "def create(self, ticket, payload=None, expires=None):\n        '''\n        Create a session identifier in memcache associated with ``ticket``.\n        '''\n        if not payload:\n            payload = True\n        self._client.set(str(ticket), payload, expires)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __check_response(self, msg):\n        if not isinstance(msg, list):\n            msg = msg.split(\"\\n\")\n        if (len(msg) > 2) and self.RE_PATTERNS['not_allowed_pattern'].match(msg[2]):\n            raise NotAllowed(msg[2][2:])\n        if self.RE_PATTERNS['credentials_required_pattern'].match(msg[0]):\n            raise AuthorizationError('Credentials required.')\n        if self.RE_PATTERNS['syntax_error_pattern'].match(msg[0]):\n            raise APISyntaxError(msg[2][2:] if len(msg) > 2 else 'Syntax error.')\n        if self.RE_PATTERNS['bad_request_pattern'].match(msg[0]):\n            raise BadRequest(msg[3] if len(msg) > 2 else 'Bad request.')", "response": "Check the response for errors and raise exceptions when found."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits message to list by commas and trim whitespace.", "response": "def __normalize_list(self, msg):\n        \"\"\"Split message to list by commas and trim whitespace.\"\"\"\n        if isinstance(msg, list):\n            msg = \"\".join(msg)\n        return list(map(lambda x: x.strip(), msg.split(\",\")))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging-in with default or supplied credetials.", "response": "def login(self, login=None, password=None):\n        \"\"\" Login with default or supplied credetials.\n\n        .. note::\n\n            Calling this method is not necessary when HTTP basic or HTTP\n            digest_auth authentication is used and RT accepts it as external\n            authentication method, because the login in this case is done\n            transparently by requests module. Anyway this method can be useful\n            to check whether given credentials are valid or not.\n\n        :keyword login: Username used for RT, if not supplied together with\n                        *password* :py:attr:`~Rt.default_login` and\n                        :py:attr:`~Rt.default_password` are used instead\n        :keyword password: Similarly as *login*\n\n        :returns: ``True``\n                      Successful login\n                  ``False``\n                      Otherwise\n        :raises AuthorizationError: In case that credentials are not supplied neither\n                                    during inicialization or call of this method.\n        \"\"\"\n\n        if (login is not None) and (password is not None):\n            login_data = {'user': login, 'pass': password}\n        elif (self.default_login is not None) and (self.default_password is not None):\n            login_data = {'user': self.default_login, 'pass': self.default_password}\n        elif self.session.auth:\n            login_data = None\n        else:\n            raise AuthorizationError('Credentials required, fill login and password.')\n        try:\n            self.login_result = self.__get_status_code(self.__request('',\n                                                                      post_data=login_data,\n                                                                      without_login=True)) == 200\n        except AuthorizationError:\n            # This happens when HTTP Basic or Digest authentication fails, but\n            # we will not raise the error but just return False to indicate\n            # invalid credentials\n            return False\n        return self.login_result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of tickets which were last updated by other users than the system one.", "response": "def new_correspondence(self, queue=None):\n        \"\"\" Obtains tickets changed by other users than the system one.\n\n        :keyword queue: Queue where to search\n\n        :returns: List of tickets which were last updated by other user than\n                  the system one ordered in decreasing order by LastUpdated.\n                  Each ticket is dictionary, the same as in\n                  :py:meth:`~Rt.get_ticket`.\n        \"\"\"\n        return self.search(Queue=queue, order='-LastUpdated', LastUpdatedBy__notexact=self.default_login)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all tickets with LastUpdated parameter later than given date.", "response": "def last_updated(self, since, queue=None):\n        \"\"\" Obtains tickets changed after given date.\n\n        :param since: Date as string in form '2011-02-24'\n        :keyword queue: Queue where to search\n\n        :returns: List of tickets with LastUpdated parameter later than\n                  *since* ordered in decreasing order by LastUpdated.\n                  Each tickets is dictionary, the same as in\n                  :py:meth:`~Rt.get_ticket`.\n        \"\"\"\n        return self.search(Queue=queue, order='-LastUpdated', LastUpdatedBy__notexact=self.default_login, LastUpdated__gt=since)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(self, Queue=None, order=None, raw_query=None, Format='l', **kwargs):\n        get_params = {}\n        query = []\n        url = 'search/ticket'\n        if Queue is not ALL_QUEUES:\n            query.append(\"Queue=\\'{}\\'\".format(Queue or self.default_queue))\n        if not raw_query:\n            operators_map = {\n                'gt': '>',\n                'lt': '<',\n                'exact': '=',\n                'notexact': '!=',\n                'like': ' LIKE ',\n                'notlike': ' NOT LIKE '\n            }\n\n            for key, value in iteritems(kwargs):\n                op = '='\n                key_parts = key.split('__')\n                if len(key_parts) > 1:\n                    key = '__'.join(key_parts[:-1])\n                    op = operators_map.get(key_parts[-1], '=')\n                if key[:3] != 'CF_':\n                    query.append(\"{}{}\\'{}\\'\".format(key, op, value))\n                else:\n                    query.append(\"'CF.{{{}}}'{}\\'{}\\'\".format(key[3:], op, value))\n        else:\n            query.append(raw_query)\n        get_params['query'] = ' AND '.join('(' + part + ')' for part in query)\n        if order:\n            get_params['orderby'] = order\n        get_params['format'] = Format\n\n        msg = self.__request(url, get_params=get_params)\n        lines = msg.split('\\n')\n        if len(lines) > 2:\n            if self.__get_status_code(lines[0]) != 200 and lines[2].startswith('Invalid query: '):\n                raise InvalidQueryError(lines[2])\n            if lines[2].startswith('No matching results.'):\n                return []\n\n        if Format == 'l':\n            msgs = map(lambda x: x.split('\\n'), msg.split('\\n--\\n'))\n            items = []\n            for msg in msgs:\n                pairs = {}\n                req_matching = [i for i, m in enumerate(msg) if self.RE_PATTERNS['requestors_pattern'].match(m)]\n                req_id = req_matching[0] if req_matching else None\n                if not req_id:\n                    raise UnexpectedMessageFormat('Missing line starting with `Requestors:`.')\n                for i in range(req_id):\n                    if ': ' in msg[i]:\n                        header, content = self.split_header(msg[i])\n                        pairs[header.strip()] = content.strip()\n                requestors = [msg[req_id][12:]]\n                req_id += 1\n                while (req_id < len(msg)) and (msg[req_id][:12] == ' ' * 12):\n                    requestors.append(msg[req_id][12:])\n                    req_id += 1\n                pairs['Requestors'] = self.__normalize_list(requestors)\n                for i in range(req_id, len(msg)):\n                    if ': ' in msg[i]:\n                        header, content = self.split_header(msg[i])\n                        pairs[header.strip()] = content.strip()\n                if pairs:\n                    items.append(pairs)\n\n                if 'Cc' in pairs:\n                    pairs['Cc'] = self.__normalize_list(pairs['Cc'])\n                if 'AdminCc' in pairs:\n                    pairs['AdminCc'] = self.__normalize_list(pairs['AdminCc'])\n\n                if 'id' not in pairs and not pairs['id'].startswitch('ticket/'):\n                    raise UnexpectedMessageFormat('Response from RT didn\\'t contain a valid ticket_id')\n                else:\n                    pairs['numerical_id'] = pairs['id'].split('ticket/')[1]\n\n            return items\n        elif Format == 's':\n            items = []\n            msgs = lines[2:]\n            for msg in msgs:\n                if \"\" == msg:  # Ignore blank line at the end\n                    continue\n                ticket_id, subject = self.split_header(msg)\n                items.append({'id': 'ticket/' + ticket_id, 'numerical_id': ticket_id, 'Subject': subject})\n            return items\n        elif Format == 'i':\n            items = []\n            msgs = lines[2:]\n            for msg in msgs:\n                if \"\" == msg:  # Ignore blank line at the end\n                    continue\n                _, ticket_id = msg.split('/', 1)\n                items.append({'id': 'ticket/' + ticket_id, 'numerical_id': ticket_id})\n            return items", "response": "Search arbitrary needles in given fields and queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ticket(self, ticket_id):\n        msg = self.__request('ticket/{}/show'.format(str(ticket_id), ))\n        status_code = self.__get_status_code(msg)\n        if status_code == 200:\n            pairs = {}\n            msg = msg.split('\\n')\n            if (len(msg) > 2) and self.RE_PATTERNS['does_not_exist_pattern'].match(msg[2]):\n                return None\n            req_matching = [i for i, m in enumerate(msg) if self.RE_PATTERNS['requestors_pattern'].match(m)]\n            req_id = req_matching[0] if req_matching else None\n            if not req_id:\n                raise UnexpectedMessageFormat('Missing line starting with `Requestors:`.')\n            for i in range(req_id):\n                if ': ' in msg[i]:\n                    header, content = self.split_header(msg[i])\n                    pairs[header.strip()] = content.strip()\n            requestors = [msg[req_id][12:]]\n            req_id += 1\n            while (req_id < len(msg)) and (msg[req_id][:12] == ' ' * 12):\n                requestors.append(msg[req_id][12:])\n                req_id += 1\n            pairs['Requestors'] = self.__normalize_list(requestors)\n            for i in range(req_id, len(msg)):\n                if ': ' in msg[i]:\n                    header, content = self.split_header(msg[i])\n                    pairs[header.strip()] = content.strip()\n\n            if 'Cc' in pairs:\n                pairs['Cc'] = self.__normalize_list(pairs['Cc'])\n            if 'AdminCc' in pairs:\n                pairs['AdminCc'] = self.__normalize_list(pairs['AdminCc'])\n\n            if 'id' not in pairs and not pairs['id'].startswitch('ticket/'):\n                raise UnexpectedMessageFormat('Response from RT didn\\'t contain a valid ticket_id')\n            else:\n                pairs['numerical_id'] = pairs['id'].split('ticket/')[1]\n\n            return pairs\n        else:\n            raise UnexpectedMessageFormat('Received status code is {:d} instead of 200.'.format(status_code))", "response": "Fetch a demanded ticket by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_ticket(self, Queue=None, files=[], **kwargs):\n\n        post_data = 'id: ticket/new\\nQueue: {}\\n'.format(Queue or self.default_queue, )\n        for key in kwargs:\n            if key[:4] == 'Text':\n                post_data += \"{}: {}\\n\".format(key, re.sub(r'\\n', r'\\n      ', kwargs[key]))\n            elif key[:3] == 'CF_':\n                post_data += \"CF.{{{}}}: {}\\n\".format(key[3:], kwargs[key])\n            else:\n                post_data += \"{}: {}\\n\".format(key, kwargs[key])\n        for file_info in files:\n            post_data += \"\\nAttachment: {}\".format(file_info[0], )\n        msg = self.__request('ticket/new', post_data={'content': post_data}, files=files)\n        for line in msg.split('\\n')[2:-1]:\n            res = self.RE_PATTERNS['ticket_created_pattern'].match(line)\n            if res is not None:\n                return int(res.group(1))\n            warnings.warn(line[2:])\n        return -1", "response": "Create new ticket and set given parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits ticket values. :param ticket_id: ID of ticket to edit :keyword kwargs: Other arguments possible to set: Requestors, Subject, Cc, AdminCc, Owner, Status, Priority, InitialPriority, FinalPriority, TimeEstimated, Starts, Due, Text,... (according to RT fields) Custom fields CF.{<CustomFieldName>} could be set with keywords CF_CustomFieldName. :returns: ``True`` Operation was successful ``False`` Ticket with given ID does not exist or unknown parameter was set (in this case all other valid fields are changed)", "response": "def edit_ticket(self, ticket_id, **kwargs):\n        \"\"\" Edit ticket values.\n\n        :param ticket_id: ID of ticket to edit\n        :keyword kwargs: Other arguments possible to set:\n\n                         Requestors, Subject, Cc, AdminCc, Owner, Status,\n                         Priority, InitialPriority, FinalPriority,\n                         TimeEstimated, Starts, Due, Text,... (according to RT\n                         fields)\n\n                         Custom fields CF.{<CustomFieldName>} could be set\n                         with keywords CF_CustomFieldName.\n        :returns: ``True``\n                      Operation was successful\n                  ``False``\n                      Ticket with given ID does not exist or unknown parameter\n                      was set (in this case all other valid fields are changed)\n        \"\"\"\n        post_data = ''\n        for key, value in iteritems(kwargs):\n            if isinstance(value, (list, tuple)):\n                value = \", \".join(value)\n            if key[:3] != 'CF_':\n                post_data += \"{}: {}\\n\".format(key, value)\n            else:\n                post_data += \"CF.{{{}}}: {}\\n\".format(key[3:], value)\n        msg = self.__request('ticket/{}/edit'.format(str(ticket_id)), post_data={'content': post_data})\n        state = msg.split('\\n')[2]\n        return self.RE_PATTERNS['update_pattern'].match(state) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of history items.", "response": "def get_history(self, ticket_id, transaction_id=None):\n        \"\"\" Get set of history items.\n\n        :param ticket_id: ID of ticket\n        :keyword transaction_id: If set to None, all history items are\n                                 returned, if set to ID of valid transaction\n                                 just one history item is returned\n\n        :returns: List of history items ordered increasingly by time of event.\n                  Each history item is dictionary with following keys:\n\n                  Description, Creator, Data, Created, TimeTaken, NewValue,\n                  Content, Field, OldValue, Ticket, Type, id, Attachments\n\n                  All these fields are strings, just 'Attachments' holds list\n                  of pairs (attachment_id,filename_with_size).\n\n                  Returns None if ticket or transaction does not exist.\n        :raises UnexpectedMessageFormat: Unexpected format of returned message.\n        \"\"\"\n        if transaction_id is None:\n            # We are using \"long\" format to get all history items at once.\n            # Each history item is then separated by double dash.\n            msgs = self.__request('ticket/{}/history?format=l'.format(str(ticket_id), ))\n        else:\n            msgs = self.__request('ticket/{}/history/id/{}'.format(str(ticket_id), str(transaction_id)))\n        lines = msgs.split('\\n')\n        if (len(lines) > 2) and (\n                self.RE_PATTERNS['does_not_exist_pattern'].match(lines[2]) or self.RE_PATTERNS['not_related_pattern'].match(\n                lines[2])):\n            return None\n        msgs = msgs.split('\\n--\\n')\n        items = []\n        for msg in msgs:\n            pairs = {}\n            msg = msg.split('\\n')\n            cont_matching = [i for i, m in enumerate(msg) if self.RE_PATTERNS['content_pattern'].match(m)]\n            cont_id = cont_matching[0] if cont_matching else None\n            if not cont_id:\n                raise UnexpectedMessageFormat('Unexpected history entry. \\\n                                               Missing line starting with `Content:`.')\n            atta_matching = [i for i, m in enumerate(msg) if self.RE_PATTERNS['attachments_pattern'].match(m)]\n            atta_id = atta_matching[0] if atta_matching else None\n            if not atta_id:\n                raise UnexpectedMessageFormat('Unexpected attachment part of history entry. \\\n                                               Missing line starting with `Attachements:`.')\n            for i in range(cont_id):\n                if ': ' in msg[i]:\n                    header, content = self.split_header(msg[i])\n                    pairs[header.strip()] = content.strip()\n            content = msg[cont_id][9:]\n            cont_id += 1\n            while (cont_id < len(msg)) and (msg[cont_id][:9] == ' ' * 9):\n                content += '\\n' + msg[cont_id][9:]\n                cont_id += 1\n            pairs['Content'] = content\n            for i in range(cont_id, atta_id):\n                if ': ' in msg[i]:\n                    header, content = self.split_header(msg[i])\n                    pairs[header.strip()] = content.strip()\n            attachments = []\n            for i in range(atta_id + 1, len(msg)):\n                if ': ' in msg[i]:\n                    header, content = self.split_header(msg[i])\n                    attachments.append((int(header),\n                                        content.strip()))\n            pairs['Attachments'] = attachments\n            items.append(pairs)\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the short history items for a ticket.", "response": "def get_short_history(self, ticket_id):\n        \"\"\" Get set of short history items\n\n        :param ticket_id: ID of ticket\n        :returns: List of history items ordered increasingly by time of event.\n                  Each history item is a tuple containing (id, Description).\n                  Returns None if ticket does not exist.\n        \"\"\"\n        msg = self.__request('ticket/{}/history'.format(str(ticket_id), ))\n        items = []\n        lines = msg.split('\\n')\n        multiline_buffer = \"\"\n        in_multiline = False\n        if self.__get_status_code(lines[0]) == 200:\n            if (len(lines) > 2) and self.RE_PATTERNS['does_not_exist_pattern'].match(lines[2]):\n                return None\n            if len(lines) >= 4:\n                for line in lines[4:]:\n                    if line == \"\":\n                        if not in_multiline:\n                            # start of multiline block\n                            in_multiline = True\n                        else:\n                            # end of multiline block\n                            line = multiline_buffer\n                            multiline_buffer = \"\"\n                            in_multiline = False\n                    else:\n                        if in_multiline:\n                            multiline_buffer += line\n                            line = \"\"\n                    if ': ' in line:\n                        hist_id, desc = line.split(': ', 1)\n                        items.append((int(hist_id), desc))\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends out the message to the ticket with the given ID.", "response": "def __correspond(self, ticket_id, text='', action='correspond', cc='', bcc='', content_type='text/plain', files=[]):\n        \"\"\" Sends out the correspondence\n\n        :param ticket_id: ID of ticket to which message belongs\n        :keyword text: Content of email message\n        :keyword action: correspond or comment\n        :keyword content_type: Content type of email message, default to text/plain\n        :keyword cc: Carbon copy just for this reply\n        :keyword bcc: Blind carbon copy just for this reply\n        :keyword files: Files to attach as multipart/form-data\n                        List of 2/3 tuples: (filename, file-like object, [content type])\n        :returns: ``True``\n                      Operation was successful\n                  ``False``\n                      Sending failed (status code != 200)\n        :raises BadRequest: When ticket does not exist\n        \"\"\"\n        post_data = {'content': \"\"\"id: {}\nAction: {}\nText: {}\nCc: {}\nBcc: {}\nContent-Type: {}\"\"\".format(str(ticket_id), action, re.sub(r'\\n', r'\\n      ', text), cc, bcc, content_type)}\n        for file_info in files:\n            post_data['content'] += \"\\nAttachment: {}\".format(file_info[0], )\n        msg = self.__request('ticket/{}/comment'.format(str(ticket_id), ),\n                             post_data=post_data, files=files)\n        return self.__get_status_code(msg) == 200"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reply(self, ticket_id, text='', cc='', bcc='', content_type='text/plain', files=[]):\n        return self.__correspond(ticket_id, text, 'correspond', cc, bcc, content_type, files)", "response": "Sends an email message to the contacts in Requestors field of the given ticket with subject as is set in Subject field of the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the list of attachments belonging to a given ticket.", "response": "def get_attachments(self, ticket_id):\n        \"\"\" Get attachment list for a given ticket\n\n        :param ticket_id: ID of ticket\n        :returns: List of tuples for attachments belonging to given ticket.\n                  Tuple format: (id, name, content_type, size)\n                  Returns None if ticket does not exist.\n        \"\"\"\n        msg = self.__request('ticket/{}/attachments'.format(str(ticket_id), ))\n        lines = msg.split('\\n')\n        if (len(lines) > 2) and self.RE_PATTERNS['does_not_exist_pattern'].match(lines[2]):\n            return None\n        attachment_infos = []\n        if (self.__get_status_code(lines[0]) == 200) and (len(lines) >= 4):\n            for line in lines[4:]:\n                info = self.RE_PATTERNS['attachments_list_pattern'].match(line)\n                if info:\n                    attachment_infos.append(info.groups())\n        return attachment_infos"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_attachments_ids(self, ticket_id):\n        attachments = self.get_attachments(ticket_id)\n        return [int(at[0]) for at in attachments] if attachments else attachments", "response": "Get the list of IDs of attachments belonging to given\n                  ticket. Returns None if ticket does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_attachment(self, ticket_id, attachment_id):\n        msg = self.__request('ticket/{}/attachments/{}'.format(str(ticket_id), str(attachment_id)),\n                             text_response=False)\n        msg = msg.split(b'\\n')\n        if (len(msg) > 2) and (self.RE_PATTERNS['invalid_attachment_pattern_bytes'].match(msg[2]) or self.RE_PATTERNS['does_not_exist_pattern_bytes'].match(msg[2])):\n            return None\n        msg = msg[2:]\n        head_matching = [i for i, m in enumerate(msg) if self.RE_PATTERNS['headers_pattern_bytes'].match(m)]\n        head_id = head_matching[0] if head_matching else None\n        if not head_id:\n            raise UnexpectedMessageFormat('Unexpected headers part of attachment entry. \\\n                                           Missing line starting with `Headers:`.')\n        msg[head_id] = re.sub(b'^Headers: (.*)$', r'\\1', msg[head_id])\n        cont_matching = [i for i, m in enumerate(msg) if self.RE_PATTERNS['content_pattern_bytes'].match(m)]\n        cont_id = cont_matching[0] if cont_matching else None\n        if not cont_matching:\n            raise UnexpectedMessageFormat('Unexpected content part of attachment entry. \\\n                                           Missing line starting with `Content:`.')\n        pairs = {}\n        for i in range(head_id):\n            if b': ' in msg[i]:\n                header, content = msg[i].split(b': ', 1)\n                pairs[header.strip().decode('utf-8')] = content.strip().decode('utf-8')\n        headers = {}\n        for i in range(head_id, cont_id):\n            if b': ' in msg[i]:\n                header, content = msg[i].split(b': ', 1)\n                headers[header.strip().decode('utf-8')] = content.strip().decode('utf-8')\n        pairs['Headers'] = headers\n        content = msg[cont_id][9:]\n        for i in range(cont_id + 1, len(msg)):\n            if msg[i][:9] == (b' ' * 9):\n                content += b'\\n' + msg[i][9:]\n        pairs['Content'] = content\n        return pairs", "response": "Get attachment for ticket."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets content of attachment.", "response": "def get_attachment_content(self, ticket_id, attachment_id):\n        \"\"\" Get content of attachment without headers.\n\n        This function is necessary to use for binary attachment,\n        as it can contain ``\\\\n`` chars, which would disrupt parsing\n        of message if :py:meth:`~Rt.get_attachment` is used.\n\n        Format of message::\n\n            RT/3.8.7 200 Ok\\n\\nStart of the content...End of the content\\n\\n\\n\n\n        :param ticket_id: ID of ticket\n        :param attachment_id: ID of attachment\n\n        Returns: Bytes with content of attachment or None if ticket or\n                 attachment does not exist.\n        \"\"\"\n\n        msg = self.__request('ticket/{}/attachments/{}/content'.format\n                             (str(ticket_id), str(attachment_id)),\n                             text_response=False)\n        lines = msg.split(b'\\n', 3)\n        if (len(lines) == 4) and (self.RE_PATTERNS['invalid_attachment_pattern_bytes'].match(lines[2]) or self.RE_PATTERNS['does_not_exist_pattern_bytes'].match(lines[2])):\n            return None\n        return msg[msg.find(b'\\n') + 2:-3]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_user(self, user_id):\n        msg = self.__request('user/{}'.format(str(user_id), ))\n        status_code = self.__get_status_code(msg)\n        if (status_code == 200):\n            pairs = {}\n            lines = msg.split('\\n')\n            if (len(lines) > 2) and self.RE_PATTERNS['does_not_exist_pattern'].match(lines[2]):\n                return None\n            for line in lines[2:]:\n                if ': ' in line:\n                    header, content = line.split(': ', 1)\n                    pairs[header.strip()] = content.strip()\n            return pairs\n        else:\n            raise UnexpectedMessageFormat('Received status code is {:d} instead of 200.'.format(status_code))", "response": "Get user details.\n\n        :param user_id: Identification of user by username (str) or user ID\n                        (int)\n        :returns: User details as strings in dictionary with these keys for RT\n                  users:\n\n                      * Lang\n                      * RealName\n                      * Privileged\n                      * Disabled\n                      * Gecos\n                      * EmailAddress\n                      * Password\n                      * id\n                      * Name\n\n                  Or these keys for external users (e.g. Requestors replying\n                  to email from RT:\n\n                      * RealName\n                      * Disabled\n                      * EmailAddress\n                      * Password\n                      * id\n                      * Name\n\n                  None is returned if user does not exist.\n        :raises UnexpectedMessageFormat: In case that returned status code is not 200"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_user(self, Name, EmailAddress, **kwargs):\n\n        return self.edit_user('new', Name=Name, EmailAddress=EmailAddress, **kwargs)", "response": "Create a user in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nediting the queue with the given ID.", "response": "def edit_queue(self, queue_id, **kwargs):\n        \"\"\" Edit queue (undocumented API feature).\n\n        :param queue_id: Identification of queue by name (str) or ID (int)\n        :param kwargs: Other fields to edit from the following list:\n\n                          * Name\n                          * Description\n                          * CorrespondAddress\n                          * CommentAddress\n                          * InitialPriority\n                          * FinalPriority\n                          * DefaultDueIn\n\n        :returns: ID or name of edited queue or False when edit fails\n        :raises BadRequest: When queue does not exist\n        :raises InvalidUse: When invalid fields are set\n        \"\"\"\n\n        valid_fields = set(\n            ('name', 'description', 'correspondaddress', 'commentaddress', 'initialpriority', 'finalpriority', 'defaultduein'))\n        used_fields = set(map(lambda x: x.lower(), kwargs.keys()))\n\n        if not used_fields <= valid_fields:\n            invalid_fields = \", \".join(list(used_fields - valid_fields))\n            raise InvalidUse(\"Unsupported names of fields: {}.\".format(invalid_fields))\n        post_data = 'id: queue/{}\\n'.format(str(queue_id))\n        for key, val in iteritems(kwargs):\n            post_data += '{}: {}\\n'.format(key, val)\n        msg = self.__request('edit', post_data={'content': post_data})\n        msgs = msg.split('\\n')\n        if (self.__get_status_code(msg) == 200) and (len(msgs) > 2):\n            match = self.RE_PATTERNS['queue_pattern'].match(msgs[2])\n            if match:\n                return match.group(1)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new queue in the cluster.", "response": "def create_queue(self, Name, **kwargs):\n        \"\"\" Create queue (undocumented API feature).\n\n        :param Name: Queue name (required)\n        :param kwargs: Optional fields to set (see edit_queue)\n        :returns: ID of new queue or False when create fails\n        :raises BadRequest: When queue already exists\n        :raises InvalidUse: When invalid fields are set\n        \"\"\"\n\n        return int(self.edit_queue('new', Name=Name, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_links(self, ticket_id):\n        msg = self.__request('ticket/{}/links/show'.format(str(ticket_id), ))\n\n        status_code = self.__get_status_code(msg)\n        if (status_code == 200):\n            pairs = {}\n            msg = msg.split('\\n')\n            if (len(msg) > 2) and self.RE_PATTERNS['does_not_exist_pattern'].match(msg[2]):\n                return None\n            i = 2\n            while i < len(msg):\n                if ': ' in msg[i]:\n                    key, link = self.split_header(msg[i])\n                    links = [link.strip()]\n                    j = i + 1\n                    pad = len(key) + 2\n                    # loop over next lines for the same key\n                    while (j < len(msg)) and msg[j].startswith(' ' * pad):\n                        links[-1] = links[-1][:-1]  # remove trailing comma from previous item\n                        links.append(msg[j][pad:].strip())\n                        j += 1\n                    pairs[key] = links\n                    i = j - 1\n                i += 1\n            return pairs\n        else:\n            raise UnexpectedMessageFormat('Received status code is {:d} instead of 200.'.format(status_code))", "response": "Gets the ticket links for a single ticket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nedit ticket links. .. warning:: This method is deprecated in favour of edit_link method, because there exists bug in RT 3.8 REST API causing mapping created links to ticket/1. The only drawback is that edit_link cannot process multiple links all at once. :param ticket_id: ID of ticket to edit :keyword kwargs: Other arguments possible to set: DependsOn, DependedOnBy, RefersTo, ReferredToBy, Members, MemberOf. Each value should be either ticker ID or external link. Int types are converted. Use empty string as value to delete existing link. :returns: ``True`` Operation was successful ``False`` Ticket with given ID does not exist or unknown parameter was set (in this case all other valid fields are changed)", "response": "def edit_ticket_links(self, ticket_id, **kwargs):\n        \"\"\" Edit ticket links.\n\n        .. warning:: This method is deprecated in favour of edit_link method, because\n           there exists bug in RT 3.8 REST API causing mapping created links to\n           ticket/1. The only drawback is that edit_link cannot process multiple\n           links all at once.\n\n        :param ticket_id: ID of ticket to edit\n        :keyword kwargs: Other arguments possible to set: DependsOn,\n                         DependedOnBy, RefersTo, ReferredToBy, Members,\n                         MemberOf. Each value should be either ticker ID or\n                         external link. Int types are converted. Use empty\n                         string as value to delete existing link.\n        :returns: ``True``\n                      Operation was successful\n                  ``False``\n                      Ticket with given ID does not exist or unknown parameter\n                      was set (in this case all other valid fields are changed)\n        \"\"\"\n        post_data = ''\n        for key in kwargs:\n            post_data += \"{}: {}\\n\".format(key, str(kwargs[key]))\n        msg = self.__request('ticket/{}/links'.format(str(ticket_id), ),\n                             post_data={'content': post_data})\n        state = msg.split('\\n')[2]\n        return self.RE_PATTERNS['links_updated_pattern'].match(state) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef edit_link(self, ticket_id, link_name, link_value, delete=False):\n        valid_link_names = set(('dependson', 'dependedonby', 'refersto',\n                                'referredtoby', 'hasmember', 'memberof'))\n        if not link_name.lower() in valid_link_names:\n            raise InvalidUse(\"Unsupported name of link.\")\n        post_data = {'rel': link_name.lower(),\n                     'to': link_value,\n                     'id': ticket_id,\n                     'del': 1 if delete else 0\n                     }\n        msg = self.__request('ticket/link', post_data=post_data)\n        state = msg.split('\\n')[2]\n        if delete:\n            return self.RE_PATTERNS['deleted_link_pattern'].match(state) is not None\n        else:\n            return self.RE_PATTERNS['created_link_pattern'].match(state) is not None", "response": "Creates or deletes a link between the specified tickets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging a ticket into another ticket.", "response": "def merge_ticket(self, ticket_id, into_id):\n        \"\"\" Merge ticket into another (undocumented API feature).\n\n        :param ticket_id: ID of ticket to be merged\n        :param into: ID of destination ticket\n        :returns: ``True``\n                      Operation was successful\n                  ``False``\n                      Either origin or destination ticket does not\n                      exist or user does not have ModifyTicket permission.\n        \"\"\"\n        msg = self.__request('ticket/{}/merge/{}'.format(str(ticket_id),\n                                                         str(into_id)))\n        state = msg.split('\\n')[2]\n        return self.RE_PATTERNS['merge_successful_pattern'].match(state) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef untake(self, ticket_id):\n        post_data = {'content': \"Ticket: {}\\nAction: untake\".format(str(ticket_id))}\n        msg = self.__request('ticket/{}/take'.format(str(ticket_id)), post_data=post_data)\n        return self.__get_status_code(msg) == 200", "response": "Untake the specified ticket."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit a header line into field name and field value tuple.", "response": "def split_header(line):\n        \"\"\" Split a header line into field name and field value.\n\n        Note that custom fields may contain colons inside the curly braces,\n        so we need a special test for them.\n\n        :param line: A message line to be split.\n\n        :returns: (Field name, field value) tuple.\n        \"\"\"\n        match = re.match(r'^(CF\\.\\{.*?}): (.*)$', line)\n        if match:\n            return (match.group(1), match.group(2))\n        return line.split(': ', 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PrivateKeyFromWIF(wif):\n        if wif is None or len(wif) is not 52:\n            raise ValueError('Please provide a wif with a length of 52 bytes (LEN: {0:d})'.format(len(wif)))\n\n        data = base58.b58decode(wif)\n\n        length = len(data)\n\n        if length is not 38 or data[0] is not 0x80 or data[33] is not 0x01:\n            raise ValueError(\"Invalid format!\")\n\n        checksum = Crypto.Hash256(data[0:34])[0:4]\n\n        if checksum != data[34:]:\n            raise ValueError(\"Invalid WIF Checksum!\")\n\n        return data[1:33]", "response": "Get the private key from a WIF key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the private key from a NEP - 2 encrypted private key.", "response": "def PrivateKeyFromNEP2(nep2_key, passphrase):\n        \"\"\"\n        Gets the private key from a NEP-2 encrypted private key\n\n        Args:\n            nep2_key (str): The nep-2 encrypted private key\n            passphrase (str): The password to encrypt the private key with, as unicode string\n\n        Returns:\n            bytes: The private key\n        \"\"\"\n        if not nep2_key or len(nep2_key) != 58:\n            raise ValueError('Please provide a nep2_key with a length of 58 bytes (LEN: {0:d})'.format(len(nep2_key)))\n\n        ADDRESS_HASH_SIZE = 4\n        ADDRESS_HASH_OFFSET = len(NEP_FLAG) + len(NEP_HEADER)\n\n        try:\n            decoded_key = base58.b58decode_check(nep2_key)\n        except Exception as e:\n            raise ValueError(\"Invalid nep2_key\")\n\n        address_hash = decoded_key[ADDRESS_HASH_OFFSET:ADDRESS_HASH_OFFSET + ADDRESS_HASH_SIZE]\n        encrypted = decoded_key[-32:]\n\n        pwd_normalized = bytes(unicodedata.normalize('NFC', passphrase), 'utf-8')\n        derived = scrypt.hash(pwd_normalized, address_hash,\n                              N=SCRYPT_ITERATIONS,\n                              r=SCRYPT_BLOCKSIZE,\n                              p=SCRYPT_PARALLEL_FACTOR,\n                              buflen=SCRYPT_KEY_LEN_BYTES)\n\n        derived1 = derived[:32]\n        derived2 = derived[32:]\n\n        cipher = AES.new(derived2, AES.MODE_ECB)\n        decrypted = cipher.decrypt(encrypted)\n        private_key = xor_bytes(decrypted, derived1)\n\n        # Now check that the address hashes match. If they don't, the password was wrong.\n        kp_new = KeyPair(priv_key=private_key)\n        kp_new_address = kp_new.GetAddress()\n        kp_new_address_hash_tmp = hashlib.sha256(kp_new_address.encode(\"utf-8\")).digest()\n        kp_new_address_hash_tmp2 = hashlib.sha256(kp_new_address_hash_tmp).digest()\n        kp_new_address_hash = kp_new_address_hash_tmp2[:4]\n        if (kp_new_address_hash != address_hash):\n            raise ValueError(\"Wrong passphrase\")\n\n        return private_key"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the public NEO address for this KeyPair", "response": "def GetAddress(self):\n        \"\"\"\n        Returns the public NEO address for this KeyPair\n\n        Returns:\n            str: The private key\n        \"\"\"\n        script = b'21' + self.PublicKey.encode_point(True) + b'ac'\n        script_hash = Crypto.ToScriptHash(script)\n        address = Crypto.ToAddress(script_hash)\n        return address"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Export(self):\n        data = bytearray(38)\n        data[0] = 0x80\n        data[1:33] = self.PrivateKey[0:32]\n        data[33] = 0x01\n\n        checksum = Crypto.Default().Hash256(data[0:34])\n        data[34:38] = checksum[0:4]\n        b58 = base58.b58encode(bytes(data))\n\n        return b58.decode(\"utf-8\")", "response": "Exports this KeyPair s private key in WIF format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ExportNEP2(self, passphrase):\n        if len(passphrase) < 2:\n            raise ValueError(\"Passphrase must have a minimum of 2 characters\")\n\n        # Hash address twice, then only use the first 4 bytes\n        address_hash_tmp = hashlib.sha256(self.GetAddress().encode(\"utf-8\")).digest()\n        address_hash_tmp2 = hashlib.sha256(address_hash_tmp).digest()\n        address_hash = address_hash_tmp2[:4]\n\n        # Normalize password and run scrypt over it with the address_hash\n        pwd_normalized = bytes(unicodedata.normalize('NFC', passphrase), 'utf-8')\n        derived = scrypt.hash(pwd_normalized, address_hash,\n                              N=SCRYPT_ITERATIONS,\n                              r=SCRYPT_BLOCKSIZE,\n                              p=SCRYPT_PARALLEL_FACTOR,\n                              buflen=SCRYPT_KEY_LEN_BYTES)\n\n        # Split the scrypt-result into two parts\n        derived1 = derived[:32]\n        derived2 = derived[32:]\n\n        # Run XOR and encrypt the derived parts with AES\n        xor_ed = xor_bytes(bytes(self.PrivateKey), derived1)\n        cipher = AES.new(derived2, AES.MODE_ECB)\n        encrypted = cipher.encrypt(xor_ed)\n\n        # Assemble the final result\n        assembled = bytearray()\n        assembled.extend(NEP_HEADER)\n        assembled.extend(NEP_FLAG)\n        assembled.extend(address_hash)\n        assembled.extend(encrypted)\n\n        # Finally, encode with Base58Check\n        encrypted_key_nep2 = base58.b58encode_check(bytes(assembled))\n        return encrypted_key_nep2.decode(\"utf-8\")", "response": "Exports the encrypted private key in NEP - 2 format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unpack(self, fmt, length=1):\n        return struct.unpack(fmt, self.stream.read(length))[0]", "response": "Unpack the stream contents according to the specified format in fmt."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a single byte from the internal buffer.", "response": "def ReadByte(self, do_ord=True):\n        \"\"\"\n        Read a single byte.\n\n        Args:\n            do_ord (bool): (default True) convert the byte to an ordinal first.\n\n        Returns:\n            bytes: a single byte if successful. 0 (int) if an exception occurred.\n        \"\"\"\n        try:\n            if do_ord:\n                return ord(self.stream.read(1))\n            return self.stream.read(1)\n        except Exception as e:\n            logger.error(\"ord expected character but got none\")\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread exactly length number of bytes from the stream.", "response": "def SafeReadBytes(self, length):\n        \"\"\"\n        Read exactly `length` number of bytes from the stream.\n\n        Raises:\n            ValueError is not enough data\n\n        Returns:\n            bytes: `length` number of bytes\n        \"\"\"\n        data = self.ReadBytes(length)\n        if len(data) < length:\n            raise ValueError(\"Not enough data available\")\n        else:\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ReadVarInt(self, max=sys.maxsize):\n        fb = self.ReadByte()\n        if fb is 0:\n            return fb\n        value = 0\n        if hex(fb) == '0xfd':\n            value = self.ReadUInt16()\n        elif hex(fb) == '0xfe':\n            value = self.ReadUInt32()\n        elif hex(fb) == '0xff':\n            value = self.ReadUInt64()\n        else:\n            value = fb\n\n        if value > max:\n            raise Exception(\"Invalid format\")\n\n        return int(value)", "response": "Reads a variable length integer from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a variable length of bytes from the stream.", "response": "def ReadVarBytes(self, max=sys.maxsize):\n        \"\"\"\n        Read a variable length of bytes from the stream.\n        The NEO network protocol supports encoded storage for space saving. See: http://docs.neo.org/en-us/node/network-protocol.html#convention\n\n        Args:\n            max (int): (Optional) maximum number of bytes to read.\n\n        Returns:\n            bytes:\n        \"\"\"\n        length = self.ReadVarInt(max)\n        return self.ReadBytes(length)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ReadString(self):\n        length = self.ReadUInt8()\n        return self.unpack(str(length) + 's', length)", "response": "Reads a string from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ReadVarString(self, max=sys.maxsize):\n        length = self.ReadVarInt(max)\n        return self.unpack(str(length) + 's', length)", "response": "Similar to ReadString but expects a variable length indicator instead of the fixed 1 byte indicator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads an array of class_name from the stream.", "response": "def ReadSerializableArray(self, class_name, max=sys.maxsize):\n        \"\"\"\n        Deserialize a stream into the object specific by `class_name`.\n\n        Args:\n            class_name (str): a full path to the class to be deserialized into. e.g. 'neo.Core.Block.Block'\n            max (int): (Optional) maximum number of bytes to read.\n\n        Returns:\n            list: list of `class_name` objects deserialized from the stream.\n        \"\"\"\n        module = '.'.join(class_name.split('.')[:-1])\n        klassname = class_name.split('.')[-1]\n        klass = getattr(importlib.import_module(module), klassname)\n        length = self.ReadVarInt(max=max)\n        items = []\n        #        logger.info(\"READING ITEM %s %s \" % (length, class_name))\n        try:\n            for i in range(0, length):\n                item = klass()\n                item.Deserialize(self)\n                #                logger.info(\"deserialized item %s %s \" % ( i, item))\n                items.append(item)\n        except Exception as e:\n            logger.error(\"Couldn't deserialize %s \" % e)\n\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Read2000256List(self):\n        items = []\n        for i in range(0, 2000):\n            data = self.ReadBytes(64)\n            ba = bytearray(binascii.unhexlify(data))\n            ba.reverse()\n            items.append(ba.hex().encode('utf-8'))\n        return items", "response": "Reads 2000 times a 64 byte value from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a list of hash values from the stream.", "response": "def ReadHashes(self):\n        \"\"\"\n        Read Hash values from the stream.\n\n        Returns:\n            list: a list of hash values. Each value is of the bytearray type.\n        \"\"\"\n        len = self.ReadVarInt()\n        items = []\n        for i in range(0, len):\n            ba = bytearray(self.ReadBytes(32))\n            ba.reverse()\n            items.append(ba.hex())\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a byte string to a script hash.", "response": "def ToScriptHash(data, unhex=True):\n        \"\"\"\n        Get a script hash of the data.\n\n        Args:\n            data (bytes): data to hash.\n            unhex (bool): (Default) True. Set to unhexlify the stream. Use when the bytes are not raw bytes; i.e. b'aabb'\n\n        Returns:\n            UInt160: script hash.\n        \"\"\"\n        if len(data) > 1 and unhex:\n            data = binascii.unhexlify(data)\n        return UInt160(data=binascii.unhexlify(bytes(Crypto.Hash160(data), encoding='utf-8')))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsigning the given message with the given private key.", "response": "def Sign(message, private_key):\n        \"\"\"\n        Sign the message with the given private key.\n\n        Args:\n            message (str): message to be signed\n            private_key (str): 32 byte key as a double digit hex string (e.g. having a length of 64)\n        Returns:\n            bytearray: the signature of the message.\n        \"\"\"\n\n        hash = hashlib.sha256(binascii.unhexlify(message)).hexdigest()\n\n        v, r, s = bitcoin.ecdsa_raw_sign(hash, private_key)\n\n        rb = bytearray(r.to_bytes(32, 'big'))\n        sb = bytearray(s.to_bytes(32, 'big'))\n\n        sig = rb + sb\n\n        return sig"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef VerifySignature(message, signature, public_key, unhex=True):\n\n        if type(public_key) is EllipticCurve.ECPoint:\n            pubkey_x = public_key.x.value.to_bytes(32, 'big')\n            pubkey_y = public_key.y.value.to_bytes(32, 'big')\n\n            public_key = pubkey_x + pubkey_y\n\n        if unhex:\n            try:\n                message = binascii.unhexlify(message)\n            except Exception as e:\n                logger.error(\"could not get m: %s\" % e)\n        elif isinstance(message, str):\n            message = message.encode('utf-8')\n\n        if len(public_key) == 33:\n            public_key = bitcoin.decompress(public_key)\n            public_key = public_key[1:]\n\n        try:\n            vk = VerifyingKey.from_string(public_key, curve=NIST256p, hashfunc=hashlib.sha256)\n            res = vk.verify(signature, message, hashfunc=hashlib.sha256)\n            return res\n        except Exception as e:\n            pass\n\n        return False", "response": "Verify the integrity of a message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef VerifySignature(self, message, signature, public_key, unhex=True):\n        return Crypto.VerifySignature(message, signature, public_key, unhex=unhex)", "response": "Verify the integrity of the message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _lucas_sequence(n, P, Q, k):\n    D = P * P - 4 * Q\n    if n < 2:\n        raise ValueError(\"n must be >= 2\")\n    if k < 0:\n        raise ValueError(\"k must be >= 0\")\n    if D == 0:\n        raise ValueError(\"D must not be zero\")\n\n    if k == 0:\n        return 0, 2\n    U = 1\n    V = P\n    Qk = Q\n    b = _bitlength(k)\n    if Q == 1:\n        # For strong tests\n        while b > 1:\n            U = (U * V) % n\n            V = (V * V - 2) % n\n            b -= 1\n            if (k >> (b - 1)) & 1:\n                t = U * D\n                U = U * P + V\n                if U & 1:\n                    U += n\n                U >>= 1\n                V = V * P + t\n                if V & 1:\n                    V += n\n                V >>= 1\n    elif P == 1 and Q == -1:\n        # For Selfridge parameters\n        while b > 1:\n            U = (U * V) % n\n            if Qk == 1:\n                V = (V * V - 2) % n\n            else:\n                V = (V * V + 2) % n\n                Qk = 1\n            b -= 1\n            if (k >> (b - 1)) & 1:\n                t = U * D\n                U = U + V\n                if U & 1:\n                    U += n\n                U >>= 1\n                V = V + t\n                if V & 1:\n                    V += n\n                V >>= 1\n                Qk = -1\n    else:\n        # The general case with any P and Q\n        while b > 1:\n            U = (U * V) % n\n            V = (V * V - 2 * Qk) % n\n            Qk *= Qk\n            b -= 1\n            if (k >> (b - 1)) & 1:\n                t = U * D\n                U = U * P + V\n                if U & 1:\n                    U += n\n                U >>= 1\n                V = V * P + t\n                if V & 1:\n                    V += n\n                V >>= 1\n                Qk *= Q\n            Qk %= n\n    U %= n\n    V %= n\n    return U, V", "response": "Return the modular Lucas sequence given a sequence defined by P Q and k."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the square root modulus p = val", "response": "def sqrt(self, val, flag):\n        \"\"\"\n        calculate the square root modulus p\n        \"\"\"\n        if val.iszero():\n            return val\n        sw = self.p % 8\n        if sw == 3 or sw == 7:\n            res = val ** ((self.p + 1) / 4)\n        elif sw == 5:\n            x = val ** ((self.p + 1) / 4)\n            if x == 1:\n                res = val ** ((self.p + 3) / 8)\n            else:\n                res = (4 * val) ** ((self.p - 5) / 8) * 2 * val\n        else:\n            raise Exception(\"modsqrt non supported for (p%8)==1\")\n\n        if res.value % 2 == flag:\n            return res\n        else:\n            return -res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef value(self, x):\n        return x if isinstance(x, FiniteField.Value) and x.field == self else FiniteField.Value(self, x)", "response": "Converts an integer or FinitField. Value to a value of this FiniteField. Value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a plain integer", "response": "def integer(self, x):\n        \"\"\"\n        returns a plain integer\n        \"\"\"\n        if type(x) is str:\n            hex = binascii.unhexlify(x)\n            return int.from_bytes(hex, 'big')\n\n        return x.value if isinstance(x, FiniteField.Value) else x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform elliptic curve addition", "response": "def add(self, p, q):\n        \"\"\"\n        perform elliptic curve addition\n        \"\"\"\n        if p.iszero():\n            return q\n        if q.iszero():\n            return p\n\n        lft = 0\n        # calculate the slope of the intersection line\n        if p == q:\n            if p.y == 0:\n                return self.zero()\n            lft = (3 * p.x ** 2 + self.a) / (2 * p.y)\n        elif p.x == q.x:\n            return self.zero()\n        else:\n            lft = (p.y - q.y) / (p.x - q.x)\n\n        # calculate the intersection point\n        x = lft ** 2 - (p.x + q.x)\n        y = lft * (p.x - x) - p.y\n        return self.point(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the additive identity point", "response": "def zero(self):\n        \"\"\"\n        Return the additive identity point ( aka '0' )\n        P + 0 = P\n        \"\"\"\n        return self.point(self.field.zero(), self.field.zero())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef point(self, x, y):\n        return EllipticCurve.ECPoint(self, self.field.value(x), self.field.value(y))", "response": "construct a point from 2 values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying if a point is on the curve", "response": "def isoncurve(self, p):\n        \"\"\"\n        verifies if a point is on the curve\n        \"\"\"\n        return p.iszero() or p.y ** 2 == p.x ** 3 + self.a * p.x + self.b"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decompress(self, x, flag):\n        x = self.field.value(x)\n        ysquare = x ** 3 + self.a * x + self.b\n\n        return self.point(x, ysquare.sqrt(flag))", "response": "calculate the y coordinate given only the x value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecompress the y coordinate given only the x value.", "response": "def decompress_from_curve(self, x, flag):\n        \"\"\"\n        calculate the y coordinate given only the x value.\n        there are 2 possible solutions, use 'flag' to select.\n        \"\"\"\n\n        cq = self.field.p\n        x = self.field.value(x)\n\n        ysquare = x ** 3 + self.a * x + self.b\n\n        ysquare_root = sqrtCQ(ysquare.value, cq)\n\n        bit0 = 0\n        if ysquare_root % 2 is not 0:\n            bit0 = 1\n\n        if bit0 != flag:\n            beta = (cq - ysquare_root) % cq\n        else:\n            beta = ysquare_root\n\n        return self.point(x, beta)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsigns the message using private key and sign secret for signsecret k message m privatekey x privatekey x return the sign of the message", "response": "def sign(self, message, privkey, secret):\n        \"\"\"\n        sign the message using private key and sign secret\n        for signsecret k, message m, privatekey x\n        return (G*k,  (m+x*r)/k)\n        \"\"\"\n        m = self.GFn.value(message)\n        x = self.GFn.value(privkey)\n        k = self.GFn.value(secret)\n\n        R = self.G * k\n\n        r = self.GFn.value(R.x)\n        s = (m + x * r) / k\n\n        return (r, s)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(self, message, pubkey, rnum, snum):\n        m = self.GFn.value(message)\n        r = self.GFn.value(rnum)\n        s = self.GFn.value(snum)\n\n        R = self.G * (m / s) + pubkey * (r / s)\n\n        # alternative methods of verifying\n        # RORG= self.ec.decompress(r, 0)\n        # RR = self.G * m + pubkey * r\n        # print \"#1: %s .. %s\"  % (RR, RORG*s)\n        # print \"#2: %s .. %s\"  % (RR*(1/s), r)\n        # print \"#3: %s .. %s\"  % (R, r)\n\n        return R.x == r", "response": "Verify the signature\n            for message m pubkey Y rnum and snum."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind pubkey Y from message rnum snum flag", "response": "def findpk(self, message, rnum, snum, flag):\n        \"\"\"\n        find pubkey Y from message m, signature (r,s)\n        Y = (R*s-G*m)/r\n        note that there are 2 pubkeys related to a signature\n        \"\"\"\n        m = self.GFn.value(message)\n        r = self.GFn.value(rnum)\n        s = self.GFn.value(snum)\n\n        R = self.ec.decompress(r, flag)\n\n        # return (R*s - self.G * m)*(1/r)\n        return R * (s / r) - self.G * (m / r)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef findpk2(self, r1, s1, r2, s2, flag1, flag2):\n        R1 = self.ec.decompress(r1, flag1)\n        R2 = self.ec.decompress(r2, flag2)\n\n        rdiff = self.GFn.value(r1 - r2)\n\n        return (R1 * s1 - R2 * s2) * (1 / rdiff)", "response": "find pubkey Y from 2 different signatures on the same message"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncracks returns the signsecret and privkey of the duplicate message m1 and m2.", "response": "def crack2(self, r, s1, s2, m1, m2):\n        \"\"\"\n        find signsecret and privkey from duplicate 'r'\n        signature (r,s1) for message m1\n        and signature (r,s2) for message m2\n        s1= (m1 + x*r)/k\n        s2= (m2 + x*r)/k\n        subtract -> (s1-s2) = (m1-m2)/k  ->  k = (m1-m2)/(s1-s2)\n        -> privkey =  (s1*k-m1)/r  .. or  (s2*k-m2)/r\n        \"\"\"\n        sdelta = self.GFn.value(s1 - s2)\n        mdelta = self.GFn.value(m1 - m2)\n\n        secret = mdelta / sdelta\n        x1 = self.crack1(r, s1, m1, secret)\n        x2 = self.crack1(r, s2, m2, secret)\n\n        if x1 != x2:\n            logger.info(\"x1= %s\" % x1)\n            logger.info(\"x2= %s\" % x2)\n\n        return (secret, x1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds privkey given signsecret k message m signature rnum snum", "response": "def crack1(self, rnum, snum, message, signsecret):\n        \"\"\"\n        find privkey, given signsecret k, message m, signature (r,s)\n        x= (s*k-m)/r\n        \"\"\"\n        m = self.GFn.value(message)\n        r = self.GFn.value(rnum)\n        s = self.GFn.value(snum)\n        k = self.GFn.value(signsecret)\n        return (s * k - m) / r"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef secp256r1():\n        GFp = FiniteField(int(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF\", 16))\n        ec = EllipticCurve(GFp, 115792089210356248762697446949407573530086143415290314195533631308867097853948, 41058363725152142129326129780047268409114441015993725554835256314039467401291)\n        # return ECDSA(GFp, ec.point(0x6B17D1F2E12C4247F8BCE6E563A440F277037D812DEB33A0F4A13945D898C296,0x4FE342E2FE1A7F9B8EE7EB4A7C0F9E162BCE33576B315ECECBB6406837BF51F5),int(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFC\", 16))\n        return ECDSA(ec,\n                     ec.point(0x6B17D1F2E12C4247F8BCE6E563A440F277037D812DEB33A0F4A13945D898C296, 0x4FE342E2FE1A7F9B8EE7EB4A7C0F9E162BCE33576B315ECECBB6406837BF51F5),\n                     GFp)", "response": "create the secp256r1 curve"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding a string of length 16 using the secp256r1 curve.", "response": "def decode_secp256r1(str, unhex=True, check_on_curve=True):\n        \"\"\"\n        decode a public key on the secp256r1 curve\n        \"\"\"\n\n        GFp = FiniteField(int(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF\", 16))\n        ec = EllipticCurve(GFp, 115792089210356248762697446949407573530086143415290314195533631308867097853948,\n                           41058363725152142129326129780047268409114441015993725554835256314039467401291)\n\n        point = ec.decode_from_hex(str, unhex=unhex)\n\n        if check_on_curve:\n            if point.isoncurve():\n                return ECDSA(GFp, point, int(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFC\", 16))\n            else:\n                raise Exception(\"Could not decode string\")\n\n        return ECDSA(GFp, point, int(\"FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFC\", 16))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the secp256k1 curve", "response": "def secp256k1():\n        \"\"\"\n        create the secp256k1 curve\n        \"\"\"\n        GFp = FiniteField(2 ** 256 - 2 ** 32 - 977)  # This is P from below... aka FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F\n        ec = EllipticCurve(GFp, 0, 7)\n        return ECDSA(ec, ec.point(0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798, 0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8), 2 ** 256 - 432420386565659656852420866394968145599)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetHashCode(self):\n        slice_length = 4 if len(self.Data) >= 4 else len(self.Data)\n        return int.from_bytes(self.Data[:slice_length], 'little')", "response": "Get the hash code of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef isValidPublicAddress(address: str) -> bool:\n    valid = False\n\n    if len(address) == 34 and address[0] == 'A':\n        try:\n            base58.b58decode_check(address.encode())\n            valid = True\n        except ValueError:\n            # checksum mismatch\n            valid = False\n\n    return valid", "response": "Check if the given address is a valid NEO address"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __Build(leaves):\n        if len(leaves) < 1:\n            raise Exception('Leaves must have length')\n        if len(leaves) == 1:\n            return leaves[0]\n\n        num_parents = int((len(leaves) + 1) / 2)\n        parents = [MerkleTreeNode() for i in range(0, num_parents)]\n\n        for i in range(0, num_parents):\n            node = parents[i]\n            node.LeftChild = leaves[i * 2]\n            leaves[i * 2].Parent = node\n            if (i * 2 + 1 == len(leaves)):\n                node.RightChild = node.LeftChild\n            else:\n                node.RightChild = leaves[i * 2 + 1]\n                leaves[i * 2 + 1].Parent = node\n\n            hasharray = bytearray(node.LeftChild.Hash.ToArray() + node.RightChild.Hash.ToArray())\n            node.Hash = UInt256(data=Crypto.Hash256(hasharray))\n\n        return MerkleTree.__Build(parents)", "response": "Builds the merkle tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ComputeRoot(hashes):\n        if not len(hashes):\n            raise Exception('Hashes must have length')\n        if len(hashes) == 1:\n            return hashes[0]\n\n        tree = MerkleTree(hashes)\n        return tree.Root.Hash", "response": "Compute the root hash from a list of hashes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __DepthFirstSearch(node, hashes):\n        if node.LeftChild is None:\n            hashes.add(node.Hash)\n        else:\n            MerkleTree.__DepthFirstSearch(node.LeftChild, hashes)\n            MerkleTree.__DepthFirstSearch(node.RightChild, hashes)", "response": "Internal helper method.\n\n        Args:\n            node (MerkleTreeNode):\n            hashes (list): each item is a bytearray."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nturn the tree into a list of hashes.", "response": "def ToHashArray(self):\n        \"\"\"\n        Turn the tree into a list of hashes.\n\n        Returns:\n            list:\n        \"\"\"\n        hashes = set()\n        MerkleTree.__DepthFirstSearch(self.Root, hashes)\n        return list(hashes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Trim(self, flags):\n        logger.info(\"Trimming!\")\n        flags = bytearray(flags)\n        length = 1 << self.Depth - 1\n        while len(flags) < length:\n            flags.append(0)\n\n        MerkleTree._TrimNode(self.Root, 0, self.Depth, flags)", "response": "Trim the nodes from the tree keeping only the root hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _TrimNode(node, index, depth, flags):\n        if depth == 1 or node.LeftChild is None:\n            return\n\n        if depth == 2:\n            if not flags[index * 2] and not flags[index * 2 + 1]:\n                node.LeftChild = None\n                node.RightChild = None\n\n        else:\n\n            MerkleTree._TrimNode(node.LeftChild, index * 2, depth - 1, flags)\n            MerkleTree._TrimNode(node.RightChild, index * 2, depth - 1, flags)\n\n            if node.LeftChild.LeftChild is None and node.RightChild.RightChild is None:\n                node.LeftChild = None\n                node.RightChild = None", "response": "Internal helper method to trim a node from the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms two SHA256 operations on the input.", "response": "def double_sha256(ba):\n    \"\"\"\n    Perform two SHA256 operations on the input.\n\n    Args:\n        ba (bytes): data to hash.\n\n    Returns:\n        str: hash as a double digit hex string.\n    \"\"\"\n    d1 = hashlib.sha256(ba)\n    d2 = hashlib.sha256()\n    d1.hexdigest()\n    d2.update(d1.digest())\n    return d2.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a scripthash to a public address.", "response": "def scripthash_to_address(scripthash):\n    \"\"\"\n    Convert a script hash to a public address.\n\n    Args:\n        scripthash (bytes):\n\n    Returns:\n        str: base58 encoded string representing the wallet address.\n    \"\"\"\n    sb = bytearray([ADDRESS_VERSION]) + scripthash\n    c256 = bin_dbl_sha256(sb)[0:4]\n    outb = sb + bytearray(c256)\n    return base58.b58encode(bytes(outb)).decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bin_hash160Bytes(bts):\n    intermed = hashlib.sha256(bts).digest()\n    return hashlib.new('ripemd160', intermed).digest()", "response": "Get a hash of the provided message using the ripemd160 algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bin_hash160(string):\n    intermed = hashlib.sha256(string).digest()\n    return hashlib.new('ripemd160', intermed).hexdigest()", "response": "Get a hash of the provided string using the ripemd160 algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef base256_encode(n, minwidth=0):  # int/long to byte array\n    if n > 0:\n        arr = []\n        while n:\n            n, rem = divmod(n, 256)\n            arr.append(rem)\n        b = bytearray(reversed(arr))\n    elif n == 0:\n        b = bytearray(b'\\x00')\n    else:\n        raise ValueError(\"Negative numbers not supported\")\n\n    if minwidth > 0 and len(b) < minwidth:  # zero padding needed?\n        padding = (minwidth - len(b)) * b'\\x00'\n        b = bytearray(padding) + b\n    b.reverse()\n\n    return b", "response": "Encode the input with base256."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a bytes array to the stream.", "response": "def WriteBytes(self, value, unhex=True):\n        \"\"\"\n        Write a `bytes` type to the stream.\n\n        Args:\n            value (bytes): array of bytes to write to the stream.\n            unhex (bool): (Default) True. Set to unhexlify the stream. Use when the bytes are not raw bytes; i.e. b'aabb'\n\n        Returns:\n            int: the number of bytes written.\n        \"\"\"\n        if unhex:\n            try:\n                value = binascii.unhexlify(value)\n            except binascii.Error:\n                pass\n        return self.stream.write(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack(self, fmt, data):\n        return self.WriteBytes(struct.pack(fmt, data), unhex=False)", "response": "Writes bytes by packing them according to the provided format string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef WriteUInt160(self, value):\n        if type(value) is UInt160:\n            value.Serialize(self)\n        else:\n            raise Exception(\"value must be UInt160 instance \")", "response": "Writes an UInt160 type to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a UInt256 type to the stream.", "response": "def WriteUInt256(self, value):\n        \"\"\"\n        Write a UInt256 type to the stream.\n\n        Args:\n            value (UInt256):\n\n        Raises:\n            Exception: when `value` is not of neocore.UInt256 type.\n        \"\"\"\n        if type(value) is UInt256:\n            value.Serialize(self)\n        else:\n            raise Exception(\"Cannot write value that is not UInt256\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WriteVarBytes(self, value, endian=\"<\"):\n        length = len(value)\n        self.WriteVarInt(length, endian)\n\n        return self.WriteBytes(value, unhex=False)", "response": "Writes a variable size integer value to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a variable size string to the stream.", "response": "def WriteVarString(self, value, encoding=\"utf-8\"):\n        \"\"\"\n        Write a string value to the stream.\n        Read more about variable size encoding here: http://docs.neo.org/en-us/node/network-protocol.html#convention\n\n        Args:\n            value (string): value to write to the stream.\n            encoding (str): string encoding format.\n        \"\"\"\n        if type(value) is str:\n            value = value.encode(encoding)\n\n        length = len(value)\n        ba = bytearray(value)\n        byts = binascii.hexlify(ba)\n        string = byts.decode(encoding)\n        self.WriteVarInt(length)\n        self.WriteBytes(string)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a fixed length string to the stream.", "response": "def WriteFixedString(self, value, length):\n        \"\"\"\n        Write a string value to the stream.\n\n        Args:\n            value (str): value to write to the stream.\n            length (int): length of the string to write.\n        \"\"\"\n        towrite = value.encode('utf-8')\n        slen = len(towrite)\n        if slen > length:\n            raise Exception(\"string longer than fixed length: %s \" % length)\n        self.WriteBytes(towrite)\n        diff = length - slen\n\n        while diff > 0:\n            self.WriteByte(0)\n            diff -= 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef WriteSerializableArray(self, array):\n        if array is None:\n            self.WriteByte(0)\n        else:\n            self.WriteVarInt(len(array))\n            for item in array:\n                item.Serialize(self)", "response": "Writes an array of serializable objects to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite an array of 2000 256 items to the stream.", "response": "def Write2000256List(self, arr):\n        \"\"\"\n        Write an array of 64 byte items to the stream.\n\n        Args:\n            arr (list): a list of 2000 items of 64 bytes in size.\n        \"\"\"\n        for item in arr:\n            ba = bytearray(binascii.unhexlify(item))\n            ba.reverse()\n            self.WriteBytes(ba)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef WriteHashes(self, arr):\n        length = len(arr)\n        self.WriteVarInt(length)\n        for item in arr:\n            ba = bytearray(binascii.unhexlify(item))\n            ba.reverse()\n            #            logger.info(\"WRITING HASH %s \" % ba)\n            self.WriteBytes(ba)", "response": "Writes a 32 byte hash array to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the identifier for a user", "response": "def get_user_id(self, user):\n        \"\"\" Get identifier for a user. Take the one defined in settings.SAML_IDP_DJANGO_USERNAME_FIELD first, if not set\n            use the USERNAME_FIELD property which is set on the user Model. This defaults to the user.username field.\n        \"\"\"\n        user_field = getattr(settings, 'SAML_IDP_DJANGO_USERNAME_FIELD', None) or \\\n                     getattr(user, 'USERNAME_FIELD', 'username')\n        return str(getattr(user, user_field))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_identity(self, user, sp_mapping, **extra_config):\n\n        return {\n            out_attr: getattr(user, user_attr)\n            for user_attr, out_attr in sp_mapping.items()\n            if hasattr(user, user_attr)\n        }", "response": "Generate an identity dictionary of the user based on the given mapping of desired user attributes by the SP\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sso_entry(request):\n    if request.method == 'POST':\n        passed_data = request.POST\n        binding = BINDING_HTTP_POST\n    else:\n        passed_data = request.GET\n        binding = BINDING_HTTP_REDIRECT\n\n    request.session['Binding'] = binding\n\n    try:\n        request.session['SAMLRequest'] = passed_data['SAMLRequest']\n    except (KeyError, MultiValueDictKeyError) as e:\n        return HttpResponseBadRequest(e)\n    request.session['RelayState'] = passed_data.get('RelayState', '')\n    # TODO check how the redirect saml way works. Taken from example idp in pysaml2.\n    if \"SigAlg\" in passed_data and \"Signature\" in passed_data:\n        request.session['SigAlg'] = passed_data['SigAlg']\n        request.session['Signature'] = passed_data['Signature']\n    return HttpResponseRedirect(reverse('djangosaml2idp:saml_login_process'))", "response": "Entrypoint view for SSO."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef metadata(request):\n    conf = IdPConfig()\n    conf.load(copy.deepcopy(settings.SAML_IDP_CONFIG))\n    metadata = entity_descriptor(conf)\n    return HttpResponse(content=text_type(metadata).encode('utf-8'), content_type=\"text/xml; charset=utf8\")", "response": "Returns an XML with the SAML 2. 0 metadata for this Idp."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs IDP server with config from settings dict", "response": "def dispatch(self, request, *args, **kwargs):\n        \"\"\" Construct IDP server with config from settings dict\n        \"\"\"\n        conf = IdPConfig()\n        try:\n            conf.load(copy.deepcopy(settings.SAML_IDP_CONFIG))\n            self.IDP = Server(config=conf)\n        except Exception as e:\n            return self.handle_error(request, exception=e)\n        return super(IdPHandlerViewMixin, self).dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate Identity dict using SP - specific mapping", "response": "def get_identity(self, processor, user, sp_config):\n        \"\"\" Create Identity dict (using SP-specific mapping)\n        \"\"\"\n        sp_mapping = sp_config.get('attribute_mapping', {'username': 'username'})\n        return processor.create_identity(user, sp_mapping, **sp_config.get('extra_config', {}))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefault behaviour does not play nice with booleans encoded in SAML as u'true'/u'false'. This will convert those attributes to real booleans when saving.", "response": "def custom_update_user(sender, instance, attributes, user_modified, **kargs):\n    \"\"\" Default behaviour does not play nice with booleans encoded in SAML as u'true'/u'false'.\n        This will convert those attributes to real booleans when saving.\n    \"\"\"\n    for k, v in attributes.items():\n        u = set.intersection(set(v), set([u'true', u'false']))\n        if u:\n            setattr(instance, k, u.pop() == u'true')\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_time(s):\n    result = None\n\n    if \"epoch\" in s:\n        epoch_time = float(s.rstrip().split(' ')[1][:-1])\n        result = datetime.datetime.utcfromtimestamp(epoch_time)\n    else:\n        _, date_part, time_part = s.split(' ')\n        year, mon, day = date_part.split('/')\n        hour, minute, sec = time_part.split(':')\n        result = datetime.datetime(*map(int, (year, mon, day, hour, minute, sec)))\n\n    return result", "response": "Parse a time string into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the key value - tuple from a string like foobar 123", "response": "def _extract_prop_option(line):\n    \"\"\"\n    Extract the (key,value)-tuple from a string like:\n    >>> \"option foobar 123\"\n    :param line:\n    :return: tuple (key, value)\n    \"\"\"\n    line = line[7:]\n    pos = line.find(' ')\n    return line[:pos], line[pos + 1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the key value - tuple from a string like set foo = bar >>>", "response": "def _extract_prop_set(line):\n    \"\"\"\n    Extract the (key, value)-tuple from a string like:\n    >>> 'set foo = \"bar\"'\n    :param line:\n    :return: tuple (key, value)\n    \"\"\"\n    token = ' = \"'\n    line = line[4:]\n    pos = line.find(token)\n    return line[:pos], line[pos + 4:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a line within a lease block and return a tuple of properties options sets and general.", "response": "def _extract_properties(config):\n    \"\"\"\n    Parse a line within a lease block\n    The line should basically match the expression:\n    >>> r\"\\s+(?P<key>(?:option|set)\\s+\\S+|\\S+) (?P<value>[\\s\\S]+?);\"\n    For easier seperation of the cases and faster parsing this is done using substrings etc..\n    :param config:\n    :return: tuple of properties dict, options dict and sets dict\n    \"\"\"\n    general, options, sets = {}, {}, {}\n    for line in config.splitlines():\n\n        # skip empty & malformed lines\n        if not line or not line[-1:] == ';' and '; #' not in line:\n            continue\n\n        # strip the trailing ';' and remove any whitespaces on the left side\n        line = line[:-1].lstrip()\n\n        # seperate the three cases\n        if line[:6] == 'option':\n            key, value = _extract_prop_option(line)\n            options[key] = value\n\n        elif line[:3] == 'set':\n            key, value = _extract_prop_set(line)\n            sets[key] = value\n\n        else:\n            # fall through to generic case\n            key, value = _extract_prop_general(line)\n            general[key] = value\n\n    return general, options, sets"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the lease file and return a list of Lease instances.", "response": "def get(self, include_backups=False):\n        \"\"\"\n        Parse the lease file and return a list of Lease instances.\n        \"\"\"\n        leases = []\n        with open(self.filename) if not self.gzip else gzip.open(self.filename) as lease_file:\n            lease_data = lease_file.read()\n            if self.gzip:\n                lease_data = lease_data.decode('utf-8')\n            for match in self.regex_leaseblock.finditer(lease_data):\n                block = match.groupdict()\n\n                properties, options, sets = _extract_properties(block['config'])\n\n                if 'hardware' not in properties and not include_backups:\n                    # E.g. rows like {'binding': 'state abandoned', ...}\n                    continue\n                lease = Lease(block['ip'], properties=properties, options=options, sets=sets)\n                leases.append(lease)\n\n            for match in self.regex_leaseblock6.finditer(lease_data):\n                block = match.groupdict()\n                properties, options, sets = _extract_properties(block['config'])\n\n                host_identifier = block['id']\n                block_type = block['type']\n                last_client_communication = parse_time(properties['cltt'])\n\n                for address_block in self.regex_iaaddr.finditer(block['config']):\n                    block = address_block.groupdict()\n                    properties, options, sets = _extract_properties(block['config'])\n\n                    lease = Lease6(block['ip'], properties, last_client_communication, host_identifier, block_type,\n                                   options=options, sets=sets)\n                    leases.append(lease)\n\n        return leases"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the lease file and return a dict of active and valid Lease instances.", "response": "def get_current(self):\n        \"\"\"\n        Parse the lease file and return a dict of active and valid Lease instances.\n        The key for this dict is the ethernet address of the lease.\n        \"\"\"\n        all_leases = self.get()\n        leases = {}\n        for lease in all_leases:\n            if lease.valid and lease.active:\n                if type(lease) is Lease:\n                    leases[lease.ethernet] = lease\n                elif type(lease) is Lease6:\n                    leases['%s-%s' % (lease.type, lease.host_identifier_string)] = lease\n        return leases"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef valid(self):\n        if self.end is None:\n            if self.start is not None:\n                return self.start <= datetime.datetime.utcnow()\n            else:\n                return True\n        else:\n            if self.start is not None:\n                return self.start <= datetime.datetime.utcnow() <= self.end\n            else:\n                return datetime.datetime.utcnow() <= self.end", "response": "Checks if the lease is currently valid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the lease is currently valid", "response": "def valid(self):\n        \"\"\"\n        Checks if the lease is currently valid (not expired)\n        :return: bool: True if lease is valid\n        \"\"\"\n        if self.end is None:\n            return True\n        else:\n            return datetime.datetime.utcnow() <= self.end"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _padleft(width, s, has_invisible=True):\n\n    def impl(val):\n        iwidth = width + len(val) - len(_strip_invisible(val)) if has_invisible else width\n        fmt = \"{0:>%ds}\" % iwidth\n        return fmt.format(val)\n\n    num_lines = s.splitlines()\n    return len(num_lines) > 1 and '\\n'.join(map(impl, num_lines)) or impl(s)", "response": "Pads a string to the left with the given width."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _visible_width(s):\n    if isinstance(s, _text_type) or isinstance(s, _binary_type):\n        return _max_line_width(_strip_invisible(s))\n    else:\n        return _max_line_width(_text_type(s))", "response": "Return the visible width of a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _normalize_tabular_data(tabular_data, headers):\n\n    if hasattr(tabular_data, \"keys\") and hasattr(tabular_data, \"values\"):\n        # dict-like and pandas.DataFrame?\n        if hasattr(tabular_data.values, \"__call__\"):\n            # likely a conventional dict\n            keys = tabular_data.keys()\n            rows = list(izip_longest(*tabular_data.values()))  # columns have to be transposed\n        elif hasattr(tabular_data, \"index\"):\n            # values is a property, has .index => it's likely a pandas.DataFrame (pandas 0.11.0)\n            keys = tabular_data.keys()\n            vals = tabular_data.values  # values matrix doesn't need to be transposed\n            names = tabular_data.index\n            rows = [[v] + list(row) for v, row in zip(names, vals)]\n        else:\n            raise ValueError(\"tabular data doesn't appear to be a dict or a DataFrame\")\n\n        if headers == \"keys\":\n            headers = list(map(_text_type, keys))  # headers should be strings\n\n    else:  # it's a usual an iterable of iterables, or a NumPy array\n        rows = list(tabular_data)\n\n        if (headers == \"keys\" and\n                hasattr(tabular_data, \"dtype\") and\n                getattr(tabular_data.dtype, \"names\")):\n            # numpy record array\n            headers = tabular_data.dtype.names\n        elif (headers == \"keys\"\n              and len(rows) > 0\n              and isinstance(rows[0], tuple)\n              and hasattr(rows[0], \"_fields\")):\n            # namedtuple\n            headers = list(map(_text_type, rows[0]._fields))\n        elif (len(rows) > 0\n              and isinstance(rows[0], dict)):\n            # dict or OrderedDict\n            uniq_keys = set()  # implements hashed lookup\n            keys = []  # storage for set\n            if headers == \"firstrow\":\n                firstdict = rows[0] if len(rows) > 0 else {}\n                keys.extend(firstdict.keys())\n                uniq_keys.update(keys)\n                rows = rows[1:]\n            for row in rows:\n                for k in row.keys():\n                    # Save unique items in input order\n                    if k not in uniq_keys:\n                        keys.append(k)\n                        uniq_keys.add(k)\n            if headers == 'keys':\n                headers = keys\n            elif isinstance(headers, dict):\n                # a dict of headers for a list of dicts\n                headers = [headers.get(k, k) for k in keys]\n                headers = list(map(_text_type, headers))\n            elif headers == \"firstrow\":\n                if len(rows) > 0:\n                    headers = [firstdict.get(k, k) for k in keys]\n                    headers = list(map(_text_type, headers))\n                else:\n                    headers = []\n            elif headers:\n                raise ValueError('headers for a list of dicts is not a dict or a keyword')\n            rows = [[row.get(k) for k in keys] for row in rows]\n        elif headers == \"keys\" and len(rows) > 0:\n            # keys are column indices\n            headers = list(map(_text_type, range(len(rows[0]))))\n\n    # take headers from the first row if necessary\n    if headers == \"firstrow\" and len(rows) > 0:\n        headers = list(map(_text_type, rows[0]))  # headers should be strings\n        rows = rows[1:]\n\n    headers = list(map(_text_type, headers))\n    rows = list(map(list, rows))\n\n    # pad with empty headers for initial columns if necessary\n    if headers and len(rows) > 0:\n        nhs = len(headers)\n        ncols = len(rows[0])\n        if nhs < ncols:\n            headers = [\"\"] * (ncols - nhs) + headers\n\n    return rows, headers", "response": "Transform a supported data type to a list of lists and a list of headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tabulate(tabular_data, headers=(), tablefmt=\"simple\",\n             floatfmt=\"g\", numalign=\"decimal\", stralign=\"left\",\n             missingval=\"\"):\n    \"\"\"Format a fixed width table for pretty printing.\n\n    >>> print(tabulate([[1, 2.34], [-56, \"8.999\"], [\"2\", \"10001\"]]))\n    ---  ---------\n      1      2.34\n    -56      8.999\n      2  10001\n    ---  ---------\n\n    The first required argument (`tabular_data`) can be a\n    list-of-lists (or another iterable of iterables), a list of named\n    tuples, a dictionary of iterables, an iterable of dictionaries,\n    a two-dimensional NumPy array, NumPy record array, or a Pandas'\n    dataframe.\n\n\n    Table headers\n    -------------\n\n    To print nice column headers, supply the second argument (`headers`):\n\n      - `headers` can be an explicit list of column headers\n      - if `headers=\"firstrow\"`, then the first row of data is used\n      - if `headers=\"keys\"`, then dictionary keys or column indices are used\n\n    Otherwise a headerless table is produced.\n\n    If the number of headers is less than the number of columns, they\n    are supposed to be names of the last columns. This is consistent\n    with the plain-text format of R and Pandas' dataframes.\n\n    >>> print(tabulate([[\"sex\",\"age\"],[\"Alice\",\"F\",24],[\"Bob\",\"M\",19]],\n    ...       headers=\"firstrow\"))\n           sex      age\n    -----  -----  -----\n    Alice  F         24\n    Bob    M         19\n\n\n    Column alignment\n    ----------------\n\n    `tabulate` tries to detect column types automatically, and aligns\n    the values properly. By default it aligns decimal points of the\n    numbers (or flushes integer numbers to the right), and flushes\n    everything else to the left. Possible column alignments\n    (`numalign`, `stralign`) are: \"right\", \"center\", \"left\", \"decimal\"\n    (only for `numalign`), and None (to disable alignment).\n\n\n    Table formats\n    -------------\n\n    `floatfmt` is a format specification used for columns which\n    contain numeric data with a decimal point.\n\n    `None` values are replaced with a `missingval` string:\n\n    >>> print(tabulate([[\"spam\", 1, None],\n    ...                 [\"eggs\", 42, 3.14],\n    ...                 [\"other\", None, 2.7]], missingval=\"?\"))\n    -----  --  ----\n    spam    1  ?\n    eggs   42  3.14\n    other   ?  2.7\n    -----  --  ----\n\n    Various plain-text table formats (`tablefmt`) are supported:\n    'plain', 'simple', 'grid', 'pipe', 'orgtbl', 'rst', 'mediawiki',\n     'latex', and 'latex_booktabs'. Variable `tabulate_formats` contains the list of\n    currently supported formats.\n\n    \"plain\" format doesn't use any pseudographics to draw tables,\n    it separates columns with a double space:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                 [\"strings\", \"numbers\"], \"plain\"))\n    strings      numbers\n    spam         41.9999\n    eggs        451\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"plain\"))\n    spam   41.9999\n    eggs  451\n\n    \"simple\" format is like Pandoc simple_tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                 [\"strings\", \"numbers\"], \"simple\"))\n    strings      numbers\n    ---------  ---------\n    spam         41.9999\n    eggs        451\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"simple\"))\n    ----  --------\n    spam   41.9999\n    eggs  451\n    ----  --------\n\n    \"grid\" is similar to tables produced by Emacs table.el package or\n    Pandoc grid_tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"grid\"))\n    +-----------+-----------+\n    | strings   |   numbers |\n    +===========+===========+\n    | spam      |   41.9999 |\n    +-----------+-----------+\n    | eggs      |  451      |\n    +-----------+-----------+\n\n    >>> print(tabulate([[\"this\\\\nis\\\\na multiline\\\\ntext\", \"41.9999\", \"foo\\\\nbar\"], [\"NULL\", \"451.0\", \"\"]],\n    ...                [\"text\", \"numbers\", \"other\"], \"grid\"))\n    +-------------+----------+-------+\n    | text        |  numbers | other |\n    +=============+==========+=======+\n    | this        |  41.9999 | foo   |\n    | is          |          | bar   |\n    | a multiline |          |       |\n    | text        |          |       |\n    +-------------+----------+-------+\n    | NULL        | 451      |       |\n    +-------------+----------+-------+\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"grid\"))\n    +------+----------+\n    | spam |  41.9999 |\n    +------+----------+\n    | eggs | 451      |\n    +------+----------+\n\n    \"fancy_grid\" draws a grid using box-drawing characters:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"fancy_grid\"))\n    \u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n    \u2502 strings   \u2502   numbers \u2502\n    \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    \u2502 spam      \u2502   41.9999 \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 eggs      \u2502  451      \u2502\n    \u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\n    \"pipe\" is like tables in PHP Markdown Extra extension or Pandoc\n    pipe_tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"pipe\"))\n    | strings   |   numbers |\n    |:----------|----------:|\n    | spam      |   41.9999 |\n    | eggs      |  451      |\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"pipe\"))\n    |:-----|---------:|\n    | spam |  41.9999 |\n    | eggs | 451      |\n\n    \"orgtbl\" is like tables in Emacs org-mode and orgtbl-mode. They\n    are slightly different from \"pipe\" format by not using colons to\n    define column alignment, and using a \"+\" sign to indicate line\n    intersections:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"orgtbl\"))\n    | strings   |   numbers |\n    |-----------+-----------|\n    | spam      |   41.9999 |\n    | eggs      |  451      |\n\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"orgtbl\"))\n    | spam |  41.9999 |\n    | eggs | 451      |\n\n    \"rst\" is like a simple table format from reStructuredText; please\n    note that reStructuredText accepts also \"grid\" tables:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                [\"strings\", \"numbers\"], \"rst\"))\n    =========  =========\n    strings      numbers\n    =========  =========\n    spam         41.9999\n    eggs        451\n    =========  =========\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"rst\"))\n    ====  ========\n    spam   41.9999\n    eggs  451\n    ====  ========\n\n    \"mediawiki\" produces a table markup used in Wikipedia and on other\n    MediaWiki-based sites:\n\n    >>> print(tabulate([[\"strings\", \"numbers\"], [\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                headers=\"firstrow\", tablefmt=\"mediawiki\"))\n    {| class=\"wikitable\" style=\"text-align: left;\"\n    |+ <!-- caption -->\n    |-\n    ! strings   !! align=\"right\"|   numbers\n    |-\n    | spam      || align=\"right\"|   41.9999\n    |-\n    | eggs      || align=\"right\"|  451\n    |}\n\n    \"html\" produces HTML markup:\n\n    >>> print(tabulate([[\"strings\", \"numbers\"], [\"spam\", 41.9999], [\"eggs\", \"451.0\"]],\n    ...                headers=\"firstrow\", tablefmt=\"html\"))\n    <table>\n    <tr><th>strings  </th><th style=\"text-align: right;\">  numbers</th></tr>\n    <tr><td>spam     </td><td style=\"text-align: right;\">  41.9999</td></tr>\n    <tr><td>eggs     </td><td style=\"text-align: right;\"> 451     </td></tr>\n    </table>\n\n    \"latex\" produces a tabular environment of LaTeX document markup:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"latex\"))\n    \\\\begin{tabular}{lr}\n    \\\\hline\n     spam &  41.9999 \\\\\\\\\n     eggs & 451      \\\\\\\\\n    \\\\hline\n    \\\\end{tabular}\n\n    \"latex_booktabs\" produces a tabular environment of LaTeX document markup\n    using the booktabs.sty package:\n\n    >>> print(tabulate([[\"spam\", 41.9999], [\"eggs\", \"451.0\"]], tablefmt=\"latex_booktabs\"))\n    \\\\begin{tabular}{lr}\n    \\\\toprule\n     spam &  41.9999 \\\\\\\\\n     eggs & 451      \\\\\\\\\n    \\\\bottomrule\n    \\end{tabular}\n    \"\"\"\n    if tabular_data is None:\n        tabular_data = []\n    list_of_lists, headers = _normalize_tabular_data(tabular_data, headers)\n    \n    # optimization: look for ANSI control codes once,\n    # enable smart width functions only if a control code is found\n    plain_text = '\\n'.join(['\\t'.join(map(_text_type, headers))] + \\\n                           ['\\t'.join(map(_text_type, row)) for row in list_of_lists])\n\n    has_invisible = re.search(_invisible_codes, plain_text)\n    enable_widechars = wcwidth is not None and WIDE_CHARS_MODE\n    is_multiline = _is_multiline(plain_text)\n    width_fn = _choose_width_fn(has_invisible, enable_widechars, is_multiline)\n\n    # format rows and columns, convert numeric values to strings\n    cols = list(zip(*list_of_lists))\n    coltypes = list(map(_column_type, cols))\n    cols = [[_format(v, ct, floatfmt, missingval, has_invisible) for v in c]\n            for c, ct in zip(cols, coltypes)]\n\n    # align columns\n    aligns = [numalign if ct in [int, float] else stralign for ct in coltypes]\n    minwidths = [width_fn(h) + MIN_PADDING for h in headers] if headers else [0] * len(cols)\n    cols = [_align_column(c, a, minw, has_invisible, enable_widechars, is_multiline)\n            for c, a, minw in zip(cols, aligns, minwidths)]\n\n    if headers:\n        # align headers and add headers\n        t_cols = cols or [['']] * len(headers)\n        t_aligns = aligns or [stralign] * len(headers)\n        minwidths = [max(minw, width_fn(c[0])) for minw, c in zip(minwidths, t_cols)]\n        headers = [_align_header(h, a, minw, width_fn(h), enable_widechars, is_multiline)\n                   for h, a, minw in zip(headers, t_aligns, minwidths)]\n        rows = list(zip(*cols))\n    else:\n        minwidths = [width_fn(c[0]) for c in cols]\n        rows = list(zip(*cols))\n    \n    if not isinstance(tablefmt, TableFormat):\n        tablefmt = _table_formats.get(tablefmt, _table_formats[\"simple\"])\n\n    return _format_table(tablefmt, headers, rows, minwidths, aligns, is_multiline)", "response": "Format a table of data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproducing a plain - text representation of the table.", "response": "def _format_table(fmt, headers, rows, colwidths, colaligns, is_multiline):\n    \"\"\"Produce a plain-text representation of the table.\"\"\"\n    lines = []\n    hidden = fmt.with_header_hide if (headers and fmt.with_header_hide) else []\n    pad = fmt.padding\n    headerrow = fmt.headerrow\n\n    padded_widths = [(w + 2 * pad) for w in colwidths]\n    if is_multiline:\n        pad_row = lambda row, _: row  # do it later, in _append_multiline_row\n        append_row = partial(_append_multiline_row, pad=pad)\n    else:\n        pad_row = _pad_row\n        append_row = _append_basic_row\n\n    padded_headers = pad_row(headers, pad)\n    padded_rows = [pad_row(row, pad) for row in rows]\n\n    if fmt.lineabove and \"lineabove\" not in hidden:\n        _append_line(lines, padded_widths, colaligns, fmt.lineabove)\n\n    if padded_headers:\n        append_row(lines, padded_headers, padded_widths, colaligns, headerrow)\n        if fmt.linebelowheader and \"linebelowheader\" not in hidden:\n            _append_line(lines, padded_widths, colaligns, fmt.linebelowheader)\n\n    if padded_rows and fmt.linebetweenrows and \"linebetweenrows\" not in hidden:\n        # initial rows with a line below\n        for row in padded_rows[:-1]:\n            append_row(lines, row, padded_widths, colaligns, fmt.datarow)\n            _append_line(lines, padded_widths, colaligns, fmt.linebetweenrows)\n        # the last row without a line below\n        append_row(lines, padded_rows[-1], padded_widths, colaligns, fmt.datarow)\n    else:\n        for row in padded_rows:\n            append_row(lines, row, padded_widths, colaligns, fmt.datarow)\n\n    if fmt.linebelow and \"linebelow\" not in hidden:\n        _append_line(lines, padded_widths, colaligns, fmt.linebelow)\n\n    return \"\\n\".join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_layout(lexer=None,\n                  reserve_space_for_menu=8,\n                  get_prompt_tokens=None,\n                  get_bottom_toolbar_tokens=None,\n                  extra_input_processors=None, multiline=False,\n                  wrap_lines=True):\n    \"\"\"\n    Creates a custom `Layout` for the Crash input REPL\n\n    This layout includes:\n        * a bottom left-aligned session toolbar container\n        * a bottom right-aligned side-bar container\n\n    +-------------------------------------------+\n    | cr> select 1;                             |\n    |                                           |\n    |                                           |\n    +-------------------------------------------+\n    | bottom_toolbar_tokens      sidebar_tokens |\n    +-------------------------------------------+\n    \"\"\"\n\n    # Create processors list.\n    input_processors = [\n        ConditionalProcessor(\n            # Highlight the reverse-i-search buffer\n            HighlightSearchProcessor(preview_search=True),\n            HasFocus(SEARCH_BUFFER)),\n    ]\n\n    if extra_input_processors:\n        input_processors.extend(extra_input_processors)\n\n    lexer = PygmentsLexer(lexer, sync_from_start=True)\n    multiline = to_cli_filter(multiline)\n\n    sidebar_token = [\n        (Token.Toolbar.Status.Key, \"[ctrl+d]\"),\n        (Token.Toolbar.Status, \" Exit\")\n    ]\n    sidebar_width = token_list_width(sidebar_token)\n\n    get_sidebar_tokens = lambda _: sidebar_token\n\n    def get_height(cli):\n        # If there is an autocompletion menu to be shown, make sure that our\n        # layout has at least a minimal height in order to display it.\n        if reserve_space_for_menu and not cli.is_done:\n            buff = cli.current_buffer\n\n            # Reserve the space, either when there are completions, or when\n            # `complete_while_typing` is true and we expect completions very\n            # soon.\n            if buff.complete_while_typing() or buff.complete_state is not None:\n                return LayoutDimension(min=reserve_space_for_menu)\n\n        return LayoutDimension()\n\n    # Create and return Container instance.\n    return HSplit([\n        VSplit([\n            HSplit([\n                # The main input, with completion menus floating on top of it.\n                FloatContainer(\n                    HSplit([\n                        Window(\n                            BufferControl(\n                                input_processors=input_processors,\n                                lexer=lexer,\n                                # enable preview search for reverse-i-search\n                                preview_search=True),\n                            get_height=get_height,\n                            wrap_lines=wrap_lines,\n                            left_margins=[\n                                # In multiline mode, use the window margin to display\n                                # the prompt and continuation tokens.\n                                ConditionalMargin(\n                                    PromptMargin(get_prompt_tokens),\n                                    filter=multiline\n                                )\n                            ],\n                        ),\n                    ]),\n                    [\n                        # Completion menu\n                        Float(xcursor=True,\n                              ycursor=True,\n                              content=CompletionsMenu(\n                                  max_height=16,\n                                  scroll_offset=1,\n                                  extra_filter=HasFocus(DEFAULT_BUFFER))\n                              ),\n                    ]\n                ),\n\n                # reverse-i-search toolbar (ctrl+r)\n                ConditionalContainer(SearchToolbar(), multiline),\n            ])\n        ]),\n    ] + [\n        VSplit([\n            # Left-Aligned Session Toolbar\n            ConditionalContainer(\n                Window(\n                    TokenListControl(get_bottom_toolbar_tokens),\n                    height=LayoutDimension.exact(1)\n                ),\n                filter=~IsDone() & RendererHeightIsKnown()),\n\n            # Right-Aligned Container\n            ConditionalContainer(\n                Window(\n                    TokenListControl(get_sidebar_tokens),\n                    height=LayoutDimension.exact(1),\n                    width=LayoutDimension.exact(sidebar_width)\n                ),\n                filter=~IsDone() & RendererHeightIsKnown())\n        ])\n    ])", "response": "Create a custom layout for the Crash input."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_config_path(args=sys.argv):\n\n    config = CONFIG_PATH\n    if '--config' in args:\n        idx = args.index('--config')\n        if len(args) > idx + 1:\n            config = args.pop(idx + 1)\n        args.pop(idx)\n    return config", "response": "Extract the config path from sys. argv and extract the first argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an argument parser that reads default values from a configuration file.", "response": "def get_parser(output_formats=[], conf=None):\n    \"\"\"\n    Create an argument parser that reads default values from a\n    configuration file if provided.\n    \"\"\"\n\n    def _conf_or_default(key, value):\n        return value if conf is None else conf.get_or_set(key, value)\n\n    parser = ArgumentParser(description='crate shell')\n    parser.add_argument('-v', '--verbose', action='count',\n                        dest='verbose', default=_conf_or_default('verbosity', 0),\n                        help='print debug information to STDOUT')\n    parser.add_argument('-A', '--no-autocomplete', action='store_false',\n                        dest='autocomplete',\n                        default=_conf_or_default('autocomplete', True),\n                        help='disable SQL keywords autocompletion')\n    parser.add_argument('-a', '--autocapitalize', action='store_true',\n                        dest='autocapitalize',\n                        default=False,\n                        help='enable automatic capitalization of SQL keywords while typing')\n    parser.add_argument('-U', '--username', type=str, metavar='USERNAME',\n                        help='Authenticate as USERNAME.')\n    parser.add_argument('-W', '--password', action='store_true',\n                        dest='force_passwd_prompt', default=_conf_or_default('force_passwd_prompt', False),\n                        help='force a password prompt')\n    parser.add_argument('--schema', type=str,\n                        help='default schema for statements if schema is not explicitly stated in queries')\n    parser.add_argument('--history', type=str, metavar='FILENAME',\n                        help='Use FILENAME as a history file', default=HISTORY_PATH)\n    parser.add_argument('--config', type=str, metavar='FILENAME',\n                        help='use FILENAME as a configuration file', default=CONFIG_PATH)\n\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('-c', '--command', type=str, metavar='STATEMENT',\n                       help='Execute the STATEMENT and exit.')\n    group.add_argument('--sysinfo', action='store_true', default=False,\n                       help='print system and cluster information')\n\n    parser.add_argument('--hosts', type=str, nargs='*',\n                        default=_conf_or_default('hosts', ['localhost:4200']),\n                        help='connect to HOSTS.', metavar='HOSTS')\n    parser.add_argument('--verify-ssl', type=boolean, default=True,\n                        help='force the verification of the server SSL certificate')\n    parser.add_argument('--cert-file', type=file_with_permissions, metavar='FILENAME',\n                        help='use FILENAME as the client certificate file')\n    parser.add_argument('--key-file', type=file_with_permissions, metavar='FILENAME',\n                        help='Use FILENAME as the client certificate key file')\n    parser.add_argument('--ca-cert-file', type=file_with_permissions, metavar='FILENAME',\n                        help='use FILENAME as the CA certificate file')\n    parser.add_argument('--format', type=str,\n                        default=_conf_or_default('format', 'tabular'),\n                        choices=output_formats, metavar='FORMAT',\n                        help='the output FORMAT of the SQL response')\n    parser.add_argument('--version', action='store_true', default=False,\n                        help='print the Crash version and exit')\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a generator of statements that can be used to parse a list of lines.", "response": "def _parse_statements(lines):\n    \"\"\"Return a generator of statements\n\n    Args: A list of strings that can contain one or more statements.\n          Statements are separated using ';' at the end of a line\n          Everything after the last ';' will be treated as the last statement.\n\n    >>> list(_parse_statements(['select * from ', 't1;', 'select name']))\n    ['select * from\\\\nt1', 'select name']\n\n    >>> list(_parse_statements(['select * from t1;', '  ']))\n    ['select * from t1']\n    \"\"\"\n    lines = (l.strip() for l in lines if l)\n    lines = (l for l in lines if l and not l.startswith('--'))\n    parts = []\n    for line in lines:\n        parts.append(line.rstrip(';'))\n        if line.endswith(';'):\n            yield '\\n'.join(parts)\n            parts[:] = []\n    if parts:\n        yield '\\n'.join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef host_and_port(host_or_port):\n    if ':' in host_or_port:\n        if len(host_or_port) == 1:\n            return 'localhost:4200'\n        elif host_or_port.startswith(':'):\n            return 'localhost' + host_or_port\n        return host_or_port\n    return host_or_port + ':4200'", "response": "Return full hostname + IP + port"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow the existing tables within the doc schema", "response": "def _show_tables(self, *args):\n        \"\"\" print the existing tables within the 'doc' schema \"\"\"\n        v = self.connection.lowest_server_version\n        schema_name = \\\n            \"table_schema\" if v >= TABLE_SCHEMA_MIN_VERSION else \"schema_name\"\n        table_filter = \\\n            \" AND table_type = 'BASE TABLE'\" if v >= TABLE_TYPE_MIN_VERSION else \"\"\n\n        self._exec(\"SELECT format('%s.%s', {schema}, table_name) AS name \"\n                   \"FROM information_schema.tables \"\n                   \"WHERE {schema} NOT IN ('sys','information_schema', 'pg_catalog')\"\n                   \"{table_filter}\"\n                   .format(schema=schema_name, table_filter=table_filter))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _connect(self, servers):\n        self._do_connect(servers.split(' '))\n        self._verify_connection(verbose=True)", "response": "connect to the given servers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self):\n        if not self.cmd.is_conn_available():\n            return\n        if self.cmd.connection.lowest_server_version >= SYSINFO_MIN_VERSION:\n            success, rows = self._sys_info()\n            self.cmd.exit_code = self.cmd.exit_code or int(not success)\n            if success:\n                for result in rows:\n                    self.cmd.pprint(result.rows, result.cols)\n                self.cmd.logger.info(\n                    \"For debugging purposes you can send above listed information to support@crate.io\")\n        else:\n            tmpl = 'Crate {version} does not support the cluster \"sysinfo\" command'\n            self.cmd.logger.warn(tmpl\n                                 .format(version=self.cmd.connection.lowest_server_version))", "response": "Execute the sysinfo command and print system and cluster info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bwc_bool_transform_from(cls, x):\n        if x.lower() == 'true':\n            return True\n        elif x.lower() == 'false':\n            return False\n        return bool(int(x))", "response": "Read boolean values from old config files correctly interpret True and False as correct booleans."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _transform_field(field):\n    if isinstance(field, bool):\n        return TRUE if field else FALSE\n    elif isinstance(field, (list, dict)):\n        return json.dumps(field, sort_keys=True, ensure_ascii=False)\n    else:\n        return field", "response": "transform field for displaying"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef script():\n    parser = argparse.ArgumentParser(description=\"Print all textual tags of one or more audio files.\")\n    parser.add_argument(\"-b\", \"--batch\", help=\"disable user interaction\", action=\"store_true\")\n    parser.add_argument(\"file\", nargs=\"+\", help=\"file(s) to print tags of\")\n    args = parser.parse_args()\n    for filename in args.file:\n        if isinstance(filename, bytes):\n            filename = filename.decode(sys.getfilesystemencoding())\n        line = \"TAGS OF '{0}'\".format(os.path.basename(filename))\n        print(\"*\" * len(line))\n        print(line)\n        print(\"*\" * len(line))\n        audioFile = taglib.File(filename)\n        tags = audioFile.tags\n        if len(tags) > 0:\n            maxKeyLen = max(len(key) for key in tags.keys())\n            for key, values in tags.items():\n                for value in values:\n                    print(('{0:' + str(maxKeyLen) + '} = {1}').format(key, value))\n        if len(audioFile.unsupported) > 0:\n            print('Unsupported tag elements: ' + \"; \".join(audioFile.unsupported))\n            if sys.version_info[0] == 2:\n                inputFunction = raw_input\n            else:\n                inputFunction = input\n            if not args.batch and inputFunction(\"remove unsupported properties? [yN] \").lower() in [\"y\", \"yes\"]:\n                audioFile.removeUnsupportedProperties(audioFile.unsupported)\n                audioFile.save()", "response": "Runs the command - line script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrigger a software reset of the SeeSaw chip.", "response": "def sw_reset(self):\n        \"\"\"Trigger a software reset of the SeeSaw chip\"\"\"\n        self.write8(_STATUS_BASE, _STATUS_SWRST, 0xFF)\n        time.sleep(.500)\n\n        chip_id = self.read8(_STATUS_BASE, _STATUS_HW_ID)\n\n        if chip_id != _HW_ID_CODE:\n            raise RuntimeError(\"Seesaw hardware ID returned (0x{:x}) is not \"\n                               \"correct! Expected 0x{:x}. Please check your wiring.\"\n                               .format(chip_id, _HW_ID_CODE))\n\n        pid = self.get_version() >> 16\n        if pid == _CRICKIT_PID:\n            from adafruit_seesaw.crickit import Crickit_Pinmap\n            self.pin_mapping = Crickit_Pinmap\n        elif pid == _ROBOHATMM1_PID:\n            from adafruit_seesaw.robohat import MM1_Pinmap\n            self.pin_mapping = MM1_Pinmap\n        else:\n            from adafruit_seesaw.samd09 import SAMD09_Pinmap\n            self.pin_mapping = SAMD09_Pinmap"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_default_cache_dir(self):\n\n        return os.path.join(os.path.dirname(__file__), self._DATA_DIR)", "response": "Returns default cache directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_default_cache_file_path(self):\n\n        default_list_path = os.path.join(\n            self._get_default_cache_dir(), self._CACHE_FILE_NAME)\n\n        if not os.access(default_list_path, os.F_OK):\n            raise CacheFileError(\n                \"Default cache file does not exist \"\n                \"'{}'!\".format(default_list_path)\n            )\n\n        return default_list_path", "response": "Returns default cache file path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_writable_cache_dir(self):\n        dir_path_data = self._get_default_cache_dir()\n\n        if os.access(dir_path_data, os.W_OK):\n            self._default_cache_file = True\n            return dir_path_data\n\n        dir_path_user = user_cache_dir(self._URLEXTRACT_NAME)\n        if not os.path.exists(dir_path_user):\n            os.makedirs(dir_path_user, exist_ok=True)\n\n        if os.access(dir_path_user, os.W_OK):\n            return dir_path_user\n\n        dir_path_temp = tempfile.gettempdir()\n        if os.access(dir_path_temp, os.W_OK):\n            return dir_path_temp\n\n        raise CacheFileError(\"Cache directories are not writable.\")", "response": "Get writable cache directory with fallback to user s cache directory\n        and global temp directory\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets path to the cache file with TLDs.", "response": "def _get_cache_file_path(self, cache_dir=None):\n        \"\"\"\n        Get path for cache file\n\n        :param str cache_dir: base path for TLD cache, defaults to data dir\n        :raises: CacheFileError when cached directory is not writable for user\n        :return: Full path to cached file with TLDs\n        :rtype: str\n        \"\"\"\n        if cache_dir is None:\n            # Tries to get writable cache dir with fallback to users data dir\n            # and temp directory\n            cache_dir = self._get_writable_cache_dir()\n        else:\n            if not os.access(cache_dir, os.W_OK):\n                raise CacheFileError(\"None of cache directories is writable.\")\n\n        # get directory for cached file\n        return os.path.join(cache_dir, self._CACHE_FILE_NAME)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions downloads list of TLDs from IANA.", "response": "def _download_tlds_list(self):\n        \"\"\"\n        Function downloads list of TLDs from IANA.\n        LINK: https://data.iana.org/TLD/tlds-alpha-by-domain.txt\n\n        :return: True if list was downloaded, False in case of an error\n        :rtype: bool\n        \"\"\"\n        url_list = 'https://data.iana.org/TLD/tlds-alpha-by-domain.txt'\n\n        # Default cache file exist (set by _default_cache_file)\n        # and we want to write permission\n        if self._default_cache_file and \\\n                not os.access(self._tld_list_path, os.W_OK):\n            self._logger.info(\"Default cache file is not writable.\")\n            self._tld_list_path = self._get_cache_file_path()\n            self._logger.info(\n                \"Changed path of cache file to: %s\",\n                self._tld_list_path\n            )\n\n        if os.access(self._tld_list_path, os.F_OK) and \\\n                not os.access(self._tld_list_path, os.W_OK):\n            self._logger.error(\"ERROR: Cache file is not writable for current \"\n                               \"user. ({})\".format(self._tld_list_path))\n            return False\n\n        req = urllib.request.Request(url_list)\n        req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.0; '\n                                     'WOW64; rv:24.0) Gecko/20100101 '\n                                     'Firefox/24.0')\n        with open(self._tld_list_path, 'w') as ftld:\n            try:\n                with urllib.request.urlopen(req) as f:\n                    page = f.read().decode('utf-8')\n                    ftld.write(page)\n            except HTTPError as e:\n                self._logger.error(\"ERROR: Can not download list ot TLDs. \"\n                                   \"(HTTPError: {})\".format(e.reason))\n                return False\n            except URLError as e:\n                self._logger.error(\"ERROR: Can not download list ot TLDs. \"\n                                   \"(URLError: {})\".format(e.reason))\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload TLDs from cached file to set.", "response": "def _load_cached_tlds(self):\n        \"\"\"\n        Loads TLDs from cached file to set.\n\n        :return: Set of current TLDs\n        :rtype: set\n        \"\"\"\n\n        # check if cached file is readable\n        if not os.access(self._tld_list_path, os.R_OK):\n            self._logger.error(\"Cached file is not readable for current \"\n                               \"user. ({})\".format(self._tld_list_path))\n            raise CacheFileError(\n                \"Cached file is not readable for current user.\"\n            )\n\n        set_of_tlds = set()\n        with open(self._tld_list_path, 'r') as f_cache_tld:\n            for line in f_cache_tld:\n                tld = line.strip().lower()\n                # skip empty lines\n                if not tld:\n                    continue\n                # skip comments\n                if tld[0] == '#':\n                    continue\n\n                set_of_tlds.add(\".\" + tld)\n                set_of_tlds.add(\".\" + idna.decode(tld))\n\n        return set_of_tlds"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_last_cachefile_modification(self):\n\n        try:\n            mtime = os.path.getmtime(self._tld_list_path)\n        except OSError:\n            return None\n\n        return datetime.fromtimestamp(mtime)", "response": "Get last modification of cache file with TLDs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _urlextract_cli():\n    import argparse\n\n    def get_args():\n        \"\"\"\n        Parse programs arguments\n        \"\"\"\n        parser = argparse.ArgumentParser(\n            description='urlextract - prints out all URLs that were '\n                        'found in input file or stdin based on locating '\n                        'their TLDs')\n\n        ver = URLExtract.get_version()\n        parser.add_argument(\"-v\", \"--version\", action=\"version\",\n                            version='%(prog)s - version {}'.format(ver))\n\n        parser.add_argument(\n            \"-u\", \"--unique\", dest='unique', action='store_true',\n            help='print out only unique URLs found in file.')\n\n        parser.add_argument(\n            'input_file', nargs='?', metavar='<input_file>',\n            type=argparse.FileType(encoding=\"UTF-8\"), default=sys.stdin,\n            help='input text file with URLs to extract. [UTF-8]')\n\n        parsed_args = parser.parse_args()\n        return parsed_args\n\n    args = get_args()\n    logging.basicConfig(\n        level=logging.INFO, stream=sys.stderr,\n        format='%(asctime)s - %(levelname)s (%(name)s): %(message)s')\n    logger = logging.getLogger('urlextract')\n\n    try:\n        urlextract = URLExtract()\n        urlextract.update_when_older(30)\n        content = args.input_file.read()\n        for url in urlextract.find_urls(content, args.unique):\n            print(url)\n    except CacheFileError as e:\n        logger.error(str(e))\n        sys.exit(-1)\n    finally:\n        args.input_file.close()", "response": "A command line interface for the urlextract command line interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_after_tld_chars(self):\n        after_tld_chars = set(string.whitespace)\n        after_tld_chars |= {'/', '\\\"', '\\'', '<', '>', '?', ':', '.', ','}\n        # get left enclosure characters\n        _, right_enclosure = zip(*self._enclosure)\n        # add right enclosure characters to be valid after TLD\n        # for correct parsing of URL e.g. (example.com)\n        after_tld_chars |= set(right_enclosure)\n\n        return after_tld_chars", "response": "Initialize after tld characters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reload_tlds_from_file(self):\n\n        tlds = sorted(self._load_cached_tlds(), key=len, reverse=True)\n        re_escaped = [re.escape(str(tld)) for tld in tlds]\n        self._tlds_re = re.compile('|'.join(re_escaped))", "response": "Reloads TLDs from file and compile regexp."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the TLD list cache file if the list is older than the given number of days.", "response": "def update_when_older(self, days):\n        \"\"\"\n        Update TLD list cache file if the list is older than\n        number of days given in parameter `days` or if does not exist.\n\n        :param int days: number of days from last change\n        :return: True if update was successful, False otherwise\n        :rtype: bool\n        \"\"\"\n\n        last_cache = self._get_last_cachefile_modification()\n        if last_cache is None:\n            return self.update()\n\n        time_to_update = last_cache + timedelta(days=days)\n\n        if datetime.now() >= time_to_update:\n            return self.update()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_stop_chars(self, stop_chars):\n\n        warnings.warn(\"Method set_stop_chars is deprecated, \"\n                      \"use `set_stop_chars_left` or \"\n                      \"`set_stop_chars_right` instead\", DeprecationWarning)\n        self._stop_chars = set(stop_chars)\n        self._stop_chars_left = self._stop_chars\n        self._stop_chars_right = self._stop_chars", "response": "Set stop characters used when determining end of URL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_stop_chars_left(self, stop_chars):\n        if not isinstance(stop_chars, set):\n            raise TypeError(\"stop_chars should be type set \"\n                            \"but {} was given\".format(type(stop_chars)))\n\n        self._stop_chars_left = stop_chars\n        self._stop_chars = self._stop_chars_left | self._stop_chars_right", "response": "Sets stop characters for text on left from TLD."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_enclosure(self, left_char, right_char):\n        assert len(left_char) == 1, \\\n            \"Parameter left_char must be character not string\"\n        assert len(right_char) == 1, \\\n            \"Parameter right_char must be character not string\"\n        self._enclosure.add((left_char, right_char))\n\n        self._after_tld_chars = self._get_after_tld_chars()", "response": "Add new enclosure pair of characters. That and should be removed\n        when they are detected at beginning and end of found URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove enclosure pair from set of enclosures.", "response": "def remove_enclosure(self, left_char, right_char):\n        \"\"\"\n        Remove enclosure pair from set of enclosures.\n\n        :param str left_char: left character of enclosure pair - e.g. \"(\"\n        :param str right_char: right character of enclosure pair - e.g. \")\"\n        \"\"\"\n        assert len(left_char) == 1, \\\n            \"Parameter left_char must be character not string\"\n        assert len(right_char) == 1, \\\n            \"Parameter right_char must be character not string\"\n        rm_enclosure = (left_char, right_char)\n        if rm_enclosure in self._enclosure:\n            self._enclosure.remove(rm_enclosure)\n\n        self._after_tld_chars = self._get_after_tld_chars()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _complete_url(self, text, tld_pos, tld):\n\n        left_ok = True\n        right_ok = True\n\n        max_len = len(text) - 1\n        end_pos = tld_pos\n        start_pos = tld_pos\n        while left_ok or right_ok:\n            if left_ok:\n                if start_pos <= 0:\n                    left_ok = False\n                else:\n                    if text[start_pos - 1] not in self._stop_chars_left:\n                        start_pos -= 1\n                    else:\n                        left_ok = False\n            if right_ok:\n                if end_pos >= max_len:\n                    right_ok = False\n                else:\n                    if text[end_pos + 1] not in self._stop_chars_right:\n                        end_pos += 1\n                    else:\n                        right_ok = False\n\n        complete_url = text[start_pos:end_pos + 1].lstrip('/')\n        # remove last character from url\n        # when it is allowed character right after TLD (e.g. dot, comma)\n        temp_tlds = {tld + c for c in self._after_tld_chars}\n        # get only dot+tld+one_char and compare\n        if complete_url[len(complete_url)-len(tld)-1:] in temp_tlds:\n            complete_url = complete_url[:-1]\n\n        complete_url = self._split_markdown(complete_url, tld_pos-start_pos)\n        complete_url = self._remove_enclosure_from_url(\n            complete_url, tld_pos-start_pos, tld)\n        if not self._is_domain_valid(complete_url, tld):\n            return \"\"\n\n        return complete_url", "response": "Expand string in both sides to match whole URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate TLD match - tells if at found position is really TLD.", "response": "def _validate_tld_match(self, text, matched_tld, tld_pos):\n        \"\"\"\n        Validate TLD match - tells if at found position is really TLD.\n\n        :param str text: text where we want to find URLs\n        :param str matched_tld: matched TLD\n        :param int tld_pos: position of matched TLD\n        :return: True if match is valid, False otherwise\n        :rtype: bool\n        \"\"\"\n        if tld_pos > len(text):\n            return False\n\n        right_tld_pos = tld_pos + len(matched_tld)\n        if len(text) > right_tld_pos:\n            if text[right_tld_pos] in self._after_tld_chars:\n                if tld_pos > 0 and text[tld_pos - 1] \\\n                        not in self._stop_chars_left:\n                    return True\n        else:\n            if tld_pos > 0 and text[tld_pos - 1] not in self._stop_chars_left:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _is_domain_valid(self, url, tld):\n\n        if not url:\n            return False\n\n        scheme_pos = url.find('://')\n        if scheme_pos == -1:\n            url = 'http://' + url\n\n        url_parts = uritools.urisplit(url)\n        # <scheme>://<authority>/<path>?<query>#<fragment>\n\n        try:\n            host = url_parts.gethost()\n        except ValueError:\n            self._logger.info(\n                \"Invalid host '%s'. \"\n                \"If the host is valid report a bug.\", url\n            )\n            return False\n\n        if not host:\n            return False\n\n        host_parts = host.split('.')\n        if len(host_parts) <= 1:\n            return False\n\n        host_tld = '.'+host_parts[-1]\n        if host_tld != tld:\n            return False\n\n        top = host_parts[-2]\n\n        if self._hostname_re.match(top) is None:\n            return False\n\n        return True", "response": "Checks if given URL has valid domain name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_enclosure_from_url(self, text_url, tld_pos, tld):\n\n        enclosure_map = {\n            left_char: right_char\n            for left_char, right_char in self._enclosure\n        }\n        # get position of most right left_char of enclosure pairs\n        left_pos = max([\n            text_url.rfind(left_char, 0, tld_pos)\n            for left_char in enclosure_map.keys()\n        ])\n        left_char = text_url[left_pos] if left_pos >= 0 else ''\n        right_char = enclosure_map.get(left_char, '')\n        right_pos = text_url.rfind(right_char) if right_char else len(text_url)\n        if right_pos < 0 or right_pos < tld_pos:\n            right_pos = len(text_url)\n\n        new_url = text_url[left_pos + 1:right_pos]\n        tld_pos -= left_pos + 1\n\n        # Get valid domain when we have input as: example.com)/path\n        # we assume that if there is enclosure character after TLD it is\n        # the end URL it self therefore we remove the rest\n        after_tld_pos = tld_pos + len(tld)\n        if after_tld_pos < len(new_url):\n            if new_url[after_tld_pos] in enclosure_map.values():\n                new_url_tmp = new_url[:after_tld_pos]\n                return self._remove_enclosure_from_url(\n                    new_url_tmp, tld_pos, tld)\n\n        return new_url", "response": "This method removes enclosure characters from given URL given in text_url."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _split_markdown(text_url, tld_pos):\n        # Markdown url can looks like:\n        # [http://example.com/](http://example.com/status/210)\n\n        left_bracket_pos = text_url.find('[')\n        # subtract 3 because URL is never shorter than 3 characters\n        if left_bracket_pos > tld_pos-3:\n            return text_url\n\n        right_bracket_pos = text_url.find(')')\n        if right_bracket_pos < tld_pos:\n            return text_url\n\n        middle_pos = text_url.rfind(\"](\")\n        if middle_pos > tld_pos:\n            return text_url[left_bracket_pos+1:middle_pos]\n        return text_url", "response": "Split Markdown URL into two lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a generator over found URLs in given text.", "response": "def gen_urls(self, text):\n        \"\"\"\n        Creates generator over found URLs in given text.\n\n        :param str text: text where we want to find URLs\n        :yields: URL found in text or empty string if no found\n        :rtype: str\n        \"\"\"\n        tld_pos = 0\n        matched_tlds = self._tlds_re.findall(text)\n\n        for tld in matched_tlds:\n            tmp_text = text[tld_pos:]\n            offset = tld_pos\n            tld_pos = tmp_text.find(tld)\n            validated = self._validate_tld_match(text, tld, offset + tld_pos)\n            if tld_pos != -1 and validated:\n                tmp_url = self._complete_url(text, offset + tld_pos, tld)\n                if tmp_url:\n                    yield tmp_url\n\n                    # do not search for TLD in already extracted URL\n                    tld_pos_url = tmp_url.find(tld)\n                    # move cursor right after found TLD\n                    tld_pos += len(tld) + offset\n                    # move cursor after end of found URL\n                    tld_pos += len(tmp_url[tld_pos_url+len(tld):])\n                    continue\n\n            # move cursor right after found TLD\n            tld_pos += len(tld) + offset"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_urls(self, text, only_unique=False):\n        urls = self.gen_urls(text)\n        urls = OrderedDict.fromkeys(urls) if only_unique else urls\n        return list(urls)", "response": "Find all URLs in given text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef possibly_award(self, **state):\n        assert \"user\" in state\n        if self.async:\n            from .tasks import AsyncBadgeAward\n            state = self.freeze(**state)\n            AsyncBadgeAward.delay(self, state)\n            return\n        self.actually_possibly_award(**state)", "response": "Checks if the user should be awarded a badge."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef actually_possibly_award(self, **state):\n        user = state[\"user\"]\n        force_timestamp = state.pop(\"force_timestamp\", None)\n        awarded = self.award(**state)\n        if awarded is None:\n            return\n        if awarded.level is None:\n            assert len(self.levels) == 1\n            awarded.level = 1\n        # awarded levels are 1 indexed, for conveineince\n        awarded = awarded.level - 1\n        assert awarded < len(self.levels)\n        if (\n            not self.multiple and\n            BadgeAward.objects.filter(user=user, slug=self.slug, level=awarded)\n        ):\n            return\n        extra_kwargs = {}\n        if force_timestamp is not None:\n            extra_kwargs[\"awarded_at\"] = force_timestamp\n        badge = BadgeAward.objects.create(\n            user=user,\n            slug=self.slug,\n            level=awarded,\n            **extra_kwargs\n        )\n        self.send_badge_messages(badge)\n        badge_awarded.send(sender=self, badge_award=badge)", "response": "Does the actual work of possibly awarding a badge."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends the badge messages to the user who just has just been awarded the badge.", "response": "def send_badge_messages(self, badge_award):\n        \"\"\"\n        If the Badge class defines a message, send it to the user who was just\n        awarded the badge.\n        \"\"\"\n        user_message = getattr(badge_award.badge, \"user_message\", None)\n        if callable(user_message):\n            message = user_message(badge_award)\n        else:\n            message = user_message\n        if message is not None:\n            badge_award.user.message_set.create(message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_lockfile(self):\n        process = subprocess.Popen(\n            self.pin_command,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n        stdout, stderr = process.communicate()\n        if process.returncode == 0:\n            self.fix_lockfile()\n        else:\n            logger.critical(\"ERROR executing %s\", ' '.join(self.pin_command))\n            logger.critical(\"Exit code: %s\", process.returncode)\n            logger.critical(stdout.decode('utf-8'))\n            logger.critical(stderr.decode('utf-8'))\n            raise RuntimeError(\"Failed to pip-compile {0}\".format(self.infile))", "response": "Create a lockfile for the current version of the current entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the file and return a set of all the file names that are referenced by the file.", "response": "def parse_references(cls, filename):\n        \"\"\"\n        Read filename line by line searching for pattern:\n\n        -r file.in\n        or\n        --requirement file.in\n\n        return set of matched file names without extension.\n        E.g. ['file']\n        \"\"\"\n        references = set()\n        for line in open(filename):\n            matched = cls.RE_REF.match(line)\n            if matched:\n                reference = matched.group('path')\n                reference_base = os.path.splitext(reference)[0]\n                references.add(reference_base)\n        return references"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pin_command(self):\n        parts = [\n            'pip-compile',\n            '--no-header',\n            '--verbose',\n            '--rebuild',\n            '--no-index',\n            '--output-file', self.outfile,\n            self.infile,\n        ]\n        if OPTIONS['upgrade']:\n            parts.insert(3, '--upgrade')\n        if self.add_hashes:\n            parts.insert(1, '--generate-hashes')\n        return parts", "response": "Compose pip - compile shell command"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning each line of outfile through fix_pin", "response": "def fix_lockfile(self):\n        \"\"\"Run each line of outfile through fix_pin\"\"\"\n        with open(self.outfile, 'rt') as fp:\n            lines = [\n                self.fix_pin(line)\n                for line in self.concatenated(fp)\n            ]\n        with open(self.outfile, 'wt') as fp:\n            fp.writelines([\n                line + '\\n'\n                for line in lines\n                if line is not None\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread lines from fp concatenating on backslash \\\\", "response": "def concatenated(fp):\n        \"\"\"Read lines from fp concatenating on backslash (\\\\)\"\"\"\n        line_parts = []\n        for line in fp:\n            line = line.strip()\n            if line.endswith('\\\\'):\n                line_parts.append(line[:-1].rstrip())\n            else:\n                line_parts.append(line)\n                yield ' '.join(line_parts)\n                line_parts[:] = []\n        if line_parts:\n            # Impossible:\n            raise RuntimeError(\"Compiled file ends with backslash \\\\\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix_pin(self, line):\n        dep = Dependency(line)\n        if dep.valid:\n            if dep.package in self.ignore:\n                ignored_version = self.ignore[dep.package]\n                if ignored_version is not None:\n                    # ignored_version can be None to disable conflict detection\n                    if dep.version and dep.version != ignored_version:\n                        logger.error(\n                            \"Package %s was resolved to different \"\n                            \"versions in different environments: %s and %s\",\n                            dep.package, dep.version, ignored_version,\n                        )\n                        raise RuntimeError(\n                            \"Please add constraints for the package \"\n                            \"version listed above\"\n                        )\n                return None\n            self.packages[dep.package] = dep.version\n            if self.forbid_post or dep.is_compatible:\n                # Always drop post for internal packages\n                dep.drop_post()\n            return dep.serialize()\n        return line.strip()", "response": "Fix dependency by removing post - releases from versions\n            and loosing constraints on internal packages."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds references to other_names in outfile", "response": "def add_references(self, other_names):\n        \"\"\"Add references to other_names in outfile\"\"\"\n        if not other_names:\n            # Skip on empty list\n            return\n        with open(self.outfile, 'rt') as fp:\n            header, body = self.split_header(fp)\n        with open(self.outfile, 'wt') as fp:\n            fp.writelines(header)\n            fp.writelines(\n                '-r {0}.{1}\\n'.format(other_name, OPTIONS['out_ext'])\n                for other_name in sorted(other_names)\n            )\n            fp.writelines(body)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_header(fp):\n        body_start, header_ended = 0, False\n        lines = []\n        for line in fp:\n            if line.startswith('#') and not header_ended:\n                # Header text\n                body_start += 1\n            else:\n                header_ended = True\n            lines.append(line)\n        return lines[:body_start], lines[body_start:]", "response": "Read file pointer and return pair of lines lists first - header second - the rest."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces pip - compile header with custom text", "response": "def replace_header(self, header_text):\n        \"\"\"Replace pip-compile header with custom text\"\"\"\n        with open(self.outfile, 'rt') as fp:\n            _, body = self.split_header(fp)\n        with open(self.outfile, 'wt') as fp:\n            fp.write(header_text)\n            fp.writelines(body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds all files matching given glob_pattern and return list of environments.", "response": "def discover(glob_pattern):\n    \"\"\"\n    Find all files matching given glob_pattern,\n    parse them, and return list of environments:\n\n    >>> envs = discover(\"requirements/*.in\")\n    >>> # print(envs)\n    >>> envs == [\n    ...     {'name': 'base', 'refs': set()},\n    ...     {'name': 'py27', 'refs': set()},\n    ...     {'name': 'test', 'refs': {'base'}},\n    ...     {'name': 'local', 'refs': {'test'}},\n    ...     {'name': 'local27', 'refs': {'test', 'py27'}},\n    ...     {'name': 'testwin', 'refs': {'test'}},\n    ... ]\n    True\n    \"\"\"\n    in_paths = glob.glob(glob_pattern)\n    names = {\n        extract_env_name(path): path\n        for path in in_paths\n    }\n    return order_by_refs([\n        {'name': name, 'refs': Environment.parse_references(in_path)}\n        for name, in_path in names.items()\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning topologicaly sorted list of environments.", "response": "def order_by_refs(envs):\n    \"\"\"\n    Return topologicaly sorted list of environments.\n    I.e. all referenced environments are placed before their references.\n    \"\"\"\n    topology = {\n        env['name']: set(env['refs'])\n        for env in envs\n    }\n    by_name = {\n        env['name']: env\n        for env in envs\n    }\n    return [\n        by_name[name]\n        for name in toposort_flatten(topology)\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, compatible, forbid_post, generate_hashes, directory,\n        in_ext, out_ext, header, only_name, upgrade):\n    \"\"\"Recompile\"\"\"\n    logging.basicConfig(level=logging.DEBUG, format=\"%(message)s\")\n    OPTIONS.update({\n        'compatible_patterns': compatible,\n        'forbid_post': set(forbid_post),\n        'add_hashes': set(generate_hashes),\n        'base_dir': directory,\n        'in_ext': in_ext,\n        'out_ext': out_ext,\n        'header_file': header or None,\n        'include_names': only_name,\n        'upgrade': upgrade,\n    })\n    if ctx.invoked_subcommand is None:\n        recompile()", "response": "Recompile the base language tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender dependency back in string using :", "response": "def serialize(self):\n        \"\"\"\n        Render dependency back in string using:\n            ~= if package is internal\n            == otherwise\n        \"\"\"\n        if self.is_vcs:\n            return self.without_editable(self.line).strip()\n        equal = '~=' if self.is_compatible else '=='\n        package_version = '{package}{equal}{version}  '.format(\n            package=self.without_editable(self.package),\n            version=self.version,\n            equal=equal,\n        )\n        if self.hashes:\n            hashes = self.hashes.split()\n            lines = [package_version.strip()]\n            lines.extend(hashes)\n            if self.comment:\n                lines.append(self.comment)\n            return ' \\\\\\n    '.join(lines)\n        else:\n            return '{0}{1}'.format(\n                package_version.ljust(self.COMMENT_JUSTIFICATION),\n                self.comment,\n            ).rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the package name is matched by compatible_patterns", "response": "def is_compatible(self):\n        \"\"\"Check if package name is matched by compatible_patterns\"\"\"\n        for pattern in OPTIONS['compatible_patterns']:\n            if fnmatch(self.package.lower(), pattern):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove postXXXX postfix from version", "response": "def drop_post(self):\n        \"\"\"Remove .postXXXX postfix from version\"\"\"\n        post_index = self.version.find('.post')\n        if post_index >= 0:\n            self.version = self.version[:post_index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that all environments have the same hash comments and report failures.", "response": "def verify_environments():\n    \"\"\"\n    For each environment verify hash comments and report failures.\n    If any failure occured, exit with code 1.\n    \"\"\"\n    env_confs = discover(\n        os.path.join(\n            OPTIONS['base_dir'],\n            '*.' + OPTIONS['in_ext'],\n        )\n    )\n    success = True\n    for conf in env_confs:\n        env = Environment(name=conf['name'])\n        current_comment = generate_hash_comment(env.infile)\n        existing_comment = parse_hash_comment(env.outfile)\n        if current_comment == existing_comment:\n            logger.info(\"OK - %s was generated from %s.\",\n                        env.outfile, env.infile)\n        else:\n            logger.error(\"ERROR! %s was not regenerated after changes in %s.\",\n                         env.outfile, env.infile)\n            logger.error(\"Expecting: %s\", current_comment.strip())\n            logger.error(\"Found:     %s\", existing_comment.strip())\n            success = False\n    return success"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a hash comment for the given file_path.", "response": "def generate_hash_comment(file_path):\n    \"\"\"\n    Read file with given file_path and return string of format\n\n        # SHA1:da39a3ee5e6b4b0d3255bfef95601890afd80709\n\n    which is hex representation of SHA1 file content hash\n    \"\"\"\n    with open(file_path, 'rb') as fp:\n        hexdigest = hashlib.sha1(fp.read().strip()).hexdigest()\n    return \"# SHA1:{0}\\n\".format(hexdigest)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading file with given file_path line by line and return first line that starts with \"# SHA1 :", "response": "def parse_hash_comment(file_path):\n    \"\"\"\n    Read file with given file_path line by line,\n    return the first line that starts with \"# SHA1:\", like this:\n\n        # SHA1:da39a3ee5e6b4b0d3255bfef95601890afd80709\n    \"\"\"\n    with open(file_path) as fp:\n        for line in fp:\n            if line.startswith(\"# SHA1:\"):\n                return line\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_sections(sections):\n    if not sections:\n        return None\n    jobs = []\n    matchers = python_version_matchers()\n    for name, options in sections:\n        target_version = options.pop('python', None)\n        if target_version in matchers:\n            jobs.append((name, options))\n    return jobs", "response": "Filter through pairs of name options and python version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_sections():\n    config = configparser.ConfigParser()\n    config.read(('requirements.ini', 'setup.cfg', 'tox.ini'))\n    return [\n        (\n            name,\n            {\n                key: parse_value(key, config[name][key])\n                for key in config[name]\n            }\n        )\n        for name in config.sections()\n        if 'requirements' in name\n    ]", "response": "Read ini files and return list of pairs ( name options )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses value as comma - delimited list if default value for it is list", "response": "def parse_value(key, value):\n    \"\"\"Parse value as comma-delimited list if default value for it is list\"\"\"\n    default = OPTIONS.get(key)\n    if isinstance(default, collections.Iterable):\n        if not isinstance(default, six.string_types):\n            return [item.strip()\n                    for item in value.split(',')]\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef python_version_matchers():\n    version = sys.version_info\n    patterns = [\n        \"{0}\",\n        \"{0}{1}\",\n        \"{0}.{1}\",\n    ]\n    matchers = [\n        pattern.format(*version)\n        for pattern in patterns\n    ] + [None]\n    return set(matchers)", "response": "Return set of string representations of current python version"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(ctx):\n    oks = run_configurations(\n        skipper(verify_environments),\n        read_sections,\n    )\n    ctx.exit(0\n             if False not in oks\n             else 1)", "response": "Verify locked dependency versions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef skipper(func):\n    @functools.wraps(func)\n    def wrapped():\n        \"\"\"Dummy docstring to make pylint happy.\"\"\"\n        key = (OPTIONS['base_dir'], OPTIONS['in_ext'], OPTIONS['out_ext'])\n        if key not in seen:\n            seen[key] = func()\n        return seen[key]\n    seen = {}\n    return wrapped", "response": "Decorator that memorizes base_dir in_ext and out_ext from OPTIONS\n    and skips execution for duplicates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_configurations(callback, sections_reader):\n    base = dict(OPTIONS)\n    sections = sections_reader()\n    if sections is None:\n        logger.info(\"Configuration not found in .ini files. \"\n                    \"Running with default settings\")\n        recompile()\n    elif sections == []:\n        logger.info(\"Configuration does not match current runtime. \"\n                    \"Exiting\")\n    results = []\n    for section, options in sections:\n        OPTIONS.clear()\n        OPTIONS.update(base)\n        OPTIONS.update(options)\n        logger.debug(\"Running configuration from section \\\"%s\\\". OPTIONS: %r\",\n                     section, OPTIONS)\n        results.append(callback())\n    return results", "response": "Parse configurations and execute callback for matching."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recompile():\n    pinned_packages = {}\n    env_confs = discover(\n        os.path.join(\n            OPTIONS['base_dir'],\n            '*.' + OPTIONS['in_ext'],\n        ),\n    )\n    if OPTIONS['header_file']:\n        with open(OPTIONS['header_file']) as fp:\n            base_header_text = fp.read()\n    else:\n        base_header_text = DEFAULT_HEADER\n    hashed_by_reference = set()\n    for name in OPTIONS['add_hashes']:\n        hashed_by_reference.update(\n            reference_cluster(env_confs, name)\n        )\n    included_and_refs = set(OPTIONS['include_names'])\n    for name in set(included_and_refs):\n        included_and_refs.update(\n            recursive_refs(env_confs, name)\n        )\n    for conf in env_confs:\n        if included_and_refs:\n            if conf['name'] not in included_and_refs:\n                # Skip envs that are not included or referenced by included:\n                continue\n        rrefs = recursive_refs(env_confs, conf['name'])\n        add_hashes = conf['name'] in hashed_by_reference\n        env = Environment(\n            name=conf['name'],\n            ignore=merged_packages(pinned_packages, rrefs),\n            forbid_post=conf['name'] in OPTIONS['forbid_post'],\n            add_hashes=add_hashes,\n        )\n        logger.info(\"Locking %s to %s. References: %r\",\n                    env.infile, env.outfile, sorted(rrefs))\n        env.create_lockfile()\n        header_text = generate_hash_comment(env.infile) + base_header_text\n        env.replace_header(header_text)\n        env.add_references(conf['refs'])\n        pinned_packages[conf['name']] = env.packages", "response": "Recompiles the requirements files for all environments."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merged_packages(env_packages, names):\n    combined_packages = sorted(itertools.chain.from_iterable(\n        env_packages[name].items()\n        for name in names\n    ))\n    result = {}\n    errors = set()\n    for name, version in combined_packages:\n        if name in result:\n            if result[name] != version:\n                errors.add((name, version, result[name]))\n        else:\n            result[name] = version\n    if errors:\n        for error in sorted(errors):\n            logger.error(\n                \"Package %s was resolved to different \"\n                \"versions in different environments: %s and %s\",\n                error[0], error[1], error[2],\n            )\n        raise RuntimeError(\n            \"Please add constraints for the package version listed above\"\n        )\n    return result", "response": "Return union set of environment packages with given names"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning set of recursive refs for given env name", "response": "def recursive_refs(envs, name):\n    \"\"\"\n    Return set of recursive refs for given env name\n\n    >>> local_refs = sorted(recursive_refs([\n    ...     {'name': 'base', 'refs': []},\n    ...     {'name': 'test', 'refs': ['base']},\n    ...     {'name': 'local', 'refs': ['test']},\n    ... ], 'local'))\n    >>> local_refs == ['base', 'test']\n    True\n    \"\"\"\n    refs_by_name = {\n        env['name']: set(env['refs'])\n        for env in envs\n    }\n    refs = refs_by_name[name]\n    if refs:\n        indirect_refs = set(itertools.chain.from_iterable([\n            recursive_refs(envs, ref)\n            for ref in refs\n        ]))\n    else:\n        indirect_refs = set()\n    return set.union(refs, indirect_refs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn set of all env names referencing or referenced by given name.", "response": "def reference_cluster(envs, name):\n    \"\"\"\n    Return set of all env names referencing or\n    referenced by given name.\n\n    >>> cluster = sorted(reference_cluster([\n    ...     {'name': 'base', 'refs': []},\n    ...     {'name': 'test', 'refs': ['base']},\n    ...     {'name': 'local', 'refs': ['test']},\n    ... ], 'test'))\n    >>> cluster == ['base', 'local', 'test']\n    True\n    \"\"\"\n    edges = [\n        set([env['name'], ref])\n        for env in envs\n        for ref in env['refs']\n    ]\n    prev, cluster = set(), set([name])\n    while prev != cluster:\n        # While cluster grows\n        prev = set(cluster)\n        to_visit = []\n        for edge in edges:\n            if cluster & edge:\n                # Add adjacent nodes:\n                cluster |= edge\n            else:\n                # Leave only edges that are out\n                # of cluster for the next round:\n                to_visit.append(edge)\n        edges = to_visit\n    return cluster"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a requests session for the", "response": "def get_requests_session():\n    \"\"\"\n    Set connection pool maxsize and block value to avoid `connection pool full` warnings.\n\n    :return: requests session\n    \"\"\"\n    session = requests.sessions.Session()\n    session.mount('http://', HTTPAdapter(pool_connections=25, pool_maxsize=25, pool_block=True))\n    session.mount('https://', HTTPAdapter(pool_connections=25, pool_maxsize=25, pool_block=True))\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting an amount of tokens for a particular address.", "response": "def request_tokens(self, amount, account):\n        \"\"\"\n        Request an amount of tokens for a particular address.\n        This transaction has gas cost\n\n        :param amount: Amount of tokens, int\n        :param account: Account instance\n        :raise OceanInvalidTransaction: Transaction failed\n        :return: bool\n        \"\"\"\n        address = account.address\n        try:\n            tx_hash = self.send_transaction(\n                'requestTokens',\n                (amount,),\n                transact={'from': address,\n                          'passphrase': account.password}\n            )\n            logging.debug(f'{address} requests {amount} tokens, returning receipt')\n            try:\n                receipt = Web3Provider.get_web3().eth.waitForTransactionReceipt(\n                    tx_hash, timeout=20)\n                logging.debug(f'requestTokens receipt: {receipt}')\n            except Timeout:\n                receipt = None\n\n            if not receipt:\n                return False\n\n            if receipt.status == 0:\n                logging.warning(f'request tokens failed: Tx-receipt={receipt}')\n                logging.warning(f'request tokens failed: account {address}')\n                return False\n\n            # check for emitted events:\n            rfe = EventFilter(\n                'RequestFrequencyExceeded',\n                self.events.RequestFrequencyExceeded,\n                argument_filters={'requester': Web3Provider.get_web3().toBytes(hexstr=address)},\n                from_block='latest',\n                to_block='latest',\n            )\n            logs = rfe.get_all_entries(max_tries=5)\n            if logs:\n                logging.warning(f'request tokens failed RequestFrequencyExceeded')\n                logging.info(f'RequestFrequencyExceeded event logs: {logs}')\n                return False\n\n            rle = EventFilter(\n                'RequestLimitExceeded',\n                self.events.RequestLimitExceeded,\n                argument_filters={'requester': Web3Provider.get_web3().toBytes(hexstr=address)},\n                from_block='latest',\n                to_block='latest',\n            )\n            logs = rle.get_all_entries(max_tries=5)\n            if logs:\n                logging.warning(f'request tokens failed RequestLimitExceeded')\n                logging.info(f'RequestLimitExceeded event logs: {logs}')\n                return False\n\n            return True\n\n        except ValueError as err:\n            raise OceanInvalidTransaction(\n                f'Requesting {amount} tokens'\n                f' to {address} failed with error: {err}'\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_network_name(network_id):\n        if os.environ.get('KEEPER_NETWORK_NAME'):\n            logging.debug('keeper network name overridden by an environment variable: {}'.format(\n                os.environ.get('KEEPER_NETWORK_NAME')))\n            return os.environ.get('KEEPER_NETWORK_NAME')\n\n        return Keeper._network_name_map.get(network_id, Keeper.DEFAULT_NETWORK_NAME)", "response": "Get the keeper network name based on the current ethereum network id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unlock_account(account):\n        return Web3Provider.get_web3().personal.unlockAccount(account.address, account.password)", "response": "Unlock the account.\n\n        :param account: Account\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the condition name for a given address.", "response": "def get_condition_name_by_address(self, address):\n        \"\"\"Return the condition name for a given address.\"\"\"\n        if self.lock_reward_condition.address == address:\n            return 'lockReward'\n        elif self.access_secret_store_condition.address == address:\n            return 'accessSecretStore'\n        elif self.escrow_reward_condition.address == address:\n            return 'escrowReward'\n        else:\n            logging.error(f'The current address {address} is not a condition address')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the service agreement for the asset identified by did.", "response": "def initialize_service_agreement(did, agreement_id, service_definition_id, signature,\n                                     account_address,\n                                     consume_endpoint):\n        \"\"\"\n        Send a request to the service provider (consume_endpoint) to initialize the service\n        agreement for the asset identified by `did`.\n\n        :param did: id of the asset includes the `did:op:` prefix, str\n        :param agreement_id: id of the agreement, hex str\n        :param service_definition_id: identifier of the service inside the asset DDO, str\n        :param signature: signed agreement hash, hex str\n        :param account_address: ethereum address of the consumer signing this agreement, hex str\n        :param consume_endpoint: url of the service provider, str\n        :return: bool\n        \"\"\"\n        payload = Brizo._prepare_consume_payload(\n            did, agreement_id, service_definition_id, signature, account_address\n        )\n        response = Brizo._http_client.post(\n            consume_endpoint, data=payload,\n            headers={'content-type': 'application/json'}\n        )\n        if response and hasattr(response, 'status_code'):\n            if response.status_code != 201:\n                msg = (f'Initialize service agreement failed at the consumeEndpoint '\n                       f'{consume_endpoint}, reason {response.text}, status {response.status_code}'\n                       )\n                logger.error(msg)\n                raise OceanInitializeServiceAgreementError(msg)\n\n            logger.info(\n                f'Service agreement initialized successfully, service agreement id {agreement_id},'\n                f' consumeEndpoint {consume_endpoint}')\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling the brizo endpoint to get access to the different files that form the asset. :param service_agreement_id: Service Agreement Id, str :param service_endpoint: Url to consume, str :param account: Account instance of the consumer signing this agreement, hex-str :param files: List containing the files to be consumed, list :param index: Index of the document that is going to be downloaded, int :param destination_folder: Path, str :return: True if was downloaded, bool", "response": "def consume_service(service_agreement_id, service_endpoint, account, files,\n                        destination_folder, index=None):\n        \"\"\"\n        Call the brizo endpoint to get access to the different files that form the asset.\n\n        :param service_agreement_id: Service Agreement Id, str\n        :param service_endpoint: Url to consume, str\n        :param account: Account instance of the consumer signing this agreement, hex-str\n        :param files: List containing the files to be consumed, list\n        :param index: Index of the document that is going to be downloaded, int\n        :param destination_folder: Path, str\n        :return: True if was downloaded, bool\n        \"\"\"\n        signature = Keeper.get_instance().sign_hash(service_agreement_id, account)\n        if index is not None:\n            assert isinstance(index, int), logger.error('index has to be an integer.')\n            assert index >= 0, logger.error('index has to be 0 or a positive integer.')\n            assert index < len(files), logger.error(\n                'index can not be bigger than the number of files')\n            consume_url = Brizo._create_consume_url(service_endpoint, service_agreement_id, account,\n                                                    None, signature, index)\n            logger.info(f'invoke consume endpoint with this url: {consume_url}')\n            response = Brizo._http_client.get(consume_url, stream=True)\n            file_name = Brizo._get_file_name(response)\n            Brizo.write_file(response, destination_folder, file_name)\n        else:\n            for i, _file in enumerate(files):\n                consume_url = Brizo._create_consume_url(service_endpoint, service_agreement_id,\n                                                        account, _file,\n                                                        signature, i)\n                logger.info(f'invoke consume endpoint with this url: {consume_url}')\n                response = Brizo._http_client.get(consume_url, stream=True)\n                file_name = Brizo._get_file_name(response)\n                Brizo.write_file(response, destination_folder, file_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _prepare_consume_payload(did, service_agreement_id, service_definition_id, signature,\n                                  consumer_address):\n        \"\"\"Prepare a payload to send to `Brizo`.\n\n        :param did: DID, str\n        :param service_agreement_id: Service Agreement Id, str\n        :param service_definition_id: identifier of the service inside the asset DDO, str\n        service in the DDO (DID document)\n        :param signature: the signed agreement message hash which includes\n         conditions and their parameters values and other details of the agreement, str\n        :param consumer_address: ethereum address of the consumer signing this agreement, hex-str\n        :return: dict\n        \"\"\"\n        return json.dumps({\n            'did': did,\n            'serviceAgreementId': service_agreement_id,\n            ServiceAgreement.SERVICE_DEFINITION_ID: service_definition_id,\n            'signature': signature,\n            'consumerAddress': consumer_address\n        })", "response": "Prepare a payload to send to Brizo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_brizo_url(config):\n        brizo_url = 'http://localhost:8030'\n        if config.has_option('resources', 'brizo.url'):\n            brizo_url = config.get('resources', 'brizo.url') or brizo_url\n\n        brizo_path = '/api/v1/brizo'\n        return f'{brizo_url}{brizo_path}'", "response": "Get the Brizo component url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_file(response, destination_folder, file_name):\n        if response.status_code == 200:\n            with open(os.path.join(destination_folder, file_name), 'wb') as f:\n                for chunk in response.iter_content(chunk_size=None):\n                    f.write(chunk)\n            logger.info(f'Saved downloaded file in {f.name}')\n        else:\n            logger.warning(f'consume failed: {response.reason}')", "response": "Write the response content in a file in the destination folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving an example of the metadata", "response": "def get_example():\n        \"\"\"Retrieve an example of the metadata\"\"\"\n        example = dict()\n        for section_key, section in Metadata.MAIN_SECTIONS.items():\n            example[section_key] = section.EXAMPLE.copy()\n\n        return example"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encrypt_document(self, document_id, content, threshold=0):\n        return self._secret_store_client(self._account).publish_document(\n            remove_0x_prefix(document_id), content, threshold\n        )", "response": "Encrypt string data using the DID as an secret store id and return the encrypted string data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(service_agreement_id, service_definition_id, ddo, consumer_account, destination,\n                 brizo, secret_store, index=None):\n        \"\"\"\n        Download asset data files or result files from a compute job.\n\n        :param service_agreement_id: Service agreement id, str\n        :param service_definition_id: identifier of the service inside the asset DDO, str\n        :param ddo: DDO\n        :param consumer_account: Account instance of the consumer\n        :param destination: Path, str\n        :param brizo: Brizo instance\n        :param secret_store: SecretStore instance\n        :param index: Index of the document that is going to be downloaded, int\n        :return: Asset folder path, str\n        \"\"\"\n        did = ddo.did\n        encrypted_files = ddo.metadata['base']['encryptedFiles']\n        encrypted_files = (\n            encrypted_files if isinstance(encrypted_files, str)\n            else encrypted_files[0]\n        )\n        sa = ServiceAgreement.from_ddo(service_definition_id, ddo)\n        consume_url = sa.consume_endpoint\n        if not consume_url:\n            logger.error(\n                'Consume asset failed, service definition is missing the \"serviceEndpoint\".')\n            raise AssertionError(\n                'Consume asset failed, service definition is missing the \"serviceEndpoint\".')\n\n        if ddo.get_service('Authorization'):\n            secret_store_service = ddo.get_service(service_type=ServiceTypes.AUTHORIZATION)\n            secret_store_url = secret_store_service.endpoints.service\n            secret_store.set_secret_store_url(secret_store_url)\n\n        # decrypt the contentUrls\n        decrypted_content_urls = json.loads(\n            secret_store.decrypt_document(did_to_id(did), encrypted_files)\n        )\n\n        if isinstance(decrypted_content_urls, str):\n            decrypted_content_urls = [decrypted_content_urls]\n        logger.debug(f'got decrypted contentUrls: {decrypted_content_urls}')\n\n        if not os.path.isabs(destination):\n            destination = os.path.abspath(destination)\n        if not os.path.exists(destination):\n            os.mkdir(destination)\n\n        asset_folder = os.path.join(destination,\n                                    f'datafile.{did_to_id(did)}.{sa.service_definition_id}')\n        if not os.path.exists(asset_folder):\n            os.mkdir(asset_folder)\n        if index is not None:\n            assert isinstance(index, int), logger.error('index has to be an integer.')\n            assert index >= 0, logger.error('index has to be 0 or a positive integer.')\n            assert index < len(decrypted_content_urls), logger.error(\n                'index can not be bigger than the number of files')\n        brizo.consume_service(\n            service_agreement_id,\n            consume_url,\n            consumer_account,\n            decrypted_content_urls,\n            asset_folder,\n            index\n        )\n        return asset_folder", "response": "Download asset data files or result files from a compute job."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assign_did(self, did):\n        if re.match('^#.*', self._id):\n            self._id = did + self._id\n        if re.match('^#.*', self._owner):\n            self._owner = did + self._owner", "response": "Assign the DID as the key id and the DID as the key value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_key_value(self, value, store_type=PUBLIC_KEY_STORE_TYPE_BASE64):\n        if isinstance(value, dict):\n            if PUBLIC_KEY_STORE_TYPE_HEX in value:\n                self.set_key_value(value[PUBLIC_KEY_STORE_TYPE_HEX], PUBLIC_KEY_STORE_TYPE_HEX)\n            elif PUBLIC_KEY_STORE_TYPE_BASE64 in value:\n                self.set_key_value(value[PUBLIC_KEY_STORE_TYPE_BASE64],\n                                   PUBLIC_KEY_STORE_TYPE_BASE64)\n            elif PUBLIC_KEY_STORE_TYPE_BASE85 in value:\n                self.set_key_value(value[PUBLIC_KEY_STORE_TYPE_BASE85],\n                                   PUBLIC_KEY_STORE_TYPE_BASE85)\n            elif PUBLIC_KEY_STORE_TYPE_JWK in value:\n                self.set_key_value(value[PUBLIC_KEY_STORE_TYPE_JWK], PUBLIC_KEY_STORE_TYPE_JWK)\n            elif PUBLIC_KEY_STORE_TYPE_PEM in value:\n                self.set_key_value(value[PUBLIC_KEY_STORE_TYPE_PEM], PUBLIC_KEY_STORE_TYPE_PEM)\n        else:\n            self._value = value\n            self._store_type = store_type", "response": "Set the key value based on it s storage type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the key value base on it s storage type.", "response": "def set_encode_key_value(self, value, store_type):\n        \"\"\"Save the key value base on it's storage type.\"\"\"\n        self._store_type = store_type\n        if store_type == PUBLIC_KEY_STORE_TYPE_HEX:\n            self._value = value.hex()\n        elif store_type == PUBLIC_KEY_STORE_TYPE_BASE64:\n            self._value = b64encode(value).decode()\n        elif store_type == PUBLIC_KEY_STORE_TYPE_BASE85:\n            self._value = b85encode(value).decode()\n        elif store_type == PUBLIC_KEY_STORE_TYPE_JWK:\n            # TODO: need to decide on which jwk library to import?\n            raise NotImplementedError\n        else:\n            self._value = value\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the key value based on it s storage type.", "response": "def get_decode_value(self):\n        \"\"\"Return the key value based on it's storage type.\"\"\"\n        if self._store_type == PUBLIC_KEY_STORE_TYPE_HEX:\n            value = bytes.fromhex(self._value)\n        elif self._store_type == PUBLIC_KEY_STORE_TYPE_BASE64:\n            value = b64decode(self._value)\n        elif self._store_type == PUBLIC_KEY_STORE_TYPE_BASE85:\n            value = b85decode(self._value)\n        elif self._store_type == PUBLIC_KEY_STORE_TYPE_JWK:\n            # TODO: need to decide on which jwk library to import?\n            raise NotImplementedError\n        else:\n            value = self._value\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the key as JSON text.", "response": "def as_text(self, is_pretty=False):\n        \"\"\"Return the key as JSON text.\"\"\"\n        values = {'id': self._id, 'type': self._type}\n        if self._owner:\n            values['owner'] = self._owner\n\n        if is_pretty:\n            return json.dumps(values, indent=4, separators=(',', ': '))\n\n        return json.dumps(values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef as_dictionary(self):\n        values = {\n            'id': self._id,\n            'type': self._type\n        }\n\n        if self._owner:\n            values['owner'] = self._owner\n        return values", "response": "Return the key as a python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_agreement(self, agreement_id, did, condition_types, condition_ids, time_locks,\n                         time_outs):\n        \"\"\"\n        Create a new agreement.\n        The agreement will create conditions of conditionType with conditionId.\n        Only \"approved\" templates can access this function.\n        :param agreement_id:id of the agreement, hex str\n        :param did: DID of the asset. The DID must be registered beforehand, bytes32\n        :param condition_types: is a list of addresses that point to Condition contracts,\n                                list(address)\n        :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n        :param time_locks: is a list of uint time lock values associated to each Condition, int\n        :param time_outs: is a list of uint time out values associated to each Condition, int\n        :return: bool\n        \"\"\"\n\n        tx_hash = self.contract_concise.createAgreement(\n            agreement_id,\n            did,\n            condition_types,\n            condition_ids,\n            time_locks,\n            time_outs,\n        )\n        receipt = self.get_tx_receipt(tx_hash)\n        return receipt and receipt.status == 1", "response": "Create a new agreement."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_agreement(self, agreement_id):\n        agreement = self.contract_concise.getAgreement(agreement_id)\n        if agreement and len(agreement) == 6:\n            agreement = AgreementValues(*agreement)\n            did = add_0x_prefix(agreement.did.hex())\n            cond_ids = [add_0x_prefix(_id.hex()) for _id in agreement.condition_ids]\n\n            return AgreementValues(\n                did,\n                agreement.owner,\n                agreement.template_id,\n                cond_ids,\n                agreement.updated_by,\n                agreement.block_number_updated\n            )\n\n        return None", "response": "Retrieve the agreement for a given agreement_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the contract instance for contract_name that represent the smart contract in the keeper network.", "response": "def _load(contract_name):\n        \"\"\"Retrieve the contract instance for `contract_name` that represent the smart\n        contract in the keeper network.\n\n        :param contract_name: str name of the solidity keeper contract without the network name.\n        :return: web3.eth.Contract instance\n        \"\"\"\n        contract_definition = ContractHandler.get_contract_dict_by_name(contract_name)\n        address = Web3Provider.get_web3().toChecksumAddress(contract_definition['address'])\n        abi = contract_definition['abi']\n        contract = Web3Provider.get_web3().eth.contract(address=address, abi=abi)\n        ContractHandler._contracts[contract_name] = (contract, ConciseContract(contract))\n        return ContractHandler._contracts[contract_name]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the smart contract definition from the json abi file and dict", "response": "def get_contract_dict_by_name(contract_name):\n        \"\"\"\n        Retrieve the Contract instance for a given contract name.\n\n        :param contract_name: str\n        :return: the smart contract's definition from the json abi file, dict\n        \"\"\"\n\n        network_name = Keeper.get_network_name(Keeper.get_network_id()).lower()\n        artifacts_path = ConfigProvider.get_config().keeper_path\n\n        # file_name = '{}.{}.json'.format(contract_name, network_name)\n        # path = os.path.join(keeper.artifacts_path, file_name)\n        path = ContractHandler._get_contract_file_path(\n            artifacts_path, contract_name, network_name)\n        if not (path and os.path.exists(path)):\n            path = ContractHandler._get_contract_file_path(\n                artifacts_path, contract_name, network_name.lower())\n\n        if not (path and os.path.exists(path)):\n            path = ContractHandler._get_contract_file_path(\n                artifacts_path, contract_name, Keeper.DEFAULT_NETWORK_NAME)\n\n        if not (path and os.path.exists(path)):\n            raise FileNotFoundError(\n                f'Keeper contract {contract_name} file '\n                f'not found in {artifacts_path} '\n                f'using network name {network_name}'\n            )\n\n        with open(path) as f:\n            contract_dict = json.loads(f.read())\n            return contract_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buy_asset():\n    ConfigProvider.set_config(ExampleConfig.get_config())\n    config = ConfigProvider.get_config()\n\n    # make ocean instance\n    ocn = Ocean()\n    acc = get_publisher_account(config)\n    if not acc:\n        acc = ([acc for acc in ocn.accounts.list() if acc.password] or ocn.accounts.list())[0]\n\n    # Register ddo\n    ddo = ocn.assets.create(Metadata.get_example(), acc, providers=[acc.address], use_secret_store=False)\n    logging.info(f'registered ddo: {ddo.did}')\n    # ocn here will be used only to publish the asset. Handling the asset by the publisher\n    # will be performed by the Brizo server running locally\n    keeper = Keeper.get_instance()\n    if 'TEST_LOCAL_NILE' in os.environ and os.environ['TEST_LOCAL_NILE'] == '1':\n        provider = keeper.did_registry.to_checksum_address(\n            '0x413c9ba0a05b8a600899b41b0c62dd661e689354'\n        )\n        keeper.did_registry.add_provider(ddo.asset_id, provider, acc)\n        logging.debug(f'is did provider: '\n                      f'{keeper.did_registry.is_did_provider(ddo.asset_id, provider)}')\n\n    cons_ocn = Ocean()\n    consumer_account = get_account_from_config(config, 'parity.address1', 'parity.password1')\n\n    # sign agreement using the registered asset did above\n    service = ddo.get_service(service_type=ServiceTypes.ASSET_ACCESS)\n    # This will send the order request to Brizo which in turn will execute the agreement on-chain\n    cons_ocn.accounts.request_tokens(consumer_account, 100)\n    sa = ServiceAgreement.from_service_dict(service.as_dictionary())\n\n    agreement_id = cons_ocn.assets.order(\n        ddo.did, sa.service_definition_id, consumer_account)\n    logging.info('placed order: %s, %s', ddo.did, agreement_id)\n    i = 0\n    while ocn.agreements.is_access_granted(\n            agreement_id, ddo.did, consumer_account.address) is not True and i < 30:\n        time.sleep(1)\n        i += 1\n\n    assert ocn.agreements.is_access_granted(agreement_id, ddo.did, consumer_account.address)\n\n    ocn.assets.consume(\n        agreement_id,\n        ddo.did,\n        sa.service_definition_id,\n        consumer_account,\n        config.downloads_path)\n    logging.info('Success buying asset.')", "response": "Buy an asset by publisher"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napproves the passed address to spend the specified amount of tokens.", "response": "def token_approve(self, spender_address, price, from_account):\n        \"\"\"\n        Approve the passed address to spend the specified amount of tokens.\n\n        :param spender_address: Account address, str\n        :param price: Asset price, int\n        :param from_account: Account address, str\n        :return: bool\n        \"\"\"\n        if not Web3Provider.get_web3().isChecksumAddress(spender_address):\n            spender_address = Web3Provider.get_web3().toChecksumAddress(spender_address)\n\n        tx_hash = self.send_transaction(\n            'approve',\n            (spender_address,\n             price),\n            transact={'from': from_account.address,\n                      'passphrase': from_account.password}\n        )\n        return self.get_tx_receipt(tx_hash).status == 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransfers tokens from one account to the receiver address.", "response": "def transfer(self, receiver_address, amount, from_account):\n        \"\"\"\n        Transfer tokens from one account to the receiver address.\n\n        :param receiver_address: Address of the transfer receiver, str\n        :param amount: Amount of tokens, int\n        :param from_account: Sender account, Account\n        :return: bool\n        \"\"\"\n        tx_hash = self.send_transaction(\n            'transfer',\n            (receiver_address,\n             amount),\n            transact={'from': from_account.address,\n                      'passphrase': from_account.password}\n        )\n        return self.get_tx_receipt(tx_hash).status == 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new event filter.", "response": "def make_event_filter(self, filter_key, filter_value):\n        \"\"\"Create a new event filter.\"\"\"\n        event_filter = EventFilter(\n            self.event_name,\n            self.event,\n            {filter_key: filter_value},\n            from_block=self.from_block,\n            to_block=self.to_block\n        )\n        event_filter.set_poll_interval(0.5)\n        return event_filter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing one event and call callback with the first entry if it is not in the queue.", "response": "def process_event(event_filter, callback, timeout_callback, timeout, args,\n                      start_time=None):\n        \"\"\"\n        Start to watch one event.\n\n        :param event_filter:\n        :param callback:\n        :param timeout_callback:\n        :param timeout:\n        :param args:\n        :param start_time:\n        :return:\n        \"\"\"\n        try:\n            events = event_filter.get_all_entries()\n            if events:\n                callback(events[0], *args)\n                return True\n\n        except (ValueError, Exception) as err:\n            # ignore error, but log it\n            logger.debug(f'Got error grabbing keeper events: {str(err)}')\n\n        if timeout:\n            elapsed = int(datetime.now().timestamp()) - start_time\n            if elapsed > timeout:\n                if timeout_callback:\n                    timeout_callback(*args)\n                else:\n                    callback(None, *args)\n\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fulfill_access_secret_store_condition(event, agreement_id, did, service_agreement,\n                                          consumer_address, publisher_account):\n    \"\"\"\n    Fulfill the access condition.\n\n    :param event: AttributeDict with the event data.\n    :param agreement_id: id of the agreement, hex str\n    :param did: DID, str\n    :param service_agreement: ServiceAgreement instance\n    :param consumer_address: ethereum account address of consumer, hex str\n    :param publisher_account: Account instance of the publisher\n    \"\"\"\n    logger.debug(f\"release reward after event {event}.\")\n    name_to_parameter = {param.name: param for param in\n                         service_agreement.condition_by_name['accessSecretStore'].parameters}\n    document_id = add_0x_prefix(name_to_parameter['_documentId'].value)\n    asset_id = add_0x_prefix(did_to_id(did))\n    assert document_id == asset_id, f'document_id {document_id} <=> asset_id {asset_id} mismatch.'\n    try:\n        tx_hash = Keeper.get_instance().access_secret_store_condition.fulfill(\n            agreement_id, document_id, consumer_address, publisher_account\n        )\n        process_tx_receipt(\n            tx_hash,\n            Keeper.get_instance().access_secret_store_condition.FULFILLED_EVENT,\n            'AccessSecretStoreCondition.Fulfilled'\n        )\n    except Exception as e:\n        # logger.error(f'Error when calling grantAccess condition function: {e}')\n        raise e", "response": "Fulfill the access condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new event filter.", "response": "def make_event_filter(self):\n        \"\"\"Create a new event filter.\"\"\"\n        event_filter = EventFilter(\n            self.event_name,\n            self.event,\n            self.filters,\n            from_block=self.from_block,\n            to_block=self.to_block\n        )\n        event_filter.set_poll_interval(0.5)\n        return event_filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef watch_one_event(event_filter, callback, timeout_callback, timeout, args,\n                        start_time=None):\n        \"\"\"\n        Start to watch one event.\n\n        :param event_filter:\n        :param callback:\n        :param timeout_callback:\n        :param timeout:\n        :param args:\n        :param start_time:\n        :return:\n        \"\"\"\n        if timeout and not start_time:\n            start_time = int(datetime.now().timestamp())\n\n        if not args:\n            args = []\n\n        while True:\n            try:\n                events = event_filter.get_all_entries()\n                if events:\n                    callback(events[0], *args)\n                    return\n\n            except (ValueError, Exception) as err:\n                # ignore error, but log it\n                logger.debug(f'Got error grabbing keeper events: {str(err)}')\n\n            time.sleep(0.1)\n            if timeout:\n                elapsed = int(datetime.now().timestamp()) - start_time\n                if elapsed > timeout:\n                    if timeout_callback:\n                        timeout_callback(*args)\n                    else:\n                        callback(None, *args)\n                    break", "response": "Watch one event in the keeper."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new asset in the keeper s DIDRegistry and the metadata store.", "response": "def create(self, metadata, publisher_account,\n               service_descriptors=None, providers=None,\n               use_secret_store=True):\n        \"\"\"\n        Register an asset in both the keeper's DIDRegistry (on-chain) and in the Metadata store (\n        Aquarius).\n\n        :param metadata: dict conforming to the Metadata accepted by Ocean Protocol.\n        :param publisher_account: Account of the publisher registering this asset\n        :param service_descriptors: list of ServiceDescriptor tuples of length 2.\n            The first item must be one of ServiceTypes and the second\n            item is a dict of parameters and values required by the service\n        :param providers: list of addresses of providers of this asset (a provider is\n            an ethereum account that is authorized to provide asset services)\n        :return: DDO instance\n        \"\"\"\n        assert isinstance(metadata, dict), f'Expected metadata of type dict, got {type(metadata)}'\n        if not metadata or not Metadata.validate(metadata):\n            raise OceanInvalidMetadata('Metadata seems invalid. Please make sure'\n                                       ' the required metadata values are filled in.')\n\n        # copy metadata so we don't change the original\n        metadata_copy = copy.deepcopy(metadata)\n\n        # Create a DDO object\n        did = DID.did()\n        logger.debug(f'Generating new did: {did}')\n        # Check if it's already registered first!\n        if did in self._get_aquarius().list_assets():\n            raise OceanDIDAlreadyExist(\n                f'Asset id {did} is already registered to another asset.')\n\n        ddo = DDO(did)\n\n        # Add public key and authentication\n        ddo.add_public_key(did, publisher_account.address)\n        ddo.add_authentication(did, PUBLIC_KEY_TYPE_RSA)\n\n        # Setup metadata service\n        # First replace `files` with encrypted `files`\n        assert metadata_copy['base'][\n            'files'], 'files is required in the metadata base attributes.'\n        assert Metadata.validate(metadata), 'metadata seems invalid.'\n        logger.debug('Encrypting content urls in the metadata.')\n        brizo = BrizoProvider.get_brizo()\n        if not use_secret_store:\n            encrypt_endpoint = brizo.get_encrypt_endpoint(self._config)\n            files_encrypted = brizo.encrypt_files_dict(\n                metadata_copy['base']['files'],\n                encrypt_endpoint,\n                ddo.asset_id,\n                publisher_account.address,\n                self._keeper.sign_hash(ddo.asset_id, publisher_account)\n            )\n        else:\n            files_encrypted = self._get_secret_store(publisher_account) \\\n                .encrypt_document(\n                did_to_id(did),\n                json.dumps(metadata_copy['base']['files']),\n            )\n\n        metadata_copy['base']['checksum'] = ddo.generate_checksum(did, metadata)\n        ddo.add_proof(metadata_copy['base']['checksum'], publisher_account, self._keeper)\n\n        # only assign if the encryption worked\n        if files_encrypted:\n            logger.info(f'Content urls encrypted successfully {files_encrypted}')\n            index = 0\n            for file in metadata_copy['base']['files']:\n                file['index'] = index\n                index = index + 1\n                del file['url']\n            metadata_copy['base']['encryptedFiles'] = files_encrypted\n        else:\n            raise AssertionError('Encrypting the files failed. Make sure the secret store is'\n                                 ' setup properly in your config file.')\n\n        # DDO url and `Metadata` service\n        ddo_service_endpoint = self._get_aquarius().get_service_endpoint(did)\n        metadata_service_desc = ServiceDescriptor.metadata_service_descriptor(metadata_copy,\n                                                                              ddo_service_endpoint)\n        if not service_descriptors:\n            service_descriptors = [ServiceDescriptor.authorization_service_descriptor(\n                self._config.secret_store_url)]\n            brizo = BrizoProvider.get_brizo()\n            service_descriptors += [ServiceDescriptor.access_service_descriptor(\n                metadata[MetadataBase.KEY]['price'],\n                brizo.get_consume_endpoint(self._config),\n                brizo.get_service_endpoint(self._config),\n                3600,\n                self._keeper.escrow_access_secretstore_template.address\n            )]\n        else:\n            service_types = set(map(lambda x: x[0], service_descriptors))\n            if ServiceTypes.AUTHORIZATION not in service_types:\n                service_descriptors += [ServiceDescriptor.authorization_service_descriptor(\n                    self._config.secret_store_url)]\n            else:\n                brizo = BrizoProvider.get_brizo()\n                service_descriptors += [ServiceDescriptor.access_service_descriptor(\n                    metadata[MetadataBase.KEY]['price'],\n                    brizo.get_consume_endpoint(self._config),\n                    brizo.get_service_endpoint(self._config),\n                    3600,\n                    self._keeper.escrow_access_secretstore_template.address\n                )]\n\n        # Add all services to ddo\n        service_descriptors = service_descriptors + [metadata_service_desc]\n        for service in ServiceFactory.build_services(did, service_descriptors):\n            ddo.add_service(service)\n\n        logger.debug(\n            f'Generated ddo and services, DID is {ddo.did},'\n            f' metadata service @{ddo_service_endpoint}, '\n            f'`Access` service initialize @{ddo.services[0].endpoints.service}.')\n        response = None\n        # register on-chain\n        registered_on_chain = self._keeper.did_registry.register(\n            did,\n            checksum=Web3Provider.get_web3().sha3(text=metadata_copy['base']['checksum']),\n            url=ddo_service_endpoint,\n            account=publisher_account,\n            providers=providers\n        )\n        if registered_on_chain is False:\n            logger.warning(f'Registering {did} on-chain failed.')\n            return None\n        logger.info(f'DDO with DID {did} successfully registered on chain.')\n        try:\n            # publish the new ddo in ocean-db/Aquarius\n            response = self._get_aquarius().publish_asset_ddo(ddo)\n            logger.debug('Asset/ddo published successfully in aquarius.')\n        except ValueError as ve:\n            raise ValueError(f'Invalid value to publish in the metadata: {str(ve)}')\n        except Exception as e:\n            logger.error(f'Publish asset in aquarius failed: {str(e)}')\n        if not response:\n            return None\n        return ddo"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretire this did of Aquarius", "response": "def retire(self, did):\n        \"\"\"\n        Retire this did of Aquarius\n\n        :param did: DID, str\n        :return: bool\n        \"\"\"\n        try:\n            ddo = self.resolve(did)\n            metadata_service = ddo.find_service_by_type(ServiceTypes.METADATA)\n            self._get_aquarius(metadata_service.endpoints.service).retire_asset_ddo(did)\n            return True\n        except AquariusGenericError as err:\n            logger.error(err)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch an asset in oceanDB using aquarius.", "response": "def search(self, text, sort=None, offset=100, page=1, aquarius_url=None):\n        \"\"\"\n        Search an asset in oceanDB using aquarius.\n\n        :param text: String with the value that you are searching\n        :param sort: Dictionary to choose order base in some value\n        :param offset: Number of elements shows by page\n        :param page: Page number\n        :param aquarius_url: Url of the aquarius where you want to search. If there is not\n            provided take the default\n        :return: List of assets that match with the query\n        \"\"\"\n        assert page >= 1, f'Invalid page value {page}. Required page >= 1.'\n        logger.info(f'Searching asset containing: {text}')\n        return [DDO(dictionary=ddo_dict) for ddo_dict in\n                self._get_aquarius(aquarius_url).text_search(text, sort, offset, page)['results']]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self, query, sort=None, offset=100, page=1, aquarius_url=None):\n        logger.info(f'Searching asset query: {query}')\n        aquarius = self._get_aquarius(aquarius_url)\n        return [DDO(dictionary=ddo_dict) for ddo_dict in\n                aquarius.query_search(query, sort, offset, page)['results']]", "response": "Search an asset in oceanDB using search query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning the service agreement.", "response": "def order(self, did, service_definition_id, consumer_account, auto_consume=False):\n        \"\"\"\n        Sign service agreement.\n\n        Sign the service agreement defined in the service section identified\n        by `service_definition_id` in the ddo and send the signed agreement to the purchase endpoint\n        associated with this service.\n\n        :param did: str starting with the prefix `did:op:` and followed by the asset id which is\n        a hex str\n        :param service_definition_id: str the service definition id identifying a specific\n        service in the DDO (DID document)\n        :param consumer_account: Account instance of the consumer\n        :param auto_consume: boolean\n        :return: tuple(agreement_id, signature) the service agreement id (can be used to query\n            the keeper-contracts for the status of the service agreement) and signed agreement hash\n        \"\"\"\n        assert consumer_account.address in self._keeper.accounts, f'Unrecognized consumer ' \\\n            f'address `consumer_account`'\n\n        agreement_id, signature = self._agreements.prepare(\n            did, service_definition_id, consumer_account\n        )\n        logger.debug(f'about to request create agreement: {agreement_id}')\n        self._agreements.send(\n            did,\n            agreement_id,\n            service_definition_id,\n            signature,\n            consumer_account,\n            auto_consume=auto_consume\n        )\n        return agreement_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconsume the asset data. Using the service endpoint defined in the ddo's service pointed to by service_definition_id. Consumer's permissions is checked implicitly by the secret-store during decryption of the contentUrls. The service endpoint is expected to also verify the consumer's permissions to consume this asset. This method downloads and saves the asset datafiles to disk. :param service_agreement_id: str :param did: DID, str :param service_definition_id: identifier of the service inside the asset DDO, str :param consumer_account: Account instance of the consumer :param destination: str path :param index: Index of the document that is going to be downloaded, int :return: str path to saved files", "response": "def consume(self, service_agreement_id, did, service_definition_id, consumer_account,\n                destination, index=None):\n        \"\"\"\n        Consume the asset data.\n\n        Using the service endpoint defined in the ddo's service pointed to by service_definition_id.\n        Consumer's permissions is checked implicitly by the secret-store during decryption\n        of the contentUrls.\n        The service endpoint is expected to also verify the consumer's permissions to consume this\n        asset.\n        This method downloads and saves the asset datafiles to disk.\n\n        :param service_agreement_id: str\n        :param did: DID, str\n        :param service_definition_id: identifier of the service inside the asset DDO, str\n        :param consumer_account: Account instance of the consumer\n        :param destination: str path\n        :param index: Index of the document that is going to be downloaded, int\n        :return: str path to saved files\n        \"\"\"\n        ddo = self.resolve(did)\n        if index is not None:\n            assert isinstance(index, int), logger.error('index has to be an integer.')\n            assert index >= 0, logger.error('index has to be 0 or a positive integer.')\n        return self._asset_consumer.download(\n            service_agreement_id,\n            service_definition_id,\n            ddo,\n            consumer_account,\n            destination,\n            BrizoProvider.get_brizo(),\n            self._get_secret_store(consumer_account),\n            index\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nproposes a new template.", "response": "def propose(self, template_address, account):\n        \"\"\"\n        Propose a new template.\n\n        :param template_address: Address of the template contract, str\n        :param account: account proposing the template, Account\n        :return: bool\n        \"\"\"\n        try:\n            proposed = self._keeper.template_manager.propose_template(template_address, account)\n            return proposed\n        except ValueError as err:\n            template_values = self._keeper.template_manager.get_template(template_address)\n            if not template_values:\n                logger.warning(f'Propose template failed: {err}')\n                return False\n\n            if template_values.state != 1:\n                logger.warning(\n                    f'Propose template failed, current state is set to {template_values.state}')\n                return False\n\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef approve(self, template_address, account):\n        try:\n            approved = self._keeper.template_manager.approve_template(template_address, account)\n            return approved\n        except ValueError as err:\n            template_values = self._keeper.template_manager.get_template(template_address)\n            if not template_values:\n                logger.warning(f'Approve template failed: {err}')\n                return False\n\n            if template_values.state == 1:\n                logger.warning(f'Approve template failed, this template is '\n                               f'currently in \"proposed\" state.')\n                return False\n\n            if template_values.state == 3:\n                logger.warning(f'Approve template failed, this template appears to be '\n                               f'revoked.')\n                return False\n\n            if template_values.state == 2:\n                return True\n\n            return False", "response": "Approve a template already proposed. The account needs to be owner of the templateManager\n        contract to be able of approve the template.\n\n        :param template_address: Address of the template contract, str\n        :param account: account approving the template, Account\n        :return: bool"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revoke(self, template_address, account):\n        try:\n            revoked = self._keeper.template_manager.revoke_template(template_address, account)\n            return revoked\n        except ValueError as err:\n            template_values = self._keeper.template_manager.get_template(template_address)\n            if not template_values:\n                logger.warning(f'Cannot revoke template since it does not exist: {err}')\n                return False\n\n            logger.warning(f'Only template admin or owner can revoke a template: {err}')\n            return False", "response": "Revoke a template already approved."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the price from the conditions parameters.", "response": "def get_price(self):\n        \"\"\"\n        Return the price from the conditions parameters.\n\n        :return: Int\n        \"\"\"\n        for cond in self.conditions:\n            for p in cond.parameters:\n                if p.name == '_amount':\n                    return p.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_service_agreement_hash(\n            self, agreement_id, asset_id, consumer_address, publisher_address, keeper):\n        \"\"\"Return the hash of the service agreement values to be signed by a consumer.\n\n        :param agreement_id:id of the agreement, hex str\n        :param asset_id:\n        :param consumer_address: ethereum account address of consumer, hex str\n        :param publisher_address: ethereum account address of publisher, hex str\n        :param keeper:\n        :return:\n        \"\"\"\n        agreement_hash = ServiceAgreement.generate_service_agreement_hash(\n            self.template_id,\n            self.generate_agreement_condition_ids(\n                agreement_id, asset_id, consumer_address, publisher_address, keeper),\n            self.conditions_timelocks,\n            self.conditions_timeouts,\n            agreement_id\n        )\n        return agreement_hash", "response": "Return the hash of the service agreement values to be signed by a consumer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the path where the keeper - contracts artifacts are allocated.", "response": "def keeper_path(self):\n        \"\"\"Path where the keeper-contracts artifacts are allocated.\"\"\"\n        keeper_path_string = self.get(self._section_name, NAME_KEEPER_PATH)\n        path = Path(keeper_path_string).expanduser().resolve()\n        # TODO: Handle the default case and make default empty string\n        # assert path.exists(), \"Can't find the keeper path: {} ({})\"..format(keeper_path_string,\n        # path)\n        if os.path.exists(path):\n            pass\n        elif os.getenv('VIRTUAL_ENV'):\n            path = os.path.join(os.getenv('VIRTUAL_ENV'), 'artifacts')\n        else:\n            path = os.path.join(site.PREFIXES[0], 'artifacts')\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a public key object to the list of public keys.", "response": "def add_public_key(self, did, public_key):\n        \"\"\"\n        Add a public key object to the list of public keys.\n\n        :param public_key: Public key, PublicKeyHex\n        \"\"\"\n        logger.debug(f'Adding public key {public_key} to the did {did}')\n        self._public_keys.append(\n            PublicKeyBase(did, **{\"owner\": public_key, \"type\": \"EthereumECDSAKey\"}))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_authentication(self, public_key, authentication_type=None):\n        authentication = {}\n        if public_key:\n            authentication = {'type': authentication_type, 'publicKey': public_key}\n        logger.debug(f'Adding authentication {authentication}')\n        self._authentications.append(authentication)", "response": "Add a authentication public key id and type to the list of authentications."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_service(self, service_type, service_endpoint=None, values=None):\n        if isinstance(service_type, Service):\n            service = service_type\n        else:\n            service = Service(service_endpoint, service_type, values, did=self._did)\n        logger.debug(f'Adding service with service type {service_type} with did {self._did}')\n        self._services.append(service)", "response": "Add a service to the list of services on the DDO."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_text(self, is_proof=True, is_pretty=False):\n        data = self.as_dictionary(is_proof)\n        if is_pretty:\n            return json.dumps(data, indent=2, separators=(',', ': '))\n\n        return json.dumps(data)", "response": "Return the DDO as a JSON text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_dictionary(self, is_proof=True):\n        if self._created is None:\n            self._created = DDO._get_timestamp()\n\n        data = {\n            '@context': DID_DDO_CONTEXT_URL,\n            'id': self._did,\n            'created': self._created,\n        }\n        if self._public_keys:\n            values = []\n            for public_key in self._public_keys:\n                values.append(public_key.as_dictionary())\n            data['publicKey'] = values\n        if self._authentications:\n            values = []\n            for authentication in self._authentications:\n                values.append(authentication)\n            data['authentication'] = values\n        if self._services:\n            values = []\n            for service in self._services:\n                values.append(service.as_dictionary())\n            data['service'] = values\n        if self._proof and is_proof:\n            data['proof'] = self._proof\n\n        return data", "response": "Return the DDO as a JSON dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_dict(self, dictionary):\n        values = dictionary\n        self._did = values['id']\n        self._created = values.get('created', None)\n        if 'publicKey' in values:\n            self._public_keys = []\n            for value in values['publicKey']:\n                if isinstance(value, str):\n                    value = json.loads(value)\n                self._public_keys.append(DDO.create_public_key_from_json(value))\n        if 'authentication' in values:\n            self._authentications = []\n            for value in values['authentication']:\n                if isinstance(value, str):\n                    value = json.loads(value)\n                self._authentications.append(DDO.create_authentication_from_json(value))\n        if 'service' in values:\n            self._services = []\n            for value in values['service']:\n                if isinstance(value, str):\n                    value = json.loads(value)\n                service = Service.from_json(value)\n                service.set_did(self._did)\n                self._services.append(service)\n        if 'proof' in values:\n            self._proof = values['proof']", "response": "Import a JSON dict into this DDO."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a proof to the DDO based on the public_key id and signed with the private key.", "response": "def add_proof(self, text, publisher_account, keeper):\n        \"\"\"Add a proof to the DDO, based on the public_key id/index and signed with the private key\n        add a static proof to the DDO, based on one of the public keys.\"\"\"\n\n        # just incase clear out the current static proof property\n        self._proof = None\n        self._proof = {\n            'type': PROOF_TYPE,\n            'created': DDO._get_timestamp(),\n            'creator': publisher_account.address,\n            'signatureValue': keeper.sign_hash(text, publisher_account),\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_public_key(self, key_id, is_search_embedded=False):\n        if isinstance(key_id, int):\n            return self._public_keys[key_id]\n\n        for item in self._public_keys:\n            if item.get_id() == key_id:\n                return item\n\n        if is_search_embedded:\n            for authentication in self._authentications:\n                if authentication.get_public_key_id() == key_id:\n                    return authentication.get_public_key()\n        return None", "response": "Returns the public key for the given key_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the count of public keys in the list and embedded.", "response": "def _get_public_key_count(self):\n        \"\"\"Return the count of public keys in the list and embedded.\"\"\"\n        index = len(self._public_keys)\n        for authentication in self._authentications:\n            if authentication.is_public_key():\n                index += 1\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_authentication_from_public_key_id(self, key_id):\n        for authentication in self._authentications:\n            if authentication.is_key_id(key_id):\n                return authentication\n        return None", "response": "Return the authentication based on the public key id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_service(self, service_type=None):\n        for service in self._services:\n            if service.type == service_type and service_type:\n                return service\n        return None", "response": "Return a service using."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_service_by_id(self, service_id):\n        service_id_key = 'serviceDefinitionId'\n        service_id = str(service_id)\n        for service in self._services:\n            if service_id_key in service.values and str(\n                    service.values[service_id_key]) == service_id:\n                return service\n\n        try:\n            # If service_id is int or can be converted to int then we couldn't find it\n            int(service_id)\n            return None\n        except ValueError:\n            pass\n\n        # try to find by type\n        return self.find_service_by_type(service_id)", "response": "Find a service by its id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding a service by type.", "response": "def find_service_by_type(self, service_type):\n        \"\"\"\n        Get service for a given service type.\n\n        :param service_type: Service type, ServiceType\n        :return: Service\n        \"\"\"\n        for service in self._services:\n            if service_type == service.type:\n                return service\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_public_key_from_json(values):\n        # currently we only support RSA public keys\n        _id = values.get('id')\n        if not _id:\n            # Make it more forgiving for now.\n            _id = ''\n            # raise ValueError('publicKey definition is missing the \"id\" value.')\n\n        if values.get('type') == PUBLIC_KEY_TYPE_RSA:\n            public_key = PublicKeyRSA(_id, owner=values.get('owner'))\n        else:\n            public_key = PublicKeyBase(_id, owner=values.get('owner'), type='EthereumECDSAKey')\n\n        public_key.set_key_value(values)\n        return public_key", "response": "Create a public key object based on the values from the JSON record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate authentitaciton object from a JSON string.", "response": "def create_authentication_from_json(values):\n        \"\"\"Create authentitaciton object from a JSON string.\"\"\"\n        key_id = values.get('publicKey')\n        authentication_type = values.get('type')\n        if not key_id:\n            raise ValueError(\n                f'Invalid authentication definition, \"publicKey\" is missing: {values}')\n\n        authentication = {'type': authentication_type, 'publicKey': key_id}\n\n        return authentication"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the hash for integrity checksum.", "response": "def generate_checksum(did, metadata):\n        \"\"\"\n        Generation of the hash for integrity checksum.\n\n        :param did: DID, str\n        :param metadata: conforming to the Metadata accepted by Ocean Protocol, dict\n        :return: hex str\n        \"\"\"\n        files_checksum = ''\n        for file in metadata['base']['files']:\n            if 'checksum' in file:\n                files_checksum = files_checksum + file['checksum']\n        return hashlib.sha3_256((files_checksum +\n                                 metadata['base']['name'] +\n                                 metadata['base']['author'] +\n                                 metadata['base']['license'] +\n                                 did).encode('UTF-8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters or update a DID on the block chain using the DIDRegistry smart contract.", "response": "def register(self, did, checksum, url, account, providers=None):\n        \"\"\"\n        Register or update a DID on the block chain using the DIDRegistry smart contract.\n\n        :param did: DID to register/update, can be a 32 byte or hexstring\n        :param checksum: hex str hash of TODO\n        :param url: URL of the resolved DID\n        :param account: instance of Account to use to register/update the DID\n        :param providers: list of addresses of providers to be allowed to serve the asset and play\n            a part in creating and fulfilling service agreements\n        :return: Receipt\n        \"\"\"\n\n        did_source_id = did_to_id_bytes(did)\n        if not did_source_id:\n            raise ValueError(f'{did} must be a valid DID to register')\n\n        if not urlparse(url):\n            raise ValueError(f'Invalid URL {url} to register for DID {did}')\n\n        if checksum is None:\n            checksum = Web3Provider.get_web3().toBytes(0)\n\n        if not isinstance(checksum, bytes):\n            raise ValueError(f'Invalid checksum value {checksum}, must be bytes or string')\n\n        if account is None:\n            raise ValueError('You must provide an account to use to register a DID')\n\n        transaction = self._register_attribute(\n            did_source_id, checksum, url, account, providers or []\n        )\n        receipt = self.get_tx_receipt(transaction)\n        return receipt and receipt.status == 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister an attribute on the block chain.", "response": "def _register_attribute(self, did, checksum, value, account, providers):\n        \"\"\"Register an DID attribute as an event on the block chain.\n\n        :param did: 32 byte string/hex of the DID\n        :param checksum: checksum of the ddo, hex str\n        :param value: url for resolve the did, str\n        :param account: account owner of this DID registration record\n        :param providers: list of providers addresses\n        \"\"\"\n        assert isinstance(providers, list), ''\n        return self.send_transaction(\n            'registerAttribute',\n            (did,\n             checksum,\n             providers,\n             value),\n            transact={'from': account.address,\n                      'passphrase': account.password}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_provider(self, did, provider_address, account):\n        tx_hash = self.send_transaction(\n            'removeDIDProvider',\n            (did,\n             provider_address),\n            transact={'from': account.address,\n                      'passphrase': account.password}\n        )\n        return self.get_tx_receipt(tx_hash)", "response": "Remove a provider from the DID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_did_providers(self, did):\n        register_values = self.contract_concise.getDIDRegister(did)\n        if register_values and len(register_values) == 5:\n            return DIDRegisterValues(*register_values).providers\n\n        return None", "response": "Returns the list of providers registered on - chain for the given did."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of assets owned by an address owner.", "response": "def get_owner_asset_ids(self, address):\n        \"\"\"\n        Get the list of assets owned by an address owner.\n\n        :param address: ethereum account address, hex str\n        :return:\n        \"\"\"\n        block_filter = self._get_event_filter(owner=address)\n        log_items = block_filter.get_all_entries(max_tries=5)\n        did_list = []\n        for log_i in log_items:\n            did_list.append(id_to_did(log_i.args['_did']))\n\n        return did_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value based on the type of encoding supported by RSA.", "response": "def set_encode_key_value(self, value, store_type=PUBLIC_KEY_STORE_TYPE_BASE64):\n        \"\"\"Set the value based on the type of encoding supported by RSA.\"\"\"\n        if store_type == PUBLIC_KEY_STORE_TYPE_PEM:\n            PublicKeyBase.set_encode_key_value(self, value.exportKey('PEM').decode(), store_type)\n        else:\n            PublicKeyBase.set_encode_key_value(self, value.exportKey('DER'), store_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a DID into its parts.", "response": "def did_parse(did):\n    \"\"\"\n    Parse a DID into it's parts.\n\n    :param did: Asset did, str.\n    :return: Python dictionary with the method and the id.\n    \"\"\"\n    if not isinstance(did, str):\n        raise TypeError(f'Expecting DID of string type, got {did} of {type(did)} type')\n\n    match = re.match('^did:([a-z0-9]+):([a-zA-Z0-9-.]+)(.*)', did)\n    if not match:\n        raise ValueError(f'DID {did} does not seem to be valid.')\n\n    result = {\n        'method': match.group(1),\n        'id': match.group(2),\n    }\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an Ocean DID from given a hex id.", "response": "def id_to_did(did_id, method='op'):\n    \"\"\"Return an Ocean DID from given a hex id.\"\"\"\n    if isinstance(did_id, bytes):\n        did_id = Web3.toHex(did_id)\n\n    # remove leading '0x' of a hex string\n    if isinstance(did_id, str):\n        did_id = remove_0x_prefix(did_id)\n    else:\n        raise TypeError(\"did id must be a hex string or bytes\")\n\n    # test for zero address\n    if Web3.toBytes(hexstr=did_id) == b'':\n        did_id = '0'\n    return f'did:{method}:{did_id}'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef did_to_id_bytes(did):\n    if isinstance(did, str):\n        if re.match('^[0x]?[0-9A-Za-z]+$', did):\n            raise ValueError(f'{did} must be a DID not a hex string')\n        else:\n            did_result = did_parse(did)\n            if not did_result:\n                raise ValueError(f'{did} is not a valid did')\n            if not did_result['id']:\n                raise ValueError(f'{did} is not a valid ocean did')\n            id_bytes = Web3.toBytes(hexstr=did_result['id'])\n    elif isinstance(did, bytes):\n        id_bytes = did\n    else:\n        raise TypeError(\n            f'Unknown did format, expected str or bytes, got {did} of type {type(did)}')\n    return id_bytes", "response": "Return an Ocean DID to it s correspondng hex id in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_template(self, template_id):\n        template = self.contract_concise.getTemplate(template_id)\n        if template and len(template) == 4:\n            return AgreementTemplate(*template)\n\n        return None", "response": "Get the template for a given template id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef propose_template(self, template_id, from_account):\n        tx_hash = self.send_transaction(\n            'proposeTemplate',\n            (template_id,),\n            transact={'from': from_account.address,\n                      'passphrase': from_account.password})\n        return self.get_tx_receipt(tx_hash).status == 1", "response": "Propose a template.\n\n        :param template_id: id of the template, str\n        :param from_account: Account\n        :return: bool"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an access service descriptor.", "response": "def access_service_descriptor(price, consume_endpoint, service_endpoint, timeout, template_id):\n        \"\"\"\n        Access service descriptor.\n\n        :param price: Asset price, int\n        :param consume_endpoint: url of the service provider, str\n        :param service_endpoint: identifier of the service inside the asset DDO, str\n        :param timeout: amount of time in seconds before the agreement expires, int\n        :param template_id: id of the template use to create the service, str\n        :return: Service descriptor.\n        \"\"\"\n        return (ServiceTypes.ASSET_ACCESS,\n                {'price': price, 'consumeEndpoint': consume_endpoint,\n                 'serviceEndpoint': service_endpoint,\n                 'timeout': timeout, 'templateId': template_id})"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes service descriptor. :param price: Asset price, int :param consume_endpoint: url of the service provider, str :param service_endpoint: identifier of the service inside the asset DDO, str :param timeout: amount of time in seconds before the agreement expires, int :return: Service descriptor.", "response": "def compute_service_descriptor(price, consume_endpoint, service_endpoint, timeout):\n        \"\"\"\n        Compute service descriptor.\n\n        :param price: Asset price, int\n        :param consume_endpoint: url of the service provider, str\n        :param service_endpoint: identifier of the service inside the asset DDO, str\n        :param timeout: amount of time in seconds before the agreement expires, int\n        :return: Service descriptor.\n        \"\"\"\n        return (ServiceTypes.CLOUD_COMPUTE,\n                {'price': price, 'consumeEndpoint': consume_endpoint,\n                 'serviceEndpoint': service_endpoint,\n                 'timeout': timeout})"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a list of services.", "response": "def build_services(did, service_descriptors):\n        \"\"\"\n        Build a list of services.\n\n        :param did: DID, str\n        :param service_descriptors: List of tuples of length 2. The first item must be one of\n        ServiceTypes\n        and the second item is a dict of parameters and values required by the service\n        :return: List of Services\n        \"\"\"\n        services = []\n        sa_def_key = ServiceAgreement.SERVICE_DEFINITION_ID\n        for i, service_desc in enumerate(service_descriptors):\n            service = ServiceFactory.build_service(service_desc, did)\n            # set serviceDefinitionId for each service\n            service.update_value(sa_def_key, str(i))\n            services.append(service)\n\n        return services"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a service from a service descriptor.", "response": "def build_service(service_descriptor, did):\n        \"\"\"\n        Build a service.\n\n        :param service_descriptor: Tuples of length 2. The first item must be one of ServiceTypes\n        and the second item is a dict of parameters and values required by the service\n        :param did: DID, str\n        :return: Service\n        \"\"\"\n        assert isinstance(service_descriptor, tuple) and len(\n            service_descriptor) == 2, 'Unknown service descriptor format.'\n        service_type, kwargs = service_descriptor\n        if service_type == ServiceTypes.METADATA:\n            return ServiceFactory.build_metadata_service(\n                did,\n                kwargs['metadata'],\n                kwargs['serviceEndpoint']\n            )\n\n        elif service_type == ServiceTypes.AUTHORIZATION:\n            return ServiceFactory.build_authorization_service(\n                kwargs['serviceEndpoint']\n            )\n\n        elif service_type == ServiceTypes.ASSET_ACCESS:\n            return ServiceFactory.build_access_service(\n                did, kwargs['price'],\n                kwargs['consumeEndpoint'], kwargs['serviceEndpoint'],\n                kwargs['timeout'], kwargs['templateId']\n            )\n\n        elif service_type == ServiceTypes.CLOUD_COMPUTE:\n            return ServiceFactory.build_compute_service(\n                did, kwargs['price'],\n                kwargs['consumeEndpoint'], kwargs['serviceEndpoint'], kwargs['timeout']\n            )\n\n        raise ValueError(f'Unknown service type {service_type}')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a metadata service.", "response": "def build_metadata_service(did, metadata, service_endpoint):\n        \"\"\"\n        Build a metadata service.\n\n        :param did: DID, str\n        :param metadata: conforming to the Metadata accepted by Ocean Protocol, dict\n        :param service_endpoint: identifier of the service inside the asset DDO, str\n        :return: Service\n        \"\"\"\n        return Service(service_endpoint,\n                       ServiceTypes.METADATA,\n                       values={'metadata': metadata},\n                       did=did)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_access_service(did, price, consume_endpoint, service_endpoint, timeout, template_id):\n        # TODO fill all the possible mappings\n        param_map = {\n            '_documentId': did_to_id(did),\n            '_amount': price,\n            '_rewardAddress': Keeper.get_instance().escrow_reward_condition.address,\n        }\n        sla_template_path = get_sla_template_path()\n        sla_template = ServiceAgreementTemplate.from_json_file(sla_template_path)\n        sla_template.template_id = template_id\n        conditions = sla_template.conditions[:]\n        for cond in conditions:\n            for param in cond.parameters:\n                param.value = param_map.get(param.name, '')\n\n            if cond.timeout > 0:\n                cond.timeout = timeout\n\n        sla_template.set_conditions(conditions)\n        sa = ServiceAgreement(\n            1,\n            sla_template,\n            consume_endpoint,\n            service_endpoint,\n            ServiceTypes.ASSET_ACCESS\n        )\n        sa.set_did(did)\n        return sa", "response": "Builds the access service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fulfill(self, agreement_id, reward_address, amount, account):\n        return self._fulfill(\n            agreement_id,\n            reward_address,\n            amount,\n            transact={'from': account.address,\n                      'passphrase': account.password}\n        )", "response": "Fulfill the lock reward condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef record_service_agreement(storage_path, service_agreement_id, did, service_definition_id, price,\n                             files, start_time,\n                             status='pending'):\n    \"\"\"\n    Records the given pending service agreement.\n\n    :param storage_path: storage path for the internal db, str\n    :param service_agreement_id:\n    :param did: DID, str\n    :param service_definition_id: identifier of the service inside the asset DDO, str\n    :param price: Asset price, int\n    :param files:\n    :param start_time:\n    :param status:\n    :return:\n    \"\"\"\n    conn = sqlite3.connect(storage_path)\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\n            '''CREATE TABLE IF NOT EXISTS service_agreements\n               (id VARCHAR PRIMARY KEY, did VARCHAR, service_definition_id INTEGER, \n                price INTEGER, files VARCHAR, start_time INTEGER, status VARCHAR(10));'''\n        )\n        cursor.execute(\n            'INSERT OR REPLACE INTO service_agreements VALUES (?,?,?,?,?,?,?)',\n            [service_agreement_id, did, service_definition_id, price, files, start_time,\n             status],\n        )\n        conn.commit()\n    finally:\n        conn.close()", "response": "Records the given pending service agreement."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the status of a specific service agreement.", "response": "def update_service_agreement_status(storage_path, service_agreement_id, status='pending'):\n    \"\"\"\n    Update the service agreement status.\n\n    :param storage_path: storage path for the internal db, str\n    :param service_agreement_id:\n    :param status:\n    :return:\n    \"\"\"\n    conn = sqlite3.connect(storage_path)\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\n            'UPDATE service_agreements SET status=? WHERE id=?',\n            (status, service_agreement_id),\n        )\n        conn.commit()\n    finally:\n        conn.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_service_agreements(storage_path, status='pending'):\n    conn = sqlite3.connect(storage_path)\n    try:\n        cursor = conn.cursor()\n        return [\n            row for row in\n            cursor.execute(\n                '''\n                SELECT id, did, service_definition_id, price, files, start_time, status\n                FROM service_agreements \n                WHERE status=?;\n                ''',\n                (status,))\n        ]\n    finally:\n        conn.close()", "response": "Get the list of service agreements pending to be executed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencrypts string data using the DID as an secret store id and the account instance as the account instance", "response": "def encrypt(self, document_id, content, account):\n        \"\"\"\n        Encrypt string data using the DID as an secret store id,\n        if secret store is enabled then return the result from secret store encryption\n\n        None for no encryption performed\n\n        :param document_id: hex str id of document to use for encryption session\n        :param content: str to be encrypted\n        :param account: Account instance encrypting this content\n        :return: hex str encrypted content\n        \"\"\"\n        return self._secret_store(account).encrypt_document(document_id, content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nresolve a DID to an URL or DDO or later an internal or external DID.", "response": "def resolve(self, did):\n        \"\"\"\n        Resolve a DID to an URL/DDO or later an internal/external DID.\n\n        :param did: 32 byte value or DID string to resolver, this is part of the ocean\n            DID did:op:<32 byte value>\n        :return string: URL or DDO of the resolved DID\n        :return None: if the DID cannot be resolved\n        :raises ValueError: if did is invalid\n        :raises TypeError: if did has invalid format\n        :raises TypeError: on non 32byte value as the DID\n        :raises TypeError: on any of the resolved values are not string/DID bytes.\n        :raises OceanDIDNotFound: if no DID can be found to resolve.\n        \"\"\"\n\n        did_bytes = did_to_id_bytes(did)\n        if not isinstance(did_bytes, bytes):\n            raise TypeError('Invalid did: a 32 Byte DID value required.')\n\n        # resolve a DID to a DDO\n        url = self.get_resolve_url(did_bytes)\n        logger.debug(f'found did {did} -> url={url}')\n        return AquariusProvider.get_aquarius(url).get_asset_ddo(did)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_resolve_url(self, did_bytes):\n        data = self._did_registry.get_registered_attribute(did_bytes)\n        if not (data and data.get('value')):\n            return None\n\n        return data['value']", "response": "Get a did value and value type from the block chain event record using did."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an instance of the class with the given name.", "response": "def get_instance(cls, dependencies=None):\n        \"\"\"\n        Return an instance for a contract name.\n\n        :param dependencies:\n        :return: Contract base instance\n        \"\"\"\n        assert cls is not ContractBase, 'ContractBase is not meant to be used directly.'\n        assert cls.CONTRACT_NAME, 'CONTRACT_NAME must be set to a valid keeper contract name.'\n        return cls(cls.CONTRACT_NAME, dependencies)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the receipt of a tx.", "response": "def get_tx_receipt(tx_hash):\n        \"\"\"\n        Get the receipt of a tx.\n\n        :param tx_hash: hash of the transaction\n        :return: Tx receipt\n        \"\"\"\n        try:\n            Web3Provider.get_web3().eth.waitForTransactionReceipt(tx_hash, timeout=20)\n        except Timeout:\n            logger.info('Waiting for transaction receipt timed out.')\n            return\n        return Web3Provider.get_web3().eth.getTransactionReceipt(tx_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a listener for the event choose.", "response": "def subscribe_to_event(self, event_name, timeout, event_filter, callback=False,\n                           timeout_callback=None, args=None, wait=False):\n        \"\"\"\n        Create a listener for the event choose.\n\n        :param event_name: name of the event to subscribe, str\n        :param timeout:\n        :param event_filter:\n        :param callback:\n        :param timeout_callback:\n        :param args:\n        :param wait: if true block the listener until get the event, bool\n        :return:\n        \"\"\"\n        from squid_py.keeper.event_listener import EventListener\n        return EventListener(\n            self.CONTRACT_NAME,\n            event_name,\n            args,\n            filters=event_filter\n        ).listen_once(\n            callback,\n            timeout_callback=timeout_callback,\n            timeout=timeout,\n            blocking=wait\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling a smart contract function using personal_sendTransaction or ether_sendTransaction.", "response": "def send_transaction(self, fn_name, fn_args, transact=None):\n        \"\"\"Calls a smart contract function using either `personal_sendTransaction` (if\n        passphrase is available) or `ether_sendTransaction`.\n\n        :param fn_name: str the smart contract function name\n        :param fn_args: tuple arguments to pass to function above\n        :param transact: dict arguments for the transaction such as from, gas, etc.\n        :return:\n        \"\"\"\n        contract_fn = getattr(self.contract.functions, fn_name)(*fn_args)\n        contract_function = SquidContractFunction(\n            contract_fn\n        )\n        return contract_function.transact(transact)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refund_reward(event, agreement_id, did, service_agreement, price, consumer_account,\n                  publisher_address, condition_ids):\n    \"\"\"\n    Refund the reward to the publisher address.\n\n    :param event: AttributeDict with the event data.\n    :param agreement_id: id of the agreement, hex str\n    :param did: DID, str\n    :param service_agreement: ServiceAgreement instance\n    :param price: Asset price, int\n    :param consumer_account: Account instance of the consumer\n    :param publisher_address: ethereum account address of publisher, hex str\n    :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n    \"\"\"\n    logger.debug(f\"trigger refund after event {event}.\")\n    access_id, lock_id = condition_ids[:2]\n    name_to_parameter = {param.name: param for param in\n                         service_agreement.condition_by_name['escrowReward'].parameters}\n    document_id = add_0x_prefix(name_to_parameter['_documentId'].value)\n    asset_id = add_0x_prefix(did_to_id(did))\n    assert document_id == asset_id, f'document_id {document_id} <=> asset_id {asset_id} mismatch.'\n    assert price == service_agreement.get_price(), 'price mismatch.'\n    # logger.info(f'About to do grantAccess: account {account.address},\n    # saId {service_agreement_id}, '\n    #             f'documentKeyId {document_key_id}')\n    try:\n        tx_hash = Keeper.get_instance().escrow_reward_condition.fulfill(\n            agreement_id,\n            price,\n            publisher_address,\n            consumer_account.address,\n            lock_id,\n            access_id,\n            consumer_account\n        )\n        process_tx_receipt(\n            tx_hash,\n            Keeper.get_instance().escrow_reward_condition.FULFILLED_EVENT,\n            'EscrowReward.Fulfilled'\n        )\n    except Exception as e:\n        # logger.error(f'Error when doing escrow_reward_condition.fulfills: {e}')\n        raise e", "response": "Refund the reward to the publisher address."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies that the keeper contracts are deployed correctly in the network.", "response": "def verify_contracts():\n        \"\"\"\n        Verify that the contracts are deployed correctly in the network.\n\n        :raise Exception: raise exception if the contracts are not deployed correctly.\n        \"\"\"\n        artifacts_path = ConfigProvider.get_config().keeper_path\n        logger.info(f'Keeper contract artifacts (JSON abi files) at: {artifacts_path}')\n\n        if os.environ.get('KEEPER_NETWORK_NAME'):\n            logger.warning(f'The `KEEPER_NETWORK_NAME` env var is set to '\n                           f'{os.environ.get(\"KEEPER_NETWORK_NAME\")}. '\n                           f'This enables the user to override the method of how the network name '\n                           f'is inferred from network id.')\n\n        # try to find contract with this network name\n        contract_name = Diagnostics.TEST_CONTRACT_NAME\n        network_id = Keeper.get_network_id()\n        network_name = Keeper.get_network_name(network_id)\n        logger.info(f'Using keeper contracts from network {network_name}, '\n                    f'network id is {network_id}')\n        logger.info(f'Looking for keeper contracts ending with \".{network_name}.json\", '\n                    f'e.g. \"{contract_name}.{network_name}.json\".')\n        existing_contract_names = os.listdir(artifacts_path)\n        try:\n            ContractHandler.get(contract_name)\n        except Exception as e:\n            logger.error(e)\n            logger.error(f'Cannot find the keeper contracts. \\n'\n                         f'Current network id is {network_id} and network name is {network_name}.'\n                         f'Expected to find contracts ending with \".{network_name}.json\",'\n                         f' e.g. \"{contract_name}.{network_name}.json\"')\n            raise OceanKeeperContractsNotFound(\n                f'Keeper contracts for keeper network {network_name} were not found '\n                f'in {artifacts_path}. \\n'\n                f'Found the following contracts: \\n\\t{existing_contract_names}'\n            )\n\n        keeper = Keeper.get_instance()\n        contracts = [keeper.dispenser, keeper.token, keeper.did_registry,\n                     keeper.agreement_manager, keeper.template_manager, keeper.condition_manager,\n                     keeper.access_secret_store_condition, keeper.sign_condition,\n                     keeper.lock_reward_condition, keeper.escrow_access_secretstore_template,\n                     keeper.escrow_reward_condition, keeper.hash_lock_condition\n                     ]\n        addresses = '\\n'.join([f'\\t{c.name}: {c.address}' for c in contracts])\n        logging.info('Finished loading keeper contracts:\\n'\n                     '%s', addresses)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an Access service instance based on the supplied attributes.", "response": "def create_access_service(price, service_endpoint, consume_endpoint, timeout=None):\n        \"\"\"\n        Publish an asset with an `Access` service according to the supplied attributes.\n\n        :param price: Asset price, int\n        :param service_endpoint: str URL for initiating service access request\n        :param consume_endpoint: str URL to consume service\n        :param timeout: int amount of time in seconds before the agreement expires\n        :return: Service instance or None\n        \"\"\"\n        timeout = timeout or 3600  # default to one hour timeout\n        service = ServiceDescriptor.access_service_descriptor(\n            price, service_endpoint, consume_endpoint, timeout, ''\n        )\n\n        return service"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfulfill the lock reward condition.", "response": "def fulfill_lock_reward_condition(event, agreement_id, price, consumer_account):\n    \"\"\"\n    Fulfill the lock reward condition.\n\n    :param event: AttributeDict with the event data.\n    :param agreement_id: id of the agreement, hex str\n    :param price: Asset price, int\n    :param consumer_account: Account instance of the consumer\n    \"\"\"\n    logger.debug(f\"about to lock reward after event {event}.\")\n    keeper = Keeper.get_instance()\n    tx_hash = None\n    try:\n        keeper.token.token_approve(keeper.lock_reward_condition.address, price, consumer_account)\n        tx_hash = keeper.lock_reward_condition.fulfill(\n            agreement_id, keeper.escrow_reward_condition.address, price, consumer_account\n        )\n        process_tx_receipt(\n            tx_hash,\n            keeper.lock_reward_condition.FULFILLED_EVENT,\n            'LockRewardCondition.Fulfilled'\n        )\n    except Exception as e:\n        logger.debug(f'error locking reward: {e}')\n        if not tx_hash:\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lock_reward(self, agreement_id, amount, account):\n        return self._keeper.lock_reward_condition.fulfill(\n            agreement_id, self._keeper.escrow_reward_condition.address, amount, account\n        )", "response": "Lock reward condition.\n\n        :param agreement_id: id of the agreement, hex str\n        :param amount: Amount of tokens, int\n        :param account: Account\n        :return: bool"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef grant_access(self, agreement_id, did, grantee_address, account):\n        return self._keeper.access_secret_store_condition.fulfill(\n            agreement_id, add_0x_prefix(did_to_id(did)), grantee_address, account\n        )", "response": "Grant access condition.\n\n        :param agreement_id: id of the agreement, hex str\n        :param did: DID, str\n        :param grantee_address: Address, hex str\n        :param account: Account\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreleasing reward condition. :param agreement_id: id of the agreement, hex str :param amount: Amount of tokens, int :param account: Account :return:", "response": "def release_reward(self, agreement_id, amount, account):\n        \"\"\"\n        Release reward condition.\n\n        :param agreement_id: id of the agreement, hex str\n        :param amount: Amount of tokens, int\n        :param account: Account\n        :return:\n        \"\"\"\n        agreement_values = self._keeper.agreement_manager.get_agreement(agreement_id)\n        consumer, provider = self._keeper.escrow_access_secretstore_template.get_agreement_data(\n            agreement_id)\n        access_id, lock_id = agreement_values.condition_ids[:2]\n        return self._keeper.escrow_reward_condition.fulfill(\n            agreement_id,\n            amount,\n            provider,\n            consumer,\n            lock_id,\n            access_id,\n            account\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refund_reward(self, agreement_id, amount, account):\n        return self.release_reward(agreement_id, amount, account)", "response": "Refund the reaward condition."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a ServiceAgreementTemplate from a json allocated in a path.", "response": "def from_json_file(cls, path):\n        \"\"\"\n        Return a template from a json allocated in a path.\n\n        :param path: string\n        :return: ServiceAgreementTemplate\n        \"\"\"\n        with open(path) as jsf:\n            template_json = json.load(jsf)\n            return cls(template_json=template_json)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_template_json(self, template_json):\n        assert template_json['type'] == self.DOCUMENT_TYPE, ''\n        self.template_id = template_json['templateId']\n        self.name = template_json.get('name')\n        self.creator = template_json.get('creator')\n        self.template = template_json['serviceAgreementTemplate']", "response": "Parse a template from a json dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the service agreement template as a dictionary.", "response": "def as_dictionary(self):\n        \"\"\"\n        Return the service agreement template as a dictionary.\n\n        :return: dict\n        \"\"\"\n        template = {\n            'contractName': self.contract_name,\n            'events': [e.as_dictionary() for e in self.agreement_events],\n            'fulfillmentOrder': self.fulfillment_order,\n            'conditionDependency': self.condition_dependency,\n            'conditions': [cond.as_dictionary() for cond in self.conditions]\n        }\n        return {\n            # 'type': self.DOCUMENT_TYPE,\n            'name': self.name,\n            'creator': self.creator,\n            'serviceAgreementTemplate': template\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting a number of tokens to be minted and transfered to account", "response": "def request(self, account, amount):\n        \"\"\"\n        Request a number of tokens to be minted and transfered to `account`\n\n        :param account: Account instance requesting the tokens\n        :param amount: int number of tokens to request\n        :return: bool\n        \"\"\"\n        return self._keeper.dispenser.request_tokens(amount, account)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transfer(self, receiver_address, amount, sender_account):\n        self._keeper.token.token_approve(receiver_address, amount,\n                                         sender_account)\n        self._keeper.token.transfer(receiver_address, amount, sender_account)", "response": "Transfer a number of tokens from sender_account to receiver_address"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_assets(self):\n        response = self.requests_session.get(self._base_url).content\n        if not response:\n            return {}\n\n        try:\n            asset_list = json.loads(response)\n        except TypeError:\n            asset_list = None\n        except ValueError:\n            raise ValueError(response.decode('UTF-8'))\n\n        if not asset_list:\n            return []\n\n        if 'ids' in asset_list:\n            return asset_list['ids']\n        return []", "response": "List all the assets registered in the aquarius instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_asset_ddo(self, did):\n        response = self.requests_session.get(f'{self.url}/{did}').content\n        if not response:\n            return {}\n        try:\n            parsed_response = json.loads(response)\n        except TypeError:\n            parsed_response = None\n        except ValueError:\n            raise ValueError(response.decode('UTF-8'))\n        if parsed_response is None:\n            return {}\n        return Asset(dictionary=parsed_response)", "response": "Retrieve asset ddo for a given did."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving asset metadata for a given DID.", "response": "def get_asset_metadata(self, did):\n        \"\"\"\n        Retrieve asset metadata for a given did.\n\n        :param did: Asset DID string\n        :return: metadata key of the DDO instance\n        \"\"\"\n        response = self.requests_session.get(f'{self._base_url}/metadata/{did}').content\n        if not response:\n            return {}\n        try:\n            parsed_response = json.loads(response)\n        except TypeError:\n            parsed_response = None\n        except ValueError:\n            raise ValueError(response.decode('UTF-8'))\n        if parsed_response is None:\n            return {}\n        return parsed_response['metadata']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_assets_ddo(self):\n        return json.loads(self.requests_session.get(self.url).content)", "response": "List all the ddos registered in the aquarius instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish_asset_ddo(self, ddo):\n        try:\n            asset_did = ddo.did\n            response = self.requests_session.post(self.url, data=ddo.as_text(),\n                                                  headers=self._headers)\n        except AttributeError:\n            raise AttributeError('DDO invalid. Review that all the required parameters are filled.')\n        if response.status_code == 500:\n            raise ValueError(\n                f'This Asset ID already exists! \\n\\tHTTP Error message: \\n\\t\\t{response.text}')\n        elif response.status_code != 201:\n            raise Exception(f'{response.status_code} ERROR Full error: \\n{response.text}')\n        elif response.status_code == 201:\n            response = json.loads(response.content)\n            logger.debug(f'Published asset DID {asset_did}')\n            return response\n        else:\n            raise Exception(f'Unhandled ERROR: status-code {response.status_code}, '\n                            f'error message {response.text}')", "response": "Publish an asset ddo in aquarius."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the ddo of an asset.", "response": "def update_asset_ddo(self, did, ddo):\n        \"\"\"\n        Update the ddo of a did already registered.\n\n        :param did: Asset DID string\n        :param ddo: DDO instance\n        :return: API response (depends on implementation)\n        \"\"\"\n        response = self.requests_session.put(f'{self.url}/{did}', data=ddo.as_text(),\n                                             headers=self._headers)\n        if response.status_code == 200 or response.status_code == 201:\n            return json.loads(response.content)\n        else:\n            raise Exception(f'Unable to update DDO: {response.content}')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching in aquarius using text query.", "response": "def text_search(self, text, sort=None, offset=100, page=1):\n        \"\"\"\n        Search in aquarius using text query.\n\n        Given the string aquarius will do a full-text query to search in all documents.\n\n        Currently implemented are the MongoDB and Elastic Search drivers.\n\n        For a detailed guide on how to search, see the MongoDB driver documentation:\n        mongodb driverCurrently implemented in:\n        https://docs.mongodb.com/manual/reference/operator/query/text/\n\n        And the Elastic Search documentation:\n        https://www.elastic.co/guide/en/elasticsearch/guide/current/full-text-search.html\n        Other drivers are possible according to each implementation.\n\n        :param text: String to be search.\n        :param sort: 1/-1 to sort ascending or descending.\n        :param offset: Integer with the number of elements displayed per page.\n        :param page: Integer with the number of page.\n        :return: List of DDO instance\n        \"\"\"\n        assert page >= 1, f'Invalid page value {page}. Required page >= 1.'\n        payload = {\"text\": text, \"sort\": sort, \"offset\": offset, \"page\": page}\n        response = self.requests_session.get(\n            f'{self.url}/query',\n            params=payload,\n            headers=self._headers\n        )\n        if response.status_code == 200:\n            return self._parse_search_response(response.content)\n        else:\n            raise Exception(f'Unable to search for DDO: {response.content}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries the DDO for the DDOs in the specified page.", "response": "def query_search(self, search_query, sort=None, offset=100, page=1):\n        \"\"\"\n        Search using a query.\n\n        Currently implemented is the MongoDB query model to search for documents according to:\n        https://docs.mongodb.com/manual/tutorial/query-documents/\n\n        And an Elastic Search driver, which implements a basic parser to convert the query into\n        elastic search format.\n\n        Example: query_search({\"price\":[0,10]})\n\n        :param search_query: Python dictionary, query following mongodb syntax\n        :param sort: 1/-1 to sort ascending or descending.\n        :param offset: Integer with the number of elements displayed per page.\n        :param page: Integer with the number of page.\n        :return: List of DDO instance\n        \"\"\"\n        assert page >= 1, f'Invalid page value {page}. Required page >= 1.'\n        search_query['sort'] = sort\n        search_query['offset'] = offset\n        search_query['page'] = page\n        response = self.requests_session.post(\n            f'{self.url}/query',\n            data=json.dumps(search_query),\n            headers=self._headers\n        )\n        if response.status_code == 200:\n            return self._parse_search_response(response.content)\n        else:\n            raise Exception(f'Unable to search for DDO: {response.content}')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretire asset ddo of Aquarius.", "response": "def retire_asset_ddo(self, did):\n        \"\"\"\n        Retire asset ddo of Aquarius.\n\n        :param did: Asset DID string\n        :return: API response (depends on implementation)\n        \"\"\"\n        response = self.requests_session.delete(f'{self.url}/{did}', headers=self._headers)\n        if response.status_code == 200:\n            logging.debug(f'Removed asset DID: {did} from metadata store')\n            return response\n\n        raise AquariusGenericError(f'Unable to remove DID: {response}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_metadata(self, metadata):\n        response = self.requests_session.post(\n            f'{self.url}/validate',\n            data=json.dumps(metadata),\n            headers=self._headers\n        )\n        if response.content == b'true\\n':\n            return True\n        else:\n            logger.info(self._parse_search_response(response.content))\n            return False", "response": "Validate that the metadata of your ddo is valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sla_template_path(service_type=ServiceTypes.ASSET_ACCESS):\n    if service_type == ServiceTypes.ASSET_ACCESS:\n        name = 'access_sla_template.json'\n    elif service_type == ServiceTypes.CLOUD_COMPUTE:\n        name = 'compute_sla_template.json'\n    elif service_type == ServiceTypes.FITCHAIN_COMPUTE:\n        name = 'fitchain_sla_template.json'\n    else:\n        raise ValueError(f'Invalid/unsupported service agreement type {service_type}')\n\n    return os.path.join(os.path.sep, *os.path.realpath(__file__).split(os.path.sep)[1:-1], name)", "response": "Get the path of the template for a ServiceType."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef balance(self, account):\n        return Balance(self._keeper.get_ether_balance(account.address),\n                       self._keeper.token.get_token_balance(account.address))", "response": "Return the balance of the account"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_service_agreement_consumer(storage_path, publisher_address, agreement_id, did,\n                                        service_agreement, service_definition_id, price,\n                                        encrypted_files, consumer_account, condition_ids,\n                                        consume_callback=None, start_time=None):\n    \"\"\"\n    Registers the given service agreement in the local storage.\n    Subscribes to the service agreement events.\n\n    :param storage_path: storage path for the internal db, str\n    :param publisher_address: ethereum account address of publisher, hex str\n    :param agreement_id: id of the agreement, hex str\n    :param did: DID, str\n    :param service_agreement: ServiceAgreement instance\n    :param service_definition_id: identifier of the service inside the asset DDO, str\n    :param price: Asset price, int\n    :param encrypted_files: resutl of the files encrypted by the secret store, hex str\n    :param consumer_account: Account instance of the consumer\n    :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n    :param consume_callback:\n    :param start_time: start time, int\n    \"\"\"\n    if start_time is None:\n        start_time = int(datetime.now().timestamp())\n\n    record_service_agreement(\n        storage_path, agreement_id, did, service_definition_id, price, encrypted_files, start_time)\n\n    process_agreement_events_consumer(\n        publisher_address, agreement_id, did, service_agreement,\n        price, consumer_account, condition_ids,\n        consume_callback\n    )", "response": "Registers the given service agreement in the local storage and subscribes to the service agreement events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the agreement events during the register of the consumer side of the service agreement.", "response": "def process_agreement_events_consumer(publisher_address, agreement_id, did, service_agreement,\n                                      price, consumer_account, condition_ids,\n                                      consume_callback):\n    \"\"\"\n    Process the agreement events during the register of the service agreement for the consumer side.\n\n    :param publisher_address: ethereum account address of publisher, hex str\n    :param agreement_id: id of the agreement, hex str\n    :param did: DID, str\n    :param service_agreement: ServiceAgreement instance\n    :param price: Asset price, int\n    :param consumer_account: Account instance of the consumer\n    :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n    :param consume_callback:\n    :return:\n    \"\"\"\n    conditions_dict = service_agreement.condition_by_name\n    events_manager = EventsManager.get_instance(Keeper.get_instance())\n    events_manager.watch_agreement_created_event(\n        agreement_id,\n        lock_reward_condition.fulfillLockRewardCondition,\n        None,\n        (agreement_id, price, consumer_account),\n        EVENT_WAIT_TIMEOUT,\n    )\n\n    if consume_callback:\n        def _refund_callback(_price, _publisher_address, _condition_ids):\n            def do_refund(_event, _agreement_id, _did, _service_agreement, _consumer_account, *_):\n                escrow_reward_condition.refund_reward(\n                    _event, _agreement_id, _did, _service_agreement, _price,\n                    _consumer_account, _publisher_address, _condition_ids\n                )\n\n            return do_refund\n\n        events_manager.watch_access_event(\n            agreement_id,\n            escrow_reward_condition.consume_asset,\n            _refund_callback(price, publisher_address, condition_ids),\n            (agreement_id, did, service_agreement, consumer_account, consume_callback),\n            conditions_dict['accessSecretStore'].timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister the given service agreement in the local storage.", "response": "def register_service_agreement_publisher(storage_path, consumer_address, agreement_id, did,\n                                         service_agreement, service_definition_id, price,\n                                         publisher_account, condition_ids, start_time=None):\n    \"\"\"\n    Registers the given service agreement in the local storage.\n    Subscribes to the service agreement events.\n\n    :param storage_path:storage path for the internal db, str\n    :param consumer_address: ethereum account address of consumer, hex str\n    :param agreement_id: id of the agreement, hex str\n    :param did: DID, str\n    :param service_agreement: ServiceAgreement instance\n    :param service_definition_id: identifier of the service inside the asset DDO, str\n    :param price: Asset price, int\n    :param publisher_account: Account instance of the publisher\n    :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n    :param start_time:\n    :return:\n    \"\"\"\n    if start_time is None:\n        start_time = int(datetime.now().timestamp())\n\n    record_service_agreement(\n        storage_path, agreement_id, did, service_definition_id, price, '', start_time)\n\n    process_agreement_events_publisher(\n        publisher_account, agreement_id, did, service_agreement,\n        price, consumer_address, condition_ids\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess the events during the register of the service agreement for the publisher side", "response": "def process_agreement_events_publisher(publisher_account, agreement_id, did, service_agreement,\n                                       price, consumer_address, condition_ids):\n    \"\"\"\n    Process the agreement events during the register of the service agreement for the publisher side\n\n    :param publisher_account: Account instance of the publisher\n    :param agreement_id: id of the agreement, hex str\n    :param did: DID, str\n    :param service_agreement: ServiceAgreement instance\n    :param price: Asset price, int\n    :param consumer_address: ethereum account address of consumer, hex str\n    :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n    :return:\n    \"\"\"\n    conditions_dict = service_agreement.condition_by_name\n    events_manager = EventsManager.get_instance(Keeper.get_instance())\n    events_manager.watch_lock_reward_event(\n        agreement_id,\n        access_secret_store_condition.fulfillAccessSecretStoreCondition,\n        None,\n        (agreement_id, did, service_agreement,\n         consumer_address, publisher_account),\n        conditions_dict['lockReward'].timeout\n    )\n\n    events_manager.watch_access_event(\n        agreement_id,\n        escrow_reward_condition.fulfillEscrowRewardCondition,\n        None,\n        (agreement_id, service_agreement,\n         price, consumer_address, publisher_account, condition_ids),\n        conditions_dict['accessSecretStore'].timeout\n    )\n\n    events_manager.watch_reward_event(\n        agreement_id,\n        verify_reward_condition.verifyRewardTokens,\n        None,\n        (agreement_id, did, service_agreement,\n         price, consumer_address, publisher_account),\n        conditions_dict['escrowReward'].timeout\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_pending_service_agreements(storage_path, account, actor_type, did_resolver_fn):\n    keeper = Keeper.get_instance()\n    # service_agreement_id, did, service_definition_id, price, files, start_time, status\n    for (agreement_id, did, _,\n         price, files, start_time, _) in get_service_agreements(storage_path):\n\n        ddo = did_resolver_fn(did)\n        for service in ddo.services:\n            if service.type != 'Access':\n                continue\n\n            consumer_provider_tuple = keeper.escrow_access_secretstore_template.get_agreement_data(\n                agreement_id)\n            if not consumer_provider_tuple:\n                continue\n\n            consumer, provider = consumer_provider_tuple\n            did = ddo.did\n            service_agreement = ServiceAgreement.from_service_dict(service.as_dictionary())\n            condition_ids = service_agreement.generate_agreement_condition_ids(\n                agreement_id, did, consumer, provider, keeper)\n\n            if actor_type == 'consumer':\n                assert account.address == consumer\n                process_agreement_events_consumer(\n                    provider, agreement_id, did, service_agreement,\n                    price, account, condition_ids, None)\n            else:\n                assert account.address == provider\n                process_agreement_events_publisher(\n                    account, agreement_id, did, service_agreement,\n                    price, consumer, condition_ids)", "response": "Executes all pending service agreements in the local storage and processes the service agreement events."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a multi - value hash of the given list of values.", "response": "def generate_multi_value_hash(types, values):\n    \"\"\"\n    Return the hash of the given list of values.\n    This is equivalent to packing and hashing values in a solidity smart contract\n    hence the use of `soliditySha3`.\n\n    :param types: list of solidity types expressed as strings\n    :param values: list of values matching the `types` list\n    :return: bytes\n    \"\"\"\n    assert len(types) == len(values)\n    return Web3Provider.get_web3().soliditySha3(\n        types,\n        values\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the transaction receipt and return the base object.", "response": "def process_tx_receipt(tx_hash, event, event_name):\n    \"\"\"\n    Wait until the tx receipt is processed.\n\n    :param tx_hash: hash of the transaction\n    :param event: AttributeDict with the event data.\n    :param event_name: name of the event to subscribe, str\n    :return:\n    \"\"\"\n    web3 = Web3Provider.get_web3()\n    try:\n        web3.eth.waitForTransactionReceipt(tx_hash, timeout=20)\n    except Timeout:\n        logger.info('Waiting for transaction receipt timed out. Cannot verify receipt and event.')\n        return\n\n    receipt = web3.eth.getTransactionReceipt(tx_hash)\n    event = event().processReceipt(receipt)\n    if event:\n        logger.info(f'Success: got {event_name} event after fulfilling condition.')\n        logger.debug(\n            f'Success: got {event_name} event after fulfilling condition. {receipt}, ::: {event}')\n    else:\n        logger.debug(f'Something is not right, cannot find the {event_name} event after calling the'\n                     f' fulfillment condition. This is the transaction receipt {receipt}')\n\n    if receipt and receipt.status == 0:\n        logger.warning(\n            f'Transaction failed: tx_hash {tx_hash}, tx event {event_name}, receipt {receipt}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_condition(self, condition_id):\n        condition = self.contract_concise.getCondition(condition_id)\n        if condition and len(condition) == 7:\n            return ConditionValues(*condition)\n\n        return None", "response": "Retrieve the condition for a condition_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfulfilling the sign conditon.", "response": "def fulfill(self, agreement_id, message, account_address, signature, from_account):\n        \"\"\"\n        Fulfill the sign conditon.\n\n        :param agreement_id: id of the agreement, hex str\n        :param message:\n        :param account_address: ethereum account address, hex str\n        :param signature: signed agreement hash, hex str\n        :param from_account: Account doing the transaction\n        :return:\n        \"\"\"\n        return self._fulfill(\n            agreement_id,\n            message,\n            account_address,\n            signature,\n            transact={'from': from_account.address,\n                      'passphrase': from_account.password}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a signed service agreement to the publisher Brizo instance.", "response": "def send(self, did, agreement_id, service_definition_id, signature,\n             consumer_account, auto_consume=False):\n        \"\"\"\n        Send a signed service agreement to the publisher Brizo instance to\n        consume/access the service.\n\n        :param did: str representation fo the asset DID. Use this to retrieve the asset DDO.\n        :param agreement_id: 32 bytes identifier created by the consumer and will be used\n         on-chain for the executed agreement.\n        :param service_definition_id: str identifies the specific service in\n         the ddo to use in this agreement.\n        :param signature: str the signed agreement message hash which includes\n         conditions and their parameters values and other details of the agreement.\n        :param consumer_account: Account instance of the consumer\n        :param auto_consume: boolean tells this function wether to automatically trigger\n            consuming the asset upon receiving access permission\n        :raises OceanInitializeServiceAgreementError: on failure\n        :return: bool\n        \"\"\"\n        asset = self._asset_resolver.resolve(did)\n        service_agreement = ServiceAgreement.from_ddo(service_definition_id, asset)\n        # subscribe to events related to this agreement_id before sending the request.\n        logger.debug(f'Registering service agreement with id: {agreement_id}')\n        publisher_address = self._keeper.did_registry.get_did_owner(asset.asset_id)\n        condition_ids = service_agreement.generate_agreement_condition_ids(\n            agreement_id, asset.asset_id, consumer_account.address, publisher_address, self._keeper)\n\n        register_service_agreement_consumer(\n            self._config.storage_path,\n            publisher_address,\n            agreement_id,\n            did,\n            service_agreement,\n            service_definition_id,\n            service_agreement.get_price(),\n            asset.encrypted_files,\n            consumer_account,\n            condition_ids,\n            self._asset_consumer.download if auto_consume else None,\n        )\n\n        return BrizoProvider.get_brizo().initialize_service_agreement(\n            did,\n            agreement_id,\n            service_definition_id,\n            signature,\n            consumer_account.address,\n            service_agreement.endpoints.service\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, did, service_definition_id, agreement_id,\n               service_agreement_signature, consumer_address, account):\n        \"\"\"\n        Execute the service agreement on-chain using keeper's ServiceAgreement contract.\n\n        The on-chain executeAgreement method requires the following arguments:\n        templateId, signature, consumer, hashes, timeouts, serviceAgreementId, did.\n        `agreement_message_hash` is necessary to verify the signature.\n        The consumer `signature` includes the conditions timeouts and parameters values which\n        is usedon-chain to verify that the values actually match the signed hashes.\n\n        :param did: str representation fo the asset DID. Use this to retrieve the asset DDO.\n        :param service_definition_id: str identifies the specific service in\n         the ddo to use in this agreement.\n        :param agreement_id: 32 bytes identifier created by the consumer and will be used\n         on-chain for the executed agreement.\n        :param service_agreement_signature: str the signed agreement message hash which includes\n         conditions and their parameters values and other details of the agreement.\n        :param consumer_address: ethereum account address of consumer, hex str\n        :param account: Account instance creating the agreement. Can be either the\n            consumer, publisher or provider\n        :return: dict the `executeAgreement` transaction receipt\n        \"\"\"\n        assert consumer_address and Web3Provider.get_web3().isChecksumAddress(\n            consumer_address), f'Invalid consumer address {consumer_address}'\n        assert account.address in self._keeper.accounts, \\\n            f'Unrecognized account address {account.address}'\n\n        agreement_template_approved = self._keeper.template_manager.is_template_approved(\n            self._keeper.escrow_access_secretstore_template.address)\n        if not agreement_template_approved:\n            msg = (f'The EscrowAccessSecretStoreTemplate contract at address '\n                   f'{self._keeper.escrow_access_secretstore_template.address} is not '\n                   f'approved and cannot be used for creating service agreements.')\n            logger.warning(msg)\n            raise OceanInvalidAgreementTemplate(msg)\n\n        asset = self._asset_resolver.resolve(did)\n        asset_id = asset.asset_id\n        service_agreement = ServiceAgreement.from_ddo(service_definition_id, asset)\n        agreement_template = self._keeper.escrow_access_secretstore_template\n\n        if agreement_template.get_agreement_consumer(agreement_id) is not None:\n            raise OceanServiceAgreementExists(\n                f'Service agreement {agreement_id} already exists, cannot reuse '\n                f'the same agreement id.')\n\n        if consumer_address != account.address:\n            if not self._verify_service_agreement_signature(\n                    did, agreement_id, service_definition_id,\n                    consumer_address, service_agreement_signature,\n                    ddo=asset\n            ):\n                raise OceanInvalidServiceAgreementSignature(\n                    f'Verifying consumer signature failed: '\n                    f'signature {service_agreement_signature}, '\n                    f'consumerAddress {consumer_address}'\n                )\n\n        publisher_address = Web3Provider.get_web3().toChecksumAddress(asset.publisher)\n        condition_ids = service_agreement.generate_agreement_condition_ids(\n            agreement_id, asset_id, consumer_address, publisher_address, self._keeper)\n\n        time_locks = service_agreement.conditions_timelocks\n        time_outs = service_agreement.conditions_timeouts\n        success = agreement_template.create_agreement(\n            agreement_id,\n            asset_id,\n            condition_ids,\n            time_locks,\n            time_outs,\n            consumer_address,\n            account\n        )\n\n        if not success:\n            # success is based on tx receipt which is not reliable.\n            # So we check on-chain directly to see if agreement_id is there\n            consumer = self._keeper.escrow_access_secretstore_template.get_agreement_consumer(agreement_id)\n            if consumer:\n                success = True\n            else:\n                event_log = self._keeper.escrow_access_secretstore_template.subscribe_agreement_created(\n                    agreement_id, 30, None, (), wait=True\n                )\n                success = event_log is not None\n\n        if success:\n            logger.info(f'Service agreement {agreement_id} created successfully.')\n        else:\n            logger.info(f'Create agreement \"{agreement_id}\" failed.')\n            self._log_agreement_info(\n                asset, service_agreement, agreement_id, service_agreement_signature,\n                consumer_address, account, condition_ids\n            )\n\n        if success:\n            # subscribe to events related to this agreement_id\n            if consumer_address == account.address:\n                register_service_agreement_consumer(\n                    self._config.storage_path,\n                    publisher_address,\n                    agreement_id,\n                    did,\n                    service_agreement,\n                    service_definition_id,\n                    service_agreement.get_price(),\n                    asset.encrypted_files,\n                    account,\n                    condition_ids,\n                    None\n                )\n\n            else:\n                register_service_agreement_publisher(\n                    self._config.storage_path,\n                    consumer_address,\n                    agreement_id,\n                    did,\n                    service_agreement,\n                    service_definition_id,\n                    service_agreement.get_price(),\n                    account,\n                    condition_ids\n                )\n\n        return success", "response": "Execute the service agreement on - chain using the EscrowAccessSecretStoreTemplate contract."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the consumer has permission to access the given asset did.", "response": "def is_access_granted(self, agreement_id, did, consumer_address):\n        \"\"\"\n        Check permission for the agreement.\n\n        Verify on-chain that the `consumer_address` has permission to access the given asset `did`\n        according to the `agreement_id`.\n\n        :param agreement_id: id of the agreement, hex str\n        :param did: DID, str\n        :param consumer_address: ethereum account address of consumer, hex str\n        :return: bool True if user has permission\n        \"\"\"\n        agreement_consumer = self._keeper.escrow_access_secretstore_template.get_agreement_consumer(\n            agreement_id)\n        if agreement_consumer != consumer_address:\n            logger.warning(f'Invalid consumer address {consumer_address} and/or '\n                           f'service agreement id {agreement_id} (did {did})'\n                           f', agreement consumer is {agreement_consumer}')\n            return False\n\n        document_id = did_to_id(did)\n        return self._keeper.access_secret_store_condition.check_permissions(\n            document_id, consumer_address\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _verify_service_agreement_signature(self, did, agreement_id, service_definition_id,\n                                            consumer_address, signature, ddo=None):\n        \"\"\"\n        Verify service agreement signature.\n\n        Verify that the given signature is truly signed by the `consumer_address`\n        and represents this did's service agreement..\n\n        :param did: DID, str\n        :param agreement_id: id of the agreement, hex str\n        :param service_definition_id: identifier of the service inside the asset DDO, str\n        :param consumer_address: ethereum account address of consumer, hex str\n        :param signature: Signature, str\n        :param ddo: DDO instance\n        :return: True if signature is legitimate, False otherwise\n        :raises: ValueError if service is not found in the ddo\n        :raises: AssertionError if conditions keys do not match the on-chain conditions keys\n        \"\"\"\n        if not ddo:\n            ddo = self._asset_resolver.resolve(did)\n\n        service_agreement = ServiceAgreement.from_ddo(service_definition_id, ddo)\n        agreement_hash = service_agreement.get_service_agreement_hash(\n            agreement_id, ddo.asset_id, consumer_address,\n            Web3Provider.get_web3().toChecksumAddress(ddo.proof['creator']), self._keeper)\n\n        prefixed_hash = prepare_prefixed_hash(agreement_hash)\n        recovered_address = Web3Provider.get_web3().eth.account.recoverHash(\n            prefixed_hash, signature=signature\n        )\n        is_valid = (recovered_address == consumer_address)\n        if not is_valid:\n            logger.warning(f'Agreement signature failed: agreement hash is {agreement_hash.hex()}')\n\n        return is_valid", "response": "Verify that the given signature is truly signed by the consumer_address and that the given DID is associated with the given DDO."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the status of a service agreement.", "response": "def status(self, agreement_id):\n        \"\"\"\n        Get the status of a service agreement.\n\n        :param agreement_id: id of the agreement, hex str\n        :return: dict with condition status of each of the agreement's conditions or None if the\n        agreement is invalid.\n        \"\"\"\n        condition_ids = self._keeper.agreement_manager.get_agreement(agreement_id).condition_ids\n        result = {\"agreementId\": agreement_id}\n        conditions = dict()\n        for i in condition_ids:\n            conditions[self._keeper.get_condition_name_by_address(\n                self._keeper.condition_manager.get_condition(\n                    i).type_ref)] = self._keeper.condition_manager.get_condition_state(i)\n        result[\"conditions\"] = conditions\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_agreement(self, agreement_id, did, condition_ids, time_locks, time_outs,\n                         consumer_address, account):\n        \"\"\"\n        Create the service agreement. Return true if it is created successfully.\n\n        :param agreement_id: id of the agreement, hex str\n        :param did: DID, str\n        :param condition_ids: is a list of bytes32 content-addressed Condition IDs, bytes32\n        :param time_locks: is a list of uint time lock values associated to each Condition, int\n        :param time_outs: is a list of uint time out values associated to each Condition, int\n        :param consumer_address: ethereum account address of consumer, hex str\n        :param account: Account instance creating the agreement\n        :return: bool\n        \"\"\"\n        logger.info(\n            f'Creating agreement {agreement_id} with did={did}, consumer={consumer_address}.')\n        tx_hash = self.send_transaction(\n            'createAgreement',\n            (agreement_id,\n             did,\n             condition_ids,\n             time_locks,\n             time_outs,\n             consumer_address),\n            transact={'from': account.address,\n                      'passphrase': account.password}\n        )\n        receipt = self.get_tx_receipt(tx_hash)\n        return receipt and receipt.status == 1", "response": "Create the service agreement. Return true if it is created successfully."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subscribe_agreement_created(self, agreement_id, timeout, callback, args, wait=False):\n        logger.info(\n            f'Subscribing {self.AGREEMENT_CREATED_EVENT} event with agreement id {agreement_id}.')\n        return self.subscribe_to_event(\n            self.AGREEMENT_CREATED_EVENT,\n            timeout,\n            {'_agreementId': Web3Provider.get_web3().toBytes(hexstr=agreement_id)},\n            callback=callback,\n            args=args,\n            wait=wait\n        )", "response": "Subscribe to an event with the agreement created."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates id for the condition.", "response": "def generate_id(self, agreement_id, types, values):\n        \"\"\"\n        Generate id for the condition.\n\n        :param agreement_id: id of the agreement, hex str\n        :param types: list of types\n        :param values: list of values\n        :return: id, str\n        \"\"\"\n        values_hash = utils.generate_multi_value_hash(types, values)\n        return utils.generate_multi_value_hash(\n            ['bytes32', 'address', 'bytes32'],\n            [agreement_id, self.address, values_hash]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fulfill(self, *args, **kwargs):\n        tx_hash = self.send_transaction('fulfill', args, **kwargs)\n        receipt = self.get_tx_receipt(tx_hash)\n        return receipt.status == 1", "response": "Fulfill the condition.\n\n        :param args:\n        :param kwargs:\n        :return: true if the condition was successfully fulfilled, bool"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subscribe_condition_fulfilled(self, agreement_id, timeout, callback, args,\n                                      timeout_callback=None, wait=False):\n        \"\"\"\n        Subscribe to the condition fullfilled event.\n\n        :param agreement_id: id of the agreement, hex str\n        :param timeout:\n        :param callback:\n        :param args:\n        :param timeout_callback:\n        :param wait: if true block the listener until get the event, bool\n        :return:\n        \"\"\"\n        logger.info(\n            f'Subscribing {self.FULFILLED_EVENT} event with agreement id {agreement_id}.')\n        return self.subscribe_to_event(\n            self.FULFILLED_EVENT,\n            timeout,\n            {'_agreementId': Web3Provider.get_web3().toBytes(hexstr=agreement_id)},\n            callback=callback,\n            timeout_callback=timeout_callback,\n            args=args,\n            wait=wait\n        )", "response": "Subscribe to the condition fullfilled event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncustomize calling smart contract transaction functions to use personal_sendTransaction instead of eth_sendTransaction.", "response": "def transact(self, transaction=None):\n        \"\"\"\n        Customize calling smart contract transaction functions to use `personal_sendTransaction`\n        instead of `eth_sendTransaction` and to estimate gas limit. This function\n        is largely copied from web3 ContractFunction with important addition.\n\n        Note: will fallback to `eth_sendTransaction` if `passphrase` is not provided in the\n        `transaction` dict.\n\n        :param transaction: dict which has the required transaction arguments per\n            `personal_sendTransaction` requirements.\n        :return: hex str transaction hash\n        \"\"\"\n        if transaction is None:\n            transact_transaction = {}\n        else:\n            transact_transaction = dict(**transaction)\n\n        if 'data' in transact_transaction:\n            raise ValueError(\"Cannot set data in transact transaction\")\n\n        cf = self._contract_function\n        if cf.address is not None:\n            transact_transaction.setdefault('to', cf.address)\n        if cf.web3.eth.defaultAccount is not empty:\n            transact_transaction.setdefault('from', cf.web3.eth.defaultAccount)\n\n        if 'to' not in transact_transaction:\n            if isinstance(self, type):\n                raise ValueError(\n                    \"When using `Contract.transact` from a contract factory you \"\n                    \"must provide a `to` address with the transaction\"\n                )\n            else:\n                raise ValueError(\n                    \"Please ensure that this contract instance has an address.\"\n                )\n\n        if 'gas' not in transact_transaction:\n            tx = transaction.copy()\n            if 'passphrase' in tx:\n                tx.pop('passphrase')\n            gas = cf.estimateGas(tx)\n            transact_transaction['gas'] = gas\n\n        return transact_with_contract_function(\n            cf.address,\n            cf.web3,\n            cf.function_identifier,\n            transact_transaction,\n            cf.contract_abi,\n            cf.abi,\n            *cf.args,\n            **cf.kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfulfill the escrow reward condition.", "response": "def fulfill(self,\n                agreement_id,\n                amount,\n                receiver_address,\n                sender_address,\n                lock_condition_id,\n                release_condition_id,\n                account):\n        \"\"\"\n        Fulfill the escrow reward condition.\n\n        :param agreement_id: id of the agreement, hex str\n        :param amount: Amount of tokens, int\n        :param receiver_address: ethereum address of the receiver, hex str\n        :param sender_address: ethereum address of the sender, hex str\n        :param lock_condition_id: id of the condition, str\n        :param release_condition_id: id of the condition, str\n        :param account: Account instance\n        :return:\n        \"\"\"\n        return self._fulfill(\n            agreement_id,\n            amount,\n            receiver_address,\n            sender_address,\n            lock_condition_id,\n            release_condition_id,\n            transact={'from': account.address,\n                      'passphrase': account.password}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hash_values(self, amount, receiver_address, sender_address, lock_condition_id,\n                    release_condition_id):\n        \"\"\"\n        Hash the values of the escrow reward condition.\n\n        :param amount: Amount of tokens, int\n        :param receiver_address: ethereum address of the receiver, hex str\n        :param sender_address: ethereum address of the sender, hex str\n        :param lock_condition_id: id of the condition, str\n        :param release_condition_id: id of the condition, str\n        :return: hex str\n        \"\"\"\n        return self._hash_values(\n            amount,\n            receiver_address,\n            sender_address,\n            lock_condition_id,\n            release_condition_id\n        )", "response": "Hash the values of the escrow reward condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_dictionary(self):\n        return {\n            \"name\": self.name,\n            \"type\": self.type,\n            \"value\": remove_0x_prefix(self.value) if self.type == 'bytes32' else self.value\n        }", "response": "Return the parameter as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_from_condition_json(self, condition_json):\n        self.name = condition_json['name']\n        self.timelock = condition_json['timelock']\n        self.timeout = condition_json['timeout']\n        self.contract_name = condition_json['contractName']\n        self.function_name = condition_json['functionName']\n        self.parameters = [Parameter(p) for p in condition_json['parameters']]\n        self.events = [Event(e) for e in condition_json['events']]", "response": "Initialize the values from a condition json."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_dictionary(self):\n        condition_dict = {\n            \"name\": self.name,\n            \"timelock\": self.timelock,\n            \"timeout\": self.timeout,\n            \"contractName\": self.contract_name,\n            \"functionName\": self.function_name,\n            \"events\": [e.as_dictionary() for e in self.events],\n            \"parameters\": [p.as_dictionary() for p in self.parameters],\n        }\n\n        return condition_dict", "response": "Return the condition as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_value(self, name, value):\n        if name not in {'id', self.SERVICE_ENDPOINT, self.CONSUME_ENDPOINT, 'type'}:\n            self._values[name] = value", "response": "Update the value of the key name in the array of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_text(self, is_pretty=False):\n        values = {\n            'type': self._type,\n            self.SERVICE_ENDPOINT: self._service_endpoint,\n        }\n        if self._consume_endpoint is not None:\n            values[self.CONSUME_ENDPOINT] = self._consume_endpoint\n        if self._values:\n            # add extra service values to the dictionary\n            for name, value in self._values.items():\n                values[name] = value\n\n        if is_pretty:\n            return json.dumps(values, indent=4, separators=(',', ': '))\n\n        return json.dumps(values)", "response": "Return the service as a JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_dictionary(self):\n        values = {\n            'type': self._type,\n            self.SERVICE_ENDPOINT: self._service_endpoint,\n        }\n        if self._consume_endpoint is not None:\n            values[self.CONSUME_ENDPOINT] = self._consume_endpoint\n        if self._values:\n            # add extra service values to the dictionary\n            for name, value in self._values.items():\n                if isinstance(value, object) and hasattr(value, 'as_dictionary'):\n                    value = value.as_dictionary()\n                elif isinstance(value, list):\n                    value = [v.as_dictionary() if hasattr(v, 'as_dictionary') else v for v in value]\n\n                values[name] = value\n        return values", "response": "Return the service as a python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_json(cls, service_dict):\n        sd = service_dict.copy()\n        service_endpoint = sd.get(cls.SERVICE_ENDPOINT)\n        if not service_endpoint:\n            logger.error(\n                'Service definition in DDO document is missing the \"serviceEndpoint\" key/value.')\n            raise IndexError\n\n        _type = sd.get('type')\n        if not _type:\n            logger.error('Service definition in DDO document is missing the \"type\" key/value.')\n            raise IndexError\n\n        sd.pop(cls.SERVICE_ENDPOINT)\n        sd.pop('type')\n        return cls(\n            service_endpoint,\n            _type,\n            sd\n        )", "response": "Create a service object from a JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fulfill(self, agreement_id, document_id, grantee_address, account):\n        return self._fulfill(\n            agreement_id,\n            document_id,\n            grantee_address,\n            transact={'from': account.address,\n                      'passphrase': account.password}\n        )", "response": "Fulfill the access secret store condition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of the assets dids consumed for an address.", "response": "def get_purchased_assets_by_address(self, address, from_block=0, to_block='latest'):\n        \"\"\"\n        Get the list of the assets dids consumed for an address.\n\n        :param address: is the address of the granted user, hex-str\n        :param from_block: block to start to listen\n        :param to_block: block to stop to listen\n        :return: list of dids\n        \"\"\"\n        block_filter = EventFilter(\n            ConditionBase.FULFILLED_EVENT,\n            getattr(self.events, ConditionBase.FULFILLED_EVENT),\n            from_block=from_block,\n            to_block=to_block,\n            argument_filters={'_grantee': address}\n        )\n        log_items = block_filter.get_all_entries(max_tries=5)\n        did_list = []\n        for log_i in log_items:\n            did_list.append(id_to_did(log_i.args['_documentId']))\n\n        return did_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the web3 instance to interact with the ethereum client.", "response": "def get_web3():\n        \"\"\"Return the web3 instance to interact with the ethereum client.\"\"\"\n        if Web3Provider._web3 is None:\n            config = ConfigProvider.get_config()\n            provider = (\n                config.web3_provider\n                if config.web3_provider\n                else CustomHTTPProvider(\n                    config.keeper_url\n                )\n            )\n            Web3Provider._web3 = Web3(provider)\n            # Reset attributes to avoid lint issue about no attribute\n            Web3Provider._web3.eth = getattr(Web3Provider._web3, 'eth')\n            Web3Provider._web3.net = getattr(Web3Provider._web3, 'net')\n            Web3Provider._web3.personal = getattr(Web3Provider._web3, 'personal')\n            Web3Provider._web3.version = getattr(Web3Provider._web3, 'version')\n            Web3Provider._web3.txpool = getattr(Web3Provider._web3, 'txpool')\n            Web3Provider._web3.miner = getattr(Web3Provider._web3, 'miner')\n            Web3Provider._web3.admin = getattr(Web3Provider._web3, 'admin')\n            Web3Provider._web3.parity = getattr(Web3Provider._web3, 'parity')\n            Web3Provider._web3.testing = getattr(Web3Provider._web3, 'testing')\n\n        return Web3Provider._web3"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the type of the soma", "response": "def _get_type(points, soma_class):\n    '''get the type of the soma\n\n    Args:\n        points: Soma points\n        soma_class(str): one of 'contour' or 'cylinder' to specify the type\n    '''\n    assert soma_class in (SOMA_CONTOUR, SOMA_CYLINDER)\n\n    npoints = len(points)\n    if soma_class == SOMA_CONTOUR:\n        return {0: None,\n                1: SomaSinglePoint,\n                2: None}.get(npoints, SomaSimpleContour)\n\n    if(npoints == 3 and\n       points[0][COLS.P] == -1 and\n       points[1][COLS.P] == 1 and\n       points[2][COLS.P] == 1):\n        L.warning('Using neuromorpho 3-Point soma')\n        # NeuroMorpho is the main provider of morphologies, but they\n        # with SWC as their default file format: they convert all\n        # uploads to SWC.  In the process of conversion, they turn all\n        # somas into their custom 'Three-point soma representation':\n        #  http://neuromorpho.org/SomaFormat.html\n\n        return SomaNeuromorphoThreePointCylinders\n\n    return {0: None,\n            1: SomaSinglePoint}.get(npoints, SomaCylinders)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_soma(points, soma_check=None, soma_class=SOMA_CONTOUR):\n    '''Make a soma object from a set of points\n\n    Infers the soma type (SomaSinglePoint, SomaSimpleContour)\n    from the points and the 'soma_class'\n\n    Parameters:\n        points: collection of points forming a soma.\n        soma_check: optional validation function applied to points. Should\n        raise a SomaError if points not valid.\n        soma_class(str): one of 'contour' or 'cylinder' to specify the type\n\n    Raises:\n        SomaError if no soma points found, points incompatible with soma, or\n        if soma_check(points) fails.\n    '''\n\n    if soma_check:\n        soma_check(points)\n\n    stype = _get_type(points, soma_class)\n\n    if stype is None:\n        raise SomaError('Invalid soma points')\n\n    return stype(points)", "response": "Make a soma object from a set of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef center(self):\n        '''Obtain the center from the average of all points'''\n        points = np.array(self._points)\n        return np.mean(points[:, COLS.XYZ], axis=0)", "response": "Obtain the center from the average of all points"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef section_tortuosity(section):\n    '''Tortuosity of a section\n\n    The tortuosity is defined as the ratio of the path length of a section\n    and the euclidian distnce between its end points.\n\n    The path length is the sum of distances between consecutive points.\n\n    If the section contains less than 2 points, the value 1 is returned.\n    '''\n    pts = section.points\n    return 1 if len(pts) < 2 else mm.section_length(pts) / mm.point_dist(pts[-1], pts[0])", "response": "Tortuosity of a section"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nends to end distance of a section", "response": "def section_end_distance(section):\n    '''End to end distance of a section\n\n    The end to end distance of a section is defined as\n    the euclidian distnce between its end points.\n\n    If the section contains less than 2 points, the value 0 is returned.\n    '''\n    pts = section.points\n    return 0 if len(pts) < 2 else mm.point_dist(pts[-1], pts[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef section_meander_angles(section):\n    '''Inter-segment opening angles in a section'''\n    p = section.points\n    return [mm.angle_3points(p[i - 1], p[i - 2], p[i])\n            for i in range(2, len(p))]", "response": "Inter - segment opening angles in a section"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbranch order of a tree section The strahler order is the inverse of the branch order, since this is computed from the tips of the tree towards the root. This implementation is a translation of the three steps described in Wikipedia (https://en.wikipedia.org/wiki/Strahler_number): - If the node is a leaf (has no children), its Strahler number is one. - If the node has one child with Strahler number i, and all other children have Strahler numbers less than i, then the Strahler number of the node is i again. - If the node has two or more children with Strahler number i, and no children with greater number, then the Strahler number of the node is i + 1. No efforts have been invested in making it computationnaly efficient, but it computes acceptably fast on tested morphologies (i.e., no waiting time).", "response": "def strahler_order(section):\n    '''Branching order of a tree section\n\n    The strahler order is the inverse of the branch order,\n    since this is computed from the tips of the tree\n    towards the root.\n\n    This implementation is a translation of the three steps described in\n    Wikipedia (https://en.wikipedia.org/wiki/Strahler_number):\n\n       - If the node is a leaf (has no children), its Strahler number is one.\n       - If the node has one child with Strahler number i, and all other children\n         have Strahler numbers less than i, then the Strahler number of the node\n         is i again.\n       - If the node has two or more children with Strahler number i, and no\n         children with greater number, then the Strahler number of the node is\n         i + 1.\n\n    No efforts have been invested in making it computationnaly efficient, but\n    it computes acceptably fast on tested morphologies (i.e., no waiting time).\n    '''\n    if section.children:\n        child_orders = [strahler_order(child) for child in section.children]\n        max_so_children = max(child_orders)\n        it = iter(co == max_so_children for co in child_orders)\n        #  check if there are *two* or more children w/ the max_so_children\n        any(it)\n        if any(it):\n            return max_so_children + 1\n        return max_so_children\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef figure_naming(pretitle='', posttitle='', prefile='', postfile=''):\n    if pretitle:\n        pretitle = \"%s -- \" % pretitle\n\n    if posttitle:\n        posttitle = \" -- %s\" % posttitle\n\n    if prefile:\n        prefile = \"%s_\" % prefile\n\n    if postfile:\n        postfile = \"_%s\" % postfile\n\n    return pretitle, posttitle, prefile, postfile", "response": "Helper function to define the strings that handle pre - post conventions\n    for viewing - plotting title and saving options."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_figure(new_fig=True, subplot='111', params=None):\n    _get_plt()\n\n    if new_fig:\n        fig = plt.figure()\n    else:\n        fig = plt.gcf()\n\n    params = dict_if_none(params)\n\n    if isinstance(subplot, (tuple, list)):\n        ax = fig.add_subplot(*subplot, **params)\n    else:\n        ax = fig.add_subplot(subplot, **params)\n\n    return fig, ax", "response": "Function to initialize the matplotlib figure and axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_plot(fig, prefile='', postfile='', output_path='./', output_name='Figure',\n              output_format='png', dpi=300, transparent=False, **_):\n    \"\"\"Generates a figure file in the selected directory.\n\n    Args:\n        fig: matplotlib figure\n        prefile(str): Include before the general filename of the figure\n        postfile(str): Included after the general filename of the figure\n        output_path(str): Define the path to the output directory\n        output_name(str): String to define the name of the output figure\n        output_format(str): String to define the format of the output figure\n        dpi(int): Define the DPI (Dots per Inch) of the figure\n        transparent(bool): If True the saved figure will have a transparent background\n    \"\"\"\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)  # Make output directory if non-exsiting\n\n    output = os.path.join(output_path,\n                          prefile + output_name + postfile + \".\" + output_format)\n\n    fig.savefig(output, dpi=dpi, transparent=transparent)", "response": "Save a matplotlib figure in the selected directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the basic options of a matplotlib figure to be used by viewing - plotting functions for the base figure.", "response": "def plot_style(fig, ax,  # pylint: disable=too-many-arguments, too-many-locals\n               # plot_title\n               pretitle='',\n               title='Figure',\n               posttitle='',\n               title_fontsize=14,\n               title_arg=None,\n               # plot_labels\n               label_fontsize=14,\n               xlabel=None,\n               xlabel_arg=None,\n               ylabel=None,\n               ylabel_arg=None,\n               zlabel=None,\n               zlabel_arg=None,\n               # plot_ticks\n               tick_fontsize=12,\n               xticks=None,\n               xticks_args=None,\n               yticks=None,\n               yticks_args=None,\n               zticks=None,\n               zticks_args=None,\n               # update_plot_limits\n               white_space=30,\n               # plot_legend\n               no_legend=True,\n               legend_arg=None,\n               # internal\n               no_axes=False,\n               aspect_ratio='equal',\n               tight=False,\n               **_):\n    \"\"\"Set the basic options of a matplotlib figure, to be used by viewing - plotting functions\n\n    Args:\n        fig(matplotlib figure): figure\n        ax(matplotlib axes, belonging to `fig`): axes\n\n        pretitle(str): String to include before the general title of the figure\n        posttitle (str): String to include after the general title of the figure\n        title (str): Set the title for the figure\n        title_fontsize (int): Defines the size of the title's font\n        title_arg (dict): Addition arguments for matplotlib.title() call\n\n        label_fontsize(int): Size of the labels' font\n        xlabel(str): The xlabel for the figure\n        xlabel_arg(dict):  Passsed into matplotlib as xlabel arguments\n        ylabel(str): The ylabel for the figure\n        ylabel_arg(dict):  Passsed into matplotlib as ylabel arguments\n        zlabel(str): The zlabel for the figure\n        zlabel_arg(dict):  Passsed into matplotlib as zlabel arguments\n\n        tick_fontsize (int): Defines the size of the ticks' font\n        xticks([list of ticks]): Defines the values of x ticks in the figure\n        xticks_args(dict):  Passsed into matplotlib as xticks arguments\n        yticks([list of ticks]): Defines the values of y ticks in the figure\n        yticks_args(dict):  Passsed into matplotlib as yticks arguments\n        zticks([list of ticks]): Defines the values of z ticks in the figure\n        zticks_args(dict):  Passsed into matplotlib as zticks arguments\n\n        white_space(float): whitespace added to surround the tight limit of the data\n\n        no_legend (bool): Defines the presence of a legend in the figure\n        legend_arg (dict): Addition arguments for matplotlib.legend() call\n\n        no_axes(bool): If True the labels and the frame will be set off\n        aspect_ratio(str): Sets aspect ratio of the figure, according to matplotlib aspect_ratio\n        tight(bool): If True the tight layout of matplotlib will be activated\n\n    Returns:\n        Matplotlib figure, matplotlib axes\n    \"\"\"\n    plot_title(ax, pretitle, title, posttitle, title_fontsize, title_arg)\n    plot_labels(ax, label_fontsize, xlabel, xlabel_arg, ylabel, ylabel_arg, zlabel, zlabel_arg)\n    plot_ticks(ax, tick_fontsize, xticks, xticks_args, yticks, yticks_args, zticks, zticks_args)\n    update_plot_limits(ax, white_space)\n    plot_legend(ax, no_legend, legend_arg)\n\n    if no_axes:\n        ax.set_frame_on(False)\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n\n    ax.set_aspect(aspect_ratio)\n\n    if tight:\n        fig.set_tight_layout(True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the title options of a matplotlib plot", "response": "def plot_title(ax, pretitle='', title='Figure', posttitle='', title_fontsize=14, title_arg=None):\n    \"\"\"Set title options of a matplotlib plot\n\n    Args:\n        ax: matplotlib axes\n        pretitle(str): String to include before the general title of the figure\n        posttitle (str): String to include after the general title of the figure\n        title (str): Set the title for the figure\n        title_fontsize (int): Defines the size of the title's font\n        title_arg (dict): Addition arguments for matplotlib.title() call\n    \"\"\"\n    current_title = ax.get_title()\n\n    if not current_title:\n        current_title = pretitle + title + posttitle\n\n    title_arg = dict_if_none(title_arg)\n\n    ax.set_title(current_title, fontsize=title_fontsize, **title_arg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_labels(ax, label_fontsize=14,\n                xlabel=None, xlabel_arg=None,\n                ylabel=None, ylabel_arg=None,\n                zlabel=None, zlabel_arg=None):\n    \"\"\"Sets the labels options of a matplotlib plot\n\n    Args:\n        ax: matplotlib axes\n        label_fontsize(int): Size of the labels' font\n        xlabel(str): The xlabel for the figure\n        xlabel_arg(dict):  Passsed into matplotlib as xlabel arguments\n        ylabel(str): The ylabel for the figure\n        ylabel_arg(dict):  Passsed into matplotlib as ylabel arguments\n        zlabel(str): The zlabel for the figure\n        zlabel_arg(dict):  Passsed into matplotlib as zlabel arguments\n    \"\"\"\n    xlabel = xlabel if xlabel is not None else ax.get_xlabel() or 'X'\n    ylabel = ylabel if ylabel is not None else ax.get_ylabel() or 'Y'\n\n    xlabel_arg = dict_if_none(xlabel_arg)\n    ylabel_arg = dict_if_none(ylabel_arg)\n\n    ax.set_xlabel(xlabel, fontsize=label_fontsize, **xlabel_arg)\n    ax.set_ylabel(ylabel, fontsize=label_fontsize, **ylabel_arg)\n\n    if hasattr(ax, 'zaxis'):\n        zlabel = zlabel if zlabel is not None else ax.get_zlabel() or 'Z'\n        zlabel_arg = dict_if_none(zlabel_arg)\n        ax.set_zlabel(zlabel, fontsize=label_fontsize, **zlabel_arg)", "response": "Sets the labels options of a matplotlib plot of the available log files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning that defines the labels options of a matplotlib plot.", "response": "def plot_ticks(ax, tick_fontsize=12,\n               xticks=None, xticks_args=None,\n               yticks=None, yticks_args=None,\n               zticks=None, zticks_args=None):\n    \"\"\"Function that defines the labels options of a matplotlib plot.\n\n    Args:\n        ax: matplotlib axes\n        tick_fontsize (int): Defines the size of the ticks' font\n        xticks([list of ticks]): Defines the values of x ticks in the figure\n        xticks_arg(dict):  Passsed into matplotlib as xticks arguments\n        yticks([list of ticks]): Defines the values of y ticks in the figure\n        yticks_arg(dict):  Passsed into matplotlib as yticks arguments\n        zticks([list of ticks]): Defines the values of z ticks in the figure\n        zticks_arg(dict):  Passsed into matplotlib as zticks arguments\n    \"\"\"\n    if xticks is not None:\n        ax.set_xticks(xticks)\n        xticks_args = dict_if_none(xticks_args)\n        ax.xaxis.set_tick_params(labelsize=tick_fontsize, **xticks_args)\n\n    if yticks is not None:\n        ax.set_yticks(yticks)\n        yticks_args = dict_if_none(yticks_args)\n        ax.yaxis.set_tick_params(labelsize=tick_fontsize, **yticks_args)\n\n    if zticks is not None:\n        ax.set_zticks(zticks)\n        zticks_args = dict_if_none(zticks_args)\n        ax.zaxis.set_tick_params(labelsize=tick_fontsize, **zticks_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_plot_limits(ax, white_space):\n\n    if hasattr(ax, 'zz_dataLim'):\n        bounds = ax.xy_dataLim.bounds\n        ax.set_xlim(bounds[0] - white_space, bounds[0] + bounds[2] + white_space)\n        ax.set_ylim(bounds[1] - white_space, bounds[1] + bounds[3] + white_space)\n\n        bounds = ax.zz_dataLim.bounds\n        ax.set_zlim(bounds[0] - white_space, bounds[0] + bounds[2] + white_space)\n    else:\n        bounds = ax.dataLim.bounds\n        assert not any(map(np.isinf, bounds)), 'Cannot set bounds if dataLim has infinite elements'\n        ax.set_xlim(bounds[0] - white_space, bounds[0] + bounds[2] + white_space)\n        ax.set_ylim(bounds[1] - white_space, bounds[1] + bounds[3] + white_space)", "response": "Updates the limits of a matplotlib plot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning that defines the legend options for a matplotlib plot.", "response": "def plot_legend(ax, no_legend=True, legend_arg=None):\n    \"\"\"\n    Function that defines the legend options\n    of a matplotlib plot.\n\n    Args:\n        ax: matplotlib axes\n        no_legend (bool): Defines the presence of a legend in the figure\n        legend_arg (dict): Addition arguments for matplotlib.legend() call\n    \"\"\"\n    legend_arg = dict_if_none(legend_arg)\n\n    if not no_legend:\n        ax.legend(**legend_arg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_normals(v):\n    '''get two vectors that form a basis w/ v\n\n    Note: returned vectors are unit\n    '''\n    not_v = np.array([1, 0, 0])\n    if np.all(np.abs(v) == not_v):\n        not_v = np.array([0, 1, 0])\n    n1 = np.cross(v, not_v)\n    n1 /= norm(n1)\n    n2 = np.cross(v, n1)\n    return n1, n2", "response": "get two vectors that form a basis w / v\n    Note that v is a unit vector"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a 3d mesh of a cylinder with start and end points and varying radius.", "response": "def generate_cylindrical_points(start, end, start_radius, end_radius,\n                                linspace_count=_LINSPACE_COUNT):\n    '''Generate a 3d mesh of a cylinder with start and end points, and varying radius\n\n    Based on: http://stackoverflow.com/a/32383775\n    '''\n    v = end - start\n    length = norm(v)\n    v = v / length\n    n1, n2 = _get_normals(v)\n\n    # pylint: disable=unbalanced-tuple-unpacking\n    l, theta = np.meshgrid(np.linspace(0, length, linspace_count),\n                           np.linspace(0, 2 * np.pi, linspace_count))\n\n    radii = np.linspace(start_radius, end_radius, linspace_count)\n    rsin = np.multiply(radii, np.sin(theta))\n    rcos = np.multiply(radii, np.cos(theta))\n\n    return np.array([start[i] +\n                     v[i] * l +\n                     n1[i] * rsin + n2[i] * rcos\n                     for i in range(3)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprojecting a cylinder onto a 2D projection", "response": "def project_cylinder_onto_2d(ax, plane,\n                             start, end, start_radius, end_radius,\n                             color='black', alpha=1.):\n    '''take cylinder defined by start/end, and project it onto the plane\n\n    Args:\n        ax: matplotlib axes\n        plane(tuple of int): where x, y, z = 0, 1, 2, so (0, 1) is the xy axis\n        start(np.array): start coordinates\n        end(np.array): end coordinates\n        start_radius(float): start radius\n        end_radius(float): end radius\n        color: matplotlib color\n        alpha(float): alpha value\n\n    Note: There are probably more efficient ways of doing this: here the\n    3d outline is calculated, the non-used plane coordinates are dropped, a\n    tight convex hull is found, and that is used for a filled polygon\n    '''\n    points = generate_cylindrical_points(start, end, start_radius, end_radius, 10)\n    points = np.vstack([points[plane[0]].ravel(),\n                        points[plane[1]].ravel()])\n    points = points.T\n    hull = ConvexHull(points)\n    ax.add_patch(Polygon(points[hull.vertices], fill=True, color=color, alpha=alpha))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_cylinder(ax, start, end, start_radius, end_radius,\n                  color='black', alpha=1., linspace_count=_LINSPACE_COUNT):\n    '''plot a 3d cylinder'''\n    assert not np.all(start == end), 'Cylinder must have length'\n    x, y, z = generate_cylindrical_points(start, end, start_radius, end_radius,\n                                          linspace_count=linspace_count)\n    ax.plot_surface(x, y, z, color=color, alpha=alpha)", "response": "plot a 3d cylinder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_sphere(ax, center, radius, color='black', alpha=1., linspace_count=_LINSPACE_COUNT):\n\n    u = np.linspace(0, 2 * np.pi, linspace_count)\n    v = np.linspace(0, np.pi, linspace_count)\n    sin_v = np.sin(v)\n    x = center[0] + radius * np.outer(np.cos(u), sin_v)\n    y = center[1] + radius * np.outer(np.sin(u), sin_v)\n    z = center[2] + radius * np.outer(np.ones_like(u), np.cos(v))\n\n    ax.plot_surface(x, y, z, linewidth=0.0, color=color, alpha=alpha)", "response": "Plots a 3d sphere given the center and radius."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_sequential_ids(data_wrapper):\n    '''Check that IDs are increasing and consecutive\n\n    returns tuple (bool, list of IDs that are not consecutive\n    with their predecessor)\n    '''\n    db = data_wrapper.data_block\n    ids = db[:, COLS.ID]\n    steps = ids[np.where(np.diff(ids) != 1)[0] + 1].astype(int)\n    return CheckResult(len(steps) == 0, steps)", "response": "Check that IDs are increasing and consecutive\n    returns tuple ( bool list of IDs that are not consecutive\n    with their predecessor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef no_missing_parents(data_wrapper):\n    '''Check that all points have existing parents\n    Point's parent ID must exist and parent must be declared\n    before child.\n\n    Returns:\n        CheckResult with result and list of IDs that have no parent\n    '''\n    db = data_wrapper.data_block\n    ids = np.setdiff1d(db[:, COLS.P], db[:, COLS.ID])[1:]\n    return CheckResult(len(ids) == 0, ids.astype(np.int) + 1)", "response": "Check that all points have existing parents\n    Point s parent ID must exist and parent must be declared\n    before child."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that data forms a single tree Only the first point has ID of - 1.", "response": "def is_single_tree(data_wrapper):\n    '''Check that data forms a single tree\n\n    Only the first point has ID of -1.\n\n    Returns:\n        CheckResult with result and list of IDs\n\n    Note:\n        This assumes no_missing_parents passed.\n    '''\n    db = data_wrapper.data_block\n    bad_ids = db[db[:, COLS.P] == -1][1:, COLS.ID]\n    return CheckResult(len(bad_ids) == 0, bad_ids.tolist())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_soma_points(data_wrapper):\n    '''Checks if the TYPE column of raw data block has an element of type soma\n\n    Returns:\n        CheckResult with result\n    '''\n    db = data_wrapper.data_block\n    return CheckResult(POINT_TYPE.SOMA in db[:, COLS.TYPE], None)", "response": "Checks if the TYPE column of raw data block has an element of type soma\n    Returns CheckResult with result\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_all_finite_radius_neurites(data_wrapper, threshold=0.0):\n    '''Check that all points with neurite type have a finite radius\n\n    Returns:\n        CheckResult with result and list of IDs of neurite points with zero radius\n    '''\n    db = data_wrapper.data_block\n    neurite_ids = np.in1d(db[:, COLS.TYPE], POINT_TYPE.NEURITES)\n    zero_radius_ids = db[:, COLS.R] <= threshold\n    bad_pts = np.array(db[neurite_ids & zero_radius_ids][:, COLS.ID],\n                       dtype=int).tolist()\n    return CheckResult(len(bad_pts) == 0, bad_pts)", "response": "Check that all points with type neurite type have a finite radius\n    Returns CheckResult with result and list of IDs of all points with zero radius\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a data block has a valid soma Returns CheckResult with result", "response": "def has_valid_soma(data_wrapper):\n    '''Check if a data block has a valid soma\n\n    Returns:\n        CheckResult with result\n    '''\n    try:\n        make_soma(data_wrapper.soma_points())\n        return CheckResult(True)\n    except SomaError:\n        return CheckResult(False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pelita_member_filter(parent_name, item_names):\n    filtered_names = []\n\n    if parent_name not in sys.modules:\n        return item_names\n    module = sys.modules[parent_name]\n\n    for item_name in item_names:\n        item = getattr(module, item_name, None)\n        location = getattr(item, '__module__', None)\n\n        if location is None or (location + \".\").startswith(parent_name + \".\"):\n            filtered_names.append(item_name)\n\n    return filtered_names", "response": "Filter a list of autodoc items for which to generate documentation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef boxplot(neurons, feature, new_fig=True, subplot=False):\n    '''\n    Plot a histogram of the selected feature for the population of neurons.\n    Plots x-axis versus y-axis on a scatter|histogram|binned values plot.\n\n    More information about the plot and how it works.\n\n    Parameters\n    ----------\n    neurons : list\n        List of Neurons. Single neurons must be encapsulated in a list.\n\n    feature : str\n    The feature of interest.\n\n    Options\n    -------\n\n    subplot : bool\n        Default is False, which returns a matplotlib figure object. If True,\n        returns a matplotlib axis object, for use as a subplot.\n\n    '''\n    feature_values = [getattr(neu, 'get_' + feature)() for neu in neurons]\n\n    _, ax = common.get_figure(new_fig=new_fig, subplot=subplot)\n\n    ax.boxplot(feature_values)\n\n    x_labels = ['neuron_id' for _ in neurons]\n\n    ax.set_xticklabels(x_labels)", "response": "Plots a histogram of the selected feature for the population of neurons."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_axon(neuron, treefun=_read_neurite_type):\n    '''Check if a neuron has an axon\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        treefun: Optional function to calculate the tree type of\n        neuron's neurites\n\n    Returns:\n        CheckResult with result\n    '''\n    return CheckResult(NeuriteType.axon in (treefun(n) for n in neuron.neurites))", "response": "Check if a neuron has an axon"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_apical_dendrite(neuron, min_number=1, treefun=_read_neurite_type):\n    '''Check if a neuron has apical dendrites\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        min_number: minimum number of apical dendrites required\n        treefun: Optional function to calculate the tree type of neuron's\n        neurites\n\n    Returns:\n        CheckResult with result\n    '''\n    types = [treefun(n) for n in neuron.neurites]\n    return CheckResult(types.count(NeuriteType.apical_dendrite) >= min_number)", "response": "Check if a neuron has apical dendrites"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_basal_dendrite(neuron, min_number=1, treefun=_read_neurite_type):\n    '''Check if a neuron has basal dendrites\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        min_number: minimum number of basal dendrites required\n        treefun: Optional function to calculate the tree type of neuron's\n        neurites\n\n    Returns:\n        CheckResult with result\n    '''\n    types = [treefun(n) for n in neuron.neurites]\n    return CheckResult(types.count(NeuriteType.basal_dendrite) >= min_number)", "response": "Check if a neuron has basal dendrites"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_no_flat_neurites(neuron, tol=0.1, method='ratio'):\n    '''Check that a neuron has no flat neurites\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        tol(float): tolerance\n        method(string): way of determining flatness, 'tolerance', 'ratio' \\\n        as described in :meth:`neurom.check.morphtree.get_flat_neurites`\n\n    Returns:\n        CheckResult with result\n    '''\n    return CheckResult(len(get_flat_neurites(neuron, tol, method)) == 0)", "response": "Check that a neuron has no flat neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_all_nonzero_segment_lengths(neuron, threshold=0.0):\n    '''Check presence of neuron segments with length not above threshold\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        threshold(float): value above which a segment length is considered to\n        be non-zero\n\n    Returns:\n        CheckResult with result including list of (section_id, segment_id)\n        of zero length segments\n    '''\n    bad_ids = []\n    for sec in _nf.iter_sections(neuron):\n        p = sec.points\n        for i, s in enumerate(zip(p[:-1], p[1:])):\n            if segment_length(s) <= threshold:\n                bad_ids.append((sec.id, i))\n\n    return CheckResult(len(bad_ids) == 0, bad_ids)", "response": "Check presence of neuron segments with length not above threshold"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_all_nonzero_section_lengths(neuron, threshold=0.0):\n    '''Check presence of neuron sections with length not above threshold\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        threshold(float): value above which a section length is considered\n        to be non-zero\n\n    Returns:\n        CheckResult with result including list of ids of bad sections\n    '''\n    bad_ids = [s.id for s in _nf.iter_sections(neuron.neurites)\n               if section_length(s.points) <= threshold]\n\n    return CheckResult(len(bad_ids) == 0, bad_ids)", "response": "Check presence of neuron sections with length not above threshold"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck presence of neurite points with radius not above threshold", "response": "def has_all_nonzero_neurite_radii(neuron, threshold=0.0):\n    '''Check presence of neurite points with radius not above threshold\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        threshold: value above which a radius is considered to be non-zero\n\n    Returns:\n        CheckResult with result including list of (section ID, point ID) pairs\n        of zero-radius points\n    '''\n    bad_ids = []\n    seen_ids = set()\n    for s in _nf.iter_sections(neuron):\n        for i, p in enumerate(s.points):\n            info = (s.id, i)\n            if p[COLS.R] <= threshold and info not in seen_ids:\n                seen_ids.add(info)\n                bad_ids.append(info)\n\n    return CheckResult(len(bad_ids) == 0, bad_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_no_jumps(neuron, max_distance=30.0, axis='z'):\n    '''Check if there are jumps (large movements in the `axis`)\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        max_distance(float): value above which consecutive z-values are\n        considered a jump\n        axis(str): one of x/y/z, which axis to check for jumps\n\n    Returns:\n        CheckResult with result list of ids of bad sections\n    '''\n    bad_ids = []\n    axis = {'x': COLS.X, 'y': COLS.Y, 'z': COLS.Z, }[axis.lower()]\n    for neurite in iter_neurites(neuron):\n        section_segment = ((sec, seg) for sec in iter_sections(neurite)\n                           for seg in iter_segments(sec))\n        for sec, (p0, p1) in islice(section_segment, 1, None):  # Skip neurite root segment\n            if max_distance < abs(p0[axis] - p1[axis]):\n                bad_ids.append((sec.id, [p0, p1]))\n    return CheckResult(len(bad_ids) == 0, bad_ids)", "response": "Check if there are no jumps in the given axis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the points in the neuron are too large", "response": "def has_no_fat_ends(neuron, multiple_of_mean=2.0, final_point_count=5):\n    '''Check if leaf points are too large\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        multiple_of_mean(float): how many times larger the final radius\n        has to be compared to the mean of the final points\n        final_point_count(int): how many points to include in the mean\n\n    Returns:\n        CheckResult with result list of ids of bad sections\n\n    Note:\n        A fat end is defined as a leaf segment whose last point is larger\n        by a factor of `multiple_of_mean` than the mean of the points in\n        `final_point_count`\n    '''\n    bad_ids = []\n    for leaf in _nf.iter_sections(neuron.neurites, iterator_type=Tree.ileaf):\n        mean_radius = np.mean(leaf.points[1:][-final_point_count:, COLS.R])\n\n        if mean_radius * multiple_of_mean <= leaf.points[-1, COLS.R]:\n            bad_ids.append((leaf.id, leaf.points[-1:]))\n\n    return CheckResult(len(bad_ids) == 0, bad_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a neuron has a narrow start", "response": "def has_no_narrow_start(neuron, frac=0.9):\n    '''Check if neurites have a narrow start\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        frac(float): Ratio that the second point must be smaller than the first\n\n    Returns:\n        CheckResult with a list of all first segments of neurites with a narrow start\n    '''\n    bad_ids = [(neurite.root_node.id, [neurite.root_node.points[1]])\n               for neurite in neuron.neurites\n               if neurite.root_node.points[1][COLS.R] < frac * neurite.root_node.points[2][COLS.R]]\n    return CheckResult(len(bad_ids) == 0, bad_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the neuron has dangling neurites", "response": "def has_no_dangling_branch(neuron):\n    '''Check if the neuron has dangling neurites'''\n    soma_center = neuron.soma.points[:, COLS.XYZ].mean(axis=0)\n    recentered_soma = neuron.soma.points[:, COLS.XYZ] - soma_center\n    radius = np.linalg.norm(recentered_soma, axis=1)\n    soma_max_radius = radius.max()\n\n    def is_dangling(neurite):\n        '''Is the neurite dangling ?'''\n        starting_point = neurite.points[1][COLS.XYZ]\n\n        if np.linalg.norm(starting_point - soma_center) - soma_max_radius <= 12.:\n            return False\n\n        if neurite.type != NeuriteType.axon:\n            return True\n\n        all_points = list(chain.from_iterable(n.points[1:]\n                                              for n in iter_neurites(neurite)\n                                              if n.type != NeuriteType.axon))\n        res = [np.linalg.norm(starting_point - p[COLS.XYZ]) >= 2 * p[COLS.R] + 2\n               for p in all_points]\n        return all(res)\n\n    bad_ids = [(n.root_node.id, [n.root_node.points[1]])\n               for n in iter_neurites(neuron) if is_dangling(n)]\n    return CheckResult(len(bad_ids) == 0, bad_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the neuron has no narrow sections", "response": "def has_no_narrow_neurite_section(neuron,\n                                  neurite_filter,\n                                  radius_threshold=0.05,\n                                  considered_section_min_length=50):\n    '''Check if the neuron has dendrites with narrow sections\n\n    Arguments:\n        neuron(Neuron): The neuron object to test\n        neurite_filter(callable): filter the neurites by this callable\n        radius_threshold(float): radii below this are considered narro\n        considered_section_min_length(float): sections with length below\n        this are not taken into account\n\n    Returns:\n        CheckResult with result. result.info contains the narrow section ids and their\n        first point\n    '''\n\n    considered_sections = (sec for sec in iter_sections(neuron, neurite_filter=neurite_filter)\n                           if sec.length > considered_section_min_length)\n\n    def narrow_section(section):\n        '''Select narrow sections'''\n        return section.points[:, COLS.R].mean() < radius_threshold\n\n    bad_ids = [(section.id, section.points[1])\n               for section in considered_sections if narrow_section(section)]\n    return CheckResult(len(bad_ids) == 0, bad_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_data(neurons, feature, params=None):\n    '''Extracts feature from a list of neurons\n       and transforms the fitted distribution in the correct format.\n       Returns the optimal distribution and corresponding parameters.\n       Normal distribution params (mean, std)\n       Exponential distribution params (loc, scale)\n       Uniform distribution params (min, range)\n    '''\n    if params is None:\n        params = {}\n\n    feature_data = [get(FEATURE_MAP[feature], n, **params) for n in neurons]\n    feature_data = list(chain(*feature_data))\n    return stats.optimal_distribution(feature_data)", "response": "Extracts feature from a list of neurons and transforms the fitted distribution in the correct format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform_header(mtype_name):\n    '''Add header to json output to wrap around distribution data.\n    '''\n    head_dict = OrderedDict()\n\n    head_dict[\"m-type\"] = mtype_name\n    head_dict[\"components\"] = defaultdict(OrderedDict)\n\n    return head_dict", "response": "Add header to json output to wrap around distribution data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform a package into a json output.", "response": "def transform_package(mtype, files, components):\n    '''Put together header and list of data into one json output.\n       feature_list contains all the information about the data to be extracted:\n       features, feature_names, feature_components, feature_min, feature_max\n    '''\n    data_dict = transform_header(mtype)\n    neurons = load_neurons(files)\n\n    for comp in components:\n        params = PARAM_MAP[comp.name]\n        for feature in comp.features:\n            result = stats.fit_results_to_dict(\n                extract_data(neurons, feature.name, params),\n                feature.limits.min, feature.limits.max\n            )\n\n            # When the distribution is normal with sigma = 0\n            # it will be replaced with constant\n            if result['type'] == 'normal' and result['sigma'] == 0.0:\n                replace_result = OrderedDict((('type', 'constant'),\n                                              ('val', result['mu'])))\n                result = replace_result\n\n            data_dict[\"components\"][comp.name].update({feature.name: result})\n\n    return data_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_args():\n    '''Parse command line arguments'''\n    parser = argparse.ArgumentParser(\n        description='Morphology fit distribution extractor',\n        epilog='Note: Outputs json of the optimal distribution \\\n                and corresponding parameters.')\n\n    parser.add_argument('datapaths',\n                        nargs='+',\n                        help='Morphology data directory paths')\n\n    parser.add_argument('--mtype', choices=MTYPE_GETTERS.keys(),\n                        help='Get mtype from filename or parent directory')\n\n    return parser.parse_args()", "response": "Parse command line arguments"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing the morphology using in the given plane", "response": "def draw(obj, plane='3d', inline=False, **kwargs):\n    '''Draw the morphology using in the given plane\n\n    plane (str): a string representing the 2D plane (example: 'xy')\n                 or '3d', '3D' for a 3D view\n\n    inline (bool): must be set to True for interactive ipython notebook plotting\n    '''\n    if plane.lower() == '3d':\n        return _plot_neuron3d(obj, inline, **kwargs)\n    return _plot_neuron(obj, plane, inline, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a figure of the neuron and neuron - 3D", "response": "def _plot_neuron3d(neuron, inline, **kwargs):\n    '''\n    Generates a figure of the neuron,\n    that contains a soma and a list of trees.\n    '''\n    return _plotly(neuron, plane='3d', title='neuron-3D', inline=inline, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the trace to be plotted", "response": "def _make_trace(neuron, plane):\n    '''Create the trace to be plotted'''\n    for neurite in iter_neurites(neuron):\n        segments = list(iter_segments(neurite))\n\n        segs = [(s[0][COLS.XYZ], s[1][COLS.XYZ]) for s in segments]\n\n        coords = dict(x=list(chain.from_iterable((p1[0], p2[0], None) for p1, p2 in segs)),\n                      y=list(chain.from_iterable((p1[1], p2[1], None) for p1, p2 in segs)),\n                      z=list(chain.from_iterable((p1[2], p2[2], None) for p1, p2 in segs)))\n\n        color = TREE_COLOR.get(neurite.root_node.type, 'black')\n        if plane.lower() == '3d':\n            plot_fun = go.Scatter3d\n        else:\n            plot_fun = go.Scatter\n            coords = dict(x=coords[plane[0]], y=coords[plane[1]])\n        yield plot_fun(\n            line=dict(color=color, width=2),\n            mode='lines',\n            **coords\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the plotly figure containing the neuron", "response": "def get_figure(neuron, plane, title):\n    '''Returns the plotly figure containing the neuron'''\n    data = list(_make_trace(neuron, plane))\n    axis = dict(\n        gridcolor='rgb(255, 255, 255)',\n        zerolinecolor='rgb(255, 255, 255)',\n        showbackground=True,\n        backgroundcolor='rgb(230, 230,230)'\n    )\n\n    if plane != '3d':\n        soma_2d = [\n            # filled circle\n            {\n                'type': 'circle',\n                'xref': 'x',\n                'yref': 'y',\n                'fillcolor': 'rgba(50, 171, 96, 0.7)',\n                'x0': neuron.soma.center[0] - neuron.soma.radius,\n                'y0': neuron.soma.center[1] - neuron.soma.radius,\n                'x1': neuron.soma.center[0] + neuron.soma.radius,\n                'y1': neuron.soma.center[1] + neuron.soma.radius,\n\n                'line': {\n                    'color': 'rgba(50, 171, 96, 1)',\n                },\n            },\n        ]\n\n    else:\n        soma_2d = []\n        theta = np.linspace(0, 2 * np.pi, 100)\n        phi = np.linspace(0, np.pi, 100)\n        z = np.outer(np.ones(100), np.cos(phi)) + neuron.soma.center[2]\n        r = neuron.soma.radius\n        data.append(\n            go.Surface(\n                x=(np.outer(np.cos(theta), np.sin(phi)) + neuron.soma.center[0]) * r,\n                y=(np.outer(np.sin(theta), np.sin(phi)) + neuron.soma.center[1]) * r,\n                z=z * r,\n                cauto=False,\n                surfacecolor=['black'] * len(z),\n                showscale=False,\n            )\n        )\n\n    layout = dict(\n        autosize=True,\n        title=title,\n        scene=dict(  # This is used for 3D plots\n            xaxis=axis, yaxis=axis, zaxis=axis,\n            camera=dict(up=dict(x=0, y=0, z=1), eye=dict(x=-1.7428, y=1.0707, z=0.7100,)),\n            aspectmode='data'\n        ),\n        yaxis=dict(scaleanchor=\"x\"),  # This is used for 2D plots\n        shapes=soma_2d,\n    )\n\n    res = dict(data=data, layout=layout)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rotate(obj, axis, angle, origin=None):\n    '''\n    Rotation around unit vector following the right hand rule\n\n    Parameters:\n        obj : obj to be rotated (e.g. neurite, neuron).\n            Must implement a transform method.\n        axis : unit vector for the axis of rotation\n        angle : rotation angle in rads\n\n    Returns:\n        A copy of the object with the applied translation.\n    '''\n    R = _rodrigues_to_dcm(axis, angle)\n\n    try:\n        return obj.transform(PivotRotation(R, origin))\n    except AttributeError:\n        raise NotImplementedError", "response": "Rotates the object around the right hand rule of the neurite."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _sin(x):\n    '''sine with case for pi multiples'''\n    return 0. if np.isclose(np.mod(x, np.pi), 0.) else np.sin(x)", "response": "sine with case for pi multiples"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _rodrigues_to_dcm(axis, angle):\n    '''\n    Generates transformation matrix from unit vector\n    and rotation angle. The rotation is applied in the direction\n    of the axis which is a unit vector following the right hand rule.\n\n    Inputs :\n\n        axis : unit vector of the direction of the rotation\n        angle : angle of rotation in rads\n\n    Returns : 3x3 Rotation matrix\n    '''\n    ux, uy, uz = axis / np.linalg.norm(axis)\n\n    uxx = ux * ux\n    uyy = uy * uy\n    uzz = uz * uz\n    uxy = ux * uy\n    uxz = ux * uz\n    uyz = uy * uz\n\n    sn = _sin(angle)\n    cs = _sin(np.pi / 2. - angle)\n    cs1 = 1. - cs\n\n    R = np.zeros([3, 3])\n\n    R[0, 0] = cs + uxx * cs1\n    R[0, 1] = uxy * cs1 - uz * sn\n    R[0, 2] = uxz * cs1 + uy * sn\n\n    R[1, 0] = uxy * cs1 + uz * sn\n    R[1, 1] = cs + uyy * cs1\n    R[1, 2] = uyz * cs1 - ux * sn\n\n    R[2, 0] = uxz * cs1 - uy * sn\n    R[2, 1] = uyz * cs1 + ux * sn\n    R[2, 2] = cs + uzz * cs1\n\n    return R", "response": "Generates transformation matrix from unit vector to unit vector of the rotation in the right hand rule."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef total_length(nrn_pop, neurite_type=NeuriteType.all):\n    '''Get the total length of all sections in the group of neurons or neurites'''\n    nrns = _neuronfunc.neuron_population(nrn_pop)\n    return list(sum(section_lengths(n, neurite_type=neurite_type)) for n in nrns)", "response": "Get the total length of all sections in a group of neurons or neurites"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnumbers of segments in a collection of neurites", "response": "def n_segments(neurites, neurite_type=NeuriteType.all):\n    '''Number of segments in a collection of neurites'''\n    return sum(len(s.points) - 1\n               for s in iter_sections(neurites, neurite_filter=is_type(neurite_type)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnumbering of neurites in a collection of neurites", "response": "def n_neurites(neurites, neurite_type=NeuriteType.all):\n    '''Number of neurites in a collection of neurites'''\n    return sum(1 for _ in iter_neurites(neurites, filt=is_type(neurite_type)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef n_sections(neurites, neurite_type=NeuriteType.all, iterator_type=Tree.ipreorder):\n    '''Number of sections in a collection of neurites'''\n    return sum(1 for _ in iter_sections(neurites,\n                                        iterator_type=iterator_type,\n                                        neurite_filter=is_type(neurite_type)))", "response": "Number of sections in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnumber of bifurcation points in a collection of neurites", "response": "def n_bifurcation_points(neurites, neurite_type=NeuriteType.all):\n    '''number of bifurcation points in a collection of neurites'''\n    return n_sections(neurites, neurite_type=neurite_type, iterator_type=Tree.ibifurcation_point)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef n_forking_points(neurites, neurite_type=NeuriteType.all):\n    '''number of forking points in a collection of neurites'''\n    return n_sections(neurites, neurite_type=neurite_type, iterator_type=Tree.iforking_point)", "response": "number of forking points in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnumbers of leaves in a collection of neurites", "response": "def n_leaves(neurites, neurite_type=NeuriteType.all):\n    '''number of leaves points in a collection of neurites'''\n    return n_sections(neurites, neurite_type=neurite_type, iterator_type=Tree.ileaf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsurfaces area in a collection of neurites.", "response": "def total_area_per_neurite(neurites, neurite_type=NeuriteType.all):\n    '''Surface area in a collection of neurites.\n\n    The area is defined as the sum of the area of the sections.\n    '''\n    return [neurite.area for neurite in iter_neurites(neurites, filt=is_type(neurite_type))]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map_sections(fun, neurites, neurite_type=NeuriteType.all, iterator_type=Tree.ipreorder):\n    '''Map `fun` to all the sections in a collection of neurites'''\n    return map(fun, iter_sections(neurites,\n                                  iterator_type=iterator_type,\n                                  neurite_filter=is_type(neurite_type)))", "response": "Map fun to all the sections in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef section_lengths(neurites, neurite_type=NeuriteType.all):\n    '''section lengths in a collection of neurites'''\n    return map_sections(_section_length, neurites, neurite_type=neurite_type)", "response": "section lengths in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef section_term_lengths(neurites, neurite_type=NeuriteType.all):\n    '''Termination section lengths in a collection of neurites'''\n    return map_sections(_section_length, neurites, neurite_type=neurite_type,\n                        iterator_type=Tree.ileaf)", "response": "Termination section lengths in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsections branch orders in a collection of neurites", "response": "def section_branch_orders(neurites, neurite_type=NeuriteType.all):\n    '''section branch orders in a collection of neurites'''\n    return map_sections(sectionfunc.branch_order, neurites, neurite_type=neurite_type)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping fun to all the neurites in a single or collection of neurons", "response": "def map_neurons(fun, neurites, neurite_type):\n    '''Map `fun` to all the neurites in a single or collection of neurons'''\n    nrns = _neuronfunc.neuron_population(neurites)\n    return [fun(n, neurite_type=neurite_type) for n in nrns]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmap func to all the segments in a collection of neurites and return list of values corresponding to each segment in the collection.", "response": "def map_segments(func, neurites, neurite_type):\n    ''' Map `func` to all the segments in a collection of neurites\n\n        `func` accepts a section and returns list of values corresponding to each segment.\n    '''\n    neurite_filter = is_type(neurite_type)\n    return [\n        s for ss in iter_sections(neurites, neurite_filter=neurite_filter) for s in func(ss)\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvolume of the segments in a collection of neurites", "response": "def segment_volumes(neurites, neurite_type=NeuriteType.all):\n    '''Volumes of the segments in a collection of neurites'''\n    def _func(sec):\n        '''list of segment volumes of a section'''\n        return [morphmath.segment_volume(seg) for seg in zip(sec.points[:-1], sec.points[1:])]\n\n    return map_segments(_func, neurites, neurite_type)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef segment_radii(neurites, neurite_type=NeuriteType.all):\n    '''arithmetic mean of the radii of the points in segments in a collection of neurites'''\n    def _seg_radii(sec):\n        '''vectorized mean radii'''\n        pts = sec.points[:, COLS.R]\n        return np.divide(np.add(pts[:-1], pts[1:]), 2.0)\n\n    return map_segments(_seg_radii, neurites, neurite_type)", "response": "arithmetic mean of the radii of the points in segments in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef segment_taper_rates(neurites, neurite_type=NeuriteType.all):\n    '''taper rates of the segments in a collection of neurites\n\n    The taper rate is defined as the absolute radii differences divided by length of the section\n    '''\n    def _seg_taper_rates(sec):\n        '''vectorized taper rates'''\n        pts = sec.points[:, COLS.XYZR]\n        diff = np.diff(pts, axis=0)\n        distance = np.linalg.norm(diff[:, COLS.XYZ], axis=1)\n        return np.divide(2 * np.abs(diff[:, COLS.R]), distance)\n\n    return map_segments(_seg_taper_rates, neurites, neurite_type)", "response": "taper rates of the segments in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninters - segment opening angles in a collection of neurites", "response": "def segment_meander_angles(neurites, neurite_type=NeuriteType.all):\n    '''Inter-segment opening angles in a section'''\n    return list(chain.from_iterable(map_sections(\n        sectionfunc.section_meander_angles, neurites, neurite_type)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef segment_midpoints(neurites, neurite_type=NeuriteType.all):\n    '''Return a list of segment mid-points in a collection of neurites'''\n    def _seg_midpoint(sec):\n        '''Return the mid-points of segments in a section'''\n        pts = sec.points[:, COLS.XYZ]\n        return np.divide(np.add(pts[:-1], pts[1:]), 2.0)\n\n    return map_segments(_seg_midpoint, neurites, neurite_type)", "response": "Return a list of segment mid - points in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef segment_radial_distances(neurites, neurite_type=NeuriteType.all, origin=None):\n    '''Lengths of the segments in a collection of neurites'''\n    def _seg_rd(sec, pos):\n        '''list of radial distances of all segments of a section'''\n        # TODO: remove this disable when pylint is fixed\n        # pylint: disable=assignment-from-no-return\n        mid_pts = np.divide(np.add(sec.points[:-1], sec.points[1:])[:, :3], 2.0)\n        return np.sqrt([morphmath.point_dist2(p, pos) for p in mid_pts])\n\n    dist = []\n    for n in iter_neurites(neurites, filt=is_type(neurite_type)):\n        pos = n.root_node.points[0] if origin is None else origin\n        dist.extend([s for ss in n.iter_sections() for s in _seg_rd(ss, pos)])\n\n    return dist", "response": "Lengths of the segments in a collection of neurites origin is the point of the origin of the segment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef local_bifurcation_angles(neurites, neurite_type=NeuriteType.all):\n    '''Get a list of local bifurcation angles in a collection of neurites'''\n    return map_sections(_bifurcationfunc.local_bifurcation_angle,\n                        neurites,\n                        neurite_type=neurite_type,\n                        iterator_type=Tree.ibifurcation_point)", "response": "Get a list of local bifurcation angles in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remote_bifurcation_angles(neurites, neurite_type=NeuriteType.all):\n    '''Get a list of remote bifurcation angles in a collection of neurites'''\n    return map_sections(_bifurcationfunc.remote_bifurcation_angle,\n                        neurites,\n                        neurite_type=neurite_type,\n                        iterator_type=Tree.ibifurcation_point)", "response": "Get a list of remote bifurcation angles in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npartition at bifurcation points of a collection of neurites", "response": "def bifurcation_partitions(neurites, neurite_type=NeuriteType.all):\n    '''Partition at bifurcation points of a collection of neurites'''\n    return map(_bifurcationfunc.bifurcation_partition,\n               iter_sections(neurites,\n                             iterator_type=Tree.ibifurcation_point,\n                             neurite_filter=is_type(neurite_type)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef partition_asymmetries(neurites, neurite_type=NeuriteType.all):\n    '''Partition asymmetry at bifurcation points of a collection of neurites'''\n    return map(_bifurcationfunc.partition_asymmetry,\n               iter_sections(neurites,\n                             iterator_type=Tree.ibifurcation_point,\n                             neurite_filter=is_type(neurite_type)))", "response": "Partition asymmetries at bifurcation points of a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef partition_pairs(neurites, neurite_type=NeuriteType.all):\n    '''Partition pairs at bifurcation points of a collection of neurites.\n    Partition pait is defined as the number of bifurcations at the two\n    daughters of the bifurcating section'''\n    return map(_bifurcationfunc.partition_pair,\n               iter_sections(neurites,\n                             iterator_type=Tree.ibifurcation_point,\n                             neurite_filter=is_type(neurite_type)))", "response": "Partition pairs at bifurcation points of a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsections radial distances in a collection of neurites.", "response": "def section_radial_distances(neurites, neurite_type=NeuriteType.all, origin=None,\n                             iterator_type=Tree.ipreorder):\n    '''Section radial distances in a collection of neurites.\n    The iterator_type can be used to select only terminal sections (ileaf)\n    or only bifurcations (ibifurcation_point).'''\n    dist = []\n    for n in iter_neurites(neurites, filt=is_type(neurite_type)):\n        pos = n.root_node.points[0] if origin is None else origin\n        dist.extend(sectionfunc.section_radial_distance(s, pos)\n                    for s in iter_sections(n,\n                                           iterator_type=iterator_type))\n    return dist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef section_term_radial_distances(neurites, neurite_type=NeuriteType.all, origin=None):\n    '''Get the radial distances of the termination sections for a collection of neurites'''\n    return section_radial_distances(neurites, neurite_type=neurite_type, origin=origin,\n                                    iterator_type=Tree.ileaf)", "response": "Get the radial distances of the termination sections for a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef section_bif_radial_distances(neurites, neurite_type=NeuriteType.all, origin=None):\n    '''Get the radial distances of the bifurcation sections for a collection of neurites'''\n    return section_radial_distances(neurites, neurite_type=neurite_type, origin=origin,\n                                    iterator_type=Tree.ibifurcation_point)", "response": "Get the radial distances of the bifurcation sections for a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the number of sections per neurite in a collection of neurites", "response": "def number_of_sections_per_neurite(neurites, neurite_type=NeuriteType.all):\n    '''Get the number of sections per neurite in a collection of neurites'''\n    return list(sum(1 for _ in n.iter_sections())\n                for n in iter_neurites(neurites, filt=is_type(neurite_type)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the path length per neurite in a collection", "response": "def total_length_per_neurite(neurites, neurite_type=NeuriteType.all):\n    '''Get the path length per neurite in a collection'''\n    return list(sum(s.length for s in n.iter_sections())\n                for n in iter_neurites(neurites, filt=is_type(neurite_type)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef terminal_path_lengths_per_neurite(neurites, neurite_type=NeuriteType.all):\n    '''Get the path lengths to each terminal point per neurite in a collection'''\n    return list(sectionfunc.section_path_length(s)\n                for n in iter_neurites(neurites, filt=is_type(neurite_type))\n                for s in iter_sections(n, iterator_type=Tree.ileaf))", "response": "Get the path lengths to each terminal point per neurite in a collection"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef total_volume_per_neurite(neurites, neurite_type=NeuriteType.all):\n    '''Get the volume per neurite in a collection'''\n    return list(sum(s.volume for s in n.iter_sections())\n                for n in iter_neurites(neurites, filt=is_type(neurite_type)))", "response": "Get the volume per neurite in a collection"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef neurite_volume_density(neurites, neurite_type=NeuriteType.all):\n    '''Get the volume density per neurite\n\n    The volume density is defined as the ratio of the neurite volume and\n    the volume of the neurite's enclosing convex hull\n    '''\n    def vol_density(neurite):\n        '''volume density of a single neurite'''\n        return neurite.volume / convex_hull(neurite).volume\n\n    return list(vol_density(n)\n                for n in iter_neurites(neurites, filt=is_type(neurite_type)))", "response": "Get the volume density per neurite"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef section_volumes(neurites, neurite_type=NeuriteType.all):\n    '''section volumes in a collection of neurites'''\n    return map_sections(sectionfunc.section_volume, neurites, neurite_type=neurite_type)", "response": "section volumes in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef section_areas(neurites, neurite_type=NeuriteType.all):\n    '''section areas in a collection of neurites'''\n    return map_sections(sectionfunc.section_area, neurites, neurite_type=neurite_type)", "response": "section areas in a collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsectioning tortuosities in a collection of neurites", "response": "def section_tortuosity(neurites, neurite_type=NeuriteType.all):\n    '''section tortuosities in a collection of neurites'''\n    return map_sections(sectionfunc.section_tortuosity, neurites, neurite_type=neurite_type)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsection end to end distances in a collection of neurites", "response": "def section_end_distances(neurites, neurite_type=NeuriteType.all):\n    '''section end to end distances in a collection of neurites'''\n    return map_sections(sectionfunc.section_end_distance, neurites, neurite_type=neurite_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef principal_direction_extents(neurites, neurite_type=NeuriteType.all, direction=0):\n    '''Principal direction extent of neurites in neurons'''\n    def _pde(neurite):\n        '''Get the PDE of a single neurite'''\n        # Get the X, Y,Z coordinates of the points in each section\n        points = neurite.points[:, :3]\n        return morphmath.principal_direction_extent(points)[direction]\n\n    return map(_pde, iter_neurites(neurites, filt=is_type(neurite_type)))", "response": "Principal direction extent of neurites in a collection of neurons"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef section_strahler_orders(neurites, neurite_type=NeuriteType.all):\n    '''Inter-segment opening angles in a section'''\n    return map_sections(sectionfunc.strahler_order, neurites, neurite_type)", "response": "Inter - segment opening angles in a section"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _plane2col(plane):\n    '''take a string like 'xy', and return the indices from COLS.*'''\n    planes = ('xy', 'yx', 'xz', 'zx', 'yz', 'zy')\n    assert plane in planes, 'No such plane found! Please select one of: ' + str(planes)\n    return (getattr(COLS, plane[0].capitalize()),\n            getattr(COLS, plane[1].capitalize()), )", "response": "take a string like xy and return the indices from COLS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_linewidth(tree, linewidth, diameter_scale):\n    '''calculate the desired linewidth based on tree contents\n\n    If diameter_scale exists, it is used to scale the diameter of each of the segments\n    in the tree\n    If diameter_scale is None, the linewidth is used.\n    '''\n    if diameter_scale is not None and tree:\n        linewidth = [2 * segment_radius(s) * diameter_scale\n                     for s in iter_segments(tree)]\n    return linewidth", "response": "calculate the desired linewidth based on tree contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a 2d figure of the tree s segments", "response": "def plot_tree(ax, tree, plane='xy',\n              diameter_scale=_DIAMETER_SCALE, linewidth=_LINEWIDTH,\n              color=None, alpha=_ALPHA):\n    '''Plots a 2d figure of the tree's segments\n\n    Args:\n        ax(matplotlib axes): on what to plot\n        tree(neurom.core.Tree or neurom.core.Neurite): plotted tree\n        plane(str): Any pair of 'xyz'\n        diameter_scale(float): Scale factor multiplied with segment diameters before plotting\n        linewidth(float): all segments are plotted with this width, but only if diameter_scale=None\n        color(str or None): Color of plotted values, None corresponds to default choice\n        alpha(float): Transparency of plotted values\n\n    Note:\n        If the tree contains one single point the plot will be empty\n        since no segments can be constructed.\n    '''\n    plane0, plane1 = _plane2col(plane)\n    segs = [((s[0][plane0], s[0][plane1]),\n             (s[1][plane0], s[1][plane1]))\n            for s in iter_segments(tree)]\n\n    linewidth = _get_linewidth(tree, diameter_scale=diameter_scale, linewidth=linewidth)\n    color = _get_color(color, tree.type)\n\n    collection = LineCollection(segs, color=color, linewidth=linewidth, alpha=alpha)\n    ax.add_collection(collection)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_soma(ax, soma, plane='xy',\n              soma_outline=True,\n              linewidth=_LINEWIDTH,\n              color=None, alpha=_ALPHA):\n    '''Generates a 2d figure of the soma.\n\n    Args:\n        ax(matplotlib axes): on what to plot\n        soma(neurom.core.Soma): plotted soma\n        plane(str): Any pair of 'xyz'\n        diameter_scale(float): Scale factor multiplied with segment diameters before plotting\n        linewidth(float): all segments are plotted with this width, but only if diameter_scale=None\n        color(str or None): Color of plotted values, None corresponds to default choice\n        alpha(float): Transparency of plotted values\n    '''\n    plane0, plane1 = _plane2col(plane)\n    color = _get_color(color, tree_type=NeuriteType.soma)\n\n    if isinstance(soma, SomaCylinders):\n        plane0, plane1 = _plane2col(plane)\n        for start, end in zip(soma.points, soma.points[1:]):\n            common.project_cylinder_onto_2d(ax, (plane0, plane1),\n                                            start=start[COLS.XYZ], end=end[COLS.XYZ],\n                                            start_radius=start[COLS.R], end_radius=end[COLS.R],\n                                            color=color, alpha=alpha)\n    else:\n        if soma_outline:\n            ax.add_artist(Circle(soma.center[[plane0, plane1]], soma.radius,\n                                 color=color, alpha=alpha))\n        else:\n            plane0, plane1 = _plane2col(plane)\n            points = [(p[plane0], p[plane1]) for p in soma.iter()]\n\n            if points:\n                points.append(points[0])  # close the loop\n                ax.plot(points, color=color, alpha=alpha, linewidth=linewidth)\n\n    ax.set_xlabel(plane[0])\n    ax.set_ylabel(plane[1])\n\n    bounding_box = geom.bounding_box(soma)\n    ax.dataLim.update_from_data_xy(np.vstack(([bounding_box[0][plane0], bounding_box[0][plane1]],\n                                              [bounding_box[1][plane0], bounding_box[1][plane1]])),\n                                   ignore=False)", "response": "Plots a 2d figure of the soma."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_neuron(ax, nrn,\n                neurite_type=NeuriteType.all,\n                plane='xy',\n                soma_outline=True,\n                diameter_scale=_DIAMETER_SCALE, linewidth=_LINEWIDTH,\n                color=None, alpha=_ALPHA):\n    '''Plots a 2D figure of the neuron, that contains a soma and the neurites\n\n    Args:\n        ax(matplotlib axes): on what to plot\n        neurite_type(NeuriteType): an optional filter on the neurite type\n        nrn(neuron): neuron to be plotted\n        soma_outline(bool): should the soma be drawn as an outline\n        plane(str): Any pair of 'xyz'\n        diameter_scale(float): Scale factor multiplied with segment diameters before plotting\n        linewidth(float): all segments are plotted with this width, but only if diameter_scale=None\n        color(str or None): Color of plotted values, None corresponds to default choice\n        alpha(float): Transparency of plotted values\n    '''\n    plot_soma(ax, nrn.soma, plane=plane, soma_outline=soma_outline, linewidth=linewidth,\n              color=color, alpha=alpha)\n\n    for neurite in iter_neurites(nrn, filt=tree_type_checker(neurite_type)):\n        plot_tree(ax, neurite, plane=plane,\n                  diameter_scale=diameter_scale, linewidth=linewidth,\n                  color=color, alpha=alpha)\n\n    ax.set_title(nrn.name)\n    ax.set_xlabel(plane[0])\n    ax.set_ylabel(plane[1])", "response": "Plots a 2D figure of the neuron that contains a tree and a soma."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the dataLim of a 3D dataLim", "response": "def _update_3d_datalim(ax, obj):\n    '''unlike w/ 2d Axes, the dataLim isn't set by collections, so it has to be updated manually'''\n    min_bounding_box, max_bounding_box = geom.bounding_box(obj)\n    xy_bounds = np.vstack((min_bounding_box[:COLS.Z],\n                           max_bounding_box[:COLS.Z]))\n    ax.xy_dataLim.update_from_data_xy(xy_bounds, ignore=False)\n\n    z_bounds = np.vstack(((min_bounding_box[COLS.Z], min_bounding_box[COLS.Z]),\n                          (max_bounding_box[COLS.Z], max_bounding_box[COLS.Z])))\n    ax.zz_dataLim.update_from_data_xy(z_bounds, ignore=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a figure of the tree in 3d.", "response": "def plot_tree3d(ax, tree,\n                diameter_scale=_DIAMETER_SCALE, linewidth=_LINEWIDTH,\n                color=None, alpha=_ALPHA):\n    '''Generates a figure of the tree in 3d.\n\n    If the tree contains one single point the plot will be empty \\\n    since no segments can be constructed.\n\n    Args:\n        ax(matplotlib axes): on what to plot\n        tree(neurom.core.Tree or neurom.core.Neurite): plotted tree\n        diameter_scale(float): Scale factor multiplied with segment diameters before plotting\n        linewidth(float): all segments are plotted with this width, but only if diameter_scale=None\n        color(str or None): Color of plotted values, None corresponds to default choice\n        alpha(float): Transparency of plotted values\n    '''\n    segs = [(s[0][COLS.XYZ], s[1][COLS.XYZ]) for s in iter_segments(tree)]\n\n    linewidth = _get_linewidth(tree, diameter_scale=diameter_scale, linewidth=linewidth)\n    color = _get_color(color, tree.type)\n\n    collection = Line3DCollection(segs, color=color, linewidth=linewidth, alpha=alpha)\n    ax.add_collection3d(collection)\n\n    _update_3d_datalim(ax, tree)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a 3d figure of the soma.", "response": "def plot_soma3d(ax, soma, color=None, alpha=_ALPHA):\n    '''Generates a 3d figure of the soma.\n\n    Args:\n        ax(matplotlib axes): on what to plot\n        soma(neurom.core.Soma): plotted soma\n        color(str or None): Color of plotted values, None corresponds to default choice\n        alpha(float): Transparency of plotted values\n    '''\n    color = _get_color(color, tree_type=NeuriteType.soma)\n\n    if isinstance(soma, SomaCylinders):\n        for start, end in zip(soma.points, soma.points[1:]):\n            common.plot_cylinder(ax,\n                                 start=start[COLS.XYZ], end=end[COLS.XYZ],\n                                 start_radius=start[COLS.R], end_radius=end[COLS.R],\n                                 color=color, alpha=alpha)\n    else:\n        common.plot_sphere(ax, center=soma.center[COLS.XYZ], radius=soma.radius,\n                           color=color, alpha=alpha)\n\n    # unlike w/ 2d Axes, the dataLim isn't set by collections, so it has to be updated manually\n    _update_3d_datalim(ax, soma)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the 3D figure of the neuron and all of its trees.", "response": "def plot_neuron3d(ax, nrn, neurite_type=NeuriteType.all,\n                  diameter_scale=_DIAMETER_SCALE, linewidth=_LINEWIDTH,\n                  color=None, alpha=_ALPHA):\n    '''\n    Generates a figure of the neuron,\n    that contains a soma and a list of trees.\n\n    Args:\n        ax(matplotlib axes): on what to plot\n        nrn(neuron): neuron to be plotted\n        neurite_type(NeuriteType): an optional filter on the neurite type\n        diameter_scale(float): Scale factor multiplied with segment diameters before plotting\n        linewidth(float): all segments are plotted with this width, but only if diameter_scale=None\n        color(str or None): Color of plotted values, None corresponds to default choice\n        alpha(float): Transparency of plotted values\n    '''\n    plot_soma3d(ax, nrn.soma, color=color, alpha=alpha)\n\n    for neurite in iter_neurites(nrn, filt=tree_type_checker(neurite_type)):\n        plot_tree3d(ax, neurite,\n                    diameter_scale=diameter_scale, linewidth=linewidth,\n                    color=color, alpha=alpha)\n\n    ax.set_title(nrn.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a single dendrogram of neurites", "response": "def _render_dendrogram(dnd, ax, displacement):\n    '''Renders dendrogram'''\n    # set of unique colors that reflect the set of types of the neurites\n    colors = set()\n\n    for n, (indices, ctype) in enumerate(zip(dnd.groups, dnd.types)):\n\n        # slice rectangles array for the current neurite\n        group = dnd.data[indices[0]:indices[1]]\n\n        if n > 0:\n            # displace the neurites by half of their maximum x dimension\n            # plus half of the previous neurite's maxmimum x dimension\n            displacement += 0.5 * (dnd.dims[n - 1][0] + dnd.dims[n][0])\n\n        # arrange the trees without overlapping with each other\n        group += (displacement, 0.)\n\n        # create the polygonal collection of the dendrogram\n        # segments\n        _generate_collection(group, ax, ctype, colors)\n\n    soma_square = dnd.soma\n\n    if soma_square is not None:\n\n        _generate_collection((soma_square + (displacement / 2., 0.),), ax, NeuriteType.soma, colors)\n        ax.plot((displacement / 2., displacement), (0., 0.), color='k')\n        ax.plot((0., displacement / 2.), (0., 0.), color='k')\n\n    return displacement"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a dendrogram of the object.", "response": "def plot_dendrogram(ax, obj, show_diameters=True):\n    '''Dendrogram of `obj`\n\n    Args:\n        obj: Neuron or tree \\\n        neurom.Neuron, neurom.Tree\n        show_diameters : boolean \\\n            Determines if node diameters will \\\n            be show or not.\n    '''\n    # create dendrogram and generate rectangle collection\n    dnd = Dendrogram(obj, show_diameters=show_diameters)\n    dnd.generate()\n\n    # render dendrogram and take into account neurite displacement which\n    # starts as zero. It is important to avoid overlapping of neurites\n    # and to determine tha limits of the figure.\n\n    _render_dendrogram(dnd, ax, 0.)\n\n    ax.set_title('Morphology Dendrogram')\n    ax.set_xlabel('micrometers (um)')\n    ax.set_ylabel('micrometers (um)')\n\n    ax.set_aspect('auto')\n    ax.legend()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_neurites(rdw):\n    '''Build neurite trees from a raw data wrapper'''\n    post_action = _NEURITE_ACTION[rdw.fmt]\n    trunks = rdw.neurite_root_section_ids()\n    if not trunks:\n        return [], []\n\n    # One pass over sections to build nodes\n    nodes = tuple(Section(section_id=i,\n                          points=rdw.data_block[sec.ids],\n                          section_type=_TREE_TYPES[sec.ntype])\n                  for i, sec in enumerate(rdw.sections))\n\n    # One pass over nodes to connect children to parents\n    for i, node in enumerate(nodes):\n        parent_id = rdw.sections[i].pid\n        parent_type = nodes[parent_id].type\n        # only connect neurites\n        if parent_id != ROOT_ID and parent_type != NeuriteType.soma:\n            nodes[parent_id].add_child(node)\n\n    neurites = tuple(Neurite(nodes[i]) for i in trunks)\n\n    if post_action is not None:\n        for n in neurites:\n            post_action(n.root_node)\n\n    return neurites, nodes", "response": "Build neurite trees from a raw data wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _remove_soma_initial_point(tree):\n    '''Remove tree's initial point if soma'''\n    if tree.points[0][COLS.TYPE] == POINT_TYPE.SOMA:\n        tree.points = tree.points[1:]", "response": "Remove tree s initial point if soma"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if points form valid soma Currently checks if there are bifurcations within a soma with more than three points.", "response": "def _check_soma_topology_swc(points):\n    '''check if points form valid soma\n\n    Currently checks if there are bifurcations within a soma\n    with more than three points.\n    '''\n    if len(points) == 3:\n        return\n\n    parents = tuple(p[COLS.P] for p in points if p[COLS.P] != ROOT_ID)\n    if len(parents) > len(set(parents)):\n        raise SomaError(\"Bifurcating soma\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef points(self):\n        '''Return unordered array with all the points in this neuron'''\n        if self._points is None:\n            _points = self.soma.points.tolist()\n            for n in self.neurites:\n                _points.extend(n.points.tolist())\n            self._points = np.array(_points)\n\n        return self._points", "response": "Return unordered array with all the points in this neuron"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform(self, trans):\n        '''Return a copy of this neuron with a 3D transformation applied'''\n        _data = deepcopy(self._data)\n        _data.data_block[:, 0:3] = trans(_data.data_block[:, 0:3])\n        return FstNeuron(_data, self.name)", "response": "Return a copy of this neuron with a 3D transformation applied"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute vector between two 3D points", "response": "def vector(p1, p2):\n    '''compute vector between two 3D points\n\n    Args:\n        p1, p2: indexable objects with\n        indices 0, 1, 2 corresponding to 3D cartesian coordinates.\n\n    Returns:\n        3-vector from p1 - p2\n    '''\n    return np.subtract(p1[COLS.XYZ], p2[COLS.XYZ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef linear_interpolate(p1, p2, fraction):\n    '''Returns the point p satisfying: p1 + fraction * (p2 - p1)'''\n    return np.array((p1[0] + fraction * (p2[0] - p1[0]),\n                     p1[1] + fraction * (p2[1] - p1[1]),\n                     p1[2] + fraction * (p2[2] - p1[2])))", "response": "Linear interpolation of two points p1 and p2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the interpolated radius that corresponds to a point P that lies at a fraction of the length r1 and r2 respectively.", "response": "def interpolate_radius(r1, r2, fraction):\n    '''Calculate the radius that corresponds to a point P that lies at a fraction of the length\n    of a cut cone P1P2 where P1, P2 are the centers of the circles that bound the shape with radii\n    r1 and r2 respectively.\n\n    Args:\n        r1: float\n            Radius of the first node of the segment.\n        r2: float\n            Radius of the second node of the segment\n        fraction: float\n            The fraction at which the interpolated radius is calculated.\n\n    Returns: float\n        The interpolated radius.\n\n    Note: The fraction is assumed from point P1, not from point P2.\n    '''\n    def f(a, b, c):\n        ''' Returns the length of the interpolated radius calculated\n        using similar triangles.\n        '''\n        return a + c * (b - a)\n    return f(r2, r1, 1. - fraction) if r1 > r2 else f(r1, r2, fraction)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path_fraction_id_offset(points, fraction, relative_offset=False):\n    '''Find the segment which corresponds to the fraction\n    of the path length along the piecewise linear curve which\n    is constructed from the set of points.\n\n    Args:\n        points: an iterable of indexable objects with indices\n        0, 1, 2 correspoding to 3D cartesian coordinates\n        fraction: path length fraction (0.0 <= fraction <= 1.0)\n        relative_offset: return absolute or relative segment distance\n\n    Returns:\n        (segment ID, segment offset) pair.\n    '''\n    if not (0. <= fraction <= 1.0):\n        raise ValueError(\"Invalid fraction: %.3f\" % fraction)\n    pts = np.array(points)[:, COLS.XYZ]\n    lengths = np.linalg.norm(np.diff(pts, axis=0), axis=1)\n    cum_lengths = np.cumsum(lengths)\n    offset = cum_lengths[-1] * fraction\n    seg_id = np.argmin(cum_lengths < offset)\n    if seg_id > 0:\n        offset -= cum_lengths[seg_id - 1]\n    if relative_offset:\n        offset /= lengths[seg_id]\n    return seg_id, offset", "response": "Find the segment which corresponds to the fraction of the path length along the piecewise linear curve which is constructed from the set of points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the point which corresponds to the fraction of the path length along the piecewise linear curve which is constructed from the set of points.", "response": "def path_fraction_point(points, fraction):\n    '''Computes the point which corresponds to the fraction\n    of the path length along the piecewise linear curve which\n    is constructed from the set of points.\n\n    Args:\n        points: an iterable of indexable objects with indices\n        0, 1, 2 correspoding to 3D cartesian coordinates\n        fraction: path length fraction (0 <= fraction <= 1)\n\n    Returns:\n        The 3D coordinates of the aforementioned point\n    '''\n    seg_id, offset = path_fraction_id_offset(points, fraction, relative_offset=True)\n    return linear_interpolate(points[seg_id], points[seg_id + 1], offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the scalar projection of v1 upon v2 upon v2", "response": "def scalar_projection(v1, v2):\n    '''compute the scalar projection of v1 upon v2\n\n    Args:\n        v1, v2: iterable\n        indices 0, 1, 2 corresponding to cartesian coordinates\n\n    Returns:\n        3-vector of the projection of point p onto the direction of v\n    '''\n    return np.dot(v1, v2) / np.linalg.norm(v2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vector_projection(v1, v2):\n    '''compute the vector projection of v1 upon v2\n\n    Args:\n        v1, v2: iterable\n        indices 0, 1, 2 corresponding to cartesian coordinates\n\n    Returns:\n        3-vector of the projection of point p onto the direction of v\n    '''\n    return scalar_projection(v1, v2) * v2 / np.linalg.norm(v2)", "response": "compute the vector projection of v1 upon v2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dist_point_line(p, l1, l2):\n    '''compute the orthogonal distance between from the line that goes through\n    the points l1, l2 and the point p\n\n    Args:\n        p, l1, l2 : iterable\n        point\n        indices 0, 1, 2 corresponding to cartesian coordinates\n    '''\n    cross_prod = np.cross(l2 - l1, p - l1)\n    return np.linalg.norm(cross_prod) / np.linalg.norm(l2 - l1)", "response": "compute the orthogonal distance between from the line that goes through\n    the points l1 l2 and the point p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the square of the euclidian distance between two 3D points p1 and p2", "response": "def point_dist2(p1, p2):\n    '''compute the square of the euclidian distance between two 3D points\n\n    Args:\n        p1, p2: indexable objects with\n        indices 0, 1, 2 corresponding to 3D cartesian coordinates.\n    Returns:\n        The square of the euclidian distance between the points.\n    '''\n    v = vector(p1, p2)\n    return np.dot(v, v)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the angle in radians between three 3D points", "response": "def angle_3points(p0, p1, p2):\n    ''' compute the angle in radians between three 3D points\n\n    Calculated as the angle between p1-p0 and p2-p0.\n\n    Args:\n        p0, p1, p2:  indexable objects with\n        indices 0, 1, 2 corresponding to 3D cartesian coordinates.\n\n    Returns:\n        Angle in radians between (p1-p0) and (p2-p0).\n        0.0 if p0==p1 or p0==p2.\n    '''\n    vec1 = vector(p1, p0)\n    vec2 = vector(p2, p0)\n    return math.atan2(np.linalg.norm(np.cross(vec1, vec2)),\n                      np.dot(vec1, vec2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the angle in radians between vectors p1 and p2.", "response": "def angle_between_vectors(p1, p2):\n    \"\"\" Computes the angle in radians between vectors 'p1' and 'p2'\n    Normalizes the input vectors and computes the relative angle\n    between them.\n\n        >>> angle_between((1, 0), (0, 1))\n        1.5707963267948966\n        >>> angle_between((1, 0), (1, 0))\n        0.0\n        >>> angle_between((1, 0), (-1, 0))\n        3.141592653589793\n    \"\"\"\n    v1 = p1 / np.linalg.norm(p1)\n    v2 = p2 / np.linalg.norm(p2)\n    return np.arccos(np.clip(np.dot(v1, v2), -1.0, 1.0))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef polygon_diameter(points):\n    ''' Compute the maximun euclidian distance between any two points\n    in a list of points\n    '''\n    return max(point_dist(p0, p1) for (p0, p1) in combinations(points, 2))", "response": "Compute the maximum euclidian distance between any two points\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef average_points_dist(p0, p_list):\n    return np.mean(list(point_dist(p0, p1) for p1 in p_list))", "response": "Computes the average distance between a list of points p0 and a given point p1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_distance(points):\n    vecs = np.diff(points, axis=0)[:, :3]\n    d2 = [np.dot(p, p) for p in vecs]\n    return np.sum(np.sqrt(d2))", "response": "Compute the path distance from given set of points"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the radial distance of a tree segment to a given point", "response": "def segment_radial_dist(seg, pos):\n    '''Return the radial distance of a tree segment to a given point\n\n    The radial distance is the euclidian distance between the mid-point of\n    the segment and the point in question.\n\n    Parameters:\n        seg: tree segment\n\n        pos: origin to which distances are measured. It must have at lease 3\n        components. The first 3 components are (x, y, z).\n    '''\n    return point_dist(pos, np.divide(np.add(seg[0], seg[1]), 2.0))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the surface area of a segment.", "response": "def segment_area(seg):\n    '''Compute the surface area of a segment.\n\n    Approximated as a conical frustum. Does not include the surface area\n    of the bounding circles.\n    '''\n    r0 = seg[0][COLS.R]\n    r1 = seg[1][COLS.R]\n    h2 = point_dist2(seg[0], seg[1])\n    return math.pi * (r0 + r1) * math.sqrt((r0 - r1) ** 2 + h2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the volume of a segment Approximated as a conical frustum. Approximated as a conical frustum. Approximated as a conical frustum. Approximated as a conical frustum. Approximated as a conical frustum.", "response": "def segment_volume(seg):\n    '''Compute the volume of a segment.\n\n    Approximated as a conical frustum.\n    '''\n    r0 = seg[0][COLS.R]\n    r1 = seg[1][COLS.R]\n    h = point_dist(seg[0], seg[1])\n    return math.pi * h * ((r0 * r0) + (r0 * r1) + (r1 * r1)) / 3.0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the taper rate between points p0 and p1.", "response": "def taper_rate(p0, p1):\n    '''Compute the taper rate between points p0 and p1\n\n    Args:\n        p0, p1: iterables with first 4 components containing (x, y, z, r)\n\n    Returns:\n        The taper rate, defined as the absolute value of the difference in\n        the diameters of p0 and p1 divided by the euclidian distance\n        between them.\n    '''\n    return 2 * abs(p0[COLS.R] - p1[COLS.R]) / point_dist(p0, p1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the extent of a set of 3D points.", "response": "def principal_direction_extent(points):\n    '''Calculate the extent of a set of 3D points.\n\n   The extent is defined as the maximum distance between\n   the projections on the principal directions of the covariance matrix\n   of the points.\n\n   Parameter:\n       points : a 2D numpy array of points\n\n   Returns:\n       extents : the extents for each of the eigenvectors of the cov matrix\n       eigs : eigenvalues of the covariance matrix\n       eigv : respective eigenvectors of the covariance matrix\n    '''\n    # center the points around 0.0\n    points = np.copy(points)\n    points -= np.mean(points, axis=0)\n\n    # principal components\n    _, eigv = pca(points)\n\n    extent = np.zeros(3)\n\n    for i in range(eigv.shape[1]):\n        # orthogonal projection onto the direction of the v component\n        scalar_projs = np.sort(np.array([np.dot(p, eigv[:, i]) for p in points]))\n        extent[i] = scalar_projs[-1]\n\n        if scalar_projs[0] < 0.:\n            extent -= scalar_projs[0]\n\n    return extent"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a histogram of the selected feature for the population of neurons.", "response": "def histogram(neuron, feature, ax, bins=15, normed=True, cumulative=False):\n    '''\n    Plot a histogram of the selected feature for the population of neurons.\n    Plots x-axis versus y-axis on a scatter|histogram|binned values plot.\n\n    Parameters :\n\n        neurons : neuron list\n\n        feature : str\n        The feature of interest.\n\n        bins : int\n        Number of bins for the histogram.\n\n        cumulative : bool\n        Sets cumulative histogram on.\n\n        ax : axes object\n            the axes in which the plot is taking place\n    '''\n\n    feature_values = nm.get(feature, neuron)\n    # generate histogram\n    ax.hist(feature_values, bins=bins, cumulative=cumulative, normed=normed)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating and return end - to - end - distance of a given neurite.", "response": "def path_end_to_end_distance(neurite):\n    '''Calculate and return end-to-end-distance of a given neurite.'''\n    trunk = neurite.root_node.points[0]\n    return max(morphmath.point_dist(l.points[-1], trunk)\n               for l in neurite.root_node.ileaf())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a plot of end - to - end distance vs number of segments", "response": "def make_end_to_end_distance_plot(nb_segments, end_to_end_distance, neurite_type):\n    '''Plot end-to-end distance vs number of segments'''\n    plt.figure()\n    plt.plot(nb_segments, end_to_end_distance)\n    plt.title(neurite_type)\n    plt.xlabel('Number of segments')\n    plt.ylabel('End-to-end distance')\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_and_plot_end_to_end_distance(neurite):\n    '''Calculate and plot the end-to-end distance vs the number of segments for\n    an increasingly larger part of a given neurite.\n\n    Note that the plots are not very meaningful for bifurcating trees.'''\n    def _dist(seg):\n        '''Distance between segmenr end and trunk'''\n        return morphmath.point_dist(seg[1], neurite.root_node.points[0])\n\n    end_to_end_distance = [_dist(s) for s in nm.iter_segments(neurite)]\n    make_end_to_end_distance_plot(np.arange(len(end_to_end_distance)) + 1,\n                                  end_to_end_distance, neurite.type)", "response": "Calculate and plot the end - to - end distance vs the number of segments for\n    an increasingly larger part of a given neurite."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntrees type checker function that takes a tree and returns true if that tree matches any of the NeuriteTypes in ref", "response": "def tree_type_checker(*ref):\n    '''Tree type checker functor\n\n    Returns:\n        Functor that takes a tree, and returns true if that tree matches any of\n        NeuriteTypes in ref\n\n    Ex:\n        >>> from neurom.core.types import NeuriteType, tree_type_checker\n        >>> tree_filter = tree_type_checker(NeuriteType.axon, NeuriteType.basal_dendrite)\n        >>> nrn.i_neurites(tree.isegment, tree_filter=tree_filter)\n    '''\n    ref = tuple(ref)\n    if NeuriteType.all in ref:\n        def check_tree_type(_):\n            '''Always returns true'''\n            return True\n    else:\n        def check_tree_type(tree):\n            '''Check whether tree has the same type as ref\n\n            Returns:\n                True if ref in the same type as tree.type or ref is NeuriteType.all\n            '''\n            return tree.type in ref\n\n    return check_tree_type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_somas(somas):\n    '''Plot set of somas on same figure as spheres, each with different color'''\n    _, ax = common.get_figure(new_fig=True, subplot=111,\n                              params={'projection': '3d', 'aspect': 'equal'})\n    for s in somas:\n        common.plot_sphere(ax, s.center, s.radius, color=random_color(), alpha=1)\n    plt.show()", "response": "Plot set of somas on same figure as spheres each with different color"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _max_recursion_depth(obj):\n    ''' Estimate recursion depth, which is defined as the number of nodes in a tree\n    '''\n    neurites = obj.neurites if hasattr(obj, 'neurites') else [obj]\n\n    return max(sum(1 for _ in neu.iter_sections()) for neu in neurites)", "response": "Estimate recursion depth which is defined as the number of nodes in a tree\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _total_rectangles(tree):\n    '''\n    Calculate the total number of segments that are required\n    for the dendrogram. There is a vertical line for each segment\n    and two horizontal line at each branching point\n    '''\n    return sum(len(sec.children) + sec.points.shape[0] - 1\n               for sec in tree.iter_sections())", "response": "Calculate the total number of rectangles required for the dendrogram."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the total number of rectangles with respect to the type of the object", "response": "def _n_rectangles(obj):\n    '''\n    Calculate the total number of rectangles with respect to\n    the type of the object\n    '''\n    return sum(_total_rectangles(neu) for neu in obj.neurites) \\\n        if hasattr(obj, 'neurites') else _total_rectangles(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _square_segment(radius, origin):\n    '''Vertices for a square\n    '''\n    return np.array(((origin[0] - radius, origin[1] - radius),\n                     (origin[0] - radius, origin[1] + radius),\n                     (origin[0] + radius, origin[1] + radius),\n                     (origin[0] + radius, origin[1] - radius)))", "response": "Vertices for a square\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _spacingx(node, max_dims, xoffset, xspace):\n    '''Determine the spacing of the current node depending on the number\n       of the leaves of the tree\n    '''\n    x_spacing = _n_terminations(node) * xspace\n\n    if x_spacing > max_dims[0]:\n        max_dims[0] = x_spacing\n\n    return xoffset - x_spacing / 2.", "response": "Determine the spacing of the current node depending on the number\n       of the leaves of the tree\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the offsets for a single object.", "response": "def _update_offsets(start_x, spacing, terminations, offsets, length):\n    '''Update the offsets\n    '''\n    return (start_x + spacing[0] * terminations / 2.,\n            offsets[1] + spacing[1] * 2. + length)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding max diameter in tree", "response": "def _max_diameter(tree):\n    '''Find max diameter in tree\n    '''\n    return 2. * max(max(node.points[:, COLS.R]) for node in tree.ipreorder())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the soma segment.", "response": "def _generate_soma(self):\n        '''soma'''\n        radius = self._obj.soma.radius\n        return _square_segment(radius, (0., -radius))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a dendrogram of the tree structure for the current neurite and all neurites.", "response": "def generate(self):\n        '''Generate dendrogram\n        '''\n        offsets = (0., 0.)\n\n        n_previous = 0\n\n        # set recursion limit with respect to\n        # the max number of nodes on the trees\n        old_depth = sys.getrecursionlimit()\n        max_depth = old_depth if old_depth > self._max_rec_depth else self._max_rec_depth\n        # TODO: This should be fixed so we don't set sys.setrecursionlimit at all\n        sys.setrecursionlimit(max_depth)\n\n        if isinstance(self._obj, Neurite):\n\n            max_diameter = _max_diameter(self._obj.root_node)\n\n            dummy_section = Tree()\n            dummy_section.add_child(self._obj.root_node)\n            self._generate_dendro(dummy_section, (max_diameter, 0.), offsets)\n\n            self._groups.append((0, self._n))\n\n            self._dims.append(self._max_dims)\n\n        else:\n\n            for neurite in self._obj.neurites:\n\n                neurite = neurite.root_node\n                max_diameter = _max_diameter(neurite)\n                dummy_section = Tree()\n\n                dummy_section.add_child(neurite)\n                self._generate_dendro(dummy_section, (max_diameter, 0.), offsets)\n\n                # store in trees the indices for the slice which corresponds\n                # to the current neurite\n                self._groups.append((n_previous, self._n))\n\n                # store the max dims per neurite for view positioning\n                self._dims.append(self._max_dims)\n\n                # reset the max dimensions for the next tree in line\n                self._max_dims = [0., 0.]\n\n                # keep track of the next tree start index in list\n                n_previous = self._n\n\n        # set it back to its initial value\n        sys.setrecursionlimit(old_depth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _generate_dendro(self, current_section, spacing, offsets):\n        '''Recursive function for dendrogram line computations\n        '''\n        max_dims = self._max_dims\n        start_x = _spacingx(current_section, max_dims, offsets[0], spacing[0])\n\n        for child in current_section.children:\n\n            segments = child.points\n\n            # number of leaves in child\n            terminations = _n_terminations(child)\n\n            # segement lengths\n            seg_lengths = np.linalg.norm(np.subtract(segments[:-1, COLS.XYZ],\n                                                     segments[1:, COLS.XYZ]), axis=1)\n\n            # segment radii\n            radii = np.vstack((segments[:-1, COLS.R], segments[1:, COLS.R])).T \\\n                if self._show_diameters else np.zeros((seg_lengths.shape[0], 2))\n\n            y_offset = offsets[1]\n            for i, slen in enumerate(seg_lengths):\n\n                # offset update for the vertical segments\n                new_offsets = _update_offsets(start_x, spacing, terminations,\n                                              (offsets[0], y_offset), slen)\n\n                # segments are drawn vertically, thus only y_offset changes from init offsets\n                self._rectangles[self._n] = _vertical_segment((offsets[0], y_offset),\n                                                              new_offsets, spacing, radii[i, :])\n                self._n += 1\n                y_offset = new_offsets[1]\n\n            if y_offset + spacing[1] * 2 + sum(seg_lengths) > max_dims[1]:\n                max_dims[1] = y_offset + spacing[1] * 2. + sum(seg_lengths)\n\n            self._max_dims = max_dims\n            # recursive call to self.\n            self._generate_dendro(child, spacing, new_offsets)\n\n            # update the starting position for the next child\n            start_x += terminations * spacing[0]\n\n            # write the horizontal lines only for bifurcations, where the are actual horizontal\n            # lines and not zero ones\n            if offsets[0] != new_offsets[0]:\n\n                # horizontal segment. Thickness is either 0 if show_diameters is false\n                # or 1. if show_diameters is true\n                self._rectangles[self._n] = _horizontal_segment(offsets, new_offsets, spacing, 0.)\n                self._n += 1", "response": "Recursive function for dendrogram line computations\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef types(self):\n        ''' Returns an iterator over the types of the neurites in the object.\n            If the object is a tree, then one value is returned.\n        '''\n        neurites = self._obj.neurites if hasattr(self._obj, 'neurites') else (self._obj,)\n        return (neu.type for neu in neurites)", "response": "Returns an iterator over the types of the neurites in the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_neurite_feature(name, func):\n    '''Register a feature to be applied to neurites\n\n    Parameters:\n        name: name of the feature, used for access via get() function.\n        func: single parameter function of a neurite.\n    '''\n    if name in NEURITEFEATURES:\n        raise NeuroMError('Attempt to hide registered feature %s' % name)\n\n    def _fun(neurites, neurite_type=_ntype.all):\n        '''Wrap neurite function from outer scope and map into list'''\n        return list(func(n) for n in _ineurites(neurites, filt=_is_type(neurite_type)))\n\n    NEURONFEATURES[name] = _fun", "response": "Register a feature to be applied to neurites"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nobtain a feature from a set of morphology objects", "response": "def get(feature, obj, **kwargs):\n    '''Obtain a feature from a set of morphology objects\n\n    Parameters:\n        feature(string): feature to extract\n        obj: a neuron, population or neurite tree\n        **kwargs: parameters to forward to underlying worker functions\n\n    Returns:\n        features as a 1D or 2D numpy array.\n\n    '''\n\n    feature = (NEURITEFEATURES[feature] if feature in NEURITEFEATURES\n               else NEURONFEATURES[feature])\n\n    return _np.array(list(feature(obj, **kwargs)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _indent(string, count):\n    '''indent `string` by `count` * INDENT'''\n    indent = _INDENT * count\n    ret = indent + string.replace('\\n', '\\n' + indent)\n    return ret.rstrip()", "response": "indent string by count INDENT"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a description of all the known available features", "response": "def _get_doc():\n    '''Get a description of all the known available features'''\n    def get_docstring(func):\n        '''extract doctstring, if possible'''\n        docstring = ':\\n'\n        if func.__doc__:\n            docstring += _indent(func.__doc__, 2)\n        return docstring\n\n    ret = ['\\nNeurite features (neurite, neuron, neuron population):']\n    ret.extend(_INDENT + '- ' + feature + get_docstring(func)\n               for feature, func in sorted(NEURITEFEATURES.items()))\n\n    ret.append('\\nNeuron features (neuron, neuron population):')\n    ret.extend(_INDENT + '- ' + feature + get_docstring(func)\n               for feature, func in sorted(NEURONFEATURES.items()))\n\n    return '\\n'.join(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a file and return a data_wrapperd object.", "response": "def read(filename, remove_duplicates=False, data_wrapper=DataWrapper):\n    '''Read a file and return a `data_wrapper'd` data\n\n    * Tries to guess the format and the H5 version.\n    * Unpacks the first block it finds out of ('repaired', 'unraveled', 'raw')\n\n    Parameters:\n        remove_duplicates: boolean, If True removes duplicate points\n        from the beginning of each section.\n    '''\n    with h5py.File(filename, mode='r') as h5file:\n        version = get_version(h5file)\n        if version == 'H5V1':\n            points, groups = _unpack_v1(h5file)\n        elif version == 'H5V2':\n            stg = next(s for s in ('repaired', 'unraveled', 'raw')\n                       if s in h5file['neuron1'])\n            points, groups = _unpack_v2(h5file, stage=stg)\n\n    if remove_duplicates:\n        points, groups = _remove_duplicate_points(points, groups)\n\n    neuron_builder = BlockNeuronBuilder()\n    points[:, POINT_DIAMETER] /= 2  # Store radius, not diameter\n    for id_, row in enumerate(zip_longest(groups,\n                                          groups[1:, GPFIRST],\n                                          fillvalue=len(points))):\n        (point_start, section_type, parent_id), point_end = row\n        neuron_builder.add_section(id_, int(parent_id), int(section_type),\n                                   points[point_start:point_end])\n\n    return neuron_builder.get_datawrapper(version, data_wrapper=data_wrapper)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_duplicate_points(points, groups):\n    ''' Removes the duplicate points from the beginning of a section,\n    if they are present in points-groups representation.\n\n    Returns:\n        points, groups with unique points.\n\n    '''\n\n    group_initial_ids = groups[:, GPFIRST]\n\n    to_be_reduced = np.zeros(len(group_initial_ids))\n    to_be_removed = []\n\n    for ig, g in enumerate(groups):\n        iid, typ, pid = g[GPFIRST], g[GTYPE], g[GPID]\n        # Remove first point from sections that are\n        # not the root section, a soma, or a child of a soma\n        if pid != -1 and typ != 1 and groups[pid][GTYPE] != 1:\n            # Remove duplicate from list of points\n            to_be_removed.append(iid)\n            # Reduce the id of the following sections\n            # in groups structure by one\n            to_be_reduced[ig + 1:] += 1\n\n    groups[:, GPFIRST] = groups[:, GPFIRST] - to_be_reduced\n    points = np.delete(points, to_be_removed, axis=0)\n\n    return points, groups", "response": "Removes duplicate points from the beginning of a section and the rest of the groups representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunpacking points and groups from HDF5 v1 file", "response": "def _unpack_v1(h5file):\n    '''Unpack groups from HDF5 v1 file'''\n    points = np.array(h5file['points'])\n    groups = np.array(h5file['structure'])\n    return points, groups"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unpack_v2(h5file, stage):\n    '''Unpack groups from HDF5 v2 file'''\n    points = np.array(h5file['neuron1/%s/points' % stage])\n    # from documentation: The /neuron1/structure/unraveled reuses /neuron1/structure/raw\n    groups_stage = stage if stage != 'unraveled' else 'raw'\n    groups = np.array(h5file['neuron1/structure/%s' % groups_stage])\n    stypes = np.array(h5file['neuron1/structure/sectiontype'])\n    groups = np.hstack([groups, stypes])\n    groups[:, [1, 2]] = groups[:, [2, 1]]\n    return points, groups", "response": "Unpack points from HDF5 v2 file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_results_to_dict(fit_results, min_bound=None, max_bound=None):\n    '''Create a JSON-comparable dict from a FitResults object\n\n    Parameters:\n        fit_results (FitResults): object containing fit parameters,\\\n            errors and type\n        min_bound: optional min value to add to dictionary if min isn't\\\n            a fit parameter.\n        max_bound: optional max value to add to dictionary if max isn't\\\n            a fit parameter.\n\n    Returns:\n        JSON-compatible dictionary with fit results\n\n    Note:\n        Supported fit types: 'norm', 'expon', 'uniform'\n    '''\n\n    type_map = {'norm': 'normal', 'expon': 'exponential', 'uniform': 'uniform'}\n    param_map = {'uniform': lambda p: [('min', p[0]), ('max', p[0] + p[1])],\n                 'norm': lambda p: [('mu', p[0]), ('sigma', p[1])],\n                 'expon': lambda p: [('lambda', 1.0 / p[1])]}\n\n    d = OrderedDict({'type': type_map[fit_results.type]})\n    d.update(param_map[fit_results.type](fit_results.params))\n\n    if min_bound is not None and 'min' not in d:\n        d['min'] = min_bound\n    if max_bound is not None and 'max' not in d:\n        d['max'] = max_bound\n\n    return d", "response": "Create a JSON - compatible dictionary from a FitResults object containing fit parameters and type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(data, distribution='norm'):\n    '''Calculate the parameters of a fit of a distribution to a data set\n\n    Parameters:\n        data: array of data points to be fitted\n\n    Options:\n        distribution (str): type of distribution to fit. Default 'norm'.\n\n    Returns:\n        FitResults object with fitted parameters, errors and distribution type\n\n    Note:\n        Uses Kolmogorov-Smirnov test to estimate distance and p-value.\n    '''\n    params = getattr(_st, distribution).fit(data)\n    return FitResults(params, _st.kstest(data, distribution, params), distribution)", "response": "Calculate the parameters of a fit of a distribution to a data set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef optimal_distribution(data, distr_to_check=('norm', 'expon', 'uniform')):\n    '''Calculate the parameters of a fit of different distributions to a data set\n       and returns the distribution of the minimal ks-distance.\n\n    Parameters:\n        data: array of data points to be fitted\n\n    Options:\n        distr_to_check: tuple of distributions to be checked\n\n    Returns:\n        FitResults object with fitted parameters, errors and distribution type\\\n            of the fit with the smallest fit distance\n\n    Note:\n        Uses Kolmogorov-Smirnov test to estimate distance and p-value.\n    '''\n    fit_results = [fit(data, d) for d in distr_to_check]\n    return min(fit_results, key=lambda fit: fit.errs[0])", "response": "Calculate the parameters of a fit of different distributions to a data set\n       and returns the distribution of the minimal ks - distance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scalar_stats(data, functions=('min', 'max', 'mean', 'std')):\n    '''Calculate the stats from the given numpy functions\n\n    Parameters:\n        data: array of data points to be used for the stats\n\n    Options:\n        functions: tuple of numpy stat functions to apply on data\n\n    Returns:\n        Dictionary with the name of the function as key and the result\n        as the respective value\n    '''\n    stats = {}\n    for func in functions:\n\n        stats[func] = getattr(np, func)(data)\n\n    return stats", "response": "Calculate the stats from the given numpy functions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomparing two distributions of data1 and data2 and assess two scores.", "response": "def compare_two(data1, data2, test=StatTests.ks):\n    '''Compares two distributions of data\n       and assess two scores: a distance between them\n       and a probability they are drawn from the same\n       distribution.\n\n    Parameters:\n        data1: numpy array of dataset 1\n        data2: numpy array of dataset 2\n        test: Stat_tests\\\n            Defines the statistical test to be used, based\\\n            on the scipy available modules.\\\n            Accepted tests: ks_2samp, wilcoxon, ttest\n\n    Returns:\n        dist: float\\\n            High numbers define high dissimilarity between the two datasets\n        p-value: float\\\n            Small numbers define high probability the data come from\\\n            same dataset.\n    '''\n    results = getattr(_st, get_test(test))(data1, data2)\n    Stats = namedtuple('Stats', ['dist', 'pvalue'])\n\n    return Stats(*results)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef total_score(paired_dats, p=2, test=StatTests.ks):\n    '''Calculates the p-norm of the distances that have been calculated from the statistical\n    test that has been applied on all the paired datasets.\n\n    Parameters:\n        paired_dats: a list of tuples or where each tuple\n                         contains the paired data lists from two datasets\n\n    Options:\n        p : integer that defines the order of p-norm\n        test: Stat_tests\\\n            Defines the statistical test to be used, based\\\n            on the scipy available modules.\\\n            Accepted tests: ks_2samp, wilcoxon, ttest\n\n    Returns:\n        A float corresponding to the p-norm of the distances that have\n        been calculated. 0 corresponds to high similarity while 1 to low.\n    '''\n    scores = np.array([compare_two(fL1, fL2, test=test).dist for fL1, fL2 in paired_dats])\n    return np.linalg.norm(scores, p)", "response": "Calculates the total score of the distances that have been calculated from the statistical\n    test that has been applied on all the paired datasets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_neurites(obj, mapfun=None, filt=None, neurite_order=NeuriteIter.FileOrder):\n    '''Iterator to a neurite, neuron or neuron population\n\n    Applies optional neurite filter and mapping functions.\n\n    Parameters:\n        obj: a neurite, neuron or neuron population.\n        mapfun: optional neurite mapping function.\n        filt: optional neurite filter function.\n        neurite_order (NeuriteIter): order upon which neurites should be iterated\n            - NeuriteIter.FileOrder: order of appearance in the file\n            - NeuriteIter.NRN: NRN simulator order: soma -> axon -> basal -> apical\n\n    Examples:\n\n        Get the number of points in each neurite in a neuron population\n\n        >>> from neurom.core import iter_neurites\n        >>> n_points = [n for n in iter_neurites(pop, lambda x : len(x.points))]\n\n        Get the number of points in each axon in a neuron population\n\n        >>> import neurom as nm\n        >>> from neurom.core import iter_neurites\n        >>> filter = lambda n : n.type == nm.AXON\n        >>> mapping = lambda n : len(n.points)\n        >>> n_points = [n for n in iter_neurites(pop, mapping, filter)]\n\n    '''\n    neurites = ((obj,) if isinstance(obj, Neurite) else\n                obj.neurites if hasattr(obj, 'neurites') else obj)\n    if neurite_order == NeuriteIter.NRN:\n        last_position = max(NRN_ORDER.values()) + 1\n        neurites = sorted(neurites, key=lambda neurite: NRN_ORDER.get(neurite.type, last_position))\n\n    neurite_iter = iter(neurites) if filt is None else filter(filt, neurites)\n    return neurite_iter if mapfun is None else map(mapfun, neurite_iter)", "response": "Iterator to a neuron or population of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_sections(neurites,\n                  iterator_type=Tree.ipreorder,\n                  neurite_filter=None,\n                  neurite_order=NeuriteIter.FileOrder):\n    '''Iterator to the sections in a neurite, neuron or neuron population.\n\n    Parameters:\n        neurites: neuron, population, neurite, or iterable containing neurite objects\n        iterator_type: section iteration order within a given neurite. Must be one of:\n            Tree.ipreorder: Depth-first pre-order iteration of tree nodes\n            Tree.ipreorder: Depth-first post-order iteration of tree nodes\n            Tree.iupstream: Iterate from a tree node to the root nodes\n            Tree.ibifurcation_point: Iterator to bifurcation points\n            Tree.ileaf: Iterator to all leaves of a tree\n\n        neurite_filter: optional top level filter on properties of neurite neurite objects.\n        neurite_order (NeuriteIter): order upon which neurites should be iterated\n            - NeuriteIter.FileOrder: order of appearance in the file\n            - NeuriteIter.NRN: NRN simulator order: soma -> axon -> basal -> apical\n\n\n    Examples:\n\n        Get the number of points in each section of all the axons in a neuron population\n\n        >>> import neurom as nm\n        >>> from neurom.core import ites_sections\n        >>> filter = lambda n : n.type == nm.AXON\n        >>> n_points = [len(s.points) for s in iter_sections(pop,  neurite_filter=filter)]\n\n    '''\n    return chain.from_iterable(\n        iterator_type(neurite.root_node) for neurite in\n        iter_neurites(neurites, filt=neurite_filter, neurite_order=neurite_order))", "response": "Iterator to the sections in a collection of neurites or neuron or collection of neurites"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator to the segments in a collection of neurites", "response": "def iter_segments(obj, neurite_filter=None, neurite_order=NeuriteIter.FileOrder):\n    '''Return an iterator to the segments in a collection of neurites\n\n    Parameters:\n        obj: neuron, population, neurite, section, or iterable containing neurite objects\n        neurite_filter: optional top level filter on properties of neurite neurite objects\n        neurite_order: order upon which neurite should be iterated. Values:\n            - NeuriteIter.FileOrder: order of appearance in the file\n            - NeuriteIter.NRN: NRN simulator order: soma -> axon -> basal -> apical\n\n    Note:\n        This is a convenience function provided for generic access to\n        neuron segments. It may have a performance overhead WRT custom-made\n        segment analysis functions that leverage numpy and section-wise iteration.\n    '''\n    sections = iter((obj,) if isinstance(obj, Section) else\n                    iter_sections(obj,\n                                  neurite_filter=neurite_filter,\n                                  neurite_order=neurite_order))\n\n    return chain.from_iterable(zip(sec.points[:-1], sec.points[1:])\n                               for sec in sections)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a neuron starting at root_section", "response": "def graft_neuron(root_section):\n    '''Returns a neuron starting at root_section'''\n    assert isinstance(root_section, Section)\n    return Neuron(soma=Soma(root_section.points[:1]), neurites=[Neurite(root_section)])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn unordered array with all the points in this neurite", "response": "def points(self):\n        '''Return unordered array with all the points in this neurite'''\n        # add all points in a section except the first one, which is a duplicate\n        _pts = [v for s in self.root_node.ipreorder()\n                for v in s.points[1:, COLS.XYZR]]\n        # except for the very first point, which is not a duplicate\n        _pts.insert(0, self.root_node.points[0][COLS.XYZR])\n        return np.array(_pts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(self, trans):\n        '''Return a copy of this neurite with a 3D transformation applied'''\n        clone = deepcopy(self)\n        for n in clone.iter_sections():\n            n.points[:, 0:3] = trans(n.points[:, 0:3])\n\n        return clone", "response": "Return a copy of this neurite with a 3D transformation applied"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting a summary statistic from an array of list of values", "response": "def eval_stats(values, mode):\n    '''Extract a summary statistic from an array of list of values\n\n    Parameters:\n        values: numpy array of values\n        mode: summary stat to extract. One of ['min', 'max', 'median', 'mean', 'std', 'raw']\n\n    Note: fails silently if values is empty, and None is returned\n    '''\n    if mode == 'raw':\n        return values.tolist()\n    if mode == 'total':\n        mode = 'sum'\n\n    try:\n        return getattr(np, mode)(values, axis=0)\n    except ValueError:\n        pass\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets stat name based on feature name and stat mode", "response": "def _stat_name(feat_name, stat_mode):\n    '''Set stat name based on feature name and stat mode'''\n    if feat_name[-1] == 's':\n        feat_name = feat_name[:-1]\n    if feat_name == 'soma_radii':\n        feat_name = 'soma_radius'\n    if stat_mode == 'raw':\n        return feat_name\n\n    return '%s_%s' % (stat_mode, feat_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_stats(neurons, config):\n    '''Extract stats from neurons'''\n\n    stats = defaultdict(dict)\n    for ns, modes in config['neurite'].items():\n        for n in config['neurite_type']:\n            n = _NEURITE_MAP[n]\n            for mode in modes:\n                stat_name = _stat_name(ns, mode)\n                stat = eval_stats(nm.get(ns, neurons, neurite_type=n), mode)\n\n                if stat is None or not stat.shape:\n                    stats[n.name][stat_name] = stat\n                else:\n                    assert stat.shape in ((3, ), ), \\\n                        'Statistic must create a 1x3 result'\n\n                    for i, suffix in enumerate('XYZ'):\n                        compound_stat_name = stat_name + '_' + suffix\n                        stats[n.name][compound_stat_name] = stat[i]\n\n    for ns, modes in config['neuron'].items():\n        for mode in modes:\n            stat_name = _stat_name(ns, mode)\n            stats[stat_name] = eval_stats(nm.get(ns, neurons), mode)\n\n    return stats", "response": "Extract stats from neurons"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_header(results):\n    '''Extracts the headers, using the first value in the dict as the template'''\n    ret = ['name', ]\n    values = next(iter(results.values()))\n    for k, v in values.items():\n        if isinstance(v, dict):\n            for metric in v.keys():\n                ret.append('%s:%s' % (k, metric))\n        else:\n            ret.append(k)\n    return ret", "response": "Extracts the headers from the results dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts from results the fields in the headers list", "response": "def generate_flattened_dict(headers, results):\n    '''extract from results the fields in the headers list'''\n    for name, values in results.items():\n        row = []\n        for header in headers:\n            if header == 'name':\n                row.append(name)\n            elif ':' in header:\n                neurite_type, metric = header.split(':')\n                row.append(values[neurite_type][metric])\n            else:\n                row.append(values[header])\n        yield row"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ipreorder(self):\n        '''Depth-first pre-order iteration of tree nodes'''\n        children = deque((self, ))\n        while children:\n            cur_node = children.pop()\n            children.extend(reversed(cur_node.children))\n            yield cur_node", "response": "Depth - first pre - order iteration of tree nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nissue a deprecation warning for a function", "response": "def deprecated(fun_name=None, msg=\"\"):\n    '''Issue a deprecation warning for a function'''\n    def _deprecated(fun):\n        '''Issue a deprecation warning for a function'''\n        @wraps(fun)\n        def _wrapper(*args, **kwargs):\n            '''Issue deprecation warning and forward arguments to fun'''\n            name = fun_name if fun_name is not None else fun.__name__\n            _warn_deprecated('Call to deprecated function %s. %s' % (name, msg))\n            return fun(*args, **kwargs)\n\n        return _wrapper\n\n    return _deprecated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecorate a checking function", "response": "def check_wrapper(fun):\n    '''Decorate a checking function'''\n    @wraps(fun)\n    def _wrapper(*args, **kwargs):\n        '''Sets the title property of the result of running a checker'''\n        title = fun.__name__.replace('_', ' ').capitalize()\n        result = fun(*args, **kwargs)\n        result.title = title\n        return result\n\n    return _wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, path):\n        '''Test a bunch of files and return a summary JSON report'''\n\n        SEPARATOR = '=' * 40\n        summary = {}\n        res = True\n\n        for _f in utils.get_files_by_path(path):\n            L.info(SEPARATOR)\n            status, summ = self._check_file(_f)\n            res &= status\n            if summ is not None:\n                summary.update(summ)\n\n        L.info(SEPARATOR)\n\n        status = 'PASS' if res else 'FAIL'\n\n        return {'files': summary, 'STATUS': status}", "response": "Test a bunch of files and return a summary JSON report"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a check function on obj", "response": "def _do_check(self, obj, check_module, check_str):\n        '''Run a check function on obj'''\n        opts = self._config['options']\n        if check_str in opts:\n            fargs = opts[check_str]\n            if isinstance(fargs, list):\n                out = check_wrapper(getattr(check_module, check_str))(obj, *fargs)\n            else:\n                out = check_wrapper(getattr(check_module, check_str))(obj, fargs)\n        else:\n            out = check_wrapper(getattr(check_module, check_str))(obj)\n\n        try:\n            if out.info:\n                L.debug('%s: %d failing ids detected: %s',\n                        out.title, len(out.info), out.info)\n        except TypeError:  # pragma: no cover\n            pass\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun all the checks in a check_module", "response": "def _check_loop(self, obj, check_mod_str):\n        '''Run all the checks in a check_module'''\n        check_module = self._check_modules[check_mod_str]\n        checks = self._config['checks'][check_mod_str]\n        result = True\n        summary = OrderedDict()\n        for check in checks:\n            ok = self._do_check(obj, check_module, check)\n            summary[ok.title] = ok.status\n            result &= ok.status\n\n        return result, summary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_file(self, f):\n        '''Run tests on a morphology file'''\n        L.info('File: %s', f)\n\n        full_result = True\n        full_summary = OrderedDict()\n        try:\n            data = load_data(f)\n        except Exception as e:  # pylint: disable=W0703\n            L.error('Failed to load data... skipping tests for this file')\n            L.error(e.args)\n            return False, {f: OrderedDict([('ALL', False)])}\n\n        try:\n            result, summary = self._check_loop(data, 'structural_checks')\n            full_result &= result\n            full_summary.update(summary)\n\n            nrn = fst_core.FstNeuron(data)\n            result, summary = self._check_loop(nrn, 'neuron_checks')\n            full_result &= result\n            full_summary.update(summary)\n        except Exception as e:  # pylint: disable=W0703\n            L.error('Check failed: %s', str(type(e)) + str(e.args))\n            full_result = False\n\n        full_summary['ALL'] = full_result\n\n        for m, s in full_summary.items():\n            self._log_msg(m, s)\n\n        return full_result, {f: full_summary}", "response": "Run tests on a morphology file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_msg(self, msg, ok):\n        '''Helper to log message to the right level'''\n        if self._config['color']:\n            CGREEN, CRED, CEND = '\\033[92m', '\\033[91m', '\\033[0m'\n        else:\n            CGREEN = CRED = CEND = ''\n\n        LOG_LEVELS = {False: logging.ERROR, True: logging.INFO}\n\n        # pylint: disable=logging-not-lazy\n        L.log(LOG_LEVELS[ok],\n              '%35s %s' + CEND, msg, CGREEN + 'PASS' if ok else CRED + 'FAIL')", "response": "Helper to log a message to the right level"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sanitize_config(config):\n        '''check that the config has the correct keys, add missing keys if necessary'''\n        if 'checks' in config:\n            checks = config['checks']\n            if 'structural_checks' not in checks:\n                checks['structural_checks'] = []\n            if 'neuron_checks' not in checks:\n                checks['neuron_checks'] = []\n        else:\n            raise ConfigError('Need to have \"checks\" in the config')\n\n        if 'options' not in config:\n            L.debug('Using default options')\n            config['options'] = {}\n\n        if 'color' not in config:\n            config['color'] = False\n\n        return config", "response": "check that the config has the correct keys add missing keys if necessary"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads an SWC file and return a tuple of data format.", "response": "def read(filename, data_wrapper=DataWrapper):\n    '''Read an SWC file and return a tuple of data, format.'''\n    data = np.loadtxt(filename)\n    if len(np.shape(data)) == 1:\n        data = np.reshape(data, (1, -1))\n    data = data[:, [X, Y, Z, R, TYPE, ID, P]]\n    return data_wrapper(data, 'SWC', None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge two sections sec_a into sec_b and sets sec_b attributes to default", "response": "def _merge_sections(sec_a, sec_b):\n    '''Merge two sections\n\n    Merges sec_a into sec_b and sets sec_a attributes to default\n    '''\n    sec_b.ids = list(sec_a.ids) + list(sec_b.ids[1:])\n    sec_b.ntype = sec_a.ntype\n    sec_b.pid = sec_a.pid\n\n    sec_a.ids = []\n    sec_a.pid = -1\n    sec_a.ntype = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _section_end_points(structure_block, id_map):\n    '''Get the section end-points'''\n    soma_idx = structure_block[:, TYPE] == POINT_TYPE.SOMA\n    soma_ids = structure_block[soma_idx, ID]\n    neurite_idx = structure_block[:, TYPE] != POINT_TYPE.SOMA\n    neurite_rows = structure_block[neurite_idx, :]\n    soma_end_pts = set(id_map[id_]\n                       for id_ in soma_ids[np.in1d(soma_ids, neurite_rows[:, PID])])\n\n    # end points have either no children or more than one\n    # ie: leaf or multifurcation nodes\n    n_children = defaultdict(int)\n    for row in structure_block:\n        n_children[row[PID]] += 1\n    end_pts = set(i for i, row in enumerate(structure_block)\n                  if n_children[row[ID]] != 1)\n\n    return end_pts.union(soma_end_pts)", "response": "Get the section end - points of a neuron."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts a list of sections from a SWC - style data wrapper block.", "response": "def _extract_sections(data_block):\n    '''Make a list of sections from an SWC-style data wrapper block'''\n    structure_block = data_block[:, COLS.TYPE:COLS.COL_COUNT].astype(np.int)\n\n    # SWC ID -> structure_block position\n    id_map = {-1: -1}\n    for i, row in enumerate(structure_block):\n        id_map[row[ID]] = i\n\n    # end points have either no children, more than one, or are the start\n    # of a new gap\n    sec_end_pts = _section_end_points(structure_block, id_map)\n\n    # a 'gap' is when a section has part of it's segments interleaved\n    # with those of another section\n    gap_sections = set()\n\n    sections = []\n\n    def new_section():\n        '''new_section'''\n        sections.append(DataBlockSection())\n        return sections[-1]\n\n    curr_section = new_section()\n\n    parent_section = {-1: -1}\n\n    for row in structure_block:\n        row_id = id_map[row[ID]]\n        parent_id = id_map[row[PID]]\n        if not curr_section.ids:\n            # first in section point is parent\n            curr_section.ids.append(parent_id)\n            curr_section.ntype = row[TYPE]\n\n        gap = parent_id != curr_section.ids[-1]\n\n        # If parent is not the previous point, create a section end-point.\n        # Else add the point to this section\n        if gap:\n            sec_end_pts.add(row_id)\n        else:\n            curr_section.ids.append(row_id)\n\n        if row_id in sec_end_pts:\n            parent_section[curr_section.ids[-1]] = len(sections) - 1\n            # Parent-child discontinuity section\n            if gap:\n                curr_section = new_section()\n                curr_section.ids.extend((parent_id, row_id))\n                curr_section.ntype = row[TYPE]\n                gap_sections.add(len(sections) - 2)\n            elif row_id != len(data_block) - 1:\n                # avoid creating an extra DataBlockSection for last row if it's a leaf\n                curr_section = new_section()\n\n    for sec in sections:\n        # get the section parent ID from the id of the first point.\n        if sec.ids:\n            sec.pid = parent_section[sec.ids[0]]\n\n        # join gap sections and \"disable\" first half\n        if sec.pid in gap_sections:\n            _merge_sections(sections[sec.pid], sec)\n\n    # TODO find a way to remove empty sections.  Currently they are\n    # required to maintain tree integrity.\n    return sections"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the section IDs of the intitial sections", "response": "def neurite_root_section_ids(self):\n        '''Get the section IDs of the intitial neurite sections'''\n        sec = self.sections\n        return [i for i, ss in enumerate(sec)\n                if ss.pid > -1 and (sec[ss.pid].ntype == POINT_TYPE.SOMA and\n                                    ss.ntype != POINT_TYPE.SOMA)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the soma points", "response": "def soma_points(self):\n        '''Get the soma points'''\n        db = self.data_block\n        return db[db[:, COLS.TYPE] == POINT_TYPE.SOMA]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_section(self, id_, parent_id, section_type, points):\n        '''add a section\n\n        Args:\n            id_(int): identifying number of the section\n            parent_id(int): identifying number of the parent of this section\n            section_type(int): the section type as defined by POINT_TYPE\n            points is an array of [X, Y, Z, R]\n        '''\n        # L.debug('Adding section %d, with parent %d, of type: %d with count: %d',\n        #         id_, parent_id, section_type, len(points))\n        assert id_ not in self.sections, 'id %s already exists in sections' % id_\n        self.sections[id_] = BlockNeuronBuilder.BlockSection(parent_id, section_type, points)", "response": "add a section to the block neuron"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a data_block and sections list as required by DataWrapper", "response": "def _make_datablock(self):\n        '''Make a data_block and sections list as required by DataWrapper'''\n        section_ids = sorted(self.sections)\n\n        # create all insertion id's, this needs to be done ahead of time\n        # as some of the children may have a lower id than their parents\n        id_to_insert_id = {}\n        row_count = 0\n        for section_id in section_ids:\n            row_count += len(self.sections[section_id].points)\n            id_to_insert_id[section_id] = row_count - 1\n\n        datablock = np.empty((row_count, COLS.COL_COUNT), dtype=np.float)\n        datablock[:, COLS.ID] = np.arange(len(datablock))\n        datablock[:, COLS.P] = datablock[:, COLS.ID] - 1\n\n        sections = []\n        insert_index = 0\n        for id_ in section_ids:\n            sec = self.sections[id_]\n            points, section_type, parent_id = sec.points, sec.section_type, sec.parent_id\n\n            idx = slice(insert_index, insert_index + len(points))\n            datablock[idx, COLS.XYZR] = points\n            datablock[idx, COLS.TYPE] = section_type\n            datablock[idx.start, COLS.P] = id_to_insert_id.get(parent_id, ROOT_ID)\n            sections.append(DataBlockSection(idx, section_type, parent_id))\n            insert_index = idx.stop\n\n        return datablock, sections"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsees if the sections have obvious errors", "response": "def _check_consistency(self):\n        '''see if the sections have obvious errors'''\n        type_count = defaultdict(int)\n        for _, section in sorted(self.sections.items()):\n            type_count[section.section_type] += 1\n\n        if type_count[POINT_TYPE.SOMA] != 1:\n            L.info('Have %d somas, expected 1', type_count[POINT_TYPE.SOMA])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_morphology_file(filepath):\n    return (\n        os.path.isfile(filepath) and\n        os.path.splitext(filepath)[1].lower() in ('.swc', '.h5', '.asc')\n    )", "response": "Check if filepath is a file with one of the morphology file extensions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of all morphology files in a directory", "response": "def get_morph_files(directory):\n    '''Get a list of all morphology files in a directory\n\n    Returns:\n        list with all files with extensions '.swc' , 'h5' or '.asc' (case insensitive)\n    '''\n    lsdir = (os.path.join(directory, m) for m in os.listdir(directory))\n    return list(filter(_is_morphology_file, lsdir))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a file or set of files from a file path Return list of files with path", "response": "def get_files_by_path(path):\n    '''Get a file or set of files from a file path\n\n    Return list of files with path\n    '''\n    if os.path.isfile(path):\n        return [path]\n    if os.path.isdir(path):\n        return get_morph_files(path)\n\n    raise IOError('Invalid data path %s' % path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild section trees from an h5 or swc file", "response": "def load_neuron(handle, reader=None):\n    '''Build section trees from an h5 or swc file'''\n    rdw = load_data(handle, reader)\n    if isinstance(handle, StringType):\n        name = os.path.splitext(os.path.basename(handle))[0]\n    else:\n        name = None\n    return FstNeuron(rdw, name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_neurons(neurons,\n                 neuron_loader=load_neuron,\n                 name=None,\n                 population_class=Population,\n                 ignored_exceptions=()):\n    '''Create a population object from all morphologies in a directory\\\n        of from morphologies in a list of file names\n\n    Parameters:\n        neurons: directory path or list of neuron file paths\n        neuron_loader: function taking a filename and returning a neuron\n        population_class: class representing populations\n        name (str): optional name of population. By default 'Population' or\\\n            filepath basename depending on whether neurons is list or\\\n            directory path respectively.\n\n    Returns:\n        neuron population object\n\n    '''\n    if isinstance(neurons, (list, tuple)):\n        files = neurons\n        name = name if name is not None else 'Population'\n    elif isinstance(neurons, StringType):\n        files = get_files_by_path(neurons)\n        name = name if name is not None else os.path.basename(neurons)\n\n    ignored_exceptions = tuple(ignored_exceptions)\n    pop = []\n    for f in files:\n        try:\n            pop.append(neuron_loader(f))\n        except NeuroMError as e:\n            if isinstance(e, ignored_exceptions):\n                L.info('Ignoring exception \"%s\" for file %s',\n                       e, os.path.basename(f))\n                continue\n            raise\n\n    return population_class(pop, name=name)", "response": "Load a list of neurons from a directory and return a population object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_file(handle):\n    '''Returns the filename of the file to read\n\n    If handle is a stream, a temp file is written on disk first\n    and its filename is returned'''\n    if not isinstance(handle, IOBase):\n        return handle\n\n    fd, temp_file = tempfile.mkstemp(str(uuid.uuid4()), prefix='neurom-')\n    os.close(fd)\n    with open(temp_file, 'w') as fd:\n        handle.seek(0)\n        shutil.copyfileobj(handle, fd)\n    return temp_file", "response": "Returns the filename of the file to read on disk first\n    and its filename is returned"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunpacking data into a raw data wrapper", "response": "def load_data(handle, reader=None):\n    '''Unpack data into a raw data wrapper'''\n    if not reader:\n        reader = os.path.splitext(handle)[1][1:].lower()\n\n    if reader not in _READERS:\n        raise NeuroMError('Do not have a loader for \"%s\" extension' % reader)\n\n    filename = _get_file(handle)\n    try:\n        return _READERS[reader](filename)\n    except Exception as e:\n        L.exception('Error reading file %s, using \"%s\" loader', filename, reader)\n        raise RawDataError('Error reading file %s:\\n%s' % (filename, str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndelaying loading of h5py until it is needed", "response": "def _load_h5(filename):\n    '''Delay loading of h5py until it is needed'''\n    from neurom.io import hdf5\n    return hdf5.read(filename,\n                     remove_duplicates=False,\n                     data_wrapper=DataWrapper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _filepath(self, name):\n        if self.file_ext is None:\n            candidates = glob.glob(os.path.join(self.directory, name + \".*\"))\n            try:\n                return next(filter(_is_morphology_file, candidates))\n            except StopIteration:\n                raise NeuroMError(\"Can not find morphology file for '%s' \" % name)\n        else:\n            return os.path.join(self.directory, name + self.file_ext)", "response": "Return the path to the morphology file for the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw a morphology object in the current figure.", "response": "def draw(obj, mode='2d', **kwargs):\n    '''Draw a morphology object\n\n    Parameters:\n        obj: morphology object to be drawn (neuron, tree, soma).\n        mode (Optional[str]): drawing mode ('2d', '3d', 'dendrogram'). Defaults to '2d'.\n        **kwargs: keyword arguments for underlying neurom.view.view functions.\n\n    Raises:\n        InvalidDrawModeError if mode is not valid\n        NotDrawableError if obj is not drawable\n        NotDrawableError if obj type and mode combination is not drawable\n\n    Examples:\n\n        >>> nrn = ... # load a neuron\n        >>> fig, _ = viewer.draw(nrn)             # 2d plot\n        >>> fig.show()\n        >>> fig3d, _ = viewer.draw(nrn, mode='3d') # 3d plot\n        >>> fig3d.show()\n        >>> fig, _ = viewer.draw(nrn.neurites[0]) # 2d plot of neurite tree\n        >>> dend, _ = viewer.draw(nrn, mode='dendrogram')\n\n    '''\n\n    if mode not in MODES:\n        raise InvalidDrawModeError('Invalid drawing mode %s' % mode)\n\n    if mode in ('2d', 'dendrogram'):\n        fig, ax = common.get_figure()\n    else:\n        fig, ax = common.get_figure(params={'projection': '3d'})\n\n    if isinstance(obj, Neuron):\n        tag = 'neuron'\n    elif isinstance(obj, (Tree, Neurite)):\n        tag = 'tree'\n    elif isinstance(obj, Soma):\n        tag = 'soma'\n    else:\n        raise NotDrawableError('draw not implemented for %s' % obj.__class__)\n\n    viewer = '%s_%s' % (tag, mode)\n    try:\n        plotter = _VIEWERS[viewer]\n    except KeyError:\n        raise NotDrawableError('No drawer for class %s, mode=%s' % (obj.__class__, mode))\n\n    output_path = kwargs.pop('output_path', None)\n    plotter(ax, obj, **kwargs)\n\n    if mode != 'dendrogram':\n        common.plot_style(fig=fig, ax=ax, **kwargs)\n\n    if output_path:\n        common.save_plot(fig=fig, output_path=output_path, **kwargs)\n\n    return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a histogram of the selected feature for the population of neurons.", "response": "def histogram(neurons, feature, new_fig=True, subplot=False, normed=False, **kwargs):\n    '''\n    Plot a histogram of the selected feature for the population of neurons.\n    Plots x-axis versus y-axis on a scatter|histogram|binned values plot.\n\n    More information about the plot and how it works.\n\n    Parameters :\n\n        neurons : list\n            List of Neurons. Single neurons must be encapsulated in a list.\n\n        feature : str\n            The feature of interest.\n\n        bins : int\n            Number of bins for the histogram.\n\n        cumulative : bool\n            Sets cumulative histogram on.\n\n        subplot : bool\n            Default is False, which returns a matplotlib figure object. If True,\n            returns a matplotlib axis object, for use as a subplot.\n\n    Returns :\n\n        figure_output : list\n            [fig|ax, figdata, figtext]\n            The first item is either a figure object (if subplot is False) or an\n            axis object. The second item is an object containing the data used to\n            generate the figure. The final item is text used in report generation\n            as a figure legend. This text needs to be manually entered in each\n            figure file.\n    '''\n\n    bins = kwargs.get('bins', 25)\n    cumulative = kwargs.get('cumulative', False)\n\n    fig, ax = common.get_figure(new_fig=new_fig, subplot=subplot)\n\n    kwargs['xlabel'] = kwargs.get('xlabel', feature)\n\n    kwargs['ylabel'] = kwargs.get('ylabel', feature + ' fraction')\n\n    kwargs['title'] = kwargs.get('title', feature + ' histogram')\n\n    feature_values = [getattr(neu, 'get_' + feature)() for neu in neurons]\n\n    neu_labels = [neu.name for neu in neurons]\n\n    ax.hist(feature_values, bins=bins, cumulative=cumulative, label=neu_labels, normed=normed)\n\n    kwargs['no_legend'] = len(neu_labels) == 1\n\n    return common.plot_style(fig=fig, ax=ax, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef population_feature_values(pops, feature):\n    '''Extracts feature values per population\n    '''\n    pops_feature_values = []\n\n    for pop in pops:\n\n        feature_values = [getattr(neu, 'get_' + feature)() for neu in pop.neurons]\n\n        # ugly hack to chain in case of list of lists\n        if any([isinstance(p, (list, np.ndarray)) for p in feature_values]):\n\n            feature_values = list(chain(*feature_values))\n\n        pops_feature_values.append(feature_values)\n\n    return pops_feature_values", "response": "Extracts feature values per population\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a histogram of the selected feature for the population of neurons.", "response": "def population_histogram(pops, feature, new_fig=True, normed=False, subplot=False, **kwargs):\n    '''\n    Plot a histogram of the selected feature for the population of neurons.\n    Plots x-axis versus y-axis on a scatter|histogram|binned values plot.\n\n    More information about the plot and how it works.\n\n    Parameters :\n\n        populations : populations list\n\n        feature : str\n        The feature of interest.\n\n        bins : int\n        Number of bins for the histogram.\n\n        cumulative : bool\n        Sets cumulative histogram on.\n\n        subplot : bool\n            Default is False, which returns a matplotlib figure object. If True,\n            returns a matplotlib axis object, for use as a subplot.\n\n    Returns :\n\n        figure_output : list\n            [fig|ax, figdata, figtext]\n            The first item is either a figure object (if subplot is False) or an\n            axis object. The second item is an object containing the data used to\n            generate the figure. The final item is text used in report generation\n            as a figure legend. This text needs to be manually entered in each\n            figure file.\n    '''\n\n    bins = kwargs.get('bins', 25)\n    cumulative = kwargs.get('cumulative', False)\n\n    fig, ax = common.get_figure(new_fig=new_fig, subplot=subplot)\n\n    kwargs['xlabel'] = kwargs.get('xlabel', feature)\n\n    kwargs['ylabel'] = kwargs.get('ylabel', feature + ' fraction')\n\n    kwargs['title'] = kwargs.get('title', feature + ' histogram')\n\n    pops_feature_values = population_feature_values(pops, feature)\n\n    pops_labels = [pop.name for pop in pops]\n\n    ax.hist(pops_feature_values, bins=bins, cumulative=cumulative, label=pops_labels, normed=normed)\n\n    kwargs['no_legend'] = len(pops_labels) == 1\n\n    return common.plot_style(fig=fig, ax=ax, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a segment given a section and segment id", "response": "def get_segment(neuron, section_id, segment_id):\n    '''Get a segment given a section and segment id\n\n    Returns:\n        array of two [x, y, z, r] points defining segment\n    '''\n    sec = neuron.sections[section_id]\n    return sec.points[segment_id:segment_id + 2][:, COLS.XYZR]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_data(data_path, feature):\n    '''Loads a list of neurons, extracts feature\n       and transforms the fitted distribution in the correct format.\n       Returns the optimal distribution, corresponding parameters,\n       minimun and maximum values.\n    '''\n    population = nm.load_neurons(data_path)\n\n    feature_data = [nm.get(feature, n) for n in population]\n    feature_data = list(chain(*feature_data))\n\n    return stats.optimal_distribution(feature_data)", "response": "Loads a list of neurons extracts feature\n       and transforms the fitted distribution in the correct format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_bifurcation_angle(bif_point):\n    '''Return the opening angle between two out-going sections\n    in a bifurcation point\n\n    We first ensure that the input point has only two children.\n\n    The bifurcation angle is defined as the angle between the first non-zero\n    length segments of a bifurcation point.\n    '''\n    def skip_0_length(sec):\n        '''Return the first point with non-zero distance to first point'''\n        p0 = sec[0]\n        cur = sec[1]\n        for i, p in enumerate(sec[1:]):\n            if not np.all(p[:COLS.R] == p0[:COLS.R]):\n                cur = sec[i + 1]\n                break\n\n        return cur\n\n    assert len(bif_point.children) == 2, 'A bifurcation point must have exactly 2 children'\n\n    ch0, ch1 = (skip_0_length(bif_point.children[0].points),\n                skip_0_length(bif_point.children[1].points))\n\n    return morphmath.angle_3points(bif_point.points[-1], ch0, ch1)", "response": "Returns the opening angle between two out - going sections\n    in a bifurcation point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the opening angle between two out - going sections in a bifurcation point", "response": "def remote_bifurcation_angle(bif_point):\n    '''Return the opening angle between two out-going sections\n    in a bifurcation point\n\n    We first ensure that the input point has only two children.\n\n    The angle is defined as between the bifurcation point and the\n    last points in the out-going sections.\n    '''\n    assert len(bif_point.children) == 2, 'A bifurcation point must have exactly 2 children'\n\n    return morphmath.angle_3points(bif_point.points[-1],\n                                   bif_point.children[0].points[-1],\n                                   bif_point.children[1].points[-1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bifurcation_partition(bif_point):\n    '''Calculate the partition at a bifurcation point\n\n    We first ensure that the input point has only two children.\n\n    The number of nodes in each child tree is counted. The partition is\n    defined as the ratio of the largest number to the smallest number.'''\n    assert len(bif_point.children) == 2, 'A bifurcation point must have exactly 2 children'\n\n    n = float(sum(1 for _ in bif_point.children[0].ipreorder()))\n    m = float(sum(1 for _ in bif_point.children[1].ipreorder()))\n    return max(n, m) / min(n, m)", "response": "Calculate the partition at a bifurcation point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the partition asymmetry at a bifurcation point", "response": "def partition_asymmetry(bif_point):\n    '''Calculate the partition asymmetry at a bifurcation point\n    as defined in https://www.ncbi.nlm.nih.gov/pubmed/18568015\n\n    The number of nodes in each child tree is counted. The partition\n    is defined as the ratio of the absolute difference and the sum\n    of the number of bifurcations in the two daughter subtrees\n    at each branch point.'''\n    assert len(bif_point.children) == 2, 'A bifurcation point must have exactly 2 children'\n    n = float(sum(1 for _ in bif_point.children[0].ipreorder()))\n    m = float(sum(1 for _ in bif_point.children[1].ipreorder()))\n    if n == m:\n        return 0.0\n    return abs(n - m) / abs(n + m)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the partition pairs at a bifurcation point", "response": "def partition_pair(bif_point):\n    '''Calculate the partition pairs at a bifurcation point\n\n    The number of nodes in each child tree is counted. The partition\n    pairs is the number of bifurcations in the two daughter subtrees\n    at each branch point.'''\n    n = float(sum(1 for _ in bif_point.children[0].ipreorder()))\n    m = float(sum(1 for _ in bif_point.children[1].ipreorder()))\n    return (n, m)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _match_section(section, match):\n    '''checks whether the `type` of section is in the `match` dictionary\n\n    Works around the unknown ordering of s-expressions in each section.\n    For instance, the `type` is the 3-rd one in for CellBodies\n        (\"CellBody\"\n         (Color Yellow)\n         (CellBody)\n         (Set \"cell10\")\n        )\n\n    Returns:\n        value associated with match[section_type], None if no match\n    '''\n    # TODO: rewrite this so it is more clear, and handles sets & dictionaries for matching\n    for i in range(5):\n        if i >= len(section):\n            return None\n        if isinstance(section[i], StringType) and section[i] in match:\n            return match[section[i]]\n    return None", "response": "checks whether the type of section is in the match dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_tokens(morph_fd):\n    '''split a file-like into tokens: split on whitespace\n\n    Note: this also strips newlines and comments\n    '''\n    for line in morph_fd:\n        line = line.rstrip()   # remove \\r\\n\n        line = line.split(';', 1)[0]  # strip comments\n        squash_token = []  # quoted strings get squashed into one token\n\n        if '<(' in line:  # skip spines, which exist on a single line\n            assert ')>' in line, 'Missing end of spine'\n            continue\n\n        for token in line.replace('(', ' ( ').replace(')', ' ) ').split():\n            if squash_token:\n                squash_token.append(token)\n                if token.endswith('\"'):\n                    token = ' '.join(squash_token)\n                    squash_token = []\n                    yield token\n            elif token.startswith('\"') and not token.endswith('\"'):\n                squash_token.append(token)\n            else:\n                yield token", "response": "split a file - like into tokens"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_section(token_iter):\n    '''take a stream of tokens, and create the tree structure that is defined\n    by the s-expressions\n    '''\n    sexp = []\n    for token in token_iter:\n        if token == '(':\n            new_sexp = _parse_section(token_iter)\n            if not _match_section(new_sexp, UNWANTED_SECTIONS):\n                sexp.append(new_sexp)\n        elif token == ')':\n            return sexp\n        else:\n            sexp.append(token)\n    return sexp", "response": "take a stream of tokens and create the tree structure that is defined\n    by the s - expressions\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_sections(morph_fd):\n    '''returns array of all the sections that exist\n\n    The format is nested lists that correspond to the s-expressions\n    '''\n    sections = []\n    token_iter = _get_tokens(morph_fd)\n    for token in token_iter:\n        if token == '(':  # find top-level sections\n            section = _parse_section(token_iter)\n            if not _match_section(section, UNWANTED_SECTIONS):\n                sections.append(section)\n    return sections", "response": "returns array of all the sections that exist\n    The format is nested lists that correspond to the s - expressions\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflattens a subsection from its nested version", "response": "def _flatten_subsection(subsection, _type, offset, parent):\n    '''Flatten a subsection from its nested version\n\n    Args:\n        subsection: Nested subsection as produced by _parse_section, except one level in\n        _type: type of section, ie: AXON, etc\n        parent: first element has this as it's parent\n        offset: position in the final array of the first element\n\n    Returns:\n        Generator of values corresponding to [X, Y, Z, R, TYPE, ID, PARENT_ID]\n    '''\n    for row in subsection:\n        # TODO: Figure out what these correspond to in neurolucida\n        if row in ('Low', 'Generated', 'High', ):\n            continue\n        elif isinstance(row[0], StringType):\n            if len(row) in (4, 5, ):\n                if len(row) == 5:\n                    assert row[4][0] == 'S', \\\n                        'Only known usage of a fifth member is Sn, found: %s' % row[4][0]\n                yield (float(row[0]), float(row[1]), float(row[2]), float(row[3]) / 2.,\n                       _type, offset, parent)\n                parent = offset\n                offset += 1\n        elif isinstance(row[0], list):\n            split_parent = offset - 1\n            start_offset = 0\n\n            slices = []\n            start = 0\n            for i, value in enumerate(row):\n                if value == '|':\n                    slices.append(slice(start + start_offset, i))\n                    start = i + 1\n            slices.append(slice(start + start_offset, len(row)))\n\n            for split_slice in slices:\n                for _row in _flatten_subsection(row[split_slice], _type, offset,\n                                                split_parent):\n                    offset += 1\n                    yield _row"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the section from a list of sections", "response": "def _extract_section(section):\n    '''Find top level sections, and get their flat contents, and append them all\n\n    Returns a numpy array with the row format:\n        [X, Y, Z, R, TYPE, ID, PARENT_ID]\n\n    Note: PARENT_ID starts at -1 for soma and 0 for neurites\n    '''\n    # sections with only one element will be skipped,\n    if len(section) == 1:\n        assert section[0] == 'Sections', \\\n            ('Only known usage of a single Section content is \"Sections\", found %s' %\n             section[0])\n        return None\n\n    # try and detect type\n    _type = WANTED_SECTIONS.get(section[0][0], None)\n\n    start = 1\n    # CellBody often has [['\"CellBody\"'], ['CellBody'] as its first two elements\n    if _type is None:\n        _type = WANTED_SECTIONS.get(section[1][0], None)\n\n        if _type is None:  # can't determine the type\n            return None\n        start = 2\n\n    parent = -1 if _type == POINT_TYPE.SOMA else 0\n    subsection_iter = _flatten_subsection(section[start:], _type, offset=0,\n                                          parent=parent)\n\n    ret = np.array([row for row in subsection_iter])\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(morph_file, data_wrapper=DataWrapper):\n    '''return a 'raw_data' np.array with the full neuron, and the format of the file\n    suitable to be wrapped by DataWrapper\n    '''\n\n    msg = ('This is an experimental reader. '\n           'There are no guarantees regarding ability to parse '\n           'Neurolucida .asc files or correctness of output.')\n\n    warnings.warn(msg)\n    L.warning(msg)\n\n    with open(morph_file, encoding='utf-8', errors='replace') as morph_fd:\n        sections = _parse_sections(morph_fd)\n    raw_data = _sections_to_raw_data(sections)\n    return data_wrapper(raw_data, 'NL-ASCII')", "response": "read a file containing a list of neurons and return a raw_data np. array with the full neuron and the format of the file\n    suitable to be wrapped by DataWrapper\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stats(data):\n    '''Dictionary with summary stats for data\n\n    Returns:\n        dicitonary with length, mean, sum, standard deviation,\\\n            min and max of data\n    '''\n    return {'len': len(data),\n            'mean': np.mean(data),\n            'sum': np.sum(data),\n            'std': np.std(data),\n            'min': np.min(data),\n            'max': np.max(data)}", "response": "Dictionary with summary stats for data\n    Returns :\n        dicitonary with length mean sum standard deviation min and max of data\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads configuration from file if in config else use default", "response": "def get_config(config, default_config):\n    '''Load configuration from file if in config, else use default'''\n    if not config:\n        logging.warning('Using default config: %s', default_config)\n        config = default_config\n\n    try:\n        with open(config, 'r') as config_file:\n            return yaml.load(config_file)\n    except (yaml.reader.ReaderError,\n            yaml.parser.ParserError,\n            yaml.scanner.ScannerError) as e:\n        raise ConfigError('Invalid yaml file: \\n %s' % str(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef soma_surface_area(nrn, neurite_type=NeuriteType.soma):\n    '''Get the surface area of a neuron's soma.\n\n    Note:\n        The surface area is calculated by assuming the soma is spherical.\n    '''\n    assert neurite_type == NeuriteType.soma, 'Neurite type must be soma'\n    return 4 * math.pi * nrn.soma.radius ** 2", "response": "Get the surface area of a neuron s soma"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the surface areas of the somata in a population of neurons", "response": "def soma_surface_areas(nrn_pop, neurite_type=NeuriteType.soma):\n    '''Get the surface areas of the somata in a population of neurons\n\n    Note:\n        The surface area is calculated by assuming the soma is spherical.\n    Note:\n        If a single neuron is passed, a single element list with the surface\n        area of its soma member is returned.\n    '''\n    nrns = neuron_population(nrn_pop)\n    assert neurite_type == NeuriteType.soma, 'Neurite type must be soma'\n    return [soma_surface_area(n) for n in nrns]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef soma_radii(nrn_pop, neurite_type=NeuriteType.soma):\n    ''' Get the radii of the somata of a population of neurons\n\n    Note:\n        If a single neuron is passed, a single element list with the\n        radius of its soma member is returned.\n    '''\n    assert neurite_type == NeuriteType.soma, 'Neurite type must be soma'\n    nrns = neuron_population(nrn_pop)\n    return [n.soma.radius for n in nrns]", "response": "Get the radii of the somata of a population of neurons"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trunk_section_lengths(nrn, neurite_type=NeuriteType.all):\n    '''list of lengths of trunk sections of neurites in a neuron'''\n    neurite_filter = is_type(neurite_type)\n    return [morphmath.section_length(s.root_node.points)\n            for s in nrn.neurites if neurite_filter(s)]", "response": "list of lengths of trunk sections of a neuron"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trunk_origin_radii(nrn, neurite_type=NeuriteType.all):\n    '''radii of the trunk sections of neurites in a neuron'''\n    neurite_filter = is_type(neurite_type)\n    return [s.root_node.points[0][COLS.R] for s in nrn.neurites if neurite_filter(s)]", "response": "radii of the trunk sections of a neuron"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of all trunk origin azimuths of a neuron or population", "response": "def trunk_origin_azimuths(nrn, neurite_type=NeuriteType.all):\n    '''Get a list of all the trunk origin azimuths of a neuron or population\n\n    The azimuth is defined as Angle between x-axis and the vector\n    defined by (initial tree point - soma center) on the x-z plane.\n\n    The range of the azimuth angle [-pi, pi] radians\n    '''\n    neurite_filter = is_type(neurite_type)\n    nrns = neuron_population(nrn)\n\n    def _azimuth(section, soma):\n        '''Azimuth of a section'''\n        vector = morphmath.vector(section[0], soma.center)\n        return np.arctan2(vector[COLS.Z], vector[COLS.X])\n\n    return [_azimuth(s.root_node.points, n.soma)\n            for n in nrns\n            for s in n.neurites if neurite_filter(s)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trunk_origin_elevations(nrn, neurite_type=NeuriteType.all):\n    '''Get a list of all the trunk origin elevations of a neuron or population\n\n    The elevation is defined as the angle between x-axis and the\n    vector defined by (initial tree point - soma center)\n    on the x-y half-plane.\n\n    The range of the elevation angle [-pi/2, pi/2] radians\n    '''\n    neurite_filter = is_type(neurite_type)\n    nrns = neuron_population(nrn)\n\n    def _elevation(section, soma):\n        '''Elevation of a section'''\n        vector = morphmath.vector(section[0], soma.center)\n        norm_vector = np.linalg.norm(vector)\n\n        if norm_vector >= np.finfo(type(norm_vector)).eps:\n            return np.arcsin(vector[COLS.Y] / norm_vector)\n        raise ValueError(\"Norm of vector between soma center and section is almost zero.\")\n\n    return [_elevation(s.root_node.points, n.soma)\n            for n in nrns\n            for s in n.neurites if neurite_filter(s)]", "response": "Get a list of all trunk origin elevations of a neuron or population"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trunk_vectors(nrn, neurite_type=NeuriteType.all):\n    '''Calculates the vectors between all the trunks of the neuron\n    and the soma center.\n    '''\n    neurite_filter = is_type(neurite_type)\n    nrns = neuron_population(nrn)\n\n    return np.array([morphmath.vector(s.root_node.points[0], n.soma.center)\n                     for n in nrns\n                     for s in n.neurites if neurite_filter(s)])", "response": "Calculates the vectors between all the trunks of the neuron\n    and the soma center."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trunk_angles(nrn, neurite_type=NeuriteType.all):\n    '''Calculates the angles between all the trunks of the neuron.\n    The angles are defined on the x-y plane and the trees\n    are sorted from the y axis and anticlock-wise.\n    '''\n    vectors = trunk_vectors(nrn, neurite_type=neurite_type)\n    # In order to avoid the failure of the process in case the neurite_type does not exist\n    if not vectors.size:\n        return []\n\n    def _sort_angle(p1, p2):\n        \"\"\"Angle between p1-p2 to sort vectors\"\"\"\n        ang1 = np.arctan2(*p1[::-1])\n        ang2 = np.arctan2(*p2[::-1])\n        return (ang1 - ang2)\n\n    # Sorting angles according to x-y plane\n    order = np.argsort(np.array([_sort_angle(i / np.linalg.norm(i), [0, 1])\n                                 for i in vectors[:, 0:2]]))\n\n    ordered_vectors = vectors[order][:, [COLS.X, COLS.Y]]\n\n    return [morphmath.angle_between_vectors(ordered_vectors[i], ordered_vectors[i - 1])\n            for i, _ in enumerate(ordered_vectors)]", "response": "Calculates the angles between all the trunks of the neuron and all the trees of the neuron."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating crossings of neurites in a single center", "response": "def sholl_crossings(neurites, center, radii):\n    '''calculate crossings of neurites\n\n    Args:\n        nrn(morph): morphology on which to perform Sholl analysis\n        radii(iterable of floats): radii for which crossings will be counted\n\n    Returns:\n        Array of same length as radii, with a count of the number of crossings\n        for the respective radius\n    '''\n    def _count_crossings(neurite, radius):\n        '''count_crossings of segments in neurite with radius'''\n        r2 = radius ** 2\n        count = 0\n        for start, end in iter_segments(neurite):\n            start_dist2, end_dist2 = (morphmath.point_dist2(center, start),\n                                      morphmath.point_dist2(center, end))\n\n            count += int(start_dist2 <= r2 <= end_dist2 or\n                         end_dist2 <= r2 <= start_dist2)\n\n        return count\n\n    return np.array([sum(_count_crossings(neurite, r)\n                         for neurite in iter_neurites(neurites))\n                     for r in radii])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms Sholl frequency calculations on a population of neurites", "response": "def sholl_frequency(nrn, neurite_type=NeuriteType.all, step_size=10):\n    '''perform Sholl frequency calculations on a population of neurites\n\n    Args:\n        nrn(morph): nrn or population\n        neurite_type(NeuriteType): which neurites to operate on\n        step_size(float): step size between Sholl radii\n\n    Note:\n        Given a neuron, the soma center is used for the concentric circles,\n        which range from the soma radii, and the maximum radial distance\n        in steps of `step_size`.  When a population is given, the concentric\n        circles range from the smallest soma radius to the largest radial neurite\n        distance.  Finally, each segment of the neuron is tested, so a neurite that\n        bends back on itself, and crosses the same Sholl radius will get counted as\n        having crossed multiple times.\n    '''\n    nrns = neuron_population(nrn)\n    neurite_filter = is_type(neurite_type)\n\n    min_soma_edge = float('Inf')\n    max_radii = 0\n    neurites_list = []\n    for neuron in nrns:\n        neurites_list.extend(((neurites, neuron.soma.center)\n                              for neurites in neuron.neurites\n                              if neurite_filter(neurites)))\n\n        min_soma_edge = min(min_soma_edge, neuron.soma.radius)\n        max_radii = max(max_radii, np.max(np.abs(bounding_box(neuron))))\n\n    radii = np.arange(min_soma_edge, max_radii + step_size, step_size)\n    ret = np.zeros_like(radii)\n    for neurites, center in neurites_list:\n        ret += sholl_crossings(neurites, center, radii)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dist_points(bin_edges, d):\n    bc = bin_centers(bin_edges)\n    if d is not None:\n        d = DISTS[d['type']](d, bc)\n    return d, bc", "response": "Return an array of values according to a distribution\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_limits(data, dist=None, padding=0.25):\n    dmin = sys.float_info.max if dist is None else dist.get('min',\n                                                            sys.float_info.max)\n    dmax = sys.float_info.min if dist is None else dist.get('max',\n                                                            sys.float_info.min)\n    _min = min(min(data), dmin)\n    _max = max(max(data), dmax)\n\n    padding = padding * (_max - _min)\n    return _min - padding, _max + padding", "response": "Calculate a suitable range for a histogram\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_neurite_features(filepath):\n    '''Unpack relevant data into megadict'''\n    stuff = defaultdict(lambda: defaultdict(list))\n    nrns = nm.load_neurons(filepath)\n    # unpack data into arrays\n    for nrn in nrns:\n        for t in NEURITES_:\n            for feat in FEATURES:\n                stuff[feat][str(t).split('.')[1]].extend(\n                    nm.get(feat, nrn, neurite_type=t)\n                )\n    return stuff", "response": "Load the neurite features from a file and return a megadict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing command line arguments", "response": "def parse_args():\n    '''Parse command line arguments'''\n    parser = argparse.ArgumentParser(\n        description='Morphology feature plotter',\n        epilog='Note: Makes plots of various features and superimposes\\\n        input distributions. Plots are saved to PDF file.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\n    parser.add_argument('datapath',\n                        help='Morphology data directory path')\n\n    parser.add_argument('--mtypeconfig',\n                        required=True,\n                        help='Get mtype JSON configuration file')\n\n    parser.add_argument('--output',\n                        default='plots.pdf',\n                        help='Output PDF file name')\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the stuff and plot the results", "response": "def main(data_dir, mtype_file):  # pylint: disable=too-many-locals\n    '''Run the stuff'''\n    # data structure to store results\n    stuff = load_neurite_features(data_dir)\n    sim_params = json.load(open(mtype_file))\n\n    # load histograms, distribution parameter sets and figures into arrays.\n    # To plot figures, do\n    # plots[i].fig.show()\n    # To modify an axis, do\n    # plots[i].ax.something()\n\n    _plots = []\n\n    for feat, d in stuff.items():\n        for typ, data in d.items():\n            dist = sim_params['components'][typ].get(feat, None)\n            print('Type = %s, Feature = %s, Distribution = %s' % (typ, feat, dist))\n            # if no data available, skip this feature\n            if not data:\n                print(\"No data found for feature %s (%s)\" % (feat, typ))\n                continue\n            # print 'DATA', data\n            num_bins = 100\n            limits = calc_limits(data, dist)\n            bin_edges = np.linspace(limits[0], limits[1], num_bins + 1)\n            histo = np.histogram(data, bin_edges, normed=True)\n            print('PLOT LIMITS:', limits)\n            # print 'DATA:', data\n            # print 'BIN HEIGHT', histo[0]\n            plot = Plot(*view_utils.get_figure(new_fig=True, subplot=111))\n            plot.ax.set_xlim(*limits)\n            plot.ax.bar(histo[1][:-1], histo[0], width=bin_widths(histo[1]))\n            dp, bc = dist_points(histo[1], dist)\n            # print 'BIN CENTERS:', bc, len(bc)\n            if dp is not None:\n                # print 'DIST POINTS:', dp, len(dp)\n                plot.ax.plot(bc, dp, 'r*')\n            plot.ax.set_title('%s (%s)' % (feat, typ))\n            _plots.append(plot)\n\n    return _plots"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_density(population, plane='xy', bins=100, neurite_type=NeuriteType.basal_dendrite):\n    '''Extracts the 2d histogram of the center\n       coordinates of segments in the selected plane.\n    '''\n    segment_midpoints = get_feat('segment_midpoints', population, neurite_type=neurite_type)\n    horiz = segment_midpoints[:, 'xyz'.index(plane[0])]\n    vert = segment_midpoints[:, 'xyz'.index(plane[1])]\n    return np.histogram2d(np.array(horiz), np.array(vert), bins=(bins, bins))", "response": "Extracts the 2d histogram of the center\n       coordinates of segments in the selected plane."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting the 2d histogram of the center coordinates of segments in the selected plane.", "response": "def plot_density(population,  # pylint: disable=too-many-arguments, too-many-locals\n                 bins=100, new_fig=True, subplot=111, levels=None, plane='xy',\n                 colorlabel='Nodes per unit area', labelfontsize=16,\n                 color_map='Reds', no_colorbar=False, threshold=0.01,\n                 neurite_type=NeuriteType.basal_dendrite, **kwargs):\n    '''Plots the 2d histogram of the center\n       coordinates of segments in the selected plane.\n    '''\n    fig, ax = common.get_figure(new_fig=new_fig, subplot=subplot)\n\n    H1, xedges1, yedges1 = extract_density(population, plane=plane, bins=bins,\n                                           neurite_type=neurite_type)\n\n    mask = H1 < threshold  # mask = H1==0\n    H2 = np.ma.masked_array(H1, mask)\n\n    getattr(plt.cm, color_map).set_bad(color='white', alpha=None)\n\n    plots = ax.contourf((xedges1[:-1] + xedges1[1:]) / 2,\n                        (yedges1[:-1] + yedges1[1:]) / 2,\n                        np.transpose(H2), # / np.max(H2),\n                        cmap=getattr(plt.cm, color_map), levels=levels)\n\n    if not no_colorbar:\n        cbar = plt.colorbar(plots)\n        cbar.ax.set_ylabel(colorlabel, fontsize=labelfontsize)\n\n    kwargs['title'] = kwargs.get('title', '')\n    kwargs['xlabel'] = kwargs.get('xlabel', plane[0])\n    kwargs['ylabel'] = kwargs.get('ylabel', plane[1])\n\n    return common.plot_style(fig=fig, ax=ax, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot the 2d histogram of the center coordinates of segments of the selected plane and superimposes the view of the first neurite of the collection.", "response": "def plot_neuron_on_density(population, # pylint: disable=too-many-arguments\n                           bins=100, new_fig=True, subplot=111, levels=None, plane='xy',\n                           colorlabel='Nodes per unit area', labelfontsize=16,\n                           color_map='Reds', no_colorbar=False, threshold=0.01,\n                           neurite_type=NeuriteType.basal_dendrite, **kwargs):\n    '''Plots the 2d histogram of the center\n       coordinates of segments in the selected plane\n       and superimposes the view of the first neurite of the collection.\n    '''\n    _, ax = common.get_figure(new_fig=new_fig)\n\n    view.plot_tree(ax, population.neurites[0])\n\n    return plot_density(population, plane=plane, bins=bins, new_fig=False, subplot=subplot,\n                        colorlabel=colorlabel, labelfontsize=labelfontsize, levels=levels,\n                        color_map=color_map, no_colorbar=no_colorbar, threshold=threshold,\n                        neurite_type=neurite_type, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the x y z bounding box of an object containing points", "response": "def bounding_box(obj):\n    '''Get the (x, y, z) bounding box of an object containing points\n\n    Returns:\n        2D numpy array of [[min_x, min_y, min_z], [max_x, max_y, max_z]]\n    '''\n    return np.array([np.min(obj.points[:, 0:3], axis=0),\n                     np.max(obj.points[:, 0:3], axis=0)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_monotonic(neurite, tol):\n    '''Check if neurite tree is monotonic\n\n    If each child has smaller or equal diameters from its parent\n\n    Args:\n        neurite(Neurite): neurite to operate on\n        tol(float): tolerance\n\n    Returns:\n        True if neurite monotonic\n    '''\n\n    for node in neurite.iter_sections():\n        # check that points in section satisfy monotonicity\n        sec = node.points\n        for point_id in range(len(sec) - 1):\n            if sec[point_id + 1][COLS.R] > sec[point_id][COLS.R] + tol:\n                return False\n        # Check that section boundary points satisfy monotonicity\n        if(node.parent is not None and\n           sec[0][COLS.R] > node.parent.points[-1][COLS.R] + tol):\n            return False\n\n    return True", "response": "Check if a neurite tree is monotonic"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a neurite is flat using the given method", "response": "def is_flat(neurite, tol, method='tolerance'):\n    '''Check if neurite is flat using the given method\n\n    Args:\n        neurite(Neurite): neurite to operate on\n        tol(float): tolerance\n        method(string): the method of flatness estimation:\n            'tolerance' returns true if any extent of the tree is smaller\n            than the given tolerance\n            'ratio' returns true if the ratio of the smallest directions\n            is smaller than tol. e.g. [1,2,3] -> 1/2 < tol\n\n    Returns:\n        True if neurite is flat\n    '''\n    ext = principal_direction_extent(neurite.points[:, COLS.XYZ])\n\n    assert method in ('tolerance', 'ratio'), \"Method must be one of 'tolerance', 'ratio'\"\n    if method == 'ratio':\n        sorted_ext = np.sort(ext)\n        return sorted_ext[0] / sorted_ext[1] < float(tol)\n    return any(ext < float(tol))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a neurite process is backtracking to a previous node.", "response": "def is_back_tracking(neurite):\n    ''' Check if a neurite process backtracks to a previous node. Back-tracking takes place\n    when a daughter of a branching process goes back and either overlaps with a previous point, or\n    lies inside the cylindrical volume of the latter.\n\n    Args:\n        neurite(Neurite): neurite to operate on\n\n    Returns:\n        True Under the following scenaria:\n            1. A segment endpoint falls back and overlaps with a previous segment's point\n            2. The geometry of a segment overlaps with a previous one in the section\n    '''\n    def pair(segs):\n        ''' Pairs the input list into triplets'''\n        return zip(segs, segs[1:])\n\n    def coords(node):\n        ''' Returns the first three values of the tree that correspond to the x, y, z coordinates'''\n        return node[COLS.XYZ]\n\n    def max_radius(seg):\n        ''' Returns maximum radius from the two segment endpoints'''\n        return max(seg[0][COLS.R], seg[1][COLS.R])\n\n    def is_not_zero_seg(seg):\n        ''' Returns True if segment has zero length'''\n        return not np.allclose(coords(seg[0]), coords(seg[1]))\n\n    def is_in_the_same_verse(seg1, seg2):\n        ''' Checks if the vectors face the same direction. This\n        is true if their dot product is greater than zero.\n        '''\n        v1 = coords(seg2[1]) - coords(seg2[0])\n        v2 = coords(seg1[1]) - coords(seg1[0])\n        return np.dot(v1, v2) >= 0\n\n    def is_seg2_within_seg1_radius(dist, seg1, seg2):\n        ''' Checks whether the orthogonal distance from the point at the end of\n        seg1 to seg2 segment body is smaller than the sum of their radii\n        '''\n        return dist <= max_radius(seg1) + max_radius(seg2)\n\n    def is_seg1_overlapping_with_seg2(seg1, seg2):\n        '''Checks if a segment is in proximity of another one upstream'''\n        # get the coordinates of seg2 (from the origin)\n        s1 = coords(seg2[0])\n        s2 = coords(seg2[1])\n\n        # vector of the center of seg2 (from the origin)\n        C = 0.5 * (s1 + s2)\n\n        # endpoint of seg1 (from the origin)\n        P = coords(seg1[1])\n\n        # vector from the center C of seg2 to the endpoint P of seg1\n        CP = P - C\n\n        # vector of seg2\n        S1S2 = s2 - s1\n\n        # projection of CP upon seg2\n        prj = mm.vector_projection(CP, S1S2)\n\n        # check if the distance of the orthogonal complement of CP projection on S1S2\n        # (vertical distance from P to seg2) is smaller than the sum of the radii. (overlap)\n        # If not exit early, because there is no way that backtracking can feasible\n        if not is_seg2_within_seg1_radius(np.linalg.norm(CP - prj), seg1, seg2):\n            return False\n\n        # projection lies within the length of the cylinder. Check if the distance between\n        # the center C of seg2 and the projection of the end point of seg1, P is smaller than\n        # half of the others length plus a 5% tolerance\n        return np.linalg.norm(prj) < 0.55 * np.linalg.norm(S1S2)\n\n    def is_inside_cylinder(seg1, seg2):\n        ''' Checks if seg2 approximately lies within a cylindrical volume of seg1.\n        Two conditions must be satisfied:\n            1. The two segments are not facing the same direction  (seg2 comes back to seg1)\n            2. seg2 is overlaping with seg1\n        '''\n        return not is_in_the_same_verse(seg1, seg2) and is_seg1_overlapping_with_seg2(seg1, seg2)\n\n    # filter out single segment sections\n    section_itr = (snode for snode in neurite.iter_sections() if snode.points.shape[0] > 2)\n    for snode in section_itr:\n        # group each section's points intro triplets\n        segment_pairs = list(filter(is_not_zero_seg, pair(snode.points)))\n\n        # filter out zero length segments\n        for i, seg1 in enumerate(segment_pairs[1:]):\n            # check if the end point of the segment lies within the previous\n            # ones in the current sectionmake\n            for seg2 in segment_pairs[0: i + 1]:\n                if is_inside_cylinder(seg1, seg2):\n                    return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a neuron has neurites that are flat within a tolerance", "response": "def get_flat_neurites(neuron, tol=0.1, method='ratio'):\n    '''Check if a neuron has neurites that are flat within a tolerance\n\n    Args:\n        neurite(Neurite): neurite to operate on\n        tol(float): the tolerance or the ratio\n        method(string): 'tolerance' or 'ratio' described in :meth:`is_flat`\n\n    Returns:\n        Bool list corresponding to the flatness check for each neurite\n        in neuron neurites with respect to the given criteria\n    '''\n    return [n for n in neuron.neurites if is_flat(n, tol, method)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_nonmonotonic_neurites(neuron, tol=1e-6):\n    '''Get neurites that are not monotonic\n\n    Args:\n        neurite(Neurite): neurite to operate on\n        tol(float): the tolerance or the ratio\n\n    Returns:\n        list of neurites that do not satisfy monotonicity test\n    '''\n    return [n for n in neuron.neurites if not is_monotonic(n, tol)]", "response": "Get neurites that are not monotonic"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates and return centre of mass of a segment. seg_volalculated as centre of mass of conical frustum", "response": "def segment_centre_of_mass(seg):\n    '''Calculate and return centre of mass of a segment.\n\n    C, seg_volalculated as centre of mass of conical frustum'''\n    h = mm.segment_length(seg)\n    r0 = seg[0][COLS.R]\n    r1 = seg[1][COLS.R]\n    num = r0 * r0 + 2 * r0 * r1 + 3 * r1 * r1\n    denom = 4 * (r0 * r0 + r0 * r1 + r1 * r1)\n    centre_of_mass_z_loc = num / denom\n    return seg[0][COLS.XYZ] + (centre_of_mass_z_loc / h) * (seg[1][COLS.XYZ] - seg[0][COLS.XYZ])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating and return centre of mass of a neurite.", "response": "def neurite_centre_of_mass(neurite):\n    '''Calculate and return centre of mass of a neurite.'''\n    centre_of_mass = np.zeros(3)\n    total_volume = 0\n\n    seg_vol = np.array(map(mm.segment_volume, nm.iter_segments(neurite)))\n    seg_centre_of_mass = np.array(map(segment_centre_of_mass, nm.iter_segments(neurite)))\n\n    # multiply array of scalars with array of arrays\n    # http://stackoverflow.com/questions/5795700/multiply-numpy-array-of-scalars-by-array-of-vectors\n    seg_centre_of_mass = seg_centre_of_mass * seg_vol[:, np.newaxis]\n    centre_of_mass = np.sum(seg_centre_of_mass, axis=0)\n    total_volume = np.sum(seg_vol)\n    return centre_of_mass / total_volume"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates and return square Euclidian distance from given point to centre of mass of given segment.", "response": "def distance_sqr(point, seg):\n    '''Calculate and return square Euclidian distance from given point to\n    centre of mass of given segment.'''\n    centre_of_mass = segment_centre_of_mass(seg)\n    return sum(pow(np.subtract(point, centre_of_mass), 2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef radius_of_gyration(neurite):\n    '''Calculate and return radius of gyration of a given neurite.'''\n    centre_mass = neurite_centre_of_mass(neurite)\n    sum_sqr_distance = 0\n    N = 0\n    dist_sqr = [distance_sqr(centre_mass, s) for s in nm.iter_segments(neurite)]\n    sum_sqr_distance = np.sum(dist_sqr)\n    N = len(dist_sqr)\n    return np.sqrt(sum_sqr_distance / N)", "response": "Calculate and return radius of gyration of a given neurite."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_annotation(result, settings):\n    '''Generate the annotation for a given checker\n\n    Arguments\n        neuron(Neuron): The neuron object\n        checker: A tuple where the first item is the checking function (usually from neuron_checks)\n                 and the second item is a dictionary of settings for the annotation. It must\n                 contain the keys name, label and color\n    Returns\n        An S-expression-like string representing the annotation\n    '''\n    if result.status:\n        return \"\"\n\n    header = (\"\\n\\n\"\n              \"({label}   ; MUK_ANNOTATION\\n\"\n              \"    (Color {color})   ; MUK_ANNOTATION\\n\"\n              \"    (Name \\\"{name}\\\")   ; MUK_ANNOTATION\").format(**settings)\n\n    points = [p for _, _points in result.info for p in _points]\n\n    annotations = (\"    ({0} {1} {2} 0.50)   ; MUK_ANNOTATION\".format(\n        p[COLS.X], p[COLS.Y], p[COLS.Z]) for p in points)\n    footer = \")   ; MUK_ANNOTATION\\n\"\n\n    return '\\n'.join(chain.from_iterable(([header], annotations, [footer])))", "response": "Generate the annotation for a given checker\n                "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconcatenating the annotations of all checkers", "response": "def annotate(results, settings):\n    '''Concatenate the annotations of all checkers'''\n    annotations = (generate_annotation(result, setting)\n                   for result, setting in zip(results, settings))\n    return '\\n'.join(annot for annot in annotations if annot)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a Point from a data block row", "response": "def as_point(row):\n    '''Create a Point from a data block row'''\n    return Point(row[COLS.X], row[COLS.Y], row[COLS.Z],\n                 row[COLS.R], int(row[COLS.TYPE]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_superuser(self, email, password, **extra_fields):\n        extra_fields.setdefault('is_staff', True)\n        extra_fields.setdefault('is_superuser', True)\n        if extra_fields.get('is_staff') is not True:\n            raise ValueError('Superuser must have is_staff=True.')\n        if extra_fields.get('is_superuser') is not True:\n            raise ValueError('Superuser must have is_superuser=True.')\n        return self._create_user(email, password, **extra_fields)", "response": "Save new User with is_staff and is_superuser set to True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_file_contents(file_path, as_list=True):\n    abs_file_path = join(HERE, file_path)\n    with open(abs_file_path, encoding='utf-8') as file_pointer:\n        if as_list:\n            return file_pointer.read().splitlines()\n        return file_pointer.read()", "response": "Load file as string or list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck whether password 1 and password 2 are equivalent.", "response": "def clean_password2(self):\n        \"\"\"\n        Check wether password 1 and password 2 are equivalent\n\n        While ideally this would be done in clean, there is a chance a\n        superclass could declare clean and forget to call super. We\n        therefore opt to run this password mismatch check in password2\n        clean, but to show the error above password1 (as we are unsure\n        whether password 1 or password 2 contains the typo, and putting\n        it above password 2 may lead some users to believe the typo is\n        in just one).\n\n        \"\"\"\n        password1 = self.cleaned_data.get('password1')\n        password2 = self.cleaned_data.get('password2')\n        if password1 and password2 and password1 != password2:\n            self.add_error(\n                'password1',\n                forms.ValidationError(\n                    self.error_messages['password_mismatch'],\n                    code='password_mismatch',\n                ))\n        return password2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun password validaton after clean methods are run", "response": "def _post_clean(self):\n        \"\"\"Run password validaton after clean methods\n\n        When clean methods are run, the user instance does not yet\n        exist.  To properly compare model values agains the password (in\n        the UserAttributeSimilarityValidator), we wait until we have an\n        instance to compare against.\n\n        https://code.djangoproject.com/ticket/28127\n        https://github.com/django/django/pull/8408\n\n        Has no effect in Django prior to 1.9\n        May become unnecessary in Django 2.0 (if this superclass changes)\n\n        \"\"\"\n        super()._post_clean()  # updates self.instance with form data\n        password = self.cleaned_data.get('password1')\n        if password:\n            try:\n                password_validation.validate_password(password, self.instance)\n            except ValidationError as error:\n                self.add_error('password1', error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean(self):\n        super().clean()\n        self.email = self.__class__.objects.normalize_email(self.email)", "response": "Override default clean method to normalize email."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclick callback that normalizes feature input values.", "response": "def normalize_feature_inputs(ctx, param, value):\n    \"\"\"Click callback that normalizes feature input values.\n\n    Returns a generator over features from the input value.\n\n    Parameters\n    ----------\n    ctx: a Click context\n    param: the name of the argument or option\n    value: object\n        The value argument may be one of the following:\n\n        1. A list of paths to files containing GeoJSON feature\n           collections or feature sequences.\n        2. A list of string-encoded coordinate pairs of the form\n           \"[lng, lat]\", or \"lng, lat\", or \"lng lat\".\n\n        If no value is provided, features will be read from stdin.\n    \"\"\"\n    for feature_like in value or ('-',):\n        try:\n            with click.open_file(feature_like) as src:\n                for feature in iter_features(iter(src)):\n                    yield feature\n        except IOError:\n            coords = list(coords_from_query(feature_like))\n            yield {\n                'type': 'Feature',\n                'properties': {},\n                'geometry': {\n                    'type': 'Point',\n                    'coordinates': coords}}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter_features(geojsonfile, func=None):\n    func = func or (lambda x: x)\n    first_line = next(geojsonfile)\n\n    # Does the geojsonfile contain RS-delimited JSON sequences?\n    if first_line.startswith(u'\\x1e'):\n        text_buffer = first_line.strip(u'\\x1e')\n        for line in geojsonfile:\n            if line.startswith(u'\\x1e'):\n                if text_buffer:\n                    obj = json.loads(text_buffer)\n                    if 'coordinates' in obj:\n                        obj = to_feature(obj)\n                    newfeat = func(obj)\n                    if newfeat:\n                        yield newfeat\n                text_buffer = line.strip(u'\\x1e')\n            else:\n                text_buffer += line\n        # complete our parsing with a for-else clause.\n        else:\n            obj = json.loads(text_buffer)\n            if 'coordinates' in obj:\n                obj = to_feature(obj)\n            newfeat = func(obj)\n            if newfeat:\n                yield newfeat\n\n    # If not, it may contains LF-delimited GeoJSON objects or a single\n    # multi-line pretty-printed GeoJSON object.\n    else:\n        # Try to parse LF-delimited sequences of features or feature\n        # collections produced by, e.g., `jq -c ...`.\n        try:\n            obj = json.loads(first_line)\n            if obj['type'] == 'Feature':\n                newfeat = func(obj)\n                if newfeat:\n                    yield newfeat\n                for line in geojsonfile:\n                    newfeat = func(json.loads(line))\n                    if newfeat:\n                        yield newfeat\n            elif obj['type'] == 'FeatureCollection':\n                for feat in obj['features']:\n                    newfeat = func(feat)\n                    if newfeat:\n                        yield newfeat\n            elif 'coordinates' in obj:\n                newfeat = func(to_feature(obj))\n                if newfeat:\n                    yield newfeat\n                for line in geojsonfile:\n                    newfeat = func(to_feature(json.loads(line)))\n                    if newfeat:\n                        yield newfeat\n\n        # Indented or pretty-printed GeoJSON features or feature\n        # collections will fail out of the try clause above since\n        # they'll have no complete JSON object on their first line.\n        # To handle these, we slurp in the entire file and parse its\n        # text.\n        except ValueError:\n            text = \"\".join(chain([first_line], geojsonfile))\n            obj = json.loads(text)\n            if obj['type'] == 'Feature':\n                newfeat = func(obj)\n                if newfeat:\n                    yield newfeat\n            elif obj['type'] == 'FeatureCollection':\n                for feat in obj['features']:\n                    newfeat = func(feat)\n                    if newfeat:\n                        yield newfeat\n            elif 'coordinates' in obj:\n                newfeat = func(to_feature(obj))\n                if newfeat:\n                    yield newfeat", "response": "This function extracts GeoJSON features from a text file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\naccepts a filename stream or string. Returns an iterator over lines of the query.", "response": "def iter_query(query):\n    \"\"\"Accept a filename, stream, or string.\n    Returns an iterator over lines of the query.\"\"\"\n    try:\n        itr = click.open_file(query).readlines()\n    except IOError:\n        itr = [query]\n    return itr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coords_from_query(query):\n    try:\n        coords = json.loads(query)\n    except ValueError:\n        query = query.replace(',', ' ')\n        vals = query.split()\n        coords = [float(v) for v in vals]\n    return tuple(coords[:2])", "response": "Transform a query line into a tuple of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake an iterable of GeoJSON - like Feature mappings or an iterable of objects with a geo interface and normalizes it to the former.", "response": "def normalize_feature_objects(feature_objs):\n    \"\"\"Takes an iterable of GeoJSON-like Feature mappings or\n    an iterable of objects with a geo interface and\n    normalizes it to the former.\"\"\"\n    for obj in feature_objs:\n        if hasattr(obj, \"__geo_interface__\") and \\\n           'type' in obj.__geo_interface__.keys() and \\\n           obj.__geo_interface__['type'] == 'Feature':\n            yield obj.__geo_interface__\n        elif isinstance(obj, dict) and 'type' in obj and \\\n                obj['type'] == 'Feature':\n            yield obj\n        else:\n            raise ValueError(\"Did not recognize object {0}\"\n                             \"as GeoJSON Feature\".format(obj))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def api(self, endpoint, params=None, test=False):\n        data = {}\n        url = \"{}/{}\".format(self._api, endpoint)\n        try:\n            async with async_timeout.timeout(8, loop=self._loop):\n                response = await self._session.get(\n                    url, auth=self._auth, headers=HEADERS, params=params\n                )\n\n            if response.status == 200:\n                self._authenticated = True\n                self._connected = True\n                if not test:\n                    data = await response.json()\n            elif response.status == 401:\n                self._authenticated = False\n                self._connected = True\n\n        except asyncio.TimeoutError as error:\n            self._authenticated, self._connected = False, False\n            if not test:\n                _LOGGER.warning(\"Timeouterror connecting to Traccar, %s\", error)\n        except aiohttp.ClientError as error:\n            self._authenticated, self._connected = False, False\n            if not test:\n                _LOGGER.warning(\"Error connecting to Traccar, %s\", error)\n        except socket.gaierror as error:\n            self._authenticated, self._connected = False, False\n            if not test:\n                _LOGGER.warning(\"Error connecting to Traccar, %s\", error)\n        except TypeError as error:\n            self._authenticated, self._connected = False, False\n            if not test:\n                _LOGGER.warning(\"Error connecting to Traccar, %s\", error)\n        except Exception as error:  # pylint: disable=broad-except\n            self._authenticated, self._connected = False, False\n            if not test:\n                _LOGGER.warning(\"Error connecting to Traccar, %s\", error)\n\n        return data", "response": "Comunicate with the API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_device_info(self, custom_attributes=None):\n        await self.get_geofences()\n        await self.get_devices()\n        await self.get_positions()\n        devinfo = {}\n        try:  # pylint: disable=too-many-nested-blocks\n            for dev in self._devices or []:\n                for pos in self._positions or []:\n                    if pos[\"deviceId\"] == dev.get(\"id\"):\n                        uid = dev.get(\"uniqueId\")\n                        devinfo[uid] = {}\n                        nested = pos.get(\"attributes\", {})\n\n                        for attribute in ATTRIBUTES[\"position\"]:\n                            key = ATTRIBUTES[\"position\"][attribute]\n                            devinfo[uid][attribute] = pos[key]\n\n                        for attribute in ATTRIBUTES[\"device\"]:\n                            key = ATTRIBUTES[\"device\"][attribute]\n                            devinfo[uid][attribute] = dev[key]\n\n                        devinfo[uid][\"battery\"] = nested.get(\"batteryLevel\")\n                        devinfo[uid][\"motion\"] = nested.get(\"motion\")\n\n                        if custom_attributes is not None:\n                            for attr in custom_attributes:\n                                if attr in nested:\n                                    attrvalue = nested.get(attr)\n                                    devinfo[uid][attr] = attrvalue\n                        try:\n                            geofence = self.geofences[dev[\"geofenceIds\"][0]]\n                        except IndexError:\n                            geofence = None\n\n                        devinfo[uid][\"geofence\"] = geofence\n            if devinfo:\n                self._device_info = devinfo\n            else:\n                self._device_info = self._device_info\n            _LOGGER.debug(self._device_info)\n        except KeyError as error:\n            _LOGGER.error(\"Error combining data from Traccar, %s\", error)", "response": "Get the local installed version of the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_geofences(self):\n        data = await self.api(\"geofences\")\n        if self.connected and self.authenticated:\n            for geofence in data or []:\n                self._geofences[geofence[\"id\"]] = geofence[\"name\"]\n        else:\n            self._geofences = self._geofences\n        _LOGGER.debug(self._geofences)", "response": "Get the local installed version."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the local installed version.", "response": "async def get_devices(self):\n        \"\"\"Get the local installed version.\"\"\"\n        data = await self.api(\"devices\")\n        if self.connected and self.authenticated:\n            self._devices = data\n        else:\n            self._devices = self._devices\n        _LOGGER.debug(self._devices)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the local installed version.", "response": "async def get_positions(self):\n        \"\"\"Get the local installed version.\"\"\"\n        data = await self.api(\"positions\")\n        if self.connected and self.authenticated:\n            self._positions = data\n        else:\n            self._positions = self._positions\n        _LOGGER.debug(self._positions)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the local installed version.", "response": "async def get_events(\n        self, device_ids, group_ids=None, from_time=None, to_time=None, event_types=None\n    ):\n        \"\"\"Get the local installed version.\"\"\"\n        if to_time is None:\n            to_time = datetime.utcnow()\n        if from_time is None:\n            from_time = to_time - timedelta(seconds=EVENT_INTERVAL)\n        if event_types is None:\n            event_types = [\"allEvents\"]\n\n        get_params = []\n\n        get_params.extend([(\"deviceId\", value) for value in device_ids])\n        if group_ids is not None:\n            get_params.extend([(\"groupId\", value) for value in group_ids])\n        get_params.extend([(\"from\", from_time.isoformat() + \"Z\")])\n        get_params.extend([(\"to\", to_time.isoformat() + \"Z\")])\n        get_params.extend([(\"type\", value) for value in event_types])\n\n        data = await self.api(\"reports/events\", get_params)\n\n        if self.connected and self.authenticated:\n            self._events = data\n        else:\n            self._events = self._events\n\n        return self._events"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scramble_string(s, key):\n    key = key_digits(key)\n    for k in key:          # foreach digit in the key\n        s = shift(s, key)  # for each char by each digit in the key in sequence\n        s = s[k:] + s[:k]  # cut the sequence around the key digit\n        s = shuffle(s)     # do a 1:1 shuffle of the 'deck'\n\n    return s", "response": "scramble a string into a column - major order"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restore(s, t):\n    t = (c for c in t)\n    return ''.join(next(t) if not is_blacksquare(c) else c for c in s)", "response": "Restore a string s to a new string t."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(event, data):\n        messages = defaultdict(lambda: 'Avast:')\n        messages['start'] = 'Thar she blows!'\n        messages['tag'] = 'Thar she blows!'\n        messages['stop'] = 'Away into the depths:'\n        messages['destroy'] = 'Away into the depths:'\n        messages['delete'] = 'Away into the depths:'\n        status = get_status(event)\n        message = messages[status] + ' %s/%s'\n        log.info(message, status, get_id(event))\n        log.debug('\"data\": %s', form_json(data))", "response": "The default handler prints basic event info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\naccess IPTables transactionally in a uniform way.", "response": "def table(tab):\n    \"\"\"Access IPTables transactionally in a uniform way.\n\n    Ensures all access is done without autocommit and that only the outer\n    most task commits, and also ensures we refresh once and commit once.\n    \"\"\"\n    global open_tables\n    if tab in open_tables:\n        yield open_tables[tab]\n    else:\n        open_tables[tab] = iptc.Table(tab)\n        open_tables[tab].refresh()\n        open_tables[tab].autocommit = False\n        yield open_tables[tab]\n        open_tables[tab].commit()\n        del open_tables[tab]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to a slot.", "response": "def connect(self, slot, *extra_args):\n        \"\"\"\n        @slot: The method to be called on signal emission\n\n        Connects to @slot\n        \"\"\"\n        slot = Slot(slot, *extra_args)\n        self._functions.add(slot)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_after(self, slot, *extra_args):\n        slot = Slot(slot, *extra_args)\n        self._after_functions.add(slot)", "response": "Connect to the signal after the other signal has been handled by other_signal_get_nentries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disconnect(self, slot, *extra_args):\n        slot = Slot(slot, *extra_args)\n        if slot in self._functions:\n            self._functions.remove(slot)\n        elif slot in self._after_functions:\n            self._after_functions.remove(slot)", "response": "Disconnect a slot from the signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _download_progress_cb(blocknum, blocksize, totalsize):\n    readsofar = blocknum * blocksize\n    if totalsize > 0:\n        percent = readsofar * 1e2 / totalsize\n        msg = \"\\r%5.1f%% %*d / %d\" % (\n            percent, len(str(totalsize)), readsofar, totalsize)\n        print(msg)\n        if readsofar >= totalsize:  # near the end\n            print(\"\\n\")\n    else:  # total size is unknown\n        print(\"read %d\\n\" % (readsofar,))", "response": "Callback for the download progress callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_symbol(self, symbol, link_resolver):\n        if not symbol:\n            return ''\n\n        if isinstance(symbol, FieldSymbol):\n            return ''\n\n        # pylint: disable=unused-variable\n        out = self._format_symbol(symbol)\n        template = self.get_template('symbol_wrapper.html')\n\n        return template.render(\n            {'symbol': symbol,\n             'formatted_doc': out})", "response": "Formats a symbol and returns a formatted doc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_assets(self, assets_path):\n        if not os.path.exists(assets_path):\n            os.mkdir(assets_path)\n\n        extra_files = self._get_extra_files()\n\n        for ex_files in Formatter.get_extra_files_signal(self):\n            extra_files.extend(ex_files)\n\n        for src, dest in extra_files:\n            dest = os.path.join(assets_path, dest)\n\n            destdir = os.path.dirname(dest)\n            if not os.path.exists(destdir):\n                os.makedirs(destdir)\n            if os.path.isfile(src):\n                shutil.copy(src, dest)\n            elif os.path.isdir(src):\n                recursive_overwrite(src, dest)", "response": "Copy all extra files to the assets_path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat a single page.", "response": "def format_page(self, page):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        self.formatting_page_signal(self, page)\n        return self._format_page(page)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_out(self, page, xml_subpages, output):\n        # pylint: disable=missing-docstring\n        def subpages(_):\n            return xml_subpages\n\n        namespace = etree.FunctionNamespace('uri:hotdoc')\n        namespace['subpages'] = subpages\n        html_output = os.path.join(output, 'html')\n\n        rel_path = os.path.join(self.get_output_folder(page), page.link.ref)\n        cached_path = os.path.join(self.__cache_dir, rel_path)\n        full_path = os.path.join(html_output, rel_path)\n\n        if not os.path.exists(os.path.dirname(full_path)):\n            os.makedirs(os.path.dirname(full_path))\n        with open(cached_path, 'r', encoding='utf-8') as _:\n            doc_root = etree.HTML(_.read())\n\n        self.__validate_html(self.extension.project, page, doc_root)\n\n        self.writing_page_signal(self, page, full_path, doc_root)\n        with open(full_path, 'w', encoding='utf-8') as _:\n            transformed = str(self.__page_transform(doc_root))\n            _.write('<!DOCTYPE html>\\n%s' % transformed)", "response": "Write out the page to the output folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing the page attributes for rendering.", "response": "def prepare_page_attributes(self, page):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        self._current_page = page\n        page.output_attrs['html']['scripts'] = OrderedSet()\n        page.output_attrs['html']['stylesheets'] = OrderedSet()\n        page.output_attrs['html']['extra_html'] = []\n        page.output_attrs['html']['edit_button'] = ''\n        page.output_attrs['html']['extra_footer_html'] = []\n        if Formatter.add_anchors:\n            page.output_attrs['html']['scripts'].add(\n                os.path.join(HERE, 'assets', 'css.escape.js'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_toplevel_config(self, config):\n        if not Formatter.initialized:\n            html_theme = config.get('html_theme', 'default')\n\n            if html_theme != 'default':\n                uri = urllib.parse.urlparse(html_theme)\n                if not uri.scheme:\n                    html_theme = config.get_path('html_theme')\n                    debug(\"Using theme located at %s\" % html_theme)\n                elif uri.scheme.startswith('http'):\n                    html_theme = self.__download_theme(uri)\n\n            if html_theme == 'default':\n                default_theme = os.path.join(HERE, os.pardir,\n                                             'hotdoc_bootstrap_theme', 'dist')\n\n                html_theme = os.path.abspath(default_theme)\n                debug(\"Using default theme\")\n\n            theme_meta_path = os.path.join(html_theme, 'theme.json')\n\n            if os.path.exists(theme_meta_path):\n                with open(theme_meta_path, 'r') as _:\n                    Formatter.theme_meta = json.loads(_.read())\n\n            searchpath = []\n            self.__load_theme_templates(searchpath, HERE)\n\n            Formatter.theme_path = html_theme\n            if html_theme:\n                self.__load_theme_templates(searchpath, html_theme)\n\n            Formatter.extra_theme_path = config.get_path('html_extra_theme')\n            if Formatter.extra_theme_path:\n                self.__load_theme_templates(searchpath,\n                                            Formatter.extra_theme_path)\n\n            Formatter.engine = Engine(\n                loader=FileLoader(searchpath, encoding='UTF-8'),\n                extensions=[CoreExtension(), CodeExtension()])\n            Formatter.engine.global_vars.update({'e': html.escape})\n\n            Formatter.initialized = True", "response": "Parse the top level configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the config dictionary and set the attributes of this object.", "response": "def parse_config(self, config):\n        \"\"\"Banana banana\n        \"\"\"\n        self.add_anchors = bool(config.get(\"html_add_anchors\"))\n        self.number_headings = bool(config.get(\"html_number_headings\"))\n        self._docstring_formatter.parse_config(config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat the navigation page.", "response": "def format_navigation(self, project):\n        \"\"\"Banana banana\n        \"\"\"\n        try:\n            template = self.get_template('site_navigation.html')\n        except IOError:\n            return None\n\n        return template.render({'project': project})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_subpages(self, page, subpages):\n        if not subpages:\n            return None\n\n        try:\n            template = self.get_template('subpages.html')\n        except IOError:\n            return None\n\n        ret = etree.XML(template.render({'page': page,\n                                         'subpages': subpages}))\n        assets = ret.xpath('.//*[@src]')\n        for asset in assets:\n            self.__lookup_asset(asset, self.extension.project, page)\n\n        return ret", "response": "Format a list of subpages into a XML document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the path for the given name already exists.", "response": "def check_path(init_dir, name):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    path = os.path.join(init_dir, name)\n    if os.path.exists(path):\n        error('setup-issue', '%s already exists' % path)\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates default layout for the current project.", "response": "def create_default_layout(config):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    project_name = config.get('project_name')\n    project_version = config.get('project_version')\n\n    if not project_name or not project_version:\n        error('setup-issue',\n              '--project-name and --project-version must be specified')\n\n    init_dir = config.get_path('init_dir')\n    if not init_dir:\n        init_dir = config.get_invoke_dir()\n    else:\n        if os.path.exists(init_dir) and not os.path.isdir(init_dir):\n            error('setup-issue',\n                  'Init directory exists but is not a directory: %s' %\n                  init_dir)\n\n    sitemap_path = check_path(init_dir, 'sitemap.txt')\n    conf_path = check_path(init_dir, 'hotdoc.json')\n    md_folder_path = check_path(init_dir, 'markdown_files')\n    assets_folder_path = check_path(init_dir, 'assets')\n    check_path(init_dir, 'built_doc')\n    cat_path = os.path.join(assets_folder_path, 'cat.gif')\n\n    os.makedirs(init_dir)\n    os.makedirs(assets_folder_path)\n    os.makedirs(md_folder_path)\n\n    with open(sitemap_path, 'w') as _:\n        _.write('index.md\\n')\n\n    with open(conf_path, 'w') as _:\n        _.write(json.dumps({'project_name': project_name,\n                            'project_version': project_version,\n                            'sitemap': 'sitemap.txt',\n                            'index': os.path.join('markdown_files',\n                                                  'index.md'),\n                            'output': 'built_doc',\n                            'extra_assets': ['assets']}, indent=4))\n\n    with open(os.path.join(md_folder_path, 'index.md'), 'w') as _:\n        _.write('# %s\\n' % project_name.capitalize())\n        try:\n            get_cat(cat_path)\n            _.write(\"\\nIt's dangerous to go alone, take this\\n\")\n            _.write('\\n![](assets/cat.gif)')\n        except:  # pylint: disable=bare-except\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the command and return the number of exit code.", "response": "def execute_command(parser, config, ext_classes):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    res = 0\n    cmd = config.get('command')\n\n    get_private_folder = config.get('get_private_folder', False)\n\n    if cmd == 'help':\n        parser.print_help()\n    elif cmd == 'run' or get_private_folder:  # git.mk backward compat\n        app = Application(ext_classes)\n        try:\n            app.parse_config(config)\n            if get_private_folder:\n                print(app.private_folder)\n                return res\n            res = app.run()\n        except HotdocException:\n            res = len(Logger.get_issues())\n        except Exception:  # pylint: disable=broad-except\n            print(\"An unknown error happened while building the documentation\"\n                  \" and hotdoc cannot recover from it. Please report \"\n                  \"a bug with this error message and the steps to \"\n                  \"reproduce it\")\n            traceback.print_exc()\n            res = 1\n        finally:\n            app.finalize()\n    elif cmd == 'init':\n        try:\n            create_default_layout(config)\n        except HotdocException:\n            res = 1\n    elif cmd == 'conf':\n        config.dump(conf_file=config.get('output_conf_file', None))\n    elif cmd is None:\n        if config.get('version'):\n            print(VERSION)\n        elif config.get('makefile_path'):\n            here = os.path.dirname(__file__)\n            path = os.path.join(here, 'utils', 'hotdoc.mk')\n            print(os.path.abspath(path))\n        elif config.get('get_conf_path'):\n            key = config.get('get_conf_path')\n            path = config.get_path(key, rel_to_cwd=True)\n            if path is not None:\n                print(path)\n        elif config.get('get_conf_key'):\n            key = config.get('get_conf_key')\n            value = config.get(key, None)\n            if value is not None:\n                print(value)\n        else:\n            parser.print_usage()\n    else:\n        parser.print_usage()\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(args):\n\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        add_help=False)\n    parser.add_argument(\"--extra-extension-path\", action=\"append\",\n                        default=[],\n                        dest=\"extra_extension_path\",\n                        help=\"An extra extension path to use\")\n    parser.add_argument('--conf-file', help='Path to the config file',\n                        dest='conf_file')\n    tmpargs, _args = parser.parse_known_args(args)\n\n    json_conf = None\n    if tmpargs.conf_file:\n        json_conf = load_config_json(tmpargs.conf_file)\n        tmpargs.extra_extension_path += json_conf.get('extra_extension_path',\n                                                      [])\n\n    # We only get these once, doing this now means all\n    # installed extensions will show up as Configurable subclasses.\n    try:\n        ext_classes = get_extension_classes(\n            sort=True, extra_extension_paths=tmpargs.extra_extension_path)\n    except HotdocException:\n        return 1\n\n    parser.add_argument('command', action=\"store\",\n                        choices=('run', 'conf', 'init', 'help'),\n                        nargs=\"?\")\n    parser.add_argument('--output-conf-file',\n                        help='Path where to save the updated conf'\n                        ' file',\n                        dest='output_conf_file')\n    parser.add_argument('--init-dir',\n                        help='Directory to initialize',\n                        dest='init_dir')\n    parser.add_argument('--version', help=\"Print version and exit\",\n                        action=\"store_true\")\n    parser.add_argument('--makefile-path',\n                        help=\"Print path to includable \"\n                        \"Makefile and exit\",\n                        action=\"store_true\")\n    parser.add_argument(\"--get-conf-key\", action=\"store\",\n                        help=\"print the value for a configuration \"\n                        \"key\")\n    parser.add_argument(\"--get-conf-path\", action=\"store\",\n                        help=\"print the value for a configuration \"\n                        \"path\")\n    parser.add_argument(\"--get-private-folder\", action=\"store_true\",\n                        help=\"get the path to hotdoc's private \"\n                        \"folder\")\n    parser.add_argument(\"--has-extension\", action=\"append\",\n                        dest=\"has_extensions\", default=[],\n                        help=\"Check if a given extension is available\")\n    parser.add_argument(\"--list-extensions\", action=\"store_true\",\n                        dest=\"list_extensions\", help=\"Print \"\n                        \"available extensions\")\n    parser.add_argument(\"-\", action=\"store_true\",\n                        help=\"Separator to allow finishing a list\"\n                        \" of arguments before a command\",\n                        dest=\"whatever\")\n\n    add_args_methods = set()\n\n    for klass in all_subclasses(Configurable):\n        if klass.add_arguments not in add_args_methods:\n            klass.add_arguments(parser)\n            add_args_methods.add(klass.add_arguments)\n\n    known_args, _ = parser.parse_known_args(args)\n\n    defaults = {}\n    actual_args = {}\n    for key, value in list(dict(vars(known_args)).items()):\n        if value != parser.get_default(key):\n            actual_args[key] = value\n        if parser.get_default(key) is not None:\n            defaults[key] = value\n\n    if known_args.has_extensions:\n        res = 0\n        for extension_name in known_args.has_extensions:\n            found = False\n            for klass in ext_classes:\n                if klass.extension_name == extension_name:\n                    found = True\n                    print(\"Extension '%s'... FOUND.\" % extension_name)\n            if not found:\n                print(\"Extension '%s'... NOT FOUND.\" % extension_name)\n                res = 1\n        return res\n\n    if known_args.list_extensions:\n        print(\"Extensions:\")\n        extensions = [e.extension_name for e in ext_classes]\n        for extension in sorted(extensions):\n            print(\" - %s \" % extension)\n        return 0\n\n    if known_args.command != 'init':\n        conf_file = actual_args.get('conf_file')\n        if conf_file is None and os.path.exists('hotdoc.json'):\n            conf_file = 'hotdoc.json'\n    else:\n        conf_file = ''\n\n    config = Config(command_line_args=actual_args,\n                    conf_file=conf_file,\n                    defaults=defaults,\n                    json_conf=json_conf)\n\n    Logger.parse_config(config)\n\n    return execute_command(parser, config, ext_classes)", "response": "This function is called by the command line interface to get the current configuration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_comment(self, comment):\n        if not comment:\n            return\n\n        self.__comments[comment.name] = comment\n        self.comment_added_signal(self, comment)", "response": "Adds a comment to the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_comment(self, name):\n        comment = self.__comments.get(name)\n\n        if comment:\n            return comment\n\n        aliases = self.__get_aliases(name)\n        for alias in aliases:\n            comment = self.__comments.get(alias)\n            if comment:\n                return comment\n\n        return None", "response": "Returns the comment for the given name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_symbol(self, type_, **kwargs):\n        unique_name = kwargs.get('unique_name')\n        if not unique_name:\n            unique_name = kwargs.get('display_name')\n            kwargs['unique_name'] = unique_name\n\n        filename = kwargs.get('filename')\n        if filename:\n            filename = os.path.abspath(filename)\n            kwargs['filename'] = os.path.abspath(filename)\n\n        if unique_name in self.__symbols:\n            warn('symbol-redefined', \"%s(unique_name=%s, filename=%s, project=%s)\"\n                 \" has already been defined: %s\" % (type_.__name__, unique_name, filename,\n                                                    kwargs.get('project_name'),\n                                                    self.get_symbol(unique_name)))\n            return None\n\n        aliases = kwargs.pop('aliases', [])\n        for alias in aliases:\n            self.create_symbol(ProxySymbol,\n                               unique_name=alias,\n                               target=unique_name)\n\n        symbol = type_()\n        debug('Created symbol with unique name %s' % unique_name,\n              'symbols')\n\n        for key, value in list(kwargs.items()):\n            setattr(symbol, key, value)\n\n        self.__symbols[unique_name] = symbol\n        for alias in aliases:\n            self.__symbols[alias] = symbol\n        self.__aliases[unique_name] = aliases\n\n        return symbol", "response": "Create a new symbol for the given type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef persist(self):\n        os.makedirs(self.__symbol_folder, exist_ok=True)\n        os.makedirs(self.__aliases_folder, exist_ok=True)\n        os.makedirs(self.__comments_folder, exist_ok=True)\n        for name, sym in self.__symbols.items():\n            with open(self.__get_pickle_path(self.__symbol_folder, name, True), 'wb') as _:\n                pickle.dump(sym, _)\n        for name, aliases in self.__aliases.items():\n            if aliases:\n                with open(self.__get_pickle_path(self.__aliases_folder, name, True), 'wb') as _:\n                    pickle.dump(aliases, _)\n        for name, comment in self.__comments.items():\n            if comment:\n                with open(self.__get_pickle_path(self.__comments_folder, name, True), 'wb') as _:\n                    pickle.dump(comment, _)", "response": "Persist the current state of the object to the local storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef splitall(path):\n    head, tail = os.path.split(os.path.normpath(path))\n    components = []\n    while tail:\n        components.insert(0, tail)\n        head, tail = os.path.split(head)\n    return components", "response": "Splits a path into a list of all the components."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nflatten a list of lists into a single list of lists.", "response": "def flatten_list(list_):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    res = []\n\n    for elem in list_:\n        if isinstance(elem, list):\n            res.extend(flatten_list(elem))\n        else:\n            res.append(elem)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __get_extra_extension_classes(paths):\n    extra_classes = []\n    wset = pkg_resources.WorkingSet([])\n    distributions, _ = wset.find_plugins(pkg_resources.Environment(paths))\n\n    for dist in distributions:\n        sys.path.append(dist.location)\n        wset.add(dist)\n\n    for entry_point in wset.iter_entry_points(group='hotdoc.extensions',\n                                              name='get_extension_classes'):\n        try:\n            activation_function = entry_point.load()\n            classes = activation_function()\n        # pylint: disable=broad-except\n        except Exception as exc:\n            info(\"Failed to load %s %s\" % (entry_point.module_name, exc))\n            debug(traceback.format_exc())\n            continue\n\n        for klass in classes:\n            extra_classes.append(klass)\n\n    return extra_classes", "response": "Get the extra extension classes from the given paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the list of extension classes that are available in the extension directory.", "response": "def get_extension_classes(sort, extra_extension_paths=None):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    all_classes = {}\n    deps_map = {}\n\n    for entry_point in pkg_resources.iter_entry_points(\n            group='hotdoc.extensions', name='get_extension_classes'):\n        if entry_point.module_name == 'hotdoc_c_extension.extensions':\n            continue\n        try:\n            activation_function = entry_point.load()\n            classes = activation_function()\n        # pylint: disable=broad-except\n        except Exception as exc:\n            info(\"Failed to load %s\" % entry_point.module_name, exc)\n            debug(traceback.format_exc())\n            continue\n\n        for klass in classes:\n            all_classes[klass.extension_name] = klass\n\n    if extra_extension_paths:\n        for klass in __get_extra_extension_classes(extra_extension_paths):\n            all_classes[klass.extension_name] = klass\n\n    klass_list = list(all_classes.values())\n    if not sort:\n        return klass_list\n\n    for i, klass in enumerate(klass_list):\n        deps = klass.get_dependencies()\n        topodeps = set()\n        for dep in deps:\n            if dep.dependency_name not in all_classes:\n                if dep.optional:\n                    continue\n                else:\n                    error(\"setup-issue\",\n                          \"Missing dependency %s for %s\" %\n                          (dep.dependency_name, klass.extension_name))\n            if dep.is_upstream:\n                topodeps.add(\n                    klass_list.index(all_classes[dep.dependency_name]))\n\n        deps_map[i] = topodeps\n\n    sorted_class_indices = toposort_flatten(deps_map)\n    sorted_classes = [klass_list[i] for i in sorted_class_indices]\n    return sorted_classes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmimicing the touch command", "response": "def touch(fname):\n    \"\"\"\n    Mimics the `touch` command\n\n    Busy loops until the mtime has actually been changed, use for tests only\n    \"\"\"\n    orig_mtime = get_mtime(fname)\n    while get_mtime(fname) == orig_mtime:\n        pathlib.Path(fname).touch()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dedent(line):\n    indentation = 0\n    for char in line:\n        if char not in ' \\t':\n            break\n        indentation += 1\n        if char == '\\t':\n            indentation = _round8(indentation)\n\n    if indentation % 8 != 0:\n        raise IndentError(column=indentation)\n\n    return indentation // 8, line.strip()", "response": "De - indent a line of text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting text to ID.", "response": "def id_from_text(text, add_hash=False):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    id_ = text.strip().lower()\n\n    # No unicode in urls\n    id_ = id_.encode('ascii', errors='ignore').decode()\n\n    id_ = re.sub(r\"[^\\w\\s]\", '', id_)\n    id_ = re.sub(r\"\\s+\", '-', id_)\n    if add_hash:\n        return '#%s' % id_\n    return id_"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discard(self, key):\n        if key in self.map:\n            key, prev, nxt = self.map.pop(key)\n            prev[2] = nxt\n            nxt[1] = prev", "response": "Removes the entry with the given key from the map."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlogging a debug message.", "response": "def debug(self, message, domain=None):\n        \"\"\"\n        Shortcut function for `utils.loggable.debug`\n\n        Args:\n            message: see `utils.loggable.debug`\n            domain: see `utils.loggable.debug`\n        \"\"\"\n        if domain is None:\n            domain = self.extension_name\n        debug(message, domain)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging information about the current object.", "response": "def info(self, message, domain=None):\n        \"\"\"\n        Shortcut function for `utils.loggable.info`\n\n        Args:\n            message: see `utils.loggable.info`\n            domain: see `utils.loggable.info`\n        \"\"\"\n        if domain is None:\n            domain = self.extension_name\n        info(message, domain)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_config(self, config):\n        prefix = self.argument_prefix\n        self.sources = config.get_sources(prefix)\n        self.smart_sources = [\n            self._get_smart_filename(s) for s in self.sources]\n        self.index = config.get_index(prefix)\n        self.source_roots = OrderedSet(\n            config.get_paths('%s_source_roots' % prefix))\n\n        for arg, dest in list(self.paths_arguments.items()):\n            val = config.get_paths(arg)\n            setattr(self, dest, val)\n\n        for arg, dest in list(self.path_arguments.items()):\n            val = config.get_path(arg)\n            setattr(self, dest, val)\n\n        self.formatter.parse_config(config)", "response": "This method will parse the configuration and set the attributes of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an index argument to the argument group.", "response": "def add_index_argument(cls, group):\n        \"\"\"\n        Subclasses may call this to add an index argument.\n\n        Args:\n            group: arparse.ArgumentGroup, the extension argument group\n            prefix: str, arguments have to be namespaced\n        \"\"\"\n        prefix = cls.argument_prefix\n\n        group.add_argument(\n            '--%s-index' % prefix, action=\"store\",\n            dest=\"%s_index\" % prefix,\n            help=(\"Name of the %s root markdown file, can be None\" % (\n                cls.extension_name)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_sources_argument(cls, group, allow_filters=True, prefix=None, add_root_paths=False):\n        prefix = prefix or cls.argument_prefix\n\n        group.add_argument(\"--%s-sources\" % prefix,\n                           action=\"store\", nargs=\"+\",\n                           dest=\"%s_sources\" % prefix.replace('-', '_'),\n                           help=\"%s source files to parse\" % prefix)\n\n        if allow_filters:\n            group.add_argument(\"--%s-source-filters\" % prefix,\n                               action=\"store\", nargs=\"+\",\n                               dest=\"%s_source_filters\" % prefix.replace(\n                                   '-', '_'),\n                               help=\"%s source files to ignore\" % prefix)\n\n        if add_root_paths:\n            group.add_argument(\"--%s-source-roots\" % prefix,\n                               action=\"store\", nargs=\"+\",\n                               dest=\"%s_source_roots\" % prefix.replace(\n                                   '-', '_'),\n                               help=\"%s source root directories allowing files \"\n                                    \"to be referenced relatively to those\" % prefix)", "response": "Adds the sources and source_filters argument to the argument group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_paths_argument(cls, group, argname, dest=None, help_=None):\n        prefixed = '%s-%s' % (cls.argument_prefix, argname)\n        if dest is None:\n            dest = prefixed.replace('-', '_')\n            final_dest = dest[len(cls.argument_prefix) + 1:]\n        else:\n            final_dest = dest\n            dest = '%s_%s' % (cls.argument_prefix, dest)\n\n        group.add_argument('--%s' % prefixed, action='store', nargs='+',\n                           dest=dest, help=help_)\n        cls.paths_arguments[dest] = final_dest", "response": "Add a paths argument to the command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_page(self, page, link_resolver, output):\n        debug('Formatting page %s' % page.link.ref, 'formatting')\n\n        if output:\n            actual_output = os.path.join(output,\n                                         'html')\n            if not os.path.exists(actual_output):\n                os.makedirs(actual_output)\n        else:\n            actual_output = None\n\n        page.format(self.formatter, link_resolver, actual_output)", "response": "Formats the specified tree. Page and writes it to the specified output directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_out_sitemap(self, opath):\n        if opath not in self.written_out_sitemaps:\n            Extension.formatted_sitemap = self.formatter.format_navigation(\n                self.app.project)\n            if Extension.formatted_sitemap:\n                escaped_sitemap = Extension.formatted_sitemap.replace(\n                    '\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace('\\n', '')\n                js_wrapper = 'sitemap_downloaded_cb(\"%s\");' % escaped_sitemap\n                with open(opath, 'w') as _:\n                    _.write(js_wrapper)\n\n        self.written_out_sitemaps.add(opath)", "response": "Write out the Sitemap file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite out the page to the output folder.", "response": "def write_out_page(self, output, page):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        subpages = OrderedDict({})\n        all_pages = self.project.tree.get_pages()\n        subpage_names = self.get_subpages_sorted(all_pages, page)\n        for pagename in subpage_names:\n            proj = self.project.subprojects.get(pagename)\n\n            if not proj:\n                cpage = all_pages[pagename]\n                sub_formatter = self.project.extensions[\n                    cpage.extension_name].formatter\n            else:\n                cpage = proj.tree.root\n                sub_formatter = proj.extensions[cpage.extension_name].formatter\n\n            subpage_link, _ = cpage.link.get_link(self.app.link_resolver)\n            prefix = sub_formatter.get_output_folder(cpage)\n            if prefix:\n                subpage_link = '%s/%s' % (prefix, subpage_link)\n            subpages[subpage_link] = cpage\n\n        html_subpages = self.formatter.format_subpages(page, subpages)\n\n        js_dir = os.path.join(output, 'html', 'assets', 'js')\n        if not os.path.exists(js_dir):\n            os.makedirs(js_dir)\n        sm_path = os.path.join(js_dir, 'sitemap.js')\n        self.write_out_sitemap(sm_path)\n\n        self.formatter.write_out(page, html_subpages, output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_subpages_sorted(self, pages, page):\n\n        sorted_pages = []\n        to_sort = []\n        for subpage in page.subpages:\n            # Do not resort subprojects even if they are\n            # 'generated'.\n            if pages[subpage].pre_sorted:\n                sorted_pages.append(subpage)\n            else:\n                to_sort.append(subpage)\n\n        return sorted_pages + sorted(\n            to_sort, key=lambda p: pages[p].get_title().lower())", "response": "Get @page subpages sorted appropriately."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef include_file_cb(include_path, line_ranges, symbol):\n        lang = ''\n        if include_path.endswith((\".md\", \".markdown\")):\n            lang = 'markdown'\n        else:\n            split = os.path.splitext(include_path)\n            if len(split) == 2:\n                ext = split[1].strip('.')\n                lang = LANG_MAPPING.get(ext) or ext\n\n        if line_ranges:\n            res = []\n            for line_range in line_ranges:\n                for lineno in range(line_range[0] + 1, line_range[1] + 1):\n                    line = linecache.getline(include_path, lineno)\n                    if not line:\n                        return None\n                    res.append(line)\n            return ''.join(res), lang\n\n        with io.open(include_path, 'r', encoding='utf-8') as _:\n            return _.read(), lang", "response": "This function is called by the include file_cb function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef persist(self):\n\n        if self.app.dry:\n            return\n\n        for proj in self.subprojects.values():\n            proj.persist()", "response": "Persist the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup(self):\n        info('Setting up %s' % self.project_name, 'project')\n\n        for extension in list(self.extensions.values()):\n            info('Setting up %s' % extension.extension_name)\n            extension.setup()\n\n        sitemap = SitemapParser().parse(self.sitemap_path)\n        self.tree.build(sitemap, self.extensions)\n\n        info(\"Resolving symbols\", 'resolution')\n        self.tree.resolve_symbols(self.app.database, self.app.link_resolver)", "response": "Setup the tree and build the sitemap file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self, link_resolver, output):\n        if not output:\n            return\n\n        self.tree.format(link_resolver, output, self.extensions)\n        self.formatted_signal(self)", "response": "Formats the object for output."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_subproject(self, fname, conf_path):\n        config = Config(conf_file=conf_path)\n        proj = Project(self.app,\n                       dependency_map=self.dependency_map)\n        proj.parse_name_from_config(config)\n        proj.parse_config(config)\n        proj.setup()\n        self.subprojects[fname] = proj", "response": "Creates and adds a new subproject."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the name from the config object.", "response": "def parse_name_from_config(self, config):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        self.project_name = config.get('project_name', None)\n        if not self.project_name:\n            error('invalid-config', 'No project name was provided')\n\n        self.project_version = config.get('project_version', None)\n        if not self.project_version:\n            error('invalid-config', 'No project version was provided')\n\n        self.sanitized_name = '%s-%s' % (re.sub(r'\\W+', '-',\n                                                self.project_name),\n                                         self.project_version)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the config and sets up the state.", "response": "def parse_config(self, config, toplevel=False):\n        \"\"\"Parses @config setting up @self state.\"\"\"\n        self.sitemap_path = config.get_path('sitemap')\n\n        if self.sitemap_path is None:\n            error('invalid-config',\n                  'No sitemap was provided')\n\n        self.include_paths = OrderedSet([])\n\n        index_file = config.get_index()\n        if index_file:\n            if not os.path.exists(index_file):\n                error('invalid-config',\n                      'The provided index \"%s\" does not exist' %\n                      index_file)\n            self.include_paths |= OrderedSet([os.path.dirname(index_file)])\n\n        self.include_paths |= OrderedSet(config.get_paths('include_paths'))\n\n        self.is_toplevel = toplevel\n\n        self.tree = Tree(self, self.app)\n\n        self.__create_extensions()\n\n        for extension in list(self.extensions.values()):\n            if toplevel:\n                extension.parse_toplevel_config(config)\n            extension.parse_config(config)\n\n        self.extra_asset_folders = OrderedSet(config.get_paths('extra_assets'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the formatter for the given extension name.", "response": "def __get_formatter(self, extension_name):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        ext = self.extensions.get(extension_name)\n        if ext:\n            return ext.formatter\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites out the sitemap to the given output folder.", "response": "def write_out(self, output):\n        \"\"\"Banana banana\n        \"\"\"\n        if not output:\n            return\n\n        ext = self.extensions.get(self.tree.root.extension_name)\n\n        self.tree.write_out(output)\n\n        self.write_extra_assets(output)\n        ext.formatter.copy_assets(os.path.join(output, 'html', 'assets'))\n\n        # Just in case the sitemap root isn't named index\n        ext_folder = ext.formatter.get_output_folder(self.tree.root)\n        ref, _ = self.tree.root.link.get_link(self.app.link_resolver)\n        index_path = os.path.join(ext_folder, ref)\n\n        default_index_path = os.path.join(output, 'html', 'index.html')\n\n        if not os.path.exists(default_index_path):\n            with open(default_index_path, 'w', encoding='utf8') as _:\n                _.write('<meta http-equiv=\"refresh\" content=\"0; url=%s\"/>' %\n                        index_path)\n\n        self.written_out_signal(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck for duplicate keys.", "response": "def _no_duplicates_constructor(loader, node, deep=False):\n    \"\"\"Check for duplicate keys.\"\"\"\n\n    mapping = {}\n    for key_node, value_node in node.value:\n        key = loader.construct_object(key_node, deep=deep)\n        value = loader.construct_object(value_node, deep=deep)\n        if key in mapping:\n            raise ConstructorError(\"while constructing a mapping\",\n                                   node.start_mark,\n                                   \"found duplicate key (%s)\" % key,\n                                   key_node.start_mark)\n        mapping[key] = value\n\n    return loader.construct_mapping(node, deep)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef page_from_raw_text(self, source_file, contents, extension_name):\n        raw_contents = contents\n\n        meta = {}\n        if contents.startswith('---\\n'):\n            split = contents.split('\\n...\\n', 1)\n            if len(split) == 2:\n                contents = split[1]\n                try:\n                    blocks = yaml.load_all(split[0], Loader=yaml.FullLoader)\n                    for block in blocks:\n                        if block:\n                            meta.update(block)\n                except ConstructorError as exception:\n                    warn('invalid-page-metadata',\n                         '%s: Invalid metadata: \\n%s' % (source_file,\n                                                         str(exception)))\n\n        output_path = os.path.dirname(os.path.relpath(\n            source_file, next(iter(self.project.include_paths))))\n\n        ast = cmark.hotdoc_to_ast(contents, self)\n        return Page(source_file, False, self.project.sanitized_name, extension_name,\n                    source_file=source_file, ast=ast, meta=meta, raw_contents=raw_contents,\n                    output_path=output_path)", "response": "Create a page from a raw text file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve all the symbols in the tree.", "response": "def resolve_symbols(self, database, link_resolver, page=None):\n        \"\"\"Will call resolve_symbols on all the stale subpages of the tree.\n        Args:\n          page: hotdoc.core.tree.Page, the page to resolve symbols in,\n          will recurse on potential subpages.\n        \"\"\"\n\n        page = page or self.root\n\n        if page.ast is None and not page.generated:\n            with io.open(page.source_file, 'r', encoding='utf-8') as _:\n                page.ast = cmark.hotdoc_to_ast(_.read(), self)\n\n        page.resolve_symbols(self, database, link_resolver)\n        self.__update_dep_map(page, page.symbols)\n\n        for pagename in page.subpages:\n            cpage = self.__all_pages[pagename]\n            self.resolve_symbols(database, link_resolver, page=cpage)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_page(self, page, link_resolver, output, extensions):\n        info('formatting %s' % page.source_file, 'formatting')\n        extension = extensions[page.extension_name]\n        extension.format_page(page, link_resolver, output)", "response": "Format a single page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self, link_resolver, output, extensions):\n        info('Formatting documentation tree', 'formatting')\n        self.__setup_folder(output)\n\n        link_resolver.get_link_signal.connect(self.__get_link_cb)\n        # Page.formatting_signal.connect(self.__formatting_page_cb)\n        # Link.resolving_link_signal.connect(self.__link_referenced_cb)\n\n        self.__extensions = extensions\n\n        for page in self.walk():\n            self.format_page(page, link_resolver, output, extensions)\n\n        self.__extensions = None\n        link_resolver.get_link_signal.disconnect(self.__get_link_cb)", "response": "Format the documentation tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites out the contents of the current page to the output file.", "response": "def write_out(self, output):\n        \"\"\"Banana banana\n        \"\"\"\n        for page in self.walk():\n            ext = self.project.extensions[page.extension_name]\n            ext.write_out_page(output, page)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the list of extension classes that can be used in the hotdoc.", "response": "def get_extension_classes():\n    \"\"\"\n    Hotdoc's setuptools entry point\n    \"\"\"\n    res = [SyntaxHighlightingExtension, SearchExtension, TagExtension,\n           DevhelpExtension, LicenseExtension, GitUploadExtension,\n           EditOnGitHubExtension]\n\n    if sys.version_info[1] >= 5:\n        res += [DBusExtension]\n\n    try:\n        from hotdoc.extensions.c.c_extension import CExtension\n        res += [CExtension]\n    except ImportError:\n        pass\n\n    try:\n        from hotdoc.extensions.gi.gi_extension import GIExtension\n        res += [GIExtension]\n    except ImportError:\n        pass\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_functions(lib, ignore_errors):\n\n    def register(item):\n        return register_function(lib, item, ignore_errors)\n\n    for f in functionList:\n        register(f)", "response": "Register function prototypes with a libclang library instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_position(tu, file, line, column):\n        return conf.lib.clang_getLocation(tu, file, line, column)", "response": "Retrieve the source location associated with a given file line and column."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_offset(tu, file, offset):\n        return conf.lib.clang_getLocationForOffset(tu, file, offset)", "response": "Retrieve a SourceLocation object from a given character offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format(self, options=None):\n        if options is None:\n            options = conf.lib.clang_defaultDiagnosticDisplayOptions()\n        if options & ~Diagnostic._FormatOptionsMask:\n            raise ValueError('Invalid format options')\n        formatted = conf.lib.clang_formatDiagnostic(self, options)\n        return str(conf.lib.clang_getCString(formatted))", "response": "Format this diagnostic for display."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_value(value):\n        result = TokenKind._value_map.get(value, None)\n\n        if result is None:\n            raise ValueError('Unknown TokenKind: %d' % value)\n\n        return result", "response": "Obtain a registered TokenKind instance from its value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a new TokenKind enumeration.", "response": "def register(value, name):\n        \"\"\"Register a new TokenKind enumeration.\n\n        This should only be called at module load time by code within this\n        package.\n        \"\"\"\n        if value in TokenKind._value_map:\n            raise ValueError('TokenKind already registered: %d' % value)\n\n        kind = TokenKind(value, name)\n        TokenKind._value_map[value] = kind\n        setattr(TokenKind, name, kind)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef location(self):\n        if not hasattr(self, '_loc'):\n            self._loc = conf.lib.clang_getCursorLocation(self)\n\n        return self._loc", "response": "Return the source location of the entity that was used by the cursor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extent(self):\n        if not hasattr(self, '_extent'):\n            self._extent = conf.lib.clang_getCursorExtent(self)\n\n        return self._extent", "response": "Return the source range occupied by the entity\n        pointed at by the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef storage_class(self):\n        if not hasattr(self, '_storage_class'):\n            self._storage_class = conf.lib.clang_Cursor_getStorageClass(self)\n\n        return StorageClass.from_id(self._storage_class)", "response": "Returns the storage class of the entity pointed at by the\n        cursor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the access specifier of the current object.", "response": "def access_specifier(self):\n        \"\"\"\n        Retrieves the access specifier (if any) of the entity pointed at by the\n        cursor.\n        \"\"\"\n        if not hasattr(self, '_access_specifier'):\n            self._access_specifier = conf.lib.clang_getCXXAccessSpecifier(self)\n\n        return AccessSpecifier.from_id(self._access_specifier)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef type(self):\n        if not hasattr(self, '_type'):\n            self._type = conf.lib.clang_getCursorType(self)\n\n        return self._type", "response": "Retrieve the type of the entity pointed at by the cursor."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the canonical Cursor corresponding to this Cursor.", "response": "def canonical(self):\n        \"\"\"Return the canonical Cursor corresponding to this Cursor.\n\n        The canonical cursor is the cursor which is representative for the\n        underlying entity. For example, if you have multiple forward\n        declarations for the same class, the canonical cursor for the forward\n        declarations will be identical.\n        \"\"\"\n        if not hasattr(self, '_canonical'):\n            self._canonical = conf.lib.clang_getCanonicalCursor(self)\n\n        return self._canonical"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef result_type(self):\n        if not hasattr(self, '_result_type'):\n            self._result_type = conf.lib.clang_getResultType(self.type)\n\n        return self._result_type", "response": "Retrieve the Type of the result for this Cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the underlying type of a typedef declaration.", "response": "def underlying_typedef_type(self):\n        \"\"\"Return the underlying type of a typedef declaration.\n\n        Returns a Type for the typedef this cursor is a declaration for. If\n        the current cursor is not a typedef, this raises.\n        \"\"\"\n        if not hasattr(self, '_underlying_type'):\n            assert self.kind.is_declaration()\n            self._underlying_type = \\\n              conf.lib.clang_getTypedefDeclUnderlyingType(self)\n\n        return self._underlying_type"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enum_type(self):\n        if not hasattr(self, '_enum_type'):\n            assert self.kind == CursorKind.ENUM_DECL\n            self._enum_type = conf.lib.clang_getEnumDeclIntegerType(self)\n\n        return self._enum_type", "response": "Return the integer type of an enum declaration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the value of an enum constant.", "response": "def enum_value(self):\n        \"\"\"Return the value of an enum constant.\"\"\"\n        if not hasattr(self, '_enum_value'):\n            assert self.kind == CursorKind.ENUM_CONSTANT_DECL\n            # Figure out the underlying type of the enum to know if it\n            # is a signed or unsigned quantity.\n            underlying_type = self.type\n            if underlying_type.kind == TypeKind.ENUM:\n                underlying_type = underlying_type.get_declaration().enum_type\n            if underlying_type.kind in (TypeKind.CHAR_U,\n                                        TypeKind.UCHAR,\n                                        TypeKind.CHAR16,\n                                        TypeKind.CHAR32,\n                                        TypeKind.USHORT,\n                                        TypeKind.UINT,\n                                        TypeKind.ULONG,\n                                        TypeKind.ULONGLONG,\n                                        TypeKind.UINT128):\n                self._enum_value = \\\n                  conf.lib.clang_getEnumConstantDeclUnsignedValue(self)\n            else:\n                self._enum_value = conf.lib.clang_getEnumConstantDeclValue(self)\n        return self._enum_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a hash of the cursor as an int.", "response": "def hash(self):\n        \"\"\"Returns a hash of the cursor as an int.\"\"\"\n        if not hasattr(self, '_hash'):\n            self._hash = conf.lib.clang_hashCursor(self)\n\n        return self._hash"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef semantic_parent(self):\n        if not hasattr(self, '_semantic_parent'):\n            self._semantic_parent = conf.lib.clang_getCursorSemanticParent(self)\n\n        return self._semantic_parent", "response": "Return the semantic parent for this cursor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the lexical parent for this cursor.", "response": "def lexical_parent(self):\n        \"\"\"Return the lexical parent for this cursor.\"\"\"\n        if not hasattr(self, '_lexical_parent'):\n            self._lexical_parent = conf.lib.clang_getCursorLexicalParent(self)\n\n        return self._lexical_parent"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef referenced(self):\n        if not hasattr(self, '_referenced'):\n            self._referenced = conf.lib.clang_getCursorReferenced(self)\n\n        return self._referenced", "response": "Returns a cursor that is a reference returns a cursor\n        representing the entity that it references."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef brief_comment(self):\n        r = conf.lib.clang_Cursor_getBriefCommentText(self)\n        if not r:\n            return None    \n        return str(r)", "response": "Returns the brief comment text associated with that Cursor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef raw_comment(self):\n        r = conf.lib.clang_Cursor_getRawCommentText(self)\n        if not r:\n            return None\n        return str(r)", "response": "Returns the raw comment text associated with that Cursor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_arguments(self):\n        num_args = conf.lib.clang_Cursor_getNumArguments(self)\n        for i in xrange(0, num_args):\n            yield conf.lib.clang_Cursor_getArgument(self, i)", "response": "Return an iterator for accessing the arguments of this cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator for accessing the children of this cursor.", "response": "def get_children(self):\n        \"\"\"Return an iterator for accessing the children of this cursor.\"\"\"\n\n        # FIXME: Expose iteration from CIndex, PR6125.\n        def visitor(child, parent, children):\n            # FIXME: Document this assertion in API.\n            # FIXME: There should just be an isNull method.\n            assert child != conf.lib.clang_getNullCursor()\n\n            # Create reference to TU so it isn't GC'd before Cursor.\n            child._tu = self._tu\n            children.append(child)\n            return 1 # continue\n        children = []\n        conf.lib.clang_visitChildren(self, callbacks['cursor_visit'](visitor),\n            children)\n        return iter(children)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef walk_preorder(self):\n        yield self\n        for child in self.get_children():\n            for descendant in child.walk_preorder():\n                yield descendant", "response": "Depth - first preorder walk over the cursor and its descendants."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_anonymous(self):\n        if self.kind == CursorKind.FIELD_DECL:\n            return self.type.get_declaration().is_anonymous()\n        return conf.lib.clang_Cursor_isAnonymous(self)", "response": "Check if the record is anonymous."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef argument_types(self):\n        class ArgumentsIterator(collections.Sequence):\n            def __init__(self, parent):\n                self.parent = parent\n                self.length = None\n\n            def __len__(self):\n                if self.length is None:\n                    self.length = conf.lib.clang_getNumArgTypes(self.parent)\n\n                return self.length\n\n            def __getitem__(self, key):\n                # FIXME Support slice objects.\n                if not isinstance(key, int):\n                    raise TypeError(\"Must supply a non-negative int.\")\n\n                if key < 0:\n                    raise IndexError(\"Only non-negative indexes are accepted.\")\n\n                if key >= len(self):\n                    raise IndexError(\"Index greater than container length: \"\n                                     \"%d > %d\" % ( key, len(self) ))\n\n                result = conf.lib.clang_getArgType(self.parent, key)\n                if result.kind == TypeKind.INVALID:\n                    raise IndexError(\"Argument could not be retrieved.\")\n\n                return result\n\n        assert self.kind == TypeKind.FUNCTIONPROTO\n        return ArgumentsIterator(self)", "response": "Retrieve a container for the non - variadic arguments for this type. The container is an iterable and indexable. Each item in the container is a Type instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element_type(self):\n        result = conf.lib.clang_getElementType(self)\n        if result.kind == TypeKind.INVALID:\n            raise Exception('Element type not available on this type.')\n\n        return result", "response": "Retrieve the Type of elements within this Type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the number of elements in this type. Returns an int.", "response": "def element_count(self):\n        \"\"\"Retrieve the number of elements in this type.\n\n        Returns an int.\n\n        If the Type is not an array or vector, this raises.\n        \"\"\"\n        result = conf.lib.clang_getNumElements(self)\n        if result < 0:\n            raise Exception('Type does not have elements.')\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_function_variadic(self):\n        assert self.kind == TypeKind.FUNCTIONPROTO\n\n        return conf.lib.clang_isFunctionTypeVariadic(self)", "response": "Determine whether this function Type is a variadic function type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_fields(self):\n\n        def visitor(field, children):\n            assert field != conf.lib.clang_getNullCursor()\n\n            # Create reference to TU so it isn't GC'd before Cursor.\n            field._tu = self._tu\n            fields.append(field)\n            return 1 # continue\n        fields = []\n        conf.lib.clang_Type_visitFields(self,\n                            callbacks['fields_visit'](visitor), fields)\n        return iter(fields)", "response": "Return an iterator for accessing the fields of this type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the translation unit from the given source code file.", "response": "def parse(self, path, args=None, unsaved_files=None, options = 0):\n        \"\"\"Load the translation unit from the given source code file by running\n        clang and generating the AST before loading. Additional command line\n        parameters can be passed to clang via the args parameter.\n\n        In-memory contents for files can be provided by passing a list of pairs\n        to as unsaved_files, the first item should be the filenames to be mapped\n        and the second should be the contents to be substituted for the\n        file. The contents may be passed as strings or file objects.\n\n        If an error was encountered during parsing, a TranslationUnitLoadError\n        will be raised.\n        \"\"\"\n        return TranslationUnit.from_source(path, args, unsaved_files, options,\n                                           self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a TranslationUnit instance from a previously - saved AST file.", "response": "def from_ast_file(cls, filename, index=None):\n        \"\"\"Create a TranslationUnit instance from a saved AST file.\n\n        A previously-saved AST file (provided with -emit-ast or\n        TranslationUnit.save()) is loaded from the filename specified.\n\n        If the file cannot be loaded, a TranslationUnitLoadError will be\n        raised.\n\n        index is optional and is the Index instance to use. If not provided,\n        a default Index will be created.\n        \"\"\"\n        if index is None:\n            index = Index.create()\n\n        ptr = conf.lib.clang_createTranslationUnit(index, filename)\n        if not ptr:\n            raise TranslationUnitLoadError(filename)\n\n        return cls(ptr=ptr, index=index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterable of FileInclusion objects that describe the innusions in a translation unit.", "response": "def get_includes(self):\n        \"\"\"\n        Return an iterable sequence of FileInclusion objects that describe the\n        sequence of inclusions in a translation unit. The first object in\n        this sequence is always the input file. Note that this method will not\n        recursively iterate over header files included through precompiled\n        headers.\n        \"\"\"\n        def visitor(fobj, lptr, depth, includes):\n            if depth > 0:\n                loc = lptr.contents\n                includes.append(FileInclusion(loc.file, File(fobj), loc, depth))\n\n        # Automatically adapt CIndex/ctype pointers to python objects\n        includes = []\n        conf.lib.clang_getInclusions(self,\n                callbacks['translation_unit_includes'](visitor), includes)\n\n        return iter(includes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_location(self, filename, position):\n        f = self.get_file(filename)\n\n        if isinstance(position, int):\n            return SourceLocation.from_offset(self, f, position)\n\n        return SourceLocation.from_position(self, f, position[0], position[1])", "response": "Obtain a SourceLocation for a file in this translation unit."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nobtain a SourceRange from this translation unit.", "response": "def get_extent(self, filename, locations):\n        \"\"\"Obtain a SourceRange from this translation unit.\n\n        The bounds of the SourceRange must ultimately be defined by a start and\n        end SourceLocation. For the locations argument, you can pass:\n\n          - 2 SourceLocation instances in a 2-tuple or list.\n          - 2 int file offsets via a 2-tuple or list.\n          - 2 2-tuple or lists of (line, column) pairs in a 2-tuple or list.\n\n        e.g.\n\n        get_extent('foo.c', (5, 10))\n        get_extent('foo.c', ((1, 1), (1, 15)))\n        \"\"\"\n        f = self.get_file(filename)\n\n        if len(locations) < 2:\n            raise Exception('Must pass object with at least 2 elements')\n\n        start_location, end_location = locations\n\n        if hasattr(start_location, '__len__'):\n            start_location = SourceLocation.from_position(self, f,\n                start_location[0], start_location[1])\n        elif isinstance(start_location, int):\n            start_location = SourceLocation.from_offset(self, f,\n                start_location)\n\n        if hasattr(end_location, '__len__'):\n            end_location = SourceLocation.from_position(self, f,\n                end_location[0], end_location[1])\n        elif isinstance(end_location, int):\n            end_location = SourceLocation.from_offset(self, f, end_location)\n\n        assert isinstance(start_location, SourceLocation)\n        assert isinstance(end_location, SourceLocation)\n\n        return SourceRange.from_locations(start_location, end_location)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diagnostics(self):\n        class DiagIterator:\n            def __init__(self, tu):\n                self.tu = tu\n\n            def __len__(self):\n                return int(conf.lib.clang_getNumDiagnostics(self.tu))\n\n            def __getitem__(self, key):\n                diag = conf.lib.clang_getDiagnostic(self.tu, key)\n                if not diag:\n                    raise IndexError\n                return Diagnostic(diag)\n\n        return DiagIterator(self)", "response": "Return an iterable containing the diagnostics."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the current instance of the TranslationUnit to a file.", "response": "def save(self, filename):\n        \"\"\"Saves the TranslationUnit to a file.\n\n        This is equivalent to passing -emit-ast to the clang frontend. The\n        saved file can be loaded back into a TranslationUnit. Or, if it\n        corresponds to a header, it can be used as a pre-compiled header file.\n\n        If an error occurs while saving, a TranslationUnitSaveError is raised.\n        If the error was TranslationUnitSaveError.ERROR_INVALID_TU, this means\n        the constructed TranslationUnit was not valid at time of save. In this\n        case, the reason(s) why should be available via\n        TranslationUnit.diagnostics().\n\n        filename -- The path to save the translation unit to.\n        \"\"\"\n        options = conf.lib.clang_defaultSaveOptions(self)\n        result = int(conf.lib.clang_saveTranslationUnit(self, filename,\n                                                        options))\n        if result != 0:\n            raise TranslationUnitSaveError(result,\n                'Error saving TranslationUnit.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncode complete in this translation unit. In-memory contents for files can be provided by passing a list of pairs as unsaved_files, the first items should be the filenames to be mapped and the second should be the contents to be substituted for the file. The contents may be passed as strings or file objects.", "response": "def codeComplete(self, path, line, column, unsaved_files=None,\n                     include_macros=False, include_code_patterns=False,\n                     include_brief_comments=False):\n        \"\"\"\n        Code complete in this translation unit.\n\n        In-memory contents for files can be provided by passing a list of pairs\n        as unsaved_files, the first items should be the filenames to be mapped\n        and the second should be the contents to be substituted for the\n        file. The contents may be passed as strings or file objects.\n        \"\"\"\n        options = 0\n\n        if include_macros:\n            options += 1\n\n        if include_code_patterns:\n            options += 2\n\n        if include_brief_comments:\n            options += 4\n\n        if unsaved_files is None:\n            unsaved_files = []\n\n        unsaved_files_array = 0\n        if len(unsaved_files):\n            unsaved_files_array = (_CXUnsavedFile * len(unsaved_files))()\n            for i,(name,value) in enumerate(unsaved_files):\n                if not isinstance(value, str):\n                    # FIXME: It would be great to support an efficient version\n                    # of this, one day.\n                    value = value.read()\n                    print(value)\n                if not isinstance(value, str):\n                    raise TypeError('Unexpected unsaved file contents.')\n                unsaved_files_array[i].name = c_string_p(name)\n                unsaved_files_array[i].contents = c_string_p(value)\n                unsaved_files_array[i].length = len(value)\n        ptr = conf.lib.clang_codeCompleteAt(self, path, line, column,\n                unsaved_files_array, len(unsaved_files), options)\n        if ptr:\n            return CodeCompletionResults(ptr)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator for Token instances in this translation unit.", "response": "def get_tokens(self, locations=None, extent=None):\n        \"\"\"Obtain tokens in this translation unit.\n\n        This is a generator for Token instances. The caller specifies a range\n        of source code to obtain tokens for. The range can be specified as a\n        2-tuple of SourceLocation or as a SourceRange. If both are defined,\n        behavior is undefined.\n        \"\"\"\n        if locations is not None:\n            extent = SourceRange(start=locations[0], end=locations[1])\n\n        return TokenGroup.get_tokens(self, extent)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef name(self):\n        return str(conf.lib.clang_getCString(conf.lib.clang_getFileName(self)))", "response": "Return the complete file and path name of the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an iterable object providing each argument in the compiler executable for the compiler invocation as a _CXString.", "response": "def arguments(self):\n        \"\"\"\n        Get an iterable object providing each argument in the\n        command line for the compiler invocation as a _CXString.\n\n        Invariant : the first argument is the compiler executable\n        \"\"\"\n        length = conf.lib.clang_CompileCommand_getNumArgs(self.cmd)\n        for i in xrange(length):\n            yield str(conf.lib.clang_CompileCommand_getArg(self.cmd, i))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a CompilationDatabase from the database found in buildDir.", "response": "def fromDirectory(buildDir):\n        \"\"\"Builds a CompilationDatabase from the database found in buildDir\"\"\"\n        errorCode = c_uint()\n        try:\n            cdb = conf.lib.clang_CompilationDatabase_fromDirectory(buildDir,\n                byref(errorCode))\n        except CompilationDatabaseError as e:\n            raise CompilationDatabaseError(int(errorCode.value),\n                                           \"CompilationDatabase loading failed\")\n        return cdb"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_translations(unique_name, node):\n    '''\n    Compute and store the title that should be displayed\n    when linking to a given unique_name, eg in python\n    when linking to test_greeter_greet() we want to display\n    Test.Greeter.greet\n    '''\n    introspectable = not node.attrib.get('introspectable') == '0'\n\n    if node.tag == core_ns('member'):\n        __TRANSLATED_NAMES['c'][unique_name] = unique_name\n        if introspectable:\n            components = get_gi_name_components(node)\n            components[-1] = components[-1].upper()\n            gi_name = '.'.join(components)\n            __TRANSLATED_NAMES['python'][unique_name] = gi_name\n            __TRANSLATED_NAMES['javascript'][unique_name] = gi_name\n    elif c_ns('identifier') in node.attrib:\n        __TRANSLATED_NAMES['c'][unique_name] = unique_name\n        if introspectable:\n            components = get_gi_name_components(node)\n            gi_name = '.'.join(components)\n            __TRANSLATED_NAMES['python'][unique_name] = gi_name\n            components[-1] = 'prototype.%s' % components[-1]\n            __TRANSLATED_NAMES['javascript'][unique_name] = '.'.join(components)\n    elif c_ns('type') in node.attrib:\n        components = get_gi_name_components(node)\n        gi_name = '.'.join(components)\n        __TRANSLATED_NAMES['c'][unique_name] = unique_name\n        if introspectable:\n            __TRANSLATED_NAMES['javascript'][unique_name] = gi_name\n            __TRANSLATED_NAMES['python'][unique_name] = gi_name\n    elif node.tag == core_ns('field'):\n        components = []\n        get_field_c_name_components(node, components)\n        display_name = '.'.join(components[1:])\n        __TRANSLATED_NAMES['c'][unique_name] = display_name\n        if introspectable:\n            __TRANSLATED_NAMES['javascript'][unique_name] = display_name\n            __TRANSLATED_NAMES['python'][unique_name] = display_name\n    elif node.tag == core_ns('virtual-method'):\n        display_name = node.attrib['name']\n        __TRANSLATED_NAMES['c'][unique_name] = display_name\n        if introspectable:\n            __TRANSLATED_NAMES['javascript'][unique_name] = 'vfunc_%s' % display_name\n            __TRANSLATED_NAMES['python'][unique_name] = 'do_%s' % display_name\n    elif node.tag == core_ns('property'):\n        display_name = node.attrib['name']\n        __TRANSLATED_NAMES['c'][unique_name] = display_name\n        if introspectable:\n            __TRANSLATED_NAMES['javascript'][unique_name] = display_name\n            __TRANSLATED_NAMES['python'][unique_name] = display_name.replace('-', '_')\n    else:\n        __TRANSLATED_NAMES['c'][unique_name] = node.attrib.get('name')\n        if introspectable:\n            __TRANSLATED_NAMES['python'][unique_name] = node.attrib.get('name')\n            __TRANSLATED_NAMES['javascript'][unique_name] = node.attrib.get('name')", "response": "Compute and store the title that should be displayed by linking to a given unique_name eg in python\n    Test. Greeter. greet\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_klass_parents(gi_name):\n    '''\n    Returns a sorted list of qualified symbols representing\n    the parents of the klass-like symbol named gi_name\n    '''\n    res = []\n    parents = __HIERARCHY_GRAPH.predecessors(gi_name)\n    if not parents:\n        return []\n    __get_parent_link_recurse(parents[0], res)\n    return res", "response": "Returns a sorted list of qualified symbols representing\n    the parents of the klass - like symbol named gi_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_klass_children(gi_name):\n    '''\n    Returns a dict of qualified symbols representing\n    the children of the klass-like symbol named gi_name\n    '''\n    res = {}\n    children = __HIERARCHY_GRAPH.successors(gi_name)\n    for gi_name in children:\n        ctype_name = ALL_GI_TYPES[gi_name]\n        qs = QualifiedSymbol(type_tokens=[Link(None, ctype_name, ctype_name)])\n        qs.add_extension_attribute ('gi-extension', 'type_desc',\n                SymbolTypeDesc([], gi_name, ctype_name, 0))\n        res[ctype_name] = qs\n    return res", "response": "Returns a dict of qualified symbols representing\n    the children of the klass - like symbol named gi_name\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cache_nodes(gir_root, all_girs):\n    '''\n    Identify and store all the gir symbols the symbols we will document\n    may link to, or be typed with\n    '''\n    ns_node = gir_root.find('./{%s}namespace' % NS_MAP['core'])\n    id_prefixes = ns_node.attrib['{%s}identifier-prefixes' % NS_MAP['c']]\n    sym_prefixes = ns_node.attrib['{%s}symbol-prefixes' % NS_MAP['c']]\n\n    id_key = '{%s}identifier' % NS_MAP['c']\n    for node in gir_root.xpath(\n            './/*[@c:identifier]',\n            namespaces=NS_MAP):\n        make_translations (node.attrib[id_key], node)\n\n    id_type = c_ns('type')\n    glib_type = glib_ns('type-name')\n    class_tag = core_ns('class')\n    callback_tag = core_ns('callback')\n    interface_tag = core_ns('interface')\n    for node in gir_root.xpath('.//*[not(self::core:type) and not (self::core:array)][@c:type or @glib:type-name]',\n            namespaces=NS_MAP):\n        try:\n            name = node.attrib[id_type]\n        except KeyError:\n            name = node.attrib[glib_type]\n        make_translations (name, node)\n        gi_name = '.'.join(get_gi_name_components(node))\n        ALL_GI_TYPES[gi_name] = get_klass_name(node)\n        if node.tag in (class_tag, interface_tag):\n            __update_hierarchies (ns_node.attrib.get('name'), node, gi_name)\n            make_translations('%s::%s' % (name, name), node)\n            __generate_smart_filters(id_prefixes, sym_prefixes, node)\n        elif node.tag in (callback_tag,):\n            ALL_CALLBACK_TYPES.add(node.attrib[c_ns('type')])\n\n    for field in gir_root.xpath('.//self::core:field', namespaces=NS_MAP):\n        unique_name = get_field_c_name(field)\n        make_translations(unique_name, field)\n\n    for node in gir_root.xpath(\n            './/core:property',\n            namespaces=NS_MAP):\n        name = '%s:%s' % (get_klass_name(node.getparent()),\n                          node.attrib['name'])\n        make_translations (name, node)\n\n    for node in gir_root.xpath(\n            './/glib:signal',\n            namespaces=NS_MAP):\n        name = '%s::%s' % (get_klass_name(node.getparent()),\n                           node.attrib['name'])\n        make_translations (name, node)\n\n    for node in gir_root.xpath(\n            './/core:virtual-method',\n            namespaces=NS_MAP):\n        name = get_symbol_names(node)[0]\n        make_translations (name, node)\n\n    for inc in gir_root.findall('./core:include',\n            namespaces = NS_MAP):\n        inc_name = inc.attrib[\"name\"]\n        inc_version = inc.attrib[\"version\"]\n        gir_file = __find_gir_file('%s-%s.gir' % (inc_name, inc_version), all_girs)\n        if not gir_file:\n            warn('missing-gir-include', \"Couldn't find a gir for %s-%s.gir\" %\n                    (inc_name, inc_version))\n            continue\n\n        if gir_file in __PARSED_GIRS:\n            continue\n\n        __PARSED_GIRS.add(gir_file)\n        inc_gir_root = etree.parse(gir_file).getroot()\n        cache_nodes(inc_gir_root, all_girs)", "response": "Identify and store all the gir symbols that we will link to or may link to or may link to."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a typed node returns a usable description", "response": "def type_description_from_node(gi_node):\n    '''\n    Parse a typed node, returns a usable description\n    '''\n    ctype_name, gi_name, array_nesting = unnest_type (gi_node)\n\n    cur_ns = get_namespace(gi_node)\n\n    if ctype_name is not None:\n        type_tokens = __type_tokens_from_cdecl (ctype_name)\n    else:\n        type_tokens = __type_tokens_from_gitype (cur_ns, gi_name)\n\n    namespaced = '%s.%s' % (cur_ns, gi_name)\n    if namespaced in ALL_GI_TYPES:\n        gi_name = namespaced\n\n    return SymbolTypeDesc(type_tokens, gi_name, ctype_name, array_nesting)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the given node is introspectable in the given language.", "response": "def is_introspectable(name, language):\n    '''\n    Do not call this before caching the nodes\n    '''\n    if name in FUNDAMENTALS[language]:\n        return True\n\n    if name not in __TRANSLATED_NAMES[language]:\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a dictionary to a list of html attributes.", "response": "def dict_to_html_attrs(dict_):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    res = ' '.join('%s=\"%s\"' % (k, v) for k, v in dict_.items())\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef title(self):\n        resolved_title = Link.resolving_title_signal(self)\n        resolved_title = [elem for elem in resolved_title if elem is not\n                          None]\n        if resolved_title:\n            return str(resolved_title[0])\n        return self._title", "response": "Return the title of the link."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the link and the attributes of the link.", "response": "def get_link(self, link_resolver):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        res = link_resolver.resolving_link_signal(self)\n        if not res:\n            return self.ref, None\n        ref = res[0] or self.ref\n        if res[1]:\n            return ref, dict_to_html_attrs(res[1])\n        return ref, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a link to the set.", "response": "def add_link(self, link):\n        \"\"\"\n        Banana banana\n        \"\"\"\n        if link.id_ not in self.__links:\n            self.__links[link.id_] = link"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upsert_link(self, link, overwrite_ref=False):\n        elink = self.__links.get(link.id_)\n\n        if elink:\n            if elink.ref is None or overwrite_ref and link.ref:\n                elink.ref = link.ref\n            # pylint: disable=protected-access\n            if link._title is not None:\n                # pylint: disable=protected-access\n                elink.title = link._title\n            return elink\n\n        if not overwrite_ref:\n            sym = self.__doc_db.get_symbol(link.id_)\n            if sym and sym.link:\n                self.__links[link.id_] = sym.link\n                return sym.link\n\n        self.add_link(link)\n        return link", "response": "Upserts a link in the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the file in the include_paths list.", "response": "def find_file(filename, include_paths):\n    \"\"\"Banana banana\n    \"\"\"\n    if os.path.isabs(filename):\n        if os.path.exists(filename):\n            return filename\n        return None\n\n    for include_path in include_paths:\n        fpath = os.path.join(include_path, filename)\n        if os.path.exists(fpath) and os.path.isfile(fpath):\n            return fpath\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve(uri, include_paths):\n    include_filename, line_ranges, symbol = __parse_include(uri)\n    if include_filename is None:\n        return None\n    include_path = find_file(include_filename, include_paths)\n    if include_path is None:\n        return None\n    return __get_content(include_path.strip(),\n                         line_ranges, symbol)", "response": "Resolve a URI into a base64 encoded version of the content."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_config_json(conf_file):\n    try:\n        with open(conf_file) as _:\n            try:\n                json_conf = json.load(_)\n            except ValueError as ze_error:\n                error('invalid-config',\n                      'The provided configuration file %s is not valid json.\\n'\n                      'The exact error was %s.\\n'\n                      'This often happens because of missing or extra commas, '\n                      'but it may be something else, please fix it!\\n' %\n                      (conf_file, str(ze_error)))\n\n    except FileNotFoundError:\n        json_conf = {}\n    except IOError as _err:\n        error('setup-issue',\n              'Passed config file %s could not be opened (%s)' %\n              (conf_file, _err))\n\n    return json_conf", "response": "Load a json file into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all the markdown files in a folder recursively.", "response": "def get_markdown_files(self, dir_):\n        \"\"\"\n        Get all the markdown files in a folder, recursively\n\n        Args:\n            dir_: str, a toplevel folder to walk.\n        \"\"\"\n        md_files = OrderedSet()\n        for root, _, files in os.walk(dir_):\n            for name in files:\n                split = os.path.splitext(name)\n                if len(split) == 1:\n                    continue\n                if split[1] in ('.markdown', '.md', '.yaml'):\n                    md_files.add(os.path.join(root, name))\n        return md_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, key, default=None):\n        if key in self.__cli:\n            return self.__cli[key]\n        if key in self.__config:\n            return self.__config.get(key)\n        if key in self.__defaults:\n            return self.__defaults.get(key)\n        return default", "response": "Get the value for the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_index(self, prefix=''):\n        if prefix:\n            prefixed = '%s_index' % prefix\n        else:\n            prefixed = 'index'\n\n        if prefixed in self.__cli and self.__cli[prefixed]:\n            index = self.__cli.get(prefixed)\n            from_conf = False\n        else:\n            index = self.__config.get(prefixed)\n            from_conf = True\n\n        return self.__abspath(index, from_conf)", "response": "Retrieve the absolute path to an index according to the specified prefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_path(self, key, rel_to_cwd=False, rel_to_conf=False):\n        if key in self.__cli:\n            path = self.__cli[key]\n            from_conf = False\n        else:\n            path = self.__config.get(key)\n            from_conf = True\n\n        if not isinstance(path, str):\n            return None\n\n        res = self.__abspath(path, from_conf)\n\n        if rel_to_cwd:\n            return os.path.relpath(res, self.__invoke_dir)\n        if rel_to_conf:\n            return os.path.relpath(res, self.__conf_dir)\n\n        return self.__abspath(path, from_conf)", "response": "Retrieve a path from the config file or the command - line."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sources(self, prefix=''):\n        prefix = prefix.replace('-', '_')\n        prefixed = '%s_sources' % prefix\n\n        if prefixed in self.__cli:\n            sources = self.__cli.get(prefixed)\n            from_conf = False\n        else:\n            sources = self.__config.get(prefixed)\n            from_conf = True\n\n        if sources is None:\n            return OrderedSet()\n\n        sources = self.__resolve_patterns(sources, from_conf)\n\n        prefixed = '%s_source_filters' % prefix\n        if prefixed in self.__cli:\n            filters = self.__cli.get(prefixed)\n            from_conf = False\n        else:\n            filters = self.__config.get(prefixed)\n            from_conf = True\n\n        if filters is None:\n            return sources\n\n        sources -= self.__resolve_patterns(filters, from_conf)\n\n        return sources", "response": "Retrieves a set of absolute paths to sources according to the given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the set of all dependencies for a given configuration.", "response": "def get_dependencies(self):\n        \"\"\"\n        Retrieve the set of all dependencies for a given configuration.\n\n        Returns:\n            utils.utils.OrderedSet: The set of all dependencies for the\n                tracked configuration.\n        \"\"\"\n        all_deps = OrderedSet()\n        for key, _ in list(self.__config.items()):\n            if key in self.__cli:\n                continue\n\n            if key.endswith('sources'):\n                all_deps |= self.get_sources(key[:len('sources') * -1 - 1])\n\n        for key, _ in list(self.__cli.items()):\n            if key.endswith('sources'):\n                all_deps |= self.get_sources(key[:len('sources') * -1 - 1])\n\n        if self.conf_file is not None:\n            all_deps.add(self.conf_file)\n\n        all_deps.add(self.get_path(\"sitemap\", rel_to_cwd=True))\n\n        cwd = os.getcwd()\n        return [os.path.relpath(fname, cwd) for fname in all_deps if fname]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump the configuration to a file.", "response": "def dump(self, conf_file=None):\n        \"\"\"\n        Dump the possibly updated config to a file.\n\n        Args:\n            conf_file: str, the destination, or None to overwrite the\n                existing configuration.\n        \"\"\"\n\n        if conf_file:\n            conf_dir = os.path.dirname(conf_file)\n            if not conf_dir:\n                conf_dir = self.__invoke_dir\n            elif not os.path.exists(conf_dir):\n                os.makedirs(conf_dir)\n        else:\n            conf_dir = self.__conf_dir\n\n        final_conf = {}\n        for key, value in list(self.__config.items()):\n            if key in self.__cli:\n                continue\n            final_conf[key] = value\n\n        for key, value in list(self.__cli.items()):\n            if key.endswith('index') or key in ['sitemap', 'output']:\n                path = self.__abspath(value, from_conf=False)\n                if path:\n                    relpath = os.path.relpath(path, conf_dir)\n                    final_conf[key] = relpath\n            elif key.endswith('sources') or key.endswith('source_filters'):\n                new_list = []\n                for path in value:\n                    path = self.__abspath(path, from_conf=False)\n                    if path:\n                        relpath = os.path.relpath(path, conf_dir)\n                        new_list.append(relpath)\n                final_conf[key] = new_list\n            elif key not in ['command', 'output_conf_file']:\n                final_conf[key] = value\n\n        with open(conf_file or self.conf_file or 'hotdoc.json', 'w') as _:\n            _.write(json.dumps(final_conf, sort_keys=True, indent=4))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_submodule_status(root, submodules):\n\n    if hasattr(sys, \"frozen\"):\n        # frozen via py2exe or similar, don't bother\n        return 'clean'\n\n    if not os.path.exists(os.path.join(root, '.git')):\n        # not in git, assume clean\n        return 'clean'\n\n    for submodule in submodules:\n        if not os.path.exists(submodule):\n            return 'missing'\n\n    # Popen can't handle unicode cwd on Windows Python 2\n    if sys.platform == 'win32' and sys.version_info[0] < 3 \\\n            and not isinstance(root, bytes):\n        root = root.encode(sys.getfilesystemencoding() or 'ascii')\n    # check with git submodule status\n    proc = subprocess.Popen('git submodule status',\n                            stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE,\n                            shell=True,\n                            cwd=root)\n    status, _ = proc.communicate()\n    status = status.decode(\"ascii\", \"replace\")\n\n    for line in status.splitlines():\n        if line.startswith('-'):\n            return 'missing'\n        elif line.startswith('+'):\n            return 'unclean'\n\n    return 'clean'", "response": "check if a submodule is present and if so return its status"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_submodules(repo_dir):\n    subprocess.check_call(\"git submodule init\", cwd=repo_dir, shell=True)\n    subprocess.check_call(\n        \"git submodule update --recursive\", cwd=repo_dir, shell=True)", "response": "update submodules in a repo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef require_clean_submodules(repo_root, submodules):\n    # PACKAGERS: Add a return here to skip checks for git submodules\n\n    # don't do anything if nothing is actually supposed to happen\n    for do_nothing in (\n            '-h', '--help', '--help-commands', 'clean', 'submodule'):\n        if do_nothing in sys.argv:\n            return\n\n    status = _check_submodule_status(repo_root, submodules)\n\n    if status == \"missing\":\n        print(\"checking out submodules for the first time\")\n        _update_submodules(repo_root)\n    elif status == \"unclean\":\n        print(UNCLEAN_SUBMODULES_MSG)", "response": "Check on git submodules before distutils can do anything"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef symlink(source, link_name):\n    if os.path.islink(link_name) and os.readlink(link_name) == source:\n        return\n\n    os_symlink = getattr(os, \"symlink\", None)\n    if callable(os_symlink):\n        os_symlink(source, link_name)\n    else:\n        import ctypes\n        csl = ctypes.windll.kernel32.CreateSymbolicLinkW\n        csl.argtypes = (ctypes.c_wchar_p, ctypes.c_wchar_p, ctypes.c_uint32)\n        csl.restype = ctypes.c_ubyte\n        flags = 1 if os.path.isdir(source) else 0\n        if csl(link_name, source, flags) == 0:\n            raise ctypes.WinError()", "response": "Create a symbolic link on Windows."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pkgconfig(*packages, **kw):\n    config = kw.setdefault('config', {})\n    optional_args = kw.setdefault('optional', '')\n\n    # { <distutils Extension arg>: [<pkg config option>, <prefix length to strip>], ...}\n    flag_map = {'include_dirs': ['--cflags-only-I', 2],\n                'library_dirs': ['--libs-only-L', 2],\n                'libraries': ['--libs-only-l', 2],\n                'extra_compile_args': ['--cflags-only-other', 0],\n                'extra_link_args': ['--libs-only-other', 0],\n                }\n    for package in packages:\n        for distutils_key, (pkg_option, n) in flag_map.items():\n            items = subprocess.check_output(['pkg-config', optional_args, pkg_option, package]).decode('utf8').split()\n            config.setdefault(distutils_key, []).extend([i[n:] for i in items])\n    return config", "response": "Query pkg - config for library compile and linking options. Return configuration in distutils\n    Extension format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_error_code(code, exception_type, domain='core'):\n        Logger._error_code_to_exception[code] = (exception_type, domain)\n        Logger._domain_codes[domain].add(code)", "response": "Register a new error code"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a new warning code", "response": "def register_warning_code(code, exception_type, domain='core'):\n        \"\"\"Register a new warning code\"\"\"\n        Logger._warning_code_to_exception[code] = (exception_type, domain)\n        Logger._domain_codes[domain].add(code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an entry to the journal", "response": "def _log(code, message, level, domain):\n        \"\"\"Call this to add an entry in the journal\"\"\"\n        entry = LogEntry(level, domain, code, message)\n        Logger.journal.append(entry)\n\n        if Logger.silent:\n            return\n\n        if level >= Logger._verbosity:\n            _print_entry(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nraises an exception and have it stored in the journal", "response": "def error(code, message, **kwargs):\n        \"\"\"Call this to raise an exception and have it stored in the journal\"\"\"\n        assert code in Logger._error_code_to_exception\n        exc_type, domain = Logger._error_code_to_exception[code]\n        exc = exc_type(message, **kwargs)\n        Logger._log(code, exc.message, ERROR, domain)\n        raise exc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef warn(code, message, **kwargs):\n\n        if code in Logger._ignored_codes:\n            return\n\n        assert code in Logger._warning_code_to_exception\n        exc_type, domain = Logger._warning_code_to_exception[code]\n\n        if domain in Logger._ignored_domains:\n            return\n\n        level = WARNING\n        if Logger.fatal_warnings:\n            level = ERROR\n\n        exc = exc_type(message, **kwargs)\n\n        Logger._log(code, exc.message, level, domain)\n\n        if Logger.fatal_warnings:\n            raise exc", "response": "Store a warning in the journal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(message, domain):\n        if domain in Logger._ignored_domains:\n            return\n\n        Logger._log(None, message, INFO, domain)", "response": "Log an info message."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets actual issues in the journal.", "response": "def get_issues():\n        \"\"\"Get actual issues in the journal.\"\"\"\n        issues = []\n        for entry in Logger.journal:\n            if entry.level >= WARNING:\n                issues.append(entry)\n        return issues"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset():\n        Logger.journal = []\n        Logger.fatal_warnings = False\n        Logger._ignored_codes = set()\n        Logger._ignored_domains = set()\n        Logger._verbosity = 2\n        Logger._last_checkpoint = 0", "response": "Resets the Logger to its initial state."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the verbosity of the log file.", "response": "def set_verbosity(verbosity):\n        \"\"\"Banana banana\n        \"\"\"\n        Logger._verbosity = min(max(0, WARNING - verbosity), 2)\n        debug(\"Verbosity set to %d\" % (WARNING - Logger._verbosity), 'logging')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwalking the hierarchy applying action to each filename.", "response": "def walk(self, action, user_data=None):\n        \"\"\"\n        Walk the hierarchy, applying action to each filename.\n\n        Args:\n            action: callable, the callable to invoke for each filename,\n                will be invoked with the filename, the subfiles, and\n                the level in the sitemap.\n        \"\"\"\n        action(self.index_file, self.__root, 0, user_data)\n        self.__do_walk(self.__root, 1, action, user_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_sources(self):\n        if self.__all_sources is None:\n            self.__all_sources = OrderedDict()\n            self.walk(self.__add_one)\n        return self.__all_sources", "response": "Returns a OrderedDict of all source file names in the hierarchy paired with\n                the names of their subpages."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a sitemap file.", "response": "def parse(self, filename):\n        \"\"\"\n        Parse a sitemap file.\n\n        Args:\n            filename: str, the path to the sitemap file.\n\n        Returns:\n            Sitemap: the generated sitemap.\n        \"\"\"\n        with io.open(filename, 'r', encoding='utf-8') as _:\n            lines = _.readlines()\n\n        all_source_files = set()\n        source_map = {}\n\n        lineno = 0\n        root = None\n        index = None\n        cur_level = -1\n        parent_queue = []\n\n        for line in lines:\n            try:\n                level, line = dedent(line)\n                if line.startswith('#'):\n                    lineno += 1\n                    continue\n                elif line.startswith('\\\\#'):\n                    line = line[1:]\n            except IndentError as exc:\n                error('bad-indent', 'Invalid indentation', filename=filename,\n                      lineno=lineno, column=exc.column)\n\n            if not line:\n                lineno += 1\n                continue\n\n            source_file = dequote(line)\n\n            if not source_file:\n                lineno += 1\n                continue\n\n            if source_file in all_source_files:\n                error('sitemap-duplicate', 'Filename listed twice',\n                      filename=filename, lineno=lineno, column=level * 8 + 1)\n\n            all_source_files.add(source_file)\n            source_map[source_file] = (lineno, level * 8 + 1)\n\n            page = OrderedDict()\n\n            if root is not None and level == 0:\n                error('sitemap-error', 'Sitemaps only support one root',\n                      filename=filename, lineno=lineno, column=0)\n\n            if root is None:\n                root = page\n                index = source_file\n            else:\n                lvl_diff = cur_level - level\n                while lvl_diff >= 0:\n                    parent_queue.pop()\n                    lvl_diff -= 1\n\n                parent_queue[-1][source_file] = page\n\n            parent_queue.append(page)\n\n            cur_level = level\n\n            lineno += 1\n\n        return Sitemap(root, filename, index, source_map)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngroup iterable into n_args elements.", "response": "def _grouper(iterable, n_args, fillvalue=None):\n    \"\"\"\n    Banana banana\n    \"\"\"\n    args = [iter(iterable)] * n_args\n    return zip_longest(*args, fillvalue=fillvalue)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a comment and returns a Comment object", "response": "def parse_comment(self, comment, filename, lineno, endlineno,\n                      include_paths=None, stripped=False):\n        \"\"\"\n        Returns a Comment given a string\n        \"\"\"\n        if not stripped and not self.__validate_c_comment(comment.strip()):\n            return None\n\n        title_offset = 0\n\n        column_offset = 0\n\n        raw_comment = comment\n        if not stripped:\n            try:\n                while comment[column_offset * -1 - 1] != '\\n':\n                    column_offset += 1\n            except IndexError:\n                column_offset = 0\n            comment, title_offset = self.__strip_comment(comment)\n\n        title_and_params, description = self.__extract_titles_params_and_description(comment)\n        try:\n            block_name, parameters, annotations, is_section = \\\n                self.__parse_title_and_parameters(filename, title_and_params)\n        except HotdocSourceException as _:\n            warn('gtk-doc-bad-syntax',\n                 message=_.message,\n                 filename=filename,\n                 lineno=lineno + title_offset)\n            return None\n\n        params_offset = 0\n        for param in parameters:\n            param.filename = filename\n            param.lineno = lineno\n            param_offset = param.line_offset\n            param.line_offset = title_offset + params_offset + 1\n            params_offset += param_offset\n            param.col_offset = column_offset\n\n        if not block_name:\n            return None\n\n        description_offset = 0\n        meta = {}\n        tags = []\n        if description is not None:\n            n_lines = len(comment.split('\\n'))\n            description_offset = (title_offset + n_lines -\n                                  len(description.split('\\n')))\n            meta['description'], tags = self.__parse_description_and_tags(description)\n\n        actual_parameters = OrderedDict({})\n        for param in parameters:\n            if is_section:\n                cleaned_up_name = param.name.lower().replace('_', '-')\n                if cleaned_up_name in ['symbols', 'private-symbols', 'auto-sort', 'sources']:\n                    meta.update(self.__parse_yaml_comment(param, filename))\n                    if cleaned_up_name == 'sources':\n                        sources_paths = [os.path.abspath(os.path.join(os.path.dirname(filename), path)) for path in meta[cleaned_up_name]]\n                        meta[cleaned_up_name] = sources_paths\n                else:\n                    meta[param.name] = param.description\n            else:\n                actual_parameters[param.name] = param\n\n        annotations = {annotation.name: annotation for annotation in\n                       annotations}\n        tags = {tag.name.lower(): tag for tag in tags}\n\n        block = Comment(name=block_name, filename=filename, lineno=lineno,\n                        endlineno=endlineno,\n                        annotations=annotations, params=actual_parameters,\n                        tags=tags, raw_comment=raw_comment,\n                        meta=meta, toplevel=is_section)\n        block.line_offset = description_offset\n        block.col_offset = column_offset\n\n        return block"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a gtk - doc comment string returns an AST containing the document root.", "response": "def comment_to_ast(self, comment, link_resolver):\n        \"\"\"\n        Given a gtk-doc comment string, returns an opaque PyCapsule\n        containing the document root.\n\n        This is an optimization allowing to parse the docstring only\n        once, and to render it multiple times with\n        `ast_to_html`, links discovery and\n        most of the link resolution being lazily done in that second phase.\n\n        If you don't care about performance, you should simply\n        use `translate`.\n\n        Args:\n            text: unicode, the docstring to parse.\n            link_resolver: hotdoc.core.links.LinkResolver, an object\n                which will be called to retrieve `hotdoc.core.links.Link`\n                objects.\n\n        Returns:\n            capsule: A PyCapsule wrapping an opaque C pointer, which\n                can be passed to `ast_to_html`\n                afterwards.\n            diagnostics: A list of diagnostics as output by the gtk-doc cmark\n                extension\n        \"\"\"\n        assert comment is not None\n\n        text = comment.description\n\n        if (self.remove_xml_tags or comment.filename in\n                self.gdbus_codegen_sources):\n            text = re.sub('<.*?>', '', text)\n\n        if self.escape_html:\n            # pylint: disable=deprecated-method\n            text = cgi.escape(text)\n        ast, diagnostics = cmark.gtkdoc_to_ast(text, link_resolver)\n\n        for diag in diagnostics:\n            if (comment.filename and comment.filename not in\n                    self.gdbus_codegen_sources):\n                column = diag.column + comment.col_offset\n                if diag.lineno == 0:\n                    column += comment.initial_col_offset\n\n                lines = text.split('\\n')\n                line = lines[diag.lineno]\n                i = 0\n                while line[i] == ' ':\n                    i += 1\n                column += i - 1\n\n                if diag.lineno > 0 and any([c != ' ' for c in\n                                            lines[diag.lineno - 1]]):\n                    column += 1\n\n                lineno = -1\n                if comment.lineno != -1:\n                    lineno = (comment.lineno - 1 + comment.line_offset +\n                              diag.lineno)\n                warn(\n                    diag.code,\n                    message=diag.message,\n                    filename=comment.filename,\n                    lineno=lineno,\n                    column=column)\n\n        return ast"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a PyCapsule object to HTML.", "response": "def ast_to_html(self, ast, link_resolver):\n        \"\"\"\n        See the documentation of `to_ast` for\n        more information.\n\n        Args:\n            ast: PyCapsule, a capsule as returned by `to_ast`\n            link_resolver: hotdoc.core.links.LinkResolver, a link\n                resolver instance.\n        \"\"\"\n        out, _ = cmark.ast_to_html(ast, link_resolver)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a gtk - doc comment string returns the translated comment in the desired format.", "response": "def translate_comment(self, comment, link_resolver):\n        \"\"\"\n        Given a gtk-doc comment string, returns the comment translated\n        to the desired format.\n        \"\"\"\n        out = u''\n\n        self.translate_tags(comment, link_resolver)\n        ast = self.comment_to_ast(comment, link_resolver)\n        out += self.ast_to_html(ast, link_resolver)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate the tags in a comment to HTML.", "response": "def translate_tags(self, comment, link_resolver):\n        \"\"\"Banana banana\n        \"\"\"\n        for tname in ('deprecated',):\n            tag = comment.tags.get(tname)\n            if tag is not None and tag.description:\n                comment = comment_from_tag(tag)\n                ast = self.comment_to_ast(comment, link_resolver)\n                tag.description = self.ast_to_html(ast, link_resolver) or ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the config and set the attributes", "response": "def parse_config(self, config):\n        \"\"\"Banana banana\n        \"\"\"\n        self.remove_xml_tags = config.get('gtk_doc_remove_xml')\n        self.escape_html = config.get('gtk_doc_escape_html')\n        self.gdbus_codegen_sources = config.get_paths('gdbus_codegen_sources')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_extension_attribute(self, ext_name, key, value):\n        attributes = self.extension_attributes.pop(ext_name, {})\n        attributes[key] = value\n        self.extension_attributes[ext_name] = attributes", "response": "Adds an attribute to the extension_attributes dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_extension_attribute(self, ext_name, key):\n        attributes = self.extension_attributes.get(ext_name)\n        if not attributes:\n            return None\n        return attributes.get(key)", "response": "Get the attribute of an extension."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_children_comments(self):\n        if self.comment is None:\n            return\n\n        for sym in self.get_children_symbols():\n            if isinstance(sym, ParameterSymbol):\n                sym.comment = self.comment.params.get(sym.argname)\n            elif isinstance(sym, FieldSymbol):\n                if not sym.comment or not sym.comment.description:\n                    sym.comment = self.comment.params.get(sym.member_name)\n            elif isinstance(sym, EnumMemberSymbol):\n                if not sym.comment or not sym.comment.description:\n                    sym.comment = self.comment.params.get(sym.unique_name)\n            elif isinstance(sym, ReturnItemSymbol):\n                tag = self.comment.tags.get('returns')\n                sym.comment = comment_from_tag(tag)\n            elif type(sym) == Symbol:\n                sym.comment = self.comment.params.get(sym.display_name)", "response": "Updates the comment of the children symbols."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_links(self, link_resolver):\n        if self.link is None:\n            self.link = Link(self.unique_name, self._make_name(),\n                             self.unique_name)\n\n        self.link = link_resolver.upsert_link(self.link, overwrite_ref=True)\n\n        for sym in self.get_children_symbols():\n            if sym:\n                sym.resolve_links(link_resolver)", "response": "Resolve links for this entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_links(self, link_resolver):\n        self.type_link = None\n        self.type_tokens = []\n\n        for child in self.get_children_symbols():\n            child.resolve_links(link_resolver)\n\n        for tok in self.input_tokens:\n            if isinstance(tok, Link):\n                self.type_link = link_resolver.upsert_link(tok)\n                self.type_tokens.append(self.type_link)\n            else:\n                self.type_tokens.append(tok)", "response": "Resolves links in the source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef comment_from_tag(tag):\n    if not tag:\n        return None\n    comment = Comment(name=tag.name,\n                      meta={'description': tag.description},\n                      annotations=tag.annotations)\n    return comment", "response": "Create a full - fledged comment for a given tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a sequence of bytes to a unicode text and length using Modified UTF-8. This function is designed to be used with Python ``codecs`` module. :param data: a string of bytes in Modified UTF-8 :param errors: handle decoding errors :return: unicode text and length :raises UnicodeDecodeError: sequence is invalid.", "response": "def decode_modified_utf8(data, errors=\"strict\"):\n    \"\"\"\n    Decodes a sequence of bytes to a unicode text and length using\n    Modified UTF-8.\n    This function is designed to be used with Python ``codecs`` module.\n\n    :param data: a string of bytes in Modified UTF-8\n    :param errors: handle decoding errors\n    :return: unicode text and length\n    :raises UnicodeDecodeError: sequence is invalid.\n    \"\"\"\n    value, length = u\"\", 0\n    it = iter(decoder(data))\n    while True:\n        try:\n            value += next(it)\n            length += 1\n        except StopIteration:\n            break\n        except UnicodeDecodeError as e:\n            if errors == \"strict\":\n                raise e\n            elif errors == \"ignore\":\n                pass\n            elif errors == \"replace\":\n                value += u\"\\uFFFD\"\n                length += 1\n    return value, length"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply mask compare to expected value shift and return result.", "response": "def apply(self, byte, value, data, i, count):\n        \"\"\"\n        Apply mask, compare to expected value, shift and return result.\n        Eventually, this could become a ``reduce`` function.\n\n        :param byte: The byte to compare\n        :param value: The currently accumulated value.\n        :param data: The data buffer, (array of bytes).\n        :param i: The position within the data buffer.\n        :param count: The position of this comparison.\n        :return: A new value with the bits merged in.\n        :raises UnicodeDecodeError: if marked bits don't match.\n        \"\"\"\n        if byte & self.mask == self.value:\n            value <<= self.bits\n            value |= byte & self.mask2\n        else:\n            raise UnicodeDecodeError(\n                NAME, data, i, i + count, \"invalid {}-byte sequence\".format(self.count)\n            )\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loads(string, *transformers, **kwargs):\n    # Read keyword argument\n    ignore_remaining_data = kwargs.get(\"ignore_remaining_data\", False)\n\n    # Reuse the load method (avoid code duplication)\n    return load(\n        BytesIO(string), *transformers, ignore_remaining_data=ignore_remaining_data\n    )", "response": "Deserializes Java objects and primitive data serialized using\n    ObjectOutputStream from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nserializes a Python primitive object into a string.", "response": "def dumps(obj, *transformers):\n    \"\"\"\n    Serializes Java primitive data and objects unmarshaled by load(s) before\n    into string.\n\n    :param obj: A Python primitive object, or one loaded using load(s)\n    :param transformers: Custom transformers to use\n    :return: The serialized data as a string\n    \"\"\"\n    marshaller = JavaObjectMarshaller()\n    # Add custom transformers\n    for transformer in transformers:\n        marshaller.add_transformer(transformer)\n\n    return marshaller.dump(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(data, fmt_str):\n    size = struct.calcsize(fmt_str)\n    return struct.unpack(fmt_str, data[:size]), data[size:]", "response": "Reads input bytes and extracts the given structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_string(data, length_fmt=\"H\"):\n    (length,), data = read(data, \">{0}\".format(length_fmt))\n    ba, data = data[:length], data[length:]\n    return to_unicode(ba), data", "response": "Reads a serialized string from the given bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flags(flags):\n        names = sorted(\n            descr for key, descr in OpCodeDebug.STREAM_CONSTANT.items() if key & flags\n        )\n        return \", \".join(names)", "response": "Returns the names of the class description flags found in the given integer\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _readStreamHeader(self):\n        (magic, version) = self._readStruct(\">HH\")\n        if magic != self.STREAM_MAGIC or version != self.STREAM_VERSION:\n            raise IOError(\n                \"The stream is not java serialized object. \"\n                \"Invalid stream header: {0:04X}{1:04X}\".format(magic, version)\n            )", "response": "Reads the magic header of a Java serialization stream"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_and_exec_opcode(self, ident=0, expect=None):\n        position = self.object_stream.tell()\n        (opid,) = self._readStruct(\">B\")\n        log_debug(\n            \"OpCode: 0x{0:X} -- {1} (at offset 0x{2:X})\".format(\n                opid, OpCodeDebug.op_id(opid), position\n            ),\n            ident,\n        )\n\n        if expect and opid not in expect:\n            raise IOError(\n                \"Unexpected opcode 0x{0:X} -- {1} (at offset 0x{2:X})\".format(\n                    opid, OpCodeDebug.op_id(opid), position\n                )\n            )\n\n        try:\n            handler = self.opmap[opid]\n        except KeyError:\n            raise RuntimeError(\n                \"Unknown OpCode in the stream: 0x{0:X} (at offset 0x{1:X})\".format(\n                    opid, position\n                )\n            )\n        else:\n            return opid, handler(ident=ident)", "response": "Reads the next opcode and executes its handler."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _readString(self, length_fmt=\"H\"):\n        (length,) = self._readStruct(\">{0}\".format(length_fmt))\n        ba = self.object_stream.read(length)\n        return to_unicode(ba)", "response": "Reads a serialized string containing the key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a TC_CLASSDESC opcode", "response": "def do_classdesc(self, parent=None, ident=0):\n        \"\"\"\n        Handles a TC_CLASSDESC opcode\n\n        :param parent:\n        :param ident: Log indentation level\n        :return: A JavaClass object\n        \"\"\"\n        # TC_CLASSDESC className serialVersionUID newHandle classDescInfo\n        # classDescInfo:\n        #   classDescFlags fields classAnnotation superClassDesc\n        # classDescFlags:\n        #   (byte)                 // Defined in Terminal Symbols and Constants\n        # fields:\n        #   (short)<count>  fieldDesc[count]\n\n        # fieldDesc:\n        #   primitiveDesc\n        #   objectDesc\n        # primitiveDesc:\n        #   prim_typecode fieldName\n        # objectDesc:\n        #   obj_typecode fieldName className1\n        clazz = JavaClass()\n        log_debug(\"[classdesc]\", ident)\n        class_name = self._readString()\n        clazz.name = class_name\n        log_debug(\"Class name: %s\" % class_name, ident)\n\n        # serialVersionUID is a Java (signed) long => 8 bytes\n        serialVersionUID, classDescFlags = self._readStruct(\">qB\")\n        clazz.serialVersionUID = serialVersionUID\n        clazz.flags = classDescFlags\n\n        self._add_reference(clazz, ident)\n\n        log_debug(\n            \"Serial: 0x{0:X} / {0:d} - classDescFlags: 0x{1:X} {2}\".format(\n                serialVersionUID, classDescFlags, OpCodeDebug.flags(classDescFlags)\n            ),\n            ident,\n        )\n        (length,) = self._readStruct(\">H\")\n        log_debug(\"Fields num: 0x{0:X}\".format(length), ident)\n\n        clazz.fields_names = []\n        clazz.fields_types = []\n        for fieldId in range(length):\n            (typecode,) = self._readStruct(\">B\")\n            field_name = self._readString()\n            field_type = self._convert_char_to_type(typecode)\n\n            log_debug(\"> Reading field {0}\".format(field_name), ident)\n\n            if field_type == self.TYPE_ARRAY:\n                _, field_type = self._read_and_exec_opcode(\n                    ident=ident + 1, expect=(self.TC_STRING, self.TC_REFERENCE)\n                )\n\n                if type(field_type) is not JavaString:\n                    raise AssertionError(\n                        \"Field type must be a JavaString, \"\n                        \"not {0}\".format(type(field_type))\n                    )\n\n            elif field_type == self.TYPE_OBJECT:\n                _, field_type = self._read_and_exec_opcode(\n                    ident=ident + 1, expect=(self.TC_STRING, self.TC_REFERENCE)\n                )\n\n                if type(field_type) is JavaClass:\n                    # FIXME: ugly trick\n                    field_type = JavaString(field_type.name)\n\n                if type(field_type) is not JavaString:\n                    raise AssertionError(\n                        \"Field type must be a JavaString, \"\n                        \"not {0}\".format(type(field_type))\n                    )\n\n            log_debug(\n                \"< FieldName: 0x{0:X} Name:{1} Type:{2} ID:{3}\".format(\n                    typecode, field_name, field_type, fieldId\n                ),\n                ident,\n            )\n            assert field_name is not None\n            assert field_type is not None\n\n            clazz.fields_names.append(field_name)\n            clazz.fields_types.append(field_type)\n\n        if parent:\n            parent.__fields = clazz.fields_names\n            parent.__types = clazz.fields_types\n\n        # classAnnotation\n        (opid,) = self._readStruct(\">B\")\n        log_debug(\n            \"OpCode: 0x{0:X} -- {1} (classAnnotation)\".format(\n                opid, OpCodeDebug.op_id(opid)\n            ),\n            ident,\n        )\n        if opid != self.TC_ENDBLOCKDATA:\n            raise NotImplementedError(\"classAnnotation isn't implemented yet\")\n\n        # superClassDesc\n        log_debug(\"Reading Super Class of {0}\".format(clazz.name), ident)\n        _, superclassdesc = self._read_and_exec_opcode(\n            ident=ident + 1, expect=(self.TC_CLASSDESC, self.TC_NULL, self.TC_REFERENCE)\n        )\n        log_debug(\n            \"Super Class for {0}: {1}\".format(clazz.name, str(superclassdesc)), ident\n        )\n        clazz.superclass = superclassdesc\n        return clazz"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_string(self, parent=None, ident=0):\n        log_debug(\"[string]\", ident)\n        ba = JavaString(self._readString())\n        self._add_reference(ba, ident)\n        return ba", "response": "Handles a TC_STRING opcode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_array(self, parent=None, ident=0):\n        # TC_ARRAY classDesc newHandle (int)<size> values[size]\n        log_debug(\"[array]\", ident)\n        _, classdesc = self._read_and_exec_opcode(\n            ident=ident + 1,\n            expect=(\n                self.TC_CLASSDESC,\n                self.TC_PROXYCLASSDESC,\n                self.TC_NULL,\n                self.TC_REFERENCE,\n            ),\n        )\n\n        array = JavaArray(classdesc)\n\n        self._add_reference(array, ident)\n\n        (size,) = self._readStruct(\">i\")\n        log_debug(\"size: {0}\".format(size), ident)\n\n        type_char = classdesc.name[0]\n        assert type_char == self.TYPE_ARRAY\n        type_char = classdesc.name[1]\n\n        if type_char == self.TYPE_OBJECT or type_char == self.TYPE_ARRAY:\n            for _ in range(size):\n                _, res = self._read_and_exec_opcode(ident=ident + 1)\n                log_debug(\"Object value: {0}\".format(res), ident)\n                array.append(res)\n        elif type_char == self.TYPE_BYTE:\n            array = JavaByteArray(self.object_stream.read(size), classdesc)\n        elif self.use_numpy_arrays:\n            import numpy\n\n            array = numpy.fromfile(\n                self.object_stream,\n                dtype=JavaObjectConstants.NUMPY_TYPE_MAP[type_char],\n                count=size,\n            )\n        else:\n            for _ in range(size):\n                res = self._read_value(type_char, ident)\n                log_debug(\"Native value: {0}\".format(repr(res)), ident)\n                array.append(res)\n\n        return array", "response": "Handles a TC_ARRAY opcode"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_reference(self, parent=None, ident=0):\n        (handle,) = self._readStruct(\">L\")\n        log_debug(\"## Reference handle: 0x{0:X}\".format(handle), ident)\n        ref = self.references[handle - self.BASE_REFERENCE_IDX]\n        log_debug(\"###-> Type: {0} - Value: {1}\".format(type(ref), ref), ident)\n        return ref", "response": "Handles a TC_REFERENCE opcode"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a TC_ENUM opcode", "response": "def do_enum(self, parent=None, ident=0):\n        \"\"\"\n        Handles a TC_ENUM opcode\n\n        :param parent:\n        :param ident: Log indentation level\n        :return: A JavaEnum object\n        \"\"\"\n        # TC_ENUM classDesc newHandle enumConstantName\n        enum = JavaEnum()\n        _, classdesc = self._read_and_exec_opcode(\n            ident=ident + 1,\n            expect=(\n                self.TC_CLASSDESC,\n                self.TC_PROXYCLASSDESC,\n                self.TC_NULL,\n                self.TC_REFERENCE,\n            ),\n        )\n        enum.classdesc = classdesc\n        self._add_reference(enum, ident)\n        _, enumConstantName = self._read_and_exec_opcode(\n            ident=ident + 1, expect=(self.TC_STRING, self.TC_REFERENCE)\n        )\n        enum.constant = enumConstantName\n        return enum"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_hexdump(src, start_offset=0, length=16):\n        FILTER = \"\".join((len(repr(chr(x))) == 3) and chr(x) or \".\" for x in range(256))\n        pattern = \"{{0:04X}}   {{1:<{0}}}  {{2}}\\n\".format(length * 3)\n\n        # Convert raw data to str (Python 3 compatibility)\n        src = to_str(src, \"latin-1\")\n\n        result = []\n        for i in range(0, len(src), length):\n            s = src[i : i + length]\n            hexa = \" \".join(\"{0:02X}\".format(ord(x)) for x in s)\n            printable = s.translate(FILTER)\n            result.append(pattern.format(i + start_offset, hexa, printable))\n\n        return \"\".join(result)", "response": "Creates a hexadecimal dump string from a binary string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a read character to a typecode.", "response": "def _convert_char_to_type(self, type_char):\n        \"\"\"\n        Ensures a read character is a typecode.\n\n        :param type_char: Read typecode\n        :return: The typecode as a string (using chr)\n        :raise RuntimeError: Unknown typecode\n        \"\"\"\n        typecode = type_char\n        if type(type_char) is int:\n            typecode = chr(type_char)\n\n        if typecode in self.TYPECODES_LIST:\n            return typecode\n        else:\n            raise RuntimeError(\n                \"Typecode {0} ({1}) isn't supported.\".format(type_char, typecode)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_reference(self, obj, ident=0):\n        log_debug(\n            \"## New reference handle 0x{0:X}: {1} -> {2}\".format(\n                len(self.references) + self.BASE_REFERENCE_IDX,\n                type(obj).__name__,\n                repr(obj),\n            ),\n            ident,\n        )\n        self.references.append(obj)", "response": "Adds a read reference to the marshaler storage."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlogging a deserialization error when the Oops state is not available.", "response": "def _oops_dump_state(self, ignore_remaining_data=False):\n        \"\"\"\n        Log a deserialization error\n\n        :param ignore_remaining_data: If True, don't log an error when\n                                      unused trailing bytes are remaining\n        \"\"\"\n        log_error(\"==Oops state dump\" + \"=\" * (30 - 17))\n        log_error(\"References: {0}\".format(self.references))\n        log_error(\"Stream seeking back at -16 byte (2nd line is an actual position!):\")\n\n        # Do not use a keyword argument\n        self.object_stream.seek(-16, os.SEEK_CUR)\n        position = self.object_stream.tell()\n        the_rest = self.object_stream.read()\n\n        if not ignore_remaining_data and len(the_rest):\n            log_error(\n                \"Warning!!!!: Stream still has {0} bytes left:\\n{1}\".format(\n                    len(the_rest), self._create_hexdump(the_rest, position)\n                )\n            )\n\n        log_error(\"=\" * 30)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(self, obj):\n        self.references = []\n        self.object_obj = obj\n        self.object_stream = BytesIO()\n        self._writeStreamHeader()\n        self.writeObject(obj)\n        return self.object_stream.getvalue()", "response": "Dumps the given object in the Java serialization format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting an object to the serialization stream.", "response": "def writeObject(self, obj):\n        \"\"\"\n        Appends an object to the serialization stream\n\n        :param obj: A string or a deserialized Java object\n        :raise RuntimeError: Unsupported type\n        \"\"\"\n        log_debug(\"Writing object of type {0}\".format(type(obj).__name__))\n        if isinstance(obj, JavaArray):\n            # Deserialized Java array\n            self.write_array(obj)\n        elif isinstance(obj, JavaEnum):\n            # Deserialized Java Enum\n            self.write_enum(obj)\n        elif isinstance(obj, JavaObject):\n            # Deserialized Java object\n            self.write_object(obj)\n        elif isinstance(obj, JavaString):\n            # Deserialized String\n            self.write_string(obj)\n        elif isinstance(obj, JavaClass):\n            # Java class\n            self.write_class(obj)\n        elif obj is None:\n            # Null\n            self.write_null()\n        elif type(obj) is str:\n            # String value\n            self.write_blockdata(obj)\n        else:\n            # Unhandled type\n            raise RuntimeError(\n                \"Object serialization of type {0} is not \"\n                \"supported.\".format(type(obj))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a string to the serialization stream.", "response": "def _writeString(self, obj, use_reference=True):\n        \"\"\"\n        Appends a string to the serialization stream\n\n        :param obj: String to serialize\n        :param use_reference: If True, allow writing a reference\n        \"\"\"\n        # TODO: Convert to \"modified UTF-8\"\n        # http://docs.oracle.com/javase/7/docs/api/java/io/DataInput.html#modified-utf-8\n        string = to_bytes(obj, \"utf-8\")\n\n        if use_reference and isinstance(obj, JavaString):\n            try:\n                idx = self.references.index(obj)\n            except ValueError:\n                # First appearance of the string\n                self.references.append(obj)\n                logging.debug(\n                    \"*** Adding ref 0x%X for string: %s\",\n                    len(self.references) - 1 + self.BASE_REFERENCE_IDX,\n                    obj,\n                )\n\n                self._writeStruct(\">H\", 2, (len(string),))\n                self.object_stream.write(string)\n            else:\n                # Write a reference to the previous type\n                logging.debug(\n                    \"*** Reusing ref 0x%X for string: %s\",\n                    idx + self.BASE_REFERENCE_IDX,\n                    obj,\n                )\n                self.write_reference(idx)\n        else:\n            self._writeStruct(\">H\", 2, (len(string),))\n            self.object_stream.write(string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_string(self, obj, use_reference=True):\n        if use_reference and isinstance(obj, JavaString):\n            try:\n                idx = self.references.index(obj)\n            except ValueError:\n                # String is not referenced: let _writeString store it\n                self._writeStruct(\">B\", 1, (self.TC_STRING,))\n                self._writeString(obj, use_reference)\n            else:\n                # Reuse the referenced string\n                logging.debug(\n                    \"*** Reusing ref 0x%X for String: %s\",\n                    idx + self.BASE_REFERENCE_IDX,\n                    obj,\n                )\n                self.write_reference(idx)\n        else:\n            # Don't use references\n            self._writeStruct(\">B\", 1, (self.TC_STRING,))\n            self._writeString(obj, use_reference)", "response": "Writes a Java string with the TC_STRING type marker."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites an Enum value to the internal buffer.", "response": "def write_enum(self, obj):\n        \"\"\"\n        Writes an Enum value\n\n        :param obj: A JavaEnum object\n        \"\"\"\n        # FIXME: the output doesn't have the same references as the real\n        # serializable form\n        self._writeStruct(\">B\", 1, (self.TC_ENUM,))\n\n        try:\n            idx = self.references.index(obj)\n        except ValueError:\n            # New reference\n            self.references.append(obj)\n            logging.debug(\n                \"*** Adding ref 0x%X for enum: %s\",\n                len(self.references) - 1 + self.BASE_REFERENCE_IDX,\n                obj,\n            )\n\n            self.write_classdesc(obj.get_class())\n        else:\n            self.write_reference(idx)\n\n        self.write_string(obj.constant)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a block of data to the serialization stream.", "response": "def write_blockdata(self, obj, parent=None):\n        \"\"\"\n        Appends a block of data to the serialization stream\n\n        :param obj: String form of the data block\n        \"\"\"\n        if type(obj) is str:\n            # Latin-1: keep bytes as is\n            obj = to_bytes(obj, \"latin-1\")\n\n        length = len(obj)\n        if length <= 256:\n            # Small block data\n            # TC_BLOCKDATA (unsigned byte)<size> (byte)[size]\n            self._writeStruct(\">B\", 1, (self.TC_BLOCKDATA,))\n            self._writeStruct(\">B\", 1, (length,))\n        else:\n            # Large block data\n            # TC_BLOCKDATALONG (unsigned int)<size> (byte)[size]\n            self._writeStruct(\">B\", 1, (self.TC_BLOCKDATALONG,))\n            self._writeStruct(\">I\", 1, (length,))\n\n        self.object_stream.write(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite an object to the serialization stream.", "response": "def write_object(self, obj, parent=None):\n        \"\"\"\n        Writes an object header to the serialization stream\n\n        :param obj: Not yet used\n        :param parent: Not yet used\n        \"\"\"\n        # Transform object\n        for transformer in self.object_transformers:\n            tmp_object = transformer.transform(obj)\n            if tmp_object is not obj:\n                obj = tmp_object\n                break\n\n        self._writeStruct(\">B\", 1, (self.TC_OBJECT,))\n        cls = obj.get_class()\n        self.write_classdesc(cls)\n\n        # Add reference\n        self.references.append([])\n        logging.debug(\n            \"*** Adding ref 0x%X for object %s\",\n            len(self.references) - 1 + self.BASE_REFERENCE_IDX,\n            obj,\n        )\n\n        all_names = collections.deque()\n        all_types = collections.deque()\n        tmpcls = cls\n        while tmpcls:\n            all_names.extendleft(reversed(tmpcls.fields_names))\n            all_types.extendleft(reversed(tmpcls.fields_types))\n            tmpcls = tmpcls.superclass\n        del tmpcls\n\n        logging.debug(\"<=> Field names: %s\", all_names)\n        logging.debug(\"<=> Field types: %s\", all_types)\n\n        for field_name, field_type in zip(all_names, all_types):\n            try:\n                logging.debug(\n                    \"Writing field %s (%s): %s\",\n                    field_name,\n                    field_type,\n                    getattr(obj, field_name),\n                )\n                self._write_value(field_type, getattr(obj, field_name))\n            except AttributeError as ex:\n                log_error(\n                    \"No attribute {0} for object {1}\\nDir: {2}\".format(\n                        ex, repr(obj), dir(obj)\n                    )\n                )\n                raise\n        del all_names, all_types\n\n        if (\n            cls.flags & self.SC_SERIALIZABLE\n            and cls.flags & self.SC_WRITE_METHOD\n            or cls.flags & self.SC_EXTERNALIZABLE\n            and cls.flags & self.SC_BLOCK_DATA\n        ):\n            for annotation in obj.annotations:\n                log_debug(\n                    \"Write annotation {0} for {1}\".format(repr(annotation), repr(obj))\n                )\n                if annotation is None:\n                    self.write_null()\n                else:\n                    self.writeObject(annotation)\n            self._writeStruct(\">B\", 1, (self.TC_ENDBLOCKDATA,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_class(self, obj, parent=None):\n        self._writeStruct(\">B\", 1, (self.TC_CLASS,))\n        self.write_classdesc(obj)", "response": "Writes a class to the stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_classdesc(self, obj, parent=None):\n        if obj not in self.references:\n            # Add reference\n            self.references.append(obj)\n            logging.debug(\n                \"*** Adding ref 0x%X for classdesc %s\",\n                len(self.references) - 1 + self.BASE_REFERENCE_IDX,\n                obj.name,\n            )\n\n            self._writeStruct(\">B\", 1, (self.TC_CLASSDESC,))\n            self._writeString(obj.name)\n            self._writeStruct(\">qB\", 1, (obj.serialVersionUID, obj.flags))\n            self._writeStruct(\">H\", 1, (len(obj.fields_names),))\n\n            for field_name, field_type in zip(obj.fields_names, obj.fields_types):\n                self._writeStruct(\">B\", 1, (self._convert_type_to_char(field_type),))\n                self._writeString(field_name)\n                if field_type[0] in (self.TYPE_OBJECT, self.TYPE_ARRAY):\n                    try:\n                        idx = self.references.index(field_type)\n                    except ValueError:\n                        # First appearance of the type\n                        self.references.append(field_type)\n                        logging.debug(\n                            \"*** Adding ref 0x%X for field type %s\",\n                            len(self.references) - 1 + self.BASE_REFERENCE_IDX,\n                            field_type,\n                        )\n\n                        self.write_string(field_type, False)\n                    else:\n                        # Write a reference to the previous type\n                        logging.debug(\n                            \"*** Reusing ref 0x%X for %s (%s)\",\n                            idx + self.BASE_REFERENCE_IDX,\n                            field_type,\n                            field_name,\n                        )\n                        self.write_reference(idx)\n\n            self._writeStruct(\">B\", 1, (self.TC_ENDBLOCKDATA,))\n            if obj.superclass:\n                self.write_classdesc(obj.superclass)\n            else:\n                self.write_null()\n        else:\n            # Use reference\n            self.write_reference(self.references.index(obj))", "response": "Writes a class description to the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a reference to the internal structure.", "response": "def write_reference(self, ref_index):\n        \"\"\"\n        Writes a reference\n        :param ref_index: Local index (0-based) to the reference\n        \"\"\"\n        self._writeStruct(\n            \">BL\", 1, (self.TC_REFERENCE, ref_index + self.BASE_REFERENCE_IDX)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a JavaArray object to the internal buffer.", "response": "def write_array(self, obj):\n        \"\"\"\n        Writes a JavaArray\n\n        :param obj: A JavaArray object\n        \"\"\"\n        classdesc = obj.get_class()\n        self._writeStruct(\">B\", 1, (self.TC_ARRAY,))\n        self.write_classdesc(classdesc)\n        self._writeStruct(\">i\", 1, (len(obj),))\n\n        # Add reference\n        self.references.append(obj)\n        logging.debug(\n            \"*** Adding ref 0x%X for array []\",\n            len(self.references) - 1 + self.BASE_REFERENCE_IDX,\n        )\n\n        type_char = classdesc.name[0]\n        assert type_char == self.TYPE_ARRAY\n        type_char = classdesc.name[1]\n\n        if type_char == self.TYPE_OBJECT:\n            for o in obj:\n                self._write_value(classdesc.name[1:], o)\n        elif type_char == self.TYPE_ARRAY:\n            for a in obj:\n                self.write_array(a)\n        else:\n            log_debug(\"Write array of type %s\" % type_char)\n            for v in obj:\n                log_debug(\"Writing: %s\" % v)\n                self._write_value(type_char, v)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite an item of the type field_type to the internal buffer.", "response": "def _write_value(self, field_type, value):\n        \"\"\"\n        Writes an item of an array\n\n        :param field_type: Value type\n        :param value: The value itself\n        \"\"\"\n        if len(field_type) > 1:\n            # We don't need details for arrays and objects\n            field_type = field_type[0]\n\n        if field_type == self.TYPE_BOOLEAN:\n            self._writeStruct(\">B\", 1, (1 if value else 0,))\n        elif field_type == self.TYPE_BYTE:\n            self._writeStruct(\">b\", 1, (value,))\n        elif field_type == self.TYPE_CHAR:\n            self._writeStruct(\">H\", 1, (ord(value),))\n        elif field_type == self.TYPE_SHORT:\n            self._writeStruct(\">h\", 1, (value,))\n        elif field_type == self.TYPE_INTEGER:\n            self._writeStruct(\">i\", 1, (value,))\n        elif field_type == self.TYPE_LONG:\n            self._writeStruct(\">q\", 1, (value,))\n        elif field_type == self.TYPE_FLOAT:\n            self._writeStruct(\">f\", 1, (value,))\n        elif field_type == self.TYPE_DOUBLE:\n            self._writeStruct(\">d\", 1, (value,))\n        elif field_type == self.TYPE_OBJECT or field_type == self.TYPE_ARRAY:\n            if value is None:\n                self.write_null()\n            elif isinstance(value, JavaEnum):\n                self.write_enum(value)\n            elif isinstance(value, (JavaArray, JavaByteArray)):\n                self.write_array(value)\n            elif isinstance(value, JavaObject):\n                self.write_object(value)\n            elif isinstance(value, JavaString):\n                self.write_string(value)\n            elif isinstance(value, str):\n                self.write_blockdata(value)\n            else:\n                raise RuntimeError(\"Unknown typecode: {0}\".format(field_type))\n        else:\n            raise RuntimeError(\"Unknown typecode: {0}\".format(field_type))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convert_type_to_char(self, type_char):\n        typecode = type_char\n        if type(type_char) is int:\n            typecode = chr(type_char)\n\n        if typecode in self.TYPECODES_LIST:\n            return ord(typecode)\n        elif len(typecode) > 1:\n            if typecode[0] == \"L\":\n                return ord(self.TYPE_OBJECT)\n            elif typecode[0] == \"[\":\n                return ord(self.TYPE_ARRAY)\n\n        raise RuntimeError(\n            \"Typecode {0} ({1}) isn't supported.\".format(type_char, typecode)\n        )", "response": "Converts the given type code to an int."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, classdesc, unmarshaller=None):\n        # type: (JavaClass, JavaObjectUnmarshaller) -> JavaObject\n        \"\"\"\n        Transforms a deserialized Java object into a Python object\n\n        :param classdesc: The description of a Java class\n        :return: The Python form of the object, or the original JavaObject\n        \"\"\"\n        try:\n            mapped_type = self.TYPE_MAPPER[classdesc.name]\n        except KeyError:\n            # Return a JavaObject by default\n            return JavaObject()\n        else:\n            log_debug(\"---\")\n            log_debug(classdesc.name)\n            log_debug(\"---\")\n\n            java_object = mapped_type(unmarshaller)\n\n            log_debug(\">>> java_object: {0}\".format(java_object))\n            return java_object", "response": "Creates a deserialized Java object from a class description."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_start_finish(msg, logger, level=logging.DEBUG):\n    logger.log(level, 'start: ' + msg)\n    yield\n    logger.log(level, 'finish: ' + msg)", "response": "A context manager to log start and finish messages."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend log output to a file.", "response": "def log_to_file(filename, level=None, fmt=None, datefmt=None):\n    \"\"\"\n    Send log output to the given file.\n\n    Parameters\n    ----------\n    filename : str\n    level : int, optional\n        An optional logging level that will apply only to this stream\n        handler.\n    fmt : str, optional\n        An optional format string that will be used for the log\n        messages.\n    datefmt : str, optional\n        An optional format string for formatting dates in the log\n        messages.\n\n    \"\"\"\n    _add_urbansim_handler(\n        logging.FileHandler(filename), fmt=fmt, datefmt=datefmt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsimulate the MNL model.", "response": "def mnl_simulate(data, coeff, numalts, GPU=False, returnprobs=True):\n    \"\"\"\n    Get the probabilities for each chooser choosing between `numalts`\n    alternatives.\n\n    Parameters\n    ----------\n    data : 2D array\n        The data are expected to be in \"long\" form where each row is for\n        one alternative. Alternatives are in groups of `numalts` rows per\n        choosers. Alternatives must be in the same order for each chooser.\n    coeff : 1D array\n        The model coefficients corresponding to each column in `data`.\n    numalts : int\n        The number of alternatives available to each chooser.\n    GPU : bool, optional\n    returnprobs : bool, optional\n        If True, return the probabilities for each chooser/alternative instead\n        of actual choices.\n\n    Returns\n    -------\n    probs or choices: 2D array\n        If `returnprobs` is True the probabilities are a 2D array with a\n        row for each chooser and columns for each alternative.\n\n    \"\"\"\n    logger.debug(\n        'start: MNL simulation with len(data)={} and numalts={}'.format(\n            len(data), numalts))\n    atype = 'numpy' if not GPU else 'cuda'\n\n    data = np.transpose(data)\n    coeff = np.reshape(np.array(coeff), (1, len(coeff)))\n\n    data, coeff = PMAT(data, atype), PMAT(coeff, atype)\n\n    probs = mnl_probs(data, coeff, numalts)\n\n    if returnprobs:\n        return np.transpose(probs.get_mat())\n\n    # convert to cpu from here on - gpu doesn't currently support these ops\n    if probs.typ == 'cuda':\n        probs = PMAT(probs.get_mat())\n\n    probs = probs.cumsum(axis=0)\n    r = pmat.random(probs.size() // numalts)\n    choices = probs.subtract(r, inplace=True).firstpositive(axis=0)\n\n    logger.debug('finish: MNL simulation')\n    return choices.get_mat()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating coefficients of the MNL model. Parameters ---------- data : 2D array The data are expected to be in \"long\" form where each row is for one alternative. Alternatives are in groups of `numalts` rows per choosers. Alternatives must be in the same order for each chooser. chosen : 2D array This boolean array has a row for each chooser and a column for each alternative. The column ordering for alternatives is expected to be the same as their row ordering in the `data` array. A one (True) indicates which alternative each chooser has chosen. numalts : int The number of alternatives. GPU : bool, optional coeffrange : tuple of floats, optional Limits of (min, max) to which coefficients are clipped. weights : ndarray, optional lcgrad : bool, optional beta : 1D array, optional Any initial guess for the coefficients. Returns ------- log_likelihood : dict Dictionary of log-likelihood values describing the quality of the model fit. fit_parameters : pandas.DataFrame Table of fit parameters with columns 'Coefficient', 'Std. Error', 'T-Score'. Each row corresponds to a column in `data` and are given in the same order as in `data`. See Also -------- scipy.optimize.fmin_l_bfgs_b : The optimization routine used.", "response": "def mnl_estimate(data, chosen, numalts, GPU=False, coeffrange=(-3, 3),\n                 weights=None, lcgrad=False, beta=None):\n    \"\"\"\n    Calculate coefficients of the MNL model.\n\n    Parameters\n    ----------\n    data : 2D array\n        The data are expected to be in \"long\" form where each row is for\n        one alternative. Alternatives are in groups of `numalts` rows per\n        choosers. Alternatives must be in the same order for each chooser.\n    chosen : 2D array\n        This boolean array has a row for each chooser and a column for each\n        alternative. The column ordering for alternatives is expected to be\n        the same as their row ordering in the `data` array.\n        A one (True) indicates which alternative each chooser has chosen.\n    numalts : int\n        The number of alternatives.\n    GPU : bool, optional\n    coeffrange : tuple of floats, optional\n        Limits of (min, max) to which coefficients are clipped.\n    weights : ndarray, optional\n    lcgrad : bool, optional\n    beta : 1D array, optional\n        Any initial guess for the coefficients.\n\n    Returns\n    -------\n    log_likelihood : dict\n        Dictionary of log-likelihood values describing the quality of\n        the model fit.\n    fit_parameters : pandas.DataFrame\n        Table of fit parameters with columns 'Coefficient', 'Std. Error',\n        'T-Score'. Each row corresponds to a column in `data` and are given\n        in the same order as in `data`.\n\n    See Also\n    --------\n    scipy.optimize.fmin_l_bfgs_b : The optimization routine used.\n\n    \"\"\"\n    logger.debug(\n        'start: MNL fit with len(data)={} and numalts={}'.format(\n            len(data), numalts))\n    atype = 'numpy' if not GPU else 'cuda'\n\n    numvars = data.shape[1]\n    numobs = data.shape[0] // numalts\n\n    if chosen is None:\n        chosen = np.ones((numobs, numalts))  # used for latent classes\n\n    data = np.transpose(data)\n    chosen = np.transpose(chosen)\n\n    data, chosen = PMAT(data, atype), PMAT(chosen, atype)\n    if weights is not None:\n        weights = PMAT(np.transpose(weights), atype)\n\n    if beta is None:\n        beta = np.zeros(numvars)\n    bounds = [coeffrange] * numvars\n\n    with log_start_finish('scipy optimization for MNL fit', logger):\n        args = (data, chosen, numalts, weights, lcgrad)\n        bfgs_result = scipy.optimize.fmin_l_bfgs_b(mnl_loglik,\n                                                   beta,\n                                                   args=args,\n                                                   fprime=None,\n                                                   factr=10,\n                                                   approx_grad=False,\n                                                   bounds=bounds\n                                                   )\n\n    if bfgs_result[2]['warnflag'] > 0:\n        logger.warn(\"mnl did not converge correctly: %s\",  bfgs_result)\n\n    beta = bfgs_result[0]\n    stderr = mnl_loglik(\n        beta, data, chosen, numalts, weights, stderr=1, lcgrad=lcgrad)\n\n    l0beta = np.zeros(numvars)\n    l0 = -1 * mnl_loglik(l0beta, *args)[0]\n    l1 = -1 * mnl_loglik(beta, *args)[0]\n\n    log_likelihood = {\n        'null': float(l0[0][0]),\n        'convergence': float(l1[0][0]),\n        'ratio': float((1 - (l1 / l0))[0][0])\n    }\n\n    fit_parameters = pd.DataFrame({\n        'Coefficient': beta,\n        'Std. Error': stderr,\n        'T-Score': beta / stderr})\n\n    logger.debug('finish: MNL fit')\n    return log_likelihood, fit_parameters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unit_choice(chooser_ids, alternative_ids, probabilities):\n    chooser_ids = np.asanyarray(chooser_ids)\n    alternative_ids = np.asanyarray(alternative_ids)\n    probabilities = np.asanyarray(probabilities)\n\n    logger.debug(\n        'start: unit choice with {} choosers and {} alternatives'.format(\n            len(chooser_ids), len(alternative_ids)))\n\n    choices = pd.Series(index=chooser_ids)\n\n    if probabilities.sum() == 0:\n        # return all nan if there are no available units\n        return choices\n\n    # probabilities need to sum to 1 for np.random.choice\n    probabilities = probabilities / probabilities.sum()\n\n    # need to see if there are as many available alternatives as choosers\n    n_available = np.count_nonzero(probabilities)\n    n_choosers = len(chooser_ids)\n    n_to_choose = n_choosers if n_choosers < n_available else n_available\n\n    chosen = np.random.choice(\n        alternative_ids, size=n_to_choose, replace=False, p=probabilities)\n\n    # if there are fewer available units than choosers we need to pick\n    # which choosers get a unit\n    if n_to_choose == n_available:\n        chooser_ids = np.random.choice(\n            chooser_ids, size=n_to_choose, replace=False)\n\n    choices[chooser_ids] = chosen\n\n    logger.debug('finish: unit choice')\n    return choices", "response": "Generates a set of random units from the given set of choosers and alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a DiscreteChoiceModel instance from a saved YAML string.", "response": "def from_yaml(cls, yaml_str=None, str_or_buffer=None):\n        \"\"\"\n        Create a DiscreteChoiceModel instance from a saved YAML configuration.\n        Arguments are mutally exclusive.\n\n        Parameters\n        ----------\n        yaml_str : str, optional\n            A YAML string from which to load model.\n        str_or_buffer : str or file like, optional\n            File name or buffer from which to load YAML.\n\n        Returns\n        -------\n        MNLDiscreteChoiceModel\n\n        \"\"\"\n        cfg = yamlio.yaml_to_dict(yaml_str, str_or_buffer)\n\n        model = cls(\n            cfg['model_expression'],\n            cfg['sample_size'],\n            probability_mode=cfg.get('probability_mode', 'full_product'),\n            choice_mode=cfg.get('choice_mode', 'individual'),\n            choosers_fit_filters=cfg.get('choosers_fit_filters', None),\n            choosers_predict_filters=cfg.get('choosers_predict_filters', None),\n            alts_fit_filters=cfg.get('alts_fit_filters', None),\n            alts_predict_filters=cfg.get('alts_predict_filters', None),\n            interaction_predict_filters=cfg.get(\n                'interaction_predict_filters', None),\n            estimation_sample_size=cfg.get('estimation_sample_size', None),\n            prediction_sample_size=cfg.get('prediction_sample_size', None),\n            choice_column=cfg.get('choice_column', None),\n            name=cfg.get('name', None)\n        )\n\n        if cfg.get('log_likelihoods', None):\n            model.log_likelihoods = cfg['log_likelihoods']\n        if cfg.get('fit_parameters', None):\n            model.fit_parameters = pd.DataFrame(cfg['fit_parameters'])\n\n        logger.debug('loaded LCM model {} from YAML'.format(model.name))\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_fit_filters(self, choosers, alternatives):\n        return super(MNLDiscreteChoiceModel, self).apply_fit_filters(\n            choosers, alternatives)", "response": "Apply fit filters to the choosers and alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies predict filters to the choosers and alternatives.", "response": "def apply_predict_filters(self, choosers, alternatives):\n        \"\"\"\n        Filter `choosers` and `alternatives` for prediction.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing,\n            e.g. buildings.\n\n        Returns\n        -------\n        filtered_choosers, filtered_alts : pandas.DataFrame\n\n        \"\"\"\n        return super(MNLDiscreteChoiceModel, self).apply_predict_filters(\n            choosers, alternatives)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfit and save model parameters based on given data.", "response": "def fit(self, choosers, alternatives, current_choice):\n        \"\"\"\n        Fit and save model parameters based on given data.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing,\n            e.g. buildings.\n        current_choice : pandas.Series or any\n            A Series describing the `alternatives` currently chosen\n            by the `choosers`. Should have an index matching `choosers`\n            and values matching the index of `alternatives`.\n\n            If a non-Series is given it should be a column in `choosers`.\n\n        Returns\n        -------\n        log_likelihoods : dict\n            Dict of log-liklihood values describing the quality of the\n            model fit. Will have keys 'null', 'convergence', and 'ratio'.\n\n        \"\"\"\n        logger.debug('start: fit LCM model {}'.format(self.name))\n\n        if not isinstance(current_choice, pd.Series):\n            current_choice = choosers[current_choice]\n\n        choosers, alternatives = self.apply_fit_filters(choosers, alternatives)\n\n        if self.estimation_sample_size:\n            choosers = choosers.loc[np.random.choice(\n                choosers.index,\n                min(self.estimation_sample_size, len(choosers)),\n                replace=False)]\n\n        current_choice = current_choice.loc[choosers.index]\n\n        _, merged, chosen = interaction.mnl_interaction_dataset(\n            choosers, alternatives, self.sample_size, current_choice)\n        model_design = dmatrix(\n            self.str_model_expression, data=merged, return_type='dataframe')\n\n        if len(merged) != model_design.as_matrix().shape[0]:\n            raise ModelEvaluationError(\n                'Estimated data does not have the same length as input.  '\n                'This suggests there are null values in one or more of '\n                'the input columns.')\n\n        self.log_likelihoods, self.fit_parameters = mnl.mnl_estimate(\n            model_design.as_matrix(), chosen, self.sample_size)\n        self.fit_parameters.index = model_design.columns\n\n        logger.debug('finish: fit LCM model {}'.format(self.name))\n        return self.log_likelihoods"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint a report of the fit results.", "response": "def report_fit(self):\n        \"\"\"\n        Print a report of the fit results.\n\n        \"\"\"\n        if not self.fitted:\n            print('Model not yet fit.')\n            return\n\n        print('Null Log-liklihood: {0:.3f}'.format(\n            self.log_likelihoods['null']))\n        print('Log-liklihood at convergence: {0:.3f}'.format(\n            self.log_likelihoods['convergence']))\n        print('Log-liklihood Ratio: {0:.3f}\\n'.format(\n            self.log_likelihoods['ratio']))\n\n        tbl = PrettyTable(\n            ['Component', ])\n        tbl = PrettyTable()\n\n        tbl.add_column('Component', self.fit_parameters.index.values)\n        for col in ('Coefficient', 'Std. Error', 'T-Score'):\n            tbl.add_column(col, self.fit_parameters[col].values)\n\n        tbl.align['Component'] = 'l'\n        tbl.float_format = '.3'\n\n        print(tbl)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef probabilities(self, choosers, alternatives, filter_tables=True):\n        logger.debug('start: calculate probabilities for LCM model {}'.format(\n            self.name))\n        self.assert_fitted()\n\n        if filter_tables:\n            choosers, alternatives = self.apply_predict_filters(\n                choosers, alternatives)\n\n        if self.prediction_sample_size is not None:\n            sample_size = self.prediction_sample_size\n        else:\n            sample_size = len(alternatives)\n\n        if self.probability_mode == 'single_chooser':\n            _, merged, _ = interaction.mnl_interaction_dataset(\n                choosers.head(1), alternatives, sample_size)\n        elif self.probability_mode == 'full_product':\n            _, merged, _ = interaction.mnl_interaction_dataset(\n                choosers, alternatives, sample_size)\n        else:\n            raise ValueError(\n                'Unrecognized probability_mode option: {}'.format(\n                    self.probability_mode))\n\n        merged = util.apply_filter_query(\n            merged, self.interaction_predict_filters)\n        model_design = dmatrix(\n            self.str_model_expression, data=merged, return_type='dataframe')\n\n        if len(merged) != model_design.as_matrix().shape[0]:\n            raise ModelEvaluationError(\n                'Simulated data does not have the same length as input.  '\n                'This suggests there are null values in one or more of '\n                'the input columns.')\n\n        # get the order of the coefficients in the same order as the\n        # columns in the design matrix\n        coeffs = [self.fit_parameters['Coefficient'][x]\n                  for x in model_design.columns]\n\n        # probabilities are returned from mnl_simulate as a 2d array\n        # with choosers along rows and alternatives along columns\n        if self.probability_mode == 'single_chooser':\n            numalts = len(merged)\n        else:\n            numalts = sample_size\n\n        probabilities = mnl.mnl_simulate(\n            model_design.as_matrix(),\n            coeffs,\n            numalts=numalts, returnprobs=True)\n\n        # want to turn probabilities into a Series with a MultiIndex\n        # of chooser IDs and alternative IDs.\n        # indexing by chooser ID will get you the probabilities\n        # across alternatives for that chooser\n        mi = pd.MultiIndex.from_arrays(\n            [merged['join_index'].values, merged.index.values],\n            names=('chooser_id', 'alternative_id'))\n        probabilities = pd.Series(probabilities.flatten(), index=mi)\n\n        logger.debug('finish: calculate probabilities for LCM model {}'.format(\n            self.name))\n        return probabilities", "response": "Returns the probabilities for a set of choosers to choose from among a set of alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summed_probabilities(self, choosers, alternatives):\n        def normalize(s):\n            return s / s.sum()\n\n        choosers, alternatives = self.apply_predict_filters(\n            choosers, alternatives)\n        probs = self.probabilities(choosers, alternatives, filter_tables=False)\n\n        # groupby the the alternatives ID and sum\n        if self.probability_mode == 'single_chooser':\n            return (\n                normalize(probs) * len(choosers)\n                ).reset_index(level=0, drop=True)\n        elif self.probability_mode == 'full_product':\n            return probs.groupby(level=0).apply(normalize)\\\n                .groupby(level=1).sum()\n        else:\n            raise ValueError(\n                'Unrecognized probability_mode option: {}'.format(\n                    self.probability_mode))", "response": "Calculates the total probability associated with each alternative."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict(self, choosers, alternatives, debug=False):\n        self.assert_fitted()\n        logger.debug('start: predict LCM model {}'.format(self.name))\n\n        choosers, alternatives = self.apply_predict_filters(\n            choosers, alternatives)\n\n        if len(choosers) == 0:\n            return pd.Series()\n\n        if len(alternatives) == 0:\n            return pd.Series(index=choosers.index)\n\n        probabilities = self.probabilities(\n            choosers, alternatives, filter_tables=False)\n\n        if debug:\n            self.sim_pdf = probabilities\n\n        if self.choice_mode == 'aggregate':\n            choices = unit_choice(\n                choosers.index.values,\n                probabilities.index.get_level_values('alternative_id').values,\n                probabilities.values)\n        elif self.choice_mode == 'individual':\n            def mkchoice(probs):\n                probs.reset_index(0, drop=True, inplace=True)\n                return np.random.choice(\n                    probs.index.values, p=probs.values / probs.sum())\n            choices = probabilities.groupby(level='chooser_id', sort=False)\\\n                .apply(mkchoice)\n        else:\n            raise ValueError(\n                'Unrecognized choice_mode option: {}'.format(self.choice_mode))\n\n        logger.debug('finish: predict LCM model {}'.format(self.name))\n        return choices", "response": "Predicts the set of agents from which the given choosers are in the group of alternatives."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_dict(self):\n        return {\n            'model_type': 'discretechoice',\n            'model_expression': self.model_expression,\n            'sample_size': self.sample_size,\n            'name': self.name,\n            'probability_mode': self.probability_mode,\n            'choice_mode': self.choice_mode,\n            'choosers_fit_filters': self.choosers_fit_filters,\n            'choosers_predict_filters': self.choosers_predict_filters,\n            'alts_fit_filters': self.alts_fit_filters,\n            'alts_predict_filters': self.alts_predict_filters,\n            'interaction_predict_filters': self.interaction_predict_filters,\n            'estimation_sample_size': self.estimation_sample_size,\n            'prediction_sample_size': self.prediction_sample_size,\n            'choice_column': self.choice_column,\n            'fitted': self.fitted,\n            'log_likelihoods': self.log_likelihoods,\n            'fit_parameters': (yamlio.frame_to_yaml_safe(self.fit_parameters)\n                               if self.fitted else None)\n        }", "response": "Return a dict respresentation of an MNLDiscreteChoiceModel\n            instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_yaml(self, str_or_buffer=None):\n        logger.debug('serializing LCM model {} to YAML'.format(self.name))\n        if (not isinstance(self.probability_mode, str) or\n                not isinstance(self.choice_mode, str)):\n            raise TypeError(\n                'Cannot serialize model with non-string probability_mode '\n                'or choice_mode attributes.')\n        return yamlio.convert_to_yaml(self.to_dict(), str_or_buffer)", "response": "Serialize a LCM model to YAML."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of columns that are used for filtering.", "response": "def choosers_columns_used(self):\n        \"\"\"\n        Columns from the choosers table that are used for filtering.\n\n        \"\"\"\n        return list(tz.unique(tz.concatv(\n            util.columns_in_filters(self.choosers_predict_filters),\n            util.columns_in_filters(self.choosers_fit_filters))))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of columns that are used for filtering.", "response": "def alts_columns_used(self):\n        \"\"\"\n        Columns from the alternatives table that are used for filtering.\n\n        \"\"\"\n        return list(tz.unique(tz.concatv(\n            util.columns_in_filters(self.alts_predict_filters),\n            util.columns_in_filters(self.alts_fit_filters))))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of columns used for filtering and in .", "response": "def interaction_columns_used(self):\n        \"\"\"\n        Columns from the interaction dataset used for filtering and in\n        the model. These may come originally from either the choosers or\n        alternatives tables.\n\n        \"\"\"\n        return list(tz.unique(tz.concatv(\n            util.columns_in_filters(self.interaction_predict_filters),\n            util.columns_in_formula(self.model_expression))))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of columns that are used in the model.", "response": "def columns_used(self):\n        \"\"\"\n        Columns from any table used in the model. May come from either\n        the choosers or alternatives tables.\n\n        \"\"\"\n        return list(tz.unique(tz.concatv(\n            self.choosers_columns_used(),\n            self.alts_columns_used(),\n            self.interaction_columns_used())))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_from_cfg(cls, choosers, chosen_fname, alternatives, cfgname, outcfgname=None):\n        logger.debug('start: fit from configuration {}'.format(cfgname))\n        lcm = cls.from_yaml(str_or_buffer=cfgname)\n        lcm.fit(choosers, alternatives, choosers[chosen_fname])\n        lcm.report_fit()\n        outcfgname = outcfgname or cfgname\n        lcm.to_yaml(str_or_buffer=outcfgname)\n        logger.debug('finish: fit into configuration {}'.format(outcfgname))\n        return lcm", "response": "Fits the MNLDiscreteChoiceModel from a given configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsimulates choices for the specified choosers and alternatives.", "response": "def predict_from_cfg(cls, choosers, alternatives, cfgname=None, cfg=None,\n                         alternative_ratio=2.0, debug=False):\n        \"\"\"\n        Simulate choices for the specified choosers\n\n        Parameters\n        ----------\n        choosers : DataFrame\n            A dataframe of agents doing the choosing.\n        alternatives : DataFrame\n            A dataframe of locations which the choosers are locating in and\n            which have a supply.\n        cfgname : string\n            The name of the yaml config file from which to read the discrete\n            choice model.\n        cfg: string\n            an ordered yaml string of the model discrete choice model configuration.\n            Used to read config from memory in lieu of loading cfgname from disk.\n        alternative_ratio : float, optional\n            Above the ratio of alternatives to choosers (default of 2.0),\n            the alternatives will be sampled to meet this ratio\n            (for performance reasons).\n        debug : boolean, optional (default False)\n            Whether to generate debug information on the model.\n\n        Returns\n        -------\n        choices : pandas.Series\n            Mapping of chooser ID to alternative ID. Some choosers\n            will map to a nan value when there are not enough alternatives\n            for all the choosers.\n        lcm : MNLDiscreteChoiceModel which was used to predict\n        \"\"\"\n        logger.debug('start: predict from configuration {}'.format(cfgname))\n        if cfgname:\n            lcm = cls.from_yaml(str_or_buffer=cfgname)\n        elif cfg:\n            lcm = cls.from_yaml(yaml_str=cfg)\n        else:\n            msg = 'predict_from_cfg requires a configuration via the cfgname or cfg arguments'\n            logger.error(msg)\n            raise ValueError(msg)\n\n        if len(alternatives) > len(choosers) * alternative_ratio:\n            logger.info(\n                (\"Alternative ratio exceeded: %d alternatives \"\n                 \"and only %d choosers\") %\n                (len(alternatives), len(choosers)))\n            idxes = np.random.choice(\n                alternatives.index, size=int(len(choosers) *\n                                             alternative_ratio),\n                replace=False)\n            alternatives = alternatives.loc[idxes]\n            logger.info(\n                \"  after sampling %d alternatives are available\\n\" %\n                len(alternatives))\n\n        new_units = lcm.predict(choosers, alternatives, debug=debug)\n        print(\"Assigned %d choosers to new units\" % len(new_units.dropna()))\n        logger.debug('finish: predict from configuration {}'.format(cfgname))\n        return new_units, lcm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_model_from_params(\n            self, name, model_expression, sample_size,\n            probability_mode='full_product', choice_mode='individual',\n            choosers_fit_filters=None, choosers_predict_filters=None,\n            alts_fit_filters=None, alts_predict_filters=None,\n            interaction_predict_filters=None, estimation_sample_size=None,\n            prediction_sample_size=None, choice_column=None):\n        \"\"\"\n        Add a model by passing parameters through to MNLDiscreteChoiceModel.\n\n        Parameters\n        ----------\n        name\n            Must match a segment in the choosers table.\n        model_expression : str, iterable, or dict\n            A patsy model expression. Should contain only a right-hand side.\n        sample_size : int\n            Number of choices to sample for estimating the model.\n        probability_mode : str, optional\n            Specify the method to use for calculating probabilities\n            during prediction.\n            Available string options are 'single_chooser' and 'full_product'.\n            In \"single chooser\" mode one agent is chosen for calculating\n            probabilities across all alternatives. In \"full product\" mode\n            probabilities are calculated for every chooser across all\n            alternatives.\n        choice_mode : str or callable, optional\n            Specify the method to use for making choices among alternatives.\n            Available string options are 'individual' and 'aggregate'.\n            In \"individual\" mode choices will be made separately for each\n            chooser. In \"aggregate\" mode choices are made for all choosers at\n            once. Aggregate mode implies that an alternative chosen by one\n            agent is unavailable to other agents and that the same\n            probabilities can be used for all choosers.\n        choosers_fit_filters : list of str, optional\n            Filters applied to choosers table before fitting the model.\n        choosers_predict_filters : list of str, optional\n            Filters applied to the choosers table before calculating\n            new data points.\n        alts_fit_filters : list of str, optional\n            Filters applied to the alternatives table before fitting the model.\n        alts_predict_filters : list of str, optional\n            Filters applied to the alternatives table before calculating\n            new data points.\n        interaction_predict_filters : list of str, optional\n            Filters applied to the merged choosers/alternatives table\n            before predicting agent choices.\n        estimation_sample_size : int, optional\n            Whether to sample choosers during estimation\n            (needs to be applied after choosers_fit_filters)\n        prediction_sample_size : int, optional\n            Whether (and how much) to sample alternatives during prediction.\n            Note that this can lead to multiple choosers picking the same\n            alternative.\n        choice_column : optional\n            Name of the column in the `alternatives` table that choosers\n            should choose. e.g. the 'building_id' column. If not provided\n            the alternatives index is used.\n\n        \"\"\"\n        logger.debug('adding model {} to LCM group {}'.format(name, self.name))\n        self.models[name] = MNLDiscreteChoiceModel(\n            model_expression, sample_size,\n            probability_mode, choice_mode,\n            choosers_fit_filters, choosers_predict_filters,\n            alts_fit_filters, alts_predict_filters,\n            interaction_predict_filters, estimation_sample_size,\n            prediction_sample_size, choice_column, name)", "response": "Adds a model to the MNLDiscreteChoiceModel instance by passing parameters through to MNLDiscreteChoiceModel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _iter_groups(self, data):\n        groups = data.groupby(self.segmentation_col)\n\n        for name, group in groups:\n            if name not in self.models:\n                continue\n            logger.debug(\n                'returning group {} in LCM group {}'.format(name, self.name))\n            yield name, group", "response": "Iterate over the groups in data after grouping by segmentation_col. Skips any groups for which there is no model stored."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfilters choosers and alternatives for fitting.", "response": "def apply_fit_filters(self, choosers, alternatives):\n        \"\"\"\n        Filter `choosers` and `alternatives` for fitting.\n        This is done by filtering each submodel and concatenating\n        the results.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing,\n            e.g. buildings.\n\n        Returns\n        -------\n        filtered_choosers, filtered_alts : pandas.DataFrame\n\n        \"\"\"\n        ch = []\n        alts = []\n\n        for name, df in self._iter_groups(choosers):\n            filtered_choosers, filtered_alts = \\\n                self.models[name].apply_fit_filters(df, alternatives)\n            ch.append(filtered_choosers)\n            alts.append(filtered_alts)\n\n        return pd.concat(ch), pd.concat(alts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit(self, choosers, alternatives, current_choice):\n        with log_start_finish(\n                'fit models in LCM group {}'.format(self.name), logger):\n            return {\n                name: self.models[name].fit(df, alternatives, current_choice)\n                for name, df in self._iter_groups(choosers)}", "response": "Fit and save models based on given data after segmenting\n            the choosers table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fitted(self):\n        return (all(m.fitted for m in self.models.values())\n                if self.models else False)", "response": "Returns True if all models in the group have been fitted False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef probabilities(self, choosers, alternatives):\n        logger.debug(\n            'start: calculate probabilities in LCM group {}'.format(self.name))\n        probs = {}\n\n        for name, df in self._iter_groups(choosers):\n            probs[name] = self.models[name].probabilities(df, alternatives)\n\n        logger.debug(\n            'finish: calculate probabilities in LCM group {}'.format(\n                self.name))\n        return probs", "response": "Returns the probability of each chooser segment in the LCM."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the sum of probabilities for each alternatives across all choosers and all alternatives across all segments.", "response": "def summed_probabilities(self, choosers, alternatives):\n        \"\"\"\n        Returns the sum of probabilities for alternatives across all\n        chooser segments.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n            Must have a column matching the .segmentation_col attribute.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing.\n\n        Returns\n        -------\n        probs : pandas.Series\n            Summed probabilities from each segment added together.\n\n        \"\"\"\n        if len(alternatives) == 0 or len(choosers) == 0:\n            return pd.Series()\n\n        logger.debug(\n            'start: calculate summed probabilities in LCM group {}'.format(\n                self.name))\n        probs = []\n\n        for name, df in self._iter_groups(choosers):\n            probs.append(\n                self.models[name].summed_probabilities(df, alternatives))\n\n        add = tz.curry(pd.Series.add, fill_value=0)\n        probs = tz.reduce(add, probs)\n\n        logger.debug(\n            'finish: calculate summed probabilities in LCM group {}'.format(\n                self.name))\n        return probs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npredict the model of the given choosers and alternatives.", "response": "def predict(self, choosers, alternatives, debug=False):\n        \"\"\"\n        Choose from among alternatives for a group of agents after\n        segmenting the `choosers` table.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n            Must have a column matching the .segmentation_col attribute.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing.\n        debug : bool\n            If debug is set to true, will set the variable \"sim_pdf\" on\n            the object to store the probabilities for mapping of the\n            outcome.\n\n        Returns\n        -------\n        choices : pandas.Series\n            Mapping of chooser ID to alternative ID. Some choosers\n            will map to a nan value when there are not enough alternatives\n            for all the choosers.\n\n        \"\"\"\n        logger.debug('start: predict models in LCM group {}'.format(self.name))\n        results = []\n\n        for name, df in self._iter_groups(choosers):\n            choices = self.models[name].predict(df, alternatives, debug=debug)\n            if self.remove_alts and len(alternatives) > 0:\n                alternatives = alternatives.loc[\n                    ~alternatives.index.isin(choices)]\n            results.append(choices)\n\n        logger.debug(\n            'finish: predict models in LCM group {}'.format(self.name))\n        return pd.concat(results) if results else pd.Series()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of columns that are used for filtering.", "response": "def alts_columns_used(self):\n        \"\"\"\n        Columns from the alternatives table that are used for filtering.\n\n        \"\"\"\n        return list(tz.unique(tz.concat(\n            m.alts_columns_used() for m in self.models.values())))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a SegmentedMNLDiscreteChoiceModel instance from a saved YAML string.", "response": "def from_yaml(cls, yaml_str=None, str_or_buffer=None):\n        \"\"\"\n        Create a SegmentedMNLDiscreteChoiceModel instance from a saved YAML\n        configuration. Arguments are mutally exclusive.\n\n        Parameters\n        ----------\n        yaml_str : str, optional\n            A YAML string from which to load model.\n        str_or_buffer : str or file like, optional\n            File name or buffer from which to load YAML.\n\n        Returns\n        -------\n        SegmentedMNLDiscreteChoiceModel\n\n        \"\"\"\n        cfg = yamlio.yaml_to_dict(yaml_str, str_or_buffer)\n\n        default_model_expr = cfg['default_config']['model_expression']\n\n        seg = cls(\n            cfg['segmentation_col'],\n            cfg['sample_size'],\n            cfg['probability_mode'],\n            cfg['choice_mode'],\n            cfg['choosers_fit_filters'],\n            cfg['choosers_predict_filters'],\n            cfg['alts_fit_filters'],\n            cfg['alts_predict_filters'],\n            cfg['interaction_predict_filters'],\n            cfg['estimation_sample_size'],\n            cfg['prediction_sample_size'],\n            cfg['choice_column'],\n            default_model_expr,\n            cfg['remove_alts'],\n            cfg['name'])\n\n        if \"models\" not in cfg:\n            cfg[\"models\"] = {}\n\n        for name, m in cfg['models'].items():\n            m['model_expression'] = m.get(\n                'model_expression', default_model_expr)\n            m['sample_size'] = cfg['sample_size']\n            m['probability_mode'] = cfg['probability_mode']\n            m['choice_mode'] = cfg['choice_mode']\n            m['choosers_fit_filters'] = None\n            m['choosers_predict_filters'] = None\n            m['alts_fit_filters'] = None\n            m['alts_predict_filters'] = None\n            m['interaction_predict_filters'] = \\\n                cfg['interaction_predict_filters']\n            m['estimation_sample_size'] = cfg['estimation_sample_size']\n            m['prediction_sample_size'] = cfg['prediction_sample_size']\n            m['choice_column'] = cfg['choice_column']\n\n            model = MNLDiscreteChoiceModel.from_yaml(\n                yamlio.convert_to_yaml(m, None))\n            seg._group.add_model(model)\n\n        logger.debug(\n            'loaded segmented LCM model {} from YAML'.format(seg.name))\n        return seg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new segment to the group.", "response": "def add_segment(self, name, model_expression=None):\n        \"\"\"\n        Add a new segment with its own model expression.\n\n        Parameters\n        ----------\n        name\n            Segment name. Must match a segment in the groupby of the data.\n        model_expression : str or dict, optional\n            A patsy model expression that can be used with statsmodels.\n            Should contain both the left- and right-hand sides.\n            If not given the default model will be used, which must not be\n            None.\n\n        \"\"\"\n        logger.debug('adding LCM model {} to segmented model {}'.format(\n            name, self.name))\n        if not model_expression:\n            if not self.default_model_expr:\n                raise ValueError(\n                    'No default model available, '\n                    'you must supply a model expression.')\n            model_expression = self.default_model_expr\n\n        # we'll take care of some of the filtering this side before\n        # segmentation\n        self._group.add_model_from_params(\n            name=name,\n            model_expression=model_expression,\n            sample_size=self.sample_size,\n            probability_mode=self.probability_mode,\n            choice_mode=self.choice_mode,\n            choosers_fit_filters=None,\n            choosers_predict_filters=None,\n            alts_fit_filters=None,\n            alts_predict_filters=None,\n            interaction_predict_filters=self.interaction_predict_filters,\n            estimation_sample_size=self.estimation_sample_size,\n            choice_column=self.choice_column)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply the fit filters to the choosers and alternatives.", "response": "def apply_fit_filters(self, choosers, alternatives):\n        \"\"\"\n        Filter `choosers` and `alternatives` for fitting.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing,\n            e.g. buildings.\n\n        Returns\n        -------\n        filtered_choosers, filtered_alts : pandas.DataFrame\n\n        \"\"\"\n        return super(SegmentedMNLDiscreteChoiceModel, self).apply_fit_filters(\n            choosers, alternatives)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the predict filters to the pickers and alternatives.", "response": "def apply_predict_filters(self, choosers, alternatives):\n        \"\"\"\n        Filter `choosers` and `alternatives` for prediction.\n\n        Parameters\n        ----------\n        choosers : pandas.DataFrame\n            Table describing the agents making choices, e.g. households.\n        alternatives : pandas.DataFrame\n            Table describing the things from which agents are choosing,\n            e.g. buildings.\n\n        Returns\n        -------\n        filtered_choosers, filtered_alts : pandas.DataFrame\n\n        \"\"\"\n        return super(\n            SegmentedMNLDiscreteChoiceModel, self\n            ).apply_predict_filters(choosers, alternatives)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self, choosers, alternatives, current_choice):\n        logger.debug('start: fit models in segmented LCM {}'.format(self.name))\n\n        choosers, alternatives = self.apply_fit_filters(choosers, alternatives)\n        unique = choosers[self.segmentation_col].unique()\n\n        # Remove any existing segments that may no longer have counterparts\n        # in the data. This can happen when loading a saved model and then\n        # calling this method with data that no longer has segments that\n        # were there the last time this was called.\n        gone = set(self._group.models) - set(unique)\n        for g in gone:\n            del self._group.models[g]\n\n        for x in unique:\n            if x not in self._group.models:\n                self.add_segment(x)\n\n        results = self._group.fit(choosers, alternatives, current_choice)\n        logger.debug(\n            'finish: fit models in segmented LCM {}'.format(self.name))\n        return results", "response": "Fit and save models based on given data after segmenting\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying filters to the choosers and alts tables.", "response": "def _filter_choosers_alts(self, choosers, alternatives):\n        \"\"\"\n        Apply filters to the choosers and alts tables.\n\n        \"\"\"\n        return (\n            util.apply_filter_query(\n                choosers, self.choosers_predict_filters),\n            util.apply_filter_query(\n                alternatives, self.alts_predict_filters))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef probabilities(self, choosers, alternatives):\n        logger.debug(\n            'start: calculate probabilities in segmented LCM {}'.format(\n                self.name))\n        choosers, alternatives = self.apply_predict_filters(\n            choosers, alternatives)\n        result = self._group.probabilities(choosers, alternatives)\n        logger.debug(\n            'finish: calculate probabilities in segmented LCM {}'.format(\n                self.name))\n        return result", "response": "Returns a dictionary of probability for each chooser segment as a dictionary keyed by segment name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict(self, choosers, alternatives, debug=False):\n        logger.debug(\n            'start: predict models in segmented LCM {}'.format(self.name))\n        choosers, alternatives = self._filter_choosers_alts(\n            choosers, alternatives)\n\n        results = self._group.predict(choosers, alternatives, debug=debug)\n        logger.debug(\n            'finish: predict models in segmented LCM {}'.format(self.name))\n        return results", "response": "Predicts the model of the given choosers and alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving redundant items from a model s configuration dict.", "response": "def _process_model_dict(self, d):\n        \"\"\"\n        Remove redundant items from a model's configuration dict.\n\n        Parameters\n        ----------\n        d : dict\n            Modified in place.\n\n        Returns\n        -------\n        dict\n            Modified `d`.\n\n        \"\"\"\n        del d['model_type']\n        del d['sample_size']\n        del d['probability_mode']\n        del d['choice_mode']\n        del d['choosers_fit_filters']\n        del d['choosers_predict_filters']\n        del d['alts_fit_filters']\n        del d['alts_predict_filters']\n        del d['interaction_predict_filters']\n        del d['estimation_sample_size']\n        del d['prediction_sample_size']\n        del d['choice_column']\n\n        if d['model_expression'] == self.default_model_expr:\n            del d['model_expression']\n\n        d[\"name\"] = yamlio.to_scalar_safe(d[\"name\"])\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_dict(self):\n        return {\n            'model_type': 'segmented_discretechoice',\n            'name': self.name,\n            'segmentation_col': self.segmentation_col,\n            'sample_size': self.sample_size,\n            'probability_mode': self.probability_mode,\n            'choice_mode': self.choice_mode,\n            'choosers_fit_filters': self.choosers_fit_filters,\n            'choosers_predict_filters': self.choosers_predict_filters,\n            'alts_fit_filters': self.alts_fit_filters,\n            'alts_predict_filters': self.alts_predict_filters,\n            'interaction_predict_filters': self.interaction_predict_filters,\n            'estimation_sample_size': self.estimation_sample_size,\n            'prediction_sample_size': self.prediction_sample_size,\n            'choice_column': self.choice_column,\n            'default_config': {\n                'model_expression': self.default_model_expr,\n            },\n            'remove_alts': self.remove_alts,\n            'fitted': self.fitted,\n            'models': {\n                yamlio.to_scalar_safe(name):\n                    self._process_model_dict(m.to_dict())\n                for name, m in self._group.models.items()\n            }\n        }", "response": "Returns a dict representation of this instance suitable for conversion to YAML."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserialize a segmented LCM object to YAML.", "response": "def to_yaml(self, str_or_buffer=None):\n        \"\"\"\n        Save a model respresentation to YAML.\n\n        Parameters\n        ----------\n        str_or_buffer : str or file like, optional\n            By default a YAML string is returned. If a string is\n            given here the YAML will be written to that file.\n            If an object with a ``.write`` method is given the\n            YAML will be written to that object.\n\n        Returns\n        -------\n        j : str\n            YAML is string if `str_or_buffer` is not given.\n\n        \"\"\"\n        logger.debug('serializing segmented LCM {} to YAML'.format(self.name))\n        return yamlio.convert_to_yaml(self.to_dict(), str_or_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of columns that are used in the model.", "response": "def columns_used(self):\n        \"\"\"\n        Columns from any table used in the model. May come from either\n        the choosers or alternatives tables.\n\n        \"\"\"\n        return list(tz.unique(tz.concatv(\n            self.choosers_columns_used(),\n            self.alts_columns_used(),\n            self.interaction_columns_used(),\n            util.columns_in_formula(self.default_model_expr),\n            [self.segmentation_col])))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit_from_cfg(cls, choosers, chosen_fname, alternatives, cfgname, outcfgname=None):\n        logger.debug('start: fit from configuration {}'.format(cfgname))\n        lcm = cls.from_yaml(str_or_buffer=cfgname)\n        lcm.fit(choosers, alternatives, choosers[chosen_fname])\n        for k, v in lcm._group.models.items():\n            print(\"LCM RESULTS FOR SEGMENT %s\\n\" % str(k))\n            v.report_fit()\n        outcfgname = outcfgname or cfgname\n        lcm.to_yaml(str_or_buffer=outcfgname)\n        logger.debug('finish: fit into configuration {}'.format(outcfgname))\n        return lcm", "response": "Fit a discrete weighted choice model to a set of alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a directory of binary array data files to a Pandas DataFrame.", "response": "def cache_to_df(dir_path):\n    \"\"\"\n    Convert a directory of binary array data files to a Pandas DataFrame.\n\n    Parameters\n    ----------\n    dir_path : str\n\n\n    \"\"\"\n    table = {}\n    for attrib in glob.glob(os.path.join(dir_path, '*')):\n        attrib_name, attrib_ext = os.path.splitext(os.path.basename(attrib))\n        if attrib_ext == '.lf8':\n            attrib_data = np.fromfile(attrib, np.float64)\n            table[attrib_name] = attrib_data\n\n        elif attrib_ext == '.lf4':\n            attrib_data = np.fromfile(attrib, np.float32)\n            table[attrib_name] = attrib_data\n\n        elif attrib_ext == '.li2':\n            attrib_data = np.fromfile(attrib, np.int16)\n            table[attrib_name] = attrib_data\n\n        elif attrib_ext == '.li4':\n            attrib_data = np.fromfile(attrib, np.int32)\n            table[attrib_name] = attrib_data\n\n        elif attrib_ext == '.li8':\n            attrib_data = np.fromfile(attrib, np.int64)\n            table[attrib_name] = attrib_data\n\n        elif attrib_ext == '.ib1':\n            attrib_data = np.fromfile(attrib, np.bool_)\n            table[attrib_name] = attrib_data\n\n        elif attrib_ext.startswith('.iS'):\n            length_string = int(attrib_ext[3:])\n            attrib_data = np.fromfile(attrib, ('a' + str(length_string)))\n            table[attrib_name] = attrib_data\n\n        else:\n            print('Array {} is not a recognized data type'.format(attrib))\n\n    df = pd.DataFrame(table)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert nested set of directories to nested set of directories.", "response": "def convert_dirs(base_dir, hdf_name, complib=None, complevel=0):\n    \"\"\"\n    Convert nested set of directories to\n\n    \"\"\"\n    print('Converting directories in {}'.format(base_dir))\n\n    dirs = glob.glob(os.path.join(base_dir, '*'))\n    dirs = {d for d in dirs if os.path.basename(d) in DIRECTORIES}\n    if not dirs:\n        raise RuntimeError('No direcotries found matching known data.')\n\n    store = pd.HDFStore(\n        hdf_name, mode='w', complevel=complevel, complib=complib)\n\n    for dirpath in dirs:\n        dirname = os.path.basename(dirpath)\n\n        print(dirname)\n        df = cache_to_df(dirpath)\n\n        if dirname == 'travel_data':\n            keys = ['from_zone_id', 'to_zone_id']\n        elif dirname == 'annual_employment_control_totals':\n            keys = ['sector_id', 'year', 'home_based_status']\n        elif dirname == 'annual_job_relocation_rates':\n            keys = ['sector_id']\n        elif dirname == 'annual_household_control_totals':\n            keys = ['year']\n        elif dirname == 'annual_household_relocation_rates':\n            keys = ['age_of_head_max', 'age_of_head_min',\n                    'income_min', 'income_max']\n        elif dirname == 'building_sqft_per_job':\n            keys = ['zone_id', 'building_type_id']\n        elif dirname == 'counties':\n            keys = ['county_id']\n        elif dirname == 'development_event_history':\n            keys = ['building_id']\n        elif dirname == 'target_vacancies':\n            keys = ['building_type_id', 'year']\n        else:\n            keys = [dirname[:-1] + '_id']\n\n        if dirname != 'annual_household_relocation_rates':\n            df = df.set_index(keys)\n\n        for colname in df.columns:\n            if df[colname].dtype == np.float64:\n                df[colname] = df[colname].astype(np.float32)\n            elif df[colname].dtype == np.int64:\n                df[colname] = df[colname].astype(np.int32)\n            else:\n                df[colname] = df[colname]\n\n        df.info()\n        print(os.linesep)\n        store.put(dirname, df)\n\n    store.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_run_number():\n    try:\n        f = open(os.path.join(os.getenv('DATA_HOME', \".\"), 'RUNNUM'), 'r')\n        num = int(f.read())\n        f.close()\n    except Exception:\n        num = 1\n    f = open(os.path.join(os.getenv('DATA_HOME', \".\"), 'RUNNUM'), 'w')\n    f.write(str(num + 1))\n    f.close()\n    return num", "response": "Returns the run number for this execution of the model system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_range(travel_data, attr, travel_time_attr, dist, agg=np.sum):\n    travel_data = travel_data.reset_index(level=1)\n    travel_data = travel_data[travel_data[travel_time_attr] < dist]\n    travel_data[\"attr\"] = attr[travel_data.to_zone_id].values\n    return travel_data.groupby(level=0).attr.apply(agg)", "response": "Compute a zone - based accessibility query using the urbansim format travel data dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reindex(series1, series2):\n\n    # turns out the merge is much faster than the .loc below\n    df = pd.merge(pd.DataFrame({\"left\": series2}),\n                  pd.DataFrame({\"right\": series1}),\n                  left_on=\"left\",\n                  right_index=True,\n                  how=\"left\")\n    return df.right", "response": "This function reindexes the first series by the second series."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new index for the current node in the tree.", "response": "def fidx(right, left, left_fk=None):\n    \"\"\"\n    Re-indexes a series or data frame (right) to align with\n    another (left) series or data frame via foreign key relationship.\n    The index of the right must be unique.\n\n    This is similar to misc.reindex, but allows for data frame\n    re-indexes and supports re-indexing data frames or\n    series with a multi-index.\n\n    Parameters:\n    -----------\n    right: pandas.DataFrame or pandas.Series\n        Series or data frame to re-index from.\n    left: pandas.Series or pandas.DataFrame\n        Series or data frame to re-index to.\n        If a series is provided, its values serve as the foreign keys.\n        If a data frame is provided, one or more columns may be used\n        as foreign keys, must specify the ``left_fk`` argument to\n        specify which column(s) will serve as keys.\n    left_fk: optional, str or list of str\n        Used when the left is a data frame, specifies the column(s) in\n        the left to serve as foreign keys. The specified columns' ordering\n        must match the order of the multi-index in the right.\n\n    Returns:\n    --------\n    pandas.Series or pandas.DataFrame with column(s) from\n    right aligned with the left.\n\n    \"\"\"\n    # ensure that we can align correctly\n    if not right.index.is_unique:\n        raise ValueError(\"The right's index must be unique!\")\n\n    # simpler case:\n    # if the left (target) is a single series then just re-index to it\n    if isinstance(left_fk, str):\n        left = left[left_fk]\n\n    if isinstance(left, pd.Series):\n        a = right.reindex(left)\n        a.index = left.index\n        return a\n\n    # when reindexing using multiple columns (composite foreign key)\n    # i.e. the right has a multindex\n\n    # if a series for the right provided, convert to a data frame\n    if isinstance(right, pd.Series):\n        right = right.to_frame('right')\n        right_cols = 'right'\n    else:\n        right_cols = right.columns\n\n    # do the merge\n    return pd.merge(\n        left=left,\n        right=right,\n        left_on=left_fk,\n        right_index=True,\n        how='left'\n    )[right_cols]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a numpy matrix to Pandas dataframe", "response": "def numpymat2df(mat):\n    \"\"\"\n    Sometimes (though not very often) it is useful to convert a numpy matrix\n    which has no column names to a Pandas dataframe for use of the Pandas\n    functions.  This method converts a 2D numpy matrix to Pandas dataframe\n    with default column headers.\n\n    Parameters\n    ----------\n    mat : The numpy matrix\n\n    Returns\n    -------\n    A pandas dataframe with the same data as the input matrix but with columns\n    named x0,  x1, ... x[n-1] for the number of columns.\n    \"\"\"\n    return pd.DataFrame(\n        dict(('x%d' % i, mat[:, i]) for i in range(mat.shape[1])))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a Pandas dataframe from 64 bit types to 32 bit types to save memory or disk space.", "response": "def df64bitto32bit(tbl):\n    \"\"\"\n    Convert a Pandas dataframe from 64 bit types to 32 bit types to save\n    memory or disk space.\n\n    Parameters\n    ----------\n    tbl : The dataframe to convert\n\n    Returns\n    -------\n    The converted dataframe\n    \"\"\"\n    newtbl = pd.DataFrame(index=tbl.index)\n    for colname in tbl.columns:\n        newtbl[colname] = series64bitto32bit(tbl[colname])\n    return newtbl"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef series64bitto32bit(s):\n    if s.dtype == np.float64:\n        return s.astype('float32')\n    elif s.dtype == np.int64:\n        return s.astype('int32')\n    return s", "response": "Convert a Pandas series from 64 bit types to 32 bit types to save\n    memory or disk space."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pandasdfsummarytojson(df, ndigits=3):\n    df = df.transpose()\n    return {k: _pandassummarytojson(v, ndigits) for k, v in df.iterrows()}", "response": "Convert the result of a pandas describe operation to json."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef column_map(tables, columns):\n    if not columns:\n        return {t.name: None for t in tables}\n\n    columns = set(columns)\n    colmap = {t.name: list(set(t.columns).intersection(columns)) for t in tables}\n    foundcols = tz.reduce(lambda x, y: x.union(y), (set(v) for v in colmap.values()))\n    if foundcols != columns:\n        raise RuntimeError('Not all required columns were found. '\n                           'Missing: {}'.format(list(columns - foundcols)))\n    return colmap", "response": "Returns a dictionary mapping tables to lists of column names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking a list of tables and a list of column names and returns the columns that are present in the tables.", "response": "def column_list(tables, columns):\n    \"\"\"\n    Take a list of tables and a list of column names and return the columns\n    that are present in the tables.\n\n    Parameters\n    ----------\n    tables : sequence of _DataFrameWrapper or _TableFuncWrapper\n        Could also be sequence of modified pandas.DataFrames, the important\n        thing is that they have ``.name`` and ``.columns`` attributes.\n    columns : sequence of str\n        The column names of interest.\n\n    Returns\n    -------\n    cols : list\n        Lists of column names available in the tables.\n\n    \"\"\"\n    columns = set(columns)\n    foundcols = tz.reduce(lambda x, y: x.union(y), (set(t.columns) for t in tables))\n    return list(columns.intersection(foundcols))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_probs(data, prob_column=None):\n    if prob_column is None:\n        p = None\n    else:\n        p = data[prob_column].fillna(0).values\n        if p.sum() == 0:\n            p = np.ones(len(p))\n        if abs(p.sum() - 1.0) > 1e-8:\n            p = p / (1.0 * p.sum())\n    return p", "response": "Returns the probability of a given column in the data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsampling rows with accounting with replacement.", "response": "def accounting_sample_replace(total, data, accounting_column, prob_column=None, max_iterations=50):\n    \"\"\"\n    Sample rows with accounting with replacement.\n\n    Parameters\n    ----------\n    total : int\n        The control total the sampled rows will attempt to match.\n    data: pandas.DataFrame\n        Table to sample from.\n    accounting_column: string\n        Name of column with accounting totals/quantities to apply towards the control.\n    prob_column: string, optional, default None\n        Name of the column in the data to provide probabilities or weights.\n    max_iterations: int, optional, default 50\n        When using an accounting attribute, the maximum number of sampling iterations\n        that will be applied.\n\n    Returns\n    -------\n    sample_rows : pandas.DataFrame\n        Table containing the sample.\n    matched: bool\n        Indicates if the total was matched exactly.\n\n    \"\"\"\n    # check for probabilities\n    p = get_probs(data, prob_column)\n\n    # determine avg number of accounting items per sample (e.g. persons per household)\n    per_sample = data[accounting_column].sum() / (1.0 * len(data.index.values))\n\n    curr_total = 0\n    remaining = total\n    sample_rows = pd.DataFrame()\n    closest = None\n    closest_remain = total\n    matched = False\n\n    for i in range(0, max_iterations):\n\n        # stop if we've hit the control\n        if remaining == 0:\n            matched = True\n            break\n\n        # if sampling with probabilities, re-caclc the # of items per sample\n        # after the initial sample, this way the sample size reflects the probabilities\n        if p is not None and i == 1:\n            per_sample = sample_rows[accounting_column].sum() / (1.0 * len(sample_rows))\n\n        # update the sample\n        num_samples = int(math.ceil(math.fabs(remaining) / per_sample))\n\n        if remaining > 0:\n            # we're short, add to the sample\n            curr_ids = np.random.choice(data.index.values, num_samples, p=p)\n            sample_rows = pd.concat([sample_rows, data.loc[curr_ids]])\n        else:\n            # we've overshot, remove from existing samples (FIFO)\n            sample_rows = sample_rows.iloc[num_samples:].copy()\n\n        # update the total and check for the closest result\n        curr_total = sample_rows[accounting_column].sum()\n        remaining = total - curr_total\n\n        if abs(remaining) < closest_remain:\n            closest_remain = abs(remaining)\n            closest = sample_rows\n\n    return closest, matched"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples rows with accounting without replacement.", "response": "def accounting_sample_no_replace(total, data, accounting_column, prob_column=None):\n    \"\"\"\n    Samples rows with accounting without replacement.\n\n    Parameters\n    ----------\n    total : int\n        The control total the sampled rows will attempt to match.\n    data: pandas.DataFrame\n        Table to sample from.\n    accounting_column: string\n        Name of column with accounting totals/quantities to apply towards the control.\n    prob_column: string, optional, default None\n        Name of the column in the data to provide probabilities or weights.\n\n    Returns\n    -------\n    sample_rows : pandas.DataFrame\n        Table containing the sample.\n    matched: bool\n        Indicates if the total was matched exactly.\n\n    \"\"\"\n    # make sure this is even feasible\n    if total > data[accounting_column].sum():\n        raise ValueError('Control total exceeds the available samples')\n\n    # check for probabilities\n    p = get_probs(data, prob_column)\n\n    # shuffle the rows\n    if p is None:\n        # random shuffle\n        shuff_idx = np.random.permutation(data.index.values)\n    else:\n        # weighted shuffle\n        ran_p = pd.Series(np.power(np.random.rand(len(p)), 1.0 / p), index=data.index)\n        ran_p.sort_values(ascending=False)\n        shuff_idx = ran_p.index.values\n\n    # get the initial sample\n    shuffle = data.loc[shuff_idx]\n    csum = np.cumsum(shuffle[accounting_column].values)\n    pos = np.searchsorted(csum, total, 'right')\n    sample = shuffle.iloc[:pos]\n\n    # refine the sample\n    sample_idx = sample.index.values\n    sample_total = sample[accounting_column].sum()\n    shortage = total - sample_total\n    matched = False\n\n    for idx, row in shuffle.iloc[pos:].iterrows():\n        if shortage == 0:\n            # we've matached\n            matched = True\n            break\n\n        # add the current element if it doesnt exceed the total\n        cnt = row[accounting_column]\n        if cnt <= shortage:\n            sample_idx = np.append(sample_idx, idx)\n            shortage -= cnt\n\n    return shuffle.loc[sample_idx].copy(), matched"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample_rows(total, data, replace=True, accounting_column=None,\n                max_iterations=50, prob_column=None, return_status=False):\n    \"\"\"\n    Samples and returns rows from a data frame while matching a desired control total. The total may\n    represent a simple row count or may attempt to match a sum/quantity from an accounting column.\n\n    Parameters\n    ----------\n    total : int\n        The control total the sampled rows will attempt to match.\n    data: pandas.DataFrame\n        Table to sample from.\n    replace: bool, optional, default True\n        Indicates if sampling with or without replacement.\n    accounting_column: string, optional\n        Name of column with accounting totals/quantities to apply towards the control.\n        If not provided then row counts will be used for accounting.\n    max_iterations: int, optional, default 50\n        When using an accounting attribute, the maximum number of sampling iterations\n        that will be applied. Only applicable when sampling with replacement.\n    prob_column: string, optional, default None\n        If provided, name of the column in the data frame to provide probabilities\n        or weights. If not provided, the sampling is random.\n    return_status: bool, optional, default True\n        If True, will also return a bool indicating if the total was matched exactly.\n\n    Returns\n    -------\n    sample_rows : pandas.DataFrame\n        Table containing the sample.\n    matched: bool\n        If return_status is True, returns True if total is matched exactly.\n\n    \"\"\"\n    if not data.index.is_unique:\n        raise ValueError('Data must have a unique index')\n\n    # simplest case, just return n random rows\n    if accounting_column is None:\n        if replace is False and total > len(data.index.values):\n            raise ValueError('Control total exceeds the available samples')\n        p = get_probs(prob_column)\n        rows = data.loc[np.random.choice(\n            data.index.values, int(total), replace=replace, p=p)].copy()\n        matched = True\n\n    # sample with accounting\n    else:\n        if replace:\n            rows, matched = accounting_sample_replace(\n                total, data, accounting_column, prob_column, max_iterations)\n        else:\n            rows, matched = accounting_sample_no_replace(\n                total, data, accounting_column, prob_column)\n\n    # return the results\n    if return_status:\n        return rows, matched\n    else:\n        return rows", "response": "Samples the rows from a data frame while matching a desired control total."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating building cost for a set of buildings for this unit mix and height.", "response": "def _building_cost(self, use_mix, stories):\n        \"\"\"\n        Generate building cost for a set of buildings\n\n        Parameters\n        ----------\n        use_mix : array\n            The mix of uses for this form\n        stories : series\n            A Pandas Series of stories\n\n        Returns\n        -------\n        array\n            The cost per sqft for this unit mix and height.\n\n        \"\"\"\n        c = self.config\n        # stories to heights\n        heights = stories * c.height_per_story\n        # cost index for this height\n        costs = np.searchsorted(c.heights_for_costs, heights)\n        # this will get set to nan later\n        costs[np.isnan(heights)] = 0\n        # compute cost with matrix multiply\n        costs = np.dot(np.squeeze(c.costs[costs.astype('int32')]), use_mix)\n        # some heights aren't allowed - cost should be nan\n        costs[np.isnan(stories).flatten()] = np.nan\n        return costs.flatten()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a lookup table for all possible inputs in the current locale.", "response": "def _generate_lookup(self):\n        \"\"\"\n        Run the developer model on all possible inputs specified in the\n        configuration object - not generally called by the user.  This part\n        computes the final cost per sqft of the building to construct and\n        then turns it into the yearly rent necessary to make break even on\n        that cost.\n\n        \"\"\"\n        c = self.config\n\n        # get all the building forms we can use\n        keys = c.forms.keys()\n        keys = sorted(keys)\n        df_d = {}\n        for name in keys:\n            # get the use distribution for each\n            uses_distrib = c.forms[name]\n\n            for parking_config in c.parking_configs:\n\n                # going to make a dataframe to store values to make\n                # pro forma results transparent\n                df = pd.DataFrame(index=c.fars)\n                df['far'] = c.fars\n                df['pclsz'] = c.tiled_parcel_sizes\n\n                building_bulk = np.reshape(\n                    c.parcel_sizes, (-1, 1)) * np.reshape(c.fars, (1, -1))\n                building_bulk = np.reshape(building_bulk, (-1, 1))\n\n                # need to converge in on exactly how much far is available for\n                # deck pkg\n                if parking_config == 'deck':\n                    building_bulk /= (1.0 + np.sum(uses_distrib * c.parking_rates) *\n                                      c.parking_sqft_d[parking_config] /\n                                      c.sqft_per_rate)\n\n                df['building_sqft'] = building_bulk\n\n                parkingstalls = building_bulk * \\\n                    np.sum(uses_distrib * c.parking_rates) / c.sqft_per_rate\n                parking_cost = (c.parking_cost_d[parking_config] *\n                                parkingstalls *\n                                c.parking_sqft_d[parking_config])\n\n                df['spaces'] = parkingstalls\n\n                if parking_config == 'underground':\n                    df['park_sqft'] = parkingstalls * \\\n                        c.parking_sqft_d[parking_config]\n                    stories = building_bulk / c.tiled_parcel_sizes\n                if parking_config == 'deck':\n                    df['park_sqft'] = parkingstalls * \\\n                        c.parking_sqft_d[parking_config]\n                    stories = ((building_bulk + parkingstalls *\n                                c.parking_sqft_d[parking_config]) /\n                               c.tiled_parcel_sizes)\n                if parking_config == 'surface':\n                    stories = building_bulk / \\\n                        (c.tiled_parcel_sizes - parkingstalls *\n                         c.parking_sqft_d[parking_config])\n                    df['park_sqft'] = 0\n                    # not all fars support surface parking\n                    stories[stories < 0.0] = np.nan\n                    # I think we can assume that stories over 3\n                    # do not work with surface parking\n                    stories[stories > 5.0] = np.nan\n\n                df['total_built_sqft'] = df.building_sqft + df.park_sqft\n                df['parking_sqft_ratio'] = df.park_sqft / df.total_built_sqft\n                stories /= c.parcel_coverage\n                df['stories'] = np.ceil(stories)\n                df['height'] = df.stories * c.height_per_story\n                df['build_cost_sqft'] = self._building_cost(uses_distrib, stories)\n\n                df['build_cost'] = df.build_cost_sqft * df.building_sqft\n                df['park_cost'] = parking_cost\n                df['cost'] = df.build_cost + df.park_cost\n\n                df['ave_cost_sqft'] = (df.cost / df.total_built_sqft) * c.profit_factor\n\n                if name == 'retail':\n                    df['ave_cost_sqft'][c.fars > c.max_retail_height] = np.nan\n                if name == 'industrial':\n                    df['ave_cost_sqft'][c.fars > c.max_industrial_height] = np.nan\n\n                df_d[(name, parking_config)] = df\n\n        self.dev_d = df_d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookup(self, form, df, only_built=True, pass_through=None):\n        df = pd.concat(self._lookup_parking_cfg(form, parking_config, df, only_built,\n                                                pass_through)\n                       for parking_config in self.config.parking_configs)\n\n        if len(df) == 0:\n            return pd.DataFrame()\n\n        max_profit_ind = df.pivot(\n            columns=\"parking_config\",\n            values=\"max_profit\").idxmax(axis=1).to_frame(\"parking_config\")\n\n        df.set_index([\"parking_config\"], append=True, inplace=True)\n        max_profit_ind.set_index([\"parking_config\"], append=True, inplace=True)\n\n        # get the max_profit idx\n        return df.loc[max_profit_ind.index].reset_index(1)", "response": "This function will perform the actual buildings for all the actual input data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _debug_output(self):\n        import matplotlib\n        matplotlib.use('Agg')\n        import matplotlib.pyplot as plt\n        c = self.config\n\n        df_d = self.dev_d\n        keys = df_d.keys()\n        keys = sorted(keys)\n        for key in keys:\n            logger.debug(\"\\n\" + str(key) + \"\\n\")\n            logger.debug(df_d[key])\n        for form in self.config.forms:\n            logger.debug(\"\\n\" + str(key) + \"\\n\")\n            logger.debug(self.get_ave_cost_sqft(form, \"surface\"))\n\n        keys = c.forms.keys()\n        keys = sorted(keys)\n        cnt = 1\n        share = None\n        fig = plt.figure(figsize=(12, 3 * len(keys)))\n        fig.suptitle('Profitable rents by use', fontsize=40)\n        for name in keys:\n            sumdf = None\n            for parking_config in c.parking_configs:\n                df = df_d[(name, parking_config)]\n                if sumdf is None:\n                    sumdf = pd.DataFrame(df['far'])\n                sumdf[parking_config] = df['ave_cost_sqft']\n            far = sumdf['far']\n            del sumdf['far']\n\n            if share is None:\n                share = plt.subplot(len(keys) / 2, 2, cnt)\n            else:\n                plt.subplot(len(keys) / 2, 2, cnt, sharex=share, sharey=share)\n\n            handles = plt.plot(far, sumdf)\n            plt.ylabel('even_rent')\n            plt.xlabel('FAR')\n            plt.title('Rents for use type %s' % name)\n            plt.legend(\n                handles, c.parking_configs, loc='lower right',\n                title='Parking type')\n            cnt += 1\n        plt.savefig('even_rents.png', bbox_inches=0)", "response": "This function creates the debugging plots to understand the behavior of the hypothetical building model and the behavior of the hypothetical building model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_rows(data, nrows, starting_index=None, accounting_column=None):\n    logger.debug('start: adding {} rows in transition model'.format(nrows))\n    if nrows == 0:\n        return data, _empty_index(), _empty_index()\n\n    if not starting_index:\n        starting_index = data.index.values.max() + 1\n\n    new_rows = sample_rows(nrows, data, accounting_column=accounting_column)\n    copied_index = new_rows.index\n    added_index = pd.Index(np.arange(\n        starting_index, starting_index + len(new_rows.index), dtype=np.int))\n    new_rows.index = added_index\n\n    logger.debug(\n        'finish: added {} rows in transition model'.format(len(new_rows)))\n    return pd.concat([data, new_rows]), added_index, copied_index", "response": "Add rows to data table according to a given nrows."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_rows(data, nrows, accounting_column=None):\n    logger.debug('start: removing {} rows in transition model'.format(nrows))\n    nrows = abs(nrows)  # in case a negative number came in\n    unit_check = data[accounting_column].sum() if accounting_column else len(data)\n    if nrows == 0:\n        return data, _empty_index()\n    elif nrows > unit_check:\n        raise ValueError('Number of rows to remove exceeds number of records in table.')\n\n    remove_rows = sample_rows(nrows, data, accounting_column=accounting_column, replace=False)\n    remove_index = remove_rows.index\n\n    logger.debug('finish: removed {} rows in transition model'.format(nrows))\n    return data.loc[data.index.difference(remove_index)], remove_index", "response": "Remove a random nrows number of rows from a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd or remove rows to a random base language tree.", "response": "def add_or_remove_rows(data, nrows, starting_index=None, accounting_column=None):\n    \"\"\"\n    Add or remove rows to/from a table. Rows are added\n    for positive `nrows` and removed for negative `nrows`.\n\n    Parameters\n    ----------\n    data : DataFrame\n    nrows : float\n        Number of rows to add or remove.\n    starting_index : int, optional\n        The starting index from which to calculate indexes for new rows.\n        If not given the max + 1 of the index of `data` will be used.\n        (Not applicable if rows are being removed.)\n\n    Returns\n    -------\n    updated : pandas.DataFrame\n        Table with random rows removed.\n    added : pandas.Index\n        New indexes of the rows that were added.\n    copied : pandas.Index\n        Indexes of rows that were copied. A row copied multiple times\n        will have multiple entries.\n    removed : pandas.Index\n        Index of rows that were removed.\n\n    \"\"\"\n    if nrows > 0:\n        updated, added, copied = add_rows(\n            data, nrows, starting_index,\n            accounting_column=accounting_column)\n        removed = _empty_index()\n\n    elif nrows < 0:\n        updated, removed = remove_rows(data, nrows, accounting_column=accounting_column)\n        added, copied = _empty_index(), _empty_index()\n\n    else:\n        updated, added, copied, removed = \\\n            data, _empty_index(), _empty_index(), _empty_index()\n\n    return updated, added, copied, removed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the linked table with new or removed rows.", "response": "def _update_linked_table(table, col_name, added, copied, removed):\n    \"\"\"\n    Copy and update rows in a table that has a column referencing another\n    table that has had rows added via copying.\n\n    Parameters\n    ----------\n    table : pandas.DataFrame\n        Table to update with new or removed rows.\n    col_name : str\n        Name of column in `table` that corresponds to the index values\n        in `copied` and `removed`.\n    added : pandas.Index\n        Indexes of rows that are new in the linked table.\n    copied : pandas.Index\n        Indexes of rows that were copied to make new rows in linked table.\n    removed : pandas.Index\n        Indexes of rows that were removed from the linked table.\n\n    Returns\n    -------\n    updated : pandas.DataFrame\n\n    \"\"\"\n    logger.debug('start: update linked table after transition')\n\n    # handle removals\n    table = table.loc[~table[col_name].isin(set(removed))]\n    if (added is None or len(added) == 0):\n        return table\n\n    # map new IDs to the IDs from which they were copied\n    id_map = pd.concat([pd.Series(copied, name=col_name), pd.Series(added, name='temp_id')], axis=1)\n\n    # join to linked table and assign new id\n    new_rows = id_map.merge(table, on=col_name)\n    new_rows.drop(col_name, axis=1, inplace=True)\n    new_rows.rename(columns={'temp_id': col_name}, inplace=True)\n\n    # index the new rows\n    starting_index = table.index.values.max() + 1\n    new_rows.index = np.arange(starting_index, starting_index + len(new_rows), dtype=np.int)\n\n    logger.debug('finish: update linked table after transition')\n    return pd.concat([table, new_rows])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transition(self, data, year):\n        if self.accounting_column is None:\n            nrows = int(round(len(data) * self.growth_rate))\n        else:\n            nrows = int(round(data[self.accounting_column].sum() * self.growth_rate))\n        with log_start_finish(\n                'adding {} rows via growth rate ({}) transition'.format(\n                    nrows, self.growth_rate),\n                logger):\n            return add_or_remove_rows(data, nrows, accounting_column=self.accounting_column)", "response": "Add or remove rows to a table according to the prescribed growth rate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transition(self, data, year):\n        with log_start_finish('tabular totals transition', logger):\n            return super(TabularTotalsTransition, self).transition(data, year)", "response": "Add or remove rows to or from a table according to the prescribed\n            totals for this model and year."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transition(self, data, year, linked_tables=None):\n        logger.debug('start: transition')\n        linked_tables = linked_tables or {}\n        updated_links = {}\n\n        with log_start_finish('add/remove rows', logger):\n            updated, added, copied, removed = self.transitioner(data, year)\n\n        for table_name, (table, col) in linked_tables.items():\n            logger.debug('updating linked table {}'.format(table_name))\n            updated_links[table_name] = \\\n                _update_linked_table(table, col, added, copied, removed)\n\n        logger.debug('finish: transition')\n        return updated, added, updated_links", "response": "Transition a set of population targets to a new state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a pandas Series to a dict that will survive YAML serialization and re - conversion back to a Series.", "response": "def series_to_yaml_safe(series, ordered=False):\n    \"\"\"\n    Convert a pandas Series to a dict that will survive YAML serialization\n    and re-conversion back to a Series.\n\n    Parameters\n    ----------\n    series : pandas.Series\n    ordered: bool, optional, default False\n        If True, an OrderedDict is returned.\n\n    Returns\n    -------\n    safe : dict or OrderedDict\n\n    \"\"\"\n    index = series.index.to_native_types(quoting=True)\n    values = series.values.tolist()\n\n    if ordered:\n        return OrderedDict(\n            tuple((k, v)) for k, v in zip(index, values))\n    else:\n        return {i: v for i, v in zip(index, values)}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef frame_to_yaml_safe(frame, ordered=False):\n    if ordered:\n        return OrderedDict(tuple((col, series_to_yaml_safe(series, True))\n                                 for col, series in frame.iteritems()))\n    else:\n        return {col: series_to_yaml_safe(series)\n                for col, series in frame.iteritems()}", "response": "Convert a pandas DataFrame to a dictionary that will survive\n    YAML serialization and re - conversion back to a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ordered_yaml(cfg, order=None):\n    if order is None:\n        order = ['name', 'model_type', 'segmentation_col', 'fit_filters',\n                 'predict_filters',\n                 'choosers_fit_filters', 'choosers_predict_filters',\n                 'alts_fit_filters', 'alts_predict_filters',\n                 'interaction_predict_filters',\n                 'choice_column', 'sample_size', 'estimation_sample_size',\n                 'prediction_sample_size',\n                 'model_expression', 'ytransform', 'min_segment_size',\n                 'default_config', 'models', 'coefficients', 'fitted']\n\n    s = []\n    for key in order:\n        if key not in cfg:\n            continue\n        s.append(\n            yaml.dump({key: cfg[key]}, default_flow_style=False, indent=4))\n\n    for key in cfg:\n        if key in order:\n            continue\n        s.append(\n            yaml.dump({key: cfg[key]}, default_flow_style=False, indent=4))\n\n    return '\\n'.join(s)", "response": "Convert a dictionary to a YAML string with preferential ordering for some keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a dictionary to YAML and return the string or write it out.", "response": "def convert_to_yaml(cfg, str_or_buffer):\n    \"\"\"\n    Convert a dictionary to YAML and return the string or write it out\n    depending on the type of `str_or_buffer`.\n\n    Parameters\n    ----------\n    cfg : dict or OrderedDict\n        Dictionary or OrderedDict to convert.\n    str_or_buffer : None, str, or buffer\n        If None: the YAML string will be returned.\n        If string: YAML will be saved to a file.\n        If buffer: YAML will be written to buffer using the ``.write`` method.\n\n    Returns\n    -------\n    str or None\n        YAML string if `str_or_buffer` is None, otherwise None since YAML\n        is written out to a separate destination.\n\n    \"\"\"\n    order = None\n    if isinstance(cfg, OrderedDict):\n        order = []\n\n    s = ordered_yaml(cfg, order)\n\n    if not str_or_buffer:\n        return s\n    elif isinstance(str_or_buffer, str):\n        with open(str_or_buffer, 'w') as f:\n            f.write(s)\n    else:\n        str_or_buffer.write(s)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a YAML string or file - like object or buffer into a dictionary.", "response": "def yaml_to_dict(yaml_str=None, str_or_buffer=None, ordered=False):\n    \"\"\"\n    Load YAML from a string, file, or buffer (an object with a .read method).\n    Parameters are mutually exclusive.\n\n    Parameters\n    ----------\n    yaml_str : str, optional\n        A string of YAML.\n    str_or_buffer : str or file like, optional\n        File name or buffer from which to load YAML.\n    ordered: bool, optional, default False\n        If True, an OrderedDict is returned.\n\n    Returns\n    -------\n    dict\n        Conversion from YAML.\n\n    \"\"\"\n    if not yaml_str and not str_or_buffer:\n        raise ValueError('One of yaml_str or str_or_buffer is required.')\n\n    # determine which load method to use\n    if ordered:\n        loader = __ordered_load\n    else:\n        loader = yaml.load\n\n    if yaml_str:\n        d = loader(yaml_str)\n    elif isinstance(str_or_buffer, str):\n        with open(str_or_buffer) as f:\n            d = loader(f)\n    else:\n        d = loader(str_or_buffer)\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_transaction(self, amount, subaccount=None, metadata=None):\n        metadata = metadata or {}\n        self.transactions.append(Transaction(amount, subaccount, metadata))\n        self.balance += amount", "response": "Adds a new transaction to the account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef total_transactions_by_subacct(self, subaccount):\n        return sum(\n            t.amount for t in self.transactions if t.subaccount == subaccount)", "response": "Get the sum of all transactions for a given subaccount."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_frame(self):\n        col_names = _column_names_from_metadata(\n            t.metadata for t in self.transactions)\n\n        def trow(t):\n            return tz.concatv(\n                (t.amount, t.subaccount),\n                (t.metadata.get(c) for c in col_names))\n        rows = [trow(t) for t in self.transactions]\n\n        if len(rows) == 0:\n            return pd.DataFrame(columns=COLS + col_names)\n\n        return pd.DataFrame(rows, columns=COLS + col_names)", "response": "Return transactions as a pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_filter_query(df, filters=None):\n    with log_start_finish('apply filter query: {!r}'.format(filters), logger):\n        if filters:\n            if isinstance(filters, str):\n                query = filters\n            else:\n                query = ' and '.join(filters)\n            return df.query(query)\n        else:\n            return df", "response": "Use the DataFrame. query method to filter a table down to the desired rows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a name and value into a string expression compatible", "response": "def _filterize(name, value):\n    \"\"\"\n    Turn a `name` and `value` into a string expression compatible\n    the ``DataFrame.query`` method.\n\n    Parameters\n    ----------\n    name : str\n        Should be the name of a column in the table to which the\n        filter will be applied.\n\n        A suffix of '_max' will result in a \"less than\" filter,\n        a suffix of '_min' will result in a \"greater than or equal to\" filter,\n        and no recognized suffix will result in an \"equal to\" filter.\n    value : any\n        Value side of filter for comparison to column values.\n\n    Returns\n    -------\n    filter_exp : str\n\n    \"\"\"\n    if name.endswith('_min'):\n        name = name[:-4]\n        comp = '>='\n    elif name.endswith('_max'):\n        name = name[:-4]\n        comp = '<'\n    else:\n        comp = '=='\n\n    result = '{} {} {!r}'.format(name, comp, value)\n    logger.debug(\n        'converted name={} and value={} to filter {}'.format(\n            name, value, result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter a table based on a set of restrictions given in Series of column name value pairs of filter parameter pairs.", "response": "def filter_table(table, filter_series, ignore=None):\n    \"\"\"\n    Filter a table based on a set of restrictions given in\n    Series of column name / filter parameter pairs. The column\n    names can have suffixes `_min` and `_max` to indicate\n    \"less than\" and \"greater than\" constraints.\n\n    Parameters\n    ----------\n    table : pandas.DataFrame\n        Table to filter.\n    filter_series : pandas.Series\n        Series of column name / value pairs of filter constraints.\n        Columns that ends with '_max' will be used to create\n        a \"less than\" filters, columns that end with '_min' will be\n        used to create \"greater than or equal to\" filters.\n        A column with no suffix will be used to make an 'equal to' filter.\n    ignore : sequence of str, optional\n        List of column names that should not be used for filtering.\n\n    Returns\n    -------\n    filtered : pandas.DataFrame\n\n    \"\"\"\n    with log_start_finish('filter table', logger):\n        ignore = ignore if ignore else set()\n\n        filters = [_filterize(name, val)\n                   for name, val in filter_series.iteritems()\n                   if not (name in ignore or\n                           (isinstance(val, numbers.Number) and\n                            np.isnan(val)))]\n\n        return apply_filter_query(table, filters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreports whether a model expression has constant specific term.", "response": "def has_constant_expr(expr):\n    \"\"\"\n    Report whether a model expression has constant specific term.\n    That is, a term explicitly specying whether the model should or\n    should not include a constant. (e.g. '+ 1' or '- 1'.)\n\n    Parameters\n    ----------\n    expr : str\n        Model expression to check.\n\n    Returns\n    -------\n    has_constant : bool\n\n    \"\"\"\n    def has_constant(node):\n        if node.type == 'ONE':\n            return True\n\n        for n in node.args:\n            if has_constant(n):\n                return True\n\n        return False\n\n    return has_constant(patsy.parse_formula.parse_formula(expr))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a string expression to a model expression suitable for use with statsmodels and patsy.", "response": "def str_model_expression(expr, add_constant=True):\n    \"\"\"\n    We support specifying model expressions as strings, lists, or dicts;\n    but for use with patsy and statsmodels we need a string.\n    This function will take any of those as input and return a string.\n\n    Parameters\n    ----------\n    expr : str, iterable, or dict\n        A string will be returned unmodified except to add or remove\n        a constant.\n        An iterable sequence will be joined together with ' + '.\n        A dictionary should have ``right_side`` and, optionally,\n        ``left_side`` keys. The ``right_side`` can be a list or a string\n        and will be handled as above. If ``left_side`` is present it will\n        be joined with ``right_side`` with ' ~ '.\n    add_constant : bool, optional\n        Whether to add a ' + 1' (if True) or ' - 1' (if False) to the model.\n        If the expression already has a '+ 1' or '- 1' this option will be\n        ignored.\n\n    Returns\n    -------\n    model_expression : str\n        A string model expression suitable for use with statsmodels and patsy.\n\n    \"\"\"\n    if not isinstance(expr, str):\n        if isinstance(expr, collections.Mapping):\n            left_side = expr.get('left_side')\n            right_side = str_model_expression(expr['right_side'], add_constant)\n        else:\n            # some kind of iterable like a list\n            left_side = None\n            right_side = ' + '.join(expr)\n\n        if left_side:\n            model_expression = ' ~ '.join((left_side, right_side))\n        else:\n            model_expression = right_side\n\n    else:\n        model_expression = expr\n\n    if not has_constant_expr(model_expression):\n        if add_constant:\n            model_expression += ' + 1'\n        else:\n            model_expression += ' - 1'\n\n    logger.debug(\n        'converted expression: {!r} to model: {!r}'.format(\n            expr, model_expression))\n    return model_expression"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sorted_groupby(df, groupby):\n    start = 0\n    prev = df[groupby].iloc[start]\n    for i, x in enumerate(df[groupby]):\n        if x != prev:\n            yield prev, df.iloc[start:i]\n            prev = x\n            start = i\n    # need to send back the last group\n    yield prev, df.iloc[start:]", "response": "Perform a groupby on a DataFrame using a specific column\nAttributeNames and assuming that the column is sorted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef columns_in_filters(filters):\n    if not filters:\n        return []\n\n    if not isinstance(filters, str):\n        filters = ' '.join(filters)\n\n    columns = []\n    reserved = {'and', 'or', 'in', 'not'}\n\n    for toknum, tokval, _, _, _ in generate_tokens(StringIO(filters).readline):\n        if toknum == NAME and tokval not in reserved:\n            columns.append(tokval)\n\n    return list(tz.unique(columns))", "response": "Returns a list of the columns used in a set of query filters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield all the individual tokens from within a patsy formula.", "response": "def _tokens_from_patsy(node):\n    \"\"\"\n    Yields all the individual tokens from within a patsy formula\n    as parsed by patsy.parse_formula.parse_formula.\n\n    Parameters\n    ----------\n    node : patsy.parse_formula.ParseNode\n\n    \"\"\"\n    for n in node.args:\n        for t in _tokens_from_patsy(n):\n            yield t\n\n    if node.token:\n        yield node.token"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef columns_in_formula(formula):\n    if formula is None:\n        return []\n\n    formula = str_model_expression(formula, add_constant=False)\n    columns = []\n\n    tokens = map(\n        lambda x: x.extra,\n        tz.remove(\n            lambda x: x.extra is None,\n            _tokens_from_patsy(patsy.parse_formula.parse_formula(formula))))\n\n    for tok in tokens:\n        # if there are parentheses in the expression we\n        # want to drop them and everything outside\n        # and start again from the top\n        if '(' in tok:\n            start = tok.find('(') + 1\n            fin = tok.rfind(')')\n            columns.extend(columns_in_formula(tok[start:fin]))\n        else:\n            for toknum, tokval, _, _, _ in generate_tokens(\n                    StringIO(tok).readline):\n                if toknum == NAME:\n                    columns.append(tokval)\n\n    return list(tz.unique(columns))", "response": "Returns the names of all the columns used in a patsy formula."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse statsmodels OLS to construct a model relation.", "response": "def fit_model(df, filters, model_expression):\n    \"\"\"\n    Use statsmodels OLS to construct a model relation.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Data to use for fit. Should contain all the columns\n        referenced in the `model_expression`.\n    filters : list of str\n        Any filters to apply before doing the model fit.\n    model_expression : str\n        A patsy model expression that can be used with statsmodels.\n        Should contain both the left- and right-hand sides.\n\n    Returns\n    -------\n    fit : statsmodels.regression.linear_model.OLSResults\n\n    \"\"\"\n    df = util.apply_filter_query(df, filters)\n    model = smf.ols(formula=model_expression, data=df)\n\n    if len(model.exog) != len(df):\n        raise ModelEvaluationError(\n            'Estimated data does not have the same length as input.  '\n            'This suggests there are null values in one or more of '\n            'the input columns.')\n\n    with log_start_finish('statsmodels OLS fit', logger):\n        return model.fit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nproduces a pandas DataFrame of model fit results from a statsmodels. LinearModel fit result object.", "response": "def _model_fit_to_table(fit):\n    \"\"\"\n    Produce a pandas DataFrame of model fit results from a statsmodels\n    fit result object.\n\n    Parameters\n    ----------\n    fit : statsmodels.regression.linear_model.RegressionResults\n\n    Returns\n    -------\n    fit_parameters : pandas.DataFrame\n        Will have columns 'Coefficient', 'Std. Error', and 'T-Score'.\n        Index will be model terms.\n\n        This frame will also have non-standard attributes\n        .rsquared and .rsquared_adj with the same meaning and value\n        as on `fit`.\n\n    \"\"\"\n    fit_parameters = pd.DataFrame(\n        {'Coefficient': fit.params,\n         'Std. Error': fit.bse,\n         'T-Score': fit.tvalues})\n    fit_parameters.rsquared = fit.rsquared\n    fit_parameters.rsquared_adj = fit.rsquared_adj\n    return fit_parameters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npredict new values by running data through the fit model.", "response": "def predict(self, data):\n        \"\"\"\n        Predict new values by running data through the fit model.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame\n            Table with columns corresponding to the RHS of `model_expression`.\n\n        Returns\n        -------\n        predicted : ndarray\n            Array of predicted values.\n\n        \"\"\"\n        with log_start_finish('_FakeRegressionResults prediction', logger):\n            model_design = dmatrix(\n                self._rhs, data=data, return_type='dataframe')\n            return model_design.dot(self.params).values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_yaml(cls, yaml_str=None, str_or_buffer=None):\n        cfg = yamlio.yaml_to_dict(yaml_str, str_or_buffer)\n\n        model = cls(\n            cfg['fit_filters'],\n            cfg['predict_filters'],\n            cfg['model_expression'],\n            YTRANSFORM_MAPPING[cfg['ytransform']],\n            cfg['name'])\n\n        if 'fitted' in cfg and cfg['fitted']:\n            fit_parameters = pd.DataFrame(cfg['fit_parameters'])\n            fit_parameters.rsquared = cfg['fit_rsquared']\n            fit_parameters.rsquared_adj = cfg['fit_rsquared_adj']\n\n            model.model_fit = _FakeRegressionResults(\n                model.str_model_expression,\n                fit_parameters,\n                cfg['fit_rsquared'], cfg['fit_rsquared_adj'])\n            model.fit_parameters = fit_parameters\n\n        logger.debug('loaded regression model {} from YAML'.format(model.name))\n        return model", "response": "Create a RegressionModel instance from a saved YAML string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfitting the model to data and store the results in the estimator.", "response": "def fit(self, data, debug=False):\n        \"\"\"\n        Fit the model to data and store/return the results.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame\n            Data to use for fitting the model. Must contain all the\n            columns referenced by the `model_expression`.\n        debug : bool\n            If debug is set to true, this sets the attribute \"est_data\"\n            to a dataframe with the actual data used for estimation of\n            this model.\n\n        Returns\n        -------\n        fit : statsmodels.regression.linear_model.OLSResults\n            This is returned for inspection, but also stored on the\n            class instance for use during prediction.\n\n        \"\"\"\n        with log_start_finish('fitting model {}'.format(self.name), logger):\n            fit = fit_model(data, self.fit_filters, self.str_model_expression)\n\n        self.model_fit = fit\n        self.fit_parameters = _model_fit_to_table(fit)\n        if debug:\n            index = util.apply_filter_query(data, self.fit_filters).index\n            assert len(fit.model.exog) == len(index), (\n                \"The estimate data is unequal in length to the original \"\n                \"dataframe, usually caused by nans\")\n            df = pd.DataFrame(\n                fit.model.exog, columns=fit.model.exog_names, index=index)\n            df[fit.model.endog_names] = fit.model.endog\n            df[\"fittedvalues\"] = fit.fittedvalues\n            df[\"residuals\"] = fit.resid\n            self.est_data = df\n        return fit"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints a report of the fit results.", "response": "def report_fit(self):\n        \"\"\"\n        Print a report of the fit results.\n\n        \"\"\"\n        if not self.fitted:\n            print('Model not yet fit.')\n            return\n\n        print('R-Squared: {0:.3f}'.format(self.model_fit.rsquared))\n        print('Adj. R-Squared: {0:.3f}'.format(self.model_fit.rsquared_adj))\n        print('')\n\n        tbl = PrettyTable(\n            ['Component', ])\n        tbl = PrettyTable()\n\n        tbl.add_column('Component', self.fit_parameters.index.values)\n        for col in ('Coefficient', 'Std. Error', 'T-Score'):\n            tbl.add_column(col, self.fit_parameters[col].values)\n\n        tbl.align['Component'] = 'l'\n        tbl.float_format = '.3'\n\n        print(tbl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(self, data):\n        self.assert_fitted()\n        with log_start_finish('predicting model {}'.format(self.name), logger):\n            return predict(\n                data, self.predict_filters, self.model_fit, self.ytransform)", "response": "Predict a new data set based on an estimated model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary representation of a RegressionModel instance.", "response": "def to_dict(self):\n        \"\"\"\n        Returns a dictionary representation of a RegressionModel instance.\n\n        \"\"\"\n        d = {\n            'model_type': 'regression',\n            'name': self.name,\n            'fit_filters': self.fit_filters,\n            'predict_filters': self.predict_filters,\n            'model_expression': self.model_expression,\n            'ytransform': YTRANSFORM_MAPPING[self.ytransform],\n            'fitted': self.fitted,\n            'fit_parameters': None,\n            'fit_rsquared': None,\n            'fit_rsquared_adj': None\n        }\n\n        if self.fitted:\n            d['fit_parameters'] = yamlio.frame_to_yaml_safe(\n                self.fit_parameters)\n            d['fit_rsquared'] = float(self.model_fit.rsquared)\n            d['fit_rsquared_adj'] = float(self.model_fit.rsquared_adj)\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the columns used in this model for filtering and in the model expression.", "response": "def columns_used(self):\n        \"\"\"\n        Returns all the columns used in this model for filtering\n        and in the model expression.\n\n        \"\"\"\n        return list(tz.unique(tz.concatv(\n            util.columns_in_filters(self.fit_filters),\n            util.columns_in_filters(self.predict_filters),\n            util.columns_in_formula(self.model_expression))))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit_from_cfg(cls, df, cfgname, debug=False, outcfgname=None):\n        logger.debug('start: fit from configuration {}'.format(cfgname))\n        hm = cls.from_yaml(str_or_buffer=cfgname)\n        ret = hm.fit(df, debug=debug)\n        print(ret.summary())\n        outcfgname = outcfgname or cfgname\n        hm.to_yaml(str_or_buffer=outcfgname)\n        logger.debug('finish: fit into configuration {}'.format(outcfgname))\n        return hm", "response": "Fits a RegressionModel from a given yaml config file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict_from_cfg(cls, df, cfgname):\n        logger.debug('start: predict from configuration {}'.format(cfgname))\n        hm = cls.from_yaml(str_or_buffer=cfgname)\n\n        price_or_rent = hm.predict(df)\n        print(price_or_rent.describe())\n\n        logger.debug('start: predict from configuration {}'.format(cfgname))\n        return price_or_rent, hm", "response": "Predict the hedonic model for a given configuration file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_model(self, model):\n        logger.debug(\n            'adding model {} to group {}'.format(model.name, self.name))\n        self.models[model.name] = model", "response": "Adds a model instance to the set of models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_model_from_params(self, name, fit_filters, predict_filters,\n                              model_expression, ytransform=None):\n        \"\"\"\n        Add a model by passing arguments through to `RegressionModel`.\n\n        Parameters\n        ----------\n        name : any\n            Must match a groupby segment name.\n        fit_filters : list of str\n            Filters applied before fitting the model.\n        predict_filters : list of str\n            Filters applied before calculating new data points.\n        model_expression : str\n            A patsy model expression that can be used with statsmodels.\n            Should contain both the left- and right-hand sides.\n        ytransform : callable, optional\n            A function to call on the array of predicted output.\n            For example, if the model relation is predicting the log\n            of price, you might pass ``ytransform=np.exp`` so that\n            the results reflect actual price.\n\n            By default no transformation is applied.\n\n        \"\"\"\n        logger.debug(\n            'adding model {} to group {}'.format(name, self.name))\n        model = RegressionModel(\n            fit_filters, predict_filters, model_expression, ytransform, name)\n        self.models[name] = model", "response": "Adds a model to the group by passing arguments through to RegressionModel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _iter_groups(self, data):\n        groups = data.groupby(self.segmentation_col)\n\n        for name in self.models:\n            yield name, groups.get_group(name)", "response": "Iterate over the groups in data after grouping by segmentation_col. Skips any groups for which there is no model stored."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(self, data, debug=False):\n        with log_start_finish(\n                'fitting models in group {}'.format(self.name), logger):\n            return {name: self.models[name].fit(df, debug=debug)\n                    for name, df in self._iter_groups(data)}", "response": "Fit each of the models in the group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, data):\n        with log_start_finish(\n                'predicting models in group {}'.format(self.name), logger):\n            results = [self.models[name].predict(df)\n                       for name, df in self._iter_groups(data)]\n        return pd.concat(results)", "response": "Predict new data for each group in the segmentation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_yaml(cls, yaml_str=None, str_or_buffer=None):\n        cfg = yamlio.yaml_to_dict(yaml_str, str_or_buffer)\n\n        default_model_expr = cfg['default_config']['model_expression']\n        default_ytransform = cfg['default_config']['ytransform']\n\n        seg = cls(\n            cfg['segmentation_col'], cfg['fit_filters'],\n            cfg['predict_filters'], default_model_expr,\n            YTRANSFORM_MAPPING[default_ytransform], cfg['min_segment_size'],\n            cfg['name'])\n\n        if \"models\" not in cfg:\n            cfg[\"models\"] = {}\n\n        for name, m in cfg['models'].items():\n            m['model_expression'] = m.get(\n                'model_expression', default_model_expr)\n            m['ytransform'] = m.get('ytransform', default_ytransform)\n            m['fit_filters'] = None\n            m['predict_filters'] = None\n            reg = RegressionModel.from_yaml(yamlio.convert_to_yaml(m, None))\n            seg._group.add_model(reg)\n\n        logger.debug(\n            'loaded segmented regression model {} from yaml'.format(seg.name))\n        return seg", "response": "Create a SegmentedRegressionModel instance from a saved YAML string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_segment(self, name, model_expression=None, ytransform='default'):\n        if not model_expression:\n            if self.default_model_expr is None:\n                raise ValueError(\n                    'No default model available, '\n                    'you must supply a model experssion.')\n            model_expression = self.default_model_expr\n\n        if ytransform == 'default':\n            ytransform = self.default_ytransform\n\n        # no fit or predict filters, we'll take care of that this side.\n        self._group.add_model_from_params(\n            name, None, None, model_expression, ytransform)\n\n        logger.debug('added segment {} to model {}'.format(name, self.name))", "response": "Add a new segment to the group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit(self, data, debug=False):\n        data = util.apply_filter_query(data, self.fit_filters)\n\n        unique = data[self.segmentation_col].unique()\n        value_counts = data[self.segmentation_col].value_counts()\n\n        # Remove any existing segments that may no longer have counterparts\n        # in the data. This can happen when loading a saved model and then\n        # calling this method with data that no longer has segments that\n        # were there the last time this was called.\n        gone = set(self._group.models) - set(unique)\n        for g in gone:\n            del self._group.models[g]\n\n        for x in unique:\n            if x not in self._group.models and \\\n                    value_counts[x] > self.min_segment_size:\n                self.add_segment(x)\n\n        with log_start_finish(\n                'fitting models in segmented model {}'.format(self.name),\n                logger):\n            return self._group.fit(data, debug=debug)", "response": "Fit each segment in the segmented model with the given data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts new data for each group in the segmentation.", "response": "def predict(self, data):\n        \"\"\"\n        Predict new data for each group in the segmentation.\n\n        Parameters\n        ----------\n        data : pandas.DataFrame\n            Data to use for prediction. Must have a column with the\n            same name as `segmentation_col`.\n\n        Returns\n        -------\n        predicted : pandas.Series\n            Predicted data in a pandas Series. Will have the index of `data`\n            after applying filters.\n\n        \"\"\"\n        with log_start_finish(\n                'predicting models in segmented model {}'.format(self.name),\n                logger):\n            data = util.apply_filter_query(data, self.predict_filters)\n            return self._group.predict(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_model_dict(self, d):\n        del d['model_type']\n        del d['fit_filters']\n        del d['predict_filters']\n\n        if d['model_expression'] == self.default_model_expr:\n            del d['model_expression']\n\n        if YTRANSFORM_MAPPING[d['ytransform']] == self.default_ytransform:\n            del d['ytransform']\n\n        d[\"name\"] = yamlio.to_scalar_safe(d[\"name\"])\n\n        return d", "response": "Process a dictionary of model - specific items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dict(self):\n        return {\n            'model_type': 'segmented_regression',\n            'name': self.name,\n            'segmentation_col': self.segmentation_col,\n            'fit_filters': self.fit_filters,\n            'predict_filters': self.predict_filters,\n            'min_segment_size': self.min_segment_size,\n            'default_config': {\n                'model_expression': self.default_model_expr,\n                'ytransform': YTRANSFORM_MAPPING[self.default_ytransform]\n            },\n            'fitted': self.fitted,\n            'models': {\n                yamlio.to_scalar_safe(name):\n                    self._process_model_dict(m.to_dict())\n                for name, m in self._group.models.items()}\n        }", "response": "Returns a dict representation of this instance suitable for conversion to YAML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef columns_used(self):\n        return list(tz.unique(tz.concatv(\n            util.columns_in_filters(self.fit_filters),\n            util.columns_in_filters(self.predict_filters),\n            util.columns_in_formula(self.default_model_expr),\n            self._group.columns_used(),\n            [self.segmentation_col])))", "response": "Returns all the columns used across all models in the group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit the model from a given yaml config file.", "response": "def fit_from_cfg(cls, df, cfgname, debug=False, min_segment_size=None, outcfgname=None):\n        \"\"\"\n        Parameters\n        ----------\n        df : DataFrame\n            The dataframe which contains the columns to use for the estimation.\n        cfgname : string\n            The name of the yaml config file which describes the hedonic model.\n        debug : boolean, optional (default False)\n            Whether to generate debug information on the model.\n        min_segment_size : int, optional\n            Set attribute on the model.\n        outcfgname : string, optional (default cfgname)\n            The name of the output yaml config file where estimation results are written into.\n\n        Returns\n        -------\n        hm : SegmentedRegressionModel which was used to fit\n        \"\"\"\n        logger.debug('start: fit from configuration {}'.format(cfgname))\n        hm = cls.from_yaml(str_or_buffer=cfgname)\n        if min_segment_size:\n            hm.min_segment_size = min_segment_size\n\n        for k, v in hm.fit(df, debug=debug).items():\n            print(\"REGRESSION RESULTS FOR SEGMENT %s\\n\" % str(k))\n            print(v.summary())\n        outcfgname = outcfgname or cfgname\n        hm.to_yaml(str_or_buffer=outcfgname)\n        logger.debug('finish: fit into configuration {}'.format(outcfgname))\n        return hm"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_movers(choosers, rates, rate_column):\n    logger.debug('start: find movers for relocation')\n    relocation_rates = pd.Series(\n        np.zeros(len(choosers)), index=choosers.index)\n\n    for _, row in rates.iterrows():\n        indexes = util.filter_table(choosers, row, ignore={rate_column}).index\n        relocation_rates.loc[indexes] = row[rate_column]\n\n    movers = relocation_rates.index[\n        relocation_rates > np.random.random(len(choosers))]\n    logger.debug('picked {} movers for relocation'.format(len(movers)))\n    logger.debug('finish: find movers for relocation')\n    return movers", "response": "Find the indices of the choosers that are slated by relocation rates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the adjustments to prices to compensate for the given locations.", "response": "def _calculate_adjustment(\n        lcm, choosers, alternatives, alt_segmenter,\n        clip_change_low, clip_change_high, multiplier_func=None):\n    \"\"\"\n    Calculate adjustments to prices to compensate for\n    supply and demand effects.\n\n    Parameters\n    ----------\n    lcm : LocationChoiceModel\n        Used to calculate the probability of agents choosing among\n        alternatives. Must be fully configured and fitted.\n    choosers : pandas.DataFrame\n    alternatives : pandas.DataFrame\n    alt_segmenter : pandas.Series\n        Will be used to segment alternatives and probabilities to do\n        comparisons of supply and demand by submarket.\n    clip_change_low : float\n        The minimum amount by which to multiply prices each iteration.\n    clip_change_high : float\n        The maximum amount by which to multiply prices each iteration.\n    multiplier_func : function (returns Series, boolean)\n        A function which takes separate demand and supply Series\n        and returns a tuple where the first item is a Series with the\n        ratio of new price to old price (all indexes should be the same) -\n        by default the ratio of demand to supply is the ratio of the new\n        price to the old price.  The second return value is a\n        boolean which when True tells this module to stop looping (that\n        convergence has been satisfied)\n\n    Returns\n    -------\n    alts_muliplier : pandas.Series\n        Same index as `alternatives`, values clipped to `clip_change_low`\n        and `clip_change_high`.\n    submarkets_multiplier : pandas.Series\n        Index is unique values from `alt_segmenter`, values are the ratio\n        of demand / supply for each segment in `alt_segmenter`.\n    finished : boolean\n        boolean indicator that this adjustment should be considered the\n        final adjustment (if True).  If false, the iterative algorithm\n        should continue.\n\n    \"\"\"\n    logger.debug('start: calculate supply and demand price adjustment ratio')\n    # probabilities of agents choosing * number of agents = demand\n    demand = lcm.summed_probabilities(choosers, alternatives)\n    # group by submarket\n    demand = demand.groupby(alt_segmenter.loc[demand.index].values).sum()\n\n    # number of alternatives\n    supply = alt_segmenter.value_counts()\n\n    if multiplier_func is not None:\n        multiplier, finished = multiplier_func(demand, supply)\n    else:\n        multiplier, finished = (demand / supply), False\n    multiplier = multiplier.clip(clip_change_low, clip_change_high)\n\n    # broadcast multiplier back to alternatives index\n    alts_muliplier = multiplier.loc[alt_segmenter]\n    alts_muliplier.index = alt_segmenter.index\n\n    logger.debug(\n        ('finish: calculate supply and demand price adjustment multiplier '\n         'with mean multiplier {}').format(multiplier.mean()))\n    return alts_muliplier, multiplier, finished"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the probability of agents choosing a given set of alternatives and demand.", "response": "def supply_and_demand(\n        lcm, choosers, alternatives, alt_segmenter, price_col,\n        base_multiplier=None, clip_change_low=0.75, clip_change_high=1.25,\n        iterations=5, multiplier_func=None):\n    \"\"\"\n    Adjust real estate prices to compensate for supply and demand effects.\n\n    Parameters\n    ----------\n    lcm : LocationChoiceModel\n        Used to calculate the probability of agents choosing among\n        alternatives. Must be fully configured and fitted.\n    choosers : pandas.DataFrame\n    alternatives : pandas.DataFrame\n    alt_segmenter : str, array, or pandas.Series\n        Will be used to segment alternatives and probabilities to do\n        comparisons of supply and demand by submarket.\n        If a string, it is expected to be the name of a column\n        in `alternatives`. If a Series it should have the same index\n        as `alternatives`.\n    price_col : str\n        The name of the column in `alternatives` that corresponds to price.\n        This column is what is adjusted by this model.\n    base_multiplier : pandas.Series, optional\n        A series describing a starting multiplier for submarket prices.\n        Index should be submarket IDs.\n    clip_change_low : float, optional\n        The minimum amount by which to multiply prices each iteration.\n    clip_change_high : float, optional\n        The maximum amount by which to multiply prices each iteration.\n    iterations : int, optional\n        Number of times to update prices based on supply/demand comparisons.\n    multiplier_func : function (returns Series, boolean)\n        A function which takes separate demand and supply Series\n        and returns a tuple where the first item is a Series with the\n        ratio of new price to old price (all indexes should be the same) -\n        by default the ratio of demand to supply is the ratio of the new\n        price to the old price.  The second return value is a\n        boolean which when True tells this module to stop looping (that\n        convergence has been satisfied)\n\n    Returns\n    -------\n    new_prices : pandas.Series\n        Equivalent of the `price_col` in `alternatives`.\n    submarkets_ratios : pandas.Series\n        Price adjustment ratio for each submarket. If `base_multiplier` is\n        given this will be a cummulative multiplier including the\n        `base_multiplier` and the multipliers calculated for this year.\n\n    \"\"\"\n    logger.debug('start: calculating supply and demand price adjustment')\n    # copy alternatives so we don't modify the user's original\n    alternatives = alternatives.copy()\n\n    # if alt_segmenter is a string, get the actual column for segmenting demand\n    if isinstance(alt_segmenter, str):\n        alt_segmenter = alternatives[alt_segmenter]\n    elif isinstance(alt_segmenter, np.array):\n        alt_segmenter = pd.Series(alt_segmenter, index=alternatives.index)\n\n    choosers, alternatives = lcm.apply_predict_filters(choosers, alternatives)\n    alt_segmenter = alt_segmenter.loc[alternatives.index]\n\n    # check base ratio and apply it to prices if given\n    if base_multiplier is not None:\n        bm = base_multiplier.loc[alt_segmenter]\n        bm.index = alt_segmenter.index\n        alternatives[price_col] = alternatives[price_col] * bm\n        base_multiplier = base_multiplier.copy()\n\n    for _ in range(iterations):\n        alts_muliplier, submarkets_multiplier, finished = _calculate_adjustment(\n            lcm, choosers, alternatives, alt_segmenter,\n            clip_change_low, clip_change_high, multiplier_func=multiplier_func)\n        alternatives[price_col] = alternatives[price_col] * alts_muliplier\n\n        # might need to initialize this for holding cumulative multiplier\n        if base_multiplier is None:\n            base_multiplier = pd.Series(\n                np.ones(len(submarkets_multiplier)),\n                index=submarkets_multiplier.index)\n\n        base_multiplier *= submarkets_multiplier\n\n        if finished:\n            break\n\n    logger.debug('finish: calculating supply and demand price adjustment')\n    return alternatives[price_col], base_multiplier"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _max_form(f, colname):\n        df = f.stack(level=0)[[colname]].stack().unstack(level=1).reset_index(level=1, drop=True)\n        return df.idxmax(axis=1)", "response": "Returns the maximum value of the column named colname in the dataframe f."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the number of units to build for a given target vacancy.", "response": "def compute_units_to_build(num_agents, num_units, target_vacancy):\n        \"\"\"\n        Compute number of units to build to match target vacancy.\n\n        Parameters\n        ----------\n        num_agents : int\n            number of agents that need units in the region\n        num_units : int\n            number of units in buildings\n        target_vacancy : float (0-1.0)\n            target vacancy rate\n\n        Returns\n        -------\n        number_of_units : int\n            the number of units that need to be built\n        \"\"\"\n        print(\"Number of agents: {:,}\".format(num_agents))\n        print(\"Number of agent spaces: {:,}\".format(int(num_units)))\n        assert target_vacancy < 1.0\n        target_units = int(max(num_agents / (1 - target_vacancy) - num_units, 0))\n        print(\"Current vacancy = {:.2f}\"\n              .format(1 - num_agents / float(num_units)))\n        print(\"Target vacancy = {:.2f}, target of new units = {:,}\"\n              .format(target_vacancy, target_units))\n        return target_units"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchoosing the buildings from the list that are feasible to build in order to match the specified demand. Parameters ---------- form : string or list One or more of the building forms from the pro forma specification - e.g. \"residential\" or \"mixedresidential\" - these are configuration parameters passed previously to the pro forma. If more than one form is passed the forms compete with each other (based on profitability) for which one gets built in order to meet demand. target_units : int The number of units to build. For non-residential buildings this should be passed as the number of job spaces that need to be created. parcel_size : series The size of the parcels. This was passed to feasibility as well, but should be passed here as well. Index should be parcel_ids. ave_unit_size : series The average residential unit size around each parcel - this is indexed by parcel, but is usually a disaggregated version of a zonal or accessibility aggregation. bldg_sqft_per_job : float (default 400.0) The average square feet per job for this building form. min_unit_size : float Values less than this number in ave_unit_size will be set to this number. Deals with cases where units are currently not built. current_units : series The current number of units on the parcel. Is used to compute the net number of units produced by the developer model. Many times the developer model is redeveloping units (demolishing them) and is trying to meet a total number of net units produced. max_parcel_size : float Parcels larger than this size will not be considered for development - usually large parcels should be specified manually in a development projects table. drop_after_build : bool Whether or not to drop parcels from consideration after they have been chosen for development. Usually this is true so as to not develop the same parcel twice. residential: bool If creating non-residential buildings set this to false and developer will fill in job_spaces rather than residential_units profit_to_prob_func: function As there are so many ways to turn the development feasibility into a probability to select it for building, the user may pass a function which takes the feasibility dataframe and returns a series of probabilities. If no function is passed, the behavior of this method will not change Returns ------- None if thar are no feasible buildings new_buildings : dataframe DataFrame of buildings to add. These buildings are rows from the DataFrame that is returned from feasibility.", "response": "def pick(self, form, target_units, parcel_size, ave_unit_size,\n             current_units, max_parcel_size=200000, min_unit_size=400,\n             drop_after_build=True, residential=True, bldg_sqft_per_job=400.0,\n             profit_to_prob_func=None):\n        \"\"\"\n        Choose the buildings from the list that are feasible to build in\n        order to match the specified demand.\n\n        Parameters\n        ----------\n        form : string or list\n            One or more of the building forms from the pro forma specification -\n            e.g. \"residential\" or \"mixedresidential\" - these are configuration\n            parameters passed previously to the pro forma.  If more than one form\n            is passed the forms compete with each other (based on profitability)\n            for which one gets built in order to meet demand.\n        target_units : int\n            The number of units to build.  For non-residential buildings this\n            should be passed as the number of job spaces that need to be created.\n        parcel_size : series\n            The size of the parcels.  This was passed to feasibility as well,\n            but should be passed here as well.  Index should be parcel_ids.\n        ave_unit_size : series\n            The average residential unit size around each parcel - this is\n            indexed by parcel, but is usually a disaggregated version of a\n            zonal or accessibility aggregation.\n        bldg_sqft_per_job : float (default 400.0)\n            The average square feet per job for this building form.\n        min_unit_size : float\n            Values less than this number in ave_unit_size will be set to this\n            number.  Deals with cases where units are currently not built.\n        current_units : series\n            The current number of units on the parcel.  Is used to compute the\n            net number of units produced by the developer model.  Many times\n            the developer model is redeveloping units (demolishing them) and\n            is trying to meet a total number of net units produced.\n        max_parcel_size : float\n            Parcels larger than this size will not be considered for\n            development - usually large parcels should be specified manually\n            in a development projects table.\n        drop_after_build : bool\n            Whether or not to drop parcels from consideration after they\n            have been chosen for development.  Usually this is true so as\n            to not develop the same parcel twice.\n        residential: bool\n            If creating non-residential buildings set this to false and\n            developer will fill in job_spaces rather than residential_units\n        profit_to_prob_func: function\n            As there are so many ways to turn the development feasibility\n            into a probability to select it for building, the user may pass\n            a function which takes the feasibility dataframe and returns\n            a series of probabilities.  If no function is passed, the behavior\n            of this method will not change\n\n        Returns\n        -------\n        None if thar are no feasible buildings\n        new_buildings : dataframe\n            DataFrame of buildings to add.  These buildings are rows from the\n            DataFrame that is returned from feasibility.\n        \"\"\"\n\n        if len(self.feasibility) == 0:\n            # no feasible buildings, might as well bail\n            return\n\n        if form is None:\n            df = self.feasibility\n        elif isinstance(form, list):\n            df = self.keep_form_with_max_profit(form)\n        else:\n            df = self.feasibility[form]\n\n        # feasible buildings only for this building type\n        df = df[df.max_profit_far > 0]\n        ave_unit_size[ave_unit_size < min_unit_size] = min_unit_size\n        df[\"ave_unit_size\"] = ave_unit_size\n        df[\"parcel_size\"] = parcel_size\n        df['current_units'] = current_units\n        df = df[df.parcel_size < max_parcel_size]\n\n        df['residential_units'] = (df.residential_sqft / df.ave_unit_size).round()\n        df['job_spaces'] = (df.non_residential_sqft / bldg_sqft_per_job).round()\n\n        if residential:\n            df['net_units'] = df.residential_units - df.current_units\n        else:\n            df['net_units'] = df.job_spaces - df.current_units\n        df = df[df.net_units > 0]\n\n        if len(df) == 0:\n            print(\"WARNING THERE ARE NO FEASIBLE BUILDING TO CHOOSE FROM\")\n            return\n\n        # print \"Describe of net units\\n\", df.net_units.describe()\n        print(\"Sum of net units that are profitable: {:,}\"\n              .format(int(df.net_units.sum())))\n\n        if profit_to_prob_func:\n            p = profit_to_prob_func(df)\n        else:\n            df['max_profit_per_size'] = df.max_profit / df.parcel_size\n            p = df.max_profit_per_size.values / df.max_profit_per_size.sum()\n\n        if df.net_units.sum() < target_units:\n            print(\"WARNING THERE WERE NOT ENOUGH PROFITABLE UNITS TO\",\n                  \"MATCH DEMAND\")\n            build_idx = df.index.values\n        elif target_units <= 0:\n            build_idx = []\n        else:\n            # we don't know how many developments we will need, as they differ in net_units.\n            # If all developments have net_units of 1 than we need target_units of them.\n            # So we choose the smaller of available developments and target_units.\n            choices = np.random.choice(df.index.values, size=min(len(df.index), target_units),\n                                       replace=False, p=p)\n            tot_units = df.net_units.loc[choices].values.cumsum()\n            ind = int(np.searchsorted(tot_units, target_units, side=\"left\")) + 1\n            build_idx = choices[:ind]\n\n        if drop_after_build:\n            self.feasibility = self.feasibility.drop(build_idx)\n\n        new_df = df.loc[build_idx]\n        new_df.index.name = \"parcel_id\"\n        return new_df.reset_index()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(old_df, new_df, return_index=False):\n        maxind = np.max(old_df.index.values)\n        new_df = new_df.reset_index(drop=True)\n        new_df.index = new_df.index + maxind + 1\n        concat_df = pd.concat([old_df, new_df], verify_integrity=True)\n        concat_df.index.name = 'building_id'\n\n        if return_index:\n            return concat_df, new_df.index\n\n        return concat_df", "response": "Merge two dataframes of buildings and returns a dataframe of the same size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a new map with the given dataframes.", "response": "def start(views,\n          center=[37.7792, -122.2191],\n          zoom=11,\n          shape_json='data/zones.json',\n          geom_name='ZONE_ID',  # from JSON file\n          join_name='zone_id',  # from data frames\n          precision=8,\n          port=8765,\n          host='localhost',\n          testing=False):\n    \"\"\"\n    Start the web service which serves the Pandas queries and generates the\n    HTML for the map.  You will need to open a web browser and navigate to\n    http://localhost:8765 (or the specified port)\n\n    Parameters\n    ----------\n    views : Python dictionary\n        This is the data that will be displayed in the maps.  Keys are strings\n        (table names) and values are dataframes.  Each data frame should have a\n        column with the name specified as join_name below\n    center : a Python list with two floats\n        The initial latitude and longitude of the center of the map\n    zoom : int\n        The initial zoom level of the map\n    shape_json : str\n        The path to the geojson file which contains that shapes that will be\n        displayed\n    geom_name : str\n        The field name from the JSON file which contains the id of the geometry\n    join_name : str\n        The column name from the dataframes passed as views (must be in each\n        view) which joins to geom_name in the shapes\n    precision : int\n        The precision of values to show in the legend on the map\n    port : int\n        The port for the web service to respond on\n    host : str\n        The hostname to run the web service from\n    testing : bool\n        Whether to print extra debug information\n\n    Returns\n    -------\n    Does not return - takes over control of the thread and responds to\n    queries from a web browser\n    \"\"\"\n\n    global DFRAMES, CONFIG\n    DFRAMES = {str(k): views[k] for k in views}\n\n    root = \"http://{}:{}/\".format(host, port)\n\n    config = {\n        'center': str(center),\n        'zoom': zoom,\n        'shape_json': shape_json,\n        'geom_name': geom_name,\n        'join_name': join_name,\n        'precision': precision,\n        'root': root\n    }\n\n    for k in views:\n        if join_name not in views[k].columns:\n            raise Exception(\"Join name must be present on all dataframes - \"\n                            \"'%s' not present on '%s'\" % (join_name, k))\n\n    config['schema'] = simplejson.dumps(get_schema())\n\n    CONFIG = config\n\n    if testing:\n        return\n\n    run(host=host, port=port, debug=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _analyze_root_causes(self):\n        causes = {}\n        for a in self.anomalies:\n            try:\n                causes[a] = self.correlations[a][0]\n            except IndexError:\n                raise exceptions.InvalidDataFormat('luminol.luminol: dict correlations contains empty list.')\n        self.causes = causes", "response": "Analyze the root causes of the anomalies and update the self. causes attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load(self, time_series):\n        if isinstance(time_series, TimeSeries):\n            return time_series\n        if isinstance(time_series, dict):\n            return TimeSeries(time_series)\n        return TimeSeries(utils.read_csv(time_series))", "response": "Load a time series into a TimeSeries object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the specific algorithm and merge the algorithm params.", "response": "def _get_algorithm_and_params(self, algorithm_name, algorithm_params):\n        \"\"\"\n        Get the specific algorithm and merge the algorithm params.\n        :param str algorithm: name of the algorithm to use.\n        :param dict algorithm_params: additional params for the specific algorithm.\n        \"\"\"\n        algorithm_name = algorithm_name or CORRELATOR_ALGORITHM\n        try:\n            self.algorithm = correlator_algorithms[algorithm_name]\n        except KeyError:\n            raise exceptions.AlgorithmNotFound('luminol.Correlator: ' + str(algorithm_name) + ' not found.')\n        # Merge parameters.\n        if algorithm_params:\n            if not isinstance(algorithm_params, dict):\n                raise exceptions.InvalidDataFormat('luminol.Correlator: algorithm_params passed is not a dictionary.')\n            else:\n                # self.algorithm_params = dict(algorithm_params.items() + self.algorithm_params.items())\n                self.algorithm_params = self.algorithm_params.copy()\n                self.algorithm_params.update(algorithm_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the time series has more than two data points.", "response": "def _sanity_check(self):\n        \"\"\"\n        Check if the time series have more than two data points.\n        \"\"\"\n        if len(self.time_series_a) < 2 or len(self.time_series_b) < 2:\n            raise exceptions.NotEnoughDataPoints('luminol.Correlator: Too few data points!')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompare with a threshold to determine whether two time series correlate to each other.", "response": "def is_correlated(self, threshold=0):\n        \"\"\"\n        Compare with a threshold to determine whether two timeseries correlate to each other.\n        :return: a CorrelationResult object if two time series correlate otherwise false.\n        \"\"\"\n        return self.correlation_result if self.correlation_result.coefficient >= threshold else False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_scores(self):\n        anom_scores = {}\n        for i, (timestamp, value) in enumerate(self.time_series.items()):\n\n            baseline_value = self.baseline_time_series[i]\n\n            if baseline_value > 0:\n                diff_percent = 100 * (value - baseline_value) / baseline_value\n            elif value > 0:\n                diff_percent = 100.0\n            else:\n                diff_percent = 0.0\n\n            anom_scores[timestamp] = 0.0\n            if self.percent_threshold_upper and diff_percent > 0 and diff_percent > self.percent_threshold_upper:\n                anom_scores[timestamp] = diff_percent\n            if self.percent_threshold_lower and diff_percent < 0 and diff_percent < self.percent_threshold_lower:\n                anom_scores[timestamp] = -1 * diff_percent\n\n        self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))", "response": "Compute anomaly scores for the time series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load(self, metrix):\n    if isinstance(metrix, TimeSeries):\n      return metrix\n    if isinstance(metrix, dict):\n      return TimeSeries(metrix)\n    return TimeSeries(utils.read_csv(metrix))", "response": "Load a time series from a CSV file or a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _analyze(self):\n    output = defaultdict(list)\n    output_by_name = defaultdict(list)\n    scores = self.anomaly_detector.get_all_scores()\n\n    if self.anomalies:\n      for anomaly in self.anomalies:\n        metrix_scores = scores\n        start_t, end_t = anomaly.get_time_window()\n        t = anomaly.exact_timestamp\n\n        # Compute extended start timestamp and extended end timestamp.\n        room = (end_t - start_t) / 2\n        if not room:\n          room = 30\n        extended_start_t = start_t - room\n        extended_end_t = end_t + room\n        metrix_scores_cropped = metrix_scores.crop(extended_start_t, extended_end_t)\n\n        # Adjust the two timestamps if not enough data points are included.\n        while len(metrix_scores_cropped) < 2:\n          extended_start_t = extended_start_t - room\n          extended_end_t = extended_end_t + room\n          metrix_scores_cropped = metrix_scores.crop(extended_start_t, extended_end_t)\n\n        # Correlate with other metrics\n        for entry in self.related_metrices:\n          try:\n            entry_correlation_result = Correlator(self.metrix, entry, time_period=(extended_start_t, extended_end_t),\n                                                  use_anomaly_score=True).get_correlation_result()\n            record = extended_start_t, extended_end_t, entry_correlation_result.__dict__, entry\n            record_by_name = extended_start_t, extended_end_t, entry_correlation_result.__dict__\n            output[t].append(record)\n            output_by_name[entry].append(record_by_name)\n          except exceptions.NotEnoughDataPoints:\n            pass\n\n    self.output = output\n    self.output_by_name = output_by_name", "response": "Analyzes if a matrix has anomalies and if any anomaly is found determine if the matrix correlates with any other matrixes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_scores(self):\n        anom_scores_ema = self.exp_avg_detector.run()\n        anom_scores_deri = self.derivative_detector.run()\n        anom_scores = {}\n        for timestamp in anom_scores_ema.timestamps:\n            # Compute a weighted anomaly score.\n            anom_scores[timestamp] = max(anom_scores_ema[timestamp],\n                                         anom_scores_ema[timestamp] * DEFAULT_DETECTOR_EMA_WEIGHT + anom_scores_deri[timestamp] * (1 - DEFAULT_DETECTOR_EMA_WEIGHT))\n            # If ema score is significant enough, take the bigger one of the weighted score and deri score.\n            if anom_scores_ema[timestamp] > DEFAULT_DETECTOR_EMA_SIGNIFICANT:\n                anom_scores[timestamp] = max(anom_scores[timestamp], anom_scores_deri[timestamp])\n        self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))", "response": "Set anomaly scores using a weighted sum of anomaly scores and a derivative score."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the derivatives of the time series items.", "response": "def _compute_derivatives(self):\n        \"\"\"\n        Compute derivatives of the time series.\n        \"\"\"\n        derivatives = []\n        for i, (timestamp, value) in enumerate(self.time_series_items):\n            if i > 0:\n                pre_item = self.time_series_items[i - 1]\n                pre_timestamp = pre_item[0]\n                pre_value = pre_item[1]\n                td = timestamp - pre_timestamp\n                derivative = (value - pre_value) / td if td != 0 else value - pre_value\n                derivative = abs(derivative)\n                derivatives.append(derivative)\n        # First timestamp is assigned the same derivative as the second timestamp.\n        if derivatives:\n            derivatives.insert(0, derivatives[0])\n        self.derivatives = derivatives"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if there are enough data points.", "response": "def _sanity_check(self):\n        \"\"\"\n        Check if there are enough data points.\n        \"\"\"\n        windows = self.lag_window_size + self.future_window_size\n        if (not self.lag_window_size or not self.future_window_size or self.time_series_length < windows or windows < DEFAULT_BITMAP_MINIMAL_POINTS_IN_WINDOWS):\n            raise exceptions.NotEnoughDataPoints\n\n        # If window size is too big, too many data points will be assigned a score of 0 in the first lag window\n        # and the last future window.\n        if self.lag_window_size > DEFAULT_BITMAP_MAXIMAL_POINTS_IN_WINDOWS:\n            self.lag_window_size = DEFAULT_BITMAP_MAXIMAL_POINTS_IN_WINDOWS\n        if self.future_window_size > DEFAULT_BITMAP_MAXIMAL_POINTS_IN_WINDOWS:\n            self.future_window_size = DEFAULT_BITMAP_MAXIMAL_POINTS_IN_WINDOWS"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a SAX representation for a single data point.", "response": "def _generate_SAX_single(self, sections, value):\n        \"\"\"\n        Generate SAX representation(Symbolic Aggregate approXimation) for a single data point.\n        Read more about it here: Assumption-Free Anomaly Detection in Time Series(http://alumni.cs.ucr.edu/~ratana/SSDBM05.pdf).\n        :param dict sections: value sections.\n        :param float value: value to be categorized.\n        :return str: a SAX representation.\n        \"\"\"\n        sax = 0\n        for section_number in sections.keys():\n            section_lower_bound = sections[section_number]\n            if value >= section_lower_bound:\n                sax = section_number\n            else:\n                break\n        return str(sax)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating SAX representation for all values of the time series.", "response": "def _generate_SAX(self):\n        \"\"\"\n        Generate SAX representation for all values of the time series.\n        \"\"\"\n        sections = {}\n        self.value_min = self.time_series.min()\n        self.value_max = self.time_series.max()\n        # Break the whole value range into different sections.\n        section_height = (self.value_max - self.value_min) / self.precision\n        for section_number in range(self.precision):\n            sections[section_number] = self.value_min + section_number * section_height\n        # Generate SAX representation.\n        self.sax = ''.join(self._generate_SAX_single(sections, value) for value in self.time_series.values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _construct_SAX_chunk_dict(self, sax):\n        frequency = defaultdict(int)\n        chunk_size = self.chunk_size\n        length = len(sax)\n        for i in range(length):\n            if i + chunk_size <= length:\n                chunk = sax[i: i + chunk_size]\n                frequency[chunk] += 1\n        return frequency", "response": "Constructs a dictionary that represents the frequency of the chunks in the SAX representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs the chunk dicts for all the time series elements.", "response": "def _construct_all_SAX_chunk_dict(self):\n        \"\"\"\n        Construct the chunk dicts for lagging window and future window at each index.\n         e.g: Suppose we have a SAX sequence as '1234567890', both window sizes are 3, and the chunk size is 2.\n         The first index that has a lagging window is 3. For index equals 3, the lagging window has sequence '123',\n         the chunk to leave lagging window(lw_leave_chunk) is '12', and the chunk to enter lagging window(lw_enter_chunk) is '34'.\n         Therefore, given chunk dicts at i, to compute chunk dicts at i+1, simply decrement the count for lw_leave_chunk,\n         and increment the count for lw_enter_chunk from chunk dicts at i. Same method applies to future window as well.\n        \"\"\"\n        lag_dicts = {}\n        fut_dicts = {}\n        length = self.time_series_length\n        lws = self.lag_window_size\n        fws = self.future_window_size\n        chunk_size = self.chunk_size\n\n        for i in range(length):\n            # If i is too small or too big, there will be no chunk dicts.\n            if i < lws or i > length - fws:\n                lag_dicts[i] = None\n\n            else:\n                # Just enter valid range.\n                if lag_dicts[i - 1] is None:\n                    lag_dict = self._construct_SAX_chunk_dict(self.sax[i - lws: i])\n                    lag_dicts[i] = lag_dict\n                    lw_leave_chunk = self.sax[0:chunk_size]\n                    lw_enter_chunk = self.sax[i - chunk_size + 1: i + 1]\n\n                    fut_dict = self._construct_SAX_chunk_dict(self.sax[i: i + fws])\n                    fut_dicts[i] = fut_dict\n                    fw_leave_chunk = self.sax[i: i + chunk_size]\n                    fw_enter_chunk = self.sax[i + fws + 1 - chunk_size: i + fws + 1]\n\n                else:\n                    # Update dicts according to leave_chunks and enter_chunks.\n                    lag_dict = copy(lag_dicts[i - 1])\n                    lag_dict[lw_leave_chunk] -= 1\n                    lag_dict[lw_enter_chunk] += 1\n                    lag_dicts[i] = lag_dict\n\n                    fut_dict = copy(fut_dicts[i - 1])\n                    fut_dict[fw_leave_chunk] -= 1\n                    fut_dict[fw_enter_chunk] += 1\n                    fut_dicts[i] = fut_dict\n\n                    # Updata leave_chunks and enter_chunks.\n                    lw_leave_chunk = self.sax[i - lws: i - lws + chunk_size]\n                    lw_enter_chunk = self.sax[i - chunk_size + 1: i + 1]\n                    fw_leave_chunk = self.sax[i: i + chunk_size]\n                    fw_enter_chunk = self.sax[i + fws + 1 - chunk_size: i + fws + 1]\n\n        self.lag_dicts = lag_dicts\n        self.fut_dicts = fut_dicts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the anomaly score between two windows.", "response": "def _compute_anom_score_between_two_windows(self, i):\n        \"\"\"\n        Compute distance difference between two windows' chunk frequencies,\n        which is then marked as the anomaly score of the data point on the window boundary in the middle.\n        :param int i: index of the data point between two windows.\n        :return float: the anomaly score.\n        \"\"\"\n        lag_window_chunk_dict = self.lag_dicts[i]\n        future_window_chunk_dict = self.fut_dicts[i]\n        score = 0\n        for chunk in lag_window_chunk_dict:\n            if chunk in future_window_chunk_dict:\n                score += math.pow(future_window_chunk_dict[chunk] - lag_window_chunk_dict[chunk], 2)\n            else:\n                score += math.pow(lag_window_chunk_dict[chunk], 2)\n        for chunk in future_window_chunk_dict:\n            if chunk not in lag_window_chunk_dict:\n                score += math.pow(future_window_chunk_dict[chunk], 2)\n        return score"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes anomaly scores for the time series by sliding both lagging window and future window.", "response": "def _set_scores(self):\n        \"\"\"\n        Compute anomaly scores for the time series by sliding both lagging window and future window.\n        \"\"\"\n        anom_scores = {}\n        self._generate_SAX()\n        self._construct_all_SAX_chunk_dict()\n        length = self.time_series_length\n        lws = self.lag_window_size\n        fws = self.future_window_size\n\n        for i, timestamp in enumerate(self.time_series.timestamps):\n            if i < lws or i > length - fws:\n                anom_scores[timestamp] = 0\n            else:\n                anom_scores[timestamp] = self._compute_anom_score_between_two_windows(i)\n        self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _denoise_scores(self, scores):\n        if scores:\n            maximal = max(scores.values())\n            if maximal:\n                for key in scores:\n                    if scores[key] < DEFAULT_NOISE_PCT_THRESHOLD * maximal:\n                        scores[key] = 0\n        return scores", "response": "Denoise anomaly scores.\n        Low anomaly scores could be noisy. The following two series will have good correlation result with out denoise:\n        [0.08, 4.6, 4.6, 4.6, 1.0, 1.0]\n        [0.0010, 0.0012, 0.0012, 0.0008, 0.0008]\n        while the second series is pretty flat(suppose it has a max score of 100).\n        param dict scores: the scores to be denoised."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _detect_correlation(self):\n        correlations = []\n        shifted_correlations = []\n        self.time_series_a.normalize()\n        self.time_series_b.normalize()\n        a, b = self.time_series_a.align(self.time_series_b)\n        a_values, b_values = a.values, b.values\n        a_avg, b_avg = a.average(), b.average()\n        a_stdev, b_stdev = a.stdev(), b.stdev()\n        n = len(a)\n        denom = a_stdev * b_stdev * n\n        # Find the maximal shift steps according to the maximal shift seconds.\n        allowed_shift_step = self._find_allowed_shift(a.timestamps)\n        if allowed_shift_step:\n            shift_upper_bound = allowed_shift_step\n            shift_lower_bound = -allowed_shift_step\n        else:\n            shift_upper_bound = 1\n            shift_lower_bound = 0\n        for delay in range(shift_lower_bound, shift_upper_bound):\n            delay_in_seconds = a.timestamps[abs(delay)] - a.timestamps[0]\n            if delay < 0:\n                delay_in_seconds = -delay_in_seconds\n            s = 0\n            for i in range(n):\n                j = i + delay\n                if j < 0 or j >= n:\n                    continue\n                else:\n                    s += ((a_values[i] - a_avg) * (b_values[j] - b_avg))\n            r = s / denom if denom != 0 else s\n            correlations.append([delay_in_seconds, r])\n            # Take shift into account to create a \"shifted correlation coefficient\".\n            if self.max_shift_milliseconds:\n                shifted_correlations.append(r * (1 + float(delay_in_seconds) / self.max_shift_milliseconds * self.shift_impact))\n            else:\n                shifted_correlations.append(r)\n        max_correlation = list(max(correlations, key=lambda k: k[1]))\n        max_shifted_correlation = max(shifted_correlations)\n        max_correlation.append(max_shifted_correlation)\n        self.correlation_result = CorrelationResult(*max_correlation)", "response": "Detect correlation coefficients for all allowed shift steps and take the maximum."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_scores(self):\n        anom_scores = {}\n        for timestamp, value in self.time_series.items():\n            anom_scores[timestamp] = 0.0\n            if self.absolute_threshold_value_upper and value > self.absolute_threshold_value_upper:\n                anom_scores[timestamp] = value - self.absolute_threshold_value_upper\n            if self.absolute_threshold_value_lower and value < self.absolute_threshold_value_lower:\n                anom_scores[timestamp] = self.absolute_threshold_value_lower - value\n        self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))", "response": "Compute anomaly scores for the time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes anomaly score for a single data point.", "response": "def _compute_anom_score(self, lag_window_points, point):\n        \"\"\"\n        Compute anomaly score for a single data point.\n        Anomaly score for a single data point(t,v) equals: abs(v - ema(lagging window)).\n        :param list lag_window_points: values in the lagging window.\n        :param float point: data point value.\n        :return float: the anomaly score.\n        \"\"\"\n        ema = utils.compute_ema(self.smoothing_factor, lag_window_points)[-1]\n        return abs(point - ema)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing anomaly scores using a lagging window.", "response": "def _compute_anom_data_using_window(self):\n        \"\"\"\n        Compute anomaly scores using a lagging window.\n        \"\"\"\n        anom_scores = {}\n        values = self.time_series.values\n        stdev = numpy.std(values)\n        for i, (timestamp, value) in enumerate(self.time_series_items):\n            if i < self.lag_window_size:\n                anom_score = self._compute_anom_score(values[:i + 1], value)\n            else:\n                anom_score = self._compute_anom_score(values[i - self.lag_window_size: i + 1], value)\n            if stdev:\n                anom_scores[timestamp] = anom_score / stdev\n            else:\n                anom_scores[timestamp] = anom_score\n        self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compute_anom_data_decay_all(self):\n        anom_scores = {}\n        values = self.time_series.values\n        ema = utils.compute_ema(self.smoothing_factor, values)\n        stdev = numpy.std(values)\n        for i, (timestamp, value) in enumerate(self.time_series_items):\n            anom_score = abs((value - ema[i]) / stdev) if stdev else value - ema[i]\n            anom_scores[timestamp] = anom_score\n        self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))", "response": "Compute anomaly scores using a lagging window covering all the data points before and after the data points after."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generic_binary_op(self, other, op):\n        output = {}\n        if isinstance(other, TimeSeries):\n            for key, value in self.items():\n                if key in other:\n                    try:\n                        result = op(value, other[key])\n                        if result is NotImplemented:\n                            other_type = type(other[key])\n                            other_op = vars(other_type).get(op.__name__)\n                            if other_op:\n                                output[key] = other_op(other_type(value), other[key])\n                        else:\n                            output[key] = result\n                    except ZeroDivisionError:\n                        continue\n        else:\n            for key, value in self.items():\n                try:\n                    result = op(value, other)\n                    if result is NotImplemented:\n                        other_type = type(other)\n                        other_op = vars(other_type).get(op.__name__)\n                        if other_op:\n                            output[key] = other_op(other_type(value), other)\n                    else:\n                        output[key] = result\n                except ZeroDivisionError:\n                    continue\n\n        if output:\n            return TimeSeries(output)\n        else:\n            raise ValueError('TimeSeries data was empty or invalid.')", "response": "Perform a generic binary operation between the values of the instance s time series and the other time series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_value_type(self, other):\n        if self.values:\n            return type(self.values[0])\n        elif isinstance(other, TimeSeries) and other.values:\n            return type(other.values[0])\n        else:\n            raise ValueError('Cannot perform arithmetic on empty time series.')", "response": "Get the type of the value within the values portion of the time series."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nalign two time series so that self. timestamps == other. timestamps.", "response": "def align(self, other):\n        \"\"\"\n        Align two time series so that len(self) == len(other) and self.timstamps == other.timestamps.\n\n        :return: :tuple:(`TimeSeries` object(the aligned self), `TimeSeries` object(the aligned other))\n        \"\"\"\n        if isinstance(other, TimeSeries):\n            aligned, other_aligned = {}, {}\n            i, other_i = self.iteritems_silent(), other.iteritems_silent()\n            item, other_item = next(i), next(other_i)\n\n            while item and other_item:\n                # Unpack timestamps and values.\n                timestamp, value = item\n                other_timestamp, other_value = other_item\n                if timestamp == other_timestamp:\n                    aligned[timestamp] = value\n                    other_aligned[other_timestamp] = other_value\n                    item = next(i)\n                    other_item = next(other_i)\n                elif timestamp < other_timestamp:\n                    aligned[timestamp] = value\n                    other_aligned[timestamp] = other_value\n                    item = next(i)\n                else:\n                    aligned[other_timestamp] = value\n                    other_aligned[other_timestamp] = other_value\n                    other_item = next(other_i)\n            # Align remaining items.\n            while item:\n                timestamp, value = item\n                aligned[timestamp] = value\n                other_aligned[timestamp] = other.values[-1]\n                item = next(i)\n            while other_item:\n                other_timestamp, other_value = other_item\n                aligned[other_timestamp] = self.values[-1]\n                other_aligned[other_timestamp] = other_value\n                other_item = next(other_i)\n            return TimeSeries(aligned), TimeSeries(other_aligned)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsmooths the data series soomth forward once and then take the average.", "response": "def smooth(self, smoothing_factor):\n        \"\"\"\n        return a new time series which is a exponential smoothed version of the original data series.\n        soomth forward once, backward once, and then take the average.\n\n        :param float smoothing_factor: smoothing factor\n        :return: :class:`TimeSeries` object.\n        \"\"\"\n        forward_smooth = {}\n        backward_smooth = {}\n        output = {}\n\n        if self:\n            pre = self.values[0]\n            next = self.values[-1]\n            for key, value in self.items():\n                forward_smooth[key] = smoothing_factor * pre + (1 - smoothing_factor) * value\n                pre = forward_smooth[key]\n            for key, value in reversed(self.items()):\n                backward_smooth[key] = smoothing_factor * next + (1 - smoothing_factor) * value\n                next = backward_smooth[key]\n            for key in forward_smooth.keys():\n                output[key] = (forward_smooth[key] + backward_smooth[key]) / 2\n\n        return TimeSeries(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_offset(self, offset):\n        self.timestamps = [ts + offset for ts in self.timestamps]", "response": "Return a new time series with all timestamps incremented by some offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize(self):\n        maximum = self.max()\n        if maximum:\n            self.values = [value / maximum for value in self.values]", "response": "Normalizes the time series to be 0 to 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef crop(self, start_timestamp, end_timestamp):\n        output = {}\n        for key, value in self.items():\n            if key >= start_timestamp and key <= end_timestamp:\n                output[key] = value\n\n        if output:\n            return TimeSeries(output)\n        else:\n            raise ValueError('TimeSeries data was empty or invalid.')", "response": "Return a new TimeSeries object containing all the timstamps and values within the specified range."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the average value over the time series.", "response": "def average(self, default=None):\n        \"\"\"\n        Calculate the average value over the time series.\n\n        :param default: Value to return as a default should the calculation not be possible.\n        :return: Float representing the average value or `None`.\n        \"\"\"\n        return numpy.asscalar(numpy.average(self.values)) if self.values else default"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the median value over the time series.", "response": "def median(self, default=None):\n        \"\"\"\n        Calculate the median value over the time series.\n\n        :param default: Value to return as a default should the calculation not be possible.\n        :return: Float representing the median value or `None`.\n        \"\"\"\n        return numpy.asscalar(numpy.median(self.values)) if self.values else default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the maximum value over the time series.", "response": "def max(self, default=None):\n        \"\"\"\n        Calculate the maximum value over the time series.\n\n        :param default: Value to return as a default should the calculation not be possible.\n        :return: Float representing the maximum value or `None`.\n        \"\"\"\n        return numpy.asscalar(numpy.max(self.values)) if self.values else default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef min(self, default=None):\n        return numpy.asscalar(numpy.min(self.values)) if self.values else default", "response": "Calculate the minimum value over the time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the Nth Percentile value over the time series.", "response": "def percentile(self, n, default=None):\n        \"\"\"\n        Calculate the Nth Percentile value over the time series.\n\n        :param int n: Integer value of the percentile to calculate.\n        :param default: Value to return as a default should the calculation not be possible.\n        :return: Float representing the Nth percentile value or `None`.\n        \"\"\"\n        return numpy.asscalar(numpy.percentile(self.values, n)) if self.values else default"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the standard deviation of the time series.", "response": "def stdev(self, default=None):\n        \"\"\"\n        Calculate the standard deviation of the time series.\n\n        :param default: Value to return as a default should the calculation not be possible.\n        :return: Float representing the standard deviation value or `None`.\n        \"\"\"\n        return numpy.asscalar(numpy.std(self.values)) if self.values else default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the sum of all the values in the times series.", "response": "def sum(self, default=None):\n        \"\"\"\n        Calculate the sum of all the values in the times series.\n\n        :param default: Value to return as a default should the calculation not be possible.\n        :return: Float representing the sum or `None`.\n        \"\"\"\n        return numpy.asscalar(numpy.sum(self.values)) if self.values else default"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_algorithm(self, algorithm_name):\n        try:\n            algorithm = anomaly_detector_algorithms[algorithm_name]\n            return algorithm\n        except KeyError:\n            raise exceptions.AlgorithmNotFound('luminol.AnomalyDetector: ' + str(algorithm_name) + ' not found.')", "response": "Get the specific algorithm object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetecting anomaly periods. :param bool score_only: if true, only anomaly scores are computed.", "response": "def _detect(self, score_only):\n        \"\"\"\n        Detect anomaly periods.\n        :param bool score_only: if true, only anomaly scores are computed.\n        \"\"\"\n        try:\n            algorithm = self.algorithm(**self.algorithm_params)\n            self.anom_scores = algorithm.run()\n        except exceptions.NotEnoughDataPoints:\n            algorithm = anomaly_detector_algorithms['default_detector'](self.time_series)\n            self.threshold = self.threshold or ANOMALY_THRESHOLD['default_detector']\n            self.anom_scores = algorithm.run()\n        if not score_only:\n            self._detect_anomalies()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _detect_anomalies(self):\n        anom_scores = self.anom_scores\n        max_anom_score = anom_scores.max()\n        anomalies = []\n\n        if max_anom_score:\n            threshold = self.threshold or max_anom_score * self.score_percent_threshold\n            # Find all the anomaly intervals.\n            intervals = []\n            start, end = None, None\n            for timestamp, value in anom_scores.iteritems():\n                if value > threshold:\n                    end = timestamp\n                    if not start:\n                        start = timestamp\n                elif start and end is not None:\n                    intervals.append([start, end])\n                    start = None\n                    end = None\n            if start is not None:\n                intervals.append([start, end])\n\n            # Locate the exact anomaly point within each anomaly interval.\n            for interval_start, interval_end in intervals:\n                interval_series = anom_scores.crop(interval_start, interval_end)\n\n                self.refine_algorithm_params['time_series'] = interval_series\n                refine_algorithm = self.refine_algorithm(**self.refine_algorithm_params)\n                scores = refine_algorithm.run()\n                max_refine_score = scores.max()\n\n                # Get the timestamp of the maximal score.\n                max_refine_timestamp = scores.timestamps[scores.values.index(max_refine_score)]\n                anomaly = Anomaly(interval_start, interval_end, interval_series.max(), max_refine_timestamp)\n                anomalies.append(anomaly)\n\n        self.anomalies = anomalies", "response": "Detect anomalies using a threshold on anomaly scores."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute exponential moving average of a list of points.", "response": "def compute_ema(smoothing_factor, points):\n    \"\"\"\n    Compute exponential moving average of a list of points.\n    :param float smoothing_factor: the smoothing factor.\n    :param list points: the data points.\n    :return list: all ema in a list.\n    \"\"\"\n    ema = []\n    # The initial point has a ema equal to itself.\n    if(len(points) > 0):\n        ema.append(points[0])\n    for i in range(1, len(points)):\n        ema.append(smoothing_factor * points[i] + (1 - smoothing_factor) * ema[i - 1])\n    return ema"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_epoch(t_str):\n    try:\n        t = float(t_str)\n        return t\n    except ValueError:\n        for format in constants.TIMESTAMP_STR_FORMATS:\n            try:\n                t = datetime.datetime.strptime(t_str, format)\n                return float(time.mktime(t.utctimetuple()) * 1000.0 + t.microsecond / 1000.0)\n            except ValueError:\n                pass\n    raise exceptions.InvalidDataFormat", "response": "Covert a timestamp string to an epoch number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_response(response):\n\n    # ignore valid responses\n    if response.status_code < 400:\n        return\n\n    cls = _status_to_exception_type.get(response.status_code, HttpError)\n\n    kwargs = {\n        'code': response.status_code,\n        'method': response.request.method,\n        'url': response.request.url,\n        'details': response.text,\n    }\n\n    if response.headers and 'retry-after' in response.headers:\n        kwargs['retry_after'] = response.headers.get('retry-after')\n\n    raise cls(**kwargs)", "response": "Given a requests. Response object throw the appropriate exception if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new instance of this resource type.", "response": "def create(self, **kwargs):\n        \"\"\"Create a new instance of this resource type.\n\n        As a general rule, the identifier should have been provided, but in\n        some subclasses the identifier is server-side-generated.  Those classes\n        have to overload this method to deal with that scenario.\n        \"\"\"\n        if self.primary_key in kwargs:\n            del kwargs[self.primary_key]\n        data = self._generate_input_dict(**kwargs)\n        self.load(self.client.post('/'.join(self.url.split('/')[:-1]) + 's', data=data))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, **kwargs):\n        data = self._generate_input_dict(**kwargs)\n        self.load(self.client.put('/'.join(self.url.split('/')[:-1]) + 's', data=data))\n        return self", "response": "Update a resource by passing in modifications via keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a resource by passing in modifications via keyword arguments.", "response": "def update(self, **kwargs):\n        \"\"\"Update a resource by passing in modifications via keyword arguments.\n\n        \"\"\"\n        data = []\n        for cl in self:\n            for classification_item in cl.list:\n                class_item_dict = dict()\n                for field in classification_item.fields:\n                    class_item_dict[field] = getattr(classification_item, field)\n                data.append(class_item_dict)\n        self.load(self.client.put(self.url, data=data))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, data, **kwargs):\n        self.client.post(self.url, data=data)", "response": "Create classifitions for specific entity"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, guid):\n        return self.client.delete(self.url, params={'guid': guid})", "response": "Delete a specific object from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, **kwargs):\n        data = self._generate_input_dict(**kwargs)\n        url = self.parent.url + '/relationship'\n        self.load(self.client.put(url, data=data))\n        return self", "response": "Update a resource by passing in modifications via keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, **kwargs):\n        raise exceptions.MethodNotImplemented(method=self.create, url=self.url, details='GUID cannot be duplicated, to create a new GUID use the relationship resource')", "response": "Raise error since guid cannot be duplicated\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize_underscore_case(name):\n    normalized = name.lower()\n    normalized = re.sub(r'_(\\w)',\n                        lambda match: ' ' + match.group(1).upper(),\n                        normalized)\n    return normalized[0].upper() + normalized[1:]", "response": "Normalize an underscore - separated descriptor to something more readable."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes a camelCase descriptor to something more readable.", "response": "def normalize_camel_case(name):\n    \"\"\"Normalize a camelCase descriptor to something more readable.\n\n    i.e. 'camelCase' or 'CamelCase' becomes 'Camel Case'\n    \"\"\"\n    normalized = re.sub('([a-z])([A-Z])',\n                        lambda match: ' '.join([match.group(1), match.group(2)]),\n                        name)\n    return normalized[0].upper() + normalized[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef version_tuple(version):\n    if isinstance(version, str):\n        return tuple(int(x) for x in version.split('.'))\n    elif isinstance(version, tuple):\n        return version\n    else:\n        raise ValueError(\"Invalid version: %s\" % version)", "response": "Convert a version string or tuple to a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a version tuple or string to a string.", "response": "def version_str(version):\n    \"\"\"Convert a version tuple or string to a string.\n\n    Should be returned in the form: major.minor.release\n    \"\"\"\n    if isinstance(version, str):\n        return version\n    elif isinstance(version, tuple):\n        return '.'.join([str(int(x)) for x in version])\n    else:\n        raise ValueError(\"Invalid version: %s\" % version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_http_basic_token(username, password):\n    token = base64.b64encode('{}:{}'.format(username, password).encode('utf-8')).decode('utf-8')\n    return token", "response": "Generates a HTTP basic token from username and password"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef identifier(self):\n        if self.primary_key not in self._data:\n            return 'Unknown'\n        return str(self._data[self.primary_key])", "response": "Return the identifier of the current model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url(self):\n        if self.parent is None:\n            # TODO: differing API Versions?\n            pieces = [self.client.base_url, 'api', 'atlas', 'v2']\n        else:\n            pieces = [self.parent.url]\n\n        pieces.append(self.model_class.path)\n        return '/'.join(pieces)", "response": "The url for this collection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the collection from the server if necessary.", "response": "def inflate(self):\n        \"\"\"Load the collection from the server, if necessary.\"\"\"\n        if not self._is_inflated:\n            self.check_version()\n            for k, v in self._filter.items():\n                if '[' in v:\n                    self._filter[k] = ast.literal_eval(v)\n            self.load(self.client.get(self.url, params=self._filter))\n\n        self._is_inflated = True\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the GET response for the collection.", "response": "def load(self, response):\n        \"\"\"Parse the GET response for the collection.\n\n        This operates as a lazy-loader, meaning that the data are only downloaded\n        from the server if there are not already loaded.\n        Collection items are loaded sequentially.\n\n        In some rare cases, a collection can have an asynchronous request\n        triggered.  For those cases, we handle it here.\n        \"\"\"\n        self._models = []\n        if isinstance(response, dict):\n            for key in response.keys():\n                model = self.model_class(self, href='')\n                model.load(response[key])\n                self._models.append(model)\n        else:\n            for item in response:\n                model = self.model_class(self,\n                                         href=item.get('href'))\n                model.load(item)\n                self._models.append(model)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, *args, **kwargs):\n        href = self.url\n        if len(args) == 1:\n            kwargs[self.model_class.primary_key] = args[0]\n            href = '/'.join([href, args[0]])\n        model = self.model_class(self,\n                                 href=href.replace('classifications/', 'classification/'),\n                                 data=kwargs)\n        model.create(**kwargs)\n        self._models.append(model)\n        return model", "response": "Add a resource to this collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating all resources in this collection.", "response": "def update(self, **kwargs):\n        \"\"\"Update all resources in this collection.\"\"\"\n        self.inflate()\n        for model in self._models:\n            model.update(**kwargs)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all resources in this collection.", "response": "def delete(self, **kwargs):\n        \"\"\"Delete all resources in this collection.\"\"\"\n        self.inflate()\n        for model in self._models:\n            model.delete(**kwargs)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait until all asynchronous requests are finished for this collection.", "response": "def wait(self, **kwargs):\n        \"\"\"Wait until any pending asynchronous requests are finished for this collection.\"\"\"\n        if self.request:\n            self.request.wait(**kwargs)\n            self.request = None\n        return self.inflate()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url(self):\n        if self._href is not None:\n            return self._href\n        if self.identifier:\n            #  for some reason atlas does not use classifications here in the path when considering one classification\n            path = '/'.join([self.parent.url.replace('classifications/', 'classficiation/'), self.identifier])\n            return path\n        raise exceptions.ClientError(\"Not able to determine object URL\")", "response": "Gets the url for the resource this model represents."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the resource from the server if not already loaded.", "response": "def inflate(self):\n        \"\"\"Load the resource from the server, if not already loaded.\"\"\"\n        if not self._is_inflated:\n            if self._is_inflating:\n                #  catch infinite recursion when attempting to inflate\n                #  an object that doesn't have enough data to inflate\n                msg = (\"There is not enough data to inflate this object.  \"\n                       \"Need either an href: {} or a {}: {}\")\n                msg = msg.format(self._href, self.primary_key, self._data.get(self.primary_key))\n                raise exceptions.ClientError(msg)\n\n            self._is_inflating = True\n\n            try:\n                params = self.searchParameters if hasattr(self, 'searchParameters') else {}\n                # To keep the method same as the original request. The default is GET\n                self.load(self.client.request(self.method, self.url, **params))\n            except Exception:\n                self.load(self._data)\n\n            self._is_inflated = True\n            self._is_inflating = False\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self, response):\n        if 'href' in response:\n            self._href = response.pop('href')\n        if self.data_key and self.data_key in response:\n            self._data.update(response.pop(self.data_key))\n            #  preload related object collections, if received\n            for rel in [x for x in self.relationships if x in response and response[x]]:\n                rel_class = self.relationships[rel]\n                collection = rel_class.collection_class(\n                    self.client, rel_class, parent=self\n                )\n                self._relationship_cache[rel] = collection(response[rel])\n        else:\n            self._data.update(response)", "response": "This method parses the raw JSON response from the server and loads the related objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new instance of this resource type.", "response": "def create(self, **kwargs):\n        \"\"\"Create a new instance of this resource type.\n\n        As a general rule, the identifier should have been provided, but in\n        some subclasses the identifier is server-side-generated.  Those classes\n        have to overload this method to deal with that scenario.\n        \"\"\"\n        self.method = 'post'\n        if self.primary_key in kwargs:\n            del kwargs[self.primary_key]\n        data = self._generate_input_dict(**kwargs)\n        self.load(self.client.post(self.url, data=data))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a resource by issuing a DELETE http request against it.", "response": "def delete(self, **kwargs):\n        \"\"\"Delete a resource by issuing a DELETE http request against it.\"\"\"\n        self.method = 'delete'\n        if len(kwargs) > 0:\n            self.load(self.client.delete(self.url, params=kwargs))\n        else:\n            self.load(self.client.delete(self.url))\n        self.parent.remove(self)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef publish(obj, event, event_state, **kwargs):\n    # short-circuit if nothing is listening\n    if len(EVENT_HANDLERS) == 0:\n        return\n\n    if inspect.isclass(obj):\n        pub_cls = obj\n    else:\n        pub_cls = obj.__class__\n    potential = [x.__name__ for x in inspect.getmro(pub_cls)]\n\n    # if we don't find a match for this event/event_state we fire the events\n    # for this event/ANY instead for the closest match\n    fallbacks = None\n    callbacks = []\n    for cls in potential:\n        event_key = '.'.join([cls, event, event_state])\n        backup_key = '.'.join([cls, event, states.ANY])\n        if event_key in EVENT_HANDLERS:\n            callbacks = EVENT_HANDLERS[event_key]\n            break\n        elif fallbacks is None and backup_key in EVENT_HANDLERS:\n            fallbacks = EVENT_HANDLERS[backup_key]\n\n    if fallbacks is not None:\n        callbacks = fallbacks\n\n    for callback in callbacks:\n        callback(obj, **kwargs)\n    return", "response": "Publish an event from an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubscribe an event from an object.", "response": "def subscribe(obj, event, callback, event_state=None):\n    \"\"\"Subscribe an event from an class.\n\n    Subclasses of the class/object will also fire events for this class,\n    unless a more specific event exists.\n    \"\"\"\n    if inspect.isclass(obj):\n        cls = obj.__name__\n    else:\n        cls = obj.__class__.__name__\n\n    if event_state is None:\n        event_state = states.ANY\n\n    event_key = '.'.join([cls, event, event_state])\n    if event_key not in EVENT_HANDLERS:\n        EVENT_HANDLERS[event_key] = []\n\n    EVENT_HANDLERS[event_key].append(callback)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_name(self, suffix=True, prefix=False, middle=False, multi=False):\n\t\t\"return cleared version of the business name\"\n\n\t\tname = self.business_name\n\n\t\t# Run it through the string_stripper once more\n\t\tname = self.string_stripper(name)\n\t\tloname = name.lower()\n\t\t\n\t\t# return name without suffixed/prefixed/middle type term(s)\n\n\t\tfor item in suffix_sort:\n\t\t\tif suffix:\n\t\t\t\tif loname.endswith(\" \" + item):\n\t\t\t\t\tstart = loname.find(item)\n\t\t\t\t\tend = len(item)\n\t\t\t\t\tname = name[0:-end-1]\n\t\t\t\t\tname = self.string_stripper(name)\n\t\t\t\t\tif multi==False:\n\t\t\t\t\t\tbreak\n\t\t\tif prefix:\n\t\t\t\tif loname.startswith(item+' '):\n\t\t\t\t\tname = name[len(item)+1:]\n\t\t\t\t\tif multi==False:\n\t\t\t\t\t\tbreak\n\t\t\tif middle:\n\t\t\t\tterm = ' ' + item + ' '\n\t\t\t\tif term in loname:\n\t\t\t\t\tstart = loname.find(term)\n\t\t\t\t\tend = start + len(term)\n\t\t\t\t\tname = name[:start] + \" \" + name[end:]\n\t\t\t\t\tif multi==False:\n\t\t\t\t\t\tbreak\n\n\t\treturn self.string_stripper(name)", "response": "return cleared version of the business name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all chordless cycles in the bond graph.", "response": "def _find_chordless_cycles(bond_graph, max_cycle_size):\n    \"\"\"Find all chordless cycles (i.e. rings) in the bond graph\n\n    Traverses the bond graph to determine all cycles (i.e. rings) each\n    atom is contained within. Algorithm has been adapted from:\n    https://stackoverflow.com/questions/4022662/find-all-chordless-cycles-in-an-undirected-graph/4028855#4028855\n    \"\"\"\n    cycles = [[] for _ in bond_graph.nodes]\n\n    ''' \n    For all nodes we need to find the cycles that they are included within.\n    '''\n    for i, node in enumerate(bond_graph.nodes):\n        neighbors = list(bond_graph.neighbors(node))\n        pairs = list(itertools.combinations(neighbors, 2)) \n        ''' \n        Loop over all pairs of neighbors of the node. We will see if a ring\n        exists that includes these branches.\n        '''\n        for pair in pairs:\n            ''' \n            We need to store all node sequences that could be rings. We will\n            update this as we traverse the graph.\n            '''\n            connected = False\n            possible_rings = []\n\n            last_node = pair[0]\n            ring = [last_node, node, pair[1]]\n            possible_rings.append(ring)\n\n            if bond_graph.has_edge(last_node, pair[1]):\n                cycles[i].append(ring)\n                connected = True\n\n            while not connected:\n                '''\n                Branch and create a new list of possible rings\n                '''\n                new_possible_rings = []\n                for possible_ring in possible_rings:\n                    next_neighbors = list(bond_graph.neighbors(possible_ring[-1]))\n                    for next_neighbor in next_neighbors:\n                        if next_neighbor != possible_ring[-2]:\n                            new_possible_rings.append(possible_ring + \\\n                                                      [next_neighbor])\n                possible_rings = new_possible_rings\n\n                for possible_ring in possible_rings:\n                    if bond_graph.has_edge(possible_ring[-1], last_node):\n                        if any([bond_graph.has_edge(possible_ring[-1], internal_node)\n                                for internal_node in possible_ring[1:-2]]):\n                            pass\n                        else:\n                            cycles[i].append(possible_ring)\n                            connected = True\n\n                if not possible_rings or len(possible_rings[0]) == max_cycle_size:\n                    break\n\n    return cycles"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing cycles and add white - or blacklists to atoms.", "response": "def _prepare_atoms(topology, compute_cycles=False):\n    \"\"\"Compute cycles and add white-/blacklists to atoms.\"\"\"\n    atom1 = next(topology.atoms())\n    has_whitelists = hasattr(atom1, 'whitelist')\n    has_cycles = hasattr(atom1, 'cycles')\n    compute_cycles = compute_cycles and not has_cycles\n\n    if compute_cycles or not has_whitelists:\n        for atom in topology.atoms():\n            if compute_cycles:\n                atom.cycles = set()\n            if not has_whitelists:\n                atom.whitelist = OrderedSet()\n                atom.blacklist = OrderedSet()\n\n    if compute_cycles:\n        bond_graph = nx.Graph()\n        bond_graph.add_nodes_from(topology.atoms())\n        bond_graph.add_edges_from(topology.bonds())\n        all_cycles = _find_chordless_cycles(bond_graph, max_cycle_size=8)\n        for atom, cycles in zip(bond_graph.nodes, all_cycles):\n            for cycle in cycles:\n                atom.cycles.add(tuple(cycle))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd all atoms in the SMARTS string as nodes in the graph.", "response": "def _add_nodes(self):\n        \"\"\"Add all atoms in the SMARTS string as nodes in the graph.\"\"\"\n        for n, atom in enumerate(self.ast.select('atom')):\n            self.add_node(n, atom=atom)\n            self._atom_indices[id(atom)] = n"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds all bonds in the SMARTS string as edges in the graph.", "response": "def _add_edges(self, ast_node, trunk=None):\n        \"\"\"\"Add all bonds in the SMARTS string as edges in the graph.\"\"\"\n        atom_indices = self._atom_indices\n        for atom in ast_node.tail:\n            if atom.head == 'atom':\n                atom_idx = atom_indices[id(atom)]\n                if atom.is_first_kid and atom.parent().head == 'branch':\n                    trunk_idx = atom_indices[id(trunk)]\n                    self.add_edge(atom_idx, trunk_idx)\n                if not atom.is_last_kid:\n                    if atom.next_kid.head == 'atom':\n                        next_idx = atom_indices[id(atom.next_kid)]\n                        self.add_edge(atom_idx, next_idx)\n                    elif atom.next_kid.head == 'branch':\n                        trunk = atom\n                else:  # We traveled through the whole branch.\n                    return\n            elif atom.head == 'branch':\n                self._add_edges(atom, trunk)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding edges between all atoms with the same atom_label in rings.", "response": "def _add_label_edges(self):\n        \"\"\"Add edges between all atoms with the same atom_label in rings.\"\"\"\n        labels = self.ast.select('atom_label')\n        if not labels:\n            return\n\n        # We need each individual label and atoms with multiple ring labels\n        # would yield e.g. the string '12' so split those up.\n        label_digits = defaultdict(list)\n        for label in labels:\n            digits = list(label.tail[0])\n            for digit in digits:\n                label_digits[digit].append(label.parent())\n\n        for label, (atom1, atom2) in label_digits.items():\n            atom1_idx = self._atom_indices[id(atom1)]\n            atom2_idx = self._atom_indices[id(atom2)]\n            self.add_edge(atom1_idx, atom2_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_matches(self, topology):\n        # Note: Needs to be updated in sync with the grammar in `smarts.py`.\n        ring_tokens = ['ring_size', 'ring_count']\n        has_ring_rules = any(self.ast.select(token)\n                             for token in ring_tokens)\n        _prepare_atoms(topology, compute_cycles=has_ring_rules)\n\n        top_graph = nx.Graph()\n        top_graph.add_nodes_from(((a.index, {'atom': a})\n                                  for a in topology.atoms()))\n        top_graph.add_edges_from(((b[0].index, b[1].index)\n                                  for b in topology.bonds()))\n\n        if self._graph_matcher is None:\n            atom = nx.get_node_attributes(self, name='atom')[0]\n            if len(atom.select('atom_symbol')) == 1 and not atom.select('not_expression'):\n                try:\n                    element = atom.select('atom_symbol').strees[0].tail[0]\n                except IndexError:\n                    try:\n                        atomic_num = atom.select('atomic_num').strees[0].tail[0]\n                        element = pt.Element[int(atomic_num)]\n                    except IndexError:\n                        element = None\n            else:\n                element = None\n            self._graph_matcher = SMARTSMatcher(top_graph, self,\n                                                node_match=self._node_match,\n                                                element=element)\n\n        matched_atoms = set()\n        for mapping in self._graph_matcher.subgraph_isomorphisms_iter():\n            mapping = {node_id: atom_id for atom_id, node_id in mapping.items()}\n            # The first node in the smarts graph always corresponds to the atom\n            # that we are trying to match.\n            atom_index = mapping[0]\n            # Don't yield duplicate matches found via matching the pattern in a\n            # different order.\n            if atom_index not in matched_atoms:\n                matched_atoms.add(atom_index)\n                yield atom_index", "response": "Find matches in a topology."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over the candidate pairs of nodes in G1 and G2.", "response": "def candidate_pairs_iter(self):\n        \"\"\"Iterator over candidate pairs of nodes in G1 and G2.\"\"\"\n        # All computations are done using the current state!\n        G2_nodes = self.G2_nodes\n\n        # First we compute the inout-terminal sets.\n        T1_inout = set(self.inout_1.keys()) - set(self.core_1.keys())\n        T2_inout = set(self.inout_2.keys()) - set(self.core_2.keys())\n\n        # If T1_inout and T2_inout are both nonempty.\n        # P(s) = T1_inout x {min T2_inout}\n        if T1_inout and T2_inout:\n            for node in T1_inout:\n                yield node, min(T2_inout)\n        else:\n            # First we determine the candidate node for G2\n            other_node = min(G2_nodes - set(self.core_2))\n            host_nodes = self.valid_nodes if other_node == 0 else self.G1.nodes()\n            for node in host_nodes:\n                if node not in self.core_1:\n                    yield node, other_node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind all atomtypes in a topology.", "response": "def find_atomtypes(topology, forcefield, max_iter=10):\n    \"\"\"Determine atomtypes for all atoms.\n\n    Parameters\n    ----------\n    topology : simtk.openmm.app.Topology\n        The topology that we are trying to atomtype.\n    forcefield : foyer.Forcefield\n        The forcefield object.\n    max_iter : int, optional, default=10\n        The maximum number of iterations.\n\n    \"\"\"\n    rules = _load_rules(forcefield)\n\n    # Only consider rules for elements found in topology\n    subrules = dict()\n    system_elements = {a.element.symbol for a in topology.atoms()}\n    for key,val in rules.items():\n        atom = val.node[0]['atom']\n        if len(atom.select('atom_symbol')) == 1 and not atom.select('not_expression'):\n            try:\n                element = atom.select('atom_symbol').strees[0].tail[0]\n            except IndexError:\n                try:\n                    atomic_num = atom.select('atomic_num').strees[0].tail[0]\n                    element = pt.Element[int(atomic_num)]\n                except IndexError:\n                    element = None\n        else:\n            element = None\n        if element is None or element in system_elements:\n            subrules[key] = val\n    rules = subrules\n\n    _iterate_rules(rules, topology, max_iter=max_iter)\n    _resolve_atomtypes(topology)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_rules(forcefield):\n    rules = dict()\n    for rule_name, smarts in forcefield.atomTypeDefinitions.items():\n        overrides = forcefield.atomTypeOverrides.get(rule_name)\n        if overrides is not None:\n            overrides = set(overrides)\n        else:\n            overrides = set()\n        rules[rule_name] = SMARTSGraph(smarts_string=smarts,\n                                       parser=forcefield.parser,\n                                       name=rule_name,\n                                       overrides=overrides)\n    return rules", "response": "Load atomtyping rules from a forcefield into SMARTSGraphs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the final atomtypes from the white - and blacklists.", "response": "def _resolve_atomtypes(topology):\n    \"\"\"Determine the final atomtypes from the white- and blacklists. \"\"\"\n    for atom in topology.atoms():\n        atomtype = [rule_name for rule_name in atom.whitelist - atom.blacklist]\n        if len(atomtype) == 1:\n            atom.id = atomtype[0]\n        elif len(atomtype) > 1:\n            raise FoyerError(\"Found multiple types for atom {} ({}): {}.\".format(\n                atom.index, atom.element.name, atomtype))\n        else:\n            raise FoyerError(\"Found no types for atom {} ({}).\".format(\n                atom.index, atom.element.name))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an OpenMM Topology from another supported topology structure.", "response": "def generate_topology(non_omm_topology, non_element_types=None,\n        residues=None):\n    \"\"\"Create an OpenMM Topology from another supported topology structure.\"\"\"\n    if non_element_types is None:\n        non_element_types = set()\n\n    if isinstance(non_omm_topology, pmd.Structure):\n        return _topology_from_parmed(non_omm_topology, non_element_types)\n    elif has_mbuild:\n        mb = import_('mbuild')\n        if (non_omm_topology, mb.Compound):\n            pmdCompoundStructure = non_omm_topology.to_parmed(residues=residues)\n            return _topology_from_parmed(pmdCompoundStructure, non_element_types)\n    else:\n        raise FoyerError('Unknown topology format: {}\\n'\n                         'Supported formats are: '\n                         '\"parmed.Structure\", '\n                         '\"mbuild.Compound\", '\n                         '\"openmm.app.Topology\"'.format(non_omm_topology))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a ParmEd Structure to an OpenMM Topology.", "response": "def _topology_from_parmed(structure, non_element_types):\n    \"\"\"Convert a ParmEd Structure to an OpenMM Topology.\"\"\"\n    topology = app.Topology()\n    residues = dict()\n    for pmd_residue in structure.residues:\n        chain = topology.addChain()\n        omm_residue = topology.addResidue(pmd_residue.name, chain)\n        residues[pmd_residue] = omm_residue\n    atoms = dict()  # pmd.Atom: omm.Atom\n\n    for pmd_atom in structure.atoms:\n        name = pmd_atom.name\n        if pmd_atom.name in non_element_types:\n            element = non_element_types[pmd_atom.name]\n        else:\n            if (isinstance(pmd_atom.atomic_number, int) and\n                    pmd_atom.atomic_number != 0):\n                element = elem.Element.getByAtomicNumber(pmd_atom.atomic_number)\n            else:\n                element = elem.Element.getBySymbol(pmd_atom.name)\n\n        omm_atom = topology.addAtom(name, element, residues[pmd_atom.residue])\n        atoms[pmd_atom] = omm_atom\n        omm_atom.bond_partners = []\n\n    for bond in structure.bonds:\n        atom1 = atoms[bond.atom1]\n        atom2 = atoms[bond.atom2]\n        topology.addBond(atom1, atom2)\n        atom1.bond_partners.append(atom2)\n        atom2.bond_partners.append(atom1)\n    if structure.box_vectors and np.any([x._value for x in structure.box_vectors]):\n        topology.setPeriodicBoxVectors(structure.box_vectors)\n\n    positions = structure.positions\n    return topology, positions"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _topology_from_residue(res):\n    topology = app.Topology()\n    chain = topology.addChain()\n    new_res = topology.addResidue(res.name, chain)\n\n    atoms = dict()  # { omm.Atom in res : omm.Atom in *new* topology }\n\n    for res_atom in res.atoms():\n        topology_atom = topology.addAtom(name=res_atom.name,\n                         element=res_atom.element,\n                         residue=new_res)\n        atoms[res_atom] = topology_atom\n        topology_atom.bond_partners = []\n\n    for bond in res.bonds():\n        atom1 = atoms[bond.atom1]\n        atom2 = atoms[bond.atom2]\n        topology.addBond(atom1, atom2)\n        atom1.bond_partners.append(atom2)\n        atom2.bond_partners.append(atom1)\n\n    return topology", "response": "Converts a openmm. app. Topology. Residue to openmm. app. Topology.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_independent_residues(topology):\n    for res in topology.residues():\n        atoms_in_residue = set([atom for atom in res.atoms()])\n        bond_partners_in_residue = [item for sublist in [atom.bond_partners for atom in res.atoms()] for item in sublist]\n        # Handle the case of a 'residue' with no neighbors\n        if not bond_partners_in_residue:\n            continue\n        if set(atoms_in_residue) != set(bond_partners_in_residue):\n            return False\n    return True", "response": "Check to see if residues will constitute independent graphs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates atomtypes in residues in a topology using a prototype topology.", "response": "def _update_atomtypes(unatomtyped_topology, res_name, prototype):\n    \"\"\"Update atomtypes in residues in a topology using a prototype topology.\n\n    Atomtypes are updated when residues in each topology have matching names.\n\n    Parameters\n    ----------\n    unatomtyped_topology : openmm.app.Topology\n        Topology lacking atomtypes defined by `find_atomtypes`.\n    prototype : openmm.app.Topology\n        Prototype topology with atomtypes defined by `find_atomtypes`.\n\n    \"\"\"\n    for res in unatomtyped_topology.residues():\n        if res.name == res_name:\n            for old_atom, new_atom_id in zip([atom for atom in res.atoms()], [atom.id for atom in prototype.atoms()]):\n                old_atom.id = new_atom_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef registerAtomType(self, parameters):\n        name = parameters['name']\n        if name in self._atomTypes:\n            raise ValueError('Found multiple definitions for atom type: ' + name)\n        atom_class = parameters['class']\n        mass = _convertParameterToNumber(parameters['mass'])\n        element = None\n        if 'element' in parameters:\n            element, custom = self._create_element(parameters['element'], mass)\n            if custom:\n                self.non_element_types[element.symbol] = element\n\n        self._atomTypes[name] = self.__class__._AtomType(name, atom_class, mass, element)\n        if atom_class in self._atomClasses:\n            type_set = self._atomClasses[atom_class]\n        else:\n            type_set = set()\n            self._atomClasses[atom_class] = type_set\n        type_set.add(name)\n        self._atomClasses[''].add(name)\n\n        name = parameters['name']\n        if 'def' in parameters:\n            self.atomTypeDefinitions[name] = parameters['def']\n        if 'overrides' in parameters:\n            overrides = set(atype.strip() for atype\n                            in parameters['overrides'].split(\",\"))\n            if overrides:\n                self.atomTypeOverrides[name] = overrides\n        if 'des' in parameters:\n            self.atomTypeDesc[name] = parameters['desc']\n        if 'doi' in parameters:\n            dois = set(doi.strip() for doi in parameters['doi'].split(','))\n            self.atomTypeRefs[name] = dois", "response": "Register a new atom type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies the force field to a molecular structure.", "response": "def apply(self, topology, references_file=None, use_residue_map=True,\n              assert_bond_params=True, assert_angle_params=True,\n              assert_dihedral_params=True, assert_improper_params=False,\n              *args, **kwargs):\n        \"\"\"Apply the force field to a molecular structure\n\n        Parameters\n        ----------\n        topology : openmm.app.Topology or parmed.Structure or mbuild.Compound\n            Molecular structure to apply the force field to\n        references_file : str, optional, default=None\n            Name of file where force field references will be written (in Bibtex\n            format)\n        use_residue_map : boolean, optional, default=True\n            Store atomtyped topologies of residues to a dictionary that maps\n            them to residue names.  Each topology, including atomtypes, will be\n            copied to other residues with the same name. This avoids repeatedly\n            calling the subgraph isomorphism on idential residues and should\n            result in better performance for systems with many identical\n            residues, i.e. a box of water. Note that for this to be applied to\n            independent molecules, they must each be saved as different\n            residues in the topology.\n        assert_bond_params : bool, optional, default=True\n            If True, Foyer will exit if parameters are not found for all system\n            bonds.\n        assert_angle_params : bool, optional, default=True\n            If True, Foyer will exit if parameters are not found for all system\n            angles.\n        assert_dihedral_params : bool, optional, default=True\n            If True, Foyer will exit if parameters are not found for all system\n            proper dihedrals.\n        assert_improper_params : bool, optional, default=False\n            If True, Foyer will exit if parameters are not found for all system\n            improper dihedrals.\n        \"\"\"\n        if self.atomTypeDefinitions == {}:\n            raise FoyerError('Attempting to atom-type using a force field '\n                    'with no atom type defitions.')\n\n        if not isinstance(topology, app.Topology):\n            residues = kwargs.get('residues')\n            topology, positions = generate_topology(topology,\n                    self.non_element_types, residues=residues)\n        else:\n            positions = np.empty(shape=(topology.getNumAtoms(), 3))\n            positions[:] = np.nan\n        box_vectors = topology.getPeriodicBoxVectors()\n        topology = self.run_atomtyping(topology, use_residue_map=use_residue_map)\n        system = self.createSystem(topology, *args, **kwargs)\n\n        structure = pmd.openmm.load_topology(topology=topology, system=system)\n\n        '''\n        Check that all topology objects (angles, dihedrals, and impropers)\n        have parameters assigned. OpenMM will generate an error if bond parameters\n        are not assigned.\n        '''\n        data = self._SystemData\n\n        if data.bonds:\n            missing = [b for b in structure.bonds\n                       if b.type is None]\n            if missing:\n                nmissing = len(structure.bonds) - len(missing)\n                msg = (\"Parameters have not been assigned to all bonds. \"\n                       \"Total system bonds: {}, Parametrized bonds: {}\"\n                       \"\".format(len(structure.bonds), nmissing))\n                _error_or_warn(assert_bond_params, msg)\n\n        if data.angles and (len(data.angles) != len(structure.angles)):\n            msg = (\"Parameters have not been assigned to all angles. Total \"\n                   \"system angles: {}, Parameterized angles: {}\"\n                   \"\".format(len(data.angles), len(structure.angles)))\n            _error_or_warn(assert_angle_params, msg)\n\n        proper_dihedrals = [dihedral for dihedral in structure.dihedrals\n                            if not dihedral.improper]\n        if data.propers and len(data.propers) != \\\n                len(proper_dihedrals) + len(structure.rb_torsions):\n            msg = (\"Parameters have not been assigned to all proper dihedrals. \"\n                   \"Total system dihedrals: {}, Parameterized dihedrals: {}. \"\n                   \"Note that if your system contains torsions of Ryckaert-\"\n                   \"Bellemans functional form, all of these torsions are \"\n                   \"processed as propers.\".format(len(data.propers),\n                   len(proper_dihedrals) + len(structure.rb_torsions)))\n            _error_or_warn(assert_dihedral_params, msg)\n\n        improper_dihedrals = [dihedral for dihedral in structure.dihedrals\n                              if dihedral.improper]\n        if data.impropers and len(data.impropers) != \\\n                len(improper_dihedrals) + len(structure.impropers):\n            msg = (\"Parameters have not been assigned to all impropers. Total \"\n                   \"system impropers: {}, Parameterized impropers: {}. \"\n                   \"Note that if your system contains torsions of Ryckaert-\"\n                   \"Bellemans functional form, all of these torsions are \"\n                   \"processed as propers\".format(len(data.impropers),\n                   len(improper_dihedrals) + len(structure.impropers)))\n            _error_or_warn(assert_improper_params, msg)\n\n        structure.bonds.sort(key=lambda x: x.atom1.idx)\n        structure.positions = positions\n        if box_vectors is not None:\n            structure.box_vectors = box_vectors\n        if references_file:\n            atom_types = set(atom.type for atom in structure.atoms)\n            self._write_references_to_file(atom_types, references_file)\n\n        return structure"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an OpenMM System representing a Topology with this force field.", "response": "def createSystem(self, topology, nonbondedMethod=NoCutoff,\n                     nonbondedCutoff=1.0 * u.nanometer, constraints=None,\n                     rigidWater=True, removeCMMotion=True, hydrogenMass=None,\n                     **args):\n        \"\"\"Construct an OpenMM System representing a Topology with this force field.\n\n        Parameters\n        ----------\n        topology : Topology\n            The Topology for which to create a System\n        nonbondedMethod : object=NoCutoff\n            The method to use for nonbonded interactions.  Allowed values are\n            NoCutoff, CutoffNonPeriodic, CutoffPeriodic, Ewald, or PME.\n        nonbondedCutoff : distance=1*nanometer\n            The cutoff distance to use for nonbonded interactions\n        constraints : object=None\n            Specifies which bonds and angles should be implemented with constraints.\n            Allowed values are None, HBonds, AllBonds, or HAngles.\n        rigidWater : boolean=True\n            If true, water molecules will be fully rigid regardless of the value\n            passed for the constraints argument\n        removeCMMotion : boolean=True\n            If true, a CMMotionRemover will be added to the System\n        hydrogenMass : mass=None\n            The mass to use for hydrogen atoms bound to heavy atoms.  Any mass\n            added to a hydrogen is subtracted from the heavy atom to keep\n            their total mass the same.\n        args\n             Arbitrary additional keyword arguments may also be specified.\n             This allows extra parameters to be specified that are specific to\n             particular force fields.\n\n        Returns\n        -------\n        system\n            the newly created System\n        \"\"\"\n\n        # Overwrite previous _SystemData object\n        self._SystemData = app.ForceField._SystemData()\n\n        data = self._SystemData\n        data.atoms = list(topology.atoms())\n        for atom in data.atoms:\n            data.excludeAtomWith.append([])\n\n        # Make a list of all bonds\n        for bond in topology.bonds():\n            data.bonds.append(app.ForceField._BondData(bond[0].index, bond[1].index))\n\n        # Record which atoms are bonded to each other atom\n        bonded_to_atom = []\n        for i in range(len(data.atoms)):\n            bonded_to_atom.append(set())\n            data.atomBonds.append([])\n        for i in range(len(data.bonds)):\n            bond = data.bonds[i]\n            bonded_to_atom[bond.atom1].add(bond.atom2)\n            bonded_to_atom[bond.atom2].add(bond.atom1)\n            data.atomBonds[bond.atom1].append(i)\n            data.atomBonds[bond.atom2].append(i)\n\n        # TODO: Better way to lookup nonbonded parameters...?\n        nonbonded_params = None\n        for generator in self.getGenerators():\n            if isinstance(generator, NonbondedGenerator):\n                nonbonded_params = generator.params.paramsForType\n                break\n\n        for chain in topology.chains():\n            for res in chain.residues():\n                for atom in res.atoms():\n                    data.atomType[atom] = atom.id\n                    if nonbonded_params:\n                        params = nonbonded_params[atom.id]\n                        data.atomParameters[atom] = params\n\n        # Create the System and add atoms\n        sys = mm.System()\n        for atom in topology.atoms():\n            # Look up the atom type name, returning a helpful error message if it cannot be found.\n            if atom not in data.atomType:\n                raise Exception(\"Could not identify atom type for atom '%s'.\" % str(atom))\n            typename = data.atomType[atom]\n\n            # Look up the type name in the list of registered atom types, returning a helpful error message if it cannot be found.\n            if typename not in self._atomTypes:\n                msg  = \"Could not find typename '%s' for atom '%s' in list of known atom types.\\n\" % (typename, str(atom))\n                msg += \"Known atom types are: %s\" % str(self._atomTypes.keys())\n                raise Exception(msg)\n\n            # Add the particle to the OpenMM system.\n            mass = self._atomTypes[typename].mass\n            sys.addParticle(mass)\n\n        # Adjust hydrogen masses if requested.\n        if hydrogenMass is not None:\n            if not u.is_quantity(hydrogenMass):\n                hydrogenMass *= u.dalton\n            for atom1, atom2 in topology.bonds():\n                if atom1.element == elem.hydrogen:\n                    (atom1, atom2) = (atom2, atom1)\n                if atom2.element == elem.hydrogen and atom1.element not in (elem.hydrogen, None):\n                    transfer_mass = hydrogenMass - sys.getParticleMass(atom2.index)\n                    sys.setParticleMass(atom2.index, hydrogenMass)\n                    mass = sys.getParticleMass(atom1.index) - transfer_mass\n                    sys.setParticleMass(atom1.index, mass)\n\n        # Set periodic boundary conditions.\n        box_vectors = topology.getPeriodicBoxVectors()\n        if box_vectors is not None:\n            sys.setDefaultPeriodicBoxVectors(box_vectors[0],\n                                             box_vectors[1],\n                                             box_vectors[2])\n        elif nonbondedMethod not in [NoCutoff, CutoffNonPeriodic]:\n            raise ValueError('Requested periodic boundary conditions for a '\n                             'Topology that does not specify periodic box '\n                             'dimensions')\n\n        # Make a list of all unique angles\n        unique_angles = set()\n        for bond in data.bonds:\n            for atom in bonded_to_atom[bond.atom1]:\n                if atom != bond.atom2:\n                    if atom < bond.atom2:\n                        unique_angles.add((atom, bond.atom1, bond.atom2))\n                    else:\n                        unique_angles.add((bond.atom2, bond.atom1, atom))\n            for atom in bonded_to_atom[bond.atom2]:\n                if atom != bond.atom1:\n                    if atom > bond.atom1:\n                        unique_angles.add((bond.atom1, bond.atom2, atom))\n                    else:\n                        unique_angles.add((atom, bond.atom2, bond.atom1))\n        data.angles = sorted(list(unique_angles))\n\n        # Make a list of all unique proper torsions\n        unique_propers = set()\n        for angle in data.angles:\n            for atom in bonded_to_atom[angle[0]]:\n                if atom not in angle:\n                    if atom < angle[2]:\n                        unique_propers.add((atom, angle[0], angle[1], angle[2]))\n                    else:\n                        unique_propers.add((angle[2], angle[1], angle[0], atom))\n            for atom in bonded_to_atom[angle[2]]:\n                if atom not in angle:\n                    if atom > angle[0]:\n                        unique_propers.add((angle[0], angle[1], angle[2], atom))\n                    else:\n                        unique_propers.add((atom, angle[2], angle[1], angle[0]))\n        data.propers = sorted(list(unique_propers))\n\n        # Make a list of all unique improper torsions\n        for atom in range(len(bonded_to_atom)):\n            bonded_to = bonded_to_atom[atom]\n            if len(bonded_to) > 2:\n                for subset in itertools.combinations(bonded_to, 3):\n                    data.impropers.append((atom, subset[0], subset[1], subset[2]))\n\n        # Identify bonds that should be implemented with constraints\n        if constraints == AllBonds or constraints == HAngles:\n            for bond in data.bonds:\n                bond.isConstrained = True\n        elif constraints == HBonds:\n            for bond in data.bonds:\n                atom1 = data.atoms[bond.atom1]\n                atom2 = data.atoms[bond.atom2]\n                bond.isConstrained = atom1.name.startswith('H') or atom2.name.startswith('H')\n        if rigidWater:\n            for bond in data.bonds:\n                atom1 = data.atoms[bond.atom1]\n                atom2 = data.atoms[bond.atom2]\n                if atom1.residue.name == 'HOH' and atom2.residue.name == 'HOH':\n                    bond.isConstrained = True\n\n        # Identify angles that should be implemented with constraints\n        if constraints == HAngles:\n            for angle in data.angles:\n                atom1 = data.atoms[angle[0]]\n                atom2 = data.atoms[angle[1]]\n                atom3 = data.atoms[angle[2]]\n                numH = 0\n                if atom1.name.startswith('H'):\n                    numH += 1\n                if atom3.name.startswith('H'):\n                    numH += 1\n                data.isAngleConstrained.append(numH == 2 or (numH == 1 and atom2.name.startswith('O')))\n        else:\n            data.isAngleConstrained = len(data.angles)*[False]\n        if rigidWater:\n            for i in range(len(data.angles)):\n                angle = data.angles[i]\n                atom1 = data.atoms[angle[0]]\n                atom2 = data.atoms[angle[1]]\n                atom3 = data.atoms[angle[2]]\n                if atom1.residue.name == 'HOH' and atom2.residue.name == 'HOH' and atom3.residue.name == 'HOH':\n                    data.isAngleConstrained[i] = True\n\n        # Add virtual sites\n        for atom in data.virtualSites:\n            (site, atoms, excludeWith) = data.virtualSites[atom]\n            index = atom.index\n            data.excludeAtomWith[excludeWith].append(index)\n            if site.type == 'average2':\n                sys.setVirtualSite(index, mm.TwoParticleAverageSite(\n                    atoms[0], atoms[1], site.weights[0], site.weights[1]))\n            elif site.type == 'average3':\n                sys.setVirtualSite(index, mm.ThreeParticleAverageSite(\n                    atoms[0], atoms[1], atoms[2],\n                    site.weights[0], site.weights[1], site.weights[2]))\n            elif site.type == 'outOfPlane':\n                sys.setVirtualSite(index, mm.OutOfPlaneSite(\n                    atoms[0], atoms[1], atoms[2],\n                    site.weights[0], site.weights[1], site.weights[2]))\n            elif site.type == 'localCoords':\n                local_coord_site = mm.LocalCoordinatesSite(\n                    atoms[0], atoms[1], atoms[2],\n                    mm.Vec3(site.originWeights[0], site.originWeights[1], site.originWeights[2]),\n                    mm.Vec3(site.xWeights[0], site.xWeights[1], site.xWeights[2]),\n                    mm.Vec3(site.yWeights[0], site.yWeights[1], site.yWeights[2]),\n                    mm.Vec3(site.localPos[0], site.localPos[1], site.localPos[2]))\n                sys.setVirtualSite(index, local_coord_site)\n\n        # Add forces to the System\n        for force in self._forces:\n            force.createForce(sys, data, nonbondedMethod, nonbondedCutoff, args)\n        if removeCMMotion:\n            sys.addForce(mm.CMMotionRemover())\n\n        # Let force generators do postprocessing\n        for force in self._forces:\n            if 'postprocessSystem' in dir(force):\n                force.postprocessSystem(sys, data, args)\n\n        # Execute scripts found in the XML files.\n        for script in self._scripts:\n            exec(script, locals())\n\n        return sys"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(command, encoding=None, decode=True, cwd=None):\n    if not encoding:\n        encoding = locale.getpreferredencoding()\n    try:\n        with open(os.devnull, 'rb') as devnull:\n            pipe = subprocess.Popen(command, stdin=devnull,\n                                    stdout=subprocess.PIPE,\n                                    stderr=subprocess.STDOUT, cwd=cwd)\n    except OSError as e:\n        raise Failure(\"could not run %s: %s\" % (command, e))\n    output = pipe.communicate()[0]\n    if decode:\n        output = output.decode(encoding)\n    status = pipe.wait()\n    if status != 0:\n        raise CommandFailed(command, status, output)\n    return output", "response": "Run a command on the available virtual languages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cd(directory):\n    old_dir = os.getcwd()\n    try:\n        os.chdir(directory)\n        yield\n    finally:\n        os.chdir(old_dir)", "response": "Change the current working directory temporarily."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mkdtemp(hint=''):\n    dirname = tempfile.mkdtemp(prefix='check-manifest-', suffix=hint)\n    try:\n        yield dirname\n    finally:\n        rmtree(dirname)", "response": "Create a temporary directory and then clean it up."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange a file s mode by adding a few bits.", "response": "def chmod_plus(path, add_bits=stat.S_IWUSR):\n    \"\"\"Change a file's mode by adding a few bits.\n\n    Like chmod +<bits> <path> in a Unix shell.\n    \"\"\"\n    try:\n        os.chmod(path, stat.S_IMODE(os.stat(path).st_mode) | add_bits)\n    except OSError:  # pragma: nocover\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_files(filelist, destdir):\n    for filename in filelist:\n        destfile = os.path.join(destdir, filename)\n        # filename should not be absolute, but let's double-check\n        assert destfile.startswith(destdir + os.path.sep)\n        destfiledir = os.path.dirname(destfile)\n        if not os.path.isdir(destfiledir):\n            os.makedirs(destfiledir)\n        if os.path.isdir(filename):\n            os.mkdir(destfile)\n        else:\n            shutil.copy2(filename, destfile)", "response": "Copy a list of files to destdir preserving directory structure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_one_file_in(dirname):\n    files = os.listdir(dirname)\n    if len(files) > 1:\n        raise Failure('More than one file exists in %s:\\n%s' %\n                      (dirname, '\\n'.join(sorted(files))))\n    elif not files:\n        raise Failure('No files found in %s' % dirname)\n    return os.path.join(dirname, files[0])", "response": "Return the pathname of the one file in a directory. Raises if the directory has more than one file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unicodify(filename):\n    if isinstance(filename, bytes):\n        return filename.decode(locale.getpreferredencoding())\n    else:\n        return filename", "response": "Make sure filename is Unicode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_archive_file_list(archive_filename):\n    if archive_filename.endswith('.zip'):\n        with closing(zipfile.ZipFile(archive_filename)) as zf:\n            return add_directories(zf.namelist())\n    elif archive_filename.endswith(('.tar.gz', '.tar.bz2', '.tar')):\n        with closing(tarfile.open(archive_filename)) as tf:\n            return add_directories(list(map(unicodify, tf.getnames())))\n    else:\n        ext = os.path.splitext(archive_filename)[-1]\n        raise Failure('Unrecognized archive type: %s' % ext)", "response": "Return the list of files in an archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstrips toplevel name from a file list.", "response": "def strip_toplevel_name(filelist):\n    \"\"\"Strip toplevel name from a file list.\n\n        >>> strip_toplevel_name(['a', 'a/b', 'a/c', 'a/c/d'])\n        ['b', 'c', 'c/d']\n\n        >>> strip_toplevel_name(['a/b', 'a/c', 'a/c/d'])\n        ['b', 'c', 'c/d']\n\n    \"\"\"\n    if not filelist:\n        return filelist\n    prefix = filelist[0]\n    if '/' in prefix:\n        prefix = prefix.partition('/')[0] + '/'\n        names = filelist\n    else:\n        prefix = prefix + '/'\n        names = filelist[1:]\n    for name in names:\n        if not name.startswith(prefix):\n            raise Failure(\"File doesn't have the common prefix (%s): %s\"\n                          % (name, prefix))\n    return [name[len(prefix):] for name in names]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef detect_vcs():\n    location = os.path.abspath('.')\n    while True:\n        for vcs in Git, Mercurial, Bazaar, Subversion:\n            if vcs.detect(location):\n                return vcs\n        parent = os.path.dirname(location)\n        if parent == location:\n            raise Failure(\"Couldn't find version control data\"\n                          \" (git/hg/bzr/svn supported)\")\n        location = parent", "response": "Detect the version control system used for the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_name(name):\n    name = os.path.normpath(name)\n    name = unicodify(name)\n    if sys.platform == 'darwin':\n        # Mac OSX may have problems comparing non-ascii filenames, so\n        # we convert them.\n        name = unicodedata.normalize('NFC', name)\n    return name", "response": "Normalize a directory name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_directories(names):\n    res = list(names)\n    seen = set(names)\n    for name in names:\n        while True:\n            name = os.path.dirname(name)\n            if not name or name in seen:\n                break\n            res.append(name)\n            seen.add(name)\n    return sorted(res)", "response": "Git / Mercurial / zip files omit directories let s add them back."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading configuration from file if possible.", "response": "def read_config():\n    \"\"\"Read configuration from file if possible.\"\"\"\n    # XXX modifies global state, which is kind of evil\n    config = _load_config()\n    if config.get(CFG_IGNORE_DEFAULT_RULES[1], False):\n        del IGNORE[:]\n    if CFG_IGNORE[1] in config:\n        IGNORE.extend(p for p in config[CFG_IGNORE[1]] if p)\n    if CFG_IGNORE_BAD_IDEAS[1] in config:\n        IGNORE_BAD_IDEAS.extend(p for p in config[CFG_IGNORE_BAD_IDEAS[1]] if p)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the configuration files and returns a dictionary of the first file that exists and has a check - manifest section.", "response": "def _load_config():\n    \"\"\"Searches for config files, reads them and returns a dictionary\n\n    Looks for a ``check-manifest`` section in ``pyproject.toml``,\n    ``setup.cfg``, and ``tox.ini``, in that order.  The first file\n    that exists and has that section will be loaded and returned as a\n    dictionary.\n\n    \"\"\"\n    if os.path.exists(\"pyproject.toml\"):\n        config = toml.load(\"pyproject.toml\")\n        if CFG_SECTION_CHECK_MANIFEST in config.get(\"tool\", {}):\n            return config[\"tool\"][CFG_SECTION_CHECK_MANIFEST]\n\n    search_files = ['setup.cfg', 'tox.ini']\n    config_parser = ConfigParser.ConfigParser()\n    for filename in search_files:\n        if (config_parser.read([filename])\n                and config_parser.has_section(CFG_SECTION_CHECK_MANIFEST)):\n            config = {}\n\n            if config_parser.has_option(*CFG_IGNORE_DEFAULT_RULES):\n                ignore_defaults = config_parser.getboolean(*CFG_IGNORE_DEFAULT_RULES)\n                config[CFG_IGNORE_DEFAULT_RULES[1]] = ignore_defaults\n\n            if config_parser.has_option(*CFG_IGNORE):\n                patterns = [\n                    p.strip()\n                    for p in config_parser.get(*CFG_IGNORE).splitlines()\n                ]\n                config[CFG_IGNORE[1]] = patterns\n\n            if config_parser.has_option(*CFG_IGNORE_BAD_IDEAS):\n                patterns = [\n                    p.strip()\n                    for p in config_parser.get(*CFG_IGNORE_BAD_IDEAS).splitlines()\n                ]\n                config[CFG_IGNORE_BAD_IDEAS[1]] = patterns\n\n            return config\n\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_manifest():\n    # XXX modifies global state, which is kind of evil\n    if not os.path.isfile('MANIFEST.in'):\n        return\n    ignore, ignore_regexps = _get_ignore_from_manifest('MANIFEST.in')\n    IGNORE.extend(ignore)\n    IGNORE_REGEXPS.extend(ignore_regexps)", "response": "Read existing configuration from MANIFEST. in."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_ignore_from_manifest(filename):\n\n    class MyTextFile(TextFile):\n        def error(self, msg, line=None):  # pragma: nocover\n            # (this is never called by TextFile in current versions of CPython)\n            raise Failure(self.gen_error(msg, line))\n\n        def warn(self, msg, line=None):\n            warning(self.gen_error(msg, line))\n\n    template = MyTextFile(filename,\n                          strip_comments=True,\n                          skip_blanks=True,\n                          join_lines=True,\n                          lstrip_ws=True,\n                          rstrip_ws=True,\n                          collapse_join=True)\n    try:\n        lines = template.readlines()\n    finally:\n        template.close()\n    return _get_ignore_from_manifest_lines(lines)", "response": "Gather the various ignore patterns from a MANIFEST. in.\n    Returns a list of standard ignore patterns and a list of regularicalical ignore expressions to ignore."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_ignore_from_manifest_lines(lines):\n    ignore = []\n    ignore_regexps = []\n    for line in lines:\n        try:\n            cmd, rest = line.split(None, 1)\n        except ValueError:\n            # no whitespace, so not interesting\n            continue\n        for part in rest.split():\n            # distutils enforces these warnings on Windows only\n            if part.startswith('/'):\n                warning(\"ERROR: Leading slashes are not allowed in MANIFEST.in on Windows: %s\" % part)\n            if part.endswith('/'):\n                warning(\"ERROR: Trailing slashes are not allowed in MANIFEST.in on Windows: %s\" % part)\n        if cmd == 'exclude':\n            # An exclude of 'dirname/*css' can match 'dirname/foo.css'\n            # but not 'dirname/subdir/bar.css'.  We need a regular\n            # expression for that, since fnmatch doesn't pay attention to\n            # directory separators.\n            for pat in rest.split():\n                if '*' in pat or '?' in pat or '[!' in pat:\n                    ignore_regexps.append(_glob_to_regexp(pat))\n                else:\n                    # No need for special handling.\n                    ignore.append(pat)\n        elif cmd == 'global-exclude':\n            ignore.extend(rest.split())\n        elif cmd == 'recursive-exclude':\n            try:\n                dirname, patterns = rest.split(None, 1)\n            except ValueError:\n                # Wrong MANIFEST.in line.\n                warning(\"You have a wrong line in MANIFEST.in: %r\\n\"\n                        \"'recursive-exclude' expects <dir> <pattern1> \"\n                        \"<pattern2> ...\" % line)\n                continue\n            # Strip path separator for clarity.\n            dirname = dirname.rstrip(os.path.sep)\n            for pattern in patterns.split():\n                if pattern.startswith('*'):\n                    ignore.append(dirname + os.path.sep + pattern)\n                else:\n                    # 'recursive-exclude plone metadata.xml' should\n                    # exclude plone/metadata.xml and\n                    # plone/*/metadata.xml, where * can be any number\n                    # of sub directories.  We could use a regexp, but\n                    # two ignores seems easier.\n                    ignore.append(dirname + os.path.sep + pattern)\n                    ignore.append(\n                        dirname + os.path.sep + '*' + os.path.sep + pattern)\n        elif cmd == 'prune':\n            # rest is considered to be a directory name.  It should\n            # not contain a path separator, as it actually has no\n            # effect in that case, but that could differ per python\n            # version.  We strip it here to avoid double separators.\n            # XXX: mg: I'm not 100% sure the above is correct, AFAICS\n            # all pythons from 2.6 complain if the path has a leading or\n            # trailing slash -- on Windows, that is.\n            rest = rest.rstrip('/\\\\')\n            ignore.append(rest)\n            ignore.append(rest + os.path.sep + '*')\n    return ignore, ignore_regexps", "response": "Gather the various ignore patterns from a MANIFEST. in."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes this filename match any of the patterns?", "response": "def file_matches(filename, patterns):\n    \"\"\"Does this filename match any of the patterns?\"\"\"\n    return any(fnmatch.fnmatch(filename, pat)\n               or fnmatch.fnmatch(os.path.basename(filename), pat)\n               for pat in patterns)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_matches_regexps(filename, patterns):\n    return any(re.match(pat, filename) for pat in patterns)", "response": "Does this filename match any of the regular expressions?"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstripping files that are only present in source distributions.", "response": "def strip_sdist_extras(filelist):\n    \"\"\"Strip generated files that are only present in source distributions.\n\n    We also strip files that are ignored for other reasons, like\n    command line arguments, setup.cfg rules or MANIFEST.in rules.\n    \"\"\"\n    return [name for name in filelist\n            if not file_matches(name, IGNORE)\n            and not file_matches_regexps(name, IGNORE_REGEXPS)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds all possible suggestions for files in a list of files.", "response": "def find_suggestions(filelist):\n    \"\"\"Suggest MANIFEST.in patterns for missing files.\"\"\"\n    suggestions = set()\n    unknowns = []\n    for filename in filelist:\n        if os.path.isdir(filename):\n            # it's impossible to add empty directories via MANIFEST.in anyway,\n            # and non-empty directories will be added automatically when we\n            # specify patterns for files inside them\n            continue\n        for pattern, suggestion in SUGGESTIONS:\n            m = pattern.match(filename)\n            if m is not None:\n                suggestions.add(pattern.sub(suggestion, filename))\n                break\n        else:\n            unknowns.append(filename)\n    return sorted(suggestions), unknowns"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract version number from sdist filename.", "response": "def extract_version_from_filename(filename):\n    \"\"\"Extract version number from sdist filename.\"\"\"\n    filename = os.path.splitext(os.path.basename(filename))[0]\n    if filename.endswith('.tar'):\n        filename = os.path.splitext(filename)[0]\n    return filename.partition('-')[2]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompares a generated source distribution with list of files in a VCS.", "response": "def check_manifest(source_tree='.', create=False, update=False,\n                   python=sys.executable):\n    \"\"\"Compare a generated source distribution with list of files in a VCS.\n\n    Returns True if the manifest is fine.\n    \"\"\"\n    all_ok = True\n    if os.path.sep in python:\n        python = os.path.abspath(python)\n    with cd(source_tree):\n        if not is_package():\n            raise Failure('This is not a Python project (no setup.py).')\n        read_config()\n        read_manifest()\n        info_begin(\"listing source files under version control\")\n        all_source_files = sorted(get_vcs_files())\n        source_files = strip_sdist_extras(all_source_files)\n        info_continue(\": %d files and directories\" % len(source_files))\n        if not all_source_files:\n            raise Failure('There are no files added to version control!')\n        info_begin(\"building an sdist\")\n        with mkdtemp('-sdist') as tempdir:\n            run([python, 'setup.py', 'sdist', '-d', tempdir])\n            sdist_filename = get_one_file_in(tempdir)\n            info_continue(\": %s\" % os.path.basename(sdist_filename))\n            sdist_files = sorted(normalize_names(strip_sdist_extras(\n                strip_toplevel_name(get_archive_file_list(sdist_filename)))))\n            info_continue(\": %d files and directories\" % len(sdist_files))\n            version = extract_version_from_filename(sdist_filename)\n        existing_source_files = list(filter(os.path.exists, all_source_files))\n        missing_source_files = sorted(set(all_source_files) - set(existing_source_files))\n        if missing_source_files:\n            warning(\"some files listed as being under source control are missing:\\n%s\"\n                    % format_list(missing_source_files))\n        info_begin(\"copying source files to a temporary directory\")\n        with mkdtemp('-sources') as tempsourcedir:\n            copy_files(existing_source_files, tempsourcedir)\n            if os.path.exists('MANIFEST.in') and 'MANIFEST.in' not in source_files:\n                # See https://github.com/mgedmin/check-manifest/issues/7\n                # if do this, we will emit a warning about MANIFEST.in not\n                # being in source control, if we don't do this, the user\n                # gets confused about their new manifest rules being\n                # ignored.\n                copy_files(['MANIFEST.in'], tempsourcedir)\n            if 'setup.py' not in source_files:\n                # See https://github.com/mgedmin/check-manifest/issues/46\n                # if do this, we will emit a warning about setup.py not\n                # being in source control, if we don't do this, the user\n                # gets a scary error\n                copy_files(['setup.py'], tempsourcedir)\n            info_begin(\"building a clean sdist\")\n            with cd(tempsourcedir):\n                with mkdtemp('-sdist') as tempdir:\n                    os.environ['SETUPTOOLS_SCM_PRETEND_VERSION'] = version\n                    run([python, 'setup.py', 'sdist', '-d', tempdir])\n                    sdist_filename = get_one_file_in(tempdir)\n                    info_continue(\": %s\" % os.path.basename(sdist_filename))\n                    clean_sdist_files = sorted(normalize_names(strip_sdist_extras(\n                        strip_toplevel_name(get_archive_file_list(sdist_filename)))))\n                    info_continue(\": %d files and directories\" % len(clean_sdist_files))\n        missing_from_manifest = set(source_files) - set(clean_sdist_files)\n        missing_from_VCS = set(sdist_files + clean_sdist_files) - set(source_files)\n        if not missing_from_manifest and not missing_from_VCS:\n            info(\"lists of files in version control and sdist match\")\n        else:\n            error(\"lists of files in version control and sdist do not match!\\n%s\"\n                  % format_missing(missing_from_VCS, missing_from_manifest,\n                                   \"VCS\", \"sdist\"))\n            suggestions, unknowns = find_suggestions(missing_from_manifest)\n            user_asked_for_help = update or (create and not\n                                                os.path.exists('MANIFEST.in'))\n            if 'MANIFEST.in' not in existing_source_files:\n                if suggestions and not user_asked_for_help:\n                    info(\"no MANIFEST.in found; you can run 'check-manifest -c' to create one\")\n                else:\n                    info(\"no MANIFEST.in found\")\n            if suggestions:\n                info(\"suggested MANIFEST.in rules:\\n%s\"\n                     % format_list(suggestions))\n                if user_asked_for_help:\n                    existed = os.path.exists('MANIFEST.in')\n                    with open('MANIFEST.in', 'a') as f:\n                        if not existed:\n                            info(\"creating MANIFEST.in\")\n                        else:\n                            info(\"updating MANIFEST.in\")\n                            f.write('\\n# added by check_manifest.py\\n')\n                        f.write('\\n'.join(suggestions) + '\\n')\n                    if unknowns:\n                        info(\"don't know how to come up with rules matching\\n%s\"\n                             % format_list(unknowns))\n            elif user_asked_for_help:\n                info(\"don't know how to come up with rules\"\n                     \" matching any of the files, sorry!\")\n            all_ok = False\n        bad_ideas = find_bad_ideas(all_source_files)\n        filtered_bad_ideas = [bad_idea for bad_idea in bad_ideas\n                              if not file_matches(bad_idea, IGNORE_BAD_IDEAS)]\n        if filtered_bad_ideas:\n            warning(\"you have %s in source control!\\nthat's a bad idea:\"\n                    \" auto-generated files should not be versioned\"\n                    % filtered_bad_ideas[0])\n            if len(filtered_bad_ideas) > 1:\n                warning(\"this also applies to the following:\\n%s\"\n                        % format_list(filtered_bad_ideas[1:]))\n            all_ok = False\n    return all_ok"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zest_releaser_check(data):\n    from zest.releaser.utils import ask\n    source_tree = data['workingdir']\n    if not is_package(source_tree):\n        # You can use zest.releaser on things that are not Python packages.\n        # It's pointless to run check-manifest in those circumstances.\n        # See https://github.com/mgedmin/check-manifest/issues/9 for details.\n        return\n    if not ask(\"Do you want to run check-manifest?\"):\n        return\n    try:\n        if not check_manifest(source_tree):\n            if not ask(\"MANIFEST.in has problems. \"\n                       \" Do you want to continue despite that?\", default=False):\n                sys.exit(1)\n    except Failure as e:\n        error(str(e))\n        if not ask(\"Something bad happened. \"\n                   \" Do you want to continue despite that?\", default=False):\n            sys.exit(2)", "response": "Check the completeness of MANIFEST. in before the release."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_versioned_files(cls):\n        files = cls._git_ls_files()\n        submodules = cls._list_submodules()\n        for subdir in submodules:\n            subdir = os.path.relpath(subdir).replace(os.path.sep, '/')\n            files += add_prefix_to_each(subdir, cls._git_ls_files(subdir))\n        return add_directories(files)", "response": "List all files versioned by git in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_versioned_files(cls):\n        encoding = cls._get_terminal_encoding()\n        output = run(['bzr', 'ls', '-VR'], encoding=encoding)\n        return output.splitlines()", "response": "List all files versioned in Bazaar in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all files under SVN control in the current directory.", "response": "def get_versioned_files(cls):\n        \"\"\"List all files under SVN control in the current directory.\"\"\"\n        output = run(['svn', 'st', '-vq', '--xml'], decode=False)\n        tree = ET.XML(output)\n        return sorted(entry.get('path') for entry in tree.findall('.//entry')\n                      if cls.is_interesting(entry))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_interesting(entry):\n        if entry.get('path') == '.':\n            return False\n        status = entry.find('wc-status')\n        if status is None:\n            warning('svn status --xml parse error: <entry path=\"%s\"> without'\n                    ' <wc-status>' % entry.get('path'))\n            return False\n        # For SVN externals we get two entries: one mentioning the\n        # existence of the external, and one about the status of the external.\n        if status.get('item') in ('unversioned', 'external'):\n            return False\n        return True", "response": "Is this entry interesting?"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self):\n        if not self.principals:\n            raise InvalidApplicationPolicyError(error_message='principals not provided')\n\n        if not self.actions:\n            raise InvalidApplicationPolicyError(error_message='actions not provided')\n\n        if any(not self._PRINCIPAL_PATTERN.match(p) for p in self.principals):\n            raise InvalidApplicationPolicyError(\n                error_message='principal should be 12-digit AWS account ID or \"*\"')\n\n        unsupported_actions = sorted(set(self.actions) - set(self.SUPPORTED_ACTIONS))\n        if unsupported_actions:\n            raise InvalidApplicationPolicyError(\n                error_message='{} not supported'.format(', '.join(unsupported_actions)))\n\n        return True", "response": "Check if the formats of principals and actions are valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef publish_application(template, sar_client=None):\n    if not template:\n        raise ValueError('Require SAM template to publish the application')\n\n    if not sar_client:\n        sar_client = boto3.client('serverlessrepo')\n\n    template_dict = _get_template_dict(template)\n    app_metadata = get_app_metadata(template_dict)\n    stripped_template_dict = strip_app_metadata(template_dict)\n    stripped_template = yaml_dump(stripped_template_dict)\n    try:\n        request = _create_application_request(app_metadata, stripped_template)\n        response = sar_client.create_application(**request)\n        application_id = response['ApplicationId']\n        actions = [CREATE_APPLICATION]\n    except ClientError as e:\n        if not _is_conflict_exception(e):\n            raise _wrap_client_error(e)\n\n        # Update the application if it already exists\n        error_message = e.response['Error']['Message']\n        application_id = parse_application_id(error_message)\n        try:\n            request = _update_application_request(app_metadata, application_id)\n            sar_client.update_application(**request)\n            actions = [UPDATE_APPLICATION]\n        except ClientError as e:\n            raise _wrap_client_error(e)\n\n        # Create application version if semantic version is specified\n        if app_metadata.semantic_version:\n            try:\n                request = _create_application_version_request(app_metadata, application_id, stripped_template)\n                sar_client.create_application_version(**request)\n                actions.append(CREATE_APPLICATION_VERSION)\n            except ClientError as e:\n                if not _is_conflict_exception(e):\n                    raise _wrap_client_error(e)\n\n    return {\n        'application_id': application_id,\n        'actions': actions,\n        'details': _get_publish_details(actions, app_metadata.template_dict)\n    }", "response": "Create a new application or update an existing application version in SAR."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_application_metadata(template, application_id, sar_client=None):\n    if not template or not application_id:\n        raise ValueError('Require SAM template and application ID to update application metadata')\n\n    if not sar_client:\n        sar_client = boto3.client('serverlessrepo')\n\n    template_dict = _get_template_dict(template)\n    app_metadata = get_app_metadata(template_dict)\n    request = _update_application_request(app_metadata, application_id)\n    sar_client.update_application(**request)", "response": "Update the application metadata for a given SAM template and application ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_template_dict(template):\n    if isinstance(template, str):\n        return parse_template(template)\n\n    if isinstance(template, dict):\n        return copy.deepcopy(template)\n\n    raise ValueError('Input template should be a string or dictionary')", "response": "Parse string template and or copy dictionary template."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_application_request(app_metadata, template):\n    app_metadata.validate(['author', 'description', 'name'])\n    request = {\n        'Author': app_metadata.author,\n        'Description': app_metadata.description,\n        'HomePageUrl': app_metadata.home_page_url,\n        'Labels': app_metadata.labels,\n        'LicenseUrl': app_metadata.license_url,\n        'Name': app_metadata.name,\n        'ReadmeUrl': app_metadata.readme_url,\n        'SemanticVersion': app_metadata.semantic_version,\n        'SourceCodeUrl': app_metadata.source_code_url,\n        'SpdxLicenseId': app_metadata.spdx_license_id,\n        'TemplateBody': template\n    }\n    # Remove None values\n    return {k: v for k, v in request.items() if v}", "response": "Construct the request body to create application."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_application_request(app_metadata, application_id):\n    request = {\n        'ApplicationId': application_id,\n        'Author': app_metadata.author,\n        'Description': app_metadata.description,\n        'HomePageUrl': app_metadata.home_page_url,\n        'Labels': app_metadata.labels,\n        'ReadmeUrl': app_metadata.readme_url\n    }\n    return {k: v for k, v in request.items() if v}", "response": "Construct the SAR UpdateApplication request body to update an application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_application_version_request(app_metadata, application_id, template):\n    app_metadata.validate(['semantic_version'])\n    request = {\n        'ApplicationId': application_id,\n        'SemanticVersion': app_metadata.semantic_version,\n        'SourceCodeUrl': app_metadata.source_code_url,\n        'TemplateBody': template\n    }\n    return {k: v for k, v in request.items() if v}", "response": "Construct the request body to create application version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping botocore ClientError exception into ServerlessRepoClientError.", "response": "def _wrap_client_error(e):\n    \"\"\"\n    Wrap botocore ClientError exception into ServerlessRepoClientError.\n\n    :param e: botocore exception\n    :type e: ClientError\n    :return: S3PermissionsRequired or InvalidS3UriError or general ServerlessRepoClientError\n    \"\"\"\n    error_code = e.response['Error']['Code']\n    message = e.response['Error']['Message']\n\n    if error_code == 'BadRequestException':\n        if \"Failed to copy S3 object. Access denied:\" in message:\n            match = re.search('bucket=(.+?), key=(.+?)$', message)\n            if match:\n                return S3PermissionsRequired(bucket=match.group(1), key=match.group(2))\n        if \"Invalid S3 URI\" in message:\n            return InvalidS3UriError(message=message)\n\n    return ServerlessRepoClientError(message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the changed fields and values of the application metadata after publishing.", "response": "def _get_publish_details(actions, app_metadata_template):\n    \"\"\"\n    Get the changed application details after publishing.\n\n    :param actions: Actions taken during publishing\n    :type actions: list of str\n    :param app_metadata_template: Original template definitions of app metadata\n    :type app_metadata_template: dict\n    :return: Updated fields and values of the application\n    :rtype: dict\n    \"\"\"\n    if actions == [CREATE_APPLICATION]:\n        return {k: v for k, v in app_metadata_template.items() if v}\n\n    include_keys = [\n        ApplicationMetadata.AUTHOR,\n        ApplicationMetadata.DESCRIPTION,\n        ApplicationMetadata.HOME_PAGE_URL,\n        ApplicationMetadata.LABELS,\n        ApplicationMetadata.README_URL\n    ]\n\n    if CREATE_APPLICATION_VERSION in actions:\n        # SemanticVersion and SourceCodeUrl can only be updated by creating a new version\n        additional_keys = [ApplicationMetadata.SEMANTIC_VERSION, ApplicationMetadata.SOURCE_CODE_URL]\n        include_keys.extend(additional_keys)\n    return {k: v for k, v in app_metadata_template.items() if k in include_keys and v}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self, required_props):\n        missing_props = [p for p in required_props if not getattr(self, p)]\n        if missing_props:\n            missing_props_str = ', '.join(sorted(missing_props))\n            raise InvalidApplicationMetadataError(properties=missing_props_str)\n        return True", "response": "Checks if the required application metadata properties have been populated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping the dictionary as a YAML document.", "response": "def yaml_dump(dict_to_dump):\n    \"\"\"\n    Dump the dictionary as a YAML document.\n\n    :param dict_to_dump: Data to be serialized as YAML\n    :type dict_to_dump: dict\n    :return: YAML document\n    :rtype: str\n    \"\"\"\n    yaml.SafeDumper.add_representer(OrderedDict, _dict_representer)\n    return yaml.safe_dump(dict_to_dump, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_template(template_str):\n    try:\n        # PyYAML doesn't support json as well as it should, so if the input\n        # is actually just json it is better to parse it with the standard\n        # json parser.\n        return json.loads(template_str, object_pairs_hook=OrderedDict)\n    except ValueError:\n        yaml.SafeLoader.add_constructor(yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG, _dict_constructor)\n        yaml.SafeLoader.add_multi_constructor('!', intrinsics_multi_constructor)\n        return yaml.safe_load(template_str)", "response": "Parse the SAM template."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_app_metadata(template_dict):\n    if SERVERLESS_REPO_APPLICATION in template_dict.get(METADATA, {}):\n        app_metadata_dict = template_dict.get(METADATA).get(SERVERLESS_REPO_APPLICATION)\n        return ApplicationMetadata(app_metadata_dict)\n\n    raise ApplicationMetadataNotFoundError(\n        error_message='missing {} section in template Metadata'.format(SERVERLESS_REPO_APPLICATION))", "response": "Get the application metadata from a SAM template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the application id from input text.", "response": "def parse_application_id(text):\n    \"\"\"\n    Extract the application id from input text.\n\n    :param text: text to parse\n    :type text: str\n    :return: application id if found in the input\n    :rtype: str\n    \"\"\"\n    result = re.search(APPLICATION_ID_PATTERN, text)\n    return result.group(0) if result else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_app_metadata(template_dict):\n    if SERVERLESS_REPO_APPLICATION not in template_dict.get(METADATA, {}):\n        return template_dict\n\n    template_dict_copy = copy.deepcopy(template_dict)\n\n    # strip the whole metadata section if SERVERLESS_REPO_APPLICATION is the only key in it\n    if not [k for k in template_dict_copy.get(METADATA) if k != SERVERLESS_REPO_APPLICATION]:\n        template_dict_copy.pop(METADATA, None)\n    else:\n        template_dict_copy.get(METADATA).pop(SERVERLESS_REPO_APPLICATION, None)\n\n    return template_dict_copy", "response": "Strip the AWS :: ServerlessRepo :: Application metadata section from template."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the application to be private.", "response": "def make_application_private(application_id, sar_client=None):\n    \"\"\"\n    Set the application to be private.\n\n    :param application_id: The Amazon Resource Name (ARN) of the application\n    :type application_id: str\n    :param sar_client: The boto3 client used to access SAR\n    :type sar_client: boto3.client\n    :raises ValueError\n    \"\"\"\n    if not application_id:\n        raise ValueError('Require application id to make the app private')\n\n    if not sar_client:\n        sar_client = boto3.client('serverlessrepo')\n\n    sar_client.put_application_policy(\n        ApplicationId=application_id,\n        Statements=[]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsharing the application with given AWS accounts.", "response": "def share_application_with_accounts(application_id, account_ids, sar_client=None):\n    \"\"\"\n    Share the application privately with given AWS account IDs.\n\n    :param application_id: The Amazon Resource Name (ARN) of the application\n    :type application_id: str\n    :param account_ids: List of AWS account IDs, or *\n    :type account_ids: list of str\n    :param sar_client: The boto3 client used to access SAR\n    :type sar_client: boto3.client\n    :raises ValueError\n    \"\"\"\n    if not application_id or not account_ids:\n        raise ValueError('Require application id and list of AWS account IDs to share the app')\n\n    if not sar_client:\n        sar_client = boto3.client('serverlessrepo')\n\n    application_policy = ApplicationPolicy(account_ids, [ApplicationPolicy.DEPLOY])\n    application_policy.validate()\n    sar_client.put_application_policy(\n        ApplicationId=application_id,\n        Statements=[application_policy.to_statement()]\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_args(cls, *args):\n        model = None\n        crudbuilder = None\n\n        for arg in args:\n            if issubclass(arg, models.Model):\n                model = arg\n            else:\n                crudbuilder = arg\n\n        return [model, crudbuilder]", "response": "Takes any arguments like a model and crud and returns a model and crudbuilder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a new crud.", "response": "def register(self, *args, **kwargs):\n        \"\"\"\n        Register a crud.\n\n        Two unordered arguments are accepted, at least one should be passed:\n        - a model,\n        - a crudbuilder class\n        \"\"\"\n\n        assert len(args) <= 2, 'register takes at most 2 args'\n        assert len(args) > 0, 'register takes at least 1 arg'\n\n        model, crudbuilder = self.__class__.extract_args(*args)\n\n        if not issubclass(model, models.Model):\n            msg = \"First argument should be Django Model\"\n            raise NotModelException(msg)\n\n        key = self._model_key(model, crudbuilder)\n\n        if key in self:\n            msg = \"Key '{key}' has already been registered.\".format(\n                key=key\n            )\n            raise AlreadyRegistered(msg)\n\n        self.__setitem__(key, crudbuilder)\n        return crudbuilder"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef construct_formset(self):\n        if not self.inline_model or not self.parent_model:\n            msg = \"Parent and Inline models are required in {}\".format(self.__class__.__name__)\n            raise NotModelException(msg)\n\n        return inlineformset_factory(\n            self.parent_model,\n            self.inline_model,\n            **self.get_factory_kwargs())", "response": "Constructs an inline formset based on the current state of the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_factory_kwargs(self):\n        kwargs = {}\n        kwargs.update({\n            'can_delete': self.can_delete,\n            'extra': self.extra,\n            'exclude': self.exclude,\n            'fields': self.fields,\n            'formfield_callback': self.formfield_callback,\n            'fk_name': self.fk_name,\n        })\n        if self.formset_class:\n            kwargs['formset'] = self.formset_class\n\n        if self.child_form:\n            kwargs['form'] = self.child_form\n        return kwargs", "response": "Returns the keyword arguments for calling the formset factory\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the plural version of the given text.", "response": "def plural(text):\n    \"\"\"\n        >>> plural('activity')\n        'activities'\n    \"\"\"\n    aberrant = {\n        'knife': 'knives',\n        'self': 'selves',\n        'elf': 'elves',\n        'life': 'lives',\n        'hoof': 'hooves',\n        'leaf': 'leaves',\n        'echo': 'echoes',\n        'embargo': 'embargoes',\n        'hero': 'heroes',\n        'potato': 'potatoes',\n        'tomato': 'tomatoes',\n        'torpedo': 'torpedoes',\n        'veto': 'vetoes',\n        'child': 'children',\n        'woman': 'women',\n        'man': 'men',\n        'person': 'people',\n        'goose': 'geese',\n        'mouse': 'mice',\n        'barracks': 'barracks',\n        'deer': 'deer',\n        'nucleus': 'nuclei',\n        'syllabus': 'syllabi',\n        'focus': 'foci',\n        'fungus': 'fungi',\n        'cactus': 'cacti',\n        'phenomenon': 'phenomena',\n        'index': 'indices',\n        'appendix': 'appendices',\n        'criterion': 'criteria',\n\n\n    }\n\n    if text in aberrant:\n        result = '%s' % aberrant[text]\n    else:\n        postfix = 's'\n        if len(text) > 2:\n            vowels = 'aeiou'\n            if text[-2:] in ('ch', 'sh'):\n                postfix = 'es'\n            elif text[-1:] == 'y':\n                if (text[-2:-1] in vowels) or (text[0] in string.ascii_uppercase):\n                    postfix = 's'\n                else:\n                    postfix = 'ies'\n                    text = text[:-1]\n            elif text[-2:] == 'is':\n                postfix = 'es'\n                text = text[:-2]\n            elif text[-1:] in ('s', 'z', 'x'):\n                postfix = 'es'\n\n        result = '%s%s' % (text, postfix)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a mixed string to the original string.", "response": "def mixedToUnder(s):  # pragma: no cover\n    \"\"\"\n    Sample:\n        >>> mixedToUnder(\"FooBarBaz\")\n        'foo_bar_baz'\n\n    Special case for ID:\n        >>> mixedToUnder(\"FooBarID\")\n        'foo_bar_id'\n    \"\"\"\n    if s.endswith('ID'):\n        return mixedToUnder(s[:-2] + \"_id\")\n    trans = _mixedToUnderRE.sub(mixedToUnderSub, s)\n    if trans.startswith('_'):\n        trans = trans[1:]\n    return trans"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef underToMixed(name):\n    if name.endswith('_id'):\n        return underToMixed(name[:-3] + \"ID\")\n    return _underToMixedRE.sub(lambda m: m.group(0)[1].upper(),\n                               name)", "response": "Convert a string to a mixed string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_crud(app):\n    '''\n    Import crud module and register all model cruds which it contains\n    '''\n\n    try:\n        app_path = import_module(app).__path__\n    except (AttributeError, ImportError):\n        return None\n\n    try:\n        imp.find_module('crud', app_path)\n    except ImportError:\n        return None\n\n    module = import_module(\"%s.crud\" % app)\n\n    return module", "response": "Imports crud module and register all model cruds which it contains\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_verbose_field_name(instance, field_name):\n    fields = [field.name for field in instance._meta.fields]\n    if field_name in fields:\n        return instance._meta.get_field(field_name).verbose_name\n    else:\n        return field_name", "response": "Returns verbose_name for a field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating modelform from Django modelform_factory", "response": "def generate_modelform(self):\n        \"\"\"Generate modelform from Django modelform_factory\"\"\"\n\n        model_class = self.get_model_class\n        excludes = self.modelform_excludes if self.modelform_excludes else []\n        _ObjectForm = modelform_factory(model_class, exclude=excludes)\n        return _ObjectForm"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_template(self, tname):\n\n        if self.custom_templates and self.custom_templates.get(tname, None):\n            return self.custom_templates.get(tname)\n        elif self.inlineformset:\n            return 'crudbuilder/inline/{}.html'.format(tname)\n        else:\n            return 'crudbuilder/instance/{}.html'.format(tname)", "response": "Get custom template from CRUD class"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_list_view(self):\n\n        name = model_class_form(self.model + 'ListView')\n        list_args = dict(\n            model=self.get_model_class,\n            context_object_name=plural(self.model),\n            template_name=self.get_template('list'),\n            table_class=self.get_actual_table(),\n            context_table_name='table_objects',\n            crud=self.crud,\n            permissions=self.view_permission('list'),\n            permission_required=self.check_permission_required,\n            login_required=self.check_login_required,\n            table_pagination={'per_page': self.tables2_pagination or 10},\n            custom_queryset=self.custom_queryset,\n            custom_context=self.custom_context,\n            custom_postfix_url=self.custom_postfix_url\n        )\n\n        list_class = type(\n            name,\n            (BaseListViewMixin, SingleTableView),\n            list_args\n        )\n        self.classes[name] = list_class\n        return list_class", "response": "Generate class based view for ListView"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_create_view(self):\n\n        name = model_class_form(self.model + 'CreateView')\n        create_args = dict(\n            form_class=self.get_actual_form('create'),\n            model=self.get_model_class,\n            template_name=self.get_template('create'),\n            permissions=self.view_permission('create'),\n            permission_required=self.check_permission_required,\n            login_required=self.check_login_required,\n            inlineformset=self.inlineformset,\n            success_url=reverse_lazy('{}-{}-list'.format(self.app, self.custom_postfix_url)),\n            custom_form=self.createupdate_forms or self.custom_modelform,\n            custom_postfix_url=self.custom_postfix_url\n        )\n\n        parent_classes = [self.get_createupdate_mixin(), CreateView]\n        if self.custom_create_view_mixin:\n            parent_classes.insert(0, self.custom_create_view_mixin)\n\n        create_class = type(\n            name,\n            tuple(parent_classes),\n            create_args\n        )\n\n        self.classes[name] = create_class\n        return create_class", "response": "Generate class based view for CreateView"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_detail_view(self):\n\n        name = model_class_form(self.model + 'DetailView')\n        detail_args = dict(\n            detailview_excludes=self.detailview_excludes,\n            model=self.get_model_class,\n            template_name=self.get_template('detail'),\n            login_required=self.check_login_required,\n            permissions=self.view_permission('detail'),\n            inlineformset=self.inlineformset,\n            permission_required=self.check_permission_required,\n            custom_postfix_url=self.custom_postfix_url\n        )\n\n        detail_class = type(name, (BaseDetailViewMixin, DetailView), detail_args)\n        self.classes[name] = detail_class\n        return detail_class", "response": "Generate class based view for DetailView"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_update_view(self):\n\n        name = model_class_form(self.model + 'UpdateView')\n        update_args = dict(\n            form_class=self.get_actual_form('update'),\n            model=self.get_model_class,\n            template_name=self.get_template('update'),\n            permissions=self.view_permission('update'),\n            permission_required=self.check_permission_required,\n            login_required=self.check_login_required,\n            inlineformset=self.inlineformset,\n            custom_form=self.createupdate_forms or self.custom_modelform,\n            success_url=reverse_lazy('{}-{}-list'.format(self.app, self.custom_postfix_url)),\n            custom_postfix_url=self.custom_postfix_url\n        )\n\n        parent_classes = [self.get_createupdate_mixin(), UpdateView]\n        if self.custom_update_view_mixin:\n            parent_classes.insert(0, self.custom_update_view_mixin)\n\n        update_class = type(\n            name,\n            tuple(parent_classes),\n            update_args\n        )\n        self.classes[name] = update_class\n        return update_class", "response": "Generate class based view for UpdateView"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_delete_view(self):\n\n        name = model_class_form(self.model + 'DeleteView')\n        delete_args = dict(\n            model=self.get_model_class,\n            template_name=self.get_template('delete'),\n            permissions=self.view_permission('delete'),\n            permission_required=self.check_permission_required,\n            login_required=self.check_login_required,\n            success_url=reverse_lazy('{}-{}-list'.format(self.app, self.custom_postfix_url)),\n            custom_postfix_url=self.custom_postfix_url\n        )\n\n        delete_class = type(name, (CrudBuilderMixin, DeleteView), delete_args)\n        self.classes[name] = delete_class\n        return delete_class", "response": "Generate class based view for DeleteView"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef incoming_references(self, client=None, query={}):\n\n        if client is None:\n            return False\n\n        query.update({'links_to_entry': self.id})\n        return client.entries(query)", "response": "Fetches all entries referencing the entry\n\n        API Reference"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build(self):\n\n        if self.json['sys']['type'] == 'Array':\n            if any(k in self.json for k in ['nextSyncUrl', 'nextPageUrl']):\n                return SyncPage(\n                    self.json,\n                    default_locale=self.default_locale,\n                    localized=True\n                )\n            return self._build_array()\n        return self._build_single()", "response": "Creates the objects from the JSON response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(cls, content_type_id):\n\n        for content_type in cls.__CACHE__:\n            if content_type.sys.get('id') == content_type_id:\n                return content_type\n        return None", "response": "Fetches a Content Type from the Cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget Error by HTTP Status Code", "response": "def get_error(response):\n    \"\"\"Gets Error by HTTP Status Code\"\"\"\n\n    errors = {\n        400: BadRequestError,\n        401: UnauthorizedError,\n        403: AccessDeniedError,\n        404: NotFoundError,\n        429: RateLimitExceededError,\n        500: ServerError,\n        502: BadGatewayError,\n        503: ServiceUnavailableError\n    }\n\n    error_class = HTTPError\n    if response.status_code in errors:\n        error_class = errors[response.status_code]\n\n    return error_class(response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef field_for(self, field_id):\n\n        for field in self.fields:\n            if field.id == field_id:\n                return field\n        return None", "response": "Fetches the contentful. ContentTypeField object for the given Field ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coerce(self, value, **kwargs):\n\n        Location = namedtuple('Location', ['lat', 'lon'])\n        return Location(float(value.get('lat')), float(value.get('lon')))", "response": "Coerce value to Location object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef coerce(self, value, **kwargs):\n\n        result = []\n        for v in value:\n            result.append(self._coercion.coerce(v, **kwargs))\n        return result", "response": "Coerces array items with proper coercion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncoercing Rich Text properly.", "response": "def coerce(self, value, includes=None, errors=None, resources=None, default_locale='en-US', locale=None):\n        \"\"\"Coerces Rich Text properly.\"\"\"\n\n        if includes is None:\n            includes = []\n        if errors is None:\n            errors = []\n\n        return self._coerce_block(\n            value,\n            includes=includes,\n            errors=errors,\n            resources=resources,\n            default_locale=default_locale,\n            locale=locale\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef coerce(self, value, **kwargs):\n\n        if value is None:\n            return None\n        return self._coercion.coerce(value, **kwargs)", "response": "Coerces the value to the proper type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching a Content Type by ID.", "response": "def content_type(self, content_type_id, query=None):\n        \"\"\"Fetches a Content Type by ID.\n\n        API Reference: https://www.contentful.com/developers/docs/references/content-delivery-api/#/reference/content-types/content-type/get-a-single-content-type\n\n        :param content_type_id: The ID of the target Content Type.\n        :param query: (optional) Dict with API options.\n        :return: :class:`ContentType <contentful.content_type.ContentType>` object.\n        :rtype: contentful.content_type.ContentType\n\n        Usage:\n            >>> cat_content_type = client.content_type('cat')\n            <ContentType[Cat] id='cat'>\n        \"\"\"\n\n        return self._get(\n            self.environment_url(\n                '/content_types/{0}'.format(content_type_id)\n            ),\n            query\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching an Entry by ID.", "response": "def entry(self, entry_id, query=None):\n        \"\"\"Fetches an Entry by ID.\n\n        API Reference: https://www.contentful.com/developers/docs/references/content-delivery-api/#/reference/entries/entry/get-a-single-entry\n\n        :param entry_id: The ID of the target Entry.\n        :param query: (optional) Dict with API options.\n        :return: :class:`Entry <contentful.entry.Entry>` object.\n        :rtype: contentful.entry.Entry\n\n        Usage:\n            >>> nyancat_entry = client.entry('nyancat')\n            <Entry[cat] id='nyancat'>\n        \"\"\"\n\n        if query is None:\n            query = {}\n        self._normalize_select(query)\n\n        try:\n            query.update({'sys.id': entry_id})\n            return self._get(\n                self.environment_url('/entries'),\n                query\n            )[0]\n        except IndexError:\n            raise EntryNotFoundError(\n                \"Entry not found for ID: '{0}'\".format(entry_id)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch all Entries from the Space.", "response": "def entries(self, query=None):\n        \"\"\"Fetches all Entries from the Space (up to the set limit, can be modified in `query`).\n\n        API Reference: https://www.contentful.com/developers/docs/references/content-delivery-api/#/reference/entries/entries-collection/get-all-entries-of-a-space\n\n        :param query: (optional) Dict with API options.\n        :return: List of :class:`Entry <contentful.entry.Entry>` objects.\n        :rtype: List of contentful.entry.Entry\n\n        Usage:\n            >>> entries = client.entries()\n            [<Entry[cat] id='happycat'>,\n             <Entry[1t9IbcfdCk6m04uISSsaIK] id='5ETMRzkl9KM4omyMwKAOki'>,\n             <Entry[dog] id='6KntaYXaHSyIw8M6eo26OK'>,\n             <Entry[1t9IbcfdCk6m04uISSsaIK] id='7qVBlCjpWE86Oseo40gAEY'>,\n             <Entry[cat] id='garfield'>,\n             <Entry[1t9IbcfdCk6m04uISSsaIK] id='4MU1s3potiUEM2G4okYOqw'>,\n             <Entry[cat] id='nyancat'>,\n             <Entry[1t9IbcfdCk6m04uISSsaIK] id='ge1xHyH3QOWucKWCCAgIG'>,\n             <Entry[human] id='finn'>,\n             <Entry[dog] id='jake'>]\n        \"\"\"\n\n        if query is None:\n            query = {}\n        self._normalize_select(query)\n\n        return self._get(\n            self.environment_url('/entries'),\n            query\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asset(self, asset_id, query=None):\n\n        return self._get(\n            self.environment_url(\n                '/assets/{0}'.format(asset_id)\n            ),\n            query\n        )", "response": "Fetches an Asset by ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch all Assets from the Space.", "response": "def assets(self, query=None):\n        \"\"\"Fetches all Assets from the Space (up to the set limit, can be modified in `query`).\n\n        API Reference: https://www.contentful.com/developers/docs/references/content-delivery-api/#/reference/assets/assets-collection/get-all-assets-of-a-space\n\n        :param query: (optional) Dict with API options.\n        :return: List of :class:`Asset <contentful.asset.Asset>` objects.\n        :rtype: List of contentful.asset.Asset\n\n        Usage:\n            >>> assets = client.assets()\n            [<Asset id='1x0xpXu4pSGS4OukSyWGUK' url='//images.content...'>,\n             <Asset id='happycat' url='//images.contentful.com/cfexam...'>,\n             <Asset id='nyancat' url='//images.contentful.com/cfexamp...'>,\n             <Asset id='jake' url='//images.contentful.com/cfexamplea...'>]\n        \"\"\"\n\n        if query is None:\n            query = {}\n        self._normalize_select(query)\n\n        return self._get(\n            self.environment_url('/assets'),\n            query\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef locales(self, query=None):\n\n        if query is None:\n            query = {}\n\n        return self._get(\n            self.environment_url('/locales'),\n            query\n        )", "response": "Fetches all Locales from the Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches content from the Sync API.", "response": "def sync(self, query=None):\n        \"\"\"Fetches content from the Sync API.\n\n        API Reference: https://www.contentful.com/developers/docs/references/content-delivery-api/#/reference/synchronization/initial-synchronization/query-entries\n\n        :param query: (optional) Dict with API options.\n        :return: :class:`SyncPage <contentful.sync_page.SyncPage>` object.\n        :rtype: contentful.sync_page.SyncPage\n\n        Usage:\n            >>> sync_page = client.sync({'initial': True})\n            <SyncPage next_sync_token='w5ZGw6JFwqZmVcKsE8Kow4grw45QdybC...'>\n        \"\"\"\n\n        if query is None:\n            query = {}\n        self._normalize_sync(query)\n\n        return self._get(\n            self.environment_url('/sync'),\n            query\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes the select operator in the query.", "response": "def _normalize_select(self, query):\n        \"\"\"\n        If the query contains the :select operator, we enforce :sys properties.\n        The SDK requires sys.type to function properly, but as other of our\n        SDKs require more parts of the :sys properties, we decided that every\n        SDK should include the complete :sys block to provide consistency\n        accross our SDKs.\n        \"\"\"\n\n        if 'select' not in query:\n            return\n\n        if isinstance(\n                query['select'],\n                string_class()):\n            query['select'] = [s.strip() for s in query['select'].split(',')]\n\n        query['select'] = [s for s\n                           in query['select']\n                           if not s.startswith('sys.')]\n\n        if 'sys' not in query['select']:\n            query['select'].append('sys')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _request_headers(self):\n\n        headers = {\n            'X-Contentful-User-Agent': self._contentful_user_agent(),\n            'Content-Type': 'application/vnd.contentful.delivery.v{0}+json'.format(  # noqa: E501\n                self.api_version\n            )\n        }\n\n        if self.authorization_as_header:\n            headers['Authorization'] = 'Bearer {0}'.format(self.access_token)\n\n        headers['Accept-Encoding'] = 'gzip' if self.gzip_encoded else 'identity'\n\n        return headers", "response": "Sets the default request headers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the Request URL.", "response": "def _url(self, url):\n        \"\"\"\n        Creates the Request URL.\n        \"\"\"\n\n        protocol = 'https' if self.https else 'http'\n        return '{0}://{1}/spaces/{2}{3}'.format(\n            protocol,\n            self.api_url,\n            self.space_id,\n            url\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting Arrays in the query to comma separated lists for proper API handling.", "response": "def _normalize_query(self, query):\n        \"\"\"\n        Converts Arrays in the query to comma\n        separaters lists for proper API handling.\n        \"\"\"\n\n        for k, v in query.items():\n            if isinstance(v, list):\n                query[k] = ','.join([str(e) for e in v])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _http_get(self, url, query):\n\n        if not self.authorization_as_header:\n            query.update({'access_token': self.access_token})\n\n        response = None\n\n        self._normalize_query(query)\n\n        kwargs = {\n            'params': query,\n            'headers': self._request_headers()\n        }\n\n        if self._has_proxy():\n            kwargs['proxies'] = self._proxy_parameters()\n\n        response = requests.get(\n            self._url(url),\n            **kwargs\n        )\n\n        if response.status_code == 429:\n            raise RateLimitExceededError(response)\n\n        return response", "response": "Performs the HTTP GET Request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping for the HTTP GET method", "response": "def _get(self, url, query=None):\n        \"\"\"\n        Wrapper for the HTTP Request,\n        Rate Limit Backoff is handled here,\n        Responses are Processed with ResourceBuilder.\n        \"\"\"\n\n        if query is None:\n            query = {}\n\n        response = retry_request(self)(self._http_get)(url, query=query)\n\n        if self.raw_mode:\n            return response\n\n        if response.status_code != 200:\n            error = get_error(response)\n            if self.raise_errors:\n                raise error\n            return error\n\n        localized = query.get('locale', '') == '*'\n        return ResourceBuilder(\n            self.default_locale,\n            localized,\n            response.json(),\n            max_depth=self.max_include_resolution_depth,\n            reuse_entries=self.reuse_entries\n        ).build()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _proxy_parameters(self):\n\n        proxy_protocol = ''\n        if self.proxy_host.startswith('https'):\n            proxy_protocol = 'https'\n        else:\n            proxy_protocol = 'http'\n\n        proxy = '{0}://'.format(proxy_protocol)\n        if self.proxy_username and self.proxy_password:\n            proxy += '{0}:{1}@'.format(self.proxy_username, self.proxy_password)\n\n        proxy += sub(r'https?(://)?', '', self.proxy_host)\n\n        if self.proxy_port:\n            proxy += ':{0}'.format(self.proxy_port)\n\n        return {\n            'http': proxy,\n            'https': proxy\n        }", "response": "Builds Proxy parameters Dict from client options."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a formatted URL for the Asset s File with serialized parameters.", "response": "def url(self, **kwargs):\n        \"\"\"Returns a formatted URL for the Asset's File\n        with serialized parameters.\n\n        Usage:\n            >>> my_asset.url()\n            \"//images.contentful.com/spaces/foobar/...\"\n            >>> my_asset.url(w=120, h=160)\n            \"//images.contentful.com/spaces/foobar/...?w=120&h=160\"\n        \"\"\"\n\n        url = self.file['url']\n        args = ['{0}={1}'.format(k, v) for k, v in kwargs.items()]\n\n        if args:\n            url += '?{0}'.format('&'.join(args))\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fields(self, locale=None):\n\n        if locale is None:\n            locale = self._locale()\n        return self._fields.get(locale, {})", "response": "Get the fields for a specific locale"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves Link to a specific Resource", "response": "def resolve(self, client):\n        \"\"\"Resolves Link to a specific Resource\"\"\"\n\n        resolve_method = getattr(client, snake_case(self.link_type))\n        if self.link_type == 'Space':\n            return resolve_method()\n        else:\n            return resolve_method(self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a snake cased version of a string.", "response": "def snake_case(a_string):\n    \"\"\"Returns a snake cased version of a string.\n\n    :param a_string: any :class:`str` object.\n\n    Usage:\n        >>> snake_case('FooBar')\n        \"foo_bar\"\n    \"\"\"\n\n    partial = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', a_string)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', partial).lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if value is an array of links.", "response": "def is_link_array(value):\n    \"\"\"Checks if value is an array of links.\n\n    :param value: any object.\n    :return: Boolean\n    :rtype: bool\n\n    Usage:\n        >>> is_link_array('foo')\n        False\n        >>> is_link_array([1, 2, 3])\n        False\n        >>> is_link([{'sys': {'type': 'Link', 'id': 'foobar'}}])\n        True\n    \"\"\"\n\n    if isinstance(value, list) and len(value) > 0:\n        return is_link(value[0])\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_for_link(link, includes, resources=None, locale=None):\n\n    if resources is not None:\n        cache_key = \"{0}:{1}:{2}\".format(\n            link['sys']['linkType'],\n            link['sys']['id'],\n            locale\n        )\n        if cache_key in resources:\n            return resources[cache_key]\n\n    for i in includes:\n        if (i['sys']['id'] == link['sys']['id'] and\n                i['sys']['type'] == link['sys']['linkType']):\n            return i\n    return None", "response": "Returns the resource that matches the link"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_resource_urls(query):\n    ''' Get all the URLs for every resource '''\n    urls = []\n    next = True\n    while next:\n        response = requests.get(query)\n        json_data = json.loads(response.content)\n        for resource in json_data['results']:\n            urls.append(resource['url'])\n        if bool(json_data['next']):\n            query = json_data['next']\n        else:\n            next = False\n    return urls", "response": "Get all the URLs for every resource"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get(id, type):\n    ''' Return a single person '''\n    result = query(\"{0}/{1}/{2}/\".format(\n        settings.BASE_URL,\n        type,\n        str(id))\n    )\n    return result", "response": "Return a single person"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all of a single resource", "response": "def get_all(resource):\n    ''' Return all of a single resource '''\n    QUERYSETS = {\n        settings.PEOPLE: PeopleQuerySet,\n        settings.PLANETS: PlanetQuerySet,\n        settings.STARSHIPS: StarshipQuerySet,\n        settings.VEHICLES: VehicleQuerySet,\n        settings.SPECIES: SpeciesQuerySet,\n        settings.FILMS: FilmQuerySet\n    }\n\n    urls = all_resource_urls(\n        \"{0}/{1}/\".format(settings.BASE_URL, resource)\n    )\n\n    return QUERYSETS[resource](urls)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_planet(planet_id):\n    ''' Return a single planet '''\n    result = _get(planet_id, settings.PLANETS)\n    return Planet(result.content)", "response": "Return a single planet"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a single person", "response": "def get_person(people_id):\n    ''' Return a single person '''\n    result = _get(people_id, settings.PEOPLE)\n    return People(result.content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_starship(starship_id):\n    ''' Return a single starship '''\n    result = _get(starship_id, settings.STARSHIPS)\n    return Starship(result.content)", "response": "Return a single starship"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_vehicle(vehicle_id):\n    ''' Return a single vehicle '''\n    result = _get(vehicle_id, settings.VEHICLES)\n    return Vehicle(result.content)", "response": "Return a single vehicle"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a single species", "response": "def get_species(species_id):\n    ''' Return a single species '''\n    result = _get(species_id, settings.SPECIES)\n    return Species(result.content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a single film", "response": "def get_film(film_id):\n    ''' Return a single film '''\n    result = _get(film_id, settings.FILMS)\n    return Film(result.content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef order_by(self, order_attribute):\n        ''' Return the list of items in a certain order '''\n        to_return = []\n        for f in sorted(self.items, key=lambda i: getattr(i, order_attribute)):\n            to_return.append(f)\n        return to_return", "response": "Return the list of items in a certain order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_crawl(self):\n        ''' Print the opening crawl one line at a time '''\n        print(\"Star Wars\")\n        time.sleep(.5)\n        print(\"Episode {0}\".format(self.episode_id))\n        time.sleep(.5)\n        print(\"\")\n        time.sleep(.5)\n        print(\"{0}\".format(self.title))\n        for line in self.gen_opening_crawl():\n            time.sleep(.5)\n            print(line)", "response": "Print the opening crawl one line at a time"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_str(string):\n    if sys.version_info[:2] >= (3, 0):\n        return isinstance(string, str)\n\n    return isinstance(string, basestring)", "response": "Checks if a string is a valid unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to find a c ++ parser in the system.", "response": "def find_xml_generator(name=\"castxml\"):\n    \"\"\"\n    Try to find a c++ parser (xml generator)\n\n    Args:\n        name (str): name of the c++ parser (e.g. castxml)\n\n    Returns:\n        path (str), name (str): path to the xml generator and it's name\n\n\n    If no c++ parser is found the function raises an exception.\n    pygccxml does currently only support castxml as c++ parser.\n\n    \"\"\"\n\n    if sys.version_info[:2] >= (3, 3):\n        path = _find_xml_generator_for_python_greater_equals_33(name)\n    else:\n        path = _find_xml_generator_for_legacy_python(name)\n\n    if path == \"\" or path is None:\n        raise Exception(\"No c++ parser found. Please install castxml.\")\n    return path.rstrip(), name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_logger_(name):\n    logger = logging.getLogger(name)\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter('%(levelname)s %(message)s'))\n    logger.addHandler(handler)\n    logger.setLevel(logging.INFO)\n    return logger", "response": "Implementation detail creates a logger."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove file from disk if exception is raised.", "response": "def remove_file_no_raise(file_name, config):\n    \"\"\"Removes file from disk if exception is raised.\"\"\"\n    # The removal can be disabled by the config for debugging purposes.\n    if config.keep_xml:\n        return True\n\n    try:\n        if os.path.exists(file_name):\n            os.remove(file_name)\n    except IOError as error:\n        loggers.root.error(\n            \"Error occurred while removing temporary created file('%s'): %s\",\n            file_name, str(error))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a temporary file name.", "response": "def create_temp_file_name(suffix, prefix=None, dir=None, directory=None):\n    \"\"\"\n    Small convenience function that creates temporary files.\n\n    This function is a wrapper around the Python built-in\n    function tempfile.mkstemp.\n\n    \"\"\"\n    if dir is not None:\n        warnings.warn(\n            \"The dir argument is deprecated.\\n\" +\n            \"Please use the directory argument instead.\", DeprecationWarning)\n        # Deprecated since 1.9.0, will be removed in 2.0.0\n        directory = dir\n\n    if not prefix:\n        prefix = tempfile.gettempprefix()\n    fd, name = tempfile.mkstemp(suffix=suffix, prefix=prefix, dir=directory)\n    file_obj = os.fdopen(fd)\n    file_obj.close()\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contains_parent_dir(fpath, dirs):\n    # Note: this function is used nowhere in pygccxml but is used\n    # at least by pypluplus; so it should stay here.\n\n    return bool([x for x in dirs if _f(fpath, x)])", "response": "Returns True if paths in dirs start with fpath."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_decl_string(\n            return_type, arguments_types, with_defaults=True):\n        \"\"\"\n        Returns free function type\n\n        :param return_type: function return type\n        :type return_type: :class:`type_t`\n        :param arguments_types: list of argument :class:`type <type_t>`\n        :rtype: :class:`free_function_type_t`\n\n        \"\"\"\n\n        return free_function_type_t.NAME_TEMPLATE % {\n            'return_type': return_type.build_decl_string(with_defaults),\n            'arguments': ','.join(\n                [_f(x, with_defaults) for x in arguments_types])}", "response": "Creates a string that can be used to create free function decl"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_typedef(self, typedef_name, unused=None, with_defaults=True):\n\n        return free_function_type_t.TYPEDEF_NAME_TEMPLATE % {\n            'typedef_name': typedef_name,\n            'return_type': self.return_type.build_decl_string(with_defaults),\n            'arguments': ','.join(\n                [_f(x, with_defaults) for x in self.arguments_types])}", "response": "returns string that contains valid C ++ code that defines typedef\n        to function typedef\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate typedef to the function typedef_name", "response": "def create_typedef(\n            self,\n            typedef_name,\n            class_alias=None,\n            with_defaults=True):\n        \"\"\"creates typedef to the function type\n\n        :param typedef_name: desired type name\n        :rtype: string\n        \"\"\"\n        has_const_str = ''\n        if self.has_const:\n            has_const_str = 'const'\n        if None is class_alias:\n            if with_defaults:\n                class_alias = self.class_inst.decl_string\n            else:\n                class_alias = self.class_inst.partial_decl_string\n\n        return member_function_type_t.TYPEDEF_NAME_TEMPLATE % {\n            'typedef_name': typedef_name,\n            'return_type': self.return_type.build_decl_string(with_defaults),\n            'class': class_alias,\n            'arguments': ','.join(\n                [_f(x, with_defaults) for x in self.arguments_types]),\n            'has_const': has_const_str}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the header files and returns a list of declarations.", "response": "def parse(\n        files,\n        config=None,\n        compilation_mode=COMPILATION_MODE.FILE_BY_FILE,\n        cache=None):\n    \"\"\"\n    Parse header files.\n\n    :param files: The header files that should be parsed\n    :type files: list of str\n    :param config: Configuration object or None\n    :type config: :class:`parser.xml_generator_configuration_t`\n    :param compilation_mode: Determines whether the files are parsed\n                             individually or as one single chunk\n    :type compilation_mode: :class:`parser.COMPILATION_MODE`\n    :param cache: Declaration cache (None=no cache)\n    :type cache: :class:`parser.cache_base_t` or str\n    :rtype: list of :class:`declarations.declaration_t`\n    \"\"\"\n    if not config:\n        config = xml_generator_configuration_t()\n    parser = project_reader_t(config=config, cache=cache)\n    declarations = parser.read_files(files, compilation_mode)\n    config.xml_generator_from_xml_file = parser.xml_generator_from_xml_file\n    return declarations"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_alias(type_):\n    if isinstance(type_, cpptypes.type_t):\n        type_ref = type_\n    elif isinstance(type_, typedef.typedef_t):\n        type_ref = type_.decl_type\n    else:\n        # Not a valid input, just return it\n        return type_\n    if type_ref.cache.remove_alias:\n        return type_ref.cache.remove_alias\n    no_alias = __remove_alias(type_ref.clone())\n    type_ref.cache.remove_alias = no_alias\n    return no_alias", "response": "Returns type_t without typedef\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decompose_type(tp):\n    if isinstance(tp, cpptypes.compound_t):\n        return [tp] + decompose_type(tp.base)\n    elif isinstance(tp, typedef.typedef_t):\n        return decompose_type(tp.decl_type)\n    elif isinstance(tp, cpptypes.declarated_t) and \\\n            isinstance(tp.declaration, typedef.typedef_t):\n        return decompose_type(tp.declaration.decl_type)\n\n    return [tp]", "response": "Decomposes a type into a list of types."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_cv_types(base):\n    return (\n        [base,\n         cpptypes.const_t(base),\n         cpptypes.volatile_t(base),\n         cpptypes.volatile_t(cpptypes.const_t(base))]\n    )", "response": "Implementation detail.\n    Implementation detail.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef does_match_definition(given, main, secondary):\n    assert isinstance(secondary, tuple)\n    assert len(secondary) == 2  # general solution could be provided\n    types = decompose_type(given)\n\n    if isinstance(types[0], main):\n        return True\n\n    if len(types) >= 2:\n        cond1 = isinstance(types[0], main)\n        cond2 = isinstance(types[1], secondary)\n        cond3 = isinstance(types[1], main)\n        cond4 = isinstance(types[0], secondary)\n        if (cond1 and cond2) or (cond3 and cond4):\n            return True\n\n        if len(types) >= 3:\n            classes = set([tp.__class__ for tp in types[:3]])\n            desired = set([main] + list(secondary))\n            diff = classes.symmetric_difference(desired)\n            if not diff:\n                return True\n            if len(diff) == 2:\n                items = list(diff)\n                return (\n                    issubclass(\n                        items[0], items[1]) or issubclass(items[1], items[0]))\n            return False\n    else:\n        return False", "response": "returns True if the given main and secondary are the same as the given main and secondary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if type represents C ++ pointer type False otherwise", "response": "def is_pointer(type_):\n    \"\"\"returns True, if type represents C++ pointer type, False otherwise\"\"\"\n    return does_match_definition(type_,\n                                 cpptypes.pointer_t,\n                                 (cpptypes.const_t, cpptypes.volatile_t)) \\\n        or does_match_definition(type_,\n                                 cpptypes.pointer_t,\n                                 (cpptypes.volatile_t, cpptypes.const_t))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_calldef_pointer(type_):\n    if not is_pointer(type_):\n        return False\n    nake_type = remove_alias(type_)\n    nake_type = remove_cv(nake_type)\n    return isinstance(nake_type, cpptypes.compound_t) \\\n        and isinstance(nake_type.base, cpptypes.calldef_type_t)", "response": "returns True if type represents pointer to free member function False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove pointer from the type definition returns the type_nake_type.", "response": "def remove_pointer(type_):\n    \"\"\"removes pointer from the type definition\n\n    If type is not pointer type, it will be returned as is.\n    \"\"\"\n    nake_type = remove_alias(type_)\n    if not is_pointer(nake_type):\n        return type_\n    elif isinstance(nake_type, cpptypes.volatile_t) and \\\n            isinstance(nake_type.base, cpptypes.pointer_t):\n        return cpptypes.volatile_t(nake_type.base.base)\n    elif isinstance(nake_type, cpptypes.const_t) and \\\n            isinstance(nake_type.base, cpptypes.pointer_t):\n        return cpptypes.const_t(nake_type.base.base)\n    elif isinstance(nake_type, cpptypes.volatile_t) \\\n            and isinstance(nake_type.base, cpptypes.const_t) \\\n            and isinstance(nake_type.base.base, cpptypes.pointer_t):\n        return (\n            cpptypes.volatile_t(cpptypes.const_t(nake_type.base.base.base))\n        )\n\n    return nake_type.base"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_array(type_):\n    nake_type = remove_alias(type_)\n    nake_type = remove_reference(nake_type)\n    nake_type = remove_cv(nake_type)\n    return isinstance(nake_type, cpptypes.array_t)", "response": "returns True if type represents C ++ array type False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef array_item_type(type_):\n    if is_array(type_):\n        type_ = remove_alias(type_)\n        type_ = remove_cv(type_)\n        return type_.base\n    elif is_pointer(type_):\n        return remove_pointer(type_)\n    else:\n        raise RuntimeError(\n            \"array_item_type functions takes as argument array or pointer \" +\n            \"types\")", "response": "returns array item type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_reference(type_):\n    nake_type = remove_alias(type_)\n    if not is_reference(nake_type):\n        return type_\n\n    return nake_type.base", "response": "removes reference from the type definition\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_const(type_):\n\n    nake_type = remove_alias(type_)\n    if not is_const(nake_type):\n        return type_\n    else:\n        # Handling for const and volatile qualified types. There is a\n        # difference in behavior between GCCXML and CastXML for cv-qual arrays.\n        # GCCXML produces the following nesting of types:\n        #       ->  volatile_t(const_t(array_t))\n        # while CastXML produces the following nesting:\n        #       ->  array_t(volatile_t(const_t))\n        # For both cases, we must unwrap the types, remove const_t, and add\n        # back the outer layers\n        if isinstance(nake_type, cpptypes.array_t):\n            is_v = is_volatile(nake_type)\n            if is_v:\n                result_type = nake_type.base.base.base\n            else:\n                result_type = nake_type.base.base\n            if is_v:\n                result_type = cpptypes.volatile_t(result_type)\n            return cpptypes.array_t(result_type, nake_type.size)\n\n        elif isinstance(nake_type, cpptypes.volatile_t):\n            return cpptypes.volatile_t(nake_type.base.base)\n\n        return nake_type.base", "response": "removes const from the type definition\n    returns type_ if type is not const"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_same(type1, type2):\n    nake_type1 = remove_declarated(type1)\n    nake_type2 = remove_declarated(type2)\n    return nake_type1 == nake_type2", "response": "returns True if type1 and type2 are same types"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if type represents C ++ elaborated type False otherwise", "response": "def is_elaborated(type_):\n    \"\"\"returns True, if type represents C++ elaborated type, False otherwise\"\"\"\n    nake_type = remove_alias(type_)\n    if isinstance(nake_type, cpptypes.elaborated_t):\n        return True\n    elif isinstance(nake_type, cpptypes.reference_t):\n        return is_elaborated(nake_type.base)\n    elif isinstance(nake_type, cpptypes.pointer_t):\n        return is_elaborated(nake_type.base)\n    elif isinstance(nake_type, cpptypes.volatile_t):\n        return is_elaborated(nake_type.base)\n    elif isinstance(nake_type, cpptypes.const_t):\n        return is_elaborated(nake_type.base)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves type - declaration class - binder class - binderer : class : elaborated_t from the type_", "response": "def remove_elaborated(type_):\n    \"\"\"removes type-declaration class-binder :class:`elaborated_t` from\n    the `type_`\n\n    If `type_` is not :class:`elaborated_t`, it will be returned as is\n    \"\"\"\n    nake_type = remove_alias(type_)\n    if not is_elaborated(nake_type):\n        return type_\n    else:\n        if isinstance(type_, cpptypes.elaborated_t):\n            type_ = type_.base\n    return type_"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_volatile(type_):\n    nake_type = remove_alias(type_)\n    if isinstance(nake_type, cpptypes.volatile_t):\n        return True\n    elif isinstance(nake_type, cpptypes.const_t):\n        return is_volatile(nake_type.base)\n    elif isinstance(nake_type, cpptypes.array_t):\n        return is_volatile(nake_type.base)\n    return False", "response": "returns True if type represents C ++ volatile type False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving volatile from the type definition returns type_ as is", "response": "def remove_volatile(type_):\n    \"\"\"removes volatile from the type definition\n\n    If type is not volatile type, it will be returned as is\n    \"\"\"\n    nake_type = remove_alias(type_)\n    if not is_volatile(nake_type):\n        return type_\n    else:\n        if isinstance(nake_type, cpptypes.array_t):\n            is_c = is_const(nake_type)\n            if is_c:\n                base_type_ = nake_type.base.base.base\n            else:\n                base_type_ = nake_type.base.base\n            result_type = base_type_\n            if is_c:\n                result_type = cpptypes.const_t(result_type)\n            return cpptypes.array_t(result_type, nake_type.size)\n        return nake_type.base"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove const and volatile from the type definition", "response": "def remove_cv(type_):\n    \"\"\"removes const and volatile from the type definition\"\"\"\n\n    nake_type = remove_alias(type_)\n    if not is_const(nake_type) and not is_volatile(nake_type):\n        return type_\n    result = nake_type\n    if is_const(result):\n        result = remove_const(result)\n    if is_volatile(result):\n        result = remove_volatile(result)\n    if is_const(result):\n        result = remove_const(result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if type represents C ++ fundamental type", "response": "def is_fundamental(type_):\n    \"\"\"returns True, if type represents C++ fundamental type\"\"\"\n    return does_match_definition(\n        type_,\n        cpptypes.fundamental_t,\n        (cpptypes.const_t, cpptypes.volatile_t)) \\\n        or does_match_definition(\n            type_,\n            cpptypes.fundamental_t,\n            (cpptypes.volatile_t, cpptypes.const_t))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_std_string(type_):\n\n    if utils.is_str(type_):\n        return type_ in string_equivalences\n\n    type_ = remove_alias(type_)\n    type_ = remove_reference(type_)\n    type_ = remove_cv(type_)\n    return type_.decl_string in string_equivalences", "response": "Returns True if type represents C ++ std string False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if type represents C ++ std :: wstring False otherwise.", "response": "def is_std_wstring(type_):\n    \"\"\"\n    Returns True, if type represents C++ `std::wstring`, False otherwise.\n\n    \"\"\"\n\n    if utils.is_str(type_):\n        return type_ in wstring_equivalences\n\n    type_ = remove_alias(type_)\n    type_ = remove_reference(type_)\n    type_ = remove_cv(type_)\n    return type_.decl_string in wstring_equivalences"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_std_ostream(type_):\n\n    if utils.is_str(type_):\n        return type_ in ostream_equivalences\n\n    type_ = remove_alias(type_)\n    type_ = remove_reference(type_)\n    type_ = remove_cv(type_)\n    return type_.decl_string in ostream_equivalences", "response": "Returns True if type represents C ++ std :: ostream False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_std_wostream(type_):\n\n    if utils.is_str(type_):\n        return type_ in wostream_equivalences\n\n    type_ = remove_alias(type_)\n    type_ = remove_reference(type_)\n    type_ = remove_cv(type_)\n    return type_.decl_string in wostream_equivalences", "response": "Returns True if type represents C ++ std :: wostream False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_pattern(self, decl_string):\n        if self.__begin == \"<\":\n            # Cleanup parentheses blocks before checking for the pattern\n            # See also the args() method (in this file) for more explanations.\n            decl_string = re.sub(\"\\\\s\\\\(.*?\\\\)\", \"\", decl_string).strip()\n\n        last_part = decl_string.split('::')[-1]\n        return (\n            decl_string.find(self.__begin) != -1 and\n            last_part.find(self.__end) != -1\n        )", "response": "Check if the given string contains a valid pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the separator of the arguments", "response": "def __find_args_separator(self, decl_string, start_pos):\n        \"\"\"implementation details\"\"\"\n        bracket_depth = 0\n        for index, ch in enumerate(decl_string[start_pos:]):\n            if ch not in (self.__begin, self.__end, self.__separator):\n                continue  # I am interested only in < and >\n            elif self.__separator == ch:\n                if not bracket_depth:\n                    return index + start_pos\n            elif self.__begin == ch:\n                bracket_depth += 1\n            elif not bracket_depth:\n                return index + start_pos\n            else:\n                bracket_depth -= 1\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract a list of arguments from the provided declaration string.", "response": "def args(self, decl_string):\n        \"\"\"\n        Extracts a list of arguments from the provided declaration string.\n\n        Implementation detail. Example usages:\n        Input: myClass<std::vector<int>, std::vector<double>>\n        Output: [std::vector<int>, std::vector<double>]\n\n        Args:\n           decl_string (str): the full declaration string\n\n        Returns:\n            list: list of arguments as strings\n\n        \"\"\"\n        args_begin = decl_string.find(self.__begin)\n        args_end = decl_string.rfind(self.__end)\n        if -1 in (args_begin, args_end) or args_begin == args_end:\n            raise RuntimeError(\n                \"%s doesn't validate template instantiation string\" %\n                decl_string)\n\n        args_only = decl_string[args_begin + 1: args_end].strip()\n\n        # The list of arguments to be returned\n        args = []\n\n        parentheses_blocks = []\n        prev_span = 0\n        if self.__begin == \"<\":\n            # In case where we are splitting template names, there\n            # can be parentheses blocks (for arguments) that need to be taken\n            # care of.\n\n            # Build a regex matching a space (\\s)\n            # + something inside parentheses\n            regex = re.compile(\"\\\\s\\\\(.*?\\\\)\")\n            for m in regex.finditer(args_only):\n                # Store the position and the content\n                parentheses_blocks.append([m.start() - prev_span, m.group()])\n                prev_span = m.end() - m.start()\n                # Cleanup the args_only string by removing the parentheses and\n                # their content.\n                args_only = args_only.replace(m.group(), \"\")\n\n        # Now we are trying to split the args_only string in multiple arguments\n        previous_found, found = 0, 0\n        while True:\n            found = self.__find_args_separator(args_only, previous_found)\n            if found == -1:\n                args.append(args_only[previous_found:].strip())\n                # This is the last argument. Break out of the loop.\n                break\n            else:\n                args.append(args_only[previous_found: found].strip())\n            previous_found = found + 1  # skip found separator\n\n        # Get the size and position for each argument\n        absolute_pos_list = []\n        absolute_pos = 0\n        for arg in args:\n            absolute_pos += len(arg)\n            absolute_pos_list.append(absolute_pos)\n\n        for item in parentheses_blocks:\n            # In case where there are parentheses blocks we add them back\n            # to the right argument\n            parentheses_block_absolute_pos = item[0]\n            parentheses_block_string = item[1]\n\n            current_arg_absolute_pos = 0\n            for arg_index, arg_absolute_pos in enumerate(absolute_pos_list):\n                current_arg_absolute_pos += arg_absolute_pos\n                if current_arg_absolute_pos >= parentheses_block_absolute_pos:\n                    # Add the parentheses block back and break out of the loop.\n                    args[arg_index] += parentheses_block_string\n                    break\n\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes a string to be used in the log file", "response": "def normalize(self, decl_string, arg_separator=None):\n        \"\"\"implementation details\"\"\"\n        if not self.has_pattern(decl_string):\n            return decl_string\n        name, args = self.split(decl_string)\n        for i, arg in enumerate(args):\n            args[i] = self.normalize(arg)\n        return self.join(name, args, arg_separator)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_public_binary_operator(type_, operator_symbol):\n    type_ = type_traits.remove_alias(type_)\n    type_ = type_traits.remove_cv(type_)\n    type_ = type_traits.remove_declarated(type_)\n    assert isinstance(type_, class_declaration.class_t)\n\n    if type_traits.is_std_string(type_) or type_traits.is_std_wstring(type_):\n        # In some case compare operators of std::basic_string are not\n        # instantiated\n        return True\n\n    operators = type_.member_operators(\n        function=matchers.custom_matcher_t(\n            lambda decl: not decl.is_artificial) &\n        matchers.access_type_matcher_t('public'),\n        symbol=operator_symbol, allow_empty=True, recursive=False)\n    if operators:\n        return True\n\n    declarated = cpptypes.declarated_t(type_)\n    const = cpptypes.const_t(declarated)\n    reference = cpptypes.reference_t(const)\n    operators = type_.top_parent.operators(\n        function=lambda decl: not decl.is_artificial,\n        arg_types=[reference, None],\n        symbol=operator_symbol,\n        allow_empty=True,\n        recursive=True)\n    if operators:\n        return True\n    for bi in type_.recursive_bases:\n        assert isinstance(bi, class_declaration.hierarchy_info_t)\n        if bi.access_type != class_declaration.ACCESS_TYPES.PUBLIC:\n            continue\n        operators = bi.related_class.member_operators(\n            function=matchers.custom_matcher_t(\n                lambda decl: not decl.is_artificial) &\n            matchers.access_type_matcher_t('public'),\n            symbol=operator_symbol, allow_empty=True, recursive=False)\n        if operators:\n            return True\n    return False", "response": "returns True if type_ has public binary operator otherwise False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_smart_pointer(type_):\n        type_ = type_traits.remove_alias(type_)\n        type_ = type_traits.remove_cv(type_)\n        type_ = type_traits.remove_declarated(type_)\n        if not isinstance(type_,\n                          (class_declaration.class_declaration_t,\n                           class_declaration.class_t)):\n            return False\n        if not (\n                traits_impl_details.impl_details.is_defined_in_xxx(\n                    'boost', type_) or\n                traits_impl_details.impl_details.is_defined_in_xxx(\n                    'std', type_)):\n            return False\n        return type_.decl_string.startswith('::boost::shared_ptr<') or \\\n            type_.decl_string.startswith('::std::shared_ptr<')", "response": "returns True if type represents instantiation of\n        boost :: shared_ptr or std :: shared_ptr False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns reference to boost :: shared_ptr \\ n or std :: shared_ptr \\ n", "response": "def value_type(type_):\n        \"\"\"returns reference to `boost::shared_ptr` \\\n        or `std::shared_ptr` value type\"\"\"\n        if not smart_pointer_traits.is_smart_pointer(type_):\n            raise TypeError(\n                'Type \"%s\" is not an instantiation of \\\n                boost::shared_ptr or std::shared_ptr' %\n                type_.decl_string)\n        try:\n            return internal_type_traits.get_by_name(type_, \"element_type\")\n        except runtime_errors.declaration_not_found_t:\n            return _search_in_bases(type_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, source_file, configuration, declarations, included_files):\n\n        # Normlize all paths...\n        source_file = os.path.normpath(source_file)\n        included_files = [os.path.normpath(p) for p in included_files]\n\n        # Create the list of dependent files. This is the included_files list\n        # + the source file. Duplicate names are removed.\n        dependent_files = {}\n        for name in [source_file] + included_files:\n            dependent_files[name] = 1\n\n        key = self._create_cache_key(source_file)\n        # Remove an existing entry (if there is one)\n        # After calling this method, it is guaranteed that __index[key]\n        # does not exist anymore.\n        self._remove_entry(source_file, key)\n\n        # Create a new entry...\n\n        # Create the sigs of all dependent files...\n        filesigs = []\n        for filename in list(dependent_files.keys()):\n            id_, sig = self.__filename_rep.acquire_filename(filename)\n            filesigs.append((id_, sig))\n\n        configsig = self._create_config_signature(configuration)\n        entry = index_entry_t(filesigs, configsig)\n        self.__index[key] = entry\n        self.__modified_flag = True\n\n        # Write the declarations into the cache file...\n        cachefilename = self._create_cache_filename(source_file)\n        self._write_file(cachefilename, declarations)", "response": "Update the cache entry with the new values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cached_value(self, source_file, configuration):\n\n        # Check if the cache contains an entry for source_file\n        key = self._create_cache_key(source_file)\n        entry = self.__index.get(key)\n        if entry is None:\n            # print \"CACHE: %s: Not cached\"%source_file\n            return None\n\n        # Check if the entry is still valid. It is not valid if:\n        #  - the source_file has been updated\n        #  - the configuration object has changed (i.e. the header is parsed\n        #    by gccxml with different settings which may influence the\n        #    declarations)\n        #  - the included files have been updated\n        #    (this list is part of the cache entry as it cannot be known\n        #    by the caller when cached_value() is called. It was instead\n        #    passed to update())\n\n        # Check if the config is different...\n        configsig = self._create_config_signature(configuration)\n        if configsig != entry.configsig:\n            # print \"CACHE: %s: Config mismatch\"%source_file\n            return None\n\n        # Check if any of the dependent files has been modified...\n        for id_, sig in entry.filesigs:\n            if self.__filename_rep.is_file_modified(id_, sig):\n                # print \"CACHE: %s: Entry not up to date\"%source_file\n                return None\n\n        # Load and return the cached declarations\n        cachefilename = self._create_cache_filename(source_file)\n        decls = self._read_file(cachefilename)\n\n        # print \"CACHE: Using cached decls for\",source_file\n        return decls", "response": "Return the cached declarations or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the cache. Loads the `index.dat` file, which contains the index table and the file name repository. This method is called by the :meth:`__init__`", "response": "def _load(self):\n        \"\"\"Load the cache.\n\n        Loads the `index.dat` file, which contains the index table and the\n        file name repository.\n\n        This method is called by the :meth:`__init__`\n        \"\"\"\n\n        indexfilename = os.path.join(self.__dir, \"index.dat\")\n        if os.path.exists(indexfilename):\n            data = self._read_file(indexfilename)\n            self.__index = data[0]\n            self.__filename_rep = data[1]\n            if self.__filename_rep._sha1_sigs != self.__sha1_sigs:\n                print((\n                    \"CACHE: Warning: sha1_sigs stored in the cache is set \" +\n                    \"to %s.\") % self.__filename_rep._sha1_sigs)\n                print(\"Please remove the cache to change this setting.\")\n                self.__sha1_sigs = self.__filename_rep._sha1_sigs\n        else:\n            self.__index = {}\n            self.__filename_rep = filename_repository_t(self.__sha1_sigs)\n\n        self.__modified_flag = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _save(self):\n\n        if self.__modified_flag:\n            self.__filename_rep.update_id_counter()\n            indexfilename = os.path.join(self.__dir, \"index.dat\")\n            self._write_file(\n                indexfilename,\n                (self.__index,\n                 self.__filename_rep))\n\n            self.__modified_flag = False", "response": "Save the cache index and the file name repository in the index. dat file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a pickled object from disk and returns it.", "response": "def _read_file(self, filename):\n        \"\"\"\n        read a Python object from a cache file.\n\n        Reads a pickled object from disk and returns it.\n\n        :param filename: Name of the file that should be read.\n        :type filename: str\n        :rtype: object\n        \"\"\"\n\n        if self.__compression:\n            f = gzip.GzipFile(filename, \"rb\")\n        else:\n            f = open(filename, \"rb\")\n        res = pickle.load(f)\n        f.close()\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_file(self, filename, data):\n\n        if self.__compression:\n            f = gzip.GzipFile(filename, \"wb\")\n        else:\n            f = open(filename, \"wb\")\n        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n        f.close()", "response": "Write a data item into a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _remove_entry(self, source_file, key):\n\n        entry = self.__index.get(key)\n        if entry is None:\n            return\n\n        # Release the referenced files...\n        for id_, _ in entry.filesigs:\n            self.__filename_rep.release_filename(id_)\n\n        # Remove the cache entry...\n        del self.__index[key]\n        self.__modified_flag = True\n\n        # Delete the corresponding cache file...\n        cachefilename = self._create_cache_filename(source_file)\n        try:\n            os.remove(cachefilename)\n        except OSError as e:\n            print(\"Could not remove cache file (%s)\" % e)", "response": "Remove an entry from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a cache key for a header file.", "response": "def _create_cache_key(source_file):\n        \"\"\"\n        return the cache key for a header file.\n\n        :param source_file: Header file name\n        :type source_file: str\n        :rtype: str\n        \"\"\"\n        path, name = os.path.split(source_file)\n        return name + str(hash(path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_cache_filename(self, source_file):\n        res = self._create_cache_key(source_file) + \".cache\"\n        return os.path.join(self.__dir, res)", "response": "create the cache file name for a header file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_config_signature(config):\n        m = hashlib.sha1()\n        m.update(config.working_directory.encode(\"utf-8\"))\n        for p in config.include_paths:\n            m.update(p.encode(\"utf-8\"))\n        for p in config.define_symbols:\n            m.update(p.encode(\"utf-8\"))\n        for p in config.undefine_symbols:\n            m.update(p.encode(\"utf-8\"))\n        for p in config.cflags:\n            m.update(p.encode(\"utf-8\"))\n        return m.digest()", "response": "Create a signature for a config object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nacquires a file name and return its id and its signature.", "response": "def acquire_filename(self, name):\n        \"\"\"Acquire a file name and return its id and its signature.\n        \"\"\"\n\n        id_ = self.__id_lut.get(name)\n        # Is this a new entry?\n        if id_ is None:\n            # then create one...\n            id_ = self.__next_id\n            self.__next_id += 1\n            self.__id_lut[name] = id_\n            entry = filename_entry_t(name)\n            self.__entries[id_] = entry\n        else:\n            # otherwise obtain the entry...\n            entry = self.__entries[id_]\n\n        entry.inc_ref_count()\n        return id_, self._get_signature(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrelease a file name.", "response": "def release_filename(self, id_):\n        \"\"\"Release a file name.\n        \"\"\"\n\n        entry = self.__entries.get(id_)\n        if entry is None:\n            raise ValueError(\"Invalid filename id (%d)\" % id_)\n\n        # Decrease reference count and check if the entry has to be removed...\n        if entry.dec_ref_count() == 0:\n            del self.__entries[id_]\n            del self.__id_lut[entry.filename]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the file referred to by id_ has been modified.", "response": "def is_file_modified(self, id_, signature):\n        \"\"\"Check if the file referred to by `id_` has been modified.\n        \"\"\"\n\n        entry = self.__entries.get(id_)\n        if entry is None:\n            raise ValueError(\"Invalid filename id_ (%d)\" % id_)\n\n        # Is the signature already known?\n        if entry.sig_valid:\n            # use the cached signature\n            filesig = entry.signature\n        else:\n            # compute the signature and store it\n            filesig = self._get_signature(entry)\n            entry.signature = filesig\n            entry.sig_valid = True\n\n        return filesig != signature"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the id_ counter so that it doesn t grow forever.", "response": "def update_id_counter(self):\n        \"\"\"Update the `id_` counter so that it doesn't grow forever.\n        \"\"\"\n\n        if not self.__entries:\n            self.__next_id = 1\n        else:\n            self.__next_id = max(self.__entries.keys()) + 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the signature of the file stored in entry.", "response": "def _get_signature(self, entry):\n        \"\"\"Return the signature of the file stored in entry.\n        \"\"\"\n\n        if self._sha1_sigs:\n            # return sha1 digest of the file content...\n            if not os.path.exists(entry.filename):\n                return None\n            try:\n                with open(entry.filename, \"r\") as f:\n                    data = f.read()\n                    return hashlib.sha1(data.encode(\"utf-8\")).digest()\n            except IOError as e:\n                print(\"Cannot determine sha1 digest:\", e)\n                return None\n        else:\n            # return file modification date...\n            try:\n                return os.path.getmtime(entry.filename)\n            except OSError:\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dump(self):  # pragma: no cover\n\n        print(70 * \"-\")\n        print(\"ID lookup table:\")\n        for name in self.__id_lut:\n            id_ = self.__id_lut[name]\n            print(\"  %s -> %d\" % (name, id_))\n\n        print(70 * \"-\")\n        print(\"%-4s %-60s %s\" % (\"ID\", \"Filename\", \"Refcount\"))\n        print(70 * \"-\")\n        for id_ in self.__entries:\n            entry = self.__entries[id_]\n            print(\"%04d %-60s %d\" % (id_, entry.filename, entry.refcount))", "response": "Dump contents for debugging and testing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_union(declaration):\n    if not is_class(declaration):\n        return False\n    decl = class_traits.get_declaration(declaration)\n    return decl.class_type == class_declaration.CLASS_TYPES.UNION", "response": "Returns True if declaration represents a C ++ union."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if declaration represents a C ++ struct False otherwise.", "response": "def is_struct(declaration):\n    \"\"\"\n    Returns True if declaration represents a C++ struct\n\n    Args:\n        declaration (declaration_t): the declaration to be checked.\n\n    Returns:\n        bool: True if declaration represents a C++ struct\n    \"\"\"\n    if not is_class(declaration):\n        return False\n    decl = class_traits.get_declaration(declaration)\n    return decl.class_type == class_declaration.CLASS_TYPES.STRUCT"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_trivial_constructor(type_):\n    assert isinstance(type_, class_declaration.class_t)\n\n    trivial = type_.constructors(\n        lambda x: is_trivial_constructor(x),\n        recursive=False,\n        allow_empty=True)\n    if trivial:\n        return trivial[0]\n\n    return None", "response": "Returns reference to trivial constructor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_copy_constructor(type_):\n    copy_ = type_.constructors(\n        lambda x: is_copy_constructor(x),\n        recursive=False,\n        allow_empty=True)\n    if copy_:\n        return copy_[0]\n\n    return None", "response": "Returns reference to copy constructor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all noncopyable variables in the class tree.", "response": "def find_noncopyable_vars(class_type, already_visited_cls_vars=None):\n    \"\"\"\n    Returns list of all `noncopyable` variables.\n\n    If an already_visited_cls_vars list is provided as argument, the returned\n    list will not contain these variables. This list will be extended with\n    whatever variables pointing to classes have been found.\n\n    Args:\n        class_type (declarations.class_t): the class to be searched.\n        already_visited_cls_vars (list): optional list of vars that should not\n            be checked a second time, to prevent infinite recursions.\n\n    Returns:\n        list: list of all `noncopyable` variables.\n\n    \"\"\"\n\n    assert isinstance(class_type, class_declaration.class_t)\n\n    logger = utils.loggers.cxx_parser\n    mvars = class_type.variables(\n        lambda v: not v.type_qualifiers.has_static,\n        recursive=False,\n        allow_empty=True)\n    noncopyable_vars = []\n\n    if already_visited_cls_vars is None:\n        already_visited_cls_vars = []\n\n    message = (\n        \"__contains_noncopyable_mem_var - %s - TRUE - \" +\n        \"contains const member variable\")\n\n    for mvar in mvars:\n\n        var_type = type_traits.remove_reference(mvar.decl_type)\n\n        if type_traits.is_const(var_type):\n            no_const = type_traits.remove_const(var_type)\n            if type_traits.is_fundamental(no_const) or is_enum(no_const):\n                logger.debug(\n                    (message + \"- fundamental or enum\"),\n                    var_type.decl_string)\n                noncopyable_vars.append(mvar)\n            if is_class(no_const):\n                logger.debug((message + \" - class\"), var_type.decl_string)\n                noncopyable_vars.append(mvar)\n            if type_traits.is_array(no_const):\n                logger.debug((message + \" - array\"), var_type.decl_string)\n                noncopyable_vars.append(mvar)\n\n        if type_traits.is_pointer(var_type):\n            continue\n\n        if class_traits.is_my_case(var_type):\n            cls = class_traits.get_declaration(var_type)\n\n            # Exclude classes that have already been visited.\n            if cls in already_visited_cls_vars:\n                continue\n            already_visited_cls_vars.append(cls)\n\n            if is_noncopyable(cls, already_visited_cls_vars):\n                logger.debug(\n                    (message + \" - class that is not copyable\"),\n                    var_type.decl_string)\n                noncopyable_vars.append(mvar)\n\n    logger.debug((\n        \"__contains_noncopyable_mem_var - %s - FALSE - doesn't \" +\n        \"contain noncopyable members\"), class_type.decl_string)\n\n    return noncopyable_vars"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_trivial_constructor(class_):\n    class_ = class_traits.get_declaration(class_)\n    trivial = find_trivial_constructor(class_)\n    if trivial and trivial.access_type == 'public':\n        return trivial", "response": "Returns the trivial constructor of class_ if it exists otherwise None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_copy_constructor(class_):\n    class_ = class_traits.get_declaration(class_)\n    copy_constructor = find_copy_constructor(class_)\n    if copy_constructor and copy_constructor.access_type == 'public':\n        return copy_constructor", "response": "Returns the public copy constructor of the given class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_destructor(class_):\n    class_ = class_traits.get_declaration(class_)\n    destructor = class_.decls(\n        decl_type=calldef_members.destructor_t,\n        recursive=False,\n        allow_empty=True)\n    if destructor:\n        return destructor[0]", "response": "Returns reference to the class s destructor if it exists None otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_public_constructor(class_):\n    class_ = class_traits.get_declaration(class_)\n    decls = class_.constructors(\n        lambda c: not is_copy_constructor(c) and c.access_type == 'public',\n        recursive=False,\n        allow_empty=True)\n    if decls:\n        return decls", "response": "Returns list of\n    if class has any public constructor otherwise None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_public_assign(class_):\n    class_ = class_traits.get_declaration(class_)\n    decls = class_.member_operators(\n        lambda o: o.symbol == '=' and o.access_type == 'public',\n        recursive=False,\n        allow_empty=True)\n    return bool(decls)", "response": "returns True if class has public assign operator False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruing if class has virtual table False otherwise.", "response": "def has_vtable(decl_type):\n    \"\"\"True, if class has virtual table, False otherwise\"\"\"\n    assert isinstance(decl_type, class_declaration.class_t)\n    return bool(\n        decl_type.calldefs(\n            lambda f: isinstance(f, calldef_members.member_function_t) and\n            f.virtuality != calldef_types.VIRTUALITY_TYPES.NOT_VIRTUAL,\n            recursive=False,\n            allow_empty=True))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_base_and_derived(based, derived):\n    assert isinstance(based, class_declaration.class_t)\n    assert isinstance(derived, (class_declaration.class_t, tuple))\n\n    if isinstance(derived, class_declaration.class_t):\n        all_derived = ([derived])\n    else:  # tuple\n        all_derived = derived\n\n    for derived_cls in all_derived:\n        for base_desc in derived_cls.recursive_bases:\n            if base_desc.related_class == based:\n                return True\n    return False", "response": "returns True if there is base and derived relationship between base and derived classes False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __is_noncopyable_single(class_, already_visited_cls_vars=None):\n    # It is not enough to check base classes, we should also to check\n    # member variables.\n    logger = utils.loggers.cxx_parser\n\n    if has_copy_constructor(class_) \\\n       and has_public_constructor(class_) \\\n       and has_public_assign(class_) \\\n       and has_public_destructor(class_):\n        msg = os.linesep.join([\n            \"__is_noncopyable_single - %s - COPYABLE:\" % class_.decl_string,\n            \"    trivial copy constructor: yes\",\n            \"    public constructor: yes\",\n            \"    public assign: yes\",\n            \"    public destructor: yes\"])\n        logger.debug(msg)\n        return False\n\n    if already_visited_cls_vars is None:\n        already_visited_cls_vars = []\n\n    if find_noncopyable_vars(class_, already_visited_cls_vars):\n        logger.debug(\n            (\"__is_noncopyable_single(TRUE) - %s - contains noncopyable \" +\n             \"members\"), class_.decl_string)\n        return True\n\n    logger.debug((\n        \"__is_noncopyable_single(FALSE) - %s - COPYABLE, because is \" +\n        \"doesn't contains noncopyable members\"), class_.decl_string)\n    return False", "response": "Implementation detail.\n\n    Checks if the class is non copyable, without considering the base classes.\n\n    Args:\n        class_ (declarations.class_t): the class to be checked\n        already_visited_cls_vars (list): optional list of vars that should not\n            be checked a second time, to prevent infinite recursions.\n\n    Returns:\n        bool: if the class is non copyable"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the class is non copyable.", "response": "def is_noncopyable(class_, already_visited_cls_vars=None):\n    \"\"\"\n    Checks if class is non copyable\n\n    Args:\n        class_ (declarations.class_t): the class to be checked\n        already_visited_cls_vars (list): optional list of vars that should not\n            be checked a second time, to prevent infinite recursions.\n            In general you can ignore this argument, it is mainly used during\n            recursive calls of is_noncopyable() done by pygccxml.\n\n    Returns:\n        bool: if the class is non copyable\n    \"\"\"\n    logger = utils.loggers.cxx_parser\n\n    class_decl = class_traits.get_declaration(class_)\n\n    true_header = \"is_noncopyable(TRUE) - %s - \" % class_.decl_string\n\n    if is_union(class_):\n        return False\n\n    if class_decl.is_abstract:\n        logger.debug(true_header + \"abstract client\")\n        return True\n\n    # if class has public, user defined copy constructor, than this class is\n    # copyable\n    copy_ = find_copy_constructor(class_decl)\n    if copy_ and copy_.access_type == 'public' and not copy_.is_artificial:\n        return False\n\n    if already_visited_cls_vars is None:\n        already_visited_cls_vars = []\n\n    for base_desc in class_decl.recursive_bases:\n        assert isinstance(base_desc, class_declaration.hierarchy_info_t)\n\n        if base_desc.related_class.decl_string in \\\n                ('::boost::noncopyable', '::boost::noncopyable_::noncopyable'):\n            logger.debug(true_header + \"derives from boost::noncopyable\")\n            return True\n\n        if not has_copy_constructor(base_desc.related_class):\n\n            base_copy_ = find_copy_constructor(base_desc.related_class)\n\n            if base_copy_ and base_copy_.access_type == 'private':\n                logger.debug(\n                    true_header +\n                    \"there is private copy constructor\")\n                return True\n            elif __is_noncopyable_single(\n                    base_desc.related_class, already_visited_cls_vars):\n                logger.debug(\n                    true_header +\n                    \"__is_noncopyable_single returned True\")\n                return True\n\n        if __is_noncopyable_single(\n                base_desc.related_class, already_visited_cls_vars):\n            logger.debug(\n                true_header +\n                \"__is_noncopyable_single returned True\")\n            return True\n\n    if not has_copy_constructor(class_decl):\n        logger.debug(true_header + \"does not have trivial copy constructor\")\n        return True\n    elif not has_public_constructor(class_decl):\n        logger.debug(true_header + \"does not have a public constructor\")\n        return True\n    elif has_destructor(class_decl) and not has_public_destructor(class_decl):\n        logger.debug(true_header + \"has private destructor\")\n        return True\n\n    return __is_noncopyable_single(class_decl, already_visited_cls_vars)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if operator is unary operator otherwise False", "response": "def is_unary_operator(oper):\n    \"\"\"returns True, if operator is unary operator, otherwise False\"\"\"\n    # definition:\n    # member in class\n    # ret-type operator symbol()\n    # ret-type operator [++ --](int)\n    # globally\n    # ret-type operator symbol( arg )\n    # ret-type operator [++ --](X&, int)\n    symbols = ['!', '&', '~', '*', '+', '++', '-', '--']\n    if not isinstance(oper, calldef_members.operator_t):\n        return False\n    if oper.symbol not in symbols:\n        return False\n    if isinstance(oper, calldef_members.member_operator_t):\n        if len(oper.arguments) == 0:\n            return True\n        elif oper.symbol in ['++', '--'] and \\\n                isinstance(oper.arguments[0].decl_type, cpptypes.int_t):\n            return True\n        return False\n\n    if len(oper.arguments) == 1:\n        return True\n    elif oper.symbol in ['++', '--'] \\\n            and len(oper.arguments) == 2 \\\n            and isinstance(oper.arguments[1].decl_type, cpptypes.int_t):\n        # may be I need to add additional check whether first argument is\n        # reference or not?\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if operator is binary operator otherwise False", "response": "def is_binary_operator(oper):\n    \"\"\"returns True, if operator is binary operator, otherwise False\"\"\"\n    # definition:\n    # member in class\n    # ret-type operator symbol(arg)\n    # globally\n    # ret-type operator symbol( arg1, arg2 )\n    symbols = [\n        ',', '()', '[]', '!=', '%', '%=', '&', '&&', '&=', '*', '*=', '+',\n        '+=', '-', '-=', '->', '->*', '/', '/=', '<', '<<', '<<=', '<=', '=',\n        '==', '>', '>=', '>>', '>>=', '^', '^=', '|', '|=', '||']\n    if not isinstance(oper, calldef_members.operator_t):\n        return False\n    if oper.symbol not in symbols:\n        return False\n\n    if isinstance(oper, calldef_members.member_operator_t):\n        if len(oper.arguments) == 1:\n            return True\n        return False\n\n    if len(oper.arguments) == 2:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the declaration is a copy constructor.", "response": "def is_copy_constructor(constructor):\n    \"\"\"\n    Check if the declaration is a copy constructor,\n\n    Args:\n        constructor (declarations.constructor_t): the constructor\n            to be checked.\n\n    Returns:\n        bool: True if this is a copy constructor, False instead.\n\n    \"\"\"\n    assert isinstance(constructor, calldef_members.constructor_t)\n    args = constructor.arguments\n    parent = constructor.parent\n\n    # A copy constructor has only one argument\n    if len(args) != 1:\n        return False\n\n    # We have only one argument, get it\n    arg = args[0]\n\n    if not isinstance(arg.decl_type, cpptypes.compound_t):\n        # An argument of type declarated_t (a typedef) could be passed to\n        # the constructor; and it could be a reference.\n        # But in c++ you can NOT write :\n        #    \"typedef class MyClass { MyClass(const MyClass & arg) {} }\"\n        # If the argument is a typedef, this is not a copy constructor.\n        # See the hierarchy of declarated_t and coumpound_t. They both\n        # inherit from type_t but are not related so we can discriminate\n        # between them.\n        return False\n\n    # The argument needs to be passed by reference in a copy constructor\n    if not type_traits.is_reference(arg.decl_type):\n        return False\n\n    # The argument needs to be const for a copy constructor\n    if not type_traits.is_const(arg.decl_type.base):\n        return False\n\n    un_aliased = type_traits.remove_alias(arg.decl_type.base)\n    # un_aliased now refers to const_t instance\n    if not isinstance(un_aliased.base, cpptypes.declarated_t):\n        # We are looking for a declaration\n        # If \"class MyClass { MyClass(const int & arg) {} }\" is used,\n        # this is not copy constructor, so we return False here.\n        # -> un_aliased.base == cpptypes.int_t (!= cpptypes.declarated_t)\n        return False\n\n    # Final check: compare the parent (the class declaration for example)\n    # with the declaration of the type passed as argument.\n    return id(un_aliased.base.declaration) == id(parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recursive_bases(self):\n        if self._recursive_bases is None:\n            to_go = self.bases[:]\n            all_bases = []\n            while to_go:\n                base = to_go.pop()\n                if base not in all_bases:\n                    all_bases.append(base)\n                    to_go.extend(base.related_class.bases)\n            self._recursive_bases = all_bases\n        return self._recursive_bases", "response": "list of all base classes that are not in the hierarchy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recursive_derived(self):\n        if self._recursive_derived is None:\n            to_go = self.derived[:]\n            all_derived = []\n            while to_go:\n                derive = to_go.pop()\n                if derive not in all_derived:\n                    all_derived.append(derive)\n                    to_go.extend(derive.related_class.derived)\n            self._recursive_derived = all_derived\n        return self._recursive_derived", "response": "list of all derived classes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_members(self, access=None):\n        if access == ACCESS_TYPES.PUBLIC:\n            return self.public_members\n        elif access == ACCESS_TYPES.PROTECTED:\n            return self.protected_members\n        elif access == ACCESS_TYPES.PRIVATE:\n            return self.private_members\n\n        all_members = []\n        all_members.extend(self.public_members)\n        all_members.extend(self.protected_members)\n        all_members.extend(self.private_members)\n        return all_members", "response": "returns list of members according to access type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adopt_declaration(self, decl, access):\n        if access == ACCESS_TYPES.PUBLIC:\n            self.public_members.append(decl)\n        elif access == ACCESS_TYPES.PROTECTED:\n            self.protected_members.append(decl)\n        elif access == ACCESS_TYPES.PRIVATE:\n            self.private_members.append(decl)\n        else:\n            raise RuntimeError(\"Invalid access type: %s.\" % access)\n        decl.parent = self\n        decl.cache.reset()\n        decl.cache.access_type = access", "response": "adds new declaration to the class\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the declaration from members list", "response": "def remove_declaration(self, decl):\n        \"\"\"\n        removes decl from  members list\n\n        :param decl: declaration to be removed\n        :type decl: :class:`declaration_t`\n        \"\"\"\n\n        access_type = self.find_out_member_access_type(decl)\n        if access_type == ACCESS_TYPES.PUBLIC:\n            container = self.public_members\n        elif access_type == ACCESS_TYPES.PROTECTED:\n            container = self.protected_members\n        else:  # decl.cache.access_type == ACCESS_TYPES.PRVATE\n            container = self.private_members\n        del container[container.index(decl)]\n        decl.cache.reset()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds out if the member is in the internal members list and return the access type of the member.", "response": "def find_out_member_access_type(self, member):\n        \"\"\"\n        returns member access type\n\n        :param member: member of the class\n        :type member: :class:`declaration_t`\n\n        :rtype: :class:ACCESS_TYPES\n        \"\"\"\n        assert member.parent is self\n        if not member.cache.access_type:\n            if member in self.public_members:\n                access_type = ACCESS_TYPES.PUBLIC\n            elif member in self.protected_members:\n                access_type = ACCESS_TYPES.PROTECTED\n            elif member in self.private_members:\n                access_type = ACCESS_TYPES.PRIVATE\n            else:\n                raise RuntimeError(\n                    \"Unable to find member within internal members list.\")\n            member.cache.access_type = access_type\n            return access_type\n        else:\n            return member.cache.access_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreference to a parent class which contains this class and defined within a namespace", "response": "def top_class(self):\n        \"\"\"reference to a parent class, which contains this class and defined\n        within a namespace\n\n        if this class is defined under a namespace, self will be returned\"\"\"\n        curr = self\n        parent = self.parent\n        while isinstance(parent, class_t):\n            curr = parent\n            parent = parent.parent\n        return curr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend another value to the enumeration.", "response": "def append_value(self, valuename, valuenum=None):\n        \"\"\"Append another enumeration value to the `enum`.\n\n        The numeric value may be None in which case it is automatically\n        determined by increasing the value of the last item.\n\n        When the 'values' attribute is accessed the resulting list will be in\n        the same order as append_value() was called.\n\n        :param valuename: The name of the value.\n        :type valuename: str\n        :param valuenum: The numeric value or None.\n        :type valuenum: int\n        \"\"\"\n        # No number given? Then use the previous one + 1\n        if valuenum is None:\n            if not self._values:\n                valuenum = 0\n            else:\n                valuenum = self._values[-1][1] + 1\n\n        # Store the new value\n        self._values.append((valuename, int(valuenum)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if this enum has a particular name among its values.", "response": "def has_value_name(self, name):\n        \"\"\"Check if this `enum` has a particular name among its values.\n\n        :param name: Enumeration value name\n        :type name: str\n        :rtype: True if there is an enumeration value with the given name\n        \"\"\"\n        for val, _ in self._values:\n            if val == name:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary that maps between enum name and enum value", "response": "def get_name2value_dict(self):\n        \"\"\"returns a dictionary, that maps between `enum` name( key ) and\n        `enum` value( value )\"\"\"\n        x = {}\n        for val, num in self._values:\n            x[val] = num\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfixing typedefs defined in no namespace by calling the default argument patcher for all declarations.", "response": "def fix_calldef_decls(decls, enums, cxx_std):\n    \"\"\"\n    some times gccxml report typedefs defined in no namespace\n    it happens for example in next situation\n    template< typename X>\n    void ddd(){ typedef typename X::Y YY;}\n    if I will fail on this bug next time, the right way to fix it may be\n    different\n    \"\"\"\n    default_arg_patcher = default_argument_patcher_t(enums, cxx_std)\n    # decls should be flat list of all declarations, you want to apply patch on\n    for decl in decls:\n        default_arg_patcher(decl)\n        if isinstance(decl, declarations.casting_operator_t):\n            _casting_oper_patcher_(decl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_unnamed_class(decls):\n\n    for decl in decls:\n        if isinstance(decl, declarations.typedef_t):\n            referent = decl.decl_type\n            if isinstance(referent, declarations.elaborated_t):\n                referent = referent.base\n            if not isinstance(referent, declarations.declarated_t):\n                continue\n            referent = referent.declaration\n            if referent.name or not isinstance(referent, declarations.class_t):\n                continue\n            referent.name = decl.name", "response": "Updates the name of the unnamed class in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_cached_source_fc(header, cached_source_file):\n\n    return file_configuration_t(\n        data=header,\n        cached_source_file=cached_source_file,\n        content_type=file_configuration_t.CONTENT_TYPE.CACHED_SOURCE_FILE)", "response": "Creates a new file_configuration_t instance with the given header and cached source file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning list of file names and \\ or \\ or \\ or \\ or \\ or \\ or \\ or \\ or \\ or \\ s", "response": "def get_os_file_names(files):\n        \"\"\"\n        returns file names\n\n        :param files: list of strings and\\\\or :class:`file_configuration_t`\n                      instances.\n        :type files: list\n        \"\"\"\n\n        fnames = []\n        for f in files:\n            if utils.is_str(f):\n                fnames.append(f)\n            elif isinstance(f, file_configuration_t):\n                if f.content_type in (\n                        file_configuration_t.CONTENT_TYPE.STANDARD_SOURCE_FILE,\n                        file_configuration_t.CONTENT_TYPE.CACHED_SOURCE_FILE):\n\n                    fnames.append(f.data)\n            else:\n                pass\n        return fnames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a set of files and returns a list of declaration_t instances.", "response": "def read_files(\n            self,\n            files,\n            compilation_mode=COMPILATION_MODE.FILE_BY_FILE):\n        \"\"\"\n        parses a set of files\n\n        :param files: list of strings and\\\\or :class:`file_configuration_t`\n                      instances.\n        :type files: list\n\n        :param compilation_mode: determines whether the files are parsed\n                                 individually or as one single chunk\n        :type compilation_mode: :class:`COMPILATION_MODE`\n        :rtype: [:class:`declaration_t`]\n        \"\"\"\n\n        if compilation_mode == COMPILATION_MODE.ALL_AT_ONCE \\\n           and len(files) == len(self.get_os_file_names(files)):\n            return self.__parse_all_at_once(files)\n        else:\n            if compilation_mode == COMPILATION_MODE.ALL_AT_ONCE:\n                msg = ''.join([\n                    \"Unable to parse files using ALL_AT_ONCE mode. \",\n                    \"There is some file configuration that is not file. \",\n                    \"pygccxml.parser.project_reader_t switches to \",\n                    \"FILE_BY_FILE mode.\"])\n                self.logger.warning(msg)\n            return self.__parse_file_by_file(files)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_string(self, content):\n        reader = source_reader.source_reader_t(\n            self.__config,\n            None,\n            self.__decl_factory)\n        decls = reader.read_string(content)\n        self.__xml_generator_from_xml_file = reader.xml_generator_from_xml_file\n        return decls", "response": "Parse a string containing C ++ source code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the C ++ code defined on the file_configurations and returns the XML generated file content", "response": "def read_xml(self, file_configuration):\n        \"\"\"parses C++ code, defined on the file_configurations and returns\n        GCCXML generated file content\"\"\"\n\n        xml_file_path = None\n        delete_xml_file = True\n        fc = file_configuration\n        reader = source_reader.source_reader_t(\n            self.__config,\n            None,\n            self.__decl_factory)\n        try:\n            if fc.content_type == fc.CONTENT_TYPE.STANDARD_SOURCE_FILE:\n                self.logger.info('Parsing source file \"%s\" ... ', fc.data)\n                xml_file_path = reader.create_xml_file(fc.data)\n            elif fc.content_type == \\\n                    file_configuration_t.CONTENT_TYPE.GCCXML_GENERATED_FILE:\n                self.logger.info('Parsing xml file \"%s\" ... ', fc.data)\n                xml_file_path = fc.data\n                delete_xml_file = False\n            elif fc.content_type == fc.CONTENT_TYPE.CACHED_SOURCE_FILE:\n                # TODO: raise error when header file does not exist\n                if not os.path.exists(fc.cached_source_file):\n                    dir_ = os.path.split(fc.cached_source_file)[0]\n                    if dir_ and not os.path.exists(dir_):\n                        os.makedirs(dir_)\n                    self.logger.info(\n                        'Creating xml file \"%s\" from source file \"%s\" ... ',\n                        fc.cached_source_file, fc.data)\n                    xml_file_path = reader.create_xml_file(\n                        fc.data,\n                        fc.cached_source_file)\n                else:\n                    xml_file_path = fc.cached_source_file\n            else:\n                xml_file_path = reader.create_xml_file_from_string(fc.data)\n            with open(xml_file_path, \"r\") as xml_file:\n                xml = xml_file.read()\n            utils.remove_file_no_raise(xml_file_path, self.__config)\n            self.__xml_generator_from_xml_file = \\\n                reader.xml_generator_from_xml_file\n            return xml\n        finally:\n            if xml_file_path and delete_xml_file:\n                utils.remove_file_no_raise(xml_file_path, self.__config)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dependencies_from_decl(decl, recursive=True):\n    result = []\n    if isinstance(decl, typedef.typedef_t) or \\\n            isinstance(decl, variable.variable_t):\n        return [dependency_info_t(decl, decl.decl_type)]\n    if isinstance(decl, namespace.namespace_t):\n        if recursive:\n            for d in decl.declarations:\n                result.extend(get_dependencies_from_decl(d))\n        return result\n    if isinstance(decl, calldef.calldef_t):\n        if decl.return_type:\n            result.append(\n                dependency_info_t(decl, decl.return_type, hint=\"return type\"))\n        for arg in decl.arguments:\n            result.append(dependency_info_t(decl, arg.decl_type))\n        for exc in decl.exceptions:\n            result.append(dependency_info_t(decl, exc, hint=\"exception\"))\n        return result\n    if isinstance(decl, class_declaration.class_t):\n        for base in decl.bases:\n            result.append(\n                dependency_info_t(\n                    decl,\n                    base.related_class,\n                    base.access_type,\n                    \"base class\"))\n        if recursive:\n            for access_type in class_declaration.ACCESS_TYPES.ALL:\n                result.extend(\n                    __find_out_member_dependencies(\n                        decl.get_members(access_type), access_type))\n        return result\n    return result", "response": "Returns the list of all types and declarations that the declaration depends on."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef i_depend_on_them(decl):\n\n        to_be_included = set()\n        for dependency_info in get_dependencies_from_decl(decl):\n            for ddecl in dependency_info.find_out_depend_on_it_declarations():\n                if ddecl:\n                    to_be_included.add(ddecl)\n\n        if isinstance(decl.parent, class_declaration.class_t):\n            to_be_included.add(decl.parent)\n        return to_be_included", "response": "Returns set of declarations. every item in the returned set depends on a declaration from the input"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef we_depend_on_them(decls):\n        to_be_included = set()\n        for decl in decls:\n            to_be_included.update(dependency_info_t.i_depend_on_them(decl))\n        return to_be_included", "response": "Returns set of declarations. every item in the returned set depends on a declaration from the input"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes the name of the node.", "response": "def normalize_name(decl):\n    \"\"\"\n    Cached variant of normalize\n\n    Args:\n        decl (declaration.declaration_t): the declaration\n\n    Returns:\n        str: normalized name\n    \"\"\"\n    if decl.cache.normalized_name is None:\n        decl.cache.normalized_name = normalize(decl.name)\n    return decl.cache.normalized_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize_partial_name(decl):\n    if decl.cache.normalized_partial_name is None:\n        decl.cache.normalized_partial_name = normalize(decl.partial_name)\n    return decl.cache.normalized_partial_name", "response": "Returns the normalized partial name of the node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_full_name_true(decl):\n    if decl.cache.normalized_full_name_true is None:\n        decl.cache.normalized_full_name_true = normalize(\n            declaration_utils.full_name(decl, with_defaults=True))\n    return decl.cache.normalized_full_name_true", "response": "Returns the full name of the current node if it is set to True otherwise returns the full name of the node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the full name of the catalical item that is not false", "response": "def normalize_full_name_false(decl):\n    \"\"\"\n    Cached variant of normalize\n\n    Args:\n        decl (declaration.declaration_t): the declaration\n\n    Returns:\n        str: normalized name\n    \"\"\"\n    if decl.cache.normalized_full_name_false is None:\n        decl.cache.normalized_full_name_false = normalize(\n            declaration_utils.full_name(decl, with_defaults=False))\n    return decl.cache.normalized_full_name_false"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_container_traits(cls_or_string):\n\n    if utils.is_str(cls_or_string):\n        if not templates.is_instantiation(cls_or_string):\n            return None\n        name = templates.name(cls_or_string)\n        if name.startswith('std::'):\n            name = name[len('std::'):]\n        if name.startswith('std::tr1::'):\n            name = name[len('std::tr1::'):]\n        for cls_traits in all_container_traits:\n            if cls_traits.name() == name:\n                return cls_traits\n    else:\n\n        if isinstance(cls_or_string, class_declaration.class_types):\n            # Look in the cache.\n            if cls_or_string.cache.container_traits is not None:\n                return cls_or_string.cache.container_traits\n\n        # Look for a container traits\n        for cls_traits in all_container_traits:\n            if cls_traits.is_my_case(cls_or_string):\n                # Store in the cache\n                if isinstance(cls_or_string, class_declaration.class_types):\n                    cls_or_string.cache.container_traits = cls_traits\n                return cls_traits", "response": "Find the container traits type of a declaration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn reference to the class declaration or None.", "response": "def get_container_or_none(self, type_):\n        \"\"\"\n        Returns reference to the class declaration or None.\n\n        \"\"\"\n\n        type_ = type_traits.remove_alias(type_)\n        type_ = type_traits.remove_cv(type_)\n\n        utils.loggers.queries_engine.debug(\n            \"Container traits: cleaned up search %s\", type_)\n\n        if isinstance(type_, cpptypes.declarated_t):\n            cls_declaration = type_traits.remove_alias(type_.declaration)\n        elif isinstance(type_, class_declaration.class_t):\n            cls_declaration = type_\n        elif isinstance(type_, class_declaration.class_declaration_t):\n            cls_declaration = type_\n        else:\n            utils.loggers.queries_engine.debug(\n                \"Container traits: returning None, type not known\\n\")\n            return\n\n        if not cls_declaration.name.startswith(self.name() + '<'):\n            utils.loggers.queries_engine.debug(\n                \"Container traits: returning None, \" +\n                \"declaration starts with \" + self.name() + '<\\n')\n            return\n\n        # When using libstd++, some container traits are defined in\n        # std::tr1::. See remove_template_defaults_tester.py.\n        # In this case the is_defined_in_xxx test needs to be done\n        # on the parent\n        decl = cls_declaration\n        if isinstance(type_, class_declaration.class_declaration_t):\n            is_ns = isinstance(type_.parent, namespace.namespace_t)\n            if is_ns and type_.parent.name == \"tr1\":\n                decl = cls_declaration.parent\n        elif isinstance(type_, cpptypes.declarated_t):\n            is_ns = isinstance(type_.declaration.parent, namespace.namespace_t)\n            if is_ns and type_.declaration.parent.name == \"tr1\":\n                decl = cls_declaration.parent\n\n        for ns in std_namespaces:\n            if traits_impl_details.impl_details.is_defined_in_xxx(ns, decl):\n                utils.loggers.queries_engine.debug(\n                    \"Container traits: get_container_or_none() will return \" +\n                    cls_declaration.name)\n                # The is_defined_in_xxx check is done on decl, but we return\n                # the original declation so that the rest of the algorithm\n                # is able to work with it.\n                return cls_declaration\n\n        # This should not happen\n        utils.loggers.queries_engine.debug(\n            \"Container traits: get_container_or_none() will return None\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef class_declaration(self, type_):\n\n        utils.loggers.queries_engine.debug(\n            \"Container traits: searching class declaration for %s\", type_)\n\n        cls_declaration = self.get_container_or_none(type_)\n        if not cls_declaration:\n            raise TypeError(\n                'Type \"%s\" is not instantiation of std::%s' %\n                (type_.decl_string, self.name()))\n        return cls_declaration", "response": "Returns reference to the class declaration of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning reference to the class value \\\\ mapped type declaration", "response": "def element_type(self, type_):\n        \"\"\"returns reference to the class value\\\\mapped type declaration\"\"\"\n        return self.__find_xxx_type(\n            type_,\n            self.element_type_index,\n            self.element_type_typedef,\n            'container_element_type')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef key_type(self, type_):\n        if not self.is_mapping(type_):\n            raise TypeError(\n                'Type \"%s\" is not \"mapping\" container' %\n                str(type_))\n        return self.__find_xxx_type(\n            type_,\n            self.key_type_index,\n            self.key_type_typedef,\n            'container_key_type')", "response": "returns reference to the class key type declaration"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves template defaults from a templated class instantiation.", "response": "def remove_defaults(self, type_or_string):\n        \"\"\"\n        Removes template defaults from a templated class instantiation.\n\n        For example:\n            .. code-block:: c++\n\n               std::vector< int, std::allocator< int > >\n\n        will become:\n            .. code-block:: c++\n\n               std::vector< int >\n\n        \"\"\"\n\n        name = type_or_string\n        if not utils.is_str(type_or_string):\n            name = self.class_declaration(type_or_string).name\n        if not self.remove_defaults_impl:\n            return name\n        no_defaults = self.remove_defaults_impl(name)\n        if not no_defaults:\n            return name\n        return no_defaults"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the global namespace from a declaration tree.", "response": "def get_global_namespace(decls):\n    \"\"\"\n    Get the global namespace (::) from a declaration tree.\n\n    Args:\n        decls (list[declaration_t]): a list of declarations\n\n    Returns:\n        namespace_t: the global namespace_t object (::)\n\n    \"\"\"\n    found = [\n        decl for decl in scopedef.make_flatten(decls) if decl.name == '::' and\n        isinstance(decl, namespace_t)]\n    if len(found) == 1:\n        return found[0]\n    raise RuntimeError(\"Unable to find global namespace.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef take_parenting(self, inst):\n\n        if self is inst:\n            return\n        for decl in inst.declarations:\n            decl.parent = self\n            self.declarations.append(decl)\n        inst.declarations = []", "response": "Takes parenting from inst and transfers it to self."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving declaration from members list.", "response": "def remove_declaration(self, decl):\n        \"\"\"\n        Removes declaration from members list.\n\n        :param decl: declaration to be removed\n        :type decl: :class:`declaration_t`\n\n        \"\"\"\n\n        del self.declarations[self.declarations.index(decl)]\n        decl.cache.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning reference to namespace declaration that matches a defined criteria.", "response": "def namespace(self, name=None, function=None, recursive=None):\n        \"\"\"\n        Returns reference to namespace declaration that matches\n        a defined criteria.\n\n        \"\"\"\n\n        return (\n            self._find_single(\n                scopedef.scopedef_t._impl_matchers[namespace_t.namespace],\n                name=name,\n                function=function,\n                recursive=recursive)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef namespaces(\n            self,\n            name=None,\n            function=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"\n        Returns a set of namespace declarations that match\n        a defined criteria.\n\n        \"\"\"\n\n        return (\n            self._find_multiple(\n                scopedef.scopedef_t._impl_matchers[namespace_t.namespace],\n                name=name,\n                function=function,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )", "response": "Returns a set of namespace declarations that match the specified criteria."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef free_function(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None):\n        \"\"\"\n        Returns reference to free function declaration that matches\n        a defined criteria.\n\n        \"\"\"\n\n        return (\n            self._find_single(\n                scopedef.scopedef_t._impl_matchers[namespace_t.free_function],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[namespace_t.free_function],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive)\n        )", "response": "Returns reference to free function declaration that matches a defined criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef free_functions(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"\n        Returns a set of free function declarations that match\n        a defined criteria.\n\n        \"\"\"\n\n        return (\n            self._find_multiple(\n                scopedef.scopedef_t._impl_matchers[namespace_t.free_function],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[namespace_t.free_function],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )", "response": "Returns a set of free function declarations that match a defined criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef free_operator(\n            self,\n            name=None,\n            function=None,\n            symbol=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None):\n        \"\"\"\n        Returns reference to free operator declaration that matches\n        a defined criteria.\n\n        \"\"\"\n        return (\n            self._find_single(\n                scopedef.scopedef_t._impl_matchers[namespace_t.free_operator],\n                name=self._build_operator_name(name, function, symbol),\n                symbol=symbol,\n                function=self._build_operator_function(name, function),\n                decl_type=self._impl_decl_types[namespace_t.free_operator],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive)\n        )", "response": "Returns reference to free operator declaration that matches a defined criteria."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract(text, default=UNKNOWN):\n        if not text:\n            return default\n        found = CALLING_CONVENTION_TYPES.pattern.match(text)\n        if found:\n            return found.group('cc')\n\n        return default", "response": "extracts calling convention from the text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning true if f1 and f2 are same function", "response": "def is_same_function(f1, f2):\n    \"\"\"returns true if f1 and f2 is same function\n\n    Use case: sometimes when user defines some virtual function in base class,\n    it overrides it in a derived one. Sometimes we need to know whether two\n    member functions is actually same function.\n    \"\"\"\n    if f1 is f2:\n        return True\n    if f1.__class__ is not f2.__class__:\n        return False\n    if isinstance(f1, calldef_members.member_calldef_t) and \\\n            f1.has_const != f2.has_const:\n        return False\n    if f1.name != f2.name:\n        return False\n    if not is_same_return_type(f1, f2):\n        return False\n    if len(f1.arguments) != len(f2.arguments):\n        return False\n    for f1_arg, f2_arg in zip(f1.arguments, f2.arguments):\n        if not type_traits.is_same(f1_arg.decl_type, f2_arg.decl_type):\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts tree representation of declarations to flatten one.", "response": "def make_flatten(decl_or_decls):\n    \"\"\"\n    Converts tree representation of declarations to flatten one.\n\n    :param decl_or_decls: reference to list of declaration's or single\n        declaration\n    :type decl_or_decls: :class:`declaration_t` or [ :class:`declaration_t` ]\n    :rtype: [ all internal declarations ]\n\n    \"\"\"\n\n    def proceed_single(decl):\n        answer = [decl]\n        if not isinstance(decl, scopedef_t):\n            return answer\n        for elem in decl.declarations:\n            if isinstance(elem, scopedef_t):\n                answer.extend(proceed_single(elem))\n            else:\n                answer.append(elem)\n        return answer\n\n    decls = []\n    if isinstance(decl_or_decls, list):\n        decls.extend(decl_or_decls)\n    else:\n        decls.append(decl_or_decls)\n    answer = []\n    for decl in decls:\n        answer.extend(proceed_single(decl))\n    return answer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all declarations that match criteria.", "response": "def find_all_declarations(\n        declarations,\n        decl_type=None,\n        name=None,\n        parent=None,\n        recursive=True,\n        fullname=None):\n    \"\"\"\n    Returns a list of all declarations that match criteria, defined by\n    developer.\n\n    For more information about arguments see :class:`match_declaration_t`\n    class.\n\n    :rtype: [ matched declarations ]\n\n    \"\"\"\n\n    if recursive:\n        decls = make_flatten(declarations)\n    else:\n        decls = declarations\n\n    return list(\n        filter(\n            algorithm.match_declaration_t(\n                decl_type=decl_type,\n                name=name,\n                fullname=fullname,\n                parent=parent),\n            decls))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_declaration(\n        declarations,\n        decl_type=None,\n        name=None,\n        parent=None,\n        recursive=True,\n        fullname=None):\n    \"\"\"\n    Returns single declaration that match criteria, defined by developer.\n    If more the one declaration was found None will be returned.\n\n    For more information about arguments see :class:`match_declaration_t`\n    class.\n\n    :rtype: matched declaration :class:`declaration_t` or None\n\n    \"\"\"\n\n    decl = find_all_declarations(\n        declarations,\n        decl_type=decl_type,\n        name=name,\n        parent=parent,\n        recursive=recursive,\n        fullname=fullname)\n    if len(decl) == 1:\n        return decl[0]", "response": "Returns a single declaration that matches criteria defined by developer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn first declaration that matches criteria defined by developer.", "response": "def find_first_declaration(\n        declarations,\n        decl_type=None,\n        name=None,\n        parent=None,\n        recursive=True,\n        fullname=None):\n    \"\"\"\n    Returns first declaration that match criteria, defined by developer.\n\n    For more information about arguments see :class:`match_declaration_t`\n    class.\n\n    :rtype: matched declaration :class:`declaration_t` or None\n\n    \"\"\"\n\n    decl_matcher = algorithm.match_declaration_t(\n        decl_type=decl_type,\n        name=name,\n        fullname=fullname,\n        parent=parent)\n    if recursive:\n        decls = make_flatten(declarations)\n    else:\n        decls = declarations\n    for decl in decls:\n        if decl_matcher(decl):\n            return decl\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns set of files that are declared in some file.", "response": "def declaration_files(decl_or_decls):\n    \"\"\"\n    Returns set of files\n\n    Every declaration is declared in some file. This function returns set, that\n    contains all file names of declarations.\n\n    :param decl_or_decls: reference to list of declaration's or single\n        declaration\n    :type decl_or_decls: :class:`declaration_t` or [:class:`declaration_t`]\n    :rtype: set(declaration file names)\n\n    \"\"\"\n\n    files = set()\n    decls = make_flatten(decl_or_decls)\n    for decl in decls:\n        if decl.location:\n            files.add(decl.location.file_name)\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find(decl_matcher, decls, recursive=True):\n\n        where = []\n        if isinstance(decls, list):\n            where.extend(decls)\n        else:\n            where.append(decls)\n        if recursive:\n            where = make_flatten(where)\n        return list(filter(decl_matcher, where))", "response": "Returns a list of declarations that match the decl_matcher criteria or None if no matching declarations are found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a reference to the declaration that matches decl_matcher defined criteria.", "response": "def find_single(decl_matcher, decls, recursive=True):\n        \"\"\"\n        Returns a reference to the declaration, that match `decl_matcher`\n        defined criteria.\n\n        if a unique declaration could not be found the method will return None.\n\n        :param decl_matcher: Python callable object, that takes one argument -\n            reference to a declaration\n        :param decls: the search scope, :class:declaration_t object or\n            :class:declaration_t objects list t\n        :param recursive: boolean, if True, the method will run `decl_matcher`\n            on the internal declarations too\n        \"\"\"\n        answer = matcher.find(decl_matcher, decls, recursive)\n        if len(answer) == 1:\n            return answer[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_single(decl_matcher, decls, recursive=True):\n        answer = matcher.find(decl_matcher, decls, recursive)\n        if len(answer) == 1:\n            return answer[0]\n        elif not answer:\n            raise runtime_errors.declaration_not_found_t(decl_matcher)\n        else:\n            raise runtime_errors.multiple_declarations_found_t(decl_matcher)", "response": "Returns a reference to declaration that matches decl_matcher criteria."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclean query optimizer state", "response": "def clear_optimizer(self):\n        \"\"\"Cleans query optimizer state\"\"\"\n        self._optimized = False\n        self._type2decls = {}\n        self._type2name2decls = {}\n        self._type2decls_nr = {}\n        self._type2name2decls_nr = {}\n        self._all_decls = None\n        self._all_decls_not_recursive = None\n\n        for decl in self.declarations:\n            if isinstance(decl, scopedef_t):\n                decl.clear_optimizer()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_optimizer(self):\n        if self.name == '::':\n            self._logger.debug(\n                \"preparing data structures for query optimizer - started\")\n        start_time = timeit.default_timer()\n\n        self.clear_optimizer()\n\n        for dtype in scopedef_t._impl_all_decl_types:\n            self._type2decls[dtype] = []\n            self._type2decls_nr[dtype] = []\n            self._type2name2decls[dtype] = {}\n            self._type2name2decls_nr[dtype] = {}\n\n        self._all_decls_not_recursive = self.declarations\n        self._all_decls = make_flatten(\n            self._all_decls_not_recursive)\n        for decl in self._all_decls:\n            types = self.__decl_types(decl)\n            for type_ in types:\n                self._type2decls[type_].append(decl)\n                name2decls = self._type2name2decls[type_]\n                if decl.name not in name2decls:\n                    name2decls[decl.name] = []\n                name2decls[decl.name].append(decl)\n                if self is decl.parent:\n                    self._type2decls_nr[type_].append(decl)\n                    name2decls_nr = self._type2name2decls_nr[type_]\n                    if decl.name not in name2decls_nr:\n                        name2decls_nr[decl.name] = []\n                    name2decls_nr[decl.name].append(decl)\n\n        for decl in self._all_decls_not_recursive:\n            if isinstance(decl, scopedef_t):\n                decl.init_optimizer()\n        if self.name == '::':\n            self._logger.debug((\n                \"preparing data structures for query optimizer - \" +\n                \"done( %f seconds ). \"), (timeit.default_timer() - start_time))\n        self._optimized = True", "response": "Initializes query optimizer state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize arguments to be consistent with the API", "response": "def __normalize_args(**keywds):\n        \"\"\"implementation details\"\"\"\n        if isinstance(keywds['name'], Callable) and \\\n                None is keywds['function']:\n            keywds['function'] = keywds['name']\n            keywds['name'] = None\n        return keywds"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a function that matches a set of declarations", "response": "def __create_matcher(self, match_class, **keywds):\n        \"\"\"implementation details\"\"\"\n        matcher_args = keywds.copy()\n        del matcher_args['function']\n        del matcher_args['recursive']\n        if 'allow_empty' in matcher_args:\n            del matcher_args['allow_empty']\n\n        decl_matcher = decl_matcher = match_class(**matcher_args)\n        if keywds['function']:\n            self._logger.debug(\n                'running query: %s and <user defined function>',\n                str(decl_matcher))\n            return lambda decl: decl_matcher(decl) and keywds['function'](decl)\n\n        self._logger.debug('running query: %s', str(decl_matcher))\n        return decl_matcher"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __findout_range(self, name, decl_type, recursive):\n        if not self._optimized:\n            self._logger.debug(\n                'running non optimized query - optimization has not been done')\n            decls = self.declarations\n            if recursive:\n                decls = make_flatten(self.declarations)\n            if decl_type:\n                decls = [d for d in decls if isinstance(d, decl_type)]\n            return decls\n\n        if name and templates.is_instantiation(name):\n            # templates has tricky mode to compare them, so lets check the\n            # whole range\n            name = None\n\n        if name and decl_type:\n            impl_match = scopedef_t._impl_matchers[scopedef_t.decl](name=name)\n            if impl_match.is_full_name():\n                name = impl_match.decl_name_only\n            if recursive:\n                self._logger.debug(\n                    'query has been optimized on type and name')\n                return self._type2name2decls[decl_type].get(name, [])\n\n            self._logger.debug(\n                'non recursive query has been optimized on type and name')\n            return self._type2name2decls_nr[decl_type].get(name, [])\n        elif decl_type:\n            if recursive:\n                self._logger.debug('query has been optimized on type')\n                return self._type2decls[decl_type]\n\n            self._logger.debug(\n                'non recursive query has been optimized on type')\n            return self._type2decls_nr[decl_type]\n        else:\n            if recursive:\n                self._logger.debug((\n                    'query has not been optimized ( hint: query does not ' +\n                    'contain type and/or name )'))\n                return self._all_decls\n\n            self._logger.debug((\n                'non recursive query has not been optimized ( hint: ' +\n                'query does not contain type and/or name )'))\n            return self._all_decls_not_recursive", "response": "returns a list of all decls that are in the specified range"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a set of declarations that are matched defined criteria", "response": "def decls(\n            self,\n            name=None,\n            function=None,\n            decl_type=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of declarations, that are matched defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[\n                    scopedef_t.decl],\n                name=name,\n                function=function,\n                decl_type=decl_type,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a set of class declarations that are matched defined criteria", "response": "def classes(\n            self,\n            name=None,\n            function=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of class declarations, that are matched defined\n        criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.class_],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.class_],\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef variable(\n            self,\n            name=None,\n            function=None,\n            decl_type=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None):\n        \"\"\"returns reference to variable declaration, that is matched defined\n        criteria\"\"\"\n\n        return (\n            self._find_single(\n                self._impl_matchers[\n                    scopedef_t.variable],\n                name=name,\n                function=function,\n                decl_type=decl_type,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive)\n        )", "response": "returns reference to variable declaration that is matched defined\n            criteria"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a set of variable declarations that are matched defined criteria", "response": "def variables(\n            self,\n            name=None,\n            function=None,\n            decl_type=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n\n        \"\"\"returns a set of variable declarations, that are matched defined\n        criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[\n                    scopedef_t.variable],\n                name=name,\n                function=function,\n                decl_type=decl_type,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of : class : calldef_t declarations that are matched defined criteria", "response": "def calldefs(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of :class:`calldef_t` declarations, that are matched\n        defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.calldef],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.calldef],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef member_functions(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of member function declarations, that are matched\n        defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.member_function],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.member_function],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )", "response": "returns a set of member function declarations that are matched\n            defined criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns reference to constructor declaration that is matched defined criteria", "response": "def constructor(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None):\n        \"\"\"returns reference to constructor declaration, that is matched\n        defined criteria\"\"\"\n        return (\n            self._find_single(\n                self._impl_matchers[scopedef_t.constructor],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.constructor],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef constructors(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of constructor declarations, that are matched\n        defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.constructor],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.constructor],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )", "response": "returns a set of constructor declarations that are matched\n            defined criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a set of casting operator declarations that are matched defined criteria", "response": "def casting_operators(\n            self,\n            name=None,\n            function=None,\n            return_type=None,\n            arg_types=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of casting operator declarations, that are matched\n        defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.casting_operator],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.casting_operator],\n                return_type=return_type,\n                arg_types=arg_types,\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enumerations(\n            self,\n            name=None,\n            function=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of enumeration declarations, that are matched\n        defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.enumeration],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.enumeration],\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )", "response": "returns a set of enumeration declarations that are matched\n            defined criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef typedef(\n            self,\n            name=None,\n            function=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None):\n        \"\"\"returns reference to typedef declaration, that is matched\n        defined criteria\"\"\"\n        return (\n            self._find_single(\n                self._impl_matchers[scopedef_t.typedef],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.typedef],\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive)\n        )", "response": "returns reference to typedef declaration that is matched\n            defined criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of typedef declarations that are matched defined criteria", "response": "def typedefs(\n            self,\n            name=None,\n            function=None,\n            header_dir=None,\n            header_file=None,\n            recursive=None,\n            allow_empty=None):\n        \"\"\"returns a set of typedef declarations, that are matched\n        defined criteria\"\"\"\n        return (\n            self._find_multiple(\n                self._impl_matchers[scopedef_t.typedef],\n                name=name,\n                function=function,\n                decl_type=self._impl_decl_types[\n                    scopedef_t.typedef],\n                header_dir=header_dir,\n                header_file=header_file,\n                recursive=recursive,\n                allow_empty=allow_empty)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads CastXML or GCC - XML configuration file.", "response": "def load_xml_generator_configuration(configuration, **defaults):\n    \"\"\"\n    Loads CastXML or GCC-XML configuration.\n\n    Args:\n         configuration (string|configparser.ConfigParser): can be\n             a string (file path to a configuration file) or\n             instance of :class:`configparser.ConfigParser`.\n         defaults: can be used to override single configuration values.\n\n    Returns:\n        :class:`.xml_generator_configuration_t`: a configuration object\n\n\n    The file passed needs to be in a format that can be parsed by\n    :class:`configparser.ConfigParser`.\n\n    An example configuration file skeleton can be found\n    `here <https://github.com/gccxml/pygccxml/blob/develop/\n    unittests/xml_generator.cfg>`_.\n\n    \"\"\"\n    parser = configuration\n    if utils.is_str(configuration):\n        parser = ConfigParser()\n        parser.read(configuration)\n\n    # Create a new empty configuration\n    cfg = xml_generator_configuration_t()\n\n    values = defaults\n    if not values:\n        values = {}\n\n    if parser.has_section('xml_generator'):\n        for name, value in parser.items('xml_generator'):\n            if value.strip():\n                values[name] = value\n\n    for name, value in values.items():\n        if isinstance(value, str):\n            value = value.strip()\n        if name == 'gccxml_path':\n            cfg.gccxml_path = value\n        if name == 'xml_generator_path':\n            cfg.xml_generator_path = value\n        elif name == 'working_directory':\n            cfg.working_directory = value\n        elif name == 'include_paths':\n            for p in value.split(';'):\n                p = p.strip()\n                if p:\n                    cfg.include_paths.append(os.path.normpath(p))\n        elif name == 'compiler':\n            cfg.compiler = value\n        elif name == 'xml_generator':\n            cfg.xml_generator = value\n        elif name == 'castxml_epic_version':\n            cfg.castxml_epic_version = int(value)\n        elif name == 'keep_xml':\n            cfg.keep_xml = value\n        elif name == 'cflags':\n            cfg.cflags = value\n        elif name == 'flags':\n            cfg.flags = value\n        elif name == 'compiler_path':\n            cfg.compiler_path = value\n        else:\n            print('\\n%s entry was ignored' % name)\n\n    # If no compiler path was set and we are using castxml, set the path\n    # Here we overwrite the default configuration done in the cfg because\n    # the xml_generator was set through the setter after the creation of a new\n    # emppty configuration object.\n    cfg.compiler_path = create_compiler_path(\n        cfg.xml_generator, cfg.compiler_path)\n\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_compiler_path(xml_generator, compiler_path):\n\n    if xml_generator == 'castxml' and compiler_path is None:\n        if platform.system() == 'Windows':\n            # Look for msvc\n            p = subprocess.Popen(\n                ['where', 'cl'],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE)\n            compiler_path = p.stdout.read().decode(\"utf-8\").rstrip()\n            p.wait()\n            p.stdout.close()\n            p.stderr.close()\n            # No msvc found; look for mingw\n            if compiler_path == '':\n                p = subprocess.Popen(\n                    ['where', 'mingw'],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE)\n                compiler_path = p.stdout.read().decode(\"utf-8\").rstrip()\n                p.wait()\n                p.stdout.close()\n                p.stderr.close()\n        else:\n            # OS X or Linux\n            # Look for clang first, then gcc\n            p = subprocess.Popen(\n                ['which', 'clang++'],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE)\n            compiler_path = p.stdout.read().decode(\"utf-8\").rstrip()\n            p.wait()\n            p.stdout.close()\n            p.stderr.close()\n            # No clang found; use gcc\n            if compiler_path == '':\n                p = subprocess.Popen(\n                    ['which', 'c++'],\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE)\n                compiler_path = p.stdout.read().decode(\"utf-8\").rstrip()\n                p.wait()\n                p.stdout.close()\n                p.stderr.close()\n\n        if compiler_path == \"\":\n            compiler_path = None\n\n    return compiler_path", "response": "Create a path for the compiler for the given xml_generator and compiler_path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the configuration settings and raises RuntimeError on error", "response": "def raise_on_wrong_settings(self):\n        \"\"\"\n        Validates the configuration settings and raises RuntimeError on error\n        \"\"\"\n        self.__ensure_dir_exists(self.working_directory, 'working directory')\n        for idir in self.include_paths:\n            self.__ensure_dir_exists(idir, 'include directory')\n        if self.__xml_generator not in [\"castxml\", \"gccxml\"]:\n            msg = ('xml_generator(\"%s\") should either be ' +\n                   '\"castxml\" or \"gccxml\".') % self.xml_generator\n            raise RuntimeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning function type. See : class : type_t hierarchy", "response": "def function_type(self):\n        \"\"\"returns function type. See :class:`type_t` hierarchy\"\"\"\n        if self.has_static:\n            return cpptypes.free_function_type_t(\n                return_type=self.return_type,\n                arguments_types=[arg.decl_type for arg in self.arguments])\n\n        return cpptypes.member_function_type_t(\n            class_inst=self.parent,\n            return_type=self.return_type,\n            arguments_types=[arg.decl_type for arg in self.arguments],\n            has_const=self.has_const)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of parent declarations names.", "response": "def declaration_path(decl):\n    \"\"\"\n    Returns a list of parent declarations names.\n\n    Args:\n        decl (declaration_t): declaration for which declaration path\n                              should be calculated.\n\n    Returns:\n        list[(str | basestring)]: list of names, where first item is the top\n                                  parent name and last item the inputted\n                                  declaration name.\n    \"\"\"\n\n    if not decl:\n        return []\n    if not decl.cache.declaration_path:\n        result = [decl.name]\n        parent = decl.parent\n        while parent:\n            if parent.cache.declaration_path:\n                result.reverse()\n                decl.cache.declaration_path = parent.cache.declaration_path + \\\n                    result\n                return decl.cache.declaration_path\n            else:\n                result.append(parent.name)\n                parent = parent.parent\n        result.reverse()\n        decl.cache.declaration_path = result\n        return result\n\n    return decl.cache.declaration_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef partial_declaration_path(decl):\n\n    # TODO:\n    # If parent declaration cache already has declaration_path, reuse it for\n    # calculation.\n    if not decl:\n        return []\n    if not decl.cache.partial_declaration_path:\n        result = [decl.partial_name]\n        parent = decl.parent\n        while parent:\n            if parent.cache.partial_declaration_path:\n                result.reverse()\n                decl.cache.partial_declaration_path \\\n                    = parent.cache.partial_declaration_path + result\n                return decl.cache.partial_declaration_path\n            else:\n                result.append(parent.partial_name)\n                parent = parent.parent\n        result.reverse()\n        decl.cache.partial_declaration_path = result\n        return result\n\n    return decl.cache.partial_declaration_path", "response": "Returns a list of parent declarations names without template arguments that have default value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the full qualified name of the class or namespace.", "response": "def full_name(decl, with_defaults=True):\n    \"\"\"\n    Returns declaration full qualified name.\n\n    If `decl` belongs to anonymous namespace or class, the function will return\n    C++ illegal qualified name.\n\n    Args:\n        decl (declaration_t): declaration for which the full qualified name\n                              should be calculated.\n\n    Returns:\n        list[(str | basestring)]: full name of the declaration.\n\n    \"\"\"\n\n    if None is decl:\n        raise RuntimeError(\"Unable to generate full name for None object!\")\n    if with_defaults:\n        if not decl.cache.full_name:\n            path = declaration_path(decl)\n            if path == [\"\"]:\n                # Declarations without names are allowed (for examples class\n                # or struct instances). In this case set an empty name..\n                decl.cache.full_name = \"\"\n            else:\n                decl.cache.full_name = full_name_from_declaration_path(path)\n        return decl.cache.full_name\n    else:\n        if not decl.cache.full_partial_name:\n            path = partial_declaration_path(decl)\n            if path == [\"\"]:\n                # Declarations without names are allowed (for examples class\n                # or struct instances). In this case set an empty name.\n                decl.cache.full_partial_name = \"\"\n            else:\n                decl.cache.full_partial_name = \\\n                    full_name_from_declaration_path(path)\n        return decl.cache.full_partial_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a reference to a named parent declaration.", "response": "def get_named_parent(decl):\n    \"\"\"\n    Returns a reference to a named parent declaration.\n\n    Args:\n        decl (declaration_t): the child declaration\n\n    Returns:\n        declaration_t: the declaration or None if not found.\n\n    \"\"\"\n\n    if not decl:\n        return None\n\n    parent = decl.parent\n    while parent and (not parent.name or parent.name == '::'):\n        parent = parent.parent\n    return parent"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting the declarations tree rooted at each of the included nodes.", "response": "def print_declarations(\n        decls,\n        detailed=True,\n        recursive=True,\n        writer=lambda x: sys.stdout.write(x + os.linesep),\n        verbose=True):\n    \"\"\"\n    print declarations tree rooted at each of the included nodes.\n\n    :param decls: either a single :class:declaration_t object or list\n        of :class:declaration_t objects\n    \"\"\"\n    prn = decl_printer_t(0, detailed, recursive, writer, verbose=verbose)\n    if not isinstance(decls, list):\n        decls = [decls]\n    for d in decls:\n        prn.level = 0\n        prn.instance = d\n        algorithm.apply_visitor(prn, d)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_declarations(declarations, file_path):\n\n    with open(file_path, \"w+\") as f:\n        print_declarations(declarations, writer=f.write)", "response": "Dump declarations tree rooted at each of the included nodes to a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd all additional defined and undefined symbols.", "response": "def __add_symbols(self, cmd):\n        \"\"\"\n        Add all additional defined and undefined symbols.\n\n        \"\"\"\n\n        if self.__config.define_symbols:\n            symbols = self.__config.define_symbols\n            cmd.append(''.join(\n                [' -D\"%s\"' % def_symbol for def_symbol in symbols]))\n\n        if self.__config.undefine_symbols:\n            un_symbols = self.__config.undefine_symbols\n            cmd.append(''.join(\n                [' -U\"%s\"' % undef_symbol for undef_symbol in un_symbols]))\n\n        return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_xml_file(self, source_file, destination=None):\n\n        xml_file = destination\n        # If file specified, remove it to start else create new file name\n        if xml_file:\n            utils.remove_file_no_raise(xml_file, self.__config)\n        else:\n            xml_file = utils.create_temp_file_name(suffix='.xml')\n\n        ffname = source_file\n        if not os.path.isabs(ffname):\n            ffname = self.__file_full_name(source_file)\n        command_line = self.__create_command_line(ffname, xml_file)\n\n        process = subprocess.Popen(\n            args=command_line,\n            shell=True,\n            stdout=subprocess.PIPE)\n\n        try:\n            results = []\n            while process.poll() is None:\n                line = process.stdout.readline()\n                if line.strip():\n                    results.append(line.rstrip())\n            for line in process.stdout.readlines():\n                if line.strip():\n                    results.append(line.rstrip())\n\n            exit_status = process.returncode\n            msg = os.linesep.join([str(s) for s in results])\n            if self.__config.ignore_gccxml_output:\n                if not os.path.isfile(xml_file):\n                    raise RuntimeError(\n                        \"Error occurred while running \" +\n                        self.__config.xml_generator.upper() +\n                        \": %s status:%s\" %\n                        (msg, exit_status))\n            else:\n                if msg or exit_status or not \\\n                        os.path.isfile(xml_file):\n                    if not os.path.isfile(xml_file):\n                        raise RuntimeError(\n                            \"Error occurred while running \" +\n                            self.__config.xml_generator.upper() +\n                            \" xml file does not exist\")\n                    else:\n                        raise RuntimeError(\n                            \"Error occurred while running \" +\n                            self.__config.xml_generator.upper() +\n                            \": %s status:%s\" % (msg, exit_status))\n        except Exception:\n            utils.remove_file_no_raise(xml_file, self.__config)\n            raise\n        finally:\n            process.wait()\n            process.stdout.close()\n        return xml_file", "response": "This method will generate a xml file from a source file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_xml_file_from_string(self, content, destination=None):\n        header_file = utils.create_temp_file_name(suffix='.h')\n\n        try:\n            with open(header_file, \"w+\") as header:\n                header.write(content)\n            xml_file = self.create_xml_file(header_file, destination)\n        finally:\n            utils.remove_file_no_raise(header_file, self.__config)\n        return xml_file", "response": "Creates XML file from text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the C ++ source file and returns the declarations tree.", "response": "def read_cpp_source_file(self, source_file):\n        \"\"\"\n        Reads C++ source file and returns declarations tree\n\n        :param source_file: path to C++ source file\n        :type source_file: str\n\n        \"\"\"\n\n        xml_file = ''\n        try:\n            ffname = self.__file_full_name(source_file)\n            self.logger.debug(\"Reading source file: [%s].\", ffname)\n            decls = self.__dcache.cached_value(ffname, self.__config)\n            if not decls:\n                self.logger.debug(\n                    \"File has not been found in cache, parsing...\")\n                xml_file = self.create_xml_file(ffname)\n                decls, files = self.__parse_xml_file(xml_file)\n                self.__dcache.update(\n                    ffname, self.__config, decls, files)\n            else:\n                self.logger.debug((\n                    \"File has not been changed, reading declarations \" +\n                    \"from cache.\"))\n        except Exception:\n            if xml_file:\n                utils.remove_file_no_raise(xml_file, self.__config)\n            raise\n        if xml_file:\n            utils.remove_file_no_raise(xml_file, self.__config)\n\n        return decls"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_xml_file(self, xml_file):\n\n        assert self.__config is not None\n\n        ffname = self.__file_full_name(xml_file)\n        self.logger.debug(\"Reading xml file: [%s]\", xml_file)\n        decls = self.__dcache.cached_value(ffname, self.__config)\n        if not decls:\n            self.logger.debug(\"File has not been found in cache, parsing...\")\n            decls, _ = self.__parse_xml_file(ffname)\n            self.__dcache.update(ffname, self.__config, decls, [])\n        else:\n            self.logger.debug(\n                \"File has not been changed, reading declarations from cache.\")\n\n        return decls", "response": "Read generated XML file and return declarations tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a Python string that contains C ++ code and returns the declarations tree.", "response": "def read_string(self, content):\n        \"\"\"\n        Reads a Python string that contains C++ code, and return\n        the declarations tree.\n\n        \"\"\"\n\n        header_file = utils.create_temp_file_name(suffix='.h')\n        with open(header_file, \"w+\") as f:\n            f.write(content)\n\n        try:\n            decls = self.read_file(header_file)\n        except Exception:\n            utils.remove_file_no_raise(header_file, self.__config)\n            raise\n        utils.remove_file_no_raise(header_file, self.__config)\n\n        return decls"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies a visitor on declaration instance.", "response": "def apply_visitor(visitor, decl_inst):\n    \"\"\"\n    Applies a visitor on declaration instance.\n\n    :param visitor: instance\n    :type visitor: :class:`type_visitor_t` or :class:`decl_visitor_t`\n\n    \"\"\"\n\n    fname = 'visit_' + \\\n        decl_inst.__class__.__name__[:-2]  # removing '_t' from class name\n    if not hasattr(visitor, fname):\n        raise runtime_errors.visit_function_has_not_been_found_t(\n            visitor, decl_inst)\n    return getattr(visitor, fname)()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef does_match_exist(self, inst):\n\n        answer = True\n        if self._decl_type is not None:\n            answer &= isinstance(inst, self._decl_type)\n        if self.name is not None:\n            answer &= inst.name == self.name\n        if self.parent is not None:\n            answer &= self.parent is inst.parent\n        if self.fullname is not None:\n            if inst.name:\n                answer &= self.fullname == declaration_utils.full_name(inst)\n            else:\n                answer = False\n        return answer", "response": "Returns True if inst does match one of the specified criteria."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the name of the class that should be used for the partial name.", "response": "def partial_name(self):\n        \"\"\"\n        Declaration name, without template default arguments.\n\n        Right now std containers is the only classes that support this\n        functionality.\n\n        \"\"\"\n\n        if None is self._partial_name:\n            self._partial_name = self._get_partial_name_impl()\n\n        return self._partial_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef top_parent(self):\n        parent = self.parent\n        while parent is not None:\n            if parent.parent is None:\n                return parent\n            else:\n                parent = parent.parent\n        return self", "response": "Return the top parent of the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct new argument_t instance", "response": "def clone(self, **keywd):\n        \"\"\"constructs new argument_t instance\n\n        return argument_t(\n            name=keywd.get('name', self.name),\n            decl_type=keywd.get('decl_type', self.decl_type),\n            default_value=keywd.get('default_value', self.default_value),\n            attributes=keywd.get('attributes', self.attributes ))\n\n        \"\"\"\n        return argument_t(\n            name=keywd.get('name', self.name),\n            decl_type=keywd.get('decl_type', self.decl_type),\n            default_value=keywd.get('default_value', self.default_value),\n            attributes=keywd.get('attributes', self.attributes))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef required_args(self):\n        r_args = []\n        for arg in self.arguments:\n            if not arg.default_value:\n                r_args.append(arg)\n            else:\n                break\n        return r_args", "response": "list of all required arguments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef overloads(self):\n        if not self.parent:\n            return []\n        # finding all functions with the same name\n        return self.parent.calldefs(\n            name=self.name,\n            function=lambda decl: decl is not self,\n            allow_empty=True,\n            recursive=False)", "response": "A list of overloaded callables."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction calling convention. See class for possible values", "response": "def calling_convention(self):\n        \"\"\"function calling convention. See\n            :class:CALLING_CONVENTION_TYPES class for possible values\"\"\"\n        if self._calling_convention is None:\n            self._calling_convention = \\\n                calldef_types.CALLING_CONVENTION_TYPES.extract(self.attributes)\n            if not self._calling_convention:\n                self._calling_convention = self.guess_calling_convention()\n        return self._calling_convention"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn function type. See type_t hierarchy", "response": "def function_type(self):\n        \"\"\"returns function type. See :class:`type_t` hierarchy\"\"\"\n        return cpptypes.free_function_type_t(\n            return_type=self.return_type,\n            arguments_types=[\n                arg.decl_type for arg in self.arguments])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef class_types(self):\n\n        if None is self.__class_types:\n            self.__class_types = []\n            for type_ in self.argument_types:\n                decl = None\n                type_ = type_traits.remove_reference(type_)\n                if type_traits_classes.is_class(type_):\n                    decl = type_traits_classes.class_traits.get_declaration(\n                        type_)\n                elif type_traits_classes.is_class_declaration(type_):\n                    tt = type_traits_classes.class_declaration_traits\n                    decl = tt.get_declaration(type_)\n                else:\n                    pass\n                if decl:\n                    self.__class_types.append(decl)\n        return self.__class_types", "response": "list of class declaration types extracted from the the\n operator arguments"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a signature for a file.", "response": "def file_signature(filename):\n    \"\"\"\n    Return a signature for a file.\n\n    \"\"\"\n\n    if not os.path.isfile(filename):\n        return None\n    if not os.path.exists(filename):\n        return None\n\n    # Duplicate auto-generated files can be recognized with the sha1 hash.\n    sig = hashlib.sha1()\n    with open(filename, \"rb\") as f:\n        buf = f.read()\n        sig.update(buf)\n\n    return sig.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configuration_signature(config):\n\n    sig = hashlib.sha1()\n    if isinstance(config, cxx_parsers_cfg.xml_generator_configuration_t):\n        sig.update(str(config.xml_generator_path).encode())\n    sig.update(str(config.working_directory).encode('utf-8'))\n    if isinstance(config, cxx_parsers_cfg.xml_generator_configuration_t):\n        sig.update(str(config.cflags).encode('utf-8'))\n    for p in config.include_paths:\n        sig.update(str(p).encode('utf-8'))\n    for s in config.define_symbols:\n        sig.update(str(s).encode('utf-8'))\n    for u in config.undefine_symbols:\n        sig.update(str(u).encode('utf-8'))\n    return sig.hexdigest()", "response": "Returns a signature for a configuration object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __load(file_name):\n\n        if os.path.exists(file_name) and not os.path.isfile(file_name):\n            raise RuntimeError(\n                'Cache should be initialized with valid full file name')\n        if not os.path.exists(file_name):\n            open(file_name, 'w+b').close()\n            return {}\n        cache_file_obj = open(file_name, 'rb')\n        try:\n            file_cache_t.logger.info('Loading cache file \"%s\".', file_name)\n            start_time = timeit.default_timer()\n            cache = pickle.load(cache_file_obj)\n            file_cache_t.logger.debug(\n                \"Cache file has been loaded in %.1f secs\",\n                (timeit.default_timer() - start_time))\n            file_cache_t.logger.debug(\n                \"Found cache in file: [%s]  entries: %s\",\n                file_name, len(list(cache.keys())))\n        except (pickle.UnpicklingError, AttributeError, EOFError,\n                ImportError, IndexError) as error:\n            file_cache_t.logger.exception(\n                \"Error occurred while reading cache file: %s\",\n                error)\n            cache_file_obj.close()\n            file_cache_t.logger.info(\n                \"Invalid cache file: [%s]  Regenerating.\",\n                file_name)\n            open(file_name, 'w+b').close()   # Create empty file\n            cache = {}                       # Empty cache\n        finally:\n            cache_file_obj.close()\n        return cache", "response": "Loads pickled cache from file and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates a cached record with the current key and value contents.", "response": "def update(self, source_file, configuration, declarations, included_files):\n        \"\"\" Update a cached record with the current key and value contents. \"\"\"\n\n        record = record_t(\n            source_signature=file_signature(source_file),\n            config_signature=configuration_signature(configuration),\n            included_files=included_files,\n            included_files_signature=list(\n                map(\n                    file_signature,\n                    included_files)),\n            declarations=declarations)\n        # Switched over to holding full record in cache so we don't have\n        # to keep creating records in the next method.\n        self.__cache[record.key()] = record\n        self.__cache[record.key()].was_hit = True\n        self.__needs_flushed = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the cached value for the given file and configuration.", "response": "def cached_value(self, source_file, configuration):\n        \"\"\"\n        Attempt to lookup the cached declarations for the given file and\n        configuration.\n\n        Returns None if declaration not found or signature check fails.\n\n        \"\"\"\n\n        key = record_t.create_key(source_file, configuration)\n        if key not in self.__cache:\n            return None\n        record = self.__cache[key]\n        if self.__is_valid_signature(record):\n            record.was_hit = True  # Record cache hit\n            return record.declarations\n\n        # some file has been changed\n        del self.__cache[key]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instance(self, inst):\n\n        self.__inst = inst\n\n        # use inst, to reduce attribute access time\n        if isinstance(inst, declarations.declaration_t) and \\\n                inst.location is not None and \\\n                inst.location.file_name != '':\n            inst.location.file_name = self.__files[inst.location.file_name]", "response": "Set the instance of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_version(file_path):\n\n    with io.open(\n            os.path.join(\n                os.path.dirname(__file__),\n                os.path.normpath(file_path)),\n            encoding=\"utf8\") as fp:\n        content = fp.read()\n\n    version_match = re.search(r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\",\n                              content, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(\"Unable to find version string.\")", "response": "Find the version of the catalinse."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing duck typing to set the size instead of in constructor", "response": "def __read_byte_size(decl, attrs):\n        \"\"\"Using duck typing to set the size instead of in constructor\"\"\"\n        size = attrs.get(XML_AN_SIZE, 0)\n        # Make sure the size is in bytes instead of bits\n        decl.byte_size = int(size) / 8"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __read_byte_offset(decl, attrs):\n        offset = attrs.get(XML_AN_OFFSET, 0)\n        # Make sure the size is in bytes instead of bits\n        decl.byte_offset = int(offset) / 8", "response": "Using duck typing to set the offset instead of in constructor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __read_byte_align(decl, attrs):\n        align = attrs.get(XML_AN_ALIGN, 0)\n        # Make sure the size is in bytes instead of bits\n        decl.byte_align = int(align) / 8", "response": "Using duck typing to set the alignment"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbinds aliases between class and typedef.", "response": "def bind_aliases(decls):\n    \"\"\"\n    This function binds between class and it's typedefs.\n\n    :param decls: list of all declarations\n\n    :rtype: None\n\n    \"\"\"\n\n    visited = set()\n    typedefs = [\n        decl for decl in decls if isinstance(decl, declarations.typedef_t)]\n    for decl in typedefs:\n        type_ = declarations.remove_alias(decl.decl_type)\n        if not isinstance(type_, declarations.declarated_t):\n            continue\n        cls_inst = type_.declaration\n        if not isinstance(cls_inst, declarations.class_types):\n            continue\n        if id(cls_inst) not in visited:\n            visited.add(id(cls_inst))\n            del cls_inst.aliases[:]\n        cls_inst.aliases.append(decl)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef before_all(ctx):\n\n    ctx.client = get_client()\n    try:\n        ctx.client.inspect_image(IMAGE)\n    except NotFound:\n        ctx.client.pull(IMAGE)", "response": "Pulls down busybox before anything is tested."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef after_scenario(ctx, scenario):\n\n    if hasattr(ctx, 'container') and hasattr(ctx, 'client'):\n        try:\n            ctx.client.remove_container(ctx.container, force=True)\n        except:\n            pass", "response": "Clean up docker containers used as test fixtures after test completes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the given file - descriptor blocking or non - blocking. Returns the original blocking status.", "response": "def set_blocking(fd, blocking=True):\n    \"\"\"\n    Set the given file-descriptor blocking or non-blocking.\n\n    Returns the original blocking status.\n    \"\"\"\n\n    old_flag = fcntl.fcntl(fd, fcntl.F_GETFL)\n\n    if blocking:\n        new_flag = old_flag & ~ os.O_NONBLOCK\n    else:\n        new_flag = old_flag | os.O_NONBLOCK\n\n    fcntl.fcntl(fd, fcntl.F_SETFL, new_flag)\n\n    return not bool(old_flag & os.O_NONBLOCK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select(read_streams, write_streams, timeout=0):\n\n    exception_streams = []\n\n    try:\n        return builtin_select.select(\n            read_streams,\n            write_streams,\n            exception_streams,\n            timeout,\n        )[0:2]\n    except builtin_select.error as e:\n        # POSIX signals interrupt select()\n        no = e.errno if six.PY3 else e[0]\n        if no == errno.EINTR:\n            return ([], [])\n        else:\n            raise e", "response": "Select the streams from read_streams that are ready for reading and write_streams."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, n=4096):\n\n        while True:\n            try:\n                if hasattr(self.fd, 'recv'):\n                    return self.fd.recv(n)\n                return os.read(self.fd.fileno(), n)\n            except EnvironmentError as e:\n                if e.errno not in Stream.ERRNO_RECOVERABLE:\n                    raise e", "response": "Read n bytes from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data):\n\n        if not data:\n            return None\n\n        self.buffer += data\n        self.do_write()\n\n        return len(data)", "response": "Write data to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the internal buffer to the local file descriptor.", "response": "def do_write(self):\n        \"\"\"\n        Flushes as much pending data from the internal write buffer as possible.\n        \"\"\"\n        while True:\n            try:\n                written = 0\n\n                if hasattr(self.fd, 'send'):\n                    written = self.fd.send(self.buffer)\n                else:\n                    written = os.write(self.fd.fileno(), self.buffer)\n\n                self.buffer = self.buffer[written:]\n\n                # try to close after writes if a close was requested\n                if self.close_requested and len(self.buffer) == 0:\n                    self.close()\n\n                return written\n            except EnvironmentError as e:\n                if e.errno not in Stream.ERRNO_RECOVERABLE:\n                    raise e"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads up to n bytes of data from the stream.", "response": "def read(self, n=4096):\n        \"\"\"\n        Read up to `n` bytes of data from the Stream, after demuxing.\n\n        Less than `n` bytes of data may be returned depending on the available\n        payload, but the number of bytes returned will never exceed `n`.\n\n        Because demuxing involves scanning 8-byte headers, the actual amount of\n        data read from the underlying stream may be greater than `n`.\n        \"\"\"\n\n        size = self._next_packet_size(n)\n\n        if size <= 0:\n            return\n        else:\n            data = six.binary_type()\n            while len(data) < size:\n                nxt = self.stream.read(size - len(data))\n                if not nxt:\n                    # the stream has closed, return what data we got\n                    return data\n                data = data + nxt\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flush(self, n=4096):\n\n        try:\n            read = self.from_stream.read(n)\n\n            if read is None or len(read) == 0:\n                self.eof = True\n                if self.propagate_close:\n                    self.to_stream.close()\n                return None\n\n            return self.to_stream.write(read)\n        except OSError as e:\n            if e.errno != errno.EPIPE:\n                raise e", "response": "Flushes n bytes of data from the reader Stream to the writer Stream. Returns the number of bytes that were actually flushed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_done(self):\n\n        return (not self.wait_for_output or self.eof) and \\\n                not (hasattr(self.to_stream, 'needs_write') and self.to_stream.needs_write())", "response": "Returns True if the read stream is done."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts a container inside the current process.", "response": "def start(client, container, interactive=True, stdout=None, stderr=None, stdin=None, logs=None):\n    \"\"\"\n    Present the PTY of the container inside the current process.\n\n    This is just a wrapper for PseudoTerminal(client, container).start()\n    \"\"\"\n\n    operation = RunOperation(client, container, interactive=interactive, stdout=stdout,\n                             stderr=stderr, stdin=stdin, logs=logs)\n\n    PseudoTerminal(client, operation).start()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning provided command via exec API in provided container.", "response": "def exec_command(\n        client, container, command, interactive=True, stdout=None, stderr=None, stdin=None):\n    \"\"\"\n    Run provided command via exec API in provided container.\n\n    This is just a wrapper for PseudoTerminal(client, container).exec_command()\n    \"\"\"\n    exec_id = exec_create(client, container, command, interactive=interactive)\n\n    operation = ExecOperation(client, exec_id,\n                              interactive=interactive, stdout=stdout, stderr=stderr, stdin=stdin)\n    PseudoTerminal(client, operation).start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef size(fd):\n\n    if not os.isatty(fd.fileno()):\n        return None\n\n    try:\n        dims = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ, 'hhhh'))\n    except:\n        try:\n            dims = (os.environ['LINES'], os.environ['COLUMNS'])\n        except:\n            return None\n\n    return dims", "response": "Returns a tuple containing the rows and cols of the TTY."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current terminal attributes and makes the tty raw. This method returns None immediately.", "response": "def start(self):\n        \"\"\"\n        Saves the current terminal attributes and makes the tty raw.\n\n        This method returns None immediately.\n        \"\"\"\n\n        if os.isatty(self.fd.fileno()) and self.israw():\n            self.original_attributes = termios.tcgetattr(self.fd)\n            tty.setraw(self.fd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestores the terminal attributes back to before setting raw mode.", "response": "def stop(self):\n        \"\"\"\n        Restores the terminal attributes back to before setting raw mode.\n\n        If the raw terminal was not started, does nothing.\n        \"\"\"\n\n        if self.original_attributes is not None:\n            termios.tcsetattr(\n                self.fd,\n                termios.TCSADRAIN,\n                self.original_attributes,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n\n        def handle(signum, frame):\n            if signum == signal.SIGWINCH:\n                self.pty.resize()\n\n        self.original_handler = signal.signal(signal.SIGWINCH, handle)", "response": "Start trapping WINCH signals and resizing the PTY."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping trapping WINCH signals and restore the previous WINCH handler.", "response": "def stop(self):\n        \"\"\"\n        Stop trapping WINCH signals and restore the previous WINCH handler.\n        \"\"\"\n\n        if self.original_handler is not None:\n            signal.signal(signal.SIGWINCH, self.original_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, sockets=None, **kwargs):\n\n        pty_stdin, pty_stdout, pty_stderr = sockets or self.sockets()\n        pumps = []\n\n        if pty_stdin and self.interactive:\n            pumps.append(io.Pump(io.Stream(self.stdin), pty_stdin, wait_for_output=False))\n\n        if pty_stdout:\n            pumps.append(io.Pump(pty_stdout, io.Stream(self.stdout), propagate_close=False))\n\n        if pty_stderr:\n            pumps.append(io.Pump(pty_stderr, io.Stream(self.stderr), propagate_close=False))\n\n        if not self._container_info()['State']['Running']:\n            self.client.start(self.container, **kwargs)\n\n        return pumps", "response": "Present the PTY of the container inside the current process.\n\n        This will take over the current process' TTY until the container's PTY\n        is closed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the PTY should operate in raw mode False otherwise.", "response": "def israw(self, **kwargs):\n        \"\"\"\n        Returns True if the PTY should operate in raw mode.\n\n        If the container was not started with tty=True, this will return False.\n        \"\"\"\n\n        if self.raw is None:\n            info = self._container_info()\n            self.raw = self.stdout.isatty() and info['Config']['Tty']\n\n        return self.raw"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple of sockets connected to the pty.", "response": "def sockets(self):\n        \"\"\"\n        Returns a tuple of sockets connected to the pty (stdin,stdout,stderr).\n\n        If any of the sockets are not attached in the container, `None` is\n        returned in the tuple.\n        \"\"\"\n\n        info = self._container_info()\n\n        def attach_socket(key):\n            if info['Config']['Attach{0}'.format(key.capitalize())]:\n                socket = self.client.attach_socket(\n                    self.container,\n                    {key: 1, 'stream': 1, 'logs': self.logs},\n                )\n                stream = io.Stream(socket)\n\n                if info['Config']['Tty']:\n                    return stream\n                else:\n                    return io.Demuxer(stream)\n            else:\n                return None\n\n        return map(attach_socket, ('stdin', 'stdout', 'stderr'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the PTY should operate in raw mode False otherwise.", "response": "def israw(self, **kwargs):\n        \"\"\"\n        Returns True if the PTY should operate in raw mode.\n\n        If the exec was not started with tty=True, this will return False.\n        \"\"\"\n\n        if self.raw is None:\n            self.raw = self.stdout.isatty() and self.is_process_tty()\n\n        return self.raw"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a single socket which is processing all I / O to exec", "response": "def sockets(self):\n        \"\"\"\n        Return a single socket which is processing all I/O to exec\n        \"\"\"\n        socket = self.client.exec_start(self.exec_id, socket=True, tty=self.interactive)\n        stream = io.Stream(socket)\n        if self.is_process_tty():\n            return stream\n        else:\n            return io.Demuxer(stream)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _exec_info(self):\n        if self._info is None:\n            self._info = self.client.exec_inspect(self.exec_id)\n        return self._info", "response": "Get the exec info for this process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resize(self, size=None):\n\n        if not self.operation.israw():\n            return\n\n        size = size or tty.size(self.operation.stdout)\n\n        if size is not None:\n            rows, cols = size\n            try:\n                self.operation.resize(height=rows, width=cols)\n            except IOError:  # Container already exited\n                pass", "response": "Resize the container s PTY."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_number(x):\n\n    if isinstance(x, float):\n        # Helps prevent loss of precision as using str() in Python 2 only prints 12 digits of precision.\n        # However, IEEE754-1985 standard says that 17 significant decimal digits is required to adequately represent a\n        # floating point number.\n        # The g option is used rather than f because g precision uses significant digits while f is just the number of\n        # digits after the decimal. (NRRD C implementation uses g).\n        value = '{:.17g}'.format(x)\n    else:\n        value = str(x)\n\n    return value", "response": "Format number to string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats a NRRD optional vector string", "response": "def format_optional_vector(x):\n    \"\"\"Format a (N,) :class:`numpy.ndarray` into a NRRD optional vector string\n\n    Function converts a (N,) :class:`numpy.ndarray` or :obj:`None` into a string using NRRD vector format. If the input\n    :obj:`x` is :obj:`None`, then :obj:`vector` will be 'none'\n\n    See :ref:`user-guide:int vector` and :ref:`user-guide:double vector` for more information on the format.\n\n    Parameters\n    ----------\n    x : (N,) :class:`numpy.ndarray` or :obj:`None`\n        Vector to convert to NRRD vector string\n\n    Returns\n    -------\n    vector : :class:`str`\n        String containing NRRD vector\n    \"\"\"\n\n    # If vector is None or all elements are NaN, then return none\n    # Otherwise format the vector as normal\n    if x is None or np.all(np.isnan(x)):\n        return 'none'\n    else:\n        return format_vector(x)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(filename, data, header=None, detached_header=False, relative_data_path=True, custom_field_map=None,\n          compression_level=9, index_order='F'):\n    \"\"\"Write :class:`numpy.ndarray` to NRRD file\n\n    The :obj:`filename` parameter specifies the absolute or relative filename to write the NRRD file to. If the\n    :obj:`filename` extension is .nhdr, then the :obj:`detached_header` parameter is set to true automatically. If the\n    :obj:`detached_header` parameter is set to :obj:`True` and the :obj:`filename` ends in .nrrd, then the header file\n    will have the same path and base name as the :obj:`filename` but with an extension of .nhdr. In all other cases,\n    the header and data are saved in the same file.\n\n    :obj:`header` is an optional parameter containing the fields and values to be added to the NRRD header.\n\n    .. note::\n            The following fields are automatically generated based on the :obj:`data` parameter ignoring these values\n            in the :obj:`header`: 'type', 'endian', 'dimension', 'sizes'. In addition, the generated fields will be\n            added to the given :obj:`header`. Thus, one can check the generated fields by viewing the passed\n            :obj:`header`.\n\n    .. note::\n            The default encoding field used if not specified in :obj:`header` is 'gzip'.\n\n    .. note::\n            The :obj:`index_order` parameter must be consistent with the index order specified in :meth:`read`.\n            Reading an NRRD file in C-order and then writing as Fortran-order or vice versa will result in the data\n            being transposed in the NRRD file.\n\n    See :ref:`user-guide:Writing NRRD files` for more information on writing NRRD files.\n\n    Parameters\n    ----------\n    filename : :class:`str`\n        Filename of the NRRD file\n    data : :class:`numpy.ndarray`\n        Data to save to the NRRD file\n    detached_header : :obj:`bool`, optional\n        Whether the header and data should be saved in separate files. Defaults to :obj:`False`\n    relative_data_path : :class:`bool`\n        Whether the data filename in detached header is saved with a relative path or absolute path.\n        This parameter is ignored if there is no detached header. Defaults to :obj:`True`\n    custom_field_map : :class:`dict` (:class:`str`, :class:`str`), optional\n        Dictionary used for parsing custom field types where the key is the custom field name and the value is a\n        string identifying datatype for the custom field.\n    compression_level : :class:`int`\n        Integer between 1 to 9 specifying the compression level when using a compressed encoding (gzip or bzip). A value\n        of :obj:`1` compresses the data the least amount and is the fastest, while a value of :obj:`9` compresses the\n        data the most and is the slowest.\n    index_order : {'C', 'F'}, optional\n        Specifies the index order used for writing. Either 'C' (C-order) where the dimensions are ordered from\n        slowest-varying to fastest-varying (e.g. (z, y, x)), or 'F' (Fortran-order) where the dimensions are ordered\n        from fastest-varying to slowest-varying (e.g. (x, y, z)).\n\n    See Also\n    --------\n    :meth:`read`, :meth:`read_header`, :meth:`read_data`\n    \"\"\"\n\n    if header is None:\n        header = {}\n\n    # Infer a number of fields from the NumPy array and overwrite values in the header dictionary.\n    # Get type string identifier from the NumPy datatype\n    header['type'] = _TYPEMAP_NUMPY2NRRD[data.dtype.str[1:]]\n\n    # If the datatype contains more than one byte and the encoding is not ASCII, then set the endian header value\n    # based on the datatype's endianness. Otherwise, delete the endian field from the header if present\n    if data.dtype.itemsize > 1 and header.get('encoding', '').lower() not in ['ascii', 'text', 'txt']:\n        header['endian'] = _NUMPY2NRRD_ENDIAN_MAP[data.dtype.str[:1]]\n    elif 'endian' in header:\n        del header['endian']\n\n    # If space is specified in the header, then space dimension can not. See\n    # http://teem.sourceforge.net/nrrd/format.html#space\n    if 'space' in header.keys() and 'space dimension' in header.keys():\n        del header['space dimension']\n\n    # Update the dimension and sizes fields in the header based on the data. Since NRRD expects meta data to be in\n    # Fortran order we are required to reverse the shape in the case of the array being in C order. E.g., data was read\n    # using index_order='C'.\n    header['dimension'] = data.ndim\n    header['sizes'] = list(data.shape) if index_order == 'F' else list(data.shape[::-1])\n\n    # The default encoding is 'gzip'\n    if 'encoding' not in header:\n        header['encoding'] = 'gzip'\n\n    # A bit of magic in handling options here.\n    # If *.nhdr filename provided, this overrides `detached_header=False`\n    # If *.nrrd filename provided AND detached_header=True, separate header and data files written.\n    # If detached_header=True and data file is present, then write the files separately\n    # For all other cases, header & data written to same file.\n    if filename.endswith('.nhdr'):\n        detached_header = True\n\n        if 'data file' not in header:\n            # Get the base filename without the extension\n            base_filename = os.path.splitext(filename)[0]\n\n            # Get the appropriate data filename based on encoding, see here for information on the standard detached\n            # filename: http://teem.sourceforge.net/nrrd/format.html#encoding\n            if header['encoding'] == 'raw':\n                data_filename = '%s.raw' % base_filename\n            elif header['encoding'] in ['ASCII', 'ascii', 'text', 'txt']:\n                data_filename = '%s.txt' % base_filename\n            elif header['encoding'] in ['gzip', 'gz']:\n                data_filename = '%s.raw.gz' % base_filename\n            elif header['encoding'] in ['bzip2', 'bz2']:\n                data_filename = '%s.raw.bz2' % base_filename\n            else:\n                raise NRRDError('Invalid encoding specification while writing NRRD file: %s' % header['encoding'])\n\n            header['data file'] = os.path.basename(data_filename) \\\n                if relative_data_path else os.path.abspath(data_filename)\n        else:\n            # TODO This will cause issues for relative data files because it will not save in the correct spot\n            data_filename = header['data file']\n    elif filename.endswith('.nrrd') and detached_header:\n        data_filename = filename\n        header['data file'] = os.path.basename(data_filename) \\\n            if relative_data_path else os.path.abspath(data_filename)\n        filename = '%s.nhdr' % os.path.splitext(filename)[0]\n    else:\n        # Write header & data as one file\n        data_filename = filename\n        detached_header = False\n\n    with open(filename, 'wb') as fh:\n        fh.write(b'NRRD0005\\n')\n        fh.write(b'# This NRRD file was generated by pynrrd\\n')\n        fh.write(b'# on ' + datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S').encode('ascii') + b'(GMT).\\n')\n        fh.write(b'# Complete NRRD file format specification at:\\n')\n        fh.write(b'# http://teem.sourceforge.net/nrrd/format.html\\n')\n\n        # Copy the options since dictionaries are mutable when passed as an argument\n        # Thus, to prevent changes to the actual options, a copy is made\n        # Empty ordered_options list is made (will be converted into dictionary)\n        local_options = header.copy()\n        ordered_options = []\n\n        # Loop through field order and add the key/value if present\n        # Remove the key/value from the local options so that we know not to add it again\n        for field in _NRRD_FIELD_ORDER:\n            if field in local_options:\n                ordered_options.append((field, local_options[field]))\n                del local_options[field]\n\n        # Leftover items are assumed to be the custom field/value options\n        # So get current size and any items past this index will be a custom value\n        custom_field_start_index = len(ordered_options)\n\n        # Add the leftover items to the end of the list and convert the options into a dictionary\n        ordered_options.extend(local_options.items())\n        ordered_options = OrderedDict(ordered_options)\n\n        for x, (field, value) in enumerate(ordered_options.items()):\n            # Get the field_type based on field and then get corresponding\n            # value as a str using _format_field_value\n            field_type = _get_field_type(field, custom_field_map)\n            value_str = _format_field_value(value, field_type)\n\n            # Custom fields are written as key/value pairs with a := instead of : delimeter\n            if x >= custom_field_start_index:\n                fh.write(('%s:=%s\\n' % (field, value_str)).encode('ascii'))\n            else:\n                fh.write(('%s: %s\\n' % (field, value_str)).encode('ascii'))\n\n        # Write the closing extra newline\n        fh.write(b'\\n')\n\n        # If header & data in the same file is desired, write data in the file\n        if not detached_header:\n            _write_data(data, fh, header, compression_level=compression_level, index_order=index_order)\n\n    # If detached header desired, write data to different file\n    if detached_header:\n        with open(data_filename, 'wb') as data_fh:\n            _write_data(data, data_fh, header, compression_level=compression_level, index_order=index_order)", "response": "Writes a numpy array to a NRRD file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse NRRD vector from string into NumPy array.", "response": "def parse_vector(x, dtype=None):\n    \"\"\"Parse NRRD vector from string into (N,) :class:`numpy.ndarray`.\n\n    See :ref:`user-guide:int vector` and :ref:`user-guide:double vector` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD vector\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking any of the vector elements\n        for fractional numbers. If found, then the vector will be converted to :class:`float`, otherwise :class:`int`.\n        Default is to automatically determine datatype.\n\n    Returns\n    -------\n    vector : (N,) :class:`numpy.ndarray`\n        Vector that is parsed from the :obj:`x` string\n    \"\"\"\n\n    if x[0] != '(' or x[-1] != ')':\n        raise NRRDError('Vector should be enclosed by parentheses.')\n\n    # Always convert to float and then truncate to integer if desired\n    # The reason why is parsing a floating point string to int will fail (i.e. int('25.1') will fail)\n    vector = np.array([float(x) for x in x[1:-1].split(',')])\n\n    # If using automatic datatype detection, then start by converting to float and determining if the number is whole\n    # Truncate to integer if dtype is int also\n    if dtype is None:\n        vector_trunc = vector.astype(int)\n\n        if np.all((vector - vector_trunc) == 0):\n            vector = vector_trunc\n    elif dtype == int:\n        vector = vector.astype(int)\n    elif dtype != float:\n        raise NRRDError('dtype should be None for automatic type detection, float or int')\n\n    return vector"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing NRRD matrix from string into a NRRD array.", "response": "def parse_matrix(x, dtype=None):\n    \"\"\"Parse NRRD matrix from string into (M,N) :class:`numpy.ndarray`.\n\n    See :ref:`user-guide:int matrix` and :ref:`user-guide:double matrix` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD matrix\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking any of the elements\n        for fractional numbers. If found, then the matrix will be converted to :class:`float`, otherwise :class:`int`.\n        Default is to automatically determine datatype.\n\n    Returns\n    -------\n    matrix : (M,N) :class:`numpy.ndarray`\n        Matrix that is parsed from the :obj:`x` string\n    \"\"\"\n\n    # Split input by spaces, convert each row into a vector and stack them vertically to get a matrix\n    matrix = [parse_vector(x, dtype=float) for x in x.split()]\n\n    # Get the size of each row vector and then remove duplicate sizes\n    # There should be exactly one value in the matrix because all row sizes need to be the same\n    if len(np.unique([len(x) for x in matrix])) != 1:\n        raise NRRDError('Matrix should have same number of elements in each row')\n\n    matrix = np.vstack(matrix)\n\n    # If using automatic datatype detection, then start by converting to float and determining if the number is whole\n    # Truncate to integer if dtype is int also\n    if dtype is None:\n        matrix_trunc = matrix.astype(int)\n\n        if np.all((matrix - matrix_trunc) == 0):\n            matrix = matrix_trunc\n    elif dtype == int:\n        matrix = matrix.astype(int)\n    elif dtype != float:\n        raise NRRDError('dtype should be None for automatic type detection, float or int')\n\n    return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses optional NRRD matrix from string into (M,N) :class:`numpy.ndarray` of :class:`float`. Function parses optional NRRD matrix from string into an (M,N) :class:`numpy.ndarray` of :class:`float`. This function works the same as :meth:`parse_matrix` except if a row vector in the matrix is none, the resulting row in the returned matrix will be all NaNs. See :ref:`user-guide:double matrix` for more information on the format. Parameters ---------- x : :class:`str` String containing NRRD matrix Returns ------- matrix : (M,N) :class:`numpy.ndarray` of :class:`float` Matrix that is parsed from the :obj:`x` string", "response": "def parse_optional_matrix(x):\n    \"\"\"Parse optional NRRD matrix from string into (M,N) :class:`numpy.ndarray` of :class:`float`.\n\n    Function parses optional NRRD matrix from string into an (M,N) :class:`numpy.ndarray` of :class:`float`. This\n    function works the same as :meth:`parse_matrix` except if a row vector in the matrix is none, the resulting row in\n    the returned matrix will be all NaNs.\n\n    See :ref:`user-guide:double matrix` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD matrix\n\n    Returns\n    -------\n    matrix : (M,N) :class:`numpy.ndarray` of :class:`float`\n        Matrix that is parsed from the :obj:`x` string\n    \"\"\"\n\n    # Split input by spaces to get each row and convert into a vector. The row can be 'none', in which case it will\n    # return None\n    matrix = [parse_optional_vector(x, dtype=float) for x in x.split()]\n\n    # Get the size of each row vector, 0 if None\n    sizes = np.array([0 if x is None else len(x) for x in matrix])\n\n    # Get sizes of each row vector removing duplicate sizes\n    # Since each row vector should be same size, the unique sizes should return one value for the row size or it may\n    # return a second one (0) if there are None vectors\n    unique_sizes = np.unique(sizes)\n\n    if len(unique_sizes) != 1 and (len(unique_sizes) != 2 or unique_sizes.min() != 0):\n        raise NRRDError('Matrix should have same number of elements in each row')\n\n    # Create a vector row of NaN's that matches same size of remaining vector rows\n    # Stack the vector rows together to create matrix\n    nan_row = np.full((unique_sizes.max()), np.nan)\n    matrix = np.vstack([nan_row if x is None else x for x in matrix])\n\n    return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing NRRD number list from string into vector.", "response": "def parse_number_list(x, dtype=None):\n    \"\"\"Parse NRRD number list from string into (N,) :class:`numpy.ndarray`.\n\n    See :ref:`user-guide:int list` and :ref:`user-guide:double list` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD number list\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking for fractional numbers. If\n        found, then the string will be converted to :class:`float`, otherwise :class:`int`. Default is to automatically\n        determine datatype.\n\n    Returns\n    -------\n    vector : (N,) :class:`numpy.ndarray`\n        Vector that is parsed from the :obj:`x` string\n    \"\"\"\n\n    # Always convert to float and then perform truncation to integer if necessary\n    number_list = np.array([float(x) for x in x.split()])\n\n    if dtype is None:\n        number_list_trunc = number_list.astype(int)\n\n        # If there is no difference between the truncated number list and the number list, then that means that the\n        # number list was all integers and we can just return that\n        if np.all((number_list - number_list_trunc) == 0):\n            number_list = number_list_trunc\n    elif dtype == int:\n        number_list = number_list.astype(int)\n    elif dtype != float:\n        raise NRRDError('dtype should be None for automatic type detection, float or int')\n\n    return number_list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_number_auto_dtype(x):\n\n    value = float(x)\n\n    if value.is_integer():\n        value = int(value)\n\n    return value", "response": "Parse a number from string with automatic type detection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _determine_datatype(fields):\n\n    # Convert the NRRD type string identifier into a NumPy string identifier using a map\n    np_typestring = _TYPEMAP_NRRD2NUMPY[fields['type']]\n\n    # This is only added if the datatype has more than one byte and is not using ASCII encoding\n    # Note: Endian is not required for ASCII encoding\n    if np.dtype(np_typestring).itemsize > 1 and fields['encoding'] not in ['ASCII', 'ascii', 'text', 'txt']:\n        if 'endian' not in fields:\n            raise NRRDError('Header is missing required field: \"endian\".')\n        elif fields['endian'] == 'big':\n            np_typestring = '>' + np_typestring\n        elif fields['endian'] == 'little':\n            np_typestring = '<' + np_typestring\n        else:\n            raise NRRDError('Invalid endian value in header: \"%s\"' % fields['endian'])\n\n    return np.dtype(np_typestring)", "response": "Determine the numpy dtype of the data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the magic line for NRRD files.", "response": "def _validate_magic_line(line):\n    \"\"\"For NRRD files, the first four characters are always \"NRRD\", and\n    remaining characters give information about the file format version\n\n    >>> _validate_magic_line('NRRD0005')\n    8\n    >>> _validate_magic_line('NRRD0006')\n    Traceback (most recent call last):\n        ...\n    NrrdError: NRRD file version too new for this library.\n    >>> _validate_magic_line('NRRD')\n    Traceback (most recent call last):\n        ...\n    NrrdError: Invalid NRRD magic line: NRRD\n    \"\"\"\n\n    if not line.startswith('NRRD'):\n        raise NRRDError('Invalid NRRD magic line. Is this an NRRD file?')\n\n    try:\n        version = int(line[4:])\n        if version > 5:\n            raise NRRDError('Unsupported NRRD file version (version: %i). This library only supports v%i and below.'\n                            % (version, 5))\n    except ValueError:\n        raise NRRDError('Invalid NRRD magic line: %s' % line)\n\n    return len(line)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_header(file, custom_field_map=None):\n\n    # If the file is a filename rather than the file handle, then open the file and call this function again with the\n    # file handle. Since read function uses a filename, it is easy to think read_header is the same syntax.\n    if isinstance(file, str) and file.count('\\n') == 0:\n        with open(file, 'rb') as fh:\n            header = read_header(fh, custom_field_map)\n            return header\n\n    # Collect number of bytes in the file header (for seeking below)\n    header_size = 0\n\n    # Get iterator for the file and extract the first line, the magic line\n    it = iter(file)\n    magic_line = next(it)\n\n    # Depending on what type file is, decoding may or may not be necessary. Decode if necessary, otherwise skip.\n    need_decode = False\n    if hasattr(magic_line, 'decode'):\n        need_decode = True\n        magic_line = magic_line.decode('ascii', 'ignore')\n\n    # Validate the magic line and increment header size by size of the line\n    header_size += _validate_magic_line(magic_line)\n\n    # Create empty header\n    # This is an OrderedDict rather than an ordinary dict because an OrderedDict will keep it's order that key/values\n    # are added for when looping back through it. The added benefit of this is that saving the header will save the\n    # fields in the same order.\n    header = OrderedDict()\n\n    # Loop through each line\n    for line in it:\n        header_size += len(line)\n        if need_decode:\n            line = line.decode('ascii', 'ignore')\n\n        # Trailing whitespace ignored per the NRRD spec\n        line = line.rstrip()\n\n        # Skip comments starting with # (no leading whitespace is allowed)\n        # Or, stop reading the header once a blank line is encountered. This separates header from data.\n        if line.startswith('#'):\n            continue\n        elif line == '':\n            break\n\n        # Read the field and value from the line, split using regex to search for := or : delimiter\n        field, value = re.split(r':=?', line, 1)\n\n        # Remove whitespace before and after the field and value\n        field, value = field.strip(), value.strip()\n\n        # Check if the field has been added already\n        if field in header.keys():\n            dup_message = \"Duplicate header field: '%s'\" % str(field)\n\n            if not ALLOW_DUPLICATE_FIELD:\n                raise NRRDError(dup_message)\n\n            warnings.warn(dup_message)\n\n        # Get the datatype of the field based on it's field name and custom field map\n        field_type = _get_field_type(field, custom_field_map)\n\n        # Parse the field value using the datatype retrieved\n        # Place it in the header dictionary\n        header[field] = _parse_field_value(value, field_type)\n\n    # Reading the file line by line is buffered and so the header is not in the correct position for reading data if\n    # the file contains the data in it as well. The solution is to set the file pointer to just behind the header.\n    if hasattr(file, 'seek'):\n        file.seek(header_size)\n\n    return header", "response": "Reads contents of header and parse values from file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_data(header, fh=None, filename=None, index_order='F'):\n\n    if index_order not in ['F', 'C']:\n        raise NRRDError('Invalid index order')\n\n    # Check that the required fields are in the header\n    for field in _NRRD_REQUIRED_FIELDS:\n        if field not in header:\n            raise NRRDError('Header is missing required field: \"%s\".' % field)\n\n    if header['dimension'] != len(header['sizes']):\n        raise NRRDError('Number of elements in sizes does not match dimension. Dimension: %i, len(sizes): %i' % (\n            header['dimension'], len(header['sizes'])))\n\n    # Determine the data type from the header\n    dtype = _determine_datatype(header)\n\n    # Determine the byte skip, line skip and the data file\n    # These all can be written with or without the space according to the NRRD spec, so we check them both\n    line_skip = header.get('lineskip', header.get('line skip', 0))\n    byte_skip = header.get('byteskip', header.get('byte skip', 0))\n    data_filename = header.get('datafile', header.get('data file', None))\n\n    # If the data file is separate from the header file, then open the data file to read from that instead\n    if data_filename is not None:\n        # If the pathname is relative, then append the current directory from the filename\n        if not os.path.isabs(data_filename):\n            if filename is None:\n                raise NRRDError('Filename parameter must be specified when a relative data file path is given')\n\n            data_filename = os.path.join(os.path.dirname(filename), data_filename)\n\n        # Override the fh parameter with the data filename\n        # Note that this is opened without a \"with\" block, thus it must be closed manually in all circumstances\n        fh = open(data_filename, 'rb')\n\n    # Get the total number of data points by multiplying the size of each dimension together\n    total_data_points = header['sizes'].prod()\n\n    # Skip the number of lines requested when line_skip >= 0\n    # Irrespective of the NRRD file having attached/detached header\n    # Lines are skipped before getting to the beginning of the data\n    if line_skip >= 0:\n        for _ in range(line_skip):\n            fh.readline()\n    else:\n        # Must close the file because if the file was opened above from detached filename, there is no \"with\" block to\n        # close it for us\n        fh.close()\n\n        raise NRRDError('Invalid lineskip, allowed values are greater than or equal to 0')\n\n    # Skip the requested number of bytes or seek backward, and then parse the data using NumPy\n    if byte_skip < -1:\n        # Must close the file because if the file was opened above from detached filename, there is no \"with\" block to\n        # close it for us\n        fh.close()\n\n        raise NRRDError('Invalid byteskip, allowed values are greater than or equal to -1')\n    elif byte_skip >= 0:\n        fh.seek(byte_skip, os.SEEK_CUR)\n    elif byte_skip == -1 and header['encoding'] not in ['gzip', 'gz', 'bzip2', 'bz2']:\n        fh.seek(-dtype.itemsize * total_data_points, os.SEEK_END)\n    else:\n        # The only case left should be: byte_skip == -1 and header['encoding'] == 'gzip'\n        byte_skip = -dtype.itemsize * total_data_points\n\n    # If a compression encoding is used, then byte skip AFTER decompressing\n    if header['encoding'] == 'raw':\n        data = np.fromfile(fh, dtype)\n    elif header['encoding'] in ['ASCII', 'ascii', 'text', 'txt']:\n        data = np.fromfile(fh, dtype, sep=' ')\n    else:\n        # Handle compressed data now\n        # Construct the decompression object based on encoding\n        if header['encoding'] in ['gzip', 'gz']:\n            decompobj = zlib.decompressobj(zlib.MAX_WBITS | 16)\n        elif header['encoding'] in ['bzip2', 'bz2']:\n            decompobj = bz2.BZ2Decompressor()\n        else:\n            # Must close the file because if the file was opened above from detached filename, there is no \"with\" block\n            # to close it for us\n            fh.close()\n\n            raise NRRDError('Unsupported encoding: \"%s\"' % header['encoding'])\n\n        # Loop through the file and read a chunk at a time (see _READ_CHUNKSIZE why it is read in chunks)\n        decompressed_data = bytearray()\n\n        # Read all of the remaining data from the file\n        # Obtain the length of the compressed data since we will be using it repeatedly, more efficient\n        compressed_data = fh.read()\n        compressed_data_len = len(compressed_data)\n        start_index = 0\n\n        # Loop through data and decompress it chunk by chunk\n        while start_index < compressed_data_len:\n            # Calculate the end index = start index plus chunk size\n            # Set to the string length to read the remaining chunk at the end\n            end_index = min(start_index + _READ_CHUNKSIZE, compressed_data_len)\n\n            # Decompress and append data\n            decompressed_data += decompobj.decompress(compressed_data[start_index:end_index])\n\n            # Update start index\n            start_index = end_index\n\n        # Delete the compressed data since we do not need it anymore\n        # This could potentially be using a lot of memory\n        del compressed_data\n\n        # Byte skip is applied AFTER the decompression. Skip first x bytes of the decompressed data and parse it using\n        # NumPy\n        data = np.frombuffer(decompressed_data[byte_skip:], dtype)\n\n    # Close the file, even if opened using \"with\" block, closing it manually does not hurt\n    fh.close()\n\n    if total_data_points != data.size:\n        raise NRRDError('Size of the data does not equal the product of all the dimensions: {0}-{1}={2}'\n                        .format(total_data_points, data.size, total_data_points - data.size))\n\n    # In the NRRD header, the fields are specified in Fortran order, i.e, the first index is the one that changes\n    # fastest and last index changes slowest. This needs to be taken into consideration since numpy uses C-order\n    # indexing.\n    \n    # The array shape from NRRD (x,y,z) needs to be reversed as numpy expects (z,y,x).\n    data = np.reshape(data, tuple(header['sizes'][::-1]))\n\n    # Transpose data to enable Fortran indexing if requested.\n    if index_order == 'F':\n        data = data.T\n\n    return data", "response": "Reads data from file into a NRRD tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(filename, custom_field_map=None, index_order='F'):\n\n    \"\"\"Read a NRRD file and return a tuple (data, header).\"\"\"\n    with open(filename, 'rb') as fh:\n        header = read_header(fh, custom_field_map)\n        data = read_data(header, fh, filename, index_order)\n\n    return data, header", "response": "Reads a NRRD file and returns the header and data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True when log2 ( duration ) is an integer.", "response": "def valid_beat_duration(duration):\n    \"\"\"Return True when log2(duration) is an integer.\"\"\"\n    if duration == 0:\n        return False\n    elif duration == 1:\n        return True\n    else:\n        r = duration\n        while r != 1:\n            if r % 2 == 1:\n                return False\n            r /= 2\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_notes(self, note, duration=None):\n        if self.instrument != None:\n            if not self.instrument.can_play_notes(note):\n                raise InstrumentRangeError, \\\n                    \"Note '%s' is not in range of the instrument (%s)\" % (note,\n                        self.instrument)\n        if duration == None:\n            duration = 4\n\n        # Check whether the last bar is full, if so create a new bar and add the\n        # note there\n        if len(self.bars) == 0:\n            self.bars.append(Bar())\n        last_bar = self.bars[-1]\n        if last_bar.is_full():\n            self.bars.append(Bar(last_bar.key, last_bar.meter))\n            # warning should hold note if it doesn't fit\n\n        return self.bars[-1].place_notes(note, duration)", "response": "Add a Note to the last Bar."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_notes(self):\n        for bar in self.bars:\n            for beat, duration, notes in bar:\n                yield beat, duration, notes", "response": "Return an iterator that iterates through every bar in the this\n        track and returns the beat duration and notes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds chords to the Track.", "response": "def from_chords(self, chords, duration=1):\n        \"\"\"Add chords to the Track.\n\n        The given chords should be a list of shorthand strings or list of\n        list of shorthand strings, etc.\n\n        Each sublist divides the value by 2.\n\n        If a tuning is set, chords will be expanded so they have a proper\n        fingering.\n\n        Example:\n        >>> t = Track().from_chords(['C', ['Am', 'Dm'], 'G7', 'C#'], 1)\n        \"\"\"\n        tun = self.get_tuning()\n\n        def add_chord(chord, duration):\n            if type(chord) == list:\n                for c in chord:\n                    add_chord(c, duration * 2)\n            else:\n                chord = NoteContainer().from_chord(chord)\n                if tun:\n                    chord = tun.find_chord_fingering(chord,\n                            return_best_as_NoteContainer=True)\n                if not self.add_notes(chord, duration):\n                    # This should be the standard behaviour of add_notes\n                    dur = self.bars[-1].value_left()\n                    self.add_notes(chord, dur)\n\n                    # warning should hold note\n                    self.add_notes(chord, value.subtract(duration, dur))\n\n        for c in chords:\n            if c is not None:\n                add_chord(c, duration)\n            else:\n                self.add_notes(None, duration)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tuning(self):\n        if self.instrument and self.instrument.tuning:\n            return self.instrument.tuning\n        return self.tuning", "response": "Return a StringTuning object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the tuning attribute on both the Track and its instrument.", "response": "def set_tuning(self, tuning):\n        \"\"\"Set the tuning attribute on both the Track and its instrument (when\n        available).\n\n        Tuning should be a StringTuning or derivative object.\n        \"\"\"\n        if self.instrument:\n            self.instrument.tuning = tuning\n        self.tuning = tuning\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transpose(self, interval, up=True):\n        for bar in self.bars:\n            bar.transpose(interval, up)\n        return self", "response": "Transposes all the notes in the track up or down the interval."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_meter(self, meter):\n        # warning should raise exception\n        if _meter.valid_beat_duration(meter[1]):\n            self.meter = (meter[0], meter[1])\n            self.length = meter[0] * (1.0 / meter[1])\n        elif meter == (0, 0):\n            self.meter = (0, 0)\n            self.length = 0.0\n        else:\n            raise MeterFormatError(\"The meter argument '%s' is not an \"\n                    \"understood representation of a meter. \"\n                    \"Expecting a tuple.\" % meter)", "response": "Set the meter of this bar."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplacing the notes on the current_beat.", "response": "def place_notes(self, notes, duration):\n        \"\"\"Place the notes on the current_beat.\n\n        Notes can be strings, Notes, list of strings, list of Notes or a\n        NoteContainer.\n\n        Raise a MeterFormatError if the duration is not valid.\n\n        Return True if succesful, False otherwise (ie. the Bar hasn't got\n        enough room for a note of that duration).\n        \"\"\"\n        # note should be able to be one of strings, lists, Notes or\n        # NoteContainers\n        if hasattr(notes, 'notes'):\n            pass\n        elif hasattr(notes, 'name'):\n            notes = NoteContainer(notes)\n        elif type(notes) == str:\n            notes = NoteContainer(notes)\n        elif type(notes) == list:\n            notes = NoteContainer(notes)\n        if self.current_beat + 1.0 / duration <= self.length or self.length\\\n             == 0.0:\n            self.bar.append([self.current_beat, duration, notes])\n            self.current_beat += 1.0 / duration\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef place_notes_at(self, notes, at):\n        for x in self.bar:\n            if x[0] == at:\n                x[0][2] += notes", "response": "Place notes at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_last_entry(self):\n        self.current_beat -= 1.0 / self.bar[-1][1]\n        self.bar = self.bar[:-1]\n        return self.current_beat", "response": "Remove the last NoteContainer in the Bar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_full(self):\n        if self.length == 0.0:\n            return False\n        if len(self.bar) == 0:\n            return False\n        if self.current_beat >= self.length - 0.001:\n            return True\n        return False", "response": "Return False if there is room in this Bar for another\n        NoteContainer True otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging the note duration at the given index to the given duration.", "response": "def change_note_duration(self, at, to):\n        \"\"\"Change the note duration at the given index to the given\n        duration.\"\"\"\n        if valid_beat_duration(to):\n            diff = 0\n            for x in self.bar:\n                if diff != 0:\n                    x[0][0] -= diff\n                if x[0] == at:\n                    cur = x[0][1]\n                    x[0][1] = to\n                    diff = 1 / cur - 1 / to"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the highest and the lowest note in a tuple.", "response": "def get_range(self):\n        \"\"\"Return the highest and the lowest note in a tuple.\"\"\"\n        (min, max) = (100000, -1)\n        for cont in self.bar:\n            for note in cont[2]:\n                if int(note) < int(min):\n                    min = note\n                elif int(note) > int(max):\n                    max = note\n        return (min, max)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transpose(self, interval, up=True):\n        for cont in self.bar:\n            cont[2].transpose(interval, up)", "response": "Transposes the notes in the bar up or down the interval."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef determine_chords(self, shorthand=False):\n        chords = []\n        for x in self.bar:\n            chords.append([x[0], x[2].determine(shorthand)])\n        return chords", "response": "Return a list of lists [ place_in_beat possible_chords ]."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef determine_progression(self, shorthand=False):\n        res = []\n        for x in self.bar:\n            res.append([x[0], progressions.determine(x[2].get_note_names(),\n                       self.key.key, shorthand)])\n        return res", "response": "Return a list of lists [ place_in_beat possible_progressions ]."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of unique note names in the Bar.", "response": "def get_note_names(self):\n        \"\"\"Return a list of unique note names in the Bar.\"\"\"\n        res = []\n        for cont in self.bar:\n            for x in cont[2].get_note_names():\n                if x not in res:\n                    res.append(x)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_midi_file_header(self, fp):\n        # Check header\n        try:\n            if fp.read(4) != 'MThd':\n                raise HeaderError('Not a valid MIDI file header. Byte %d.'\n                        % self.bytes_read)\n            self.bytes_read += 4\n        except:\n            raise IOError(\"Couldn't read from file.\")\n\n        # Parse chunk size\n        try:\n            chunk_size = self.bytes_to_int(fp.read(4))\n            self.bytes_read += 4\n        except:\n            raise IOError(\"Couldn't read chunk size from file. Byte %d.\"\n                    % self.bytes_read)\n\n        # Expect chunk size to be at least 6\n        if chunk_size < 6:\n            return False\n        try:\n            format_type = self.bytes_to_int(fp.read(2))\n            self.bytes_read += 2\n            if format_type not in [0, 1, 2]:\n                raise FormatError('%d is not a valid MIDI format.'\n                        % format_type)\n        except:\n            raise IOError(\"Couldn't read format type from file.\")\n        try:\n            number_of_tracks = self.bytes_to_int(fp.read(2))\n            time_division = self.parse_time_division(fp.read(2))\n            self.bytes_read += 4\n        except:\n            raise IOError(\"Couldn't read number of tracks \"\n                    \"and/or time division from tracks.\")\n\n        chunk_size -= 6\n        if chunk_size % 2 == 1:\n            raise FormatError(\"Won't parse this.\")\n        fp.read(chunk_size / 2)\n        self.bytes_read += chunk_size / 2\n        return (format_type, number_of_tracks, time_division)", "response": "Read the header of a MIDI file and return a tuple containing the format type number of tracks and parsed time division information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_time_division(self, bytes):\n        # If highest bit is set, time division is set in frames per second\n        # otherwise in ticks_per_beat\n        value = self.bytes_to_int(bytes)\n        if not value & 0x8000:\n            return {'fps': False, 'ticks_per_beat': value & 0x7FFF}\n        else:\n            SMPTE_frames = (value & 0x7F00) >> 2\n            if SMPTE_frames not in [24, 25, 29, 30]:\n                raise TimeDivisionError, \\\n                    \"'%d' is not a valid value for the number of SMPTE frames\"\\\n                     % SMPTE_frames\n            clock_ticks = (value & 0x00FF) >> 2\n            return {'fps': True, 'SMPTE_frames': SMPTE_frames,\n                    'clock_ticks': clock_ticks}", "response": "Parse the time division found in the MIDI file and return a dictionary with the boolean fps set to indicate whether the frames per second or ticks per beat is set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_track(self, fp):\n        events = []\n        chunk_size = self.parse_track_header(fp)\n        bytes = chunk_size\n        while chunk_size > 0:\n            (delta_time, chunk_delta) = self.parse_varbyte_as_int(fp)\n            chunk_size -= chunk_delta\n            (event, chunk_delta) = self.parse_midi_event(fp)\n            chunk_size -= chunk_delta\n            events.append([delta_time, event])\n        if chunk_size < 0:\n            print 'yikes.', self.bytes_read, chunk_size\n        return events", "response": "Parse a MIDI track from its header to its events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_midi_event(self, fp):\n        chunk_size = 0\n        try:\n            ec = self.bytes_to_int(fp.read(1))\n            chunk_size += 1\n            self.bytes_read += 1\n        except:\n            raise IOError(\"Couldn't read event type \"\n                    \"and channel data from file.\")\n\n        # Get the nibbles\n        event_type = (ec & 0xf0) >> 4\n        channel = ec & 0x0f\n\n        # I don't know what these events are supposed to do, but I keep finding\n        # them. The parser ignores them.\n        if event_type < 8:\n            raise FormatError('Unknown event type %d. Byte %d.' % (event_type,\n                self.bytes_read))\n\n        # Meta events can have strings of variable length\n        if event_type == 0x0f:\n            try:\n                meta_event = self.bytes_to_int(fp.read(1))\n                (length, chunk_delta) = self.parse_varbyte_as_int(fp)\n                data = fp.read(length)\n                chunk_size += 1 + chunk_delta + length\n                self.bytes_read += 1 + length\n            except:\n                raise IOError(\"Couldn't read meta event from file.\")\n            return ({'event': event_type, 'meta_event': meta_event,\n                'data': data}, chunk_size)\n        elif event_type in [12, 13]:\n            # Program change and Channel aftertouch events only have one\n            # parameter\n            try:\n                param1 = fp.read(1)\n                chunk_size += 1\n                self.bytes_read += 1\n            except:\n                raise IOError(\"Couldn't read MIDI event parameters from file.\")\n            param1 = self.bytes_to_int(param1)\n            return ({'event': event_type, 'channel': channel,\n                'param1': param1}, chunk_size)\n        else:\n            try:\n                param1 = fp.read(1)\n                param2 = fp.read(1)\n                chunk_size += 2\n                self.bytes_read += 2\n            except:\n                raise IOError(\"Couldn't read MIDI event parameters from file.\")\n            param1 = self.bytes_to_int(param1)\n            param2 = self.bytes_to_int(param2)\n            return ({'event': event_type, 'channel': channel, 'param1': param1,\n                'param2': param2}, chunk_size)", "response": "Parse a MIDI event."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the track header.", "response": "def parse_track_header(self, fp):\n        \"\"\"Return the size of the track chunk.\"\"\"\n        # Check the header\n        try:\n            h = fp.read(4)\n            self.bytes_read += 4\n        except:\n            raise IOError(\"Couldn't read track header from file. Byte %d.\"\n                    % self.bytes_read)\n        if h != 'MTrk':\n            raise HeaderError('Not a valid Track header. Byte %d.'\n                    % self.bytes_read)\n\n        # Parse the size of the header\n        try:\n            chunk_size = fp.read(4)\n            self.bytes_read += 4\n        except:\n            raise IOError(\"Couldn't read track chunk size from file.\")\n        chunk_size = self.bytes_to_int(chunk_size)\n        return chunk_size"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a MIDI file and return the header and the parsed MIDI taxonomy.", "response": "def parse_midi_file(self, file):\n        \"\"\"Parse a MIDI file.\n\n        Return the header -as a tuple containing respectively the MIDI\n        format, the number of tracks and the time division-, the parsed\n        track data and the number of bytes read.\n        \"\"\"\n        try:\n            f = open(file, 'r')\n        except:\n            raise IOError('File not found')\n        self.bytes_read = 0\n        header = self.parse_midi_file_header(f)\n        tracks = header[1]\n        result = []\n        while tracks > 0:\n            events = self.parse_track(f)\n            result.append(events)\n            tracks -= 1\n        f.close()\n        return (header, result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a variable length byte from the file and return the corresponding integer.", "response": "def parse_varbyte_as_int(self, fp, return_bytes_read=True):\n        \"\"\"Read a variable length byte from the file and return the\n        corresponding integer.\"\"\"\n        result = 0\n        bytes_read = 0\n        r = 0x80\n        while r & 0x80:\n            try:\n                r = self.bytes_to_int(fp.read(1))\n                self.bytes_read += 1\n            except:\n                raise IOError(\"Couldn't read variable length byte from file.\")\n            if r & 0x80:\n                result = (result << 7) + (r & 0x7F)\n            else:\n                result = (result << 7) + r\n            bytes_read += 1\n        if not return_bytes_read:\n            return result\n        else:\n            return (result, bytes_read)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the note to name in octave with dynamics.", "response": "def set_note(self, name='C', octave=4, dynamics={}):\n        \"\"\"Set the note to name in octave with dynamics.\n\n        Return the objects if it succeeded, raise an NoteFormatError\n        otherwise.\n        \"\"\"\n        dash_index = name.split('-')\n        if len(dash_index) == 1:\n            if notes.is_valid_note(name):\n                self.name = name\n                self.octave = octave\n                self.dynamics = dynamics\n                return self\n            else:\n                raise NoteFormatError(\"The string '%s' is not a valid \"\n                        \"representation of a note in mingus\" % name)\n        elif len(dash_index) == 2:\n            if notes.is_valid_note(dash_index[0]):\n                self.name = dash_index[0]\n                self.octave = int(dash_index[1])\n                self.dynamics = dynamics\n                return self\n            else:\n                raise NoteFormatError(\"The string '%s' is not a valid \"\n                        \"representation of a note in mingus\" % name)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the octave of the note to the current octave + diff.", "response": "def change_octave(self, diff):\n        \"\"\"Change the octave of the note to the current octave + diff.\"\"\"\n        self.octave += diff\n        if self.octave < 0:\n            self.octave = 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transpose(self, interval, up=True):\n        (old, o_octave) = (self.name, self.octave)\n        self.name = intervals.from_shorthand(self.name, interval, up)\n        if up:\n            if self < Note(old, o_octave):\n                self.octave += 1\n        else:\n            if self > Note(old, o_octave):\n                self.octave -= 1", "response": "Transposes the note up or down the interval."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the Note corresponding to the integer.", "response": "def from_int(self, integer):\n        \"\"\"Set the Note corresponding to the integer.\n\n        0 is a C on octave 0, 12 is a C on octave 1, etc.\n\n        Example:\n        >>> Note().from_int(12)\n        'C-1'\n        \"\"\"\n        self.name = notes.int_to_note(integer % 12)\n        self.octave = integer // 12\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the Note name and pitch from the hertz value.", "response": "def from_hertz(self, hertz, standard_pitch=440):\n        \"\"\"Set the Note name and pitch, calculated from the hertz value.\n\n        The standard_pitch argument can be used to set the pitch of A-4,\n        from which the rest is calculated.\n        \"\"\"\n        value = ((log((float(hertz) * 1024) / standard_pitch, 2) +\n            1.0 / 24) * 12 + 9)  # notes.note_to_int(\"A\")\n        self.name = notes.int_to_note(int(value) % 12)\n        self.octave = int(value / 12) - 6\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives the traditional Helmhotz pitch notation.", "response": "def to_shorthand(self):\n        \"\"\"Give the traditional Helmhotz pitch notation.\n\n        Examples:\n        >>> Note('C-4').to_shorthand()\n        \"c'\"\n        >>> Note('C-3').to_shorthand()\n        'c'\n        >>> Note('C-2').to_shorthand()\n        'C'\n        >>> Note('C-1').to_shorthand()\n        'C,'\n        \"\"\"\n        if self.octave < 3:\n            res = self.name\n        else:\n            res = str.lower(self.name)\n        o = self.octave - 3\n        while o < -1:\n            res += ','\n            o += 1\n        while o > 0:\n            res += \"'\"\n            o -= 1\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert from traditional Helmhotz pitch notation to internal representation.", "response": "def from_shorthand(self, shorthand):\n        \"\"\"Convert from traditional Helmhotz pitch notation.\n\n        Examples:\n        >>> Note().from_shorthand(\"C,,\")\n        'C-0'\n        >>> Note().from_shorthand(\"C\")\n        'C-2'\n        >>> Note().from_shorthand(\"c'\")\n        'C-4'\n        \"\"\"\n        name = ''\n        octave = 0\n        for x in shorthand:\n            if x in ['a', 'b', 'c', 'd', 'e', 'f', 'g']:\n                name = str.upper(x)\n                octave = 3\n            elif x in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n                name = x\n                octave = 2\n            elif x in ['#', 'b']:\n                name += x\n            elif x == ',':\n                octave -= 1\n            elif x == \"'\":\n                octave += 1\n        return self.set_note(name, octave, {})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the note found at the interval starting from start_note in the given key", "response": "def interval(key, start_note, interval):\n    \"\"\"Return the note found at the interval starting from start_note in the\n    given key.\n\n    Raise a KeyError exception if start_note is not a valid note.\n\n    Example:\n    >>> interval('C', 'D', 1)\n    'E'\n    \"\"\"\n    if not notes.is_valid_note(start_note):\n        raise KeyError(\"The start note '%s' is not a valid note\" % start_note)\n    notes_in_key = keys.get_notes(key)\n    for n in notes_in_key:\n        if n[0] == start_note[0]:\n            index = notes_in_key.index(n)\n    return notes_in_key[(index + interval) % 7]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_interval(note, interval, key='C'):\n    intervals = map(lambda x: (notes.note_to_int(key) + x) % 12, [\n        0,\n        2,\n        4,\n        5,\n        7,\n        9,\n        11,\n        ])\n    key_notes = keys.get_notes(key)\n    for x in key_notes:\n        if x[0] == note[0]:\n            result = (intervals[key_notes.index(x)] + interval) % 12\n    if result in intervals:\n        return key_notes[intervals.index(result)] + note[1:]\n    else:\n        return notes.diminish(key_notes[intervals.index((result + 1) % 12)]\n                               + note[1:])", "response": "Return the note an interval away from the given note."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef measure(note1, note2):\n    res = notes.note_to_int(note2) - notes.note_to_int(note1)\n    if res < 0:\n        return 12 - res * -1\n    else:\n        return res", "response": "Return an integer in the range of 0 - 11 determining the half note steps between note1 and note2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef augment_or_diminish_until_the_interval_is_right(note1, note2, interval):\n    cur = measure(note1, note2)\n    while cur != interval:\n        if cur > interval:\n            note2 = notes.diminish(note2)\n        elif cur < interval:\n            note2 = notes.augment(note2)\n        cur = measure(note1, note2)\n\n    # We are practically done right now, but we need to be able to create the\n    # minor seventh of Cb and get Bbb instead of B######### as the result\n    val = 0\n    for token in note2[1:]:\n        if token == '#':\n            val += 1\n        elif token == 'b':\n            val -= 1\n\n    # These are some checks to see if we have generated too much #'s or too much\n    # b's. In these cases we need to convert #'s to b's and vice versa.\n    if val > 6:\n        val = val % 12\n        val = -12 + val\n    elif val < -6:\n        val = val % -12\n        val = 12 + val\n\n    # Rebuild the note\n    result = note2[0]\n    while val > 0:\n        result = notes.augment(result)\n        val -= 1\n    while val < 0:\n        result = notes.diminish(result)\n        val += 1\n    return result", "response": "A helper function for the minor and major functions. Augment the note1 and note2 until the interval is right."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef invert(interval):\n    interval.reverse()\n    res = list(interval)\n    interval.reverse()\n    return res", "response": "Invert an interval.\n\n    Example:\n    >>> invert(['C', 'E'])\n    ['E', 'C']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the name of the interval between note1 and note2.", "response": "def determine(note1, note2, shorthand=False):\n    \"\"\"Name the interval between note1 and note2.\n\n    Examples:\n    >>> determine('C', 'E')\n    'major third'\n    >>> determine('C', 'Eb')\n    'minor third'\n    >>> determine('C', 'E#')\n    'augmented third'\n    >>> determine('C', 'Ebb')\n    'diminished third'\n\n    This works for all intervals. Note that there are corner cases for major\n    fifths and fourths:\n    >>> determine('C', 'G')\n    'perfect fifth'\n    >>> determine('C', 'F')\n    'perfect fourth'\n    \"\"\"\n    # Corner case for unisons ('A' and 'Ab', for instance)\n    if note1[0] == note2[0]:\n        def get_val(note):\n            \"\"\"Private function: count the value of accidentals.\"\"\"\n            r = 0\n            for x in note[1:]:\n                if x == 'b':\n                    r -= 1\n                elif x == '#':\n                    r += 1\n            return r\n\n        x = get_val(note1)\n        y = get_val(note2)\n        if x == y:\n            if not shorthand:\n                return 'major unison'\n            return '1'\n        elif x < y:\n            if not shorthand:\n                return 'augmented unison'\n            return '#1'\n        elif x - y == 1:\n            if not shorthand:\n                return 'minor unison'\n            return 'b1'\n        else:\n            if not shorthand:\n                return 'diminished unison'\n            return 'bb1'\n\n    # Other intervals\n    n1 = notes.fifths.index(note1[0])\n    n2 = notes.fifths.index(note2[0])\n    number_of_fifth_steps = n2 - n1\n    if n2 < n1:\n        number_of_fifth_steps = len(notes.fifths) - n1 + n2\n\n    # [name, shorthand_name, half notes for major version of this interval]\n    fifth_steps = [\n        ['unison', '1', 0],\n        ['fifth', '5', 7],\n        ['second', '2', 2],\n        ['sixth', '6', 9],\n        ['third', '3', 4],\n        ['seventh', '7', 11],\n        ['fourth', '4', 5],\n        ]\n\n    # Count half steps between note1 and note2\n    half_notes = measure(note1, note2)\n\n    # Get the proper list from the number of fifth steps\n    current = fifth_steps[number_of_fifth_steps]\n\n    # maj = number of major steps for this interval\n    maj = current[2]\n\n    # if maj is equal to the half steps between note1 and note2 the interval is\n    # major or perfect\n    if maj == half_notes:\n        # Corner cases for perfect fifths and fourths\n        if current[0] == 'fifth':\n            if not shorthand:\n                return 'perfect fifth'\n        elif current[0] == 'fourth':\n            if not shorthand:\n                return 'perfect fourth'\n        if not shorthand:\n            return 'major ' + current[0]\n        return current[1]\n    elif maj + 1 <= half_notes:\n        # if maj + 1 is equal to half_notes, the interval is augmented.\n        if not shorthand:\n            return 'augmented ' + current[0]\n        return '#' * (half_notes - maj) + current[1]\n    elif maj - 1 == half_notes:\n        # etc.\n        if not shorthand:\n            return 'minor ' + current[0]\n        return 'b' + current[1]\n    elif maj - 2 >= half_notes:\n        if not shorthand:\n            return 'diminished ' + current[0]\n        return 'b' * (maj - half_notes) + current[1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the note on interval up or down.", "response": "def from_shorthand(note, interval, up=True):\n    \"\"\"Return the note on interval up or down.\n\n    Examples:\n    >>> from_shorthand('A', 'b3')\n    'C'\n    >>> from_shorthand('D', '2')\n    'E'\n    >>> from_shorthand('E', '2', False)\n    'D'\n    \"\"\"\n    # warning should be a valid note.\n    if not notes.is_valid_note(note):\n        return False\n\n    # [shorthand, interval function up, interval function down]\n    shorthand_lookup = [\n        ['1', major_unison, major_unison],\n        ['2', major_second, minor_seventh],\n        ['3', major_third, minor_sixth],\n        ['4', major_fourth, major_fifth],\n        ['5', major_fifth, major_fourth],\n        ['6', major_sixth, minor_third],\n        ['7', major_seventh, minor_second],\n        ]\n\n    # Looking up last character in interval in shorthand_lookup and calling that\n    # function.\n    val = False\n    for shorthand in shorthand_lookup:\n        if shorthand[0] == interval[-1]:\n            if up:\n                val = shorthand[1](note)\n            else:\n                val = shorthand[2](note)\n\n    # warning Last character in interval should be 1-7\n    if val == False:\n        return False\n\n    # Collect accidentals\n    for x in interval:\n        if x == '#':\n            if up:\n                val = notes.augment(val)\n            else:\n                val = notes.diminish(val)\n        elif x == 'b':\n            if up:\n                val = notes.diminish(val)\n            else:\n                val = notes.augment(val)\n        else:\n            return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_consonant(note1, note2, include_fourths=True):\n    return (is_perfect_consonant(note1, note2, include_fourths) or\n            is_imperfect_consonant(note1, note2))", "response": "Return True if the given note1 and note2 are consonant."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the interval is a perfect consonant one.", "response": "def is_perfect_consonant(note1, note2, include_fourths=True):\n    \"\"\"Return True if the interval is a perfect consonant one.\n\n    Perfect consonances are either unisons, perfect fourths or fifths, or\n    octaves (which is the same as a unison in this model).\n\n    Perfect fourths are usually included as well, but are considered\n    dissonant when used contrapuntal, which is why you can exclude them.\n    \"\"\"\n    dhalf = measure(note1, note2)\n    return dhalf in [0, 7] or include_fourths and dhalf == 5"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a track to the composition.", "response": "def add_track(self, track):\n        \"\"\"Add a track to the composition.\n\n        Raise an UnexpectedObjectError if the argument is not a\n        mingus.containers.Track object.\n        \"\"\"\n        if not hasattr(track, 'bars'):\n            raise UnexpectedObjectError(\"Unexpected object '%s', \"\n                    \"expecting a mingus.containers.Track object\" % track)\n        self.tracks.append(track)\n        self.selected_tracks = [len(self.tracks) - 1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_note(self, note):\n        for n in self.selected_tracks:\n            self.tracks[n] + note", "response": "Add a note to the selected tracks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild and apply a ctypes prototype complete with parameter flags.", "response": "def cfunc(name, result, *args):\n    \"\"\"Build and apply a ctypes prototype complete with parameter flags.\"\"\"\n    atypes = []\n    aflags = []\n    for arg in args:\n        atypes.append(arg[1])\n        aflags.append((arg[2], arg[0]) + arg[3:])\n    return CFUNCTYPE(result, *atypes)((name, _fl), tuple(aflags))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn generated samples in stereo 16 - bit format.", "response": "def fluid_synth_write_s16_stereo(synth, len):\n    \"\"\"Return generated samples in stereo 16-bit format.\n\n    Return value is a Numpy array of samples.\n    \"\"\"\n    import numpy\n    buf = create_string_buffer(len * 4)\n    fluid_synth_write_s16(synth, len, buf, 0, 2, buf, 1, 2)\n    return numpy.fromstring(buf[:], dtype=numpy.int16)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting audio output driver in separate background thread.", "response": "def start(self, driver=None):\n        \"\"\"Start audio output driver in separate background thread.\n\n        Call this function any time after creating the Synth object.\n        If you don't call this function, use get_samples() to generate\n        samples.\n\n        Optional keyword argument:\n          driver: which audio driver to use for output\n                  Possible choices:\n                    'alsa', 'oss', 'jack', 'portaudio'\n                    'sndmgr', 'coreaudio', 'Direct Sound',\n                    'dsound', 'pulseaudio'\n\n        Not all drivers will be available for every platform, it depends on\n        which drivers were compiled into FluidSynth for your platform.\n        \"\"\"\n        if driver is not None:\n            assert driver in [\n                    'alsa',\n                    'oss',\n                    'jack',\n                    'portaudio',\n                    'sndmgr',\n                    'coreaudio',\n                    'Direct Sound',\n                    'dsound',\n                    'pulseaudio'\n                    ]\n            fluid_settings_setstr(self.settings, 'audio.driver', driver)\n        self.audio_driver = new_fluid_audio_driver(self.settings, self.synth)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cc(self, chan, ctrl, val):\n        return fluid_synth_cc(self.synth, chan, ctrl, val)", "response": "Send control change value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef int_to_note(note_int, accidentals='#'):\n    if note_int not in range(12):\n        raise RangeError('int out of bounds (0-11): %d' % note_int)\n    ns = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n    nf = ['C', 'Db', 'D', 'Eb', 'E', 'F', 'Gb', 'G', 'Ab', 'A', 'Bb', 'B']\n    if accidentals == '#':\n        return ns[note_int]\n    elif accidentals == 'b':\n        return nf[note_int]\n    else:\n        raise FormatError(\"'%s' not valid as accidental\" % accidentals)", "response": "Convert an integer to notes in the range of 0 - 11."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if note is in a recognised format. False if not.", "response": "def is_valid_note(note):\n    \"\"\"Return True if note is in a recognised format. False if not.\"\"\"\n    if not _note_dict.has_key(note[0]):\n        return False\n    for post in note[1:]:\n        if post != 'b' and post != '#':\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a note in the form of C Cb C## etc. to an integer in the range of 0 - 11.", "response": "def note_to_int(note):\n    \"\"\"Convert notes in the form of C, C#, Cb, C##, etc. to an integer in the\n    range of 0-11.\n\n    Throw a NoteFormatError exception if the note format is not recognised.\n    \"\"\"\n    if is_valid_note(note):\n        val = _note_dict[note[0]]\n    else:\n        raise NoteFormatError(\"Unknown note format '%s'\" % note)\n\n    # Check for '#' and 'b' postfixes\n    for post in note[1:]:\n        if post == 'b':\n            val -= 1\n        elif post == '#':\n            val += 1\n    return val % 12"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreducing any extra accidentals to proper notes.", "response": "def reduce_accidentals(note):\n    \"\"\"Reduce any extra accidentals to proper notes.\n\n    Example:\n    >>> reduce_accidentals('C####')\n    'E'\n    \"\"\"\n    val = note_to_int(note[0])\n    for token in note[1:]:\n        if token == 'b':\n            val -= 1\n        elif token == '#':\n            val += 1\n        else:\n            raise NoteFormatError(\"Unknown note format '%s'\" % note)\n    if val >= note_to_int(note[0]):\n        return int_to_note(val%12)\n    else:\n        return int_to_note(val%12, 'b')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_redundant_accidentals(note):\n    val = 0\n    for token in note[1:]:\n        if token == 'b':\n            val -= 1\n        elif token == '#':\n            val += 1\n    result = note[0]\n    while val > 0:\n        result = augment(result)\n        val -= 1\n    while val < 0:\n        result = diminish(result)\n        val += 1\n    return result", "response": "Remove redundant sharps and flats from the given note."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _gcd(a=None, b=None, terms=None):\n    if terms:\n        return reduce(lambda a, b: _gcd(a, b), terms)\n    else:\n        while b:\n            (a, b) = (b, a % b)\n        return a", "response": "Return the greatest common divisor using Euclid s Algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an XML file or MXL file for a given composition.", "response": "def write_Composition(composition, filename, zip=False):\n    \"\"\"Create an XML file (or MXL if compressed) for a given composition.\"\"\"\n    text = from_Composition(composition)\n    if not zip:\n        f = open(filename + '.xml', 'w')\n        f.write(text)\n        f.close()\n    else:\n        import zipfile\n        import os\n        zf = zipfile.ZipFile(filename + '.mxl', mode='w',\n                             compression=zipfile.ZIP_DEFLATED)\n        zi = zipfile.ZipInfo('META-INF' + os.sep + 'container.xml')\n        zi.external_attr = 0660 << 16L\n        zf.writestr(zi,\n                    \"<?xml version='1.0' encoding='UTF-8'?>\"\n                    \"<container><rootfiles><rootfile full-path='{0}.xml'/>\"\n                    \"</rootfiles></container>\".format(filename))\n        zi = zipfile.ZipInfo(filename + '.xml')\n        zi.external_attr = 0660 << 16L\n        zf.writestr(zi, text)\n        zf.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the key signature for a given key.", "response": "def get_key_signature(key='C'):\n    \"\"\"Return the key signature.\n\n    0 for C or a, negative numbers for flat key signatures, positive numbers\n    for sharp key signatures.\n    \"\"\"\n    if not is_valid_key(key):\n        raise NoteFormatError(\"unrecognized format for key '%s'\" % key)\n\n    for couple in keys:\n        if key in couple:\n            accidentals = keys.index(couple) - 7\n            return accidentals"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_key_signature_accidentals(key='C'):\n    accidentals = get_key_signature(key)\n    res = []\n\n    if accidentals < 0:\n        for i in range(-accidentals):\n            res.append('{0}{1}'.format(list(reversed(notes.fifths))[i], 'b'))\n    elif accidentals > 0:\n        for i in range(accidentals):\n            res.append('{0}{1}'.format(notes.fifths[i], '#'))\n    return res", "response": "Return the list of accidentals present into the key signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an ordered list of the notes in this natural key.", "response": "def get_notes(key='C'):\n    \"\"\"Return an ordered list of the notes in this natural key.\n\n    Examples:\n    >>> get_notes('F')\n    ['F', 'G', 'A', 'Bb', 'C', 'D', 'E']\n    >>> get_notes('c')\n    ['C', 'D', 'Eb', 'F', 'G', 'Ab', 'Bb']\n    \"\"\"\n    if _key_cache.has_key(key):\n        return _key_cache[key]\n    if not is_valid_key(key):\n        raise NoteFormatError(\"unrecognized format for key '%s'\" % key)\n    result = []\n\n    # Calculate notes\n    altered_notes = map(operator.itemgetter(0),\n            get_key_signature_accidentals(key))\n\n    if get_key_signature(key) < 0:\n        symbol = 'b'\n    elif get_key_signature(key) > 0:\n        symbol = '#'\n\n    raw_tonic_index = base_scale.index(key.upper()[0])\n\n    for note in islice(cycle(base_scale), raw_tonic_index, raw_tonic_index+7):\n        if note in altered_notes:\n            result.append('%s%s' % (note, symbol))\n        else:\n            result.append(note)\n    \n    # Save result to cache\n    _key_cache[key] = result\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attach(self, listener):\n        if listener not in self.listeners:\n            self.listeners.append(listener)", "response": "Attach an object that should be notified of events."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetaches a listening object so that it won t receive any events.", "response": "def detach(self, listener):\n        \"\"\"Detach a listening object so that it won't receive any events\n        anymore.\"\"\"\n        if listener in self.listeners:\n            self.listeners.remove(listener)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a message to all the observers.", "response": "def notify_listeners(self, msg_type, params):\n        \"\"\"Send a message to all the observers.\"\"\"\n        for c in self.listeners:\n            c.notify(msg_type, params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the channel to the instrument _instr_.", "response": "def set_instrument(self, channel, instr, bank=0):\n        \"\"\"Set the channel to the instrument _instr_.\"\"\"\n        self.instr_event(channel, instr, bank)\n        self.notify_listeners(self.MSG_INSTR, {'channel': int(channel),\n            'instr': int(instr), 'bank': int(bank)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a control change message.", "response": "def control_change(self, channel, control, value):\n        \"\"\"Send a control change message.\n\n        See the MIDI specification for more information.\n        \"\"\"\n        if control < 0 or control > 128:\n            return False\n        if value < 0 or value > 128:\n            return False\n        self.cc_event(channel, control, value)\n        self.notify_listeners(self.MSG_CC, {'channel': int(channel),\n            'control': int(control), 'value': int(value)})\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef play_Note(self, note, channel=1, velocity=100):\n        if hasattr(note, 'velocity'):\n            velocity = note.velocity\n        if hasattr(note, 'channel'):\n            channel = note.channel\n        self.play_event(int(note) + 12, int(channel), int(velocity))\n        self.notify_listeners(self.MSG_PLAY_INT, {'channel': int(channel),\n            'note': int(note) + 12, 'velocity': int(velocity)})\n        self.notify_listeners(self.MSG_PLAY_NOTE, {'channel': int(channel),\n            'note': note, 'velocity': int(velocity)})\n        return True", "response": "Play a Note object on a channel with a velocity [ 0 - 127 ]."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops a note on a channel.", "response": "def stop_Note(self, note, channel=1):\n        \"\"\"Stop a note on a channel.\n\n        If Note.channel is set, it will take presedence over the channel\n        argument given here.\n        \"\"\"\n        if hasattr(note, 'channel'):\n            channel = note.channel\n        self.stop_event(int(note) + 12, int(channel))\n        self.notify_listeners(self.MSG_STOP_INT, {'channel': int(channel),\n            'note': int(note) + 12})\n        self.notify_listeners(self.MSG_STOP_NOTE, {'channel': int(channel),\n            'note': note})\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops all the notes on all channels.", "response": "def stop_everything(self):\n        \"\"\"Stop all the notes on all channels.\"\"\"\n        for x in range(118):\n            for c in range(16):\n                self.stop_Note(x, c)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplay the Notes in the NoteContainer nc.", "response": "def play_NoteContainer(self, nc, channel=1, velocity=100):\n        \"\"\"Play the Notes in the NoteContainer nc.\"\"\"\n        self.notify_listeners(self.MSG_PLAY_NC, {'notes': nc,\n            'channel': channel, 'velocity': velocity})\n        if nc is None:\n            return True\n        for note in nc:\n            if not self.play_Note(note, channel, velocity):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_NoteContainer(self, nc, channel=1):\n        self.notify_listeners(self.MSG_PLAY_NC, {'notes': nc,\n            'channel': channel})\n        if nc is None:\n            return True\n        for note in nc:\n            if not self.stop_Note(note, channel):\n                return False\n        return True", "response": "Stop playing the notes in NoteContainer nc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef play_Bar(self, bar, channel=1, bpm=120):\n        self.notify_listeners(self.MSG_PLAY_BAR, {'bar': bar, 'channel'\n                              : channel, 'bpm': bpm})\n\n        # length of a quarter note\n        qn_length = 60.0 / bpm\n        for nc in bar:\n            if not self.play_NoteContainer(nc[2], channel, 100):\n                return {}\n\n            # Change the quarter note length if the NoteContainer has a bpm\n            # attribute\n            if hasattr(nc[2], 'bpm'):\n                bpm = nc[2].bpm\n                qn_length = 60.0 / bpm\n            ms = qn_length * (4.0 / nc[1])\n            self.sleep(ms)\n            self.notify_listeners(self.MSG_SLEEP, {'s': ms})\n            self.stop_NoteContainer(nc[2], channel)\n        return {'bpm': bpm}", "response": "Play a Bar object and return a dictionary with the bpm lemma set on success and an empty dict with the bpm lemma set on failure."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplays several Bar objects at the same time.", "response": "def play_Bars(self, bars, channels, bpm=120):\n        \"\"\"Play several bars (a list of Bar objects) at the same time.\n\n        A list of channels should also be provided. The tempo can be changed\n        by providing one or more of the NoteContainers with a bpm argument.\n        \"\"\"\n        self.notify_listeners(self.MSG_PLAY_BARS, {'bars': bars,\n            'channels': channels, 'bpm': bpm})\n        qn_length = 60.0 / bpm  # length of a quarter note\n        tick = 0.0  # place in beat from 0.0 to bar.length\n        cur = [0] * len(bars)  # keeps the index of the NoteContainer under\n                               # investigation in each of the bars\n        playing = []  # The NoteContainers being played.\n\n        while tick < bars[0].length:\n            # Prepare a and play a list of NoteContainers that are ready for it.\n            # The list `playing_new` holds both the duration and the\n            # NoteContainer.\n            playing_new = []\n            for (n, x) in enumerate(cur):\n                (start_tick, note_length, nc) = bars[n][x]\n                if start_tick <= tick:\n                    self.play_NoteContainer(nc, channels[n])\n                    playing_new.append([note_length, n])\n                    playing.append([note_length, nc, channels[n], n])\n\n                    # Change the length of a quarter note if the NoteContainer\n                    # has a bpm attribute\n                    if hasattr(nc, 'bpm'):\n                        bpm = nc.bpm\n                        qn_length = 60.0 / bpm\n\n            # Sort the list and sleep for the shortest duration\n            if len(playing_new) != 0:\n                playing_new.sort()\n                shortest = playing_new[-1][0]\n                ms = qn_length * (4.0 / shortest)\n                self.sleep(ms)\n                self.notify_listeners(self.MSG_SLEEP, {'s': ms})\n            else:\n                # If somehow, playing_new doesn't contain any notes (something\n                # that shouldn't happen when the bar was filled properly), we\n                # make sure that at least the notes that are still playing get\n                # handled correctly.\n                if len(playing) != 0:\n                    playing.sort()\n                    shortest = playing[-1][0]\n                    ms = qn_length * (4.0 / shortest)\n                    self.sleep(ms)\n                    self.notify_listeners(self.MSG_SLEEP, {'s': ms})\n                else:\n                    # warning: this could lead to some strange behaviour. OTOH.\n                    # Leaving gaps is not the way Bar works. should we do an\n                    # integrity check on bars first?\n                    return {}\n\n            # Add shortest interval to tick\n            tick += 1.0 / shortest\n\n            # This final piece adjusts the duration in `playing` and checks if a\n            # NoteContainer should be stopped.\n            new_playing = []\n            for (length, nc, chan, n) in playing:\n                duration = 1.0 / length - 1.0 / shortest\n                if duration >= 0.00001:\n                    new_playing.append([1.0 / duration, nc, chan, n])\n                else:\n                    self.stop_NoteContainer(nc, chan)\n                    if cur[n] < len(bars[n]) - 1:\n                        cur[n] += 1\n            playing = new_playing\n\n        for p in playing:\n            self.stop_NoteContainer(p[1], p[2])\n            playing.remove(p)\n        return {'bpm': bpm}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplay a Track object.", "response": "def play_Track(self, track, channel=1, bpm=120):\n        \"\"\"Play a Track object.\"\"\"\n        self.notify_listeners(self.MSG_PLAY_TRACK, {'track': track, 'channel'\n                              : channel, 'bpm': bpm})\n        for bar in track:\n            res = self.play_Bar(bar, channel, bpm)\n            if res != {}:\n                bpm = res['bpm']\n            else:\n                return {}\n        return {'bpm': bpm}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplay a list of Tracks.", "response": "def play_Tracks(self, tracks, channels, bpm=120):\n        \"\"\"Play a list of Tracks.\n\n        If an instance of MidiInstrument is used then the instrument will be\n        set automatically.\n        \"\"\"\n        self.notify_listeners(self.MSG_PLAY_TRACKS, {'tracks': tracks,\n            'channels': channels, 'bpm': bpm})\n\n        # Set the right instruments\n        for x in range(len(tracks)):\n            instr = tracks[x].instrument\n            if isinstance(instr, MidiInstrument):\n                try:\n                    i = instr.names.index(instr.name)\n                except:\n                    i = 1\n                self.set_instrument(channels[x], i)\n            else:\n                self.set_instrument(channels[x], 1)\n        current_bar = 0\n        max_bar = len(tracks[0])\n\n        # Play the bars\n        while current_bar < max_bar:\n            playbars = []\n            for tr in tracks:\n                playbars.append(tr[current_bar])\n            res = self.play_Bars(playbars, channels, bpm)\n            if res != {}:\n                bpm = res['bpm']\n            else:\n                return {}\n            current_bar += 1\n        return {'bpm': bpm}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplay a Composition object.", "response": "def play_Composition(self, composition, channels=None, bpm=120):\n        \"\"\"Play a Composition object.\"\"\"\n        self.notify_listeners(self.MSG_PLAY_COMPOSITION, {'composition'\n                              : composition, 'channels': channels, 'bpm': bpm})\n        if channels == None:\n            channels = map(lambda x: x + 1, range(len(composition.tracks)))\n        return self.play_Tracks(composition.tracks, channels, bpm)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_log_index(f):\n    global _last_asked, _log_cache\n    (begin, end) = (0, 128)\n\n    # Most calls are sequential, this keeps track of the last value asked for so\n    # that we need to search much, much less.\n    if _last_asked is not None:\n        (lastn, lastval) = _last_asked\n        if f >= lastval:\n            if f <= _log_cache[lastn]:\n                _last_asked = (lastn, f)\n                return lastn\n            elif f <= _log_cache[lastn + 1]:\n                _last_asked = (lastn + 1, f)\n                return lastn + 1\n            begin = lastn\n\n    # Do some range checking\n    if f > _log_cache[127] or f <= 0:\n        return 128\n\n    # Binary search related algorithm to find the index\n    while begin != end:\n        n = (begin + end) // 2\n        c = _log_cache[n]\n        cp = _log_cache[n - 1] if n != 0 else 0\n        if cp < f <= c:\n            _last_asked = (n, f)\n            return n\n        if f < c:\n            end = n\n        else:\n            begin = n\n    _last_asked = (begin, f)\n    return begin", "response": "Find the index of the frequency f in the frequency table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts audio data into a frequency - amplitude table using fast fourier transform.", "response": "def find_frequencies(data, freq=44100, bits=16):\n    \"\"\"Convert audio data into a frequency-amplitude table using fast fourier\n    transformation.\n\n    Return a list of tuples (frequency, amplitude).\n\n    Data should only contain one channel of audio.\n    \"\"\"\n    # Fast fourier transform\n    n = len(data)\n    p = _fft(data)\n    uniquePts = numpy.ceil((n + 1) / 2.0)\n\n    # Scale by the length (n) and square the value to get the amplitude\n    p = [(abs(x) / float(n)) ** 2 * 2 for x in p[0:uniquePts]]\n    p[0] = p[0] / 2\n    if n % 2 == 0:\n        p[-1] = p[-1] / 2\n\n    # Generate the frequencies and zip with the amplitudes\n    s = freq / float(n)\n    freqArray = numpy.arange(0, uniquePts * s, s)\n    return zip(freqArray, p)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_notes(freqTable, maxNote=100):\n    res = [0] * 129\n    n = Note()\n    for (freq, ampl) in freqTable:\n        if freq > 0 and ampl > 0:\n            f = _find_log_index(freq)\n            if f < maxNote:\n                res[f] += ampl\n            else:\n                res[128] += ampl\n    return [(Note().from_int(x) if x < 128 else None, n) for (x, n) in\n            enumerate(res)]", "response": "Convert the frequencies and amplitude list to a ( Note maxNote"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning first channel data sample frequency sample width from a. wav file.", "response": "def data_from_file(file):\n    \"\"\"Return (first channel data, sample frequency, sample width) from a .wav\n    file.\"\"\"\n    fp = wave.open(file, 'r')\n    data = fp.readframes(fp.getnframes())\n    channels = fp.getnchannels()\n    freq = fp.getframerate()\n    bits = fp.getsampwidth()\n\n    # Unpack bytes -- warning currently only tested with 16 bit wavefiles. 32\n    # bit not supported.\n    data = struct.unpack(('%sh' % fp.getnframes()) * channels, data)\n\n    # Only use first channel\n    channel1 = []\n    n = 0\n    for d in data:\n        if n % channels == 0:\n            channel1.append(d)\n        n += 1\n    fp.close()\n    return (channel1, freq, bits)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_Note(data, freq, bits):\n    data = find_frequencies(data, freq, bits)\n    return sorted(find_notes(data), key=operator.itemgetter(1))[-1][0]", "response": "Get the frequencies feed them to find_notes and the return the Note\n    with the highest amplitude."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncut the one channel data in chunks and analyzes them separately.", "response": "def analyze_chunks(data, freq, bits, chunksize=512):\n    \"\"\"Cut the one channel data in chunks and analyzes them separately.\n\n    Making the chunksize a power of two works fastest.\n    \"\"\"\n    res = []\n    while data != []:\n        f = find_frequencies(data[:chunksize], freq, bits)\n        res.append(sorted(find_notes(f), key=operator.itemgetter(1))[-1][0])\n        data = data[chunksize:]\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncuts the sample into chunks and analyze each chunk and return a list of Note objects where each note is the most dominant Note.", "response": "def find_melody(file='440_480_clean.wav', chunksize=512):\n    \"\"\"Cut the sample into chunks and analyze each chunk.\n\n    Return a list [(Note, chunks)] where chunks is the number of chunks\n    where that note is the most dominant.\n\n    If two consequent chunks turn out to return the same Note they are\n    grouped together.\n\n    This is an experimental function.\n    \"\"\"\n    (data, freq, bits) = data_from_file(file)\n    res = []\n    for d in analyze_chunks(data, freq, bits, chunksize):\n        if res != []:\n            if res[-1][0] == d:\n                val = res[-1][1]\n                res[-1] = (d, val + 1)\n            else:\n                res.append((d, 1))\n        else:\n            res.append((d, 1))\n    return [(x, freq) for (x, freq) in res]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_Note(file, note, bpm=120, repeat=0, verbose=False):\n    m = MidiFile()\n    t = MidiTrack(bpm)\n    m.tracks = [t]\n    while repeat >= 0:\n        t.set_deltatime('\\x00')\n        t.play_Note(note)\n        t.set_deltatime(\"\\x48\")\n        t.stop_Note(note)\n        repeat -= 1\n    return m.write_file(file, verbose)", "response": "Write a Note object to a MIDI file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a mingus. NoteContainer to a MIDI file.", "response": "def write_NoteContainer(file, notecontainer, bpm=120, repeat=0, verbose=False):\n    \"\"\"Write a mingus.NoteContainer to a MIDI file.\"\"\"\n    m = MidiFile()\n    t = MidiTrack(bpm)\n    m.tracks = [t]\n    while repeat >= 0:\n        t.set_deltatime('\\x00')\n        t.play_NoteContainer(notecontainer)\n        t.set_deltatime(\"\\x48\")\n        t.stop_NoteContainer(notecontainer)\n        repeat -= 1\n    return m.write_file(file, verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_Bar(file, bar, bpm=120, repeat=0, verbose=False):\n    m = MidiFile()\n    t = MidiTrack(bpm)\n    m.tracks = [t]\n    while repeat >= 0:\n        t.play_Bar(bar)\n        repeat -= 1\n    return m.write_file(file, verbose)", "response": "Write a mingus. Bar to a MIDI file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_Track(file, track, bpm=120, repeat=0, verbose=False):\n    m = MidiFile()\n    t = MidiTrack(bpm)\n    m.tracks = [t]\n    while repeat >= 0:\n        t.play_Track(track)\n        repeat -= 1\n    return m.write_file(file, verbose)", "response": "Write a mingus. Track to a MIDI file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_Composition(file, composition, bpm=120, repeat=0, verbose=False):\n    m = MidiFile()\n    t = []\n    for x in range(len(composition.tracks)):\n        t += [MidiTrack(bpm)]\n    m.tracks = t\n    while repeat >= 0:\n        for i in range(len(composition.tracks)):\n            m.tracks[i].play_Track(composition.tracks[i])\n        repeat -= 1\n    return m.write_file(file, verbose)", "response": "Write a mingus. Composition to a MIDI file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncollecting and return the raw binary MIDI data from the tracks.", "response": "def get_midi_data(self):\n        \"\"\"Collect and return the raw, binary MIDI data from the tracks.\"\"\"\n        tracks = [t.get_midi_data() for t in self.tracks if t.track_data != '']\n        return self.header() + ''.join(tracks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef header(self):\n        tracks = a2b_hex('%04x' % len([t for t in self.tracks if\n            t.track_data != '']))\n        return 'MThd\\x00\\x00\\x00\\x06\\x00\\x01' + tracks + self.time_division", "response": "Return a header for type 1 MIDI file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the MIDI data to a file.", "response": "def write_file(self, file, verbose=False):\n        \"\"\"Collect the data from get_midi_data and write to file.\"\"\"\n        dat = self.get_midi_data()\n        try:\n            f = open(file, 'wb')\n        except:\n            print \"Couldn't open '%s' for writing.\" % file\n            return False\n        try:\n            f.write(dat)\n        except:\n            print 'An error occured while writing data to %s.' % file\n            return False\n        f.close()\n        if verbose:\n            print 'Written %d bytes to %s.' % (len(dat), file)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fingers_needed(fingering):\n    split = False # True if an open string must be played, thereby making any\n                  # subsequent strings impossible to bar with the index finger\n    indexfinger = False # True if the index finger was already accounted for\n                        # in the count\n    minimum = min(finger for finger in fingering if finger) # the index finger\n                                                            # plays the lowest\n                                                            # finger position\n    result = 0\n    for finger in reversed(fingering):\n        if finger == 0: # an open string is played\n            split = True # subsequent strings are impossible to bar with the\n                         # index finger\n        else:\n            if not split and finger == minimum: # if an open string hasn't been\n                                                # played and this is a job for\n                                                # the index finger:\n                if not indexfinger: # if the index finger hasn't been accounted\n                                    # for:\n                    result += 1\n                    indexfinger = True # index finger has now been accounted for\n            else:\n                result += 1\n    return result", "response": "Return the number of fingers needed to play the given fingering."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_tuning(instrument, description, tuning):\n    t = StringTuning(instrument, description, tuning)\n    if _known.has_key(str.upper(instrument)):\n        _known[str.upper(instrument)][1][str.upper(description)] = t\n    else:\n        _known[str.upper(instrument)] = (instrument,\n                {str.upper(description): t})", "response": "Add a new tuning to the index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_tuning(instrument, description, nr_of_strings=None, nr_of_courses=None):\n    searchi = str.upper(instrument)\n    searchd = str.upper(description)\n    keys = _known.keys()\n    for x in keys:\n        if (searchi not in keys and x.find(searchi) == 0 or searchi in keys and\n                x == searchi):\n            for (desc, tun) in _known[x][1].iteritems():\n                if desc.find(searchd) == 0:\n                    if nr_of_strings is None and nr_of_courses is None:\n                        return tun\n                    elif nr_of_strings is not None and nr_of_courses is None:\n                        if tun.count_strings() == nr_of_strings:\n                            return tun\n                    elif nr_of_strings is None and nr_of_courses is not None:\n                        if tun.count_courses() == nr_of_courses:\n                            return tun\n                    else:\n                        if tun.count_courses() == nr_of_courses\\\n                             and tun.count_strings() == nr_of_strings:\n                            return tun", "response": "Get the first tuning that satisfies the constraints."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching tunings on instrument strings courses or combination.", "response": "def get_tunings(instrument=None, nr_of_strings=None, nr_of_courses=None):\n    \"\"\"Search tunings on instrument, strings, courses or a combination.\n\n    The instrument is actually treated like a case-insensitive prefix. So\n    asking for 'bass' yields the same tunings as 'Bass Guitar'; the string\n    'ba' yields all the instruments starting with 'ba'.\n\n    Example:\n    >>> tunings.get_tunings(nr_of_string = 4)\n    >>> tunings.get_tunings('bass')\n    \"\"\"\n    search = ''\n    if instrument is not None:\n        search = str.upper(instrument)\n    result = []\n    keys = _known.keys()\n    inkeys = search in keys\n    for x in keys:\n        if (instrument is None or not inkeys and x.find(search) == 0 or\n                inkeys and search == x):\n            if nr_of_strings is None and nr_of_courses is None:\n                result += _known[x][1].values()\n            elif nr_of_strings is not None and nr_of_courses is None:\n                result += [y for y in _known[x][1].itervalues()\n                           if y.count_strings() == nr_of_strings]\n            elif nr_of_strings is None and nr_of_courses is not None:\n                result += [y for y in _known[x][1].itervalues()\n                           if y.count_courses() == nr_of_courses]\n            else:\n                result += [y for y in _known[x][1].itervalues()\n                           if y.count_strings() == nr_of_strings\n                            and y.count_courses() == nr_of_courses]\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_courses(self):\n        c = 0\n        for x in self.tuning:\n            if type(x) == list:\n                c += len(x)\n            else:\n                c += 1\n        return float(c) / len(self.tuning)", "response": "Return the average number of courses per string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_frets(self, note, maxfret=24):\n        result = []\n        if type(note) == str:\n            note = Note(note)\n        for x in self.tuning:\n            if type(x) == list:\n                base = x[0]\n            else:\n                base = x\n            diff = base.measure(note)\n            if 0 <= diff <= maxfret:\n                result.append(diff)\n            else:\n                result.append(None)\n        return result", "response": "Return a list with for each string the fret on which the note is played or None if it can t be played on that particular string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of possible fingerings for the given notes.", "response": "def find_fingering(self, notes, max_distance=4, not_strings=[]):\n        \"\"\"Return a list [(string, fret)] of possible fingerings for\n        'notes'.\n\n        The notes parameter should be a list of strings or Notes or a\n        NoteContainer; max_distance denotes the maximum distance between\n        frets; not_strings can be used to disclude certain strings and is\n        used internally to recurse.\n\n        Example:\n        >>> t = tunings.StringTuning('test', 'test', ['A-3', 'E-4', 'A-5'])\n        >>> t.find_fingering(['E-4', 'B-4'])\n        [[(0, 7), (1, 7)], [(1, 0), (0, 14)]]\n        \"\"\"\n        if notes is None:\n            return []\n        if len(notes) == 0:\n            return []\n        first = notes[0]\n        notes = notes[1:]\n        frets = self.find_frets(first)\n        result = []\n        for (string, fret) in enumerate(frets):\n            if fret is not None and string not in not_strings:\n                if len(notes) > 0:\n                    # recursively find fingerings for\n                    # remaining notes\n                    r = self.find_fingering(notes, max_distance, not_strings\n                             + [string])\n                    if r != []:\n                        for f in r:\n                            result.append([(string, fret)] + f)\n                else:\n                    result.append([(string, fret)])\n\n        # filter impossible fingerings and sort\n        res = []\n        for r in result:\n            (min, max) = (1000, -1)\n            frets = 0\n            for (string, fret) in r:\n                if fret > max:\n                    max = fret\n                if fret < min and fret != 0:\n                    min = fret\n                frets += fret\n            if 0 <= max - min < max_distance or min == 1000 or max == -1:\n                res.append((frets, r))\n        return [r for (_, r) in sorted(res)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the possible fingerings for a given note.", "response": "def find_chord_fingering(self, notes, max_distance=4, maxfret=18,\n            max_fingers=4, return_best_as_NoteContainer=False):\n        \"\"\"Return a list of fret lists that are considered possible fingerings.\n\n        This function only looks at and matches on the note _names_ so it\n        does more than find_fingering.\n\n        Example:\n        >>> t = tunings.get_tuning('guitar', 'standard', 6, 1)\n        >>> t.find_chord_fingering(NoteContainer().from_chord('Am'))\n        [[0, 0, 2, 2, 1, 0], [0, 3, 2, 2, 1, 0], ......]\n        \"\"\"\n        def follow(string, next, name, prev=-1):\n            \"\"\"Follow the fret 'next' on 'string'; build result on the way.\"\"\"\n            if string >= len(self.tuning) - 1:\n                return [[(next, name)]]\n            result = []\n            cur = res[string][next]\n            if cur != []:\n                for y in cur[1]:\n                    for sub in follow(string + 1, y[0], y[1]):\n                        if prev < 0:\n                            result.append([(next, name)] + sub)\n                        else:\n                            if sub[0][0] == 0 or abs(sub[0][0] - prev)\\\n                                 < max_distance:\n                                result.append([(next, name)] + sub)\n            for s in follow(string + 1, maxfret + 1, None, next):\n                result.append([(next, name)] + s)\n            return [[(next, name)]] if result == [] else result\n\n        def make_lookup_table():\n            \"\"\"Prepare the lookup table.\n\n            table[string][fret] = (name, dest_frets)\n            \"\"\"\n            res = [[[] for x in xrange(maxfret + 2)] for x in\n                   xrange(len(self.tuning) - 1)]\n            for x in xrange(0, len(self.tuning) - 1):\n                addedNone = -1\n                next = fretdict[x + 1]\n                for (fret, name) in fretdict[x]:\n                    for (f2, n2) in next:\n                        if n2 != name and (f2 == 0 or abs(fret - f2)\n                                 < max_distance):\n                            if res[x][fret] != []:\n                                res[x][fret][1].append((f2, n2))\n                            else:\n                                res[x][fret] = (name, [(f2, n2)])\n                        if addedNone < x:\n                            if res[x][maxfret + 1] != []:\n                                res[x][maxfret + 1][1].append((f2, n2))\n                            else:\n                                res[x][maxfret + 1] = (None, [(f2, n2)])\n                    addedNone = x\n            return res\n\n        # Convert to NoteContainer if necessary\n        n = notes\n        if notes != [] and type(notes) == list and type(notes[0]) == str:\n            n = NoteContainer(notes)\n\n        # Check number of note names.\n        notenames = [x.name for x in n]\n        if len(notenames) == 0 or len(notenames) > len(self.tuning):\n            return []\n\n        # Make string-fret dictionary\n        fretdict = []\n        for x in xrange(0, len(self.tuning)):\n            fretdict.append(self.find_note_names(notes, x, maxfret))\n\n        # Build table\n        res = make_lookup_table()\n\n        # Build result using table\n        result = []\n\n        # For each fret on the first string\n        for (i, y) in enumerate(res[0]):\n            if y != []:\n                (yname, next) = (y[0], y[1])\n\n                # For each destination fret in y\n                for (fret, name) in next:\n\n                    # For each followed result\n                    for s in follow(1, fret, name):\n                        subresult = [(i, yname)] + s\n\n                        # Get boundaries\n                        (mi, ma, names) = (1000, -1000, [])\n                        for (f, n) in subresult:\n                            if n is not None:\n                                if f != 0 and f <= mi:\n                                    mi = f\n                                if f != 0 and f >= ma:\n                                    ma = f\n                                names.append(n)\n\n                        # Enforce boundaries\n                        if abs(ma - mi) < max_distance:\n                            # Check if all note\n                            # names are present\n                            covered = True\n                            for n in notenames:\n                                if n not in names:\n                                    covered = False\n\n                            # Add to result\n                            if covered and names != []:\n                                result.append([y[0] if y[1]\n                                         is not None else y[1] for y in\n                                        subresult])\n\n        # Return semi-sorted list\n        s = sorted(result, key=lambda x: sum([t if t is not None else 1000\n                   for (i, t) in enumerate(x)]))\n        s = filter(lambda a: fingers_needed(a) <= max_fingers, s)\n        if not return_best_as_NoteContainer:\n            return s\n        else:\n            rnotes = self.frets_to_NoteContainer(s[0])\n            for (i, x) in enumerate(rnotes):\n                if x.string < len(self.tuning) - 1:\n                    if res[x.string][x.fret] != []:\n                        rnotes[i].name = res[x.string][x.fret][0]\n            return rnotes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a list such as returned by find_fret to a NoteContainer.", "response": "def frets_to_NoteContainer(self, fingering):\n        \"\"\"Convert a list such as returned by find_fret to a NoteContainer.\"\"\"\n\n        res = []\n        for (string, fret) in enumerate(fingering):\n            if fret is not None:\n                res.append(self.get_Note(string, fret))\n        return NoteContainer(res)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of note names in ascending order. Notelist should be a list of Notes note - strings or a NoteContainer.", "response": "def find_note_names(self, notelist, string=0, maxfret=24):\n        \"\"\"Return a list [(fret, notename)] in ascending order.\n\n        Notelist should be a list of Notes, note-strings or a NoteContainer.\n\n        Example:\n        >>> t = tunings.StringTuning('test', 'test', ['A-3', 'A-4'])\n        >>> t.find_note_names(['A', 'C', 'E'], 0, 12)\n        [(0, 'E'), (5, 'A'), (8, 'C'), (12, 'E')]\n        \"\"\"\n        n = notelist\n        if notelist != [] and type(notelist[0]) == str:\n            n = NoteContainer(notelist)\n        result = []\n        names = [x.name for x in n]\n        int_notes = [notes.note_to_int(x) for x in names]\n\n        # Base of the string\n        s = int(self.tuning[string]) % 12\n        for x in xrange(0, maxfret + 1):\n            if (s + x) % 12 in int_notes:\n                result.append((x, names[int_notes.index((s + x) % 12)]))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the Note on string fret.", "response": "def get_Note(self, string=0, fret=0, maxfret=24):\n        \"\"\"Return the Note on 'string', 'fret'.\n\n        Throw a RangeError if either the fret or string is unplayable.\n\n        Examples:\n        >>> t = tunings.StringTuning('test', 'test', ['A-3', 'A-4'])\n        >>> t,get_Note(0, 0)\n        'A-3'\n        >>> t.get_Note(0, 1)\n        'A#-3'\n        >>> t.get_Note(1, 0)\n        'A-4'\n        \"\"\"\n        if 0 <= string < self.count_strings():\n            if 0 <= fret <= maxfret:\n                s = self.tuning[string]\n                if type(s) == list:\n                    s = s[0]\n                n = Note(int(s) + fret)\n                n.string = string\n                n.fret = fret\n                return n\n            else:\n                raise RangeError(\"Fret '%d' on string '%d' is out of range\"\n                        % (string, fret))\n        else:\n            raise RangeError(\"String '%d' out of range\" % string)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading image and return an image object", "response": "def load_img(name):\n    \"\"\"Load image and return an image object\"\"\"\n\n    fullname = name\n    try:\n        image = pygame.image.load(fullname)\n        if image.get_alpha() is None:\n            image = image.convert()\n        else:\n            image = image.convert_alpha()\n    except pygame.error, message:\n        print \"Error: couldn't load image: \", fullname\n        raise SystemExit, message\n    return (image, image.get_rect())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef play_note(note):\n\n    index = None\n    if note == Note('B', 2):\n        index = 0\n    elif note == Note('A', 2):\n        index = 1\n    elif note == Note('G', 2):\n        index = 2\n    elif note == Note('E', 2):\n        index = 3\n    elif note == Note('C', 2):\n        index = 4\n    elif note == Note('A', 3):\n        index = 5\n    elif note == Note('B', 3):\n        index = 6\n    elif note == Note('A#', 2):\n        index = 7\n    elif note == Note('G#', 2):\n        index = 8\n    if index != None and status == 'record':\n        playing.append([index, tick])\n        recorded.append([index, tick, note])\n        recorded_buffer.append([index, tick])\n    fluidsynth.play_Note(note, 9, 100)", "response": "play_note determines which pad was hit and send the applet play request to the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a composition to the suite.", "response": "def add_composition(self, composition):\n        \"\"\"Add a composition to the suite.\n\n        Raise an UnexpectedObjectError when the supplied argument is not a\n        Composition object.\n        \"\"\"\n        if not hasattr(composition, 'tracks'):\n            raise UnexpectedObjectError(\"Object '%s' not expected. Expecting \"\n                    \"a mingus.containers.Composition object.\" % composition)\n        self.compositions.append(composition)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the author of the suite.", "response": "def set_author(self, author, email=''):\n        \"\"\"Set the author of the suite.\"\"\"\n        self.author = author\n        self.email = email"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the title and subtitle of the suite.", "response": "def set_title(self, title, subtitle=''):\n        \"\"\"Set the title and the subtitle of the suite.\"\"\"\n        self.title = title\n        self.subtitle = subtitle"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_range(self, range):\n        if type(range[0]) == str:\n            range[0] = Note(range[0])\n            range[1] = Note(range[1])\n        if not hasattr(range[0], 'name'):\n            raise UnexpectedObjectError(\"Unexpected object '%s'. \"\n                    \"Expecting a mingus.containers.Note object\" % range[0])\n        self.range = range", "response": "Set the range of the instrument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntesting whether a note is in the range of this Instrument.", "response": "def note_in_range(self, note):\n        \"\"\"Test whether note is in the range of this Instrument.\n\n        Return True if so, False otherwise.\n        \"\"\"\n        if type(note) == str:\n            note = Note(note)\n        if not hasattr(note, 'name'):\n            raise UnexpectedObjectError(\"Unexpected object '%s'. \"\n                    \"Expecting a mingus.containers.Note object\" % note)\n        if note >= self.range[0] and note <= self.range[1]:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if the notes lie within the range of the instrument. Return True if so False otherwise.", "response": "def can_play_notes(self, notes):\n        \"\"\"Test if the notes lie within the range of the instrument.\n\n        Return True if so, False otherwise.\n        \"\"\"\n        if hasattr(notes, 'notes'):\n            notes = notes.notes\n        if type(notes) != list:\n            notes = [notes]\n        for n in notes:\n            if not self.note_in_range(n):\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef play_Note(self, note):\n        velocity = 64\n        channel = 1\n        if hasattr(note, 'dynamics'):\n            if 'velocity' in note.dynamics:\n                velocity = note.dynamics['velocity']\n            if 'channel' in note.dynamics:\n                channel = note.dynamics['channel']\n        if hasattr(note, 'channel'):\n            channel = note.channel\n        if hasattr(note, 'velocity'):\n            velocity = note.velocity\n        if self.change_instrument:\n            self.set_instrument(channel, self.instrument)\n            self.change_instrument = False\n        self.track_data += self.note_on(channel, int(note) + 12, velocity)", "response": "Convert a Note object to a midi event and adds it to the track_data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef play_NoteContainer(self, notecontainer):\n        if len(notecontainer) <= 1:\n            [self.play_Note(x) for x in notecontainer]\n        else:\n            self.play_Note(notecontainer[0])\n            self.set_deltatime(0)\n            [self.play_Note(x) for x in notecontainer[1:]]", "response": "Convert a mingus. containers. NoteContainer to the equivalent MIDI\n        events and add it to the track_data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a Bar object to MIDI events and write them to the track_data.", "response": "def play_Bar(self, bar):\n        \"\"\"Convert a Bar object to MIDI events and write them to the\n        track_data.\"\"\"\n        self.set_deltatime(self.delay)\n        self.delay = 0\n        self.set_meter(bar.meter)\n        self.set_deltatime(0)\n        self.set_key(bar.key)\n        for x in bar:\n            tick = int(round((1.0 / x[1]) * 288))\n            if x[2] is None or len(x[2]) == 0:\n                self.delay += tick\n            else:\n                self.set_deltatime(self.delay)\n                self.delay = 0\n                if hasattr(x[2], 'bpm'):\n                    self.set_deltatime(0)\n                    self.set_tempo(x[2].bpm)\n                self.play_NoteContainer(x[2])\n                self.set_deltatime(self.int_to_varbyte(tick))\n                self.stop_NoteContainer(x[2])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a Track object to MIDI events and write them to the the track_data.", "response": "def play_Track(self, track):\n        \"\"\"Convert a Track object to MIDI events and write them to the\n        track_data.\"\"\"\n        if hasattr(track, 'name'):\n            self.set_track_name(track.name)\n        self.delay = 0\n        instr = track.instrument\n        if hasattr(instr, 'instrument_nr'):\n            self.change_instrument = True\n            self.instrument = instr.instrument_nr\n        for bar in track:\n            self.play_Bar(bar)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop_Note(self, note):\n        velocity = 64\n        channel = 1\n        if hasattr(note, 'dynamics'):\n            if 'velocity' in note.dynamics:\n                velocity = note.dynamics['velocity']\n            if 'channel' in note.dynamics:\n                channel = note.dynamics['channel']\n        if hasattr(note, 'channel'):\n            channel = note.channel\n        if hasattr(note, 'velocity'):\n            velocity = note.velocity\n        self.track_data += self.note_off(channel, int(note) + 12, velocity)", "response": "Add a note_off event for note to event_track."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the events for each note in the NoteContainer.", "response": "def stop_NoteContainer(self, notecontainer):\n        \"\"\"Add note_off events for each note in the NoteContainer to the\n        track_data.\"\"\"\n        # if there is more than one note in the container, the deltatime should\n        # be set back to zero after the first one has been stopped\n        if len(notecontainer) <= 1:\n            [self.stop_Note(x) for x in notecontainer]\n        else:\n            self.stop_Note(notecontainer[0])\n            self.set_deltatime(0)\n            [self.stop_Note(x) for x in notecontainer[1:]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a program change and bank select event to the track_data.", "response": "def set_instrument(self, channel, instr, bank=1):\n        \"\"\"Add a program change and bank select event to the track_data.\"\"\"\n        self.track_data += self.select_bank(channel, bank)\n        self.track_data += self.program_change_event(channel, instr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the bytes for the header of the track.", "response": "def header(self):\n        \"\"\"Return the bytes for the header of track.\n\n        The header contains the length of the track_data, so you'll have to\n        call this function when you're done adding data (when you're not\n        using get_midi_data).\n        \"\"\"\n        chunk_size = a2b_hex('%08x' % (len(self.track_data)\n                              + len(self.end_of_track())))\n        return TRACK_HEADER + chunk_size"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts and return the paraters as a MIDI event in bytes.", "response": "def midi_event(self, event_type, channel, param1, param2=None):\n        \"\"\"Convert and return the paraters as a MIDI event in bytes.\"\"\"\n        assert event_type < 0x80 and event_type >= 0\n        assert channel < 16 and channel >= 0\n        tc = a2b_hex('%x%x' % (event_type, channel))\n        if param2 is None:\n            params = a2b_hex('%02x' % param1)\n        else:\n            params = a2b_hex('%02x%02x' % (param1, param2))\n        return self.delta_time + tc + params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn bytes for a note off event.", "response": "def note_off(self, channel, note, velocity):\n        \"\"\"Return bytes for a 'note off' event.\"\"\"\n        return self.midi_event(NOTE_OFF, channel, note, velocity)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef note_on(self, channel, note, velocity):\n        return self.midi_event(NOTE_ON, channel, note, velocity)", "response": "Return a MIDI note_on event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef controller_event(self, channel, contr_nr, contr_val):\n        return self.midi_event(CONTROLLER, channel, contr_nr, contr_val)", "response": "Return the bytes for a MIDI controller event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the delta_time. Can be an integer or a variable length byte.", "response": "def set_deltatime(self, delta_time):\n        \"\"\"Set the delta_time.\n\n        Can be an integer or a variable length byte.\n        \"\"\"\n        if type(delta_time) == int:\n            delta_time = self.int_to_varbyte(delta_time)\n        self.delta_time = delta_time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_tempo(self, bpm):\n        self.bpm = bpm\n        self.track_data += self.set_tempo_event(self.bpm)", "response": "Convert the bpm to a midi event and write it to the track_data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the microseconds per quarter note.", "response": "def set_tempo_event(self, bpm):\n        \"\"\"Calculate the microseconds per quarter note.\"\"\"\n        ms_per_min = 60000000\n        mpqn = a2b_hex('%06x' % (ms_per_min / bpm))\n        return self.delta_time + META_EVENT + SET_TEMPO + '\\x03' + mpqn"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef time_signature_event(self, meter=(4, 4)):\n        numer = a2b_hex('%02x' % meter[0])\n        denom = a2b_hex('%02x' % int(log(meter[1], 2)))\n        return self.delta_time + META_EVENT + TIME_SIGNATURE + '\\x04' + numer\\\n             + denom + '\\x18\\x08'", "response": "Return a time signature event for meter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_key(self, key='C'):\n        if isinstance(key, Key):\n            key = key.name[0]\n        self.track_data += self.key_signature_event(key)", "response": "Add a key signature event to the track_data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the bytes for a key signature event.", "response": "def key_signature_event(self, key='C'):\n        \"\"\"Return the bytes for a key signature event.\"\"\"\n        if key.islower():\n            val = minor_keys.index(key) - 7\n            mode = '\\x01'\n        else:\n            val = major_keys.index(key) - 7\n            mode = '\\x00'\n        if val < 0:\n            val = 256 + val\n        key = a2b_hex('%02x' % val)\n        return '{0}{1}{2}\\x02{3}{4}'.format(self.delta_time, META_EVENT,\n                KEY_SIGNATURE, key, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the bytes for a track name meta event.", "response": "def track_name_event(self, name):\n        \"\"\"Return the bytes for a track name meta event.\"\"\"\n        l = self.int_to_varbyte(len(name))\n        return '\\x00' + META_EVENT + TRACK_NAME + l + name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef int_to_varbyte(self, value):\n        # Warning: bit kung-fu ahead. The length of the integer in bytes\n        length = int(log(max(value, 1), 0x80)) + 1\n\n        # Remove the highest bit and move the bits to the right if length > 1\n        bytes = [value >> i * 7 & 0x7F for i in range(length)]\n        bytes.reverse()\n\n        # Set the first bit on every one but the last bit.\n        for i in range(len(bytes) - 1):\n            bytes[i] = bytes[i] | 0x80\n        return pack('%sB' % len(bytes), *bytes)", "response": "Convert an integer into a variable length byte."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a list of chord functions or a string to a list of chords.", "response": "def to_chords(progression, key='C'):\n    \"\"\"Convert a list of chord functions or a string to a list of chords.\n\n    Examples:\n    >>> to_chords(['I', 'V7'])\n    [['C', 'E', 'G'], ['G', 'B', 'D', 'F']]\n    >>> to_chords('I7')\n    [['C', 'E', 'G', 'B']]\n\n    Any number of accidentals can be used as prefix to augment or diminish;\n    for example: bIV or #I.\n    \n    All the chord abbreviations in the chord module can be used as suffixes;\n    for example: Im7, IVdim7, etc.\n    \n    You can combine prefixes and suffixes to manage complex progressions:\n    #vii7, #iidim7, iii7, etc.\n    \n    Using 7 as suffix is ambiguous, since it is classicly used to denote the\n    seventh chord when talking about progressions instead of just the\n    dominant seventh chord. We have taken the classic route; I7 will get\n    you a major seventh chord. If you specifically want a dominanth seventh,\n    use Idom7.\n    \"\"\"\n    if type(progression) == str:\n        progression = [progression]\n    result = []\n    for chord in progression:\n        # strip preceding accidentals from the string\n        (roman_numeral, acc, suffix) = parse_string(chord)\n\n        # There is no roman numeral parsing, just a simple check. Sorry to\n        # disappoint. warning Should throw exception\n        if roman_numeral not in numerals:\n            return []\n\n        # These suffixes don't need any post processing\n        if suffix == '7' or suffix == '':\n            roman_numeral += suffix\n\n            # ahh Python. Everything is a dict.\n            r = chords.__dict__[roman_numeral](key)\n        else:\n            r = chords.__dict__[roman_numeral](key)\n            r = chords.chord_shorthand[suffix](r[0])\n\n        while acc < 0:\n            r = map(notes.diminish, r)\n            acc += 1\n        while acc > 0:\n            r = map(notes.augment, r)\n            acc -= 1\n        result.append(r)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the harmonic function of chord in key.", "response": "def determine(chord, key, shorthand=False):\n    \"\"\"Determine the harmonic function of chord in key.\n\n    This function can also deal with lists of chords.\n\n    Examples:\n    >>> determine(['C', 'E', 'G'], 'C')\n    ['tonic']\n    >>> determine(['G', 'B', 'D'], 'C')\n    ['dominant']\n    >>> determine(['G', 'B', 'D', 'F'], 'C', True)\n    ['V7']\n    >>> determine([['C', 'E', 'G'], ['G', 'B', 'D']], 'C', True)\n    [['I'], ['V']]\n    \"\"\"\n    result = []\n\n    # Handle lists of chords\n    if type(chord[0]) == list:\n        for c in chord:\n            result.append(determine(c, key, shorthand))\n        return result\n\n    func_dict = {\n        'I': 'tonic',\n        'ii': 'supertonic',\n        'iii': 'mediant',\n        'IV': 'subdominant',\n        'V': 'dominant',\n        'vi': 'submediant',\n        'vii': 'subtonic',\n        }\n    expected_chord = [\n        ['I', 'M', 'M7'],\n        ['ii', 'm', 'm7'],\n        ['iii', 'm', 'm7'],\n        ['IV', 'M', 'M7'],\n        ['V', 'M', '7'],\n        ['vi', 'm', 'm7'],\n        ['vii', 'dim', 'm7b5'],\n        ]\n    type_of_chord = chords.determine(chord, True, False, True)\n    for chord in type_of_chord:\n        name = chord[0]\n\n        # Get accidentals\n        a = 1\n        for n in chord[1:]:\n            if n == 'b':\n                name += 'b'\n            elif n == '#':\n                name += '#'\n            else:\n                break\n            a += 1\n        chord_type = chord[a:]\n\n        # Determine chord function\n        (interval_type, interval) = intervals.determine(key, name).split(' ')\n        if interval == 'unison':\n            func = 'I'\n        elif interval == 'second':\n            func = 'ii'\n        elif interval == 'third':\n            func = 'iii'\n        elif interval == 'fourth':\n            func = 'IV'\n        elif interval == 'fifth':\n            func = 'V'\n        elif interval == 'sixth':\n            func = 'vi'\n        elif interval == 'seventh':\n            func = 'vii'\n\n        # Check whether the chord is altered or not\n        for x in expected_chord:\n            if x[0] == func:\n                # Triads\n                if chord_type == x[1]:\n                    if not shorthand:\n                        func = func_dict[func]\n                elif chord_type == x[2]:\n                    # Sevenths\n                    if shorthand:\n                        func += '7'\n                    else:\n                        func = func_dict[func] + ' seventh'\n                else:\n                    # Other\n                    if shorthand:\n                        func += chord_type\n                    else:\n                        func = func_dict[func]\\\n                             + chords.chord_shorthand_meaning[chord_type]\n\n        # Handle b's and #'s (for instance Dbm in key C is bII)\n        if shorthand:\n            if interval_type == 'minor':\n                func = 'b' + func\n            elif interval_type == 'augmented':\n                func = '#' + func\n            elif interval_type == 'diminished':\n                func = 'bb' + func\n        else:\n            if interval_type == 'minor':\n                func = 'minor ' + func\n            elif interval_type == 'augmented':\n                func = 'augmented ' + func\n            elif interval_type == 'diminished':\n                func = 'diminished ' + func\n\n        # Add to results\n        result.append(func)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a string into a tuple of roman numeral accidentals chord suffix.", "response": "def parse_string(progression):\n    \"\"\"Return a tuple (roman numeral, accidentals, chord suffix).\n\n    Examples:\n    >>> parse_string('I')\n    ('I', 0, '')\n    >>> parse_string('bIM7')\n    ('I', -1, 'M7')\n    \"\"\"\n    acc = 0\n    roman_numeral = ''\n    suffix = ''\n    i = 0\n    for c in progression:\n        if c == '#':\n            acc += 1\n        elif c == 'b':\n            acc -= 1\n        elif c.upper() == 'I' or c.upper() == 'V':\n            roman_numeral += c.upper()\n        else:\n            break\n        i += 1\n    suffix = progression[i:]\n    return (roman_numeral, acc, suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a string from tuples returned by parse_string.", "response": "def tuple_to_string(prog_tuple):\n    \"\"\"Create a string from tuples returned by parse_string.\"\"\"\n    (roman, acc, suff) = prog_tuple\n    if acc > 6:\n        acc = 0 - acc % 6\n    elif acc < -6:\n        acc = acc % 6\n    while acc < 0:\n        roman = 'b' + roman\n        acc += 1\n    while acc > 0:\n        roman = '#' + roman\n        acc -= 1\n    return roman + suff"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing simple harmonic substitutions. Return a list of possible substitions for the given progression.", "response": "def substitute_harmonic(progression, substitute_index, ignore_suffix=False):\n    \"\"\"Do simple harmonic substitutions. Return a list of possible substitions\n    for progression[substitute_index].\n\n    If ignore_suffix is set to True the suffix of the chord being\n    substituted will be ignored. Otherwise only progressions without a\n    suffix, or with suffix '7' will be substituted.\n\n    The following table is used to convert progressions:\n    || I || III ||\n    || I || VI ||\n    || IV || II ||\n    || IV || VI ||\n    || V || VII ||\n    \"\"\"\n    simple_substitutions = [('I', 'III'), ('I', 'VI'), ('IV', 'II'),\n            ('IV', 'VI'), ('V', 'VII')]\n    res = []\n    (roman, acc, suff) = parse_string(progression[substitute_index])\n    if suff == '' or suff == '7' or ignore_suffix:\n        for subs in simple_substitutions:\n            r = subs[1] if roman == subs[0] else None\n            if r == None:\n                r = subs[0] if roman == subs[1] else None\n            if r != None:\n                suff = suff if suff == '7' else ''\n                res.append(tuple_to_string((r, acc, suff)))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubstituting minor chords for its major equivalent.", "response": "def substitute_minor_for_major(progression, substitute_index,\n        ignore_suffix=False):\n    \"\"\"Substitute minor chords for its major equivalent.\n\n    'm' and 'm7' suffixes recognized, and ['II', 'III', 'VI'] if there is no\n    suffix.\n\n    Examples:\n    >>> substitute_minor_for_major(['VI'], 0)\n    ['I']\n    >>> substitute_minor_for_major(['Vm'], 0)\n    ['bVIIM']\n    >>> substitute_minor_for_major(['VIm7'], 0)\n    ['IM7']\n    \"\"\"\n    (roman, acc, suff) = parse_string(progression[substitute_index])\n    res = []\n\n    # Minor to major substitution\n    if suff == 'm' or suff == 'm7' or suff == '' and roman in ['II', 'III', 'VI'\n            ] or ignore_suffix:\n        n = skip(roman, 2)\n        a = interval_diff(roman, n, 3) + acc\n        if suff == 'm' or ignore_suffix:\n            res.append(tuple_to_string((n, a, 'M')))\n        elif suff == 'm7' or ignore_suffix:\n            res.append(tuple_to_string((n, a, 'M7')))\n        elif suff == '' or ignore_suffix:\n            res.append(tuple_to_string((n, a, '')))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef substitute_diminished_for_diminished(progression, substitute_index,\n        ignore_suffix=False):\n    \"\"\"Substitute a diminished chord for another diminished chord.\n\n    'dim' and 'dim7' suffixes recognized, and 'VI' if there is no suffix.\n\n    Example:\n    >>> substitute_diminished_for_diminished(['VII'], 0)\n    ['IIdim', 'bIVdim', 'bbVIdim']\n    \"\"\"\n    (roman, acc, suff) = parse_string(progression[substitute_index])\n    res = []\n\n    # Diminished progressions\n    if suff == 'dim7' or suff == 'dim' or suff == '' and roman in ['VII']\\\n         or ignore_suffix:\n        if suff == '':\n            suff = 'dim'\n\n        # Add diminished chord\n        last = roman\n        for x in range(3):\n            next = skip(last, 2)\n            acc += interval_diff(last, next, 3)\n            res.append(tuple_to_string((next, acc, suff)))\n            last = next\n    return res", "response": "Substitute a diminished chord for another diminished chord."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef substitute(progression, substitute_index, depth=0):\n    res = []\n    simple_substitutions = [\n        ('I', 'III'),\n        ('I', 'VI'),\n        ('IV', 'II'),\n        ('IV', 'VI'),\n        ('V', 'VII'),\n        ('V', 'VIIdim7'),\n        ('V', 'IIdim7'),\n        ('V', 'IVdim7'),\n        ('V', 'bVIIdim7'),\n        ]\n    p = progression[substitute_index]\n    (roman, acc, suff) = parse_string(p)\n\n    # Do the simple harmonic substitutions\n    if suff == '' or suff == '7':\n        for subs in simple_substitutions:\n            r = None\n            if roman == subs[0]:\n                r = subs[1]\n            elif roman == subs[1]:\n                r = subs[0]\n            if r != None:\n                res.append(tuple_to_string((r, acc, '')))\n\n                # Add seventh or triad depending on r\n                if r[-1] != '7':\n                    res.append(tuple_to_string((r, acc, '7')))\n                else:\n                    res.append(tuple_to_string((r[:-1], acc, '')))\n\n    if suff == '' or suff == 'M' or suff == 'm':\n        res.append(tuple_to_string((roman, acc, suff + '7')))\n\n    if suff == 'm' or suff == 'm7':\n        n = skip(roman, 2)\n        a = interval_diff(roman, n, 3) + acc\n        res.append(tuple_to_string((n, a, 'M')))\n        res.append(tuple_to_string((n, a, 'M7')))\n\n    # Major to minor substitution\n    if suff == 'M' or suff == 'M7':\n        n = skip(roman, 5)\n        a = interval_diff(roman, n, 9) + acc\n        res.append(tuple_to_string((n, a, 'm')))\n        res.append(tuple_to_string((n, a, 'm7')))\n\n    if suff == 'dim7' or suff == 'dim':\n        # Add the corresponding dominant seventh\n        res.append(tuple_to_string((skip(roman, 5), acc, 'dom7')))\n\n        n = skip(roman, 1)\n        res.append(tuple_to_string((n, acc + interval_diff(roman, n, 1),\n            'dom7')))\n\n        # Add diminished chord\n        last = roman\n        for x in range(4):\n            next = skip(last, 2)\n            acc += interval_diff(last, next, 3)\n            res.append(tuple_to_string((next, acc, suff)))\n            last = next\n    res2 = []\n    if depth > 0:\n        for x in res:\n            new_progr = progression\n            new_progr[substitute_index] = x\n            res2 += substitute(new_progr, substitute_index, depth - 1)\n    return res + res2", "response": "Returns a list of possible substitutions for the given progression."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interval_diff(progression1, progression2, interval):\n    i = numeral_intervals[numerals.index(progression1)]\n    j = numeral_intervals[numerals.index(progression2)]\n    acc = 0\n    if j < i:\n        j += 12\n    while j - i > interval:\n        acc -= 1\n        j -= 1\n    while j - i < interval:\n        acc += 1\n        j += 1\n    return acc", "response": "Return the number of half steps between progression1 and progression2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nskipping the given places to the next roman numeral.", "response": "def skip(roman_numeral, skip=1):\n    \"\"\"Skip the given places to the next roman numeral.\n\n    Examples:\n    >>> skip('I')\n    'II'\n    >>> skip('VII')\n    'I'\n    >>> skip('I', 2)\n    'III'\n    \"\"\"\n    i = numerals.index(roman_numeral) + skip\n    return numerals[i % 7]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a note to the container and sorts the notes from low to high.", "response": "def add_note(self, note, octave=None, dynamics={}):\n        \"\"\"Add a note to the container and sorts the notes from low to high.\n\n        The note can either be a string, in which case you could also use\n        the octave and dynamics arguments, or a Note object.\n        \"\"\"\n        if type(note) == str:\n            if octave is not None:\n                note = Note(note, octave, dynamics)\n            elif len(self.notes) == 0:\n                note = Note(note, 4, dynamics)\n            else:\n                if Note(note, self.notes[-1].octave) < self.notes[-1]:\n                    note = Note(note, self.notes[-1].octave + 1, dynamics)\n                else:\n                    note = Note(note, self.notes[-1].octave, dynamics)\n        if not hasattr(note, 'name'):\n            raise UnexpectedObjectError(\"Object '%s' was not expected. \"\n                    \"Expecting a mingus.containers.Note object.\" % note)\n        if note not in self.notes:\n            self.notes.append(note)\n            self.notes.sort()\n        return self.notes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_notes(self, notes):\n        if hasattr(notes, 'notes'):\n            for x in notes.notes:\n                self.add_note(x)\n            return self.notes\n        elif hasattr(notes, 'name'):\n            self.add_note(notes)\n            return self.notes\n        elif type(notes) == str:\n            self.add_note(notes)\n            return self.notes\n        for x in notes:\n            if type(x) == list and len(x) != 1:\n                if len(x) == 2:\n                    self.add_note(x[0], x[1])\n                else:\n                    self.add_note(x[0], x[1], x[2])\n            else:\n                self.add_note(x)\n        return self.notes", "response": "Feed notes to self. add_note."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nemptying the container and add the notes in the shorthand.", "response": "def from_chord_shorthand(self, shorthand):\n        \"\"\"Empty the container and add the notes in the shorthand.\n\n        See mingus.core.chords.from_shorthand for an up to date list of\n        recognized format.\n\n        Example:\n        >>> NoteContainer().from_chord_shorthand('Am')\n        ['A-4', 'C-5', 'E-5']\n        \"\"\"\n        self.empty()\n        self.add_notes(chords.from_shorthand(shorthand))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nemptying the container and add the notes described in the startnote and shorthand.", "response": "def from_interval_shorthand(self, startnote, shorthand, up=True):\n        \"\"\"Empty the container and add the note described in the startnote and\n        shorthand.\n\n        See core.intervals for the recognized format.\n\n        Examples:\n        >>> nc = NoteContainer()\n        >>> nc.from_interval_shorthand('C', '5')\n        ['C-4', 'G-4']\n        >>> nc.from_interval_shorthand('C', '5', False)\n        ['F-3', 'C-4']\n        \"\"\"\n        self.empty()\n        if type(startnote) == str:\n            startnote = Note(startnote)\n        n = Note(startnote.name, startnote.octave, startnote.dynamics)\n        n.transpose(shorthand, up)\n        self.add_notes([startnote, n])\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nempties the container and add the notes described in the progression shorthand.", "response": "def from_progression_shorthand(self, shorthand, key='C'):\n        \"\"\"Empty the container and add the notes described in the progressions\n        shorthand (eg. 'IIm6', 'V7', etc).\n\n        See mingus.core.progressions for all the recognized format.\n\n        Example:\n        >>> NoteContainer().from_progression_shorthand('VI')\n        ['A-4', 'C-5', 'E-5']\n        \"\"\"\n        self.empty()\n        chords = progressions.to_chords(shorthand, key)\n        # warning Throw error, not a valid shorthand\n\n        if chords == []:\n            return False\n        notes = chords[0]\n        self.add_notes(notes)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a note from the container.", "response": "def remove_note(self, note, octave=-1):\n        \"\"\"Remove note from container.\n\n        The note can either be a Note object or a string representing the\n        note's name. If no specific octave is given, the note gets removed\n        in every octave.\n        \"\"\"\n        res = []\n        for x in self.notes:\n            if type(note) == str:\n                if x.name != note:\n                    res.append(x)\n                else:\n                    if x.octave != octave and octave != -1:\n                        res.append(x)\n            else:\n                if x != note:\n                    res.append(x)\n        self.notes = res\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves notes from the containers.", "response": "def remove_notes(self, notes):\n        \"\"\"Remove notes from the containers.\n\n        This function accepts a list of Note objects or notes as strings and\n        also single strings or Note objects.\n        \"\"\"\n        if type(notes) == str:\n            return self.remove_note(notes)\n        elif hasattr(notes, 'name'):\n            return self.remove_note(notes)\n        else:\n            map(lambda x: self.remove_note(x), notes)\n            return self.notes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_duplicate_notes(self):\n        res = []\n        for x in self.notes:\n            if x not in res:\n                res.append(x)\n        self.notes = res\n        return res", "response": "Remove duplicate and enharmonic notes from the container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransposing all the notes in the container up or down the given interval.", "response": "def transpose(self, interval, up=True):\n        \"\"\"Transpose all the notes in the container up or down the given\n        interval.\"\"\"\n        for n in self.notes:\n            n.transpose(interval, up)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list with all the note names in the current container.", "response": "def get_note_names(self):\n        \"\"\"Return a list with all the note names in the current container.\n\n        Every name will only be mentioned once.\n        \"\"\"\n        res = []\n        for n in self.notes:\n            if n.name not in res:\n                res.append(n.name)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef determine(notes):\n    notes = set(notes)\n    res = []\n\n    for key in keys:\n        for scale in _Scale.__subclasses__():\n            if scale.type == 'major':\n                if (notes <= set(scale(key[0]).ascending()) or\n                        notes <= set(scale(key[0]).descending())):\n                    res.append(scale(key[0]).name)\n            elif scale.type == 'minor':\n                if (notes <= set(scale(get_notes(key[1])[0]).ascending()) or\n                        notes <= set(scale(get_notes(key[1])[0]).descending())):\n                    res.append(scale(get_notes(key[1])[0]).name)\n    return res", "response": "Determine the scales containing the notes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef degree(self, degree_number, direction='a'):\n        if degree_number < 1:\n            raise RangeError(\"degree '%s' out of range\" % degree_number)\n        if direction == 'a':\n            notes = self.ascending()[:-1]\n            return notes[degree_number-1]\n        elif direction == 'd':\n            notes = reversed(self.descending())[:-1]\n            return notes[degree_number-1]\n        else:\n            raise FormatError(\"Unrecognised direction '%s'\" % direction)", "response": "Return the asked scale degree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef begin_track(tuning, padding=2):\n    # find longest shorthand tuning base\n    names = [x.to_shorthand() for x in tuning.tuning]\n    basesize = len(max(names)) + 3\n\n    # Build result\n    res = []\n    for x in names:\n        r = ' %s' % x\n        spaces = basesize - len(r)\n        r += ' ' * spaces + '||' + '-' * padding\n        res.append(r)\n    return res", "response": "Helper function that builds the first few characters of every bar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_headers(width=80, title='Untitled', subtitle='', author='', email='',\n        description='', tunings=[]):\n    \"\"\"Create a nice header in the form of a list of strings using the\n    information that has been filled in.\n\n    All arguments except 'width' and 'tunings' should be strings. 'width'\n    should be an integer and 'tunings' a list of tunings representing the\n    instruments.\n    \"\"\"\n    result = ['']\n    title = str.upper(title)\n    result += [str.center('  '.join(title), width)]\n    if subtitle != '':\n        result += ['', str.center(str.title(subtitle), width)]\n    if author != '' or email != '':\n        result += ['', '']\n        if email != '':\n            result += [str.center('Written by: %s <%s>' % (author, email),\n                       width)]\n        else:\n            result += [str.center('Written by: %s' % author, width)]\n    if description != '':\n        result += ['', '']\n        words = description.split()\n        lines = []\n        line = []\n        last = 0\n        for word in words:\n            if len(word) + last < width - 10:\n                line.append(word)\n                last += len(word) + 1\n            else:\n                lines.append(line)\n                line = [word]\n                last = len(word) + 1\n        lines.append(line)\n        for line in lines:\n            result += [str.center(' '.join(line), width)]\n    if tunings != []:\n        result += ['', '', str.center('Instruments', width)]\n        for (i, tuning) in enumerate(tunings):\n            result += ['', str.center('%d. %s' % (i + 1, tuning.instrument),\n                       width), str.center(tuning.description, width)]\n    result += ['', '']\n    return result", "response": "Create a nice header in the form of a list of strings using the available headers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string made out of ASCII tablature representing a Note object.", "response": "def from_Note(note, width=80, tuning=None):\n    \"\"\"Return a string made out of ASCII tablature representing a Note object\n    or note string.\n\n    Throw a RangeError if a suitable fret can't be found.\n\n    'tuning' should be a StringTuning object or None for the default tuning.\n\n    To force a certain fingering you can use a 'string' and 'fret' attribute\n    on the Note. If the fingering is valid, it will get used instead of the\n    default one.\n    \"\"\"\n    if tuning is None:\n        tuning = default_tuning\n    result = begin_track(tuning)\n    min = 1000\n    (s, f) = (-1, -1)\n\n    # Do an attribute check\n    if hasattr(note, 'string') and hasattr(note, 'fret'):\n        n = tuning.get_Note(note.string, note.fret)\n        if n is not None and int(n) == int(note):\n            (s, f) = (note.string, note.fret)\n            min = 0\n\n    if min == 1000:\n        for (string, fret) in enumerate(tuning.find_frets(note)):\n            if fret is not None:\n                if fret < min:\n                    min = fret\n                    (s, f) = (string, fret)\n    l = len(result[0])\n    w = max(4, (width - l) - 1)\n\n    # Build ASCII\n    if min != 1000:\n        fret = str(f)\n        for i in range(len(result)):\n            d = len(fret)\n            if i != s:\n                result[i] += '-' * w + '|'\n            else:\n                d = w - len(fret)\n                result[i] += '-' * (d / 2) + fret\n                d = (w - d / 2) - len(fret)\n                result[i] += '-' * d + '|'\n    else:\n        raise RangeError(\"No fret found that could play note '%s'. \"\n                \"Note out of range.\" % note)\n    result.reverse()\n    return os.linesep.join(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_NoteContainer(notes, width=80, tuning=None):\n    if tuning is None:\n        tuning = default_tuning\n    result = begin_track(tuning)\n    l = len(result[0])\n    w = max(4, (width - l) - 1)\n    fingerings = tuning.find_fingering(notes)\n    if fingerings != []:\n        # Do an attribute check\n        f = []\n        attr = []\n        for note in notes:\n            if hasattr(note, 'string') and hasattr(note, 'fret'):\n                n = tuning.get_Note(note.string, note.fret)\n                if n is not None and int(n) == int(note):\n                    f += (note.string, note.fret)\n                    attr.append(int(note))\n\n        # See if there are any possible fingerings with the attributes\n        # that are set.\n        fres = []\n        if f != []:\n            for x in fingerings:\n                found = True\n                for pos in f:\n                    if pos not in x:\n                        found = False\n                if found:\n                    fres.append(x)\n\n        # Use best fingering.\n        if fres != []:\n            f = fres[0]\n        else:\n            # Use default fingering if attributes don't make sense\n            f = fingerings[0]\n\n        # Build {string: fret} result\n        res = {}\n        for (string, fret) in f:\n            res[string] = str(fret)\n        maxfret = max(res.values())\n\n        # Produce ASCII\n        for i in range(len(result)):\n            if i not in res.keys():\n                result[i] += '-' * w + '|'\n            else:\n                d = w - len(res[i])\n                result[i] += '-' * (d / 2) + res[i]\n                d = (w - d / 2) - len(res[i])\n                result[i] += '-' * d + '|'\n    else:\n        raise FingerError('No playable fingering found for: %s' % notes)\n    result.reverse()\n    return os.linesep.join(result)", "response": "Return a string made out of ASCII tablature representing a list of Note objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a mingus. containers. Bar object to ASCII tablature.", "response": "def from_Bar(bar, width=40, tuning=None, collapse=True):\n    \"\"\"Convert a mingus.containers.Bar object to ASCII tablature.\n\n    Throw a FingerError if no playable fingering can be found.\n\n    'tuning' should be a StringTuning object or None for the default tuning.\n    If 'collapse' is False this will return a list of lines, if it's True\n    all lines will be concatenated with a newline symbol.\n\n    Use 'string' and 'fret' attributes on Notes to force certain fingerings.\n    \"\"\"\n    if tuning is None:\n        tuning = default_tuning\n\n    # Size of a quarter note\n    qsize = _get_qsize(tuning, width)\n    result = begin_track(tuning, max(2, qsize / 2))\n\n    # Add bar\n    for entry in bar.bar:\n        (beat, duration, notes) = entry\n        fingering = tuning.find_fingering(notes)\n        if fingering != [] or notes is None:\n\n            # Do an attribute check\n            f = []\n            attr = []\n            if notes is not None:\n                for note in notes:\n                    if hasattr(note, 'string') and hasattr(note, 'fret'):\n                        n = tuning.get_Note(note.string, note.fret)\n                        if n is not None and int(n) == int(note):\n                            f.append((note.string, note.fret))\n                            attr.append(int(note))\n\n            # See if there are any possible fingerings with the attributes that\n            # are set.\n            fres = []\n            if f != []:\n                for x in fingering:\n                    found = True\n                    for pos in f:\n                        if pos not in x:\n                            found = False\n                    if found:\n                        fres.append(x)\n\n            # Use best fingering.\n            maxlen = 0\n            if fres != []:\n                f = fres[0]\n            else:\n                # Use default fingering if attributes don't make sense\n                if notes is None:\n                    f = []\n                    maxlen = 1\n                else:\n                    f = fingering[0]\n\n            # Make {string: fret} dictionary and find highest fret\n            d = {}\n            for (string, fret) in f:\n                d[string] = str(fret)\n                if len(str(fret)) > maxlen:\n                    maxlen = len(str(fret))\n\n            # Add to result\n            for i in range(len(result)):\n                dur = int(((1.0 / duration) * qsize) * 4) - maxlen\n                if i not in d.keys():\n                    result[i] += '-' * maxlen + '-' * dur\n                else:\n                    result[i] += ('%' + str(maxlen) + 's') % d[i] + '-' * dur\n        else:\n            raise FingerError('No playable fingering found for: %s' % notes)\n\n    # Padding at the end\n    l = len(result[i]) + 1\n    for i in range(len(result)):\n        result[i] += (width - l) * '-' + '|'\n    result.reverse()\n\n    # Mark quarter notes\n    pad = ' ' * int(((1.0 / bar.meter[1]) * qsize) * 4 - 1)\n    r = ' ' * (result[0].find('||') + 2 + max(2, qsize / 2)) + ('*' + pad)\\\n         * bar.meter[0]\n    r += ' ' * (len(result[0]) - len(r))\n    if not collapse:\n        return [r] + result\n    else:\n        return os.linesep.join([r] + result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_Track(track, maxwidth=80, tuning=None):\n    result = []\n    width = _get_width(maxwidth)\n    if not tuning:\n        tuning = track.get_tuning()\n    lastlen = 0\n    for bar in track:\n        r = from_Bar(bar, width, tuning, collapse=False)\n        barstart = r[1].find('||') + 2\n        if (len(r[0]) + lastlen) - barstart < maxwidth and result != []:\n            for i in range(1, len(r) + 1):\n                item = r[len(r) - i]\n                result[-i] += item[barstart:]\n        else:\n            result += ['', ''] + r\n        lastlen = len(result[-1])\n    return os.linesep.join(result)", "response": "Convert a mingus. containers. Track object to an ASCII tablature string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_Composition(composition, width=80):\n    # Collect tunings\n    instr_tunings = []\n    for track in composition:\n        tun = track.get_tuning()\n        if tun:\n            instr_tunings.append(tun)\n        else:\n            instr_tunings.append(default_tuning)\n    result = add_headers(\n        width,\n        composition.title,\n        composition.subtitle,\n        composition.author,\n        composition.email,\n        composition.description,\n        instr_tunings,\n        )\n\n    # Some variables\n    w = _get_width(width)\n    barindex = 0\n    bars = width / w\n    lastlen = 0\n    maxlen = max([len(x) for x in composition.tracks])\n\n    while barindex < maxlen:\n        notfirst = False\n        for tracks in composition:\n            tuning = tracks.get_tuning()\n            ascii = []\n            for x in xrange(bars):\n                if barindex + x < len(tracks):\n                    bar = tracks[barindex + x]\n                    r = from_Bar(bar, w, tuning, collapse=False)\n                    barstart = r[1].find('||') + 2\n\n                    # Add extra '||' to quarter note marks to connect tracks.\n                    if notfirst:\n                        r[0] = (r[0])[:barstart - 2] + '||' + (r[0])[barstart:]\n\n                    # Add bar to ascii\n                    if ascii != []:\n                        for i in range(1, len(r) + 1):\n                            item = r[len(r) - i]\n                            ascii[-i] += item[barstart:]\n                    else:\n                        ascii += r\n\n            # Add extra '||' to connect tracks\n            if notfirst and ascii != []:\n                pad = ascii[-1].find('||')\n                result += [' ' * pad + '||', ' ' * pad + '||']\n            else:\n                notfirst = True\n\n            # Finally, add ascii to result\n            result += ascii\n        result += ['', '', '']\n        barindex += bars\n    return os.linesep.join(result)", "response": "Convert a mingus. containers. Composition to an ASCII tablature string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_Suite(suite, maxwidth=80):\n    subtitle = str(len(suite.compositions)) + ' Compositions' if suite.subtitle\\\n         == '' else suite.subtitle\n    result = os.linesep.join(add_headers(\n        maxwidth,\n        suite.title,\n        subtitle,\n        suite.author,\n        suite.email,\n        suite.description,\n        ))\n    hr = maxwidth * '='\n    n = os.linesep\n    result = n + hr + n + result + n + hr + n + n\n    for comp in suite:\n        c = from_Composition(comp, maxwidth)\n        result += c + n + hr + n + n\n    return result", "response": "Convert a mingus. containers. Suite to an ASCII tablature string with headers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a reasonable quarter note size for tuning and width.", "response": "def _get_qsize(tuning, width):\n    \"\"\"Return a reasonable quarter note size for 'tuning' and 'width'.\"\"\"\n    names = [x.to_shorthand() for x in tuning.tuning]\n    basesize = len(max(names)) + 3\n    barsize = ((width - basesize) - 2) - 1\n\n    # x * 4 + 0.5x - barsize = 0 4.5x = barsize x = barsize / 4.5\n    return max(0, int(barsize / 4.5))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_width(maxwidth):\n    width = maxwidth / 3\n    if maxwidth <= 60:\n        width = maxwidth\n    elif 60 < maxwidth <= 120:\n        width = maxwidth / 2\n    return width", "response": "Return the width of a single bar when width of the page is given."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the triad on note in key as a list.", "response": "def triad(note, key):\n    \"\"\"Return the triad on note in key as a list.\n\n    Examples:\n    >>> triad('E', 'C')\n    ['E', 'G', 'B']\n    >>> triad('E', 'B')\n    ['E', 'G#', 'B']\n    \"\"\"\n    return [note, intervals.third(note, key), intervals.fifth(note, key)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef triads(key):\n    if _triads_cache.has_key(key):\n        return _triads_cache[key]\n    res = map(lambda x: triad(x, key), keys.get_notes(key))\n    _triads_cache[key] = res\n    return res", "response": "Return all the triads in key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding an augmented triad on note.", "response": "def augmented_triad(note):\n    \"\"\"Build an augmented triad on note.\n\n    Example:\n    >>> augmented_triad('C')\n    ['C', 'E', 'G#']\n    \"\"\"\n    return [note, intervals.major_third(note),\n            notes.augment(intervals.major_fifth(note))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef seventh(note, key):\n    return triad(note, key) + [intervals.seventh(note, key)]", "response": "Return the seventh chord on note in key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sevenths(key):\n    if _sevenths_cache.has_key(key):\n        return _sevenths_cache[key]\n    res = map(lambda x: seventh(x, key), keys.get_notes(key))\n    _sevenths_cache[key] = res\n    return res", "response": "Return all the sevenths chords in key in a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dominant_flat_ninth(note):\n    res = dominant_ninth(note)\n    res[4] = intervals.minor_second(note)\n    return res", "response": "Build a dominant flat ninth chord on note."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dominant_sharp_ninth(note):\n    res = dominant_ninth(note)\n    res[4] = notes.augment(intervals.major_second(note))\n    return res", "response": "Build a dominant sharp ninth chord on note."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eleventh(note):\n    return [note, intervals.perfect_fifth(note), intervals.minor_seventh(note),\n            intervals.perfect_fourth(note)]", "response": "Build an eleventh chord on note."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a dominant flat five chord on note.", "response": "def dominant_flat_five(note):\n    \"\"\"Build a dominant flat five chord on note.\n\n    Example:\n    >>> dominant_flat_five('C')\n    ['C', 'E', 'Gb', 'Bb']\n    \"\"\"\n    res = dominant_seventh(note)\n    res[2] = notes.diminish(res[2])\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a chord written in shorthand and return the notes in the base base.", "response": "def from_shorthand(shorthand_string, slash=None):\n    \"\"\"Take a chord written in shorthand and return the notes in the chord.\n\n    The function can recognize triads, sevenths, sixths, ninths, elevenths,\n    thirteenths, slashed chords and a number of altered chords.\n\n    The second argument should not be given and is only used for a recursive\n    call when a slashed chord or polychord is found.\n\n    See http://tinyurl.com/3hn6v8u for a nice overview of chord patterns.\n\n    Examples:\n    >>> from_shorthand('Amin')\n    ['A', 'C', 'E']\n    >>> from_shorthand('Am/M7')\n    ['A', 'C', 'E', 'G#']\n    >>> from_shorthand('A')\n    ['A', 'C#', 'E']\n    >>> from_shorthand('A/G')\n    ['G', 'A', 'C#', 'E']\n    >>> from_shorthand('Dm|G')\n    ['G', 'B', 'D', 'F', 'A']\n\n    Recognised abbreviations: the letters \"m\" and \"M\" in the following\n    abbreviations can always be substituted by respectively \"min\", \"mi\" or\n    \"-\" and \"maj\" or \"ma\".\n    \n    Example:\n    >>> from_shorthand('Amin7') == from_shorthand('Am7')\n    True\n\n    Triads: 'm', 'M' or '', 'dim'\n\n    Sevenths: 'm7', 'M7', '7', 'm7b5', 'dim7', 'm/M7' or 'mM7'\n\n    Augmented chords: 'aug' or '+', '7#5' or 'M7+5', 'M7+', 'm7+', '7+'\n\n    Suspended chords: 'sus4', 'sus2', 'sus47' or '7sus4', 'sus', '11',\n    'sus4b9' or 'susb9'\n\n    Sixths: '6', 'm6', 'M6', '6/7' or '67', '6/9' or '69'\n\n    Ninths: '9' or 'add9', 'M9', 'm9', '7b9', '7#9'\n\n    Elevenths: '11' or 'add11', '7#11', 'm11'\n\n    Thirteenths: '13' or 'add13', 'M13', 'm13'\n\n    Altered chords: '7b5', '7b9', '7#9', '67' or '6/7'\n\n    Special: '5', 'NC', 'hendrix'\n    \"\"\"\n    # warning reduce??\n    if type(shorthand_string) == list:\n        res = []\n        for x in shorthand_string:\n            res.append(from_shorthand(x))\n        return res\n    if shorthand_string in ['NC', 'N.C.']:\n        return []\n\n    # Shrink shorthand_string to a format recognised by chord_shorthand\n    shorthand_string = shorthand_string.replace('min', 'm')\n    shorthand_string = shorthand_string.replace('mi', 'm')\n    shorthand_string = shorthand_string.replace('-', 'm')\n    shorthand_string = shorthand_string.replace('maj', 'M')\n    shorthand_string = shorthand_string.replace('ma', 'M')\n\n    # Get the note name\n    if not notes.is_valid_note(shorthand_string[0]):\n        raise NoteFormatError, \"Unrecognised note '%s' in chord '%s'\"\\\n             % (shorthand_string[0], shorthand_string)\n    name = shorthand_string[0]\n\n    # Look for accidentals\n    for n in shorthand_string[1:]:\n        if n == '#':\n            name += n\n        elif n == 'b':\n            name += n\n        else:\n            break\n\n    # Look for slashes and polychords '|'\n    slash_index = -1\n    s = 0\n    rest_of_string = shorthand_string[len(name):]\n    for n in rest_of_string:\n        if n == '/':\n            slash_index = s\n        elif n == '|':\n            # Generate polychord\n            return from_shorthand(shorthand_string[:len(name) + s],\n                    from_shorthand(shorthand_string[len(name) + s + 1:]))\n        s += 1\n\n    # Generate slash chord\n    if slash_index != -1 and rest_of_string not in ['m/M7', '6/9', '6/7']:\n        res = shorthand_string[:len(name) + slash_index]\n        return from_shorthand(shorthand_string[:len(name) + slash_index],\n                              shorthand_string[len(name) + slash_index + 1:])\n    shorthand_start = len(name)\n\n    short_chord = shorthand_string[shorthand_start:]\n    if chord_shorthand.has_key(short_chord):\n        res = chord_shorthand[short_chord](name)\n        if slash != None:\n            # Add slashed chords\n            if type(slash) == str:\n                if notes.is_valid_note(slash):\n                    res = [slash] + res\n                else:\n                    raise NoteFormatError, \\\n                        \"Unrecognised note '%s' in slash chord'%s'\" % (slash,\n                            slash + shorthand_string)\n            elif type(slash) == list:\n                # Add polychords\n                r = slash\n                for n in res:\n                    if n != r[-1]:\n                        r.append(n)\n                return r\n        return res\n    else:\n        raise FormatError, 'Unknown shorthand: %s' % shorthand_string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef determine(chord, shorthand=False, no_inversions=False, no_polychords=False):\n    if chord == []:\n        return []\n    elif len(chord) == 1:\n        return chord\n    elif len(chord) == 2:\n        return [intervals.determine(chord[0], chord[1])]\n    elif len(chord) == 3:\n        return determine_triad(chord, shorthand, no_inversions, no_polychords)\n    elif len(chord) == 4:\n        return determine_seventh(chord, shorthand, no_inversions, no_polychords)\n    elif len(chord) == 5:\n        return determine_extended_chord5(chord, shorthand, no_inversions,\n                no_polychords)\n    elif len(chord) == 6:\n        return determine_extended_chord6(chord, shorthand, no_inversions,\n                no_polychords)\n    elif len(chord) == 7:\n        return determine_extended_chord7(chord, shorthand, no_inversions,\n                no_polychords)\n    else:\n        return determine_polychords(chord, shorthand)", "response": "Name a chord. A chord is a list of names."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef determine_triad(triad, shorthand=False, no_inversions=False,\n        placeholder=None):\n    \"\"\"Name the triad; return answers in a list.\n\n    The third argument should not be given. If shorthand is True the answers\n    will be in abbreviated form.\n\n    This function can determine major, minor, diminished and suspended\n    triads. Also knows about invertions.\n\n    Examples:\n    >>> determine_triad(['A', 'C', 'E'])\n    'A minor triad'\n    >>> determine_triad(['C', 'E', 'A'])\n    'A minor triad, first inversion'\n    >>> determine_triad(['A', 'C', 'E'], True)\n    'Am'\n    \"\"\"\n    if len(triad) != 3:\n        # warning: raise exception: not a triad\n        return False\n\n    def inversion_exhauster(triad, shorthand, tries, result):\n        \"\"\"Run tries every inversion and save the result.\"\"\"\n        intval1 = intervals.determine(triad[0], triad[1], True)\n        intval2 = intervals.determine(triad[0], triad[2], True)\n\n        def add_result(short):\n            result.append((short, tries, triad[0]))\n\n        intval = intval1 + intval2\n        if intval == '25':\n            add_result('sus2')\n        elif intval == '3b7':\n            add_result('dom7')  # changed from just '7'\n        elif intval == '3b5':\n            add_result('7b5')  # why not b5?\n        elif intval == '35':\n            add_result('M')\n        elif intval == '3#5':\n            add_result('aug')\n        elif intval == '36':\n            add_result('M6')\n        elif intval == '37':\n            add_result('M7')\n        elif intval == 'b3b5':\n            add_result('dim')\n        elif intval == 'b35':\n            add_result('m')\n        elif intval == 'b36':\n            add_result('m6')\n        elif intval == 'b3b7':\n            add_result('m7')\n        elif intval == 'b37':\n            add_result('m/M7')\n        elif intval == '45':\n            add_result('sus4')\n        elif intval == '5b7':\n            add_result('m7')\n        elif intval == '57':\n            add_result('M7')\n        if tries != 3 and not no_inversions:\n            return inversion_exhauster([triad[-1]] + triad[:-1], shorthand,\n                                       tries + 1, result)\n        else:\n            res = []\n            for r in result:\n                if shorthand:\n                    res.append(r[2] + r[0])\n                else:\n                    res.append(r[2] + chord_shorthand_meaning[r[0]] +\n                            int_desc(r[1]))\n            return res\n    return inversion_exhauster(triad, shorthand, 1, [])", "response": "Determine the name of a triad."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_seventh(seventh, shorthand=False, no_inversion=False,\n        no_polychords=False):\n    \"\"\"Determine the type of seventh chord; return the results in a list,\n    ordered on inversions.\n\n    This function expects seventh to be a list of 4 notes.\n\n    If shorthand is set to True, results will be returned in chord shorthand\n    ('Cmin7', etc.); inversions will be dropped in that case.\n\n    Example:\n    >>> determine_seventh(['C', 'E', 'G', 'B'])\n    ['C major seventh']\n    \"\"\"\n    if len(seventh) != 4:\n        # warning raise exception: seventh chord is not a seventh chord\n        return False\n\n    def inversion_exhauster(seventh, shorthand, tries, result, polychords):\n        \"\"\"Determine sevenths recursive functions.\"\"\"\n        # Check whether the first three notes of seventh are part of some triad.\n        triads = determine_triad(seventh[:3], True, True)\n\n        # Get the interval between the first and last note\n        intval3 = intervals.determine(seventh[0], seventh[3])\n\n        def add_result(short, poly=False):\n            \"\"\"Helper function.\"\"\"\n            result.append((short, tries, seventh[0], poly))\n\n        # Recognizing polychords\n        if tries == 1 and not no_polychords:\n            polychords = polychords + determine_polychords(seventh, shorthand)\n\n        # Recognizing sevenths\n        for triad in triads:\n            # Basic triads\n            triad = triad[len(seventh[0]):]\n            if triad == 'm':\n                if intval3 == 'minor seventh':\n                    add_result('m7')\n                elif intval3 == 'major seventh':\n                    add_result('m/M7')\n                elif intval3 == 'major sixth':\n                    add_result('m6')\n            elif triad == 'M':\n                if intval3 == 'major seventh':\n                    add_result('M7')\n                elif intval3 == 'minor seventh':\n                    add_result('7')\n                elif intval3 == 'major sixth':\n                    add_result('M6')\n            elif triad == 'dim':\n                if intval3 == 'minor seventh':\n                    add_result('m7b5')\n                elif intval3 == 'diminished seventh':\n                    add_result('dim7')\n            elif triad == 'aug':\n                if intval3 == 'minor seventh':\n                    add_result('m7+')\n                if intval3 == 'major seventh':\n                    add_result('M7+')\n            elif triad == 'sus4':\n                if intval3 == 'minor seventh':\n                    add_result('sus47')\n                elif intval3 == 'minor second':\n                    add_result('sus4b9')\n            elif triad == 'm7':\n\n            # Other\n                if intval3 == 'perfect fourth':\n                    add_result('11')\n            elif triad == '7b5':\n                if intval3 == 'minor seventh':\n                    add_result('7b5')\n\n        if tries != 4 and not no_inversion:\n            return inversion_exhauster([seventh[-1]] + seventh[:-1], shorthand,\n                    tries + 1, result, polychords)\n        else:\n            # Return results\n            res = []\n\n            # Reset seventh\n            seventh = [seventh[3]] + seventh[0:3]\n            for x in result:\n                if shorthand:\n                    res.append(x[2] + x[0])\n                else:\n                    res.append(x[2] + chord_shorthand_meaning[x[0]]\n                                + int_desc(x[1]))\n            return res + polychords\n    return inversion_exhauster(seventh, shorthand, 1, [], [])", "response": "Determine the type of a seventh chord and return the results in a list ordered on inversions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the names of an extended chord.", "response": "def determine_extended_chord5(chord, shorthand=False, no_inversions=False,\n        no_polychords=False):\n    \"\"\"Determine the names of an extended chord.\"\"\"\n    if len(chord) != 5:\n        # warning raise exeption: not an extended chord\n        return False\n\n    def inversion_exhauster(chord, shorthand, tries, result, polychords):\n        \"\"\"Recursive helper function.\"\"\"\n        def add_result(short):\n            result.append((short, tries, chord[0]))\n\n        triads = determine_triad(chord[:3], True, True)\n        sevenths = determine_seventh(chord[:4], True, True, True)\n\n        # Determine polychords\n        if tries == 1 and not no_polychords:\n            polychords += determine_polychords(chord, shorthand)\n\n        intval4 = intervals.determine(chord[0], chord[4])\n        for seventh in sevenths:\n            seventh = seventh[len(chord[0]):]\n            if seventh == 'M7':\n                if intval4 == 'major second':\n                    add_result('M9')\n            elif seventh == 'm7':\n                if intval4 == 'major second':\n                    add_result('m9')\n                elif intval4 == 'perfect fourth':\n                    add_result('m11')\n            elif seventh == '7':\n                if intval4 == 'major second':\n                    add_result('9')\n                elif intval4 == 'minor second':\n                    add_result('7b9')\n                elif intval4 == 'augmented second':\n                    add_result('7#9')\n                elif intval4 == 'minor third':\n                    add_result('7b12')\n                elif intval4 == 'augmented fourth':\n                    add_result('7#11')\n                elif intval4 == 'major sixth':\n                    add_result('13')\n            elif seventh == 'M6':\n                if intval4 == 'major second':\n                    add_result('6/9')\n                elif intval4 == 'minor seventh':\n                    add_result('6/7')\n        if tries != 5 and not no_inversions:\n            return inversion_exhauster([chord[-1]] + chord[:-1], shorthand,\n                    tries + 1, result, polychords)\n        else:\n            res = []\n            for r in result:\n                if shorthand:\n                    res.append(r[2] + r[0])\n                else:\n                    res.append(r[2] + chord_shorthand_meaning[r[0]]\n                                + int_desc(r[1]))\n            return res + polychords\n\n    return inversion_exhauster(chord, shorthand, 1, [], [])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef determine_extended_chord6(chord, shorthand=False, no_inversions=False,\n        no_polychords=False):\n    \"\"\"Determine the names of an 6 note chord.\"\"\"\n    if len(chord) != 6:\n        # warning raise exeption: not an extended chord\n        return False\n\n    def inversion_exhauster(\n        chord,\n        shorthand,\n        tries,\n        result,\n        polychords,\n        ):\n        \"\"\"Recursive helper function\"\"\"\n\n        # Determine polychords\n        if tries == 1 and not no_polychords:\n            polychords += determine_polychords(chord, shorthand)\n\n        def add_result(short):\n            result.append((short, tries, chord[0]))\n\n        ch = determine_extended_chord5(chord[:5], True, True, True)\n        intval5 = intervals.determine(chord[0], chord[5])\n        for c in ch:\n            c = c[len(chord[0]):]\n            if c == '9':\n                if intval5 == 'perfect fourth':\n                    add_result('11')\n                elif intval5 == 'augmented fourth':\n                    add_result('7#11')\n                elif intval5 == 'major sixth':\n                    add_result('13')\n            elif c == 'm9':\n                if intval5 == 'perfect fourth':\n                    add_result('m11')\n                elif intval5 == 'major sixth':\n                    add_result('m13')\n            elif c == 'M9':\n                if intval5 == 'perfect fourth':\n                    add_result('M11')\n                elif intval5 == 'major sixth':\n                    add_result('M13')\n        if tries != 6 and not no_inversions:\n            return inversion_exhauster([chord[-1]] + chord[:-1], shorthand,\n                    tries + 1, result, polychords)\n        else:\n            res = []\n            for r in result:\n                if shorthand:\n                    res.append(r[2] + r[0])\n                else:\n                    res.append(r[2] + chord_shorthand_meaning[r[0]] +\n                            int_desc(r[1]))\n            return res + polychords\n    return inversion_exhauster(chord, shorthand, 1, [], [])", "response": "Determine the names of an extended 6 note chord."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining the polychords in a chord.", "response": "def determine_polychords(chord, shorthand=False):\n    \"\"\"Determine the polychords in chord.\n    \n    This function can handle anything from polychords based on two triads to\n    6 note extended chords.\n    \"\"\"\n    polychords = []\n    function_list = [determine_triad, determine_seventh,\n                     determine_extended_chord5, determine_extended_chord6,\n                     determine_extended_chord7]\n\n    # Range tracking.\n    if len(chord) <= 3:\n        return []\n    elif len(chord) > 14:\n        return []\n    elif len(chord) - 3 <= 5:\n        function_nr = range(0, len(chord) - 3)\n    else:\n        function_nr = range(0, 5)\n    for f in function_nr:\n        for f2 in function_nr:\n            # The clever part: Try the function_list[f] on the len(chord) - (3 +\n            # f) last notes of the chord. Then try the function_list[f2] on the\n            # f2 + 3 first notes of the chord. Thus, trying all possible\n            # combinations.\n            for chord1 in function_list[f](chord[len(chord) - (3 + f):], True,\n                    True, True):\n                for chord2 in function_list[f2](chord[:f2 + 3], True, True,\n                        True):\n                    polychords.append('%s|%s' % (chord1, chord2))\n    if shorthand:\n        for p in polychords:\n            p = p + ' polychord'\n    return polychords"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_NoteContainer(nc, duration=None, standalone=True):\n    # Throw exception\n    if nc is not None and not hasattr(nc, 'notes'):\n        return False\n\n    # Return rests for None or empty lists\n    if nc is None or len(nc.notes) == 0:\n        result = 'r'\n    elif len(nc.notes) == 1:\n\n    # Return a single note if the list contains only one note\n        result = from_Note(nc.notes[0], standalone=False)\n    else:\n        # Return the notes grouped in '<' and '>'\n        result = '<'\n        for notes in nc.notes:\n            result += from_Note(notes, standalone=False) + ' '\n        result = result[:-1] + '>'\n\n    # Add the duration\n    if duration != None:\n        parsed_value = value.determine(duration)\n\n        # Special case: check for longa and breve in the duration (issue #37)\n        dur = parsed_value[0]\n        if dur == value.longa:\n            result += '\\\\longa'\n        elif dur == value.breve:\n            result += '\\\\breve'\n        else:\n            result += str(int(parsed_value[0]))\n        for i in range(parsed_value[1]):\n            result += '.'\n    if not standalone:\n        return result\n    else:\n        return '{ %s }' % result", "response": "Get a NoteContainer object and return the LilyPond equivalent in a\n    string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the LilyPond equivalent in a string.", "response": "def from_Bar(bar, showkey=True, showtime=True):\n    \"\"\"Get a Bar object and return the LilyPond equivalent in a string.\n\n    The showkey and showtime parameters can be set to determine whether the\n    key and the time should be shown.\n    \"\"\"\n    # Throw exception\n    if not hasattr(bar, 'bar'):\n        return False\n\n    # Process the key\n    if showkey:\n        key_note = Note(bar.key.key[0].upper() + bar.key.key[1:])\n        key = '\\\\key %s \\\\%s ' % (from_Note(key_note, False, standalone=False), bar.key.mode)\n        result = key\n    else:\n        result = ''\n\n    # Handle the NoteContainers\n    latest_ratio = (1, 1)\n    ratio_has_changed = False\n    for bar_entry in bar.bar:\n        parsed_value = value.determine(bar_entry[1])\n        ratio = parsed_value[2:]\n        if ratio == latest_ratio:\n            result += from_NoteContainer(bar_entry[2], bar_entry[1],\n                    standalone=False) + ' '\n        else:\n            if ratio_has_changed:\n                result += '}'\n            result += '\\\\times %d/%d {' % (ratio[1], ratio[0])\n            result += from_NoteContainer(bar_entry[2], bar_entry[1],\n                    standalone=False) + ' '\n            latest_ratio = ratio\n            ratio_has_changed = True\n    if ratio_has_changed:\n        result += '}'\n\n    # Process the time\n    if showtime:\n        return '{ \\\\time %d/%d %s}' % (bar.meter[0], bar.meter[1], result)\n    else:\n        return '{ %s}' % result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a Track object and return the LilyPond equivalent in a string.", "response": "def from_Track(track):\n    \"\"\"Process a Track object and return the LilyPond equivalent in a string.\"\"\"\n    # Throw exception\n    if not hasattr(track, 'bars'):\n        return False\n    lastkey = Key('C')\n    lasttime = (4, 4)\n\n    # Handle the Bars:\n    result = ''\n    for bar in track.bars:\n        if lastkey != bar.key:\n            showkey = True\n        else:\n            showkey = False\n        if lasttime != bar.meter:\n            showtime = True\n        else:\n            showtime = False\n        result += from_Bar(bar, showkey, showtime) + ' '\n        lastkey = bar.key\n        lasttime = bar.meter\n    return '{ %s}' % result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the LilyPond equivalent of a Composition in a string.", "response": "def from_Composition(composition):\n    \"\"\"Return the LilyPond equivalent of a Composition in a string.\"\"\"\n    # warning Throw exception\n    if not hasattr(composition, 'tracks'):\n        return False\n    result = '\\\\header { title = \"%s\" composer = \"%s\" opus = \"%s\" } '\\\n         % (composition.title, composition.author, composition.subtitle)\n    for track in composition.tracks:\n        result += from_Track(track) + ' '\n    return result[:-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nanalyse the value and return a tuple containing the parts it s made of.", "response": "def determine(value):\n    \"\"\"Analyse the value and return a tuple containing the parts it's made of.\n\n    The tuple respectively consists of the base note value, the number of\n    dots, and the ratio (see tuplet).\n\n    Examples:\n    >>> determine(8)\n    (8, 0, 1, 1)\n    >>> determine(12)\n    (8, 0, 3, 2)\n    >>> determine(14)\n    (8, 0, 7, 4)\n\n    This function recognizes all the base values, triplets, quintuplets,\n    septuplets and up to four dots. The values are matched on range.\n    \"\"\"\n    i = -2\n    for v in base_values:\n        if value == v:\n            return (value, 0, 1, 1)\n        if value < v:\n            break\n        i += 1\n    scaled = float(value) / 2 ** i\n    if scaled >= 0.9375:  # base value\n        return (base_values[i], 0, 1, 1)\n    elif scaled >= 0.8125:\n        # septuplet: scaled = 0.875\n        return (base_values[i + 1], 0, 7, 4)\n    elif scaled >= 17 / 24.0:\n        # triplet: scaled = 0.75\n        return (base_values[i + 1], 0, 3, 2)\n    elif scaled >= 31 / 48.0:\n        # dotted note (one dot): scaled = 2/3.0\n        return (v, 1, 1, 1)\n    elif scaled >= 67 / 112.0:\n        # quintuplet: scaled = 0.625\n        return (base_values[i + 1], 0, 5, 4)\n    d = 3\n    for x in range(2, 5):\n        d += 2 ** x\n        if scaled == 2.0 ** x / d:\n            return (v, x, 1, 1)\n    return (base_values[i + 1], 0, 1, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(sf2, driver=None, file=None):\n    global midi, initialized\n    if not initialized:\n        if file is not None:\n            midi.start_recording(file)\n        else:\n            midi.start_audio_output(driver)\n        if not midi.load_sound_font(sf2):\n            return False\n        midi.fs.program_reset()\n        initialized = True\n    return True", "response": "Initialize the audio.\n\n    Return True on success, False on failure.\n\n    This function needs to be called before you can have any audio.\n\n    The sf2 argument should be the location of a valid soundfont file.\n\n    The optional driver argument can be any of 'alsa', 'oss', 'jack',\n    'portaudio', 'sndmgr', 'coreaudio' or 'Direct Sound'.\n\n    If the file argument is not None, then instead of loading the driver, a\n    new wave file will be initialized to store the audio data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_recording(self, file='mingus_dump.wav'):\n        w = wave.open(file, 'wb')\n        w.setnchannels(2)\n        w.setsampwidth(2)\n        w.setframerate(44100)\n        self.wav = w", "response": "Initialize a new wave file for recording."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a sound font from a file.", "response": "def load_sound_font(self, sf2):\n        \"\"\"Load a sound font.\n\n        Return True on success, False on failure.\n\n        This function should be called before your audio can be played,\n        since the instruments are kept in the sf2 file.\n        \"\"\"\n        self.sfid = self.fs.sfload(sf2)\n        return not self.sfid == -1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Greengrass group in the given region.", "response": "def create(self, group_type, config_file, group_name=None,\n               region=None, profile_name=None):\n        \"\"\"\n        Create a Greengrass group in the given region.\n\n        :param group_type: the type of group to create. Must match a `key` in\n            the `group_types` dict\n        :param config_file: config file of the group to create\n        :param group_name: the name of the group. If no name is given, then\n            group_type will be used.\n        :param region: the region in which to create the new group.\n            [default: us-west-2]\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        \"\"\"\n        logging.info(\"[begin] create command using group_types:{0}\".format(\n            self.group_types))\n\n        config = GroupConfigFile(config_file=config_file)\n        if config.is_fresh() is False:\n            raise ValueError(\n                \"Config file already tracking previously created group\"\n            )\n\n        if group_type not in self.group_types.keys():\n            raise ValueError(\"Can only create {0} groups.\".format(\n                self.group_types)\n            )\n\n        if region is None:\n            region = self._region\n\n        # create an instance of the requested group type that uses the given\n        # config file and region\n        gt = self.group_types[group_type](config=config, region=region)\n\n        # get and store the account's IoT endpoint for future use\n        ep = _get_iot_session(region=region).describe_endpoint()\n        misc = config['misc']\n        misc['iot_endpoint'] = ep['endpointAddress']\n        config['misc'] = misc\n\n        # Create a Group\n        logging.info(\"[begin] Creating a Greengrass Group\")\n        if group_name is None:\n            group_name = group_type\n\n        gg_client = _get_gg_session(region=region, profile_name=profile_name)\n\n        group_info = gg_client.create_group(Name=\"{0}\".format(group_name))\n        config['group'] = {\"id\": group_info['Id']}\n\n        # setup the policies and roles\n        gt.create_and_attach_thing_policy()\n        gt.create_and_attach_iam_role()\n\n        cl_arn = self._create_core_definition(\n            gg_client=gg_client, group_type=gt,\n            config=config, group_name=group_name\n        )\n        dl_arn = self._create_device_definition(\n            gg_client=gg_client, group_type=gt,\n            config=config, group_name=group_name\n        )\n        lv_arn = self._create_function_definition(\n            gg_client=gg_client, group_type=gt,\n            config=config\n        )\n        log_arn = self._create_logger_definition(\n            gg_client=gg_client, group_type=gt,\n            config=config\n        )\n        sub_arn = self._create_subscription_definition(\n            gg_client=gg_client, group_type=gt,\n            config=config\n        )\n\n        logging.info(\n            'Group details, core_def:{0} device_def:{1} func_def:{2} '\n            'logger_def:{3} subs_def:{4}'.format(\n                cl_arn, dl_arn, lv_arn, log_arn, sub_arn)\n        )\n\n        # Add all the constituent parts to the Greengrass Group\n        group_args = {'GroupId': group_info['Id']}\n        if cl_arn:\n            group_args['CoreDefinitionVersionArn'] = cl_arn\n        if dl_arn:\n            group_args['DeviceDefinitionVersionArn'] = dl_arn\n        if lv_arn:\n            group_args['FunctionDefinitionVersionArn'] = lv_arn\n        if log_arn:\n            group_args['LoggerDefinitionVersionArn'] = log_arn\n        if sub_arn:\n            group_args['SubscriptionDefinitionVersionArn'] = sub_arn\n        grp = gg_client.create_group_version(\n            **group_args\n        )\n\n        # store info about the provisioned artifacts into the local config file\n        config['group'] = {\n            \"id\": group_info['Id'],\n            \"version_arn\": grp['Arn'],\n            \"version\": grp['Version'],\n            \"name\": group_name\n        }\n        logging.info(\n            \"[end] Created Greengrass Group {0}\".format(group_info['Id']))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_subscription_definition(gg_client, group_type, config):\n        logging.info('[begin] Configuring routing subscriptions')\n        sub_info = gg_client.create_subscription_definition(\n            Name=\"{0}_routing\".format(group_type.type_name)\n        )\n        logging.info('Created subscription definition: {0}'.format(sub_info))\n\n        subs = group_type.get_subscription_definition(config=config)\n        if subs is None:\n            logging.warning(\n                \"[end] No SubscriptionDefinition exists in GroupType:{0}\".format(\n                    group_type.type_name)\n            )\n            return\n\n        subv = gg_client.create_subscription_definition_version(\n            SubscriptionDefinitionId=sub_info['Id'],\n            Subscriptions=subs\n        )\n        sub_arn = subv['Arn']\n        config['subscription_def'] = {\n            \"id\": sub_info['Id'],\n            \"version_arn\": sub_arn\n        }\n        logging.info('[end] Configured routing subscriptions')\n        return sub_arn", "response": "Create a new subscription definition for a Greengrass group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncleaning all Core related provisioned artifacts from both the local file and the AWS Greengrass service.", "response": "def clean_core(self, config_file, region=None, profile_name=None):\n        \"\"\"\n        Clean all Core related provisioned artifacts from both the local file\n        and the AWS Greengrass service.\n\n        :param config_file: config file containing the core to clean\n        :param region: the region in which the core should be cleaned.\n            [default: us-west-2]\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        :return:\n        \"\"\"\n        config = GroupConfigFile(config_file=config_file)\n\n        if region is None:\n            region = self._region\n\n        # delete the Core's Certificate\n        core_cert_id = config['core']['cert_id']\n        core_cert_arn = config['core']['cert_arn']\n        core_thing_name = config['core']['thing_name']\n        policy_name = config['misc']['policy_name']\n        logging.info('Deleting core_thing_name:{0}'.format(core_thing_name))\n        GroupCommands._delete_thing(\n            cert_arn=core_cert_arn, cert_id=core_cert_id,\n            thing_name=core_thing_name, region=region,\n            policy_name=policy_name, profile_name=profile_name\n        )\n        config.make_core_fresh()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_devices(self, config_file, region=None, profile_name=None):\n        config = GroupConfigFile(config_file=config_file)\n        if region is None:\n            region = self._region\n\n        devices = config['devices']\n        if 'device_thing_name' in devices:\n            logging.info('Configured devices already clean')\n            return\n\n        policy_name = config['misc']['policy_name']\n        for device in devices:\n            cert_arn = devices[device]['cert_arn']\n            cert_id = devices[device]['cert_id']\n            thing_name = device\n            logging.info('Deleting device_thing_name:{0}'.format(thing_name))\n            GroupCommands._delete_thing(\n                cert_arn, cert_id, thing_name, region, policy_name, profile_name\n            )\n        config.make_devices_fresh()", "response": "Clean all device related provisioned artifacts from both the local file\n        and the AWS Greengrass service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean_file(config_file):\n        logging.info('[begin] Cleaning config file')\n        config = GroupConfigFile(config_file=config_file)\n\n        if config.is_fresh() is True:\n            raise ValueError(\"Config is already clean.\")\n        config.make_fresh()\n        logging.info('[end] Cleaned config file:{0}'.format(config_file))", "response": "Clean all provisioned artifacts from the local config file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean all provisioned artifacts from both the local file and the Greengrass service.", "response": "def clean_all(self, config_file, region=None, profile_name=None):\n        \"\"\"\n        Clean all provisioned artifacts from both the local file and the AWS\n        Greengrass service.\n\n        :param config_file: config file containing the group to clean\n        :param region: the region in which the group should be cleaned.\n            [default: us-west-2]\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        \"\"\"\n        logging.info('[begin] Cleaning all provisioned artifacts')\n        config = GroupConfigFile(config_file=config_file)\n        if config.is_fresh() is True:\n            raise ValueError(\"Config is already clean.\")\n\n        if region is None:\n            region = self._region\n\n        self._delete_group(\n            config_file, region=region, profile_name=profile_name)\n        self.clean_core(config_file, region=region)\n        self.clean_devices(config_file, region=region)\n        self.clean_file(config_file)\n\n        logging.info('[end] Cleaned all provisioned artifacts')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeploy the configuration and Lambda functions of a Greengrass group to a specific region.", "response": "def deploy(self, config_file, region=None, profile_name=None):\n        \"\"\"\n        Deploy the configuration and Lambda functions of a Greengrass group to\n        the Greengrass core contained in the group.\n\n        :param config_file: config file of the group to deploy\n        :param region: the region from which to deploy the group.\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        \"\"\"\n        config = GroupConfigFile(config_file=config_file)\n        if config.is_fresh():\n            raise ValueError(\"Config not yet tracking a group. Cannot deploy.\")\n\n        if region is None:\n            region = self._region\n\n        gg_client = _get_gg_session(region=region, profile_name=profile_name)\n\n        dep_req = gg_client.create_deployment(\n            GroupId=config['group']['id'],\n            GroupVersionId=config['group']['version'],\n            DeploymentType=\"NewDeployment\"\n        )\n        print(\"Group deploy requested for deployment_id:{0}\".format(\n            dep_req['DeploymentId'],\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_core(self, thing_name, config_file, region=None,\n                    cert_dir=None, account_id=None,\n                    policy_name='ggc-default-policy', profile_name=None):\n        \"\"\"\n        Using the `thing_name` value, creates a Thing in AWS IoT, attaches and\n        downloads new keys & certs to the certificate directory, then records\n        the created information in the local config file for inclusion in the\n        Greengrass Group as a Greengrass Core.\n\n        :param thing_name: the name of the thing to create and use as a\n            Greengrass Core\n        :param config_file: config file used to track the Greengrass Core in the\n            group\n        :param region: the region in which to create the new core.\n            [default: us-west-2]\n        :param cert_dir: the directory in which to store the thing's keys and\n            certs. If `None` then use the current directory.\n        :param account_id: the account_id in which to create the new core.\n            [default: None]\n        :param policy_name: the name of the policy to associate with the device.\n            [default: 'ggc-default-policy']\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        \"\"\"\n        config = GroupConfigFile(config_file=config_file)\n        if config.is_fresh() is False:\n            raise ValueError(\n                \"Config file already tracking previously created core or group\"\n            )\n        if region is None:\n            region = self._region\n        if account_id is None:\n            account_id = self._account_id\n        keys_cert, thing = self.create_thing(thing_name, region, cert_dir)\n\n        cert_arn = keys_cert['certificateArn']\n        config['core'] = {\n            'thing_arn': thing['thingArn'],\n            'cert_arn': cert_arn,\n            'cert_id': keys_cert['certificateId'],\n            'thing_name': thing_name\n        }\n        logging.debug(\"create_core cfg:{0}\".format(config))\n        logging.info(\"Thing:'{0}' associated with cert:'{1}'\".format(\n            thing_name, cert_arn))\n        core_policy = self.get_core_policy(\n            core_name=thing_name, account_id=account_id, region=region)\n        iot_client = _get_iot_session(region=region, profile_name=profile_name)\n        self._create_attach_thing_policy(\n            cert_arn, core_policy,\n            iot_client=iot_client, policy_name=policy_name\n        )\n        misc = config['misc']\n        misc['policy_name'] = policy_name\n        config['misc'] = misc", "response": "Creates a new Greengrass Core in AWS IoT"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_devices(self, thing_names, config_file, region=None,\n                       cert_dir=None, append=False, account_id=None,\n                       policy_name='ggd-discovery-policy', profile_name=None):\n        \"\"\"\n        Using the `thing_names` values, creates Things in AWS IoT, attaches and\n        downloads new keys & certs to the certificate directory, then records\n        the created information in the local config file for inclusion in the\n        Greengrass Group as Greengrass Devices.\n\n        :param thing_names: the thing name or list of thing names to create and\n            use as Greengrass Devices\n        :param config_file: config file used to track the Greengrass Devices in\n            the group\n        :param region: the region in which to create the new devices.\n            [default: us-west-2]\n        :param cert_dir: the directory in which to store the thing's keys and\n            certs. If `None` then use the current directory.\n        :param append: append the created devices to the list of devices in the\n            config file. [default: False]\n        :param account_id: the account ID in which to create devices. If 'None'\n            the config_file will be checked for an `account_id` value in the\n            `misc` section.\n        :param policy_name: the name of the policy to associate with the device.\n            [default: 'ggd-discovery-policy']\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        \"\"\"\n        logging.info(\"create_devices thing_names:{0}\".format(thing_names))\n        config = GroupConfigFile(config_file=config_file)\n        if append is False and config.is_device_fresh() is False:\n            raise ValueError(\n                \"Config file tracking previously created devices. Append \"\n                \"devices instead\"\n            )\n\n        if region is None:\n            region = self._region\n        if account_id is None:\n            account_id = self._account_id\n        devices = dict()\n        if append:\n            devices = config['devices']\n        if type(thing_names) is str:\n            thing_names = [thing_names]\n\n        iot_client = _get_iot_session(region=region, profile_name=profile_name)\n        for thing_name in thing_names:\n            keys_cert, thing = self.create_thing(thing_name, region, cert_dir)\n            cert_arn = keys_cert['certificateArn']\n            devices[thing_name] = {\n                'thing_arn': thing['thingArn'],\n                'cert_arn': cert_arn,\n                'cert_id': keys_cert['certificateId'],\n                'thing_name': thing_name\n            }\n            logging.info(\"Thing:'{0}' associated with cert:'{1}'\".format(\n                thing_name, cert_arn))\n            device_policy = self.get_device_policy(\n                device_name=thing_name, account_id=account_id, region=region\n            )\n            self._create_attach_thing_policy(cert_arn, device_policy,\n                                             iot_client, policy_name)\n\n        config['devices'] = devices\n        logging.info(\"create_devices cfg:{0}\".format(config))", "response": "Create a set of devices for a set of thing names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassociating existing Things with a Greengrass Group with a Greengrass Devices.", "response": "def associate_devices(self, thing_names, config_file, region=None,\n                          profile_name=None):\n        # TODO remove this function when Group discovery is enriched\n        \"\"\"\n        Using the `thing_names` values, associate existing Things in AWS IoT\n        with the config of another Greengrass Group for use as Greengrass\n        Devices.\n\n        :param thing_names: the thing name or list of thing names to associate\n            as Greengrass Devices\n        :param config_file: config file used to track the Greengrass Devices in\n            the group\n        :param region: the region in which to associate devices.\n            [default: us-west-2]\n        :param profile_name: the name of the `awscli` profile to use.\n            [default: None]\n        \"\"\"\n        logging.info(\"associate_devices thing_names:{0}\".format(thing_names))\n        config = GroupConfigFile(config_file=config_file)\n        if region is None:\n            region = self._region\n        devices = config['devices']\n        if type(thing_names) is str:\n            thing_names = [thing_names]\n        iot_client = _get_iot_session(region=region, profile_name=profile_name)\n        for thing_name in thing_names:\n            thing = iot_client.describe_thing(thingName=thing_name)\n            logging.info(\"Found existing Thing:{0}\".format(thing))\n            p = iot_client.list_thing_principals(thingName=thing_name)\n            logging.info(\"Existing Thing has principals:{0}\".format(p))\n            devices[thing_name] = {\n                'thing_arn': thing['attributes']['thingArn'],\n                'cert_arn': p['principals'][0],\n                'cert_id': thing['attributes']['certificateId'],\n                'thing_name': thing_name\n            }\n            logging.info(\"Thing:'{0}' associated with config:'{1}'\".format(\n                thing_name, config_file))\n\n        config['devices'] = devices"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a rectangle i j height and width can be put into self. output", "response": "def _check_validity(self, i, j, height, width):\n        \"\"\"\n        check if a rectangle (i, j, height, width) can be put into self.output\n        \"\"\"\n        return all(self._check_cell_validity(ii, jj) for ii in range(i, i+height) for jj in range(j, j+width))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_cell_validity(self, i, j):\n        if i >= len(self._output):\n            return True\n        if j >= len(self._output[i]):\n            return True\n        if self._output[i][j] is None:\n            return True\n        return False", "response": "check if a cell is valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_data(self, message):\n        '''\n            Given an object, encode as JSON and transmit to the server.\n        '''\n        #logger.debug(\"TX:\\n%s\", json.dumps(message, indent=2))\n        data = json.dumps(message).encode('utf-8') + b'\\n'\n        self.transport.write(data)", "response": "Encode as JSON and transmit to the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def got_who_reply(self, nick=None, real_name=None, **kws):\n        '''\n            Server replied to one of our WHO requests, with details.\n        '''\n        #logger.debug('who reply: %r' % kws)\n\n        nick = nick[2:] if nick[0:2] == 'E_' else nick\n        host, ports = real_name.split(' ', 1)\n\n        self.servers.remove(nick)\n\n        logger.debug(\"Found: '%s' at %s with port list: %s\",nick, host, ports)\n        self.results[host.lower()] = ServerInfo(nick, host, ports)\n\n        if not self.servers:\n            self.all_done.set()", "response": "Called when a WHO reply is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to a specific server.", "response": "async def connect(self, server_info, proto_code=None, *,\n                            use_tor=False, disable_cert_verify=False,\n                            proxy=None, short_term=False):\n        '''\n            Start connection process.\n            Destination must be specified in a ServerInfo() record (first arg).\n        '''\n        self.server_info = server_info\n        if not proto_code:\n             proto_code,*_ = server_info.protocols\n        self.proto_code = proto_code\n\n        logger.debug(\"Connecting to: %r\" % server_info)\n\n        if proto_code == 'g':       # websocket\n            # to do this, we'll need a websockets implementation that\n            # operates more like a asyncio.Transport\n            # maybe: `asyncws` or `aiohttp` \n            raise NotImplementedError('sorry no WebSocket transport yet')\n\n        hostname, port, use_ssl = server_info.get_port(proto_code)\n\n        if use_tor:\n            if have_aiosocks:\n                # Connect via Tor proxy proxy, assumed to be on localhost:9050\n                # unless a tuple is given with another host/port combo.\n                try:\n                    socks_host, socks_port = use_tor\n                except TypeError:\n                    socks_host, socks_port = 'localhost', 9050\n\n                # basically no-one has .onion SSL certificates, and\n                # pointless anyway.\n                disable_cert_verify = True\n\n                assert not proxy, \"Sorry not yet supporting proxy->tor->dest\"\n\n                logger.debug(\" .. using TOR\")\n\n                proxy = aiosocks.Socks5Addr(socks_host, int(socks_port))\n            else:\n                logger.debug(\"Error: want to use tor, but no aiosocks module.\")\n\n        if use_ssl == True and disable_cert_verify:\n            # Create a more liberal SSL context that won't\n            # object to self-signed certicates. This is \n            # very bad on public Internet, but probably ok\n            # over Tor\n            use_ssl = ssl.create_default_context()\n            use_ssl.check_hostname = False\n            use_ssl.verify_mode = ssl.CERT_NONE\n\n            logger.debug(\" .. SSL cert check disabled\")\n\n        async def _reconnect():\n            if self.protocol: return        # race/duplicate work\n\n            if proxy:\n                if have_aiosocks:\n                    transport, protocol = await aiosocks.create_connection(\n                                            StratumProtocol, proxy=proxy,\n                                            proxy_auth=None,\n                                            remote_resolve=True, ssl=use_ssl,\n                                            dst=(hostname, port))\n                else:\n                    logger.debug(\"Error: want to use proxy, but no aiosocks module.\")\n            else:\n                transport, protocol = await self.loop.create_connection(\n                                                        StratumProtocol, host=hostname,\n                                                        port=port, ssl=use_ssl)\n\n            self.protocol = protocol\n            protocol.client = self\n\n            # capture actual values used\n            self.actual_connection = dict(hostname=hostname, port=int(port),\n                                            ssl=bool(use_ssl), tor=bool(proxy))\n            self.actual_connection['ip_addr'] = transport.get_extra_info('peername',\n                                                        default=['unknown'])[0]\n\n            if not short_term:\n                self.ka_task = self.loop.create_task(self._keepalive())\n\n            logger.debug(\"Connected to: %r\" % server_info)\n\n        # close whatever we had\n        if self.protocol:\n            self.protocol.close()\n            self.protocol = None\n\n        self.reconnect = _reconnect\n        await self.reconnect()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nkeep our connection alive forever with some pointless traffic.", "response": "async def _keepalive(self):\n        '''\n            Keep our connect to server alive forever, with some \n            pointless traffic.\n        '''\n        while self.protocol:\n            vers = await self.RPC('server.version')\n            logger.debug(\"Server version: \" + repr(vers))\n\n            # Five minutes isn't really enough anymore; looks like\n            # servers are killing 2-minute old idle connections now.\n            # But decreasing interval this seems rude.\n            await asyncio.sleep(600)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _send_request(self, method, params=[], is_subscribe = False):\n        '''\n            Send a new request to the server. Serialized the JSON and\n            tracks id numbers and optional callbacks.\n        '''\n        # pick a new ID\n        self.next_id += 1\n        req_id = self.next_id\n\n        # serialize as JSON\n        msg = {'id': req_id, 'method': method, 'params': params}\n\n        # subscriptions are a Q, normal requests are a future\n        if is_subscribe:\n            waitQ = asyncio.Queue()\n            self.subscriptions[method].append(waitQ)\n\n        fut = asyncio.Future(loop=self.loop)\n\n        self.inflight[req_id] = (msg, fut)\n\n        # send it via the transport, which serializes it\n        if not self.protocol:\n            logger.debug(\"Need to reconnect to server\")\n\n            async def connect_first():\n                await self.reconnect()\n                self.protocol.send_data(msg)\n\n            self.loop.create_task(connect_first())\n        else:\n            # typical case, send request immediatedly, response is a future\n            self.protocol.send_data(msg)\n\n        return fut if not is_subscribe else (fut, waitQ)", "response": "Send a new request to the server. Serialized the JSON and\n            tracks id numbers and optional callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _got_response(self, msg):\n        '''\n            Decode and dispatch responses from the server.\n\n            Has already been unframed and deserialized into an object.\n        '''\n\n        #logger.debug(\"MSG: %r\" % msg)\n\n        resp_id = msg.get('id', None)\n\n        if resp_id is None:\n            # subscription traffic comes with method set, but no req id.\n            method = msg.get('method', None)\n            if not method:\n                logger.error(\"Incoming server message had no ID nor method in it\", msg)\n                return\n\n            # not obvious, but result is on params, not result, for subscriptions\n            result = msg.get('params', None)\n\n            logger.debug(\"Traffic on subscription: %s\" % method)\n\n            subs = self.subscriptions.get(method)\n            for q in subs:\n                self.loop.create_task(q.put(result))\n\n            return\n\n        assert 'method' not in msg\n        result = msg.get('result')\n\n        # fetch and forget about the request\n        inf = self.inflight.pop(resp_id) \n        if not inf:\n            logger.error(\"Incoming server message had unknown ID in it: %s\" % resp_id)\n            return\n\n        # it's a future which is done now\n        req, rv = inf\n\n        if 'error' in msg:\n            err = msg['error']\n            \n            logger.info(\"Error response: '%s'\" % err)\n            rv.set_exception(ElectrumErrorResponse(err, req))\n\n        else:\n            rv.set_result(result)", "response": "Decode and dispatch a response from the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubscribe to the specified node.", "response": "def subscribe(self, method, *params):\n        '''\n            Perform a remote command which will stream events/data to us.\n\n            Expects a method name, which look like:\n                server.peers.subscribe\n            .. and sometimes take arguments, all of which are positional.\n    \n            Returns a tuple: (Future, asyncio.Queue).\n            The future will have the result of the initial\n            call, and the queue will receive additional\n            responses as they happen.\n        '''\n        assert '.' in method\n        assert method.endswith('subscribe')\n        return self._send_request(method, params, is_subscribe=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn hostname port number ssl flag for the protocol.", "response": "def get_port(self, for_protocol):\n        '''\n            Return (hostname, port number, ssl) pair for the protocol.\n            Assuming only one port per host.\n        '''\n        assert len(for_protocol) == 1, \"expect single letter code\"\n\n        use_ssl = for_protocol in ('s', 'g')\n\n        if 'port' in self: return self['hostname'], int(self['port']), use_ssl\n\n        rv = next(i for i in self['ports'] if i[0] == for_protocol)\n\n        port = None\n        if len(rv) >= 2:\n            try:\n                port = int(rv[1:])\n            except:\n                pass\n        port = port or DEFAULT_PORTS[for_protocol]\n\n        return self['hostname'], port, use_ssl"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_json(self, fname):\n        '''\n            Read contents of a CSV containing a list of servers.\n        '''\n        with open(fname, 'rt') as fp:\n            for row in json.load(fp):\n                nn = ServerInfo.from_dict(row)\n                self[str(nn)] = nn", "response": "Read contents of a CSV containing a list of servers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_irc(self, irc_nickname=None, irc_password=None):\n        '''\n            Connect to the IRC channel and find all servers presently connected.\n\n            Slow; takes 30+ seconds but authoritative and current.\n\n            OBSOLETE.\n        '''\n        if have_bottom:\n            from .findall import IrcListener\n\n            # connect and fetch current set of servers who are\n            # on #electrum channel at freenode\n\n            bot = IrcListener(irc_nickname=irc_nickname, irc_password=irc_password)\n            results = bot.loop.run_until_complete(bot.collect_data())\n            bot.loop.close()\n\n            # merge by nick name\n            self.update(results)\n        else:\n            return(False)", "response": "Connect to the IRC channel and find all servers presently connected."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_single(self, hostname, ports, nickname=None, **kws):\n        '''\n            Explicitly add a single entry.\n            Hostname is a FQDN and ports is either a single int (assumed to be TCP port)\n            or Electrum protocol/port number specification with spaces in between.\n        '''\n        nickname = nickname or hostname\n\n        self[hostname.lower()] = ServerInfo(nickname, hostname, ports, **kws)", "response": "Explicitly add a single entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites out to a CSV file.", "response": "def save_json(self, fname='servers.json'):\n        '''\n            Write out to a CSV file.\n        '''\n        rows = sorted(self.keys())\n        with open(fname, 'wt') as fp:\n            json.dump([self[k] for k in rows], fp, indent=1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting all servers with indicated protocol support. Shuffled. Find all servers with indicated protocol support. Shuffled. Filter by TOR support. Shuffled. Return a list of servers with indicated protocol support.", "response": "def select(self, **kws):\n        '''\n            Find all servers with indicated protocol support. Shuffled.\n\n            Filter by TOR support, and pruning level.\n        '''\n        lst = [i for i in self.values() if i.select(**kws)]\n\n        random.shuffle(lst)\n\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _post_patched_request(consumers, lti_key, body,\n                          url, method, content_type):\n    \"\"\"\n    Authorization header needs to be capitalized for some LTI clients\n    this function ensures that header is capitalized\n\n    :param body: body of the call\n    :param client: OAuth Client\n    :param url: outcome url\n    :return: response\n    \"\"\"\n    # pylint: disable=too-many-locals, too-many-arguments\n    oauth_server = LTIOAuthServer(consumers)\n    oauth_server.add_signature_method(SignatureMethod_HMAC_SHA1_Unicode())\n    lti_consumer = oauth_server.lookup_consumer(lti_key)\n    lti_cert = oauth_server.lookup_cert(lti_key)\n    secret = lti_consumer.secret\n\n    consumer = oauth2.Consumer(key=lti_key, secret=secret)\n    client = oauth2.Client(consumer)\n\n    if lti_cert:\n        client.add_certificate(key=lti_cert, cert=lti_cert, domain='')\n        log.debug(\"cert %s\", lti_cert)\n\n    import httplib2\n\n    http = httplib2.Http\n    # pylint: disable=protected-access\n    normalize = http._normalize_headers\n\n    def my_normalize(self, headers):\n        \"\"\" This function patches Authorization header \"\"\"\n        ret = normalize(self, headers)\n        if 'authorization' in ret:\n            ret['Authorization'] = ret.pop('authorization')\n        log.debug(\"headers\")\n        log.debug(headers)\n        return ret\n\n    http._normalize_headers = my_normalize\n    monkey_patch_function = normalize\n    response, content = client.request(\n        url,\n        method,\n        body=body.encode('utf-8'),\n        headers={'Content-Type': content_type})\n\n    http = httplib2.Http\n    # pylint: disable=protected-access\n    http._normalize_headers = monkey_patch_function\n\n    log.debug(\"key %s\", lti_key)\n    log.debug(\"secret %s\", secret)\n    log.debug(\"url %s\", url)\n    log.debug(\"response %s\", response)\n    log.debug(\"content %s\", format(content))\n\n    return response, content", "response": "This function is used to post a request to LTI server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_message(consumers, lti_key, url, body):\n    content_type = 'application/xml'\n    method = 'POST'\n    (_, content) = _post_patched_request(\n        consumers,\n        lti_key,\n        body,\n        url,\n        method,\n        content_type,\n    )\n\n    is_success = b\"<imsx_codeMajor>success</imsx_codeMajor>\" in content\n    log.debug(\"is success %s\", is_success)\n    return is_success", "response": "Post a signed message to LTI consumer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npost a signed message to LTI consumer using LTI 2. 0 format", "response": "def post_message2(consumers, lti_key, url, body,\n                  method='POST', content_type='application/xml'):\n    \"\"\"\n        Posts a signed message to LTI consumer using LTI 2.0 format\n\n    :param: consumers: consumers from config\n    :param: lti_key: key to find appropriate consumer\n    :param: url: post url\n    :param: body: xml body\n    :return: success\n    \"\"\"\n    # pylint: disable=too-many-arguments\n    (response, _) = _post_patched_request(\n        consumers,\n        lti_key,\n        body,\n        url,\n        method,\n        content_type,\n    )\n\n    is_success = response.status == 200\n    log.debug(\"is success %s\", is_success)\n\n    return is_success"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_request_common(consumers, url, method, headers, params):\n    log.debug(\"consumers %s\", consumers)\n    log.debug(\"url %s\", url)\n    log.debug(\"method %s\", method)\n    log.debug(\"headers %s\", headers)\n    log.debug(\"params %s\", params)\n\n    oauth_server = LTIOAuthServer(consumers)\n    oauth_server.add_signature_method(\n        SignatureMethod_PLAINTEXT_Unicode())\n    oauth_server.add_signature_method(\n        SignatureMethod_HMAC_SHA1_Unicode())\n\n    # Check header for SSL before selecting the url\n    if headers.get('X-Forwarded-Proto', 'http') == 'https':\n        url = url.replace('http:', 'https:', 1)\n\n    oauth_request = Request_Fix_Duplicate.from_request(\n        method,\n        url,\n        headers=dict(headers),\n        parameters=params\n    )\n    if not oauth_request:\n        log.info('Received non oauth request on oauth protected page')\n        raise LTIException('This page requires a valid oauth session '\n                           'or request')\n    try:\n        # pylint: disable=protected-access\n        oauth_consumer_key = oauth_request.get_parameter('oauth_consumer_key')\n        consumer = oauth_server.lookup_consumer(oauth_consumer_key)\n        if not consumer:\n            raise oauth2.Error('Invalid consumer.')\n        oauth_server.verify_request(oauth_request, consumer, None)\n    except oauth2.Error:\n        # Rethrow our own for nice error handling (don't print\n        # error message as it will contain the key\n        raise LTIException(\"OAuth error: Please check your key and secret\")\n\n    return True", "response": "Verify that a request is valid for the given consumers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate LTI 1. 1 XML for posting result to LTI consumer.", "response": "def generate_request_xml(message_identifier_id, operation,\n                         lis_result_sourcedid, score):\n    # pylint: disable=too-many-locals\n    \"\"\"\n    Generates LTI 1.1 XML for posting result to LTI consumer.\n\n    :param message_identifier_id:\n    :param operation:\n    :param lis_result_sourcedid:\n    :param score:\n    :return: XML string\n    \"\"\"\n    root = etree.Element(u'imsx_POXEnvelopeRequest',\n                         xmlns=u'http://www.imsglobal.org/services/'\n                               u'ltiv1p1/xsd/imsoms_v1p0')\n\n    header = etree.SubElement(root, 'imsx_POXHeader')\n    header_info = etree.SubElement(header, 'imsx_POXRequestHeaderInfo')\n    version = etree.SubElement(header_info, 'imsx_version')\n    version.text = 'V1.0'\n    message_identifier = etree.SubElement(header_info,\n                                          'imsx_messageIdentifier')\n    message_identifier.text = message_identifier_id\n    body = etree.SubElement(root, 'imsx_POXBody')\n    xml_request = etree.SubElement(body, '%s%s' % (operation, 'Request'))\n    record = etree.SubElement(xml_request, 'resultRecord')\n\n    guid = etree.SubElement(record, 'sourcedGUID')\n\n    sourcedid = etree.SubElement(guid, 'sourcedId')\n    sourcedid.text = lis_result_sourcedid\n    if score is not None:\n        result = etree.SubElement(record, 'result')\n        result_score = etree.SubElement(result, 'resultScore')\n        language = etree.SubElement(result_score, 'language')\n        language.text = 'en'\n        text_string = etree.SubElement(result_score, 'textString')\n        text_string.text = score.__str__()\n    ret = \"<?xml version='1.0' encoding='utf-8'?>\\n{}\".format(\n        etree.tostring(root, encoding='utf-8').decode('utf-8'))\n\n    log.debug(\"XML Response: \\n%s\", ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlooking through the keys AttributeNames and return the cert if found.", "response": "def lookup_cert(self, key):\n        \"\"\"\n        Search through keys\n        \"\"\"\n        if not self.consumers:\n            log.critical((\"No consumers defined in settings.\"\n                          \"Have you created a configuration file?\"))\n            return None\n\n        consumer = self.consumers.get(key)\n        if not consumer:\n            log.info(\"Did not find consumer, using key: %s \", key)\n            return None\n        cert = consumer.get('cert', None)\n        return cert"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether the given signature is the correct signature for the given request.", "response": "def check(self, request, consumer, token, signature):\n        \"\"\"\n        Returns whether the given signature is the correct signature for\n        the given consumer and token signing the given request.\n        \"\"\"\n        built = self.sign(request, consumer, token)\n        if isinstance(signature, STRING_TYPES):\n            signature = signature.encode(\"utf8\")\n        return built == signature"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef name(self):  # pylint: disable=no-self-use\n        if 'lis_person_sourcedid' in self.session:\n            return self.session['lis_person_sourcedid']\n        elif 'lis_person_contact_email_primary' in self.session:\n            return self.session['lis_person_contact_email_primary']\n        elif 'user_id' in self.session:\n            return self.session['user_id']\n        else:\n            return ''", "response": "Return user s name or email or user_id depending on the user s session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying if LTI request is valid", "response": "def verify(self):\n        \"\"\"\n        Verify if LTI request is valid, validation\n        depends on @lti wrapper arguments\n\n        :raises: LTIException\n        \"\"\"\n        log.debug('verify request=%s', self.lti_kwargs.get('request'))\n        if self.lti_kwargs.get('request') == 'session':\n            self._verify_session()\n        elif self.lti_kwargs.get('request') == 'initial':\n            self.verify_request()\n        elif self.lti_kwargs.get('request') == 'any':\n            self._verify_any()\n        else:\n            raise LTIException(\"Unknown request type\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_role(self, role):\n        log.debug(\"is_role %s\", role)\n        roles = self.session['roles'].split(',')\n        if role in LTI_ROLES:\n            role_list = LTI_ROLES[role]\n            # find the intersection of the roles\n            roles = set(role_list) & set(roles)\n            is_user_role_there = len(roles) >= 1\n            log.debug(\n                \"is_role roles_list=%s role=%s in list=%s\", role_list,\n                roles, is_user_role_there\n            )\n            return is_user_role_there\n        else:\n            raise LTIException(\"Unknown role {}.\".format(role))", "response": "Verify if user is in role"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that user is in role specified as wrapper attribute.", "response": "def _check_role(self):\n        \"\"\"\n        Check that user is in role specified as wrapper attribute\n\n        :exception: LTIRoleException if user is not in roles\n        \"\"\"\n        role = u'any'\n        if 'role' in self.lti_kwargs:\n            role = self.lti_kwargs['role']\n        log.debug(\n            \"check_role lti_role=%s decorator_role=%s\", self.role, role\n        )\n        if not (role == u'any' or self.is_role(self, role)):\n            raise LTIRoleException('Not authorized.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nposts grade to LTI consumer using XML clfset.", "response": "def post_grade(self, grade):\n        \"\"\"\n        Post grade to LTI consumer using XML\n\n        :param: grade: 0 <= grade <= 1\n        :return: True if post successful and grade valid\n        :exception: LTIPostMessageException if call failed\n        \"\"\"\n        message_identifier_id = self.message_identifier_id()\n        operation = 'replaceResult'\n        lis_result_sourcedid = self.lis_result_sourcedid\n        # # edX devbox fix\n        score = float(grade)\n        if 0 <= score <= 1.0:\n            xml = generate_request_xml(\n                message_identifier_id, operation, lis_result_sourcedid,\n                score)\n            ret = post_message(self._consumers(), self.key,\n                               self.response_url, xml)\n            if not ret:\n                raise LTIPostMessageException(\"Post Message Failed\")\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post_grade2(self, grade, user=None, comment=''):\n        content_type = 'application/vnd.ims.lis.v2.result+json'\n        if user is None:\n            user = self.user_id\n        lti2_url = self.response_url.replace(\n            \"/grade_handler\",\n            \"/lti_2_0_result_rest_handler/user/{}\".format(user))\n        score = float(grade)\n        if 0 <= score <= 1.0:\n            body = json.dumps({\n                \"@context\": \"http://purl.imsglobal.org/ctx/lis/v2/Result\",\n                \"@type\": \"Result\",\n                \"resultScore\": score,\n                \"comment\": comment\n            })\n            ret = post_message2(self._consumers(), self.key, lti2_url, body,\n                                method='PUT',\n                                content_type=content_type)\n            if not ret:\n                raise LTIPostMessageException(\"Post Message Failed\")\n            return True\n\n        return False", "response": "Post grade to LTI consumer using REST API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lti(app=None, request='any', error=default_error, role='any',\n        *lti_args, **lti_kwargs):\n    \"\"\"\n    LTI decorator\n\n    :param: app - Flask App object (optional).\n        :py:attr:`flask.current_app` is used if no object is passed in.\n    :param: error - Callback if LTI throws exception (optional).\n        :py:attr:`pylti.flask.default_error` is the default.\n    :param: request - Request type from\n        :py:attr:`pylti.common.LTI_REQUEST_TYPE`. (default: any)\n    :param: roles - LTI Role (default: any)\n    :return: wrapper\n    \"\"\"\n\n    def _lti(function):\n        \"\"\"\n        Inner LTI decorator\n\n        :param: function:\n        :return:\n        \"\"\"\n\n        @wraps(function)\n        def wrapper(*args, **kwargs):\n            \"\"\"\n            Pass LTI reference to function or return error.\n            \"\"\"\n            try:\n                the_lti = LTI(lti_args, lti_kwargs)\n                the_lti.verify()\n                the_lti._check_role()  # pylint: disable=protected-access\n                kwargs['lti'] = the_lti\n                return function(*args, **kwargs)\n            except LTIException as lti_exception:\n                error = lti_kwargs.get('error')\n                exception = dict()\n                exception['exception'] = lti_exception\n                exception['kwargs'] = kwargs\n                exception['args'] = args\n                return error(exception=exception)\n\n        return wrapper\n\n    lti_kwargs['request'] = request\n    lti_kwargs['error'] = error\n    lti_kwargs['role'] = role\n\n    if (not app) or isinstance(app, Flask):\n        lti_kwargs['app'] = app\n        return _lti\n    else:\n        # We are wrapping without arguments\n        lti_kwargs['app'] = None\n        return _lti(app)", "response": "Decorator for LTI class methods."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting consumer s map from app config", "response": "def _consumers(self):\n        \"\"\"\n        Gets consumer's map from app config\n\n        :return: consumers map\n        \"\"\"\n        app_config = self.lti_kwargs['app'].config\n        config = app_config.get('PYLTI_CONFIG', dict())\n        consumers = config.get('consumers', dict())\n        return consumers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_request(self):\n        if flask_request.method == 'POST':\n            params = flask_request.form.to_dict()\n        else:\n            params = flask_request.args.to_dict()\n        log.debug(params)\n        log.debug('verify_request?')\n        try:\n            verify_request_common(self._consumers(), flask_request.url,\n                                  flask_request.method, flask_request.headers,\n                                  params)\n            log.debug('verify_request success')\n\n            # All good to go, store all of the LTI params into a\n            # session dict for use in views\n            for prop in LTI_PROPERTY_LIST:\n                if params.get(prop, None):\n                    log.debug(\"params %s=%s\", prop, params.get(prop, None))\n                    session[prop] = params[prop]\n\n            # Set logged in session key\n            session[LTI_SESSION_KEY] = True\n            return True\n        except LTIException:\n            log.debug('verify_request failed')\n            for prop in LTI_PROPERTY_LIST:\n                if session.get(prop, None):\n                    del session[prop]\n\n            session[LTI_SESSION_KEY] = False\n            raise", "response": "Verify the LTI request and return the current LTI class ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the url to the response of the current session.", "response": "def response_url(self):\n        \"\"\"\n        Returns remapped lis_outcome_service_url\n        uses PYLTI_URL_FIX map to support edX dev-stack\n\n        :return: remapped lis_outcome_service_url\n        \"\"\"\n        url = \"\"\n        url = self.session['lis_outcome_service_url']\n        app_config = self.lti_kwargs['app'].config\n        urls = app_config.get('PYLTI_URL_FIX', dict())\n        # url remapping is useful for using devstack\n        # devstack reports httpS://localhost:8000/ and listens on HTTP\n        for prefix, mapping in urls.items():\n            if url.startswith(prefix):\n                for _from, _to in mapping.items():\n                    url = url.replace(_from, _to)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that the current request is in the session and that the current session is not.", "response": "def _verify_any(self):\n        \"\"\"\n        Verify that an initial request has been made, or failing that, that\n        the request is in the session\n        :raises: LTIException\n        \"\"\"\n        log.debug('verify_any enter')\n\n        # Check to see if there is a new LTI launch request incoming\n        newrequest = False\n        if flask_request.method == 'POST':\n            params = flask_request.form.to_dict()\n            initiation = \"basic-lti-launch-request\"\n            if params.get(\"lti_message_type\", None) == initiation:\n                newrequest = True\n                # Scrub the session of the old authentication\n                for prop in LTI_PROPERTY_LIST:\n                    if session.get(prop, None):\n                        del session[prop]\n                session[LTI_SESSION_KEY] = False\n\n        # Attempt the appropriate validation\n        # Both of these methods raise LTIException as necessary\n        if newrequest:\n            self.verify_request()\n        else:\n            self._verify_session()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting consumers from Lambda environment variables prefixed with CONSUMER_KEY_SECRET_.", "response": "def _consumers(self):\n        \"\"\"\n        Gets consumers from Lambda environment variables prefixed with\n        CONSUMER_KEY_SECRET_. For example, given a consumer key of foo\n        and a shared secret of bar, you should have an environment\n        variable CONSUMER_KEY_SECRET_foo=bar.\n\n        :return: consumers map\n        :raises: LTIException if environment variables are not found\n        \"\"\"\n        consumers = {}\n        for env in os.environ:\n            if env.startswith('CONSUMER_KEY_SECRET_'):\n                key = env[20:]  # Strip off the CONSUMER_KEY_SECRET_ prefix\n                # TODO: remove below after live test\n                # consumers[key] = {\"secret\": os.environ[env], \"cert\": 'NA'}\n                consumers[key] = {\"secret\": os.environ[env], \"cert\": None}\n        if not consumers:\n            raise LTIException(\"No consumers found. Chalice stores \"\n                               \"consumers in Lambda environment variables. \"\n                               \"Have you created the environment variables?\")\n        return consumers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_request(self):\n        request = self.lti_kwargs['app'].current_request\n        if request.method == 'POST':\n            # Chalice expects JSON and does not nativly support forms data in\n            # a post body. The below is copied from the parsing of query\n            # strings as implimented in match_route of Chalice local.py\n            parsed_url = request.raw_body.decode()\n            parsed_qs = parse_qs(parsed_url, keep_blank_values=True)\n            params = {k: v[0] for k, v in parsed_qs .items()}\n        else:\n            params = request.query_params\n        log.debug(params)\n        log.debug('verify_request?')\n        try:\n            # Chalice does not have a url property therefore building it.\n            protocol = request.headers.get('x-forwarded-proto', 'http')\n            hostname = request.headers['host']\n            path = request.context['path']\n            url = urlunparse((protocol, hostname, path, \"\", \"\", \"\"))\n            verify_request_common(self._consumers(), url,\n                                  request.method, request.headers,\n                                  params)\n            log.debug('verify_request success')\n\n            # All good to go, store all of the LTI params into a\n            # session dict for use in views\n            for prop in LTI_PROPERTY_LIST:\n                if params.get(prop, None):\n                    log.debug(\"params %s=%s\", prop, params.get(prop, None))\n                    self.session[prop] = params[prop]\n\n            # Set logged in session key\n            self.session[LTI_SESSION_KEY] = True\n            return True\n        except LTIException:\n            log.debug('verify_request failed')\n            for prop in LTI_PROPERTY_LIST:\n                if self.session.get(prop, None):\n                    del self.session[prop]\n\n            self.session[LTI_SESSION_KEY] = False\n            raise", "response": "Verify the request for the current Chalice and return True if the request was successful."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a queryset of all recent events in link form.", "response": "def get_queryset(self):\n        ''' Recent events are listed in link form. '''\n\n        return Event.objects.filter(\n            Q(startTime__gte=timezone.now() - timedelta(days=90)) & (\n                Q(series__isnull=False) | Q(publicevent__isnull=False)\n            )\n        ).annotate(count=Count('eventregistration')).annotate(**self.get_annotations()).exclude(\n            Q(count=0) & Q(status__in=[\n                Event.RegStatus.hidden, Event.RegStatus.regHidden, Event.RegStatus.disabled\n            ])\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the list of registrations for the given series", "response": "def get_context_data(self, **kwargs):\n        ''' Add the list of registrations for the given series '''\n\n        # Update the site session data so that registration processes know to send return links to\n        # the view class registrations page.  set_return_page() is in SiteHistoryMixin.\n        self.set_return_page('viewregistrations',_('View Registrations'),event_id=self.object.id)\n\n        context = {\n            'event': self.object,\n            'registrations': EventRegistration.objects.filter(\n                event=self.object,\n                cancelled=False\n            ).order_by('registration__customer__user__first_name', 'registration__customer__user__last_name'),\n        }\n        context.update(kwargs)\n        return super(EventRegistrationSummaryView, self).get_context_data(**context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the context data for the submission redirect view.", "response": "def get_context_data(self, **kwargs):\n        '''\n        The URL to redirect to can be explicitly specified, or it can come\n        from the site session history, or it can be the default admin success page\n        as specified in the site settings.\n        '''\n\n        context = super(SubmissionRedirectView, self).get_context_data(**kwargs)\n\n        redirect_url = unquote(self.request.GET.get('redirect_url', ''))\n        if not redirect_url:\n            redirect_url = self.get_return_page().get('url','')\n        if not redirect_url:\n            try:\n                redirect_url = Page.objects.get(\n                    pk=getConstant('general__defaultAdminSuccessPage')\n                ).get_absolute_url(settings.LANGUAGE_CODE)\n            except ObjectDoesNotExist:\n                redirect_url = '/'\n\n        context.update({\n            'redirect_url': redirect_url,\n            'seconds': self.request.GET.get('seconds', 5),\n        })\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, request, *args, **kwargs):\n        '''\n        Invoices can be viewed only if the validation string is provided, unless\n        the user is logged in and has view_all_invoice permissions\n        '''\n        user_has_validation_string = self.get_object().validationString\n        user_has_permissions = request.user.has_perm('core.view_all_invoices')\n        if request.GET.get('v', None) == user_has_validation_string or user_has_permissions:\n            return super(ViewInvoiceView, self).get(request, *args, **kwargs)\n        return self.handle_no_permission()", "response": "Check if the user has view all invoices permission and if so handle the view"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the set of invoices for which to permit notifications", "response": "def dispatch(self, request, *args, **kwargs):\n        ''' Get the set of invoices for which to permit notifications '''\n\n        if 'pk' in self.kwargs:\n            try:\n                self.invoices = Invoice.objects.filter(pk=self.kwargs.get('pk'))[:]\n            except ValueError:\n                raise Http404()\n            if not self.invoices:\n                raise Http404()\n        else:\n            ids = request.GET.get('invoices', '')\n            try:\n                self.invoices = Invoice.objects.filter(id__in=[x for x in ids.split(',')])[:]\n            except ValueError:\n                return HttpResponseBadRequest(_('Invalid invoice identifiers specified.'))\n\n        if not self.invoices:\n            return HttpResponseBadRequest(_('No invoice identifiers specified.'))\n\n        toNotify = []\n        cannotNotify = []\n\n        for invoice in self.invoices:\n            if invoice.get_default_recipients():\n                toNotify.append(invoice)\n            else:\n                cannotNotify.append(invoice)\n        self.toNotify = toNotify\n        self.cannotNotify = cannotNotify\n\n        return super(InvoiceNotificationView, self).dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npassing the set of invoices to the form for creation", "response": "def get_form_kwargs(self):\n        ''' Pass the set of invoices to the form for creation '''\n        kwargs = super(InvoiceNotificationView, self).get_form_kwargs()\n        kwargs['invoices'] = self.toNotify\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the list of customers or groups and then parse it", "response": "def dispatch(self, request, *args, **kwargs):\n        ''' If a list of customers or groups was passed, then parse it '''\n        ids = request.GET.get('customers')\n        groups = request.GET.get('customergroup')\n        self.customers = None\n\n        if ids or groups:\n            # Initial filter applies to no one but allows appending by logical or\n            filters = Q(id__isnull=True)\n\n            if ids:\n                filters = filters | Q(id__in=[int(x) for x in ids.split(',')])\n            if groups:\n                filters = filters | Q(groups__id__in=[int(x) for x in groups.split(',')])\n\n            try:\n                self.customers = Customer.objects.filter(filters)\n            except ValueError:\n                return HttpResponseBadRequest(_('Invalid customer ids passed'))\n\n        return super(SendEmailView, self).dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of recent months and recent series to pass to the form", "response": "def get_form_kwargs(self, **kwargs):\n        '''\n        Get the list of recent months and recent series to pass to the form\n        '''\n\n        numMonths = 12\n        lastStart = (\n            Event.objects.annotate(Min('eventoccurrence__startTime'))\n            .order_by('-eventoccurrence__startTime__min')\n            .values_list('eventoccurrence__startTime__min', flat=True)\n            .first()\n        )\n        if lastStart:\n            month = lastStart.month\n            year = lastStart.year\n        else:\n            month = timezone.now().month\n            year = timezone.now().year\n\n        months = [('', _('None'))]\n        for i in range(0, numMonths):\n            newmonth = (month - i - 1) % 12 + 1\n            newyear = year\n            if month - i - 1 < 0:\n                newyear = year - 1\n            newdate = datetime(year=newyear, month=newmonth, day=1)\n            newdateStr = newdate.strftime(\"%m-%Y\")\n            monthStr = newdate.strftime(\"%B, %Y\")\n            months.append((newdateStr, monthStr))\n\n        cutoff = timezone.now() - timedelta(days=120)\n\n        allEvents = Event.objects.filter(startTime__gte=cutoff).order_by('-startTime')\n        recentSeries = [('', 'None')] + [(x.id, '%s %s: %s' % (month_name[x.month], x.year, x.name)) for x in allEvents]\n\n        kwargs = super(SendEmailView, self).get_form_kwargs(**kwargs)\n        kwargs.update({\n            \"months\": months,\n            \"recentseries\": recentSeries,\n            \"customers\": self.customers,\n        })\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the initial data for the current user.", "response": "def get_initial(self):\n        '''\n        If the user already submitted the form and decided to return from the\n        confirmation page, then re-populate the form\n        '''\n        initial = super(SendEmailView, self).get_initial()\n\n        form_data = self.request.session.get(EMAIL_VALIDATION_STR, {}).get('form_data', {})\n        if form_data:\n            initial.update(form_data)\n        return initial"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef form_valid(self, form):\n        ''' Pass form data to the confirmation view '''\n        form.cleaned_data.pop('template', None)\n        self.request.session[EMAIL_VALIDATION_STR] = {'form_data': form.cleaned_data}\n        return HttpResponseRedirect(reverse('emailConfirmation'))", "response": "Pass form data to the confirmation view"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form_valid(self, form):\n        ''' For each object in the queryset, create the duplicated objects '''\n\n        startDate = form.cleaned_data.get('startDate')\n        repeatEvery = form.cleaned_data.get('repeatEvery')\n        periodicity = form.cleaned_data.get('periodicity')\n        quantity = form.cleaned_data.get('quantity')\n        endDate = form.cleaned_data.get('endDate')\n\n        # Create a list of start dates, based on the passed  values of repeatEvery,\n        # periodicity, quantity and endDate.  This list will be iterated through to\n        # create the new instances for each event.\n        if periodicity == 'D':\n            delta = {'days': repeatEvery}\n        elif periodicity == 'W':\n            delta = {'weeks': repeatEvery}\n        elif periodicity == 'M':\n            delta = {'months': repeatEvery}\n\n        repeat_list = []\n        this_date = startDate\n\n        if quantity:\n            for k in range(0, quantity):\n                repeat_list.append(this_date)\n                this_date = this_date + relativedelta(**delta)\n        elif endDate:\n            while (this_date <= endDate):\n                repeat_list.append(this_date)\n                this_date = this_date + relativedelta(**delta)\n\n        # Now, loop through the events in the queryset to create duplicates of them\n        for event in self.queryset:\n\n            # For each new occurrence, we determine the new startime by the distance from\n            # midnight of the first occurrence date, where the first occurrence date is\n            # replaced by the date given in repeat list\n            old_min_time = event.localStartTime.replace(hour=0, minute=0, second=0, microsecond=0)\n\n            old_occurrence_data = [\n                (x.startTime - old_min_time, x.endTime - old_min_time, x.cancelled)\n                for x in event.eventoccurrence_set.all()\n            ]\n\n            old_role_data = [(x.role, x.capacity) for x in event.eventrole_set.all()]\n\n            for instance_date in repeat_list:\n\n                # Ensure that time zones are treated properly\n                combined_datetime = datetime.combine(instance_date, datetime.min.time())\n                new_datetime = ensure_timezone(combined_datetime, old_min_time.tzinfo)\n\n                # Removing the pk and ID allow new instances of the event to\n                # be created upon saving with automatically generated ids.\n                event.id = None\n                event.pk = None\n                event.save()\n\n                # Create new occurrences\n                for occurrence in old_occurrence_data:\n                    EventOccurrence.objects.create(\n                        event=event,\n                        startTime=new_datetime + occurrence[0],\n                        endTime=new_datetime + occurrence[1],\n                        cancelled=occurrence[2],\n                    )\n\n                # Create new event-specific role data\n                for role in old_role_data:\n                    EventRole.objects.create(\n                        event=event,\n                        role=role[0],\n                        capacity=role[1],\n                    )\n\n                # Need to save twice to ensure that startTime etc. get\n                # updated properly.\n                event.save()\n\n            return super(RepeatEventsView, self).form_valid(form)", "response": "Create the duplicated objects for each object in the queryset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the set of recent and upcoming events to which this list applies.", "response": "def recentEvents(self):\n        '''\n        Get the set of recent and upcoming events to which this list applies.\n        '''\n        return Event.objects.filter(\n            Q(pk__in=self.individualEvents.values_list('pk',flat=True)) |\n            Q(session__in=self.eventSessions.all()) |\n            Q(publicevent__category__in=self.eventCategories.all()) |\n            Q(series__category__in=self.seriesCategories.all())\n        ).filter(\n            Q(startTime__lte=timezone.now() + timedelta(days=60)) &\n            Q(endTime__gte=timezone.now() - timedelta(days=60))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef currentEvent(self):\n        '''\n        Return the first event that hasn't ended yet, or if there are no\n        future events, the last one to end.\n        '''\n        currentEvent =  self.recentEvents.filter(endTime__gte=timezone.now()).order_by('startTime').first()\n        if not currentEvent:\n            currentEvent = self.recentEvents.filter(\n                endTime__lte=timezone.now()\n            ).order_by('-endTime').first()\n        return currentEvent", "response": "Return the first event that has not ended yet or the last one to end."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef appliesToEvent(self, event):\n        ''' Check whether this guest list is applicable to an event. '''\n        return (\n            event in self.individualEvents.all() or\n            event.session in self.eventSessions.all() or\n            event.category in self.seriesCategories.all() or\n            event.category in self.eventCategories.all()\n        )", "response": "Check whether this guest list is applicable to an event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure local time and get the beginning of the day", "response": "def getDayStart(self, dateTime):\n        ''' Ensure local time and get the beginning of the day '''\n        return ensure_localtime(dateTime).replace(hour=0,minute=0,second=0,microsecond=0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a parsimonious set of intervals and associated Q objects for a given component.", "response": "def getComponentFilters(self,component,event=None,dateTime=None):\n        '''\n        Get a parsimonious set of intervals and the associated Q() objects\n        based on the occurrences of a specified event, and the rule that\n        implicitly defines the start and end of each interval.\n        '''\n\n        # Limit to the staff member or staff category specified by the rule.\n        if component.staffMember:\n            filters = Q(pk=component.staffMember.pk)\n        else:\n            filters = Q(eventstaffmember__category=component.staffCategory)\n\n        # Handle 'Always' and 'EventOnly' rules first, because they do not require an analysis of intervals.\n        if component.admissionRule == 'EventOnly' and event:\n            # Skip the analysis of intervals and include only those who are staffed for the event.\n            return Q(filters & Q(eventstaffmember__event=event))\n        elif component.admissionRule in ['Always','EventOnly']:\n            # If 'Always' or no event is specified, include all associated staff\n            return Q(filters)\n\n        # Start with the event occurrence intervals, or with the specified time.\n        if event:\n            intervals = [(x.startTime,x.endTime) for x in event.eventoccurrence_set.all()]\n        elif dateTime:\n            intervals = [(dateTime,dateTime)]\n        else:\n            raise ValueError(_('Must provide either an event or a datetime to get interval queries.'))\n\n        if component.admissionRule == 'Day':\n            # The complete days of each event occurrence\n            intervals = [\n                (self.getDayStart(x[0]),self.getDayStart(x[1]) + timedelta(days=1)) for x in intervals\n            ]\n        elif component.admissionRule == 'Week':\n            # The complete weeks of each event occurrence\n            intervals = [\n                (\n                    self.getDayStart(x[0]) - timedelta(days=x[0].weekday()),\n                    self.getDayStart(x[1]) - timedelta(days=x[1].weekday() - 7)\n                ) for x in intervals\n            ]\n        elif component.admissionRule == 'Month':\n            # The complete month of each event occurrence\n            intervals = [\n                (\n                    self.getDayStart(x[0]).replace(day=1),\n                    self.getDayStart(x[1]).replace(day=1) + relativedelta(months=1)\n                ) for x in intervals\n            ]\n        elif component.admissionRule == 'Year':\n            # The complete years of each event occurrence\n            intervals = [\n                (\n                    self.getDayStart(x[0]).replace(month=1,day=1),\n                    self.getDayStart(x[1]).replace(year=x[1].year + 1,month=1,day=1)\n                ) for x in intervals\n            ]\n        else:\n            # This is a failsafe that will always evaluate as False.\n            return Q(pk__isnull=True)\n\n        # Use intervaltree to create the most parsimonious set of intervals for this interval\n        # and then filter on those intervals\n        intervals = [sorted(x) for x in intervals]\n        tree = IntervalTree.from_tuples(intervals)\n        tree.merge_overlaps()\n\n        # Since we are OR appending, start with something that is always False.\n        intervalFilters = Q(pk__isnull=True)\n\n        for item in tree.items():\n            intervalFilters = intervalFilters | Q(\n                Q(eventstaffmember__event__eventoccurrence__endTime__gte=item[0]) &\n                Q(eventstaffmember__event__eventoccurrence__startTime__lte=item[1])\n            )\n\n        return Q(filters & intervalFilters)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of names associated with a particular event.", "response": "def getListForEvent(self, event=None):\n        ''' Get the list of names associated with a particular event. '''\n        names = list(self.guestlistname_set.annotate(\n            guestType=Case(\n                When(notes__isnull=False, then=F('notes')),\n                default=Value(ugettext('Manually Added')),\n                output_field=models.CharField()\n            )\n        ).values('firstName','lastName','guestType'))\n\n        # Component-by-component, OR append filters to an initial filter that always\n        # evaluates to False.\n        components = self.guestlistcomponent_set.all()\n        filters = Q(pk__isnull=True)\n\n        # Add prior staff based on the component rule.\n        for component in components:\n            if event and self.appliesToEvent(event):\n                filters = filters | self.getComponentFilters(component,event=event)\n            else:\n                filters = filters | self.getComponentFilters(component,dateTime=timezone.now())\n\n        # Add all event staff if that box is checked (no need for separate components)\n        if self.includeStaff and event and self.appliesToEvent(event):\n            filters = filters | Q(eventstaffmember__event=event)\n\n        # Execute the constructed query and add the names of staff\n        names += list(StaffMember.objects.filter(filters).annotate(\n            guestType=Case(\n                When(eventstaffmember__event=event, then=Concat(Value('Event Staff: '), 'eventstaffmember__category__name')),\n                default=Value(ugettext('Other Staff')),\n                output_field=models.CharField()\n            )\n        ).distinct().values('firstName','lastName','guestType'))\n\n        if self.includeRegistrants and event and self.appliesToEvent(event):\n            names += list(Registration.objects.filter(eventregistration__event=event).annotate(\n                guestType=Value(_('Registered'),output_field=models.CharField())\n            ).values('firstName','lastName','guestType'))\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that either staffCategory or staffMember are filled in but not both.", "response": "def clean(self):\n        ''' Either staffCategory or staffMember must be filled in, but not both. '''\n        if not self.staffCategory and not self.staffMember:\n            raise ValidationError(_('Either staff category or staff member must be specified.'))\n        if self.staffCategory and self.staffMember:\n           raise ValidationError(_('Specify either a staff category or a staff member, not both.'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getEmailTemplate(request):\r\n    '''\r\n    This function handles the Ajax call made when a user wants a specific email template\r\n    '''\r\n    if request.method != 'POST':\r\n        return HttpResponse(_('Error, no POST data.'))\r\n\r\n    if not hasattr(request,'user'):\r\n        return HttpResponse(_('Error, not authenticated.'))\r\n\r\n    template_id = request.POST.get('template')\r\n\r\n    if not template_id:\r\n        return HttpResponse(_(\"Error, no template ID provided.\"))\r\n\r\n    try:\r\n        this_template = EmailTemplate.objects.get(id=template_id)\r\n    except ObjectDoesNotExist:\r\n        return HttpResponse(_(\"Error getting template.\"))\r\n\r\n    if this_template.groupRequired and this_template.groupRequired not in request.user.groups.all():\r\n        return HttpResponse(_(\"Error, no permission to access this template.\"))\r\n    if this_template.hideFromForm:\r\n        return HttpResponse(_(\"Error, no permission to access this template.\"))\r\n\r\n    return JsonResponse({\r\n        'subject': this_template.subject,\r\n        'content': this_template.content,\r\n        'html_content': this_template.html_content,\r\n        'richTextChoice': this_template.richTextChoice,\r\n    })", "response": "This function handles the Ajax call made when a user wants a specific email template"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef boolean_input(self, question, default=None):\r\n        '''\r\n        Method for yes/no boolean inputs\r\n        '''\r\n        result = input(\"%s: \" % question)\r\n        if not result and default is not None:\r\n            return default\r\n        while len(result) < 1 or result[0].lower() not in \"yn\":\r\n            result = input(\"Please answer yes or no: \")\r\n        return result[0].lower() == \"y\"", "response": "Method for yes or no boolean inputs\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new set of expense items for a given Venue - Rental.", "response": "def createExpenseItemsForVenueRental(request=None, datetimeTuple=None, rule=None, event=None):\r\n    '''\r\n    For each Location or Room-related Repeated Expense Rule, look for Events\r\n    in the designated time window that do not already have expenses associated\r\n    with them.  For hourly rental expenses, then generate new expenses that are\r\n    associated with this rule.  For non-hourly expenses, generate new expenses\r\n    based on the non-overlapping intervals of days, weeks or months for which\r\n    there is not already an ExpenseItem associated with the rule in question.\r\n    '''\r\n\r\n    # These are used repeatedly, so they are put at the top\r\n    submissionUser = getattr(request, 'user', None)\r\n    rental_category = getConstant('financial__venueRentalExpenseCat')\r\n\r\n    # Return the number of new expense items created\r\n    generate_count = 0\r\n\r\n    # First, construct the set of rules that need to be checked for affiliated events\r\n    rule_filters = Q(disabled=False) & Q(rentalRate__gt=0) & \\\r\n        (Q(locationrentalinfo__isnull=False) | Q(roomrentalinfo__isnull=False))\r\n    if rule:\r\n        rule_filters = rule_filters & Q(id=rule.id)\r\n    rulesToCheck = RepeatedExpenseRule.objects.filter(rule_filters).distinct()\r\n\r\n    # These are the filters place on Events that overlap the window in which\r\n    # expenses are being generated.\r\n    event_timefilters = Q()\r\n\r\n    if datetimeTuple and len(datetimeTuple) == 2:\r\n        timelist = list(datetimeTuple)\r\n        timelist.sort()\r\n        event_timefilters = event_timefilters & (\r\n            Q(startTime__gte=timelist[0]) & Q(startTime__lte=timelist[1])\r\n        )\r\n    if event:\r\n        event_timefilters = event_timefilters & Q(id=event.id)\r\n\r\n    # Now, we loop through the set of rules that need to be applied, then loop through the\r\n    # Events in the window in question that occurred at the location indicated by the rule.\r\n    for rule in rulesToCheck:\r\n\r\n        venue = (\r\n            getattr(rule, 'location', None) if\r\n            isinstance(rule, RoomRentalInfo) else\r\n            getattr(rule, 'location', None)\r\n        )\r\n        loc = getattr(venue, 'location') if isinstance(venue, Room) else venue\r\n        event_locfilter = Q(room=venue) if isinstance(venue, Room) else Q(location=venue)\r\n\r\n        # Find or create the TransactionParty associated with the location.\r\n        loc_party = TransactionParty.objects.get_or_create(\r\n            location=loc, defaults={'name': loc.name}\r\n        )[0]\r\n\r\n        if rule.advanceDays:\r\n            if rule.advanceDaysReference == RepeatedExpenseRule.MilestoneChoices.end:\r\n                event_timefilters = event_timefilters & \\\r\n                    Q(endTime__lte=timezone.now() + timedelta(days=rule.advanceDays))\r\n            elif rule.advanceDaysReference == RepeatedExpenseRule.MilestoneChoices.start:\r\n                event_timefilters = event_timefilters & \\\r\n                    Q(startTime__lte=timezone.now() + timedelta(days=rule.advanceDays))\r\n        if rule.priorDays:\r\n            if rule.priorDaysReference == RepeatedExpenseRule.MilestoneChoices.end:\r\n                event_timefilters = event_timefilters & \\\r\n                    Q(endTime__gte=timezone.now() - timedelta(days=rule.priorDays))\r\n            elif rule.priorDaysReference == RepeatedExpenseRule.MilestoneChoices.start:\r\n                event_timefilters = event_timefilters & \\\r\n                    Q(startTime__gte=timezone.now() - timedelta(days=rule.priorDays))\r\n        if rule.startDate:\r\n            event_timefilters = event_timefilters & Q(\r\n                event__startTime__gte=timezone.now().replace(\r\n                    year=rule.startDate.year, month=rule.startDate.month, day=rule.startDate.day,\r\n                    hour=0, minute=0, second=0, microsecond=0,\r\n                )\r\n            )\r\n        if rule.endDate:\r\n            event_timefilters = event_timefilters & Q(\r\n                event__startTime__lte=timezone.now().replace(\r\n                    year=rule.endDate.year, month=rule.endDate.month, day=rule.endDate.day,\r\n                    hour=0, minute=0, second=0, microsecond=0,\r\n                )\r\n            )\r\n\r\n        # For construction of expense descriptions\r\n        replacements = {\r\n            'type': _('Event/Series venue rental'),\r\n            'of': _('of'),\r\n            'location': venue.name,\r\n            'for': _('for'),\r\n        }\r\n\r\n        # Loop through Events for which there are not already directly allocated\r\n        # expenses under this rule, and create new ExpenseItems for them depending\r\n        # on whether the rule requires hourly expenses or non-hourly ones to\r\n        # be generated.\r\n        events = Event.objects.filter(event_locfilter & event_timefilters).exclude(\r\n            Q(expenseitem__expenseRule=rule)).distinct()\r\n\r\n        if rule.applyRateRule == rule.RateRuleChoices.hourly:\r\n            for this_event in events:\r\n                # Hourly expenses are always generated without checking for\r\n                # overlapping windows, because the periods over which hourly expenses\r\n                # are defined are disjoint.  However, hourly expenses are allocated\r\n                # directly to events, so we just need to create expenses for any events\r\n                # that do not already have an Expense Item generate under this rule.\r\n                replacements['name'] = this_event.name\r\n                replacements['dates'] = this_event.localStartTime.strftime('%Y-%m-%d')\r\n                if (\r\n                        event.localStartTime.strftime('%Y-%m-%d') != \\\r\n                        this_event.localEndTime.strftime('%Y-%m-%d')\r\n                ):\r\n                    replacements['dates'] += ' %s %s' % (\r\n                        _('to'), this_event.localEndTime.strftime('%Y-%m-%d')\r\n                    )\r\n\r\n                ExpenseItem.objects.create(\r\n                    event=this_event,\r\n                    category=rental_category,\r\n                    payTo=loc_party,\r\n                    expenseRule=rule,\r\n                    description='%(type)s %(of)s %(location)s %(for)s: %(name)s, %(dates)s' % \\\r\n                        replacements,\r\n                    submissionUser=submissionUser,\r\n                    total=this_event.duration * rule.rentalRate,\r\n                    accrualDate=this_event.startTime,\r\n                )\r\n                generate_count += 1\r\n        else:\r\n            # Non-hourly expenses are generated by constructing the time\r\n            # intervals in which the occurrence occurs, and removing from that\r\n            # interval any intervals in which an expense has already been\r\n            # generated under this rule (so, for example, monthly rentals will\r\n            # now show up multiple times). So, we just need to construct the set\r\n            # of intervals for which to construct expenses\r\n            intervals = [\r\n                (x.localStartTime, x.localEndTime) for x in \\\r\n                    EventOccurrence.objects.filter(event__in=events)\r\n            ]\r\n            remaining_intervals = rule.getWindowsAndTotals(intervals)\r\n\r\n            for startTime, endTime, total, description in remaining_intervals:\r\n                replacements['when'] = description\r\n\r\n                ExpenseItem.objects.create(\r\n                    category=rental_category,\r\n                    payTo=loc_party,\r\n                    expenseRule=rule,\r\n                    periodStart=startTime,\r\n                    periodEnd=endTime,\r\n                    description='%(type)s %(of)s %(location)s %(for)s %(when)s' % replacements,\r\n                    submissionUser=submissionUser,\r\n                    total=total,\r\n                    accrualDate=startTime,\r\n                )\r\n                generate_count += 1\r\n    rulesToCheck.update(lastRun=timezone.now())\r\n    return generate_count"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new set of expense items for each event in the designated time window.", "response": "def createExpenseItemsForEvents(request=None, datetimeTuple=None, rule=None, event=None):\r\n    '''\r\n    For each StaffMember-related Repeated Expense Rule, look for EventStaffMember\r\n    instances in the designated time window that do not already have expenses associated\r\n    with them.  For hourly rental expenses, then generate new expenses that are\r\n    associated with this rule.  For non-hourly expenses, generate new expenses\r\n    based on the non-overlapping intervals of days, weeks or months for which\r\n    there is not already an ExpenseItem associated with the rule in question.\r\n    '''\r\n\r\n    # This is used repeatedly, so it is put at the top\r\n    submissionUser = getattr(request, 'user', None)\r\n\r\n    # Return the number of new expense items created\r\n    generate_count = 0\r\n\r\n    # First, construct the set of rules that need to be checked for affiliated events\r\n    rule_filters = Q(disabled=False) & Q(rentalRate__gt=0) & \\\r\n        Q(Q(staffmemberwageinfo__isnull=False) | Q(staffdefaultwage__isnull=False))\r\n    if rule:\r\n        rule_filters = rule_filters & Q(id=rule.id)\r\n    rulesToCheck = RepeatedExpenseRule.objects.filter(\r\n        rule_filters).distinct().order_by(\r\n            '-staffmemberwageinfo__category', '-staffdefaultwage__category'\r\n        )\r\n\r\n    # These are the filters placed on Events that overlap the window in which\r\n    # expenses are being generated.\r\n    event_timefilters = Q()\r\n\r\n    if datetimeTuple and len(datetimeTuple) == 2:\r\n        timelist = list(datetimeTuple)\r\n        timelist.sort()\r\n        event_timefilters = event_timefilters & (\r\n            Q(event__startTime__gte=timelist[0]) & Q(event__startTime__lte=timelist[1])\r\n        )\r\n\r\n    if event:\r\n        event_timefilters = event_timefilters & Q(event__id=event.id)\r\n\r\n    # Now, we loop through the set of rules that need to be applied, then loop\r\n    # through the Events in the window in question that involved the staff\r\n    # member indicated by the rule.\r\n    for rule in rulesToCheck:\r\n        staffMember = getattr(rule, 'staffMember', None)\r\n        staffCategory = getattr(rule, 'category', None)\r\n\r\n        # No need to continue if expenses are not to be generated\r\n        if (\r\n                (not staffMember and not staffCategory) or\r\n                (\r\n                    not staffMember and not\r\n                    getConstant('financial__autoGenerateFromStaffCategoryDefaults')\r\n                )\r\n        ):\r\n            continue\r\n\r\n        # For construction of expense descriptions\r\n        replacements = {\r\n            'type': _('Staff'),\r\n            'to': _('payment to'),\r\n            'for': _('for'),\r\n        }\r\n\r\n        # This is the generic category for all Event staff, but it may be overridden below\r\n        expense_category = getConstant('financial__otherStaffExpenseCat')\r\n\r\n        if staffCategory:\r\n            if staffMember:\r\n                # This staff member in this category\r\n                eventstaff_filter = Q(staffMember=staffMember) & Q(category=staffCategory)\r\n            elif getConstant('financial__autoGenerateFromStaffCategoryDefaults'):\r\n                # Any staff member who does not already have a rule specified this category\r\n                eventstaff_filter = (\r\n                    Q(category=staffCategory) &\r\n                    ~Q(staffMember__expenserules__category=staffCategory)\r\n                )\r\n            replacements['type'] = staffCategory.name\r\n\r\n            # For standard categories of staff, map the EventStaffCategory to\r\n            # an ExpenseCategory using the stored constants.  Otherwise, the\r\n            # ExpenseCategory is a generic one.\r\n            if staffCategory == getConstant('general__eventStaffCategoryAssistant'):\r\n                expense_category = getConstant('financial__assistantClassInstructionExpenseCat')\r\n            elif staffCategory in [\r\n                    getConstant('general__eventStaffCategoryInstructor'),\r\n                    getConstant('general__eventStaffCategorySubstitute')\r\n            ]:\r\n                expense_category = getConstant('financial__classInstructionExpenseCat')\r\n\r\n        else:\r\n            # We don't want to generate duplicate expenses when there is both a category-limited\r\n            # rule and a non-limited rule for the same person, so we have to construct the list\r\n            # of categories that are to be excluded if no category is specified by this rule.\r\n            coveredCategories = list(staffMember.expenserules.filter(\r\n                category__isnull=False).values_list('category__id', flat=True))\r\n            eventstaff_filter = Q(staffMember=staffMember) & ~Q(category__id__in=coveredCategories)\r\n\r\n        if rule.advanceDays is not None:\r\n            if rule.advanceDaysReference == RepeatedExpenseRule.MilestoneChoices.end:\r\n                event_timefilters = event_timefilters & Q(\r\n                    event__endTime__lte=timezone.now() + timedelta(days=rule.advanceDays)\r\n                )\r\n            elif rule.advanceDaysReference == RepeatedExpenseRule.MilestoneChoices.start:\r\n                event_timefilters = event_timefilters & Q(\r\n                    event__startTime__lte=timezone.now() + timedelta(days=rule.advanceDays)\r\n                )\r\n        if rule.priorDays is not None:\r\n            if rule.priorDaysReference == RepeatedExpenseRule.MilestoneChoices.end:\r\n                event_timefilters = event_timefilters & Q(\r\n                    event__endTime__gte=timezone.now() - timedelta(days=rule.priorDays)\r\n                )\r\n            elif rule.priorDaysReference == RepeatedExpenseRule.MilestoneChoices.start:\r\n                event_timefilters = event_timefilters & Q(\r\n                    event__startTime__gte=timezone.now() - timedelta(days=rule.priorDays)\r\n                )\r\n        if rule.startDate:\r\n            event_timefilters = event_timefilters & Q(event__startTime__gte=timezone.now().replace(\r\n                year=rule.startDate.year, month=rule.startDate.month, day=rule.startDate.day,\r\n                hour=0, minute=0, second=0, microsecond=0,\r\n            ))\r\n        if rule.endDate:\r\n            event_timefilters = event_timefilters & Q(event__startTime__lte=timezone.now().replace(\r\n                year=rule.endDate.year, month=rule.endDate.month, day=rule.endDate.day,\r\n                hour=0, minute=0, second=0, microsecond=0,\r\n            ))\r\n\r\n        # Loop through EventStaffMembers for which there are not already\r\n        # directly allocated expenses under this rule, and create new\r\n        # ExpenseItems for them depending on whether the rule requires hourly\r\n        # expenses or non-hourly ones to be generated.\r\n\r\n        staffers = EventStaffMember.objects.filter(eventstaff_filter & event_timefilters).exclude(\r\n            Q(event__expenseitem__expenseRule=rule)).distinct()\r\n\r\n        if rule.applyRateRule == rule.RateRuleChoices.hourly:\r\n            for staffer in staffers:\r\n                # Hourly expenses are always generated without checking for\r\n                # overlapping windows, because the periods over which hourly\r\n                # expenses are defined are disjoint.  However, hourly expenses\r\n                # are allocated directly to events, so we just need to create\r\n                # expenses for any events that do not already have an Expense\r\n                # Item generate under this rule.\r\n                replacements['event'] = staffer.event.name\r\n                replacements['name'] = staffer.staffMember.fullName\r\n                replacements['dates'] = staffer.event.startTime.strftime('%Y-%m-%d')\r\n                if (\r\n                        staffer.event.startTime.strftime('%Y-%m-%d') !=\r\n                        staffer.event.endTime.strftime('%Y-%m-%d')\r\n                ):\r\n                    replacements['dates'] += ' %s %s' % (\r\n                        _('to'), staffer.event.endTime.strftime('%Y-%m-%d')\r\n                    )\r\n\r\n                # Find or create the TransactionParty associated with the staff member.\r\n                staffer_party = TransactionParty.objects.get_or_create(\r\n                    staffMember=staffer.staffMember,\r\n                    defaults={\r\n                        'name': staffer.staffMember.fullName,\r\n                        'user': getattr(staffer.staffMember, 'userAccount', None)\r\n                    }\r\n                )[0]\r\n\r\n                params = {\r\n                    'event': staffer.event,\r\n                    'category': expense_category,\r\n                    'expenseRule': rule,\r\n                    'description': '%(type)s %(to)s %(name)s %(for)s: %(event)s, %(dates)s' % \\\r\n                        replacements,\r\n                    'submissionUser': submissionUser,\r\n                    'hours': staffer.netHours,\r\n                    'wageRate': rule.rentalRate,\r\n                    'total': staffer.netHours * rule.rentalRate,\r\n                    'accrualDate': staffer.event.startTime,\r\n                    'payTo': staffer_party,\r\n                }\r\n\r\n                ExpenseItem.objects.create(**params)\r\n                generate_count += 1\r\n        else:\r\n            # Non-hourly expenses are generated by constructing the time\r\n            # intervals in which the occurrence occurs, and removing from that\r\n            # interval any intervals in which an expense has already been\r\n            # generated under this rule (so, for example, monthly rentals will\r\n            # now show up multiple times). So, we just need to construct the set\r\n            # of intervals for which to construct expenses.  We first need to\r\n            # split the set of EventStaffMember objects by StaffMember (in case\r\n            # this rule is not person-specific) and then run this provedure\r\n            # separated by StaffMember.\r\n            members = StaffMember.objects.filter(eventstaffmember__in=staffers)\r\n\r\n            for member in members:\r\n                events = [x.event for x in staffers.filter(staffMember=member)]\r\n\r\n                # Find or create the TransactionParty associated with the staff member.\r\n                staffer_party = TransactionParty.objects.get_or_create(\r\n                    staffMember=member,\r\n                    defaults={\r\n                        'name': member.fullName,\r\n                        'user': getattr(member, 'userAccount', None)\r\n                    }\r\n                )[0]\r\n\r\n                intervals = [\r\n                    (x.localStartTime, x.localEndTime) for x in\r\n                    EventOccurrence.objects.filter(event__in=events)\r\n                ]\r\n                remaining_intervals = rule.getWindowsAndTotals(intervals)\r\n\r\n                for startTime, endTime, total, description in remaining_intervals:\r\n                    replacements['when'] = description\r\n                    replacements['name'] = member.fullName\r\n\r\n                    params = {\r\n                        'category': expense_category,\r\n                        'expenseRule': rule,\r\n                        'periodStart': startTime,\r\n                        'periodEnd': endTime,\r\n                        'description': '%(type)s %(to)s %(name)s %(for)s %(when)s' % replacements,\r\n                        'submissionUser': submissionUser,\r\n                        'total': total,\r\n                        'accrualDate': startTime,\r\n                        'payTo': staffer_party,\r\n                    }\r\n\r\n                    ExpenseItem.objects.create(**params)\r\n                    generate_count += 1\r\n    rulesToCheck.update(lastRun=timezone.now())\r\n    return generate_count"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating generic expenses for the specified request and datetime tuple.", "response": "def createGenericExpenseItems(request=None, datetimeTuple=None, rule=None):\r\n    '''\r\n    Generic repeated expenses are created by just entering an\r\n    expense at each exact point specified by the rule, without\r\n    regard for whether events are scheduled in the specified\r\n    window,\r\n    '''\r\n\r\n    # These are used repeatedly, so they are put at the top\r\n    submissionUser = getattr(request, 'user', None)\r\n\r\n    # Return the number of new expense items created\r\n    generate_count = 0\r\n\r\n    # First, construct the set of rules that need to be checked for affiliated events\r\n    rule_filters = Q(disabled=False) & Q(rentalRate__gt=0) & \\\r\n        Q(genericrepeatedexpense__isnull=False)\r\n    if rule:\r\n        rule_filters = rule_filters & Q(id=rule.id)\r\n    rulesToCheck = RepeatedExpenseRule.objects.filter(rule_filters).distinct()\r\n\r\n    # These are the filters place on Events that overlap the window in which\r\n    # expenses are being generated.\r\n    if datetimeTuple and len(datetimeTuple) == 2:\r\n        timelist = list(datetimeTuple)\r\n        timelist.sort()\r\n    else:\r\n        timelist = None\r\n\r\n    # Now, we loop through the set of rules that need to be applied, check for an\r\n    # existing expense item at each point specified by the rule, and create a new\r\n    # expense if one does not exist.\r\n    for rule in rulesToCheck:\r\n\r\n        limits = timelist or [ensure_timezone(datetime.min), ensure_timezone(datetime.max)]\r\n\r\n        if rule.advanceDays:\r\n            limits[1] = min(limits[1], timezone.now() + timedelta(days=rule.advanceDays))\r\n        if rule.priorDays:\r\n            limits[0] = max(limits[0], timezone.now() - timedelta(days=rule.priorDays))\r\n\r\n        if rule.startDate:\r\n            limits[0] = max(\r\n                limits[0],\r\n                timezone.now().replace(\r\n                    year=rule.startDate.year, month=rule.startDate.month, day=rule.startDate.day,\r\n                    hour=0, minute=0, second=0, microsecond=0,\r\n                )\r\n            )\r\n        if rule.endDate:\r\n            limits[1] = min(\r\n                limits[1],\r\n                timezone.now().replace(\r\n                    year=rule.endDate.year, month=rule.endDate.month, day=rule.endDate.day,\r\n                    hour=0, minute=0, second=0, microsecond=0,\r\n                )\r\n            )\r\n\r\n        # Find the first start time greater than the lower bound time.\r\n        if rule.applyRateRule == RepeatedExpenseRule.RateRuleChoices.hourly:\r\n            this_time = limits[0].replace(minute=0, second=0, microsecond=0)\r\n            if this_time < limits[0]:\r\n                this_time += timedelta(hours=1)\r\n        elif rule.applyRateRule == RepeatedExpenseRule.RateRuleChoices.daily:\r\n            this_time = limits[0].replace(hour=rule.dayStarts, minute=0, second=0, microsecond=0)\r\n            if this_time < limits[0]:\r\n                this_time += timedelta(days=1)\r\n        elif rule.applyRateRule == RepeatedExpenseRule.RateRuleChoices.weekly:\r\n            offset = limits[0].weekday() - rule.weekStarts\r\n            this_time = limits[0].replace(\r\n                day=limits[0].day - offset, hour=rule.dayStarts, minute=0, second=0, microsecond=0\r\n            )\r\n            if this_time < limits[0]:\r\n                this_time += timedelta(days=7)\r\n        else:\r\n            this_time = limits[0].replace(\r\n                day=rule.monthStarts, hour=rule.dayStarts, minute=0, second=0, microsecond=0\r\n            )\r\n            if this_time < limits[0]:\r\n                this_time += relativedelta(months=1)\r\n\r\n        while this_time <= limits[1]:\r\n            defaults_dict = {\r\n                'category': rule.category,\r\n                'description': rule.name,\r\n                'submissionUser': submissionUser,\r\n                'total': rule.rentalRate,\r\n                'accrualDate': this_time,\r\n                'payTo': rule.payTo,\r\n            }\r\n            item, created = ExpenseItem.objects.get_or_create(\r\n                expenseRule=rule,\r\n                periodStart=this_time,\r\n                periodEnd=this_time,\r\n                defaults=defaults_dict\r\n            )\r\n            if created:\r\n                generate_count += 1\r\n            if rule.applyRateRule == RepeatedExpenseRule.RateRuleChoices.hourly:\r\n                this_time += timedelta(hours=1)\r\n            elif rule.applyRateRule == RepeatedExpenseRule.RateRuleChoices.daily:\r\n                this_time += timedelta(days=1)\r\n            elif rule.applyRateRule == RepeatedExpenseRule.RateRuleChoices.weekly:\r\n                this_time += timedelta(days=7)\r\n            else:\r\n                this_time += relativedelta(months=1)\r\n    rulesToCheck.update(lastRun=timezone.now())\r\n    return generate_count"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dispatch(self,request,*args,**kwargs):\n        '''\n        Check that a valid Invoice ID has been passed in session data,\n        and that said invoice is marked as paid.\n        '''\n        paymentSession = request.session.get(INVOICE_VALIDATION_STR, {})\n        self.invoiceID = paymentSession.get('invoiceID')\n        self.amount = paymentSession.get('amount',0)\n        self.success_url = paymentSession.get('success_url',reverse('registration'))\n\n        # Check that Invoice matching passed ID exists\n        try:\n            i = Invoice.objects.get(id=self.invoiceID)\n        except ObjectDoesNotExist:\n            return HttpResponseBadRequest(_('Invalid invoice information passed.'))\n\n        if i.unpaid or i.amountPaid != self.amount:\n            return HttpResponseBadRequest(_('Passed invoice is not paid.'))\n\n        return super(GiftCertificateCustomizeView,self).dispatch(request,*args,**kwargs)", "response": "Check that a valid invoice ID has been passed in session data and that the invoice is paid and that the amount passed in is not paid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef form_valid(self,form):\n        '''\n        Create the gift certificate voucher with the indicated information and send\n        the email as directed.\n        '''\n        emailTo = form.cleaned_data.get('emailTo')\n        emailType = form.cleaned_data.get('emailType')\n        recipientName = form.cleaned_data.get('recipientName')\n        fromName = form.cleaned_data.get('fromName')\n        message = form.cleaned_data.get('message')\n\n        logger.info('Processing gift certificate.')\n\n        try:\n            voucher = Voucher.create_new_code(\n                prefix='GC_',\n                name=_('Gift certificate: %s%s for %s' % (getConstant('general__currencySymbol'),self.amount, emailTo)),\n                category=getConstant('vouchers__giftCertCategory'),\n                originalAmount=self.amount,\n                singleUse=False,\n                forFirstTimeCustomersOnly=False,\n                expirationDate=None,\n            )\n        except IntegrityError:\n            logger.error('Error creating gift certificate voucher for Invoice #%s' % self.invoiceId)\n            emailErrorMessage(_('Gift certificate transaction not completed'), self.invoiceId)\n\n        template = getConstant('vouchers__giftCertTemplate')\n\n        # Attempt to attach a PDF of the gift certificate\n        rf = RequestFactory()\n        pdf_request = rf.get('/')\n\n        pdf_kwargs = {\n            'currencySymbol': getConstant('general__currencySymbol'),\n            'businessName': getConstant('contact__businessName'),\n            'certificateAmount': voucher.originalAmount,\n            'certificateCode': voucher.voucherId,\n            'certificateMessage': message,\n            'recipientName': recipientName,\n            'fromName': fromName,\n        }\n        if recipientName:\n            pdf_kwargs.update({})\n\n        attachment = GiftCertificatePDFView(request=pdf_request).get(request=pdf_request,**pdf_kwargs).content or None\n\n        if attachment:\n            attachment_name = 'gift_certificate.pdf'\n        else:\n            attachment_name = None\n\n        # Send a confirmation email\n        email_class = EmailRecipientMixin()\n        email_class.email_recipient(\n            subject=template.subject,\n            content=template.content,\n            send_html=template.send_html,\n            html_content=template.html_content,\n            from_address=template.defaultFromAddress,\n            from_name=template.defaultFromName,\n            cc=template.defaultCC,\n            to=emailTo,\n            currencySymbol=getConstant('general__currencySymbol'),\n            businessName=getConstant('contact__businessName'),\n            certificateAmount=voucher.originalAmount,\n            certificateCode=voucher.voucherId,\n            certificateMessage=message,\n            recipientName=recipientName,\n            fromName=fromName,\n            emailType=emailType,\n            recipient_name=recipientName,\n            attachment_name=attachment_name,\n            attachment=attachment\n        )\n\n        # Remove the invoice session data\n        self.request.session.pop(INVOICE_VALIDATION_STR,None)\n\n        return HttpResponseRedirect(self.get_success_url())", "response": "Create the gift certificate voucher with the indicated information and send it as directed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the status of the Series that are currently open for registration.", "response": "def updateSeriesRegistrationStatus():\r\n    '''\r\n    Every hour, check if the series that are currently open for registration\r\n    should be closed.\r\n    '''\r\n    from .models import Series\r\n\r\n    if not getConstant('general__enableCronTasks'):\r\n        return\r\n\r\n    logger.info('Checking status of Series that are open for registration.')\r\n\r\n    open_series = Series.objects.filter().filter(**{'registrationOpen': True})\r\n\r\n    for series in open_series:\r\n        series.updateRegistrationStatus()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef updateFinancialItems():\n    '''\n    Every hour, create any necessary revenue items and expense items for\n    activities that need them.\n    '''\n    if not getConstant('general__enableCronTasks'):\n        return\n\n    logger.info('Creating automatically-generated financial items.')\n\n    if getConstant('financial__autoGenerateExpensesEventStaff'):\n        createExpenseItemsForEvents()\n    if getConstant('financial__autoGenerateExpensesVenueRental'):\n        createExpenseItemsForVenueRental()\n    if getConstant('financial__autoGenerateRevenueRegistrations'):\n        createRevenueItemsForRegistrations()", "response": "Update the financial items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend an error message via email.", "response": "def emailErrorMessage(subject,message):\n    '''\n    Useful for sending error messages via email.\n    '''\n    if not getConstant('email__enableErrorEmails'):\n        logger.info('Not sending error email: error emails are not enabled.')\n        return\n\n    send_from = getConstant('email__errorEmailFrom')\n    send_to = getConstant('email__errorEmailTo')\n\n    if not send_from or not send_to:\n        logger.error('Cannot send error emails because addresses have not been specified.')\n        return\n\n    try:\n        send_mail(subject,message,\n                  send_from,\n                  [send_to], fail_silently=False)\n        logger.debug('Error email sent.')\n    except Exception as e:\n        logger.error('Error email was not sent: %s' % e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self,request,*args,**kwargs):\n        '''\n        Allow passing of basis and time limitations\n        '''\n        try:\n            year = int(self.kwargs.get('year'))\n        except (ValueError, TypeError):\n            year = getIntFromGet(request,'year')\n\n        kwargs.update({\n            'year': year,\n            'basis': request.GET.get('basis'),\n        })\n\n        if kwargs.get('basis') not in EXPENSE_BASES.keys():\n            kwargs['basis'] = 'accrualDate'\n\n        return super().get(request, *args, **kwargs)", "response": "Allow passing of basis and time limitations\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self,request,*args,**kwargs):\n        '''\n        Pass any permissable GET data.  URL parameters override GET parameters\n        '''\n        try:\n            year = int(self.kwargs.get('year'))\n        except (ValueError, TypeError):\n            year = getIntFromGet(request,'year')\n\n        if self.kwargs.get('month'):\n            try:\n                month = int(self.kwargs.get('month'))\n            except (ValueError, TypeError):\n                try:\n                    month = list(month_name).index(self.kwargs.get('month').title())\n                except (ValueError, TypeError):\n                    month = None\n        else:\n            month = getIntFromGet(request, 'month')\n\n        try:\n            event_id = int(self.kwargs.get('event'))\n        except (ValueError, TypeError):\n            event_id = getIntFromGet(request, 'event')\n        \n        event = None\n        if event_id:\n            try:\n                event = Event.objects.get(id=event_id)\n            except ObjectDoesNotExist:\n                pass\n\n        kwargs.update({\n            'year': year,\n            'month': month,\n            'startDate': getDateTimeFromGet(request,'startDate'),\n            'endDate': getDateTimeFromGet(request,'endDate'),\n            'basis': request.GET.get('basis'),\n            'event': event,\n        })\n\n        if kwargs.get('basis') not in EXPENSE_BASES.keys():\n            kwargs['basis'] = 'accrualDate'\n\n        context = self.get_context_data(**kwargs)\n        return self.render_to_response(context)", "response": "Returns a GET response for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_form_kwargs(self, **kwargs):\n        ''' pass the list of staff members along to the form '''\n        kwargs = super(CompensationActionView, self).get_form_kwargs(**kwargs)\n        kwargs['staffmembers'] = self.queryset\n        return kwargs", "response": "pass the list of staff members along to the form"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getDateTimeFromGet(request,key):\r\n    '''\r\n    This function just parses the request GET data for the requested key,\r\n    and returns it in datetime format, returning none if the key is not\r\n    available or is in incorrect format.\r\n    '''\r\n    if request.GET.get(key,''):\r\n        try:\r\n            return ensure_timezone(datetime.strptime(unquote(request.GET.get(key,'')),'%Y-%m-%d'))\r\n        except (ValueError, TypeError):\r\n            pass\r\n    return None", "response": "Returns a datetime object from the GET data for the requested key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinalizes the private lesson registration.", "response": "def finalizePrivateLessonRegistration(sender,**kwargs):\r\n    '''\r\n    Once a private lesson registration is finalized, mark the slots that were\r\n    used to book the private lesson as booked and associate them with the final\r\n    registration.  No need to notify students in this instance because they are\r\n    already receiving a notification of their registration.\r\n    '''\r\n\r\n    finalReg = kwargs.pop('registration')\r\n\r\n    for er in finalReg.eventregistration_set.filter(\r\n        event__privatelessonevent__isnull=False\r\n    ):\r\n        er.event.finalizeBooking(eventRegistration=er,notifyStudent=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(self, context, instance, placeholder):\r\n        ''' Create a UUID and check if a voucher with that ID exists before rendering '''\r\n        context = super(StripeGiftCertificateFormPlugin, self).render(context, instance, placeholder)\r\n\r\n        context.update({\r\n            'stripe_key': getattr(settings,'STRIPE_PUBLIC_KEY',''),\r\n            'business_name': getConstant('contact__businessName'),\r\n            'currencyCode': getConstant('general__currencyCode'),\r\n        })\r\n\r\n        return context", "response": "Create a UUID and check if a voucher with that ID exists before rendering"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_text_for_html(html_content):\r\n    '''\r\n    Take the HTML content (from, for example, an email)\r\n    and construct a simple plain text version of that content\r\n    (for example, for inclusion in a multipart email message).\r\n    '''\r\n\r\n    soup = BeautifulSoup(html_content)\r\n\r\n    # kill all script and style elements\r\n    for script in soup([\"script\", \"style\"]):\r\n        script.extract()    # rip it out\r\n\r\n    # Replace all links with HREF with the link text and the href in brackets\r\n    for a in soup.findAll('a', href=True):\r\n        a.replaceWith('%s <%s>' % (a.string, a.get('href')))\r\n\r\n    # get text\r\n    text = soup.get_text()\r\n\r\n    # break into lines and remove leading and trailing space on each\r\n    lines = (line.strip() for line in text.splitlines())\r\n    # break multi-headlines into a line each\r\n    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\r\n    # drop blank lines\r\n    text = '\\n'.join(chunk for chunk in chunks if chunk)\r\n\r\n    return text", "response": "Returns the text of the given HTML content as a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding polymorphic default to put the subclass - specific fields first", "response": "def get_fieldsets(self, request, obj=None):\n        ''' Override polymorphic default to put the subclass-specific fields first '''\n        # If subclass declares fieldsets, this is respected\n        if (hasattr(self, 'declared_fieldset') and self.declared_fieldsets) \\\n           or not self.base_fieldsets:\n            return super(PolymorphicChildModelAdmin, self).get_fieldsets(request, obj)\n\n        other_fields = self.get_subclass_fields(request, obj)\n\n        if other_fields:\n            return (\n                (self.extra_fieldset_title, {'fields': other_fields}),\n            ) + self.base_fieldsets\n        else:\n            return self.base_fieldsets"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pattern_input(self, question, message='Invalid entry', pattern='^[a-zA-Z0-9_ ]+$', default='',required=True):\n        '''\n        Method for input disallowing special characters, with optionally\n        specifiable regex pattern and error message.\n        '''\n        result = ''\n        requiredFlag = True\n\n        while (not result and requiredFlag):\n            result = input('%s: ' % question)\n            if result and pattern and not re.match(pattern, result):\n                self.stdout.write(self.style.ERROR(message))\n                result = ''\n            elif not result and default:\n                # Return default for fields with default\n                return default\n            elif not result and required:\n                # Ask again for required fields\n                self.stdout.write(self.style.ERROR('Answer is required.'))\n            elif not required:\n                # No need to re-ask for non-required fields\n                requiredFlag = False\n        return result", "response": "Method for input disallowing special characters with optionally specifiable regex pattern and error message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_timezone(dateTime,timeZone=None):\r\n    '''\r\n    Since this project is designed to be used in both time-zone aware\r\n    and naive environments, this utility just returns a datetime as either\r\n    aware or naive depending on whether time zone support is enabled.\r\n    '''\r\n\r\n    if is_aware(dateTime) and not getattr(settings,'USE_TZ',False):\r\n        return make_naive(dateTime,timezone=timeZone)\r\n    if is_naive(dateTime) and getattr(settings,'USE_TZ',False):\r\n        return make_aware(dateTime,timezone=timeZone)\r\n    # If neither condition is met, then we can return what was passed\r\n    return dateTime", "response": "Ensure that a datetime is in time - zone aware or naive depending on the settings. USE_TZ setting."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a new instance of the GiftCertificateFormPlugin and update the context with the new voucher s attributes.", "response": "def render(self, context, instance, placeholder):\r\n        ''' Create a UUID and check if a voucher with that ID exists before rendering '''\r\n        context = super(GiftCertificateFormPlugin, self).render(context, instance, placeholder)\r\n\r\n        # Paypal \"live\" mode is \"production\" to checkout.js\r\n        mode = getattr(settings,'PAYPAL_MODE', 'sandbox')\r\n        if mode == 'live':\r\n            mode = 'production'\r\n\r\n        context.update({\r\n            'paypal_mode': mode,\r\n        })\r\n\r\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getFullName(obj):\n    '''\n    This function replaces the fullName property for StaffMembers and the\n    get_full_name() method for Users, since those methods are not available\n    in the migration.\n    '''\n    if hasattr(obj, 'firstName') and hasattr(obj, 'lastName'):\n        return ' '.join([obj.firstName or '', obj.lastName or ''])\n    return ' '.join([getattr(obj, 'first_name', ''),getattr(obj, 'last_name', '')])", "response": "This function replaces the fullName property for StaffMembers and the\n    get_full_name method for Users and Users."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a TransactionParty object from a string.", "response": "def createPartyFromName(apps, name):\n    '''\n    For creating/matching TransactionParty objects using names alone.\n    Look for staff members with the same name and match to them first if there is\n    exactly one match.  Then, look for users and match them if there is exactly one\n    match. Otherwise, just generate a TransactionParty for the name only.\n    '''\n\n    TransactionParty = apps.get_model('financial', 'TransactionParty')\n    StaffMember = apps.get_model('core', 'StaffMember')\n    User = apps.get_model('auth', 'User')\n\n    firstName = name.split(' ')[0]\n    lastName = ' '.join(name.split(' ')[1:])\n\n    members = StaffMember.objects.filter(\n        firstName__istartswith=firstName, lastName__istartswith=lastName\n    )\n    users = User.objects.filter(\n        first_name__istartswith=firstName, last_name__istartswith=lastName\n    )\n\n    if members.count() == 1:\n        this_member = members.first()\n        party = TransactionParty.objects.get_or_create(\n            staffMember=this_member,\n            defaults={\n                'name': getFullName(this_member),\n                'user': this_member.userAccount,\n            }\n        )[0]\n    elif users.count() == 1:\n        this_user = users.first()\n        party = TransactionParty.objects.get_or_create(\n            user=this_user,\n            defaults={\n                'name': getFullName(this_user),\n                'staffMember': getattr(this_user, 'staffmember', None),\n            }\n        )[0]\n    else:\n        party = TransactionParty.objects.get_or_create(\n            name=name\n        )[0]\n    return party"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_payTo(apps, schema_editor):\n    '''\n    With the new TransactionParty model, the senders and recipients of financial\n    transactions are held in one place.  So, we need to loop through old ExpenseItems,\n    RevenueItems, and GenericRepeatedExpense and move their old party references\n    to the new party model. \n    '''\n    TransactionParty = apps.get_model('financial', 'TransactionParty')\n    ExpenseItem = apps.get_model('financial', 'ExpenseItem')\n    RevenueItem = apps.get_model('financial', 'RevenueItem')\n    GenericRepeatedExpense = apps.get_model('financial', 'GenericRepeatedExpense')\n\n    # First, update expense items and Generic repeated expense rules\n    for item in chain(\n        ExpenseItem.objects.filter(\n            Q(payToUser__isnull=False) | Q(payToLocation__isnull=False) | Q(payToName__isnull=False)\n        ),\n        GenericRepeatedExpense.objects.filter(\n            Q(payToUser__isnull=False) | Q(payToLocation__isnull=False) | Q(payToName__isnull=False)\n        ),\n    ):\n        if getattr(item, 'payToUser', None):\n            party = TransactionParty.objects.get_or_create(\n                user=item.payToUser,\n                defaults={\n                    'name': getFullName(item.payToUser),\n                    'staffMember': getattr(item.payToUser, 'staffmember', None),\n                }\n            )[0]\n        elif getattr(item, 'payToLocation', None):\n            party = TransactionParty.objects.get_or_create(\n                location=item.payToLocation,\n                defaults={\n                    'name': item.payToLocation.name,\n                }\n            )[0]\n        elif getattr(item, 'payToName', None):\n            party = createPartyFromName(apps, item.payToName)\n\n        item.payTo = party\n        item.save()\n\n    # Finally, update revenue items\n    for item in RevenueItem.objects.filter(\n        Q(receivedFromName__isnull=False)\n    ):\n        party = createPartyFromName(apps, item.receivedFromName)\n        item.receivedFrom = party\n        item.save()", "response": "Update the TransactionParty model with new TransactionParty model and TransactionParty models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a default category for existing discounts", "response": "def create_initial_category(apps, schema_editor):\n    ''' Create a default category for existing discounts '''\n    DiscountCategory = apps.get_model('discounts','DiscountCategory')\n    db_alias = schema_editor.connection.alias\n    DiscountCategory.objects.using(db_alias).create(\n        id=1,name='General Discounts',order=1,cannotCombine=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that registration is online before proceeding.", "response": "def dispatch(self, request, *args, **kwargs):\n        '''\n        Check that registration is online before proceeding.  If this is a POST\n        request, determine whether the response should be provided in JSON form.\n        '''\n        self.returnJson = (request.POST.get('json') in ['true', True])\n\n        regonline = getConstant('registration__registrationEnabled')\n        if not regonline:\n            returnUrl = reverse('registrationOffline')\n\n            if self.returnJson:\n                return JsonResponse({'status': 'success', 'redirect': returnUrl})\n            return HttpResponseRedirect(returnUrl)\n\n        return super().dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the event and series listing data", "response": "def get_context_data(self,**kwargs):\n        ''' Add the event and series listing data '''\n        context = self.get_listing()\n        context['showDescriptionRule'] = getConstant('registration__showDescriptionRule') or 'all'\n        context.update(kwargs)\n\n        # Update the site session data so that registration processes know to send return links to\n        # the registration page.  set_return_page() is in SiteHistoryMixin.\n        self.set_return_page('registration',_('Registration'))\n\n        return super(ClassRegistrationView,self).get_context_data(**context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntells the form which fields to render '''", "response": "def get_form_kwargs(self, **kwargs):\n        ''' Tell the form which fields to render '''\n        kwargs = super(ClassRegistrationView, self).get_form_kwargs(**kwargs)\n        kwargs['user'] = self.request.user if hasattr(self.request,'user') else None\n\n        listing = self.get_listing()\n\n        kwargs.update({\n            'openEvents': listing['openEvents'],\n            'closedEvents': listing['closedEvents'],\n        })\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef form_valid(self,form):\n        '''\n        If the form is valid, pass its contents on to the next view.  In order to permit the registration\n        form to be overridden flexibly, but without permitting storage of arbitrary data keys that could\n        lead to potential security issues, a form class for this view can optionally specify a list of\n        keys that are permitted.  If no such list is specified as instance.permitted_event_keys, then\n        the default list are used.\n        '''\n        regSession = self.request.session.get(REG_VALIDATION_STR, {})\n\n        # The session expires after a period of inactivity that is specified in preferences.\n        expiry = timezone.now() + timedelta(minutes=getConstant('registration__sessionExpiryMinutes'))\n        permitted_keys = getattr(form,'permitted_event_keys',['role',])\n\n        try:\n            event_listing = {\n                int(key.split(\"_\")[-1]): {k:v for k,v in json.loads(value[0]).items() if k in permitted_keys}\n                for key,value in form.cleaned_data.items() if 'event' in key and value\n            }\n            non_event_listing = {key: value for key,value in form.cleaned_data.items() if 'event' not in key}\n        except (ValueError, TypeError) as e:\n            form.add_error(None,ValidationError(_('Invalid event information passed.'),code='invalid'))\n            return super(ClassRegistrationView,self).form_invalid(form)\n\n        associated_events = Event.objects.filter(id__in=[k for k in event_listing.keys()])\n\n        # Include the submission user if the user is authenticated\n        if self.request.user.is_authenticated:\n            submissionUser = self.request.user\n        else:\n            submissionUser = None\n\n        reg = TemporaryRegistration(\n            submissionUser=submissionUser,dateTime=timezone.now(),\n            payAtDoor=non_event_listing.pop('payAtDoor',False),\n            expirationDate=expiry,\n        )\n\n        # Anything passed by this form that is not an Event field (any extra fields) are\n        # passed directly into the TemporaryRegistration's data.\n        reg.data = non_event_listing or {}\n\n        if regSession.get('marketing_id'):\n            reg.data.update({'marketing_id': regSession.pop('marketing_id',None)})\n\n        eventRegs = []\n        grossPrice = 0\n\n        for key,value in event_listing.items():\n            this_event = associated_events.get(id=key)\n\n            # Check if registration is still feasible based on both completed registrations\n            # and registrations that are not yet complete\n            this_role_id = value.get('role',None) if 'role' in permitted_keys else None\n            soldOut = this_event.soldOutForRole(role=this_role_id,includeTemporaryRegs=True)\n\n            if soldOut:\n                if self.request.user.has_perm('core.override_register_soldout'):\n                    # This message will be displayed on the Step 2 page by default.\n                    messages.warning(self.request,_(\n                        'Registration for \\'%s\\' is sold out. Based on your user permission level, ' % this_event.name +\n                        'you may proceed with registration.  However, if you do not wish to exceed ' +\n                        'the listed capacity of the event, please do not proceed.'\n                    ))\n                else:\n                    # For users without permissions, don't allow registration for sold out things\n                    # at all.\n                    form.add_error(None, ValidationError(_('Registration for \"%s\" is tentatively sold out while others complete their registration.  Please try again later.' % this_event.name),code='invalid'))\n                    return super(ClassRegistrationView,self).form_invalid(form)\n\n            dropInList = [int(k.split(\"_\")[-1]) for k,v in value.items() if k.startswith('dropin_') and v is True]\n\n            # If nothing is sold out, then proceed to create a TemporaryRegistration and\n            # TemporaryEventRegistration objects for the items selected by this form.  The\n            # expiration date is set to be identical to that of the session.\n\n            logger.debug('Creating temporary event registration for: %s' % key)\n            if len(dropInList) > 0:\n                tr = TemporaryEventRegistration(\n                    event=this_event, dropIn=True, price=this_event.getBasePrice(dropIns=len(dropInList))\n                )\n            else:\n                tr = TemporaryEventRegistration(\n                    event=this_event, price=this_event.getBasePrice(payAtDoor=reg.payAtDoor), role_id=this_role_id\n                )\n            # If it's possible to store additional data and such data exist, then store them.\n            tr.data = {k: v for k,v in value.items() if k in permitted_keys and k != 'role'}\n            eventRegs.append(tr)\n            grossPrice += tr.price\n\n        # If we got this far with no issues, then save\n        reg.priceWithDiscount = grossPrice\n        reg.save()\n        for er in eventRegs:\n            er.registration = reg\n            er.save()\n\n        regSession[\"temporaryRegistrationId\"] = reg.id\n        regSession[\"temporaryRegistrationExpiry\"] = expiry.strftime('%Y-%m-%dT%H:%M:%S%z')\n        self.request.session[REG_VALIDATION_STR] = regSession\n\n        if self.returnJson:\n            return JsonResponse({\n                'status': 'success', 'redirect': self.get_success_url()\n            })\n        return HttpResponseRedirect(self.get_success_url())", "response": "This method is called by the form class to validate the contents of the form."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_allEvents(self):\n        '''\n        Splitting this method out to get the set of events to filter allows\n        one to subclass for different subsets of events without copying other\n        logic\n        '''\n\n        if not hasattr(self,'allEvents'):\n            timeFilters = {'endTime__gte': timezone.now()}\n            if getConstant('registration__displayLimitDays') or 0 > 0:\n                timeFilters['startTime__lte'] = timezone.now() + timedelta(days=getConstant('registration__displayLimitDays'))\n\n            # Get the Event listing here to avoid duplicate queries\n            self.allEvents = Event.objects.filter(\n                **timeFilters\n            ).filter(\n                Q(instance_of=PublicEvent) |\n                Q(instance_of=Series)\n            ).annotate(\n                **self.get_annotations()\n            ).exclude(\n                Q(status=Event.RegStatus.hidden) |\n                Q(status=Event.RegStatus.regHidden) |\n                Q(status=Event.RegStatus.linkOnly)\n            ).order_by(*self.get_ordering())\n\n        return self.allEvents", "response": "This method returns a list of all events that are in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch(self,request,*args,**kwargs):\n        ''' Always check that the temporary registration has not expired '''\n        regSession = self.request.session.get(REG_VALIDATION_STR,{})\n\n        if not regSession:\n            return HttpResponseRedirect(reverse('registration'))\n\n        try:\n            reg = TemporaryRegistration.objects.get(\n                id=self.request.session[REG_VALIDATION_STR].get('temporaryRegistrationId')\n            )\n        except ObjectDoesNotExist:\n            messages.error(request,_('Invalid registration identifier passed to summary view.'))\n            return HttpResponseRedirect(reverse('registration'))\n\n        expiry = parse_datetime(\n            self.request.session[REG_VALIDATION_STR].get('temporaryRegistrationExpiry',''),\n        )\n        if not expiry or expiry < timezone.now():\n            messages.info(request,_('Your registration session has expired. Please try again.'))\n            return HttpResponseRedirect(reverse('registration'))\n\n        # If OK, pass the registration and proceed\n        kwargs.update({\n            'reg': reg,\n        })\n        return super(RegistrationSummaryView,self).dispatch(request, *args, **kwargs)", "response": "Check that the temporary registration has not expired and proceed with the new registration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npasses the initial kwargs then update with the needed registration info.", "response": "def get_context_data(self,**kwargs):\n        ''' Pass the initial kwargs, then update with the needed registration info. '''\n        context_data = super(RegistrationSummaryView,self).get_context_data(**kwargs)\n\n        regSession = self.request.session[REG_VALIDATION_STR]\n        reg_id = regSession[\"temp_reg_id\"]\n        reg = TemporaryRegistration.objects.get(id=reg_id)\n\n        discount_codes = regSession.get('discount_codes',None)\n        discount_amount = regSession.get('total_discount_amount',0)\n        voucher_names = regSession.get('voucher_names',[])\n        total_voucher_amount = regSession.get('total_voucher_amount',0)\n        addons = regSession.get('addons',[])\n\n        if reg.priceWithDiscount == 0:\n            # Create a new Invoice if one does not already exist.\n            new_invoice = Invoice.get_or_create_from_registration(reg,status=Invoice.PaymentStatus.paid)\n            new_invoice.processPayment(0,0,forceFinalize=True)\n            isFree = True\n        else:\n            isFree = False\n\n        context_data.update({\n            'registration': reg,\n            \"totalPrice\": reg.totalPrice,\n            'subtotal': reg.priceWithDiscount,\n            'taxes': reg.addTaxes,\n            \"netPrice\": reg.priceWithDiscountAndTaxes,\n            \"addonItems\": addons,\n            \"discount_codes\": discount_codes,\n            \"discount_code_amount\": discount_amount,\n            \"voucher_names\": voucher_names,\n            \"total_voucher_amount\": total_voucher_amount,\n            \"total_discount_amount\": discount_amount + total_voucher_amount,\n            \"currencyCode\": getConstant('general__currencyCode'),\n            'payAtDoor': reg.payAtDoor,\n            'is_free': isFree,\n        })\n\n        if self.request.user:\n            door_permission = self.request.user.has_perm('core.accept_door_payments')\n            invoice_permission = self.request.user.has_perm('core.send_invoices')\n\n            if door_permission or invoice_permission:\n                context_data['form'] = DoorAmountForm(\n                    user=self.request.user,\n                    doorPortion=door_permission,\n                    invoicePortion=invoice_permission,\n                    payerEmail=reg.email,\n                    discountAmount=max(reg.totalPrice - reg.priceWithDiscount,0),\n                )\n\n        return context_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dispatch(self, request, *args, **kwargs):\n        '''\n        Require session data to be set to proceed, otherwise go back to step 1.\n        Because they have the same expiration date, this also implies that the\n        TemporaryRegistration object is not yet expired.\n        '''\n        if REG_VALIDATION_STR not in request.session:\n            return HttpResponseRedirect(reverse('registration'))\n\n        try:\n            self.temporaryRegistration = TemporaryRegistration.objects.get(\n                id=self.request.session[REG_VALIDATION_STR].get('temporaryRegistrationId')\n            )\n        except ObjectDoesNotExist:\n            messages.error(request,_('Invalid registration identifier passed to sign-up form.'))\n            return HttpResponseRedirect(reverse('registration'))\n\n        expiry = parse_datetime(\n            self.request.session[REG_VALIDATION_STR].get('temporaryRegistrationExpiry',''),\n        )\n        if not expiry or expiry < timezone.now():\n            messages.info(request,_('Your registration session has expired. Please try again.'))\n            return HttpResponseRedirect(reverse('registration'))\n\n        return super(StudentInfoView,self).dispatch(request,*args,**kwargs)", "response": "This method is called by the user to check if the temporaryRegistration object is expired and if so check if the temporaryRegistration object is not yet expired."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_form_kwargs(self, **kwargs):\n        ''' Pass along the request data to the form '''\n        kwargs = super(StudentInfoView, self).get_form_kwargs(**kwargs)\n        kwargs['request'] = self.request\n        kwargs['registration'] = self.temporaryRegistration\n        return kwargs", "response": "Pass along the request data to the form"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevening if this form is valid, the handlers for this form may have added messages to the request. In that case, then the page should be handled as if the form were invalid. Otherwise, update the session data with the form data and then move to the next view", "response": "def form_valid(self,form):\n        '''\n        Even if this form is valid, the handlers for this form may have added messages\n        to the request.  In that case, then the page should be handled as if the form\n        were invalid.  Otherwise, update the session data with the form data and then\n        move to the next view\n        '''\n        reg = self.temporaryRegistration\n\n        # The session expires after a period of inactivity that is specified in preferences.\n        expiry = timezone.now() + timedelta(minutes=getConstant('registration__sessionExpiryMinutes'))\n        self.request.session[REG_VALIDATION_STR][\"temporaryRegistrationExpiry\"] = \\\n            expiry.strftime('%Y-%m-%dT%H:%M:%S%z')\n        self.request.session.modified = True\n\n        # Update the expiration date for this registration, and pass in the data from\n        # this form.\n        reg.expirationDate = expiry\n        reg.firstName = form.cleaned_data.pop('firstName')\n        reg.lastName = form.cleaned_data.pop('lastName')\n        reg.email = form.cleaned_data.pop('email')\n        reg.phone = form.cleaned_data.pop('phone', None)\n        reg.student = form.cleaned_data.pop('student',False)\n        reg.comments = form.cleaned_data.pop('comments',None)\n        reg.howHeardAboutUs = form.cleaned_data.pop('howHeardAboutUs',None)\n\n        # Anything else in the form goes to the TemporaryRegistration data.\n        reg.data.update(form.cleaned_data)\n        reg.save()\n\n        # This signal (formerly the post_temporary_registration signal) allows\n        # vouchers to be applied temporarily, and it can be used for other tasks\n        post_student_info.send(sender=StudentInfoView,registration=reg)\n        return HttpResponseRedirect(self.get_success_url())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef linkUserToMostRecentCustomer(sender,**kwargs):\n    '''\n    If a new primary email address has just been confirmed, check if the user\n    associated with that email has an associated customer object yet.  If not,\n    then look for the customer with that email address who most recently\n    registered for something and that is not associated with another user.\n    Automatically associate the User with with Customer, and if missing, fill in\n    the user's name information with the Customer's name.  This way, when a new\n    or existing customer creates a user account, they are seamlessly linked to\n    their most recent existing registration at the time they verify their email\n    address.\n    '''\n    email_address = kwargs.get('email_address',None)\n\n    if not email_address or not email_address.primary or not email_address.verified:\n        return\n\n    user = email_address.user\n\n    if not hasattr(user, 'customer'):\n        last_reg = Registration.objects.filter(\n            customer__email=email_address.email,\n            customer__user__isnull=True,\n            dateTime__isnull=False\n        ).order_by('-dateTime').first()\n\n        if last_reg:\n            customer = last_reg.customer\n            customer.user = user\n            customer.save()\n\n            if not user.first_name and not user.last_name:\n                user.first_name = customer.first_name\n                user.last_name = customer.last_name\n                user.save()", "response": "Link a User to the most recently registered customer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlink a Customer with a User if it has been verified as belonging to a specific User.", "response": "def linkCustomerToVerifiedUser(sender, **kwargs):\n    \"\"\"\n    If a Registration is processed in which the associated Customer does not yet\n    have a User, then check to see if the Customer's email address has been\n    verified as belonging to a specific User, and if that User has an associated\n    Customer.  If such a User is found, then associated this Customer with that\n    User.  This way, if a new User verifies their email account before they have\n    submitted any Registrations, their Customer account is seamlessly linked when\n    they do complete their first Registration.\n    \"\"\"\n    registration = kwargs.get('registration', None)\n\n    if not registration or (hasattr(registration.customer,'user') and registration.customer.user):\n        return\n\n    logger.debug('Checking for User for Customer with no associated registration.')\n\n    customer = registration.customer\n\n    try:\n        verified_email = EmailAddress.objects.get(\n            email=customer.email,\n            verified=True,\n            primary=True,\n            user__customer__isnull=True\n        )\n\n        logger.info(\"Found user %s to associate with customer %s.\", verified_email.user.id, customer.id)\n\n        customer.user = verified_email.user\n        customer.save()\n\n        if not customer.user.first_name and not customer.user.last_name:\n            customer.user.first_name = customer.first_name\n            customer.user.last_name = customer.last_name\n            customer.user.save()\n    except ObjectDoesNotExist:\n        logger.info(\"No user found to associate with customer %s.\", customer.id)\n    except MultipleObjectsReturned:\n        # This should never happen, as email should be unique in the db table account_emailaddress.\n        # If it does, something's broken in the database or Django.\n        errmsg = \"Something's not right with the database: more than one entry found on the database for the email %s. \\\n             This duplicate key value violates unique constraint \\\"account_emailaddress_email_key\\\". \\\n             The email field should be unique for each account.\\n\"\n        logger.exception(errmsg, customer.email)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallows creation of staff members using a full name string.", "response": "def create_object(self, text):\r\n        ''' Allow creation of staff members using a full name string. '''\r\n        if self.create_field == 'fullName':\r\n            firstName = text.split(' ')[0]\r\n            lastName = ' '.join(text.split(' ')[1:])\r\n            return self.get_queryset().create(**{'firstName': firstName, 'lastName': lastName})\r\n        else:\r\n            return super(StaffMemberAutoComplete,self).create_object(text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkBanlist(sender, **kwargs):\r\n    '''\r\n    Check that this individual is not on the ban list.\r\n    '''\r\n\r\n    if not getConstant('registration__enableBanList'):\r\n        return\r\n\r\n    logger.debug('Signal to check RegistrationContactForm handled by banlist app.')\r\n\r\n    formData = kwargs.get('formData', {})\r\n    first = formData.get('firstName')\r\n    last = formData.get('lastName')\r\n    email = formData.get('email')\r\n\r\n    request = kwargs.get('request', {})\r\n    session = getattr(request, 'session', {}).get(REG_VALIDATION_STR, {})\r\n    registrationId = getattr(kwargs.get('registration', None), 'id', None)\r\n\r\n    records = BannedPerson.objects.exclude(\r\n        disabled=True\r\n    ).exclude(\r\n        expirationDate__lte=timezone.now()\r\n    ).filter(\r\n        (Q(firstName__iexact=first) & Q(lastName__iexact=last)) |\r\n        Q(bannedemail__email__iexact=email)\r\n    )\r\n\r\n    if not records.exists():\r\n        return\r\n\r\n    # Generate an \"error code\" to reference so that it is easier to lookup\r\n    # the record on why they were flagged.\r\n    flagCode = ''.join(random.choice(string.ascii_uppercase) for x in range(8))\r\n    ip = get_client_ip(request)\r\n    respondTo = getConstant('registration__banListContactEmail') or getConstant('contact__businessEmail')\r\n\r\n    for record in records:\r\n        flagRecord = BanFlaggedRecord.objects.create(\r\n            flagCode=flagCode,\r\n            person=record,\r\n            ipAddress=ip,\r\n            data={'session': session, 'formData': formData, 'registrationId': registrationId}\r\n        )\r\n\r\n    notify = getConstant('registration__banListNotificationEmail')\r\n    if notify:\r\n        send_from = getConstant('contact__businessEmail')\r\n        subject = _('Notice of attempted registration by banned individual')\r\n        message = _(\r\n            'This is an automated notification that the following individual has attempted ' +\r\n            'to register for a class series or event:\\n\\n' +\r\n            'Name: %s\\n' % record.fullName +\r\n            'Email: %s\\n' % email +\r\n            'Date/Time: %s\\n' % flagRecord.dateTime +\r\n            'IP Address: %s\\n\\n' % ip +\r\n            'This individual has been prevented from finalizing their registration, and they ' +\r\n            'have been asked to notify the school at %s with code %s to proceed.' % (respondTo, flagCode)\r\n        )\r\n\r\n        sendEmail(subject, message, send_from, to=[notify])\r\n\r\n    message = ugettext('There appears to be an issue with this registration. '\r\n                       'Please contact %s to proceed with the registration process. '\r\n                       'You may reference the error code %s.' % (respondTo, flagCode))\r\n\r\n    if request.user.has_perm('banlist.ignore_ban'):\r\n        messages.warning(request, message)\r\n\r\n    else:\r\n        raise ValidationError(message)", "response": "Check that this individual is on the ban list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean(self):\n        '''\n        Verify that the user and staffMember are not mismatched.\n        Location can only be specified if user and staffMember are not.\n        '''\n\n        if self.staffMember and self.staffMember.userAccount and \\\n        self.user and not self.staffMember.userAccount == self.user:\n            raise ValidationError(_('Transaction party user does not match staff member user.'))\n\n        if self.location and (self.user or self.staffMember):\n            raise ValidationError(_('Transaction party may not be both a Location and a User or StaffMember.'))", "response": "Verify that the user and staffMember are not mismatched."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the object to the database.", "response": "def save(self, updateBy=None, *args, **kwargs):\n        '''\n        Verify that the user and staffMember are populated with linked information, and\n        ensure that the name is properly specified.\n        '''\n\n        if (\n            self.staffMember and self.staffMember.userAccount and not self.user\n        ) or (\n            isinstance(updateBy,StaffMember) and self.staffMember.userAccount\n        ):\n            self.user = self.staffMember.userAccount\n        elif (\n            self.user and getattr(self.user,'staffmember',None) and not self.staffMember\n        ) or (\n            isinstance(updateBy,User) and getattr(self.user,'staffmember',None)\n        ):\n            self.staffMember = self.user.staffmember\n\n        # Don't replace the name if it has been given, but do fill it out if it is blank.\n        if not self.name:\n            if self.user and self.user.get_full_name():\n                self.name = self.user.get_full_name()\n            elif self.staffMember:\n                self.name = self.staffMember.fullName or self.staffMember.privateEmail\n            elif self.location:\n                self.name = self.location.name\n\n        super(TransactionParty, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef timeAtThreshold(self,dateTime):\n        '''\n        A convenience method for checking when a time is on the start/end boundary\n        for this rule.\n        '''\n\n        # Anything that's not at a day boundary is for sure not at a threshold.\n        if not (\n            dateTime.hour == self.dayStarts and dateTime.minute == 0 and\n            dateTime.second == 0 and dateTime.microsecond == 0\n        ):\n            return False\n\n        if self.applyRateRule == self.RateRuleChoices.daily:\n            return True\n        elif self.applyRateRule == self.RateRuleChoices.weekly:\n            return (dateTime == self.weekStarts)\n        elif self.applyRateRule == self.RateRuleChoices.monthly:\n            return (dateTime.day == self.monthStarts)\n\n        # Everything else is nonsensical, so False.\n        return False", "response": "Returns True if a time is at a threshold for this rule."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ruleName(self):\n        ''' This should be overridden for child classes '''\n        return '%s %s' % (self.rentalRate, self.RateRuleChoices.values.get(self.applyRateRule,self.applyRateRule))", "response": "This method returns the name of the rule that should be applied to therental rate."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string that can be used to identify the user.", "response": "def ruleName(self):\n        ''' overrides from parent class '''\n        return _('%s at %s' % (self.room.name, self.room.location.name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self):\n        ''' priorDays is required for Generic Repeated Expenses to avoid infinite loops '''\n        if not self.priorDays and not self.startDate:\n            raise ValidationError(_(\n                'Either a start date or an \"up to __ days in the past\" limit is required ' +\n                'for repeated expense rules that are not associated with a venue or a staff member.'\n            ))\n        super(GenericRepeatedExpense,self).clean()", "response": "Validate that the venue has not been associated with a venue or staff member."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relatedItems(self):\n        '''\n        If this item is associated with a registration, then return all other items associated with\n        the same registration.\n        '''\n        if self.registration:\n            return self.registration.revenueitem_set.exclude(pk=self.pk)", "response": "Returns all items related with this item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, *args, **kwargs):\n        '''\n        This custom save method ensures that a revenue item is not attributed to multiple categories.\n        It also ensures that the series and event properties are always associated with any\n        type of revenue of that series or event.\n        '''\n\n        # Set the received date if the payment was just marked received\n        if not hasattr(self,'__received'):\n            if self.received and not self.receivedDate:\n                self.receivedDate = timezone.now()\n        else:\n            if self.received and not self.receivedDate and not self.__receivedDate:\n                self.receivedDate = timezone.now()\n\n        # Set the accrual date.  The method for series/events ensures that the accrualDate month\n        # is the same as the reported month of the event/series by accruing to the start date of the first\n        # occurrence in that month.\n        if not self.accrualDate:\n            if self.invoiceItem and self.invoiceItem.finalEventRegistration:\n                min_event_time = self.invoiceItem.finalEventRegistration.event.eventoccurrence_set.filter(**{'startTime__month':self.invoiceItem.finalEventRegistration.event.month}).first().startTime\n                self.accrualDate = min_event_time\n            elif self.event:\n                self.accrualDate = self.event.eventoccurrence_set.order_by('startTime').filter(**{'startTime__month': self.event.month}).last().startTime\n            elif self.invoiceItem:\n                self.accrualDate = self.invoiceItem.invoice.creationDate\n            elif self.receivedDate:\n                self.accrualDate = self.receivedDate\n            elif self.submissionDate:\n                self.accrualDate = self.submissionDate\n            else:\n                self.submissionDate = timezone.now()\n                self.accrualDate = self.submissionDate\n\n        # Now, set the registration property and check that this item is not attributed\n        # to multiple categories.\n        if self.invoiceItem and self.invoiceItem.finalEventRegistration:\n            self.event = self.invoiceItem.finalEventRegistration.event\n        elif self.invoiceItem and self.invoiceItem.temporaryEventRegistration:\n            self.event = self.invoiceItem.temporaryEventRegistration.event\n\n        # If no grossTotal is reported, use the net total.  If no net total is reported, use the grossTotal\n        if self.grossTotal is None and self.total:\n            self.grossTotal = self.total\n        if self.total is None and self.grossTotal:\n            self.total = self.grossTotal\n\n        super(RevenueItem, self).save(*args, **kwargs)\n        self.__received = self.received\n        self.__receivedDate = self.receivedDate\n\n        # If a file is attached, ensure that it is not public, and that it is saved in the 'Expense Receipts' folder\n        if self.attachment:\n            try:\n                self.attachment.folder = Folder.objects.get(name=_('Revenue Receipts'))\n            except ObjectDoesNotExist:\n                pass\n            self.attachment.is_public = False\n            self.attachment.save()", "response": "This method is used to save the invoice item to the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean(self):\r\n        '''\r\n        Only allow submission if there are not already slots in the submitted window,\r\n        and only allow rooms associated with the chosen location.\r\n        '''\r\n\r\n        super(SlotCreationForm,self).clean()\r\n\r\n        startDate = self.cleaned_data.get('startDate')\r\n        endDate = self.cleaned_data.get('endDate')\r\n        startTime = self.cleaned_data.get('startTime')\r\n        endTime = self.cleaned_data.get('endTime')\r\n        instructor = self.cleaned_data.get('instructorId')\r\n\r\n        existingSlots = InstructorAvailabilitySlot.objects.filter(\r\n            instructor=instructor,\r\n            startTime__gt=(\r\n                ensure_localtime(datetime.combine(startDate,startTime)) -\r\n                timedelta(minutes=getConstant('privateLessons__lessonLengthInterval'))\r\n            ),\r\n            startTime__lt=ensure_localtime(datetime.combine(endDate,endTime)),\r\n        )\r\n\r\n        if existingSlots.exists():\r\n            raise ValidationError(_('Newly created slots cannot overlap existing slots for this instructor.'),code='invalid')", "response": "Only allow submission if there are not already slots in the submitted window and only allow rooms associated with the chosen location."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all available methods in the order of paymentMethod.", "response": "def get_method_list():\r\n    '''\r\n    Include manual methods by default\r\n    '''\r\n    methods = [str(_('Cash')),str(_('Check')),str(_('Bank/Debit Card')),str(_('Other'))]\r\n    methods += ExpenseItem.objects.order_by().values_list('paymentMethod',flat=True).distinct()\r\n    methods += RevenueItem.objects.order_by().values_list('paymentMethod',flat=True).distinct()\r\n    methods_list = list(set(methods))\r\n\r\n    if None in methods_list:\r\n        methods_list.remove(None)\r\n\r\n    return methods_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_create_option(self, context, q):\r\n        create_option = []\r\n        display_create_option = False\r\n        if self.create_field and q:\r\n            page_obj = context.get('page_obj', None)\r\n            if page_obj is None or page_obj.number == 1:\r\n                display_create_option = True\r\n\r\n        if display_create_option and self.has_add_permission(self.request):\r\n            '''\r\n            Generate querysets of Locations, StaffMembers, and Users that \r\n            match the query string.\r\n            '''\r\n            for s in Location.objects.filter(\r\n                Q(\r\n                    Q(name__istartswith=q) & Q(transactionparty__isnull=True)\r\n                )\r\n            ):\r\n                create_option += [{\r\n                    'id': 'Location_%s' % s.id,\r\n                    'text': _('Generate from location \"%(location)s\"') % {'location': s.name},\r\n                    'create_id': True,\r\n                }]\r\n\r\n            for s in StaffMember.objects.filter(\r\n                Q(\r\n                    (Q(firstName__istartswith=q) | Q(lastName__istartswith=q)) &\r\n                    Q(transactionparty__isnull=True)\r\n                )\r\n            ):\r\n                create_option += [{\r\n                    'id': 'StaffMember_%s' % s.id,\r\n                    'text': _('Generate from staff member \"%(staff_member)s\"') % {'staff_member': s.fullName},\r\n                    'create_id': True,\r\n                }]\r\n\r\n            for s in User.objects.filter(\r\n                Q(\r\n                    (Q(first_name__istartswith=q) | Q(last_name__istartswith=q)) &\r\n                    Q(staffmember__isnull=True) & Q(transactionparty__isnull=True)\r\n                )\r\n            ):\r\n                create_option += [{\r\n                    'id': 'User_%s' % s.id,\r\n                    'text': _('Generate from user \"%(user)s\"') % {'user': s.get_full_name()},\r\n                    'create_id': True,\r\n                }]\r\n\r\n            # Finally, allow creation from a name only.\r\n            create_option += [{\r\n                'id': q,\r\n                'text': _('Create \"%(new_value)s\"') % {'new_value': q},\r\n                'create_id': True,\r\n            }]\r\n        return create_option", "response": "Form the correct create_option to append to results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nallowing creation of transaction parties using a full name string.", "response": "def create_object(self, text):\r\n        ''' Allow creation of transaction parties using a full name string. '''\r\n\r\n        if self.create_field == 'name':\r\n            if text.startswith('Location_'):\r\n                this_id = text[len('Location_'):]\r\n                this_loc = Location.objects.get(id=this_id)\r\n                return self.get_queryset().get_or_create(\r\n                    name=this_loc.name,location=this_loc\r\n                )[0]\r\n            elif text.startswith('StaffMember_'):\r\n                this_id = text[len('StaffMember_'):]\r\n                this_member = StaffMember.objects.get(id=this_id)\r\n                return self.get_queryset().get_or_create(\r\n                    name=this_member.fullName,staffMember=this_member,\r\n                    defaults={'user': getattr(this_member,'userAccount',None)}\r\n                )[0]\r\n            elif text.startswith('User_'):\r\n                this_id = text[len('User_'):]\r\n                this_user = User.objects.get(id=this_id)\r\n                return self.get_queryset().get_or_create(\r\n                    name=this_user.get_full_name(),user=this_user,\r\n                    defaults={'staffMember': getattr(this_user,'staffmember',None)}\r\n                )[0]\r\n            else:\r\n                return self.get_queryset().get_or_create(\r\n                    name=text,staffMember=None,user=None,location=None\r\n                )[0]\r\n        else:\r\n            return super(TransactionPartyAutoComplete,self).create_object(text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the given user has the given group.", "response": "def has_group(user, group_name):\r\n    '''\r\n    This allows specification group-based permissions in templates.\r\n    In most instances, creating model-based permissions and giving\r\n    them to the desired group is preferable.\r\n    '''\r\n    if user.groups.filter(name=group_name).exists():\r\n        return True\r\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item_by_key(passed_list, key, value):\r\n    '''\r\n    This one allows us to get one or more items from a list of\r\n    dictionaries based on the value of a specified key, where\r\n    both the key and the value can be variable names.  Does\r\n    not work with None or null string passed values.\r\n    '''\r\n\r\n    if value in [None, '']:\r\n        return\r\n\r\n    if type(passed_list) in [QuerySet, PolymorphicQuerySet]:\r\n        sub_list = passed_list.filter(**{key: value})\r\n    else:\r\n        sub_list = [x for x in passed_list if x.get(key) == value]\r\n\r\n    if len(sub_list) == 1:\r\n        return sub_list[0]\r\n    return sub_list", "response": "This function allows us to get one or more items from a list of\r\n    dictionaries based on the value of a specified key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef template_exists(template_name):\r\n    '''\r\n    Determine if a given template exists so that it can be loaded\r\n    if so, or a default alternative can be used if not.\r\n    '''\r\n    try:\r\n        template.loader.get_template(template_name)\r\n        return True\r\n    except template.TemplateDoesNotExist:\r\n        return False", "response": "Determines if a given template exists so that it can be loaded\r\n    can be used if not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of registrations for the given role.", "response": "def numRegisteredForRole(event, role):\r\n    '''\r\n    This tag allows one to access the number of registrations\r\n    for any dance role.\r\n    '''\r\n    if not isinstance(event, Event) or not isinstance(role, DanceRole):\r\n        return None\r\n    return event.numRegisteredForRole(role)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the event is sold out for the given role.", "response": "def soldOutForRole(event, role):\r\n    '''\r\n    This tag allows one to determine whether any event is sold out for any\r\n    particular role.\r\n    '''\r\n    if not isinstance(event, Event) or not isinstance(role, DanceRole):\r\n        return None\r\n    return event.soldOutForRole(role)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of registrations for a given role name.", "response": "def numRegisteredForRoleName(event, roleName):\r\n    '''\r\n    This tag allows one to access the number of registrations\r\n    for any dance role using only the role's name.\r\n    '''\r\n    if not isinstance(event, Event):\r\n        return None\r\n\r\n    try:\r\n        role = DanceRole.objects.get(name=roleName)\r\n    except ObjectDoesNotExist:\r\n        return None\r\n\r\n    return event.numRegisteredForRole(role)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new tag that returns the URL of the current page and title of the current page.", "response": "def getReturnPage(context, prior=False):\r\n    '''\r\n    This tag makes it easy to get return links from within a template without\r\n    requiring custom logic inside the view.  Just include\r\n    {% getReturnPage as returnPage %} and then reference {{ returnPage.url }}\r\n    and {{ returnPage.title }} as needed.\r\n    '''\r\n    siteHistory = getattr(context.get('request',None),'session',{}).get('SITE_HISTORY',{})\r\n    return returnPageHelper(siteHistory,prior=prior)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new Voucher with a unique voucherId", "response": "def create_new_code(cls,**kwargs):\n        '''\n        Creates a new Voucher with a unique voucherId\n        '''\n        prefix = kwargs.pop('prefix','')\n\n        new = False\n        while not new:\n            # Standard is a ten-letter random string of uppercase letters\n            random_string = ''.join(random.choice(string.ascii_uppercase) for z in range(10))\n            if not Voucher.objects.filter(voucherId='%s%s' % (prefix, random_string)).exists():\n                new = True\n\n        return Voucher.objects.create(voucherId='%s%s' % (prefix, random_string),**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render(self, context, instance, placeholder):\n        ''' Add the cart-specific context to this form '''\n        context = super(PayAtDoorFormPlugin, self).render(context, instance, placeholder)\n\n        context.update({\n            'business_name': getConstant('contact__businessName'),\n            'currencyCode': getConstant('general__currencyCode'),\n            'form': self.get_form(context, instance, placeholder),\n        })\n\n        return context", "response": "Add the cart - specific context to this form"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the TransactionParty object with the new information.", "response": "def updateTransactionParty(sender,instance,**kwargs):\r\n    '''\r\n    If a User, StaffMember, or Location is updated, and there exists an associated\r\n    TransactionParty, then the name and other attributes of that party should be updated\r\n    to reflect the new information.\r\n    '''\r\n\r\n    if 'loaddata' in sys.argv or ('raw' in kwargs and kwargs['raw']):\r\n        return\r\n\r\n    logger.debug('TransactionParty signal fired for %s %s.' % (instance.__class__.__name__, instance.id))\r\n\r\n    party = getattr(instance,'transactionparty',None)\r\n    if party:\r\n        party.save(updateBy=instance)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the fees of the Square Checkout API.", "response": "def updateSquareFees(paymentRecord):\r\n    '''\r\n    The Square Checkout API does not calculate fees immediately, so this task is\r\n    called to be asynchronously run 1 minute after the initial transaction, so that\r\n    any Invoice or ExpenseItem associated with this transaction also remains accurate.\r\n    '''\r\n\r\n    fees = paymentRecord.netFees\r\n    invoice = paymentRecord.invoice\r\n    invoice.fees = fees\r\n    invoice.save()\r\n    invoice.allocateFees()\r\n    return fees"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getClassTypeMonthlyData(year=None, series=None, typeLimit=None):\n    '''\n    To break out by class type and month simultaneously, get data for each\n    series and aggregate by class type.\n    '''\n\n    # If no year specified, report current year to date.\n    if not year:\n        year = timezone.now().year\n\n    role_list = DanceRole.objects.distinct()\n\n    # Report data on all students registered unless otherwise specified\n    if series not in ['registrations','studenthours'] and series not in [x.pluralName for x in role_list]:\n        series = 'registrations'\n\n    when_all = {\n        'eventregistration__dropIn': False,\n        'eventregistration__cancelled': False,\n    }\n\n    annotations = {'registrations': Sum(Case(When(Q(**when_all),then=1),output_field=FloatField()))}\n\n    for this_role in role_list:\n        annotations[this_role.pluralName] = Sum(Case(When(Q(Q(**when_all) & Q(eventregistration__role=this_role)),then=1),output_field=FloatField()))\n\n    series_counts = Series.objects.filter(year=year).annotate(**annotations).annotate(studenthours=F('duration') * F('registrations')).select_related('classDescription__danceTypeLevel__danceType','classDescription__danceTypeLevel')\n\n    # If no limit specified on number of types, then do not aggregate dance types.\n    # Otherwise, report the typeLimit most common types individually, and report all\n    # others as other.  This gets tuples of names and counts\n    dance_type_counts = [(dance_type,count) for dance_type,count in Counter([x.classDescription.danceTypeLevel for x in series_counts]).items()]\n    dance_type_counts.sort(key=lambda k: k[1],reverse=True)\n\n    if typeLimit:\n        dance_types = [x[0] for x in dance_type_counts[:typeLimit]]\n    else:\n        dance_types = [x[0] for x in dance_type_counts]\n\n    results = []\n\n    # Month by month, calculate the result data\n    for month in range(1,13):\n        this_month_result = {\n            'month': month,\n            'month_name': month_name[month],\n        }\n        for dance_type in dance_types:\n            this_month_result[dance_type.__str__()] = \\\n                series_counts.filter(classDescription__danceTypeLevel=dance_type,month=month).aggregate(Sum(series))['%s__sum' % series]\n\n        if typeLimit:\n            this_month_result['Other'] = \\\n                series_counts.filter(month=month).exclude(classDescription__danceTypeLevel__in=dance_types).aggregate(Sum(series))['%s__sum' % series]\n\n        results.append(this_month_result)\n\n    # Now get totals\n    totals_result = {\n        'month': 'Totals',\n        'month_name': 'totals',\n    }\n\n    for dance_type in dance_types:\n        totals_result[dance_type.__str__()] = \\\n            series_counts.filter(classDescription__danceTypeLevel=dance_type).aggregate(Sum(series))['%s__sum' % series]\n\n    if typeLimit:\n        totals_result['Other'] = \\\n            series_counts.exclude(classDescription__danceTypeLevel__in=dance_types).aggregate(Sum(series))['%s__sum' % series]\n\n    results.append(totals_result)\n\n    return results", "response": "Get data for each class type and month simultaneously and aggregate by class type and month."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates slots and return success message.", "response": "def form_valid(self, form):\n        '''\n        Create slots and return success message.\n        '''\n        startDate = form.cleaned_data['startDate']\n        endDate = form.cleaned_data['endDate']\n        startTime = form.cleaned_data['startTime']\n        endTime = form.cleaned_data['endTime']\n        instructor = form.cleaned_data['instructorId']\n\n        interval_minutes = getConstant('privateLessons__lessonLengthInterval')\n\n        this_date = startDate\n        while this_date <= endDate:\n            this_time = startTime\n            while this_time < endTime:\n                InstructorAvailabilitySlot.objects.create(\n                    instructor=instructor,\n                    startTime=ensure_localtime(datetime.combine(this_date, this_time)),\n                    duration=interval_minutes,\n                    location=form.cleaned_data.get('location'),\n                    room=form.cleaned_data.get('room'),\n                    pricingTier=form.cleaned_data.get('pricingTier'),\n                )\n                this_time = (ensure_localtime(datetime.combine(this_date, this_time)) + timedelta(minutes=interval_minutes)).time()\n            this_date += timedelta(days=1)\n\n        return JsonResponse({'valid': True})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef form_valid(self, form):\n        '''\n        Modify or delete the availability slot as requested and return success message.\n        '''\n        slotIds = form.cleaned_data['slotIds']\n        deleteSlot = form.cleaned_data.get('deleteSlot', False)\n\n        these_slots = InstructorAvailabilitySlot.objects.filter(id__in=slotIds)\n\n        if deleteSlot:\n            these_slots.delete()\n        else:\n            for this_slot in these_slots:\n                this_slot.location = form.cleaned_data['updateLocation']\n                this_slot.room = form.cleaned_data['updateRoom']\n                this_slot.status = form.cleaned_data['updateStatus']\n                this_slot.pricingTier = form.cleaned_data.get('updatePricing')\n                this_slot.save()\n\n        return JsonResponse({'valid': True})", "response": "Modify or delete the availability slot as requested and return success message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_form_kwargs(self, **kwargs):\n        '''\n        Pass the current user to the form to render the payAtDoor field if applicable.\n        '''\n        kwargs = super(BookPrivateLessonView, self).get_form_kwargs(**kwargs)\n        kwargs['user'] = self.request.user if hasattr(self.request,'user') else None\n        return kwargs", "response": "Pass the current user to the form to render the payAtDoor field."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dispatch(self,request,*args,**kwargs):\n        '''\n        Handle the session data passed by the prior view.\n        '''\n\n        lessonSession = request.session.get(PRIVATELESSON_VALIDATION_STR,{})\n\n        try:\n            self.lesson = PrivateLessonEvent.objects.get(id=lessonSession.get('lesson'))\n        except (ValueError, ObjectDoesNotExist):\n            messages.error(request,_('Invalid lesson identifier passed to sign-up form.'))\n            return HttpResponseRedirect(reverse('bookPrivateLesson'))\n\n        expiry = parse_datetime(lessonSession.get('expiry',''),)\n        if not expiry or expiry < timezone.now():\n            messages.info(request,_('Your registration session has expired. Please try again.'))\n            return HttpResponseRedirect(reverse('bookPrivateLesson'))\n\n        self.payAtDoor = lessonSession.get('payAtDoor',False)\n        return super(PrivateLessonStudentInfoView,self).dispatch(request,*args,**kwargs)", "response": "Handle the session data passed by the prior view."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npassing along the request data to the form", "response": "def get_form_kwargs(self, **kwargs):\n        ''' Pass along the request data to the form '''\n        kwargs = super(PrivateLessonStudentInfoView, self).get_form_kwargs(**kwargs)\n        kwargs['request'] = self.request\n        kwargs['payAtDoor'] = self.payAtDoor\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_object(self, queryset=None):\r\n        ''' Get the guest list from the URL '''\r\n        return get_object_or_404(\r\n            GuestList.objects.filter(id=self.kwargs.get('guestlist_id')))", "response": "Get the guest list from the URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds the list of names for the given guest list.", "response": "def get_context_data(self,**kwargs):\r\n        ''' Add the list of names for the given guest list '''\r\n        event = Event.objects.filter(id=self.kwargs.get('event_id')).first()\r\n        if self.kwargs.get('event_id') and not self.object.appliesToEvent(event):\r\n            raise Http404(_('Invalid event.'))\r\n\r\n        # Use the most current event if nothing has been specified.\r\n        if not event:\r\n            event = self.object.currentEvent\r\n\r\n        context = {\r\n            'guestList': self.object,\r\n            'event': event,\r\n            'names': self.object.getListForEvent(event),\r\n        }\r\n        context.update(kwargs)\r\n        return super(GuestListView,self).get_context_data(**context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef customers(self):\n        '''\n        List both any individuals signed up via the registration and payment system,\n        and any individuals signed up without payment.\n        '''\n        return Customer.objects.filter(\n            Q(privatelessoncustomer__lesson=self) |\n            Q(registration__eventregistration__event=self)\n        ).distinct()", "response": "Return a list of all customers that are signed up via the registration and payment system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, *args, **kwargs):\n        ''' Set registration status to hidden if it is not specified otherwise '''\n        if not self.status:\n            self.status == Event.RegStatus.hidden\n        super(PrivateLessonEvent,self).save(*args,**kwargs)", "response": "Set registration status to hidden if it is not specified otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef availableRoles(self):\n        '''\n        Some instructors only offer private lessons for certain roles, so we should only allow booking\n        for the roles that have been selected for the instructor.\n        '''\n        if not hasattr(self.instructor,'instructorprivatelessondetails'):\n            return []\n        return [\n            [x.id,x.name] for x in\n            self.instructor.instructorprivatelessondetails.roles.all()\n        ]", "response": "Returns a list of all available roles for the instructor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef checkIfAvailable(self, dateTime=timezone.now()):\n        '''\n        Available slots are available, but also tentative slots that have been held as tentative\n        past their expiration date\n        '''\n        return (\n            self.startTime >= dateTime + timedelta(days=getConstant('privateLessons__closeBookingDays')) and\n            self.startTime <= dateTime + timedelta(days=getConstant('privateLessons__openBookingDays')) and not\n            self.eventRegistration and (\n                self.status == self.SlotStatus.available or (\n                    self.status == self.SlotStatus.tentative and\n                    getattr(getattr(self.temporaryEventRegistration,'registration',None),'expirationDate',timezone.now()) <= timezone.now()\n                )\n            )\n        )", "response": "Check if this slot is available but also tentative and not yet held as tentative\n        past their expiration date."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallows this plugin to use templates designed for a list of locations.", "response": "def render(self, context, instance, placeholder):\r\n        ''' Allows this plugin to use templates designed for a list of locations. '''\r\n        context = super(StatsGraphPlugin,self).render(context,instance,placeholder)\r\n\r\n        # Javascript makes it difficult to calculate date/time differences, so instead\r\n        # pass the most useful ones to the template context in a dictionary.  These are used\r\n        # to show stats over different time ranges.\r\n        limitMonthDates = {}\r\n        for m in range(0,25):\r\n            limitMonthDates[m] = (timezone.now() - relativedelta(months=m)).strftime('%Y-%m-%d')\r\n\r\n        # The same for graphs that allow one to choose different years.\r\n        recentYears = [timezone.now().year + x for x in range(-5,1)]\r\n\r\n        series_by_year = Series.objects.order_by('year')\r\n\r\n        if series_by_year.count() > 0:\r\n            first_year = series_by_year.first().year\r\n            allYears = [x for x in range(first_year,timezone.now().year + 1)]\r\n        else:\r\n            allYears = []\r\n\r\n        context.update({\r\n            'limitMonthDates': limitMonthDates,\r\n            'recentYears': recentYears,\r\n            'allYears': allYears,\r\n        })\r\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a JSON news feed for the current user.", "response": "def json_event_feed(request,location_id=None,room_id=None):\r\n    '''\r\n    The Jquery fullcalendar app requires a JSON news feed, so this function\r\n    creates the feed from upcoming PrivateEvent objects\r\n    '''\r\n\r\n    if not getConstant('calendar__privateCalendarFeedEnabled') or not request.user.is_staff:\r\n        return JsonResponse({})\r\n    this_user = request.user\r\n\r\n    startDate = request.GET.get('start','')\r\n    endDate = request.GET.get('end','')\r\n    timeZone = request.GET.get('timezone',getattr(settings,'TIME_ZONE','UTC'))\r\n\r\n    time_filter_dict_events = {}\r\n    if startDate:\r\n        time_filter_dict_events['startTime__gte'] = ensure_timezone(datetime.strptime(startDate,'%Y-%m-%d'))\r\n    if endDate:\r\n        time_filter_dict_events['endTime__lte'] = ensure_timezone(datetime.strptime(endDate,'%Y-%m-%d')) + timedelta(days=1)\r\n\r\n    instructor_groups = list(this_user.groups.all().values_list('id',flat=True))\r\n\r\n    filters = Q(event__privateevent__isnull=False) & (\r\n        Q(event__privateevent__displayToGroup__in=instructor_groups) |\r\n        Q(event__privateevent__displayToUsers=this_user) |\r\n        (Q(event__privateevent__displayToGroup__isnull=True) & Q(event__privateevent__displayToUsers__isnull=True))\r\n    )\r\n\r\n    if location_id:\r\n        filters = filters & Q(event__location__id=location_id)\r\n    if room_id:\r\n        filters = filters & Q(event__room_id=room_id)\r\n\r\n    occurrences = EventOccurrence.objects.filter(filters).filter(**time_filter_dict_events).order_by('-startTime')\r\n\r\n    eventlist = [EventFeedItem(x,timeZone=timeZone).__dict__ for x in occurrences]\r\n\r\n    return JsonResponse(eventlist,safe=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nallowing this plugin to use templates designed for a list of locations.", "response": "def render(self, context, instance, placeholder):\r\n        ''' Allows this plugin to use templates designed for a list of locations. '''\r\n        context = super(LocationListPlugin,self).render(context,instance,placeholder)\r\n        context['location_list'] = Location.objects.filter(status=Location.StatusChoices.active)\r\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, context, instance, placeholder):\r\n        ''' Allows this plugin to use templates designed for a list of locations. '''\r\n        context = super(LocationPlugin,self).render(context,instance,placeholder)\r\n        context['location_list'] = [instance.location,]\r\n        return context", "response": "Allows this plugin to use templates designed for a list of locations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkRequirements(sender,**kwargs):\r\n    '''\r\n    Check that the customer meets all prerequisites for the items in the registration.\r\n    '''\r\n\r\n    if not getConstant('requirements__enableRequirements'):\r\n        return\r\n\r\n    logger.debug('Signal to check RegistrationContactForm handled by prerequisites app.')\r\n\r\n    formData = kwargs.get('formData',{})\r\n    first = formData.get('firstName')\r\n    last = formData.get('lastName')\r\n    email = formData.get('email')\r\n\r\n    request = kwargs.get('request',{})\r\n    registration = kwargs.get('registration',None)\r\n\r\n    customer = Customer.objects.filter(\r\n        first_name=first,\r\n        last_name=last,\r\n        email=email).first()\r\n\r\n    requirement_warnings = []\r\n    requirement_errors = []\r\n\r\n    for ter in registration.temporaryeventregistration_set.all():\r\n        if hasattr(ter.event,'getRequirements'):\r\n            for req in ter.event.getRequirements():\r\n                if not req.customerMeetsRequirement(\r\n                    customer=customer,\r\n                    danceRole=ter.role\r\n                ):\r\n                    if req.enforcementMethod == Requirement.EnforcementChoice.error:\r\n                        requirement_errors.append((ter.event.name, req.name))\r\n                    if req.enforcementMethod == Requirement.EnforcementChoice.warning:\r\n                        requirement_warnings.append((ter.event.name,req.name))\r\n\r\n    if requirement_errors:\r\n        raise ValidationError(format_html(\r\n            '<p>{}</p> <ul>{}</ul> <p>{}</p>',\r\n            ugettext('Unfortunately, you do not meet the following requirements/prerequisites for the items you have chosen:\\n'),\r\n            mark_safe(''.join(['<li><em>%s:</em> %s</li>\\n' % x for x in requirement_errors])),\r\n            getConstant('requirements__errorMessage') or '',\r\n        ))\r\n\r\n    if requirement_warnings:\r\n        messages.warning(request,format_html(\r\n            '<p>{}</p> <ul>{}</ul> <p>{}</p>',\r\n            mark_safe(ugettext('<strong>Please Note:</strong> It appears that you do not meet the following requirements/prerequisites for the items you have chosen:\\n')),\r\n            mark_safe(''.join(['<li><em>%s:</em> %s</li>\\n' % x for x in requirement_warnings])),\r\n            getConstant('requirements__warningMessage') or '',\r\n        ))", "response": "Check that the customer meets all prerequisites for the items in the registration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef email_recipient(self, subject, content, **kwargs):\r\n        '''\r\n        This method allows for direct emailing of an object's recipient(s)\r\n        (default or manually specified), with both object-specific context\r\n        provided using the get_email_context() method.  This is used, for example,\r\n        to email an individual registrant or the recipient of an individual invoice.\r\n        '''\r\n\r\n        email_kwargs = {}\r\n\r\n        for list_arg in [\r\n            'to','cc','bcc',\r\n        ]:\r\n            email_kwargs[list_arg] = kwargs.pop(list_arg,[]) or []\r\n            if isinstance(email_kwargs[list_arg],string_types):\r\n                email_kwargs[list_arg] = [email_kwargs[list_arg],]\r\n\r\n        for none_arg in ['attachment_name','attachment']:\r\n            email_kwargs[none_arg] = kwargs.pop(none_arg,None) or None\r\n\r\n        # Ignore any passed HTML content unless explicitly told to send as HTML\r\n        if kwargs.pop('send_html',False) and kwargs.get('html_message'):\r\n            email_kwargs['html_content'] = render_to_string(\r\n                'email/html_email_base.html',\r\n                context={'html_content': kwargs.get('html_message'),'subject': subject}\r\n            )\r\n\r\n        email_kwargs['from_name'] = kwargs.pop('from_name',getConstant('email__defaultEmailName')) or \\\r\n            getConstant('email__defaultEmailName')\r\n        email_kwargs['from_address'] = kwargs.pop('from_name',getConstant('email__defaultEmailFrom')) or \\\r\n            getConstant('email__defaultEmailFrom')\r\n\r\n        # Add the object's default recipients if they are provided\r\n        default_recipients = self.get_default_recipients() or []\r\n        if isinstance(default_recipients,string_types):\r\n            default_recipients = [default_recipients,]\r\n\r\n        email_kwargs['bcc'] += default_recipients\r\n\r\n        if not (email_kwargs['bcc'] or email_kwargs['cc'] or email_kwargs['to']):\r\n            raise ValueError(_('Email must have a recipient.'))\r\n\r\n        # In situations where there are no context\r\n        # variables to be rendered, send a mass email\r\n        has_tags = re.search('\\{\\{.+\\}\\}',content)\r\n        if not has_tags:\r\n            t = Template(content)\r\n            rendered_content = t.render(Context(kwargs))\r\n            sendEmail(subject,rendered_content,**email_kwargs)\r\n            return\r\n\r\n        # Otherwise, get the object-specific email context and email\r\n        # each recipient\r\n        template_context = self.get_email_context() or {}\r\n        template_context.update(kwargs)\r\n\r\n        # For security reasons, the following tags are removed from the template before parsing:\r\n        # {% extends %}{% load %}{% debug %}{% include %}{% ssi %}\r\n        content = re.sub(\r\n            '\\{%\\s*((extends)|(load)|(debug)|(include)|(ssi))\\s+.*?\\s*%\\}',\r\n            '',\r\n            content\r\n        )\r\n        t = Template(content)\r\n        rendered_content = t.render(Context(template_context))\r\n\r\n        if email_kwargs.get('html_content'):\r\n            html_content = re.sub(\r\n                '\\{%\\s*((extends)|(load)|(debug)|(include)|(ssi))\\s+.*?\\s*%\\}',\r\n                '',\r\n                email_kwargs.get('html_content')\r\n            )\r\n            t = Template(html_content)\r\n            email_kwargs['html_content'] = t.render(Context(template_context))\r\n\r\n        sendEmail(subject,rendered_content,**email_kwargs)", "response": "This method allows for direct emailing of an object s recipient with the specified subject and content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_email_context(self,**kwargs):\r\n        '''\r\n        This method can be overridden in classes that inherit from this mixin\r\n        so that additional object-specific context is provided to the email\r\n        template.  This should return a dictionary.  By default, only general\r\n        financial context variables are added to the dictionary, and kwargs are\r\n        just passed directly.\r\n\r\n        Note also that it is in general not a good idea for security reasons\r\n        to pass model instances in the context here, since these methods can be\r\n        accessed by logged in users who use the SendEmailView.  So, In the default\r\n        models of this app, the values of fields and properties are passed\r\n        directly instead.\r\n        '''\r\n        context = kwargs\r\n        context.update({\r\n            'currencyCode': getConstant('general__currencyCode'),\r\n            'currencySymbol': getConstant('general__currencySymbol'),\r\n            'businessName': getConstant('contact__businessName'),\r\n            'site_url': getConstant('email__linkProtocol') + '://' + Site.objects.get_current().domain,\r\n        })\r\n        return context", "response": "Returns a dictionary that contains the additional context variables for the object instance with the same name as the given kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_group_required(self):\r\n        ''' Get the group_required value from the object '''\r\n        this_object = self.model_object\r\n        if hasattr(this_object,self.group_required_field):\r\n            if hasattr(getattr(this_object,self.group_required_field),'name'):\r\n                return [getattr(this_object,self.group_required_field).name]\r\n        return ['']", "response": "Get the group_required value from the object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallowing for objects with no required groups", "response": "def check_membership(self, groups):\r\n        ''' Allows for objects with no required groups '''\r\n        if not groups or groups == ['']:\r\n            return True\r\n        if self.request.user.is_superuser:\r\n            return True\r\n        user_groups = self.request.user.groups.values_list(\"name\", flat=True)\r\n        return set(groups).intersection(set(user_groups))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dispatch(self, request, *args, **kwargs):\r\n        '''\r\n        This override of dispatch ensures that if no group is required, then\r\n        the request still goes through without being logged in.\r\n        '''\r\n        self.request = request\r\n        in_group = False\r\n        required_group = self.get_group_required()\r\n        if not required_group or required_group == ['']:\r\n            in_group = True\r\n        elif self.request.user.is_authenticated():\r\n            in_group = self.check_membership(required_group)\r\n\r\n        if not in_group:\r\n            if self.raise_exception:\r\n                raise PermissionDenied\r\n            else:\r\n                return redirect_to_login(\r\n                    request.get_full_path(),\r\n                    self.get_login_url(),\r\n                    self.get_redirect_field_name())\r\n        return super(GroupRequiredMixin, self).dispatch(\r\n            request, *args, **kwargs)", "response": "Override dispatch to ensure that the group is required and that the user is logged in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self,value):\r\n        '''\r\n        Check for empty values, and for an existing template, but do not check if\r\n        this is one of the initial choices provided.\r\n        '''\r\n        super(ChoiceField,self).validate(value)\r\n\r\n        try:\r\n            get_template(value)\r\n        except TemplateDoesNotExist:\r\n            raise ValidationError(_('%s is not a valid template.' % value))", "response": "Check for empty values and for an existing template but do not check for an existing template."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npermit setting of the template in the plugin instance configuration", "response": "def render(self, context, instance, placeholder):\r\n        ''' Permits setting of the template in the plugin instance configuration '''\r\n        if instance and instance.template:\r\n            self.render_template = instance.template\r\n        return super(PluginTemplateMixin,self).render(context,instance,placeholder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list of annotations for the current object.", "response": "def get_annotations(self):\r\n        '''\r\n        This method gets the annotations for the queryset.  Unlike get_ordering() below, it\r\n        passes the actual Case() and F() objects that will be evaluated with the queryset, returned\r\n        in a dictionary that is compatible with get_ordering().\r\n        '''\r\n        rule = getConstant('registration__orgRule')\r\n\r\n        # Initialize with null values that get filled in based on the logic below.\r\n        annotations = {\r\n            'nullParam': Case(default_value=None,output_field=IntegerField()),\r\n            'paramOne': Case(default_value=None,output_field=IntegerField()),\r\n            'paramTwo': Case(default_value=None,output_field=IntegerField()),\r\n        }\r\n\r\n        if rule == 'SessionFirst':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(session__startTime__isnull=False, then=0),\r\n                    When(month__isnull=False, then=1),\r\n                    default_value=2,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': F('session__startTime'),\r\n                'paramTwo': ExpressionWrapper(12 * F('year') + F('month'), output_field=IntegerField()),\r\n            })\r\n        elif rule == 'SessionAlphaFirst':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(session__name__isnull=False, then=0),\r\n                    When(month__isnull=False, then=1),\r\n                    default_value=2,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': F('session__name'),\r\n                'paramTwo': ExpressionWrapper(12 * F('year') + F('month'), output_field=IntegerField()),\r\n            })\r\n        elif rule == 'Month':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(month__isnull=False, then=0),\r\n                    default_value=1,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': ExpressionWrapper(12*F('year') + F('month'), output_field=IntegerField()),\r\n            })\r\n        elif rule == 'Session':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(session__startTime__isnull=False, then=0),\r\n                    default_value=1,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': F('session__startTime'),\r\n            })\r\n        elif rule == 'SessionAlpha':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(session__name__isnull=False, then=0),\r\n                    default_value=1,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': F('session__name'),\r\n            })\r\n        elif rule == 'SessionMonth':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(Q(session__startTime__isnull=False) & Q(month__isnull=False), then=0),\r\n                    When(Q(session__startTime__isnull=True) & Q(month__isnull=False), then=1),\r\n                    When(Q(session__startTime__isnull=False) & Q(month__isnull=True), then=2),\r\n                    default_value=3,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': ExpressionWrapper(12 * F('year') + F('month'), output_field=IntegerField()),\r\n                'paramTwo': F('session__startTime'),\r\n            })\r\n        elif rule == 'SessionAlphaMonth':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(Q(session__name__isnull=False) & Q(month__isnull=False), then=0),\r\n                    When(Q(session__name__isnull=True) & Q(month__isnull=False), then=1),\r\n                    When(Q(session__name__isnull=False) & Q(month__isnull=True), then=2),\r\n                    default_value=3,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': ExpressionWrapper(12*F('year') + F('month'), output_field=IntegerField()),\r\n                'paramTwo': F('session__name'),\r\n            })\r\n        elif rule == 'Weekday':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(startTime__week_day__isnull=False, then=0),\r\n                    default_value=1,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': ExtractWeekDay('startTime'),\r\n            })\r\n        elif rule == 'MonthWeekday':\r\n            annotations.update({\r\n                'nullParam': Case(\r\n                    When(Q(month__isnull=False) & Q(startTime__week_day__isnull=False), then=0),\r\n                    default_value=1,\r\n                    output_field=IntegerField()\r\n                ),\r\n                'paramOne': ExpressionWrapper(12*F('year') + F('month'), output_field=IntegerField()),\r\n                'paramTwo': ExtractWeekDay('startTime'),\r\n            })\r\n\r\n        return annotations"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ordering(self, reverseTime=False):\r\n        '''\r\n        This method provides the tuple for ordering of querysets.  However, this will only\r\n        work if the annotations generated by the get_annotations() method above have been\r\n        added to the queryset.  Otherwise, the use of this ordering tuple will fail because\r\n        the appropriate column names will not exist to sort with.\r\n        '''\r\n\r\n        # Reverse ordering can be optionally specified in the view class definition.\r\n        reverseTime = getattr(self,'reverse_time_ordering',reverseTime)\r\n        timeParameter = '-startTime' if reverseTime is True else 'startTime'\r\n        return ('nullParam', 'paramOne', 'paramTwo', timeParameter)", "response": "Returns a tuple that can be used to sort the querysets in the view class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_return_page(self,prior=False):\r\n        ''' This is just a wrapper for the getReturnPage helper function. '''\r\n        siteHistory = self.request.session.get('SITE_HISTORY',{})\r\n        return getReturnPage(siteHistory,prior=prior)", "response": "This is just a wrapper for the getReturnPage helper function. It is just a wrapper for the getReturnPage helper function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the current form is valid.", "response": "def is_valid(self):\n        '''\n        For this form to be considered valid, there must be not only no errors, but also no messages on\n        the request that need to be shown.\n        '''\n\n        valid = super(RegistrationContactForm,self).is_valid()\n        msgs = messages.get_messages(self._request)\n\n        # We only want validation messages to show up once, so pop messages that have already show up\n        # before checking to see if any messages remain to be shown.\n        prior_messages = self._session.pop('prior_messages',[])\n        remaining_messages = []\n\n        for m in msgs:\n            m_dict = {'message': m.message, 'level': m.level, 'extra_tags': m.extra_tags}\n            if m_dict not in prior_messages:\n                remaining_messages.append(m_dict)\n\n        if remaining_messages:\n            self._session['prior_messages'] = remaining_messages\n            self._request.session.modified = True\n            return False\n        return valid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate that the total amount of refunds is correct.", "response": "def clean_total_refund_amount(self):\n        '''\n        The Javascript should ensure that the hidden input is updated, but double check it here.\n        '''\n        initial = self.cleaned_data.get('initial_refund_amount', 0)\n        total = self.cleaned_data['total_refund_amount']\n        summed_refunds = sum([v for k,v in self.cleaned_data.items() if k.startswith('item_refundamount_')])\n\n        if not self.cleaned_data.get('id'):\n            raise ValidationError('ID not in cleaned data')\n\n        if summed_refunds != total:\n            raise ValidationError(_('Passed value does not match sum of allocated refunds.'))\n        elif summed_refunds > self.cleaned_data['id'].amountPaid + self.cleaned_data['id'].refunds:\n            raise ValidationError(_('Total refunds allocated exceed revenue received.'))\n        elif total < initial:\n            raise ValidationError(_('Cannot reduce the total amount of the refund.'))\n        return total"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that a given list of possible PK values is valid and returns a QuerySet of the EventOccurrence objects. Raises a ValidationError if a given value is invalid.", "response": "def _check_values(self, value):\n        \"\"\"\n        Given a list of possible PK values, returns a QuerySet of the\n        corresponding objects. Raises a ValidationError if a given value is\n        invalid (not a valid PK, not in the queryset, etc.)\n        \"\"\"\n        key = self.to_field_name or 'pk'\n        # deduplicate given values to avoid creating many querysets or\n        # requiring the database backend deduplicate efficiently.\n        try:\n            value = frozenset(value)\n        except TypeError:\n            # list of lists isn't hashable, for example\n            raise ValidationError(\n                self.error_messages['list'],\n                code='list',\n            )\n        for pk in value:\n            try:\n                self.queryset.filter(**{key: pk})\n            except (ValueError, TypeError):\n                raise ValidationError(\n                    self.error_messages['invalid_pk_value'],\n                    code='invalid_pk_value',\n                    params={'pk': pk},\n                )\n        qs = EventOccurrence.objects.filter(**{'%s__in' % key: value})\n        pks = set(force_text(getattr(o, key)) for o in qs)\n        for val in value:\n            if force_text(val) not in pks:\n                raise ValidationError(\n                    self.error_messages['invalid_choice'],\n                    code='invalid_choice',\n                    params={'value': val},\n                )\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, commit=True):\n        '''\n        If a staff member is reporting substitute teaching for a second time, then we should update\n        the list of occurrences for which they are a substitute on their existing EventStaffMember\n        record, rather than creating a new record and creating database issues.\n        '''\n        existing_record = EventStaffMember.objects.filter(\n            staffMember=self.cleaned_data.get('staffMember'),\n            event=self.cleaned_data.get('event'),\n            category=getConstant('general__eventStaffCategorySubstitute'),\n            replacedStaffMember=self.cleaned_data.get('replacedStaffMember'),\n        )\n        if existing_record.exists():\n            record = existing_record.first()\n            for x in self.cleaned_data.get('occurrences'):\n                record.occurrences.add(x)\n            record.save()\n            return record\n        else:\n            return super(SubstituteReportingForm,self).save()", "response": "Save the current state of the SubstituteReportingForm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, commit=True):\n        ''' If the staff member is an instructor, also update the availableForPrivates field on the Instructor record. '''\n        if getattr(self.instance,'instructor',None):\n            self.instance.instructor.availableForPrivates = self.cleaned_data.pop('availableForPrivates',self.instance.instructor.availableForPrivates)\n            self.instance.instructor.save(update_fields=['availableForPrivates',])\n        super(StaffMemberBioChangeForm,self).save(commit=True)", "response": "Save the staff member bu change form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a tuple containing the last offered month of the Series.", "response": "def lastOfferedMonth(self):\n        '''\n        Sometimes a Series is associated with a month other than the one\n        in which the first class begins, so this returns a (year,month) tuple\n        that can be used in admin instead.\n        '''\n        lastOfferedSeries = self.event_set.order_by('-startTime').first()\n        return (lastOfferedSeries.year,lastOfferedSeries.month)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getBasePrice(self,**kwargs):\n        '''\n        This handles the logic of finding the correct price.  If more sophisticated\n        discounting systems are needed, then this PricingTier model can be subclassed,\n        or the discounts and vouchers apps can be used.\n        '''\n        payAtDoor = kwargs.get('payAtDoor', False)\n        dropIns = kwargs.get('dropIns', 0)\n\n        if dropIns:\n            return dropIns * self.dropinPrice\n        if payAtDoor:\n            return self.doorPrice\n        return self.onlinePrice", "response": "This method returns the base price for a PricingTier model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getMonthName(self):\n        '''\n        This exists as a separate method because sometimes events should really\n        belong to more than one month (e.g. class series that persist over multiple months).\n        '''\n        class_counter = Counter([(x.startTime.year, x.startTime.month) for x in self.eventoccurrence_set.all()])\n        multiclass_months = [x[0] for x in class_counter.items() if x[1] > 1]\n        all_months = [x[0] for x in class_counter.items()]\n\n        if multiclass_months:\n            multiclass_months.sort()\n            return '/'.join([month_name[x[1]] for x in multiclass_months])\n\n        else:\n            return month_name[min(all_months)[1]]", "response": "This method returns the month name of the event series."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef name(self):\n        '''\n        Since other types of events (PublicEvents, class Series, etc.) are subclasses\n        of this class, it is a good idea to override this method for those subclasses,\n        to provide a more intuitive name.  However, defining this property at the\n        event level ensures that <object>.name can always be used to access a readable\n        name for describing the event.\n        '''\n        if self.startTime:\n            return _('Event, begins %s' % (self.startTime.strftime('%a., %B %d, %Y, %I:%M %p')))\n        else:\n            return _('Event #%s' % (self.id))", "response": "Return a string describing the event."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the default recipients for this event.", "response": "def get_default_recipients(self):\n        ''' Overrides EmailRecipientMixin '''\n        return [x.registration.customer.email for x in self.eventregistration_set.filter(cancelled=False)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary of the email context for this event.", "response": "def get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n        context = super(Event,self).get_email_context(**kwargs)\n        context.update({\n            'id': self.id,\n            'name': self.__str__(),\n            'title': self.name,\n            'start': self.firstOccurrenceTime,\n            'next': self.nextOccurrenceTime,\n            'last': self.lastOccurrenceTime,\n            'url': self.url,\n        })\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if registration is enabled.", "response": "def registrationEnabled(self):\n        ''' Just checks if this event ever permits/permitted registration '''\n        return self.status in [self.RegStatus.enabled,self.RegStatus.heldOpen,self.RegStatus.heldClosed]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef availableRoles(self):\n        '''\n        Returns the set of roles for this event.  Since roles are not always custom specified for\n        event, this looks for the set of available roles in multiple places.  If no roles are found,\n        then the method returns an empty list, in which case it can be assumed that the event's registration\n        is not role-specific.\n        '''\n        eventRoles = self.eventrole_set.filter(capacity__gt=0)\n        if eventRoles.count() > 0:\n            return [x.role for x in eventRoles]\n        elif isinstance(self,Series):\n            return self.classDescription.danceTypeLevel.danceType.roles.all()\n        return []", "response": "Returns the set of roles that this event is available for."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the number of registrations for a given role.", "response": "def numRegisteredForRole(self, role, includeTemporaryRegs=False):\n        '''\n        Accepts a DanceRole object and returns the number of registrations of that role.\n        '''\n        count = self.eventregistration_set.filter(cancelled=False,dropIn=False,role=role).count()\n        if includeTemporaryRegs:\n            count += self.temporaryeventregistration_set.filter(dropIn=False,role=role).exclude(\n                registration__expirationDate__lte=timezone.now()).count()\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef numRegisteredByRole(self):\n        '''\n        Return a dictionary listing registrations by all available roles (including no role)\n        '''\n        role_list = list(self.availableRoles) + [None,]\n        return {getattr(x,'name',None):self.numRegisteredForRole(x) for x in role_list}", "response": "Return a dictionary listing registrations by all available roles including no role"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the overall capacity for the given role at this event.", "response": "def capacityForRole(self,role):\n        '''\n        Accepts a DanceRole object and determines the capacity for that role at this event.this\n        Since roles are not always custom specified for events, this looks for the set of\n        available roles in multiple places, and only returns the overall capacity of the event\n        if roles are not found elsewhere.\n        '''\n        if isinstance(role, DanceRole):\n            role_id = role.id\n        else:\n            role_id = role\n\n        eventRoles = self.eventrole_set.filter(capacity__gt=0)\n        if eventRoles.count() > 0 and role_id not in [x.role.id for x in eventRoles]:\n            ''' Custom role capacities exist but role this is not one of them. '''\n            return 0\n        elif eventRoles.count() > 0:\n            ''' The role is a match to custom roles, so check the capacity. '''\n            return eventRoles.get(role=role).capacity\n\n        # No custom roles for this event, so get the danceType roles and use the overall\n        # capacity divided by the number of roles\n        if isinstance(self,Series):\n            try:\n                availableRoles = self.classDescription.danceTypeLevel.danceType.roles.all()\n\n                if availableRoles.count() > 0 and role_id not in [x.id for x in availableRoles]:\n                    ''' DanceType roles specified and this is not one of them '''\n                    return 0\n                elif availableRoles.count() > 0 and self.capacity:\n                    # Divide the total capacity by the number of roles and round up.\n                    return ceil(self.capacity / availableRoles.count())\n            except ObjectDoesNotExist as e:\n                logger.error('Error in calculating capacity for role: %s' % e)\n\n        # No custom roles and no danceType to get roles from, so return the overall capacity\n        return self.capacity"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef soldOutForRole(self,role,includeTemporaryRegs=False):\n        '''\n        Accepts a DanceRole object and responds if the number of registrations for that\n        role exceeds the capacity for that role at this event.\n        '''\n        return self.numRegisteredForRole(\n            role,includeTemporaryRegs=includeTemporaryRegs) >= (self.capacityForRole(role) or 0)", "response": "Returns True if the number of registrations for that role exceeds the capacity for that role at this event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the registration status of the series.", "response": "def updateRegistrationStatus(self, saveMethod=False):\n        '''\n        If called via cron job or otherwise, then update the registrationOpen\n        property for this series to reflect any manual override and/or the automatic\n        closing of this series for registration.\n        '''\n        logger.debug('Beginning update registration status.  saveMethod=%s' % saveMethod)\n\n        modified = False\n        open = self.registrationOpen\n\n        startTime = self.startTime or getattr(self.eventoccurrence_set.order_by('startTime').first(),'startTime',None)\n        endTime = self.endTime or getattr(self.eventoccurrence_set.order_by('-endTime').first(),'endTime',None)\n\n        # If set to these codes, then registration will be held closed\n        force_closed_codes = [\n            self.RegStatus.disabled,\n            self.RegStatus.heldClosed,\n            self.RegStatus.regHidden,\n            self.RegStatus.hidden\n        ]\n        # If set to these codes, then registration will be held open\n        force_open_codes = [\n            self.RegStatus.heldOpen,\n        ]\n\n        # If set to these codes, then registration will be open or closed\n        # automatically depending on the value of closeAfterDays\n        automatic_codes = [\n            self.RegStatus.enabled,\n            self.RegStatus.linkOnly,\n        ]\n\n        if (self.status in force_closed_codes or not self.pricingTier) and open is True:\n            open = False\n            modified = True\n        elif not self.pricingTier:\n            open = False\n            modified = False\n        elif (self.status in force_open_codes and self.pricingTier) and open is False:\n            open = True\n            modified = True\n        elif (\n            startTime and self.status in automatic_codes and ((\n                self.closeAfterDays and timezone.now() > startTime + timedelta(days=self.closeAfterDays)) or\n                timezone.now() > endTime) and open is True):\n                    open = False\n                    modified = True\n        elif startTime and self.status in automatic_codes and ((\n            timezone.now() < endTime and not self.closeAfterDays) or (\n                self.closeAfterDays and timezone.now() < startTime + timedelta(days=self.closeAfterDays))) and open is False:\n                    open = True\n                    modified = True\n\n        # Save if something has changed, otherwise, do nothing\n        if modified and not saveMethod:\n            logger.debug('Attempting to save Series object with status: %s' % open)\n            self.registrationOpen = open\n            self.save(fromUpdateRegistrationStatus=True)\n        logger.debug('Returning value: %s' % open)\n        return (modified, open)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef allDayForDate(self,this_date,timeZone=None):\n        '''\n        This method determines whether the occurrence lasts the entirety of\n        a specified day in the specified time zone.  If no time zone is specified,\n        then it uses the default time zone).  Also, give a grace period of a few\n        minutes to account for issues with the way events are sometimes entered.\n        '''\n        if isinstance(this_date,datetime):\n            d = this_date.date()\n        else:\n            d = this_date\n\n        date_start = datetime(d.year,d.month,d.day)\n        naive_start = self.startTime if timezone.is_naive(self.startTime) else timezone.make_naive(self.startTime, timezone=timeZone)\n        naive_end = self.endTime if timezone.is_naive(self.endTime) else timezone.make_naive(self.endTime, timezone=timeZone)\n\n        return (\n            # Ensure that all comparisons are done in local time\n            naive_start <= date_start and\n            naive_end >= date_start + timedelta(days=1,minutes=-30)\n        )", "response": "This method determines whether the occurrence is all day for a specified date."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the net hours of the event staff.", "response": "def netHours(self):\n        '''\n        For regular event staff, this is the net hours worked for financial purposes.\n        For Instructors, netHours is caclulated net of any substitutes.\n        '''\n        if self.specifiedHours is not None:\n            return self.specifiedHours\n        elif self.category in [getConstant('general__eventStaffCategoryAssistant'),getConstant('general__eventStaffCategoryInstructor')]:\n            return self.event.duration - sum([sub.netHours for sub in self.replacementFor.all()])\n        else:\n            return sum([x.duration for x in self.occurrences.filter(cancelled=False)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the short description of the event.", "response": "def shortDescription(self):\n        '''\n        Overrides property from Event base class.\n        '''\n        cd = getattr(self,'classDescription',None)\n        if cd:\n            sd = getattr(cd,'shortDescription','')\n            d = getattr(cd,'description','')\n            return sd if sd else d\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef netHours(self):\n        '''\n        For regular event staff, this is the net hours worked for financial purposes.\n        For Instructors, netHours is calculated net of any substitutes.\n        '''\n        if self.specifiedHours is not None:\n            return self.specifiedHours\n        return self.event.duration - sum([sub.netHours for sub in self.replacementFor.all()])", "response": "Returns the net hours of the event staff."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list that indicates each series the person has registered for and how many registrations they have for that series.", "response": "def getSeriesRegistered(self,q_filter=Q(),distinct=True,counter=False,**kwargs):\n        '''\n        Return a list that indicates each series the person has registered for\n        and how many registrations they have for that series (because of couples).\n        This can be filtered by any keyword arguments passed (e.g. year and month).\n        '''\n        series_set = Series.objects.filter(q_filter,eventregistration__registration__customer=self,**kwargs)\n\n        if not distinct:\n            return series_set\n        elif distinct and not counter:\n            return series_set.distinct()\n        elif 'year' in kwargs or 'month' in kwargs:\n            return [str(x[1]) + 'x: ' + x[0].classDescription.title for x in Counter(series_set).items()]\n        else:\n            return [str(x[1]) + 'x: ' + x[0].__str__() for x in Counter(series_set).items()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of all series that the person has registered for.", "response": "def getMultiSeriesRegistrations(self,q_filter=Q(),name_series=False,**kwargs):\n        '''\n        Use the getSeriesRegistered method above to get a list of each series the\n        person has registered for.  The return only indicates whether they are\n        registered more than once for the same series (e.g. for keeping track of\n        dance admissions for couples who register under one name).\n        '''\n        series_registered = self.getSeriesRegistered(q_filter,distinct=False,counter=False,**kwargs)\n        counter_items = Counter(series_registered).items()\n        multireg_list = [x for x in counter_items if x[1] > 1]\n\n        if name_series and multireg_list:\n            if 'year' in kwargs or 'month' in kwargs:\n                return [str(x[1]) + 'x: ' + x[0].classDescription.title for x in multireg_list]\n            else:\n                return [str(x[1]) + 'x: ' + x[0].__str__() for x in multireg_list]\n        elif multireg_list:\n            return '%sx registration' % max([x[1] for x in multireg_list])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n        context = super(Customer,self).get_email_context(**kwargs)\n        context.update({\n            'first_name': self.first_name,\n            'last_name': self.last_name,\n            'email': self.email,\n            'fullName': self.fullName,\n            'phone': self.phone,\n        })\n        return context", "response": "Returns a dictionary of all the related attributes for the customer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTimeOfClassesRemaining(self,numClasses=0):\n        '''\n        For checking things like prerequisites, it's useful to check if a requirement is 'almost' met\n        '''\n        occurrences = EventOccurrence.objects.filter(\n            cancelled=False,\n            event__in=[x.event for x in self.temporaryeventregistration_set.filter(event__series__isnull=False)],\n        ).order_by('-endTime')\n        if occurrences.count() > numClasses:\n            return occurrences[numClasses].endTime\n        else:\n            return occurrences.last().startTime", "response": "Returns the time of the next numClasses times in the event."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary of all the related attributes for this TemporaryRegistration.", "response": "def get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n        context = super(TemporaryRegistration,self).get_email_context(**kwargs)\n        context.update({\n            'first_name': self.firstName,\n            'last_name': self.lastName,\n            'registrationComments': self.comments,\n            'registrationHowHeardAboutUs': self.howHeardAboutUs,\n            'eventList': [x.get_email_context(includeName=False) for x in self.temporaryeventregistration_set.all()],\n        })\n\n        if hasattr(self,'invoice') and self.invoice:\n            context.update({\n                'invoice': self.invoice.get_email_context(),\n            })\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a boolean indicating if the event is a warning.", "response": "def warningFlag(self):\n        '''\n        When viewing individual event registrations, there are a large number of potential\n        issues that can arise that may warrant scrutiny. This property just checks all of\n        these conditions and indicates if anything is amiss so that the template need not\n        check each of these conditions individually repeatedly.\n        '''\n        if not hasattr(self,'invoice'):\n            return True\n        if apps.is_installed('danceschool.financial'):\n            '''\n            If the financial app is installed, then we can also check additional\n            properties set by that app to ensure that there are no inconsistencies\n            '''\n            if self.invoice.revenueNotYetReceived != 0 or self.invoice.revenueMismatch:\n                return True\n        return (\n            self.priceWithDiscount != self.invoice.total or\n            self.invoice.unpaid or self.invoice.outstandingBalance != 0\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n        context = super(Registration,self).get_email_context(**kwargs)\n        context.update({\n            'first_name': self.customer.first_name,\n            'last_name': self.customer.last_name,\n            'registrationComments': self.comments,\n            'registrationHowHeardAboutUs': self.howHeardAboutUs,\n            'eventList': [x.get_email_context(includeName=False) for x in self.eventregistration_set.all()],\n        })\n\n        if hasattr(self,'invoice') and self.invoice:\n            context.update({\n                'invoice': self.invoice.get_email_context(),\n            })\n\n        return context", "response": "Returns a dictionary of email context information for this registration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a boolean indicating if the event is a warning.", "response": "def warningFlag(self):\n        '''\n        When viewing individual event registrations, there are a large number of potential\n        issues that can arise that may warrant scrutiny. This property just checks all of\n        these conditions and indicates if anything is amiss so that the template need not\n        check each of these conditions individually repeatedly.\n        '''\n        if not hasattr(self,'invoiceitem'):\n            return True\n        if apps.is_installed('danceschool.financial'):\n            '''\n            If the financial app is installed, then we can also check additional\n            properties set by that app to ensure that there are no inconsistencies\n            '''\n            if self.invoiceitem.revenueNotYetReceived != 0 or self.invoiceitem.revenueMismatch:\n                return True\n        return (\n            self.price != self.invoiceitem.grossTotal or\n            self.invoiceitem.invoice.unpaid or self.invoiceitem.invoice.outstandingBalance != 0\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride EmailRecipientMixin to add additional information to the email context.", "response": "def get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n        includeName = kwargs.pop('includeName',True)\n        context = super(EventRegistration,self).get_email_context(**kwargs)\n        context.update({\n            'title': self.event.name,\n            'start': self.event.firstOccurrenceTime,\n            'end': self.event.lastOccurrenceTime,\n        })\n\n        if includeName:\n            context.update({\n                'first_name': self.registration.customer.first_name,\n                'last_name': self.registration.customer.last_name,\n            })\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n\n        includeName = kwargs.pop('includeName',True)\n        context = super(TemporaryEventRegistration,self).get_email_context(**kwargs)\n\n        context.update({\n            'title': self.event.name,\n            'start': self.event.firstOccurrenceTime,\n            'end': self.event.lastOccurrenceTime,\n        })\n\n        if includeName:\n            context.update({\n                'first_name': self.registration.firstName,\n                'last_name': self.registration.lastName,\n            })\n        return context", "response": "Overrides EmailRecipientMixin to add additional information to the email context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, *args, **kwargs):\n        '''\n        If this is an HTML template, then set the non-HTML content to be the stripped version of the HTML.\n        If this is a plain text template, then set the HTML content to be null.\n        '''\n        if self.send_html:\n            self.content = get_text_for_html(self.html_content)\n        else:\n            self.html_content = None\n\n        super(EmailTemplate, self).save(*args, **kwargs)", "response": "Save the contents of this email template."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_from_item(cls, amount, item_description, **kwargs):\n        '''\n        Creates an Invoice as well as a single associated InvoiceItem\n        with the passed description (for things like gift certificates)\n        '''\n        submissionUser = kwargs.pop('submissionUser', None)\n        collectedByUser = kwargs.pop('collectedByUser', None)\n        calculate_taxes = kwargs.pop('calculate_taxes', False)\n        grossTotal = kwargs.pop('grossTotal',None)\n\n        new_invoice = cls(\n            grossTotal=grossTotal or amount,\n            total=amount,\n            submissionUser=submissionUser,\n            collectedByUser=collectedByUser,\n            buyerPaysSalesTax=getConstant('registration__buyerPaysSalesTax'),\n            data=kwargs,\n        )\n\n        if calculate_taxes:\n            new_invoice.calculateTaxes()\n\n        new_invoice.save()\n\n        InvoiceItem.objects.create(\n            invoice=new_invoice,\n            grossTotal=grossTotal or amount,\n            total=amount,\n            taxes=new_invoice.taxes,\n            description=item_description,\n        )\n        return new_invoice", "response": "Creates an InvoiceItem and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_from_registration(cls, reg, **kwargs):\n        '''\n        Handles the creation of an Invoice as well as one InvoiceItem per\n        assodciated TemporaryEventRegistration or registration.  Also handles taxes\n        appropriately.\n        '''\n        submissionUser = kwargs.pop('submissionUser', None)\n        collectedByUser = kwargs.pop('collectedByUser', None)\n        status = kwargs.pop('status',Invoice.PaymentStatus.unpaid)\n\n        new_invoice = cls(\n            firstName=reg.firstName,\n            lastName=reg.lastName,\n            email=reg.email,\n            grossTotal=reg.totalPrice,\n            total=reg.priceWithDiscount,\n            submissionUser=submissionUser,\n            collectedByUser=collectedByUser,\n            buyerPaysSalesTax=getConstant('registration__buyerPaysSalesTax'),\n            status=status,\n            data=kwargs,\n        )\n\n        if isinstance(reg, Registration):\n            new_invoice.finalRegistration = reg\n            ter_set = reg.eventregistration_set.all()\n        elif isinstance(reg, TemporaryRegistration):\n            new_invoice.temporaryRegistration = reg\n            ter_set = reg.temporaryeventregistration_set.all()\n        else:\n            raise ValueError('Object passed is not a registration.')\n\n        new_invoice.calculateTaxes()\n        new_invoice.save()\n\n        # Now, create InvoiceItem records for each EventRegistration\n        for ter in ter_set:\n            # Discounts and vouchers are always applied equally to all items at initial\n            # invoice creation.\n            item_kwargs = {\n                'invoice': new_invoice,\n                'grossTotal': ter.price,\n            }\n\n            if new_invoice.grossTotal > 0:\n                item_kwargs.update({\n                    'total': ter.price * (new_invoice.total / new_invoice.grossTotal),\n                    'taxes': new_invoice.taxes * (ter.price / new_invoice.grossTotal),\n                    'fees': new_invoice.fees * (ter.price / new_invoice.grossTotal),\n                })\n            else:\n                item_kwargs.update({\n                    'total': ter.price,\n                    'taxes': new_invoice.taxes,\n                    'fees': new_invoice.fees,\n                })\n\n            if isinstance(ter,TemporaryEventRegistration):\n                item_kwargs['temporaryEventRegistration'] = ter\n            elif isinstance(ter,EventRegistration):\n                item_kwargs['finalEventRegistration'] = ter\n\n            this_item = InvoiceItem(**item_kwargs)\n            this_item.save()\n\n        return new_invoice", "response": "Create an InvoiceItem from a Registration object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the URL of the invoice.", "response": "def url(self):\n        '''\n        Because invoice URLs are generally emailed, this\n        includes the default site URL and the protocol specified in\n        settings.\n        '''\n        if self.id:\n            return '%s://%s%s' % (\n                getConstant('email__linkProtocol'),\n                Site.objects.get_current().domain,\n                reverse('viewInvoice', args=[self.id,]),\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of default recipients for this instance.", "response": "def get_default_recipients(self):\n        ''' Overrides EmailRecipientMixin '''\n        if self.email:\n            return [self.email,]\n        if self.finalRegistration:\n            return [self.finalRegistration.customer.email,]\n        elif self.temporaryRegistration:\n            return [self.temporaryRegistration.email,]\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_email_context(self,**kwargs):\n        ''' Overrides EmailRecipientMixin '''\n        context = super(Invoice,self).get_email_context(**kwargs)\n        context.update({\n            'id': self.id,\n            'url': '%s?v=%s' % (self.url, self.validationString),\n            'amountPaid': self.amountPaid,\n            'outstandingBalance': self.outstandingBalance,\n            'status': self.statusLabel,\n            'creationDate': self.creationDate,\n            'modifiedDate': self.modifiedDate,\n            'paidOnline': self.paidOnline,\n            'grossTotal': self.grossTotal,\n            'total': self.total,\n            'adjustments': self.adjustments,\n            'taxes': self.taxes,\n            'fees': self.fees,\n            'comments': self.comments,\n        })\n        return context", "response": "Returns a copy of the invoice s email context with all related information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the amount of taxes for the current item based on the local rate of the item.", "response": "def calculateTaxes(self):\n        '''\n        Updates the tax field to reflect the amount of taxes depending on\n        the local rate as well as whether the buyer or seller pays sales tax.\n        '''\n\n        tax_rate = (getConstant('registration__salesTaxRate') or 0) / 100\n\n        if tax_rate > 0:\n            if self.buyerPaysSalesTax:\n                # If the buyer pays taxes, then taxes are just added as a fraction of the price\n                self.taxes = self.total * tax_rate\n            else:\n                # If the seller pays sales taxes, then adjusted_total will be their net revenue,\n                # and under this calculation adjusted_total + taxes = the price charged\n                adjusted_total = self.total / (1 + tax_rate)\n                self.taxes = adjusted_total * tax_rate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef processPayment(self, amount, fees, paidOnline=True, methodName=None, methodTxn=None, submissionUser=None, collectedByUser=None, forceFinalize=False, status=None, notify=None):\n        '''\n        When a payment processor makes a successful payment against an invoice, it can call this method\n        which handles status updates, the creation of a final registration object (if applicable), and\n        the firing of appropriate registration-related signals.\n        '''\n        epsilon = .01\n\n        paymentTime = timezone.now()\n\n        logger.info('Processing payment and creating registration objects if applicable.')\n\n        # The payment history record is primarily for convenience, and passed values are not\n        # validated.  Payment processing apps should keep individual transaction records with\n        # a ForeignKey to the Invoice object.\n        paymentHistory = self.data.get('paymentHistory',[])\n        paymentHistory.append({\n            'dateTime': paymentTime.isoformat(),\n            'amount': amount,\n            'fees': fees,\n            'paidOnline': paidOnline,\n            'methodName': methodName,\n            'methodTxn': methodTxn,\n            'submissionUser': getattr(submissionUser,'id',None),\n            'collectedByUser': getattr(collectedByUser,'id',None),\n        })\n        self.data['paymentHistory'] = paymentHistory\n\n        self.amountPaid += amount\n        self.fees += fees\n        self.paidOnline = paidOnline\n\n        if submissionUser and not self.submissionUser:\n            self.submissionUser = submissionUser\n        if collectedByUser and not self.collectedByUser:\n            self.collectedByUser = collectedByUser\n\n        # if this completed the payment, then finalize the registration and mark\n        # the invoice as Paid unless told to do otherwise.\n        if forceFinalize or abs(self.outstandingBalance) < epsilon:\n            self.status = status or self.PaymentStatus.paid\n            if not self.finalRegistration and self.temporaryRegistration:\n                self.finalRegistration = self.temporaryRegistration.finalize(dateTime=paymentTime)\n            else:\n                self.sendNotification(invoicePaid=True,thisPaymentAmount=amount,payerEmail=notify)\n            self.save()\n            if self.finalRegistration:\n                for eventReg in self.finalRegistration.eventregistration_set.filter(cancelled=False):\n                    # There can only be one eventreg per event in a registration, so we\n                    # can filter on temporaryRegistration event to get the invoiceItem\n                    # to which we should attach a finalEventRegistration\n                    this_invoice_item = self.invoiceitem_set.filter(\n                        temporaryEventRegistration__event=eventReg.event,\n                        finalEventRegistration__isnull=True\n                    ).first()\n                    if this_invoice_item:\n                        this_invoice_item.finalEventRegistration = eventReg\n                        this_invoice_item.save()\n        else:\n            # The payment wasn't completed so don't finalize, but do send a notification recording the payment.\n            if notify:\n                self.sendNotification(invoicePaid=True,thisPaymentAmount=amount,payerEmail=notify)\n            else:\n                self.sendNotification(invoicePaid=True,thisPaymentAmount=amount)\n            self.save()\n\n        # If there were transaction fees, then these also need to be allocated among the InvoiceItems\n        # All fees from payments are allocated proportionately.\n        self.allocateFees()", "response": "This method is used to process a payment against an invoice."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef allocateFees(self):\n        '''\n        Fees are allocated across invoice items based on their discounted\n        total price net of adjustments as a proportion of the overall\n        invoice's total price\n        '''\n        items = list(self.invoiceitem_set.all())\n\n        # Check that totals and adjusments match.  If they do not, raise an error.\n        if self.total != sum([x.total for x in items]):\n            msg = _('Invoice item totals do not match invoice total.  Unable to allocate fees.')\n            logger.error(str(msg))\n            raise ValidationError(msg)\n        if self.adjustments != sum([x.adjustments for x in items]):\n            msg = _('Invoice item adjustments do not match invoice adjustments.  Unable to allocate fees.')\n            logger.error(str(msg))\n            raise ValidationError(msg)\n\n        for item in items:\n            saveFlag = False\n\n            if self.total - self.adjustments > 0:\n                item.fees = self.fees * ((item.total - item.adjustments) / (self.total - self.adjustments))\n                saveFlag = True\n\n            # In the case of full refunds, allocate fees according to the\n            # initial total price of the item only.\n            elif self.total - self.adjustments == 0 and self.total > 0:\n                item.fees = self.fees * (item.total / self.total)\n                saveFlag = True\n\n            # In the unexpected event of fees with no total, just divide\n            # the fees equally among the items.\n            elif self.fees:\n                item.fees = self.fees * (1 / len(items))\n                saveFlag = True\n\n            if saveFlag:\n                item.save()", "response": "Allocate fees for all items in the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef applyAndAllocate(self,allocatedPrices,tieredTuples,payAtDoor=False):\n        '''\n        This method takes an initial allocation of prices across events, and\n        an identical length list of allocation tuples.  It applies the rule\n        specified by this discount, allocates the discount across the listed\n        items, and returns both the price and the allocation\n        '''\n        initial_net_price = sum([x for x in allocatedPrices])\n\n        if self.discountType == self.DiscountType.flatPrice:\n            # Flat-price for all applicable items (partial application for items which are\n            # only partially needed to apply the discount).  Flat prices ignore any previous discounts\n            # in other categories which may have been the best, but they only are applied if they are\n            # lower than the price that would be feasible by applying those prior discounts alone.\n            applicable_price = self.getFlatPrice(payAtDoor) or 0\n\n            this_price = applicable_price \\\n                + sum([x[0].event.getBasePrice(payAtDoor=payAtDoor) * x[1] if x[1] != 1 else x[0].price for x in tieredTuples])\n\n            # Flat prices are allocated equally across all events\n            this_allocated_prices = [x * (this_price / initial_net_price) for x in allocatedPrices]\n\n        elif self.discountType == self.DiscountType.dollarDiscount:\n            # Discount the set of applicable items by a specific number of dollars (currency units)\n            # Dollar discounts are allocated equally across all events.\n            this_price = initial_net_price - self.dollarDiscount\n            this_allocated_prices = [x * (this_price / initial_net_price) for x in allocatedPrices]\n\n        elif self.discountType == DiscountCombo.DiscountType.percentDiscount:\n            # Percentage off discounts, which may be applied to all items in the cart,\n            # or just to the items that were needed to apply the discount\n\n            if self.percentUniversallyApplied:\n                this_price = \\\n                    initial_net_price * (1 - (max(min(self.percentDiscount or 0,100),0) / 100))\n                this_allocated_prices = [x * (this_price / initial_net_price) for x in allocatedPrices]\n            else:\n                # Allocate the percentage discount based on the prior allocation from the prior category\n                this_price = 0\n                this_allocated_prices = []\n\n                for idx, val in enumerate(tieredTuples):\n                    this_val = (\n                        allocatedPrices[idx] *\n                        (1 - val[1]) * (1 - (max(min(self.percentDiscount or 0,100),0) / 100)) +\n                        allocatedPrices[idx] * val[1]\n                    )\n                    this_allocated_prices.append(this_val)\n                    this_price += this_val\n        else:\n            raise KeyError(_('Invalid discount type.'))\n\n        if this_price < initial_net_price:\n            # Ensure no negative prices\n            this_price = max(this_price, 0)\n            return self.DiscountInfo(self, this_price, initial_net_price - this_price, this_allocated_prices)", "response": "This method applies the discount across the items in the cart and returns the price and allocation of the items in the cart."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the flat price of the door or online discount.", "response": "def getFlatPrice(self,payAtDoor=False):\n        '''\n        Rather than embedding logic re: door pricing,\n        other code can call this method.\n        '''\n        if self.discountType is not DiscountCombo.DiscountType.flatPrice:\n            return None\n        if payAtDoor:\n            return self.doorPrice\n        else:\n            return self.onlinePrice"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, *args, **kwargs):\n        '''\n        Don't save any passed values related to a type of discount\n        that is not the specified type\n        '''\n\n        if self.discountType != self.DiscountType.flatPrice:\n            self.onlinePrice = None\n            self.doorPrice = None\n\n        if self.discountType != self.DiscountType.dollarDiscount:\n            self.dollarDiscount = None\n\n        if self.discountType != self.DiscountType.percentDiscount:\n            self.percentDiscount = None\n            self.percentUniversallyApplied = False\n\n        super(DiscountCombo, self).save(*args, **kwargs)", "response": "Save the current discount to the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getBestDiscount(sender,**kwargs):\n    '''\n    When a customer registers for events, discounts may need to be\n    automatically applied.  A given shopping cart may, in fact,\n    be eligible for multiple different types of discounts (e.g. hours-based\n    discounts for increasing numbers of class hours), but typically, only one\n    discount should be applied.  Therefore, this handler loops through all potential\n    discounts, finds the ones that are applicable to the passed registration or set\n    of items, and returns the code and discounted price of the best available discount,\n    in a tuple of the form (code, discounted_price).\n    '''\n    if not getConstant('general__discountsEnabled'):\n        return\n\n    logger.debug('Signal fired to request discounts.')\n\n    reg = kwargs.pop('registration',None)\n    if not reg:\n        logger.warning('No registration passed, discounts not applied.')\n        return\n\n    payAtDoor = reg.payAtDoor\n\n    # Check if this is a new customer, who may be eligible for special discounts\n    newCustomer = True\n    customer = Customer.objects.filter(email=reg.email,first_name=reg.firstName,last_name=reg.lastName).first()\n    if (customer and customer.numClassSeries > 0) or sender != RegistrationSummaryView:\n        newCustomer = False\n\n    eligible_filter = (\n        Q(event__series__pricingTier__isnull=False) |\n        Q(event__publicevent__pricingTier__isnull=False)\n    )\n    ineligible_filter = (\n        (Q(event__series__isnull=False) & Q(event__series__pricingTier__isnull=True)) |\n        (Q(event__publicevent__isnull=False) & Q(event__publicevent__pricingTier__isnull=True)) |\n        Q(dropIn=True)\n    )\n    if apps.is_installed('danceschool.private_lessons'):\n        eligible_filter = eligible_filter | Q(event__privatelessonevent__pricingTier__isnull=False)\n        ineligible_filter = ineligible_filter | (\n            Q(event__privatelessonevent__isnull=False) &\n            Q(event__privatelessonevent__pricingTier__isnull=True)\n        )\n\n    # The items for which the customer registered.\n    eventregs_list = reg.temporaryeventregistration_set.all()\n    eligible_list = eventregs_list.filter(dropIn=False).filter(eligible_filter)\n    ineligible_list = eventregs_list.filter(ineligible_filter)\n\n    ineligible_total = sum(\n        [x.event.getBasePrice(payAtDoor=payAtDoor) for x in ineligible_list.exclude(dropIn=True)] +\n        [x.price for x in ineligible_list.filter(dropIn=True)]\n    )\n\n    # Get the applicable discounts and sort them in ascending category order\n    # so that the best discounts are always listed in the order that they will\n    # be applied.\n    discountCodesApplicable = getApplicableDiscountCombos(eligible_list, newCustomer, reg.student, customer=customer, addOn=False, cannotCombine=False, dateTime=reg.dateTime)\n    discountCodesApplicable.sort(key=lambda x: x.code.category.order)\n\n    # Once we have a list of codes to try, calculate the discounted price for each possibility,\n    # and pick the one in each category that has the lowest total price.  We also need to keep track\n    # of the way in which some discounts are allocated across individual events.\n    best_discounts = OrderedDict()\n\n    initial_prices = [x.event.getBasePrice(payAtDoor=payAtDoor) for x in eligible_list]\n    initial_total = sum(initial_prices)\n\n    if discountCodesApplicable:\n        net_allocated_prices = initial_prices\n        net_precategory_price = initial_total\n        last_category = discountCodesApplicable[0].code.category\n\n    for discount in discountCodesApplicable:\n\n        # If the category has changed, then the new net_allocated_prices and the\n        # new net_precategory price are whatever was found to be best in the last category.\n        if (discount.code.category != last_category):\n            last_category = discount.code.category\n\n            if best_discounts:\n                # Since this is an OrderedDict, we can get the last element of the dict from\n                # the iterator, which is the last category for which there was a valid discount.\n                last_discount = best_discounts.get(next(reversed(best_discounts)))\n                net_allocated_prices = last_discount.net_allocated_prices\n                net_precategory_price = last_discount.net_price\n\n        # The second item in each tuple is now adjusted, so that each item that is wholly or partially\n        # applied against the discount will be wholly (value goes to 0) or partially subtracted from the\n        # remaining value to be calculated at full price.\n        tieredTuples = [(x,1) for x in eligible_list[:]]\n\n        for itemTuple in discount.itemTuples:\n            tieredTuples = [(p,q) if p != itemTuple[0] else (p,q - itemTuple[1]) for (p,q) in tieredTuples]\n\n        response = discount.code.applyAndAllocate(net_allocated_prices,tieredTuples,payAtDoor)\n\n        # Once the final price has been calculated, apply it iff it is less than\n        # the previously best discount found.\n        current_code = best_discounts.get(discount.code.category.name, None)\n        if (\n            response and (\n                (not current_code and response.net_price < net_precategory_price) or\n                (current_code and response.net_price < current_code.net_price)\n            )\n        ):\n            best_discounts[discount.code.category.name] = response\n\n    # Now, repeat the basic process for codes that cannot be combined.  These codes are always\n    # compared against the base price, and there is no need to allocate across items since\n    # only one code will potentially be applied.\n    uncombinedCodesApplicable = getApplicableDiscountCombos(\n        eligible_list, newCustomer, reg.student, customer=customer, addOn=False, cannotCombine=True, dateTime=reg.dateTime\n    )\n\n    for discount in uncombinedCodesApplicable:\n\n        # The second item in each tuple is now adjusted, so that each item that is wholly or partially\n        # applied against the discount will be wholly (value goes to 0) or partially subtracted from the\n        # remaining value to be calculated at full price.\n        tieredTuples = [(x,1) for x in eligible_list[:]]\n\n        for itemTuple in discount.itemTuples:\n            tieredTuples = [(p,q) if p != itemTuple[0] else (p,q - itemTuple[1]) for (p,q) in tieredTuples]\n\n        response = discount.code.applyAndAllocate(initial_prices,tieredTuples,payAtDoor)\n\n        # Once the final price has been calculated, apply it iff it is less than\n        # the previously best discount or combination of discounts found.\n        if (\n            response and\n            response.net_price < min([x.net_price for x in best_discounts.values()] + [initial_total])\n        ):\n            best_discounts = OrderedDict({discount.code.category.name: response})\n\n    if not best_discounts:\n        logger.debug('No applicable discounts found.')\n\n    # Return the list of discounts to be applied (in DiscountInfo tuples), along with the additional\n    # price of ineligible items to be added.\n    return DiscountCombo.DiscountApplication([x for x in best_discounts.values()], ineligible_total)", "response": "This handler returns the code and discounted price of the best available discount for the given registration or set\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the cart - specific context to this form", "response": "def render(self, context, instance, placeholder):\r\n        ''' Add the cart-specific context to this form '''\r\n        context = super(SquareCheckoutFormPlugin, self).render(context, instance, placeholder)\r\n\r\n        context.update({\r\n            'squareApplicationId': getattr(settings,'SQUARE_APPLICATION_ID',''),\r\n        })\r\n\r\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef checkVoucherCode(sender,**kwargs):\r\n    '''\r\n    Check that the given voucher code is valid\r\n    '''\r\n    logger.debug('Signal to check RegistrationContactForm handled by vouchers app.')\r\n\r\n    formData = kwargs.get('formData',{})\r\n    request = kwargs.get('request',{})\r\n    registration = kwargs.get('registration',None)\r\n    session = getattr(request,'session',{}).get(REG_VALIDATION_STR,{})\r\n\r\n    id = formData.get('gift','')\r\n    first = formData.get('firstName')\r\n    last = formData.get('lastName')\r\n    email = formData.get('email')\r\n\r\n    # Clean out the session data relating to vouchers so that we can revalidate it.\r\n    session.pop('total_voucher_amount',0)\r\n    session.pop('voucher_names',None)\r\n    session.pop('gift',None)\r\n\r\n    if id == '':\r\n        return\r\n\r\n    if not getConstant('vouchers__enableVouchers'):\r\n        raise ValidationError({'gift': _('Vouchers are disabled.')})\r\n\r\n    if session.get('gift','') != '':\r\n        raise ValidationError({'gift': _('Can\\'t have more than one voucher')})\r\n\r\n    eventids = [x.event.id for x in registration.temporaryeventregistration_set.exclude(dropIn=True)]\r\n    seriess = Series.objects.filter(id__in=eventids)\r\n\r\n    obj = Voucher.objects.filter(voucherId=id).first()\r\n    if not obj:\r\n        raise ValidationError({'gift':_('Invalid Voucher Id')})\r\n    else:\r\n        customer = Customer.objects.filter(\r\n            first_name=first,\r\n            last_name=last,\r\n            email=email).first()\r\n\r\n        # This will raise any other errors that may be relevant\r\n        try:\r\n            obj.validateForCustomerAndSeriess(customer,seriess)\r\n        except ValidationError as e:\r\n            # Ensures that the error is applied to the correct field\r\n            raise ValidationError({'gift': e})\r\n\r\n    # If we got this far, then the voucher is determined to be valid, so the registration\r\n    # can proceed with no errors.\r\n    return", "response": "Check that the given voucher code is valid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef applyVoucherCodeTemporarily(sender,**kwargs):\r\n    '''\r\n    When the core registration system creates a temporary registration with a voucher code,\r\n    the voucher app looks for vouchers that match that code and creates TemporaryVoucherUse\r\n    objects to keep track of the fact that the voucher may be used.\r\n    '''\r\n    logger.debug('Signal fired to apply temporary vouchers.')\r\n\r\n    reg = kwargs.pop('registration')\r\n    voucherId = reg.data.get('gift','')\r\n\r\n    try:\r\n        voucher = Voucher.objects.get(voucherId=voucherId)\r\n    except ObjectDoesNotExist:\r\n        logger.debug('No applicable vouchers found.')\r\n        return\r\n\r\n    tvu = TemporaryVoucherUse(voucher=voucher,registration=reg,amount=0)\r\n    tvu.save()\r\n    logger.debug('Temporary voucher use object created.')", "response": "This signal is fired when a voucher code is used."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef applyReferrerVouchersTemporarily(sender,**kwargs):\r\n    '''\r\n    Unlike voucher codes which have to be manually supplied, referrer discounts are\r\n    automatically applied here, assuming that the referral program is enabled.\r\n    '''\r\n\r\n    # Only continue if the referral program is enabled\r\n    if not getConstant('referrals__enableReferralProgram'):\r\n        return\r\n\r\n    logger.debug('Signal fired to temporarily apply referrer vouchers.')\r\n\r\n    reg = kwargs.pop('registration')\r\n\r\n    # Email address is unique for users, so use that\r\n    try:\r\n        c = Customer.objects.get(user__email=reg.email)\r\n        vouchers = c.getReferralVouchers()\r\n    except ObjectDoesNotExist:\r\n        vouchers = None\r\n\r\n    if not vouchers:\r\n        logger.debug('No referral vouchers found.')\r\n        return\r\n\r\n    for v in vouchers:\r\n        TemporaryVoucherUse(voucher=v,registration=reg,amount=0).save()", "response": "This signal is used to temporarily apply referrer vouchers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef applyVoucherCodesFinal(sender,**kwargs):\r\n    '''\r\n    Once a registration has been completed, vouchers are used and referrers are awarded\r\n    '''\r\n    logger.debug('Signal fired to mark voucher codes as applied.')\r\n\r\n    finalReg = kwargs.pop('registration')\r\n    tr = finalReg.temporaryRegistration\r\n\r\n    tvus = TemporaryVoucherUse.objects.filter(registration=tr)\r\n\r\n    for tvu in tvus:\r\n        vu = VoucherUse(voucher=tvu.voucher,registration=finalReg,amount=tvu.amount)\r\n        vu.save()\r\n        if getConstant('referrals__enableReferralProgram'):\r\n            awardReferrers(vu)", "response": "This signal is fired when a registration is completed and the amount of vouchers in the final registration is applied."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef provideCustomerReferralCode(sender,**kwargs):\r\n    '''\r\n    If the vouchers app is installed and referrals are enabled, then the customer's profile page can show their voucher referral code.\r\n    '''\r\n    customer = kwargs.pop('customer')\r\n    if getConstant('vouchers__enableVouchers') and getConstant('referrals__enableReferralProgram'):\r\n        vrd = ensureReferralVouchersExist(customer)\r\n\r\n        return {\r\n            'referralVoucherId': vrd.referreeVoucher.voucherId\r\n        }", "response": "This is a helper method that provides the details of the customer s voucher referral code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getConstant(name):\n    '''\n    This is a convenience function that makes it easy to access the value of a preference/constant\n    without needing to check if the django_dynamic_preferences app has been set up and without\n    needing to load from that model directly.\n    '''\n\n    # We instantiate a manager for our global preferences\n    if 'dynamic_preferences_globalpreferencemodel' in connection.introspection.table_names() and not isPreliminaryRun():\n        params = global_preferences_registry.manager()\n        try:\n            return params.get(name)\n        except NotFoundInRegistry as e:\n            logger.error('Error in getting constant: %s' % e)\n            return None", "response": "Get a constant from the registry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateConstant(name,value,fail_silently=False):\n    '''\n    This is a convenience function that makes it easy to update the value of a preference/constant\n    without needing to check if the django_dynamic_preferences app has been set up, without\n    needing to load from that model directly, and with the option to suppress any errors\n    (e.g. KeyErrors resulting from the order in which apps are loaded).\n    '''\n\n    # We instantiate a manager for our global preferences\n    if 'dynamic_preferences_globalpreferencemodel' in connection.introspection.table_names() and not isPreliminaryRun():\n        params = global_preferences_registry.manager()\n        try:\n            params[name] = value\n            return True\n        except Exception as e:\n            logger.error('Error in updating constant: %s' % e)\n            if not fail_silently:\n                raise\n            return False", "response": "Updates the value of a preference in a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef processSquarePayment(request):\n    '''\n    This view handles the charging of approved Square Checkout payments.\n\n    All Checkout payments must either be associated with a pre-existing Invoice\n    or a registration, or they must have an amount and type passed in the post data\n    (such as gift certificate payment requests).\n    '''\n    logger.info('Received request for Square Checkout payment.')\n\n    nonce_id = request.POST.get('nonce')\n    invoice_id = request.POST.get('invoice_id')\n    tr_id = request.POST.get('reg_id')\n    amount = request.POST.get('amount')\n    submissionUserId = request.POST.get('user_id')\n    transactionType = request.POST.get('transaction_type')\n    taxable = request.POST.get('taxable', False)\n    sourceUrl = request.POST.get('sourceUrl', reverse('showRegSummary'))\n    addSessionInfo = request.POST.get('addSessionInfo',False)\n    successUrl = request.POST.get('successUrl',reverse('registration'))\n    customerEmail = request.POST.get('customerEmail')\n\n    # If a specific amount to pay has been passed, then allow payment\n    # of that amount.\n    if amount:\n        try:\n            amount = float(amount)\n        except ValueError:\n            logger.error('Invalid amount passed')\n            messages.error(\n                request,\n                format_html(\n                    '<p>{}</p><ul><li>{}</li></ul>',\n                    str(_('ERROR: Error with Square checkout transaction attempt.')),\n                    str(_('Invalid amount passed.'))\n                )\n            )\n            return HttpResponseRedirect(sourceUrl)\n\n    # Parse if a specific submission user is indicated\n    submissionUser = None\n    if submissionUserId:\n        try:\n            submissionUser = User.objects.get(id=int(submissionUserId))\n        except (ValueError, ObjectDoesNotExist):\n            logger.warning('Invalid user passed, submissionUser will not be recorded.')\n\n    try:\n        # Invoice transactions are usually payment on an existing invoice.\n        if invoice_id:\n            this_invoice = Invoice.objects.get(id=invoice_id)\n            this_description = _('Invoice Payment: %s' % this_invoice.id)\n            if not amount:\n                amount = this_invoice.outstandingBalance\n        # This is typical of payment at the time of registration\n        elif tr_id:\n            tr = TemporaryRegistration.objects.get(id=int(tr_id))\n            tr.expirationDate = timezone.now() + timedelta(minutes=getConstant('registration__sessionExpiryMinutes'))\n            tr.save()\n            this_invoice = Invoice.get_or_create_from_registration(tr, submissionUser=submissionUser)\n            this_description = _('Registration Payment: #%s' % tr_id)\n            if not amount:\n                amount = this_invoice.outstandingBalance\n        # All other transactions require both a transaction type and an amount to be specified\n        elif not transactionType or not amount:\n            logger.error('Insufficient information passed to createSquarePayment view.')\n            messages.error(\n                request,\n                format_html(\n                    '<p>{}</p><ul><li>{}</li></ul>',\n                    str(_('ERROR: Error with Square checkout transaction attempt.')),\n                    str(_('Insufficient information passed to createSquarePayment view.'))\n                )\n            )\n            return HttpResponseRedirect(sourceUrl)\n        else:\n            # Gift certificates automatically get a nicer invoice description\n            if transactionType == 'Gift Certificate':\n                this_description = _('Gift Certificate Purchase')\n            else:\n                this_description = transactionType\n            this_invoice = Invoice.create_from_item(\n                float(amount),\n                this_description,\n                submissionUser=submissionUser,\n                calculate_taxes=(taxable is not False),\n                transactionType=transactionType,\n            )\n    except (ValueError, ObjectDoesNotExist) as e:\n        logger.error('Invalid registration information passed to createSquarePayment view: (%s, %s, %s)' % (invoice_id, tr_id, amount))\n        messages.error(\n            request,\n            format_html(\n                '<p>{}</p><ul><li>{}</li></ul>',\n                str(_('ERROR: Error with Square checkout transaction attempt.')),\n                str(_('Invalid registration information passed to createSquarePayment view: (%s, %s, %s)' % (invoice_id, tr_id, amount)))\n            )\n        )\n        return HttpResponseRedirect(sourceUrl)\n\n    this_currency = getConstant('general__currencyCode')\n    this_total = min(this_invoice.outstandingBalance, amount)\n\n    api_instance = TransactionsApi()\n    api_instance.api_client.configuration.access_token = getattr(settings,'SQUARE_ACCESS_TOKEN','')\n    idempotency_key = str(uuid.uuid1())\n    location_id = getattr(settings,'SQUARE_LOCATION_ID','')\n    amount = {'amount': int(100 * this_total), 'currency': this_currency}\n    body = {'idempotency_key': idempotency_key, 'card_nonce': nonce_id, 'amount_money': amount}\n\n    errors_list = []\n\n    try:\n        # Charge\n        api_response = api_instance.charge(location_id, body)\n        if api_response.errors:\n            logger.error('Error in charging Square transaction: %s' % api_response.errors)\n            errors_list = api_response.errors\n    except ApiException as e:\n        logger.error('Exception when calling TransactionApi->charge: %s\\n' % e)\n        errors_list = json.loads(e.body).get('errors',[])\n\n    if errors_list:\n        this_invoice.status = Invoice.PaymentStatus.error\n        this_invoice.save()\n        errors_string = ''\n        for err in errors_list:\n            errors_string += '<li><strong>CODE:</strong> %s, %s</li>' % (\n                err.get('code',str(_('Unknown'))), err.get('detail',str(_('Unknown')))\n            )\n        messages.error(\n            request,\n            format_html(\n                '<p>{}</p><ul>{}</ul>',\n                str(_('ERROR: Error with Square checkout transaction attempt.')),\n                mark_safe(errors_list),\n            )\n        )\n        return HttpResponseRedirect(sourceUrl)\n    else:\n        logger.info('Square charge successfully created.')\n\n    transaction = api_response.transaction\n\n    paymentRecord = SquarePaymentRecord.objects.create(\n        invoice=this_invoice,\n        transactionId=transaction.id,\n        locationId=transaction.location_id,\n    )\n\n    # We process the payment now, and enqueue the job to retrieve the\n    # transaction again once fees have been calculated by Square\n    this_invoice.processPayment(\n        amount=this_total,\n        fees=0,\n        paidOnline=True,\n        methodName='Square Checkout',\n        methodTxn=transaction.id,\n        notify=customerEmail,\n    )\n    updateSquareFees.schedule(args=(paymentRecord,), delay=60)\n\n    if addSessionInfo:\n        paymentSession = request.session.get(INVOICE_VALIDATION_STR, {})\n\n        paymentSession.update({\n            'invoiceID': str(this_invoice.id),\n            'amount': this_total,\n            'successUrl': successUrl,\n        })\n        request.session[INVOICE_VALIDATION_STR] = paymentSession\n\n    return HttpResponseRedirect(successUrl)", "response": "This view handles the charging of approved Square Checkout payments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_prep_lookup(self):\n    raise FieldError(\"{} '{}' does not support lookups\".format(\n        self.lhs.field.__class__.__name__, self.lookup_name))", "response": "Raise errors for unsupported lookups"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef derive_fernet_key(input_key):\n    hkdf = HKDF(\n        algorithm=hashes.SHA256(),\n        length=32,\n        salt=salt,\n        info=info,\n        backend=backend,\n    )\n    return base64.urlsafe_b64encode(hkdf.derive(force_bytes(input_key)))", "response": "Derive a 32 - bit b64 - encoded Fernet key from arbitrary input key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reduce_cpu(f, x, axes, dtype):\n    axes = _get_axes(axes, x.ndim)\n    if not axes:\n        return x\n\n    permute = [n for n in range(x.ndim) if n not in axes]\n    permute = axes + permute\n\n    T = x.transpose(permute=permute)\n\n    N = len(axes)\n    t = T.type.at(N, dtype=dtype)\n    acc = x.empty(t, device=x.device)\n\n    if f.identity is not None:\n        _copyto(acc, f.identity)\n        tl = T\n    elif N == 1 and T.type.shape[0] > 0:\n        hd, tl = T[0], T[1:]\n        acc[()] = hd\n    else:\n        raise ValueError(\n            \"reduction not possible for function without an identity element\")\n\n    return fold(f, acc, tl)", "response": "NumPy s reduce in terms of fold."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reduce_cuda(g, x, axes, dtype):\n    if axes != 0:\n        raise NotImplementedError(\"'axes' keyword is not implemented for CUDA\")\n\n    return g(x, dtype=dtype)", "response": "Reductions in CUDA use the thrust library for speed and have limited\n       functionality."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maxlevel(lst):\n    maxlev = 0\n    def f(lst, level):\n        nonlocal maxlev\n        if isinstance(lst, list):\n            level += 1\n            maxlev = max(level, maxlev)\n            for item in lst:\n                f(item, level)\n    f(lst, 0)\n    return maxlev", "response": "Return maximum nesting depth of a list of objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef genslices(n):\n    def range_with_none():\n        yield None\n        yield from range(-n, n+1)\n\n    for t in product(range_with_none(), range_with_none(), range_with_none()):\n        s = slice(*t)\n        if s.step != 0:\n            yield s", "response": "Generate all possible slices for a single dimension."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates all possible slice tuples for shape.", "response": "def genslices_ndim(ndim, shape):\n    \"\"\"Generate all possible slice tuples for 'shape'.\"\"\"\n    iterables = [genslices(shape[n]) for n in range(ndim)]\n    yield from product(*iterables)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an inspyred mutator function based on the given function.", "response": "def mutator(mutate):\n    \"\"\"Return an inspyred mutator function based on the given function.\n    \n    This function generator takes a function that operates on only\n    one candidate to produce a single mutated candidate. The generator \n    handles the iteration over each candidate in the set to be mutated.\n\n    The given function ``mutate`` must have the following signature::\n    \n        mutant = mutate(random, candidate, args)\n        \n    This function is most commonly used as a function decorator with\n    the following usage::\n    \n        @mutator\n        def mutate(random, candidate, args):\n            # Implementation of mutation\n            pass\n            \n    The generated function also contains an attribute named\n    ``single_mutation`` which holds the original mutation function.\n    In this way, the original single-candidate function can be\n    retrieved if necessary.\n    \n    \"\"\"\n    @functools.wraps(mutate)\n    def inspyred_mutator(random, candidates, args):\n        mutants = []\n        for i, cs in enumerate(candidates):\n            mutants.append(mutate(random, cs, args))\n        return mutants\n    inspyred_mutator.single_mutation = mutate\n    return inspyred_mutator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bit_flip_mutation(random, candidate, args):\n    rate = args.setdefault('mutation_rate', 0.1)\n    mutant = copy.copy(candidate)\n    if len(mutant) == len([x for x in mutant if x in [0, 1]]):\n        for i, m in enumerate(mutant):\n            if random.random() < rate:\n                mutant[i] = (m + 1) % 2\n    return mutant", "response": "This function performs a bit - flip mutation on the candidates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef random_reset_mutation(random, candidate, args):\n    bounder = args['_ec'].bounder\n    try:\n        values = bounder.values\n    except AttributeError:\n        values = None\n    if values is not None:\n        rate = args.setdefault('mutation_rate', 0.1)\n        mutant = copy.copy(candidate)\n        for i, m in enumerate(mutant):\n            if random.random() < rate:\n                mutant[i] = random.choice(values)\n        return mutant\n    else:\n        return candidate", "response": "This function returns the mutants produced by randomly choosing new values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the mutants created by scramble mutation on the candidates. This function performs scramble mutation. It randomly chooses two locations along the candidate and scrambles the values within that slice. .. Arguments: random -- the random number generator object candidate -- the candidate solution args -- a dictionary of keyword arguments Optional keyword arguments in args: - *mutation_rate* -- the rate at which mutation is performed (default 0.1) The mutation rate is applied to the candidate as a whole (i.e., it either mutates or it does not, based on the rate).", "response": "def scramble_mutation(random, candidate, args):\n    \"\"\"Return the mutants created by scramble mutation on the candidates.\n\n    This function performs scramble mutation. It randomly chooses two\n    locations along the candidate and scrambles the values within that\n    slice. \n\n    .. Arguments:\n       random -- the random number generator object\n       candidate -- the candidate solution\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *mutation_rate* -- the rate at which mutation is performed (default 0.1)\n      \n    The mutation rate is applied to the candidate as a whole (i.e., it\n    either mutates or it does not, based on the rate).\n    \n    \"\"\"\n    rate = args.setdefault('mutation_rate', 0.1)\n    if random.random() < rate:\n        size = len(candidate)\n        p = random.randint(0, size-1)\n        q = random.randint(0, size-1)\n        p, q = min(p, q), max(p, q)\n        s = candidate[p:q+1]\n        random.shuffle(s)\n        return candidate[:p] + s[::-1] + candidate[q+1:]\n    else:\n        return candidate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gaussian_mutation(random, candidate, args):\n    mut_rate = args.setdefault('mutation_rate', 0.1)\n    mean = args.setdefault('gaussian_mean', 0.0)\n    stdev = args.setdefault('gaussian_stdev', 1.0)\n    bounder = args['_ec'].bounder\n    mutant = copy.copy(candidate)\n    for i, m in enumerate(mutant):\n        if random.random() < mut_rate:\n            mutant[i] += random.gauss(mean, stdev)\n    mutant = bounder(mutant, args)\n    return mutant", "response": "This function performs a Gaussian mutation on the candidates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the mutants produced by nonuniform mutation on the candidates. The function performs nonuniform mutation as specified in (Michalewicz, \"Genetic Algorithms + Data Structures = Evolution Programs,\" Springer, 1996). This function also makes use of the bounder function as specified in the EC's ``evolve`` method. .. note:: This function **requires** that *max_generations* be specified in the *args* dictionary. Therefore, it is best to use this operator in conjunction with the ``generation_termination`` terminator. .. Arguments: random -- the random number generator object candidate -- the candidate solution args -- a dictionary of keyword arguments Required keyword arguments in args: - *max_generations* -- the maximum number of generations for which evolution should take place Optional keyword arguments in args: - *mutation_strength* -- the strength of the mutation, where higher values correspond to greater variation (default 1)", "response": "def nonuniform_mutation(random, candidate, args):\n    \"\"\"Return the mutants produced by nonuniform mutation on the candidates.\n\n    The function performs nonuniform mutation as specified in\n    (Michalewicz, \"Genetic Algorithms + Data Structures = Evolution\n    Programs,\" Springer, 1996). This function also makes use of the \n    bounder function as specified in the EC's ``evolve`` method.\n    \n    .. note::\n    \n       This function **requires** that *max_generations* be specified in \n       the *args* dictionary. Therefore, it is best to use this operator \n       in conjunction with the ``generation_termination`` terminator. \n\n    .. Arguments:\n       random -- the random number generator object\n       candidate -- the candidate solution\n       args -- a dictionary of keyword arguments\n\n    Required keyword arguments in args:\n    \n    - *max_generations* -- the maximum number of generations for which\n      evolution should take place\n    \n    Optional keyword arguments in args:\n    \n    - *mutation_strength* -- the strength of the mutation, where higher\n      values correspond to greater variation (default 1)\n    \n    \"\"\"\n    bounder = args['_ec'].bounder\n    num_gens = args['_ec'].num_generations\n    max_gens = args['max_generations']\n    strength = args.setdefault('mutation_strength', 1)\n    exponent = (1.0 - num_gens / float(max_gens)) ** strength\n    mutant = copy.copy(candidate)\n    for i, (c, lo, hi) in enumerate(zip(candidate, bounder.lower_bound, bounder.upper_bound)):\n        if random.random() <= 0.5:\n            new_value = c + (hi - c) * (1.0 - random.random() ** exponent)\n        else:\n            new_value = c - (c - lo) * (1.0 - random.random() ** exponent)\n        mutant[i] = new_value\n    return mutant"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef population_archiver(random, population, archive, args):\n    new_archive = []\n    for ind in population:\n        new_archive.append(ind)\n    return new_archive", "response": "Archive the current population."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef best_archiver(random, population, archive, args):\n    new_archive = archive\n    for ind in population:\n        if len(new_archive) == 0:\n            new_archive.append(ind)\n        else:\n            should_remove = []\n            should_add = True\n            for a in new_archive:\n                if ind.candidate == a.candidate:\n                    should_add = False\n                    break\n                elif ind < a:\n                    should_add = False\n                elif ind > a:\n                    should_remove.append(a)\n            for r in should_remove:\n                new_archive.remove(r)\n            if should_add:\n                new_archive.append(ind)\n    return new_archive", "response": "This function archives the best solutions and removes inferior ones."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\narchiving only the best individual(s) using a fixed size grid. This function archives the best solutions by using a fixed-size grid to determine which existing solutions should be removed in order to make room for new ones. This archiver is designed specifically for use with the Pareto Archived Evolution Strategy (PAES). .. Arguments: random -- the random number generator object population -- the population of individuals archive -- the current archive of individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *max_archive_size* -- the maximum number of individuals in the archive (default len(population)) - *num_grid_divisions* -- the number of grid divisions (default 1)", "response": "def adaptive_grid_archiver(random, population, archive, args):\n    \"\"\"Archive only the best individual(s) using a fixed size grid.\n    \n    This function archives the best solutions by using a fixed-size grid\n    to determine which existing solutions should be removed in order to\n    make room for new ones. This archiver is designed specifically for\n    use with the Pareto Archived Evolution Strategy (PAES).\n\n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       archive -- the current archive of individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *max_archive_size* -- the maximum number of individuals in the archive\n      (default len(population))\n    - *num_grid_divisions* -- the number of grid divisions (default 1)\n    \n    \"\"\"\n    def get_grid_location(fitness, num_grid_divisions, global_smallest, global_largest):\n        loc = 0\n        n = 1\n        num_objectives = len(fitness)\n        inc = [0 for _ in range(num_objectives)]\n        width = [0 for _ in range(num_objectives)]\n        local_smallest = global_smallest[:]\n        for i, f in enumerate(fitness):\n            if f < local_smallest[i] or f > local_smallest[i] + global_largest[i] - global_smallest[i]:\n                return -1\n        for i in range(num_objectives):\n            inc[i] = n\n            n *= 2\n            width[i] = global_largest[i] - global_smallest[i]\n        for d in range(num_grid_divisions):\n            for i, f in enumerate(fitness):\n                if f < width[i] / 2.0 + local_smallest[i]:\n                    loc += inc[i]\n                else:\n                    local_smallest[i] += width[i] / 2.0\n            for i in range(num_objectives):\n                inc[i] *= num_objectives * 2\n                width[i] /= 2.0\n        return loc\n \n    def update_grid(individual, archive, num_grid_divisions, global_smallest, global_largest, grid_population):\n        if len(archive) == 0:\n            num_objectives = len(individual.fitness)\n            smallest = [individual.fitness[o] for o in range(num_objectives)]\n            largest = [individual.fitness[o] for o in range(num_objectives)]\n        else:\n            num_objectives = min(min([len(a.fitness) for a in archive]), len(individual.fitness))\n            smallest = [min(min([a.fitness[o] for a in archive]), individual.fitness[o]) for o in range(num_objectives)] \n            largest = [max(max([a.fitness[o] for a in archive]), individual.fitness[o]) for o in range(num_objectives)]\n        for i in range(num_objectives):\n            global_smallest[i] = smallest[i] - abs(0.2 * smallest[i])\n            global_largest[i] = largest[i] + abs(0.2 * largest[i])\n        for i in range(len(grid_population)):\n            grid_population[i] = 0\n        for a in archive:\n            loc = get_grid_location(a.fitness, num_grid_divisions, global_smallest, global_largest)\n            a.grid_location = loc\n            grid_population[loc] += 1\n        loc = get_grid_location(individual.fitness, num_grid_divisions, global_smallest, global_largest)\n        individual.grid_location = loc\n        grid_population[loc] += 1\n\n    max_archive_size = args.setdefault('max_archive_size', len(population))\n    num_grid_divisions = args.setdefault('num_grid_divisions', 1)\n        \n    if not 'grid_population' in dir(adaptive_grid_archiver):\n        adaptive_grid_archiver.grid_population = [0 for _ in range(2**(min([len(p.fitness) for p in population]) * num_grid_divisions))]\n    if not 'global_smallest' in dir(adaptive_grid_archiver):\n        adaptive_grid_archiver.global_smallest = [0 for _ in range(min([len(p.fitness) for p in population]))]\n    if not 'global_largest' in dir(adaptive_grid_archiver):\n        adaptive_grid_archiver.global_largest = [0 for _ in range(min([len(p.fitness) for p in population]))]\n     \n    new_archive = archive\n    for ind in population:\n        update_grid(ind, new_archive, num_grid_divisions, adaptive_grid_archiver.global_smallest, \n                    adaptive_grid_archiver.global_largest, adaptive_grid_archiver.grid_population)\n        should_be_added = True\n        for a in new_archive:\n            if ind == a or a > ind:\n                should_be_added = False\n                \n        if should_be_added:\n            if len(new_archive) == 0:\n                new_archive.append(ind)\n            else:\n                join = False\n                nondominated = True\n                removal_set = []\n                for i, a in enumerate(new_archive):\n                    if ind > a and not join:\n                        new_archive[i] = ind\n                        join = True\n                    elif ind > a:\n                        if not a in removal_set: \n                            removal_set.append(a)\n                    # Otherwise, the individual is nondominated against this archive member.\n                    \n                # We can't use set difference because Individual objects are not hashable.\n                # We'd like to say...\n                #     new_archive = list(set(new_archive) - set(removal_set))\n                # So this code gets that same result without using sets.\n                temp_archive = []\n                for ind in new_archive:\n                    if ind not in removal_set:\n                        temp_archive.append(ind)\n                new_archive = temp_archive\n                \n                if not join and nondominated:\n                    if len(new_archive) == max_archive_size:\n                        replaced_index = 0\n                        found_replacement = False\n                        loc = get_grid_location(ind.fitness, num_grid_divisions, \n                                                adaptive_grid_archiver.global_smallest, \n                                                adaptive_grid_archiver.global_largest)\n                        ind.grid_location = loc\n                        if ind.grid_location >= 0:\n                            most = adaptive_grid_archiver.grid_population[ind.grid_location]\n                        else:\n                            most = -1\n                        for i, a in enumerate(new_archive):\n                            pop_at_a = adaptive_grid_archiver.grid_population[a.grid_location]\n                            if pop_at_a > most:\n                                most = pop_at_a\n                                replaced_index = i\n                                found_replacement = True\n                        if found_replacement:\n                            new_archive[replaced_index] = ind\n                    else:\n                        new_archive.append(ind)\n    return new_archive"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ring_topology(random, population, args):\n    neighborhood_size = args.setdefault('neighborhood_size', 3)\n    half_hood = neighborhood_size // 2\n    neighbor_index_start = []\n    for index in range(len(population)):\n        if index < half_hood:\n            neighbor_index_start.append(len(population) - half_hood + index)\n        else:\n            neighbor_index_start.append(index - half_hood)\n    neighbors = []\n    for start in neighbor_index_start:\n        n = []\n        for i in range(0, neighborhood_size):\n            n.append(population[(start + i) % len(population)])\n        yield n", "response": "This function returns the neighbors using a ring topology."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evolve(self, generator, evaluator, pop_size=100, seeds=None, maximize=True, bounder=None, **args):\n        self._kwargs = args\n        self._kwargs['_ec'] = self\n        \n        if seeds is None:\n            seeds = []\n        if bounder is None:\n            bounder = Bounder()\n        \n        self.termination_cause = None\n        self.generator = generator\n        self.evaluator = evaluator\n        self.bounder = bounder\n        self.maximize = maximize\n        self.population = []\n        self.archive = []\n        \n        # Create the initial population.\n        if not isinstance(seeds, collections.Sequence):\n            seeds = [seeds]\n        initial_cs = copy.copy(seeds)\n        num_generated = max(pop_size - len(seeds), 0)\n        i = 0\n        self.logger.debug('generating initial population')\n        while i < num_generated:\n            cs = generator(random=self._random, args=self._kwargs)\n            initial_cs.append(cs)\n            i += 1\n        self.logger.debug('evaluating initial population')\n        initial_fit = evaluator(candidates=initial_cs, args=self._kwargs)\n        \n        for cs, fit in zip(initial_cs, initial_fit):\n            if fit is not None:\n                ind = Individual(cs, maximize=maximize)\n                ind.fitness = fit\n                self.population.append(ind)\n            else:\n                self.logger.warning('excluding candidate {0} because fitness received as None'.format(cs))\n        self.logger.debug('population size is now {0}'.format(len(self.population)))\n        \n        self.num_evaluations = len(initial_fit)\n        self.num_generations = 0\n        \n        self.logger.debug('archiving initial population')\n        self.archive = self.archiver(random=self._random, population=list(self.population), archive=list(self.archive), args=self._kwargs)\n        self.logger.debug('archive size is now {0}'.format(len(self.archive)))\n        self.logger.debug('population size is now {0}'.format(len(self.population)))\n\n        # Turn observers and variators into lists if not already\n        if isinstance(self.observer, collections.Iterable):\n            observers = self.observer\n        else:\n            observers = [self.observer]\n        if isinstance(self.variator, collections.Iterable):\n            variators = self.variator\n        else:\n            variators = [self.variator]\n\n        for obs in observers:\n            self.logger.debug('observation using {0} at generation {1} and evaluation {2}'.format(obs.__name__, self.num_generations, self.num_evaluations))\n            obs(population=list(self.population), num_generations=self.num_generations, num_evaluations=self.num_evaluations, args=self._kwargs)\n        \n        while not self._should_terminate(list(self.population), self.num_generations, self.num_evaluations):\n            # Select individuals.\n            self.logger.debug('selection using {0} at generation {1} and evaluation {2}'.format(self.selector.__name__, self.num_generations, self.num_evaluations))\n            parents = self.selector(random=self._random, population=list(self.population), args=self._kwargs)\n            self.logger.debug('selected {0} candidates'.format(len(parents)))\n            offspring_cs = [copy.deepcopy(i.candidate) for i in parents]\n            \n            for op in variators:\n                self.logger.debug('variation using {0} at generation {1} and evaluation {2}'.format(op.__name__, self.num_generations, self.num_evaluations))\n                offspring_cs = op(random=self._random, candidates=offspring_cs, args=self._kwargs)\n            self.logger.debug('created {0} offspring'.format(len(offspring_cs)))\n            \n            # Evaluate offspring.\n            self.logger.debug('evaluation using {0} at generation {1} and evaluation {2}'.format(evaluator.__name__, self.num_generations, self.num_evaluations))\n            offspring_fit = evaluator(candidates=offspring_cs, args=self._kwargs)\n            offspring = []\n            for cs, fit in zip(offspring_cs, offspring_fit):\n                if fit is not None:\n                    off = Individual(cs, maximize=maximize)\n                    off.fitness = fit\n                    offspring.append(off)\n                else:\n                    self.logger.warning('excluding candidate {0} because fitness received as None'.format(cs))\n            self.num_evaluations += len(offspring_fit)        \n\n            # Replace individuals.\n            self.logger.debug('replacement using {0} at generation {1} and evaluation {2}'.format(self.replacer.__name__, self.num_generations, self.num_evaluations))\n            self.population = self.replacer(random=self._random, population=self.population, parents=parents, offspring=offspring, args=self._kwargs)\n            self.logger.debug('population size is now {0}'.format(len(self.population)))\n            \n            # Migrate individuals.\n            self.logger.debug('migration using {0} at generation {1} and evaluation {2}'.format(self.migrator.__name__, self.num_generations, self.num_evaluations))\n            self.population = self.migrator(random=self._random, population=self.population, args=self._kwargs)\n            self.logger.debug('population size is now {0}'.format(len(self.population)))\n            \n            # Archive individuals.\n            self.logger.debug('archival using {0} at generation {1} and evaluation {2}'.format(self.archiver.__name__, self.num_generations, self.num_evaluations))\n            self.archive = self.archiver(random=self._random, archive=self.archive, population=list(self.population), args=self._kwargs)\n            self.logger.debug('archive size is now {0}'.format(len(self.archive)))\n            self.logger.debug('population size is now {0}'.format(len(self.population)))\n            \n            self.num_generations += 1\n            for obs in observers:\n                self.logger.debug('observation using {0} at generation {1} and evaluation {2}'.format(obs.__name__, self.num_generations, self.num_evaluations))\n                obs(population=list(self.population), num_generations=self.num_generations, num_evaluations=self.num_evaluations, args=self._kwargs)\n\n        return self.population", "response": "This function creates a new population and runs the evolutionary computation of the candidate solutions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects the best individuals from the population. This function performs truncation selection, which means that only the best individuals from the current population are selected. This is a completely deterministic selection mechanism. .. Arguments: random -- the random number generator object population -- the population of individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *num_selected* -- the number of individuals to be selected (default len(population))", "response": "def truncation_selection(random, population, args):\n    \"\"\"Selects the best individuals from the population.\n    \n    This function performs truncation selection, which means that only\n    the best individuals from the current population are selected. This\n    is a completely deterministic selection mechanism.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *num_selected* -- the number of individuals to be selected \n      (default len(population))\n    \n    \"\"\"\n    num_selected = args.setdefault('num_selected', len(population))\n    population.sort(reverse=True)\n    return population[:num_selected]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uniform_selection(random, population, args):\n    num_selected = args.setdefault('num_selected', 1)\n    selected = []\n    for _ in range(num_selected):\n        selected.append(population[random.randint(0, len(population)-1)])\n    return selected", "response": "This function performs a uniform selection by randomly choosing the next set of individuals from the population."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning fitness proportionate sampling of individuals from the population. This function stochastically chooses individuals from the population with probability proportional to their fitness. This is often referred to as \"roulette wheel\" selection. Note that this selection is not valid for minimization problems. .. Arguments: random -- the random number generator object population -- the population of individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *num_selected* -- the number of individuals to be selected (default 1)", "response": "def fitness_proportionate_selection(random, population, args):\n    \"\"\"Return fitness proportionate sampling of individuals from the population.\n    \n    This function stochastically chooses individuals from the population\n    with probability proportional to their fitness. This is often \n    referred to as \"roulette wheel\" selection. Note that this selection\n    is not valid for minimization problems.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *num_selected* -- the number of individuals to be selected (default 1)\n    \n    \"\"\"\n    num_selected = args.setdefault('num_selected', 1)\n    len_pop = len(population)\n    psum = [i for i in range(len_pop)]\n    pop_max_fit = (max(population)).fitness\n    pop_min_fit = (min(population)).fitness\n    \n    # If we're actually doing minimimization,\n    # fitness proportionate selection is not defined.\n    if pop_max_fit < pop_min_fit:\n        raise ValueError('Fitness proportionate selection is not valid for minimization.')\n    \n    # Set up the roulette wheel\n    if pop_max_fit == pop_min_fit:\n        psum = [(index + 1) / float(len_pop) for index in range(len_pop)]\n    elif (pop_max_fit > 0 and pop_min_fit >= 0) or (pop_max_fit <= 0 and pop_min_fit < 0):\n        population.sort(reverse=True)\n        psum[0] = population[0].fitness\n        for i in range(1, len_pop):\n            psum[i] = population[i].fitness + psum[i-1]\n        for i in range(len_pop):\n            psum[i] /= float(psum[len_pop-1])\n            \n    # Select the individuals\n    selected = []\n    for _ in range(num_selected):\n        cutoff = random.random()\n        lower = 0\n        upper = len_pop - 1\n        while(upper >= lower):\n            mid = (lower + upper) // 2\n            if psum[mid] > cutoff: \n                upper = mid - 1\n            else: \n                lower = mid + 1\n        lower = max(0, min(len_pop-1, lower))\n        selected.append(population[lower])\n    return selected"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a rank-based sampling of individuals from the population. This function behaves similarly to fitness proportionate selection, except that it uses the individual's rank in the population, rather than its raw fitness value, to determine its probability. This means that it can be used for both maximization and minimization problems, since higher rank can be defined correctly for both. .. Arguments: random -- the random number generator object population -- the population of individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *num_selected* -- the number of individuals to be selected (default 1)", "response": "def rank_selection(random, population, args):\n    \"\"\"Return a rank-based sampling of individuals from the population.\n    \n    This function behaves similarly to fitness proportionate selection,\n    except that it uses the individual's rank in the population, rather\n    than its raw fitness value, to determine its probability. This\n    means that it can be used for both maximization and minimization \n    problems, since higher rank can be defined correctly for both.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *num_selected* -- the number of individuals to be selected (default 1)\n    \n    \"\"\"\n    num_selected = args.setdefault('num_selected', 1)\n\n    # Set up the roulette wheel\n    len_pop = len(population)\n    population.sort()\n    psum = list(range(len_pop))\n    den = (len_pop * (len_pop + 1)) / 2.0\n    for i in range(len_pop):\n        psum[i] = (i + 1) / den\n    for i in range(1, len_pop):\n        psum[i] += psum[i-1]\n        \n    # Select the individuals\n    selected = []\n    for _ in range(num_selected):\n        cutoff = random.random()\n        lower = 0\n        upper = len_pop - 1\n        while(upper >= lower):\n            mid = (lower + upper) // 2\n            if psum[mid] > cutoff: \n                upper = mid - 1\n            else: \n                lower = mid + 1\n        lower = max(0, min(len_pop-1, lower))\n        selected.append(population[lower])\n    return selected"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a tournament sampling of individuals from the population. This function selects ``num_selected`` individuals from the population. It selects each one by using random sampling without replacement to pull ``tournament_size`` individuals and adds the best of the tournament as its selection. If ``tournament_size`` is greater than the population size, the population size is used instead as the size of the tournament. .. Arguments: random -- the random number generator object population -- the population of individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *num_selected* -- the number of individuals to be selected (default 1) - *tournament_size* -- the tournament size (default 2)", "response": "def tournament_selection(random, population, args):\n    \"\"\"Return a tournament sampling of individuals from the population.\n    \n    This function selects ``num_selected`` individuals from the population. \n    It selects each one by using random sampling without replacement\n    to pull ``tournament_size`` individuals and adds the best of the\n    tournament as its selection. If ``tournament_size`` is greater than\n    the population size, the population size is used instead as the size\n    of the tournament.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *num_selected* -- the number of individuals to be selected (default 1)\n    - *tournament_size* -- the tournament size (default 2)\n    \n    \"\"\"\n    num_selected = args.setdefault('num_selected', 1)\n    tournament_size = args.setdefault('tournament_size', 2)\n    if tournament_size > len(population):\n        tournament_size = len(population)\n    selected = []\n    for _ in range(num_selected):\n        tourn = random.sample(population, tournament_size)\n        selected.append(max(tourn))\n    return selected"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints the best individual in the population to the screen.", "response": "def best_observer(population, num_generations, num_evaluations, args):\n    \"\"\"Print the best individual in the population to the screen.\n    \n    This function displays the best individual in the population to \n    the screen. \n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    \"\"\"\n    print(\"Best Individual: {0}\\n\".format(str(max(population))))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stats_observer(population, num_generations, num_evaluations, args):\n    stats = inspyred.ec.analysis.fitness_statistics(population)\n    worst_fit = '{0:>10}'.format(stats['worst'])[:10]\n    best_fit = '{0:>10}'.format(stats['best'])[:10]\n    avg_fit = '{0:>10}'.format(stats['mean'])[:10]\n    med_fit = '{0:>10}'.format(stats['median'])[:10]\n    std_fit = '{0:>10}'.format(stats['std'])[:10]\n            \n    print('Generation Evaluation      Worst       Best     Median    Average    Std Dev')\n    print('---------- ---------- ---------- ---------- ---------- ---------- ----------')\n    print('{0:>10} {1:>10} {2:>10} {3:>10} {4:>10} {5:>10} {6:>10}\\n'.format(num_generations, \n                                                                             num_evaluations, \n                                                                             worst_fit, \n                                                                             best_fit, \n                                                                             med_fit, \n                                                                             avg_fit, \n                                                                             std_fit))", "response": "This function displays the statistics of the evolutionary computation in the screen."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints the current population of the evolutionary computation to the screen. This function displays the current population of the evolutionary computation to the screen in fitness-sorted order. .. Arguments: population -- the population of Individuals num_generations -- the number of elapsed generations num_evaluations -- the number of candidate solution evaluations args -- a dictionary of keyword arguments", "response": "def population_observer(population, num_generations, num_evaluations, args):\n    \"\"\"Print the current population of the evolutionary computation to the screen.\n    \n    This function displays the current population of the evolutionary \n    computation to the screen in fitness-sorted order. \n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    \"\"\"\n    population.sort(reverse=True)\n    print('----------------------------------------------------------------------------')\n    print('                            Current Population')\n    print('----------------------------------------------------------------------------')\n    for ind in population:\n        print(str(ind))\n    print('----------------------------------------------------------------------------')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_observer(population, num_generations, num_evaluations, args):\n    try:\n        statistics_file = args['statistics_file']\n    except KeyError:\n        statistics_file = open('inspyred-statistics-file-{0}.csv'.format(time.strftime('%m%d%Y-%H%M%S')), 'w')\n        args['statistics_file'] = statistics_file\n    try:\n        individuals_file = args['individuals_file']\n    except KeyError:\n        individuals_file = open('inspyred-individuals-file-{0}.csv'.format(time.strftime('%m%d%Y-%H%M%S')), 'w')\n        args['individuals_file'] = individuals_file\n\n    stats = inspyred.ec.analysis.fitness_statistics(population)\n    worst_fit = stats['worst']\n    best_fit = stats['best']\n    avg_fit = stats['mean']\n    med_fit = stats['median']\n    std_fit = stats['std']\n    \n    statistics_file.write('{0}, {1}, {2}, {3}, {4}, {5}, {6}\\n'.format(num_generations, len(population), worst_fit, best_fit, med_fit, avg_fit, std_fit))\n    for i, p in enumerate(population):\n        individuals_file.write('{0}, {1}, {2}, {3}\\n'.format(num_generations, i, p.fitness, str(p.candidate)))\n    statistics_file.flush()\n    individuals_file.flush()", "response": "This function is used to save the output of the evolutionary computation to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the current archive to the screen. This function displays the current archive of the evolutionary computation to the screen. .. Arguments: population -- the population of Individuals num_generations -- the number of elapsed generations num_evaluations -- the number of candidate solution evaluations args -- a dictionary of keyword arguments", "response": "def archive_observer(population, num_generations, num_evaluations, args):\n    \"\"\"Print the current archive to the screen.\n    \n    This function displays the current archive of the evolutionary \n    computation to the screen. \n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n       \n    \"\"\"\n    archive = args['_ec'].archive\n    print('----------------------------------------------------------------------------')\n    print('                         Archive ({0:5} individuals)'.format(len(archive)))\n    print('----------------------------------------------------------------------------')\n    for a in archive:\n        print(a)\n    print('----------------------------------------------------------------------------')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_observer(population, num_generations, num_evaluations, args):    \n    import matplotlib.pyplot as plt\n    import numpy\n    \n    stats = inspyred.ec.analysis.fitness_statistics(population)\n    best_fitness = stats['best']\n    worst_fitness = stats['worst']\n    median_fitness = stats['median']\n    average_fitness = stats['mean']\n    colors = ['black', 'blue', 'green', 'red']\n    labels = ['average', 'median', 'best', 'worst']\n    data = []\n    if num_generations == 0:\n        plt.ion()\n        data = [[num_evaluations], [average_fitness], [median_fitness], [best_fitness], [worst_fitness]]\n        lines = []\n        for i in range(4):\n            line, = plt.plot(data[0], data[i+1], color=colors[i], label=labels[i])\n            lines.append(line)\n        # Add the legend when the first data is added.\n        plt.legend(loc='lower right')\n        args['plot_data'] = data\n        args['plot_lines'] = lines\n        plt.xlabel('Evaluations')\n        plt.ylabel('Fitness')\n    else:\n        data = args['plot_data']\n        data[0].append(num_evaluations)\n        data[1].append(average_fitness)\n        data[2].append(median_fitness)\n        data[3].append(best_fitness)\n        data[4].append(worst_fitness)\n        lines = args['plot_lines']\n        for i, line in enumerate(lines):\n            line.set_xdata(numpy.array(data[0]))\n            line.set_ydata(numpy.array(data[i+1]))\n        args['plot_data'] = data\n        args['plot_lines'] = lines\n    ymin = min([min(d) for d in data[1:]])\n    ymax = max([max(d) for d in data[1:]])\n    yrange = ymax - ymin\n    plt.xlim((0, num_evaluations))\n    plt.ylim((ymin - 0.1*yrange, ymax + 0.1*yrange))\n    plt.draw()", "response": "This function plots the output of the evolutionary computation as a line graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef diversity_termination(population, num_generations, num_evaluations, args):\n    min_diversity = args.setdefault('min_diversity', 0.001)\n    cart_prod = itertools.product(population, population)\n    distance = []\n    for (p, q) in cart_prod:\n        d = 0\n        for x, y in zip(p.candidate, q.candidate):\n            d += (x - y)**2\n        distance.append(math.sqrt(d))\n    return max(distance) < min_diversity", "response": "Return True if the population diversity is less than a minimum diversity."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the average fitness of the candidate solution is near its best fitness.", "response": "def average_fitness_termination(population, num_generations, num_evaluations, args):\n    \"\"\"Return True if the population's average fitness is near its best fitness.\n    \n    This function calculates the average fitness of the population, as well\n    as the best fitness. If the difference between those values is less \n    than a specified tolerance, the function returns True. \n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    Optional keyword arguments in args:\n    \n    - *tolerance* -- the minimum allowable difference between average \n      and best fitness (default 0.001)\n    \n    \"\"\"\n    tolerance = args.setdefault('tolerance', 0.001)\n    avg_fit = sum([x.fitness for x in population]) / float(len(population))\n    best_fit = max([x.fitness for x in population])\n    return (best_fit - avg_fit) < tolerance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the number of candidate solution evaluations meets or exceeds a maximum.", "response": "def evaluation_termination(population, num_generations, num_evaluations, args):\n    \"\"\"Return True if the number of function evaluations meets or exceeds a maximum.\n    \n    This function compares the number of function evaluations that have been \n    generated with a specified maximum. It returns True if the maximum is met\n    or exceeded.\n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    Optional keyword arguments in args:\n    \n    - *max_evaluations* -- the maximum candidate solution evaluations (default \n      len(population)) \n    \n    \"\"\"\n    max_evaluations = args.setdefault('max_evaluations', len(population))\n    return num_evaluations >= max_evaluations"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the number of generations meets or exceeds a maximum. This function compares the number of generations with a specified maximum. It returns True if the maximum is met or exceeded. .. Arguments: population -- the population of Individuals num_generations -- the number of elapsed generations num_evaluations -- the number of candidate solution evaluations args -- a dictionary of keyword arguments Optional keyword arguments in args: - *max_generations* -- the maximum generations (default 1)", "response": "def generation_termination(population, num_generations, num_evaluations, args):\n    \"\"\"Return True if the number of generations meets or exceeds a maximum.\n    \n    This function compares the number of generations with a specified \n    maximum. It returns True if the maximum is met or exceeded.\n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    Optional keyword arguments in args:\n    \n    - *max_generations* -- the maximum generations (default 1) \n    \n    \"\"\"\n    max_generations = args.setdefault('max_generations', 1)\n    return num_generations >= max_generations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the elapsed time meets or exceeds a duration of time. This function compares the elapsed time with a specified maximum. It returns True if the maximum is met or exceeded. If the `start_time` keyword argument is omitted, it defaults to `None` and will be set to the current system time (in seconds). If the `max_time` keyword argument is omitted, it will default to `None` and will immediately terminate. The `max_time` argument can be specified in seconds as a floating-point number, as minutes/seconds as a two-element tuple of floating-point numbers, or as hours/minutes/seconds as a three-element tuple of floating-point numbers. .. Arguments: population -- the population of Individuals num_generations -- the number of elapsed generations num_evaluations -- the number of candidate solution evaluations args -- a dictionary of keyword arguments Optional keyword arguments in args: - *start_time* -- the time from which to start measuring (default None) - *max_time* -- the maximum time that should elapse (default None)", "response": "def time_termination(population, num_generations, num_evaluations, args):\n    \"\"\"Return True if the elapsed time meets or exceeds a duration of time.\n    \n    This function compares the elapsed time with a specified maximum. \n    It returns True if the maximum is met or exceeded. If the `start_time`\n    keyword argument is omitted, it defaults to `None` and will be set to\n    the current system time (in seconds). If the `max_time` keyword argument\n    is omitted, it will default to `None` and will immediately terminate.\n    The `max_time` argument can be specified in seconds as a floating-point\n    number, as minutes/seconds as a two-element tuple of floating-point\n    numbers, or as hours/minutes/seconds as a three-element tuple of \n    floating-point numbers.\n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    Optional keyword arguments in args:\n    \n    - *start_time* -- the time from which to start measuring (default None)\n    - *max_time* -- the maximum time that should elapse (default None)\n    \n    \"\"\"\n    start_time = args.setdefault('start_time', None)\n    max_time = args.setdefault('max_time', None)\n    logging = args.get('_ec').logger\n\n    if start_time is None:\n        start_time = time.time()\n        args['start_time'] = start_time\n        logging.debug('time_termination terminator added without setting the start_time argument; setting start_time to current time')\n    if max_time is None:\n        logging.debug('time_termination terminator added without setting the max_time argument; terminator will immediately terminate')\n    else:\n        try:\n            max_time = max_time[0] * 3600.0 + max_time[1] * 60.00 + max_time[2]\n            args['max_time'] = max_time\n        except TypeError:\n            pass\n        except IndexError:\n            max_time = max_time[0] * 60 + max_time[1]\n            args['max_time'] = max_time\n    time_elapsed = time.time() - start_time\n    return max_time is None or time_elapsed >= max_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef user_termination(population, num_generations, num_evaluations, args):\n    def getch():\n        unix = ('darwin', 'linux2')\n        if sys.platform not in unix:\n            try:\n                import msvcrt\n            except ImportError:\n                return -1\n            if msvcrt.kbhit():\n                return msvcrt.getch()\n            else:\n                return -1\n        elif sys.platform in unix:\n            def _getch(stdscr):\n                stdscr.nodelay(1)\n                ch = stdscr.getch()\n                stdscr.nodelay(0)\n                return ch\n            import curses\n            return curses.wrapper(_getch)\n    \n    num_secs = args.get('termination_response_timeout', 5)\n    clear_buffer = args.get('clear_termination_buffer', True)\n    if clear_buffer:\n        while getch() > -1:\n            pass\n    sys.stdout.write('Press ESC to terminate (%d secs):' % num_secs)\n    count = 1\n    start = time.time()\n    while time.time() - start < num_secs:\n        ch = getch()\n        if ch > -1 and ord(ch) == 27:\n            sys.stdout.write('\\n\\n')\n            return True\n        elif time.time() - start == count:\n            sys.stdout.write('.')\n            count += 1\n    sys.stdout.write('\\n')\n    return False", "response": "This function returns True if the user presses the ESC key when prompted and if it does not terminate the evolution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the current best fitness does not change for a number of generations.", "response": "def no_improvement_termination(population, num_generations, num_evaluations, args):\n    \"\"\"Return True if the best fitness does not change for a number of generations.\n    \n    This function keeps track of the current best fitness and compares it to\n    the best fitness in previous generations. Whenever those values are the \n    same, it begins a generation count. If that count exceeds a specified \n    number, the terminator returns True.\n    \n    .. Arguments:\n       population -- the population of Individuals\n       num_generations -- the number of elapsed generations\n       num_evaluations -- the number of candidate solution evaluations\n       args -- a dictionary of keyword arguments\n    \n    Optional keyword arguments in args:\n    \n    - *max_generations* -- the number of generations allowed for no change in fitness (default 10)\n    \n    \"\"\"\n    max_generations = args.setdefault('max_generations', 10)\n    previous_best = args.setdefault('previous_best', None)\n    current_best = max(population).fitness\n    if previous_best is None or previous_best != current_best:\n        args['previous_best'] = current_best\n        args['generation_count'] = 0\n        return False\n    else:\n        if args['generation_count'] >= max_generations:\n            return True\n        else:\n            args['generation_count'] += 1\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a globally optimal solution to this problem.", "response": "def global_optimum(self):\n        \"\"\"Return a globally optimal solution to this problem.\n        \n        This function returns a globally optimal solution (i.e., a \n        solution that lives on the Pareto front). Since there are many\n        solutions that are Pareto-optimal, this function randomly \n        chooses one to return.\n        \n        \"\"\"\n        x = [random.uniform(0, 1) for _ in range(self.objectives - 1)]\n        x.extend([0.5 for _ in range(self.dimensions - self.objectives + 1)])\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a candidate solution for an evolutionary computation.", "response": "def generator(self, random, args):\n        \"\"\"Return a candidate solution for an evolutionary computation.\"\"\"\n        locations = [i for i in range(len(self.weights))]\n        random.shuffle(locations)\n        return locations"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef constructor(self, random, args):\n        self._use_ants = True\n        candidate = []\n        while len(candidate) < len(self.weights) - 1:\n            # Find feasible components\n            feasible_components = []\n            if len(candidate) == 0:\n                feasible_components = self.components\n            elif len(candidate) == len(self.weights) - 1:\n                first = candidate[0]\n                last = candidate[-1]\n                feasible_components = [c for c in self.components if c.element[0] == last.element[1] and c.element[1] == first.element[0]]\n            else:\n                last = candidate[-1]\n                already_visited = [c.element[0] for c in candidate]\n                already_visited.extend([c.element[1] for c in candidate])\n                already_visited = set(already_visited)\n                feasible_components = [c for c in self.components if c.element[0] == last.element[1] and c.element[1] not in already_visited]\n            if len(feasible_components) == 0:\n                candidate = []\n            else:\n                # Choose a feasible component\n                if random.random() <= self.bias:\n                    next_component = max(feasible_components)\n                else:\n                    next_component = selectors.fitness_proportionate_selection(random, feasible_components, {'num_selected': 1})[0]\n                candidate.append(next_component)\n        return candidate", "response": "Return a candidate solution for an ant colony optimization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the fitness values for the given candidates.", "response": "def evaluator(self, candidates, args):\n        \"\"\"Return the fitness values for the given candidates.\"\"\"\n        fitness = []\n        if self._use_ants:\n            for candidate in candidates:\n                total = 0\n                for c in candidate:\n                    total += self.weights[c.element[0]][c.element[1]]\n                last = (candidate[-1].element[1], candidate[0].element[0])\n                total += self.weights[last[0]][last[1]]\n                fitness.append(1 / total)\n        else:\n            for candidate in candidates:\n                total = 0\n                for src, dst in zip(candidate, candidate[1:] + [candidate[0]]):\n                    total += self.weights[src][dst]\n                fitness.append(1 / total)\n        return fitness"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a candidate solution for an evolutionary computation.", "response": "def generator(self, random, args):\n        \"\"\"Return a candidate solution for an evolutionary computation.\"\"\"\n        if self.duplicates:\n            max_count = [self.capacity // item[0] for item in self.items]\n            return [random.randint(0, m) for m in max_count]\n        else:\n            return [random.choice([0, 1]) for _ in range(len(self.items))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a candidate solution for an ant colony optimization.", "response": "def constructor(self, random, args):\n        \"\"\"Return a candidate solution for an ant colony optimization.\"\"\"\n        self._use_ants = True\n        candidate = []\n        while len(candidate) < len(self.components):\n            # Find feasible components\n            feasible_components = []\n            if len(candidate) == 0:\n                feasible_components = self.components\n            else:\n                remaining_capacity = self.capacity - sum([c.element for c in candidate])\n                if self.duplicates:\n                    feasible_components = [c for c in self.components if c.element <= remaining_capacity]\n                else:\n                    feasible_components = [c for c in self.components if c not in candidate and c.element <= remaining_capacity]\n            if len(feasible_components) == 0:\n                break\n            else:\n                # Choose a feasible component\n                if random.random() <= self.bias:\n                    next_component = max(feasible_components)\n                else:\n                    next_component = selectors.fitness_proportionate_selection(random, feasible_components, {'num_selected': 1})[0]\n                candidate.append(next_component)\n        return candidate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating the fitness values for the given candidates.", "response": "def evaluator(self, candidates, args):\n        \"\"\"Return the fitness values for the given candidates.\"\"\"\n        fitness = []\n        if self._use_ants:\n            for candidate in candidates:\n                total = 0\n                for c in candidate:\n                    total += c.value\n                fitness.append(total)\n        else:\n            for candidate in candidates:\n                total_value = 0\n                total_weight = 0\n                for c, i in zip(candidate, self.items):\n                    total_weight += c * i[0]\n                    total_value += c * i[1]\n                if total_weight > self.capacity:\n                    fitness.append(self.capacity - total_weight)\n                else:\n                    fitness.append(total_value)\n        return fitness"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an inspyred crossover function based on the given function.", "response": "def crossover(cross):\n    \"\"\"Return an inspyred crossover function based on the given function.\n\n    This function generator takes a function that operates on only\n    two parent candidates to produce an iterable sequence of offspring\n    (typically two). The generator handles the pairing of selected\n    parents and collecting of all offspring.\n\n    The generated function chooses every odd candidate as a 'mom' and\n    every even as a 'dad' (discounting the last candidate if there is\n    an odd number). For each mom-dad pair, offspring are produced via\n    the `cross` function.\n\n    The given function ``cross`` must have the following signature::\n\n        offspring = cross(random, mom, dad, args)\n\n    This function is most commonly used as a function decorator with\n    the following usage::\n\n        @crossover\n        def cross(random, mom, dad, args):\n            # Implementation of paired crossing\n            pass\n\n    The generated function also contains an attribute named\n    ``single_crossover`` which holds the original crossover function.\n    In this way, the original single-set-of-parents function can be\n    retrieved if necessary.\n\n    \"\"\"\n    @functools.wraps(cross)\n    def inspyred_crossover(random, candidates, args):\n        if len(candidates) % 2 == 1:\n            candidates = candidates[:-1]\n        moms = candidates[::2]\n        dads = candidates[1::2]\n        children = []\n        for i, (mom, dad) in enumerate(zip(moms, dads)):\n            cross.index = i\n            offspring = cross(random, mom, dad, args)\n            for o in offspring:\n                children.append(o)\n        return children\n    inspyred_crossover.single_crossover = cross\n    return inspyred_crossover"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the offspring of n-point crossover on the candidates. This function performs n-point crossover (NPX). It selects *n* random points without replacement at which to 'cut' the candidate solutions and recombine them. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0) - *num_crossover_points* -- the number of crossover points used (default 1)", "response": "def n_point_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of n-point crossover on the candidates.\n\n    This function performs n-point crossover (NPX). It selects *n* \n    random points without replacement at which to 'cut' the candidate \n    solutions and recombine them.\n\n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n    - *num_crossover_points* -- the number of crossover points used (default 1)\n    \n    \"\"\"\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    num_crossover_points = args.setdefault('num_crossover_points', 1)\n    children = []\n    if random.random() < crossover_rate:\n        num_cuts = min(len(mom)-1, num_crossover_points)\n        cut_points = random.sample(range(1, len(mom)), num_cuts)\n        cut_points.sort()\n        bro = copy.copy(dad)\n        sis = copy.copy(mom)\n        normal = True\n        for i, (m, d) in enumerate(zip(mom, dad)):\n            if i in cut_points:\n                normal = not normal\n            if not normal:\n                bro[i] = m\n                sis[i] = d\n                normal = not normal\n        children.append(bro)\n        children.append(sis)\n    else:\n        children.append(mom)\n        children.append(dad)\n    return children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the offspring of uniform crossover on the candidates. This function performs uniform crossover (UX). For each element of the parents, a biased coin is flipped to determine whether the first offspring gets the 'mom' or the 'dad' element. An optional keyword argument in args, ``ux_bias``, determines the bias. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0) - *ux_bias* -- the bias toward the first candidate in the crossover (default 0.5)", "response": "def uniform_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of uniform crossover on the candidates.\n\n    This function performs uniform crossover (UX). For each element \n    of the parents, a biased coin is flipped to determine whether \n    the first offspring gets the 'mom' or the 'dad' element. An \n    optional keyword argument in args, ``ux_bias``, determines the bias.\n\n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n    - *ux_bias* -- the bias toward the first candidate in the crossover \n      (default 0.5)\n    \n    \"\"\"\n    ux_bias = args.setdefault('ux_bias', 0.5)\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    children = []\n    if random.random() < crossover_rate:\n        bro = copy.copy(dad)\n        sis = copy.copy(mom)\n        for i, (m, d) in enumerate(zip(mom, dad)):\n            if random.random() < ux_bias:\n                bro[i] = m\n                sis[i] = d\n        children.append(bro)\n        children.append(sis)\n    else:\n        children.append(mom)\n        children.append(dad)\n    return children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the offspring of partially matched crossover on the candidates. This function performs partially matched crossover (PMX). This type of crossover assumes that candidates are composed of discrete values that are permutations of a given set (typically integers). It produces offspring that are themselves permutations of the set. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0)", "response": "def partially_matched_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of partially matched crossover on the candidates.\n\n    This function performs partially matched crossover (PMX). This type of\n    crossover assumes that candidates are composed of discrete values that\n    are permutations of a given set (typically integers). It produces offspring\n    that are themselves permutations of the set.\n\n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n\n    \"\"\"\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    if random.random() < crossover_rate:\n        size = len(mom)\n        points = random.sample(range(size), 2)\n        x, y = min(points), max(points)\n        bro = copy.copy(dad)\n        bro[x:y+1] = mom[x:y+1]\n        sis = copy.copy(mom)\n        sis[x:y+1] = dad[x:y+1]\n        for parent, child in zip([dad, mom], [bro, sis]):\n            for i in range(x, y+1):\n                if parent[i] not in child[x:y+1]:\n                    spot = i\n                    while x <= spot <= y:\n                        spot = parent.index(child[spot])\n                    child[spot] = parent[i]\n        return [bro, sis]\n    else:\n        return [mom, dad]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the offspring of arithmetic crossover on the candidates. This function performs arithmetic crossover (AX), which is similar to a generalized weighted averaging of the candidate elements. The allele of each parent is weighted by the *ax_alpha* keyword argument, and the allele of the complement parent is weighted by 1 - *ax_alpha*. This averaging is only done on the alleles listed in the *ax_points* keyword argument. If this argument is ``None``, then all alleles are used. This means that if this function is used with all default values, then offspring are simple averages of their parents. This function also makes use of the bounder function as specified in the EC's ``evolve`` method. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0) - *ax_alpha* -- the weight for the averaging (default 0.5) - *ax_points* -- a list of points specifying the alleles to recombine (default None)", "response": "def arithmetic_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of arithmetic crossover on the candidates.\n\n    This function performs arithmetic crossover (AX), which is similar to a \n    generalized weighted averaging of the candidate elements. The allele\n    of each parent is weighted by the *ax_alpha* keyword argument, and\n    the allele of the complement parent is weighted by 1 - *ax_alpha*.\n    This averaging is only done on the alleles listed in the *ax_points*\n    keyword argument. If this argument is ``None``, then all alleles\n    are used. This means that if this function is used with all default\n    values, then offspring are simple averages of their parents.\n    This function also makes use of the bounder function as specified \n    in the EC's ``evolve`` method.\n\n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n    - *ax_alpha* -- the weight for the averaging (default 0.5)\n    - *ax_points* -- a list of points specifying the alleles to\n      recombine (default None)\n    \n    \"\"\"\n    ax_alpha = args.setdefault('ax_alpha', 0.5)\n    ax_points = args.setdefault('ax_points', None)\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    bounder = args['_ec'].bounder\n    children = []\n    if random.random() < crossover_rate:\n        bro = copy.copy(dad)\n        sis = copy.copy(mom)\n        if ax_points is None:\n            ax_points = list(range(min(len(bro), len(sis))))\n        for i in ax_points:\n            bro[i] = ax_alpha * mom[i] + (1 - ax_alpha) * dad[i]\n            sis[i] = ax_alpha * dad[i] + (1 - ax_alpha) * mom[i]\n        bro = bounder(bro, args)\n        sis = bounder(sis, args)\n        children.append(bro)\n        children.append(sis)\n    else:\n        children.append(mom)\n        children.append(dad)\n    return children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the offspring of blend crossover on the candidates. This function performs blend crossover (BLX), which is similar to arithmetic crossover with a bit of mutation. It creates offspring whose values are chosen randomly from a range bounded by the parent alleles but that is also extended by some amount proportional to the *blx_alpha* keyword argument. It is this extension of the range that provides the additional exploration. This averaging is only done on the alleles listed in the *blx_points* keyword argument. If this argument is ``None``, then all alleles are used. This function also makes use of the bounder function as specified in the EC's ``evolve`` method. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0) - *blx_alpha* -- the blending rate (default 0.1) - *blx_points* -- a list of points specifying the alleles to recombine (default None)", "response": "def blend_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of blend crossover on the candidates.\n\n    This function performs blend crossover (BLX), which is similar to \n    arithmetic crossover with a bit of mutation. It creates offspring\n    whose values are chosen randomly from a range bounded by the\n    parent alleles but that is also extended by some amount proportional\n    to the *blx_alpha* keyword argument. It is this extension of the\n    range that provides the additional exploration. This averaging is \n    only done on the alleles listed in the *blx_points* keyword argument. \n    If this argument is ``None``, then all alleles are used. This function \n    also makes use of the bounder function as specified in the EC's \n    ``evolve`` method.\n\n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n    - *blx_alpha* -- the blending rate (default 0.1)\n    - *blx_points* -- a list of points specifying the alleles to\n      recombine (default None)\n    \n    \"\"\"\n    blx_alpha = args.setdefault('blx_alpha', 0.1)\n    blx_points = args.setdefault('blx_points', None)\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    bounder = args['_ec'].bounder\n    children = []\n    if random.random() < crossover_rate:\n        bro = copy.copy(dad)\n        sis = copy.copy(mom)\n        if blx_points is None:\n            blx_points = list(range(min(len(bro), len(sis))))\n        for i in blx_points:\n            smallest, largest = min(mom[i], dad[i]), max(mom[i], dad[i])\n            delta = blx_alpha * (largest - smallest)\n            bro[i] = smallest - delta + random.random() * (largest - smallest + 2 * delta)\n            sis[i] = smallest - delta + random.random() * (largest - smallest + 2 * delta)\n        bro = bounder(bro, args)\n        sis = bounder(sis, args)\n        children.append(bro)\n        children.append(sis)\n    else:\n        children.append(mom)\n        children.append(dad)\n    return children"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef heuristic_crossover(random, candidates, args):\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    bounder = args['_ec'].bounder\n        \n    if len(candidates) % 2 == 1:\n        candidates = candidates[:-1]\n        \n    # Since we don't have fitness information in the candidates, we need \n    # to make a dictionary containing the candidate and its corresponding \n    # individual in the population.\n    population = list(args['_ec'].population)\n    lookup = dict(zip([pickle.dumps(p.candidate, 1) for p in population], population))\n    \n    moms = candidates[::2]\n    dads = candidates[1::2]\n    children = []\n    for mom, dad in zip(moms, dads):\n        if random.random() < crossover_rate:\n            bro = copy.copy(dad)\n            sis = copy.copy(mom)\n            mom_is_better = lookup[pickle.dumps(mom, 1)] > lookup[pickle.dumps(dad, 1)]\n            for i, (m, d) in enumerate(zip(mom, dad)):\n                negpos = 1 if mom_is_better else -1\n                val = d if mom_is_better else m\n                bro[i] = val + random.random() * negpos * (m - d)\n                sis[i] = val + random.random() * negpos * (m - d)\n            bro = bounder(bro, args)\n            sis = bounder(sis, args)\n            children.append(bro)\n            children.append(sis)\n        else:\n            children.append(mom)\n            children.append(dad)\n    return children", "response": "This function returns the offspring of heuristic crossover on the candidates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the offspring of simulated binary crossover on the candidates. This function performs simulated binary crossover (SBX), following the implementation in NSGA-II `(Deb et al., ICANNGA 1999) <http://vision.ucsd.edu/~sagarwal/icannga.pdf>`_. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0) - *sbx_distribution_index* -- the non-negative distribution index (default 10) A small value of the `sbx_distribution_index` optional argument allows solutions far away from parents to be created as child solutions, while a large value restricts only near-parent solutions to be created as child solutions.", "response": "def simulated_binary_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of simulated binary crossover on the candidates.\n    \n    This function performs simulated binary crossover (SBX), following the \n    implementation in NSGA-II \n    `(Deb et al., ICANNGA 1999) <http://vision.ucsd.edu/~sagarwal/icannga.pdf>`_.\n \n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n\n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n    - *sbx_distribution_index* -- the non-negative distribution index \n      (default 10)\n    \n    A small value of the `sbx_distribution_index` optional argument allows \n    solutions far away from parents to be created as child solutions, \n    while a large value restricts only near-parent solutions to be created as\n    child solutions.\n    \n    \"\"\"\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    if random.random() < crossover_rate:\n        di = args.setdefault('sbx_distribution_index', 10)\n        bounder = args['_ec'].bounder\n        bro = copy.copy(dad)\n        sis = copy.copy(mom)\n        for i, (m, d, lb, ub) in enumerate(zip(mom, dad, bounder.lower_bound, bounder.upper_bound)):\n            try:\n                if m > d:\n                    m, d = d, m\n                beta = 1.0 + 2 * min(m - lb, ub - d) / float(d - m)\n                alpha = 2.0 - 1.0 / beta**(di + 1.0)\n                u = random.random() \n                if u <= (1.0 / alpha):\n                    beta_q = (u * alpha)**(1.0 / float(di + 1.0))\n                else:\n                    beta_q = (1.0 / (2.0 - u * alpha))**(1.0 / float(di + 1.0))\n                bro_val = 0.5 * ((m + d) - beta_q * (d - m))\n                bro_val = max(min(bro_val, ub), lb)        \n                sis_val = 0.5 * ((m + d) + beta_q * (d - m))\n                sis_val = max(min(sis_val, ub), lb)\n                if random.random() > 0.5:\n                    bro_val, sis_val = sis_val, bro_val\n                bro[i] = bro_val\n                sis[i] = sis_val\n            except ZeroDivisionError:\n                # The offspring already have legitimate values for every element,\n                # so no need to take any special action here.\n                pass\n        return [bro, sis]\n    else:\n        return [mom, dad]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the offspring of Laplace crossover on the candidates. This function performs Laplace crosssover (LX), following the implementation specified in (Deep and Thakur, \"A new crossover operator for real coded genetic algorithms,\" Applied Mathematics and Computation, Volume 188, Issue 1, May 2007, pp. 895--911). This function also makes use of the bounder function as specified in the EC's ``evolve`` method. .. Arguments: random -- the random number generator object mom -- the first parent candidate dad -- the second parent candidate args -- a dictionary of keyword arguments Optional keyword arguments in args: - *crossover_rate* -- the rate at which crossover is performed (default 1.0) - *lx_location* -- the location parameter (default 0) - *lx_scale* -- the scale parameter (default 0.5) In some sense, the *lx_location* and *lx_scale* parameters can be thought of as analogs in a Laplace distribution to the mean and standard deviation of a Gaussian distribution. If *lx_scale* is near zero, offspring will be produced near the parents. If *lx_scale* is farther from zero, offspring will be produced far from the parents.", "response": "def laplace_crossover(random, mom, dad, args):\n    \"\"\"Return the offspring of Laplace crossover on the candidates.\n    \n    This function performs Laplace crosssover (LX), following the \n    implementation specified in (Deep and Thakur, \"A new crossover \n    operator for real coded genetic algorithms,\" Applied Mathematics \n    and Computation, Volume 188, Issue 1, May 2007, pp. 895--911).\n    This function also makes use of the bounder function as specified \n    in the EC's ``evolve`` method.    \n \n    .. Arguments:\n       random -- the random number generator object\n       mom -- the first parent candidate\n       dad -- the second parent candidate\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *crossover_rate* -- the rate at which crossover is performed \n      (default 1.0)\n    - *lx_location* -- the location parameter (default 0)\n    - *lx_scale* -- the scale parameter (default 0.5)\n    \n    In some sense, the *lx_location* and *lx_scale* parameters can be thought \n    of as analogs in a Laplace distribution to the mean and standard \n    deviation of a Gaussian distribution. If *lx_scale* is near zero, offspring \n    will be produced near the parents. If *lx_scale* is farther from zero, \n    offspring will be produced far from the parents.\n    \n    \"\"\"\n    crossover_rate = args.setdefault('crossover_rate', 1.0)\n    if random.random() < crossover_rate:\n        bounder = args['_ec'].bounder\n        a = args.setdefault('lx_location', 0)\n        b = args.setdefault('lx_scale', 0.5)\n        bro = copy.copy(dad)\n        sis = copy.copy(mom)\n        for i, (m, d) in enumerate(zip(mom, dad)):\n            u = random.random()\n            if random.random() <= 0.5:\n                beta = a - b * math.log(u)\n            else:\n                beta = a + b * math.log(u)\n            bro[i] = m + beta * abs(m - d)\n            sis[i] = d + beta * abs(m - d)\n        bro = bounder(bro, args)\n        sis = bounder(sis, args)\n        return [bro, sis]\n    else:\n        return [mom, dad]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fitness_statistics(population):\n    population.sort(reverse=True)\n    worst_fit = population[-1].fitness\n    best_fit = population[0].fitness\n    try:\n        import numpy\n        f = [p.fitness for p in population]\n        med_fit = numpy.median(f)\n        avg_fit = numpy.mean(f)\n        std_fit = numpy.std(f)\n    except ImportError:\n        try:\n            plen = len(population)\n            if plen % 2 == 1:\n                med_fit = population[(plen - 1) // 2].fitness\n            else:\n                med_fit = float(population[plen // 2 - 1].fitness + population[plen // 2].fitness) / 2\n            avg_fit = sum([p.fitness for p in population]) / float(plen)\n            if plen > 1:\n                std_fit = math.sqrt(sum([(p.fitness - avg_fit)**2 for p in population]) / float(plen - 1))\n            else:\n                std_fit = 0\n        except TypeError:\n            med_fit = float('nan')\n            avg_fit = float('nan')\n            std_fit = float('nan')\n    return {'best': best_fit, 'worst': worst_fit, 'mean': avg_fit, \n            'median': med_fit, 'std': std_fit}", "response": "Return the basic statistics of the fitness values in the given population."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the results of the algorithm using generation statistics. This function creates a plot of the generation fitness statistics (best, worst, median, and average). This function requires the matplotlib library. .. note:: This function only works for single-objective problems. .. figure:: _static/generation_plot.png :alt: Example generation plot :align: center An example image saved from the ``generation_plot`` function (without error bars). Arguments: - *file* -- a file-like object representing the statistics file produced by the file_observer - *errorbars* -- Boolean value stating whether standard error bars should be drawn (default True)", "response": "def generation_plot(file, errorbars=True):\n    \"\"\"Plot the results of the algorithm using generation statistics.\n    \n    This function creates a plot of the generation fitness statistics \n    (best, worst, median, and average). This function requires the \n    matplotlib library.\n    \n    .. note::\n    \n       This function only works for single-objective problems.\n\n    .. figure:: _static/generation_plot.png\n        :alt: Example generation plot\n        :align: center\n        \n        An example image saved from the ``generation_plot`` function (without error bars).\n    \n    Arguments:\n    \n    - *file* -- a file-like object representing the statistics file \n      produced by the file_observer \n    - *errorbars* -- Boolean value stating whether standard error bars should \n      be drawn (default True)\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import matplotlib.font_manager \n    \n    generation = []\n    psize = []\n    worst = []\n    best = []\n    median = []\n    average = []\n    stdev = []\n    reader = csv.reader(file)\n    for row in reader:\n        generation.append(int(row[0]))\n        psize.append(int(row[1]))\n        worst.append(float(row[2]))\n        best.append(float(row[3]))\n        median.append(float(row[4]))\n        average.append(float(row[5]))\n        stdev.append(float(row[6]))\n    stderr = [s / math.sqrt(p) for s, p in zip(stdev, psize)]\n    \n    data = [average, median, best, worst]\n    colors = ['black', 'blue', 'green', 'red']\n    labels = ['average', 'median', 'best', 'worst']\n    figure = plt.figure()\n    if errorbars:\n        plt.errorbar(generation, average, stderr, color=colors[0], label=labels[0])\n    else:\n        plt.plot(generation, average, color=colors[0], label=labels[0])\n    for d, col, lab in zip(data[1:], colors[1:], labels[1:]):\n        plt.plot(generation, d, color=col, label=lab)\n    plt.fill_between(generation, data[2], data[3], color='#e6f2e6')\n    plt.grid(True)\n    ymin = min([min(d) for d in data])\n    ymax = max([max(d) for d in data])\n    yrange = ymax - ymin\n    plt.ylim((ymin - 0.1*yrange, ymax + 0.1*yrange))  \n    prop = matplotlib.font_manager.FontProperties(size=8) \n    plt.legend(loc='upper left', prop=prop)    \n    plt.xlabel('Generation')\n    plt.ylabel('Fitness')\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the alleles from each generation from the individuals file. This function creates a plot of the individual allele values as they change through the generations. It creates three subplots, one for each of the best, median, and average individual. The best and median individuals are chosen using the fitness data for each generation. The average individual, on the other hand, is actually an individual created by averaging the alleles within a generation. This function requires the matplotlib library. .. note:: This function only works for single-objective problems. .. figure:: _static/allele_plot.png :alt: Example allele plot :align: center An example image saved from the ``allele_plot`` function. Arguments: - *file* -- a file-like object representing the individuals file produced by the file_observer - *normalize* -- Boolean value stating whether allele values should be normalized before plotting (default False) - *alleles* -- a list of allele index values that should be plotted (default None) - *generations* -- a list of generation numbers that should be plotted (default None) If *alleles* is ``None``, then all alleles are plotted. Similarly, if *generations* is ``None``, then all generations are plotted.", "response": "def allele_plot(file, normalize=False, alleles=None, generations=None):\n    \"\"\"Plot the alleles from each generation from the individuals file.\n    \n    This function creates a plot of the individual allele values as they\n    change through the generations. It creates three subplots, one for each\n    of the best, median, and average individual. The best and median \n    individuals are chosen using the fitness data for each generation. The \n    average individual, on the other hand, is actually an individual created\n    by averaging the alleles within a generation. This function requires the \n    matplotlib library.\n\n    .. note::\n    \n       This function only works for single-objective problems.\n\n    .. figure:: _static/allele_plot.png\n        :alt: Example allele plot\n        :align: center\n        \n        An example image saved from the ``allele_plot`` function.\n    \n    Arguments:\n    \n    - *file* -- a file-like object representing the individuals file \n      produced by the file_observer \n    - *normalize* -- Boolean value stating whether allele values should be\n      normalized before plotting (default False)\n    - *alleles* -- a list of allele index values that should be plotted\n      (default None)\n    - *generations* -- a list of generation numbers that should be plotted\n      (default None)\n\n    If *alleles* is ``None``, then all alleles are plotted. Similarly, if \n    *generations* is ``None``, then all generations are plotted.\n\n    \"\"\"    \n    import matplotlib.pyplot as plt\n    \n    generation_data = []\n    reader = csv.reader(open(file))\n    for row in reader:\n        g = int(row[0])\n        row[3] = row[3].replace('[', '')\n        row[-1] = row[-1].replace(']', '')\n        individual = [float(r) for r in row[3:]]\n        individual.append(float(row[2]))\n        try:\n            generation_data[g]\n        except IndexError:\n            generation_data.append([])\n        generation_data[g].append(individual)\n    for gen in generation_data:\n        gen.sort(key=lambda x: x[-1])\n        for j, g in enumerate(gen):\n            gen[j] = g[:-1]\n        \n    best = []\n    median = []\n    average = []\n    for gen in generation_data:\n        best.append(gen[0])\n        plen = len(gen)\n        if plen % 2 == 1:\n            med = gen[(plen - 1) // 2]\n        else:\n            med = []\n            for a, b in zip(gen[plen // 2 - 1], gen[plen // 2]):\n                med.append(float(a + b) / 2)\n        median.append(med)\n        avg = [0] * len(gen[0])\n        for individual in gen:\n            for i, allele in enumerate(individual):\n                avg[i] += allele\n        for i, a in enumerate(avg):\n            avg[i] /= float(len(gen))\n        average.append(avg)        \n    \n    for plot_num, (data, title) in enumerate(zip([best, median, average], \n                                                 [\"Best\", \"Median\", \"Average\"])):\n        if alleles is None:\n            alleles = list(range(len(data[0])))\n        if generations is None:\n            generations = list(range(len(data)))    \n        if normalize:\n            columns = list(zip(*data))\n            max_col = [max(c) for c in columns]\n            min_col = [min(c) for c in columns]\n            for dat in data:\n                for i, d in enumerate(dat):\n                    dat[i] = (d - min_col[i]) / float(max_col[i] - min_col[i])\n        plot_data = []\n        for g in generations:\n            plot_data.append([data[g][a] for a in alleles])\n        sub = plt.subplot(3, 1, plot_num + 1)\n        plt.pcolor(plt.array(plot_data))\n        plt.colorbar()\n        step_size = max(len(generations) // 7, 1)\n        ytick_locs = list(range(step_size, len(generations), step_size))\n        ytick_labs = generations[step_size::step_size]\n        plt.yticks(ytick_locs, ytick_labs)\n        plt.ylabel('Generation')\n        if plot_num == 2:\n            xtick_locs = list(range(len(alleles)))\n            xtick_labs = alleles\n            plt.xticks(xtick_locs, xtick_labs)\n            plt.xlabel('Allele')\n        else:\n            plt.setp(sub.get_xticklabels(), visible=False)\n        plt.title(title)\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the hypervolume of a nondominated objectives set.", "response": "def hypervolume(pareto_set, reference_point=None):\n    \"\"\"Calculates the hypervolume by slicing objectives (HSO).\n    \n    This function calculates the hypervolume (or S-measure) of a nondominated\n    set using the Hypervolume by Slicing Objectives (HSO) procedure of `While, et al. \n    (IEEE CEC 2005) <http://www.lania.mx/~ccoello/EMOO/while05a.pdf.gz>`_.\n    The *pareto_set* should be a list of lists of objective values.\n    The *reference_point* may be specified or it may be left as the default \n    value of None. In that case, the reference point is calculated to be the\n    maximum value in the set for all objectives (the ideal point). This function \n    assumes that objectives are to be maximized.\n    \n    Arguments:\n    \n    - *pareto_set* -- the list or lists of objective values comprising the Pareto front\n    - *reference_point* -- the reference point to be used (default None)\n    \n    \"\"\"\n    def dominates(p, q, k=None):\n        if k is None:\n            k = len(p)\n        d = True\n        while d and k < len(p):\n            d = not (q[k] > p[k])\n            k += 1\n        return d\n        \n    def insert(p, k, pl):\n        ql = []\n        while pl and pl[0][k] > p[k]:\n            ql.append(pl[0])\n            pl = pl[1:]\n        ql.append(p)\n        while pl:\n            if not dominates(p, pl[0], k):\n                ql.append(pl[0])\n            pl = pl[1:]\n        return ql\n\n    def slice(pl, k, ref):\n        p = pl[0]\n        pl = pl[1:]\n        ql = []\n        s = []\n        while pl:\n            ql = insert(p, k + 1, ql)\n            p_prime = pl[0]\n            s.append((math.fabs(p[k] - p_prime[k]), ql))\n            p = p_prime\n            pl = pl[1:]\n        ql = insert(p, k + 1, ql)\n        s.append((math.fabs(p[k] - ref[k]), ql))\n        return s\n\n    ps = pareto_set\n    ref = reference_point\n    n = min([len(p) for p in ps])\n    if ref is None:\n        ref = [max(ps, key=lambda x: x[o])[o] for o in range(n)]\n    pl = ps[:]\n    pl.sort(key=lambda x: x[0], reverse=True)\n    s = [(1, pl)]\n    for k in range(n - 1):\n        s_prime = []\n        for x, ql in s:\n            for x_prime, ql_prime in slice(ql, k, ref):\n                s_prime.append((x * x_prime, ql_prime))\n        s = s_prime\n    vol = 0\n    for x, ql in s:\n        vol = vol + x * math.fabs(ql[0][n - 1] - ref[n - 1])\n    return vol"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gravitational_force(position_a, mass_a, position_b, mass_b):\n    distance = distance_between(position_a, position_b)\n\n    # Calculate the direction and magnitude of the force.\n    angle = math.atan2(position_a[1] - position_b[1], position_a[0] - position_b[0])\n    magnitude = G * mass_a * mass_b / (distance**2)\n\n    # Find the x and y components of the force.\n    # Determine sign based on which one is the larger body.\n    sign = -1 if mass_b > mass_a else 1\n    x_force = sign * magnitude * math.cos(angle)\n    y_force = sign * magnitude * math.sin(angle)\n    return x_force, y_force", "response": "Returns the gravitational force between the two bodies a and b."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef force_on_satellite(position, mass):\n    earth_grav_force = gravitational_force(position, mass, earth_position, earth_mass)\n    moon_grav_force = gravitational_force(position, mass, moon_position, moon_mass)\n    F_x = earth_grav_force[0] + moon_grav_force[0]\n    F_y = earth_grav_force[1] + moon_grav_force[1]\n    return F_x, F_y", "response": "Returns the total gravitational force acting on the body from the Earth and Moon."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the acceleration based on all forces acting upon the body.", "response": "def acceleration_of_satellite(position, mass):\n    \"\"\"Returns the acceleration based on all forces acting upon the body.\"\"\"\n    F_x, F_y = force_on_satellite(position, mass)\n    return F_x / mass, F_y / mass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef truncation_replacement(random, population, parents, offspring, args):\n    psize = len(population)\n    population.extend(list(offspring))\n    population.sort(reverse=True)\n    return population[:psize]", "response": "This function replaces the current population with the best of the population and offspring."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef steady_state_replacement(random, population, parents, offspring, args):\n    population.sort()\n    num_to_replace = min(len(offspring), len(population))\n    population[:num_to_replace] = offspring[:num_to_replace]\n    return population", "response": "This function performs steady - state replacement for the offspring."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming generational replacement with optional weak elitism. This function performs generational replacement, which means that the entire existing population is replaced by the offspring, truncating to the population size if the number of offspring is larger. Weak elitism may also be specified through the `num_elites` keyword argument in args. If this is used, the best `num_elites` individuals in the current population are allowed to survive if they are better than the worst `num_elites` offspring. .. Arguments: random -- the random number generator object population -- the population of individuals parents -- the list of parent individuals offspring -- the list of offspring individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *num_elites* -- number of elites to consider (default 0)", "response": "def generational_replacement(random, population, parents, offspring, args):\n    \"\"\"Performs generational replacement with optional weak elitism.\n    \n    This function performs generational replacement, which means that\n    the entire existing population is replaced by the offspring,\n    truncating to the population size if the number of offspring is \n    larger. Weak elitism may also be specified through the `num_elites`\n    keyword argument in args. If this is used, the best `num_elites`\n    individuals in the current population are allowed to survive if\n    they are better than the worst `num_elites` offspring.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       parents -- the list of parent individuals\n       offspring -- the list of offspring individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *num_elites* -- number of elites to consider (default 0)\n    \n    \"\"\"\n    num_elites = args.setdefault('num_elites', 0)\n    population.sort(reverse=True)\n    offspring.extend(population[:num_elites])\n    offspring.sort(reverse=True)\n    survivors = offspring[:len(population)]\n    return survivors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform random replacement with optional weak elitism. This function performs random replacement, which means that the offspring replace random members of the population, keeping the population size constant. Weak elitism may also be specified through the `num_elites` keyword argument in args. If this is used, the best `num_elites` individuals in the current population are allowed to survive if they are better than the worst `num_elites` offspring. .. Arguments: random -- the random number generator object population -- the population of individuals parents -- the list of parent individuals offspring -- the list of offspring individuals args -- a dictionary of keyword arguments Optional keyword arguments in args: - *num_elites* -- number of elites to consider (default 0)", "response": "def random_replacement(random, population, parents, offspring, args):\n    \"\"\"Performs random replacement with optional weak elitism.\n    \n    This function performs random replacement, which means that\n    the offspring replace random members of the population, keeping\n    the population size constant. Weak elitism may also be specified \n    through the `num_elites` keyword argument in args. If this is used, \n    the best `num_elites` individuals in the current population are \n    allowed to survive if they are better than the worst `num_elites`\n    offspring.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       parents -- the list of parent individuals\n       offspring -- the list of offspring individuals\n       args -- a dictionary of keyword arguments\n\n    Optional keyword arguments in args:\n    \n    - *num_elites* -- number of elites to consider (default 0)\n    \n    \"\"\"\n    num_elites = args.setdefault('num_elites', 0)\n    population.sort(reverse=True)\n    num_to_replace = min(len(offspring), len(population) - num_elites) \n    valid_indices = range(num_elites, len(population))\n    rep_index = random.sample(valid_indices, num_to_replace)\n    for i, repind in enumerate(rep_index):\n        population[repind] = offspring[i]\n    return population"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plus_replacement(random, population, parents, offspring, args):\n    pool = list(offspring)\n    pool.extend(parents)\n    pool.sort(reverse=True)\n    survivors = pool[:len(population)]\n    return survivors", "response": "This function performs a plus replacement."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef comma_replacement(random, population, parents, offspring, args):\n    offspring.sort(reverse=True)\n    survivors = offspring[:len(population)]\n    return survivors", "response": "This function replaces all the offspring elements in the object with the new ones."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef crowding_replacement(random, population, parents, offspring, args):\n    def distance(x, y):\n        return math.sqrt(sum([(a - b)**2 for a, b in zip(x, y)]))\n    try:\n        distance_function = args['distance_function']\n    except KeyError:\n        distance_function = distance\n        args['distance_function'] = distance_function\n    crowding_distance = args.setdefault('crowding_distance', 2)\n    survivors = population\n    for o in offspring:\n        pool = random.sample(survivors, crowding_distance)\n        closest = min(pool, key=lambda x: distance_function(o.candidate, x.candidate))\n        if o > closest:\n            survivors.remove(closest)\n            survivors.append(o)\n    return survivors", "response": "This function performs crowding replacement as a form of niching."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef simulated_annealing_replacement(random, population, parents, offspring, args):\n    try:\n        temp = args['temperature']\n        cooling_rate = args['cooling_rate']\n        temp = temp * cooling_rate\n        args['temperature'] = temp\n    except KeyError:\n        try:\n            num_evals = args['_ec'].num_evaluations\n            max_evals = args['max_evaluations']\n            temp = float(max_evals - num_evals) / float(max_evals)\n        except KeyError:\n            num_gens = args['_ec'].num_generations\n            max_gens = args['max_generations']\n            temp = 1 - float(max_gens - num_gens) / float(max_gens)\n        \n    new_pop = []\n    for p, o in zip(parents, offspring):\n        if o >= p:\n            new_pop.append(o)\n        elif temp > 0 and random.random() < math.exp(-abs(p.fitness - o.fitness) / float(temp)):\n            new_pop.append(o)\n        else:\n            new_pop.append(p)\n            \n    return new_pop", "response": "This function replaces the population using the simulated annealing replacement."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nsga_replacement(random, population, parents, offspring, args):\n    survivors = []\n    combined = list(population)\n    combined.extend(offspring)\n    \n    # Perform the non-dominated sorting to determine the fronts.\n    fronts = []\n    pop = set(range(len(combined)))\n    while len(pop) > 0:\n        front = []\n        for p in pop:\n            dominated = False\n            for q in pop:\n                if combined[p] < combined[q]:\n                    dominated = True\n                    break\n            if not dominated:\n                front.append(p)\n        fronts.append([dict(individual=combined[f], index=f) for f in front])\n        pop = pop - set(front)\n    \n    # Go through each front and add all the elements until doing so\n    # would put you above the population limit. At that point, fall\n    # back to the crowding distance to determine who to put into the\n    # next population. Individuals with higher crowding distances\n    # (i.e., more distance between neighbors) are preferred.\n    for i, front in enumerate(fronts):\n        if len(survivors) + len(front) > len(population):\n            # Determine the crowding distance.\n            distance = [0 for _ in range(len(combined))]\n            individuals = list(front)\n            num_individuals = len(individuals)\n            num_objectives = len(individuals[0]['individual'].fitness)\n            for obj in range(num_objectives):\n                individuals.sort(key=lambda x: x['individual'].fitness[obj])\n                distance[individuals[0]['index']] = float('inf')\n                distance[individuals[-1]['index']] = float('inf')\n                for i in range(1, num_individuals-1):\n                    distance[individuals[i]['index']] = (distance[individuals[i]['index']] + \n                                                         (individuals[i+1]['individual'].fitness[obj] - \n                                                          individuals[i-1]['individual'].fitness[obj]))\n                \n            crowd = [dict(dist=distance[f['index']], index=f['index']) for f in front]\n            crowd.sort(key=lambda x: x['dist'], reverse=True)\n            last_rank = [combined[c['index']] for c in crowd]\n            r = 0\n            num_added = 0\n            num_left_to_add = len(population) - len(survivors)\n            while r < len(last_rank) and num_added < num_left_to_add:\n                if last_rank[r] not in survivors:\n                    survivors.append(last_rank[r])\n                    num_added += 1\n                r += 1\n            # If we've filled out our survivor list, then stop.\n            # Otherwise, process the next front in the list.\n            if len(survivors) == len(population):\n                break\n        else:\n            for f in front:\n                if f['individual'] not in survivors:\n                    survivors.append(f['individual'])\n    return survivors", "response": "This function replaces the population using the non - dominated sorting technique from NSGA - II."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreplaces population using the Pareto Archived Evolution Strategy method.", "response": "def paes_replacement(random, population, parents, offspring, args):\n    \"\"\"Replaces population using the Pareto Archived Evolution Strategy method.\n    \n    .. Arguments:\n       random -- the random number generator object\n       population -- the population of individuals\n       parents -- the list of parent individuals\n       offspring -- the list of offspring individuals\n       args -- a dictionary of keyword arguments\n    \n    \"\"\"\n    archive = args['_ec'].archive\n    archiver = args['_ec'].archiver\n        \n    survivors = []\n    for p, o in zip(parents, offspring):\n        if o == p:\n            survivors.append(p)\n        elif o in archive:\n            survivors.append(p)\n        elif o > p:\n            archive = archiver(random, [o], archive, args)\n            survivors.append(o)\n        elif o >= p:\n            for a in archive:\n                if o > a or o < a:\n                    break\n            if o >= a:\n                archive = archiver(random, [o], archive, args)\n                if o > a or archiver.grid_population[o.grid_location] <= archiver.grid_population[p.grid_location]:\n                    survivors.append(o)\n                else:\n                    survivors.append(p)\n            else:\n                survivors.append(p)\n        else:\n            survivors.append(p)\n    return survivors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evaluator(evaluate):\n    @functools.wraps(evaluate)\n    def inspyred_evaluator(candidates, args):\n        fitness = []\n        for candidate in candidates:\n            fitness.append(evaluate(candidate, args))\n        return fitness\n    inspyred_evaluator.single_evaluation = evaluate\n    return inspyred_evaluator", "response": "Return an inspyred evaluator function based on the given function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the candidates in parallel using Parallel Python.", "response": "def parallel_evaluation_pp(candidates, args):\n    \"\"\"Evaluate the candidates in parallel using Parallel Python.\n\n    This function allows parallel evaluation of candidate solutions.\n    It uses the `Parallel Python <http://www.parallelpython.com>`_  (pp)\n    library to accomplish the parallelization. This library must already \n    be installed in order to use this function. The function assigns the \n    evaluation of each candidate to its own job, all of which are then \n    distributed to the available processing units.\n    \n    .. note::\n    \n       All arguments to the evaluation function must be pickleable.\n       Those that are not will not be sent through the ``args`` variable\n       and will be unavailable to your function.\n       \n    .. Arguments:\n       candidates -- the candidate solutions\n       args -- a dictionary of keyword arguments\n\n    Required keyword arguments in args:\n    \n    - *pp_evaluator* -- actual evaluation function to be used (This function\n      should have the same signature as any other inspyred evaluation function.)\n\n    Optional keyword arguments in args:\n    \n    - *pp_dependencies* -- tuple of functional dependencies of the serial \n      evaluator (default ())\n    - *pp_modules* -- tuple of modules that must be imported for the \n      functional dependencies (default ())\n    - *pp_servers* -- tuple of servers (on a cluster) that will be used \n      for parallel processing (default (\"*\",))\n    - *pp_secret* -- string representing the secret key needed to authenticate\n      on a worker node (default \"inspyred\")\n    - *pp_nprocs* -- integer representing the number of worker processes to\n      start on the local machine (default \"autodetect\", which sets it to the\n      number of processors in the system)\n      \n    For more information about these arguments, please consult the\n    documentation for `Parallel Python <http://www.parallelpython.com>`_.\n    \n    \"\"\"\n    import pp\n    logger = args['_ec'].logger\n    \n    try:\n        evaluator = args['pp_evaluator']\n    except KeyError:\n        logger.error('parallel_evaluation_pp requires \\'pp_evaluator\\' be defined in the keyword arguments list')\n        raise \n    secret_key = args.setdefault('pp_secret', 'inspyred')\n    try:\n        job_server = args['_pp_job_server']\n    except KeyError:\n        pp_servers = args.get('pp_servers', (\"*\",))\n        pp_nprocs = args.get('pp_nprocs', 'autodetect')\n        job_server = pp.Server(ncpus=pp_nprocs, ppservers=pp_servers, secret=secret_key)\n        args['_pp_job_server'] = job_server\n    pp_depends = args.setdefault('pp_dependencies', ())\n    pp_modules = args.setdefault('pp_modules', ())\n        \n    pickled_args = {}\n    for key in args:\n        try:\n            pickle.dumps(args[key])\n            pickled_args[key] = args[key]\n        except (TypeError, pickle.PickleError, pickle.PicklingError):\n            logger.debug('unable to pickle args parameter {0} in parallel_evaluation_pp'.format(key))\n            pass\n            \n    func_template = pp.Template(job_server, evaluator, pp_depends, pp_modules)\n    jobs = [func_template.submit([c], pickled_args) for c in candidates]\n    \n    fitness = []\n    for i, job in enumerate(jobs):\n        r = job()\n        try:\n            fitness.append(r[0])\n        except TypeError:\n            logger.warning('parallel_evaluation_pp generated an invalid fitness for candidate {0}'.format(candidates[i]))\n            fitness.append(None)\n    return fitness"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parallel_evaluation_mp(candidates, args):\n    import time\n    import multiprocessing\n    logger = args['_ec'].logger\n    \n    try:\n        evaluator = args['mp_evaluator']\n    except KeyError:\n        logger.error('parallel_evaluation_mp requires \\'mp_evaluator\\' be defined in the keyword arguments list')\n        raise \n    try:\n        nprocs = args['mp_nprocs']\n    except KeyError:\n        nprocs = multiprocessing.cpu_count()\n        \n    pickled_args = {}\n    for key in args:\n        try:\n            pickle.dumps(args[key])\n            pickled_args[key] = args[key]\n        except (TypeError, pickle.PickleError, pickle.PicklingError):\n            logger.debug('unable to pickle args parameter {0} in parallel_evaluation_mp'.format(key))\n            pass\n\n    start = time.time()\n    try:\n        pool = multiprocessing.Pool(processes=nprocs)\n        results = [pool.apply_async(evaluator, ([c], pickled_args)) for c in candidates]\n        pool.close()\n        pool.join()\n        return [r.get()[0] for r in results]\n    except (OSError, RuntimeError) as e:\n        logger.error('failed parallel_evaluation_mp: {0}'.format(str(e)))\n        raise\n    else:\n        end = time.time()\n        logger.debug('completed parallel_evaluation_mp in {0} seconds'.format(end - start))", "response": "Evaluate the candidates in parallel using multiprocessing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strategize(generator):\n    @functools.wraps(generator)\n    def strategy_generator(random, args):\n        candidate = generator(random, args)\n        n = len(candidate)\n        candidate.extend([random.random() for _ in range(n)])\n        return candidate\n    return strategy_generator", "response": "Decorator to strategize a generator function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncaching a function's return value each time it is called. This function serves as a function decorator to provide a caching of evaluated fitness values. If called later with the same arguments, the cached value is returned instead of being re-evaluated. This decorator assumes that candidates are individually pickleable, and their pickled values are used for hashing into a dictionary. It should be used when evaluating an *expensive* fitness function to avoid costly re-evaluation of those fitnesses. The typical usage is as follows:: @memoize def expensive_fitness_function(candidates, args): # Implementation of expensive fitness calculation pass It is also possible to provide the named argument *maxlen*, which specifies the size of the memoization cache to use. (If *maxlen* is ``None``, then an unbounded cache is used.) Once the size of the cache has reached *maxlen*, the oldest element is replaced by the newest element in order to keep the size constant. This usage is as follows:: @memoize(maxlen=100) def expensive_fitness_function(candidates, args): # Implementation of expensive fitness calculation pass .. warning:: The ``maxlen`` parameter must be passed as a named keyword argument, or an ``AttributeError`` will be raised (e.g., saying ``@memoize(100)`` will cause an error).", "response": "def memoize(func=None, maxlen=None):\n    \"\"\"Cache a function's return value each time it is called.\n    \n    This function serves as a function decorator to provide a caching of\n    evaluated fitness values. If called later with the same arguments, \n    the cached value is returned instead of being re-evaluated.\n    \n    This decorator assumes that candidates are individually pickleable, \n    and their pickled values are used for hashing into a dictionary. It \n    should be used when evaluating an *expensive* fitness \n    function to avoid costly re-evaluation of those fitnesses. The \n    typical usage is as follows::\n    \n        @memoize\n        def expensive_fitness_function(candidates, args):\n            # Implementation of expensive fitness calculation\n            pass\n            \n    It is also possible to provide the named argument *maxlen*, which\n    specifies the size of the memoization cache to use. (If *maxlen* is\n    ``None``, then an unbounded cache is used.) Once the size of the cache \n    has reached *maxlen*, the oldest element is replaced by the newest\n    element in order to keep the size constant. This usage is as follows::\n    \n        @memoize(maxlen=100)\n        def expensive_fitness_function(candidates, args):\n            # Implementation of expensive fitness calculation\n            pass\n            \n    .. warning:: The ``maxlen`` parameter must be passed as a named keyword\n       argument, or an ``AttributeError`` will be raised (e.g., saying \n       ``@memoize(100)`` will cause an error).\n    \n    \"\"\"\n    if func is not None:\n        cache = BoundedOrderedDict(maxlen=maxlen)\n        @functools.wraps(func)\n        def memo_target(candidates, args):\n            fitness = []\n            for candidate in candidates:\n                lookup_value = pickle.dumps(candidate, 1)\n                if lookup_value not in cache:\n                    cache[lookup_value] = func([candidate], args)[0]\n                fitness.append(cache[lookup_value])\n            return fitness\n        return memo_target\n    else:\n        def memoize_factory(func):\n            return memoize(func, maxlen=maxlen)\n        return memoize_factory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting function to determine whether to show the toolbar on a given page.", "response": "def allow_ajax(request):\n    \"\"\"\n    Default function to determine whether to show the toolbar on a given page.\n    \"\"\"\n    if request.META.get('REMOTE_ADDR', None) not in settings.INTERNAL_IPS:\n        return False\n    if toolbar_version < LooseVersion('1.8') \\\n            and request.get_full_path().startswith(DEBUG_TOOLBAR_URL_PREFIX) \\\n            and request.GET.get('panel_id', None) != 'RequestHistoryPanel':\n        return False\n    return bool(settings.DEBUG)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef content(self):\n        toolbars = OrderedDict()\n        for id, toolbar in DebugToolbar._store.items():\n            content = {}\n            for panel in toolbar.panels:\n                panel_id = None\n                nav_title = ''\n                nav_subtitle = ''\n                try:\n                    panel_id = panel.panel_id\n                    nav_title = panel.nav_title\n                    nav_subtitle = panel.nav_subtitle() if isinstance(\n                        panel.nav_subtitle, Callable) else panel.nav_subtitle\n                except Exception:\n                    logger.debug('Error parsing panel info:', exc_info=True)\n                if panel_id is not None:\n                    content.update({\n                        panel_id: {\n                            'panel_id': panel_id,\n                            'nav_title': nav_title,\n                            'nav_subtitle': nav_subtitle,\n                        }\n                    })\n            toolbars[id] = {\n                'toolbar': toolbar,\n                'content': content\n            }\n        return get_template().render(Context({\n            'toolbars': OrderedDict(reversed(list(toolbars.items()))),\n            'trunc_length': CONFIG.get('RH_POST_TRUNC_LENGTH', 0)\n        }))", "response": "Return the content of the panel when it s displayed in full screen."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute_command(self):\n        print(Back.GREEN + Fore.BLACK + \"Scrapple Web Interface\")\n        print(Back.RESET + Fore.RESET)\n        p1 = Process(target = self.run_flask)\n        p2 = Process(target = lambda : webbrowser.open('http://127.0.0.1:5000'))\n        p1.start()\n        p2.start()", "response": "Execute the command in a separate process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_command(self):\n        print(Back.GREEN + Fore.BLACK + \"Scrapple Generate\")\n        print(Back.RESET + Fore.RESET)\n        directory = os.path.join(scrapple.__path__[0], 'templates', 'scripts')\n        with open(os.path.join(directory, 'generate.txt'), 'r') as f:\n            template_content = f.read()\n        template = Template(template_content)\n        try:\n            with open(self.args['<projectname>'] + '.json', 'r') as f:\n                config = json.load(f)\n            if self.args['--output_type'] == 'csv':\n                from scrapple.utils.config import extract_fieldnames\n                config['fields'] = str(extract_fieldnames(config))\n            config['output_file'] = self.args['<output_filename>']\n            config['output_type'] = self.args['--output_type']\n            rendered = template.render(config=config)\n            with open(self.args['<output_filename>'] + '.py', 'w') as f:\n                f.write(rendered)\n            print(Back.WHITE + Fore.RED + self.args['<output_filename>'], \\\n                  \".py has been created\" + Back.RESET + Fore.RESET, sep=\"\")\n        except IOError:\n            print(Back.WHITE + Fore.RED + self.args['<projectname>'], \".json does not \", \\\n                  \"exist. Use ``scrapple genconfig``.\" + Back.RESET + Fore.RESET, sep=\"\")", "response": "The generate command uses `Jinja2 <http://jinja.pocoo.org/>`_ templates \\\n        to create Python scripts, according to the specification in the configuration \\\n        file. The predefined templates use the extract_content() method of the \\\n        :ref:`selector classes <implementation-selectors>` to implement linear extractors \\\n        and use recursive for loops to implement multiple levels of link crawlers. This \\\n        implementation is effectively a representation of the traverse_next() \\\n        :ref:`utility function <implementation-utils>`, using the loop depth to \\\n        differentiate between levels of the crawler execution. \n\n        According to the --output_type argument in the CLI input, the results are \\\n        written into a JSON document or a CSV document. \n\n        The Python script is written into <output_filename>.py - running this file \\\n        is the equivalent of using the Scrapple :ref:`run command <command-run>`."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_links(self, selector='', *args, **kwargs):\n\t\ttry:\n\t\t\tlinks = self.get_tree_tag(selector=selector)\n\t\t\tfor link in links:\n\t\t\t\tnext_url = urljoin(self.url, link.get('href'))\n\t\t\t\tyield type(self)(next_url)\n\t\texcept XPathError:\n\t\t\traise Exception(\"Invalid %s selector - %s\" % (self.__selector_type__, selector))\n\t\texcept Exception:\n\t\t\traise Exception(\"Invalid %s selector - %s\" % (self.__selector_type__, selector))", "response": "This method returns a list of links that are crawled through the crawler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrow data extraction for extract_tabular", "response": "def extract_rows(self, result={}, selector='', table_headers=[], attr='', connector='', default='', verbosity=0, *args, **kwargs):\n\t\t\"\"\"\n\t\tRow data extraction for extract_tabular\n\t\t\"\"\"\n\t\tresult_list = []\n\n\t\ttry:\n\t\t\tvalues = self.get_tree_tag(selector)\n\t\t\tif len(table_headers) >= len(values):\n\t\t\t\tfrom itertools import izip_longest\n\t\t\t\tpairs = izip_longest(table_headers, values, fillvalue=default)\n\t\t\telse:\n\t\t\t\tfrom itertools import izip\n\t\t\t\tpairs = izip(table_headers, values)\n\t\t\tfor head, val in pairs:\n\t\t\t\tif verbosity > 1:\n\t\t\t\t\tprint(\"\\nExtracting\", head, \"attribute\", sep=' ', end='')\n\t\t\t\tif attr.lower() == \"text\":\n\t\t\t\t\ttry:\n\t\t\t\t\t\tcontent = connector.join([make_ascii(x).strip() for x in val.itertext()])\n\t\t\t\t\texcept Exception:\n\t\t\t\t\t\tcontent = default\n\t\t\t\t\tcontent = content.replace(\"\\n\", \" \").strip()\n\t\t\t\telse:\n\t\t\t\t\tcontent = val.get(attr)\n\t\t\t\t\tif attr in [\"href\", \"src\"]:\n\t\t\t\t\t\tcontent = urljoin(self.url, content)\n\t\t\t\tresult[head] = content\n\t\t\tresult_list.append(result)\n\t\texcept XPathError:\n\t\t\traise Exception(\"Invalid %s selector - %s\" % (self.__selector_type__, selector))\n\t\texcept TypeError:\n\t\t\traise Exception(\"Selector expression string to be provided. Got \" + selector)\n\n\t\treturn result_list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_columns(self, result={}, selector='', table_headers=[], attr='', connector='', default='', verbosity=0, *args, **kwargs):\n\t\tresult_list = []\n\n\t\ttry:\n\t\t\tif type(selector) in [str, unicode]:\n\t\t\t\tselectors = [selector]\n\t\t\telif type(selector) == list:\n\t\t\t\tselectors = selector[:]\n\t\t\telse:\n\t\t\t\traise Exception(\"Use a list of selector expressions for the various columns\")\n\t\t\tfrom itertools import izip, count\n\t\t\tpairs = izip(table_headers, selectors)\n\t\t\tcolumns = {}\n\t\t\tfor head, selector in pairs:\n\t\t\t\tcolumns[head] = self.get_tree_tag(selector)\n\t\t\ttry:\n\t\t\t\tfor i in count(start=0):\n\t\t\t\t\tr = result.copy()\n\t\t\t\t\tfor head in columns.keys():\n\t\t\t\t\t\tif verbosity > 1:\n\t\t\t\t\t\t\tprint(\"\\nExtracting\", head, \"attribute\", sep=' ', end='')\n\t\t\t\t\t\tcol = columns[head][i]\n\t\t\t\t\t\tif attr == \"text\":\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\tcontent = connector.join([make_ascii(x).strip() for x in col.itertext()])\n\t\t\t\t\t\t\texcept Exception:\n\t\t\t\t\t\t\t\tcontent = default\n\t\t\t\t\t\t\tcontent = content.replace(\"\\n\", \" \").strip()\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tcontent = col.get(attr)\n\t\t\t\t\t\t\tif attr in [\"href\", \"src\"]:\n\t\t\t\t\t\t\t\tcontent = urljoin(self.url, content)\n\t\t\t\t\t\tr[head] = content\n\t\t\t\t\tresult_list.append(r)\n\t\t\texcept IndexError:\n\t\t\t\tpass\n\t\texcept XPathError:\n\t\t\traise Exception(\"Invalid %s selector - %s\" % (self.__selector_type__, selector))\n\t\texcept TypeError:\n\t\t\traise Exception(\"Selector expression string to be provided. Got \" + selector)\n\n\t\treturn result_list", "response": "This function extracts the columns from a table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef runCLI():\n    args = docopt(__doc__, version='0.3.0')\n    try:\n        check_arguments(args)\n        command_list = ['genconfig', 'run', 'generate']\n        select = itemgetter('genconfig', 'run', 'generate')\n        selectedCommand = command_list[select(args).index(True)]\n        cmdClass = get_command_class(selectedCommand)\n        obj = cmdClass(args)\n        obj.execute_command()\n    except POSSIBLE_EXCEPTIONS as e:\n        print('\\n', e, '\\n')", "response": "This function is the main entry point for the Scrapple command line tool. It is responsible for running the command line tool."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the arguments passed through the docopt module and raises an exception if they are not.", "response": "def check_arguments(args):\n\t\"\"\"\n\tValidates the arguments passed through the CLI commands.\n\n\t:param args: The arguments passed in the CLI, parsed by the docopt module\n\t:return: None\n\n\t\"\"\"\n\tprojectname_re = re.compile(r'[^a-zA-Z0-9_]')\n\tif args['genconfig']:\n\t\tif args['--type'] not in ['scraper', 'crawler']:\n\t\t\traise InvalidType(\"--type has to be 'scraper' or 'crawler'\")\n\t\tif args['--selector'] not in ['xpath', 'css']:\n\t\t\traise InvalidSelector(\"--selector has to be 'xpath' or 'css'\")\n\tif args['generate'] or args['run']:\n\t\tif args['--output_type'] not in ['json', 'csv']:\n\t\t\traise InvalidOutputType(\"--output_type has to be 'json' or 'csv'\")\n\tif args['genconfig'] or args['generate'] or args['run']:\n\t\tif projectname_re.search(args['<projectname>']) is not None:\n\t\t\tmessage = \"<projectname> should consist of letters, digits or _\"\n\t\t\traise InvalidProjectName(message)\n\ttry:\n\t\tif int(args['--levels']) < 1:\n\t\t\tmessage = \"--levels should be greater than, or equal to 1\"\n\t\t\traise InvalidLevels(message)\n\texcept (TypeError, ValueError):\n\t\tmessage = \" \".join([\n\t\t\t\"--levels should be an integer and not of type\",\n\t\t\t\"{}\".format(type(args['--levels']))\n\t\t])\n\t\traise InvalidLevels(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_command_class(command):\n    from scrapple.commands import genconfig, generate, run, web\n    commandMapping = {\n    \t'genconfig': genconfig,\n    \t'generate': generate,\n    \t'run': run,\n    \t'web': web\n    }\n    cmdClass = getattr(commandMapping.get(command), command.title() + 'Command')\n    return cmdClass", "response": "Returns the command class corresponding to the selected command"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake the POST request in the web interface and generates the JSON config \\ n\\ n", "response": "def form_to_json(form):\n\t\"\"\"\n\tTakes the form from the POST request in the web interface, and generates the JSON config\\\n\tfile \n\n\t:param form: The form from the POST request\n\t:return: None\n\n\t\"\"\"\n\tconfig = dict()\n\tif form['project_name'] == \"\":\n\t\traise Exception('Project name cannot be empty.')\n\tif form['selector_type'] not in [\"css\", \"xpath\"]:\n\t\traise Exception('Selector type has to css or xpath')\n\tconfig['project_name'] = form['project_name']\n\tconfig['selector_type'] = form['selector_type']\n\tconfig['scraping'] = dict()\n\tif form['url'] == \"\":\n\t\traise Exception('URL cannot be empty')\n\tconfig['scraping']['url'] = form['url']\n\tconfig['scraping']['data'] = list()\n\tfor i in itertools.count(start=1):\n\t\ttry:\n\t\t\tdata = {\n\t\t\t\t'field': form['field_' + str(i)],\n\t\t\t\t'selector': form['selector_' + str(i)],\n\t\t\t\t'attr': form['attribute_' + str(i)],\n\t\t\t\t'default': form['default_' + str(i)]\n\t\t\t}\n\t\t\tconfig['scraping']['data'].append(data)\n\t\texcept KeyError:\n\t\t\tbreak\n\t# TODO : Crawler 'next' parameter handling\n\twith open(os.path.join(os.getcwd(), form['project_name'] + '.json'), 'w') as f:\n\t\tjson.dump(config, f)\n\treturn"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the command that handles the execution of the command.", "response": "def execute_command(self):\n        \"\"\"\n        The run command implements the web content extractor corresponding to the given \\\n        configuration file. \n\n        The execute_command() validates the input project name and opens the JSON \\\n        configuration file. The run() method handles the execution of the extractor run.\n\n        The extractor implementation follows these primary steps :\n\n        1. Selects the appropriate :ref:`selector class <implementation-selectors>` through \\\n        a dynamic dispatch, with the selector_type argument from the CLI input. \n\n        #. Iterate through the data section in level-0 of the configuration file. \\\n        On each data item, call the extract_content() method from the selector class to \\\n        extract the content according to the specified extractor rule. \n\n        #. If there are multiple levels of the extractor, i.e, if there is a 'next' \\\n        attribute in the configuration file, call the traverse_next() \\\n        :ref:`utility function <implementation-utils>` and parse through successive levels \\\n        of the configuration file.\n\n        #. According to the --output_type argument, the result data is saved in a JSON \\\n        document or a CSV document. \n\n        \"\"\"\n        try:\n            self.args['--verbosity'] = int(self.args['--verbosity'])\n            if self.args['--verbosity'] not in [0, 1, 2]:\n                raise ValueError\n            if self.args['--verbosity'] > 0:\n                print(Back.GREEN + Fore.BLACK + \"Scrapple Run\")\n                print(Back.RESET + Fore.RESET)\n            import json\n            with open(self.args['<projectname>'] + '.json', 'r') as f:\n                self.config = json.load(f)\n            validate_config(self.config)\n            self.run()\n        except ValueError:\n            print(Back.WHITE + Fore.RED + \"Use 0, 1 or 2 for verbosity.\" \\\n                + Back.RESET + Fore.RESET, sep=\"\")\n        except IOError:\n            print(Back.WHITE + Fore.RED + self.args['<projectname>'], \".json does not \", \\\n                  \"exist. Use ``scrapple genconfig``.\" + Back.RESET + Fore.RESET, sep=\"\")\n        except InvalidConfigException as e:\n            print(Back.WHITE + Fore.RED + e + Back.RESET + Fore.RESET, sep=\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the extractor configuration file.", "response": "def validate_config(config):\n    \"\"\"\n    Validates the extractor configuration file. Ensures that there are no duplicate field names, etc.\n\n    :param config: The configuration file that contains the specification of the extractor\n    :return: True if config is valid, else raises a exception that specifies the correction to be made\n\n    \"\"\"\n    fields = [f for f in get_fields(config)]\n    if len(fields) != len(set(fields)):\n        raise InvalidConfigException(\n            \"Invalid configuration file - %d duplicate field names\" % len(fields) - len(set(fields))\n        )\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_fields(config):\n    for data in config['scraping']['data']:\n        if data['field'] != '': \n            yield data['field']\n    if 'next' in config['scraping']:\n        for n in config['scraping']['next']:\n            for f in get_fields(n): \n                yield f", "response": "Recursive generator that yields the field names in the config file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_fieldnames(config):\n    fields = []\n    for x in get_fields(config):\n        if x in fields:\n            fields.append(x + '_' + str(fields.count(x) + 1))\n        else:\n            fields.append(x)\n    return fields", "response": "Function to return a list of unique field names from the config file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_command(self):\n        print(Back.GREEN + Fore.BLACK + \"Scrapple Genconfig\")\n        print(Back.RESET + Fore.RESET)\n        directory = os.path.join(scrapple.__path__[0], 'templates', 'configs')\n        with open(os.path.join(directory, self.args['--type'] + '.txt'), 'r') as f:\n            template_content = f.read()\n        print(\"\\n\\nUsing the\", self.args['--type'], \"template\\n\\n\")\n        template = Template(template_content)\n        settings = {\n            'projectname': self.args['<projectname>'],\n            'selector_type': self.args['--selector'],\n            'url': self.args['<url>'],\n            'levels': int(self.args['--levels'])\n        }\n        rendered = template.render(settings=settings)\n        with open(self.args['<projectname>'] + '.json', 'w') as f:\n            rendered_data = json.loads(rendered)\n            json.dump(rendered_data, f, indent=3)\n        print(Back.WHITE + Fore.RED + self.args['<projectname>'], \".json has been created\" \\\n            + Back.RESET + Fore.RESET, sep=\"\")", "response": "Execute the genconfig command"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of Pauli pairs for the Jordan_Wigner mode.", "response": "def _jordan_wigner_mode(n):\n        \"\"\"\n        Jordan_Wigner mode.\n        Args:\n            n (int): number of modes\n        \"\"\"\n        a = []\n        for i in range(n):\n            xv = np.asarray([1] * i + [0] + [0] * (n - i - 1))\n            xw = np.asarray([0] * i + [1] + [0] * (n - i - 1))\n            yv = np.asarray([1] * i + [1] + [0] * (n - i - 1))\n            yw = np.asarray([0] * i + [1] + [0] * (n - i - 1))\n            a.append((Pauli(xv, xw), Pauli(yv, yw)))\n        return a"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _one_body_mapping(a_i, a_j, threshold=0.000001):\n        pauli_list = []\n        for alpha in range(2):\n            for beta in range(2):\n                pauli_prod = Pauli.sgn_prod(a_i[alpha], a_j[beta])\n                coeff = 1.0/4 * pauli_prod[1] * np.power(-1j, alpha) * np.power(1j, beta)\n                pauli_term = [coeff, pauli_prod[0]]\n                if np.absolute(pauli_term[0]) > threshold:\n                    pauli_list.append(pauli_term)\n        return Operator(paulis=pauli_list)", "response": "Subroutine for one body mapping."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of cirq. GridQubit s corresponding to the qubit nodes provided on the given Architecture.", "response": "def get_grid_qubits(arc: SquareGrid, nodes: Iterator[int]) -> List[cirq.GridQubit]:\n    \"\"\"Gets a list of :py:class:GridQubit` s corresponding to the qubit nodes provided on the given Architecture.\n\n       :param arc: The grid Architecture\n       :param nodes: An iterator of node index values\n\n       :return: The list of qubits\n    \"\"\"\n\n    return [cirq.GridQubit(*arc.qind_to_squind(i)) for i in nodes]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cirq_to_tk(circuit: cirq.Circuit) -> Circuit:\n    qubit_list = _indexed_qubits_from_circuit(circuit)\n    qid_to_num = {q : i for i, q in enumerate(qubit_list)}\n    n_qubits = len(circuit.all_qubits())\n    tkcirc = Circuit(n_qubits)\n    for moment in circuit:\n        for op in moment.operations:\n            gate = op.gate\n            gatetype = type(gate)\n\n            qb_lst = [qid_to_num[q] for q in op.qubits]\n\n            n_qubits = len(op.qubits)\n\n            if gatetype == cirq_common.HPowGate and gate.exponent == 1:\n                gatetype = cirq_common.H\n            elif gatetype == cirq_common.CNotPowGate and gate.exponent == 1:\n                gatetype = cirq_common.CNOT\n\n            try:\n                optype = _cirq2ops_mapping[gatetype]\n            except KeyError as error:\n                raise NotImplementedError(\"Operation not supported by tket: \" + str(op.gate)) from error\n            if isinstance(gate, _rotation_types):\n                o = tkcirc._get_op(optype,n_qubits,n_qubits,gate.exponent)\n            elif isinstance(gate, cirq_common.MeasurementGate) :\n                o = tkcirc._get_op(optype,n_qubits,n_qubits,gate.key)\n            else:\n                o = tkcirc._get_op(optype)\n            tkcirc._add_operation(o,qb_lst)\n    return tkcirc", "response": "Converts a Cirq object to a Tk object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a Tket Circuit to a Cirq.", "response": "def tk_to_cirq(tkcirc: Circuit, indexed_qubits: List[QubitId]) -> cirq.Circuit:\n    \"\"\"Converts a :math:`\\\\mathrm{t|ket}\\\\rangle` :py:class:`Circuit` object to a Cirq :py:class:`Circuit`.\n    \n    :param tkcirc: The input :math:`\\\\mathrm{t|ket}\\\\rangle` :py:class:`Circuit`\n    :param indexed_qubits: Map from :math:`\\\\mathrm{t|ket}\\\\rangle` qubit indices to Cirq :py:class:`QubitId` s\n    \n    :return: The Cirq :py:class:`Circuit` corresponding to the input circuit\n    \"\"\"\n\n    grid = tkcirc._int_routing_grid()\n    qubits = _grid_to_qubits(grid)\n    oplst = []\n    slices = []\n    for s in grid:\n        news = set()\n        for pair in s:\n            if pair[0]>-1:\n                news.add(pair[0])\n        slices.append(news)\n    for s in slices:\n        for v in s:\n            op = tkcirc._unsigned_to_op(v)\n            optype = op.get_type()\n            if optype == OpType.Input or optype == OpType.Output:\n                continue\n            try:\n                gatetype = _ops2cirq_mapping[optype]\n            except KeyError as error:\n                raise NotImplementedError(\"Cannot convert tket Op to cirq gate: \" + op.get_name()) from error\n            n_qubits = op.get_n_inputs()\n            qids = []\n            for i in range(n_qubits):\n                qbit = qubits[(v,i)]\n                qids.append(indexed_qubits[qbit])\n            params = op.get_params()\n            if gatetype in _rotation_types:\n                cirqop = gatetype(exponent=params[0])(*qids)\n            elif gatetype == cirq_common.MeasurementGate:\n                for q in qids:\n                    cirqop = cirq_common.measure(q, key=op.get_desc())\n            else:\n                cirqop = gatetype(*qids)\n            oplst.append(cirqop)\n\n    return cirq.Circuit.from_ops(*oplst)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dagcircuit_to_tk(dag:DAGCircuit, _BOX_UNKNOWN:bool=BOX_UNKNOWN, _DROP_CONDS:bool=DROP_CONDS) -> Circuit :\n    qs = dag.get_qubits()\n    qnames = [\"%s[%d]\" % (r.name, i) for r, i in qs]\n    g = dag.multi_graph\n    circ = Circuit()\n    if DEBUG :\n        print(\"new graph w \" + str(len(qs)) + \" qubits\")\n        print(str(qs))\n\n    # process vertices\n    tk_vs = [ None for _ in range(dag.node_counter + 1) ]    \n    for n in g.nodes :\n        node = g.nodes[n]\n        if DEBUG : \n            print(str(n) + \" \" + str(node[\"type\"])+ \" \" + str(node[\"name\"]))\n        if ((node[\"type\"]==\"in\" or node[\"type\"]==\"out\") and not node[\"name\"] in qnames) :\n            # don't create vertices for in/outs of classical registers\n            if DEBUG:\n                print(\"Dropping node \" + str(n))\n            continue\n        else :\n            tk_vs[n] = circ._add_vertex(_node_converter(circ, node, _BOX_UNKNOWN=_BOX_UNKNOWN, _DROP_CONDS=_DROP_CONDS))\n            if DEBUG:\n                print(\"qiskit vertex \" + str(n) + \" is t|ket> vertex \" +str(tk_vs[n]))\n    # process edges\n    for e in g.edges(data=True) :\n        wire = e[2][\"wire\"]\n        if wire in qs : # ignore classical wires\n            src_port = _get_port_for_edge(g.node[e[0]], wire)\n            tgt_port = _get_port_for_edge(g.node[e[1]], wire)\n            if DEBUG : \n                print(_make_edge_str(tk_vs[e[0]],src_port,tk_vs[e[1]],tgt_port))\n            circ._add_edge(tk_vs[e[0]],src_port,tk_vs[e[1]],tgt_port)                \n\n    return circ", "response": "Converts a DAGCircuit into a TK - style circuit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tk_to_dagcircuit(circ:Circuit,_qreg_name:str=\"q\") -> DAGCircuit :\n    dc = DAGCircuit()\n    qreg = QuantumRegister(circ.n_qubits(), name=_qreg_name)\n    dc.add_qreg(qreg)\n    grid = circ._int_routing_grid()\n    slices = _grid_to_slices(grid)\n    qubits = _grid_to_qubits(grid, qreg)\n    in_boundary = circ._get_boundary()[0]\n    out_boundary = circ._get_boundary()[1]\n    for s in slices :\n        for v in s:\n            o = circ._unsigned_to_op(v)\n            qargs = [ qubits[(v,i)] for i in range(o.get_n_inputs()) ]\n            name, cargs, params = _translate_ops(circ,v)\n            if cargs :\n                _extend_cregs(dc,cargs)\n            if name :\n                dc.add_basis_element(name,o.get_n_inputs(),number_classical=len(cargs),number_parameters=len(params))\n                ins = Instruction(name, list(map(_normalise_param_out, params)), qargs, cargs)\n                dc.apply_operation_back(ins ,qargs=qargs,\n                                        cargs=cargs)\n    tk2dg_outs = {}\n    for v in out_boundary:\n        tk2dg_outs[v] = dc.output_map[qubits[(v,0)]]\n    for i, v in enumerate(out_boundary):\n        dc.multi_graph.node[tk2dg_outs[v]][\"wire\"] = [qubits[(in_boundary[i],0)]]\n        dc.output_map[qubits[(in_boundary[i],0)]] = tk2dg_outs[v]\n    return dc", "response": "Converts a TK to a DAG circuit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef coupling_to_arc(coupling_map:List[List[int]]) -> Architecture:\n    coupling = CouplingMap(couplinglist=coupling_map)\n    return DirectedGraph(coupling_map,coupling.size())", "response": "Creates a directed coupling map that can be used to create a coupling map for the given coupling map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning one pass of optimisation on the circuit and route for the given backend.", "response": "def run(self, dag:DAGCircuit) -> DAGCircuit:\n        \"\"\"\n           Run one pass of optimisation on the circuit and route for the given backend.\n\n        :param dag: The circuit to optimise and route\n\n        :return: The modified circuit\n        \"\"\"\n\n        circ = dagcircuit_to_tk(dag, _DROP_CONDS=self.DROP_CONDS,_BOX_UNKNOWN=self.BOX_UNKNOWN)\n        circ, circlay = self.process_circ(circ)\n        newdag = tk_to_dagcircuit(circ)\n        newdag.name = dag.name \n        finlay = dict()\n        for i, qi in enumerate(circlay):\n            finlay[('q', i)] = ('q', qi)\n        newdag.final_layout = finlay\n        return newdag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sort_row_col(qubits: Iterator[GridQubit]) -> List[GridQubit]:\n\n    return sorted(qubits, key=lambda x: (x.row, x.col))", "response": "Sort grid qubits first by row then by column"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xmon_to_arc(xmon: XmonDevice) -> Architecture:\n\n    nodes = len(xmon.qubits)\n    indexed_qubits = _sort_row_col(xmon.qubits)\n    pairs = []\n    for qb in indexed_qubits:\n        neighbours = xmon.neighbors_of(qb)\n        #filter only higher index neighbours to avoid double counting edges\n        forward_neighbours = filter(lambda x: indexed_qubits.index(x)>indexed_qubits.index(qb), neighbours)\n        for x in forward_neighbours:\n            pairs.append((indexed_qubits.index(qb), indexed_qubits.index(x)))\n    return Architecture(pairs, nodes)", "response": "Converts a Cirq device to a Arc."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a pyQuil Program to a Tk.", "response": "def pyquil_to_tk(prog: Program) -> Circuit:\n    \"\"\"\n    Convert a :py:class:`pyquil.Program` to a :math:`\\\\mathrm{t|ket}\\\\rangle` :py:class:`Circuit` .\n    Note that not all pyQuil operations are currently supported by pytket.\n    \n    :param prog: A circuit to be converted\n\n    :return: The converted circuit\n    \"\"\"\n    reg_name = None\n    qubits = prog.get_qubits()\n    n_qubits = max(qubits) + 1\n    tkc = Circuit(n_qubits)\n    for i in prog.instructions:\n        if isinstance(i, Gate):\n            name = i.name\n            try:\n                optype = _known_quil_gate[name]\n            except KeyError as error:\n                raise NotImplementedError(\"Operation not supported by tket: \" + str(i)) from error\n            if len(i.params) == 0:\n                tkc.add_operation(optype, [q.index for q in i.qubits])\n            else:\n                params = [p/PI for p in i.params]\n                op = tkc._get_op(optype,len(i.qubits),len(i.qubits),params)\n                tkc._add_operation(op, [q.index for q in i.qubits])\n        elif isinstance(i, Measurement):\n            if not i.classical_reg:\n                raise NotImplementedError(\"Program has no defined classical register for measurement on qubit: \", i.qubits[0])\n            reg = i.classical_reg\n            if reg_name and reg_name != reg.name:\n                raise NotImplementedError(\"Program has multiple classical registers: \", reg_name, reg.name)\n            reg_name = reg.name\n            op = tkc._get_op(OpType.Measure,1,1,str(reg.offset))\n            tkc._add_operation(op, [i.qubit.index])\n        elif isinstance(i, Declare):\n            continue\n        elif isinstance(i, Pragma):\n            continue\n        elif isinstance(i, Halt):\n            return tkc\n        else:\n            raise NotImplementedError(\"Pyquil instruction is not a gate: \" + str(i))\n    return tkc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a Tket circuit to a pyQuil program.", "response": "def tk_to_pyquil(circ: Circuit) -> Program:\n    \"\"\"\n       Convert a :math:`\\\\mathrm{t|ket}\\\\rangle` :py:class:`Circuit` to a :py:class:`pyquil.Program` .\n    \n    :param circ: A circuit to be converted\n\n    :return: The converted circuit\n    \"\"\"\n    p = Program()\n    ro = p.declare('ro', 'BIT', circ.n_qubits())\n    grid = circ._int_routing_grid()\n    qubits = _grid_to_qubits(grid)\n    slices = []\n    for s in grid:\n        news = set()\n        for pair in s:\n            if pair[0]>-1:\n                news.add(pair[0])\n        slices.append(news)\n    for s in slices:\n        for v in s:\n            op = circ._unsigned_to_op(v)\n            optype = op.get_type()\n            if optype == OpType.Input or optype == OpType.Output:\n                continue\n            elif optype == OpType.Measure:\n                p += Measurement(qubits[(v, 0)], ro[int(op.get_desc())])\n                continue\n            try:\n                gatetype = _known_quil_gate_rev[optype]\n            except KeyError as error:\n                raise NotImplementedError(\"Cannot convert tket Op to pyquil gate: \" + op.get_name()) from error\n            params = [p*PI for p in op.get_params()]\n            g = Gate(gatetype, params, [qubits[(v,port)] for port in range(op.get_n_inputs())])\n            p += g\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_setting(self) -> str:\n        ret = \"\\n\"\n        ret += \"==================== Setting of {} ============================\\n\".format(self.configuration['name'])\n        ret += \"{}\".format(self.setting)\n        ret += \"===============================================================\\n\"\n        ret += \"{}\".format(self._var_form.setting)\n        ret += \"===============================================================\\n\"\n        return ret", "response": "Prints the current QSE settings as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _energy_evaluation(self, operator):\n        if self._quantum_state is not None:\n            input_circuit = self._quantum_state\n        else:\n            input_circuit = [self.opt_circuit]\n        if operator._paulis:\n            mean_energy, std_energy = operator.evaluate_with_result(self._operator_mode, input_circuit,\n                                                                    self._quantum_instance.backend, self.ret)\n        else:\n            mean_energy = 0.0\n            std_energy = 0.0\n        operator.disable_summarize_circuits()\n        logger.debug('Energy evaluation {} returned {}'.format(self._eval_count, np.real(mean_energy)))\n        return np.real(mean_energy), np.real(std_energy)", "response": "Evaluate the energy of the current input circuit with respect to the given operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the QSE algorithm to compute the eigenvalues of the Hamiltonian.", "response": "def _run(self) -> dict:\n        \"\"\"\n        Runs the QSE algorithm to compute the eigenvalues of the Hamiltonian.\n\n        :return: Dictionary of results\n        \"\"\"\n        if not self._quantum_instance.is_statevector:\n            raise AquaError(\"Can only calculate state for QSE with statevector backends\")\n        ret = self._quantum_instance.execute(self.opt_circuit)\n        self.ret = ret\n        self._eval_count = 0\n        self._solve()\n        self._ret['eval_count'] = self._eval_count\n        self._ret['eval_time'] = self._eval_time\n        return self._ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef whooshee_search(self, search_string, group=whoosh.qparser.OrGroup, whoosheer=None,\n                        match_substrings=True, limit=None, order_by_relevance=10):\n        \"\"\"Do a fulltext search on the query.\n        Returns a query filtered with results of the fulltext search.\n\n        :param search_string: The string to search for.\n        :param group: The whoosh group to use for searching.\n                      Defaults to :class:`whoosh.qparser.OrGroup` which\n                      searches for all words in all columns.\n        :param match_substrings: ``True`` if you want to match substrings,\n                                 ``False`` otherwise\n        :param limit: The number of the top records to be returned.\n                      Defaults to ``None`` and returns all records.\n        \"\"\"\n        if not whoosheer:\n            ### inspiration taken from flask-WhooshAlchemy\n            # find out all entities in join\n            entities = set()\n            # directly queried entities\n            for cd in self.column_descriptions:\n                entities.add(cd['type'])\n            # joined entities\n            if self._join_entities and isinstance(self._join_entities[0], Mapper):\n                # SQLAlchemy >= 0.8.0\n                entities.update(set([x.entity for x in self._join_entities]))\n            else:\n                # SQLAlchemy < 0.8.0\n                entities.update(set(self._join_entities))\n            # make sure we can work with aliased entities\n            unaliased = set()\n            for entity in entities:\n                if isinstance(entity, (AliasedClass, AliasedInsp)):\n                    unaliased.add(inspect(entity).mapper.class_)\n                else:\n                    unaliased.add(entity)\n\n            whoosheer = next(w for w in _get_config(self)['whoosheers']\n                             if set(w.models) == unaliased)\n\n        # TODO what if unique field doesn't exist or there are multiple?\n        for fname, field in list(whoosheer.schema._fields.items()):\n            if field.unique:\n                uniq = fname\n\n        # TODO: use something more general than id\n        res = whoosheer.search(search_string=search_string,\n                               values_of=uniq,\n                               group=group,\n                               match_substrings=match_substrings,\n                               limit=limit)\n        if not res:\n            return self.filter(text('null'))\n\n        # transform unique field name into model attribute field\n        attr = None\n\n        if hasattr(whoosheer, '_is_model_whoosheer'):\n            attr = getattr(whoosheer.models[0], uniq)\n        else:\n            # non-model whoosheers must have unique field named\n            # model.__name__.lower + '_' + attr\n            for m in whoosheer.models:\n                if m.__name__.lower() == uniq.split('_')[0]:\n                    attr = getattr(m, uniq.split('_')[1])\n\n        search_query = self.filter(attr.in_(res))\n\n        if order_by_relevance < 0: # we want all returned rows ordered\n            search_query = search_query.order_by(sqlalchemy.sql.expression.case(\n                [(attr == uniq_val, index) for index, uniq_val in enumerate(res)],\n            ))\n        elif order_by_relevance > 0: # we want only number of specified rows ordered\n            search_query = search_query.order_by(sqlalchemy.sql.expression.case(\n                [(attr == uniq_val, index) for index, uniq_val in enumerate(res) if index < order_by_relevance],\n                else_=order_by_relevance\n            ))\n        else: # no ordering\n            pass\n\n        return search_query", "response": "Do a fulltext search on the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(cls, search_string, values_of='', group=whoosh.qparser.OrGroup, match_substrings=True, limit=None):\n        index = Whooshee.get_or_create_index(_get_app(cls), cls)\n        prepped_string = cls.prep_search_string(search_string, match_substrings)\n        with index.searcher() as searcher:\n            parser = whoosh.qparser.MultifieldParser(cls.schema.names(), index.schema, group=group)\n            query = parser.parse(prepped_string)\n            results = searcher.search(query, limit=limit)\n            if values_of:\n                return [x[values_of] for x in results]\n            return results", "response": "Searches the fields for given search_string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prep_search_string(cls, search_string, match_substrings):\n        if sys.version < '3' and not isinstance(search_string, unicode):\n            search_string = search_string.decode('utf-8')\n        s = search_string.strip()\n        # we don't want stars from user\n        s = s.replace('*', '')\n        if len(s) < _get_config(cls)['search_string_min_len']:\n            raise ValueError('Search string must have at least 3 characters')\n        # replace multiple with star space star\n        if match_substrings:\n            s = u'*{0}*'.format(re.sub('[\\s]+', '* *', s))\n        # TODO: some sanitization\n        return s", "response": "Prepares the search string for a proper whoosh search string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_app(self, app):\n        if not hasattr(app, 'extensions'):\n            app.extensions = {}\n        config = app.extensions.setdefault('whooshee', {})\n        # mapping that caches whoosheers to their indexes; used by `get_or_create_index`\n        config['whoosheers_indexes'] = {}\n        # store a reference to self whoosheers; this way, even whoosheers created after init_app\n        # was called will be found\n        config['whoosheers'] = self.whoosheers\n        config['index_path_root'] = app.config.get('WHOOSHEE_DIR', '') or 'whooshee'\n        config['writer_timeout'] = app.config.get('WHOOSHEE_WRITER_TIMEOUT', 2)\n        config['search_string_min_len'] = app.config.get('WHOOSHEE_MIN_STRING_LEN', 3)\n        config['memory_storage'] = app.config.get(\"WHOOSHEE_MEMORY_STORAGE\", False)\n        config['enable_indexing'] = app.config.get('WHOOSHEE_ENABLE_INDEXING', True)\n\n        if app.config.get('WHOOSHE_MIN_STRING_LEN', None) is not None:\n            warnings.warn(WhoosheeDeprecationWarning(\"The config key WHOOSHE_MIN_STRING_LEN has been renamed to WHOOSHEE_MIN_STRING_LEN. The mispelled config key is deprecated and will be removed in upcoming releases. Change it to WHOOSHEE_MIN_STRING_LEN to suppress this warning\"))\n            config['search_string_min_len'] = app.config.get('WHOOSHE_MIN_STRING_LEN')\n\n        if not os.path.exists(config['index_path_root']):\n            os.makedirs(config['index_path_root'])", "response": "Initialize the extension. It will create the `index_path_root`\n        directory upon initalization but it will **not** create the index.\n        Please use :meth:`reindex` for this.\n\n        :param app: The application instance for which the extension should\n                    be initialized."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_model(self, *index_fields, **kw):\n        # construct subclass of AbstractWhoosheer for a model\n        class ModelWhoosheer(AbstractWhoosheerMeta):\n            @classmethod\n            def _assign_primary(cls, primary, primary_is_numeric, attrs, model):\n                attrs[primary] = getattr(model, primary)\n                if not primary_is_numeric:\n                    if sys.version < '3':\n                        attrs[primary] = unicode(attrs[primary])\n                    else:\n                        attrs[primary] = str(attrs[primary])\n\n\n        mwh = ModelWhoosheer\n\n        def inner(model):\n            mwh.index_subdir = model.__tablename__\n            mwh.models = [model]\n\n            schema_attrs = {}\n            for field in model.__table__.columns:\n                if field.primary_key:\n                    primary = field.name\n                    primary_is_numeric = True\n                    if isinstance(field.type, SQLInteger):\n                        schema_attrs[field.name] = whoosh.fields.NUMERIC(stored=True, unique=True)\n                    else:\n                        primary_is_numeric = False\n                        schema_attrs[field.name] = whoosh.fields.ID(stored=True, unique=True)\n                elif field.name in index_fields:\n                    schema_attrs[field.name] = whoosh.fields.TEXT(**kw)\n            mwh.schema = whoosh.fields.Schema(**schema_attrs)\n            # we can't check with isinstance, because ModelWhoosheer is private\n            # so use this attribute to find out\n            mwh._is_model_whoosheer = True\n\n            @classmethod\n            def update_model(cls, writer, model):\n                attrs = {}\n                cls._assign_primary(primary, primary_is_numeric, attrs, model)\n                for f in index_fields:\n                    attrs[f] = getattr(model, f)\n                    if not isinstance(attrs[f], int):\n                        if sys.version < '3':\n                            attrs[f] = unicode(attrs[f])\n                        else:\n                            attrs[f] = str(attrs[f])\n                writer.update_document(**attrs)\n\n            @classmethod\n            def insert_model(cls, writer, model):\n                attrs = {}\n                cls._assign_primary(primary, primary_is_numeric, attrs, model)\n                for f in index_fields:\n                    attrs[f] = getattr(model, f)\n                    if not isinstance(attrs[f], int):\n                        if sys.version < '3':\n                            attrs[f] = unicode(attrs[f])\n                        else:\n                            attrs[f] = str(attrs[f])\n                writer.add_document(**attrs)\n\n            @classmethod\n            def delete_model(cls, writer, model):\n                writer.delete_by_term(primary, getattr(model, primary))\n\n            setattr(mwh, '{0}_{1}'.format(UPDATE_KWD, model.__name__.lower()), update_model)\n            setattr(mwh, '{0}_{1}'.format(INSERT_KWD, model.__name__.lower()), insert_model)\n            setattr(mwh, '{0}_{1}'.format(DELETE_KWD, model.__name__.lower()), delete_model)\n            model._whoosheer_ = mwh\n            model.whoosh_search = mwh.search\n            self.register_whoosheer(mwh)\n            return model\n\n        return inner", "response": "This creates a new model for fulltext search. This basically creates a simple Whoosheer for the model and registers it with the Whoosheer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_index(cls, app, wh):\n        # TODO: do we really want/need to use camel casing?\n        # everywhere else, there is just .lower()\n        if app.extensions['whooshee']['memory_storage']:\n            storage = RamStorage()\n            index = storage.create_index(wh.schema)\n            assert index\n            return index\n        else:\n            index_path = os.path.join(app.extensions['whooshee']['index_path_root'],\n                                      getattr(wh, 'index_subdir', cls.camel_to_snake(wh.__name__)))\n            if whoosh.index.exists_in(index_path):\n                index = whoosh.index.open_dir(index_path)\n            else:\n                if not os.path.exists(index_path):\n                    os.makedirs(index_path)\n                index = whoosh.index.create_in(index_path, wh.schema)\n            return index", "response": "Creates and opens an index for the given whoosheer and app."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef camel_to_snake(self, s):\n        return self._underscore_re2.sub(r'\\1_\\2', self._underscore_re1.sub(r'\\1_\\2', s)).lower()", "response": "Constructs nice dir name from class name e. g. FooBar to FooBar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_or_create_index(cls, app, wh):\n        if wh in app.extensions['whooshee']['whoosheers_indexes']:\n            return app.extensions['whooshee']['whoosheers_indexes'][wh]\n        index = cls.create_index(app, wh)\n        app.extensions['whooshee']['whoosheers_indexes'][wh] = index\n        return index", "response": "Gets a previously cached index or creates a new one for the given app and whoosheer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_commit(self, changes):\n        if _get_config(self)['enable_indexing'] is False:\n            return None\n\n        for wh in self.whoosheers:\n            if not wh.auto_update:\n                continue\n            writer = None\n            for change in changes:\n                if change[0].__class__ in wh.models:\n                    method_name = '{0}_{1}'.format(change[1], change[0].__class__.__name__.lower())\n                    method = getattr(wh, method_name, None)\n                    if method:\n                        if not writer:\n                            writer = type(self).get_or_create_index(_get_app(self), wh).\\\n                                writer(timeout=_get_config(self)['writer_timeout'])\n                        method(writer, change[0])\n            if writer:\n                writer.commit()", "response": "Method that gets called when a model is changed. This serves\n        to do the actual index writing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reindex(self):\n        for wh in self.whoosheers:\n            index = type(self).get_or_create_index(_get_app(self), wh)\n            writer = index.writer(timeout=_get_config(self)['writer_timeout'])\n            for model in wh.models:\n                method_name = \"{0}_{1}\".format(UPDATE_KWD, model.__name__.lower())\n                for item in model.query.all():\n                    getattr(wh, method_name)(writer, item)\n            writer.commit()", "response": "Reindex all data from the registered models and the related ones."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a domain name in DNS.", "response": "def create_domain(self, domain, ipaddr, params=None):\n        ''' /v1/dns/create_domain\n        POST - account\n        Create a domain name in DNS\n\n        Link: https://www.vultr.com/api/#dns_create_domain\n        '''\n        params = update_params(params, {\n            'domain': domain,\n            'ip': ipaddr\n        })\n        return self.request('/v1/dns/create_domain', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_record(self, domain, name, _type, data, params=None):\n        ''' /v1/dns/create_domain\n        POST - account\n        Add a DNS record\n\n        Link: https://www.vultr.com/api/#dns_create_record\n        '''\n        params = update_params(params, {\n            'domain': domain,\n            'name': name,\n            'type': _type,\n            'data': data\n        })\n        return self.request('/v1/dns/create_record', params, 'POST')", "response": "Create a DNS record in the current account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a domain name and all associated records.", "response": "def delete_domain(self, domain, params=None):\n        ''' /v1/dns/delete_domain\n        POST - account\n        Delete a domain name (and all associated records)\n\n        Link: https://www.vultr.com/api/#dns_delete_domain\n        '''\n        params = update_params(params, {'domain': domain})\n        return self.request('/v1/dns/delete_domain', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_record(self, domain, recordid, params=None):\n        ''' /v1/dns/delete_record\n        POST - account\n        Deletes an individual DNS record\n\n        Link: https://www.vultr.com/api/#dns_delete_record\n        '''\n        params = update_params(params, {\n            'domain': domain,\n            'RECORDID': recordid\n        })\n        return self.request('/v1/dns/delete_record', params, 'POST')", "response": "Delete a DNS record."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef records(self, domain, params=None):\n        ''' /v1/dns/records\n        GET - account\n        List all the records associated with a particular domain\n\n        Link: https://www.vultr.com/api/#dns_records\n        '''\n        params = update_params(params, {'domain': domain})\n        return self.request('/v1/dns/records', params, 'GET')", "response": "GET - account\n        List all the records associated with a particular domain"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a DNS record in a domain.", "response": "def update_record(self, domain, recordid, params=None):\n        ''' /v1/dns/update_record\n        POST - account\n        Update a DNS record\n\n        Link: https://www.vultr.com/api/#dns_update_record\n        '''\n        params = update_params(params, {\n            'domain': domain,\n            'RECORDID': recordid\n        })\n        return self.request('/v1/dns/update_record', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef group_list(self, params=None):\n        ''' /v1/firewall/group_list\n        GET - account\n        List all firewall groups on the current account.\n\n        Link: https://www.vultr.com/api/#firewall_group_list\n        '''\n        params = params if params else dict()\n        return self.request('/v1/firewall/group_list', params, 'GET')", "response": "This API endpoint returns a list of firewall groups on the current account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting information about the current set of keys.", "response": "def info(self, params=None):\n        ''' /v1/account/info\n        GET - account\n        Retrieve information about the current account\n\n        Link: https://www.vultr.com/api/#account_info\n        '''\n        params = params if params else dict()\n        return self.request('/v1/account/info', params, 'GET')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump_info():\n    '''Shows various details about the account & servers'''\n    vultr = Vultr(API_KEY)\n\n    try:\n        logging.info('Listing account info:\\n%s', dumps(\n            vultr.account.info(), indent=2\n        ))\n\n        logging.info('Listing apps:\\n%s', dumps(\n            vultr.app.list(), indent=2\n        ))\n\n        logging.info('Listing backups:\\n%s', dumps(\n            vultr.backup.list(), indent=2\n        ))\n\n        logging.info('Listing DNS:\\n%s', dumps(\n            vultr.dns.list(), indent=2\n        ))\n\n        logging.info('Listing ISOs:\\n%s', dumps(\n            vultr.iso.list(), indent=2\n        ))\n\n        logging.info('Listing OSs:\\n%s', dumps(\n            vultr.os.list(), indent=2\n        ))\n\n        logging.info('Listing plans:\\n%s', dumps(\n            vultr.plans.list(), indent=2\n        ))\n\n        logging.info('Listing regions:\\n%s', dumps(\n            vultr.regions.list(), indent=2\n        ))\n\n        logging.info('Listing servers:\\n%s', dumps(\n            vultr.server.list(), indent=2\n        ))\n\n        logging.info('Listing snapshots:\\n%s', dumps(\n            vultr.snapshot.list(), indent=2\n        ))\n\n        logging.info('Listing SSH keys:\\n%s', dumps(\n            vultr.sshkey.list(), indent=2\n        ))\n\n        logging.info('Listing startup scripts:\\n%s', dumps(\n            vultr.startupscript.list(), indent=2\n        ))\n    except VultrError as ex:\n        logging.error('VultrError: %s', ex)", "response": "Shows various details about the account & servers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef availability(self, dcid, params=None):\n        ''' /v1/regions/availability\n        GET - public\n        Retrieve a list of the VPSPLANIDs currently available\n        in this location. If your account has special plans available,\n        you will need to pass your api_key in in order to see them.\n        For all other accounts, the API key is not optional.\n\n        Link: https://www.vultr.com/api/#regions_region_available\n        '''\n        params = update_params(params, {'DCID': dcid})\n        return self.request('/v1/regions/availability', params, 'GET')", "response": "Get a list of the VPSPLANIDs currently available in this region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_params(params, updates):\n    '''Merges updates into params'''\n    params = params.copy() if isinstance(params, dict) else dict()\n    params.update(updates)\n    return params", "response": "Merges updates into params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadjust the request per second at run - time", "response": "def set_requests_per_second(self, req_per_second):\n        '''Adjusts the request/second at run-time'''\n        self.req_per_second = req_per_second\n        self.req_duration = 1 / self.req_per_second"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _request_get_helper(self, url, params=None):\n        '''API GET request helper'''\n        if not isinstance(params, dict):\n            params = dict()\n\n        if self.api_key:\n            params['api_key'] = self.api_key\n        return requests.get(url, params=params, timeout=60)", "response": "API GET request helper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(self, path, params=None, method='GET'):\n        '''API request / call method'''\n        _start = time.time()\n\n        if not path.startswith('/'):\n            path = '/' + path\n\n        resp = self._request_helper(self.api_endpoint + path, params, method)\n\n        if resp.status_code != 200:\n            if resp.status_code == 400:\n                raise VultrError('Invalid API location. Check the URL that' +\n                                 ' you are using')\n            elif resp.status_code == 403:\n                raise VultrError('Invalid or missing API key. Check that' +\n                                 ' your API key is present and matches' +\n                                 ' your assigned key')\n            elif resp.status_code == 405:\n                raise VultrError('Invalid HTTP method. Check that the' +\n                                 ' method (POST|GET) matches what the' +\n                                 ' documentation indicates')\n            elif resp.status_code == 412:\n                raise VultrError('Request failed. Check the response body ' +\n                                 'for a more detailed description. Body: \\n' +\n                                 resp.text)\n            elif resp.status_code == 500:\n                raise VultrError('Internal server error. Try again at a' +\n                                 ' later time')\n            elif resp.status_code == 503:\n                raise VultrError('Rate limit hit. API requests are limited' +\n                                 ' to an average of 1/s. Try your request' +\n                                 ' again later.')\n\n        # very simplistic synchronous rate limiting;\n        _elapsed = time.time() - _start\n        if _elapsed < self.req_duration:\n            time.sleep(self.req_duration - _elapsed)\n\n        # return an empty json object if the API doesn't respond with a value.\n        return resp.json() if resp.text else json_module.loads('{}')", "response": "API request / call method"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a snapshot from an existing virtual machine.", "response": "def create(self, subid, params=None):\n        ''' /v1/snapshot/create\n        POST - account\n        Create a snapshot from an existing virtual machine.\n        The virtual machine does not need to be stopped.\n\n        Link: https://www.vultr.com/api/#snapshot_create\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/snapshot/create', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef destroy(self, subid, ipaddr, params=None):\n        ''' /v1/server/destroy_ipv4\n        POST - account\n        Removes a secondary IPv4 address from a server. Your server will be\n        hard-restarted. We suggest halting the machine gracefully before\n        removing IPs.\n\n        Link: https://www.vultr.com/api/#server_destroy_ipv4\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'ip': ipaddr\n        })\n        return self.request('/v1/server/destroy_ipv4', params, 'POST')", "response": "This method deletes a secondary IPv4 address from a server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self, subid, params=None):\n        ''' /v1/server/list_ipv4\n        GET - account\n        List the IPv4 information of a virtual machine. IP information is only\n        available for virtual machines in the \"active\" state.\n\n        Link: https://www.vultr.com/api/#server_list_ipv4\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/list_ipv4', params, 'GET')", "response": "List the IPv4 information of a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse_set(self, subid, ipaddr, entry, params=None):\n        ''' /v1/server/reverse_set_ipv4\n        POST - account\n        Set a reverse DNS entry for an IPv4 address of a virtual machine. Upon\n        success, DNS changes may take 6-12 hours to become active.\n\n        Link: https://www.vultr.com/api/#server_reverse_set_ipv4\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'ip': ipaddr,\n            'entry': entry\n        })\n        return self.request('/v1/server/reverse_set_ipv4', params, 'POST')", "response": "This method allows you to change the reverse DNS entry for an IPv4 address of a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the bandwidth used by a virtual machine.", "response": "def bandwidth(self, subid, params=None):\n        ''' /v1/server/bandwidth\n        GET - account\n        Get the bandwidth used by a virtual machine\n\n        Link: https://www.vultr.com/api/#server_bandwidth\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/bandwidth', params, 'GET')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new virtual machine.", "response": "def create(self, dcid, vpsplanid, osid, params=None):\n        ''' /v1/server/create\n        POST - account\n        Create a new virtual machine. You will start being billed for this\n        immediately. The response only contains the SUBID for the new machine.\n        You should use v1/server/list to poll and wait for the machine to be\n        created (as this does not happen instantly).\n\n        Link: https://www.vultr.com/api/#server_create\n        '''\n        params = update_params(params, {\n            'DCID': dcid,\n            'VPSPLANID': vpsplanid,\n            'OSID': osid\n        })\n        return self.request('/v1/server/create', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_data(self, subid, params=None):\n        ''' /v1/server/get_user_data\n        GET - account\n        Retrieves the (base64 encoded) user-data for this subscription.\n\n        Link: https://www.vultr.com/api/#server_get_user_data\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/get_user_data', params, 'GET')", "response": "Get the base64 encoded user - data for the specified subscription."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhalting a virtual machine.", "response": "def halt(self, subid, params=None):\n        ''' /v1/server/halt\n        POST - account\n        Halt a virtual machine. This is a hard power off (basically, unplugging\n        the machine). The data on the machine will not be modified, and you\n        will still be billed for the machine. To completely delete a\n        machine, see v1/server/destroy\n\n        Link: https://www.vultr.com/api/#server_halt\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/halt', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef label_set(self, subid, label, params=None):\n        ''' /v1/server/label_set\n        POST - account\n        Set the label of a virtual machine.\n\n        Link: https://www.vultr.com/api/#server_label_set\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'label': label\n        })\n        return self.request('/v1/server/label_set', params, 'POST')", "response": "This method allows you to change the label of a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the operating system of a virtual machine.", "response": "def os_change(self, subid, osid, params=None):\n        ''' /v1/server/os_change\n        POST - account\n        Changes the operating system of a virtual machine. All data will be\n        permanently lost.\n\n        Link: https://www.vultr.com/api/#server_os_change\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'OSID': osid\n        })\n        return self.request('/v1/server/os_change', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef os_change_list(self, subid, params=None):\n        ''' /v1/server/os_change_list\n        GET - account\n        Retrieves a list of operating systems to which this server can be\n        changed.\n\n        Link: https://www.vultr.com/api/#server_os_change_list\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/os_change_list', params, 'GET')", "response": "This API endpoint returns a list of operating systems that can be changed for a given locale."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reboot(self, subid, params=None):\n        ''' /v1/server/reboot\n        POST - account\n        Reboot a virtual machine. This is a hard reboot\n        (basically, unplugging the machine).\n\n        Link: https://www.vultr.com/api/#server_reboot\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/reboot', params, 'POST')", "response": "Reboot a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reinstall(self, subid, params=None):\n        ''' /v1/server/reinstall\n        POST - account\n        Reinstall the operating system on a virtual machine. All data\n        will be permanently lost, but the IP address will remain the\n        same There is no going back from this call.\n\n        Link: https://www.vultr.com/api/#server_reinstall\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/reinstall', params, 'POST')", "response": "Reinstall the operating system on a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore_snapshot(self, subid, snapshotid, params=None):\n        ''' /v1/server/restore_snapshot\n        POST - account\n        Restore the specificed snapshot to the virtual machine.\n        Any data already on the virtual machine will be lost.\n\n        Link: https://www.vultr.com/api/#server_restore_snapshot\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'SNAPSHOTID': snapshotid\n        })\n        return self.request('/v1/server/restore_snapshot', params, 'POST')", "response": "This API endpoint allows you to restore a specificed snapshot to the virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_user_data(self, subid, userdata, params=None):\n        ''' /v1/server/set_user_data\n        POST - account\n        Sets the cloud-init user-data (base64) for this subscription.\n        Note that user-data is not supported on every operating\n        system, and is generally only provided on instance startup.\n\n        Link: https://www.vultr.com/api/#server_set_user_data\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'userdata': userdata\n        })\n        return self.request('/v1/server/set_user_data', params, 'POST')", "response": "Set the cloud - init user - data for this subscription."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start(self, subid, params=None):\n        ''' /v1/server/start\n        POST - account\n        Start a virtual machine. If the machine is already\n        running, it will be restarted.\n\n        Link: https://www.vultr.com/api/#server_start\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/start', params, 'POST')", "response": "Start a virtual machine with the specified subid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupgrade the plan of a virtual machine.", "response": "def upgrade_plan(self, subid, vpsplanid, params=None):\n        ''' /v1/server/upgrade_plan\n        POST - account\n        Upgrade the plan of a virtual machine. The virtual machine will be\n        rebooted upon a successful upgrade.\n\n        Link: https://www.vultr.com/api/#server_upgrade_plan\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'VPSPLANID': vpsplanid\n        })\n        return self.request('/v1/server/upgrade_plan', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new SSH Key in the account.", "response": "def create(self, name, ssh_key, params=None):\n        ''' /v1/sshkey/create\n        POST - account\n        Create a new SSH Key\n\n        Link: https://www.vultr.com/api/#sshkey_create\n        '''\n        params = update_params(params, {\n            'name': name,\n            'ssh_key': ssh_key\n        })\n        return self.request('/v1/sshkey/create', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef destroy(self, sshkeyid, params=None):\n        ''' /v1/sshkey/destroy\n        POST - account\n        Remove a SSH key. Note that this will not remove\n        the key from any machines that already have it.\n\n        Link: https://www.vultr.com/api/#sshkey_destroy\n        '''\n        params = update_params(params, {'SSHKEYID': sshkeyid})\n        return self.request('/v1/sshkey/destroy', params, 'POST')", "response": "This method deletes an SSH key from the account."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, sshkeyid, params=None):\n        ''' /v1/sshkey/update\n        POST - account\n        Update an existing SSH Key. Note that this will only\n        update newly installed machines. The key will not be\n        updated on any existing machines.\n\n        Link: https://www.vultr.com/api/#sshkey_update\n        '''\n        params = update_params(params, {'SSHKEYID': sshkeyid})\n        return self.request('/v1/sshkey/update', params, 'POST')", "response": "Update an existing SSH Key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_ipv6(self, subid, params=None):\n        ''' /v1/server/list_ipv6\n        GET - account\n        List the IPv6 information of a virtual machine. IP information is only\n        available for virtual machines in the \"active\" state. If the virtual\n        machine does not have IPv6 enabled, then an empty array is returned.\n\n        Link: https://www.vultr.com/api/#server_list_ipv6\n        '''\n        params = update_params(params, {'SUBID': subid})\n        return self.request('/v1/server/list_ipv6', params, 'GET')", "response": "List the IPv6 information of a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reverse_delete_ipv6(self, subid, ipaddr, params=None):\n        ''' /v1/server/reverse_delete_ipv6\n        POST - account\n        Remove a reverse DNS entry for an IPv6 address of a virtual machine.\n        Upon success, DNS changes may take 6-12 hours to become active.\n\n        Link: https://www.vultr.com/api/#server_reverse_delete_ipv6\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'ip': ipaddr\n        })\n        return self.request('/v1/server/reverse_delete_ipv6', params, 'POST')", "response": "This method deletes a reverse DNS entry for an IPv6 address of a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reverse_set_ipv6(self, subid, ipaddr, entry, params=None):\n        ''' /v1/server/reverse_set_ipv6\n        POST - account\n        Set a reverse DNS entry for an IPv6 address of a virtual machine. Upon\n        success, DNS changes may take 6-12 hours to become active.\n\n        Link: https://www.vultr.com/api/#server_reverse_set_ipv6\n        '''\n        params = update_params(params, {\n            'SUBID': subid,\n            'ip': ipaddr,\n            'entry': entry\n        })\n        return self.request('/v1/server/reverse_set_ipv6', params, 'POST')", "response": "This method allows you to change the reverse DNS entry for an IPv6 address of a virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef destroy(self, scriptid, params=None):\n        ''' /v1/startupscript/destroy\n        POST - account\n        Remove a startup script\n\n        Link: https://www.vultr.com/api/#startupscript_destroy\n        '''\n        params = update_params(params, {'SCRIPTID': scriptid})\n        return self.request('/v1/startupscript/destroy', params, 'POST')", "response": "This method is used to remove a startup script from the set of available startup scripts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating an existing startup script with the specified ID.", "response": "def update(self, scriptid, params=None):\n        ''' /v1/startupscript/update\n        POST - account\n        Update an existing startup script\n\n        Link: https://www.vultr.com/api/#startupscript_update\n        '''\n        params = update_params(params, {'SCRIPTID': scriptid})\n        return self.request('/v1/startupscript/update', params, 'POST')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef halt_running():\n    '''Halts all running servers'''\n    vultr = Vultr(API_KEY)\n\n    try:\n            serverList = vultr.server.list()\n            #logging.info('Listing servers:\\n%s', dumps(\n            #serverList, indent=2\n        #))\n    except VultrError as ex:\n        logging.error('VultrError: %s', ex)\n\n    for serverID in serverList:\n        if serverList[serverID]['power_status'] == 'running':\n            logging.info(serverList[serverID]['label'] + \" will be gracefully shutdown.\")\n            vultr.server.halt(serverID)", "response": "Halts all running servers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntag arxiv report numbers in a single line.", "response": "def tag_arxiv(line):\n    \"\"\"Tag arxiv report numbers\n\n    We handle arXiv in 2 ways:\n    * starting with arXiv:1022.1111\n    * this format exactly 9999.9999\n    We also format the output to the standard arxiv notation:\n    * arXiv:2007.12.1111\n    * arXiv:2007.12.1111v2\n    \"\"\"\n    def tagger(match):\n        groups = match.groupdict()\n        if match.group('suffix'):\n            groups['suffix'] = ' ' + groups['suffix']\n        else:\n            groups['suffix'] = ''\n        return u'<cds.REPORTNUMBER>arXiv:%(year)s'\\\n            u'%(month)s.%(num)s%(suffix)s' \\\n            u'</cds.REPORTNUMBER>' % groups\n\n    line = re_arxiv_5digits.sub(tagger, line)\n    line = re_arxiv.sub(tagger, line)\n    line = re_new_arxiv_5digits.sub(tagger, line)\n    line = re_new_arxiv.sub(tagger, line)\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tag_arxiv_more(line):\n    line = RE_ARXIV_CATCHUP.sub(ur\"\\g<suffix>/\\g<year>\\g<month>\\g<num>\", line)\n\n    for report_re, report_repl in RE_OLD_ARXIV:\n        report_number = report_repl + ur\"/\\g<num>\"\n        line = report_re.sub(\n            u'<cds.REPORTNUMBER>' + report_number + u'</cds.REPORTNUMBER>',\n            line\n        )\n    return line", "response": "Tag arXiv report numbers with new arXiv report numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntags POS volume number as POS.", "response": "def tag_pos_volume(line):\n    \"\"\"Tag POS volume number\n\n    POS is journal that has special volume numbers\n    e.g. PoS LAT2007 (2007) 369\n    \"\"\"\n    def tagger(match):\n        groups = match.groupdict()\n        try:\n            year = match.group('year')\n        except IndexError:\n            # Extract year from volume name\n            # which should always include the year\n            g = re.search(re_pos_year_num, match.group(\n                'volume_num'), re.UNICODE)\n            year = g.group(0)\n\n        if year:\n            groups[\n                'year'] = ' <cds.YR>(%s)</cds.YR>' % year.strip().strip('()')\n        else:\n            groups['year'] = ''\n\n        return '<cds.JOURNAL>PoS</cds.JOURNAL>' \\\n            ' <cds.VOL>%(volume_name)s%(volume_num)s</cds.VOL>' \\\n            '%(year)s' \\\n            ' <cds.PG>%(page)s</cds.PG>' % groups\n\n    for p in re_pos:\n        line = p.sub(tagger, line)\n\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_numeration_more(line):\n    # First, attempt to use marked-up titles\n    patterns = (\n        re_correct_numeration_2nd_try_ptn1,\n        re_correct_numeration_2nd_try_ptn2,\n        re_correct_numeration_2nd_try_ptn3,\n        re_correct_numeration_2nd_try_ptn4,\n    )\n    for pattern in patterns:\n        match = pattern.search(line)\n        if match:\n            info = match.groupdict()\n            series = extract_series_from_volume(info['vol'])\n            if not info['vol_num']:\n                info['vol_num'] = info['vol_num_alt']\n            if not info['vol_num']:\n                info['vol_num'] = info['vol_num_alt2']\n            return {'year': info.get('year', None),\n                    'series': series,\n                    'volume': info['vol_num'],\n                    'page': info['page'] or info['jinst_page'],\n                    'page_end': info['page_end'],\n                    'len': len(info['aftertitle'])}\n\n    return None", "response": "Look for other numeration in line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_tagged_publisher(reading_line,\n                         matched_publisher,\n                         startpos,\n                         true_replacement_index,\n                         extras,\n                         kb_publishers):\n    \"\"\"In rebuilding the line, add an identified periodical TITLE (standardised\n       and tagged) into the line.\n       @param reading_line: (string) The reference line before capitalization\n        was performed, and before REPORT-NUMBERs and TITLEs were stripped out.\n       @param len_title: (integer) the length of the matched TITLE.\n       @param matched_title: (string) the matched TITLE text.\n       @param previous_match: (string) the previous periodical TITLE citation to\n        have been matched in the current reference line. It is used when\n        replacing an IBID instance in the line.\n       @param startpos: (integer) the pointer to the next position in the\n        reading-line from which to start rebuilding.\n       @param true_replacement_index: (integer) the replacement index of the\n        matched TITLE in the reading-line, with stripped punctuation and\n        whitespace accounted for.\n       @param extras: (integer) extras to be added into the replacement index.\n       @param standardised_titles: (dictionary) the standardised versions of\n        periodical titles, keyed by their various non-standard versions.\n       @return: (tuple) containing a string (the rebuilt line segment), an\n        integer (the next 'startpos' in the reading-line), and an other string\n        (the newly updated previous-match).\n    \"\"\"\n    # Fill 'rebuilt_line' (the segment of the line that is being rebuilt to\n    # include the tagged and standardised periodical TITLE) with the contents\n    # of the reading-line, up to the point of the matched TITLE:\n    rebuilt_line = reading_line[startpos:true_replacement_index]\n    # This is a normal title, not an IBID\n    rebuilt_line += \"<cds.PUBLISHER>%(title)s</cds.PUBLISHER>\" \\\n                    % {'title': kb_publishers[matched_publisher]['repl']}\n    # Compute new start pos\n    startpos = true_replacement_index + len(matched_publisher) + extras\n\n    # return the rebuilt line-segment, the position (of the reading line) from\n    # which the next part of the rebuilt line should be started, and the newly\n    # updated previous match.\n\n    return rebuilt_line, startpos", "response": "In rebuilding the line add a tagged periodical TITLE and a standardised version of the publisher."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_replacement_types(titles, reportnumbers, publishers):\n    rep_types = {}\n    for item_idx in titles:\n        rep_types[item_idx] = \"journal\"\n    for item_idx in reportnumbers:\n        rep_types[item_idx] = \"reportnumber\"\n    for item_idx in publishers:\n        rep_types[item_idx] = \"publisher\"\n    return rep_types", "response": "Given the indices of the titles reportnumbers and publishers that have been\n       recognised within a reference line create a dictionary keyed by each item in the line that contains the replacement types at the given locations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a line where Authors have been tagged and all other tags have been replaced with underscores go through and try to tag them into the H tagging process.", "response": "def identify_and_tag_collaborations(line, collaborations_kb):\n    \"\"\"Given a line where Authors have been tagged, and all other tags\n       and content has been replaced with underscores, go through and try\n       to identify extra items of data which should be placed into 'h'\n       subfields.\n       Later on, these tagged pieces of information will be merged into\n       the content of the most recently found author. This is separated\n       from the author tagging procedure since separate tags can be used,\n       which won't influence the reference splitting heuristics\n       (used when looking at mulitple <AUTH> tags in a line).\n    \"\"\"\n    for dummy_collab, re_collab in collaborations_kb.iteritems():\n        matches = re_collab.finditer(strip_tags(line))\n\n        for match in reversed(list(matches)):\n            line = line[:match.start()] \\\n                + CFG_REFEXTRACT_MARKER_OPENING_COLLABORATION \\\n                + match.group(1).strip(\".,:;- [](){}\") \\\n                + CFG_REFEXTRACT_MARKER_CLOSING_COLLABORATION \\\n                + line[match.end():]\n\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identify_and_tag_authors(line, authors_kb):\n    re_auth, re_auth_near_miss = get_author_regexps()\n\n    # Replace authors which do not convert well from utf-8\n    for pattern, repl in authors_kb:\n        line = line.replace(pattern, repl)\n\n    output_line = line\n\n    # We matched authors here\n    line = strip_tags(output_line)\n    matched_authors = list(re_auth.finditer(line))\n    # We try to have better results by unidecoding\n    unidecoded_line = strip_tags(unidecode(output_line))\n    matched_authors_unidecode = list(re_auth.finditer(unidecoded_line))\n\n    if len(matched_authors_unidecode) > len(matched_authors):\n        output_line = unidecode(output_line)\n        matched_authors = matched_authors_unidecode\n\n    # If there is at least one matched author group\n    if matched_authors:\n        matched_positions = []\n        preceeding_text_string = line\n        preceeding_text_start = 0\n        for auth_no, match in enumerate(matched_authors):\n            # Only if there are no underscores or closing arrows found in the matched author group\n            # This must be checked for here, as it cannot be applied to the re without clashing with\n            # other Unicode characters\n            if line[match.start():match.end()].find(\"_\") == -1:\n                # Has the group with name 'et' (for 'et al') been found in the pattern?\n                # Has the group with name 'es' (for ed. before the author) been found in the pattern?\n                # Has the group with name 'ee' (for ed. after the author) been\n                # found in the pattern?\n                matched_positions.append({\n                    'start': match.start(),\n                    'end': match.end(),\n                    'etal': match.group('et') or match.group('et2'),\n                    'ed_start': match.group('es'),\n                    'ed_end': match.group('ee'),\n                    'multi_auth': match.group('multi_auth'),\n                    'multi_surs': match.group('multi_surs'),\n                    'text_before': preceeding_text_string[preceeding_text_start:match.start()],\n                    'auth_no': auth_no,\n                    'author_names': match.group('author_names')\n                })\n                # Save the end of the match, from where to snip the misc text\n                # found before an author match\n                preceeding_text_start = match.end()\n\n        # Work backwards to avoid index problems when adding AUTH tags\n        matched_positions.reverse()\n        for m in matched_positions:\n            dump_in_misc = False\n            start = m['start']\n            end = m['end']\n\n            # Check the text before the current match to see if it has a bad\n            # 'et al'\n            lower_text_before = m['text_before'].strip().lower()\n            for e in etal_matches:\n                if lower_text_before.endswith(e):\n                    # If so, this author match is likely to be a bad match on a\n                    # missed title\n                    dump_in_misc = True\n                    break\n\n            # An AND found here likely indicates a missed author before this text\n            # Thus, triggers weaker author searching, within the previous misc text\n            # (Check the text before the current match to see if it has a bad 'and')\n            # A bad 'and' will only be denoted as such if there exists only one author after it\n            # and the author group is legit (not to be dumped in misc)\n            if not dump_in_misc and not (m['multi_auth'] or m['multi_surs']) \\\n                    and (lower_text_before.endswith(' and')):\n                # Search using a weaker author pattern to try and find the\n                # missed author(s) (cut away the end 'and')\n                weaker_match = re_auth_near_miss.match(m['text_before'])\n                if weaker_match and not (weaker_match.group('es') or weaker_match.group('ee')):\n                    # Change the start of the author group to include this new\n                    # author group\n                    start = start - \\\n                        (len(m['text_before']) - weaker_match.start())\n                # Still no match, do not add tags for this author match.. dump\n                # it into misc\n                else:\n                    dump_in_misc = True\n\n            add_to_misc = \"\"\n            # If a semi-colon was found at the end of this author group, keep it in misc\n            # so that it can be looked at for splitting heurisitics\n            if len(output_line) > m['end']:\n                if output_line[m['end']].strip(\" ,.\") == ';':\n                    add_to_misc = ';'\n\n            # Standardize eds. notation\n            tmp_output_line = re.sub(re_ed_notation, '(ed.)',\n                                     output_line[start:end], re.IGNORECASE)\n            # Standardize et al. notation\n            tmp_output_line = re.sub(re_etal, 'et al.',\n                                     tmp_output_line, re.IGNORECASE)\n            # Strip\n            tmp_output_line = tmp_output_line.lstrip('.').strip(\",:;- [](\")\n            if not tmp_output_line.endswith('(ed.)'):\n                tmp_output_line = tmp_output_line.strip(')')\n\n            # ONLY wrap author data with tags IF there is no evidence that it is an\n            # ed. author. (i.e. The author is not referred to as an editor)\n            # Does this author group string have 'et al.'?\n            if m['etal'] and not (m['ed_start'] or m['ed_end'] or dump_in_misc):\n                output_line = output_line[:start] \\\n                    + \"<cds.AUTHetal>\" \\\n                    + tmp_output_line \\\n                    + CFG_REFEXTRACT_MARKER_CLOSING_AUTHOR_ETAL \\\n                    + add_to_misc \\\n                    + output_line[end:]\n            elif not (m['ed_start'] or m['ed_end'] or dump_in_misc):\n                # Insert the std (standard) tag\n                output_line = output_line[:start] \\\n                    + \"<cds.AUTHstnd>\" \\\n                    + tmp_output_line \\\n                    + CFG_REFEXTRACT_MARKER_CLOSING_AUTHOR_STND \\\n                    + add_to_misc \\\n                    + output_line[end:]\n            # Apply the 'include in $h' method to author groups marked as\n            # editors\n            elif m['ed_start'] or m['ed_end']:\n                ed_notation = \" (eds.)\"\n                # Standardize et al. notation\n                tmp_output_line = re.sub(re_etal, 'et al.',\n                                         m['author_names'], re.IGNORECASE)\n                # remove any characters which denote this author group\n                # to be editors, just take the\n                # author names, and append '(ed.)'\n                output_line = output_line[:start] \\\n                    + \"<cds.AUTHincl>\" \\\n                    + tmp_output_line.strip(\",:;- [](\") \\\n                    + ed_notation \\\n                    + CFG_REFEXTRACT_MARKER_CLOSING_AUTHOR_INCL \\\n                    + add_to_misc \\\n                    + output_line[end:]\n\n    return output_line", "response": "Given a reference look for a group of author names place tags around the author group and return the newly tagged line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive two dictionaries of totals where each total refers to a key in the dictionary add the totals.", "response": "def sum_2_dictionaries(dicta, dictb):\n    \"\"\"Given two dictionaries of totals, where each total refers to a key\n       in the dictionary, add the totals.\n       E.g.:  dicta = { 'a' : 3, 'b' : 1 }\n              dictb = { 'a' : 1, 'c' : 5 }\n              dicta + dictb = { 'a' : 4, 'b' : 1, 'c' : 5 }\n       @param dicta: (dictionary)\n       @param dictb: (dictionary)\n       @return: (dictionary) - the sum of the 2 dictionaries\n    \"\"\"\n    dict_out = dicta.copy()\n    for key in dictb.keys():\n        if 'key' in dict_out:\n            # Add the sum for key in dictb to that of dict_out:\n            dict_out[key] += dictb[key]\n        else:\n            # the key is not in the first dictionary - add it directly:\n            dict_out[key] = dictb[key]\n    return dict_out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef identify_ibids(line):\n    ibid_match_txt = {}\n    # Record details of each matched ibid:\n    for m_ibid in re_ibid.finditer(line):\n        ibid_match_txt[m_ibid.start()] = m_ibid.group(0)\n        # Replace matched text in line with underscores:\n        line = line[0:m_ibid.start()] + \\\n            \"_\" * len(m_ibid.group(0)) + \\\n            line[m_ibid.end():]\n\n    return ibid_match_txt, line", "response": "Identify IBIDs within the line and return a dictionary containing the position and length of each matched IBID and the line with the IBIDs replaced with underscores."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_numeration(line):\n    patterns = (\n        # vol,page,year\n        re_numeration_vol_page_yr,\n        re_numeration_vol_nucphys_page_yr,\n        re_numeration_nucphys_vol_page_yr,\n        # With sub volume\n        re_numeration_vol_subvol_nucphys_yr_page,\n        re_numeration_vol_nucphys_yr_subvol_page,\n        # vol,year,page\n        re_numeration_vol_yr_page,\n        re_numeration_nucphys_vol_yr_page,\n        re_numeration_vol_nucphys_series_yr_page,\n        # vol,page,year\n        re_numeration_vol_series_nucphys_page_yr,\n        re_numeration_vol_nucphys_series_page_yr,\n        # year,vol,page\n        re_numeration_yr_vol_page,\n    )\n\n    for pattern in patterns:\n        match = pattern.match(line)\n        if match:\n            info = match.groupdict()\n            series = info.get('series', None)\n            if not series:\n                series = extract_series_from_volume(info['vol'])\n            if not info['vol_num']:\n                info['vol_num'] = info['vol_num_alt']\n            if not info['vol_num']:\n                info['vol_num'] = info['vol_num_alt2']\n            return {'year': info.get('year', None),\n                    'series': series,\n                    'volume': info['vol_num'],\n                    'page': info['page'] or info['jinst_page'],\n                    'page_end': info['page_end'],\n                    'len': match.end()}\n\n    return None", "response": "Given a reference line attempt to locate instances of citation\n       numeration in the line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef identify_journals(line, kb_journals):\n    periodical_title_search_kb = kb_journals[0]\n    periodical_title_search_keys = kb_journals[2]\n\n    title_matches = {}            # the text matched at the given line\n    # location (i.e. the title itself)\n    titles_count = {}             # sum totals of each 'bad title found in\n    # line.\n\n    # Begin searching:\n    for title in periodical_title_search_keys:\n        # search for all instances of the current periodical title\n        # in the line:\n        # for each matched periodical title:\n        for title_match in periodical_title_search_kb[title].finditer(line):\n\n            if title not in titles_count:\n                # Add this title into the titles_count dictionary:\n                titles_count[title] = 1\n            else:\n                # Add 1 to the count for the given title:\n                titles_count[title] += 1\n\n            # record the details of this title match:\n            # record the match length:\n            title_matches[title_match.start()] = title\n\n            len_to_replace = len(title)\n\n            # replace the matched title text in the line it n * '_',\n            # where n is the length of the matched title:\n            line = u\"\".join((line[:title_match.start()],\n                             u\"_\" * len_to_replace,\n                             line[title_match.start() + len_to_replace:]))\n\n    # return recorded information about matched periodical titles,\n    # along with the newly changed working line:\n    return title_matches, line, titles_count", "response": "Attempts to identify all periodical titles in a working reference line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to identify all preprint report numbers in a given line.", "response": "def identify_report_numbers(line, kb_reports):\n    \"\"\"Attempt to identify all preprint report numbers in a reference\n       line.\n       Report numbers will be identified, their information (location\n       in line, length in line, and standardised replacement version)\n       will be recorded, and they will be replaced in the working-line\n       by underscores.\n       @param line: (string) - the working reference line.\n       @param preprint_repnum_search_kb: (dictionary) - contains the\n        regexp patterns used to identify preprint report numbers.\n       @param preprint_repnum_standardised_categs: (dictionary) -\n        contains the standardised 'category' of a given preprint report\n        number.\n       @return: (tuple) - 3 elements:\n           * a dictionary containing the lengths in the line of the\n             matched preprint report numbers, keyed by the index at\n             which each match was found in the line.\n           * a dictionary containing the replacement strings (standardised\n             versions) of preprint report numbers that were matched in\n             the line.\n           * a string, that is the new version of the working reference\n             line, in which any matched preprint report numbers have been\n             replaced by underscores.\n        Returned tuple is therefore in the following order:\n            (matched-reportnum-lengths, matched-reportnum-replacements,\n             working-line)\n    \"\"\"\n    def _by_len(a, b):\n        \"\"\"Comparison function used to sort a list by the length of the\n           strings in each element of the list.\n        \"\"\"\n        if len(a[1]) < len(b[1]):\n            return 1\n        elif len(a[1]) == len(b[1]):\n            return 0\n        else:\n            return -1\n\n    repnum_matches_matchlen = {}  # info about lengths of report numbers\n    # matched at given locations in line\n    repnum_matches_repl_str = {}  # standardised report numbers matched\n    # at given locations in line\n\n    repnum_search_kb, repnum_standardised_categs = kb_reports\n    repnum_categs = repnum_standardised_categs.keys()\n    repnum_categs.sort(_by_len)\n\n    # Handle CERN/LHCC/98-013\n    line = line.replace('/', ' ')\n\n    # try to match preprint report numbers in the line:\n    for categ in repnum_categs:\n        # search for all instances of the current report\n        # numbering style in the line:\n        repnum_matches_iter = repnum_search_kb[categ].finditer(line)\n\n        # for each matched report number of this style:\n        for repnum_match in repnum_matches_iter:\n            # Get the matched text for the numeration part of the\n            # preprint report number:\n            numeration_match = repnum_match.group('numn')\n            # clean/standardise this numeration text:\n            numeration_match = numeration_match.replace(\" \", \"-\")\n            numeration_match = re_multiple_hyphens.sub(\"-\", numeration_match)\n            numeration_match = numeration_match.replace(\"/-\", \"/\")\n            numeration_match = numeration_match.replace(\"-/\", \"/\")\n            numeration_match = numeration_match.replace(\"-/-\", \"/\")\n\n            # replace the found preprint report number in the\n            # string with underscores\n            # (this will replace chars in the lower-cased line):\n            line = line[0:repnum_match.start(1)] \\\n                + \"_\" * len(repnum_match.group(1)) + line[repnum_match.end(1):]\n\n            # record the information about the matched preprint report number:\n            # total length in the line of the matched preprint report number:\n            repnum_matches_matchlen[repnum_match.start(1)] = \\\n                len(repnum_match.group(1))\n            # standardised replacement for the matched preprint report number:\n            repnum_matches_repl_str[repnum_match.start(1)] = \\\n                repnum_standardised_categs[categ] \\\n                + numeration_match\n\n    # return recorded information about matched report numbers, along with\n    # the newly changed working line:\n    return repnum_matches_matchlen, repnum_matches_repl_str, line"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identify_and_tag_URLs(line):\n    # Take a copy of the line:\n    line_pre_url_check = line\n    # Dictionaries to record details of matched URLs:\n    found_url_full_matchlen = {}\n    found_url_urlstring = {}\n    found_url_urldescr = {}\n\n    # List to contain details of all matched URLs:\n    identified_urls = []\n\n    # Attempt to identify and tag all HTML-MARKED-UP URLs in the line:\n    m_tagged_url_iter = re_html_tagged_url.finditer(line)\n    for m_tagged_url in m_tagged_url_iter:\n        startposn = m_tagged_url.start()        # start position of matched URL\n        endposn = m_tagged_url.end()          # end position of matched URL\n        matchlen = len(m_tagged_url.group(0))  # total length of URL match\n\n        found_url_full_matchlen[startposn] = matchlen\n        found_url_urlstring[startposn] = m_tagged_url.group('url')\n        found_url_urldescr[startposn] = m_tagged_url.group('desc')\n        # temporarily replace the URL match with underscores so that\n        # it won't be re-found\n        line = line[0:startposn] + u\"_\" * matchlen + line[endposn:]\n\n    # Attempt to identify and tag all RAW (i.e. not\n    # HTML-marked-up) URLs in the line:\n    m_raw_url_iter = re_raw_url.finditer(line)\n    for m_raw_url in m_raw_url_iter:\n        startposn = m_raw_url.start()        # start position of matched URL\n        endposn = m_raw_url.end()          # end position of matched URL\n        matchlen = len(m_raw_url.group(0))  # total length of URL match\n        matched_url = m_raw_url.group('url')\n\n        if len(matched_url) > 0 and matched_url[-1] in (\".\", \",\"):\n            # Strip the full-stop or comma from the end of the url:\n            matched_url = matched_url[:-1]\n\n        found_url_full_matchlen[startposn] = matchlen\n        found_url_urlstring[startposn] = matched_url\n        found_url_urldescr[startposn] = matched_url\n        # temporarily replace the URL match with underscores\n        # so that it won't be re-found\n        line = line[0:startposn] + u\"_\" * matchlen + line[endposn:]\n\n    # Now that all URLs have been identified, insert them\n    # back into the line, tagged:\n    found_url_positions = found_url_urlstring.keys()\n    found_url_positions.sort()\n    found_url_positions.reverse()\n    for url_position in found_url_positions:\n        line = line[0:url_position] + \"<cds.URL />\" \\\n            + line[url_position + found_url_full_matchlen[url_position]:]\n\n    # The line has been rebuilt. Now record the information about the\n    # matched URLs:\n    found_url_positions = found_url_urlstring.keys()\n    found_url_positions.sort()\n    for url_position in found_url_positions:\n        identified_urls.append((found_url_urlstring[url_position],\n                                found_url_urldescr[url_position]))\n\n    # Somehow the number of URLs found doesn't match the number of\n    # URLs recorded in \"identified_urls\". Raise an IndexError.\n    msg = \"\"\"Error: The number of URLs found in the reference line \"\"\" \\\n          \"\"\"does not match the number of URLs recorded in the \"\"\" \\\n          \"\"\"list of identified URLs!\\nLine pre-URL checking: %s\\n\"\"\" \\\n          \"\"\"Line post-URL checking: %s\\n\"\"\" \\\n          % (line_pre_url_check, line)\n    assert len(identified_urls) == len(found_url_positions), msg\n\n    # return the line containing the tagged URLs:\n    return line, identified_urls", "response": "Given a reference line and a list of URLs in the line record the URLs in the line and replace them with a \"<cds. URL > tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a single citation line and attempts to identify any DOI references in both http and standard DOI notation and the standard DOI notation.", "response": "def identify_and_tag_DOI(line):\n    \"\"\"takes a single citation line and attempts to locate any DOI references.\n       DOI references are recognised in both http (url) format and also the\n       standard DOI notation (DOI: ...)\n       @param line: (string) the reference line in which to search for DOI's.\n       @return: the tagged line and a list of DOI strings (if any)\n    \"\"\"\n    # Used to hold the DOI strings in the citation line\n    doi_strings = []\n\n    # Run the DOI pattern on the line, returning the re.match objects\n    matched_doi = re_doi.finditer(line)\n    # For each match found in the line\n    for match in reversed(list(matched_doi)):\n        # Store the start and end position\n        start = match.start()\n        end = match.end()\n        # Get the actual DOI string (remove the url part of the doi string)\n        doi_phrase = match.group('doi')\n        if '%2f' in doi_phrase.lower():\n            doi_phrase = unquote(doi_phrase)\n\n        # Replace the entire matched doi with a tag\n        line = line[0:start] + \"<cds.DOI />\" + line[end:]\n        # Add the single DOI string to the list of DOI strings\n        doi_strings.append(doi_phrase)\n\n    doi_strings.reverse()\n    return line, doi_strings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrimming a reference line s marker from the beginning of the line.", "response": "def remove_reference_line_marker(line):\n    \"\"\"Trim a reference line's 'marker' from the beginning of the line.\n       @param line: (string) - the reference line.\n       @return: (tuple) containing two strings:\n                 + The reference line's marker (or if there was not one,\n                   a 'space' character.\n                 + The reference line with it's marker removed from the\n                   beginning.\n    \"\"\"\n    # Get patterns to identify reference-line marker patterns:\n    marker_patterns = get_reference_line_numeration_marker_patterns()\n    line = line.lstrip()\n\n    marker_match = regex_match_list(line, marker_patterns)\n\n    if marker_match is not None:\n        # found a marker:\n        marker_val = marker_match.group(u'mark')\n        # trim the marker from the start of the line:\n        line = line[marker_match.end():].lstrip()\n    else:\n        marker_val = u\" \"\n    return (marker_val, line)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert numbers from roman to arabic", "response": "def roman2arabic(num):\n    \"\"\"Convert numbers from roman to arabic\n\n    This function expects a string like XXII\n    and outputs an integer\n    \"\"\"\n    t = 0\n    p = 0\n    for r in num:\n        n = 10 ** (205558 % ord(r) % 7) % 9995\n        t += n - 2 * p % n\n        p = n\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_volume(citation_elements):\n    re_roman = re.compile(re_roman_numbers + u'$', re.UNICODE)\n    for el in citation_elements:\n        if el['type'] == 'JOURNAL' and re_roman.match(el['volume']):\n            el['volume'] = str(roman2arabic(el['volume'].upper()))\n    return citation_elements", "response": "format volume number (roman numbers to arabic)\n\n    When the volume number is expressed in roman numbers (CXXII),\n    they are converted to their equivalent in arabic numbers (42)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_special_journals(citation_elements, kbs):\n    for el in citation_elements:\n        if el['type'] == 'JOURNAL' and el['title'] in kbs['special_journals']:\n            if re.match(r'\\d{1,2}$', el['volume']):\n                # Sometimes the page is omitted and the year is written in its place\n                # We can never be sure but it's very likely that page > 1900 is\n                # actually a year, so we skip this reference\n                if el['year'] == '' and re.match(r'(19|20)\\d{2}$', el['page']):\n                    el['type'] = 'MISC'\n                    el['misc_txt'] = \"%s,%s,%s\" \\\n                        % (el['title'], el['volume'], el['page'])\n                el['volume'] = el['year'][-2:] + '%02d' % int(el['volume'])\n            if el['page'].isdigit():\n                # JHEP and JCAP have always pages 3 digits long\n                el['page'] = '%03d' % int(el['page'])\n\n    return citation_elements", "response": "format special journals (like JHEP) volume number\n\n    JHEP needs the volume number prefixed with the year\n    e.g. JHEP 0301 instead of JHEP 01"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_report_number(citation_elements):\n    re_report = re.compile(ur'^(?P<name>[A-Z-]+)(?P<nums>[\\d-]+)$', re.UNICODE)\n    for el in citation_elements:\n        if el['type'] == 'REPORTNUMBER':\n            m = re_report.match(el['report_num'])\n            if m:\n                name = m.group('name')\n                if not name.endswith('-'):\n                    el['report_num'] = m.group('name') + '-' + m.group('nums')\n    return citation_elements", "response": "Format report numbers that are missing a dash"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_hep(citation_elements):\n    prefixes = ('astro-ph-', 'hep-th-', 'hep-ph-', 'hep-ex-', 'hep-lat-',\n                'math-ph-')\n    for el in citation_elements:\n        if el['type'] == 'REPORTNUMBER':\n            for p in prefixes:\n                if el['report_num'].startswith(p):\n                    el['report_num'] = el['report_num'][:len(p) - 1] + '/' + \\\n                        el['report_num'][len(p):]\n    return citation_elements", "response": "Format hep - th report numbers with a dash"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstandardise author ed and eds.", "response": "def format_author_ed(citation_elements):\n    \"\"\"Standardise to (ed.) and (eds.)\n\n    e.g. Remove extra space in (ed. )\n    \"\"\"\n    for el in citation_elements:\n        if el['type'] == 'AUTH':\n            el['auth_txt'] = el['auth_txt'].replace('(ed. )', '(ed.)')\n            el['auth_txt'] = el['auth_txt'].replace('(eds. )', '(eds.)')\n    return citation_elements"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef look_for_books(citation_elements, kbs):\n    title = None\n    for el in citation_elements:\n        if el['type'] == 'QUOTED':\n            title = el\n            break\n\n    if title:\n        normalized_title = title['title'].upper()\n        if normalized_title in kbs['books']:\n            line = kbs['books'][normalized_title]\n            el = {'type': 'BOOK',\n                  'misc_txt': '',\n                  'authors': line[0],\n                  'title': line[1],\n                  'year': line[2].strip(';')}\n            citation_elements.append(el)\n            citation_elements.remove(title)\n\n    return citation_elements", "response": "Look for books in our knowledge base and return them as a list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsplitting volume from journal title", "response": "def split_volume_from_journal(citation_elements):\n    \"\"\"Split volume from journal title\n\n    We need this because sometimes the volume is attached to the journal title\n    instead of the volume. In those cases we move it here from the title to the\n    volume\n    \"\"\"\n    for el in citation_elements:\n        if el['type'] == 'JOURNAL' and ';' in el['title']:\n            el['title'], series = el['title'].rsplit(';', 1)\n            el['volume'] = series + el['volume']\n    return citation_elements"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_b_for_nucl_phys(citation_elements):\n    for el in citation_elements:\n        if el['type'] == 'JOURNAL' and el['title'] == 'Nucl.Phys.Proc.Suppl.' \\\n                and 'volume' in el \\\n                and (el['volume'].startswith('b') or el['volume'].startswith('B')):\n            el['volume'] = el['volume'][1:]\n    return citation_elements", "response": "Removes the b from the volume of some journals that are not part of a nucleotide system."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes sure the volume letter is before the volume number", "response": "def mangle_volume(citation_elements):\n    \"\"\"Make sure the volume letter is before the volume number\n\n    e.g. transforms 100B to B100\n    \"\"\"\n    volume_re = re.compile(ur\"(\\d+)([A-Z])\", re.U | re.I)\n    for el in citation_elements:\n        if el['type'] == 'JOURNAL':\n            matches = volume_re.match(el['volume'])\n            if matches:\n                el['volume'] = matches.group(2) + matches.group(1)\n\n    return citation_elements"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting a citation line in multiple citations", "response": "def split_citations(citation_elements):\n    \"\"\"Split a citation line in multiple citations\n\n    We handle the case where the author has put 2 citations in the same line\n    but split with ; or some other method.\n    \"\"\"\n    splitted_citations = []\n    new_elements = []\n    current_recid = None\n    current_doi = None\n\n    def check_ibid(current_elements, trigger_el):\n        for el in new_elements:\n            if el['type'] == 'AUTH':\n                return\n\n        # Check for ibid\n        if trigger_el.get('is_ibid', False):\n            if splitted_citations:\n                els = chain(reversed(current_elements),\n                            reversed(splitted_citations[-1]))\n            else:\n                els = reversed(current_elements)\n            for el in els:\n                if el['type'] == 'AUTH':\n                    new_elements.append(el.copy())\n                    break\n\n    def start_new_citation():\n        \"\"\"Start new citation\"\"\"\n        splitted_citations.append(new_elements[:])\n        del new_elements[:]\n\n    for el in citation_elements:\n        try:\n            el_recid = el['recid']\n        except KeyError:\n            el_recid = None\n\n        if current_recid and el_recid and current_recid == el_recid:\n            # Do not start a new citation\n            pass\n        elif current_recid and el_recid and current_recid != el_recid \\\n                or current_doi and el['type'] == 'DOI' and \\\n                current_doi != el['doi_string']:\n            start_new_citation()\n            # Some authors may be found in the previous citation\n            balance_authors(splitted_citations, new_elements)\n        elif ';' in el['misc_txt']:\n            misc_txt, el['misc_txt'] = el['misc_txt'].split(';', 1)\n            if misc_txt:\n                new_elements.append({'type': 'MISC',\n                                     'misc_txt': misc_txt})\n            start_new_citation()\n            # In case el['recid'] is None, we want to reset it\n            # because we are starting a new reference\n            current_recid = el_recid\n            while ';' in el['misc_txt']:\n                misc_txt, el['misc_txt'] = el['misc_txt'].split(';', 1)\n                if misc_txt:\n                    new_elements.append({'type': 'MISC',\n                                         'misc_txt': misc_txt})\n                    start_new_citation()\n                    current_recid = None\n\n        if el_recid:\n            current_recid = el_recid\n\n        if el['type'] == 'DOI':\n            current_doi = el['doi_string']\n\n        check_ibid(new_elements, el)\n        new_elements.append(el)\n\n    splitted_citations.append(new_elements)\n\n    return [el for el in splitted_citations if not empty_citation(el)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlook for handle identifiers in the misc txt of the citation elements When finding an HDL element creates a new HDL element.", "response": "def look_for_hdl(citation_elements):\n    \"\"\"Looks for handle identifiers in the misc txt of the citation elements\n\n       When finding an hdl, creates a new HDL element.\n       @param citation_elements: (list) elements to process\n    \"\"\"\n    for el in list(citation_elements):\n        matched_hdl = re_hdl.finditer(el['misc_txt'])\n        for match in reversed(list(matched_hdl)):\n            hdl_el = {'type': 'HDL',\n                      'hdl_id': match.group('hdl_id'),\n                      'misc_txt': el['misc_txt'][match.end():]}\n            el['misc_txt'] = el['misc_txt'][0:match.start()]\n            citation_elements.insert(citation_elements.index(el) + 1, hdl_el)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook for handle identifiers that have already been identified as urls ATTRIBS When finding an HDL element creates a new HDL element.", "response": "def look_for_hdl_urls(citation_elements):\n    \"\"\"Looks for handle identifiers that have already been identified as urls\n\n       When finding an hdl, creates a new HDL element.\n       @param citation_elements: (list) elements to process\n    \"\"\"\n    for el in citation_elements:\n        if el['type'] == 'URL':\n            match = re_hdl.match(el['url_string'])\n            if match:\n                el['type'] = 'HDL'\n                el['hdl_id'] = match.group('hdl_id')\n                del el['url_desc']\n                del el['url_string']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_reference_line(ref_line, kbs, bad_titles_count={}, linker_callback=None):\n    # Strip the 'marker' (e.g. [1]) from this reference line:\n    line_marker, ref_line = remove_reference_line_marker(ref_line)\n    # Find DOI sections in citation\n    ref_line, identified_dois = identify_and_tag_DOI(ref_line)\n    # Identify and replace URLs in the line:\n    ref_line, identified_urls = identify_and_tag_URLs(ref_line)\n    # Tag <cds.JOURNAL>, etc.\n    tagged_line, bad_titles_count = tag_reference_line(ref_line,\n                                                       kbs,\n                                                       bad_titles_count)\n\n    # Debug print tagging (authors, titles, volumes, etc.)\n    LOGGER.debug(\"tags %r\", tagged_line)\n\n    # Using the recorded information, create a MARC XML representation\n    # of the rebuilt line:\n    # At the same time, get stats of citations found in the reference line\n    # (titles, urls, etc):\n    citation_elements, line_marker, counts = \\\n        parse_tagged_reference_line(line_marker,\n                                    tagged_line,\n                                    identified_dois,\n                                    identified_urls)\n\n    # Transformations on elements\n    split_volume_from_journal(citation_elements)\n    format_volume(citation_elements)\n    handle_special_journals(citation_elements, kbs)\n    format_report_number(citation_elements)\n    format_author_ed(citation_elements)\n    look_for_books(citation_elements, kbs)\n    format_hep(citation_elements)\n    remove_b_for_nucl_phys(citation_elements)\n    mangle_volume(citation_elements)\n    arxiv_urls_to_report_numbers(citation_elements)\n    look_for_hdl(citation_elements)\n    look_for_hdl_urls(citation_elements)\n\n    # Link references if desired\n    if linker_callback:\n        associate_recids(citation_elements, linker_callback)\n\n    # Split the reference in multiple ones if needed\n    splitted_citations = split_citations(citation_elements)\n\n    # Look for implied ibids\n    look_for_implied_ibids(splitted_citations)\n    # Find year\n    add_year_elements(splitted_citations)\n    # Look for books in misc field\n    look_for_undetected_books(splitted_citations, kbs)\n\n    if linker_callback:\n        # Link references with the newly added ibids/books information\n        for citations in splitted_citations:\n            associate_recids(citations, linker_callback)\n\n    # FIXME: Needed?\n    # Remove references with only misc text\n    # splitted_citations = remove_invalid_references(splitted_citations)\n    # Merge references with only misc text\n    # splitted_citations = merge_invalid_references(splitted_citations)\n\n    remove_duplicated_authors(splitted_citations)\n    remove_duplicated_dois(splitted_citations)\n    remove_duplicated_collaborations(splitted_citations)\n    add_recid_elements(splitted_citations)\n\n    # For debugging purposes\n    print_citations(splitted_citations, line_marker)\n\n    return splitted_citations, line_marker, counts, bad_titles_count", "response": "Parse one reference line into a list of elements objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_for_book_in_misc(citation, kbs):\n    citation_year = year_from_citation(citation)\n    for citation_element in citation:\n        LOGGER.debug(u\"Searching for book title in: %s\", citation_element['misc_txt'])\n        for title in kbs['books']:\n            startIndex = find_substring_ignore_special_chars(citation_element['misc_txt'], title)\n            if startIndex != -1:\n                line = kbs['books'][title.upper()]\n                book_year = line[2].strip(';')\n                book_authors = line[0]\n                book_found = False\n                if citation_year == book_year:\n                    # For now consider the citation as valid, we are using\n                    # an exact search, we don't need to check the authors\n                    # However, the code below will be useful if we decide\n                    # to introduce fuzzy matching.\n                    book_found = True\n\n                    for author in get_possible_author_names(citation):\n                        if find_substring_ignore_special_chars(book_authors, author) != -1:\n                            book_found = True\n\n                    for author in re.findall('[a-zA-Z]{4,}', book_authors):\n                        if find_substring_ignore_special_chars(citation_element['misc_txt'], author) != -1:\n                            book_found = True\n\n                    if book_found:\n                        LOGGER.debug(u\"Book found: %s\", title)\n                        book_element = {'type': 'BOOK',\n                                        'misc_txt': '',\n                                        'authors': book_authors,\n                                        'title': line[1],\n                                        'year': book_year}\n                        citation.append(book_element)\n                        citation_element['misc_txt'] = cut_substring_with_special_chars(citation_element['misc_txt'], title, startIndex)\n                        # Remove year from misc txt\n                        citation_element['misc_txt'] = remove_year(citation_element['misc_txt'], book_year)\n                        return True\n\n        LOGGER.debug(\"Book not found!\")\n\n    return False", "response": "Searches for books in the misc_txt field if they are not recognized as a journal book etc."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_references_elements(ref_sect, kbs, linker_callback=None):\n    # a list to contain the processed reference lines:\n    citations = []\n    # counters for extraction stats:\n    counts = {\n        'misc': 0,\n        'title': 0,\n        'reportnum': 0,\n        'url': 0,\n        'doi': 0,\n        'auth_group': 0,\n    }\n    # A dictionary to contain the total count of each 'bad title' found\n    # in the entire reference section:\n    bad_titles_count = {}\n\n    # Cleanup the reference lines\n\n    # process references line-by-line:\n    for ref_line in ref_sect:\n        clean_line = wash_and_repair_reference_line(ref_line)\n\n        citation_elements, line_marker, this_counts, bad_titles_count = \\\n            parse_reference_line(\n                clean_line, kbs, bad_titles_count, linker_callback)\n\n        # Accumulate stats\n        counts = sum_2_dictionaries(counts, this_counts)\n\n        citations.append({'elements': citation_elements,\n                          'line_marker': line_marker,\n                          'raw_ref': ref_line})\n\n    # Return the list of processed reference lines:\n    return citations, counts, bad_titles_count", "response": "Given a complete reference section process each line and attempt to standardise individual citations within the line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_tagged_reference_line(line_marker,\n                                line,\n                                identified_dois,\n                                identified_urls):\n    \"\"\" Given a single tagged reference line, convert it to its MARC-XML representation.\n        Try to find all tags and extract their contents and their types into corresponding\n        dictionary elements. Append each dictionary tag representation onto a list, which\n        is given to 'build_formatted_xml_citation()' where the correct xml output will be generated.\n\n        This method is dumb, with very few heuristics. It simply looks for tags, and makes dictionaries\n        from the data it finds in a tagged reference line.\n\n        @param line_marker: (string) The line marker for this single reference line (e.g. [19])\n        @param line: (string) The tagged reference line.\n        @param identified_dois: (list) a list of dois which were found in this line. The ordering of\n        dois corresponds to the ordering of tags in the line, reading from left to right.\n        @param identified_urls: (list) a list of urls which were found in this line. The ordering of\n        urls corresponds to the ordering of tags in the line, reading from left to right.\n        @param which format to use for references,\n        roughly \"<title> <volume> <page>\" or \"<title>,<volume>,<page>\"\n        @return xml_line: (string) the MARC-XML representation of the tagged reference line\n        @return count_*: (integer) the number of * (pieces of info) found in the reference line.\n    \"\"\"\n    count_misc = count_title = count_reportnum = count_url = count_doi = count_auth_group = 0\n    processed_line = line\n    cur_misc_txt = u\"\"\n\n    tag_match = re_tagged_citation.search(processed_line)\n\n    # contains a list of dictionary entries of previously cited items\n    citation_elements = []\n    # the last tag element found when working from left-to-right across the\n    # line\n    identified_citation_element = None\n\n    while tag_match is not None:\n        # While there are tags inside this reference line...\n        tag_match_start = tag_match.start()\n        tag_match_end = tag_match.end()\n        tag_type = tag_match.group(1)\n        cur_misc_txt += processed_line[0:tag_match_start]\n\n        # Catches both standard titles, and ibid's\n        if tag_type.find(\"JOURNAL\") != -1:\n            # This tag is an identified journal TITLE. It should be followed\n            # by VOLUME, YEAR and PAGE tags.\n\n            # See if the found title has been tagged as an ibid:\n            # <cds.JOURNALibid>\n            if tag_match.group('ibid'):\n                is_ibid = True\n                closing_tag_length = len(\n                    CFG_REFEXTRACT_MARKER_CLOSING_TITLE_IBID)\n                idx_closing_tag = processed_line.find(CFG_REFEXTRACT_MARKER_CLOSING_TITLE_IBID,\n                                                      tag_match_end)\n            else:\n                is_ibid = False\n                closing_tag_length = len(CFG_REFEXTRACT_MARKER_CLOSING_TITLE)\n                # extract the title from the line:\n                idx_closing_tag = processed_line.find(CFG_REFEXTRACT_MARKER_CLOSING_TITLE,\n                                                      tag_match_end)\n\n            if idx_closing_tag == -1:\n                # no closing TITLE tag found - get rid of the solitary tag\n                processed_line = processed_line[tag_match_end:]\n                identified_citation_element = None\n            else:\n\n                # Closing tag was found:\n                # The title text to be used in the marked-up citation:\n                title_text = processed_line[tag_match_end:idx_closing_tag]\n\n                # Now trim this matched title and its tags from the start of\n                # the line:\n                processed_line = processed_line[\n                    idx_closing_tag + closing_tag_length:]\n\n                numeration_match = re_recognised_numeration_for_title_plus_series.search(\n                    processed_line)\n                if numeration_match:\n                    # recognised numeration immediately after the title -\n                    # extract it:\n                    reference_volume = numeration_match.group('vol')\n                    reference_year = numeration_match.group('yr') or ''\n                    reference_page = numeration_match.group('pg')\n\n                    # This is used on two accounts:\n                    # 1. To get the series char from the title, if no series was found with the numeration\n                    # 2. To always remove any series character from the title match text\n                    # series_from_title = re_series_from_title.search(title_text)\n                    #\n                    if numeration_match.group('series'):\n                        reference_volume = numeration_match.group(\n                            'series') + reference_volume\n\n                    # Skip past the matched numeration in the working line:\n                    processed_line = processed_line[numeration_match.end():]\n\n                    # 'id_ibid' saves whether THIS TITLE is an ibid or not. (True or False)\n                    # 'extra_ibids' are there to hold ibid's without the word 'ibid', which\n                    # come directly after this title\n                    # i.e., they are recognised using title numeration instead\n                    # of ibid notation\n                    identified_citation_element = {'type': \"JOURNAL\",\n                                                   'misc_txt': cur_misc_txt,\n                                                   'title': title_text,\n                                                   'volume': reference_volume,\n                                                   'year': reference_year,\n                                                   'page': reference_page,\n                                                   'is_ibid': is_ibid,\n                                                   'extra_ibids': []\n                                                   }\n                    count_title += 1\n                    cur_misc_txt = u\"\"\n\n                    # Try to find IBID's after this title, on top of previously found titles that were\n                    # denoted with the word 'IBID'. (i.e. look for IBID's without the word 'IBID' by\n                    # looking at extra numeration after this title)\n\n                    numeration_match = re_numeration_no_ibid_txt.match(\n                        processed_line)\n                    while numeration_match is not None:\n\n                        reference_volume = numeration_match.group('vol')\n                        reference_year = numeration_match.group('yr')\n                        reference_page = numeration_match.group('pg')\n\n                        if numeration_match.group('series'):\n                            reference_volume = numeration_match.group(\n                                'series') + reference_volume\n\n                        # Skip past the matched numeration in the working line:\n                        processed_line = processed_line[\n                            numeration_match.end():]\n\n                        # Takes the just found title text\n                        identified_citation_element['extra_ibids'].append(\n                            {'type': \"JOURNAL\",\n                             'misc_txt': \"\",\n                             'title': title_text,\n                             'volume': reference_volume,\n                             'year': reference_year,\n                             'page': reference_page,\n                             })\n                        # Increment the stats counters:\n                        count_title += 1\n\n                        title_text = \"\"\n                        reference_volume = \"\"\n                        reference_year = \"\"\n                        reference_page = \"\"\n                        numeration_match = re_numeration_no_ibid_txt.match(\n                            processed_line)\n                else:\n                    # No numeration was recognised after the title. Add the\n                    # title into a MISC item instead:\n                    cur_misc_txt += \"%s\" % title_text\n                    identified_citation_element = None\n\n        elif tag_type == \"REPORTNUMBER\":\n\n            # This tag is an identified institutional report number:\n\n            # extract the institutional report-number from the line:\n            idx_closing_tag = processed_line.find(CFG_REFEXTRACT_MARKER_CLOSING_REPORT_NUM,\n                                                  tag_match_end)\n            # Sanity check - did we find a closing report-number tag?\n            if idx_closing_tag == -1:\n                # no closing </cds.REPORTNUMBER> tag found - strip the opening tag and move past this\n                # recognised reportnumber as it is unreliable:\n                processed_line = processed_line[tag_match_end:]\n                identified_citation_element = None\n            else:\n                # closing tag was found\n                report_num = processed_line[tag_match_end:idx_closing_tag]\n                # now trim this matched institutional report-number\n                # and its tags from the start of the line:\n                ending_tag_pos = idx_closing_tag \\\n                    + len(CFG_REFEXTRACT_MARKER_CLOSING_REPORT_NUM)\n                processed_line = processed_line[ending_tag_pos:]\n\n                identified_citation_element = {'type': \"REPORTNUMBER\",\n                                               'misc_txt': cur_misc_txt,\n                                               'report_num': report_num}\n                count_reportnum += 1\n                cur_misc_txt = u\"\"\n\n        elif tag_type == \"URL\":\n            # This tag is an identified URL:\n\n            # From the \"identified_urls\" list, get this URL and its\n            # description string:\n            url_string = identified_urls[0][0]\n            url_desc = identified_urls[0][1]\n\n            # Now move past this \"<cds.URL />\"tag in the line:\n            processed_line = processed_line[tag_match_end:]\n\n            # Delete the information for this URL from the start of the list\n            # of identified URLs:\n            identified_urls[0:1] = []\n\n            # Save the current misc text\n            identified_citation_element = {\n                'type': \"URL\",\n                'misc_txt': \"%s\" % cur_misc_txt,\n                'url_string': \"%s\" % url_string,\n                'url_desc': \"%s\" % url_desc\n            }\n\n            count_url += 1\n            cur_misc_txt = u\"\"\n\n        elif tag_type == \"DOI\":\n            # This tag is an identified DOI:\n\n            # From the \"identified_dois\" list, get this DOI and its\n            # description string:\n            doi_string = identified_dois[0]\n\n            # Now move past this \"<cds.CDS />\"tag in the line:\n            processed_line = processed_line[tag_match_end:]\n\n            # Remove DOI from the list of DOI strings\n            identified_dois[0:1] = []\n\n            # SAVE the current misc text\n            identified_citation_element = {\n                'type': \"DOI\",\n                'misc_txt': \"%s\" % cur_misc_txt,\n                'doi_string': \"%s\" % doi_string\n            }\n\n            # Increment the stats counters:\n            count_doi += 1\n            cur_misc_txt = u\"\"\n\n        elif tag_type.find(\"AUTH\") != -1:\n            # This tag is an identified Author:\n\n            auth_type = \"\"\n            # extract the title from the line:\n            if tag_type.find(\"stnd\") != -1:\n                auth_type = \"stnd\"\n                idx_closing_tag_nearest = processed_line.find(\n                    CFG_REFEXTRACT_MARKER_CLOSING_AUTHOR_STND, tag_match_end)\n            elif tag_type.find(\"etal\") != -1:\n                auth_type = \"etal\"\n                idx_closing_tag_nearest = processed_line.find(\n                    CFG_REFEXTRACT_MARKER_CLOSING_AUTHOR_ETAL, tag_match_end)\n            elif tag_type.find(\"incl\") != -1:\n                auth_type = \"incl\"\n                idx_closing_tag_nearest = processed_line.find(\n                    CFG_REFEXTRACT_MARKER_CLOSING_AUTHOR_INCL, tag_match_end)\n\n            if idx_closing_tag_nearest == -1:\n                # no closing </cds.AUTH****> tag found - strip the opening tag\n                # and move past it\n                processed_line = processed_line[tag_match_end:]\n                identified_citation_element = None\n            else:\n                auth_txt = processed_line[\n                    tag_match_end:idx_closing_tag_nearest]\n                # Now move past the ending tag in the line:\n                processed_line = processed_line[\n                    idx_closing_tag_nearest + len(\"</cds.AUTHxxxx>\"):]\n                # SAVE the current misc text\n                identified_citation_element = {\n                    'type': \"AUTH\",\n                    'misc_txt': \"%s\" % cur_misc_txt,\n                    'auth_txt': \"%s\" % auth_txt,\n                    'auth_type': \"%s\" % auth_type\n                }\n\n                # Increment the stats counters:\n                count_auth_group += 1\n                cur_misc_txt = u\"\"\n\n        # These following tags may be found separately;\n        # They are usually found when a \"JOURNAL\" tag is hit\n        # (ONLY immediately afterwards, however)\n        # Sitting by themselves means they do not have\n        # an associated TITLE tag, and should be MISC\n        elif tag_type == \"SER\":\n            # This tag is a SERIES tag; Since it was not preceeded by a TITLE\n            # tag, it is useless - strip the tag and put it into miscellaneous:\n            (cur_misc_txt, processed_line) = \\\n                convert_unusable_tag_to_misc(processed_line, cur_misc_txt,\n                                             tag_match_end,\n                                             CFG_REFEXTRACT_MARKER_CLOSING_SERIES)\n            identified_citation_element = None\n\n        elif tag_type == \"VOL\":\n            # This tag is a VOLUME tag; Since it was not preceeded by a TITLE\n            # tag, it is useless - strip the tag and put it into miscellaneous:\n            (cur_misc_txt, processed_line) = \\\n                convert_unusable_tag_to_misc(processed_line, cur_misc_txt,\n                                             tag_match_end,\n                                             CFG_REFEXTRACT_MARKER_CLOSING_VOLUME)\n            identified_citation_element = None\n\n        elif tag_type == \"YR\":\n            # This tag is a YEAR tag; Since it's not preceeded by TITLE and\n            # VOLUME tags, it is useless - strip the tag and put the contents\n            # into miscellaneous:\n            (cur_misc_txt, processed_line) = \\\n                convert_unusable_tag_to_misc(processed_line, cur_misc_txt,\n                                             tag_match_end,\n                                             CFG_REFEXTRACT_MARKER_CLOSING_YEAR)\n            identified_citation_element = None\n\n        elif tag_type == \"PG\":\n            # This tag is a PAGE tag; Since it's not preceeded by TITLE,\n            # VOLUME and YEAR tags, it is useless - strip the tag and put the\n            # contents into miscellaneous:\n            (cur_misc_txt, processed_line) = \\\n                convert_unusable_tag_to_misc(processed_line, cur_misc_txt,\n                                             tag_match_end,\n                                             CFG_REFEXTRACT_MARKER_CLOSING_PAGE)\n            identified_citation_element = None\n\n        elif tag_type == \"QUOTED\":\n            identified_citation_element, processed_line, cur_misc_txt = \\\n                map_tag_to_subfield(tag_type,\n                                    processed_line[tag_match_end:],\n                                    cur_misc_txt,\n                                    'title')\n\n        elif tag_type == \"ISBN\":\n            identified_citation_element, processed_line, cur_misc_txt = \\\n                map_tag_to_subfield(tag_type,\n                                    processed_line[tag_match_end:],\n                                    cur_misc_txt,\n                                    tag_type)\n\n        elif tag_type == \"PUBLISHER\":\n            identified_citation_element, processed_line, cur_misc_txt = \\\n                map_tag_to_subfield(tag_type,\n                                    processed_line[tag_match_end:],\n                                    cur_misc_txt,\n                                    'publisher')\n\n        elif tag_type == \"COLLABORATION\":\n            identified_citation_element, processed_line, cur_misc_txt = \\\n                map_tag_to_subfield(tag_type,\n                                    processed_line[tag_match_end:],\n                                    cur_misc_txt,\n                                    'collaboration')\n\n        if identified_citation_element:\n            # Append the found tagged data and current misc text\n            citation_elements.append(identified_citation_element)\n            identified_citation_element = None\n\n        # Look for the next tag in the processed line:\n        tag_match = re_tagged_citation.search(processed_line)\n\n    # place any remaining miscellaneous text into the\n    # appropriate MARC XML fields:\n    cur_misc_txt += processed_line\n\n    # This MISC element will hold the entire citation in the event\n    # that no tags were found.\n    if len(cur_misc_txt.strip(\" .;,\")) > 0:\n        # Increment the stats counters:\n        count_misc += 1\n        identified_citation_element = {\n            'type': \"MISC\",\n            'misc_txt': cur_misc_txt,\n        }\n        citation_elements.append(identified_citation_element)\n\n    return (citation_elements, line_marker, {\n        'misc': count_misc,\n        'title': count_title,\n        'reportnum': count_reportnum,\n        'url': count_url,\n        'doi': count_doi,\n        'auth_group': count_auth_group\n    })", "response": "Given a single tagged reference line parse it to its MARC - XML representation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping a tag to a subtype of another tag.", "response": "def map_tag_to_subfield(tag_type, line, cur_misc_txt, dest):\n    \"\"\"Create a new reference element\"\"\"\n    closing_tag = '</cds.%s>' % tag_type\n    # extract the institutional report-number from the line:\n    idx_closing_tag = line.find(closing_tag)\n    # Sanity check - did we find a closing tag?\n    if idx_closing_tag == -1:\n        # no closing </cds.TAG> tag found - strip the opening tag and move past this\n        # recognised reportnumber as it is unreliable:\n        identified_citation_element = None\n        line = line[len('<cds.%s>' % tag_type):]\n    else:\n        tag_content = line[:idx_closing_tag]\n        identified_citation_element = {'type': tag_type,\n                                       'misc_txt': cur_misc_txt,\n                                       dest: tag_content}\n        ending_tag_pos = idx_closing_tag + len(closing_tag)\n        line = line[ending_tag_pos:]\n        cur_misc_txt = u\"\"\n\n    return identified_citation_element, line, cur_misc_txt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to convert an unusable tag from a reference file line into a miscellaneous text variable.", "response": "def convert_unusable_tag_to_misc(line,\n                                 misc_text,\n                                 tag_match_end,\n                                 closing_tag):\n    \"\"\"Function to remove an unwanted, tagged, citation item from a reference\n       line. The tagged item itself is put into the miscellaneous text variable;\n       the data up to the closing tag is then trimmed from the beginning of the\n       working line. For example, the following working line:\n         Example, AN. Testing software; <cds.YR>(2001)</cds.YR>, CERN, Geneva.\n       ...would be trimmed down to:\n         , CERN, Geneva.\n       ...And the Miscellaneous text taken from the start of the line would be:\n         Example, AN. Testing software; (2001)\n       ...(assuming that the details of <cds.YR> and </cds.YR> were passed to\n       the function).\n       @param line: (string) - the reference line.\n       @param misc_text: (string) - the variable containing the miscellaneous\n        text recorded so far.\n       @param tag_match_end: (integer) - the index of the end of the opening tag\n        in the line.\n       @param closing_tag: (string) - the closing tag to look for in the line\n        (e.g. </cds.YR>).\n       @return: (tuple) - containing misc_text (string) and line (string)\n    \"\"\"\n\n    # extract the tagged information:\n    idx_closing_tag = line.find(closing_tag, tag_match_end)\n    # Sanity check - did we find a closing tag?\n    if idx_closing_tag == -1:\n        # no closing tag found - strip the opening tag and move past this\n        # recognised item as it is unusable:\n        line = line[tag_match_end:]\n    else:\n        # closing tag was found\n        misc_text += line[tag_match_end:idx_closing_tag]\n        # now trim the matched item and its tags from the start of the line:\n        line = line[idx_closing_tag + len(closing_tag):]\n    return (misc_text, line)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a file - path to a plain - text document return a list of unicode strings where each string is a line of the fulltext file.", "response": "def get_plaintext_document_body(fpath, keep_layout=False):\n    \"\"\"Given a file-path to a full-text, return a list of unicode strings\n       whereby each string is a line of the fulltext.\n       In the case of a plain-text document, this simply means reading the\n       contents in from the file. In the case of a PDF however,\n       this means converting the document to plaintext.\n       It raises UnknownDocumentTypeError if the document is not a PDF or\n       plain text.\n       @param fpath: (string) - the path to the fulltext file\n       @return: (list) of strings - each string being a line in the document.\n    \"\"\"\n    textbody = []\n    mime_type = magic.from_file(fpath, mime=True)\n\n    if mime_type == \"text/plain\":\n        with open(fpath, \"r\") as f:\n            textbody = [line.decode(\"utf-8\") for line in f.readlines()]\n\n    elif mime_type == \"application/pdf\":\n        textbody = convert_PDF_to_plaintext(fpath, keep_layout)\n\n    else:\n        raise UnknownDocumentTypeError(mime_type)\n\n    return textbody"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a list of references Given a list of raw reference lines return a list of dictionaries containing the parsed references and the counts of the references and the counts of the references.", "response": "def parse_references(reference_lines,\n                     recid=None,\n                     override_kbs_files=None,\n                     reference_format=u\"{title} {volume} ({year}) {page}\",\n                     linker_callback=None):\n    \"\"\"Parse a list of references\n\n    Given a list of raw reference lines (list of strings),\n    output a list of dictionaries containing the parsed references\n    \"\"\"\n    # RefExtract knowledge bases\n    kbs = get_kbs(custom_kbs_files=override_kbs_files)\n    # Identify journal titles, report numbers, URLs, DOIs, and authors...\n    processed_references, counts, dummy_bad_titles_count = \\\n        parse_references_elements(reference_lines, kbs, linker_callback)\n\n    return (build_references(processed_references, reference_format),\n            build_stats(counts))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild stats information from counts structure.", "response": "def build_stats(counts):\n    \"\"\"Return stats information from counts structure.\"\"\"\n    stats = {\n        'status': 0,\n        'reportnum': counts['reportnum'],\n        'title': counts['title'],\n        'author': counts['auth_group'],\n        'url': counts['url'],\n        'doi': counts['doi'],\n        'misc': counts['misc'],\n    }\n    stats_str = \"%(status)s-%(reportnum)s-%(title)s-%(author)s-%(url)s-%(doi)s-%(misc)s\" % stats\n    stats[\"old_stats_str\"] = stats_str\n    stats[\"date\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    stats[\"version\"] = version\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_undesirable_characters(line):\n    # These are separate because we want a particular order\n    for bad_string, replacement in UNDESIRABLE_STRING_REPLACEMENTS:\n        line = line.replace(bad_string, replacement)\n\n    for bad_char, replacement in iteritems(UNDESIRABLE_CHAR_REPLACEMENTS):\n        line = line.replace(bad_char, replacement)\n\n    return line", "response": "Replace certain bad characters in a text line."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a PDF file to text using pdftotext.", "response": "def convert_PDF_to_plaintext(fpath, keep_layout=False):\n    \"\"\" Convert PDF to txt using pdftotext\n\n    Take the path to a PDF file and run pdftotext for this file, capturing\n    the output.\n    @param fpath: (string) path to the PDF file\n    @return: (list) of unicode strings (contents of the PDF file translated\n    into plaintext; each string is a line in the document.)\n    \"\"\"\n    if not os.path.isfile(CFG_PATH_PDFTOTEXT):\n        raise IOError('Missing pdftotext executable')\n\n    if keep_layout:\n        layout_option = \"-layout\"\n    else:\n        layout_option = \"-raw\"\n    doclines = []\n    # Pattern to check for lines with a leading page-break character.\n    # If this pattern is matched, we want to split the page-break into\n    # its own line because we rely upon this for trying to strip headers\n    # and footers, and for some other pattern matching.\n    p_break_in_line = re.compile(ur'^\\s*\\f(.+)$', re.UNICODE)\n    # build pdftotext command:\n    cmd_pdftotext = [CFG_PATH_PDFTOTEXT, layout_option, \"-q\",\n                     \"-enc\", \"UTF-8\", fpath, \"-\"]\n\n    LOGGER.debug(u\"%s\", ' '.join(cmd_pdftotext))\n    # open pipe to pdftotext:\n    pipe_pdftotext = subprocess.Popen(cmd_pdftotext, stdout=subprocess.PIPE)\n\n    # read back results:\n    for docline in pipe_pdftotext.stdout:\n        unicodeline = docline.decode(\"utf-8\")\n        # Check for a page-break in this line:\n        m_break_in_line = p_break_in_line.match(unicodeline)\n        if m_break_in_line is None:\n            # There was no page-break in this line. Just add the line:\n            doclines.append(unicodeline)\n        else:\n            # If there was a page-break character in the same line as some\n            # text, split it out into its own line so that we can later\n            # try to find headers and footers:\n            doclines.append(u\"\\f\")\n            doclines.append(m_break_in_line.group(1))\n\n    LOGGER.debug(u\"convert_PDF_to_plaintext found: %s lines of text\", len(doclines))\n\n    return doclines"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_author_affiliation_numeration_str(punct=None):\n\n    # FIXME cater for start or end numeration (ie two puncs)\n\n    # Number to look for, either general or specific\n    re_number = r'(?:\\d\\d?)'\n    re_chained_numbers = r\"(?:(?:[,;]\\s*%s\\.?\\s*))*\" % re_number\n    # Punctuation surrounding the number, either general or specific again\n    if punct is None:\n        re_punct = r\"(?:[\\{\\(\\[]?)\"\n    else:\n        re_punct = re.escape(punct)\n\n    # Generic number finder (MUST NOT INCLUDE NAMED GROUPS!!!)\n    numeration_str = r\"\"\"\n    (?:\\s*(%(punct)s)\\s*            ## Left numeration punctuation\n        (%(num)s\\s*                 ## Core numeration item, either specific or generic\n            %(num_chain)s           ## Extra numeration, either generic or empty\n        )\n        (?:(%(punct)s))       ## Right numeration punctuation\n    )\"\"\" % {'num': re_number,\n            'num_chain': re_chained_numbers,\n            'punct': re_punct}\n    return numeration_str", "response": "Returns a string which can be used to find numeration next to an author name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_initial_surname_author_pattern(incl_numeration=False):\n    # Possible inclusion of superscript numeration at the end of author names\n    # Will match the empty string\n    if incl_numeration:\n        append_num_re = get_author_affiliation_numeration_str() + '?'\n    else:\n        append_num_re = \"\"\n\n    return ur\"\"\"\n    (?:\n        (?:%(uppercase_re)s\\w{2,20}\\s+)?                     ## Optionally a first name before the initials\n\n        (?<!Volume\\s)                                        ## Initials (1-5) (cannot follow 'Volume\\s')\n        %(uppercase_re)s(?:\\s*[.'\u2019\\s-]{1,3}\\s*%(uppercase_re)s){0,4}[.\\s-]{1,2}\\s* ## separated by .,-,',etc.\n\n        (?:%(uppercase_re)s\\w{2,20}\\s+)?                     ## Optionally a first name after the initials\n\n        (?:\n            (?!%(invalid_prefixes)s)                         ## Invalid prefixes to avoid\n            \\w{1,3}(?<!and)(?:(?:[\u2019'`\u00b4-]\\s?)|\\s)             ## The surname prefix: 1, 2 or 3\n        )?                                                   ## character prefixes before the surname (e.g. 'van','de')\n\n        (?!%(invalid_surnames)s)                             ## Invalid surnames to avoid\n        %(uppercase_re)s                                     ## The surname, which must start with an upper case character\n        (?:[rR]\\.|\\w{1,20})                                  ## handle Jr.\n        (?:[\\-\u2019'`\u00b4][\\w\u2019']{1,20})?                            ## single hyphen allowed jan-el or Figueroa-O'Farrill\n        [\u2019']?                                                ## Eventually an ending '\n\n        %(numeration)s                                       ## A possible number to appear after an author name, used for author extraction\n\n        (?:               # Look for editor notation after the author group...\n            \\s*,?\\s*      # Eventually a coma/space\n            %(ed)s\n        )?\n    )\"\"\" % {\n        'uppercase_re': get_uppercase_re(),\n        'invalid_prefixes': '|'.join(invalid_prefixes),\n        'invalid_surnames': '|'.join(invalid_surnames),\n        'ed': re_ed_notation,\n        'numeration': append_num_re,\n    }", "response": "Return a pattern that matches an author name of the form Initials and a Surname."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_surname_initial_author_pattern(incl_numeration=False):\n    # Possible inclusion of superscript numeration at the end of author names\n    # Will match the empty string\n    if incl_numeration:\n        append_num_re = get_author_affiliation_numeration_str() + '?'\n    else:\n        append_num_re = \"\"\n\n    return ur\"\"\"\n    (?:\n        (?:\n            (?!%(invalid_prefixes)s)                             ## Invalid prefixes to avoid\n            \\w{1,3}(?<!and)(?<!in)(?:(?:[\u2019'`\u00b4-]\\s?)|\\s)\n        )?   ## The optional surname prefix:\n                                                                 ## 1 or 2, 2-3 character prefixes before the surname (e.g. 'van','de')\n\n        (?!%(invalid_surnames)s)                                 ## Invalid surnames to avoid\n        %(uppercase_re)s\\w{2,20}(?:[\\-\u2019'`\u00b4]\\w{2,20})?            ## The surname, which must start with an upper case character (single hyphen allowed)\n\n        \\s*[,.\\s]\\s*                                             ## The space between the surname and its initials\n\n        (?<!Volume\\s)                                            ## Initials\n        %(uppercase_re)s(?:\\s*[.'\u2019\\s-]{1,2}\\s*%(uppercase_re)s){0,4}\\.{0,2}\n\n                                                                 ## Either a comma or an 'and' MUST be present ... OR an end of line marker\n                                                                 ## (maybe some space's between authors)\n                                                                 ## Uses positive lookahead assertion\n        %(numeration)s                                           ## A possible number to appear after an author name, used for author extraction\n\n        (?:               # Look for editor notation after the author group...\n            \\s*,?\\s*      # Eventually a coma/space\n            %(ed)s\n        )?\n    )\"\"\" % {\n        'uppercase_re': get_uppercase_re(),\n        'invalid_prefixes': '|'.join(invalid_prefixes),\n        'invalid_surnames': '|'.join(invalid_surnames),\n        'ed': re_ed_notation,\n        'numeration': append_num_re,\n    }", "response": "Return an author pattern that matches the surname initials of the author group."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_auth_regex_str(etal, initial_surname_author=None, surname_initial_author=None):\n    if not initial_surname_author:\n        # Standard author, with a maximum of 6 initials, and a surname.\n        # The Initials MUST be uppercase, and MUST have at least a dot, hypen\n        # or apostrophe between them.\n        initial_surname_author = get_initial_surname_author_pattern()\n\n    if not surname_initial_author:\n        # The author name of the form: 'surname initial(s)'\n        # This is sometimes the represention of the first author found inside an author group.\n        # This author pattern is only used to find a maximum of ONE author inside an author group.\n        # Authors of this form MUST have either a comma after the initials, or an 'and',\n        # which denotes the presence of other authors in the author group.\n        surname_initial_author = get_surname_initial_author_pattern()\n\n    # Pattern used to locate a GROUP of author names in a reference\n    # The format of an author can take many forms:\n    # J. Bloggs, W.-H. Smith, D. De Samuel, G.L. Bayetian, C. Hayward et al.,\n    # (the use of 'et. al' is a giveaway that the preceeding\n    # text was indeed an author name)\n    # This will also match authors which seem to be labeled as editors (with the phrase 'ed.')\n    # In which case, the author will be thrown away later on.\n    # The regex returned has around 100 named groups already (max), so any new groups must be\n    # started using '?:'\n\n    return ur\"\"\"\n     (?:^|\\s+|\\()                                                     ## Must be the start of the line, or a space (or an opening bracket in very few cases)\n     (?P<es>                                                        ## Look for editor notation before the author\n      (?:(?:(?:[Ee][Dd]s?|[Ee]dited|[Ee]ditors?)((?:\\.\\s?)|(?:\\.?\\s)))                    ## 'eds?. '     | 'ed '      | 'ed.'\n      |(?:(?:[Ee][Dd]s?|[Ee]dited|[Ee]ditions?)(?:(?:\\.\\s?)|(?:\\.?\\s))by(?:\\s|([:,]\\s)))    ## 'eds?. by, ' | 'ed. by: ' | 'ed by '  | 'ed. by '| 'ed by: '\n      |(?:\\(\\s?([Ee][Dd]s?|[Ee]dited|[Ee]ditors?)(?:(?:\\.\\s?)|(?:\\.?\\s))?\\)))           ## '( eds?. )'  | '(ed.)'    | '(ed )'   | '( ed )' | '(ed)'\n     )?\n\n                                                                    ## **** (1) , one or two surnames which MUST end with 'et al' (e.g. Amaldi et al.,)\n   (?P<author_names>\n       (?:\n         (?:[A-Z](?:\\s*[.'\u2019-]{1,2}\\s*[A-Z]){0,4}[.\\s]\\s*)?          ## Initials\n         [A-Z][^0-9_\\.\\s]{2,20}(?:(?:[,\\.]\\s*)|(?:[,\\.]?\\s+))       ## Surname\n         (?:[A-Z](?:\\s*[.'\u2019-]{1,2}\\s*[A-Z]){0,4}[.\\s]\\s*)?          ## Initials\n         (?P<multi_surs>\n          (?:(?:[Aa][Nn][Dd]|\\&)\\s+)                                ## Maybe 'and' or '&' tied with another name\n          [A-Z][^0-9_\\.\\s]{3,20}(?:(?:[,\\.]\\s*)|(?:[,\\.]?\\s+))      ## More surnames\n          (?:[A-Z](?:[ -][A-Z])?\\s+)?                               ## with initials\n         )?\n         (?:                     # Look for editor notation after the author group...\n             \\s*[,\\s]?\\s*        # Eventually a coma/space\n             %(ed)s\n         )?\n         (?P<et2>\n            %(etal)s                                                ## et al, MUST BE PRESENT however, for this author form\n         )\n         (?:                     # Look for editor notation after the author group...\n             \\s*[,\\s]?\\s*        # Eventually a coma/space\n             %(ed)s\n         )?\n       ) |\n\n        (?:\n                                                                    ## **** (2) , The standard author form.. (e.g. J. Bloggs)\n                                                                    ## This author form can either start with a normal 'initial surname' author,\n                                                                    ## or it can begin with a single 'surname initial' author\n\n            (?:                                                     ## The first author in the 'author group'\n               %(i_s_author)s |\n               (?P<sur_initial_auth>%(s_i_author)s)\n            )\n\n            (?P<multi_auth>\n                (?:                                                 ## Then 0 or more author names\n                    \\s*[,\\s]\\s*\n                    (?:\n                        %(i_s_author)s | %(s_i_author)s\n                    )\n                )*\n\n                (?:                                                 ## Maybe 'and' or '&' tied with another name\n                    (?:\n                        \\s*[,\\s]\\s*                                 ## handle \"J. Dan, and H. Pon\"\n                        (?:[Aa][Nn][DdsS]|\\&)\n                        \\s+\n                    )\n                    (?P<mult_auth_sub>\n                        %(i_s_author)s | %(s_i_author)s\n                    )\n                )?\n             )\n             (?P<et>            # 'et al' need not be present for either of\n                \\s*[,\\s]\\s*\n                %(etal)s        # 'initial surname' or 'surname initial' authors\n             )?\n        )\n    )\n    (?P<ee>\n        \\s*[,\\s]\\s*\n        \\(?\n        (?:[Ee][Dd]s|[Ee]ditors)\\.?\n        \\)?\n        [\\.\\,]{0,2}\n    )?\n    # End of all author name patterns\n\n    \\)?                # A possible closing bracket to finish the author group\n    (?=[\\s,.;:])        # Consolidate by checking we are not partially matching\n                       # something else\n\n    \"\"\" % {'etal': etal,\n           'i_s_author': initial_surname_author,\n           's_i_author': surname_initial_author,\n           'ed': re_ed_notation}", "response": "This method returns a regular expression that can be used to identify author names in a citation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_collaborations_regex_str():\n    def add_to_auth_list(s):\n        \"\"\"Strip the line, replace spaces with 'backslash s' and append 'the'\n        to the start and 's' to the end. Add the prepared line to the list of\n        extra kb authors.\"\"\"\n        s = ur\"(?:the\\s)?\" + s.strip().replace(u' ', ur'\\s') + u\"s?\"\n        auths.append(s)\n\n    # Build the 'or'd regular expression of the author lines in the author\n    # knowledge base\n    auths = []\n    fpath = CFG_REFEXTRACT_KBS['collaborations']\n\n    try:\n        fh = open(fpath, \"r\")\n    except IOError:\n        # problem opening KB for reading, or problem while reading from it:\n        LOGGER.debug(u\"Error: Could not build knowledge base containing author patterns - failed to read from KB %s s.\\n\", fpath)\n        raise IOError(\"Error: Unable to open collaborations kb '%s'\" % fpath)\n\n    for line_num, rawline in enumerate(fh):\n        try:\n            rawline = rawline.decode(\"utf-8\")\n        except UnicodeError:\n            LOGGER.debug(u\"Unicode problems in %s for line %d\", fpath, line_num)\n            raise UnicodeError(\n                \"Error: Unable to parse collaboration kb (line: %s)\" % str(line_num))\n        if rawline.strip() and rawline[0].strip() != '#':\n            add_to_auth_list(rawline)\n            # Shorten collaboration to 'coll'\n            if rawline.lower().endswith('collaboration\\n'):\n                coll_version = rawline[:rawline.lower().find(\n                    u'collaboration\\n')] + ur\"coll[\\.\\,]\"\n                add_to_auth_list(\n                    coll_version.strip().replace(' ', r'\\s') + u\"s?\")\n\n    author_match_re = \"\"\n    if len(auths) > 0:\n        author_match_re = u'|'.join([u\"(?:\" + a + u\")\" for a in auths])\n        author_match_re = ur\"(?:(?:[\\(\\\"]?(?P<extra_auth>\" + \\\n            author_match_re + ur\")[\\)\\\"]?[\\,\\.]?\\s?(?:and\\s)?)+)\"\n\n    return author_match_re", "response": "Build a single regex that can be used to find matches in the collaborations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch in document body for the first line of the reference section.", "response": "def find_reference_section(docbody):\n    \"\"\"Search in document body for its reference section.\n\n    More precisely, find\n    the first line of the reference section. Effectively, the function starts\n    at the end of a document and works backwards, line-by-line, looking for\n    the title of a reference section. It stops when (if) it finds something\n    that it considers to be the first line of a reference section.\n    @param docbody: (list) of strings - the full document body.\n    @return: (dictionary) :\n        { 'start_line' : (integer) - index in docbody of 1st reference line,\n          'title_string' : (string) - title of the reference section.\n          'marker' : (string) - the marker of the first reference line,\n          'marker_pattern' : (string) - regexp string used to find the marker,\n          'title_marker_same_line' : (integer) - flag to indicate whether the\n                                        reference section title was on the same\n                                        line as the first reference line's\n                                        marker or not. 1 if it was; 0 if not.\n        }\n        Much of this information is used by later functions to rebuild\n        a reference section.\n         -- OR --\n                (None) - when the reference section could not be found.\n    \"\"\"\n    ref_details = None\n    title_patterns = get_reference_section_title_patterns()\n\n    # Try to find refs section title:\n    for title_pattern in title_patterns:\n        # Look for title pattern in docbody\n        for reversed_index, line in enumerate(reversed(docbody)):\n            title_match = title_pattern.match(line)\n            if title_match:\n                title = title_match.group('title')\n                index = len(docbody) - 1 - reversed_index\n                temp_ref_details, found_title = find_numeration(docbody[index:index + 6], title)\n                if temp_ref_details:\n                    if ref_details and 'title' in ref_details and ref_details['title'] and not temp_ref_details['title']:\n                        continue\n                    if ref_details and 'marker' in ref_details and ref_details['marker'] and not temp_ref_details['marker']:\n                        continue\n\n                    ref_details = temp_ref_details\n                    ref_details['start_line'] = index\n                    ref_details['title_string'] = title\n\n                if found_title:\n                    break\n\n        if ref_details:\n            break\n\n    return ref_details"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding numeration in the document body and title.", "response": "def find_numeration(docbody, title):\n    \"\"\"Find numeration pattern\n\n    1st try to find numeration in the title\n    e.g.\n    References [4] Riotto...\n\n    2nd find the numeration alone in the line after the title\n    e.g.\n    References\n    1\n    Riotto\n\n    3rnd find the numeration in the following line\n    e.g.\n    References\n    [1] Riotto\n    \"\"\"\n    ref_details, found_title = find_numeration_in_title(docbody, title)\n    if not ref_details:\n        ref_details, found_title = find_numeration_in_body(docbody)\n\n    return ref_details, found_title"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlocating and extract the reference section from a fulltext document.", "response": "def extract_references_from_fulltext(fulltext):\n    \"\"\"Locate and extract the reference section from a fulltext document.\n       Return the extracted reference section as a list of strings, whereby each\n       string in the list is considered to be a single reference line.\n        E.g. a string could be something like:\n        '[19] Wilson, A. Unpublished (1986).\n       @param fulltext: (list) of strings, whereby each string is a line of the\n        document.\n       @return: (list) of strings, where each string is an extracted reference\n        line.\n    \"\"\"\n    # Try to remove pagebreaks, headers, footers\n    fulltext = remove_page_boundary_lines(fulltext)\n    status = 0\n    # How ref section found flag\n    how_found_start = 0\n    # Find start of refs section\n    ref_sect_start = get_reference_section_beginning(fulltext)\n\n    if ref_sect_start is None:\n        # No References\n        refs = []\n        status = 4\n        LOGGER.debug(u\"extract_references_from_fulltext: ref_sect_start is None\")\n    else:\n        # If a reference section was found, however weak\n        ref_sect_end = \\\n            find_end_of_reference_section(fulltext,\n                                          ref_sect_start[\"start_line\"],\n                                          ref_sect_start[\"marker\"],\n                                          ref_sect_start[\"marker_pattern\"])\n        if ref_sect_end is None:\n            # No End to refs? Not safe to extract\n            refs = []\n            status = 5\n            LOGGER.debug(u\"extract_references_from_fulltext: no end to refs!\")\n        else:\n            # If the end of the reference section was found.. start extraction\n            refs = get_reference_lines(fulltext,\n                                       ref_sect_start[\"start_line\"],\n                                       ref_sect_end,\n                                       ref_sect_start[\"title_string\"],\n                                       ref_sect_start[\"marker_pattern\"],\n                                       ref_sect_start[\"title_marker_same_line\"])\n\n    return refs, status, how_found_start"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_reference_lines(docbody,\n                        ref_sect_start_line,\n                        ref_sect_end_line,\n                        ref_sect_title,\n                        ref_line_marker_ptn,\n                        title_marker_same_line):\n    \"\"\"After the reference section of a document has been identified, and the\n       first and last lines of the reference section have been recorded, this\n       function is called to take the reference lines out of the document body.\n       The document's reference lines are returned in a list of strings whereby\n       each string is a reference line. Before this can be done however, the\n       reference section is passed to another function that rebuilds any broken\n       reference lines.\n       @param docbody: (list) of strings - the entire document body.\n       @param ref_sect_start_line: (integer) - the index in docbody of the first\n        reference line.\n       @param ref_sect_end_line: (integer) - the index in docbody of the last\n        reference line.\n       @param ref_sect_title: (string) - the title of the reference section\n        (e.g. \"References\").\n       @param ref_line_marker_ptn: (string) - the patern used to match the\n        marker for each reference line (e.g., could be used to match lines\n        with markers of the form [1], [2], etc.)\n       @param title_marker_same_line: (integer) - a flag to indicate whether\n        or not the reference section title was on the same line as the first\n        reference line's marker.\n       @return: (list) of strings. Each string is a reference line, extracted\n        from the document.\n    \"\"\"\n    start_idx = ref_sect_start_line\n    if title_marker_same_line:\n        # Title on same line as 1st ref- take title out!\n        title_start = docbody[start_idx].find(ref_sect_title)\n        if title_start != -1:\n            # Set the first line with no title\n            docbody[start_idx] = docbody[start_idx][title_start +\n                                                    len(ref_sect_title):]\n    elif ref_sect_title is not None:\n        # Set the start of the reference section to be after the title line\n        start_idx += 1\n\n    if ref_sect_end_line is not None:\n        ref_lines = docbody[start_idx:ref_sect_end_line + 1]\n    else:\n        ref_lines = docbody[start_idx:]\n\n    if ref_sect_title:\n        ref_lines = strip_footer(ref_lines, ref_sect_title)\n    # Now rebuild reference lines:\n    # (Go through each raw reference line, and format them into a set\n    # of properly ordered lines based on markers)\n    return rebuild_reference_lines(ref_lines, ref_line_marker_ptn)", "response": "This function takes the reference lines out of the document body and returns the list of strings where each string is a reference line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match_pagination(ref_line):\n    pattern = ur'\\(?\\[?(\\d{1,4})\\]?\\)?\\.?\\s*$'\n    re_footer = re.compile(pattern, re.UNICODE)\n    match = re_footer.match(ref_line)\n    if match:\n        return int(match.group(1))\n    return None", "response": "Remove footer pagination from references lines"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip_footer(ref_lines, section_title):\n    pattern = ur'\\(?\\[?\\d{0,4}\\]?\\)?\\.?\\s*%s\\s*$' % re.escape(section_title)\n    re_footer = re.compile(pattern, re.UNICODE)\n    return [l for l in ref_lines if not re_footer.match(l)]", "response": "Remove footer title from references lines"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a reference section, rebuild the reference lines. After translation from PDF to text, reference lines are often broken. This is because pdftotext doesn't know what is a wrapped-line and what is a genuine new line. As a result, the following 2 reference lines: [1] See http://invenio-software.org/ for more details. [2] Example, AN: private communication (1996). ...could be broken into the following 4 lines during translation from PDF to plaintext: [1] See http://invenio-software.org/ fo r more details. [2] Example, AN: private communica tion (1996). Such a situation could lead to a citation being separated across 'lines', meaning that it wouldn't be correctly recognised. This function tries to rebuild the reference lines. It uses the pattern used to recognise a reference line's numeration marker to indicate the start of a line. If no reference line numeration was recognised, it will simply join all lines together into one large reference line. @param ref_sectn: (list) of strings. The (potentially broken) reference lines. @param ref_line_marker_ptn: (string) - the pattern used to recognise a reference line's numeration marker. @return: (list) of strings - the rebuilt reference section. Each string in the list represents a complete reference line.", "response": "def rebuild_reference_lines(ref_sectn, ref_line_marker_ptn):\n    \"\"\"Given a reference section, rebuild the reference lines. After translation\n       from PDF to text, reference lines are often broken. This is because\n       pdftotext doesn't know what is a wrapped-line and what is a genuine new\n       line. As a result, the following 2 reference lines:\n        [1] See http://invenio-software.org/ for more details.\n        [2] Example, AN: private communication (1996).\n       ...could be broken into the following 4 lines during translation from PDF\n       to plaintext:\n        [1] See http://invenio-software.org/ fo\n        r more details.\n        [2] Example, AN: private communica\n        tion (1996).\n       Such a situation could lead to a citation being separated across 'lines',\n       meaning that it wouldn't be correctly recognised.\n       This function tries to rebuild the reference lines. It uses the pattern\n       used to recognise a reference line's numeration marker to indicate the\n       start of a line. If no reference line numeration was recognised, it will\n       simply join all lines together into one large reference line.\n       @param ref_sectn: (list) of strings. The (potentially broken) reference\n        lines.\n       @param ref_line_marker_ptn: (string) - the pattern used to recognise a\n        reference line's numeration marker.\n       @return: (list) of strings - the rebuilt reference section. Each string\n        in the list represents a complete reference line.\n    \"\"\"\n    indentation_splitting = False\n\n    # This should be moved the function detecting the pattern!\n    if not ref_line_marker_ptn:\n        if test_for_blank_lines_separating_reference_lines(ref_sectn):\n            # Use blank lines to separate ref lines\n            ref_line_marker_ptn = ur'^\\s*$'\n        else:\n            # No ref line dividers\n            # We are guessing this the format:\n            # Reference1\n            #      etc\n            # Reference2\n            #      etc\n            # We split when there's no identation\n            indentation_splitting = True\n            ref_line_marker_ptn = ur'^[^\\s]'\n\n    LOGGER.debug(u\"references separator %s\", ref_line_marker_ptn)\n    p_ref_line_marker = re.compile(ref_line_marker_ptn, re.I | re.UNICODE)\n\n    # Start from ref 1\n    # Append each fixed reference line to rebuilt_references\n    # and rebuild references as we go\n    current_ref = 0\n    rebuilt_references = []\n    working_ref = []\n\n    def prepare_ref(working_ref):\n        working_ref = working_ref[:CFG_REFEXTRACT_MAX_LINES]\n        working_line = \"\"\n        for l in working_ref:\n            working_line = join_lines(working_line, l.strip())\n        return working_line.rstrip()\n\n    lower_case_start = re.compile(ur'[a-z]')\n    continuing_line_markers = re.compile(ur'[,&-]$')\n\n    for line in ref_sectn:\n        # Can't find a good way to distinguish between\n        # pagination and the page number of a journal numeration that\n        # happens to be alone in a new line\n        # m = match_pagination(line)\n        # if m and current_ref and current_ref != m + 1:\n        #     continue\n\n        # Try to find the marker for the reference line\n        m_ref_line_marker = p_ref_line_marker.search(line)\n\n        if m_ref_line_marker:\n            try:\n                marknum = int(m_ref_line_marker.group('marknum'))\n            except IndexError:\n                marknum = None\n            except ValueError:\n                # If the mark is a unicode character category [Nd],\n                # it is not always convertible to int by int()\n                # We can't use its numerical value, but we still accept it\n                # as numeration\n                pass\n\n            new_line_detected = False\n            if marknum is None or current_ref + 1 == marknum:\n                new_line_detected = True\n            if indentation_splitting:\n                if lower_case_start.match(line.strip()):\n                    new_line_detected = False\n                if working_ref and \\\n                        continuing_line_markers.search(working_ref[-1].strip()):\n                    new_line_detected = False\n\n            if new_line_detected:\n                # Reference line marker found! : Append this reference to the\n                # list of fixed references and reset the working_line to\n                # 'blank'\n                start = m_ref_line_marker.start()\n                if line[:start]:\n                    # If it's not a blank line to separate refs\n                    # Only append from the start of the marker\n                    # For this case:\n                    # [1] hello\n                    # hello2 [2] foo\n                    working_ref.append(line[:start])\n\n                # Append current working line to the refs list\n                if working_ref:\n                    rebuilt_references.append(prepare_ref(working_ref))\n\n                current_ref = marknum\n                working_ref = []\n                if line[start:]:\n                    working_ref.append(line[start:])\n\n            else:\n                # Our marker does not match the counting\n                # Either we missed one, the author missed one or\n                # it is not a line marker\n                # For now we assume it is not line marker\n                working_ref.append(line)\n\n        elif line:\n            # Continuation of line\n            working_ref.append(line)\n\n    if working_ref:\n        # Append last line\n        rebuilt_references.append(prepare_ref(working_ref))\n\n    return rebuilt_references"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwash a reference line of undesirable characters and repair any errors.", "response": "def wash_and_repair_reference_line(line):\n    \"\"\"Wash a reference line of undesirable characters (such as poorly-encoded\n       letters, etc), and repair any errors (such as broken URLs) if possible.\n       @param line: (string) the reference line to be washed/repaired.\n       @return: (string) the washed reference line.\n    \"\"\"\n    # repair URLs in line:\n    line = repair_broken_urls(line)\n    # Replace various undesirable characters with their alternatives:\n    line = replace_undesirable_characters(line)\n    # Replace \"<title>,\" with \"<title>\",\n    # common typing mistake\n    line = re.sub(ur'\"([^\"]+),\"', ur'\"\\g<1>\",', line)\n    line = replace_undesirable_characters(line)\n    # Remove instances of multiple spaces from line, replacing with a\n    # single space:\n    line = re_multiple_space.sub(u' ', line)\n    return line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract references from the PDF specified in the url.", "response": "def extract_references_from_url(url, headers=None, chunk_size=1024, **kwargs):\n    \"\"\"Extract references from the pdf specified in the url.\n\n    The first parameter is the URL of the file.\n    It returns a list of parsed references.\n\n    It raises FullTextNotAvailableError if the URL gives a 404,\n    UnknownDocumentTypeError if it is not a PDF or plain text.\n\n    The standard reference format is: {title} {volume} ({year}) {page}.\n\n    E.g. you can change that by passing the reference_format:\n\n    >>> extract_references_from_url(path, reference_format=\"{title},{volume},{page}\")\n\n    If you want to also link each reference to some other resource (like a record),\n    you can provide a linker_callback function to be executed for every reference\n    element found.\n\n    To override KBs for journal names etc., use ``override_kbs_files``:\n\n    >>> extract_references_from_url(path, override_kbs_files={'journals': 'my/path/to.kb'})\n\n    \"\"\"\n    # Get temporary filepath to download to\n    filename, filepath = mkstemp(\n        suffix=u\"_{0}\".format(os.path.basename(url)),\n    )\n    os.close(filename)\n\n    try:\n        req = requests.get(\n            url=url,\n            headers=headers,\n            stream=True\n        )\n        req.raise_for_status()\n        with open(filepath, 'wb') as f:\n            for chunk in req.iter_content(chunk_size):\n                f.write(chunk)\n        references = extract_references_from_file(filepath, **kwargs)\n    except requests.exceptions.HTTPError:\n        raise FullTextNotAvailableError(u\"URL not found: '{0}'\".format(url)), None, sys.exc_info()[2]\n    finally:\n        os.remove(filepath)\n    return references"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_references_from_file(path,\n                                 recid=None,\n                                 reference_format=u\"{title} {volume} ({year}) {page}\",\n                                 linker_callback=None,\n                                 override_kbs_files=None):\n    \"\"\"Extract references from a local pdf file.\n\n    The first parameter is the path to the file.\n    It returns a list of parsed references.\n    It raises FullTextNotAvailableError if the file does not exist,\n    UnknownDocumentTypeError if it is not a PDF or plain text.\n\n    The standard reference format is: {title} {volume} ({year}) {page}.\n\n    E.g. you can change that by passing the reference_format:\n\n    >>> extract_references_from_file(path, reference_format=u\"{title},{volume},{page}\")\n\n    If you want to also link each reference to some other resource (like a record),\n    you can provide a linker_callback function to be executed for every reference\n    element found.\n\n    To override KBs for journal names etc., use ``override_kbs_files``:\n\n    >>> extract_references_from_file(path, override_kbs_files={'journals': 'my/path/to.kb'})\n\n    \"\"\"\n    if not os.path.isfile(path):\n        raise FullTextNotAvailableError(u\"File not found: '{0}'\".format(path))\n\n    docbody = get_plaintext_document_body(path)\n    reflines, dummy, dummy = extract_references_from_fulltext(docbody)\n    if not reflines:\n        docbody = get_plaintext_document_body(path, keep_layout=True)\n        reflines, dummy, dummy = extract_references_from_fulltext(docbody)\n\n    parsed_refs, stats = parse_references(\n        reflines,\n        recid=recid,\n        reference_format=reference_format,\n        linker_callback=linker_callback,\n        override_kbs_files=override_kbs_files,\n    )\n\n    if magic.from_file(path, mime=True) == \"application/pdf\":\n        texkeys = extract_texkeys_from_pdf(path)\n        if len(texkeys) == len(parsed_refs):\n            parsed_refs = [dict(ref, texkey=[key]) for ref, key in izip(parsed_refs, texkeys)]\n\n    return parsed_refs", "response": "Extract references from a local PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_references_from_string(source,\n                                   is_only_references=True,\n                                   recid=None,\n                                   reference_format=\"{title} {volume} ({year}) {page}\",\n                                   linker_callback=None,\n                                   override_kbs_files=None):\n    \"\"\"Extract references from a raw string.\n\n    The first parameter is the path to the file.\n    It returns a tuple (references, stats).\n\n    If the string does not only contain references, improve accuracy by\n    specifing ``is_only_references=False``.\n\n    The standard reference format is: {title} {volume} ({year}) {page}.\n\n    E.g. you can change that by passing the reference_format:\n\n    >>> extract_references_from_string(path, reference_format=\"{title},{volume},{page}\")\n\n    If you want to also link each reference to some other resource (like a record),\n    you can provide a linker_callback function to be executed for every reference\n    element found.\n\n    To override KBs for journal names etc., use ``override_kbs_files``:\n\n    >>> extract_references_from_string(path, override_kbs_files={'journals': 'my/path/to.kb'})\n    \"\"\"\n    docbody = source.split('\\n')\n    if not is_only_references:\n        reflines, dummy, dummy = extract_references_from_fulltext(docbody)\n    else:\n        refs_info = get_reference_section_beginning(docbody)\n        if not refs_info:\n            refs_info, dummy = find_numeration_in_body(docbody)\n            refs_info['start_line'] = 0\n            refs_info['end_line'] = len(docbody) - 1,\n\n        reflines = rebuild_reference_lines(\n            docbody, refs_info['marker_pattern'])\n    parsed_refs, stats = parse_references(\n        reflines,\n        recid=recid,\n        reference_format=reference_format,\n        linker_callback=linker_callback,\n        override_kbs_files=override_kbs_files,\n    )\n    return parsed_refs", "response": "Extract references from a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_journal_reference(line, override_kbs_files=None):\n    kbs = get_kbs(custom_kbs_files=override_kbs_files)\n    references, dummy_m, dummy_c, dummy_co = parse_reference_line(line, kbs)\n\n    for elements in references:\n        for el in elements:\n            if el['type'] == 'JOURNAL':\n                return el", "response": "Extracts the journal reference from string and parses for specific\n    journal information."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_references(citations, reference_format=False):\n    # Now, run the method which will take as input:\n    # 1. A list of lists of dictionaries, where each dictionary is a piece\n    # of citation information corresponding to a tag in the citation.\n    # 2. The line marker for this entire citation line (mulitple citation\n    # 'finds' inside a single citation will use the same marker value)\n    # The resulting xml line will be a properly marked up form of the\n    # citation. It will take into account authors to try and split up\n    # references which should be read as two SEPARATE ones.\n    return [c for citation_elements in citations\n            for elements in citation_elements['elements']\n            for c in build_reference_fields(elements,\n                                            citation_elements['line_marker'],\n                                            citation_elements['raw_ref'],\n                                            reference_format)]", "response": "Builds a list of reference dictionaries from a list of citations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the final representation of the reference information.", "response": "def build_reference_fields(citation_elements, line_marker, raw_ref,\n                           reference_format):\n    \"\"\"Create the final representation of the reference information.\n\n    @param citation_elements: (list) an ordered list of dictionary elements,\n                              with each element corresponding to a found\n                              piece of information from a reference line.\n    @param line_marker: (string) The line marker for this single reference\n                        line (e.g. [19])\n    @param raw_ref: (string) The raw string of this line\n    @return reference_fields: (list) A list of one dictionary containing the\n                      reference elements\n    \"\"\"\n    # Begin the datafield element\n    current_field = create_reference_field(line_marker)\n    current_field['raw_ref'] = [raw_ref]\n\n    reference_fields = [current_field]\n\n    for element in citation_elements:\n        # Before going onto checking 'what' the next element is,\n        # handle misc text and semi-colons\n        # Multiple misc text subfields will be compressed later\n        # This will also be the only part of the code that deals with MISC\n        # tag_typed elements\n        misc_txt = element['misc_txt']\n        if misc_txt.strip(\"., [](){}\"):\n            misc_txt = misc_txt.lstrip('])} ,.').rstrip('[({ ,.')\n            add_subfield(current_field, 'misc', misc_txt)\n\n        # Now handle the type dependent actions\n        # JOURNAL\n        if element['type'] == \"JOURNAL\":\n            add_journal_subfield(current_field, element, reference_format)\n\n        # REPORT NUMBER\n        elif element['type'] == \"REPORTNUMBER\":\n            add_subfield(current_field, 'reportnumber', element['report_num'])\n\n        # URL\n        elif element['type'] == \"URL\":\n            if element['url_string'] == element['url_desc']:\n                # Build the datafield for the URL segment of the reference\n                # line:\n                add_subfield(current_field, 'url', element['url_string'])\n            # Else, in the case that the url string and the description differ\n            # in some way, include them both\n            else:\n                add_subfield(current_field, 'url', element['url_string'])\n                add_subfield(current_field, 'urldesc', element['url_desc'])\n\n        # DOI\n        elif element['type'] == \"DOI\":\n            add_subfield(current_field, 'doi', 'doi:' + element['doi_string'])\n\n        # HDL\n        elif element['type'] == \"HDL\":\n            add_subfield(current_field, 'hdl', 'hdl:' + element['hdl_id'])\n\n        # AUTHOR\n        elif element['type'] == \"AUTH\":\n            value = element['auth_txt']\n            if element['auth_type'] == 'incl':\n                value = \"(%s)\" % value\n\n            add_subfield(current_field, 'author', value)\n\n        elif element['type'] == \"QUOTED\":\n            add_subfield(current_field, 'title', element['title'])\n\n        elif element['type'] == \"ISBN\":\n            add_subfield(current_field, 'isbn', element['ISBN'])\n\n        elif element['type'] == \"BOOK\":\n            add_subfield(current_field, 'title', element['title'])\n\n        elif element['type'] == \"PUBLISHER\":\n            add_subfield(current_field, 'publisher', element['publisher'])\n\n        elif element['type'] == \"YEAR\":\n            add_subfield(current_field, 'year', element['year'])\n\n        elif element['type'] == \"COLLABORATION\":\n            add_subfield(current_field,\n                         'collaboration',\n                         element['collaboration'])\n\n        elif element['type'] == \"RECID\":\n            add_subfield(current_field, 'recid', str(element['recid']))\n\n    return reference_fields"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_texkeys_from_pdf(pdf_file):\n    with open(pdf_file, 'rb') as pdf_stream:\n        try:\n            pdf = PdfFileReader(pdf_stream, strict=False)\n            destinations = pdf.getNamedDestinations()\n        except Exception:\n            LOGGER.debug(u\"PDF: Internal PyPDF2 error, no TeXkeys returned.\")\n            return []\n        # not all named destinations point to references\n        refs = [dest for dest in destinations.iteritems()\n                if re_reference_in_dest.match(dest[0])]\n        try:\n            if _destinations_in_two_columns(pdf, refs):\n                LOGGER.debug(u\"PDF: Using two-column layout\")\n\n                def sortfunc(dest_couple):\n                    return _destination_position(pdf, dest_couple[1])\n\n            else:\n                LOGGER.debug(u\"PDF: Using single-column layout\")\n\n                def sortfunc(dest_couple):\n                    (page, _, ypos, xpos) = _destination_position(\n                        pdf, dest_couple[1])\n                    return (page, ypos, xpos)\n\n            refs.sort(key=sortfunc)\n            # extract the TeXkey from the named destination name\n            return [re_reference_in_dest.match(destname).group(1)\n                    for (destname, _) in refs]\n        except Exception:\n            LOGGER.debug(u\"PDF: Impossible to determine layout, no TeXkeys returned\")\n            return []", "response": "Extract the TeXkeys from the given PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _destinations_in_two_columns(pdf, destinations, cutoff=3):\n    # iterator for the x coordinates of refs in the would-be second column\n    xpositions = (_destination_position(pdf, dest)[3] for (_, dest)\n                  in destinations\n                  if _destination_position(pdf, dest)[1] == 1)\n    xpos_count = {}\n    for xpos in xpositions:\n        xpos_count[xpos] = xpos_count.get(xpos, 0) + 1\n        if xpos_count[xpos] >= cutoff:\n            return True\n    return False", "response": "Check if the destinations are organized along two columns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _destination_position(pdf, destination):\n    pagewidth = pdf.getPage(\n        pdf.getDestinationPageNumber(destination)\n    ).cropBox.lowerRight[0]\n    if not destination.left or not destination.top:\n        raise IncompleteCoordinatesError(destination)\n    # assuming max 2 columns\n    column = (2 * destination.left) // pagewidth\n    return (pdf.getDestinationPageNumber(destination),\n            column, -destination.top, destination.left)", "response": "Returns a tuple representing the position of the named destination in the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_regex_pattern_add_optional_spaces_to_word_characters(word):\n    new_word = u\"\"\n    for ch in word:\n        if ch.isspace():\n            new_word += ch\n        else:\n            new_word += ch + ur'\\s*'\n    return new_word", "response": "Adds optional spaces between all of the characters in a word."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_reference_line_numeration_marker_patterns(prefix=u''):\n    title = u\"\"\n    if type(prefix) in (str, unicode):\n        title = prefix\n    g_name = u'(?P<mark>'\n    g_close = u')'\n    space = ur'\\s*'\n    patterns = [\n        # [1]\n        space + title + g_name + ur'\\[\\s*(?P<marknum>\\d+)\\s*\\]' + g_close,\n        # [<letters and numbers]\n        space + title + g_name +\n        ur'\\[\\s*[a-zA-Z:-]+\\+?\\s?(\\d{1,4}[A-Za-z:-]?)?\\s*\\]' + g_close,\n        # {1}\n        space + title + g_name + ur'\\{\\s*(?P<marknum>\\d+)\\s*\\}' + g_close,\n        # (1)\n        space + title + g_name + ur'\\<\\s*(?P<marknum>\\d+)\\s*\\>' + g_close,\n        space + title + g_name + ur'\\(\\s*(?P<marknum>\\d+)\\s*\\)' + g_close,\n        space + title + g_name + ur'(?P<marknum>\\d+)\\s*\\.(?!\\d)' + g_close,\n        space + title + g_name + ur'(?P<marknum>\\d+)\\s+' + g_close,\n        space + title + g_name + ur'(?P<marknum>\\d+)\\s*\\]' + g_close,\n        # 1]\n        space + title + g_name + ur'(?P<marknum>\\d+)\\s*\\}' + g_close,\n        # 1}\n        space + title + g_name + ur'(?P<marknum>\\d+)\\s*\\)' + g_close,\n        # 1)\n        space + title + g_name + ur'(?P<marknum>\\d+)\\s*\\>' + g_close,\n        # [1.1]\n        space + title + g_name + ur'\\[\\s*\\d+\\.\\d+\\s*\\]' + g_close,\n        # [    ]\n        space + title + g_name + ur'\\[\\s*\\]' + g_close,\n        # *\n        space + title + g_name + ur'\\*' + g_close,\n    ]\n    return [re.compile(p, re.I | re.UNICODE) for p in patterns]", "response": "Return a list of compiled regex patterns used to search for the marker\n       of a reference line in a full - text document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_reference_line_marker_pattern(pattern):\n    return re.compile(u'(?P<mark>' + pattern + u')', re.I | re.UNICODE)", "response": "Return a list of compiled regex patterns used to search for the first\n       reference line in a full - text document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of compiled regex patterns used to search for the title of the section after the reference section in a full - text document.", "response": "def get_post_reference_section_title_patterns():\n    \"\"\"Return a list of compiled regex patterns used to search for the title\n       of the section after the reference section in a full-text document.\n       @return: (list) of compiled regex patterns.\n    \"\"\"\n    compiled_patterns = []\n    thead = ur'^\\s*([\\{\\(\\<\\[]?\\s*(\\w|\\d)\\s*[\\)\\}\\>\\.\\-\\]]?\\s*)?'\n    ttail = ur'(\\s*\\:\\s*)?'\n    numatn = ur'(\\d+|\\w\\b|i{1,3}v?|vi{0,3})[\\.\\,]{0,2}\\b'\n    roman_numbers = ur'[LVIX]'\n    patterns = [\n        # Section titles\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'appendix') + ttail,\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'appendices') + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'acknowledgement') + ur's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'acknowledgment') + ur's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'table') + ur'\\w?s?\\d?' + ttail,\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'figure') + ur's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'list of figure') + ur's?' + ttail,\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'annex') + ur's?' + ttail,\n        thead + _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'discussion') + ur's?' + ttail,\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'remercie') + ur's?' + ttail,\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'index') + ur's?' + ttail,\n        thead +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'summary') + ur's?' + ttail,\n        # Figure nums\n        ur'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'figure') + numatn,\n        ur'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'fig') + ur'\\.\\s*' + numatn,\n        ur'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'fig') + ur'\\.?\\s*\\d\\w?\\b',\n        # Tables\n        ur'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'table') + numatn,\n        ur'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'tab') + ur'\\.\\s*' + numatn,\n        ur'^\\s*' +\n        _create_regex_pattern_add_optional_spaces_to_word_characters(\n            u'tab') + ur'\\.?\\s*\\d\\w?\\b',\n        # Other titles formats\n        ur'^\\s*' + roman_numbers + ur'\\.?\\s*[Cc]onclusion[\\w\\s]*$',\n        ur'^\\s*Appendix\\s[A-Z]\\s*\\:\\s*[a-zA-Z]+\\s*',\n    ]\n\n    for p in patterns:\n        compiled_patterns.append(re.compile(p, re.I | re.UNICODE))\n\n    return compiled_patterns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of compiled regex patterns used to search for various keywords that can often be found after and suggest the end of the reference section.", "response": "def get_post_reference_section_keyword_patterns():\n    \"\"\"Return a list of compiled regex patterns used to search for various\n       keywords that can often be found after, and therefore suggest the end of,\n       a reference section in a full-text document.\n       @return: (list) of compiled regex patterns.\n    \"\"\"\n    compiled_patterns = []\n    patterns = [u'(' + _create_regex_pattern_add_optional_spaces_to_word_characters(u'prepared') +\n                ur'|' + _create_regex_pattern_add_optional_spaces_to_word_characters(u'created') +\n                ur').*(AAS\\s*)?\\sLATEX',\n                ur'AAS\\s+?LATEX\\s+?' +\n                _create_regex_pattern_add_optional_spaces_to_word_characters(\n                    u'macros') + u'v',\n                ur'^\\s*' + _create_regex_pattern_add_optional_spaces_to_word_characters(\n                    u'This paper has been produced using'),\n                ur'^\\s*' +\n                _create_regex_pattern_add_optional_spaces_to_word_characters(u'This article was processed by the author using Springer-Verlag') +\n                u' LATEX']\n    for p in patterns:\n        compiled_patterns.append(re.compile(p, re.I | re.UNICODE))\n    return compiled_patterns"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a list of compiled regex patters perform the re. match operation on the line for every pattern.", "response": "def regex_match_list(line, patterns):\n    \"\"\"Given a list of COMPILED regex patters, perform the \"re.match\" operation\n       on the line for every pattern.\n       Break from searching at the first match, returning the match object.\n       In the case that no patterns match, the None type will be returned.\n       @param line: (unicode string) to be searched in.\n       @param patterns: (list) of compiled regex patterns to search  \"line\"\n        with.\n       @return: (None or an re.match object), depending upon whether one of\n        the patterns matched within line or not.\n    \"\"\"\n    m = None\n    for ptn in patterns:\n        m = ptn.match(line)\n        if m is not None:\n            break\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialise and return a list of precompiled regexp patterns that are used to assemble URLs that have been broken during a document s conversion to plain - text.", "response": "def get_url_repair_patterns():\n    \"\"\"Initialise and return a list of precompiled regexp patterns that\n       are used to try to re-assemble URLs that have been broken during\n       a document's conversion to plain-text.\n       @return: (list) of compiled re regexp patterns used for finding\n        various broken URLs.\n    \"\"\"\n    file_types_list = [\n        ur'h\\s*t\\s*m',          # htm\n        ur'h\\s*t\\s*m\\s*l',      # html\n        ur't\\s*x\\s*t'           # txt\n        ur'p\\s*h\\s*p'           # php\n        ur'a\\s*s\\s*p\\s*'        # asp\n        ur'j\\s*s\\s*p',          # jsp\n        ur'p\\s*y',              # py (python)\n        ur'p\\s*l',              # pl (perl)\n        ur'x\\s*m\\s*l',          # xml\n        ur'j\\s*p\\s*g',          # jpg\n        ur'g\\s*i\\s*f'           # gif\n        ur'm\\s*o\\s*v'           # mov\n        ur's\\s*w\\s*f'           # swf\n        ur'p\\s*d\\s*f'           # pdf\n        ur'p\\s*s'               # ps\n        ur'd\\s*o\\s*c',          # doc\n        ur't\\s*e\\s*x',          # tex\n        ur's\\s*h\\s*t\\s*m\\s*l',  # shtml\n    ]\n\n    pattern_list = [\n        ur'(h\\s*t\\s*t\\s*p\\s*\\:\\s*\\/\\s*\\/)',\n        ur'(f\\s*t\\s*p\\s*\\:\\s*\\/\\s*\\/\\s*)',\n        ur'((http|ftp):\\/\\/\\s*[\\w\\d])',\n        ur'((http|ftp):\\/\\/([\\w\\d\\s\\._\\-])+?\\s*\\/)',\n        ur'((http|ftp):\\/\\/([\\w\\d\\_\\.\\-])+\\/(([\\w\\d\\_\\s\\.\\-])+?\\/)+)',\n        ur'((http|ftp):\\/\\/([\\w\\d\\_\\.\\-])+\\/(([\\w\\d\\_\\s\\.\\-])+?\\/)*([\\w\\d\\_\\s\\-]+\\.\\s?[\\w\\d]+))',\n    ]\n    pattern_list = [re.compile(p, re.I | re.UNICODE) for p in pattern_list]\n\n    # some possible endings for URLs:\n    p = ur'((http|ftp):\\/\\/([\\w\\d\\_\\.\\-])+\\/(([\\w\\d\\_\\.\\-])+?\\/)*([\\w\\d\\_\\-]+\\.%s))'\n    for extension in file_types_list:\n        p_url = re.compile(p % extension, re.I | re.UNICODE)\n        pattern_list.append(p_url)\n\n    # if url last thing in line, and only 10 letters max, concat them\n    p_url = re.compile(\n        r'((http|ftp):\\/\\/([\\w\\d\\_\\.\\-])+\\/(([\\w\\d\\_\\.\\-])+?\\/)*\\s*?([\\w\\d\\_\\.\\-]\\s?){1,10}\\s*)$',\n        re.I | re.UNICODE)\n    pattern_list.append(p_url)\n\n    return pattern_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\njoin two lines of text into one.", "response": "def join_lines(line1, line2):\n    \"\"\"Join 2 lines of text\n\n    >>> join_lines('abc', 'de')\n    'abcde'\n    >>> join_lines('a-', 'b')\n    'ab'\n    \"\"\"\n    if line1 == u\"\":\n        pass\n    elif line1[-1] == u'-':\n        # hyphenated word at the end of the\n        # line - don't add in a space and remove hyphen\n        line1 = line1[:-1]\n    elif line1[-1] != u' ':\n        # no space at the end of this\n        # line, add in a space\n        line1 = line1 + u' '\n    return line1 + line2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef repair_broken_urls(line):\n    def _chop_spaces_in_url_match(m):\n        \"\"\"Suppresses spaces in a matched URL.\"\"\"\n        return m.group(1).replace(\" \", \"\")\n    for ptn in re_list_url_repair_patterns:\n        line = ptn.sub(_chop_spaces_in_url_match, line)\n    return line", "response": "Attempt to repair broken URLs in a line of text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_and_record_multiple_spaces_in_line(line):\n    removed_spaces = {}\n    # get a collection of match objects for all instances of\n    # multiple-spaces found in the line:\n    multispace_matches = re_group_captured_multiple_space.finditer(line)\n    # record the number of spaces found at each match position:\n    for multispace in multispace_matches:\n        removed_spaces[multispace.start()] = \\\n            (multispace.end() - multispace.start() - 1)\n    # now remove the multiple-spaces from the line, replacing with a\n    # single space at each position:\n    line = re_group_captured_multiple_space.sub(u' ', line)\n    return (removed_spaces, line)", "response": "For a given line find all ocurrences of multiple spaces in the line and record the number of spaces found at each position."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wash_line(line):\n    line = re_space_comma.sub(',', line)\n    line = re_space_semicolon.sub(';', line)\n    line = re_space_period.sub('.', line)\n    line = re_colon_space_colon.sub(':', line)\n    line = re_comma_space_colon.sub(':', line)\n    line = re_space_closing_square_bracket.sub(']', line)\n    line = re_opening_square_bracket_space.sub('[', line)\n    line = re_hyphens.sub('-', line)\n    line = re_multiple_space.sub(' ', line)\n    return line", "response": "Wash a text line of certain punctuation errors replacing them with\n       more correct alternatives."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_page_boundary_lines(docbody):\n    number_head_lines = number_foot_lines = 0\n    # Make sure document not just full of whitespace:\n    if not document_contains_text(docbody):\n        # document contains only whitespace - cannot safely\n        # strip headers/footers\n        return docbody\n\n    # Get list of index posns of pagebreaks in document:\n    page_break_posns = get_page_break_positions(docbody)\n\n    # Get num lines making up each header if poss:\n    number_head_lines = get_number_header_lines(docbody, page_break_posns)\n\n    # Get num lines making up each footer if poss:\n    number_foot_lines = get_number_footer_lines(docbody, page_break_posns)\n\n    # Remove pagebreaks,headers,footers:\n    docbody = strip_headers_footers_pagebreaks(docbody,\n                                               page_break_posns,\n                                               number_head_lines,\n                                               number_foot_lines)\n\n    return docbody", "response": "Try to locate page breaks headers and footers within a document body and remove the array cells at which they are found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlocate page breaks in the list of document lines and create a list sgi positions in the document body list.", "response": "def get_page_break_positions(docbody):\n    \"\"\"Locate page breaks in the list of document lines and create a list\n       positions in the document body list.\n       @param docbody: (list) of strings - each string is a line in the\n        document.\n       @return: (list) of integer positions, whereby each integer represents the\n        position (in the document body) of a page-break.\n    \"\"\"\n    page_break_posns = []\n    p_break = re.compile(ur'^\\s*\\f\\s*$', re.UNICODE)\n    num_document_lines = len(docbody)\n    for i in xrange(num_document_lines):\n        if p_break.match(docbody[i]) is not None:\n            page_break_posns.append(i)\n    return page_break_posns"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to guess the number of header lines that make up each page of a document.", "response": "def get_number_header_lines(docbody, page_break_posns):\n    \"\"\"Try to guess the number of header lines each page of a document has.\n       The positions of the page breaks in the document are used to try to guess\n       the number of header lines.\n       @param docbody: (list) of strings - each string being a line in the\n        document\n       @param page_break_posns: (list) of integers - each integer is the\n        position of a page break in the document.\n       @return: (int) the number of lines that make up the header of each page.\n    \"\"\"\n    remaining_breaks = len(page_break_posns) - 1\n    num_header_lines = empty_line = 0\n    # pattern to search for a word in a line:\n    p_wordSearch = re.compile(ur'([A-Za-z0-9-]+)', re.UNICODE)\n    if remaining_breaks > 2:\n        if remaining_breaks > 3:\n            # Only check odd page headers\n            next_head = 2\n        else:\n            # Check headers on each page\n            next_head = 1\n        keep_checking = 1\n        while keep_checking:\n            cur_break = 1\n            if docbody[(page_break_posns[cur_break] +\n                        num_header_lines + 1)].isspace():\n                # this is a blank line\n                empty_line = 1\n\n            if (page_break_posns[cur_break] + num_header_lines + 1) \\\n                    == (page_break_posns[(cur_break + 1)]):\n                # Have reached next page-break: document has no\n                # body - only head/footers!\n                keep_checking = 0\n\n            grps_headLineWords = \\\n                p_wordSearch.findall(docbody[(page_break_posns[cur_break] +\n                                              num_header_lines + 1)])\n            cur_break = cur_break + next_head\n            while (cur_break < remaining_breaks) and keep_checking:\n                lineno = page_break_posns[cur_break] + num_header_lines + 1\n                if lineno >= len(docbody):\n                    keep_checking = 0\n                    break\n                grps_thisLineWords = \\\n                    p_wordSearch.findall(docbody[lineno])\n                if empty_line:\n                    if len(grps_thisLineWords) != 0:\n                        # This line should be empty, but isn't\n                        keep_checking = 0\n                else:\n                    if (len(grps_thisLineWords) == 0) or \\\n                            (len(grps_headLineWords) != len(grps_thisLineWords)):\n                        # Not same num 'words' as equivilent line\n                        # in 1st header:\n                        keep_checking = 0\n                    else:\n                        keep_checking = \\\n                            check_boundary_lines_similar(grps_headLineWords,\n                                                         grps_thisLineWords)\n                # Update cur_break for nxt line to check\n                cur_break = cur_break + next_head\n            if keep_checking:\n                # Line is a header line: check next\n                num_header_lines = num_header_lines + 1\n            empty_line = 0\n    return num_header_lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to guess the number of footer lines each page of a document has.", "response": "def get_number_footer_lines(docbody, page_break_posns):\n    \"\"\"Try to guess the number of footer lines each page of a document has.\n       The positions of the page breaks in the document are used to try to guess\n       the number of footer lines.\n       @param docbody: (list) of strings - each string being a line in the\n        document\n       @param page_break_posns: (list) of integers - each integer is the\n        position of a page break in the document.\n       @return: (int) the number of lines that make up the footer of each page.\n    \"\"\"\n    num_breaks = len(page_break_posns)\n    num_footer_lines = 0\n    empty_line = 0\n    keep_checking = 1\n    p_wordSearch = re.compile(unicode(r'([A-Za-z0-9-]+)'), re.UNICODE)\n    if num_breaks > 2:\n        while keep_checking:\n            cur_break = 1\n            if page_break_posns[cur_break] - num_footer_lines - 1 < 0 or \\\n               page_break_posns[cur_break] - num_footer_lines - 1 > \\\n               len(docbody) - 1:\n                # Be sure that the docbody list boundary wasn't overstepped:\n                break\n            if docbody[(page_break_posns[cur_break] -\n                        num_footer_lines - 1)].isspace():\n                empty_line = 1\n            grps_headLineWords = \\\n                p_wordSearch.findall(docbody[(page_break_posns[cur_break] -\n                                              num_footer_lines - 1)])\n            cur_break = cur_break + 1\n            while (cur_break < num_breaks) and keep_checking:\n                grps_thisLineWords = \\\n                    p_wordSearch.findall(docbody[(page_break_posns[cur_break] -\n                                                  num_footer_lines - 1)])\n                if empty_line:\n                    if len(grps_thisLineWords) != 0:\n                        # this line should be empty, but isn't\n                        keep_checking = 0\n                else:\n                    if (len(grps_thisLineWords) == 0) or \\\n                            (len(grps_headLineWords) != len(grps_thisLineWords)):\n                        # Not same num 'words' as equivilent line\n                        # in 1st footer:\n                        keep_checking = 0\n                    else:\n                        keep_checking = \\\n                            check_boundary_lines_similar(grps_headLineWords,\n                                                         grps_thisLineWords)\n                # Update cur_break for nxt line to check\n                cur_break = cur_break + 1\n            if keep_checking:\n                # Line is a footer line: check next\n                num_footer_lines = num_footer_lines + 1\n            empty_line = 0\n    return num_footer_lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_headers_footers_pagebreaks(docbody,\n                                     page_break_posns,\n                                     num_head_lines,\n                                     num_foot_lines):\n    \"\"\"Remove page-break lines, header lines, and footer lines from the\n       document.\n       @param docbody: (list) of strings, whereby each string in the list is a\n        line in the document.\n       @param page_break_posns: (list) of integers, whereby each integer\n        represents the index in docbody at which a page-break is found.\n       @param num_head_lines: (int) the number of header lines each page in the\n        document has.\n       @param num_foot_lines: (int) the number of footer lines each page in the\n        document has.\n       @return: (list) of strings - the document body after the headers,\n        footers, and page-break lines have been stripped from the list.\n    \"\"\"\n    num_breaks = len(page_break_posns)\n    page_lens = []\n    for x in xrange(0, num_breaks):\n        if x < num_breaks - 1:\n            page_lens.append(page_break_posns[x + 1] - page_break_posns[x])\n    page_lens.sort()\n    if (len(page_lens) > 0) and \\\n            (num_head_lines + num_foot_lines + 1 < page_lens[0]):\n        # Safe to chop hdrs & ftrs\n        page_break_posns.reverse()\n        first = 1\n        for i in xrange(0, len(page_break_posns)):\n            # Unless this is the last page break, chop headers\n            if not first:\n                for dummy in xrange(1, num_head_lines + 1):\n                    docbody[page_break_posns[i] +\n                            1:page_break_posns[i] + 2] = []\n            else:\n                first = 0\n            # Chop page break itself\n            docbody[page_break_posns[i]:page_break_posns[i] + 1] = []\n            # Chop footers (unless this is the first page break)\n            if i != len(page_break_posns) - 1:\n                for dummy in xrange(1, num_foot_lines + 1):\n                    docbody[page_break_posns[i] -\n                            num_foot_lines:page_break_posns[i] -\n                            num_foot_lines + 1] = []\n    return docbody", "response": "Removes page - breaks from the document body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_boundary_lines_similar(l_1, l_2):\n    num_matches = 0\n    if (type(l_1) != list) or (type(l_2) != list) or (len(l_1) != len(l_2)):\n        # these 'boundaries' are not similar\n        return 0\n\n    num_elements = len(l_1)\n    for i in xrange(0, num_elements):\n        if l_1[i].isdigit() and l_2[i].isdigit():\n            # both lines are integers\n            num_matches += 1\n        else:\n            l1_str = l_1[i].lower()\n            l2_str = l_2[i].lower()\n            if (l1_str[0] == l2_str[0]) and \\\n                    (l1_str[len(l1_str) - 1] == l2_str[len(l2_str) - 1]):\n                num_matches = num_matches + 1\n    if (len(l_1) == 0) or (float(num_matches) / float(len(l_1)) < 0.9):\n        return 0\n    else:\n        return 1", "response": "Compare two lists to see if their elements are roughly the same."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading kbs from the specified files and store them in the specified dictionary.", "response": "def get_kbs(custom_kbs_files=None, cache={}):  # noqa\n    \"\"\"Load kbs (with caching).\n\n    This function stores the loaded kbs into the cache variable\n    For the caching to work, it needs to receive an empty dictionary\n    as \"cache\" paramater.\n    \"\"\"\n\n    cache_key = make_cache_key(custom_kbs_files)\n    if cache_key not in cache:\n        # Build paths from defaults and specified ones\n        kbs_files = CFG_REFEXTRACT_KBS.copy()\n        if custom_kbs_files:\n            for key, path in custom_kbs_files.items():\n                if path:\n                    kbs_files[key] = path\n        # Loads kbs from those paths\n        cache[cache_key] = load_kbs(kbs_files)\n    return cache[cache_key]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_kbs(kbs_files):\n\n    return {\n        'journals_re': build_journals_re_kb(kbs_files['journals-re']),\n        'journals': load_kb(kbs_files['journals'], build_journals_kb),\n        'report-numbers': build_reportnum_kb(kbs_files['report-numbers']),\n        'authors': build_authors_kb(kbs_files['authors']),\n        'books': build_books_kb(kbs_files['books']),\n        'publishers': load_kb(kbs_files['publishers'], build_publishers_kb),\n        'special_journals': build_special_journals_kb(kbs_files['special-journals']),\n        'collaborations': load_kb(kbs_files['collaborations'], build_collaborations_kb),\n    }", "response": "Load the kbs files into a dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_cache_key(custom_kbs_files=None):\n    if custom_kbs_files:\n        serialized_args = ('%s=%s' % v for v in iteritems(custom_kbs_files))\n        serialized_args = ';'.join(serialized_args)\n    else:\n        serialized_args = \"default\"\n    cache_key = md5(serialized_args).digest()\n    return cache_key", "response": "Create a unique key for kbs caches instances"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a grouped regexp pattern for recognising numeration patterns for institute preprint references.", "response": "def create_institute_numeration_group_regexp_pattern(patterns):\n    \"\"\"Using a list of regexp patterns for recognising numeration patterns\n       for institute preprint references, ordered by length - longest to\n       shortest - create a grouped 'OR' or of these patterns, ready to be\n       used in a bigger regexp.\n       @param patterns: (list) of strings. All of the numeration regexp\n        patterns for recognising an institute's preprint reference styles.\n       @return: (string) a grouped 'OR' regexp pattern of the numeration\n        patterns. E.g.:\n           (?P<num>[12]\\d{3} \\d\\d\\d|\\d\\d \\d\\d\\d|[A-Za-z] \\d\\d\\d)\n    \"\"\"\n    patterns_list = [institute_num_pattern_to_regex(p[1]) for p in patterns]\n    grouped_numeration_pattern = u\"(?P<numn>%s)\" % u'|'.join(patterns_list)\n    return grouped_numeration_pattern"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef institute_num_pattern_to_regex(pattern):\n    simple_replacements = [\n        ('9', r'\\d'),\n        ('w+', r'\\w+'),\n        ('a', r'[A-Za-z]'),\n        ('v', r'[Vv]'),\n        ('mm', r'(0[1-9]|1[0-2])'),\n        ('yyyy', r'[12]\\d{3}'),\n        ('yy', r'\\d\\d'),\n        ('s', r'\\s*'),\n        (r'/', r'\\/')]\n\n    # now loop through and carry out the simple replacements:\n    for repl in simple_replacements:\n        pattern = pattern.replace(repl[0], repl[1])\n\n    # now replace a couple of regexp-like paterns:\n    # quoted string with non-quoted version (\"hello\" with hello);\n    # Replace / [abcd ]/ with /( [abcd])?/ :\n    pattern = re_extract_quoted_text[0].sub(re_extract_quoted_text[1],\n                                            pattern)\n    pattern = re_extract_char_class[0].sub(re_extract_char_class[1],\n                                           pattern)\n\n    # the pattern has been transformed\n    return pattern", "response": "Given a numeration pattern from the institutes preprint report\n       numbers KB convert it into a regexp string for the corresponding pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a list of dicts that contains the number of times the given preprint report is found in the given file.", "response": "def build_reportnum_kb(fpath):\n    \"\"\"Given the path to a knowledge base file containing the details\n       of institutes and the patterns that their preprint report\n       numbering schemes take, create a dictionary of regexp search\n       patterns to recognise these preprint references in reference\n       lines, and a dictionary of replacements for non-standard preprint\n       categories in these references.\n\n       The knowledge base file should consist only of lines that take one\n       of the following 3 formats:\n\n         #####Institute Name####\n\n       (the name of the institute to which the preprint reference patterns\n        belong, e.g. '#####LANL#####', surrounded by 5 # on either side.)\n\n         <pattern>\n\n       (numeration patterns for an institute's preprints, surrounded by\n        < and >.)\n\n         seek-term       ---   replace-term\n       (i.e. a seek phrase on the left hand side, a replace phrase on the\n       right hand side, with the two phrases being separated by 3 hyphens.)\n       E.g.:\n         ASTRO PH        ---astro-ph\n\n       The left-hand side term is a non-standard version of the preprint\n       reference category; the right-hand side term is the standard version.\n\n       If the KB file cannot be read from, or an unexpected line is\n       encountered in the KB, an error message is output to standard error\n       and execution is halted with an error-code 0.\n\n       @param fpath: (string) the path to the knowledge base file.\n       @return: (tuple) containing 2 dictionaries. The first contains regexp\n        search patterns used to identify preprint references in a line. This\n        dictionary is keyed by a tuple containing the line number of the\n        pattern in the KB and the non-standard category string.\n        E.g.: (3, 'ASTRO PH').\n        The second dictionary contains the standardised category string,\n        and is keyed by the non-standard category string. E.g.: 'astro-ph'.\n    \"\"\"\n    def _add_institute_preprint_patterns(preprint_classifications,\n                                         preprint_numeration_ptns,\n                                         preprint_reference_search_regexp_patterns,\n                                         standardised_preprint_reference_categories,\n                                         kb_line_num):\n        \"\"\"For a list of preprint category strings and preprint numeration\n           patterns for a given institute, create the regexp patterns for\n           each of the preprint types.  Add the regexp patterns to the\n           dictionary of search patterns\n           (preprint_reference_search_regexp_patterns), keyed by the line\n           number of the institute in the KB, and the preprint category\n           search string.  Also add the standardised preprint category string\n           to another dictionary, keyed by the line number of its position\n           in the KB and its non-standardised version.\n           @param preprint_classifications: (list) of tuples whereby each tuple\n            contains a preprint category search string and the line number of\n            the name of institute to which it belongs in the KB.\n            E.g.: (45, 'ASTRO PH').\n           @param preprint_numeration_ptns: (list) of preprint reference\n            numeration search patterns (strings)\n           @param preprint_reference_search_regexp_patterns: (dictionary) of\n            regexp patterns used to search in document lines.\n           @param standardised_preprint_reference_categories: (dictionary)\n            containing the standardised strings for preprint reference\n            categories. (E.g. 'astro-ph'.)\n           @param kb_line_num: (integer) - the line number int the KB at\n            which a given institute name was found.\n           @return: None\n        \"\"\"\n        if preprint_classifications and preprint_numeration_ptns:\n            # the previous institute had both numeration styles and categories\n            # for preprint references.\n            # build regexps and add them for this institute:\n            # First, order the numeration styles by line-length, and build a\n            # grouped regexp for recognising numeration:\n            ordered_patterns = \\\n                order_reportnum_patterns_bylen(preprint_numeration_ptns)\n            # create a grouped regexp for numeration part of\n            # preprint reference:\n            numeration_regexp = \\\n                create_institute_numeration_group_regexp_pattern(\n                    ordered_patterns)\n\n            # for each \"classification\" part of preprint references, create a\n            # complete regex:\n            # will be in the style \"(categ)-(numatn1|numatn2|numatn3|...)\"\n            for classification in preprint_classifications:\n                search_pattern_str = ur'(?:^|[^a-zA-Z0-9\\/\\.\\-])([\\[\\(]?(?P<categ>' \\\n                                     + classification[0].strip() + u')' \\\n                                     + numeration_regexp + ur'[\\]\\)]?)'\n\n                re_search_pattern = re.compile(search_pattern_str,\n                                               re.UNICODE)\n                preprint_reference_search_regexp_patterns[(kb_line_num,\n                                                           classification[0])] =\\\n                    re_search_pattern\n                standardised_preprint_reference_categories[(kb_line_num,\n                                                            classification[0])] =\\\n                    classification[1]\n\n    preprint_reference_search_regexp_patterns = {}  # a dictionary of patterns\n    # used to recognise\n    # categories of preprints\n    # as used by various\n    # institutes\n    standardised_preprint_reference_categories = {}  # dictionary of\n    # standardised category\n    # strings for preprint cats\n    current_institute_preprint_classifications = []  # list of tuples containing\n    # preprint categories in\n    # their raw & standardised\n    # forms, as read from KB\n    current_institute_numerations = []               # list of preprint\n    # numeration patterns, as\n    # read from the KB\n\n    # pattern to recognise an institute name line in the KB\n    re_institute_name = re.compile(ur'^\\*{5}\\s*(.+)\\s*\\*{5}$', re.UNICODE)\n\n    # pattern to recognise an institute preprint categ line in the KB\n    re_preprint_classification = \\\n        re.compile(ur'^\\s*(\\w.*)\\s*---\\s*(\\w.*)\\s*$', re.UNICODE)\n\n    # pattern to recognise a preprint numeration-style line in KB\n    re_numeration_pattern = re.compile(ur'^\\<(.+)\\>$', re.UNICODE)\n\n    kb_line_num = 0    # when making the dictionary of patterns, which is\n    # keyed by the category search string, this counter\n    # will ensure that patterns in the dictionary are not\n    # overwritten if 2 institutes have the same category\n    # styles.\n    with file_resolving(fpath) as fh:\n        for rawline in fh:\n            if rawline.startswith('#'):\n                continue\n\n            kb_line_num += 1\n            m_institute_name = re_institute_name.search(rawline)\n            if m_institute_name:\n                # This KB line is the name of an institute\n                # append the last institute's pattern list to the list of\n                # institutes:\n                _add_institute_preprint_patterns(current_institute_preprint_classifications,\n                                                 current_institute_numerations,\n                                                 preprint_reference_search_regexp_patterns,\n                                                 standardised_preprint_reference_categories,\n                                                 kb_line_num)\n\n                # Now start a new dictionary to contain the search patterns\n                # for this institute:\n                current_institute_preprint_classifications = []\n                current_institute_numerations = []\n                # move on to the next line\n                continue\n\n            m_preprint_classification = \\\n                re_preprint_classification.search(rawline)\n            if m_preprint_classification:\n                # This KB line contains a preprint classification for\n                # the current institute\n                try:\n                    current_institute_preprint_classifications.append((m_preprint_classification.group(1),\n                                                                       m_preprint_classification.group(2)))\n                except (AttributeError, NameError):\n                    # didn't match this line correctly - skip it\n                    pass\n                # move on to the next line\n                continue\n\n            m_numeration_pattern = re_numeration_pattern.search(rawline)\n            if m_numeration_pattern:\n                # This KB line contains a preprint item numeration pattern\n                # for the current institute\n                try:\n                    current_institute_numerations.append(\n                        m_numeration_pattern.group(1))\n                except (AttributeError, NameError):\n                    # didn't match the numeration pattern correctly - skip it\n                    pass\n                continue\n\n        _add_institute_preprint_patterns(current_institute_preprint_classifications,\n                                         current_institute_numerations,\n                                         preprint_reference_search_regexp_patterns,\n                                         standardised_preprint_reference_categories,\n                                         kb_line_num)\n\n    # return the preprint reference patterns and the replacement strings\n    # for non-standard categ-strings:\n    return (preprint_reference_search_regexp_patterns,\n            standardised_preprint_reference_categories)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cmp_bystrlen_reverse(a, b):\n    if len(a) > len(b):\n        return -1\n    elif len(a) < len(b):\n        return 1\n    else:\n        return 0", "response": "Private function used by the sort function of a knowledge base by string - length - LONGEST - > SHORTEST."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the special journals database from file and return a set of all journals that are unique.", "response": "def build_special_journals_kb(fpath):\n    \"\"\"Load special journals database from file\n\n    Special journals are journals that have a volume which is not unique\n    among different years. To keep the volume unique we are adding the year\n    before the volume.\n    \"\"\"\n    journals = set()\n    with file_resolving(fpath) as fh:\n        for line in fh:\n            # Skip commented lines\n            if line.startswith('#'):\n                continue\n            # Skip empty line\n            if not line.strip():\n                continue\n            journals.add(line.strip())\n\n    return journals"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading journals regexps knowledge base", "response": "def build_journals_re_kb(fpath):\n    \"\"\"Load journals regexps knowledge base\n\n    @see build_journals_kb\n    \"\"\"\n    def make_tuple(match):\n        regexp = match.group('seek')\n        repl = match.group('repl')\n        return regexp, repl\n\n    kb = []\n\n    with file_resolving(fpath) as fh:\n        for rawline in fh:\n            if rawline.startswith('#'):\n                continue\n            # Extract the seek->replace terms from this KB line:\n            m_kb_line = re_kb_line.search(rawline)\n            kb.append(make_tuple(m_kb_line))\n\n    return kb"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a list of journals from a file in a Knowledge base file.", "response": "def build_journals_kb(knowledgebase):\n    \"\"\"Given the path to a knowledge base file, read in the contents\n       of that file into a dictionary of search->replace word phrases.\n       The search phrases are compiled into a regex pattern object.\n       The knowledge base file should consist only of lines that take\n       the following format:\n         seek-term       ---   replace-term\n       (i.e. a seek phrase on the left hand side, a replace phrase on\n       the right hand side, with the two phrases being separated by 3\n       hyphens.) E.g.:\n         ASTRONOMY AND ASTROPHYSICS              ---Astron. Astrophys.\n\n       The left-hand side term is a non-standard version of the title,\n       whereas the right-hand side term is the standard version.\n       If the KB file cannot be read from, or an unexpected line is\n       encountered in the KB, an error\n       message is output to standard error and execution is halted with\n       an error-code 0.\n\n       @param fpath: (string) the path to the knowledge base file.\n       @return: (tuple) containing a list and a dictionary. The list\n        contains compiled regex patterns used as search terms and will\n        be used to force searching order to match that of the knowledge\n        base.\n        The dictionary contains the search->replace terms.  The keys of\n        the dictionary are the compiled regex word phrases used for\n        searching in the reference lines; The values in the dictionary are\n        the replace terms for matches.\n    \"\"\"\n    # Initialise vars:\n    # dictionary of search and replace phrases from KB:\n    kb = {}\n    standardised_titles = {}\n    seek_phrases = []\n    # A dictionary of \"replacement terms\" (RHS) to be inserted into KB as\n    # \"seek terms\" later, if they were not already explicitly added\n    # by the KB:\n    repl_terms = {}\n    for seek_phrase, repl in knowledgebase:\n        # We match on a simplified line, thus dots are replaced\n        # with spaces\n        seek_phrase = seek_phrase.replace('.', ' ').upper()\n\n        # good KB line\n        # Add the 'replacement term' into the dictionary of\n        # replacement terms:\n        repl_terms[repl] = None\n\n        # add the phrase from the KB if the 'seek' phrase is longer\n        # compile the seek phrase into a pattern:\n        seek_ptn = re.compile(ur'(?<!\\w)(%s)\\W' % re.escape(seek_phrase),\n                              re.UNICODE)\n\n        kb[seek_phrase] = seek_ptn\n        standardised_titles[seek_phrase] = repl\n        seek_phrases.append(seek_phrase)\n\n    # Now, for every 'replacement term' found in the KB, if it is\n    # not already in the KB as a \"search term\", add it:\n    for repl_term in repl_terms.keys():\n        raw_repl_phrase = repl_term.upper()\n        raw_repl_phrase = re_punctuation.sub(u' ', raw_repl_phrase)\n        raw_repl_phrase = \\\n            re_group_captured_multiple_space.sub(u' ', raw_repl_phrase)\n        raw_repl_phrase = raw_repl_phrase.strip()\n        if raw_repl_phrase not in kb:\n            # The replace-phrase was not in the KB as a seek phrase\n            # It should be added.\n            pattern = ur'(?<!\\/)\\b(%s)[^A-Z0-9]' % re.escape(raw_repl_phrase)\n            seek_ptn = re.compile(pattern, re.U)\n            kb[raw_repl_phrase] = seek_ptn\n            standardised_titles[raw_repl_phrase] = repl_term\n            seek_phrases.append(raw_repl_phrase)\n\n    # Sort the titles by string length (long - short)\n    seek_phrases.sort(_cmp_bystrlen_reverse)\n\n    # return the raw knowledge base:\n    return kb, standardised_titles, seek_phrases"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_content_type(content_type: Optional[str]) -> Tuple[Optional[str], str]:\n    if not content_type:\n        return None, \"utf-8\"\n    else:\n        type_, parameters = cgi.parse_header(content_type)\n        encoding = parameters.get(\"charset\", \"utf-8\")\n        return type_, encoding", "response": "Tease out the content - type and character encoding."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding an HTTP body based on the content type.", "response": "def _decode_body(content_type: Optional[str], body: bytes,\n                 *, strict: bool = False) -> Any:\n    \"\"\"Decode an HTTP body based on the specified content type.\n\n    If 'strict' is true, then raise ValueError if the content type\n    is not recognized. Otherwise simply returned the body as a decoded\n    string.\n    \"\"\"\n    type_, encoding = _parse_content_type(content_type)\n    if not len(body) or not content_type:\n        return None\n    decoded_body = body.decode(encoding)\n    if type_ == \"application/json\":\n        return json.loads(decoded_body)\n    elif type_ == \"application/x-www-form-urlencoded\":\n        return json.loads(urllib.parse.parse_qs(decoded_body)[\"payload\"][0])\n    elif strict:\n        raise ValueError(f\"unrecognized content type: {type_!r}\")\n    return decoded_body"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_event(payload: bytes, *, signature: str, secret: str) -> None:\n    # https://developer.github.com/webhooks/securing/#validating-payloads-from-github\n    signature_prefix = \"sha1=\"\n    if not signature.startswith(signature_prefix):\n        raise ValidationFailure(\"signature does not start with \"\n                                           f\"{repr(signature_prefix)}\")\n    hmac_ = hmac.new(secret.encode(\"UTF-8\"), msg=payload, digestmod=\"sha1\")\n    calculated_sig = signature_prefix + hmac_.hexdigest()\n    if not hmac.compare_digest(signature, calculated_sig):\n        raise ValidationFailure(\"payload's signature does not align \"\n                                           \"with the secret\")", "response": "Validate the signature of a webhook event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accept_format(*, version: str = \"v3\", media: Optional[str] = None,\n                  json: bool = True) -> str:\n    \"\"\"Construct the specification of the format that a request should return.\n\n    The version argument defaults to v3 of the GitHub API and is applicable to\n    all requests. The media argument along with 'json' specifies what format\n    the request should return, e.g. requesting the rendered HTML of a comment.\n    Do note that not all of GitHub's API supports alternative formats.\n\n    The default arguments of this function will always return the latest stable\n    version of the GitHub API in the default format that this library is\n    designed to support.\n    \"\"\"\n    # https://developer.github.com/v3/media/\n    # https://developer.github.com/v3/#current-version\n    accept = f\"application/vnd.github.{version}\"\n    if media is not None:\n        accept += f\".{media}\"\n    if json:\n        accept += \"+json\"\n    return accept", "response": "Construct the Accept header for a request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a dict representing GitHub - specific headers.", "response": "def create_headers(requester: str, *, accept: str = accept_format(),\n                   oauth_token: Optional[str] = None,\n                   jwt: Optional[str] = None) -> Dict[str, str]:\n    \"\"\"Create a dict representing GitHub-specific header fields.\n\n    The user agent is set according to who the requester is. GitHub asks it be\n    either a username or project name.\n\n    The 'accept' argument corresponds to the 'accept' field and defaults to the\n    default result of accept_format(). You should only need to change this value\n    if you are using a different version of the API -- e.g. one that is under\n    development -- or if you are looking for a different format return type,\n    e.g. wanting the rendered HTML of a Markdown file.\n\n    The 'oauth_token' allows making an authenticated request using a personal access\n    token. This can be important if you need the expanded rate limit provided\n    by an authenticated request.\n\n    The 'jwt' allows authenticating as a GitHub App by passing in the\n    bearer token.\n\n    You can only supply only one of oauth_token or jwt, not both.\n\n    For consistency, all keys in the returned dict will be lowercased.\n    \"\"\"\n    # user-agent: https://developer.github.com/v3/#user-agent-required\n    # accept: https://developer.github.com/v3/#current-version\n    #         https://developer.github.com/v3/media/\n    # authorization: https://developer.github.com/v3/#authentication\n    # authenticating as a GitHub App: https://developer.github.com/apps/building-github-apps/authenticating-with-github-apps/#authenticating-as-a-github-app\n\n    if oauth_token is not None and jwt is not None:\n        raise ValueError(\"Cannot pass both oauth_token and jwt.\")\n    headers = {\"user-agent\": requester, \"accept\": accept}\n    if oauth_token is not None:\n        headers[\"authorization\"] = f\"token {oauth_token}\"\n    elif jwt is not None:\n        headers[\"authorization\"] = f\"bearer {jwt}\"\n    return headers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecipher an HTTP response for a GitHub API request.", "response": "def decipher_response(status_code: int, headers: Mapping[str, str],\n                      body: bytes) -> Tuple[Any, Optional[RateLimit], Optional[str]]:\n    \"\"\"Decipher an HTTP response for a GitHub API request.\n\n    The mapping providing the headers is expected to support lowercase keys.\n\n    The parameters of this function correspond to the three main parts\n    of an HTTP response: the status code, headers, and body. Assuming\n    no errors which lead to an exception being raised, a 3-item tuple\n    is returned. The first item is the decoded body (typically a JSON\n    object, but possibly None or a string depending on the content\n    type of the body). The second item is an instance of RateLimit\n    based on what the response specified.\n\n    The last item of the tuple is the URL where to request the next\n    part of results. If there are no more results then None is\n    returned. Do be aware that the URL can be a URI template and so\n    may need to be expanded.\n\n    If the status code is anything other than 200, 201, or 204, then\n    an HTTPException is raised.\n    \"\"\"\n    data = _decode_body(headers.get(\"content-type\"), body)\n    if status_code in {200, 201, 204}:\n        return data, RateLimit.from_http(headers), _next_link(headers.get(\"link\"))\n    else:\n        try:\n            message = data[\"message\"]\n        except (TypeError, KeyError):\n            message = None\n        exc_type: Type[HTTPException]\n        if status_code >= 500:\n            exc_type = GitHubBroken\n        elif status_code >= 400:\n            exc_type = BadRequest\n            if status_code == 403:\n                rate_limit = RateLimit.from_http(headers)\n                if rate_limit and not rate_limit.remaining:\n                    raise RateLimitExceeded(rate_limit, message)\n            elif status_code == 422:\n                errors = data.get(\"errors\", None)\n                if errors:\n                    fields = \", \".join(repr(e[\"field\"]) for e in errors)\n                    message = f\"{message} for {fields}\"\n                else:\n                    message = data[\"message\"]\n                raise InvalidField(errors, message)\n        elif status_code >= 300:\n            exc_type = RedirectionException\n        else:\n            exc_type = HTTPException\n        status_code_enum = http.HTTPStatus(status_code)\n        args: Union[Tuple[http.HTTPStatus, str], Tuple[http.HTTPStatus]]\n        if message:\n            args = status_code_enum, message\n        else:\n            args = status_code_enum,\n        raise exc_type(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_url(url: str, url_vars: Mapping[str, Any]) -> str:\n    url = urllib.parse.urljoin(DOMAIN, url)  # Works even if 'url' is fully-qualified.\n    expanded_url: str = uritemplate.expand(url, var_dict=url_vars)\n    return expanded_url", "response": "Construct a URL for the GitHub API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_http(cls, headers: Mapping[str, str], body: bytes,\n                  *, secret: Optional[str] = None) -> \"Event\":\n        \"\"\"Construct an event from HTTP headers and JSON body data.\n\n        The mapping providing the headers is expected to support lowercase keys.\n\n        Since this method assumes the body of the HTTP request is JSON, a check\n        is performed for a content-type of \"application/json\" (GitHub does\n        support other content-types). If the content-type does not match,\n        BadRequest is raised.\n\n        If the appropriate headers are provided for event validation, then it\n        will be performed unconditionally. Any failure in validation\n        (including not providing a secret) will lead to ValidationFailure being\n        raised.\n        \"\"\"\n        if \"x-hub-signature\" in headers:\n                if secret is None:\n                    raise ValidationFailure(\"secret not provided\")\n                validate_event(body, signature=headers[\"x-hub-signature\"],\n                               secret=secret)\n        elif secret is not None:\n            raise ValidationFailure(\"signature is missing\")\n\n        try:\n            data = _decode_body(headers[\"content-type\"], body, strict=True)\n        except (KeyError, ValueError) as exc:\n            raise BadRequest(http.HTTPStatus(415),\n                             \"expected a content-type of \"\n                             \"'application/json' or \"\n                             \"'application/x-www-form-urlencoded'\") from exc\n        return cls(data, event=headers[\"x-github-event\"],\n                   delivery_id=headers[\"x-github-delivery\"])", "response": "Construct an event from HTTP headers and JSON body data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngathers rate limit information from HTTP headers.", "response": "def from_http(cls, headers: Mapping[str, str]) -> Optional[\"RateLimit\"]:\n        \"\"\"Gather rate limit information from HTTP headers.\n\n        The mapping providing the headers is expected to support lowercase\n        keys.  Returns ``None`` if ratelimit info is not found in the headers.\n        \"\"\"\n        try:\n            limit = int(headers[\"x-ratelimit-limit\"])\n            remaining = int(headers[\"x-ratelimit-remaining\"])\n            reset_epoch = float(headers[\"x-ratelimit-reset\"])\n        except KeyError:\n            return None\n        else:\n            return cls(limit=limit, remaining=remaining, reset_epoch=reset_epoch)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, func: AsyncCallback, event_type: str, **data_detail: Any) -> None:\n        if len(data_detail) > 1:\n            msg = ()\n            raise TypeError(\"dispatching based on data details is only \"\n                            \"supported up to one level deep; \"\n                            f\"{len(data_detail)} levels specified\")\n        elif not data_detail:\n            callbacks = self._shallow_routes.setdefault(event_type, [])\n            callbacks.append(func)\n        else:\n            data_key, data_value = data_detail.popitem()\n            data_details = self._deep_routes.setdefault(event_type, {})\n            specific_detail = data_details.setdefault(data_key, {})\n            callbacks = specific_detail.setdefault(data_value, [])\n            callbacks.append(func)", "response": "Add a new route."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def dispatch(self, event: sansio.Event, *args: Any,\n                       **kwargs: Any) -> None:\n        \"\"\"Dispatch an event to all registered function(s).\"\"\"\n\n        found_callbacks = []\n        try:\n            found_callbacks.extend(self._shallow_routes[event.event])\n        except KeyError:\n            pass\n        try:\n            details = self._deep_routes[event.event]\n        except KeyError:\n            pass\n        else:\n            for data_key, data_values in details.items():\n                if data_key in event.data:\n                    event_value = event.data[data_key]\n                    if event_value in data_values:\n                        found_callbacks.extend(data_values[event_value])\n        for callback in found_callbacks:\n            await callback(event, *args, **kwargs)", "response": "Dispatch an event to all registered function s."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _request(self, method: str, url: str, headers: Mapping[str, str],\n                       body: bytes = b'') -> Tuple[int, Mapping[str, str], bytes]:\n        \"\"\"Make an HTTP request.\"\"\"", "response": "Make an HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _make_request(self, method: str, url: str, url_vars: Dict[str, str],\n                            data: Any, accept: str,\n                            jwt: Opt[str] = None,\n                            oauth_token: Opt[str] = None,\n                            ) -> Tuple[bytes, Opt[str]]:\n        \"\"\"Construct and make an HTTP request.\"\"\"\n        if oauth_token is not None and jwt is not None:\n            raise ValueError(\"Cannot pass both oauth_token and jwt.\")\n        filled_url = sansio.format_url(url, url_vars)\n        if jwt is not None:\n            request_headers = sansio.create_headers(\n                self.requester, accept=accept,\n                jwt=jwt)\n        elif oauth_token is not None:\n            request_headers = sansio.create_headers(\n                self.requester, accept=accept,\n                oauth_token=oauth_token)\n        else:\n            # fallback to using oauth_token\n            request_headers = sansio.create_headers(\n                self.requester, accept=accept,\n                oauth_token=self.oauth_token)\n        cached = cacheable = False\n        # Can't use None as a \"no body\" sentinel as it's a legitimate JSON type.\n        if data == b\"\":\n            body = b\"\"\n            request_headers[\"content-length\"] = \"0\"\n            if method == \"GET\" and self._cache is not None:\n                cacheable = True\n                try:\n                    etag, last_modified, data, more = self._cache[filled_url]\n                    cached = True\n                except KeyError:\n                    pass\n                else:\n                    if etag is not None:\n                        request_headers[\"if-none-match\"] = etag\n                    if last_modified is not None:\n                        request_headers[\"if-modified-since\"] = last_modified\n        else:\n            charset = \"utf-8\"\n            body = json.dumps(data).encode(charset)\n            request_headers['content-type'] = f\"application/json; charset={charset}\"\n            request_headers['content-length'] = str(len(body))\n        if self.rate_limit is not None:\n            self.rate_limit.remaining -= 1\n        response = await self._request(method, filled_url, request_headers, body)\n        if not (response[0] == 304 and cached):\n            data, self.rate_limit, more = sansio.decipher_response(*response)\n            has_cache_details = (\"etag\" in response[1]\n                                 or \"last-modified\" in response[1])\n            if self._cache is not None and cacheable and has_cache_details:\n                etag = response[1].get(\"etag\")\n                last_modified = response[1].get(\"last-modified\")\n                self._cache[filled_url] = etag, last_modified, data, more\n        return data, more", "response": "Construct and make an HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def getitem(self, url: str, url_vars: Dict[str, str] = {},\n                      *, accept: str = sansio.accept_format(),\n                      jwt: Opt[str] = None,\n                      oauth_token: Opt[str] = None\n                      ) -> Any:\n        \"\"\"Send a GET request for a single item to the specified endpoint.\"\"\"\n\n        data, _ = await self._make_request(\"GET\", url, url_vars, b\"\", accept,\n                                           jwt=jwt, oauth_token=oauth_token)\n        return data", "response": "Send a GET request for a single item to the specified endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an async iterable for all the items at a specified endpoint.", "response": "async def getiter(self, url: str, url_vars: Dict[str, str] = {},\n                      *, accept: str = sansio.accept_format(),\n                      jwt: Opt[str] = None,\n                      oauth_token: Opt[str] = None\n                      ) -> AsyncGenerator[Any, None]:\n        \"\"\"Return an async iterable for all the items at a specified endpoint.\"\"\"\n        data, more = await self._make_request(\"GET\", url, url_vars, b\"\", accept,\n                                              jwt=jwt, oauth_token=oauth_token)\n\n        if isinstance(data, dict) and \"items\" in data:\n            data = data[\"items\"]\n\n        for item in data:\n            yield item\n        if more:\n            # `yield from` is not supported in coroutines.\n            async for item in self.getiter(more, url_vars, accept=accept,\n                                           jwt=jwt, oauth_token=oauth_token):\n                yield item"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _request(self, method: str, url: str, headers: Mapping[str, str],\n                       body: bytes = b'') -> Tuple[int, Mapping[str, str], bytes]:\n        \"\"\"Make an HTTP request.\"\"\"\n        if method == \"GET\" and not body:\n            real_body = None\n        else:\n            real_body = body\n        request = httpclient.HTTPRequest(url, method, headers, real_body)\n        # Since Tornado has designed AsyncHTTPClient to be a singleton, there's\n        # no reason not to simply instantiate it every time.\n        client = httpclient.AsyncHTTPClient()\n        response = await client.fetch(request, raise_error=False)\n        return response.code, response.headers, response.body", "response": "Make an HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the hue value of a color in the color system.", "response": "def hue(p):\n    \"\"\"\n    Returns the saturation of a pixel.\n    Gray pixels have saturation 0.\n    :param p: A tuple of (R,G,B) values\n    :return: A saturation value between 0 and 360\n    \"\"\"\n    min_c = min(p)\n    max_c = max(p)\n    d = float(max_c - min_c)\n    if d == 0:\n        return 0\n\n    if max_c == p[0]:\n        h = (p[1] - p[2]) / d\n    elif max_c == p[1]:\n        h = 2 + (p[2] - p[0]) / d\n    else:\n        h = 4 + (p[0] - p[1]) / d\n    h *= 60\n    if h < 0:\n        h += 360\n    return h"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef saturation(p):\n    max_c = max(p)\n    min_c = min(p)\n    if max_c == 0:\n        return 0\n    return (max_c - min_c) / float(max_c)", "response": "Returns the saturation of a pixel in a sequence of chroma values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef weighted_random_choice(items):\n    l = list(items)\n    r = random.random() * sum([i[1] for i in l])\n    for x, p in l:\n        if p > r:\n            return x\n        r -= p\n    return None", "response": "Returns a weighted random choice from a list of items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying pixel sorting to an image. This is done by first creating a sort mask that describes the sorting intervals, and then calling apply_sort_mask to the image using the generated mask. :param discretize: Amount by which to \"discretize\" pixel values. This is done by dividing each pixel's value (after applying the sort key) by the given amount and then converting to an integer. This would mean that pixels are \"binned\" into discrete categories, and sorting would be different. Since sorting is stable, this means that pixels with low-level noise remain grouped together, and small details can be preserved in sorting. :param progressive_amount: If this is non-zero, then the sorting interval increases as one progresses row-by-row through the image. progressive_amount indicates the amount, in pixels, by which to increase the sorting interval after each row. :param path: The specific path used to iterate through the image, as a list of rows, where each row is a list of (x, y) coordinates. :param path_kwargs: Arguments that should be passed to the path iterator. :param image: A list of tuples (R,G,B) representing the pixels of the image :param size: The size of the image as a tuple (width, height) :param vertical: Whether or not the color sorting is applied vertically (the default is horizontal) :param max_interval: The largest interval of adjacent pixels to sort :param randomize: Whether to use random intervals of pixels :param key: The function to use for sorting, e.g. brightness or red amount. This function takes a pixel and returns a value to be sorted. :param reverse: Whether or not to reverse the direction of the sorting :param mirror: Mirrors each pixel interval after sorting. :param splice: Splices each pixel interval after sorting, at the given position (from 0.0 to 1.0). :param splice_random: Splices each pixel interval at a random position. :param edge_threshold: If greater than zero, stops sorting intervals at pixels whose \"edge detection\" value is greater than the given threshold. :param edge_data: Stores edge data for the image, if it is already cached. :param image_threshold: If not None, uses pixel's brightness to determine sort intervals. Pixels that are outside the range [threshold, MAX - threshold] are not sorted. So a value of 0 will sort all pixels (depending on the value of other arguments, of course), while a value of 1 will not sort any pixels. :param image_mask: The image to use as an initial sorting mask. Edge data and other sorting intervals will be applied on top of this. :return: The pixels of the resulting image as a list of (R,G,B) tuples", "response": "def sort_image(image, size, vertical=False, path=None, path_kwargs=None, max_interval=0, progressive_amount=0,\n               randomize=False,\n               edge_threshold=0, edge_data=None, image_threshold=None, image_mask=None, key=None, discretize=0,\n               reverse=False,\n               mirror=False, splice=0, splice_random=False):\n    \"\"\"\n    Applies pixel sorting to an image. This is done by first creating a sort mask that describes the sorting intervals,\n    and then calling apply_sort_mask to the image using the generated mask.\n    :param discretize: Amount by which to \"discretize\" pixel values. This is done by dividing each pixel's value\n    (after applying the sort key) by the given amount and then converting to an integer.\n    This would mean that pixels are \"binned\" into discrete categories, and sorting would be different.\n    Since sorting is stable, this means that pixels with low-level noise remain grouped together,\n    and small details can be preserved in sorting.\n    :param progressive_amount: If this is non-zero,\n    then the sorting interval increases as one progresses row-by-row through the image.\n    progressive_amount indicates the amount, in pixels, by which to increase the sorting interval after each row.\n    :param path: The specific path used to iterate through the image, as a list of rows,\n    where each row is a list of (x, y) coordinates.\n    :param path_kwargs: Arguments that should be passed to the path iterator.\n    :param image: A list of tuples (R,G,B) representing the pixels of the image\n    :param size: The size of the image as a tuple (width, height)\n    :param vertical: Whether or not the color sorting is applied vertically (the default is horizontal)\n    :param max_interval: The largest interval of adjacent pixels to sort\n    :param randomize: Whether to use random intervals of pixels\n    :param key: The function to use for sorting, e.g. brightness or red amount.\n                This function takes a pixel and returns a value to be sorted.\n    :param reverse: Whether or not to reverse the direction of the sorting\n    :param mirror: Mirrors each pixel interval after sorting.\n    :param splice: Splices each pixel interval after sorting, at the given position (from 0.0 to 1.0).\n    :param splice_random: Splices each pixel interval at a random position.\n    :param edge_threshold: If greater than zero, stops sorting intervals at pixels whose \"edge detection\" value\n    is greater than the given threshold.\n    :param edge_data: Stores edge data for the image, if it is already cached.\n    :param image_threshold: If not None, uses pixel's brightness to determine sort intervals.\n    Pixels that are outside the range [threshold, MAX - threshold] are not sorted. So a value of 0 will sort all pixels\n    (depending on the value of other arguments, of course), while a value of 1 will not sort any pixels.\n    :param image_mask: The image to use as an initial sorting mask. Edge data and other sorting intervals\n    will be applied on top of this.\n    :return: The pixels of the resulting image as a list of (R,G,B) tuples\n    \"\"\"\n    width, height = size\n    out_pixels = list(image)\n\n    # get edge data if necessary\n    if edge_threshold > 0 and edge_data is None:\n        edge_data = edge_detect(image, size)\n\n    if image_threshold is not None:\n        image_threshold = clamp(image_threshold, 0.0, 1.0)\n\n    if discretize > 0 and key is not None:\n        def sort_key(p):\n            return int(key(p) / discretize)\n    else:\n        sort_key = key\n\n    # if path not given, use a horizontal or vertical path\n    if path is None:\n        if vertical:\n            path_iterator = vertical_path(size)\n        else:\n            path_iterator = horizontal_path(size)\n    else:\n        # path_iterator = path_generator(size, **(path_kwargs if path_kwargs is not None else {}))\n        path_iterator = path(size, **path_kwargs)\n\n    # check if interval should increase progressively through image\n    if progressive_amount > 0:\n        current_max_interval = max_interval * progressive_amount\n    else:\n        current_max_interval = max_interval\n\n    # traverse image and compute random sort intervals\n    pixels_sorted = 0\n    for row_iter in path_iterator:\n        path_finished = False\n        # traverse path until it is finished\n        while not path_finished:\n            if progressive_amount > 0:\n                current_max_interval += max_interval * progressive_amount\n\n            if randomize and current_max_interval > 0:\n                interval = randint(1, int(current_max_interval) + 1)\n            else:\n                interval = current_max_interval\n\n            # get pixel coordinates of path\n            i = 0\n\n            px_indices = []\n            # if interval is 0, just sort whole line at once\n            while i < interval or interval == 0:\n                try:\n                    coords = next(row_iter)\n                except StopIteration:\n                    path_finished = True\n                    break\n\n                i += 1\n                pixels_sorted += 1\n                if pixels_sorted % 200000 == 0:\n                    logger.info(\"Created sort mask for %d / %d pixels (%2.2f%%)...\" %\n                                (pixels_sorted, width * height, 100 * pixels_sorted / float(width * height)))\n\n                idx = coords_to_index(coords, width)\n\n                # use various image data to set up sort intervals, before computing random intervals\n                if image_mask is not None and luma(image_mask[idx]) > 128:\n                    break\n                # edge detection\n                if edge_data is not None and edge_data[idx] > edge_threshold > 0:\n                    break\n                # use image color to determine ends of sorting intervals\n                if image_threshold is not None:\n                    brightness = luma(image[idx])\n                    t = image_threshold * 255 / 2\n                    if brightness < t or brightness > 255 - t:\n                        break\n\n                # add current pixel to interval\n                px_indices.append(idx)\n\n            # sort pixels, apply to output image\n            if len(px_indices) > 0:\n                sorted_pixels = sorted([out_pixels[i] for i in px_indices], key=sort_key, reverse=reverse)\n                sorted_pixels = sort_filter(sorted_pixels, mirror=mirror, splice=splice, splice_random=splice_random)\n                for i in range(len(px_indices)):\n                    index = px_indices[i]\n                    pixel = sorted_pixels[i]\n                    out_pixels[index] = pixel\n\n    return out_pixels"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sort_filter(l, mirror=False, splice=0, splice_random=False):\n    if len(l) == 0:\n        return l\n    nl = list(l)\n\n    if mirror:\n        get_index = put_index = 0\n        while get_index < len(l):\n            nl[put_index] = l[get_index]\n            get_index += 1\n            if put_index >= 0:\n                put_index += 1\n            put_index *= -1\n\n    if splice_random:\n        splice_start = randrange(len(l))\n    elif splice > 0:\n        splice_start = int((len(l) - 1) * splice)\n    else:\n        splice_start = None\n\n    if splice_start is not None:\n        nl = nl[splice_start:] + nl[:splice_start]\n\n    return nl", "response": "Sort a list of pixels in a random interval."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of tile pixels and size from the given image.", "response": "def get_tile_from_image(image, size, top_left_corner, tile_size):\n    \"\"\"\n    Returns a rectangular region of the given image as a separate image\n    If the tile goes off the edge of the image, it will be truncated. The new size is also returned.\n    :param image: The given image, as a list of (R,G,B) tuples\n    :param size: The size of the image, as (width, height)\n    :param top_left_corner: The top left corner of the tile, relative to the image, as a tuple (x,y)\n    :param tile_size: The size of the tile, as a tuple (width, height)\n    :return: A tuple (tile, size) where the tile is a list of (R,G,B) tuples and the size is (width, height)\n    \"\"\"\n    tile_pixels = []\n    # crop tile if necessary\n    tile_x = min(size[0] - top_left_corner[0], tile_size[0])\n    tile_y = min(size[1] - top_left_corner[1], tile_size[1])\n    tile_size = tile_x, tile_y\n    for y in range(tile_size[1]):\n        for x in range(tile_size[0]):\n            coords = (x + top_left_corner[0], y + top_left_corner[1])\n            tile_pixels.append(image[coords_to_index(coords, size[0])])\n    return tile_pixels, tile_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies a tile onto an image", "response": "def apply_tile_to_image(image, size, tile, tile_size, tile_corner):\n    \"\"\"\n    Copies a tile with a given offset onto an image\n    :param image: The image the file is to be copied onto (as a list of (R,G,B) tuples)\n    :param size: The size of the image as a tuple (width, height)\n    :param tile: The tile to be copied over (as a list of (R,G,B) tuples)\n    :param tile_size: The size of the tile as a tuple (width, height)\n    :param tile_corner: The top left corner of the tile, in terms of the coordinates of the image, as a tuple (x,y)\n    \"\"\"\n    for y in range(tile_size[1]):\n        for x in range(tile_size[0]):\n            img_coords = (x + tile_corner[0], y + tile_corner[1])\n            image[coords_to_index(img_coords, size[0])] = tile[coords_to_index((x, y), tile_size[0])]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sort_image_tiles(image, size, sorting_args, tile_size, tile_density=1.0, randomize_tiles=False):\n    out_image = list(image)\n    width, height = size\n    tile_width, tile_height = tile_size\n\n    i = 0\n    total_tiles = ceil(height / float(tile_height)) * ceil(width / float(tile_width))\n    tiles_completed = 0\n    pixels_per_tiles = tile_width * tile_height\n    for y in range(0, height, tile_height):\n        for x in range(0, width, tile_width):\n            # logging\n            tiles_completed += 1\n            if tiles_completed % (200000 / pixels_per_tiles) == 0:\n                logger.info(\"Completed %d / %d tiles... (%2.2f%%)\" %\n                            (tiles_completed, total_tiles, 100.0 * tiles_completed / total_tiles))\n\n            i += 1\n            if randomize_tiles:\n                # if using randomized tiles, skip a tile with probability 1 - density\n                r = random()\n                if r >= tile_density:\n                    continue\n            else:\n                # if tiles are not randomized, add a tile once every 1/density times\n                if tile_density == 0 or i < 1.0 / tile_density:\n                    continue\n                else:\n                    i -= 1.0 / tile_density\n            # extract a tile, sort it, and copy it back to the image\n            tile, current_tile_size = get_tile_from_image(image, size, (x, y), tile_size)\n            sorted_tile = sort_image(tile, current_tile_size, **sorting_args)\n            apply_tile_to_image(out_image, size, sorted_tile, current_tile_size, (x, y))\n\n    return out_image", "response": "Sorts an image by taking various tiles and sorting them individually."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a generator that yields a set of rows through an image.", "response": "def horizontal_path(size):\n    \"\"\"\n    Creates a generator for progressing horizontally through an image.\n    :param size: A tuple (width, height) of the image size\n    :return: A generator that yields a set of rows through the image.\n    Each row is a generator that yields pixel coordinates.\n    \"\"\"\n    width, height = size\n    return (((x, y) for x in range(width)) for y in range(height))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator that yields a set of columns through an image.", "response": "def vertical_path(size):\n    \"\"\"\n    Creates a generator for progressing vertically through an image.\n    :param size: A tuple (width, height) of the image size\n    :return: A generator that yields a set of columns through the image.\n    Each column is a generator that yields pixel coordinates.\n    \"\"\"\n    width, height = size\n    return (((x, y) for y in range(height)) for x in range(width))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing a line from the given start point to the given size and the given slope.", "response": "def draw_line(start, size, slope):\n    \"\"\"\n    Draws a line from the starting point with the given slope, until the line goes out of the given bounds.\n    :param start: The starting point (x, y) for the line\n    :param size: The size of the image as (width, height). This determined the bounds for the image.\n    :param slope: The slope of the line\n    :return: Yields a set of points as coordinate (0,0)\n    \"\"\"\n    error = -1.0\n    if abs(slope) > 1:\n        slope = 1/slope\n        switch_xy = True\n    else:\n        switch_xy = False\n    slope_sgn = sign(slope)\n    # represent change from inital x and y. If slope > 1, these are switched, since the algorithm only works when\n    # the slope is less than 1.\n    dx = dy = 0\n    current_point = start\n    x0, y0 = start\n    while in_bounds((0, 0), size, current_point):\n        yield current_point\n        dx += 1\n        error += abs(slope)\n        if error > 0:\n            dy += slope_sgn\n            error -= 1\n        current_point = (x0 + dx, y0 + dy) if not switch_xy else (x0 + abs(dy), y0 + slope_sgn * dx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef angled_path(size, angle=0):\n    # y coordinates are inverted in images, so this allows for users to input more intuitive angle values.\n    angle = -angle\n    if angle % 180 == 0:\n        yield from horizontal_path(size)\n        return\n    if angle % 180 == 90:\n        yield from vertical_path(size)\n        return\n    width, height = size\n    slope = tan(radians(angle))\n    start_y = 0 if slope > 0 else height - 1\n    for x in range(width-1, 0, -1):\n        yield draw_line((x, start_y), size, slope)\n    for y in range(height):\n        yield draw_line((0, y), size, slope)", "response": "Generates a set of lines across an image with the given angle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a set of diagonal paths moving from the top left to the bottom right of the image.", "response": "def diagonal_path(size):\n    \"\"\"\n    Creates a set of diagonal paths moving from the top left to the bottom right of the image.\n    Successive rows start at the bottom-left corner and move up until the top-right corner.\n    :param size: The dimensions of the image (width, height)\n    :return: A generator that yields a set of paths, each path is a set of (x,y) pixel coordinates.\n    \"\"\"\n    width, height = size\n    return (((x, x + offset) for x in range(max(0, -offset), min(width, height - offset))) for offset in\n            range(height - 1, -width, -1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a set of diagonal paths moving from the top left to the bottom right of the image.", "response": "def diagonal_single_path(size):\n    \"\"\"\n    Creates a set of diagonal paths moving from the top left to the bottom right of the image.\n    Successive rows start at the bottom-left corner and move up until the top-right corner.\n    :param size: The dimensions of the image (width, height)\n    :return: A generator that yields a set of paths, each path is a set of (x,y) pixel coordinates.\n    \"\"\"\n    width, height = size\n\n    def diagonal_path_iter():\n        for offset in range(height - 1, -width, -1):\n            for x in range(max(0, -offset), min(width, height - offset)):\n                yield (x, x + offset)\n\n    yield diagonal_path_iter()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef concentric_rectangle_path(size):\n\n    def conc_rect_iter():\n        for x in range(min_x, max_x):\n            yield (x, min_y)\n        # if rectangle only has height of 1, prevent path from doubling back along x\n        if min_y + 1 == max_y:\n            return\n        for y in range(min_y + 1, max_y):\n            yield (max_x - 1, y)\n        for x in range(max_x - 2, min_x - 1, -1):\n            yield (x, max_y - 1)\n        for y in range(max_y - 2, min_y, -1):\n            yield (min_x, y)\n\n    width, height = size\n    min_x, max_x = 0, width\n    min_y, max_y = 0, height\n\n    while min_x < max_x and min_y < max_y:\n        yield conc_rect_iter()\n\n        min_x += 1\n        min_y += 1\n        max_x -= 1\n        max_y -= 1", "response": "Creates a generator that yields the concentric rectangles of the image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_walk_path(size, distribution=None, start_points=None):\n\n    # TODO allow non-adjacent neighbors also?\n\n    def random_walk_iter(start_pt):\n        x, y = start_pt\n        while True:\n            dx, dy = weighted_random_choice(iter(distribution.items()))\n            x += dx\n            y += dy\n            if x < 0 or x >= width or y < 0 or y >= height:\n                return\n            yield (x, y)\n\n    width, height = size\n    neighbors = [(dx, dy) for dx in [-1, 0, 1] for dy in [-1, 0, 1] if dy != 0 or dx != 0]\n    if distribution is None:\n        distribution = {n: 0.125 for n in neighbors}\n    else:\n        for n in neighbors:\n            if n not in distribution:\n                distribution[n] = 0\n        neighbor_sum = sum(distribution[n] for n in neighbors)\n        if neighbor_sum <= 0:\n            raise ValueError(\"Distribution must be positive, nonzero for adjacent neighbors\")\n        else:\n            distribution = {n: p / float(neighbor_sum) for n, p in distribution.items()}\n    if start_points is None:\n        start_points = [(int(random() * width), int(random() * height)) for _ in range(10)]\n\n        # # by default, just start at each pixel on the left edge of the image\n        # start_points = [(0, y) for y in xrange(height)]\n\n    for x0, y0 in start_points:\n        yield random_walk_iter((x0, y0))", "response": "Generates a random walk of the specified size with optional distribution and start points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef horizontal_random_walk(size):\n    _, height = size\n    distribution = {(1, dy): 1 / 3.0 for dy in [-1, 0, 1]}\n    start_points = [(0, y) for y in range(height)]\n    return random_walk_path(size, distribution, start_points)", "response": "Generates a horizontal random walk of the given size."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vertical_random_walk(size):\n    width, _ = size\n    distribution = {(dx, 1): 1 / 3.0 for dx in [-1, 0, 1]}\n    start_points = [(x, 0) for x in range(width)]\n    return random_walk_path(size, distribution, start_points)", "response": "Generates a vertical random walk of the given size."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bresenham_circle_octant(radius):\n    x, y = radius, 0\n    r2 = radius * radius\n    coords = []\n    while x >= y:\n        coords.append((x, y))\n        y += 1\n        if abs((x - 1) * (x - 1) + y * y - r2) < abs(x * x + y * y - r2):\n            x -= 1\n    # add a point on the line x = y at the end if it's not already there.\n    if coords[-1][0] != coords[-1][1]:\n        coords.append((coords[-1][0], coords[-1][0]))\n    return coords", "response": "Uses Bresenham s algorithm to draw a single octant of a circle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef concentric_circle(center, radius, size=None):\n    c_out = bresenham_circle_octant(radius + 1)\n    c_in = bresenham_circle_octant(radius)\n    coords = []\n\n    # note that in this loop, y also serves as the array index,\n    # since it starts at 0 and increments each element.\n    for x, y in c_in:\n        for x1 in range(x, c_out[y][0]):\n            coords.append((x1, y))\n    # copy octant 8 times to get other pixels\n    # TODO might recount pixels where x == y\n    next_octant = [(y, x) for x, y in reversed(coords)]\n    coords.extend(next_octant)\n    next_quadrant = [(-y, x) for x, y in coords]\n    coords.extend(next_quadrant)\n    next_half = [(-x, -y) for x, y in coords]\n    coords.extend(next_half)\n\n    for x, y in coords:\n        c = x + center[0], y + center[1]\n        if size is not None:\n            if not in_bounds((0, 0), size, c):\n                continue\n        yield c", "response": "Returns a generator that yields the concentric circle of the given center and radius."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a path that fills a concentric circle with the given radius and center.", "response": "def fill_concentric_circles(size, center, radius):\n    \"\"\"\n    Returns a path that fills a concentric circle with the given radius and center.\n    :param radius:\n    :param center:\n    :param size: The size of the image, used to skip points that are out of bounds.\n    :return: Yields iterators, where each iterator yields (x,y) coordinates of points about the circle.\n    The path moves outwards from the center of the circle.\n    If `size` is specified, points that are out of bounds are skipped.\n    \"\"\"\n    for r in range(radius):\n        yield concentric_circle(center, r, size=size)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef concentric_circles_path(size):\n    width, height = size\n    x0, y0 = width // 2, height // 2\n    max_radius = int(sqrt(2) * max(height, width))\n    yield from fill_concentric_circles(radius=max_radius, center=(x0, y0), size=size)", "response": "Generates a set of paths that are concentric circles moving outwards about the center of the image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfilling a set of concentric circles with a given radius.", "response": "def fill_with_circles_path(size, radius=100):\n    \"\"\"\n    Covers an image with a set of overlapping circles of the given radius.\n    :param size: The size of the image\n    :param radius: The radius of the circles in question\n    :return: Yields a set of filled circles that cover the whole image.\n    Each circle is made up of individual concentric circles.\n    \"\"\"\n    width, height = size\n    radius = int(radius)\n    dx = dy = int(2 * radius / sqrt(2))\n    for x in range(dx // 2, width + dx, dx):\n        for y in range(dy // 2, height + dy, dy):\n            yield from fill_concentric_circles(center=(x, y), radius=radius, size=size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert an integer to two bytes.", "response": "def intToBin(i):\n    \"\"\" Integer to two bytes \"\"\"\n    # divide in two parts (bytes)\n    i1 = i % 256\n    i2 = int(i / 256)\n    # make string (little endian)\n    return i.to_bytes(2, byteorder='little')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the frames from an animated gif.", "response": "def get_gif_frames(img):\n    \"\"\"\n    Extracts the frames from an animated gif.\n    :param img: A PIL Image object\n    :return: An array of PIL image objects, each corresponding to a frame in the animation.\n    \"\"\"\n    gif_frames = []\n    n = 0\n    while img:\n        if img.mode != \"RGB\":\n            image = img.convert(mode=\"RGB\")\n        else:\n            image = img\n        gif_frames.append(image)\n        n += 1\n        try:\n            img.seek(n)\n        except EOFError:\n            break\n    return gif_frames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget animation header. To replace PILs getheaderAnim", "response": "def getheaderAnim(self, im):\n        \"\"\" getheaderAnim(im)\n\n        Get animation header. To replace PILs getheader()[0]\n\n        \"\"\"\n        bb = b'GIF89a'\n        bb += intToBin(im.size[0])\n        bb += intToBin(im.size[1])\n        bb += b'\\x87\\x00\\x00'\n        return bb"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the byte string that can be used to generate a new image.", "response": "def getImageDescriptor(self, im, xy=None):\n        \"\"\" getImageDescriptor(im, xy=None)\n\n        Used for the local color table properties per image.\n        Otherwise global color table applies to all frames irrespective of\n        whether additional colors comes in play that require a redefined\n        palette. Still a maximum of 256 color per frame, obviously.\n\n        Written by Ant1 on 2010-08-22\n        Modified by Alex Robinson in Janurary 2011 to implement subrectangles.\n\n        \"\"\"\n\n        # Default use full image and place at upper left\n        if xy is None:\n            xy = (0, 0)\n\n        # Image separator,\n        bb = b'\\x2C'\n\n        # Image position and size\n        bb += intToBin(xy[0])  # Left position\n        bb += intToBin(xy[1])  # Top position\n        bb += intToBin(im.size[0])  # image width\n        bb += intToBin(im.size[1])  # image height\n\n        # packed field: local color table flag1, interlace0, sorted table0,\n        # reserved00, lct size111=7=2^(7+1)=256.\n        bb += b'\\x87'\n\n        # LZW minimum size code now comes later, begining of [image data] blocks\n        return bb"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the Graphics Control Extension.", "response": "def getGraphicsControlExt(self, duration=0.1, dispose=2, transparent_flag=0, transparency_index=0):\n        \"\"\" getGraphicsControlExt(duration=0.1, dispose=2)\n\n        Graphics Control Extension. A sort of header at the start of\n        each image. Specifies duration and transparancy.\n\n        Dispose\n        -------\n          * 0 - No disposal specified.\n          * 1 - Do not dispose. The graphic is to be left in place.\n          * 2 -\tRestore to background color. The area used by the graphic\n            must be restored to the background color.\n          * 3 -\tRestore to previous. The decoder is required to restore the\n            area overwritten by the graphic with what was there prior to\n            rendering the graphic.\n          * 4-7 -To be defined.\n\n        \"\"\"\n\n        bb = b'\\x21\\xF9\\x04'\n        bb += bytes([((dispose & 3) << 2) | (transparent_flag & 1)])  # low bit 1 == transparency,\n        # 2nd bit 1 == user input , next 3 bits, the low two of which are used,\n        # are dispose.\n        bb += intToBin(int(duration * 100))  # in 100th of seconds\n        bb += bytes([transparency_index])\n        bb += b'\\x00'  # end\n        return bb"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove neuron i towards biased ( b g r", "response": "def altersingle(self, alpha, i, b, g, r):\n        \"\"\"Move neuron i towards biased (b,g,r) by factor alpha\"\"\"\n        n = self.network[i]  # Alter hit neuron\n        n[0] -= (alpha * (n[0] - b))\n        n[1] -= (alpha * (n[1] - g))\n        n[2] -= (alpha * (n[2] - r))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quantize(self, image):\n        if get_cKDTree():\n            return self.quantize_with_scipy(image)\n        else:\n            print('Scipy not available, falling back to slower version.')\n            return self.quantize_without_scipy(image)", "response": "Use a kdtree to quickly find the closest palette colors for the pixels"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for BGR values 0.. 255 and return colour index", "response": "def inxsearch(self, r, g, b):\n        \"\"\"Search for BGR values 0..255 and return colour index\"\"\"\n        dists = (self.colormap[:, :3] - np.array([r, g, b]))\n        a = np.argmin((dists * dists).sum(1))\n        return a"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a Sobel filter to the given image. :param image: An image as a list of (R,G,B) values :param size: The size of the image as a tuple (width, height) :return: An array of the Sobel gradient value of each image pixel This value roughly corresponds to how much of an \"edge\" a pixel is.", "response": "def edge_detect(image, size):\n    \"\"\"\n    Applies a Sobel filter to the given image.\n    :param image: An image as a list of (R,G,B) values\n    :param size: The size of the image as a tuple (width, height)\n    :return: An array of the Sobel gradient value of each image pixel\n    This value roughly corresponds to how much of an \"edge\" a pixel is.\n    \"\"\"\n    # TODO get edge data for boundaries\n    width, height = size\n    edge_data = [0] * len(image)\n    gray_scale_img = list(map(luma, image))\n    for y in range(1, height - 1):\n        for x in range(1, width - 1):\n            idx = coords_to_index((x, y), width)\n\n            a, b, c = gray_scale_img[idx - 1 - width: idx + 2 - width]\n            d, e, f = gray_scale_img[idx - 1: idx + 2]\n            g, h, i = gray_scale_img[idx - 1 + width: idx + 2 + width]\n\n            g_x = -a - 2 * d - d + c + 2 * f + i\n            g_y = -a - 2 * b - c + g + 2 * h + i\n\n            g = sqrt(g_x * g_x + g_y * g_y)\n            edge_data[idx] = g\n\n            if idx % 200000 == 0:\n                logger.info(\"Edge detection done for %d / %d pixels... (%2.2f%%)\" %\n                            (idx, width * height, 100 * idx / float(width * height)))\n    return edge_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef highlight_threshold(image, img_data, threshold, color=(255, 0, 0)):\n    out_pixels = list(image)\n    for i in range(len(image)):\n        p, e = image[i], img_data[i]\n        if e > threshold:\n            out_pixels[i] = color\n    return out_pixels", "response": "Highlights pixels with high - value pixels above the given threshold."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a filename from an endpoint with timestamp.", "response": "def gen_filename(endpoint):\n    \"\"\"Generate a filename from endpoint with timestamp.\n\n    return: str\n        hostname_port_YearMonthDay_HourMinSecFrac.h5\n    \"\"\"\n    now = datetime.now().strftime('%Y%m%d_%H%M%S%f')[:-4]\n    base = endpoint.split('://', 1)[1]\n    if base.startswith('localhost:'):\n        base = gethostname().split('.')[0] + base[9:]\n    base = base.replace(':', '_').replace('/', '_')\n    return '{}_{}.h5'.format(base, now)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_to_hdf5(dic, endpoint):\n    filename = gen_filename(endpoint)\n    with h5py.File(filename, 'w') as handler:\n        walk_dict_to_hdf5(dic, handler)\n    print('dumped to', filename)", "response": "Dump a dict to an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the content of an hdf5 file to a dict", "response": "def hdf5_to_dict(filepath, group='/'):\n    \"\"\"load the content of an hdf5 file to a dict.\n\n    # TODO: how to split domain_type_dev : parameter : value ?\n    \"\"\"\n    if not h5py.is_hdf5(filepath):\n        raise RuntimeError(filepath, 'is not a valid HDF5 file.')\n\n    with h5py.File(filepath, 'r') as handler:\n        dic = walk_hdf5_to_dict(handler[group])\n    return dic"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_one_train(client, verbosity=0):\n    ts_before = time()\n    data, meta = client.next()\n    ts_after = time()\n\n    if not data:\n        print(\"Empty data\")\n        return\n\n    train_id = list(meta.values())[0].get('timestamp.tid', 0)\n    print(\"Train ID:\", train_id, \"--------------------------\")\n    delta = ts_after - ts_before\n    print('Data from {} sources, REQ-REP took {:.2f} ms'\n          .format(len(data), delta))\n    print()\n\n    for i, (source, src_data) in enumerate(sorted(data.items()), start=1):\n        src_metadata = meta.get(source, {})\n        tid = src_metadata.get('timestamp.tid', 0)\n        print(\"Source {}: {!r} @ {}\".format(i, source, tid))\n        try:\n            ts = src_metadata['timestamp']\n        except KeyError:\n            print(\"No timestamp\")\n        else:\n            dt = strftime('%Y-%m-%d %H:%M:%S', localtime(ts))\n\n            delay = (ts_after - ts) * 1000\n            print('timestamp: {} ({}) | delay: {:.2f} ms'\n                  .format(dt, ts, delay))\n\n        if verbosity < 1:\n            print(\"- data:\", sorted(src_data))\n            print(\"- metadata:\", sorted(src_metadata))\n        else:\n            print('data:')\n            pretty_print(src_data, verbosity=verbosity - 1)\n            if src_metadata:\n                print('metadata:')\n                pretty_print(src_metadata)\n        print()\n\n    return data, meta", "response": "Retrieve data for one train and print it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pretty_print(d, ind='', verbosity=0):\n    assert isinstance(d, dict)\n    for k, v in sorted(d.items()):\n        str_base = '{} - [{}] {}'.format(ind, type(v).__name__, k)\n\n        if isinstance(v, dict):\n            print(str_base.replace('-', '+', 1))\n            pretty_print(v, ind=ind+'  ', verbosity=verbosity)\n            continue\n        elif isinstance(v, np.ndarray):\n            node = '{}, {}, {}'.format(str_base, v.dtype, v.shape)\n            if verbosity >= 2:\n                node += '\\n{}'.format(v)\n        elif isinstance(v, Sequence):\n            if v and isinstance(v, (list, tuple)):\n                itemtype = ' of ' + type(v[0]).__name__\n                pos = str_base.find(']')\n                str_base = str_base[:pos] + itemtype + str_base[pos:]\n            node = '{}, {}'.format(str_base, v)\n            if verbosity < 1 and len(node) > 80:\n                node = node[:77] + '...'\n        else:\n            node = '{}, {}'.format(str_base, v)\n        print(node)", "response": "Pretty print a data dictionary from the bridge client\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsimulate a Karabo Bridge server and send random data from a detector.", "response": "def start_gen(port, ser='msgpack', version='2.2', detector='AGIPD',\n              raw=False, nsources=1, datagen='random', *,\n              debug=True):\n    \"\"\"\"Karabo bridge server simulation.\n\n    Simulate a Karabo Bridge server and send random data from a detector,\n    either AGIPD or LPD.\n\n    Parameters\n    ----------\n    port: str\n        The port to on which the server is bound.\n    ser: str, optional\n        The serialization algorithm, default is msgpack.\n    version: str, optional\n        The container version of the serialized data.\n    detector: str, optional\n        The data format to send, default is AGIPD detector.\n    raw: bool, optional\n        Generate raw data output if True, else CORRECTED. Default is False.\n    nsources: int, optional\n        Number of sources.\n    datagen: string, optional\n        Generator function used to generate detector data. Default is random.\n    \"\"\"\n    context = zmq.Context()\n    socket = context.socket(zmq.REP)\n    socket.setsockopt(zmq.LINGER, 0)\n    socket.bind('tcp://*:{}'.format(port))\n\n    if ser != 'msgpack':\n        raise ValueError(\"Unknown serialisation format %s\" % ser)\n    serialize = partial(msgpack.dumps, use_bin_type=True)\n    det = Detector.getDetector(detector, raw=raw, gen=datagen)\n    generator = generate(det, nsources)\n\n    print('Simulated Karabo-bridge server started on:\\ntcp://{}:{}'.format(\n          uname().nodename, port))\n\n    t_prev = time()\n    n = 0\n\n    try:\n        while True:\n            msg = socket.recv()\n            if msg == b'next':\n                train = next(generator)\n                msg = containize(train, ser, serialize, version)\n                socket.send_multipart(msg, copy=False)\n                if debug:\n                    print('Server : emitted train:',\n                          train[1][list(train[1].keys())[0]]['timestamp.tid'])\n                n += 1\n                if n % TIMING_INTERVAL == 0:\n                    t_now = time()\n                    print('Sent {} trains in {:.2f} seconds ({:.2f} Hz)'\n                          ''.format(TIMING_INTERVAL, t_now - t_prev,\n                                    TIMING_INTERVAL / (t_now - t_prev)))\n                    t_prev = t_now\n            else:\n                print('wrong request')\n                break\n    except KeyboardInterrupt:\n        print('\\nStopped.')\n    finally:\n        socket.close()\n        context.destroy()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self):\n        if self._pattern == zmq.REQ and not self._recv_ready:\n            self._socket.send(b'next')\n            self._recv_ready = True\n        try:\n            msg = self._socket.recv_multipart(copy=False)\n        except zmq.error.Again:\n            raise TimeoutError(\n                'No data received from {} in the last {} ms'.format(\n                    self._socket.getsockopt_string(zmq.LAST_ENDPOINT),\n                    self._socket.getsockopt(zmq.RCVTIMEO)))\n        self._recv_ready = False\n        return self._deserialize(msg)", "response": "Request next data container."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_open_fds():\n    pid = os.getpid()\n    procs = subprocess.check_output([\"lsof\", '-w', '-Ff', \"-p\", str(pid)])\n    procs = procs.decode(\"utf-8\")\n\n    return len([s for s in procs.split('\\n')\n                if s and s[0] == 'f' and s[1:].isdigit()])", "response": "Return the number of open file descriptors for current process\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nacquires the lock file.", "response": "def acquire(self):\n        \"\"\"\n        Acquire the lock, if possible. If the lock is in use, it check again\n        every `delay` seconds. It does this until it either gets the lock or\n        exceeds `timeout` number of seconds, in which case it throws\n        an exception.\n        \"\"\"\n        start_time = time.time()\n        while True:\n            try:\n                self.fd = os.open(self.lockfile,\n                                  os.O_CREAT | os.O_EXCL | os.O_RDWR)\n                break\n            except (OSError,) as e:\n                if e.errno != errno.EEXIST:\n                    raise\n                if (time.time() - start_time) >= self.timeout:\n                    raise FileLockException(\"%s: Timeout occured.\" %\n                                            self.lockfile)\n                time.sleep(self.delay)\n\n        self.is_locked = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef release(self):\n        if self.is_locked:\n            os.close(self.fd)\n            os.unlink(self.lockfile)\n            self.is_locked = False", "response": "Release the lock file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter(self, names):\n        names = list_strings(names)\n\n        fnames = []\n        for f in names:\n            for pat in self.pats:\n                if fnmatch.fnmatch(f, pat):\n                    fnames.append(f)\n\n        return fnames", "response": "Returns a list with the names matching the pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match(self, name):\n        for pat in self.pats:\n            if fnmatch.fnmatch(name, pat):\n                return True\n\n        return False", "response": "Returns True if name matches one of the patterns."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ncpus():\n    # Python 2.6+\n    # May raise NonImplementedError\n    try:\n        return multiprocessing.cpu_count()\n    except (ImportError, NotImplementedError):\n        pass\n\n    # POSIX\n    try:\n        res = int(os.sysconf('SC_NPROCESSORS_ONLN'))\n        if res > 0:\n            return res\n    except (AttributeError, ValueError):\n        pass\n\n    # Windows\n    try:\n        res = int(os.environ['NUMBER_OF_PROCESSORS'])\n        if res > 0:\n            return res\n    except (KeyError, ValueError):\n        pass\n\n    # jython\n    try:\n        from java.lang import Runtime\n        runtime = Runtime.getRuntime()\n        res = runtime.availableProcessors()\n        if res > 0:\n            return res\n    except ImportError:\n        pass\n\n    # BSD\n    try:\n        sysctl = subprocess.Popen(['sysctl', '-n', 'hw.ncpu'],\n                                  stdout=subprocess.PIPE)\n        scstdout = sysctl.communicate()[0]\n        res = int(scstdout)\n        if res > 0:\n            return res\n    except (OSError, ValueError):\n        pass\n\n    # Linux\n    try:\n        res = open('/proc/cpuinfo').read().count('processor\\t:')\n        if res > 0:\n            return res\n    except IOError:\n        pass\n\n    # Solaris\n    try:\n        pseudo_devices = os.listdir('/devices/pseudo/')\n        expr = re.compile('^cpuid@[0-9]+$')\n        res = 0\n        for pd in pseudo_devices:\n            if expr.match(pd) is not None:\n                res += 1\n        if res > 0:\n            return res\n    except OSError:\n        pass\n\n    # Other UNIXes (heuristic)\n    try:\n        try:\n            dmesg = open('/var/run/dmesg.boot').read()\n        except IOError:\n            dmesg_process = subprocess.Popen(['dmesg'], stdout=subprocess.PIPE)\n            dmesg = dmesg_process.communicate()[0]\n\n        res = 0\n        while '\\ncpu' + str(res) + ':' in dmesg:\n            res += 1\n\n        if res > 0:\n            return res\n    except OSError:\n        pass\n\n    logger.warning('Cannot determine number of CPUs on this system!')\n    return -1", "response": "Return the number of CPUs on the system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_excepthook(hook_type=\"color\", **kwargs):\n    try:\n        from IPython.core import ultratb\n    except ImportError:\n        import warnings\n        warnings.warn(\n            \"Cannot install excepthook, IPyhon.core.ultratb not available\")\n        return 1\n\n    # Select the hook.\n    hook = dict(\n        color=ultratb.ColorTB,\n        verbose=ultratb.VerboseTB,\n    ).get(hook_type.lower(), None)\n\n    if hook is None:\n        return 2\n\n    import sys\n    sys.excepthook = hook(**kwargs)\n    return 0", "response": "Installs an exception hook in the current IPython traceback."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of all the at matches in a file.", "response": "def regrep(filename, patterns, reverse=False, terminate_on_match=False,\n           postprocess=str):\n    \"\"\"\n    A powerful regular expression version of grep.\n\n    Args:\n        filename (str): Filename to grep.\n        patterns (dict): A dict of patterns, e.g.,\n            {\"energy\": \"energy\\(sigma->0\\)\\s+=\\s+([\\d\\-\\.]+)\"}.\n        reverse (bool): Read files in reverse. Defaults to false. Useful for\n            large files, especially when used with terminate_on_match.\n        terminate_on_match (bool): Whether to terminate when there is at\n            least one match in each key in pattern.\n        postprocess (callable): A post processing function to convert all\n            matches. Defaults to str, i.e., no change.\n\n    Returns:\n        A dict of the following form:\n            {key1: [[[matches...], lineno], [[matches...], lineno],\n                    [[matches...], lineno], ...],\n            key2: ...}\n        For reverse reads, the lineno is given as a -ve number. Please note\n        that 0-based indexing is used.\n    \"\"\"\n    compiled = {k: re.compile(v) for k, v in patterns.items()}\n    matches = collections.defaultdict(list)\n    gen = reverse_readfile(filename) if reverse else zopen(filename, \"rt\")\n    for i, l in enumerate(gen):\n        for k, p in compiled.items():\n            m = p.search(l)\n            if m:\n                matches[k].append([[postprocess(g) for g in m.groups()],\n                                   -i if reverse else i])\n        if terminate_on_match and all([\n                len(matches.get(k, [])) for k in compiled.keys()]):\n            break\n    try:\n        # Try to close open file handle. Pass if it is a generator.\n        gen.close()\n    except:\n        pass\n    return matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cached_class(klass):\n    cache = {}\n\n    @wraps(klass, assigned=(\"__name__\", \"__module__\"), updated=())\n    class _decorated(klass):\n        # The wraps decorator can't do this because __doc__\n        # isn't writable once the class is created\n        __doc__ = klass.__doc__\n\n        def __new__(cls, *args, **kwargs):\n            key = (cls,) + args + tuple(kwargs.items())\n            try:\n                inst = cache.get(key, None)\n            except TypeError:\n                # Can't cache this set of arguments\n                inst = key = None\n            if inst is None:\n                # Technically this is cheating, but it works,\n                # and takes care of initializing the instance\n                # (so we can override __init__ below safely);\n                # calling up to klass.__new__ would be the\n                # \"official\" way to create the instance, but\n                # that raises DeprecationWarning if there are\n                # args or kwargs and klass does not override\n                # __new__ (which most classes don't), because\n                # object.__new__ takes no parameters (and in\n                # Python 3 the warning will become an error)\n                inst = klass(*args, **kwargs)\n                # This makes isinstance and issubclass work\n                # properly\n                inst.__class__ = cls\n                if key is not None:\n                    cache[key] = inst\n            return inst\n\n        def __init__(self, *args, **kwargs):\n            # This will be called every time __new__ is\n            # called, so we skip initializing here and do\n            # it only when the instance is created above\n            pass\n\n    return _decorated", "response": "A class decorator that caches the instances of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef operator_from_str(op):\n    d = {\"==\": operator.eq,\n         \"!=\": operator.ne,\n         \">\": operator.gt,\n         \">=\": operator.ge,\n         \"<\": operator.lt,\n         \"<=\": operator.le,\n         '+': operator.add,\n         '-': operator.sub,\n         '*': operator.mul,\n         '%': operator.mod,\n         '^': operator.xor,\n         }\n\n    try:\n        d['/'] = operator.truediv\n    except AttributeError:\n        pass\n\n    return d[op]", "response": "Return the operator associated to the given string op. Raise KeyError if invalid string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a command in a separated thread and wait timeout seconds.", "response": "def run(self, timeout=None, **kwargs):\n        \"\"\"\n        Run a command in a separated thread and wait timeout seconds.\n        kwargs are keyword arguments passed to Popen.\n\n        Return: self\n        \"\"\"\n        from subprocess import Popen, PIPE\n\n        def target(**kw):\n            try:\n                # print('Thread started')\n                self.process = Popen(self.command, **kw)\n                self.output, self.error = self.process.communicate()\n                self.retcode = self.process.returncode\n                # print('Thread stopped')\n            except:\n                import traceback\n                self.error = traceback.format_exc()\n                self.retcode = -1\n\n        # default stdout and stderr\n        if 'stdout' not in kwargs:\n            kwargs['stdout'] = PIPE\n\n        if 'stderr' not in kwargs:\n            kwargs['stderr'] = PIPE\n\n        # thread\n        import threading\n        thread = threading.Thread(target=target, kwargs=kwargs)\n        thread.start()\n        thread.join(timeout)\n\n        if thread.is_alive():\n            # print(\"Terminating process\")\n            self.process.terminate()\n            self.killed = True\n            thread.join()\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef marquee(text=\"\", width=78, mark='*'):\n    if not text:\n        return (mark*width)[:width]\n\n    nmark = (width-len(text)-2)//len(mark)//2\n    if nmark < 0: \n        nmark = 0\n\n    marks = mark * nmark\n    return '%s %s %s' % (marks, text, marks)", "response": "Return the input string centered in a marquee."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string in a boxed format.", "response": "def boxed(msg, ch=\"=\", pad=5):\n    \"\"\"\n    Returns a string in a box\n\n    Args:\n        msg: Input string.\n        ch: Character used to form the box.\n        pad: Number of characters ch added before and after msg.\n\n    >>> print(boxed(\"hello\", ch=\"*\", pad=2))\n    ***********\n    ** hello **\n    ***********\n    \"\"\"\n    if pad > 0:\n        msg = pad * ch + \" \" + msg.strip() + \" \" + pad * ch\n\n    return \"\\n\".join([len(msg) * ch,\n                      msg,\n                      len(msg) * ch,\n                     ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nindents the lines in a string by padding each one with proper number of pad characters", "response": "def indent(lines, amount, ch=' '):\n    \"\"\"Indent the lines in a string by padding each one with proper number of pad characters\"\"\"\n    padding = amount * ch\n    return padding + ('\\n' + padding).join(lines.split('\\n'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef return_if_raise(exception_tuple, retval_if_exc, disabled=False):\n    # we need a tuple of exceptions.\n    if isinstance(exception_tuple, list):\n        exception_tuple = tuple(exception_tuple)\n    elif not isinstance(exception_tuple, tuple):\n        exception_tuple = (exception_tuple,)\n    else:\n        raise TypeError(\"Wrong exception_tuple %s\" % type(exception_tuple))\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if disabled:\n                return func(*args, **kwargs)\n            try:\n                return func(*args, **kwargs)\n            except exception_tuple:\n                return retval_if_exc\n            else:\n                raise RuntimeError()\n        return wrapper\n    return decorator", "response": "Decorator for functions methods or properties. Execute the callable in a\n    and return retval_if_exc if one of the exceptions listed in exception_tuple is raised."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninvalidating a lazy attribute.", "response": "def invalidate(cls, inst, name):\n        \"\"\"Invalidate a lazy attribute.\n\n        This obviously violates the lazy contract. A subclass of lazy\n        may however have a contract where invalidation is appropriate.\n        \"\"\"\n        inst_cls = inst.__class__\n\n        if not hasattr(inst, '__dict__'):\n            raise AttributeError(\"'%s' object has no attribute '__dict__'\"\n                                 % (inst_cls.__name__,))\n\n        if name.startswith('__') and not name.endswith('__'):\n            name = '_%s%s' % (inst_cls.__name__, name)\n\n        if not isinstance(getattr(inst_cls, name), cls):\n            raise AttributeError(\"'%s.%s' is not a %s attribute\"\n                                 % (inst_cls.__name__, name, cls.__name__))\n\n        if name in inst.__dict__:\n            del inst.__dict__[name]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loadfn(fn, *args, **kwargs):\n    if \"mpk\" in os.path.basename(fn).lower():\n        if msgpack is None:\n            raise RuntimeError(\n                \"Loading of message pack files is not \"\n                \"possible as msgpack-python is not installed.\")\n        if \"object_hook\" not in kwargs:\n            kwargs[\"object_hook\"] = object_hook\n        with zopen(fn, \"rb\") as fp:\n            return msgpack.load(fp, *args, **kwargs)\n    else:\n        with zopen(fn) as fp:\n            if \"yaml\" in os.path.basename(fn).lower():\n                if yaml is None:\n                    raise RuntimeError(\"Loading of YAML files is not \"\n                                       \"possible as ruamel.yaml is not installed.\")\n                if \"Loader\" not in kwargs:\n                    kwargs[\"Loader\"] = Loader\n                return yaml.load(fp, *args, **kwargs)\n            else:\n                if \"cls\" not in kwargs:\n                    kwargs[\"cls\"] = MontyDecoder\n                return json.load(fp, *args, **kwargs)", "response": "Loads a file - like object from a filename instead of a msgpack file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dumpfn(obj, fn, *args, **kwargs):\n    if \"mpk\" in os.path.basename(fn).lower():\n        if msgpack is None:\n            raise RuntimeError(\n                \"Loading of message pack files is not \"\n                \"possible as msgpack-python is not installed.\")\n        if \"default\" not in kwargs:\n            kwargs[\"default\"] = default\n        with zopen(fn, \"wb\") as fp:\n            msgpack.dump(obj, fp, *args, **kwargs)\n    else:\n        with zopen(fn, \"wt\") as fp:\n            if \"yaml\" in os.path.basename(fn).lower():\n                if yaml is None:\n                    raise RuntimeError(\"Loading of YAML files is not \"\n                                       \"possible as ruamel.yaml is not installed.\")\n                if \"Dumper\" not in kwargs:\n                    kwargs[\"Dumper\"] = Dumper\n                yaml.dump(obj, fp, *args, **kwargs)\n            else:\n                if \"cls\" not in kwargs:\n                    kwargs[\"cls\"] = MontyEncoder\n                fp.write(\"%s\" % json.dumps(obj, *args, **kwargs))", "response": "Dump an object to a file - like object by filename instead of a File - like object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_set(obj):\n    if obj is None or isinstance(obj, collections.Set):\n        return obj\n\n    if not isinstance(obj, collections.Iterable):\n        return set((obj,))\n    else:\n        return set(obj)", "response": "Convert obj into a set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable_logging(main):\n    @functools.wraps(main)\n    def wrapper(*args, **kwargs):\n        import argparse\n        parser = argparse.ArgumentParser()\n\n        parser.add_argument(\n            '--loglevel', default=\"ERROR\", type=str,\n            help=\"Set the loglevel. Possible values: CRITICAL, ERROR (default),\"\n                 \"WARNING, INFO, DEBUG\")\n\n        options = parser.parse_args()\n\n        # loglevel is bound to the string value obtained from the command line\n        # argument.\n        # Convert to upper case to allow the user to specify --loglevel=DEBUG\n        # or --loglevel=debug\n        numeric_level = getattr(logging, options.loglevel.upper(), None)\n        if not isinstance(numeric_level, int):\n            raise ValueError('Invalid log level: %s' % options.loglevel)\n        logging.basicConfig(level=numeric_level)\n\n        retcode = main(*args, **kwargs)\n        return retcode\n\n    return wrapper", "response": "This is a decorator that enables the logging module to be used for all the main functions. It is used to decorate main functions that are used to initialize the log module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn full path to a executable command.", "response": "def which(cmd):\n    \"\"\"\n    Returns full path to a executable.\n\n    Args:\n        cmd (str): Executable command to search for.\n\n    Returns:\n        (str) Full path to command. None if it is not found.\n\n    Example::\n\n        full_path_to_python = which(\"python\")\n    \"\"\"\n    def is_exe(fp):\n        return os.path.isfile(fp) and os.access(fp, os.X_OK)\n\n    fpath, fname = os.path.split(cmd)\n    if fpath:\n        if is_exe(cmd):\n            return cmd\n    else:\n        for path in os.environ[\"PATH\"].split(os.pathsep):\n            exe_file = os.path.join(path, cmd)\n            if is_exe(exe_file):\n                return exe_file\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an existing file path given the unzipped version of the file.", "response": "def zpath(filename):\n    \"\"\"\n    Returns an existing (zipped or unzipped) file path given the unzipped\n    version. If no path exists, returns the filename unmodified.\n\n    Args:\n        filename: filename without zip extension\n\n    Returns:\n        filename with a zip extension (unless an unzipped version\n        exists). If filename is not found, the same filename is returned\n        unchanged.\n    \"\"\"\n    for ext in [\"\", '.gz', '.GZ', '.bz2', '.BZ2', '.z', '.Z']:\n        zfilename = \"{}{}\".format(filename, ext)\n        if os.path.exists(zfilename):\n            return zfilename\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all files with the specified extensions in top and return a list of absolute paths.", "response": "def find_exts(top, exts, exclude_dirs=None, include_dirs=None,\n              match_mode=\"basename\"):\n    \"\"\"\n    Find all files with the extension listed in `exts` that are located within\n    the directory tree rooted at `top` (including top itself, but excluding\n    '.' and '..')\n\n    Args:\n        top (str): Root directory\n        exts (str or list of strings): List of extensions.\n        exclude_dirs (str): Wildcards used to exclude particular directories.\n            Can be concatenated via `|`\n        include_dirs (str): Wildcards used to select particular directories.\n            `include_dirs` and `exclude_dirs` are mutually exclusive\n        match_mode (str): \"basename\" if  match should be done on the basename.\n            \"abspath\" for absolute path.\n\n    Returns:\n        (list of str): Absolute paths of the files.\n\n    Examples::\n\n        # Find all pdf and ps files starting from the current directory.\n        find_exts(\".\", (\"pdf\", \"ps\"))\n\n        # Find all pdf files, exclude hidden directories and dirs whose name\n        # starts with `_`\n        find_exts(\".\", \"pdf\", exclude_dirs=\"_*|.*\")\n\n        # Find all ps files, in the directories whose basename starts with\n        # output.\n        find_exts(\".\", \"ps\", include_dirs=\"output*\"))\n    \"\"\"\n    from monty.string import list_strings\n    exts = list_strings(exts)\n\n    # Handle file!\n    if os.path.isfile(top):\n        return [os.path.abspath(top)] if any(top.endswith(ext)\n                                             for ext in exts) else []\n\n    # Build shell-style wildcards.\n    from monty.fnmatch import WildCard\n    if exclude_dirs is not None:\n        exclude_dirs = WildCard(exclude_dirs)\n\n    if include_dirs is not None:\n        include_dirs = WildCard(include_dirs)\n\n    mangle = dict(\n        basename=os.path.basename,\n        abspath=os.path.abspath)[match_mode]\n\n    # Assume directory\n    paths = []\n    for dirpath, dirnames, filenames in os.walk(top):\n        dirpath = os.path.abspath(dirpath)\n\n        if exclude_dirs and exclude_dirs.match(mangle(dirpath)):\n            continue\n        if include_dirs and not include_dirs.match(mangle(dirpath)):\n            continue\n\n        for filename in filenames:\n            if any(filename.endswith(ext) for ext in exts):\n                paths.append(os.path.join(dirpath, filename))\n\n    return paths"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list with all subclasses of cls and so on.", "response": "def all_subclasses(cls):\n    \"\"\"\n    Given a class `cls`, this recursive function returns a list with\n    all subclasses, subclasses of subclasses, and so on.\n    \"\"\"\n    subclasses = cls.__subclasses__() \n    return subclasses + [g for s in subclasses for g in all_subclasses(s)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initializer(func):\n    names, varargs, keywords, defaults = inspect.getargspec(func)\n\n    from functools import wraps\n    @wraps(func)\n    def wrapper(self, *args, **kargs):\n        #print(\"names\", names, \"defaults\", defaults)\n        for name, arg in list(zip(names[1:], args)) + list(kargs.items()):\n            setattr(self, name, arg)\n\n        # Avoid TypeError: argument to reversed() must be a sequence\n        if defaults is not None:\n            for name, default in zip(reversed(names), reversed(defaults)):\n                if not hasattr(self, name):\n                    setattr(self, name, default)\n\n        return func(self, *args, **kargs)\n\n    return wrapper", "response": "A decorator that creates a new object with the same parameters as the passed in function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pprint_table(table, out=sys.stdout, rstrip=False):\n    def max_width_col(table, col_idx):\n        \"\"\"\n        Get the maximum width of the given column index\n        \"\"\"\n        return max([len(row[col_idx]) for row in table])\n\n    if rstrip:\n        for row_idx, row in enumerate(table):\n            table[row_idx] = [c.rstrip() for c in row]\n\n    col_paddings = []\n    ncols = len(table[0])\n    for i in range(ncols):\n        col_paddings.append(max_width_col(table, i))\n\n    for row in table:\n        # left col\n        out.write(row[0].ljust(col_paddings[0] + 1))\n        # rest of the cols\n        for i in range(1, len(row)):\n            col = row[i].rjust(col_paddings[i] + 2)\n            out.write(col)\n        out.write(\"\\n\")", "response": "Prints out a table of data padded for alignment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef draw_tree(node, child_iter=lambda n: n.children, text_str=lambda n: str(n)):\n    return _draw_tree(node, '', child_iter, text_str)", "response": "Draw a tree from a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the greatest common divisor of a sequence of numbers.", "response": "def gcd(*numbers):\n    \"\"\"\n    Returns the greatest common divisor for a sequence of numbers.\n\n    Args:\n        \\*numbers: Sequence of numbers.\n\n    Returns:\n        (int) Greatest common divisor of numbers.\n    \"\"\"\n    n = numbers[0]\n    for i in numbers:\n        n = pygcd(n, i)\n    return n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the lowest common multiple of a sequence of numbers.", "response": "def lcm(*numbers):\n    \"\"\"\n    Return lowest common multiple of a sequence of numbers.\n\n    Args:\n        \\*numbers: Sequence of numbers.\n\n    Returns:\n        (int) Lowest common multiple of numbers.\n    \"\"\"\n    n = 1\n    for i in numbers:\n        n = (i * n) // gcd(i, n)\n    return n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gcd_float(numbers, tol=1e-8):\n\n    def pair_gcd_tol(a, b):\n        \"\"\"Calculate the Greatest Common Divisor of a and b.\n\n        Unless b==0, the result will have the same sign as b (so that when\n        b is divided by it, the result comes out positive).\n        \"\"\"\n        while b > tol:\n            a, b = b, a % b\n        return a\n\n    n = numbers[0]\n    for i in numbers:\n        n = pair_gcd_tol(n, i)\n    return n", "response": "Returns the greatest common divisor of a sequence of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields successive n - sized chunks from a list - like object.", "response": "def chunks(items, n):\n    \"\"\"\n    Yield successive n-sized chunks from a list-like object.\n\n    >>> import pprint\n    >>> pprint.pprint(list(chunks(range(1, 25), 10)))\n    [(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n     (11, 12, 13, 14, 15, 16, 17, 18, 19, 20),\n     (21, 22, 23, 24)]\n    \"\"\"\n    it = iter(items)\n    chunk = tuple(itertools.islice(it, n))\n    while chunk:\n        yield chunk\n        chunk = tuple(itertools.islice(it, n))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing an iterator given a slice object s.", "response": "def iterator_from_slice(s):\n    \"\"\"\n    Constructs an iterator given a slice object s.\n\n    .. note::\n\n        The function returns an infinite iterator if s.stop is None\n    \"\"\"\n    import numpy as np\n    start = s.start if s.start is not None else 0\n    step = s.step if s.step is not None else 1\n\n    if s.stop is None:\n        # Infinite iterator.\n        return itertools.count(start=start, step=step)\n    else:\n        # xrange-like iterator that supports float.\n        return iter(np.arange(start, s.stop, step))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iuptri(items, diago=True, with_inds=False):\n    for (ii, item1) in enumerate(items):\n        for (jj, item2) in enumerate(items):\n            do_yield = (jj >= ii) if diago else (jj > ii)\n            if do_yield:\n                if with_inds:\n                    yield (ii, jj), (item1, item2)\n                else:\n                    yield item1, item2", "response": "A generator that yields the upper triangle of the matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cprint(text, color=None, on_color=None, attrs=None, **kwargs):\n    try:\n        print((colored(text, color, on_color, attrs)), **kwargs)\n    except TypeError:\n        # flush is not supported by py2.7\n        kwargs.pop(\"flush\", None)\n        print((colored(text, color, on_color, attrs)), **kwargs)", "response": "Print colorize text.\n\n    It accepts arguments of print function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn colorized text. cmap is a dict mapping tokens to color options.", "response": "def colored_map(text, cmap):\n    \"\"\"\n    Return colorized text. cmap is a dict mapping tokens to color options.\n\n    .. Example:\n\n        colored_key(\"foo bar\", {bar: \"green\"})\n        colored_key(\"foo bar\", {bar: {\"color\": \"green\", \"on_color\": \"on_red\"}})\n    \"\"\"\n    if not __ISON: return text\n    for key, v in cmap.items():\n        if isinstance(v, dict):\n            text = text.replace(key, colored(key, **v))\n        else:\n            text = text.replace(key, colored(key, color=v))\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint colorize text. cmap is a dict mapping keys to color options. kwargs are passed to print function.", "response": "def cprint_map(text, cmap, **kwargs):\n    \"\"\"\n    Print colorize text.\n    cmap is a dict mapping keys to color options.\n    kwargs are passed to print function\n\n    Example:\n        cprint_map(\"Hello world\", {\"Hello\": \"red\"})\n    \"\"\"\n    try:\n        print(colored_map(text, cmap), **kwargs)\n    except TypeError:\n        # flush is not supported by py2.7\n        kwargs.pop(\"flush\", None)\n        print(colored_map(text, cmap), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_terminal_size():\n    try:\n        rc = os.popen('stty size', 'r').read().split()\n        return int(rc[0]), int(rc[1])\n    except:\n        pass\n\n    env = os.environ\n\n    def ioctl_GWINSZ(fd):\n        try:\n            import fcntl, termios, struct\n            rc = struct.unpack('hh',\n                               fcntl.ioctl(fd, termios.TIOCGWINSZ, '1234'))\n            return rc\n        except:\n            return None\n\n    rc = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)\n\n    if not rc:\n        try:\n            fd = os.open(os.ctermid(), os.O_RDONLY)\n            rc = ioctl_GWINSZ(fd)\n            os.close(fd)\n        except:\n            pass\n\n    if not rc:\n        rc = (env.get('LINES', 25), env.get('COLUMNS', 80))\n\n    return int(rc[0]), int(rc[1])", "response": "Return the size of the terminal as ( nrow ncols )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index(a, x, atol=None):\n    i = bs.bisect_left(a, x)\n    if i != len(a):\n        if atol is None:\n            if a[i] == x: return i\n        else:\n            if abs(a[i] - x) < atol: return i\n    raise ValueError", "response": "Locate the leftmost value exactly equal to x."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_lt(a, x):\n    i = bs.bisect_left(a, x)\n    if i: return i - 1\n    raise ValueError", "response": "Find rightmost value less than x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind rightmost value less than or equal to x.", "response": "def find_le(a, x):\n    \"\"\"Find rightmost value less than or equal to x.\"\"\"\n    i = bs.bisect_right(a, x)\n    if i: return i - 1\n    raise ValueError"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind leftmost value greater than x.", "response": "def find_gt(a, x):\n    \"\"\"Find leftmost value greater than x.\"\"\"\n    i = bs.bisect_right(a, x)\n    if i != len(a): return i\n    raise ValueError"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_ge(a, x):\n    i = bs.bisect_left(a, x)\n    if i != len(a): return i\n    raise ValueError", "response": "Find the leftmost item greater than or equal to x."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jsanitize(obj, strict=False, allow_bson=False):\n    if allow_bson and (isinstance(obj, (datetime.datetime, bytes)) or \\\n                       (bson is not None and isinstance(obj,\n                                                        bson.objectid.ObjectId))):\n        return obj\n    if isinstance(obj, (list, tuple)):\n        return [jsanitize(i, strict=strict, allow_bson=allow_bson) for i in obj]\n    elif np is not None and isinstance(obj, np.ndarray):\n        return [jsanitize(i, strict=strict, allow_bson=allow_bson) for i in\n                obj.tolist()]\n    elif isinstance(obj, dict):\n        return {k.__str__(): jsanitize(v, strict=strict, allow_bson=allow_bson)\n                for k, v in obj.items()}\n    elif isinstance(obj, six.integer_types + tuple([float])):\n        return obj\n    elif obj is None:\n        return None\n\n    else:\n        if not strict:\n            return obj.__str__()\n        else:\n            if isinstance(obj, six.string_types):\n                return obj.__str__()\n            else:\n                return jsanitize(obj.as_dict(), strict=strict,\n                                 allow_bson=allow_bson)", "response": "This method cleans an input json - like object and converts all non - string items in the tree to strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dict representation of the object.", "response": "def as_dict(self):\n        \"\"\"\n        A JSON serializable dict representation of an object.\n        \"\"\"\n        d = {\"@module\": self.__class__.__module__,\n             \"@class\": self.__class__.__name__}\n\n        try:\n            parent_module = self.__class__.__module__.split('.')[0]\n            module_version = import_module(parent_module).__version__\n            d[\"@version\"] = u\"{}\".format(module_version)\n        except AttributeError:\n            d[\"@version\"] = None\n\n        args = getargspec(self.__class__.__init__).args\n\n        def recursive_as_dict(obj):\n            if isinstance(obj, (list, tuple)):\n                return [recursive_as_dict(it) for it in obj]\n            elif isinstance(obj, dict):\n                return {kk: recursive_as_dict(vv) for kk, vv in obj.items()}\n            elif hasattr(obj, \"as_dict\"):\n                return obj.as_dict()\n            return obj\n\n        for c in args:\n            if c != \"self\":\n                try:\n                    a = self.__getattribute__(c)\n                except AttributeError:\n                    try:\n                        a = self.__getattribute__(\"_\" + c)\n                    except AttributeError:\n                        raise NotImplementedError(\n                            \"Unable to automatically determine as_dict \"\n                            \"format from class. MSONAble requires all \"\n                            \"args to be present as either self.argname or \"\n                            \"self._argname, and kwargs to be present under\"\n                            \"a self.kwargs variable to automatically \"\n                            \"determine the dict format. Alternatively, \"\n                            \"you can implement both as_dict and from_dict.\")\n                d[c] = recursive_as_dict(a)\n        if hasattr(self, \"kwargs\"):\n            d.update(**self.kwargs)\n        if hasattr(self, \"_kwargs\"):\n            d.update(**self._kwargs)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noverriding default method for JSON encoding.", "response": "def default(self, o):\n        \"\"\"\n        Overriding default method for JSON encoding. This method does two\n        things: (a) If an object has a to_dict property, return the to_dict\n        output. (b) If the @module and @class keys are not in the to_dict,\n        add them to the output automatically. If the object has no to_dict\n        property, the default Python json encoder default method is called.\n\n        Args:\n            o: Python object.\n\n        Return:\n            Python dict representation.\n        \"\"\"\n        if isinstance(o, datetime.datetime):\n            return {\"@module\": \"datetime\", \"@class\": \"datetime\",\n                    \"string\": o.__str__()}\n        if np is not None:\n            if isinstance(o, np.ndarray):\n                return {\"@module\": \"numpy\",\n                        \"@class\": \"array\",\n                        \"dtype\": o.dtype.__str__(),\n                        \"data\": o.tolist()}\n            elif isinstance(o, np.generic):\n                return o.item()\n        if bson is not None:\n            if isinstance(o, bson.objectid.ObjectId):\n                return {\"@module\": \"bson.objectid\",\n                        \"@class\": \"ObjectId\",\n                        \"oid\": str(o)}\n\n        try:\n            d = o.as_dict()\n            if \"@module\" not in d:\n                d[\"@module\"] = u\"{}\".format(o.__class__.__module__)\n            if \"@class\" not in d:\n                d[\"@class\"] = u\"{}\".format(o.__class__.__name__)\n            if \"@version\" not in d:\n                try:\n                    parent_module = o.__class__.__module__.split('.')[0]\n                    module_version = import_module(parent_module).__version__\n                    d[\"@version\"] = u\"{}\".format(module_version)\n                except AttributeError:\n                    d[\"@version\"] = None\n            return d\n        except AttributeError:\n            return json.JSONEncoder.default(self, o)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nCr(n, r):\n    f = math.factorial\n    return int(f(n) / f(r) / f(n-r))", "response": "Calculates the n - Cr value for a given set of items."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nPr(n, r):\n    f = math.factorial\n    return int(f(n) / f(n-r))", "response": "Calculates the n - th item of the n - th item of the r - th item of the n - th item of the r - th item of the n - th item"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements a recursive copy function similar to Unix's \"cp -r\" command. Surprisingly, python does not have a real equivalent. shutil.copytree only works if the destination directory is not present. Args: src (str): Source folder to copy. dst (str): Destination folder.", "response": "def copy_r(src, dst):\n    \"\"\"\n    Implements a recursive copy function similar to Unix's \"cp -r\" command.\n    Surprisingly, python does not have a real equivalent. shutil.copytree\n    only works if the destination directory is not present.\n\n    Args:\n        src (str): Source folder to copy.\n        dst (str): Destination folder.\n    \"\"\"\n\n    abssrc = os.path.abspath(src)\n    absdst = os.path.abspath(dst)\n    try:\n        os.makedirs(absdst)\n    except OSError:\n        # If absdst exists, an OSError is raised. We ignore this error.\n        pass\n    for f in os.listdir(abssrc):\n        fpath = os.path.join(abssrc, f)\n        if os.path.isfile(fpath):\n            shutil.copy(fpath, absdst)\n        elif not absdst.startswith(fpath):\n            copy_r(fpath, os.path.join(absdst, f))\n        else:\n            warnings.warn(\"Cannot copy %s to itself\" % fpath)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compress_file(filepath, compression=\"gz\"):\n    if compression not in [\"gz\", \"bz2\"]:\n        raise ValueError(\"Supported compression formats are 'gz' and 'bz2'.\")\n    from monty.io import zopen\n    if not filepath.lower().endswith(\".%s\" % compression):\n        with open(filepath, 'rb') as f_in, \\\n                zopen('%s.%s' % (filepath, compression), 'wb') as f_out:\n            f_out.writelines(f_in)\n        os.remove(filepath)", "response": "Compresses a file with the correct extension."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compress_dir(path, compression=\"gz\"):\n    for parent, subdirs, files in os.walk(path):\n        for f in files:\n            compress_file(os.path.join(parent, f), compression=compression)", "response": "Recursively compresses all files in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decompress_file(filepath):\n    toks = filepath.split(\".\")\n    file_ext = toks[-1].upper()\n    from monty.io import zopen\n    if file_ext in [\"BZ2\", \"GZ\", \"Z\"]:\n        with open(\".\".join(toks[0:-1]), 'wb') as f_out, \\\n                zopen(filepath, 'rb') as f_in:\n            f_out.writelines(f_in)\n        os.remove(filepath)", "response": "Decompresses a file with the correct extension. Automatically detects\nCTYPE gz bz2 or z extension. Automatically detects\nCTYPE gz or bz2 or z extension. Automatically detects\nCTYPE gz or bz2 or z extension. Automatically detects\nCTYPE bz2 or z extension. Automatically detects\nCTYPE gz or bz2. Defaults to gz."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decompress_dir(path):\n    for parent, subdirs, files in os.walk(path):\n        for f in files:\n            decompress_file(os.path.join(parent, f))", "response": "Recursively decompresses all files in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(path, follow_symlink=False):\n    if os.path.isfile(path):\n        os.remove(path)\n    elif os.path.islink(path):\n        if follow_symlink:\n            remove(os.readlink(path))\n        os.unlink(path)\n    else:\n        shutil.rmtree(path)", "response": "Removes a file or symlink from the tree and the tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing hashes for multiple algorithms. Default is MD5.", "response": "def compute_hashes(obj, hashes=frozenset(['md5'])):\n    \"\"\"\n       Digests input data read from file-like object fd or passed directly as bytes-like object.\n       Compute hashes for multiple algorithms. Default is MD5.\n       Returns a tuple of a hex-encoded digest string and a base64-encoded value suitable for an HTTP header.\n    \"\"\"\n    if not (hasattr(obj, 'read') or isinstance(obj, bytes)):\n        raise ValueError(\"Cannot compute hash for given input: a file-like object or bytes-like object is required\")\n\n    hashers = dict()\n    for alg in hashes:\n        try:\n            hashers[alg] = hashlib.new(alg.lower())\n        except ValueError:\n            logging.warning(\"Unable to validate file contents using unknown hash algorithm: %s\", alg)\n\n    while True:\n        if hasattr(obj, 'read'):\n            block = obj.read(1024 ** 2)\n        else:\n            block = obj\n            obj = None\n        if not block:\n            break\n        for i in hashers.values():\n            i.update(block)\n\n    hashes = dict()\n    for alg, h in hashers.items():\n        digest = h.hexdigest()\n        base64digest = base64.b64encode(h.digest())\n        # base64.b64encode returns str on python 2.7 and bytes on 3.x, so deal with that and always return a str\n        if not isinstance(base64digest, str) and isinstance(base64digest, bytes):\n            base64digest = base64digest.decode('ascii')\n        hashes[alg] = digest\n        hashes[alg + \"_base64\"] = base64digest\n\n    return hashes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_file_hashes(file_path, hashes=frozenset(['md5'])):\n    if not os.path.exists(file_path):\n        logging.warning(\"%s does not exist\" % file_path)\n        return\n    else:\n        logging.debug(\"Computing [%s] hashes for file [%s]\" % (','.join(hashes), file_path))\n\n    try:\n        with open(file_path, 'rb') as fd:\n            return compute_hashes(fd, hashes)\n    except (IOError, OSError) as e:\n        logging.warning(\"Error while calculating digest(s) for file %s: %s\" % (file_path, str(e)))\n        raise", "response": "Compute the hashes for a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a bag from a given directory.", "response": "def make_bag(bag_dir,\n             bag_info=None,\n             processes=1,\n             checksums=None,\n             encoding='utf-8',\n             remote_entries=None,\n             spec_version=\"0.97\"):\n    \"\"\"\n    Convert a given directory into a bag. You can pass in arbitrary\n    key/value pairs to put into the bag-info.txt metadata file as\n    the bag_info dictionary.\n    \"\"\"\n\n    if spec_version not in SUPPORTED_BAGIT_SPECS:\n        raise RuntimeError(_(\"Unsupported BagIt specfication version: %s\" % spec_version))\n    bag_version = parse_version(spec_version)\n\n    if checksums is None:\n        checksums = DEFAULT_CHECKSUMS\n\n    bag_dir = os.path.abspath(bag_dir)\n    cwd = os.path.abspath(os.path.curdir)\n\n    if cwd.startswith(bag_dir) and cwd != bag_dir:\n        raise RuntimeError(_('Bagging a parent of the current directory is not supported'))\n\n    LOGGER.info(_(\"Creating bag for directory %s\"), bag_dir)\n\n    if not os.path.isdir(bag_dir):\n        LOGGER.error(_(\"Bag directory %s does not exist\"), bag_dir)\n        raise RuntimeError(_(\"Bag directory %s does not exist\") % bag_dir)\n\n    # FIXME: we should do the permissions checks before changing directories\n    old_dir = os.path.abspath(os.path.curdir)\n\n    try:\n        # TODO: These two checks are currently redundant since an unreadable directory will also\n        #       often be unwritable, and this code will require review when we add the option to\n        #       bag to a destination other than the source. It would be nice if we could avoid\n        #       walking the directory tree more than once even if most filesystems will cache it\n\n        unbaggable = _can_bag(bag_dir)\n\n        if unbaggable:\n            LOGGER.error(_(\"Unable to write to the following directories and files:\\n%s\"), unbaggable)\n            raise BagError(_(\"Missing permissions to move all files and directories\"))\n\n        unreadable_dirs, unreadable_files = _can_read(bag_dir)\n\n        if unreadable_dirs or unreadable_files:\n            if unreadable_dirs:\n                LOGGER.error(_(\"The following directories do not have read permissions:\\n%s\"),\n                             unreadable_dirs)\n            if unreadable_files:\n                LOGGER.error(_(\"The following files do not have read permissions:\\n%s\"),\n                             unreadable_files)\n            raise BagError(_(\"Read permissions are required to calculate file fixities\"))\n        else:\n            LOGGER.info(_(\"Creating data directory\"))\n\n            # FIXME: if we calculate full paths we won't need to deal with changing directories\n            os.chdir(bag_dir)\n            cwd = os.getcwd()\n            temp_data = tempfile.mkdtemp(dir=cwd)\n\n            for f in os.listdir('.'):\n                if os.path.abspath(f) == temp_data:\n                    continue\n                new_f = os.path.join(temp_data, f)\n                LOGGER.info(_('Moving %(source)s to %(destination)s'), {'source': f, 'destination': new_f})\n                os.rename(f, new_f)\n\n            LOGGER.info(_('Moving %(source)s to %(destination)s'), {'source': temp_data, 'destination': 'data'})\n            os.rename(temp_data, 'data')\n\n            # permissions for the payload directory should match those of the\n            # original directory\n            os.chmod('data', os.stat(cwd).st_mode)\n\n            strict = True if bag_version >= (1, 0) else False\n            validate_remote_entries(remote_entries, bag_dir)\n            total_bytes, total_files = make_manifests(\n                'data', processes, algorithms=checksums, encoding=encoding, remote=remote_entries, strict=strict)\n\n            _make_fetch_file(bag_dir, remote_entries)\n\n            LOGGER.info(_(\"Creating bagit.txt\"))\n            txt = \"\"\"BagIt-Version: %s\\nTag-File-Character-Encoding: UTF-8\\n\"\"\" % spec_version\n            with open_text_file('bagit.txt', 'w') as bagit_file:\n                bagit_file.write(txt)\n\n            LOGGER.info(_(\"Creating bag-info.txt\"))\n            if bag_info is None:\n                bag_info = {}\n\n            # allow 'Bagging-Date' and 'Bag-Software-Agent' to be overidden\n            if 'Bagging-Date' not in bag_info:\n                bag_info['Bagging-Date'] = date.strftime(date.today(), \"%Y-%m-%d\")\n            if 'Bag-Software-Agent' not in bag_info:\n                bag_info['Bag-Software-Agent'] = \\\n                    'BDBag version: %s (Bagit version: %s) <%s>' % (VERSION, BAGIT_VERSION, PROJECT_URL)\n            bag_info['Payload-Oxum'] = \"%s.%s\" % (total_bytes, total_files)\n            _make_tag_file('bag-info.txt', bag_info)\n\n            for c in checksums:\n                _make_tagmanifest_file(c, bag_dir, encoding='utf-8')\n    except Exception:\n        LOGGER.error(_(\"An error occurred creating a bag in %s\"), bag_dir)\n        raise\n    finally:\n        os.chdir(old_dir)\n\n    return BDBag(bag_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, processes=1, manifests=False):\n        # Error checking\n        if not self.path:\n            raise BagError(_('Bag.save() called before setting the path!'))\n\n        if not os.access(self.path, os.R_OK | os.W_OK | os.X_OK):\n            raise BagError(_('Cannot save bag to non-existent or inaccessible directory %s') % self.path)\n\n        unbaggable = _can_bag(self.path)\n        if unbaggable:\n            LOGGER.error(_(\"Missing write permissions for the following directories and files:\\n%s\"),\n                         unbaggable)\n            raise BagError(_(\"Missing permissions to move all files and directories\"))\n\n        unreadable_dirs, unreadable_files = _can_read(self.path)\n        if unreadable_dirs or unreadable_files:\n            if unreadable_dirs:\n                LOGGER.error(_(\"The following directories do not have read permissions:\\n%s\"),\n                             unreadable_dirs)\n            if unreadable_files:\n                LOGGER.error(_(\"The following files do not have read permissions:\\n%s\"),\n                             unreadable_files)\n            raise BagError(_(\"Read permissions are required to calculate file fixities\"))\n\n        # Change working directory to bag directory so helper functions work\n        old_dir = os.path.abspath(os.path.curdir)\n        try:\n            os.chdir(self.path)\n\n            # Generate new manifest files\n            if manifests:\n                strict = True if self.version_info >= (1, 0) else False\n                self._sync_remote_entries_with_existing_fetch()\n                validate_remote_entries(self.remote_entries, self.path)\n                total_bytes, total_files = make_manifests('data', processes,\n                                                          algorithms=self.algorithms,\n                                                          encoding=self.encoding,\n                                                          remote=self.remote_entries,\n                                                          strict=strict)\n\n                # Update fetch.txt\n                _make_fetch_file(self.path, self.remote_entries)\n\n                # Update Payload-Oxum\n                LOGGER.info(_('Updating Payload-Oxum in %s'), self.tag_file_name)\n                self.info['Payload-Oxum'] = '%s.%s' % (total_bytes, total_files)\n\n            _make_tag_file(self.tag_file_name, self.info)\n\n            # Update tag-manifest for changes to manifest & bag-info files\n            for alg in self.algorithms:\n                _make_tagmanifest_file(alg, self.path, encoding=self.encoding)\n\n            # Reload the manifests\n            self._load_manifests()\n\n        except Exception:\n            LOGGER.error(_(\"An error occurred updating bag in %s\"), self.path)\n            raise\n\n        finally:\n            os.chdir(old_dir)", "response": "Saves the bag to disk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the structure and contents are valid.", "response": "def validate(self, processes=1, fast=False, completeness_only=False, callback=None):\n        \"\"\"Checks the structure and contents are valid.\n\n        If you supply the parameter fast=True the Payload-Oxum (if present) will\n        be used to check that the payload files are present and accounted for,\n        instead of re-calculating fixities and comparing them against the\n        manifest. By default validate() will re-calculate fixities (fast=False).\n        \"\"\"\n\n        self._validate_structure()\n        self._validate_bagittxt()\n\n        self._validate_fetch()\n\n        self._validate_contents(processes=processes, fast=fast, completeness_only=completeness_only, callback=callback)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_fetch(self):\n        for url, file_size, filename in self.fetch_entries():\n            # fetch_entries will raise a BagError for unsafe filenames\n            # so at this point we will check only that the URL is minimally\n            # well formed:\n            parsed_url = urlparse(url)\n\n            # only check for a scheme component since per the spec the URL field is actually a URI per\n            # RFC3986 (https://tools.ietf.org/html/rfc3986)\n            if not all(parsed_url.scheme):\n                raise BagError(_('Malformed URL in fetch.txt: %s') % url)", "response": "Validate the fetch. txt file\n            Raises BagError for errors and otherwise returns no value\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies that the actual file manifests match the files in the data directory.", "response": "def _validate_completeness(self):\n        \"\"\"\n        Verify that the actual file manifests match the files in the data directory\n        \"\"\"\n        errors = list()\n\n        # First we'll make sure there's no mismatch between the filesystem\n        # and the list of files in the manifest(s)\n        only_in_manifests, only_on_fs, only_in_fetch = self.compare_manifests_with_fs_and_fetch()\n        for path in only_in_manifests:\n            e = FileMissing(path)\n            LOGGER.warning(force_unicode(e))\n            errors.append(e)\n        for path in only_on_fs:\n            e = UnexpectedFile(path)\n            LOGGER.warning(force_unicode(e))\n            errors.append(e)\n        for path in only_in_fetch:\n            e = UnexpectedRemoteFile(path)\n            # this is non-fatal according to spec but the warning is still reasonable\n            LOGGER.warning(force_unicode(e))\n\n        if errors:\n            raise BagValidationError(_(\"Bag validation failed\"), errors)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the entries of the manifest file.", "response": "def _validate_entries(self, processes, callback=None):\n        \"\"\"\n        Verify that the actual file contents match the recorded hashes stored in the manifest files\n        \"\"\"\n        errors = list()\n\n        if os.name == 'posix':\n            worker_init = posix_multiprocessing_worker_initializer\n        else:\n            worker_init = None\n\n        args = ((self.path,\n                 self.normalized_filesystem_names.get(rel_path, rel_path),\n                 hashes,\n                 self.algorithms) for rel_path, hashes in self.entries.items())\n\n        try:\n            if processes == 1:\n                count = 0\n                hash_results = []\n                totalHashes = len(self.entries.items())\n                for i in args:\n                    hash_results.append(_calc_hashes(i))\n                    count += 1\n                    if callback:\n                        if not callback(count, totalHashes):\n                            raise BaggingInterruptedError(\"Bag validation interrupted!\")\n\n            else:\n                pool = None\n                try:\n                    pool = multiprocessing.Pool(processes if processes else None, initializer=worker_init)\n                    hash_results = pool.map(_calc_hashes, args)\n                finally:\n                    if pool:\n                        pool.terminate()\n        except BaggingInterruptedError:\n            raise\n        # Any unhandled exceptions are probably fatal\n        except:\n            LOGGER.error(_(\"Unable to calculate file hashes for %s\"), self)\n            raise\n\n        for rel_path, f_hashes, hashes in hash_results:\n            for alg, computed_hash in f_hashes.items():\n                stored_hash = hashes[alg]\n                if stored_hash.lower() != computed_hash:\n                    e = ChecksumMismatch(rel_path, alg, stored_hash.lower(), computed_hash)\n                    LOGGER.warning(force_unicode(e))\n                    errors.append(e)\n\n        if errors:\n            raise BagValidationError(_(\"Bag validation failed\"), errors)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the results from detector.", "response": "def get_detection_results(url, timeout, metadata=False, save_har=False):\n    \"\"\" Return results from detector.\n\n    This function prepares the environment loading the plugins,\n    getting the response and passing it to the detector.\n\n    In case of errors, it raises exceptions to be handled externally.\n\n    \"\"\"\n    plugins = load_plugins()\n    if not plugins:\n        raise NoPluginsError('No plugins found')\n\n    logger.debug('[+] Starting detection with %(n)d plugins', {'n': len(plugins)})\n\n    response = get_response(url, plugins, timeout)\n\n    # Save HAR\n    if save_har:\n        fd, path = tempfile.mkstemp(suffix='.har')\n        logger.info(f'Saving HAR file to {path}')\n\n        with open(fd, 'w') as f:\n            json.dump(response['har'], f)\n\n    det = Detector(response, plugins, url)\n    softwares = det.get_results(metadata=metadata)\n\n    output = {\n        'url': url,\n        'softwares': softwares,\n    }\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plugins(metadata):\n    plugins = load_plugins()\n    if not plugins:\n        raise NoPluginsError('No plugins found')\n\n    results = []\n    for p in sorted(plugins.get_all(), key=attrgetter('name')):\n        if metadata:\n            data = {'name': p.name, 'homepage': p.homepage}\n            hints = getattr(p, 'hints', [])\n            if hints:\n                data['hints'] = hints\n            results.append(data)\n        else:\n            results.append(p.name)\n    return results", "response": "Return the registered plugins.\n    Load and return all registered plugins.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_most_complete_pm(pms):\n    if not pms:\n        return None\n\n    selected_version = None\n    selected_presence = None\n\n    for pm in pms:\n        if pm.version:\n            if not selected_version:\n                selected_version = pm\n            else:\n                if len(pm.version) > len(selected_version.version):\n                    selected_version = pm\n        elif pm.presence:\n            selected_presence = pm\n\n    return selected_version or selected_presence", "response": "Return the most complete plugin with longer version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef docker_container():\n    if SETUP_SPLASH:\n        dm = DockerManager()\n        dm.start_container()\n\n    try:\n        requests.post(f'{SPLASH_URL}/_gc')\n    except requests.exceptions.RequestException:\n        pass\n\n    yield", "response": "Start the Splash server on a Docker container."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_url_allowed(url):\n    blacklist = [\n        r'\\.ttf', r'\\.woff', r'fonts\\.googleapis\\.com', r'\\.png', r'\\.jpe?g', r'\\.gif',\n        r'\\.svg'\n    ]\n\n    for ft in blacklist:\n        if re.search(ft, url):\n            return False\n\n    return True", "response": "Return True if url is allowed in the base base."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid_mimetype(response):\n    blacklist = [\n        'image/',\n    ]\n\n    mimetype = response.get('mimeType')\n    if not mimetype:\n        return True\n\n    for bw in blacklist:\n        if bw in mimetype:\n            return False\n\n    return True", "response": "Return True if the mimetype is blacklisted."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_charset(response):\n    # Set default charset\n    charset = DEFAULT_CHARSET\n\n    m = re.findall(r';charset=(.*)', response.get('mimeType', ''))\n    if m:\n        charset = m[0]\n\n    return charset", "response": "Return charset from response or default charset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_lua_script(plugins):\n    lua_template = pkg_resources.resource_string('detectem', 'script.lua')\n    template = Template(lua_template.decode('utf-8'))\n\n    javascript_data = to_javascript_data(plugins)\n\n    return template.substitute(js_data=json.dumps(javascript_data))", "response": "Create a script template filled up with plugin javascript data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_javascript_data(plugins):\n\n    def escape(v):\n        return re.sub(r'\"', r'\\\\\"', v)\n\n    def dom_matchers(p):\n        dom_matchers = p.get_matchers('dom')\n        escaped_dom_matchers = []\n\n        for dm in dom_matchers:\n            check_statement, version_statement = dm\n\n            escaped_dom_matchers.append({\n                'check_statement': escape(check_statement),\n                # Escape '' and not None\n                'version_statement': escape(version_statement or ''),\n            })\n\n        return escaped_dom_matchers\n\n    return [{'name': p.name, 'matchers': dom_matchers(p)}\n            for p in plugins.with_dom_matchers()]", "response": "Returns a dictionary with all JavaScript matchers. Quotes are escaped."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_response(url, plugins, timeout=SPLASH_TIMEOUT):\n    lua_script = create_lua_script(plugins)\n    lua = urllib.parse.quote_plus(lua_script)\n    page_url = f'{SPLASH_URL}/execute?url={url}&timeout={timeout}&lua_source={lua}'\n\n    try:\n        with docker_container():\n            logger.debug('[+] Sending request to Splash instance')\n            res = requests.get(page_url)\n    except requests.exceptions.ConnectionError:\n        raise SplashError(\"Could not connect to Splash server {}\".format(SPLASH_URL))\n\n    logger.debug('[+] Response received')\n\n    json_data = res.json()\n\n    if res.status_code in ERROR_STATUS_CODES:\n        raise SplashError(get_splash_error(json_data))\n\n    softwares = json_data['softwares']\n    scripts = json_data['scripts'].values()\n    har = get_valid_har(json_data['har'])\n\n    js_error = get_evaljs_error(json_data)\n    if js_error:\n        logger.debug('[+] WARNING: failed to eval JS matchers: %(n)s', {'n': js_error})\n    else:\n        logger.debug('[+] Detected %(n)d softwares from the DOM', {'n': len(softwares)})\n    logger.debug('[+] Detected %(n)d scripts from the DOM', {'n': len(scripts)})\n    logger.debug('[+] Final HAR has %(n)d valid entries', {'n': len(har)})\n\n    return {'har': har, 'scripts': scripts, 'softwares': softwares}", "response": "Get response from Splash server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn list of valid HAR entries.", "response": "def get_valid_har(har_data):\n    \"\"\" Return list of valid HAR entries.\n\n    :rtype: list\n\n    \"\"\"\n    new_entries = []\n    entries = har_data.get('log', {}).get('entries', [])\n    logger.debug('[+] Detected %(n)d entries in HAR', {'n': len(entries)})\n\n    for entry in entries:\n        url = entry['request']['url']\n        if not is_url_allowed(url):\n            continue\n\n        response = entry['response']['content']\n        if not is_valid_mimetype(response):\n            continue\n\n        if response.get('text'):\n            charset = get_charset(response)\n            response['text'] = base64.b64decode(response['text']).decode(charset)\n        else:\n            response['text'] = ''\n\n        new_entries.append(entry)\n\n        logger.debug('[+] Added URL: %(url)s ...', {'url': url[:100]})\n\n    return new_entries"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_files_from_github(user_and_repo, filedir, regex, prefer_tags):\n    ''' Return dictionary of version:directory and directory has extracted files. '''\n    github_url = f'https://api.github.com/repos/{user_and_repo}'\n    args = f'?per_page={N_RESULTS}'\n    results = []\n    json_data = None\n\n    # Determine the right url\n    if not prefer_tags:\n        url = f'{github_url}/releases{args}'\n        json_data = requests.get(url).json()\n\n    if not json_data:\n        url = f'{github_url}/tags{args}'\n        json_data = requests.get(url).json()\n\n    logger.debug(f'[+] Using {url} as base url.')\n\n    # Get all the releases/tags available\n    results = json_data\n    for n_page in range(2, 1000):\n        logger.debug(f'[+] Requesting page {n_page} of releases/tags ..')\n        json_data = requests.get(f'{url}&page={n_page}').json()\n        results += json_data\n\n        if len(json_data) < N_RESULTS:\n            break\n\n    if not results:\n        raise ValueError(f'No releases/tags for {user_and_repo}')\n\n    directories = {}\n    for result in results:\n        name = result['name']\n        m = re.match(regex, name)\n        if not m:\n            continue\n\n        name = m.groups()[0]\n\n        logger.debug(f'[+] Downloading zip file for {name} version ..')\n\n        # Download zip file and extract in temporary directory\n        zip_url = result['zipball_url']\n        zf = requests.get(zip_url, allow_redirects=True)\n        z = zipfile.ZipFile(io.BytesIO(zf.content))\n        output_dir = f'{filedir}/{z.namelist()[0]}'\n\n        z.extractall(path=filedir)\n        directories[name] = output_dir\n\n    return directories", "response": "Download and extract files from github."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn entry for embed script", "response": "def _script_to_har_entry(cls, script, url):\n        ''' Return entry for embed script '''\n        entry = {\n            'request': {'url': url},\n            'response': {'url': url, 'content': {'text': script}}\n        }\n\n        cls._set_entry_type(entry, INLINE_SCRIPT_ENTRY)\n\n        return entry"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmark one entry as main entry and the rest as resource entry.", "response": "def mark_entries(self, entries):\n        ''' Mark one entry as main entry and the rest as resource entry.\n\n            Main entry is the entry that contain response's body\n            of the requested URL.\n        '''\n\n        for entry in entries:\n            self._set_entry_type(entry, RESOURCE_ENTRY)\n\n        # If first entry doesn't have a redirect, set is as main entry\n        main_entry = entries[0]\n        main_location = self._get_location(main_entry)\n        if not main_location:\n            self._set_entry_type(main_entry, MAIN_ENTRY)\n            return\n\n        # Resolve redirected URL and see if it's in the rest of entries\n        main_url = urllib.parse.urljoin(get_url(main_entry), main_location)\n        for entry in entries[1:]:\n            url = get_url(entry)\n            if url == main_url:\n                self._set_entry_type(entry, MAIN_ENTRY)\n                break\n        else:\n            # In fail case, set the first entry\n            self._set_entry_type(main_entry, MAIN_ENTRY)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning plugin hints from plugin.", "response": "def get_hints(self, plugin):\n        ''' Return plugin hints from ``plugin``. '''\n        hints = []\n\n        for hint_name in getattr(plugin, 'hints', []):\n            hint_plugin = self._plugins.get(hint_name)\n            if hint_plugin:\n                hint_result = Result(\n                    name=hint_plugin.name,\n                    homepage=hint_plugin.homepage,\n                    from_url=self.requested_url,\n                    type=HINT_TYPE,\n                    plugin=plugin.name,\n                )\n                hints.append(hint_result)\n\n                logger.debug(f'{plugin.name} & hint {hint_result.name} detected')\n            else:\n                logger.error(f'{plugin.name} hints an invalid plugin: {hint_name}')\n\n        return hints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding softwares found in the DOM", "response": "def process_from_splash(self):\n        ''' Add softwares found in the DOM '''\n        for software in self._softwares_from_splash:\n            plugin = self._plugins.get(software['name'])\n\n            # Determine if it's a version or presence result\n            try:\n                additional_data = {'version': software['version']}\n            except KeyError:\n                additional_data = {'type': INDICATOR_TYPE}\n\n            self._results.add_result(\n                Result(\n                    name=plugin.name,\n                    homepage=plugin.homepage,\n                    from_url=self.requested_url,\n                    plugin=plugin.name,\n                    **additional_data,\n                )\n            )\n\n            for hint in self.get_hints(plugin):\n                self._results.add_result(hint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses the HAR file and return a list of results.", "response": "def process_har(self):\n        \"\"\" Detect plugins present in the page. \"\"\"\n        hints = []\n\n        version_plugins = self._plugins.with_version_matchers()\n        generic_plugins = self._plugins.with_generic_matchers()\n\n        for entry in self.har:\n            for plugin in version_plugins:\n                pm = self.apply_plugin_matchers(plugin, entry)\n                if not pm:\n                    continue\n\n                # Set name if matchers could detect modular name\n                if pm.name:\n                    name = '{}-{}'.format(plugin.name, pm.name)\n                else:\n                    name = plugin.name\n\n                if pm.version:\n                    self._results.add_result(\n                        Result(\n                            name=name,\n                            version=pm.version,\n                            homepage=plugin.homepage,\n                            from_url=get_url(entry),\n                            plugin=plugin.name,\n                        )\n                    )\n                elif pm.presence:\n                    # Try to get version through file hashes\n                    version = get_version_via_file_hashes(plugin, entry)\n                    if version:\n                        self._results.add_result(\n                            Result(\n                                name=name,\n                                version=version,\n                                homepage=plugin.homepage,\n                                from_url=get_url(entry),\n                                plugin=plugin.name,\n                            )\n                        )\n                    else:\n                        self._results.add_result(\n                            Result(\n                                name=name,\n                                homepage=plugin.homepage,\n                                from_url=get_url(entry),\n                                type=INDICATOR_TYPE,\n                                plugin=plugin.name,\n                            )\n                        )\n                hints += self.get_hints(plugin)\n\n            for plugin in generic_plugins:\n                pm = self.apply_plugin_matchers(plugin, entry)\n                if not pm:\n                    continue\n\n                plugin_data = plugin.get_information(entry)\n\n                # Only add to results if it's a valid result\n                if 'name' in plugin_data:\n                    self._results.add_result(\n                        Result(\n                            name=plugin_data['name'],\n                            homepage=plugin_data['homepage'],\n                            from_url=get_url(entry),\n                            type=GENERIC_TYPE,\n                            plugin=plugin.name,\n                        )\n                    )\n\n                hints += self.get_hints(plugin)\n\n        for hint in hints:\n            self._results.add_result(hint)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_results(self, metadata=False):\n        results_data = []\n\n        self.process_har()\n        self.process_from_splash()\n\n        for rt in sorted(self._results.get_results()):\n            rdict = {'name': rt.name}\n            if rt.version:\n                rdict['version'] = rt.version\n\n            if metadata:\n                rdict['homepage'] = rt.homepage\n                rdict['type'] = rt.type\n                rdict['from_url'] = rt.from_url\n                rdict['plugin'] = rt.plugin\n\n            results_data.append(rdict)\n\n        return results_data", "response": "Return the results of the analysis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_plugins():\n    loader = _PluginLoader()\n\n    for pkg in PLUGIN_PACKAGES:\n        loader.load_plugins(pkg)\n\n    return loader.plugins", "response": "Load all the plugins in the current project."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of every module in plugin_dir.", "response": "def _get_plugin_module_paths(self, plugin_dir):\n        ''' Return a list of every module in `plugin_dir`. '''\n        filepaths = [\n            fp for fp in glob.glob('{}/**/*.py'.format(plugin_dir), recursive=True)\n            if not fp.endswith('__init__.py')\n        ]\n        rel_paths = [re.sub(plugin_dir.rstrip('/') + '/', '', fp) for fp in filepaths]\n        module_paths = [rp.replace('/', '.').replace('.py', '') for rp in rel_paths]\n\n        return module_paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the plugin is ok.", "response": "def _is_plugin_ok(self, instance):\n        ''' Return `True` if:\n        1. Plugin meets plugin interface.\n        2. Is not already registered in the plugin collection.\n        3. Have accepted tags.\n\n        Otherwise, return `False` and log warnings.\n\n        '''\n        try:\n            verifyObject(IPlugin, instance)\n        except BrokenImplementation:\n            logger.warning(\n                \"Plugin '%(name)s' doesn't provide the plugin interface\",\n                {'name': self._full_class_name(instance)}\n            )\n            return False\n\n        # Check if the plugin is already registered\n        reg = self.plugins.get(instance.name)\n        if reg:\n            logger.warning(\n                \"Plugin '%(name)s' by '%(instance)s' is already provided by '%(reg)s'\", {\n                    'name': instance.name, 'instance': self._full_class_name(instance),\n                    'reg': self._full_class_name(reg)\n                }\n            )\n            return False\n\n        for tag in instance.tags:\n            if tag not in PLUGIN_TAGS:\n                logger.warning(\n                    \"Invalid tag '%(tag)s' in '%(instance)s'\",\n                    {'tag': tag, 'instance': self._full_class_name(instance)}\n                )\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading plugins from plugins_package module.", "response": "def load_plugins(self, plugins_package):\n        ''' Load plugins from `plugins_package` module. '''\n        try:\n            # Resolve directory in the filesystem\n            plugin_dir = find_spec(plugins_package).submodule_search_locations[0]\n        except ImportError:\n            logger.error(\n                \"Could not load plugins package '%(pkg)s'\", {'pkg': plugins_package}\n            )\n            return\n\n        for module_path in self._get_plugin_module_paths(plugin_dir):\n            # Load the module dynamically\n            spec = find_spec('{}.{}'.format(plugins_package, module_path))\n            m = module_from_spec(spec)\n            spec.loader.exec_module(m)\n\n            # Get classes from module and extract the plugin classes\n            classes = inspect.getmembers(m, predicate=inspect.isclass)\n            for _, klass in classes:\n                # Avoid imports processing\n                if klass.__module__ != spec.name:\n                    continue\n\n                # Avoid classes not ending in Plugin\n                if not klass.__name__.endswith('Plugin'):\n                    continue\n\n                instance = klass()\n                if self._is_plugin_ok(instance):\n                    self.plugins.add(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the named_group match from text reached by using a matcher from matchers.", "response": "def extract_named_group(text, named_group, matchers, return_presence=False):\n    ''' Return ``named_group`` match from ``text`` reached\n        by using a matcher from ``matchers``.\n\n        It also supports matching without a ``named_group`` in a matcher,\n        which sets ``presence=True``.\n\n        ``presence`` is only returned if ``return_presence=True``.\n\n    '''\n    presence = False\n\n    for matcher in matchers:\n        if isinstance(matcher, str):\n            v = re.search(matcher, text, flags=re.DOTALL)\n            if v:\n                dict_result = v.groupdict()\n                try:\n                    return dict_result[named_group]\n                except KeyError:\n                    if dict_result:\n                        # It's other named group matching, discard\n                        continue\n                    else:\n                        # It's a matcher without named_group\n                        # but we can't return it until every matcher pass\n                        # because a following matcher could have a named group\n                        presence = True\n        elif callable(matcher):\n            v = matcher(text)\n            if v:\n                return v\n\n    if return_presence and presence:\n        return 'presence'\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parsed(self):\n        return BeautifulSoup(\n            self.response.content,\n            features=self.browser.parser,\n        )", "response": "Lazily parse response content using HTML parser specified by the\n            browser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_send_args(self, **kwargs):\n        out = {}\n        out.update(self._default_send_args)\n        out.update(kwargs)\n        return out", "response": "Merge optional arguments with defaults."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a URL. :param str url: URL to open :param str method: Optional method; defaults to `'get'` :param kwargs: Keyword arguments to `Session::request`", "response": "def open(self, url, method='get', **kwargs):\n        \"\"\"Open a URL.\n\n        :param str url: URL to open\n        :param str method: Optional method; defaults to `'get'`\n        :param kwargs: Keyword arguments to `Session::request`\n\n        \"\"\"\n        response = self.session.request(method, url, **self._build_send_args(**kwargs))\n        self._update_state(response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_state(self, response):\n        # Clear trailing states\n        self._states = self._states[:self._cursor + 1]\n\n        # Append new state\n        state = RoboState(self, response)\n        self._states.append(state)\n        self._cursor += 1\n\n        # Clear leading states\n        if self._maxlen:\n            decrement = len(self._states) - self._maxlen\n            if decrement > 0:\n                self._states = self._states[decrement:]\n                self._cursor -= decrement", "response": "Update the state of the browser. Create a new state object and append to or overwrite the browser s state history."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _traverse(self, n=1):\n        if not self.history:\n            raise exceptions.RoboError('Not tracking history')\n        cursor = self._cursor + n\n        if cursor >= len(self._states) or cursor < 0:\n            raise exceptions.RoboError('Index out of range')\n        self._cursor = cursor", "response": "Traverse the browser history. Used by back and forward methods."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind an anchor or button by containing text as well as standard BeautifulSoup arguments.", "response": "def get_link(self, text=None, *args, **kwargs):\n        \"\"\"Find an anchor or button by containing text, as well as standard\n        BeautifulSoup arguments.\n\n        :param text: String or regex to be matched in link text\n        :return: BeautifulSoup tag if found, else None\n\n        \"\"\"\n        return helpers.find(\n            self.parsed, _link_ptn, text=text, *args, **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_links(self, text=None, *args, **kwargs):\n        return helpers.find_all(\n            self.parsed, _link_ptn, text=text, *args, **kwargs\n        )", "response": "Find anchors or buttons by containing text as well as standard\n        BeautifulSoup arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds form by ID as well as standard BeautifulSoup arguments.", "response": "def get_form(self, id=None, *args, **kwargs):\n        \"\"\"Find form by ID, as well as standard BeautifulSoup arguments.\n\n        :param str id: Form ID\n        :return: BeautifulSoup tag if found, else None\n\n        \"\"\"\n        if id:\n            kwargs['id'] = id\n        form = self.find(_form_ptn, *args, **kwargs)\n        if form is not None:\n            return Form(form)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds forms by standard BeautifulSoup arguments.", "response": "def get_forms(self, *args, **kwargs):\n        \"\"\"Find forms by standard BeautifulSoup arguments.\n        :args: Positional arguments to `BeautifulSoup::find_all`\n        :args: Keyword arguments to `BeautifulSoup::find_all`\n\n        :return: List of BeautifulSoup tags\n\n        \"\"\"\n        forms = self.find_all(_form_ptn, *args, **kwargs)\n        return [\n            Form(form)\n            for form in forms\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclicks a link. :param Tag link: Link to click :param kwargs: Keyword arguments to `Session::send`", "response": "def follow_link(self, link, **kwargs):\n        \"\"\"Click a link.\n\n        :param Tag link: Link to click\n        :param kwargs: Keyword arguments to `Session::send`\n\n        \"\"\"\n        try:\n            href = link['href']\n        except KeyError:\n            raise exceptions.RoboError('Link element must have \"href\" '\n                                       'attribute')\n        self.open(self._build_url(href), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubmit a form. :param Form form: Filled-out form object :param Submit submit: Optional `Submit` to click, if form includes multiple submits :param kwargs: Keyword arguments to `Session::send`", "response": "def submit_form(self, form, submit=None, **kwargs):\n        \"\"\"Submit a form.\n\n        :param Form form: Filled-out form object\n        :param Submit submit: Optional `Submit` to click, if form includes\n            multiple submits\n        :param kwargs: Keyword arguments to `Session::send`\n\n        \"\"\"\n        # Get HTTP verb\n        method = form.method.upper()\n\n        # Send request\n        url = self._build_url(form.action) or self.url\n        payload = form.serialize(submit=submit)\n        serialized = payload.to_requests(method)\n        send_args = self._build_send_args(**kwargs)\n        send_args.update(serialized)\n        response = self.session.request(method, url, **send_args)\n\n        # Update history\n        self._update_state(response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(soup, name=None, attrs=None, recursive=True, text=None, **kwargs):\n    tags = find_all(\n        soup, name, attrs or {}, recursive, text, 1, **kwargs\n    )\n    if tags:\n        return tags[0]", "response": "Modified find method ; see find_all."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncoerces a value to Tag or list of Tags .", "response": "def ensure_soup(value, parser=None):\n    \"\"\"Coerce a value (or list of values) to Tag (or list of Tag).\n\n    :param value: String, BeautifulSoup, Tag, or list of the above\n    :param str parser: Parser to use; defaults to BeautifulSoup default\n    :return: Tag or list of Tags\n\n    \"\"\"\n    if isinstance(value, BeautifulSoup):\n        return value.find()\n    if isinstance(value, Tag):\n        return value\n    if isinstance(value, list):\n        return [\n            ensure_soup(item, parser=parser)\n            for item in value\n        ]\n    parsed = BeautifulSoup(value, features=parser)\n    return parsed.find()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlowers - case all attribute names of the provided BeautifulSoup tag.", "response": "def lowercase_attr_names(tag):\n    \"\"\"Lower-case all attribute names of the provided BeautifulSoup tag.\n    Note: this mutates the tag's attribute names and does not return a new\n    tag.\n\n    :param Tag: BeautifulSoup tag\n\n    \"\"\"\n    # Use list comprehension instead of dict comprehension for 2.6 support\n    tag.attrs = dict([\n        (key.lower(), value)\n        for key, value in iteritems(tag.attrs)\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_initial(self, initial):\n        super(Select, self)._set_initial(initial)\n        if not self._value and self.options:\n            self.value = self.options[0]", "response": "Set the initial value of the option."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode_if_py2(func):\n    if not PY2:\n        return func\n    def wrapped(*args, **kwargs):\n        ret = func(*args, **kwargs)\n        if not isinstance(ret, unicode):\n            raise TypeError('Wrapped function must return `unicode`')\n        return ret.encode('utf-8', 'ignore')\n    return wrapped", "response": "Decorate a function to encode unicode return value\nAttributeNames to UTF - 8 ; else noop."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreducing size of cache by date.", "response": "def _reduce_age(self, now):\n        \"\"\"Reduce size of cache by date.\n\n        :param datetime.datetime now: Current time\n\n        \"\"\"\n        if self.max_age:\n            keys = [\n                key for key, value in iteritems(self.data)\n                if now - value['date'] > self.max_age\n            ]\n            for key in keys:\n                del self.data[key]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _reduce_count(self):\n        if self.max_count:\n            while len(self.data) > self.max_count:\n                self.data.popitem(last=False)", "response": "Reduce size of cache by count."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef store(self, response):\n        if response.status_code not in CACHE_CODES:\n            return\n        now = datetime.datetime.now()\n        self.data[response.url] = {\n            'date': now,\n            'response': response,\n        }\n        logger.info('Stored response in cache')\n        self._reduce_age(now)\n        self._reduce_count()", "response": "Store a response in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retrieve(self, request):\n        if request.method not in CACHE_VERBS:\n            return\n        try:\n            response = self.data[request.url]['response']\n            logger.info('Retrieved response from cache')\n            return response\n        except KeyError:\n            return None", "response": "Retrieve the response from cache if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _group_flat_tags(tag, tags):\n    grouped = [tag]\n    name = tag.get('name', '').lower()\n    while tags and tags[0].get('name', '').lower() == name:\n        grouped.append(tags.pop(0))\n    return grouped", "response": "Extract tags sharing the same name as the provided tag. Used to collect\n    options for radio and checkbox inputs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse form fields from HTML.", "response": "def _parse_fields(parsed):\n    \"\"\"Parse form fields from HTML.\n\n    :param BeautifulSoup parsed: Parsed HTML\n    :return OrderedDict: Collection of field objects\n\n    \"\"\"\n    # Note: Call this `out` to avoid name conflict with `fields` module\n    out = []\n\n    # Prepare field tags\n    tags = parsed.find_all(_tag_ptn)\n    for tag in tags:\n        helpers.lowercase_attr_names(tag)\n\n    while tags:\n        tag = tags.pop(0)\n        try:\n            field = _parse_field(tag, tags)\n        except exceptions.InvalidNameError:\n            continue\n        if field is not None:\n            out.append(field)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, data, key=None):\n        sink = self.options[key] if key is not None else self.data\n        for key, value in iteritems(data):\n            sink.add(key, value)", "response": "Add field values to container."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_requests(self, method='get'):\n        out = {}\n        data_key = 'params' if method.lower() == 'get' else 'data'\n        out[data_key] = self.data\n        out.update(self.options)\n        return dict([\n            (key, list(value.items(multi=True)))\n            for key, value in iteritems(out)\n        ])", "response": "Export to Requests format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_field(self, field):\n        if not isinstance(field, fields.BaseField):\n            raise ValueError('Argument \"field\" must be an instance of '\n                             'BaseField')\n        self.fields.add(field.name, field)", "response": "Add a field to the set of related objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing each form field to a Payload container.", "response": "def serialize(self, submit=None):\n        \"\"\"Serialize each form field to a Payload container.\n\n        :param Submit submit: Optional `Submit` to click, if form includes\n            multiple submits\n        :return: Payload instance\n\n        \"\"\"\n        include_fields = prepare_fields(self.fields, self.submit_fields, submit)\n        return Payload.from_fields(include_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, path):\n\n        path = path.strip('/')\n        self.log.info('Appmode get: %s', path)\n\n        # Abort if the app path is not below configured trusted_path.\n        if not path.startswith(self.trusted_path):\n            self.log.warn('Appmode refused to launch %s outside trusted path %s.', path, self.trusted_path)\n            raise web.HTTPError(401, 'Notebook is not within trusted Appmode path.')\n\n        cm = self.contents_manager\n\n        # will raise 404 on not found\n        try:\n            model = cm.get(path, content=False)\n        except web.HTTPError as e:\n            if e.status_code == 404 and 'files' in path.split('/'):\n                # 404, but '/files/' in URL, let FilesRedirect take care of it\n                return FilesRedirectHandler.redirect_to_files(self, path)\n            else:\n                raise\n        if model['type'] != 'notebook':\n            # not a notebook, redirect to files\n            return FilesRedirectHandler.redirect_to_files(self, path)\n\n        # fix back button navigation\n        self.add_header(\"Cache-Control\", \"cache-control: private, max-age=0, no-cache, no-store\")\n\n        # gather template parameters\n        tmp_path = self.mk_tmp_copy(path)\n        tmp_name = tmp_path.rsplit('/', 1)[-1]\n        render_kwargs = {\n            'notebook_path': tmp_path,\n            'notebook_name': tmp_name,\n            'kill_kernel': False,\n            'mathjax_url': self.mathjax_url,\n            'mathjax_config': self.mathjax_config,\n            'show_edit_button': self.show_edit_button,\n            'show_other_buttons': self.show_other_buttons,\n        }\n\n        # template parameters changed over time\n        if hasattr(orig_handler, \"get_custom_frontend_exporters\"):\n            get_cfw = orig_handler.get_custom_frontend_exporters\n            render_kwargs['get_custom_frontend_exporters'] = get_cfw\n\n        # Ok let's roll ....\n        self.write(self.render_template('appmode.html', **render_kwargs))", "response": "Get the contents of a notebook at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the object to Redis.", "response": "async def save(self, db):\n        \"\"\"Save the object to Redis.\n        \"\"\"\n        kwargs = {}\n        for col in self._auto_columns:\n            if not self.has_real_data(col.name):\n                kwargs[col.name] = await col.auto_generate(db, self)\n        self.__dict__.update(kwargs)\n\n        # we have to delete the old index key\n        stale_object = await self.__class__.load(db, identifier=self.identifier())\n        d = {\n            k: (v.strftime(DATETIME_FORMAT) if isinstance(v, datetime) else v)\n            for k, v in self.__dict__.items()\n        }\n        success = await db.hmset_dict(self.redis_key(), d)\n        await self.save_index(db, stale_object=stale_object)\n        return success"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the object from redis.", "response": "async def load(cls, db, identifier=None, redis_key=None):\n        \"\"\"Load the object from redis. Use the identifier (colon-separated\n        composite keys or the primary key) or the redis_key.\n        \"\"\"\n        if not identifier and not redis_key:\n            raise InvalidQuery('Must supply identifier or redis_key')\n        if redis_key is None:\n            redis_key = cls.make_key(identifier)\n        if await db.exists(redis_key):\n            data = await db.hgetall(redis_key)\n            kwargs = {}\n            for key_bin, value_bin in data.items():\n                key, value = key_bin, value_bin\n                column = getattr(cls, key, False)\n                if not column or (column.field_type == str):\n                    kwargs[key] = value\n                elif column.field_type == datetime:\n                    kwargs[key] = datetime.strptime(value, DATETIME_FORMAT)\n                else:\n                    kwargs[key] = column.field_type(value)\n            kwargs['loading'] = True\n            return cls(**kwargs)\n        else:\n            logger.debug(\"No Redis key found: {}\".format(redis_key))\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries by attributes iteratively.", "response": "async def filter_by(cls, db, offset=None, limit=None, **kwargs):\n        \"\"\"Query by attributes iteratively. Ordering is not supported\n        Example:\n            User.get_by(db, age=[32, 54])\n            User.get_by(db, age=23, name=\"guido\")\n\n        \"\"\"\n        if limit and type(limit) is not int:\n            raise InvalidQuery('If limit is supplied it must be an int')\n        if offset and type(offset) is not int:\n            raise InvalidQuery('If offset is supplied it must be an int')\n\n        ids_to_iterate = await cls._get_ids_filter_by(db, **kwargs)\n        if offset:\n            # Using offset without order_by is pretty strange, but allowed\n            if limit:\n                ids_to_iterate = ids_to_iterate[offset:offset+limit]\n            else:\n                ids_to_iterate = ids_to_iterate[offset:]\n        elif limit:\n            ids_to_iterate = ids_to_iterate[:limit]\n\n        for key in ids_to_iterate:\n            yield await cls.load(db, key)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_object_or_none(cls, db, **kwargs):\n        async for obj in cls.filter_by(db, limit=1, **kwargs):\n            return obj\n        return None", "response": "Get the first object in the database or None if no object exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_address(address):\n    if isinstance(address, tuple):\n        check_host(address[0])\n        check_port(address[1])\n    elif isinstance(address, string_types):\n        if os.name != 'posix':\n            raise ValueError('Platform does not support UNIX domain sockets')\n        if not (os.path.exists(address) or\n                os.access(os.path.dirname(address), os.W_OK)):\n            raise ValueError('ADDRESS not a valid socket domain socket ({0})'\n                             .format(address))\n    else:\n        raise ValueError('ADDRESS is not a tuple, string, or character buffer '\n                         '({0})'.format(type(address).__name__))", "response": "Check if the format of the given address is correct for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_addresses(address_list, is_remote=False):\n    assert all(isinstance(x, (tuple, string_types)) for x in address_list)\n    if (is_remote and any(isinstance(x, string_types) for x in address_list)):\n        raise AssertionError('UNIX domain sockets not allowed for remote'\n                             'addresses')\n\n    for address in address_list:\n        check_address(address)", "response": "Checks if the format of the addresses is correct for the internal structures in the base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_logger(logger=None,\n                  loglevel=None,\n                  capture_warnings=True,\n                  add_paramiko_handler=True):\n    \"\"\"\n    Attach or create a new logger and add a console handler if not present\n\n    Arguments:\n\n        logger (Optional[logging.Logger]):\n            :class:`logging.Logger` instance; a new one is created if this\n            argument is empty\n\n        loglevel (Optional[str or int]):\n            :class:`logging.Logger`'s level, either as a string (i.e.\n            ``ERROR``) or in numeric format (10 == ``DEBUG``)\n\n            .. note:: a value of 1 == ``TRACE`` enables Tracing mode\n\n        capture_warnings (boolean):\n            Enable/disable capturing the events logged by the warnings module\n            into ``logger``'s handlers\n\n            Default: True\n\n            .. note:: ignored in python 2.6\n\n        add_paramiko_handler (boolean):\n            Whether or not add a console handler for ``paramiko.transport``'s\n            logger if no handler present\n\n            Default: True\n    Return:\n        :class:`logging.Logger`\n    \"\"\"\n    logger = logger or logging.getLogger(\n        '{0}.SSHTunnelForwarder'.format(__name__)\n    )\n    if not any(isinstance(x, logging.Handler) for x in logger.handlers):\n        logger.setLevel(loglevel or DEFAULT_LOGLEVEL)\n        console_handler = logging.StreamHandler()\n        _add_handler(logger,\n                     handler=console_handler,\n                     loglevel=loglevel or DEFAULT_LOGLEVEL)\n    if loglevel:  # override if loglevel was set\n        logger.setLevel(loglevel)\n        for handler in logger.handlers:\n            handler.setLevel(loglevel)\n\n    if add_paramiko_handler:\n        _check_paramiko_handlers(logger=logger)\n\n    if capture_warnings and sys.version_info >= (2, 7):\n        logging.captureWarnings(True)\n        pywarnings = logging.getLogger('py.warnings')\n        pywarnings.handlers.extend(logger.handlers)\n    return logger", "response": "Create a new logger instance and add a console handler if not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_handler(logger, handler=None, loglevel=None):\n    handler.setLevel(loglevel or DEFAULT_LOGLEVEL)\n    if handler.level <= logging.DEBUG:\n        _fmt = '%(asctime)s| %(levelname)-4.3s|%(threadName)10.9s/' \\\n               '%(lineno)04d@%(module)-10.9s| %(message)s'\n        handler.setFormatter(logging.Formatter(_fmt))\n    else:\n        handler.setFormatter(logging.Formatter(\n            '%(asctime)s| %(levelname)-8s| %(message)s'\n        ))\n    logger.addHandler(handler)", "response": "Add a handler to a logging. Logger object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a console handler for paramiko. transport s logger if not present.", "response": "def _check_paramiko_handlers(logger=None):\n    \"\"\"\n    Add a console handler for paramiko.transport's logger if not present\n    \"\"\"\n    paramiko_logger = logging.getLogger('paramiko.transport')\n    if not paramiko_logger.handlers:\n        if logger:\n            paramiko_logger.handlers = logger.handlers\n        else:\n            console_handler = logging.StreamHandler()\n            console_handler.setFormatter(\n                logging.Formatter('%(asctime)s | %(levelname)-8s| PARAMIKO: '\n                                  '%(lineno)03d@%(module)-10s| %(message)s')\n            )\n            paramiko_logger.addHandler(console_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all keys whose value is None", "response": "def _remove_none_values(dictionary):\n    \"\"\" Remove dictionary keys whose value is None \"\"\"\n    return list(map(dictionary.pop,\n                    [i for i in dictionary if dictionary[i] is None]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen an SSH tunnel and return a new SSHTunnel object.", "response": "def open_tunnel(*args, **kwargs):\n    \"\"\"\n    Open an SSH Tunnel, wrapper for :class:`SSHTunnelForwarder`\n\n    Arguments:\n        destination (Optional[tuple]):\n            SSH server's IP address and port in the format\n            (``ssh_address``, ``ssh_port``)\n\n    Keyword Arguments:\n        debug_level (Optional[int or str]):\n            log level for :class:`logging.Logger` instance, i.e. ``DEBUG``\n\n        skip_tunnel_checkup (boolean):\n            Enable/disable the local side check and populate\n            :attr:`~SSHTunnelForwarder.tunnel_is_up`\n\n            Default: True\n\n            .. versionadded:: 0.1.0\n\n    .. note::\n        A value of ``debug_level`` set to 1 == ``TRACE`` enables tracing mode\n    .. note::\n        See :class:`SSHTunnelForwarder` for keyword arguments\n\n    **Example**::\n\n        from sshtunnel import open_tunnel\n\n        with open_tunnel(SERVER,\n                         ssh_username=SSH_USER,\n                         ssh_port=22,\n                         ssh_password=SSH_PASSWORD,\n                         remote_bind_address=(REMOTE_HOST, REMOTE_PORT),\n                         local_bind_address=('', LOCAL_PORT)) as server:\n            def do_something(port):\n                pass\n\n            print(\"LOCAL PORTS:\", server.local_bind_port)\n\n            do_something(server.local_bind_port)\n    \"\"\"\n    # Attach a console handler to the logger or create one if not passed\n    kwargs['logger'] = create_logger(logger=kwargs.get('logger', None),\n                                     loglevel=kwargs.pop('debug_level', None))\n\n    ssh_address_or_host = kwargs.pop('ssh_address_or_host', None)\n    # Check if deprecated arguments ssh_address or ssh_host were used\n    for deprecated_argument in ['ssh_address', 'ssh_host']:\n        ssh_address_or_host = SSHTunnelForwarder._process_deprecated(\n            ssh_address_or_host,\n            deprecated_argument,\n            kwargs\n        )\n\n    ssh_port = kwargs.pop('ssh_port', None)\n    skip_tunnel_checkup = kwargs.pop('skip_tunnel_checkup', True)\n    if not args:\n        if isinstance(ssh_address_or_host, tuple):\n            args = (ssh_address_or_host, )\n        else:\n            args = ((ssh_address_or_host, ssh_port), )\n    forwarder = SSHTunnelForwarder(*args, **kwargs)\n    forwarder.skip_tunnel_checkup = skip_tunnel_checkup\n    return forwarder"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine type of data expected for remote and local bind address lists AttributeNames", "response": "def _bindlist(input_str):\n    \"\"\" Define type of data expected for remote and local bind address lists\n        Returns a tuple (ip_address, port) whose elements are (str, int)\n    \"\"\"\n    try:\n        ip_port = input_str.split(':')\n        if len(ip_port) == 1:\n            _ip = ip_port[0]\n            _port = None\n        else:\n            (_ip, _port) = ip_port\n        if not _ip and not _port:\n            raise AssertionError\n        elif not _port:\n            _port = '22'  # default port if not given\n        return _ip, int(_port)\n    except ValueError:\n        raise argparse.ArgumentTypeError(\n            'Address tuple must be of type IP_ADDRESS:PORT'\n        )\n    except AssertionError:\n        raise argparse.ArgumentTypeError(\"Both IP:PORT can't be missing!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_arguments(args=None):\n    parser = argparse.ArgumentParser(\n        description='Pure python ssh tunnel utils\\n'\n                    'Version {0}'.format(__version__),\n        formatter_class=argparse.RawTextHelpFormatter\n    )\n\n    parser.add_argument(\n        'ssh_address',\n        type=str,\n        help='SSH server IP address (GW for SSH tunnels)\\n'\n             'set with \"-- ssh_address\" if immediately after '\n             '-R or -L'\n    )\n\n    parser.add_argument(\n        '-U', '--username',\n        type=str,\n        dest='ssh_username',\n        help='SSH server account username'\n    )\n\n    parser.add_argument(\n        '-p', '--server_port',\n        type=int,\n        dest='ssh_port',\n        default=22,\n        help='SSH server TCP port (default: 22)'\n    )\n\n    parser.add_argument(\n        '-P', '--password',\n        type=str,\n        dest='ssh_password',\n        help='SSH server account password'\n    )\n\n    parser.add_argument(\n        '-R', '--remote_bind_address',\n        type=_bindlist,\n        nargs='+',\n        default=[],\n        metavar='IP:PORT',\n        required=True,\n        dest='remote_bind_addresses',\n        help='Remote bind address sequence: '\n             'ip_1:port_1 ip_2:port_2 ... ip_n:port_n\\n'\n             'Equivalent to ssh -Lxxxx:IP_ADDRESS:PORT\\n'\n             'If port is omitted, defaults to 22.\\n'\n             'Example: -R 10.10.10.10: 10.10.10.10:5900'\n    )\n\n    parser.add_argument(\n        '-L', '--local_bind_address',\n        type=_bindlist,\n        nargs='*',\n        dest='local_bind_addresses',\n        metavar='IP:PORT',\n        help='Local bind address sequence: '\n             'ip_1:port_1 ip_2:port_2 ... ip_n:port_n\\n'\n             'Elements may also be valid UNIX socket domains: \\n'\n             '/tmp/foo.sock /tmp/bar.sock ... /tmp/baz.sock\\n'\n             'Equivalent to ssh -LPORT:xxxxxxxxx:xxxx, '\n             'being the local IP address optional.\\n'\n             'By default it will listen in all interfaces '\n             '(0.0.0.0) and choose a random port.\\n'\n             'Example: -L :40000'\n    )\n\n    parser.add_argument(\n        '-k', '--ssh_host_key',\n        type=str,\n        help=\"Gateway's host key\"\n    )\n\n    parser.add_argument(\n        '-K', '--private_key_file',\n        dest='ssh_private_key',\n        metavar='KEY_FILE',\n        type=str,\n        help='RSA/DSS/ECDSA private key file'\n    )\n\n    parser.add_argument(\n        '-S', '--private_key_password',\n        dest='ssh_private_key_password',\n        metavar='KEY_PASSWORD',\n        type=str,\n        help='RSA/DSS/ECDSA private key password'\n    )\n\n    parser.add_argument(\n        '-t', '--threaded',\n        action='store_true',\n        help='Allow concurrent connections to each tunnel'\n    )\n\n    parser.add_argument(\n        '-v', '--verbose',\n        action='count',\n        default=0,\n        help='Increase output verbosity (default: {0})'.format(\n            logging.getLevelName(DEFAULT_LOGLEVEL)\n        )\n    )\n\n    parser.add_argument(\n        '-V', '--version',\n        action='version',\n        version='%(prog)s {version}'.format(version=__version__),\n        help='Show version number and quit'\n    )\n\n    parser.add_argument(\n        '-x', '--proxy',\n        type=_bindlist,\n        dest='ssh_proxy',\n        metavar='IP:PORT',\n        help='IP and port of SSH proxy to destination'\n    )\n\n    parser.add_argument(\n        '-c', '--config',\n        type=str,\n        default=SSH_CONFIG_FILE,\n        dest='ssh_config_file',\n        help='SSH configuration file, defaults to {0}'.format(SSH_CONFIG_FILE)\n    )\n\n    parser.add_argument(\n        '-z', '--compress',\n        action='store_true',\n        dest='compression',\n        help='Request server for compression over SSH transport'\n    )\n\n    parser.add_argument(\n        '-n', '--noagent',\n        action='store_false',\n        dest='allow_agent',\n        help='Disable looking for keys from an SSH agent'\n    )\n\n    parser.add_argument(\n        '-d', '--host_pkey_directories',\n        nargs='*',\n        dest='host_pkey_directories',\n        metavar='FOLDER',\n        help='List of directories where SSH pkeys (in the format `id_*`) '\n             'may be found'\n    )\n    return vars(parser.parse_args(args))", "response": "Parse command line arguments passed from CLI"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommand line interface for the open_tunnel command.", "response": "def _cli_main(args=None):\n    \"\"\" Pass input arguments to open_tunnel\n\n        Mandatory: ssh_address, -R (remote bind address list)\n\n        Optional:\n        -U (username) we may gather it from SSH_CONFIG_FILE or current username\n        -p (server_port), defaults to 22\n        -P (password)\n        -L (local_bind_address), default to 0.0.0.0:22\n        -k (ssh_host_key)\n        -K (private_key_file), may be gathered from SSH_CONFIG_FILE\n        -S (private_key_password)\n        -t (threaded), allow concurrent connections over tunnels\n        -v (verbose), up to 3 (-vvv) to raise loglevel from ERROR to DEBUG\n        -V (version)\n        -x (proxy), ProxyCommand's IP:PORT, may be gathered from config file\n        -c (ssh_config), ssh configuration file (defaults to SSH_CONFIG_FILE)\n        -z (compress)\n        -n (noagent), disable looking for keys from an Agent\n        -d (host_pkey_directories), look for keys on these folders\n    \"\"\"\n    arguments = _parse_arguments(args)\n    # Remove all \"None\" input values\n    _remove_none_values(arguments)\n    verbosity = min(arguments.pop('verbose'), 4)\n    levels = [logging.ERROR,\n              logging.WARNING,\n              logging.INFO,\n              logging.DEBUG,\n              TRACE_LEVEL]\n    arguments.setdefault('debug_level', levels[verbosity])\n    with open_tunnel(**arguments) as tunnel:\n        if tunnel.is_alive:\n            input_('''\n\n            Press <Ctrl-C> or <Enter> to stop!\n\n            ''')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a tunnel is up.", "response": "def local_is_up(self, target):\n        \"\"\"\n        Check if a tunnel is up (remote target's host is reachable on TCP\n        target's port)\n\n        Arguments:\n            target (tuple):\n                tuple of type (``str``, ``int``) indicating the listen IP\n                address and port\n        Return:\n            boolean\n\n        .. deprecated:: 0.1.0\n            Replaced by :meth:`.check_tunnels()` and :attr:`.tunnel_is_up`\n        \"\"\"\n        try:\n            check_address(target)\n        except ValueError:\n            self.logger.warning('Target must be a tuple (IP, port), where IP '\n                                'is a string (i.e. \"192.168.0.1\") and port is '\n                                'an integer (i.e. 40000). Alternatively '\n                                'target can be a valid UNIX domain socket.')\n            return False\n\n        if self.skip_tunnel_checkup:  # force tunnel check at this point\n            self.skip_tunnel_checkup = False\n            self.check_tunnels()\n            self.skip_tunnel_checkup = True  # roll it back\n        return self.tunnel_is_up.get(target, True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_ssh_forward_handler_class(self, remote_address_):\n        class Handler(_ForwardHandler):\n            remote_address = remote_address_\n            ssh_transport = self._transport\n            logger = self.logger\n        return Handler", "response": "Make SSH Handler class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking SSH forward proxy server class.", "response": "def _make_ssh_forward_server(self, remote_address, local_bind_address):\n        \"\"\"\n        Make SSH forward proxy Server class\n        \"\"\"\n        _Handler = self._make_ssh_forward_handler_class(remote_address)\n        try:\n            if isinstance(local_bind_address, string_types):\n                forward_maker_class = self._make_unix_ssh_forward_server_class\n            else:\n                forward_maker_class = self._make_ssh_forward_server_class\n            _Server = forward_maker_class(remote_address)\n            ssh_forward_server = _Server(\n                local_bind_address,\n                _Handler,\n                logger=self.logger,\n            )\n\n            if ssh_forward_server:\n                ssh_forward_server.daemon_threads = self.daemon_forward_servers\n                self._server_list.append(ssh_forward_server)\n                self.tunnel_is_up[ssh_forward_server.server_address] = False\n            else:\n                self._raise(\n                    BaseSSHTunnelForwarderError,\n                    'Problem setting up ssh {0} <> {1} forwarder. You can '\n                    'suppress this exception by using the `mute_exceptions`'\n                    'argument'.format(address_to_str(local_bind_address),\n                                      address_to_str(remote_address))\n                )\n        except IOError:\n            self._raise(\n                BaseSSHTunnelForwarderError,\n                \"Couldn't open tunnel {0} <> {1} might be in use or \"\n                \"destination not reachable\".format(\n                    address_to_str(local_bind_address),\n                    address_to_str(remote_address)\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_ssh_config(ssh_host,\n                         ssh_config_file,\n                         ssh_username=None,\n                         ssh_pkey=None,\n                         ssh_port=None,\n                         ssh_proxy=None,\n                         compression=None,\n                         logger=None):\n        \"\"\"\n        Read ssh_config_file and tries to look for user (ssh_username),\n        identityfile (ssh_pkey), port (ssh_port) and proxycommand\n        (ssh_proxy) entries for ssh_host\n        \"\"\"\n        ssh_config = paramiko.SSHConfig()\n        if not ssh_config_file:  # handle case where it's an empty string\n            ssh_config_file = None\n\n        # Try to read SSH_CONFIG_FILE\n        try:\n            # open the ssh config file\n            with open(os.path.expanduser(ssh_config_file), 'r') as f:\n                ssh_config.parse(f)\n            # looks for information for the destination system\n            hostname_info = ssh_config.lookup(ssh_host)\n            # gather settings for user, port and identity file\n            # last resort: use the 'login name' of the user\n            ssh_username = (\n                ssh_username or\n                hostname_info.get('user')\n            )\n            ssh_pkey = (\n                ssh_pkey or\n                hostname_info.get('identityfile', [None])[0]\n            )\n            ssh_host = hostname_info.get('hostname')\n            ssh_port = ssh_port or hostname_info.get('port')\n\n            proxycommand = hostname_info.get('proxycommand')\n            ssh_proxy = ssh_proxy or (paramiko.ProxyCommand(proxycommand) if\n                                      proxycommand else None)\n            if compression is None:\n                compression = hostname_info.get('compression', '')\n                compression = True if compression.upper() == 'YES' else False\n        except IOError:\n            if logger:\n                logger.warning(\n                    'Could not read SSH configuration file: {0}'\n                    .format(ssh_config_file)\n                )\n        except (AttributeError, TypeError):  # ssh_config_file is None\n            if logger:\n                logger.info('Skipping loading of ssh configuration file')\n        finally:\n            return (ssh_host,\n                    ssh_username or getpass.getuser(),\n                    ssh_pkey,\n                    int(ssh_port) if ssh_port else 22,  # fallback value\n                    ssh_proxy,\n                    compression)", "response": "Read SSH configuration file and return a dict containing the SSH user and password and the SSH proxycommand."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_agent_keys(logger=None):\n        paramiko_agent = paramiko.Agent()\n        agent_keys = paramiko_agent.get_keys()\n        if logger:\n            logger.info('{0} keys loaded from agent'.format(len(agent_keys)))\n        return list(agent_keys)", "response": "Load public keys from any available SSH agent"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_keys(logger=None, host_pkey_directories=None, allow_agent=False):\n        keys = SSHTunnelForwarder.get_agent_keys(logger=logger) \\\n            if allow_agent else []\n\n        if host_pkey_directories is not None:\n            paramiko_key_types = {'rsa': paramiko.RSAKey,\n                                  'dsa': paramiko.DSSKey,\n                                  'ecdsa': paramiko.ECDSAKey,\n                                  'ed25519': paramiko.Ed25519Key}\n            for directory in host_pkey_directories or [DEFAULT_SSH_DIRECTORY]:\n                for keytype in paramiko_key_types.keys():\n                    ssh_pkey_expanded = os.path.expanduser(\n                        os.path.join(directory, 'id_{}'.format(keytype))\n                    )\n                    if os.path.isfile(ssh_pkey_expanded):\n                        ssh_pkey = SSHTunnelForwarder.read_private_key_file(\n                            pkey_file=ssh_pkey_expanded,\n                            logger=logger,\n                            key_type=paramiko_key_types[keytype]\n                        )\n                        if ssh_pkey:\n                            keys.append(ssh_pkey)\n        if logger:\n            logger.info('{0} keys loaded from host directory'.format(\n                len(keys))\n            )\n\n        return keys", "response": "Load public keys from any available SSH agent or local directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _consolidate_binds(local_binds, remote_binds):\n        count = len(remote_binds) - len(local_binds)\n        if count < 0:\n            raise ValueError('Too many local bind addresses '\n                             '(local_bind_addresses > remote_bind_addresses)')\n        local_binds.extend([('0.0.0.0', 0) for x in range(count)])\n        return local_binds", "response": "Consolidate local_binds with defaults when no value or s were specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets sure authentication information is in place. ``ssh_pkey`` may be of classes: - ``str`` - in this case it represents a private key file; public key will be obtained from it - ``paramiko.Pkey`` - it will be transparently added to loaded keys", "response": "def _consolidate_auth(ssh_password=None,\n                          ssh_pkey=None,\n                          ssh_pkey_password=None,\n                          allow_agent=True,\n                          host_pkey_directories=None,\n                          logger=None):\n        \"\"\"\n        Get sure authentication information is in place.\n        ``ssh_pkey`` may be of classes:\n            - ``str`` - in this case it represents a private key file; public\n            key will be obtained from it\n            - ``paramiko.Pkey`` - it will be transparently added to loaded keys\n\n        \"\"\"\n        ssh_loaded_pkeys = SSHTunnelForwarder.get_keys(\n            logger=logger,\n            host_pkey_directories=host_pkey_directories,\n            allow_agent=allow_agent\n        )\n\n        if isinstance(ssh_pkey, string_types):\n            ssh_pkey_expanded = os.path.expanduser(ssh_pkey)\n            if os.path.exists(ssh_pkey_expanded):\n                ssh_pkey = SSHTunnelForwarder.read_private_key_file(\n                    pkey_file=ssh_pkey_expanded,\n                    pkey_password=ssh_pkey_password or ssh_password,\n                    logger=logger\n                )\n            elif logger:\n                logger.warning('Private key file not found: {0}'\n                               .format(ssh_pkey))\n        if isinstance(ssh_pkey, paramiko.pkey.PKey):\n            ssh_loaded_pkeys.insert(0, ssh_pkey)\n\n        if not ssh_password and not ssh_loaded_pkeys:\n            raise ValueError('No password or public key available!')\n        return (ssh_password, ssh_loaded_pkeys)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the SSH transport to the remote gateway", "response": "def _get_transport(self):\n        \"\"\" Return the SSH transport to the remote gateway \"\"\"\n        if self.ssh_proxy:\n            if isinstance(self.ssh_proxy, paramiko.proxy.ProxyCommand):\n                proxy_repr = repr(self.ssh_proxy.cmd[1])\n            else:\n                proxy_repr = repr(self.ssh_proxy)\n            self.logger.debug('Connecting via proxy: {0}'.format(proxy_repr))\n            _socket = self.ssh_proxy\n        else:\n            _socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        if isinstance(_socket, socket.socket):\n            _socket.settimeout(SSH_TIMEOUT)\n            _socket.connect((self.ssh_host, self.ssh_port))\n        transport = paramiko.Transport(_socket)\n        transport.set_keepalive(self.set_keepalive)\n        transport.use_compression(compress=self.compression)\n        transport.daemon = self.daemon_transport\n\n        return transport"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_tunnels(self):\n        if not self.is_active:\n            try:\n                self._connect_to_gateway()\n            except socket.gaierror:  # raised by paramiko.Transport\n                msg = 'Could not resolve IP address for {0}, aborting!' \\\n                    .format(self.ssh_host)\n                self.logger.error(msg)\n                return\n            except (paramiko.SSHException, socket.error) as e:\n                template = 'Could not connect to gateway {0}:{1} : {2}'\n                msg = template.format(self.ssh_host, self.ssh_port, e.args[0])\n                self.logger.error(msg)\n                return\n        for (rem, loc) in zip(self._remote_binds, self._local_binds):\n            try:\n                self._make_ssh_forward_server(rem, loc)\n            except BaseSSHTunnelForwarderError as e:\n                msg = 'Problem setting SSH Forwarder up: {0}'.format(e.value)\n                self.logger.error(msg)", "response": "Create SSH tunnels on top of a transport to the remote gateway"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess optional deprecate arguments", "response": "def _process_deprecated(attrib, deprecated_attrib, kwargs):\n        \"\"\"\n        Processes optional deprecate arguments\n        \"\"\"\n        if deprecated_attrib not in DEPRECATIONS:\n            raise ValueError('{0} not included in deprecations list'\n                             .format(deprecated_attrib))\n        if deprecated_attrib in kwargs:\n            warnings.warn(\"'{0}' is DEPRECATED use '{1}' instead\"\n                          .format(deprecated_attrib,\n                                  DEPRECATIONS[deprecated_attrib]),\n                          DeprecationWarning)\n            if attrib:\n                raise ValueError(\"You can't use both '{0}' and '{1}'. \"\n                                 \"Please only use one of them\"\n                                 .format(deprecated_attrib,\n                                         DEPRECATIONS[deprecated_attrib]))\n            else:\n                return kwargs.pop(deprecated_attrib)\n        return attrib"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a private key file and returns the SSH Public key object.", "response": "def read_private_key_file(pkey_file,\n                              pkey_password=None,\n                              key_type=None,\n                              logger=None):\n        \"\"\"\n        Get SSH Public key from a private key file, given an optional password\n\n        Arguments:\n            pkey_file (str):\n                File containing a private key (RSA, DSS or ECDSA)\n        Keyword Arguments:\n            pkey_password (Optional[str]):\n                Password to decrypt the private key\n            logger (Optional[logging.Logger])\n        Return:\n            paramiko.Pkey\n        \"\"\"\n        ssh_pkey = None\n        for pkey_class in (key_type,) if key_type else (\n            paramiko.RSAKey,\n            paramiko.DSSKey,\n            paramiko.ECDSAKey,\n            paramiko.Ed25519Key\n        ):\n            try:\n                ssh_pkey = pkey_class.from_private_key_file(\n                    pkey_file,\n                    password=pkey_password\n                )\n                if logger:\n                    logger.debug('Private key file ({0}, {1}) successfully '\n                                 'loaded'.format(pkey_file, pkey_class))\n                break\n            except paramiko.PasswordRequiredException:\n                if logger:\n                    logger.error('Password is required for key {0}'\n                                 .format(pkey_file))\n                break\n            except paramiko.SSHException:\n                if logger:\n                    logger.debug('Private key file ({0}) could not be loaded '\n                                 'as type {1} or bad password'\n                                 .format(pkey_file, pkey_class))\n        return ssh_pkey"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_tunnel(self, _srv):\n        if self.skip_tunnel_checkup:\n            self.tunnel_is_up[_srv.local_address] = True\n            return\n        self.logger.info('Checking tunnel to: {0}'.format(_srv.remote_address))\n        if isinstance(_srv.local_address, string_types):  # UNIX stream\n            s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        else:\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(TUNNEL_TIMEOUT)\n        try:\n            # Windows raises WinError 10049 if trying to connect to 0.0.0.0\n            connect_to = ('127.0.0.1', _srv.local_port) \\\n                if _srv.local_host == '0.0.0.0' else _srv.local_address\n            s.connect(connect_to)\n            self.tunnel_is_up[_srv.local_address] = _srv.tunnel_ok.get(\n                timeout=TUNNEL_TIMEOUT * 1.1\n            )\n            self.logger.debug(\n                'Tunnel to {0} is DOWN'.format(_srv.remote_address)\n            )\n        except socket.error:\n            self.logger.debug(\n                'Tunnel to {0} is DOWN'.format(_srv.remote_address)\n            )\n            self.tunnel_is_up[_srv.local_address] = False\n\n        except queue.Empty:\n            self.logger.debug(\n                'Tunnel to {0} is UP'.format(_srv.remote_address)\n            )\n            self.tunnel_is_up[_srv.local_address] = True\n        finally:\n            s.close()", "response": "Check if tunnel is established"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the SSH tunnels.", "response": "def start(self):\n        \"\"\" Start the SSH tunnels \"\"\"\n        if self.is_alive:\n            self.logger.warning('Already started!')\n            return\n        self._create_tunnels()\n        if not self.is_active:\n            self._raise(BaseSSHTunnelForwarderError,\n                        reason='Could not establish session to SSH gateway')\n        for _srv in self._server_list:\n            thread = threading.Thread(\n                target=self._serve_forever_wrapper,\n                args=(_srv, ),\n                name='Srv-{0}'.format(address_to_str(_srv.local_port))\n            )\n            thread.daemon = self.daemon_forward_servers\n            thread.start()\n            self._check_tunnel(_srv)\n        self.is_alive = any(self.tunnel_is_up.values())\n        if not self.is_alive:\n            self._raise(HandlerSSHTunnelForwarderError,\n                        'An error occurred while opening tunnels.')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        self.logger.info('Closing all open connections...')\n        opened_address_text = ', '.join(\n            (address_to_str(k.local_address) for k in self._server_list)\n        ) or 'None'\n        self.logger.debug('Listening tunnels: ' + opened_address_text)\n        self._stop_transport()\n        self._server_list = []  # reset server list\n        self.tunnel_is_up = {}", "response": "Shut down the tunnel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen connection to the SSH gateway", "response": "def _connect_to_gateway(self):\n        \"\"\"\n        Open connection to SSH gateway\n         - First try with all keys loaded from an SSH agent (if allowed)\n         - Then with those passed directly or read from ~/.ssh/config\n         - As last resort, try with a provided password\n        \"\"\"\n        for key in self.ssh_pkeys:\n            self.logger.debug('Trying to log in with key: {0}'\n                              .format(hexlify(key.get_fingerprint())))\n            try:\n                self._transport = self._get_transport()\n                self._transport.connect(hostkey=self.ssh_host_key,\n                                        username=self.ssh_username,\n                                        pkey=key)\n                if self._transport.is_alive:\n                    return\n            except paramiko.AuthenticationException:\n                self.logger.debug('Authentication error')\n                self._stop_transport()\n\n        if self.ssh_password:  # avoid conflict using both pass and pkey\n            self.logger.debug('Trying to log in with password: {0}'\n                              .format('*' * len(self.ssh_password)))\n            try:\n                self._transport = self._get_transport()\n                self._transport.connect(hostkey=self.ssh_host_key,\n                                        username=self.ssh_username,\n                                        password=self.ssh_password)\n                if self._transport.is_alive:\n                    return\n            except paramiko.AuthenticationException:\n                self.logger.debug('Authentication error')\n                self._stop_transport()\n\n        self.logger.error('Could not open connection to gateway')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping for the server created for a SSH forward", "response": "def _serve_forever_wrapper(self, _srv, poll_interval=0.1):\n        \"\"\"\n        Wrapper for the server created for a SSH forward\n        \"\"\"\n        self.logger.info('Opening tunnel: {0} <> {1}'.format(\n            address_to_str(_srv.local_address),\n            address_to_str(_srv.remote_address))\n        )\n        _srv.serve_forever(poll_interval)  # blocks until finished\n\n        self.logger.info('Tunnel: {0} <> {1} released'.format(\n            address_to_str(_srv.local_address),\n            address_to_str(_srv.remote_address))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _stop_transport(self):\n        try:\n            self._check_is_started()\n        except (BaseSSHTunnelForwarderError,\n                HandlerSSHTunnelForwarderError) as e:\n            self.logger.warning(e)\n        for _srv in self._server_list:\n            tunnel = _srv.local_address\n            if self.tunnel_is_up[tunnel]:\n                self.logger.info('Shutting down tunnel {0}'.format(tunnel))\n                _srv.shutdown()\n            _srv.server_close()\n            # clean up the UNIX domain socket if we're using one\n            if isinstance(_srv, _UnixStreamForwardServer):\n                try:\n                    os.unlink(_srv.local_address)\n                except Exception as e:\n                    self.logger.error('Unable to unlink socket {0}: {1}'\n                                      .format(self.local_address, repr(e)))\n        self.is_alive = False\n        if self.is_active:\n            self._transport.close()\n            self._transport.stop_thread()\n        self.logger.debug('Transport is closed')", "response": "Close the underlying transport when nothing more is needed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef local_bind_ports(self):\n        self._check_is_started()\n        return [_server.local_port for _server in self._server_list if\n                _server.local_port is not None]", "response": "Returns a list containing the local bind ports of the TCP tunnels that are started on the local side of the TCP tunnels."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list containing the IP addresses listening for the tunnels", "response": "def local_bind_hosts(self):\n        \"\"\"\n        Return a list containing the IP addresses listening for the tunnels\n        \"\"\"\n        self._check_is_started()\n        return [_server.local_host for _server in self._server_list if\n                _server.local_host is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary containing the active remote<>remote tunnel_bindings", "response": "def tunnel_bindings(self):\n        \"\"\"\n        Return a dictionary containing the active local<>remote tunnel_bindings\n        \"\"\"\n        return dict((_server.remote_address, _server.local_address) for\n                    _server in self._server_list if\n                    self.tunnel_is_up[_server.local_address])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_submodules(module):\n    if not inspect.ismodule(module):\n        raise RuntimeError(\n            'Can only extract submodules from a module object, '\n            'for example imported via importlib.import_module')\n\n    submodules = get_members(module, inspect.ismodule)\n\n    module_path = list(getattr(module, '__path__', [None]))[0]\n\n    if module_path is not None:\n        for item in listdir(module_path):\n            module_name = extract_module_name(osp.join(module_path, item))\n\n            if module_name is not None:\n                try:\n                    submodules[module_name] = importlib.import_module(\n                        '.{}'.format(module_name), package=module.__name__)\n                except ImportError:\n                    # This is necessary in case random directories are in the path or things can\n                    # just not be imported due to other ImportErrors.\n                    pass\n\n    return submodules", "response": "This function imports all sub - modules of the supplied module and returns a dictionary with module names as keys and sub - modules as values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_members(obj, predicate=None):\n    members = {member: getattr(obj, member) for member in dir(obj) if not member.startswith('__')}\n\n    if predicate is None:\n        return members\n\n    return {name: member for name, member in members.items() if predicate(member)}", "response": "Returns all members of an object that do not start with __."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_module_name(absolute_path):\n    base_name = osp.basename(osp.normpath(absolute_path))\n\n    # If the basename starts with _ it's probably __init__.py or __pycache__ or something internal.\n    # At the moment there seems to be no use case for those\n    if base_name[0] in ('.', '_'):\n        return None\n\n    # If it's a directory, there's nothing else to check, so it can be returned directly\n    if osp.isdir(absolute_path):\n        return base_name\n\n    module_name, extension = osp.splitext(base_name)\n\n    # If it's a file, it must have a .py ending\n    if extension == '.py':\n        return module_name\n\n    return None", "response": "This function tries to extract a valid module name from the basename of the supplied path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_strict_update(base_dict, update_dict):\n    additional_keys = set(update_dict.keys()) - set(base_dict.keys())\n    if len(additional_keys) > 0:\n        raise RuntimeError(\n            'The update dictionary contains keys that are not part of '\n            'the base dictionary: {}'.format(str(additional_keys)),\n            additional_keys)\n\n    base_dict.update(update_dict)", "response": "This function updates the base_dict with update_dict if and only if update_dict contains keys that are not already in base_dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_doc_text(text):\n\n    return '\\n'.join(\n        textwrap.fill(line, width=99, initial_indent='    ', subsequent_indent='    ')\n        for line in inspect.cleandoc(text).splitlines())", "response": "A very thin wrapper around textwrap. fill to consistently wrap documentation text\n    for display in a command line environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_compatible_with_framework(version):\n    if version is None:\n        return None\n\n    lewis_version = Version.coerce(__version__)\n\n    return lewis_version == Version.coerce(version.strip())", "response": "Returns True if the supplied version is compatible with the current framework version otherwise returns False."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_import(self, *names):\n        try:\n            module_object = importlib.import_module(self._module)\n\n            objects = tuple(getattr(module_object, name) for name in names)\n        except ImportError:\n            def failing_init(obj, *args, **kwargs):\n                raise self._exception\n\n            objects = tuple(type(name, (object,), {'__init__': failing_init})\n                            for name in names)\n\n        return objects if len(objects) != 1 else objects[0]", "response": "Tries to import names from the module specified on initialization\n                 of the FromOptionalDependency - object. If an ImportError occurs the module is imported and the requested names are replaced with stub objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_api(self):\n        return {'class': type(self._object).__name__, 'methods': list(self._function_map.keys())}", "response": "This method returns the class name and a list of exposed methods."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_object(self, obj, name):\n        if name in self._object_map:\n            raise RuntimeError('An object is already registered under that name.')\n\n        exposed_object = self._object_map[name] = \\\n            obj if isinstance(obj, ExposedObject) else ExposedObject(obj)\n\n        for method_name in exposed_object:\n            glue = '.' if not method_name.startswith(':') else ''\n            self._add_function(name + glue + method_name, exposed_object[method_name])", "response": "Adds the supplied object to the collection under the supplied name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an object from the internal object map.", "response": "def remove_object(self, name):\n        \"\"\"\n        Remove the object exposed under that name. If no object is registered under the supplied\n        name, a RuntimeError is raised.\n\n        :param name: Name of object to be removed.\n        \"\"\"\n        if name not in self._object_map:\n            raise RuntimeError('No object with name {} is registered.'.format(name))\n\n        for fn_name in list(self._function_map.keys()):\n            if fn_name.startswith(name + '.') or fn_name.startswith(name + ':'):\n                self._remove_function(fn_name)\n\n        del self._object_map[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the target temperature in C. Must be positive.", "response": "def set_set_point(self, param):\n        \"\"\"\n        Sets the target temperature.\n\n        :param param: The new temperature in C. Must be positive.\n        :return: Empty string.\n        \"\"\"\n        if self.temperature_low_limit <= param <= self.temperature_high_limit:\n            self.set_point_temperature = param\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_circulating(self, param):\n        if param == 0:\n            self.is_circulating = param\n            self.circulate_commanded = False\n        elif param == 1:\n            self.is_circulating = param\n            self.circulate_commanded = True\n        return \"\"", "response": "Sets whether to circulate - in effect whether the heater is on."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of available protocols for the specified device.", "response": "def get_protocols(self, device):\n        \"\"\"Returns a list of available protocols for the specified device.\"\"\"\n        return self._reg.device_builder(device, self._rv).protocols"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, device, setup=None, protocols=None, control_server=None):\n\n        device_builder = self._reg.device_builder(device, self._rv)\n        device = device_builder.create_device(setup)\n\n        adapters = []\n\n        if protocols is not None:\n            for protocol, options in protocols.items():\n                interface = device_builder.create_interface(protocol)\n                interface.device = device\n\n                adapter = interface.adapter(options=options or {})\n                adapter.interface = interface\n\n                adapters.append(adapter)\n\n        return Simulation(\n            device=device,\n            adapters=adapters,\n            device_builder=device_builder,\n            control_server=control_server)", "response": "Creates a new simulation according to the supplied parameters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if obj is a device type.", "response": "def is_device(obj):\n    \"\"\"\n    Returns True if obj is a device type (derived from DeviceBase), but not defined in\n    :mod:`lewis.core.devices` or :mod:`lewis.devices`.\n\n    :param obj: Object to test.\n    :return: True if obj is a device type.\n    \"\"\"\n    return isinstance(obj, type) and issubclass(\n        obj, DeviceBase) and obj.__module__ not in ('lewis.devices', 'lewis.core.devices')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the given object is an interface.", "response": "def is_interface(obj):\n    \"\"\"\n    Returns True if obj is an interface (derived from :class:`InterfaceBase`), but not defined in\n    :mod:`lewis.adapters`, where concrete interfaces for protocols are defined.\n\n    :param obj: Object to test.\n    :return: True if obj is an interface type.\n    \"\"\"\n    return isinstance(obj, type) and issubclass(\n        obj, InterfaceBase) and not (\n        obj.__module__.startswith('lewis.core.devices') or obj.__module__.startswith(\n            'lewis.adapters'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef meta(self):\n        if not self._pv.meta_data_property or not self._meta_target:\n            return {}\n\n        return getattr(self._meta_target, self._pv.meta_data_property)", "response": "Value of the bound meta - property on the target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the docstring of the property on the target or override specified on PV - object.", "response": "def doc(self):\n        \"\"\"Docstring of property on target or override specified on PV-object.\"\"\"\n        return self._pv.doc or inspect.getdoc(\n            getattr(type(self._target), self._pv.property, None)) or ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbinds the PV to one of the supplied targets.", "response": "def bind(self, *targets):\n        \"\"\"\n        Tries to bind the PV to one of the supplied targets. Targets are inspected according to\n        the order in which they are supplied.\n\n        :param targets: Objects to inspect from.\n        :return: BoundPV instance with the PV bound to the target property.\n        \"\"\"\n        self.property = 'value'\n        self.meta_data_property = 'meta'\n\n        return BoundPV(self,\n                       self._get_target(self.property, *targets),\n                       self._get_target(self.meta_data_property, *targets))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_specification(self, spec):\n        if spec is None or callable(spec) or isinstance(spec, string_types):\n            spec = (spec,)\n        if len(spec) == 1:\n            spec = (spec[0], None)\n        return spec", "response": "Helper method to create a homogeneous representation of a specified getter or setter pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_target(self, prop, *targets):\n\n        if prop is None:\n            return None\n\n        raw_getter, raw_setter = self._specifications.get(prop, (None, None))\n\n        target = None\n\n        if isinstance(raw_getter, string_types):\n            target = next(\n                (obj for obj in targets if\n                 isinstance(\n                     getattr(type(obj), raw_getter, None), property)\n                 or not callable(\n                     getattr(obj, raw_getter, lambda: True))),\n                None)\n\n        if target is not None:\n            # If the property is an actual property and has no setter, read_only can be\n            # set to True at this point automatically.\n            target_prop = getattr(type(target), raw_getter, None)\n\n            if prop == 'value' and isinstance(target_prop, property) and target_prop.fset is None:\n                self.read_only = True\n\n            # Now the target does not need to be constructed, property or meta_data_property\n            # needs to change.\n            setattr(self, 'property' if prop == 'value' else 'meta_data_property', raw_getter)\n            return target\n\n        getter = self._create_getter(raw_getter, *targets)\n        setter = self._create_setter(raw_setter, *targets)\n\n        if getter is None and setter is None:\n            return None\n\n        if prop == 'value' and setter is None:\n            self.read_only = True\n\n        return type(prop, (object,), {prop: property(getter, setter)})()", "response": "This method returns the target object that is used by the bound PV."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a function wrapping the supplied function and returns a wrapper that can be used as the get_value_of_object method.", "response": "def _create_getter(self, func, *targets):\n        \"\"\"\n        Returns a function wrapping the supplied function. The returned wrapper can be used as the\n        getter in a property definition. Raises a RuntimeError if the signature of the supplied\n        function is not compatible with the getter-concept (no arguments except self).\n\n        :param func: Callable or name of method on one object in targets.\n        :param targets: List of targets with decreasing priority for finding func.\n        :return: Getter function for constructing a wrapper-property.\n        \"\"\"\n        if not func:\n            return None\n\n        final_callable = self._get_callable(func, *targets)\n\n        if not self._function_has_n_args(final_callable, 0):\n            raise RuntimeError(\n                'The function \\'{}\\' does not look like a getter function. A valid getter '\n                'function has no arguments that do not have a default. The self-argument of '\n                'methods does not count towards that number.'.format(final_callable.__name__))\n\n        @wraps(final_callable)\n        def getter(obj):\n            return final_callable()\n\n        return getter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_setter(self, func, *targets):\n        if not func:\n            return None\n\n        func = self._get_callable(func, *targets)\n\n        if not self._function_has_n_args(func, 1):\n            raise RuntimeError(\n                'The function \\'{}\\' does not look like a setter function. A valid setter '\n                'function has exactly one argument without a default. The self-argument of '\n                'methods does not count towards that number.'.format(func.__name__))\n\n        def setter(obj, value):\n            func(value)\n\n        return setter", "response": "Creates a function wrapping the supplied function and returns a wrapper that can be used as the\n        setter in a property definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_callable(self, func, *targets):\n        if not callable(func):\n            func_name = func\n            func = next((getattr(obj, func, None) for obj in targets if func in dir(obj)),\n                        None)\n\n            if not func:\n                raise AttributeError(\n                    'No method with the name \\'{}\\' could be found on any of the target objects '\n                    '(device, interface). Please check the spelling.'.format(func_name))\n\n        return func", "response": "Returns the callable that is called on one of the objects in targets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _function_has_n_args(self, func, n):\n        if inspect.ismethod(func):\n            n += 1\n\n        argspec = inspect.getargspec(func)\n        defaults = argspec.defaults or ()\n\n        return len(argspec.args) - len(defaults) == n", "response": "Returns true if func has n arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a pcaspy-server. .. note:: The server does not process requests unless :meth:`handle` is called regularly.", "response": "def start_server(self):\n        \"\"\"\n        Creates a pcaspy-server.\n\n        .. note::\n\n            The server does not process requests unless :meth:`handle` is called regularly.\n        \"\"\"\n        if self._server is None:\n            self._server = SimpleServer()\n            self._server.createPV(prefix=self._options.prefix,\n                                  pvdb={k: v.config for k, v in self.interface.bound_pvs.items()})\n            self._driver = PropertyExposingDriver(interface=self.interface,\n                                                  device_lock=self.device_lock)\n            self._driver.process_pv_updates(force=True)\n\n            self.log.info('Started serving PVs: %s',\n                          ', '.join((self._options.prefix + pv for pv in\n                                     self.interface.bound_pvs.keys())))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall this method to spend about ``cycle_delay`` seconds processing requests in the pcaspy server. Under load, for example when running ``caget`` at a high frequency, the actual time spent in the method may be much shorter. This effect is not corrected for. :param cycle_delay: Approximate time to be spent processing requests in pcaspy server.", "response": "def handle(self, cycle_delay=0.1):\n        \"\"\"\n        Call this method to spend about ``cycle_delay`` seconds processing\n        requests in the pcaspy server. Under load, for example when running ``caget`` at a\n        high frequency, the actual time spent in the method may be much shorter. This effect\n        is not corrected for.\n\n        :param cycle_delay: Approximate time to be spent processing requests in pcaspy server.\n        \"\"\"\n        if self._server is not None:\n            self._server.process(cycle_delay)\n            self._driver.process_pv_updates()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_rpc(self, method, *args):\n        request_id = str(uuid.uuid4())\n\n        try:\n            self._socket.send_json(\n                {'method': method,\n                 'params': args,\n                 'jsonrpc': '2.0',\n                 'id': request_id\n                 })\n\n            return self._socket.recv_json(), request_id\n        except zmq.error.Again:\n            raise ProtocolException(\n                'The ZMQ connection to {} timed out after {:.2f}s.'.format(\n                    self._connection_string, self.timeout / 1000))", "response": "This method sends a JSON - RPC to the remote server and waits for a reply to the server and returns the JSON result and request id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_request(self, method, *args):\n        response, request_id = self._connection.json_rpc(self._prefix + method, *args)\n\n        if 'id' not in response:\n            raise ProtocolException('JSON-RPC response does not contain ID field.')\n\n        if response['id'] != request_id:\n            raise ProtocolException(\n                'ID of JSON-RPC request ({}) did not match response ({}).'.format(\n                    request_id, response['id']))\n\n        if 'result' in response:\n            return response['result']\n\n        if 'error' in response:\n            if 'data' in response['error']:\n                exception_type = response['error']['data']['type']\n                exception_message = response['error']['data']['message']\n\n                if not hasattr(exceptions, exception_type):\n                    raise RemoteException(exception_type, exception_message)\n                else:\n                    exception = getattr(exceptions, exception_type)\n                    raise exception(exception_message)\n            else:\n                raise ProtocolException(response['error']['message'])", "response": "This method performs a JSON - RPC request via the object s ZMQ socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_status(self):\n\n        # \"The first command sent must be a 'T' command\" from T95 manual\n        self.device.serial_command_mode = True\n\n        Tarray = [0x80] * 10\n\n        # Status byte (SB1)\n        Tarray[0] = {\n            'stopped': 0x01,\n            'heat': 0x10,\n            'cool': 0x20,\n            'hold': 0x30,\n        }.get(self.device._csm.state, 0x01)\n\n        if Tarray[0] == 0x30 and self.device.hold_commanded:\n            Tarray[0] = 0x50\n\n        # Error status byte (EB1)\n        if self.device.pump_overspeed:\n            Tarray[1] |= 0x01\n        # TODO: Add support for other error conditions?\n\n        # Pump status byte (PB1)\n        Tarray[2] = 0x80 + self.device.pump_speed\n\n        # Temperature\n        Tarray[6:10] = [ord(x) for x in \"%04x\" % (int(self.device.temperature * 10) & 0xFFFF)]\n\n        return ''.join(chr(c) for c in Tarray)", "response": "Returns the status of the device as a single byte array consisting of 10 status bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_rate(self, param):\n        # TODO: Is not having leading zeroes / 4 digits an error?\n        rate = int(param)\n        if 1 <= rate <= 15000:\n            self.device.temperature_rate = rate / 100.0\n        return \"\"", "response": "Models Rate Command functionality of device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmodel Limit Command functionality of device.", "response": "def set_limit(self, param):\n        \"\"\"\n        Models \"Limit Command\" functionality of device.\n\n        Sets the target temperate to be reached.\n\n        :param param: Target temperature in C, multiplied by 10, as a string. Can be negative.\n        :return: Empty string.\n        \"\"\"\n        # TODO: Is not having leading zeroes / 4 digits an error?\n        limit = int(param)\n        if -2000 <= limit <= 6000:\n            self.device.temperature_limit = limit / 10.0\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmodel LNP Pump Commands functionality of device.", "response": "def pump_command(self, param):\n        \"\"\"\n        Models \"LNP Pump Commands\" functionality of device.\n\n        Switches between automatic or manual pump mode, and adjusts speed when in manual mode.\n\n        :param param: 'a0' for auto, 'm0' for manual, [0-N] for speed.\n        :return:\n        \"\"\"\n        lookup = [c for c in \"0123456789:;<=>?@ABCDEFGHIJKLMN\"]\n\n        if param == \"a0\":\n            self.device.pump_manual_mode = False\n        elif param == \"m0\":\n            self.device.pump_manual_mode = True\n        elif param in lookup:\n            self.device.manual_target_speed = lookup.index(param)\n\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_context(self, new_context):\n        self._context = new_context\n\n        if hasattr(self, '_set_logging_context'):\n            self._set_logging_context(self._context)", "response": "Assigns the new context to the member variable _context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _initialize_data(self):\n        self.serial_command_mode = False\n        self.pump_overspeed = False\n\n        self.start_commanded = False\n        self.stop_commanded = False\n        self.hold_commanded = False\n\n        # Real device remembers values from last run, we use arbitrary defaults\n        self.temperature_rate = 5.0  # Rate of change of temperature in C/min\n        self.temperature_limit = 0.0  # Target temperature in C\n\n        self.pump_speed = 0  # Pump speed in arbitrary unit, ranging 0 to 30\n        self.temperature = 24.0  # Current temperature in C\n\n        self.pump_manual_mode = False\n        self.manual_target_speed = 0", "response": "Initializes the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_log(target):\n    logger_name = target.__name__\n\n    def get_logger_name(context=None):\n        log_names = [root_logger_name, logger_name]\n\n        if context is not None:\n            log_names.insert(1,\n                             context if isinstance(context,\n                                                   string_types) else context.__class__.__name__)\n\n        return '.'.join(log_names)\n\n    def _set_logging_context(obj, context):\n        \"\"\"\n        Changes the logger name of this class using the supplied context\n        according to the rules described in the documentation of :func:`has_log`. To\n        clear the context of a class logger, supply ``None`` as the argument.\n\n        :param context: String or object, ``None`` to clear context.\n        \"\"\"\n        obj.log.name = get_logger_name(context)\n\n    target.log = logging.getLogger(get_logger_name())\n    target._set_logging_context = _set_logging_context\n\n    return target", "response": "This is a simple decorator to add logging functionality to a class or function. It is a simple decorator to add two new methods that are used to add a log to the state machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_usage_text(parser, indent=None):\n    usage_text = StringIO()\n    parser.print_help(usage_text)\n\n    usage_string = usage_text.getvalue()\n\n    if indent is None:\n        return usage_string\n\n    return '\\n'.join([' ' * indent + line for line in usage_string.split('\\n')])", "response": "This small helper function extracts the help information from an ArgumentParser instance and indents the text by the number of spaces supplied in the indent - argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping the motor and returns the new target and position which are equal", "response": "def stop(self):\n        \"\"\"Stops the motor and returns the new target and position, which are equal\"\"\"\n\n        self._target = self.position\n\n        self.log.info('Stopping movement after user request.')\n\n        return self.target, self.position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_target(self, new_target):\n        try:\n            self.device.target = new_target\n            return 'T={}'.format(new_target)\n        except RuntimeError:\n            return 'err: not idle'\n        except ValueError:\n            return 'err: not 0<=T<=250'", "response": "Sets the new target in mm"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map_arguments(self, arguments):\n        if self.argument_mappings is None:\n            return arguments\n\n        return [f(a) for f, a in zip(self.argument_mappings, arguments)]", "response": "Returns the mapped function arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmapping the return_value of a processed request to the value that is returned by the user.", "response": "def map_return_value(self, return_value):\n        \"\"\"\n        Returns the mapped return_value of a processed request. If no return_mapping has been\n        defined, the value is returned as is. If return_mapping is a static value, that value\n        is returned, ignoring return_value completely.\n\n        :param return_value: Value to map.\n        :return: Mapped return value.\n        \"\"\"\n        if callable(self.return_mapping):\n            return self.return_mapping(return_value)\n\n        if self.return_mapping is not None:\n            return self.return_mapping\n\n        return return_value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start_server(self):\n        if self._server is None:\n            if self._options.telnet_mode:\n                self.interface.in_terminator = '\\r\\n'\n                self.interface.out_terminator = '\\r\\n'\n\n            self._server = StreamServer(self._options.bind_address, self._options.port,\n                                        self.interface, self.device_lock)", "response": "Starts the TCP stream server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(self, cycle_delay=0.1):\n        asyncore.loop(cycle_delay, count=1)\n        self._server.process(int(cycle_delay * 1000))", "response": "Process requests from the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _override_data(self, overrides):\n        if overrides is not None:\n            for name, val in overrides.items():\n                self.log.debug('Trying to override initial data (%s=%s)', name, val)\n                if name not in dir(self):\n                    raise AttributeError(\n                        'Can not override non-existing attribute'\n                        '\\'{}\\' of class \\'{}\\'.'.format(name, type(self).__name__))\n\n                setattr(self, name, val)", "response": "This method overrides data members of the class but does not allow for adding new members."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, addr, count):\n        addr -= self._start_addr\n        data = self._data[addr:addr + count]\n        if len(data) != count:\n            addr += self._start_addr\n            raise IndexError(\"Invalid address range [{:#06x} - {:#06x}]\"\n                             .format(addr, addr + count))\n        return data", "response": "Reads the list of count values at addr memory location in DataBank."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(self, addr, values):\n        addr -= self._start_addr\n        end = addr + len(values)\n        if not 0 <= addr <= end <= len(self._data):\n            addr += self._start_addr\n            raise IndexError(\"Invalid address range [{:#06x} - {:#06x}]\"\n                             .format(addr, addr + len(values)))\n        self._data[addr:end] = values", "response": "Writes the list values to addr memory location in DataBank."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a modbus frame from input data stream.", "response": "def from_bytearray(self, stream):\n        \"\"\"\n        Constructs this frame from input data stream, consuming as many bytes as necessary from\n        the beginning of the stream.\n\n        If stream does not contain enough data to construct a complete modbus frame, an EOFError\n        is raised and no data is consumed.\n\n        :param stream: bytearray to consume data from to construct this frame.\n        :except EOFError: Not enough data for complete frame; no data consumed.\n        \"\"\"\n        fmt = '>HHHBB'\n        size_header = struct.calcsize(fmt)\n        if len(stream) < size_header:\n            raise EOFError\n\n        (\n            self.transaction_id,\n            self.protocol_id,\n            self.length,\n            self.unit_id,\n            self.fcode\n        ) = struct.unpack(fmt, bytes(stream[:size_header]))\n\n        size_total = size_header + self.length - 2\n        if len(stream) < size_total:\n            raise EOFError\n\n        self.data = stream[size_header:size_total]\n        del stream[:size_total]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert this frame into its bytearray representation.", "response": "def to_bytearray(self):\n        \"\"\"\n        Convert this frame into its bytearray representation.\n\n        :return: bytearray representation of this frame.\n        \"\"\"\n        header = bytearray(struct.pack(\n            '>HHHBB',\n            self.transaction_id,\n            self.protocol_id,\n            self.length,\n            self.unit_id,\n            self.fcode\n        ))\n        return header + self.data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking integrity and validity of this frame.", "response": "def is_valid(self):\n        \"\"\"\n        Check integrity and validity of this frame.\n\n        :return: bool True if this frame is structurally valid.\n        \"\"\"\n        conditions = [\n            self.protocol_id == 0,  # Modbus always uses protocol 0\n            2 <= self.length <= 260,  # Absolute length limits\n            len(self.data) == self.length - 2,  # Total length matches data length\n        ]\n        return all(conditions)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an exception frame based on this frame.", "response": "def create_exception(self, code):\n        \"\"\"\n        Create an exception frame based on this frame.\n\n        :param code: Modbus exception code to use for this exception\n        :return: ModbusTCPFrame instance that represents an exception\n        \"\"\"\n        frame = deepcopy(self)\n        frame.length = 3\n        frame.fcode += 0x80\n        frame.data = bytearray(chr(code))\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_response(self, data=None):\n        frame = deepcopy(self)\n        if data is not None:\n            frame.data = data\n        frame.length = 2 + len(frame.data)\n        return frame", "response": "Create a response frame based on this frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _all_expander(fringe, iteration, viewer):\n    '''\n    Expander that expands all nodes on the fringe.\n    '''\n    expanded_neighbors = [node.expand(local_search=True)\n                          for node in fringe]\n\n    if viewer:\n        viewer.event('expanded', list(fringe), expanded_neighbors)\n\n    list(map(fringe.extend, expanded_neighbors))", "response": "Expander that expands all nodes on the fringe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbeam search. beam_size is the size of the beam. If iterations_limit is specified, the algorithm will end after that number of iterations. Else, it will continue until it can't find a better node than the current one. Requires: SearchProblem.actions, SearchProblem.result, SearchProblem.value, and SearchProblem.generate_random_state.", "response": "def beam(problem, beam_size=100, iterations_limit=0, viewer=None):\n    '''\n    Beam search.\n\n    beam_size is the size of the beam.\n    If iterations_limit is specified, the algorithm will end after that\n    number of iterations. Else, it will continue until it can't find a\n    better node than the current one.\n    Requires: SearchProblem.actions, SearchProblem.result, SearchProblem.value,\n    and SearchProblem.generate_random_state.\n    '''\n    return _local_search(problem,\n                         _all_expander,\n                         iterations_limit=iterations_limit,\n                         fringe_size=beam_size,\n                         random_initial_states=True,\n                         stop_when_no_better=iterations_limit==0,\n                         viewer=viewer)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbeaming search best first. beam_size is the size of the beam. If iterations_limit is specified, the algorithm will end after that number of iterations. Else, it will continue until it can't find a better node than the current one. Requires: SearchProblem.actions, SearchProblem.result, and SearchProblem.value.", "response": "def beam_best_first(problem, beam_size=100, iterations_limit=0, viewer=None):\n    '''\n    Beam search best first.\n\n    beam_size is the size of the beam.\n    If iterations_limit is specified, the algorithm will end after that\n    number of iterations. Else, it will continue until it can't find a\n    better node than the current one.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.value.\n    '''\n    return _local_search(problem,\n                         _first_expander,\n                         iterations_limit=iterations_limit,\n                         fringe_size=beam_size,\n                         random_initial_states=True,\n                         stop_when_no_better=iterations_limit==0,\n                         viewer=viewer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _random_best_expander(fringe, iteration, viewer):\n    '''\n    Expander that expands one randomly chosen nodes on the fringe that\n    is better than the current (first) node.\n    '''\n    current = fringe[0]\n    neighbors = current.expand(local_search=True)\n    if viewer:\n        viewer.event('expanded', [current], [neighbors])\n\n    betters = [n for n in neighbors\n               if n.value > current.value]\n    if betters:\n        chosen = random.choice(betters)\n        if viewer:\n            viewer.event('chosen_node', chosen)\n        fringe.append(chosen)", "response": "Expander that expands one randomly chosen node on the fringe that is better than the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hill_climbing_random_restarts(problem, restarts_limit, iterations_limit=0, viewer=None):\n    '''\n    Hill climbing with random restarts.\n\n    restarts_limit specifies the number of times hill_climbing will be runned.\n    If iterations_limit is specified, each hill_climbing will end after that\n    number of iterations. Else, it will continue until it can't find a\n    better node than the current one.\n    Requires: SearchProblem.actions, SearchProblem.result, SearchProblem.value,\n    and SearchProblem.generate_random_state.\n    '''\n    restarts = 0\n    best = None\n\n    while restarts < restarts_limit:\n        new = _local_search(problem,\n                            _first_expander,\n                            iterations_limit=iterations_limit,\n                            fringe_size=1,\n                            random_initial_states=True,\n                            stop_when_no_better=True,\n                            viewer=viewer)\n\n        if not best or best.value < new.value:\n            best = new\n\n        restarts += 1\n\n    if viewer:\n        viewer.event('no_more_runs', best, 'returned after %i runs' % restarts_limit)\n\n    return best", "response": "Hill climbing with random restarts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _exp_schedule(iteration, k=20, lam=0.005, limit=100):\n    '''\n    Possible scheduler for simulated_annealing, based on the aima example.\n    '''\n    return k * math.exp(-lam * iteration)", "response": "Return the scheduler for simulated_annealing based on the aima example."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_simulated_annealing_expander(schedule):\n    '''\n    Creates an expander that has a random chance to choose a node that is worse\n    than the current (first) node, but that chance decreases with time.\n    '''\n    def _expander(fringe, iteration, viewer):\n        T = schedule(iteration)\n        current = fringe[0]\n        neighbors = current.expand(local_search=True)\n\n        if viewer:\n            viewer.event('expanded', [current], [neighbors])\n\n        if neighbors:\n            succ = random.choice(neighbors)\n            delta_e = succ.value - current.value\n            if delta_e > 0 or random.random() < math.exp(delta_e / T):\n                fringe.pop()\n                fringe.append(succ)\n\n                if viewer:\n                    viewer.event('chosen_node', succ)\n\n    return _expander", "response": "Create a function that expands a node in a tree with a random chance to choose a node that is worse\n    than the current node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef simulated_annealing(problem, schedule=_exp_schedule, iterations_limit=0, viewer=None):\n    '''\n    Simulated annealing.\n\n    schedule is the scheduling function that decides the chance to choose worst\n    nodes depending on the time.\n    If iterations_limit is specified, the algorithm will end after that\n    number of iterations. Else, it will continue until it can't find a\n    better node than the current one.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.value.\n    '''\n    return _local_search(problem,\n                         _create_simulated_annealing_expander(schedule),\n                         iterations_limit=iterations_limit,\n                         fringe_size=1,\n                         stop_when_no_better=iterations_limit==0,\n                         viewer=viewer)", "response": "Simulated annealing.\n\n    schedule is the scheduling function that decides the chance to choose worst\n    nodes depending on the time.\n    If iterations_limit is specified, the algorithm will end after that\n    number of iterations. Else, it will continue until it can't find a\n    better node than the current one.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an expander that expands the bests nodes of the population crossing over them.", "response": "def _create_genetic_expander(problem, mutation_chance):\n    '''\n    Creates an expander that expands the bests nodes of the population,\n    crossing over them.\n    '''\n    def _expander(fringe, iteration, viewer):\n        fitness = [x.value for x in fringe]\n        sampler = InverseTransformSampler(fitness, fringe)\n        new_generation = []\n\n        expanded_nodes = []\n        expanded_neighbors = []\n\n        for _ in fringe:\n            node1 = sampler.sample()\n            node2 = sampler.sample()\n            child = problem.crossover(node1.state, node2.state)\n            action = 'crossover'\n            if random.random() < mutation_chance:\n                # Noooouuu! she is... he is... *IT* is a mutant!\n                child = problem.mutate(child)\n                action += '+mutation'\n\n            child_node = SearchNodeValueOrdered(state=child, problem=problem, action=action)\n            new_generation.append(child_node)\n\n            expanded_nodes.append(node1)\n            expanded_neighbors.append([child_node])\n            expanded_nodes.append(node2)\n            expanded_neighbors.append([child_node])\n\n        if viewer:\n            viewer.event('expanded', expanded_nodes, expanded_neighbors)\n\n        fringe.clear()\n        for node in new_generation:\n            fringe.append(node)\n\n    return _expander"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef genetic(problem, population_size=100, mutation_chance=0.1,\n            iterations_limit=0, viewer=None):\n    '''\n    Genetic search.\n\n    population_size specifies the size of the population (ORLY).\n    mutation_chance specifies the probability of a mutation on a child,\n    varying from 0 to 1.\n    If iterations_limit is specified, the algorithm will end after that\n    number of iterations. Else, it will continue until it can't find a\n    better node than the current one.\n    Requires: SearchProblem.generate_random_state, SearchProblem.crossover,\n    SearchProblem.mutate and SearchProblem.value.\n    '''\n    return _local_search(problem,\n                         _create_genetic_expander(problem, mutation_chance),\n                         iterations_limit=iterations_limit,\n                         fringe_size=population_size,\n                         random_initial_states=True,\n                         stop_when_no_better=iterations_limit==0,\n                         viewer=viewer)", "response": "Generate a genetic search of a random tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the location of a piece in the puzzle. ocks. org.", "response": "def find_location(rows, element_to_find):\n    '''Find the location of a piece in the puzzle.\n       Returns a tuple: row, column'''\n    for ir, row in enumerate(rows):\n        for ic, element in enumerate(row):\n            if element == element_to_find:\n                return ir, ic"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of the pieces we can move to the empty space.", "response": "def actions(self, state):\n        '''Returns a list of the pieces we can move to the empty space.'''\n        rows = string_to_list(state)\n        row_e, col_e = find_location(rows, 'e')\n\n        actions = []\n        if row_e > 0:\n            actions.append(rows[row_e - 1][col_e])\n        if row_e < 2:\n            actions.append(rows[row_e + 1][col_e])\n        if col_e > 0:\n            actions.append(rows[row_e][col_e - 1])\n        if col_e < 2:\n            actions.append(rows[row_e][col_e + 1])\n\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the resulting state after moving a piece to the empty space.", "response": "def result(self, state, action):\n        '''Return the resulting state after moving a piece to the empty space.\n           (the \"action\" parameter contains the piece to move)\n        '''\n        rows = string_to_list(state)\n        row_e, col_e = find_location(rows, 'e')\n        row_n, col_n = find_location(rows, action)\n\n        rows[row_e][col_e], rows[row_n][col_n] = rows[row_n][col_n], rows[row_e][col_e]\n\n        return list_to_string(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an * estimation* of the distance from a state to the goal. A heuristic is used to calculate the manhattan distance.", "response": "def heuristic(self, state):\n        '''Returns an *estimation* of the distance from a state to the goal.\n           We are using the manhattan distance.\n        '''\n        rows = string_to_list(state)\n\n        distance = 0\n\n        for number in '12345678e':\n            row_n, col_n = find_location(rows, number)\n            row_n_goal, col_n_goal = goal_positions[number]\n\n            distance += abs(row_n - row_n_goal) + abs(col_n - col_n_goal)\n\n        return distance"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a pickled version of the classifier saved in filepath.", "response": "def load(cls, filepath):\n        \"\"\"\n        Loads a pickled version of the classifier saved in `filepath`\n        \"\"\"\n        with open(filepath, \"rb\") as filehandler:\n            classifier = pickle.load(filehandler)\n\n        if not isinstance(classifier, Classifier):\n            raise ValueError(\"Pickled object is not a Classifier\")\n\n        return classifier"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tree_to_str(root):\n\n    xs = []\n    for value, node, depth in iter_tree(root):\n        template = \"{indent}\"\n        if node is not root:\n            template += \"case={value}\\t\"\n        if node.attribute is None:\n            template += \"result={result} -- P={prob:.2}\"\n        else:\n            template += \"split by {split}:\\t\" +\\\n                        \"(partial result={result} -- P={prob:.2})\"\n        line = template.format(indent=\"    \" * depth,\n                               value=value,\n                               result=node.result[0],\n                               prob=node.result[1],\n                               split=str(node.attribute))\n        xs.append(line)\n    return \"\\n\".join(xs)", "response": "Returns a string representation of a decision tree with a root node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef learn(self, examples, attributes, parent_examples):\n        if not examples:\n            return self.plurality_value(parent_examples)\n        elif len(set(map(self.target, examples))) == 1:\n            return self.plurality_value(examples)\n        elif not attributes:\n            return self.plurality_value(examples)\n        A = max(attributes, key=lambda a: self.importance(a, examples))\n        tree = DecisionTreeNode(attribute=A)\n        for value in set(map(A, examples)):\n            exs = [e for e in examples if A(e) == value]\n            subtree = self.learn(exs, attributes - set([A]), examples)\n            tree.add_branch(value, subtree)\n        return tree", "response": "A decision tree learner that follows the pseudocode given in\n        AIMA."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the classifier to filepath.", "response": "def save(self, filepath):\n        \"\"\"\n        Saves the classifier to `filepath`.\n        Because this classifier needs to save the dataset, it must\n        be something that can be pickled and not something like an\n        iterator.\n        \"\"\"\n\n        if not filepath or not isinstance(filepath, str):\n            raise ValueError(\"Invalid filepath\")\n\n        with open(filepath, \"wb\") as filehandler:\n            pickle.dump(self, filehandler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef take_branch(self, example):\n        if self.attribute is None:\n            return None\n        value = self.attribute(example)\n        return self.branches.get(value, None)", "response": "Returns a DecisionTreeNode instance that can better classify\n        example based on the selectors value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an OnlineInformationGain of the attribute with max gain based on examples.", "response": "def _max_gain_split(self, examples):\n        \"\"\"\n        Returns an OnlineInformationGain of the attribute with\n        max gain based on `examples`.\n        \"\"\"\n        gains = self._new_set_of_gain_counters()\n        for example in examples:\n            for gain in gains:\n                gain.add(example)\n        winner = max(gains, key=lambda gain: gain.get_gain())\n        if not winner.get_target_class_counts():\n            raise ValueError(\"Dataset is empty\")\n        return winner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbacktracking search. variable_heuristic is the heuristic for variable choosing, can be MOST_CONSTRAINED_VARIABLE, HIGHEST_DEGREE_VARIABLE, or blank for simple ordered choosing. value_heuristic is the heuristic for value choosing, can be LEAST_CONSTRAINING_VALUE or blank for simple ordered choosing.", "response": "def backtrack(problem, variable_heuristic='', value_heuristic='', inference=True):\n    '''\n    Backtracking search.\n\n    variable_heuristic is the heuristic for variable choosing, can be\n    MOST_CONSTRAINED_VARIABLE, HIGHEST_DEGREE_VARIABLE, or blank for simple\n    ordered choosing.\n    value_heuristic is the heuristic for value choosing, can be\n    LEAST_CONSTRAINING_VALUE or blank for simple ordered choosing.\n    '''\n    assignment = {}\n    domains = deepcopy(problem.domains)\n\n    if variable_heuristic == MOST_CONSTRAINED_VARIABLE:\n        variable_chooser = _most_constrained_variable_chooser\n    elif variable_heuristic == HIGHEST_DEGREE_VARIABLE:\n        variable_chooser = _highest_degree_variable_chooser\n    else:\n        variable_chooser = _basic_variable_chooser\n\n    if value_heuristic == LEAST_CONSTRAINING_VALUE:\n        values_sorter = _least_constraining_values_sorter\n    else:\n        values_sorter = _basic_values_sorter\n    return _backtracking(problem,\n                         assignment,\n                         domains,\n                         variable_chooser,\n                         values_sorter,\n                         inference=inference)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _most_constrained_variable_chooser(problem, variables, domains):\n    '''\n    Choose the variable that has less available values.\n    '''\n    # the variable with fewer values available\n    return sorted(variables, key=lambda v: len(domains[v]))[0]", "response": "Choose the variable that has less available values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchoosing the variable that is involved on more constraints.", "response": "def _highest_degree_variable_chooser(problem, variables, domains):\n    '''\n    Choose the variable that is involved on more constraints.\n    '''\n    # the variable involved in more constraints\n    return sorted(variables, key=lambda v: problem.var_degrees[v], reverse=True)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of violated constraints on a given assignment.", "response": "def _count_conflicts(problem, assignment, variable=None, value=None):\n    '''\n    Count the number of violated constraints on a given assignment.\n    '''\n    return len(_find_conflicts(problem, assignment, variable, value))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_conflicts(problem, assignment, variable=None, value=None):\n    '''\n    Find violated constraints on a given assignment, with the possibility\n    of specifying a new variable and value to add to the assignment before\n    checking.\n    '''\n    if variable is not None and value is not None:\n        assignment = deepcopy(assignment)\n        assignment[variable] = value\n\n    conflicts = []\n    for neighbors, constraint in problem.constraints:\n        # if all the neighbors on the constraint have values, check if conflict\n        if all(n in assignment for n in neighbors):\n            if not _call_constraint(assignment, neighbors, constraint):\n                conflicts.append((neighbors, constraint))\n\n    return conflicts", "response": "Find violated constraints on a given assignment with the possibility\n    of specifying a new variable and value to add to the assignment before checking."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsort values based on how many conflicts they generate if assigned.", "response": "def _least_constraining_values_sorter(problem, assignment, variable, domains):\n    '''\n    Sort values based on how many conflicts they generate if assigned.\n    '''\n    # the value that generates less conflicts\n    def update_assignment(value):\n        new_assignment = deepcopy(assignment)\n        new_assignment[variable] = value\n        return new_assignment\n\n    values = sorted(domains[variable][:],\n                    key=lambda v: _count_conflicts(problem, assignment,\n                                                   variable, v))\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _backtracking(problem, assignment, domains, variable_chooser, values_sorter, inference=True):\n    '''\n    Internal recursive backtracking algorithm.\n    '''\n    from simpleai.search.arc import arc_consistency_3\n    if len(assignment) == len(problem.variables):\n        return assignment\n\n    pending = [v for v in problem.variables\n               if v not in assignment]\n    variable = variable_chooser(problem, pending, domains)\n\n    values = values_sorter(problem, assignment, variable, domains)\n\n    for value in values:\n        new_assignment = deepcopy(assignment)\n        new_assignment[variable] = value\n\n        if not _count_conflicts(problem, new_assignment):  # TODO on aima also checks if using fc\n            new_domains = deepcopy(domains)\n            new_domains[variable] = [value]\n\n            if not inference or arc_consistency_3(new_domains, problem.constraints):\n                result = _backtracking(problem,\n                                       new_assignment,\n                                       new_domains,\n                                       variable_chooser,\n                                       values_sorter,\n                                       inference=inference)\n                if result:\n                    return result\n\n    return None", "response": "Internal recursive backtracking algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _min_conflicts_value(problem, assignment, variable):\n    '''\n    Return the value generate the less number of conflicts.\n    In case of tie, a random value is selected among this values subset.\n    '''\n    return argmin(problem.domains[variable], lambda x: _count_conflicts(problem, assignment, variable, x))", "response": "Returns the value generated the less number of conflicts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_to_binary(variables, domains, constraints):\n\n    def wdiff(vars_):\n        def diff(variables, values):\n            hidden, other = variables\n            if hidden.startswith('hidden'):\n                idx = vars_.index(other)\n                return values[1] == values[0][idx]\n            else:\n                idx = vars_.index(hidden)\n                return values[0] == values[1][idx]\n        diff.no_wrap = True  # so it's not wrapped to swap values\n        return diff\n\n    new_constraints = []\n    new_domains = copy(domains)\n    new_variables = list(variables)\n    last = 0\n\n    for vars_, const in constraints:\n        if len(vars_) == 2:\n            new_constraints.append((vars_, const))\n            continue\n\n        hidden = 'hidden%d' % last\n        new_variables.append(hidden)\n        last += 1\n        new_domains[hidden] = [t for t in product(*map(domains.get, vars_)) if const(vars_, t)]\n        for var in vars_:\n            new_constraints.append(((hidden, var), wdiff(vars_)))\n    return new_variables, new_domains, new_constraints", "response": "Convert a list of variables domains and constraints to binary form."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an action with a probability depending on utilities and temperature", "response": "def boltzmann_exploration(actions, utilities, temperature, action_counter):\n    '''returns an action with a probability depending on utilities and temperature'''\n    utilities = [utilities[x] for x in actions]\n    temperature = max(temperature, 0.01)\n    _max = max(utilities)\n    _min = min(utilities)\n    if _max == _min:\n        return random.choice(actions)\n\n    utilities = [math.exp(((u - _min) / (_max - _min)) / temperature) for u in utilities]\n    probs = [u / sum(utilities) for u in utilities]\n    i = 0\n    tot = probs[i]\n    r = random.random()\n    while i < len(actions) and r >= tot:\n        i += 1\n        tot += probs[i]\n    return actions[i]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_exponential_temperature(initial_temperature, alpha):\n    '''returns a function like initial / exp(n * alpha)'''\n    def _function(n):\n        try:\n            return initial_temperature / math.exp(n * alpha)\n        except OverflowError:\n            return 0.01\n    return _function", "response": "returns a function like initial / exp ( n * alpha )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake constraint list for binary constraint problem.", "response": "def mkconstraints():\n    \"\"\"\n    Make constraint list for binary constraint problem.\n    \"\"\"\n    constraints = []\n\n    for j in range(1, 10):\n        vars = [\"%s%d\" % (i, j) for i in uppercase[:9]]\n        constraints.extend((c, const_different) for c in combinations(vars, 2))\n\n    for i in uppercase[:9]:\n        vars = [\"%s%d\" % (i, j) for j in range(1, 10)]\n        constraints.extend((c, const_different) for c in combinations(vars, 2))\n\n    for b0 in ['ABC', 'DEF', 'GHI']:\n        for b1 in [[1, 2, 3], [4, 5, 6], [7, 8, 9]]:\n            vars = [\"%s%d\" % (i, j) for i in b0 for j in b1]\n            l = list((c, const_different) for c in combinations(vars, 2))\n            constraints.extend(l)\n\n    return constraints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a number between 0. 0 and 1. 0 with the highest precision of classification for each example in testset.", "response": "def precision(classifier, testset):\n    \"\"\"\n    Runs the classifier for each example in `testset`\n    and verifies that the classification is correct\n    using the `target`.\n\n    Returns a number between 0.0 and 1.0 with the\n    precision of classification for this test set.\n    \"\"\"\n\n    hit = 0\n    total = 0\n    for example in testset:\n        if classifier.classify(example)[0] == classifier.target(example):\n            hit += 1\n        total += 1\n    if total == 0:\n        raise ValueError(\"Empty testset!\")\n    return hit / float(total)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kfold(dataset, problem, method, k=10):\n\n    if k <= 1:\n        raise ValueError(\"k argument must be at least 2\")\n\n    dataset = list(dataset)\n    random.shuffle(dataset)\n\n    trials = 0\n    positive = 0\n    for i in range(k):\n        train = [x for j, x in enumerate(dataset) if j % k != i]\n        test = [x for j, x in enumerate(dataset) if j % k == i]\n        classifier = method(train, problem)\n        for data in test:\n            trials += 1\n            result = classifier.classify(data)\n            if result is not None and result[0] == problem.target(data):\n                positive += 1\n\n    return float(positive) / float(trials)", "response": "Does a k - fold on dataset with method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\naction are index where we can make a move", "response": "def actions(self, state):\n        'actions are index where we can make a move'\n        actions = []\n        for index, char in enumerate(state):\n            if char == '_':\n                actions.append(index)\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef actions(self, s):\n        '''Possible actions from a state.'''\n        # we try to generate every possible state and then filter those\n        # states that are valid\n        return [a for a in self._actions if self._is_valid(self.result(s, a))]", "response": "Possible actions from a state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a state is valid.", "response": "def _is_valid(self, s):\n        '''Check if a state is valid.'''\n        # valid states: no more cannibals than missioners on each side,\n        # and numbers between 0 and 3\n        return ((s[0] >= s[1] or s[0] == 0)) and \\\n                ((3 - s[0]) >= (3 - s[1]) or s[0] == 3) and \\\n                (0 <= s[0] <= 3) and \\\n                (0 <= s[1] <= 3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef result(self, s, a):\n        '''Result of applying an action to a state.'''\n        # result: boat on opposite side, and numbers of missioners and\n        # cannibals updated according to the move\n        if s[2] == 0:\n            return (s[0] - a[1][0], s[1] - a[1][1], 1)\n        else:\n            return (s[0] + a[1][0], s[1] + a[1][1], 0)", "response": "Result of applying an action to a state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef revise(domains, arc, constraints):\n    x, y = arc\n    related_constraints = [(neighbors, constraint)\n                           for neighbors, constraint in constraints\n                           if set(arc) == set(neighbors)]\n\n    modified = False\n\n    for neighbors, constraint in related_constraints:\n        for x_value in domains[x]:\n            constraint_results = (_call_constraint({x: x_value, y: y_value},\n                                                   neighbors, constraint)\n                                  for y_value in domains[y])\n\n            if not any(constraint_results):\n                domains[x].remove(x_value)\n                modified = True\n\n    return modified", "response": "Given the arc X Y and constraints removes the values from X s domain that do not meet the constraint between X and Y."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_arcs(constraints):\n    arcs = set()\n\n    for neighbors, constraint in constraints:\n        if len(neighbors) == 2:\n            x, y = neighbors\n            list(map(arcs.add, ((x, y), (y, x))))\n\n    return arcs", "response": "Returns a set of all arcs that are in the constraints."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef arc_consistency_3(domains, constraints):\n    arcs = list(all_arcs(constraints))\n    pending_arcs = set(arcs)\n\n    while pending_arcs:\n        x, y = pending_arcs.pop()\n        if revise(domains, (x, y), constraints):\n            if len(domains[x]) == 0:\n                return False\n            pending_arcs = pending_arcs.union((x2, y2) for x2, y2 in arcs\n                                              if y2 == x)\n    return True", "response": "Makes a CSP problem arc consistent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of nodes and actions from root to this node.", "response": "def path(self):\n        '''Path (list of nodes and actions) from root to this node.'''\n        node = self\n        path = []\n        while node:\n            path.append((node.action, node.state))\n            node = node.parent\n        return list(reversed(path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef depth_first(problem, graph_search=False, viewer=None):\n    '''\n    Depth first search.\n\n    If graph_search=True, will avoid exploring repeated states.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.is_goal.\n    '''\n    return _search(problem,\n                   LifoList(),\n                   graph_search=graph_search,\n                   viewer=viewer)", "response": "Depth first search.\n\n    If graph_search=True, will avoid exploring repeated states.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.is_goal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef limited_depth_first(problem, depth_limit, graph_search=False, viewer=None):\n    '''\n    Limited depth first search.\n\n    Depth_limit is the maximum depth allowed, being depth 0 the initial state.\n    If graph_search=True, will avoid exploring repeated states.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.is_goal.\n    '''\n    return _search(problem,\n                   LifoList(),\n                   graph_search=graph_search,\n                   depth_limit=depth_limit,\n                   viewer=viewer)", "response": "Limited depth first search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterative_limited_depth_first(problem, graph_search=False, viewer=None):\n    '''\n    Iterative limited depth first search.\n\n    If graph_search=True, will avoid exploring repeated states.\n    Requires: SearchProblem.actions, SearchProblem.result, and\n    SearchProblem.is_goal.\n    '''\n    solution = None\n    limit = 0\n\n    while not solution:\n        solution = limited_depth_first(problem,\n                                       depth_limit=limit,\n                                       graph_search=graph_search,\n                                       viewer=viewer)\n        limit += 1\n\n    if viewer:\n        viewer.event('no_more_runs', solution, 'returned after %i runs' % limit)\n\n    return solution", "response": "Iterative limited depth first search."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uniform_cost(problem, graph_search=False, viewer=None):\n    '''\n    Uniform cost search.\n\n    If graph_search=True, will avoid exploring repeated states.\n    Requires: SearchProblem.actions, SearchProblem.result,\n    SearchProblem.is_goal, and SearchProblem.cost.\n    '''\n    return _search(problem,\n                   BoundedPriorityQueue(),\n                   graph_search=graph_search,\n                   node_factory=SearchNodeCostOrdered,\n                   graph_replace_when_better=True,\n                   viewer=viewer)", "response": "Uniform cost search.\n\n    If graph_search=True, will avoid exploring repeated states.\n    Requires: SearchProblem.actions, SearchProblem.result,\n    SearchProblem.is_goal, and SearchProblem.cost."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _search(problem, fringe, graph_search=False, depth_limit=None,\n            node_factory=SearchNode, graph_replace_when_better=False,\n            viewer=None):\n    '''\n    Basic search algorithm, base of all the other search algorithms.\n    '''\n    if viewer:\n        viewer.event('started')\n\n    memory = set()\n    initial_node = node_factory(state=problem.initial_state,\n                                problem=problem)\n    fringe.append(initial_node)\n\n    while fringe:\n        if viewer:\n            viewer.event('new_iteration', fringe.sorted())\n\n        node = fringe.pop()\n\n        if problem.is_goal(node.state):\n            if viewer:\n                viewer.event('chosen_node', node, True)\n                viewer.event('finished', fringe.sorted(), node, 'goal found')\n            return node\n        else:\n            if viewer:\n                viewer.event('chosen_node', node, False)\n\n        memory.add(node.state)\n\n        if depth_limit is None or node.depth < depth_limit:\n            expanded = node.expand()\n            if viewer:\n                viewer.event('expanded', [node], [expanded])\n\n            for n in expanded:\n                if graph_search:\n                    others = [x for x in fringe if x.state == n.state]\n                    assert len(others) in (0, 1)\n                    if n.state not in memory and len(others) == 0:\n                        fringe.append(n)\n                    elif graph_replace_when_better and len(others) > 0 and n < others[0]:\n                        fringe.remove(others[0])\n                        fringe.append(n)\n                else:\n                    fringe.append(n)\n\n    if viewer:\n        viewer.event('finished', fringe.sorted(), None, 'goal not found')", "response": "Basic search algorithm base of all the other search algorithms."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all paths through the tree as list of node_ids SSHA", "response": "def _get_tree_paths(tree, node_id, depth=0):\n    \"\"\"\n    Returns all paths through the tree as list of node_ids\n    \"\"\"\n    if node_id == _tree.TREE_LEAF:\n        raise ValueError(\"Invalid node_id %s\" % _tree.TREE_LEAF)\n\n    left_child = tree.children_left[node_id]\n    right_child = tree.children_right[node_id]\n\n    if left_child != _tree.TREE_LEAF:\n        left_paths = _get_tree_paths(tree, left_child, depth=depth + 1)\n        right_paths = _get_tree_paths(tree, right_child, depth=depth + 1)\n\n        for path in left_paths:\n            path.append(node_id)\n        for path in right_paths:\n            path.append(node_id)\n        paths = left_paths + right_paths\n    else:\n        paths = [[node_id]]\n    return paths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npredicting the tree for a given model.", "response": "def _predict_tree(model, X, joint_contribution=False):\n    \"\"\"\n    For a given DecisionTreeRegressor, DecisionTreeClassifier,\n    ExtraTreeRegressor, or ExtraTreeClassifier,\n    returns a triple of [prediction, bias and feature_contributions], such\n    that prediction \u2248 bias + feature_contributions.\n    \"\"\"\n    leaves = model.apply(X)\n    paths = _get_tree_paths(model.tree_, 0)\n\n    for path in paths:\n        path.reverse()\n\n    leaf_to_path = {}\n    #map leaves to paths\n    for path in paths:\n        leaf_to_path[path[-1]] = path         \n    \n    # remove the single-dimensional inner arrays\n    values = model.tree_.value.squeeze(axis=1)\n    # reshape if squeezed into a single float\n    if len(values.shape) == 0:\n        values = np.array([values])\n    if isinstance(model, DecisionTreeRegressor):\n        biases = np.full(X.shape[0], values[paths[0][0]])\n        line_shape = X.shape[1]\n    elif isinstance(model, DecisionTreeClassifier):\n        # scikit stores category counts, we turn them into probabilities\n        normalizer = values.sum(axis=1)[:, np.newaxis]\n        normalizer[normalizer == 0.0] = 1.0\n        values /= normalizer\n\n        biases = np.tile(values[paths[0][0]], (X.shape[0], 1))\n        line_shape = (X.shape[1], model.n_classes_)\n    direct_prediction = values[leaves]\n    \n    \n    #make into python list, accessing values will be faster\n    values_list = list(values)\n    feature_index = list(model.tree_.feature)\n    \n    contributions = []\n    if joint_contribution:\n        for row, leaf in enumerate(leaves):\n            path = leaf_to_path[leaf]\n            \n            \n            path_features = set()\n            contributions.append({})\n            for i in range(len(path) - 1):\n                path_features.add(feature_index[path[i]])\n                contrib = values_list[path[i+1]] - \\\n                         values_list[path[i]]\n                #path_features.sort()\n                contributions[row][tuple(sorted(path_features))] = \\\n                    contributions[row].get(tuple(sorted(path_features)), 0) + contrib\n        return direct_prediction, biases, contributions\n        \n    else:\n        unique_leaves = np.unique(leaves)\n        unique_contributions = {}\n        \n        for row, leaf in enumerate(unique_leaves):\n            for path in paths:\n                if leaf == path[-1]:\n                    break\n            \n            contribs = np.zeros(line_shape)\n            for i in range(len(path) - 1):\n                \n                contrib = values_list[path[i+1]] - \\\n                         values_list[path[i]]\n                contribs[feature_index[path[i]]] += contrib\n            unique_contributions[leaf] = contribs\n            \n        for row, leaf in enumerate(leaves):\n            contributions.append(unique_contributions[leaf])\n\n        return direct_prediction, biases, np.array(contributions)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _predict_forest(model, X, joint_contribution=False):\n    biases = []\n    contributions = []\n    predictions = []\n\n    \n    if joint_contribution:\n        \n        for tree in model.estimators_:\n            pred, bias, contribution = _predict_tree(tree, X, joint_contribution=joint_contribution)\n\n            biases.append(bias)\n            contributions.append(contribution)\n            predictions.append(pred)\n        \n        \n        total_contributions = []\n        \n        for i in range(len(X)):\n            contr = {}\n            for j, dct in enumerate(contributions):\n                for k in set(dct[i]).union(set(contr.keys())):\n                    contr[k] = (contr.get(k, 0)*j + dct[i].get(k,0) ) / (j+1)\n\n            total_contributions.append(contr)    \n            \n        for i, item in enumerate(contribution):\n            total_contributions[i]\n            sm = sum([v for v in contribution[i].values()])\n                \n\n        \n        return (np.mean(predictions, axis=0), np.mean(biases, axis=0),\n            total_contributions)\n    else:\n        for tree in model.estimators_:\n            pred, bias, contribution = _predict_tree(tree, X)\n\n            biases.append(bias)\n            contributions.append(contribution)\n            predictions.append(pred)\n        \n        \n        return (np.mean(predictions, axis=0), np.mean(biases, axis=0),\n            np.mean(contributions, axis=0))", "response": "Predicts the forest for a given model."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npredicts the model on X.", "response": "def predict(model, X, joint_contribution=False):\n    \"\"\" Returns a triple (prediction, bias, feature_contributions), such\n    that prediction \u2248 bias + feature_contributions.\n    Parameters\n    ----------\n    model : DecisionTreeRegressor, DecisionTreeClassifier,\n        ExtraTreeRegressor, ExtraTreeClassifier,\n        RandomForestRegressor, RandomForestClassifier,\n        ExtraTreesRegressor, ExtraTreesClassifier\n    Scikit-learn model on which the prediction should be decomposed.\n\n    X : array-like, shape = (n_samples, n_features)\n    Test samples.\n    \n    joint_contribution : boolean\n    Specifies if contributions are given individually from each feature,\n    or jointly over them\n\n    Returns\n    -------\n    decomposed prediction : triple of\n    * prediction, shape = (n_samples) for regression and (n_samples, n_classes)\n        for classification\n    * bias, shape = (n_samples) for regression and (n_samples, n_classes) for\n        classification\n    * contributions, If joint_contribution is False then returns and  array of \n        shape = (n_samples, n_features) for regression or\n        shape = (n_samples, n_features, n_classes) for classification, denoting\n        contribution from each feature.\n        If joint_contribution is True, then shape is array of size n_samples,\n        where each array element is a dict from a tuple of feature indices to\n        to a value denoting the contribution from that feature tuple.\n    \"\"\"\n    # Only single out response variable supported,\n    if model.n_outputs_ > 1:\n        raise ValueError(\"Multilabel classification trees not supported\")\n\n    if (isinstance(model, DecisionTreeClassifier) or\n        isinstance(model, DecisionTreeRegressor)):\n        return _predict_tree(model, X, joint_contribution=joint_contribution)\n    elif (isinstance(model, ForestClassifier) or\n          isinstance(model, ForestRegressor)):\n        return _predict_forest(model, X, joint_contribution=joint_contribution)\n    else:\n        raise ValueError(\"Wrong model type. Base learner needs to be a \"\n                         \"DecisionTreeClassifier or DecisionTreeRegressor.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_keywords_from_sentences(self, sentences):\n        phrase_list = self._generate_phrases(sentences)\n        self._build_frequency_dist(phrase_list)\n        self._build_word_co_occurance_graph(phrase_list)\n        self._build_ranklist(phrase_list)", "response": "Method to extract keywords from the list of sentences provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the co - occurance graph of words in the body of text to compute degree of each word.", "response": "def _build_word_co_occurance_graph(self, phrase_list):\n        \"\"\"Builds the co-occurance graph of words in the given body of text to\n        compute degree of each word.\n\n        :param phrase_list: List of List of strings where each sublist is a\n                            collection of words which form a contender phrase.\n        \"\"\"\n        co_occurance_graph = defaultdict(lambda: defaultdict(lambda: 0))\n        for phrase in phrase_list:\n            # For each phrase in the phrase list, count co-occurances of the\n            # word with other words in the phrase.\n            #\n            # Note: Keep the co-occurances graph as is, to help facilitate its\n            # use in other creative ways if required later.\n            for (word, coword) in product(phrase, phrase):\n                co_occurance_graph[word][coword] += 1\n        self.degree = defaultdict(lambda: 0)\n        for key in co_occurance_graph:\n            self.degree[key] = sum(co_occurance_graph[key].values())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_phrases(self, sentences):\n        phrase_list = set()\n        # Create contender phrases from sentences.\n        for sentence in sentences:\n            word_list = [word.lower() for word in wordpunct_tokenize(sentence)]\n            phrase_list.update(self._get_phrase_list_from_words(word_list))\n        return phrase_list", "response": "Method to generate contender phrases given the sentences of the text\nAttributeNames document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _retain_centroids(numbers, thres):\n    numbers.sort()\n    prev = -1\n    ret = []\n    for n in numbers:\n        if prev < 0 or n - prev > thres:\n            ret.append(n)\n            prev = n\n    return ret", "response": "Only keep one number for each cluster within thres of each other"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _split_vlines_hlines(lines):\n    vlines, hlines = [], []\n    for line in lines:\n        (vlines if line.x1 - line.x0 < 0.1 else hlines).append(line)\n    return vlines, hlines", "response": "Separates lines into horizontal and vertical ones"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _npiter(arr):\n    for a in np.nditer(arr, flags=[\"refs_ok\"]):\n        c = a.item()\n        if c is not None:\n            yield c", "response": "Wrapper for iterating numpy array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all mentions in the grid.", "response": "def get_normalized_grid(self):\n        \"\"\"\n        Analyzes subcell structure\n        \"\"\"\n        log = logging.getLogger(__name__)\n        # Resolve multirow mentions, TODO: validate against all PDFs\n        #  subcol_count = 0\n        mega_rows = []\n        for row_id, row in enumerate(self._grid):\n            # maps yc_grid -> [mentions]\n            subrow_across_cell = defaultdict(list)\n            for col_id, cell in enumerate(row):\n                # Keep cell text in reading order\n                cell.texts.sort(key=cmp_to_key(reading_order))\n                log.debug(\"=\" * 50)\n                for m in cell.texts:\n                    subrow_across_cell[m.yc_grid].append(m)\n                    #  prev = m\n\n            log.debug(pformat(dict(subrow_across_cell)))\n\n            mega_rows.append(subrow_across_cell)\n\n        # Multiline paragraph check\n        # Subrow/Subcolumn\n\n        return mega_rows"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mark_grid_bounds(self, plane, region_bbox):\n        # Grid boundaries\n        vbars = np.zeros([self.num_rows, self.num_cols + 1], dtype=np.bool)\n        hbars = np.zeros([self.num_rows + 1, self.num_cols], dtype=np.bool)\n\n        def closest_idx(arr, elem):\n            left = bisect.bisect_left(arr, elem) - 1\n            right = bisect.bisect_right(arr, elem) - 1\n            return left if abs(arr[left] - elem) < abs(arr[right] - elem) else right\n\n        # Figure out which separating segments are missing, i.e. merge cells\n        for row, (y0, y1) in enumerate(self.yranges):\n            yc = (y0 + y1) // 2\n            for l in plane.find((region_bbox.x0, yc, region_bbox.x1, yc)):\n                vbars[row, closest_idx(self.xs, l.xc)] = True\n        for col, (x0, x1) in enumerate(self.xranges):\n            xc = (x0 + x1) // 2\n            for l in plane.find((xc, region_bbox.y0, xc, region_bbox.y1)):\n                hbars[closest_idx(self.ys, l.yc), col] = True\n        return vbars, hbars", "response": "Mark grid boundaries as missing in the given region_bbox."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef aligned(e1, e2):\n    return (\n        any(close(c1, c2) for c1, c2 in zip(e1.bbox, e2.bbox))\n        or x_center_aligned(e1, e2)\n        or y_center_aligned(e1, e2)\n    )", "response": "Returns True if two boxes are aligned with the same a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the minimal bbox that contains all given bboxes", "response": "def bound_bboxes(bboxes):\n    \"\"\"\n    Finds the minimal bbox that contains all given bboxes\n    \"\"\"\n    group_x0 = min(map(lambda l: l[x0], bboxes))\n    group_y0 = min(map(lambda l: l[y0], bboxes))\n    group_x1 = max(map(lambda l: l[x1], bboxes))\n    group_y1 = max(map(lambda l: l[y1], bboxes))\n    return (group_x0, group_y0, group_x1, group_y1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the minimal bounding box that contains all given elems", "response": "def bound_elems(elems):\n    \"\"\"\n    Finds the minimal bbox that contains all given elems\n    \"\"\"\n    group_x0 = min(map(lambda l: l.x0, elems))\n    group_y0 = min(map(lambda l: l.y0, elems))\n    group_x1 = max(map(lambda l: l.x1, elems))\n    group_y1 = max(map(lambda l: l.y1, elems))\n    return (group_x0, group_y0, group_x1, group_y1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if two rectangles intersect", "response": "def intersect(a, b):\n    \"\"\"\n    Check if two rectangles intersect\n    \"\"\"\n    if a[x0] == a[x1] or a[y0] == a[y1]:\n        return False\n    if b[x0] == b[x1] or b[y0] == b[y1]:\n        return False\n    return a[x0] <= b[x1] and b[x0] <= a[x1] and a[y0] <= b[y1] and b[y0] <= a[y1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_intervals(elems, overlap_thres=2.0):\n    overlap_thres = max(0.0, overlap_thres)\n    ordered = sorted(elems, key=lambda e: e.x0)\n\n    intervals = []\n    cur = [-overlap_thres, -overlap_thres]\n    for e in ordered:\n        if e.x0 - cur[1] > overlap_thres:\n            # Check interval validity\n            if cur[1] > 0.0:\n                intervals.append(cur)\n            cur = [e.x0, e.x1]\n            continue\n        cur[1] = max(cur[1], e.x1)\n    intervals.append(cur)\n    # Freeze the interval to tuples\n    return map(tuple, intervals)", "response": "Merge the intervals of the given list of segments into a single list of non - overlapping intervals."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an image corresponding to the page of the pdf documents saved at pdf_path. If the image is not found in img_dir this function creates it and saves it in img_dir. :param pdf_path: path to the pdf document. :param page_num: page number to create image from in the pdf file. :return:", "response": "def predict_heatmap(pdf_path, page_num, model, img_dim=448, img_dir=\"tmp/img\"):\n    \"\"\"\n    Return an image corresponding to the page of the pdf\n    documents saved at pdf_path. If the image is not found in img_dir this\n    function creates it and saves it in img_dir.\n\n    :param pdf_path: path to the pdf document.\n    :param page_num: page number to create image from in the pdf file.\n    :return:\n    \"\"\"\n    if not os.path.isdir(img_dir):\n        print(\"\\nCreating image folder at {}\".format(img_dir))\n        os.makedirs(img_dir)\n    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n    # TODO: add hashing function to make sure name is unique\n    # TODO: add parallelization\n    img_path = os.path.join(img_dir, pdf_name + \"-{}.png\".format(page_num))\n    if not os.path.isfile(img_path):\n        # create image for a page in the pdf document and save it in img_dir\n        save_image(pdf_path, img_path, page_num)\n    image = load_img(img_path, grayscale=True, target_size=(img_dim, img_dim))\n    image = img_to_array(image, data_format=K.image_data_format())\n    image = (\n        image.reshape((img_dim, img_dim, 1))\n        .repeat(3, axis=2)\n        .reshape((1, img_dim, img_dim, 3))\n    )\n    return (\n        image.astype(np.uint8).reshape((img_dim, img_dim, 3)),\n        model.predict(image).reshape((img_dim, img_dim)),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_intersect(bb1, bb2):\n    if bb1[0] + bb1[2] < bb2[0] or bb2[0] + bb2[2] < bb1[0]:\n        return False\n    if bb1[1] + bb1[3] < bb2[1] or bb2[1] + bb2[3] < bb1[1]:\n        return False\n    return True", "response": "Helper function that returns True if two bounding boxes overlap."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bboxes(\n    img,\n    mask,\n    nb_boxes=100,\n    score_thresh=0.5,\n    iou_thresh=0.2,\n    prop_size=0.09,\n    prop_scale=1.2,\n):\n    \"\"\"\n    Uses selective search to generate candidate bounding boxes and keeps the\n    ones that have the largest iou with the predicted mask.\n\n    :param img: original image\n    :param mask: predicted mask\n    :param nb_boxes: max number of candidate bounding boxes\n    :param score_thresh: scre threshold to consider prediction is True\n    :param iou_thresh: iou threshold to consider a candidate is a correct region\n    :param prop_size: selective search parameter\n    :param prop_scale: selective search parameter, larger prop_scale favorizes\n        large boudning boxes\n    :return: list of bounding boxes and ious, boudning boxes are tuples (left,\n        top, width, height)\n    \"\"\"\n    min_size = int(img.shape[0] * prop_size * img.shape[1] * prop_size)\n    scale = int(img.shape[0] * prop_scale)\n    # TODO: cross validate for multiple values of prop_size, prop_scale, and nb_bboxes\n    img_lbl, regions = selectivesearch.selective_search(\n        img, scale=scale, sigma=0.8, min_size=min_size\n    )\n    rect = [None] * nb_boxes\n    max_iou = -1 * np.ones(nb_boxes)\n    mask = 1.0 * (mask > score_thresh)\n    # compute iou for each candidate bounding box and save top nb_bboxes\n    for region in regions:\n        left, top, width, height = region[\"rect\"]\n        intersection = mask[top : top + height, left : left + width].sum()\n        union = height * width + mask.sum() - intersection\n        iou = intersection / union\n        idx = np.argmin(max_iou)\n        if iou > max_iou[idx]:\n            max_iou[idx] = iou\n            rect[idx] = region[\"rect\"]\n    # Exclusive maximum\n    remove_indexes = max_iou == -1\n    bboxes = []\n    filtered_ious = []\n    for idx in np.argsort([-x for x in max_iou]):\n        if remove_indexes[idx]:\n            # no more tables bounding boxes\n            break\n        if len(bboxes) == 0:\n            # first candidate table bounding box\n            if max_iou[idx] > iou_thresh:\n                bboxes += [rect[idx]]\n                filtered_ious += [max_iou[idx]]\n            else:\n                # No tables in this document\n                break\n        else:\n            # If it doensn't intersect with any other bounding box\n            if not any(\n                [do_intersect(rect[idx], bboxes[k]) for k in range(len(bboxes))]\n            ):\n                if max_iou[idx] > iou_thresh:\n                    bboxes += [rect[idx]]\n                    filtered_ious += [max_iou[idx]]\n    return bboxes, filtered_ious", "response": "Generate a list of bounding boxes and ious for each image in the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nanalyze the PDF file and returns a generator that yields each page in the PDF file.", "response": "def analyze_pages(file_name, char_margin=1.0):\n    \"\"\"\n    Input: the file path to the PDF file\n    Output: yields the layout object for each page in the PDF\n    \"\"\"\n    log = logging.getLogger(__name__)\n    # Open a PDF file.\n    with open(os.path.realpath(file_name), \"rb\") as fp:\n        # Create a PDF parser object associated with the file object.\n        parser = PDFParser(fp)\n        # Create a PDF document object that stores the document structure.\n        # Supply the password for initialization.\n        document = PDFDocument(parser, password=\"\")\n        # Create a PDF resource manager object that stores shared resources.\n        rsrcmgr = PDFResourceManager()\n        # Set parameters for analysis.\n        laparams = LAParams(\n            char_margin=char_margin, word_margin=0.1, detect_vertical=True\n        )\n        # Create a PDF page aggregator object.\n        device = CustomPDFPageAggregator(rsrcmgr, laparams=laparams)\n        # Create a PDF interpreter object.\n        interpreter = PDFPageInterpreter(rsrcmgr, device)\n        # Process each page contained in the document.\n        for page_num, page in enumerate(PDFPage.create_pages(document)):\n            try:\n                interpreter.process_page(page)\n            except OverflowError as oe:\n                log.exception(\n                    \"{}, skipping page {} of {}\".format(oe, page_num, file_name)\n                )\n                continue\n            layout = device.get_result()\n            yield layout"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_pdf(layout, scaler):\n    chars = []\n    mentions = []\n    height = scaler * layout.height\n    font_size_counter = collections.Counter()\n    # Lines longer than this are included in segments\n    pts_thres = 2.0 * scaler\n    segments = []\n    curves = []\n    figures = []\n\n    def processor(m):\n        # Normalizes the coordinate system to be consistent with\n        # image library conventions (top left as origin)\n        if isinstance(m, LTComponent):\n            m.set_bbox(normalize_bbox(m.bbox, height, scaler))\n\n            if isinstance(m, LTCurve):\n                m.pts = normalize_pts(m.pts, height, scaler)\n                # Only keep longer lines here\n                if isinstance(m, LTLine) and max(m.width, m.height) > pts_thres:\n                    segments.append(m)\n                    return\n                # Here we exclude straight lines from curves\n                curves.append(m)\n                return\n\n            if isinstance(m, LTFigure):\n                figures.append(m)\n                return\n\n            # Collect stats on the chars\n            if isinstance(m, LTChar):\n                chars.append(m)\n                # fonts could be rotated 90/270 degrees\n                font_size = _font_size_of(m)\n                font_size_counter[font_size] += 1\n                return\n\n            if isinstance(m, LTTextLine):\n                mention_text = keep_allowed_chars(m.get_text()).strip()\n                # Skip empty and invalid lines\n                if mention_text:\n                    # TODO: add subscript detection and use latex underscore\n                    # or superscript\n                    m.clean_text = mention_text\n                    m.font_name, m.font_size = _font_of_mention(m)\n                    mentions.append(m)\n                return\n\n        # Also include non character annotations\n        if isinstance(m, LTAnno):\n            chars.append(m)\n\n    traverse_layout(layout, processor)\n\n    # Resets mention y0 to the first y0 of alphanum character instead of\n    # considering exotic unicode symbols and sub/superscripts to reflect\n    # accurate alignment info\n    for m in mentions:\n        # best_y1 = min(c.y1 for c in m if isinstance(c, LTChar))\n        alphanum_c = next((c for c in m if c.get_text().isalnum()), None)\n        if alphanum_c:\n            m.set_bbox((m.x0, alphanum_c.y0, m.x1, alphanum_c.y1))\n\n        #     mentions.sort(key = lambda m: (m.y0,m.x0))\n    elems = PDFElems(mentions, segments, curves, figures, layout, chars)\n    return elems, font_size_counter", "response": "Normalizes pdf object coordinates to be consistent with image library conventions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _print_dict(elem_dict):\n    for key, value in sorted(elem_dict.iteritems()):\n        if isinstance(value, collections.Iterable):\n            print(key, len(value))\n        else:\n            print(key, value)", "response": "Print a dict in a readable way"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the font type and size of the first alphanumeric unicode character in the text.", "response": "def _font_of_mention(m):\n    \"\"\"\n    Returns the font type and size of the first alphanumeric\n    char in the text or None if there isn't any.\n    \"\"\"\n    for ch in m:\n        if isinstance(ch, LTChar) and ch.get_text().isalnum():\n            return (ch.fontname, _font_size_of(ch))\n    return (None, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _allowed_char(c):\n    c = ord(c)\n    if c < 0:\n        return False\n    if c < 128:\n        return _ascii_allowed[c]\n    # Genereally allow unicodes, TODO: check for unicode control characters\n    # characters\n    return True", "response": "Returns whether the given unicode char is allowed in the output\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nkeeps only allowed characters in the text.", "response": "def keep_allowed_chars(text):\n    \"\"\"\n    Cleans the text for output\n    \"\"\"\n    #     print ','.join(str(ord(c)) for c in text)\n    return \"\".join(\" \" if c == \"\\n\" else c for c in text.strip() if _allowed_char(c))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef paint_path(self, gstate, stroke, fill, evenodd, path):\n        shape = \"\".join(x[0] for x in path)\n        prev_split = 0\n        for i in range(len(shape)):\n            if shape[i] == \"m\" and prev_split != i:\n                self.paint_single_path(\n                    gstate, stroke, fill, evenodd, path[prev_split:i]\n                )\n                prev_split = i\n            if shape[i] == \"h\":\n                self.paint_single_path(\n                    gstate, stroke, fill, evenodd, path[prev_split : i + 1]\n                )\n                prev_split = i + 1\n\n        # clean up remaining segments\n        if prev_split < len(shape):\n            self.paint_single_path(gstate, stroke, fill, evenodd, path[prev_split:])", "response": "Convert long paths to small segments each time we move or close path for polygon\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a single path draw command into lines and curves objects", "response": "def paint_single_path(self, gstate, stroke, fill, evenodd, path):\n        \"\"\"\n        Converting a single path draw command into lines and curves objects\n        \"\"\"\n        if len(path) < 2:\n            return\n        shape = \"\".join(x[0] for x in path)\n\n        pts = []\n        for p in path:\n            for i in range(1, len(p), 2):\n                pts.append(apply_matrix_pt(self.ctm, (p[i], p[i + 1])))\n\n        # Line mode\n        if self.line_only_shape.match(shape):\n            # check for sloped lines first\n            has_slope = False\n            for i in range(len(pts) - 1):\n                if pts[i][0] != pts[i + 1][0] and pts[i][1] != pts[i + 1][1]:\n                    has_slope = True\n                    break\n            if not has_slope:\n                for i in range(len(pts) - 1):\n                    self.cur_item.add(LTLine(gstate.linewidth, pts[i], pts[i + 1]))\n\n                # Adding the closing line for a polygon, especially rectangles\n                if shape.endswith(\"h\"):\n                    self.cur_item.add(LTLine(gstate.linewidth, pts[0], pts[-1]))\n                return\n\n        # Add the curve as an arbitrary polyline (belzier curve info is lost here)\n        self.cur_item.add(LTCurve(gstate.linewidth, pts))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntreeing walker and invokes the callback as it CTYPE traverse pdf object tree", "response": "def traverse_layout(root, callback):\n    \"\"\"\n    Tree walker and invokes the callback as it\n    traverse pdf object tree\n    \"\"\"\n    callback(root)\n    if isinstance(root, collections.Iterable):\n        for child in root:\n            traverse_layout(child, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all items that are near the key tree_key.", "response": "def get_near_items(tree, tree_key):\n    \"\"\"\n    Check both possible neighbors for key\n    in a binary tree\n    \"\"\"\n    try:\n        yield tree.floor_item(tree_key)\n    except KeyError:\n        pass\n    try:\n        yield tree.ceiling_item(tree_key)\n    except KeyError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef align_add(tree, key, item, align_thres=2.0):\n    for near_key, near_list in get_near_items(tree, key):\n        if abs(key - near_key) < align_thres:\n            near_list.append(item)\n            return\n    # Create a new group if no items are close\n    tree[key] = [item]", "response": "Add an item object to a binary tree with the given key while allow for small key differences\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of elements that are contained inside the given bbox.", "response": "def collect_table_content(table_bboxes, elems):\n    \"\"\"\n    Returns a list of elements that are contained inside\n    the corresponding supplied bbox.\n    \"\"\"\n    # list of table content chars\n    table_contents = [[] for _ in range(len(table_bboxes))]\n    prev_content = None\n    prev_bbox = None\n    for cid, c in enumerate(elems):\n        # Annotations should not fall outside alone\n        if isinstance(c, LTAnno):\n            if prev_content is not None:\n                prev_content.append(c)\n            continue\n        # Generally speaking table contents should be included sequentially\n        # and we can avoid checking all tables for elems inside\n        # Elements only need to intersect the bbox for table as some\n        # formatting of fonts may result in slightly out of bbox text\n        if prev_bbox is not None and intersect(prev_bbox, c.bbox):\n            prev_content.append(c)\n            continue\n        # Search the rest of the tables for membership when done with\n        # the current one\n        for table_id, table_bbox in enumerate(table_bboxes):\n            if intersect(table_bbox, c.bbox):\n                prev_bbox = table_bbox\n                prev_content = table_contents[table_id]\n                prev_content.append(c)\n                break\n    return table_contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gaps_from(intervals):\n    sliding_window = zip(intervals, intervals[1:])\n    gaps = [b[0] - a[1] for a, b in sliding_window]\n    return gaps", "response": "Extract gaps from a list of intervals"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef project_onto(objs, axis, min_gap_size=4.0):\n    if axis == \"x\":\n        axis = 0\n    if axis == \"y\":\n        axis = 1\n    axis_end = axis + 2\n    if axis == 0:  # if projecting onto X axis\n        objs.sort(key=lambda o: o.x0)\n    else:\n        objs.sort(key=lambda o: o.y0)\n\n    intervals = []\n    groups = []\n\n    start_i = 0\n    start = objs[0].bbox[axis]\n    end = objs[0].bbox[axis_end]\n\n    # Use _inf_bbox to trigger the last interval divide\n    for o_i, o in enumerate(chain(objs, [_inf_bbox])):\n\n        # Get current interval\n        o_start = o.bbox[axis]\n        o_end = o.bbox[axis_end]\n\n        # start new interval when gap with previous end is big\n        if o_start > end + min_gap_size:\n\n            # Append new interval coordinates for children\n            intervals.append((start, end))\n\n            # Append child object group on page\n            groups.append(objs[start_i:o_i])\n\n            # Mark next obj list range\n            start_i = o_i\n            start = o_start\n\n        # Always check to extend current interval to new end\n        if o_end > end:\n            end = o_end\n        # else do nothing\n    return intervals, groups", "response": "Projects objects onto the specified axis and returns the unioned intervals and groups of objects in intervals."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recursive_xy_divide(elems, avg_font_size):\n    log = logging.getLogger(__name__)\n    log.info(avg_font_size)\n    objects = list(elems.mentions)\n    objects.extend(elems.segments)\n    bboxes = []\n\n    # A tree that is a list of its children\n    # bboxes can be recursively reconstructed from\n    # the leaves\n    def divide(objs, bbox, h_split=True, is_single=False):\n        \"\"\"\n        Recursive wrapper for splitting a list of objects\n        with bounding boxes.\n        h_split: whether to split along y axis, otherwise\n        we split along x axis.\n        \"\"\"\n        if not objs:\n            return []\n\n        # range start/end indices\n        axis = 1 if h_split else 0\n\n        intervals, groups = project_onto(objs, axis, avg_font_size)\n\n        # base case where we can not actually divide\n        single_child = len(groups) == 1\n\n        # Can not divide in both X and Y, stop\n        if is_single and single_child:\n            bboxes.append(bbox)\n            return objs\n        else:\n            children = []\n\n            for interval, group in zip(intervals, groups):\n                # Create the bbox for the subgroup\n                sub_bbox = np.array(bbox)\n                sub_bbox[[axis, axis + 2]] = interval\n                # Append the sub-document tree\n                child = divide(group, sub_bbox, not h_split, single_child)\n                children.append(child)\n            return children\n\n    full_page_bbox = (0, 0, elems.layout.width, elems.layout.height)\n    # Filter out invalid objects\n    objects = [o for o in objects if inside(full_page_bbox, o.bbox)]\n    log.info(\"avg_font_size for dividing\", avg_font_size)\n    tree = divide(objects, full_page_bbox) if objects else []\n    return bboxes, tree", "response": "Recursively group the document by white stripes by projecting elements onto alternating axes as intervals and then divides the document by the top - left corner of the elements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doOverlap(bbox1, bbox2):\n    if bbox1[2] < bbox2[0] or bbox2[2] < bbox1[0]:\n        return False\n    if bbox1[3] < bbox2[1] or bbox2[3] < bbox1[1]:\n        return False\n    return True", "response": "Checks if two rectangles overlap with the current one"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if bbox1 is contained in bbox2.", "response": "def isContained(bbox1, bbox2, tol=TOLERANCE):\n    \"\"\"\n    :param bbox1: bounding box of the first rectangle\n    :param bbox2: bounding box of the second rectangle\n    :return: True if bbox1 is contaned in bbox2\n    \"\"\"\n    if bbox1[0] > bbox2[0] - tol and bbox1[1] > bbox2[1] - tol:\n        if bbox1[2] < bbox2[2] + tol and bbox1[3] < bbox2[3] + tol:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mergeBboxes(bbox1, bbox2):\n    if isContained(bbox1, bbox2):\n        return bbox2\n    elif isContained(bbox2, bbox1):\n        return bbox1\n    else:\n        return (\n            min(bbox1[0], bbox2[0]),\n            min(bbox1[1], bbox2[1]),\n            max(bbox1[2], bbox2[2]),\n            max(bbox1[3], bbox2[3]),\n        )", "response": "Merge two bounding boxes into one."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of rectangles for the tables in the n - tree.", "response": "def get_rectangles(vertical_lines, horizontal_lines):\n    \"\"\"\n    :param vertical_lines: list of vertical lines coordinates\n    :param horizontal_lines: list of horizontal lines coordinates\n    :return: List of bounding boxes for tables\n    \"\"\"\n    rectangles = []\n    i = 0\n    j = 0\n    while i < len(horizontal_lines) and j < len(vertical_lines):\n        if int(horizontal_lines[i][0]) == vertical_lines[j][0]:\n            if int(horizontal_lines[i][1]) == int(vertical_lines[j][1]):\n                h = horizontal_lines[i]\n                v = vertical_lines[j]\n                rectangles += [(v[0], h[1], v[2], h[3])]\n                i += 1\n                j += 1\n            elif int(horizontal_lines[i][1]) < int(vertical_lines[j][1]):\n                i += 1\n            else:\n                j += 1\n        elif int(horizontal_lines[i][0]) < int(vertical_lines[j][0]):\n            i += 1\n        else:\n            j += 1\n    rectangles = [\n        r\n        for r in rectangles\n        if ((r[2] - r[0]) > TOLERANCE and (r[3] - r[1]) > TOLERANCE)\n    ]\n    return rectangles"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_outer_bounding_boxes(rectangles):\n    if len(rectangles) == 0:\n        return []\n    outer_bboxes = [rectangles[0]]\n    for bbox2 in rectangles[1:]:\n        overlap_indexes = []\n        for i, bbox1 in enumerate(outer_bboxes):  # TODO: optimize this !!\n            if doOverlap(bbox1, bbox2):\n                overlap_indexes.append(i)\n        for i in overlap_indexes:\n            bbox2 = mergeBboxes(bbox2, outer_bboxes[i])\n        for i in sorted(overlap_indexes, reverse=True):\n            del outer_bboxes[i]\n        outer_bboxes.append(bbox2)\n    return outer_bboxes", "response": "returns a list of bounding boxes that intersect the given list of rectangles"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the intersection of two bboxes.", "response": "def get_intersection(bbox1, bbox2):\n    \"\"\"\n    :param bbox1: (page, width, height, top, left, bottom, right)\n    :param bbox2: (page, width, height, top, left, bottom, right)\n    :return: intersection if bboxes are in the same page and intersect\n    \"\"\"\n    intersection = []\n    page_1, page_width, page_height, top_1, left_1, bottom_1, right_1 = bbox1\n    page_2, _, _, top_2, left_2, bottom_2, right_2 = bbox2\n    if page_1 == page_2:\n        if doOverlap(\n            (top_1, left_1, bottom_1, right_1), (top_2, left_2, bottom_2, right_2)\n        ):\n            intersection += [\n                (\n                    page_1,\n                    page_width,\n                    page_height,\n                    max(top_1, top_2),\n                    max(left_1, left_2),\n                    min(bottom_1, bottom_2),\n                    min(right_1, right_2),\n                )\n            ]\n    return intersection"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_iou(bbox1, bbox2):\n    top_1, left_1, bottom_1, right_1 = bbox1\n    top_2, left_2, bottom_2, right_2 = bbox2\n    if doOverlap(\n        (top_1, left_1, bottom_1, right_1), (top_2, left_2, bottom_2, right_2)\n    ):\n        intersection = (min(bottom_1, bottom_2) - max(top_1, top_2)) * (\n            min(right_1, right_2) - max(left_1, left_2)\n        )\n        union = (\n            (bottom_1 - top_1) * (right_1 - left_1)\n            + (bottom_2 - top_2) * (right_2 - left_2)\n            - intersection\n        )\n        return float(intersection) / float(union)\n    return 0.0", "response": "Compute the intersection over union of two bboxes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef display_bounding_boxes(img, blocks, alternatecolors=False, color=Color(\"blue\")):\n    draw = Drawing()\n    draw.fill_color = Color(\"rgba(0, 0, 0, 0)\")\n    draw.stroke_color = color\n    for block in blocks:\n        top, left, bottom, right = block[-4:]\n        if alternatecolors:\n            draw.stroke_color = Color(\n                \"rgba({},{},{}, 1)\".format(\n                    str(np.random.randint(255)),\n                    str(np.random.randint(255)),\n                    str(np.random.randint(255)),\n                )\n            )\n        draw.rectangle(\n            left=float(left), top=float(top), right=float(right), bottom=float(bottom)\n        )\n        draw(img)\n    display(img)", "response": "Displays the bounding boxes of the passed in blocks on an image of the pdf file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_bounding_boxes_within_notebook(\n    page_num, extractor, blocks, alternatecolors=False, color=Color(\"blue\")\n):\n    \"\"\"\n    Displays each of the bounding boxes passed in 'boxes' on an image of the pdf\n    pointed to by pdf_file\n    boxes is a list of 5-tuples (page, top, left, bottom, right)\n    \"\"\"\n    elems = extractor.elems[page_num]\n    page_width, page_height = int(elems.layout.width), int(elems.layout.height)\n    img = pdf_to_img(extractor.pdf_file, page_num, page_width, page_height)\n    draw = Drawing()\n    draw.fill_color = Color(\"rgba(0, 0, 0, 0)\")\n    draw.stroke_color = color\n    for block in blocks:\n        top, left, bottom, right = block[-4:]\n        if alternatecolors:\n            draw.stroke_color = Color(\n                \"rgba({},{},{}, 1)\".format(\n                    str(np.random.randint(255)),\n                    str(np.random.randint(255)),\n                    str(np.random.randint(255)),\n                )\n            )\n        draw.rectangle(\n            left=float(left), top=float(top), right=float(right), bottom=float(bottom)\n        )\n        draw(img)\n    return img", "response": "Displays the bounding boxes of the page in the notebook."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a pdf file into an image object", "response": "def pdf_to_img(pdf_file, page_num, page_width, page_height):\n    \"\"\"\n    Converts pdf file into image\n    :param pdf_file: path to the pdf file\n    :param page_num: page number to convert (index starting at 1)\n    :return: wand image object\n    \"\"\"\n    img = Image(filename=\"{}[{}]\".format(pdf_file, page_num - 1))\n    img.resize(page_width, page_height)\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndraws a rectangle on the grid.", "response": "def draw_rect(self, bbox, cell_val):\n        \"\"\"\n        Fills the bbox with the content values\n        Float bbox values are normalized to have non-zero area\n        \"\"\"\n        new_x0 = int(bbox[x0])\n        new_y0 = int(bbox[y0])\n        new_x1 = max(new_x0 + 1, int(bbox[x1]))\n        new_y1 = max(new_y0 + 1, int(bbox[y1]))\n\n        self.grid[new_x0:new_x1, new_y0:new_y1] = cell_val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay each of the bounding boxes passed in boxes on images of the pdf_file containing the page numbers of the pdf_file.", "response": "def display_boxes(self, tree, html_path, filename_prefix, alternate_colors=False):\n        \"\"\"\n        Displays each of the bounding boxes passed in 'boxes' on images of the pdf\n        pointed to by pdf_file\n        boxes is a list of 5-tuples (page, top, left, bottom, right)\n        \"\"\"\n        imgs = []\n        colors = {\n            \"section_header\": Color(\"blue\"),\n            \"figure\": Color(\"green\"),\n            \"figure_caption\": Color(\"green\"),\n            \"table_caption\": Color(\"red\"),\n            \"list\": Color(\"yellow\"),\n            \"paragraph\": Color(\"gray\"),\n            \"table\": Color(\"red\"),\n            \"header\": Color(\"brown\"),\n        }\n        for i, page_num in enumerate(tree.keys()):\n            img = self.pdf_to_img(page_num)\n            draw = Drawing()\n            draw.fill_color = Color(\"rgba(0, 0, 0, 0.0)\")\n            for clust in tree[page_num]:\n                for (pnum, pwidth, pheight, top, left, bottom, right) in tree[page_num][\n                    clust\n                ]:\n                    draw.stroke_color = colors[clust]\n                    draw.rectangle(left=left, top=top, right=right, bottom=bottom)\n                    draw.push()\n                    draw.font_size = 20\n                    draw.font_weight = 10\n                    draw.fill_color = colors[clust]\n                    if int(left) > 0 and int(top) > 0:\n                        draw.text(x=int(left), y=int(top), body=clust)\n                    draw.pop()\n            draw(img)\n            img.save(filename=html_path + filename_prefix + \"_page_\" + str(i) + \".png\")\n            imgs.append(img)\n        return imgs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef display_candidates(self, tree, html_path, filename_prefix):\n        imgs = self.display_boxes(\n            tree, html_path, filename_prefix, alternate_colors=True\n        )\n        return display(*imgs)", "response": "Displays the bounding boxes corresponding to candidates on an image of the pdf\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pdf_to_img(self, page_num, pdf_dim=None):\n        if not pdf_dim:\n            pdf_dim = get_pdf_dim(self.pdf_file)\n        page_width, page_height = pdf_dim\n        img = Image(filename=\"{}[{}]\".format(self.pdf_file, page_num - 1))\n        img.resize(page_width, page_height)\n        return img", "response": "Converts a pdf file into an image object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse pdf texts into a hypergraph grouped into rows and columns and then output", "response": "def parse_layout(elems, font_stat, combine=False):\n    \"\"\"\n    Parses pdf texts into a hypergraph grouped into rows\n    and columns and then output\n    \"\"\"\n    boxes_segments = elems.segments\n    boxes_curves = elems.curves\n    boxes_figures = elems.figures\n    page_width = elems.layout.width\n    #  page_height = elems.layout.height\n    boxes = elems.mentions\n    avg_font_pts = get_most_common_font_pts(elems.mentions, font_stat)\n    width = get_page_width(boxes + boxes_segments + boxes_figures + boxes_curves)\n    char_width = get_char_width(boxes)\n    grid_size = avg_font_pts / 2.0\n    for i, m in enumerate(boxes + elems.figures):\n        m.id = i\n        m.feats = defaultdict(bool)\n        prefix = \"\"\n        if isinstance(m, LTTextLine) and m.font_name:\n            prefix = m.font_name + \"-\" + str(m.font_size) + \"-\"\n        m.xc = (m.x0 + m.x1) / 2.0\n        m.yc = (m.y0 + m.y1) / 2.0\n        m.feats[prefix + \"x0\"] = m.x0_grid = m.x0 // grid_size\n        m.feats[prefix + \"x1\"] = m.x1_grid = m.x1 // grid_size\n        m.feats[prefix + \"xc\"] = m.xc_grid = m.xc // grid_size\n        m.feats[prefix + \"yc\"] = m.yc_grid = m.yc // grid_size\n\n    tbls, tbl_features = cluster_vertically_aligned_boxes(\n        boxes,\n        elems.layout.bbox,\n        avg_font_pts,\n        width,\n        char_width,\n        boxes_segments,\n        boxes_curves,\n        boxes_figures,\n        page_width,\n        combine,\n    )\n    return tbls, tbl_features"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_nodes(nodes, plane, page_stat, merge_indices):\n    # Merge inner boxes to the best outer box\n    # nodes.sort(key=Node.area)\n    to_be_removed = set()\n    for inner_idx in range(len(nodes)):\n        inner = nodes[inner_idx]\n        outers = []\n        outers_indices = []\n        for outer_idx in range(len(nodes)):\n            outer = nodes[outer_idx]\n            if outer is inner or outer in to_be_removed:\n                continue\n            if intersect(outer.bbox, inner.bbox):\n                outers.append(outer)\n                outers_indices.append(outer_idx)\n        if not outers:\n            continue\n        # Best is defined as min L1 distance to outer center\n        best_outer = min(\n            outers, key=lambda outer: l1(center(outer.bbox), center(inner.bbox))\n        )\n        best_outer_idx = outers_indices[outers.index(best_outer)]\n        to_be_removed.add(inner)\n        best_outer.merge(inner)\n        for cid_iter in range(len(merge_indices)):\n            if merge_indices[cid_iter] == merge_indices[inner_idx]:\n                merge_indices[cid_iter] = merge_indices[best_outer_idx]\n    return nodes, merge_indices", "response": "Merges overlapping nodes into a single node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_most_common_font_pts(mentions, font_stat):\n    log = logging.getLogger(__name__)\n    try:\n        # default min font size of 1 pt in case no font present\n        most_common_font_size = font_stat.most_common(1)[0][0]\n\n        count = 0.01  # avoid division by zero\n        height_sum = 0.02  # default to pts 2.0\n        for m in mentions:\n            if m.font_size == most_common_font_size:\n                height_sum += m.height\n                count += 1\n        return height_sum / count\n\n    except IndexError:\n        log.info(\"No text found on page. Default most_common_font_pts to 2.0\")\n        return 2.0", "response": "Get the most common font size for a list of mentions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncount the number of columns based on the content of the row_content.", "response": "def _get_cols(row_content):\n    \"\"\"\n    Counting the number columns based on the content of this row\n    \"\"\"\n    cols = []\n    subcell_col = []\n    prev_bar = None\n    for _coord, item in row_content:\n        if isinstance(item, LTTextLine):\n            subcell_col.append(item)\n        else:  # bar, add column content\n            # When there is no content, we count a None column\n            if prev_bar:\n                bar_ranges = (prev_bar, item)\n                col_items = subcell_col if subcell_col else [None]\n                cols.extend([bar_ranges, col_items])\n            prev_bar = item\n            subcell_col = []\n    # Remove extra column before first bar\n    return cols"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _one_contains_other(s1, s2):\n    return min(len(s1), len(s2)) == len(s1 & s2)", "response": "Returns True if one set contains the other."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_table(self):\n        if self.type_counts[\"text\"] < 6 or \"figure\" in self.type_counts:\n            return False\n        for e in self.elems:\n            # Characters written as curve are usually small, discard diagrams here\n            if elem_type(e) == \"curve\" and e.height * e.width > 100:\n                return False\n        # import re\n        # space_re = '\\\\s+'\n        # ws_arr = []\n        # whitespace_aligned = False\n        # for elem in self.elems:\n        #     elem_ws = []\n        #     for m in re.finditer(space_re, elem.get_text()):\n        #         elem_ws.append(m.start())\n        #     # print elem, elem_ws\n        #     if(len(elem_ws)>0):\n        #         ws_arr.append(elem_ws)\n        # # print ws_arr\n        # if(len(ws_arr)>0):\n        #     count_arr = max([ws_arr.count(i) for i in ws_arr])\n        #     if(float(count_arr)/len(ws_arr) > 0.75):\n        #         return True\n        if (\n            self.sum_elem_bbox / (self.height * self.width)\n        ) > self.table_area_threshold:\n            return False\n        has_many_x_align = False\n        has_many_y_align = False\n        for k, v in six.iteritems(self.feat_counts):\n            font_key = k[0]\n            if (\n                v >= 2 and \"-\" in font_key\n            ):  # Text row or column with more than 2 elements\n                if font_key[-2] == \"x\":\n                    has_many_x_align = True\n                if font_key[-2] == \"y\":\n                    has_many_y_align = True\n        return has_many_x_align and has_many_y_align", "response": "Determine if the node is a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_grid(self):\n        mentions, lines = _split_text_n_lines(self.elems)\n        # Sort mentions in reading order where y values are snapped to half\n        # height-sized grid\n        mentions.sort(key=lambda m: (m.yc_grid, m.xc))\n\n        grid = Grid(mentions, lines, self)\n        return grid", "response": "Standardize the layout of the table into a grid"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reorder_lines(lines, tol=TOLERANCE):\n    reordered_lines = []\n    for line in lines:\n        # we divide by tol and multiply by tol to truncate numbers, stairs function\n        reordered_lines += [\n            (\n                int(round(line.y0 / tol) * tol),\n                int(round(line.x0 / tol) * tol),\n                int(round(line.y1 / tol) * tol),\n                int(round(line.x1 / tol) * tol),\n            )\n        ]\n    return reordered_lines", "response": "Reorder the lines in a node list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_vertical_and_horizontal(lines):\n    # TODO: add some angle tolerance when lines are not perfectly aligned (eg:\n    # scanned pdf)\n    vertical_lines = sorted(\n        [e for e in lines if e[1] == e[3]], key=lambda tup: (tup[1], tup[0])\n    )\n    horitontal_lines = sorted([e for e in lines if e[0] == e[2]])\n    if len(vertical_lines) > 0:\n        vertical_lines = merge_vertical_lines(vertical_lines)\n    if len(horitontal_lines) > 0:\n        horitontal_lines = merge_horizontal_lines(horitontal_lines)\n    return vertical_lines, horitontal_lines", "response": "Extracts vertical and horizontal lines lists\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize the bounding box of the base image", "response": "def normalize_bbox(coords, ymax, scaler=2):\n    \"\"\"\n    scales all coordinates and flip y axis due to different\n    origin coordinates (top left vs. bottom left)\n    \"\"\"\n    return [\n        coords[0] * scaler,\n        ymax - (coords[3] * scaler),\n        coords[2] * scaler,\n        ymax - (coords[1] * scaler),\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes all coordinates and flip y axis due to different origin coordinates", "response": "def normalize_pts(pts, ymax, scaler=2):\n    \"\"\"\n    scales all coordinates and flip y axis due to different\n    origin coordinates (top left vs. bottom left)\n    \"\"\"\n    return [(x * scaler, ymax - (y * scaler)) for x, y in pts]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_debug_img(\n    file_name,\n    page_num,\n    elems,\n    nodes=[],\n    scaler=1,\n    print_segments=False,\n    print_curves=True,\n    print_table_bbox=True,\n    print_text_as_rect=True,\n):\n    \"\"\"\n    Shows an image rendering of the pdf page along with debugging\n    info printed\n    \"\"\"\n    # For debugging show the boolean pixels in black white grayscale\n    height = scaler * int(elems.layout.height)\n    width = scaler * int(elems.layout.width)\n    debug_img, draw = create_img((0, 0, width, height))\n    font = lazy_load_font()\n    large_font = lazy_load_font(24)\n\n    if print_curves:\n        for i, c in enumerate(elems.curves):\n            if len(c.pts) > 1:\n                draw.polygon(c.pts, outline=blue)\n            draw.rectangle(c.bbox, fill=blue)\n            # for fig in elems.figures:\n            #     draw.rectangle(fig.bbox, fill = blue)\n\n    for i, m in enumerate(elems.mentions):\n        if isinstance(m, LTAnno):\n            continue\n        if print_text_as_rect:\n            fill = \"pink\" if hasattr(m, \"feats\") and m.feats[\"is_cell\"] else green\n            #             fill = green\n            draw.rectangle(m.bbox, fill=fill)\n            # draw.text(center(m.bbox), str(i), black, font = font) # Draw id\n            draw.text(\n                m.bbox[:2], m.get_text(), black, font=font\n            )  # Draw mention content\n        else:\n            draw.text(m.bbox[:2], m.get_text(), \"black\", font=font)\n\n    if print_segments:\n        # draw skeleton for all segments\n        for i, s in enumerate(elems.segments):\n            draw.line(s.bbox, fill=\"black\")\n\n    if print_table_bbox:\n        for node in nodes:\n            is_table = node.is_table()\n            color = \"red\" if is_table else \"green\"\n            draw.rectangle(node.bbox, outline=color)\n            if is_table:\n                # text = 'Borderless' if node.is_borderless() else 'Bordered'\n                text = \"Table\"\n                draw.rectangle(node.bbox, outline=color)\n                draw.text(node.bbox[:2], text, red, font=large_font)\n\n    # Water mark with file name so we can identify among multiple images\n    if file_name and page_num is not None:\n        water_mark = (\n            file_name + \":page \" + str(page_num + 1) + \"@%dx%d\" % (width, height)\n        )\n        draw.text((10, 10), water_mark, black, font=font)\n    debug_img.show()\n    return debug_img", "response": "Render a debug image of the pdf page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_labels(self, gt_tables):\n        labels = np.zeros(len(self.candidates))\n        for i, candidate in enumerate(self.candidates):\n            page_num = candidate[0]\n            try:\n                tables = gt_tables[page_num]\n                for gt_table in tables:\n                    page_width, page_height, y0, x0, y1, x1 = gt_table\n                    w_ratio = float(candidate[1]) / page_width\n                    h_ratio = float(candidate[2]) / page_height\n                    rescaled_gt_table = (\n                        y0 * h_ratio,\n                        x0 * w_ratio,\n                        y1 * h_ratio,\n                        x1 * w_ratio,\n                    )\n                    iou = compute_iou(candidate[-4:], rescaled_gt_table)\n                    if iou > self.iou_thresh:\n                        # candidate region is a table\n                        labels[i] = 1\n            except KeyError:\n                # any of the candidates is a true table, all zero labels\n                pass\n        return labels", "response": "returns a list of labels that are used to identify the page that is in the GT tables"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_text_sparsity(bbox, mentions):\n    b = bbox[-4:]\n    bbox_area = (b[2] - b[0]) * (b[3] - b[1])\n    text_area = 0\n    for m in mentions:\n        text_area += (m.x1 - m.x0) * (m.y1 - m.y0)\n    try:\n        return 1.0 * text_area / bbox_area\n    except ZeroDivisionError:\n        return 0.0", "response": "computes the text sparsity of a list of mentions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _partition_estimators(n_estimators, n_jobs):\n    # Compute the number of jobs\n    if n_jobs == -1:\n        n_jobs = min(cpu_count(), n_estimators)\n\n    else:\n        n_jobs = min(n_jobs, n_estimators)\n\n    # Partition estimators between jobs\n    n_estimators_per_job = (n_estimators // n_jobs) * np.ones(n_jobs,\n                                                              dtype=np.int)\n    n_estimators_per_job[:n_estimators % n_jobs] += 1\n    starts = np.cumsum(n_estimators_per_job)\n\n    return n_jobs, n_estimators_per_job.tolist(), [0] + starts.tolist()", "response": "Private function used to partition estimators between jobs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parallel_build_estimators(n_estimators, ensemble, X, y, cost_mat,\n                               seeds, verbose):\n    \"\"\"Private function used to build a batch of estimators within a job.\"\"\"\n    # Retrieve settings\n    n_samples, n_features = X.shape\n    max_samples = ensemble.max_samples\n    max_features = ensemble.max_features\n\n    if (not isinstance(max_samples, (numbers.Integral, np.integer)) and\n            (0.0 < max_samples <= 1.0)):\n        max_samples = int(max_samples * n_samples)\n\n    if (not isinstance(max_features, (numbers.Integral, np.integer)) and\n            (0.0 < max_features <= 1.0)):\n        max_features = int(max_features * n_features)\n\n    bootstrap = ensemble.bootstrap\n    bootstrap_features = ensemble.bootstrap_features\n\n    # Build estimators\n    estimators = []\n    estimators_samples = []\n    estimators_features = []\n\n    for i in range(n_estimators):\n        if verbose > 1:\n            print((\"building estimator %d of %d\" % (i + 1, n_estimators)))\n\n        random_state = check_random_state(seeds[i])\n        seed = check_random_state(random_state.randint(MAX_INT))\n        estimator = ensemble._make_estimator(append=False)\n\n        try:  # Not all estimator accept a random_state\n            estimator.set_params(random_state=seed)\n        except ValueError:\n            pass\n\n        # Draw features\n        if bootstrap_features:\n            features = random_state.randint(0, n_features, max_features)\n        else:\n            features = sample_without_replacement(n_features,\n                                                  max_features,\n                                                  random_state=random_state)\n\n        # Draw samples, using a mask, and then fit\n        if bootstrap:\n            indices = random_state.randint(0, n_samples, max_samples)\n        else:\n            indices = sample_without_replacement(n_samples,\n                                                 max_samples,\n                                                 random_state=random_state)\n\n        sample_counts = np.bincount(indices, minlength=n_samples)\n\n        estimator.fit((X[indices])[:, features], y[indices], cost_mat[indices, :])\n        samples = sample_counts > 0.\n\n        estimators.append(estimator)\n        estimators_samples.append(samples)\n        estimators_features.append(features)\n\n    return estimators, estimators_samples, estimators_features", "response": "Private function used to build a batch of estimators within a job."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parallel_predict_proba(estimators, estimators_features, X, n_classes, combination, estimators_weight):\n    n_samples = X.shape[0]\n    proba = np.zeros((n_samples, n_classes))\n\n    for estimator, features, weight in zip(estimators, estimators_features, estimators_weight):\n        proba_estimator = estimator.predict_proba(X[:, features])\n        if combination in ['weighted_voting', 'weighted_bmr']:\n            proba += proba_estimator * weight\n        else:\n            proba += proba_estimator\n\n    return proba", "response": "Private function used to compute ( proba - ) predictions within a job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(self, X, y, cost_mat, sample_weight=None):\n        random_state = check_random_state(self.random_state)\n\n        # Convert data\n        # X, y = check_X_y(X, y, ['csr', 'csc', 'coo'])  # Not in sklearn verion 0.15\n\n        # Remap output\n        n_samples, self.n_features_ = X.shape\n        y = self._validate_y(y)\n\n        # Check parameters\n        self._validate_estimator()\n\n        if isinstance(self.max_samples, (numbers.Integral, np.integer)):\n            max_samples = self.max_samples\n        else:  # float\n            max_samples = int(self.max_samples * X.shape[0])\n\n        if not (0 < max_samples <= X.shape[0]):\n            raise ValueError(\"max_samples must be in (0, n_samples]\")\n\n        if isinstance(self.max_features, (numbers.Integral, np.integer)):\n            max_features = self.max_features\n        else:  # float\n            max_features = int(self.max_features * self.n_features_)\n\n        if not (0 < max_features <= self.n_features_):\n            raise ValueError(\"max_features must be in (0, n_features]\")\n\n        # Free allocated memory, if any\n        self.estimators_ = None\n\n        # Parallel loop\n        n_jobs, n_estimators, starts = _partition_estimators(self.n_estimators,\n                                                             self.n_jobs)\n        seeds = random_state.randint(MAX_INT, size=self.n_estimators)\n\n        all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n            delayed(_parallel_build_estimators)(\n                n_estimators[i],\n                self,\n                X,\n                y,\n                cost_mat,\n                seeds[starts[i]:starts[i + 1]],\n                verbose=self.verbose)\n            for i in range(n_jobs))\n\n        # Reduce\n        self.estimators_ = list(itertools.chain.from_iterable(\n            t[0] for t in all_results))\n        self.estimators_samples_ = list(itertools.chain.from_iterable(\n            t[1] for t in all_results))\n        self.estimators_features_ = list(itertools.chain.from_iterable(\n            t[2] for t in all_results))\n\n        self._evaluate_oob_savings(X, y, cost_mat)\n\n        if self.combination in ['stacking', 'stacking_proba', 'stacking_bmr', 'stacking_proba_bmr']:\n            self._fit_stacking_model(X, y, cost_mat)\n\n        if self.combination in ['majority_bmr', 'weighted_bmr', 'stacking_bmr', 'stacking_proba_bmr']:\n            self._fit_bmr_model(X, y)\n\n        return self", "response": "Fits the base estimator on the training set X and y and returns the ensemble of estimators."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _fit_bmr_model(self, X, y):\n        self.f_bmr = BayesMinimumRiskClassifier()\n        X_bmr = self.predict_proba(X)\n        self.f_bmr.fit(y, X_bmr)\n        return self", "response": "Private function used to fit the BayesMinimumRiskClassifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _evaluate_oob_savings(self, X, y, cost_mat):\n        estimators_weight = []\n        for estimator, samples, features in zip(self.estimators_, self.estimators_samples_,\n                                                self.estimators_features_):\n            # Test if all examples where used for training\n            if not np.any(~samples):\n                # Then use training\n                oob_pred = estimator.predict(X[:, features])\n                oob_savings = max(0, savings_score(y, oob_pred, cost_mat))\n            else:\n                # Then use OOB\n                oob_pred = estimator.predict((X[~samples])[:, features])\n                oob_savings = max(0, savings_score(y[~samples], oob_pred, cost_mat[~samples]))\n\n            estimators_weight.append(oob_savings)\n\n        # Control in case were all weights are 0\n        if sum(estimators_weight) == 0:\n            self.estimators_weight_ = np.ones(len(estimators_weight)) / len(estimators_weight)\n        else:\n            self.estimators_weight_ = (np.array(estimators_weight) / sum(estimators_weight)).tolist()\n\n        return self", "response": "Private function used to calculate the OOB Savings of each estimator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, X, cost_mat=None):\n        # Check data\n        # X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])  # Dont in version 0.15\n\n        if self.n_features_ != X.shape[1]:\n            raise ValueError(\"Number of features of the model must \"\n                             \"match the input. Model n_features is {0} and \"\n                             \"input n_features is {1}.\"\n                             \"\".format(self.n_features_, X.shape[1]))\n\n        #TODO: check if combination in possible combinations\n\n        if self.combination in ['stacking', 'stacking_proba']:\n\n            X_stacking = _create_stacking_set(self.estimators_, self.estimators_features_,\n                                              self.estimators_weight_, X, self.combination)\n            return self.f_staking.predict(X_stacking)\n\n        elif self.combination in ['majority_voting', 'weighted_voting']:\n            # Parallel loop\n            n_jobs, n_estimators, starts = _partition_estimators(self.n_estimators,\n                                                                 self.n_jobs)\n\n            all_pred = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n                delayed(_parallel_predict)(\n                    self.estimators_[starts[i]:starts[i + 1]],\n                    self.estimators_features_[starts[i]:starts[i + 1]],\n                    X,\n                    self.n_classes_,\n                    self.combination,\n                    self.estimators_weight_[starts[i]:starts[i + 1]])\n                for i in range(n_jobs))\n\n            # Reduce\n            pred = sum(all_pred) / self.n_estimators\n\n            return self.classes_.take(np.argmax(pred, axis=1), axis=0)\n\n        elif self.combination in ['majority_bmr', 'weighted_bmr', 'stacking_bmr', 'stacking_proba_bmr']:\n            #TODO: Add check if cost_mat == None\n            X_bmr = self.predict_proba(X)\n            return self.f_bmr.predict(X_bmr, cost_mat)", "response": "Predicts the class with the highest mean predicted probability of an input sample."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npredicting class probabilities for X.", "response": "def predict_proba(self, X):\n        \"\"\"Predict class probabilities for X.\n\n        The predicted class probabilities of an input sample is computed as\n        the mean predicted class probabilities of the base estimators in the\n        ensemble. If base estimators do not implement a ``predict_proba``\n        method, then it resorts to voting and the predicted class probabilities\n        of a an input sample represents the proportion of estimators predicting\n        each class.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n            The training input samples. Sparse matrices are accepted only if\n            they are supported by the base estimator.\n\n        Returns\n        -------\n        p : array of shape = [n_samples, n_classes]\n            The class probabilities of the input samples. The order of the\n            classes corresponds to that in the attribute `classes_`.\n        \"\"\"\n        # Check data\n        # X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])  # Dont in version 0.15\n\n        if self.n_features_ != X.shape[1]:\n            raise ValueError(\"Number of features of the model must \"\n                             \"match the input. Model n_features is {0} and \"\n                             \"input n_features is {1}.\"\n                             \"\".format(self.n_features_, X.shape[1]))\n\n        # Parallel loop\n        n_jobs, n_estimators, starts = _partition_estimators(self.n_estimators, self.n_jobs)\n\n        all_proba = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n            delayed(_parallel_predict_proba)(\n                self.estimators_[starts[i]:starts[i + 1]],\n                self.estimators_features_[starts[i]:starts[i + 1]],\n                X,\n                self.n_classes_,\n                self.combination,\n                self.estimators_weight_[starts[i]:starts[i + 1]])\n            for i in range(n_jobs))\n\n        # Reduce\n        if self.combination in ['majority_voting', 'majority_bmr']:\n            proba = sum(all_proba) / self.n_estimators\n        elif self.combination in ['weighted_voting', 'weighted_bmr']:\n            proba = sum(all_proba)\n        elif self.combination in ['stacking', 'stacking_proba', 'stacking_bmr', 'stacking_proba_bmr']:\n            X_stacking = _create_stacking_set(self.estimators_, self.estimators_features_,\n                                              self.estimators_weight_, X, self.combination)\n            proba = self.f_staking.predict_proba(X_stacking)\n\n        return proba"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cost_sampling(X, y, cost_mat, method='RejectionSampling', oversampling_norm=0.1, max_wc=97.5):\n\n    #TODO: Check consistency of input\n\n    # The methods are construct only for the misclassification costs, not the full cost matrix.\n    cost_mis = cost_mat[:, 0]\n    cost_mis[y == 1] = cost_mat[y == 1, 1]\n\n    # wc = cost_mis / cost_mis.max()\n    wc = np.minimum(cost_mis / np.percentile(cost_mis, max_wc), 1)\n\n    n_samples = X.shape[0]\n\n    filter_ = list(range(n_samples))\n\n    if method == 'RejectionSampling':\n        # under-sampling by rejection [1]\n        #TODO: Add random state\n        rej_rand = np.random.rand(n_samples)\n\n        filter_ = rej_rand <= wc\n\n    elif method == 'OverSampling':\n        # over-sampling with normalized wn [2]\n        wc_n = np.ceil(wc / oversampling_norm).astype(np.int)\n\n        new_n = wc_n.sum()\n\n        filter_ = np.ones(new_n, dtype=np.int)\n\n        e = 0\n        #TODO replace for\n        for i in range(n_samples):\n            filter_[e: e + wc_n[i]] = i\n            e += wc_n[i]\n\n    x_cps = X[filter_]\n    y_cps = y[filter_]\n    cost_mat_cps = cost_mat[filter_]\n\n    return x_cps, y_cps, cost_mat_cps", "response": "Cost - proportionate sampling of the given data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload and return the churn dataset.", "response": "def load_churn():\n    \"\"\"Load and return the churn dataset (classification).\n\n    The bank marketing is a easily transformable example-dependent cost-sensitive classification dataset.\n\n    Returns\n    -------\n    data : Bunch\n        Dictionary-like object, the interesting attributes are:\n        'data', the data to learn, 'target', the classification labels,\n        'cost_mat', the cost matrix of each example,\n        'target_names', the meaning of the labels, 'feature_names', the\n        meaning of the features, and 'DESCR', the full description of the dataset.\n\n    References\n    ----------\n    .. [1] A. Correa Bahnsen, D.Aouada, B, Ottersten,\n           `\"A novel cost-sensitive framework for customer churn predictive modeling\" <http://www.decisionanalyticsjournal.com/content/pdf/s40165-015-0014-6.pdf>`__,\n           Decision Analytics, 2:5, 2015.\n\n    Examples\n    --------\n    Let's say you are interested in the samples 10, 25, and 50\n\n    >>> from costcla.datasets import load_churn\n    >>> data = load_churn()\n    >>> data.target[[10, 18, 24]]\n    array([0, 0, 1])\n    >>> data.cost_mat[[10, 18, 24]]\n    array([[   70.571429,  1371.428571,   109.657143,     0.      ],\n           [   79.142857,   857.142857,   141.542857,     0.      ],\n           [   79.142857,  1542.857143,   123.114286,     0.      ]])\n    \"\"\"\n    module_path = dirname(__file__)\n    raw_data = pd.read_csv(join(module_path, 'data', 'churn_tv_subscriptions.csv.gz'),\n                           delimiter=',', compression='gzip')\n    descr = open(join(module_path, 'descr', 'churn_tv_subscriptions.rst')).read()\n\n    target = raw_data['target'].values.astype(np.int)\n    n_samples = raw_data.shape[0]\n\n    # Continous features\n    data = raw_data.ix[:, 1:-5]\n\n    cost_mat = np.ones((n_samples, 4))  #cost_mat[FP,FN,TP,TN]\n    cost_mat[:, 0] = raw_data.C_FP\n    cost_mat[:, 1] = raw_data.C_FN\n    cost_mat[:, 2] = raw_data.C_TP\n    cost_mat[:, 3] = raw_data.C_TN\n\n    return Bunch(data=data.values, target=target, cost_mat=cost_mat,\n                 target_names=['no', 'yes'], DESCR=descr,\n                 feature_names=data.columns.values, name='Churn')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload and return the bank marketing dataset.", "response": "def load_bankmarketing(cost_mat_parameters=None):\n    \"\"\"Load and return the bank marketing dataset (classification).\n\n    The bank marketing is a easily transformable example-dependent cost-sensitive classification dataset.\n\n    Parameters\n    ----------\n    cost_mat_parameters : Dictionary-like object, optional (default=None)\n        If not None, must include 'per_balance', 'ca', and 'int_r'\n\n    Returns\n    -------\n    data : Bunch\n        Dictionary-like object, the interesting attributes are:\n        'data', the data to learn, 'target', the classification labels,\n        'cost_mat', the cost matrix of each example,\n        'target_names', the meaning of the labels, 'feature_names', the\n        meaning of the features, and 'DESCR', the full description of the dataset.\n\n    References\n    ----------\n    .. [1] A. Correa Bahnsen, A. Stojanovic, D.Aouada, B, Ottersten,\n           `\"Improving Credit Card Fraud Detection with Calibrated Probabilities\" <http://albahnsen.com/files/%20Improving%20Credit%20Card%20Fraud%20Detection%20by%20using%20Calibrated%20Probabilities%20-%20Publish.pdf>`__, in Proceedings of the fourteenth SIAM International Conference on Data Mining,\n           677-685, 2014.\n\n    Examples\n    --------\n    Let's say you are interested in the samples 10, 25, and 50\n\n    >>> from costcla.datasets import load_bankmarketing\n    >>> data = load_bankmarketing()\n    >>> data.target[[10, 25, 319]]\n    array([0, 0, 1])\n    >>> data.cost_mat[[10, 25, 319]]\n    array([[ 1.        ,  1.66274977,  1.        ,  0.        ],\n           [ 1.        ,  1.63195811,  1.        ,  0.        ],\n           [ 1.        ,  5.11141597,  1.        ,  0.        ]])\n    \"\"\"\n    module_path = dirname(__file__)\n    raw_data = pd.read_csv(join(module_path, 'data', 'bankmarketing.csv.gz'), delimiter=';', compression='gzip')\n    descr = open(join(module_path, 'descr', 'bankmarketing.rst')).read()\n\n    #only use features pre-contact:\n    # 1 - age (numeric)\n    # 2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\n    #                        \"student\",\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n    # 3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\";\n    #                               note: \"divorced\" means divorced or widowed)\n    # 4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n    # 5 - default: has credit in default? (binary: \"yes\",\"no\")\n    # 6 - balance: average yearly balance, in euros (numeric)\n    # 7 - housing: has housing loan? (binary: \"yes\",\"no\")\n    # 8 - loan: has personal loan? (binary: \"yes\",\"no\")\n    # 15 - previous: number of contacts performed before this campaign and for this client (numeric)\n    # 16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n\n    #Folloring features exclude because are collected after the contact event\n    # # related with the last contact of the current campaign:\n    # 9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\")\n    # 10 - day: last contact day of the month (numeric)\n    # 11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n    # 12 - duration: last contact duration, in seconds (numeric)\n    # # other attributes:\n    # 13 - campaign: number of contacts performed during this campaign and for this client\n    # 14 - pdays: number of days that passed by after the client was last contacted from a\n    #       previous campaign (numeric, -1 means client was not previously contacted)\n\n    #Filter if balance>0\n    raw_data = raw_data.loc[raw_data['balance'] > 0]\n\n    n_samples = raw_data.shape[0]\n\n    target = np.zeros((n_samples,), dtype=np.int)\n    target[raw_data['y'].values == 'yes'] = 1\n\n    # Create dummies\n    data = raw_data[['age', 'balance', 'previous']]\n    cols_dummies = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome']\n\n    for col_ in cols_dummies:\n        temp_ = pd.get_dummies(raw_data[col_], prefix=col_)\n        data = data.join(temp_)\n\n    # Calculate cost_mat (see[1])\n    if cost_mat_parameters is None:\n        cost_mat_parameters = {'per_balance': 0.25, 'ca': 1, 'int_r': 0.02463333}\n\n    per_balance = cost_mat_parameters['per_balance']\n    ca = cost_mat_parameters['ca']\n    int_r = cost_mat_parameters['int_r']\n\n    cost_mat = np.zeros((n_samples, 4))  # cost_mat[FP,FN,TP,TN]\n    cost_mat[:, 0] = ca\n    cost_mat[:, 1] = np.maximum(data['balance'].values * int_r * per_balance, ca)  # C_FN >= C_TN Elkan\n    cost_mat[:, 2] = ca\n    cost_mat[:, 3] = 0.0\n\n    return Bunch(data=data.values, target=target, cost_mat=cost_mat,\n                 target_names=['no', 'yes'], DESCR=descr,\n                 feature_names=data.columns.values, name='DirectMarketing')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_creditscoring1(cost_mat_parameters=None):\n    module_path = dirname(__file__)\n    raw_data = pd.read_csv(join(module_path, 'data', 'creditscoring1.csv.gz'), delimiter=',', compression='gzip')\n    descr = open(join(module_path, 'descr', 'creditscoring1.rst')).read()\n\n    # Exclude MonthlyIncome = nan or =0 or DebtRatio >1\n    raw_data = raw_data.dropna()\n    raw_data = raw_data.loc[(raw_data['MonthlyIncome'] > 0)]\n    raw_data = raw_data.loc[(raw_data['DebtRatio'] < 1)]\n\n    target = raw_data['SeriousDlqin2yrs'].values.astype(np.int)\n\n    data = raw_data.drop(['SeriousDlqin2yrs', 'id'], 1)\n\n    # Calculate cost_mat (see[1])\n    if cost_mat_parameters is None:\n        cost_mat_parameters = {'int_r': 0.0479 / 12,\n                               'int_cf': 0.0294 / 12,\n                               'cl_max': 25000,\n                               'n_term': 24,\n                               'k': 3,\n                               'lgd': .75}\n\n    pi_1 = target.mean()\n    cost_mat = _creditscoring_costmat(data['MonthlyIncome'].values, data['DebtRatio'].values, pi_1, cost_mat_parameters)\n\n    return Bunch(data=data.values, target=target, cost_mat=cost_mat,\n                 target_names=['no', 'yes'], DESCR=descr,\n                 feature_names=data.columns.values, name='CreditScoring_Kaggle2011')", "response": "Load and return the credit scoring dataset for a single class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading and return the credit scoring PAKDD 2009 competition dataset.", "response": "def load_creditscoring2(cost_mat_parameters=None):\n    \"\"\"Load and return the credit scoring PAKDD 2009 competition dataset (classification).\n\n    The credit scoring is a easily transformable example-dependent cost-sensitive classification dataset.\n\n    Parameters\n    ----------\n    cost_mat_parameters : Dictionary-like object, optional (default=None)\n        If not None, must include 'int_r', 'int_cf', 'cl_max', 'n_term', 'k','lgd'\n\n    Returns\n    -------\n    data : Bunch\n        Dictionary-like object, the interesting attributes are:\n        'data', the data to learn, 'target', the classification labels,\n        'cost_mat', the cost matrix of each example,\n        'target_names', the meaning of the labels, 'feature_names', the\n        meaning of the features, and 'DESCR', the full description of the dataset.\n\n    References\n    ----------\n    .. [1] A. Correa Bahnsen, D.Aouada, B, Ottersten,\n           \"Example-Dependent Cost-Sensitive Logistic Regression for Credit Scoring\",\n           in Proceedings of the International Conference on Machine Learning and Applications,\n           , 2014.\n\n    Examples\n    --------\n    Let's say you are interested in the samples 10, 25, and 50\n\n    >>> from costcla.datasets import load_creditscoring2\n    >>> data = load_creditscoring2()\n    >>> data.target[[10, 17, 50]]\n    array([1, 0, 0])\n    >>> data.cost_mat[[10, 17, 50]]\n    array([[ 209.   ,  547.965,    0.   ,    0.   ],\n           [  24.   ,  274.725,    0.   ,    0.   ],\n           [  89.   ,  371.25 ,    0.   ,    0.   ]])\n    \"\"\"\n    module_path = dirname(__file__)\n    raw_data = pd.read_csv(join(module_path, 'data', 'creditscoring2.csv.gz'), delimiter='\\t', compression='gzip')\n    descr = open(join(module_path, 'descr', 'creditscoring2.rst')).read()\n\n    # Exclude TARGET_LABEL_BAD=1 == 'N'\n    raw_data = raw_data.loc[raw_data['TARGET_LABEL_BAD=1'] != 'N']\n\n    # Exclude 100<PERSONAL_NET_INCOME<10000\n    raw_data = raw_data.loc[(raw_data['PERSONAL_NET_INCOME'].values.astype(np.float) > 100)]\n    raw_data = raw_data.loc[(raw_data['PERSONAL_NET_INCOME'].values.astype(np.float) < 10000)]\n\n    target = raw_data['TARGET_LABEL_BAD=1'].values.astype(np.int)\n\n    # Continuous features\n    cols_con = ['ID_SHOP', 'AGE', 'AREA_CODE_RESIDENCIAL_PHONE', 'PAYMENT_DAY', 'SHOP_RANK',\n                'MONTHS_IN_RESIDENCE', 'MONTHS_IN_THE_JOB', 'PROFESSION_CODE', 'MATE_INCOME',\n                'QUANT_ADDITIONAL_CARDS_IN_THE_APPLICATION', 'PERSONAL_NET_INCOME']\n    data = raw_data[cols_con].astype(float)\n\n    cols_dummies = ['SEX', 'MARITAL_STATUS', 'FLAG_RESIDENCIAL_PHONE', 'RESIDENCE_TYPE',\n                    'FLAG_MOTHERS_NAME', 'FLAG_FATHERS_NAME', 'FLAG_RESIDENCE_TOWN_eq_WORKING_TOWN',\n                    'FLAG_RESIDENCE_STATE_eq_WORKING_STATE', 'FLAG_RESIDENCIAL_ADDRESS_eq_POSTAL_ADDRESS']\n    for col_ in cols_dummies:\n        temp_ = pd.get_dummies(raw_data[col_], prefix=col_)\n        data = data.join(temp_)\n\n    # Calculate cost_mat (see[1])\n    if cost_mat_parameters is None:\n        cost_mat_parameters = {'int_r': 0.63 / 12,\n                               'int_cf': 0.165 / 12,\n                               'cl_max': 25000 * 0.33,\n                               'n_term': 24,\n                               'k': 3,\n                               'lgd': .75}\n\n    n_samples = data.shape[0]\n    pi_1 = target.mean()\n    monthly_income = data['PERSONAL_NET_INCOME'].values * 0.33\n    cost_mat = _creditscoring_costmat(monthly_income, np.zeros(n_samples), pi_1, cost_mat_parameters)\n\n    return Bunch(data=data.values, target=target, cost_mat=cost_mat,\n                 target_names=['no', 'yes'], DESCR=descr,\n                 feature_names=data.columns.values, name='CreditScoring_PAKDD2009')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _creditscoring_costmat(income, debt, pi_1, cost_mat_parameters):\n    def calculate_a(cl_i, int_, n_term):\n        \"\"\" Private function \"\"\"\n        return cl_i * ((int_ * (1 + int_) ** n_term) / ((1 + int_) ** n_term - 1))\n\n    def calculate_pv(a, int_, n_term):\n        \"\"\" Private function \"\"\"\n        return a / int_ * (1 - 1 / (1 + int_) ** n_term)\n\n    #Calculate credit line Cl\n    def calculate_cl(k, inc_i, cl_max, debt_i, int_r, n_term):\n        \"\"\" Private function \"\"\"\n        cl_k = k * inc_i\n        A = calculate_a(cl_k, int_r, n_term)\n        Cl_debt = calculate_pv(inc_i * min(A / inc_i, 1 - debt_i), int_r, n_term)\n        return min(cl_k, cl_max, Cl_debt)\n\n    #calculate costs\n    def calculate_cost_fn(cl_i, lgd):\n        return cl_i * lgd\n\n    def calculate_cost_fp(cl_i, int_r, n_term, int_cf, pi_1, lgd, cl_avg):\n        a = calculate_a(cl_i, int_r, n_term)\n        pv = calculate_pv(a, int_cf, n_term)\n        r = pv - cl_i\n        r_avg = calculate_pv(calculate_a(cl_avg, int_r, n_term), int_cf, n_term) - cl_avg\n        cost_fp = r - (1 - pi_1) * r_avg + pi_1 * calculate_cost_fn(cl_avg, lgd)\n        return max(0, cost_fp)\n\n    v_calculate_cost_fp = np.vectorize(calculate_cost_fp)\n    v_calculate_cost_fn = np.vectorize(calculate_cost_fn)\n\n    v_calculate_cl = np.vectorize(calculate_cl)\n\n    # Parameters\n    k = cost_mat_parameters['k']\n    int_r = cost_mat_parameters['int_r']\n    n_term = cost_mat_parameters['n_term']\n    int_cf = cost_mat_parameters['int_cf']\n    lgd = cost_mat_parameters['lgd']\n    cl_max = cost_mat_parameters['cl_max']\n\n    cl = v_calculate_cl(k, income, cl_max, debt, int_r, n_term)\n    cl_avg = cl.mean()\n\n    n_samples = income.shape[0]\n    cost_mat = np.zeros((n_samples, 4))  #cost_mat[FP,FN,TP,TN]\n    cost_mat[:, 0] = v_calculate_cost_fp(cl, int_r, n_term, int_cf, pi_1, lgd, cl_avg)\n    cost_mat[:, 1] = v_calculate_cost_fn(cl, lgd)\n    cost_mat[:, 2] = 0.0\n    cost_mat[:, 3] = 0.0\n\n    return cost_mat", "response": "Private function to calculate the cost matrix of the credit scoring models."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(self, y, p):\n\n        # TODO: Check input\n        if p.size != p.shape[0]:\n            p = p[:, 1]\n\n        fpr, tpr, thresholds = roc_curve(y, p)\n        #works with sklearn 0.11\n        if fpr.min() > 0 or tpr.min() > 0:\n            fpr = np.hstack((0, fpr))\n            tpr = np.hstack((0, tpr))\n            thresholds = np.hstack((1.01, thresholds))\n\n        def prob_freq(y, predict_proba):\n            #calculate distribution and return in inverse order\n            proba_bins = np.unique(predict_proba)\n            freq_all = np.bincount(proba_bins.searchsorted(predict_proba))\n            freq_0_tempa = np.unique(predict_proba[np.nonzero(y == 0)[0]])\n            freq_0_tempb = np.bincount(freq_0_tempa.searchsorted(predict_proba[np.nonzero(y == 0)[0]]))\n            freq = np.zeros((proba_bins.shape[0], 3))\n            freq[:, 0] = proba_bins\n            for i in range(freq_0_tempa.shape[0]):\n                freq[np.nonzero(proba_bins == freq_0_tempa[i])[0], 1] = freq_0_tempb[i]\n            freq[:, 2] = freq_all - freq[:, 1]\n            freq = freq[proba_bins.argsort()[::-1], :]\n            pr = freq[:, 2] / freq[:, 1:].sum(axis=1)\n            pr = pr.reshape(freq.shape[0], 1)\n            #fix when no negatives in range\n            pr[pr == 1.0] = 0\n            freq = np.hstack((freq, pr))\n            return freq\n\n        f = prob_freq(y, p)\n        temp_hull = []\n        for i in range(fpr.shape[0]):\n            temp_hull.append((fpr[i], tpr[i]))\n        #close the plane\n        temp_hull.append((1, 0))\n        rocch_ = _convexhull(temp_hull)\n        rocch = np.array([(a, b) for (a, b) in rocch_[:-1]])\n        rocch_find = np.zeros(fpr.shape[0], dtype=np.bool)\n        for i in range(rocch.shape[0]):\n            rocch_find[np.intersect1d(np.nonzero(rocch[i, 0] == fpr)[0],\n                                      np.nonzero(rocch[i, 1] == tpr)[0])] = True\n        rocch_thresholds = thresholds[rocch_find]\n        #calibrated probabilities using ROCCH\n        f_cal = np.zeros((rocch_thresholds.shape[0] - 1, 5))\n        for i in range(rocch_thresholds.shape[0] - 1):\n            f_cal[i, 0] = rocch_thresholds[i]\n            f_cal[i, 1] = rocch_thresholds[i + 1]\n            join_elements = np.logical_and(f_cal[i, 1] <= f[:, 0], f_cal[i, 0] > f[:, 0])\n            f_cal[i, 2] = f[join_elements, 1].sum()\n            f_cal[i, 3] = f[join_elements, 2].sum()\n        f_cal[:, 4] = f_cal[:, 3] / f_cal[:, [2, 3]].sum(axis=1)\n        #fix to add 0\n        f_cal[-1, 1] = 0\n        calibrated_map = f_cal[:, [0, 1, 4]]\n\n        self.calibration_map = calibrated_map", "response": "Fit the calibration map to the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict_proba(self, p):\n\n        # TODO: Check input\n        if p.size != p.shape[0]:\n            p = p[:, 1]\n\n        calibrated_proba = np.zeros(p.shape[0])\n        for i in range(self.calibration_map.shape[0]):\n            calibrated_proba[np.logical_and(self.calibration_map[i, 1] <= p, self.calibration_map[i, 0] > p)] = \\\n                self.calibration_map[i, 2]\n\n        # TODO: return 2D and refactor\n        return calibrated_proba", "response": "Predict the calibrated probabilities for a set of entries in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1,\n                    verbose=0, fit_params=None, pre_dispatch='2*n_jobs'):\n    \"\"\"Evaluate a score by cross-validation\n\n    Parameters\n    ----------\n    estimator : estimator object implementing 'fit'\n        The object to use to fit the data.\n\n    X : array-like\n        The data to fit. Can be, for example a list, or an array at least 2d.\n\n    y : array-like, optional, default: None\n        The target variable to try to predict in the case of\n        supervised learning.\n\n    scoring : string, callable or None, optional, default: None\n        A string (see model evaluation documentation) or\n        a scorer callable object / function with signature\n        ``scorer(estimator, X, y)``.\n\n    cv : cross-validation generator or int, optional, default: None\n        A cross-validation generator to use. If int, determines\n        the number of folds in StratifiedKFold if y is binary\n        or multiclass and estimator is a classifier, or the number\n        of folds in KFold otherwise. If None, it is equivalent to cv=3.\n\n    n_jobs : integer, optional\n        The number of CPUs to use to do the computation. -1 means\n        'all CPUs'.\n\n    verbose : integer, optional\n        The verbosity level.\n\n    fit_params : dict, optional\n        Parameters to pass to the fit method of the estimator.\n\n    pre_dispatch : int, or string, optional\n        Controls the number of jobs that get dispatched during parallel\n        execution. Reducing this number can be useful to avoid an\n        explosion of memory consumption when more jobs get dispatched\n        than CPUs can process. This parameter can be:\n\n            - None, in which case all the jobs are immediately\n              created and spawned. Use this for lightweight and\n              fast-running jobs, to avoid delays due to on-demand\n              spawning of the jobs\n\n            - An int, giving the exact number of total jobs that are\n              spawned\n\n            - A string, giving an expression as a function of n_jobs,\n              as in '2*n_jobs'\n\n    Returns\n    -------\n    scores : array of float, shape=(len(list(cv)),)\n        Array of scores of the estimator for each run of the cross validation.\n    \"\"\"\n    X, y = indexable(X, y)\n\n    cv = _check_cv(cv, X, y, classifier=is_classifier(estimator))\n    scorer = check_scoring(estimator, scoring=scoring)\n    # We clone the estimator to make sure that all the folds are\n    # independent, and that it is pickle-able.\n    parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n                        pre_dispatch=pre_dispatch)\n    scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n                                              train, test, verbose, None,\n                                              fit_params)\n                      for train, test in cv)\n    return np.array(scores)[:, 0]", "response": "Evaluate a score by cross - validation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters,\n                   fit_params, return_train_score=False,\n                   return_parameters=False):\n    \"\"\"Fit estimator and compute scores for a given dataset split.\n\n    Parameters\n    ----------\n    estimator : estimator object implementing 'fit'\n        The object to use to fit the data.\n\n    X : array-like of shape at least 2D\n        The data to fit.\n\n    y : array-like, optional, default: None\n        The target variable to try to predict in the case of\n        supervised learning.\n\n    scoring : callable\n        A scorer callable object / function with signature\n        ``scorer(estimator, X, y)``.\n\n    train : array-like, shape = (n_train_samples,)\n        Indices of training samples.\n\n    test : array-like, shape = (n_test_samples,)\n        Indices of test samples.\n\n    verbose : integer\n        The verbosity level.\n\n    parameters : dict or None\n        Parameters to be set on the estimator.\n\n    fit_params : dict or None\n        Parameters that will be passed to ``estimator.fit``.\n\n    return_train_score : boolean, optional, default: False\n        Compute and return score on training set.\n\n    return_parameters : boolean, optional, default: False\n        Return parameters that has been used for the estimator.\n\n    Returns\n    -------\n    train_score : float, optional\n        Score on training set, returned only if `return_train_score` is `True`.\n\n    test_score : float\n        Score on test set.\n\n    n_test_samples : int\n        Number of test samples.\n\n    scoring_time : float\n        Time spent for fitting and scoring in seconds.\n\n    parameters : dict or None, optional\n        The parameters that have been evaluated.\n    \"\"\"\n    if verbose > 1:\n        if parameters is None:\n            msg = \"no parameters to be set\"\n        else:\n            msg = '%s' % (', '.join('%s=%s' % (k, v)\n                          for k, v in list(parameters.items())))\n        print(\"[CV] %s %s\" % (msg, (64 - len(msg)) * '.'))\n\n    # Adjust lenght of sample weights\n    n_samples = _num_samples(X)\n    fit_params = fit_params if fit_params is not None else {}\n    fit_params = dict([(k, np.asarray(v)[train]\n                       if hasattr(v, '__len__') and len(v) == n_samples else v)\n                       for k, v in list(fit_params.items())])\n\n    if parameters is not None:\n        estimator.set_params(**parameters)\n\n    start_time = time.time()\n\n    X_train, y_train = _safe_split(estimator, X, y, train)\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n    if y_train is None:\n        estimator.fit(X_train, **fit_params)\n    else:\n        estimator.fit(X_train, y_train, **fit_params)\n    test_score = _score(estimator, X_test, y_test, scorer)\n    if return_train_score:\n        train_score = _score(estimator, X_train, y_train, scorer)\n\n    scoring_time = time.time() - start_time\n\n    if verbose > 2:\n        msg += \", score=%f\" % test_score\n    if verbose > 1:\n        end_msg = \"%s -%s\" % (msg, logger.short_format_time(scoring_time))\n        print(\"[CV] %s %s\" % ((64 - len(end_msg)) * '.', end_msg))\n\n    ret = [train_score] if return_train_score else []\n    ret.extend([test_score, _num_samples(X_test), scoring_time])\n    if return_parameters:\n        ret.append(parameters)\n    return ret", "response": "Fit an estimator and compute scores for a given dataset split."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _safe_split(estimator, X, y, indices, train_indices=None):\n    if hasattr(estimator, 'kernel') and isinstance(estimator.kernel, collections.Callable):\n        # cannot compute the kernel values with custom function\n        raise ValueError(\"Cannot use a custom kernel function. \"\n                         \"Precompute the kernel matrix instead.\")\n\n    if not hasattr(X, \"shape\"):\n        if getattr(estimator, \"_pairwise\", False):\n            raise ValueError(\"Precomputed kernels or affinity matrices have \"\n                             \"to be passed as arrays or sparse matrices.\")\n        X_subset = [X[idx] for idx in indices]\n    else:\n        if getattr(estimator, \"_pairwise\", False):\n            # X is a precomputed square kernel matrix\n            if X.shape[0] != X.shape[1]:\n                raise ValueError(\"X should be a square kernel matrix\")\n            if train_indices is None:\n                X_subset = X[np.ix_(indices, indices)]\n            else:\n                X_subset = X[np.ix_(indices, train_indices)]\n        else:\n            X_subset = safe_indexing(X, indices)\n\n    if y is not None:\n        y_subset = safe_indexing(y, indices)\n    else:\n        y_subset = None\n\n    return X_subset, y_subset", "response": "Create subset of dataset and properly handle kernels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the score of an estimator on a given test set.", "response": "def _score(estimator, X_test, y_test, scorer):\n    \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    if y_test is None:\n        score = scorer(estimator, X_test)\n    else:\n        score = scorer(estimator, X_test, y_test)\n    if not isinstance(score, numbers.Number):\n        raise ValueError(\"scoring must return a number, got %s (%s) instead.\"\n                         % (str(score), type(score)))\n    return score"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a shuffled copy of y eventually shuffle among same labels.", "response": "def _shuffle(y, labels, random_state):\n    \"\"\"Return a shuffled copy of y eventually shuffle among same labels.\"\"\"\n    if labels is None:\n        ind = random_state.permutation(len(y))\n    else:\n        ind = np.arange(len(labels))\n        for label in np.unique(labels):\n            this_mask = (labels == label)\n            ind[this_mask] = random_state.permutation(ind[this_mask])\n    return y[ind]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_cv(cv, X=None, y=None, classifier=False):\n    return _check_cv(cv, X=X, y=y, classifier=classifier, warn_mask=True)", "response": "Input checker utility for building a CV in a user friendly way."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _SMOTE(T, N, k, h = 1.0):\n    n_minority_samples, n_features = T.shape\n\n    if N < 100:\n        #create synthetic samples only for a subset of T.\n        #TODO: select random minortiy samples\n        N = 100\n        pass\n\n    if (N % 100) != 0:\n        raise ValueError(\"N must be < 100 or multiple of 100\")\n\n    N = N/100\n    n_synthetic_samples = N * n_minority_samples\n    S = np.zeros(shape=(n_synthetic_samples, n_features))\n\n    #Learn nearest neighbours\n    neigh = NearestNeighbors(n_neighbors = k)\n    neigh.fit(T)\n\n    #Calculate synthetic samples\n    for i in range(n_minority_samples):\n        nn = neigh.kneighbors(T[i], return_distance=False)\n        for n in range(int(N)):\n            nn_index = choice(nn[0])\n            #NOTE: nn includes T[i], we don't want to select it\n            while nn_index == i:\n                nn_index = choice(nn[0])\n\n            dif = T[nn_index] - T[i]\n            gap = np.random.uniform(low = 0.0, high = h)\n            S[n + i * N, :] = T[i,:] + gap * dif[:]\n\n    return S", "response": "Generate synthetic samples for a given set of features."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns synthetic minority samples.", "response": "def _borderlineSMOTE(X, y, minority_target, N, k):\n    \"\"\"\n    Returns synthetic minority samples.\n\n    Parameters\n    ----------\n    X : array-like, shape = [n__samples, n_features]\n        Holds the minority and majority samples\n    y : array-like, shape = [n__samples]\n        Holds the class targets for samples\n    minority_target : value for minority class\n    N : percetange of new synthetic samples:\n        n_synthetic_samples = N/100 * n_minority_samples. Can be < 100.\n    k : int. Number of nearest neighbours.\n    h : high in random.uniform to scale dif of snythetic sample\n\n    Returns\n    -------\n    safe : Safe minorities\n    synthetic : Synthetic sample of minorities in danger zone\n    danger : Minorities of danger zone\n    \"\"\"\n\n    n_samples, _ = X.shape\n\n    #Learn nearest neighbours on complete training set\n    neigh = NearestNeighbors(n_neighbors = k)\n    neigh.fit(X)\n\n    safe_minority_indices = list()\n    danger_minority_indices = list()\n\n    for i in range(n_samples):\n        if y[i] != minority_target: continue\n\n        nn = neigh.kneighbors(X[i], return_distance=False)\n\n        majority_neighbours = 0\n        for n in nn[0]:\n            if y[n] != minority_target:\n                majority_neighbours += 1\n\n        if majority_neighbours == len(nn):\n            continue\n        elif majority_neighbours < (len(nn)/2):\n            logger.debug(\"Add sample to safe minorities.\")\n            safe_minority_indices.append(i)\n        else:\n            #DANGER zone\n            danger_minority_indices.append(i)\n\n    #SMOTE danger minority samples\n    synthetic_samples = _SMOTE(X[danger_minority_indices], N, k, h = 0.5)\n\n    return (X[safe_minority_indices],\n            synthetic_samples,\n            X[danger_minority_indices])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfits the ROCConvexHull model to the object.", "response": "def fit(self,y_true_cal=None, y_prob_cal=None):\n        \"\"\" If calibration, then train the calibration of probabilities\n\n        Parameters\n        ----------\n        y_true_cal : array-like of shape = [n_samples], optional default = None\n            True class to be used for calibrating the probabilities\n\n        y_prob_cal : array-like of shape = [n_samples, 2], optional default = None\n            Predicted probabilities to be used for calibrating the probabilities\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n        if self.calibration:\n            self.cal = ROCConvexHull()\n            self.cal.fit(y_true_cal, y_prob_cal[:, 1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict(self, y_prob, cost_mat):\n        if self.calibration:\n\n            y_prob[:, 1] = self.cal.predict_proba(y_prob[:, 1])\n            y_prob[:, 0] = 1 - y_prob[:, 1]\n\n        # t_BMR = (cost_fp - cost_tn) / (cost_fn - cost_tn - cost_tp + cost_fp)\n        # cost_mat[FP,FN,TP,TN]\n        t_bmr = (cost_mat[:, 0] - cost_mat[:, 3]) / (cost_mat[:, 1] - cost_mat[:, 3] - cost_mat[:, 2] + cost_mat[:, 0])\n\n        y_pred = np.greater(y_prob[:, 1], t_bmr).astype(np.float)\n\n        return y_pred", "response": "Calculate the prediction using the Bayes minimum risk classifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit the Bayes minimum risk classifier and predict the class.", "response": "def fit_predict(self, y_prob, cost_mat, y_true_cal=None, y_prob_cal=None):\n        \"\"\" Calculate the prediction using the Bayes minimum risk classifier.\n\n        Parameters\n        ----------\n        y_prob : array-like of shape = [n_samples, 2]\n            Predicted probabilities.\n\n        cost_mat : array-like of shape = [n_samples, 4]\n            Cost matrix of the classification problem\n            Where the columns represents the costs of: false positives, false negatives,\n            true positives and true negatives, for each example.\n\n        y_true_cal : array-like of shape = [n_samples], optional default = None\n            True class to be used for calibrating the probabilities\n\n        y_prob_cal : array-like of shape = [n_samples, 2], optional default = None\n            Predicted probabilities to be used for calibrating the probabilities\n\n        Returns\n        -------\n        y_pred : array-like of shape = [n_samples]\n            Predicted class\n        \"\"\"\n\n        #TODO: Check input\n\n        if self.calibration:\n            self.cal = ROCConvexHull()\n\n            if y_prob_cal is None:\n                y_prob_cal = y_prob\n\n            self.cal.fit(y_true_cal, y_prob_cal[:, 1])\n            y_prob[:, 1] = self.cal.predict_proba(y_prob[:, 1])\n            y_prob[:, 0] = 1 - y_prob[:, 1]\n\n        # t_BMR = (cost_fp - cost_tn) / (cost_fn - cost_tn - cost_tp + cost_fp)\n        # cost_mat[FP,FN,TP,TN]\n        t_bmr = (cost_mat[:, 0] - cost_mat[:, 3]) / (cost_mat[:, 1] - cost_mat[:, 3] - cost_mat[:, 2] + cost_mat[:, 0])\n\n        y_pred = np.greater(y_prob[:, 1], t_bmr).astype(np.float)\n\n        return y_pred"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the thresholding optimization algorithm to the classification problem.", "response": "def fit(self, y_prob, cost_mat, y_true):\n        \"\"\" Calculate the optimal threshold using the ThresholdingOptimization.\n\n        Parameters\n        ----------\n        y_prob : array-like of shape = [n_samples, 2]\n            Predicted probabilities.\n\n        cost_mat : array-like of shape = [n_samples, 4]\n            Cost matrix of the classification problem\n            Where the columns represents the costs of: false positives, false negatives,\n            true positives and true negatives, for each example.\n\n        y_true : array-like of shape = [n_samples]\n            True class\n\n        Returns\n        -------\n        self\n        \"\"\"\n\n        #TODO: Check input\n\n        if self.calibration:\n            cal = ROCConvexHull()\n\n            cal.fit(y_true, y_prob[:, 1])\n            y_prob[:, 1] = cal.predict_proba(y_prob[:, 1])\n            y_prob[:, 0] = 1 - y_prob[:, 1]\n\n        thresholds = np.unique(y_prob)\n\n        cost = np.zeros(thresholds.shape)\n        for i in range(thresholds.shape[0]):\n            pred = np.floor(y_prob[:, 1]+(1-thresholds[i]))\n            cost[i] = cost_loss(y_true, pred, cost_mat)\n\n        self.threshold_ = thresholds[np.argmin(cost)]\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the prediction using the ThresholdingOptimization.", "response": "def predict(self, y_prob):\n        \"\"\" Calculate the prediction using the ThresholdingOptimization.\n\n        Parameters\n        ----------\n        y_prob : array-like of shape = [n_samples, 2]\n            Predicted probabilities.\n\n        Returns\n        -------\n        y_pred : array-like of shape = [n_samples]\n            Predicted class\n        \"\"\"\n        y_pred = np.floor(y_prob[:, 1] + (1 - self.threshold_))\n\n        return y_pred"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef undersampling(X, y, cost_mat=None, per=0.5):\n\n    n_samples = X.shape[0]\n    #TODO: allow y different from (0, 1)\n    num_y1 = y.sum()\n    num_y0 = n_samples - num_y1\n\n    filter_rand = np.random.rand(int(num_y1 + num_y0))\n\n    #TODO: rewrite in a more readable way\n    if num_y1 < num_y0:\n        num_y0_new = num_y1 * 1.0 / per - num_y1\n        num_y0_new_per = num_y0_new * 1.0 / num_y0\n        filter_0 = np.logical_and(y == 0, filter_rand <= num_y0_new_per)\n        filter_ = np.nonzero(np.logical_or(y == 1, filter_0))[0]\n    else:\n        num_y1_new = num_y0 * 1.0 / per - num_y0\n        num_y1_new_per = num_y1_new * 1.0 / num_y1\n        filter_1 = np.logical_and(y == 1, filter_rand <= num_y1_new_per)\n        filter_ = np.nonzero(np.logical_or(y == 0, filter_1))[0]\n\n    X_u = X[filter_, :]\n    y_u = y[filter_]\n\n    if not cost_mat is None:\n        cost_mat_u = cost_mat[filter_, :]\n        return X_u, y_u, cost_mat_u\n    else:\n        return X_u, y_u", "response": "Under - sampling of the under - sampled data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef smote(X, y, cost_mat=None, per=0.5):\n    #TODO: Add random state\n    #TODO: Check input\n    n_samples = X.shape[0]\n    #TODO: allow y different from (0, 1)\n    num_y1 = y.sum()\n    num_y0 = n_samples - num_y1\n\n    #TODO: rewrite in a more readable way\n    if num_y1 < num_y0:\n        N = int((num_y0 * 1.0 / (1 - per) - num_y0) / num_y1) * 100\n        X_m = X[y == 1]\n        X_majority = X[y == 0]\n        minority = 1\n    else:\n        N = int((num_y1 * 1.0 / (1 - per) - num_y1) / num_y0) * 100\n        X_m = X[y == 0]\n        X_majority = X[y == 1]\n        minority = 0\n\n    X_m_o = _SMOTE(X_m, N, k=3)\n\n    X_s = np.vstack((X_majority, X_m_o))\n\n    n_samples_s = X_s.shape[0]\n\n    y_s = np.ones(n_samples_s) * (minority - 1)**2\n    y_s[max(num_y1, num_y0):] = minority\n\n    #TODO: Include cost_mat\n\n    return X_s, y_s", "response": "Synthetic Minority Over - Sampling technique"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _node_cost(self, y_true, cost_mat):\n        n_samples = len(y_true)\n\n        # Evaluates the cost by predicting the node as positive and negative\n        costs = np.zeros(2)\n        costs[0] = cost_loss(y_true, np.zeros(y_true.shape), cost_mat)\n        costs[1] = cost_loss(y_true, np.ones(y_true.shape), cost_mat)\n\n        pi = np.array([1 - y_true.mean(), y_true.mean()])\n\n        if self.criterion == 'direct_cost':\n            costs = costs\n        elif self.criterion == 'pi_cost':\n            costs *= pi\n        elif self.criterion == 'gini_cost':\n            costs *= pi ** 2\n        elif self.criterion in 'entropy_cost':\n            if pi[0] == 0 or pi[1] == 0:\n                costs *= 0\n            else:\n                costs *= -np.log(pi)\n\n        y_pred = np.argmin(costs)\n\n        # Calculate the predicted probability of a node using laplace correction.\n        n_positives = y_true.sum()\n        y_prob = (n_positives + 1.0) / (n_samples + 2.0)\n\n        return costs[y_pred], y_pred, y_prob", "response": "Private function to calculate the cost of a node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _best_split(self, y_true, X, cost_mat):\n\n        n_samples, n_features = X.shape\n        num_pct = self.num_pct\n\n        cost_base, y_pred, y_prob = self._node_cost(y_true, cost_mat)\n\n        # Calculate the gain of all features each split in num_pct\n        gains = np.zeros((n_features, num_pct))\n        pred = np.zeros((n_features, num_pct))\n        splits = np.zeros((n_features, num_pct))\n\n        # Selected features\n        selected_features = np.arange(0, self.n_features_)\n        # Add random state\n        np.random.shuffle(selected_features)\n        selected_features = selected_features[:self.max_features_]\n        selected_features.sort()\n\n        #TODO:  # Skip the CPU intensive evaluation of the impurity criterion for\n                # features that were already detected as constant (hence not suitable\n                # for good splitting) by ancestor nodes and save the information on\n                # newly discovered constant features to spare computation on descendant\n                # nodes.\n\n        # For each feature test all possible splits\n        for j in selected_features:\n            splits[j, :] = np.percentile(X[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())\n\n            for l in range(num_pct):\n                # Avoid repeated values, since np.percentile may return repeated values\n                if l == 0 or (l > 0 and splits[j, l] != splits[j, l - 1]):\n                    split = (j, splits[j, l])\n                    gains[j, l], pred[j, l] = self._calculate_gain(cost_base, y_true, X, cost_mat, split)\n\n        best_split = np.unravel_index(gains.argmax(), gains.shape)\n\n        return (best_split[0], splits[best_split]), gains.max(), pred[best_split], y_pred, y_prob", "response": "Private function to calculate the split that gives the best gain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _tree_grow(self, y_true, X, cost_mat, level=0):\n\n        #TODO: Find error, add min_samples_split\n        if len(X.shape) == 1:\n            tree = dict(y_pred=y_true, y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n            return tree\n\n        # Calculate the best split of the current node\n        split, gain, Xl_pred, y_pred, y_prob = self._best_split(y_true, X, cost_mat)\n\n        n_samples, n_features = X.shape\n\n        # Construct the tree object as a dictionary\n\n        #TODO: Convert tree to be equal to sklearn.tree.tree object\n        tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=n_samples, gain=gain)\n\n        # Check the stopping criteria\n        if gain < self.min_gain:\n            return tree\n        if self.max_depth is not None:\n            if level >= self.max_depth:\n                return tree\n        if n_samples <= self.min_samples_split:\n            return tree\n        \n        j, l = split\n        filter_Xl = (X[:, j] <= l)\n        filter_Xr = ~filter_Xl\n        n_samples_Xl = np.nonzero(filter_Xl)[0].shape[0]\n        n_samples_Xr = np.nonzero(filter_Xr)[0].shape[0]\n\n        if min(n_samples_Xl, n_samples_Xr) <= self.min_samples_leaf:\n            return tree\n\n        # No stooping criteria is met\n        tree['split'] = split\n        tree['node'] = self.tree_.n_nodes\n        self.tree_.n_nodes += 1\n\n        tree['sl'] = self._tree_grow(y_true[filter_Xl], X[filter_Xl], cost_mat[filter_Xl], level + 1)\n        tree['sr'] = self._tree_grow(y_true[filter_Xr], X[filter_Xr], cost_mat[filter_Xr], level + 1)\n\n        return tree", "response": "Private function to grow the decision tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit(self, X, y, cost_mat, check_input=False):\n\n        #TODO: Check input\n        #TODO: Add random state\n        n_samples, self.n_features_ = X.shape\n\n        self.tree_ = self._tree_class()\n\n        # Maximum number of features to be taken into account per split\n        if isinstance(self.max_features, six.string_types):\n            if self.max_features == \"auto\":\n                max_features = max(1, int(np.sqrt(self.n_features_)))\n            elif self.max_features == \"sqrt\":\n                max_features = max(1, int(np.sqrt(self.n_features_)))\n            elif self.max_features == \"log2\":\n                max_features = max(1, int(np.log2(self.n_features_)))\n            else:\n                raise ValueError(\n                    'Invalid value for max_features. Allowed string '\n                    'values are \"auto\", \"sqrt\" or \"log2\".')\n        elif self.max_features is None:\n            max_features = self.n_features_\n        elif isinstance(self.max_features, (numbers.Integral, np.integer)):\n            max_features = self.max_features\n        else:  # float\n            if self.max_features > 0.0:\n                max_features = max(1, int(self.max_features * self.n_features_))\n            else:\n                max_features = 1  # On sklearn is 0.\n        self.max_features_ = max_features\n\n        self.tree_.tree = self._tree_grow(y, X, cost_mat)\n\n        if self.pruned:\n            self.pruning(X, y, cost_mat)\n\n        self.classes_ = np.array([0, 1])\n\n        return self", "response": "Fits the example - dependent decision tree from the training set X y and cost_mat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npredicting the class of each sample in X.", "response": "def predict(self, X):\n        \"\"\" Predict class of X.\n\n        The predicted class for each sample in X is returned.\n\n        Parameters\n        ----------\n\n        X : array-like of shape = [n_samples, n_features]\n            The input samples.\n\n        Returns\n        -------\n        y : array of shape = [n_samples]\n            The predicted classes,\n        \"\"\"\n        #TODO: Check consistency of X\n        if self.pruned:\n            tree_ = self.tree_.tree_pruned\n        else:\n            tree_ = self.tree_.tree\n\n        return self._classify(X, tree_, proba=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npredicts class probabilities of the input samples X.", "response": "def predict_proba(self, X):\n        \"\"\"Predict class probabilities of the input samples X.\n\n        Parameters\n        ----------\n        X : array-like of shape = [n_samples, n_features]\n            The input samples.\n\n        Returns\n        -------\n        prob : array of shape = [n_samples, 2]\n            The class probabilities of the input samples.\n        \"\"\"\n        #TODO: Check consistency of X\n        n_samples, n_features = X.shape\n        prob = np.zeros((n_samples, 2))\n\n        if self.pruned:\n            tree_ = self.tree_.tree_pruned\n        else:\n            tree_ = self.tree_.tree\n\n        prob[:, 1] = self._classify(X, tree_, proba=True)\n        prob[:, 0] = 1 - prob[:, 1]\n\n        return prob"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pruning(self, X, y_true, cost_mat):\n        # Calculate gains\n        nodes = self._nodes(self.tree_.tree_pruned)\n        n_nodes = len(nodes)\n        gains = np.zeros(n_nodes)\n\n        y_pred = self._classify(X, self.tree_.tree_pruned)\n        cost_base = cost_loss(y_true, y_pred, cost_mat)\n\n        for m, node in enumerate(nodes):\n\n            # Create temporal tree by eliminating node from tree_pruned\n            temp_tree = self._delete_node(self.tree_.tree_pruned, node)\n            y_pred = self._classify(X, temp_tree)\n\n            nodes_pruned = self._nodes(temp_tree)\n\n            # Calculate %gain\n            gain = (cost_base - cost_loss(y_true, y_pred, cost_mat)) / cost_base\n\n            # Calculate %gain_size\n            gain_size = (len(nodes) - len(nodes_pruned)) * 1.0 / len(nodes)\n\n            # Calculate weighted gain\n            gains[m] = gain * gain_size\n\n        best_gain = np.max(gains)\n        best_node = nodes[int(np.argmax(gains))]\n\n        if best_gain > self.min_gain:\n            self.tree_.tree_pruned = self._delete_node(self.tree_.tree_pruned, best_node)\n\n            # If best tree is not root node, then recursively pruning the tree\n            if best_node != 0:\n                self._pruning(X, y_true, cost_mat)", "response": "Private function that prunes the decision tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pruning(self, X, y, cost_mat):\n        self.tree_.tree_pruned = copy.deepcopy(self.tree_.tree)\n        if self.tree_.n_nodes > 0:\n            self._pruning(X, y, cost_mat)\n            nodes_pruned = self._nodes(self.tree_.tree_pruned)\n            self.tree_.n_nodes_pruned = len(nodes_pruned)", "response": "Function that prune the decision tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncosting classification loss. This function calculates the cost of using y_pred on y_true with cost-matrix cost-mat. It differ from traditional classification evaluation measures since measures such as accuracy asing the same cost to different errors, but that is not the real case in several real-world classification problems as they are example-dependent cost-sensitive in nature, where the costs due to misclassification vary between examples. Parameters ---------- y_true : array-like or label indicator matrix Ground truth (correct) labels. y_pred : array-like or label indicator matrix Predicted labels, as returned by a classifier. cost_mat : array-like of shape = [n_samples, 4] Cost matrix of the classification problem Where the columns represents the costs of: false positives, false negatives, true positives and true negatives, for each example. Returns ------- loss : float Cost of a using y_pred on y_true with cost-matrix cost-mat References ---------- .. [1] C. Elkan, \"The foundations of Cost-Sensitive Learning\", in Seventeenth International Joint Conference on Artificial Intelligence, 973-978, 2001. .. [2] A. Correa Bahnsen, A. Stojanovic, D.Aouada, B, Ottersten, `\"Improving Credit Card Fraud Detection with Calibrated Probabilities\" <http://albahnsen.com/files/%20Improving%20Credit%20Card%20Fraud%20Detection%20by%20using%20Calibrated%20Probabilities%20-%20Publish.pdf>`__, in Proceedings of the fourteenth SIAM International Conference on Data Mining, 677-685, 2014. See also -------- savings_score Examples -------- >>> import numpy as np >>> from costcla.metrics import cost_loss >>> y_pred = [0, 1, 0, 0] >>> y_true = [0, 1, 1, 0] >>> cost_mat = np.array([[4, 1, 0, 0], [1, 3, 0, 0], [2, 3, 0, 0], [2, 1, 0, 0]]) >>> cost_loss(y_true, y_pred, cost_mat) 3", "response": "def cost_loss(y_true, y_pred, cost_mat):\n    #TODO: update description\n    \"\"\"Cost classification loss.\n\n    This function calculates the cost of using y_pred on y_true with\n    cost-matrix cost-mat. It differ from traditional classification evaluation\n    measures since measures such as accuracy asing the same cost to different\n    errors, but that is not the real case in several real-world classification\n    problems as they are example-dependent cost-sensitive in nature, where the\n    costs due to misclassification vary between examples.\n\n    Parameters\n    ----------\n    y_true : array-like or label indicator matrix\n        Ground truth (correct) labels.\n\n    y_pred : array-like or label indicator matrix\n        Predicted labels, as returned by a classifier.\n\n    cost_mat : array-like of shape = [n_samples, 4]\n        Cost matrix of the classification problem\n        Where the columns represents the costs of: false positives, false negatives,\n        true positives and true negatives, for each example.\n\n    Returns\n    -------\n    loss : float\n        Cost of a using y_pred on y_true with cost-matrix cost-mat\n\n    References\n    ----------\n    .. [1] C. Elkan, \"The foundations of Cost-Sensitive Learning\",\n           in Seventeenth International Joint Conference on Artificial Intelligence,\n           973-978, 2001.\n\n    .. [2] A. Correa Bahnsen, A. Stojanovic, D.Aouada, B, Ottersten,\n           `\"Improving Credit Card Fraud Detection with Calibrated Probabilities\" <http://albahnsen.com/files/%20Improving%20Credit%20Card%20Fraud%20Detection%20by%20using%20Calibrated%20Probabilities%20-%20Publish.pdf>`__, in Proceedings of the fourteenth SIAM International Conference on Data Mining,\n           677-685, 2014.\n\n    See also\n    --------\n    savings_score\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from costcla.metrics import cost_loss\n    >>> y_pred = [0, 1, 0, 0]\n    >>> y_true = [0, 1, 1, 0]\n    >>> cost_mat = np.array([[4, 1, 0, 0], [1, 3, 0, 0], [2, 3, 0, 0], [2, 1, 0, 0]])\n    >>> cost_loss(y_true, y_pred, cost_mat)\n    3\n    \"\"\"\n\n    #TODO: Check consistency of cost_mat\n\n    y_true = column_or_1d(y_true)\n    y_true = (y_true == 1).astype(np.float)\n    y_pred = column_or_1d(y_pred)\n    y_pred = (y_pred == 1).astype(np.float)\n    cost = y_true * ((1 - y_pred) * cost_mat[:, 1] + y_pred * cost_mat[:, 2])\n    cost += (1 - y_true) * (y_pred * cost_mat[:, 0] + (1 - y_pred) * cost_mat[:, 3])\n    return np.sum(cost)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the Brier score for a single item in a set of items.", "response": "def brier_score_loss(y_true, y_prob):\n    \"\"\"Compute the Brier score\n\n    The smaller the Brier score, the better, hence the naming with \"loss\".\n\n    Across all items in a set N predictions, the Brier score measures the\n    mean squared difference between (1) the predicted probability assigned\n    to the possible outcomes for item i, and (2) the actual outcome.\n    Therefore, the lower the Brier score is for a set of predictions, the\n    better the predictions are calibrated. Note that the Brier score always\n    takes on a value between zero and one, since this is the largest\n    possible difference between a predicted probability (which must be\n    between zero and one) and the actual outcome (which can take on values\n    of only 0 and 1).\n\n    The Brier score is appropriate for binary and categorical outcomes that\n    can be structured as true or false, but is inappropriate for ordinal\n    variables which can take on three or more values (this is because the\n    Brier score assumes that all possible outcomes are equivalently\n    \"distant\" from one another).\n\n    Parameters\n    ----------\n    y_true : array, shape (n_samples,)\n    True targets.\n\n    y_prob : array, shape (n_samples,)\n    Probabilities of the positive class.\n\n    Returns\n    -------\n    score : float\n    Brier score\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from costcla.metrics import brier_score_loss\n    >>> y_true = [0, 1, 1, 0]\n    >>> y_prob = [0.1, 0.9, 0.8, 0.3]\n    >>> brier_score_loss(y_true, y_prob) # doctest: +ELLIPSIS\n    0.037...\n    >>> brier_score_loss(y_true, np.array(y_prob) > 0.5)\n    0.0\n\n    References\n    ----------\n    http://en.wikipedia.org/wiki/Brier_score\n    \"\"\"\n    y_true = column_or_1d(y_true)\n    y_prob = column_or_1d(y_prob)\n    return np.mean((y_true - y_prob) ** 2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _intercept_dot(w, X):\n    c = 0.\n    if w.size == X.shape[1] + 1:\n        c = w[-1]\n        w = w[:-1]\n\n    z = np.dot(X, w) + c\n    return w, c, z", "response": "Computes y = w + X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the logistic loss of a single tree node.", "response": "def _logistic_cost_loss(w, X, y, cost_mat, alpha):\n    \"\"\"Computes the logistic loss.\n\n    Parameters\n    ----------\n    w : array-like, shape (n_w, n_features,) or (n_w, n_features + 1,)\n        Coefficient vector or matrix of coefficient.\n\n    X : array-like, shape (n_samples, n_features)\n        Training data.\n\n    y : ndarray, shape (n_samples,)\n        Array of labels.\n\n    cost_mat : array-like of shape = [n_samples, 4]\n        Cost matrix of the classification problem\n        Where the columns represents the costs of: false positives, false negatives,\n        true positives and true negatives, for each example.\n\n    alpha : float\n        Regularization parameter. alpha is equal to 1 / C.\n\n    Returns\n    -------\n    out : float\n        Logistic loss.\n    \"\"\"\n\n    if w.shape[0] == w.size:\n        # Only evaluating one w\n        return _logistic_cost_loss_i(w, X, y, cost_mat, alpha)\n\n    else:\n        # Evaluating a set of w\n        n_w = w.shape[0]\n        out = np.zeros(n_w)\n\n        for i in range(n_w):\n            out[i] = _logistic_cost_loss_i(w[i], X, y, cost_mat, alpha)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfitting a example - dependent logistic regression from the training set X y and cost_mat.", "response": "def fit(self, X, y, cost_mat):\n        \"\"\" Build a example-dependent cost-sensitive logistic regression from the training set (X, y, cost_mat)\n\n        Parameters\n        ----------\n        X : array-like of shape = [n_samples, n_features]\n            The input samples.\n\n        y : array indicator matrix\n            Ground truth (correct) labels.\n\n        cost_mat : array-like of shape = [n_samples, 4]\n            Cost matrix of the classification problem\n            Where the columns represents the costs of: false positives, false negatives,\n            true positives and true negatives, for each example.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n\n        #TODO: Check input\n\n        n_features = X.shape[1]\n        if self.fit_intercept:\n            w0 = np.zeros(n_features + 1)\n        else:\n            w0 = np.zeros(n_features)\n\n        if self.solver == 'ga':\n            #TODO: add n_jobs\n            res = GeneticAlgorithmOptimizer(_logistic_cost_loss,\n                                            w0.shape[0],\n                                            iters=self.max_iter,\n                                            type_='cont',\n                                            n_chromosomes=100,\n                                            per_mutations=0.25,\n                                            n_elite=10,\n                                            fargs=(X, y, cost_mat, 1. / self.C),\n                                            range_=(-5, 5),\n                                            n_jobs=1,\n                                            verbose=self.verbose)\n            res.fit()\n\n        elif self.solver == 'bfgs':\n\n            if self.verbose > 0:\n                disp = True\n            else:\n                disp = False\n\n            res = minimize(_logistic_cost_loss,\n                           w0,\n                           method='BFGS',\n                           args=(X, y, cost_mat, 1. / self.C),\n                           tol=self.tol,\n                           options={'maxiter': self.max_iter, 'disp': disp})\n\n        if self.fit_intercept:\n            self.coef_ = res.x[:-1]\n            self.intercept_ = res.x[-1]\n        else:\n            self.coef_ = res.x"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npredicts class. Parameters ---------- X : array-like, shape = [n_samples, n_features] Returns ------- T : array-like, shape = [n_samples] Returns the prediction of the sample..", "response": "def predict(self, X, cut_point=0.5):\n        \"\"\"Predicted class.\n\n        Parameters\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n\n        Returns\n        -------\n        T : array-like, shape = [n_samples]\n            Returns the prediction of the sample..\n        \"\"\"\n        return np.floor(self.predict_proba(X)[:, 1] + (1 - cut_point))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_tags(userdata):\n        macros = re.findall('@(.*?)@', userdata)\n        logging.info('List of available macros:')\n        for macro in macros:\n            logging.info('\\t%r', macro)", "response": "List all used macros within a UserData script."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert macro values or auto export variables in UserData scripts.", "response": "def handle_tags(userdata, macros):\n        \"\"\"Insert macro values or auto export variables in UserData scripts.\n\n        :param userdata: The UserData script.\n        :type userdata: str\n        :param macros: UserData macros as key value pair.\n        :type macros: dict\n        :return: UserData script with the macros replaced with their values.\n        :rtype: str\n        \"\"\"\n        macro_vars = re.findall('@(.*?)@', userdata)\n        for macro_var in macro_vars:\n            if macro_var == '!all_macros_export':\n                macro_var_export_list = []\n                for defined_macro in macros:\n                    macro_var_export_list.append('export %s=\"%s\"' % (defined_macro, macros[defined_macro]))\n                macro_var_exports = \"\\n\".join(macro_var_export_list)\n\n                userdata = userdata.replace('@%s@' % macro_var, macro_var_exports)\n            elif macro_var == \"!all_macros_docker\":\n                macro_var_export_list = []\n                for defined_macro in macros:\n                    macro_var_export_list.append(\"-e '%s=%s'\" % (defined_macro, macros[defined_macro]))\n                macro_var_exports = \" \".join(macro_var_export_list)\n\n                userdata = userdata.replace('@%s@' % macro_var, macro_var_exports)\n            else:\n                if \"|\" in macro_var:\n                    macro_var, default_value = macro_var.split('|')\n                    if macro_var not in macros:\n                        logging.warning('Using default variable value %s for @%s@ ', default_value, macro_var)\n                        value = default_value\n                    else:\n                        value = macros[macro_var]\n\n                    userdata = userdata.replace('@%s|%s@' % (macro_var, default_value), value)\n                else:\n                    if macro_var not in macros:\n                        logging.error('Undefined variable @%s@ in UserData script', macro_var)\n                        return None\n\n                    userdata = userdata.replace('@%s@' % macro_var, macros[macro_var])\n\n        return userdata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_import_tags(userdata, import_root):\n        imports = re.findall('@import\\((.*?)\\)@', userdata)  # pylint: disable=anomalous-backslash-in-string\n        if not imports:\n            return userdata\n\n        for filepath in imports:\n            logger.info('Processing \"import\" of %s', filepath)\n            import_path = os.path.join(import_root, filepath)\n            try:\n                with open(import_path) as fo:\n                    content = fo.read()\n                    userdata = userdata.replace('@import(%s)@' % filepath, content)\n            except FileNotFoundError:\n                raise UserDataException('Import path {} not found.'.format(import_path))\n\n        return userdata", "response": "Handle the contents of a UserData script with the contents of the imported files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls the given function with the given arguments retrying if the method fails due to an EC2ResponseError.", "response": "def retry_on_ec2_error(self, func, *args, **kwargs):\n        \"\"\"\n        Call the given method with the given arguments, retrying if the call\n        failed due to an EC2ResponseError. This method will wait at most 30\n        seconds and perform up to 6 retries. If the method still fails, it will\n        propagate the error.\n\n        :param func: Function to call\n        :type func: function\n        \"\"\"\n        exception_retry_count = 6\n        while True:\n            try:\n                return func(*args, **kwargs)\n            except (boto.exception.EC2ResponseError, ssl.SSLError) as msg:\n                exception_retry_count -= 1\n                if exception_retry_count <= 0:\n                    raise msg\n                time.sleep(5)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to a EC2 region and set the attributes of the local cache.", "response": "def connect(self, region, **kw_params):\n        \"\"\"Connect to a EC2.\n\n        :param region: The name of the region to connect to.\n        :type region: str\n        :param kw_params:\n        :type kw_params: dict\n        \"\"\"\n        self.ec2 = boto.ec2.connect_to_region(region, **kw_params)\n        if not self.ec2:\n            raise EC2ManagerException('Unable to connect to region \"%s\"' % region)\n        self.remote_images.clear()\n\n        if self.images and any(('image_name' in img and 'image_id' not in img) for img in self.images.values()):\n            for img in self.images.values():\n                if 'image_name' in img and 'image_id' not in img:\n                    img['image_id'] = self.resolve_image_name(img.pop('image_name'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_image_name(self, image_name):\n        # look at each scope in order of size\n        scopes = ['self', 'amazon', 'aws-marketplace']\n        if image_name in self.remote_images:\n            return self.remote_images[image_name]\n        for scope in scopes:\n            logger.info('Retrieving available AMIs owned by %s...', scope)\n            remote_images = self.ec2.get_all_images(owners=[scope], filters={'name': image_name})\n            self.remote_images.update({ri.name: ri.id for ri in remote_images})\n            if image_name in self.remote_images:\n                return self.remote_images[image_name]\n        raise EC2ManagerException('Failed to resolve AMI name \"%s\" to an AMI' % image_name)", "response": "Resolve an image name to an AMI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating one or more EC2 on - demand instances.", "response": "def create_on_demand(self,\n                         instance_type='default',\n                         tags=None,\n                         root_device_type='ebs',\n                         size='default',\n                         vol_type='gp2',\n                         delete_on_termination=False):\n        \"\"\"Create one or more EC2 on-demand instances.\n\n        :param size: Size of root device\n        :type size: int\n        :param delete_on_termination:\n        :type delete_on_termination: boolean\n        :param vol_type:\n        :type vol_type: str\n        :param root_device_type: The type of the root device.\n        :type root_device_type: str\n        :param instance_type: A section name in amazon.json\n        :type instance_type: str\n        :param tags:\n        :type tags: dict\n        :return: List of instances created\n        :rtype: list\n        \"\"\"\n        name, size = self._get_default_name_size(instance_type, size)\n\n        if root_device_type == 'ebs':\n            self.images[instance_type]['block_device_map'] = \\\n                self._configure_ebs_volume(vol_type, name, size, delete_on_termination)\n\n        reservation = self.ec2.run_instances(**self.images[instance_type])\n\n        logger.info('Creating requested tags...')\n        for i in reservation.instances:\n            self.retry_on_ec2_error(self.ec2.create_tags, [i.id], tags or {})\n\n        instances = []\n        logger.info('Waiting for instances to become ready...')\n        while len(reservation.instances): # pylint: disable=len-as-condition\n            for i in reservation.instances:\n                if i.state == 'running':\n                    instances.append(i)\n                    reservation.instances.pop(reservation.instances.index(i))\n                    logger.info('%s is %s at %s (%s)',\n                                i.id,\n                                i.state,\n                                i.public_dns_name,\n                                i.ip_address)\n                else:\n                    self.retry_on_ec2_error(i.update)\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates one or more EC2 spot instances.", "response": "def create_spot_requests(self,\n                             price,\n                             instance_type='default',\n                             root_device_type='ebs',\n                             size='default',\n                             vol_type='gp2',\n                             delete_on_termination=False,\n                             timeout=None):\n        \"\"\"Request creation of one or more EC2 spot instances.\n\n        :param size:\n        :param vol_type:\n        :param delete_on_termination:\n        :param root_device_type: The type of the root device.\n        :type root_device_type: str\n        :param price: Max price to pay for spot instance per hour.\n        :type price: float\n        :param instance_type: A section name in amazon.json\n        :type instance_type: str\n        :param timeout: Seconds to keep the request open (cancelled if not fulfilled).\n        :type timeout: int\n        :return: List of requests created\n        :rtype: list\n        \"\"\"\n        name, size = self._get_default_name_size(instance_type, size)\n\n        if root_device_type == 'ebs':\n            self.images[instance_type]['block_device_map'] = \\\n                self._configure_ebs_volume(vol_type, name, size, delete_on_termination)\n\n        valid_until = None\n        if timeout is not None:\n            valid_until = (datetime.datetime.now() + datetime.timedelta(seconds=timeout)).isoformat()\n\n        requests = self.ec2.request_spot_instances(price, valid_until=valid_until, **self.images[instance_type])\n        return [r.id for r in requests]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_spot_requests(self, requests, tags=None):\n        instances = [None] * len(requests)\n        ec2_requests = self.retry_on_ec2_error(self.ec2.get_all_spot_instance_requests, request_ids=requests)\n\n        for req in ec2_requests:\n            if req.instance_id:\n                instance = self.retry_on_ec2_error(self.ec2.get_only_instances, req.instance_id)[0]\n\n                if not instance:\n                    raise EC2ManagerException('Failed to get instance with id %s for %s request %s'\n                                              % (req.instance_id, req.status.code, req.id))\n\n                instances[requests.index(req.id)] = instance\n\n                self.retry_on_ec2_error(self.ec2.create_tags, [instance.id], tags or {})\n                logger.info('Request %s is %s and %s.',\n                            req.id,\n                            req.status.code,\n                            req.state)\n                logger.info('%s is %s at %s (%s)',\n                            instance.id,\n                            instance.state,\n                            instance.public_dns_name,\n                            instance.ip_address)\n            elif req.state != \"open\":\n                # return the request so we don't try again\n                instances[requests.index(req.id)] = req\n\n        return instances", "response": "Check status of one or more EC2 spot instance requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cancel_spot_requests(self, requests):\n        ec2_requests = self.retry_on_ec2_error(self.ec2.get_all_spot_instance_requests, request_ids=requests)\n\n        for req in ec2_requests:\n            req.cancel()", "response": "Cancel one or more EC2 spot instance requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates one or more EC2 spot instances.", "response": "def create_spot(self,\n                    price,\n                    instance_type='default',\n                    tags=None,\n                    root_device_type='ebs',\n                    size='default',\n                    vol_type='gp2',\n                    delete_on_termination=False,\n                    timeout=None):\n        \"\"\"Create one or more EC2 spot instances.\n\n        :param root_device_type:\n        :param size:\n        :param vol_type:\n        :param delete_on_termination:\n        :param timeout:\n        :param price: Max price to pay for spot instance per hour.\n        :type price: float\n        :param instance_type: A section name in amazon.json\n        :type instance_type: str\n        :param tags:\n        :type tags: dict\n        :return: List of instances created\n        :rtype: list\n        \"\"\"\n        request_ids = self.create_spot_requests(price,\n                                                instance_type=instance_type,\n                                                root_device_type=root_device_type,\n                                                size=size,\n                                                vol_type=vol_type,\n                                                delete_on_termination=delete_on_termination)\n        instances = []\n        logger.info('Waiting on fulfillment of requested spot instances.')\n        poll_resolution = 5.0\n        time_exceeded = False\n        while request_ids:\n            time.sleep(poll_resolution)\n\n            new_instances = self.check_spot_requests(request_ids, tags=tags)\n\n            if timeout is not None:\n                timeout -= poll_resolution\n                time_exceeded = timeout <= 0\n\n            fulfilled = []\n            for idx, instance in enumerate(new_instances):\n                if instance.status.code == \"bad-parameters\":\n                    logging.error('Spot request for \"%s\" failed due to bad parameters.', instance.id)\n                    self.cancel_spot_requests([instance.id])\n                if instance is not None:\n                    fulfilled.append(idx)\n                if isinstance(instance, boto.ec2.instance.Instance):\n                    instances.append(instance)\n            for idx in reversed(fulfilled):\n                request_ids.pop(idx)\n\n            if request_ids and time_exceeded:\n                self.cancel_spot_requests(request_ids)\n                break\n\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _scale_down(self, instances, count):\n        i = sorted(instances, key=lambda i: i.launch_time, reverse=True)\n        if not i:\n            return []\n        running = len(i)\n        logger.info('%d instance/s are running.', running)\n        logger.info('Scaling down %d instances of those.', count)\n        if count > running:\n            logger.info('Scale-down value is > than running instance/s - using maximum of %d!', running)\n            count = running\n        return i[:count]", "response": "Return a list of count last created instances by launch time."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if root device name and size were specified in the image definition.", "response": "def _get_default_name_size(self, instance_type, size):\n        \"\"\"Checks if root device name/size were specified in the image definition.\n\n        :param instance_type: A section name in amazon.json.\n        :type instance_type: str\n        :param size:\n        :type size: int\n        :return: Root device name and size\n        :rtype: tuple(str, int)\n        \"\"\"\n        if 'root_size' in self.images[instance_type]:\n            size = self.images[instance_type].pop('root_size')\n\n        if 'root_device' in self.images[instance_type]:\n            name = self.images[instance_type].pop('root_device')\n        else:\n            name = '/dev/sda1'\n\n        return name, size"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures the root EBS volume.", "response": "def _configure_ebs_volume(self, vol_type, name, size, delete_on_termination):\n        \"\"\"Sets the desired root EBS size, otherwise the default EC2 value is used.\n\n        :param vol_type: Type of EBS storage - gp2 (SSD), io1 or standard (magnetic)\n        :type vol_type: str\n        :param size: Desired root EBS size.\n        :type size: int\n        :param delete_on_termination: Toggle this flag to delete EBS volume on termination.\n        :type delete_on_termination: bool\n        :return: A BlockDeviceMapping object.\n        :rtype: object\n        \"\"\"\n        # From GitHub boto docs: http://git.io/veyDv\n        root_dev = boto.ec2.blockdevicemapping.BlockDeviceType()\n        root_dev.delete_on_termination = delete_on_termination\n        root_dev.volume_type = vol_type\n        if size != 'default':\n            root_dev.size = size  # change root volume to desired size\n        bdm = boto.ec2.blockdevicemapping.BlockDeviceMapping()\n        bdm[name] = root_dev\n        return bdm"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop each provided running instance.", "response": "def stop(self, instances, count=0):\n        \"\"\"Stop each provided running instance.\n\n        :param count:\n        :param instances: A list of instances.\n        :type instances: list\n        \"\"\"\n        if not instances:\n            return\n        if count > 0:\n            instances = self._scale_down(instances, count)\n        self.ec2.stop_instances([i.id for i in instances])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nterminate each provided running or stopped instance.", "response": "def terminate(self, instances, count=0):\n        \"\"\"Terminate each provided running or stopped instance.\n\n        :param count:\n        :param instances: A list of instances.\n        :type instances: list\n        \"\"\"\n        if not instances:\n            return\n        if count > 0:\n            instances = self._scale_down(instances, count)\n        self.ec2.terminate_instances([i.id for i in instances])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(self, instance_ids=None, filters=None):\n        instances = []\n        reservations = self.retry_on_ec2_error(self.ec2.get_all_instances, instance_ids=instance_ids, filters=filters)\n        for reservation in reservations:\n            instances.extend(reservation.instances)\n        return instances", "response": "Find all the instances in the specified list of instance ids."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the CommandLine classes from each provider.", "response": "def command_line_interfaces(self):\n        \"\"\"Return the CommandLine classes from each provider.\n        \"\"\"\n        interfaces = []\n        for _, module in self.modules.items():\n            for entry in dir(module):\n                if entry.endswith('CommandLine'):\n                    interfaces.append((module, entry))\n        return interfaces"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pluralize(item):\n        assert isinstance(item, (int, list))\n        if isinstance(item, int):\n            return 's' if item > 1 else ''\n        if isinstance(item, list):\n            return 's' if len(item) > 1 else ''\n        return ''", "response": "Return a human - readable version of the given item."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms some basic configuration validation.", "response": "def validate(self):\n        \"\"\"Perform some basic configuration validation.\n        \"\"\"\n        if not self.conf.get('auth_token'):\n            raise PacketManagerException('The auth token for Packet is not defined but required.')\n        if not self.conf.get('projects'):\n            raise PacketManagerException('Required \"projects\" section is missing.')\n\n        projects = self.conf.get('projects')\n        if not projects.keys():\n            raise PacketManagerException('At least one project at Packet is required.')\n\n        failure = False\n        for project, identifier in projects.items():\n            if not identifier:\n                failure = True\n                logging.error('Project \"%s\" has no valid identifier.', project)\n        if failure:\n            raise PacketManagerException('One or more projects are not setup appropriately.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_projects(self, projects):\n        for project in projects:\n            print('{}: {}'.format(project.name, project.id))", "response": "Print method for projects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_operating_systems(self, operating_systems):\n        for _os in operating_systems:\n            print('{}: {}'.format(_os.name, _os.slug))", "response": "Print the operating systems."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_plans(self, plans):\n        for plan in plans:\n            print('Name: {} \"{}\" Price: {} USD'.format(plan.name, plan.slug, plan.pricing['hour']))\n            self.pprint(plan.specs)\n            print('\\n')", "response": "Print the details of the plans."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint method for facilities.", "response": "def print_facilities(self, facilities):\n        \"\"\"Print method for facilities.\n        \"\"\"\n        for facility in facilities:\n            print('{} - ({}): {}'.format(facility.code, facility.name, \",\".join(facility.features)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_devices(self, project_id, conditions=None, params=None):\n        default_params = {'per_page': 1000}\n        if params:\n            default_params.update(params)\n        data = self.api('projects/%s/devices' % project_id, params=default_params)\n        devices = []\n        for device in self.filter(conditions, data['devices']):\n            devices.append(packet.Device(device, self.manager))\n        return devices", "response": "Retrieve list of devices in a project by one of more conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints method for devices.", "response": "def print_devices(self, devices):\n        \"\"\"Print method for devices.\n        \"\"\"\n        for device in devices:\n            print('ID: {} OS: {} IP: {} State: {} ({}) Tags: {}'\n                  .format(device.id,\n                          device.operating_system.slug,\n                          self.get_public_ip(device.ip_addresses),\n                          device.state,\n                          'spot' if device.spot_instance else 'on-demand',\n                          device.tags))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter(criterias, devices):  # pylint: disable=too-many-branches\n        if not criterias:\n            return devices\n        result = []\n        for device in devices:  # pylint: disable=too-many-nested-blocks\n            for criteria_name, criteria_values in criterias.items():\n                if criteria_name in device.keys():\n                    if isinstance(device[criteria_name], list):\n                        for criteria_value in criteria_values:\n                            if criteria_value in device[criteria_name]:\n                                result.append(device)\n                                break\n                    elif isinstance(device[criteria_name], str):\n                        for criteria_value in criteria_values:\n                            if criteria_value == device[criteria_name]:\n                                result.append(device)\n                    elif isinstance(device[criteria_name], int):\n                        for criteria_value in criteria_values:\n                            if criteria_value == device[criteria_name]:\n                                result.append(device)\n                    else:\n                        continue\n        return result", "response": "Filter a device by criterias on the root level of the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns either the devices public IPv4 or IPv6 address.", "response": "def get_public_ip(addresses, version=4):\n        \"\"\"Return either the devices public IPv4 or IPv6 address.\n        \"\"\"\n        for addr in addresses:\n            if addr['public'] and addr['address_family'] == version:\n                return addr.get('address')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates if a deploy can be fulfilled.", "response": "def validate_capacity(self, servers):\n        \"\"\"Validates if a deploy can be fulfilled.\n        \"\"\"\n        try:\n            return self.manager.validate_capacity(servers)\n        except packet.baseapi.Error as msg:\n            raise PacketManagerException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new volume.", "response": "def create_volume(self, project_id, plan, size, facility, label=\"\"):\n        \"\"\"Creates a new volume.\n        \"\"\"\n        try:\n            return self.manager.create_volume(project_id, label, plan, size, facility)\n        except packet.baseapi.Error as msg:\n            raise PacketManagerException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattaches the created Volume to a Device.", "response": "def attach_volume_to_device(self, volume_id, device_id):\n        \"\"\"Attaches the created Volume to a Device.\n        \"\"\"\n        try:\n            volume = self.manager.get_volume(volume_id)\n            volume.attach(device_id)\n        except packet.baseapi.Error as msg:\n            raise PacketManagerException(msg)\n        return volume"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new on demand device under the given project.", "response": "def create_demand(self,\n                      project_id,\n                      facility,\n                      plan,\n                      operating_system,\n                      tags=None,\n                      userdata='',\n                      hostname=None,\n                      count=1):\n        \"\"\"Create a new on demand device under the given project.\n        \"\"\"\n        tags = {} if tags is None else tags\n        hostname = self.get_random_hostname() if hostname is None else hostname\n        devices = []\n        for i in range(1, count + 1):\n            new_hostname = hostname if count == 1 else hostname + '-' + str(i)\n            self.logger.info('Adding to project %s: %s, %s, %s, %s, %r',\n                             project_id,\n                             new_hostname,\n                             facility,\n                             plan,\n                             operating_system,\n                             tags)\n            try:\n                device = self.manager.create_device(project_id=project_id,\n                                                    hostname=new_hostname,\n                                                    facility=facility,\n                                                    plan=plan,\n                                                    tags=tags,\n                                                    userdata=userdata,\n                                                    operating_system=operating_system)\n                devices.append(device)\n            except packet.baseapi.Error as msg:\n                raise PacketManagerException(msg)\n        return devices"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self, devices):\n        for device in devices:\n            self.logger.info('Stopping: %s', device.id)\n            try:\n                device.power_off()\n            except packet.baseapi.Error:\n                raise PacketManagerException('Unable to stop instance \"{}\"'.format(device.id))", "response": "Power - Off one or more running devices."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reboot(self, devices):\n        for device in devices:\n            self.logger.info('Rebooting: %s', device.id)\n            try:\n                device.reboot()\n            except packet.baseapi.Error:\n                raise PacketManagerException('Unable to reboot instance \"{}\"'.format(device.id))", "response": "Reboot one or more devices."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nterminates one or more running or stopped instances.", "response": "def terminate(self, devices):\n        \"\"\"Terminate one or more running or stopped instances.\n        \"\"\"\n        for device in devices:\n            self.logger.info('Terminating: %s', device.id)\n            try:\n                device.delete()\n            except packet.baseapi.Error:\n                raise PacketManagerException('Unable to terminate instance \"{}\"'.format(device.id))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter by tags. :param tags: Tags to filter. :type tags: ``list`` :return: A list of Node objects. :rtype: ``list`` of :class:`Node`", "response": "def tags(self, tags=None):\n        \"\"\"Filter by tags.\n\n        :param  tags: Tags to filter.\n        :type   tags: ``list``\n\n        :return: A list of Node objects.\n        :rtype:  ``list`` of :class:`Node`\n        \"\"\"\n        if tags is None or not tags:\n            return self\n        nodes = []\n        for node in self.nodes:\n            if any(tag in node.extra['tags'] for tag in tags):\n                nodes.append(node)\n        self.nodes = nodes\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering by state. :param tags: States to filter. :type tags: ``list`` :return: A list of Node objects. :rtype: ``list`` of :class:`Node`", "response": "def state(self, states=None):\n        \"\"\"Filter by state.\n\n        :param  tags: States to filter.\n        :type   tags: ``list``\n\n        :return: A list of Node objects.\n        :rtype:  ``list`` of :class:`Node`\n        \"\"\"\n        if states is None or not states:\n            return self\n        nodes = []\n        for node in self.nodes:\n            if any(state.lower() == node.state.lower() for state in states):\n                nodes.append(node)\n        self.nodes = nodes\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering by node name.", "response": "def name(self, names=None):\n        \"\"\"Filter by node name.\n\n        :param  names: Node names to filter.\n        :type   names: ``list``\n\n        :return: A list of Node objects.\n        :rtype:  ``list`` of :class:`Node`\n        \"\"\"\n        if names is None or not names:\n            return self\n        nodes = []\n        for node in self.nodes:\n            if any(name == node.name for name in names):\n                nodes.append(node)\n        self.nodes = nodes\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters by preemptible scheduling.", "response": "def is_preemptible(self):\n        \"\"\"Filter by preemptible scheduling.\n\n        :return: A list of Node objects.\n        :rtype:  ``list`` of :class:`Node`\n        \"\"\"\n        nodes = []\n        for node in self.nodes:\n            if Kurz.is_preemtible(node):\n                nodes.append(node)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef expr(self, callback):\n        nodes = []\n        for node in self.nodes:\n            if callback(node):\n                nodes.append(node)\n        self.nodes = nodes\n        return self", "response": "Filter by custom expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects to Google Compute Engine.", "response": "def connect(self, **kwargs):\n        \"\"\"Connect to Google Compute Engine.\n        \"\"\"\n        try:\n            self.gce = get_driver(Provider.GCE)(\n                self.user_id,\n                self.key,\n                project=self.project,\n                **kwargs)\n        except:\n            raise ComputeEngineManagerException(\"Unable to connect to Google Compute Engine.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_connected(self, attempts=3):\n        if self.gce is None:\n            while attempts > 0:\n                self.logger.info(\"Attempting to connect ...\")\n                try:\n                    self.connect()\n                except ComputeEngineManagerException:\n                    attempts -= 1\n                    continue\n                self.logger.info(\"Connection established.\")\n                return True\n            self.logger.error(\"Unable to connect to Google Compute Engine.\")\n            return False\n\n        return True", "response": "Attempts to connect to Google Compute Engine."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, size, number, meta, name=None, image=None, attempts=3):\n        if name is None:\n            name = Common.get_random_hostname()\n\n        if image is None and number == 1:\n            raise ComputeEngineManagerException(\"Base image not provided.\")\n\n        successful = 0\n        nodes = []\n\n        while number - successful > 0 and attempts > 0:\n            if number == 1:\n                # Used because of suffix naming scheme in ex_create_multiple_nodes() for a single node.\n                nodes = [self.gce.create_node(name, size, image, **meta)]\n            else:\n                nodes = self.gce.ex_create_multiple_nodes(name, size, None, number - successful,\n                                                          ignore_errors=False,\n                                                          poll_interval=1,\n                                                          **meta)\n            for node in nodes:\n                if isinstance(node, GCEFailedNode):\n                    self.logger.error(\"Node failed to create, code %s error: %s\", node.code, node.error)\n                    continue\n                successful += 1\n                self.nodes.append(node)\n\n            attempts -= 1\n\n        if number != successful:\n            self.logger.error(\"We tried but %d nodes failed to create.\", number - successful)\n\n        return nodes", "response": "Creates a container VM nodes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self, nodes=None):\n        if not self.is_connected():\n            return None\n\n        nodes = nodes or self.nodes\n        result = []\n\n        for node in nodes:\n            if node.state == 'stopped':\n                logging.warning('Node %s is already \"stopped\".', node.name)\n                continue\n            try:\n                status = self.gce.ex_stop_node(node)\n                if status:\n                    result.append(node)\n            except InvalidRequestError as err:\n                raise ComputeEngineManagerException(err)\n\n        return result", "response": "Stop one or many nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, nodes=None):\n        if not self.is_connected():\n            return None\n\n        nodes = nodes or self.nodes\n        result = []\n\n        for node in nodes:\n            if node.state == 'running':\n                logging.warning('Node %s is already \"running\".', node.name)\n                continue\n            try:\n                status = self.gce.ex_start_node(node)\n                if status:\n                    result.append(node)\n            except InvalidRequestError as err:\n                raise ComputeEngineManagerException(err)\n\n        return result", "response": "Start one or many nodes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndestroying one or many nodes.", "response": "def terminate(self, nodes=None):\n        \"\"\"Destroy one or many nodes.\n\n        :param   nodes: Nodes to be destroyed.\n        :type    nodes: ``list``\n\n        :return: List of nodes which failed to terminate.\n        :rtype:  ``list``\n        \"\"\"\n        if not self.is_connected():\n            return None\n\n        nodes = nodes or self.nodes\n        failed_kill = []\n\n        result = self.gce.ex_destroy_multiple_nodes(nodes, poll_interval=1, ignore_errors=False)\n\n        # Verify whether all instances have been terminated.\n        for i, success in enumerate(result):\n            if success:\n                logging.info('Successfully destroyed: %s', nodes[i].name)\n            else:\n                logging.error('Failed to destroy: %s', nodes[i].name)\n                failed_kill.append(nodes[i])\n\n        return failed_kill"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef terminate_with_threads(self, nodes=None):\n        if not self.is_connected():\n            return None\n\n        nodes = nodes or self.nodes\n        failed_kill = []\n\n        def worker(gce, node):\n            self.logger.info(\"Terminating node: %s\", node.name)\n            terminated = gce.destroy_node(node)\n            if not terminated:\n                failed_kill.append(node)\n\n        threads = []\n        for node in nodes:\n            thread = threading.Thread(target=worker, args=(self.gce, node))\n            threads.append(thread)\n            thread.start()\n\n        self.logger.info(\"Waiting for nodes to shut down ...\")\n        for thread in threads:\n            thread.join()\n\n        return failed_kill", "response": "Terminate one or many nodes threaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps method for terminate.", "response": "def terminate_ex(self, nodes, threads=False, attempts=3):\n        \"\"\"Wrapper method for terminate.\n\n        :param   nodes: Nodes to be destroyed.\n        :type    nodes: ``list``\n\n        :param   attempts: The amount of attempts for retrying to terminate failed instances.\n        :type    attempts: ``int``\n\n        :param   threads: Whether to use the threaded approach or not.\n        :type    threads: ``bool``\n\n        \"\"\"\n        while nodes and attempts > 0:\n            if threads:\n                nodes = self.terminate_with_threads(nodes)\n            else:\n                nodes = self.terminate(nodes)\n            if nodes:\n                logger.info(\"Attempt to terminate the remaining instances once more.\")\n                attempts -= 1\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a boot disk struct.", "response": "def build_bootdisk(self, image, size=10, auto_delete=True):\n        \"\"\"Buid a disk struct.\n\n        :param  image: Base image name.\n        :type   image: ``str``\n\n        :param  size: Persistent disk size.\n        :type   size: ``int``\n\n        :param  auto_delete: Wether to auto delete disk on instance termination.\n        :type   auto_delete: ``bool``\n        \"\"\"\n        if image is None:\n            raise ComputeEngineManagerException(\"Image must not be None.\")\n        return {\n            'boot': True,\n            'autoDelete': auto_delete,\n            'initializeParams': {\n                'sourceImage': \"projects/cos-cloud/global/images/{}\".format(image),\n                'diskSizeGb': size,\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a dictionary of keyword arguments for a container VM.", "response": "def build_container_vm(self, container, disk, zone=\"us-east1-b\", tags=None, preemptible=True):\n        \"\"\"Build kwargs for a container VM.\n\n        :param   container: Container declaration.\n        :type    container: ``dict``\n\n        :param   disk: Disk definition structure.\n        :type    disk: ``dict``\n\n        :param   zone: The zone in which the instance should run.\n        :type    zone: ``str``\n\n        :param   tags: Tags associated with the instance.\n        :type    tags: ``dict``\n\n        :param   preemptible: Wether the instance is a preemtible or not.\n        :type    preemptible: ``bool``\n        \"\"\"\n        if tags is None:\n            tags = []\n        if container is None:\n            raise ComputeEngineManagerException(\"Container declaration must not be None.\")\n        if disk is None:\n            raise ComputeEngineManagerException(\"Disk structure must not be None.\")\n        return {\n            'ex_metadata': {\n                \"gce-container-declaration\": container,\n                \"google-logging-enabled\": \"true\"\n            },\n            'location': zone,\n            'ex_tags': tags,\n            'ex_disks_gce_struct': [disk],\n            'ex_preemptible': preemptible\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter(self, zone='all'):\n        if not self.is_connected():\n            return None\n\n        nodes = self.gce.list_nodes(zone)\n        return Filter(nodes)", "response": "Return a chainable filter object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_arguments(cls, subparsers, dirs):\n        parser = subparsers.add_parser(\n            'packet',\n            help='Packet Bare Metal',\n            formatter_class=lambda prog: argparse.ArgumentDefaultsHelpFormatter(prog, max_help_position=40, width=120))\n\n        m = parser.add_argument_group('Mandatory Packet Parameters') # pylint: disable=invalid-name\n\n        g = m.add_mutually_exclusive_group(required=False) # pylint: disable=invalid-name\n        g.add_argument('-create-demand',\n                       action='store_true',\n                       help='Create an on demand based bare metal device instance.')\n\n        g.add_argument('-create-spot',\n                       action='store_true',\n                       help='Create a spot price based bare metal device instance.')\n\n        g.add_argument('-reboot',\n                       nargs='?',\n                       const=-1,\n                       metavar='n',\n                       help='Reboot active instances.')\n\n        g.add_argument('-stop',\n                       nargs='?',\n                       const=-1,\n                       metavar='n',\n                       help='Stop active instances.')\n\n        g.add_argument('-terminate',\n                       nargs='?',\n                       const=-1,\n                       metavar='n',\n                       help='Terminate active instances.')\n\n        o = parser.add_argument_group('Optional Parameters') # pylint: disable=invalid-name\n        o.add_argument('-create-volume',\n                       nargs='+',\n                       type=str,\n                       metavar='s',\n                       help='Create storage: <plan> <size> <region> <description>')\n\n        o.add_argument('-conf',\n                       metavar='path',\n                       type=argparse.FileType(),\n                       default=os.path.join(dirs.user_config_dir, 'examples', 'packet', 'packet.json'),\n                       help='Packet configuration')\n\n        o.add_argument('-list-projects',\n                       action='store_true',\n                       help='List available projects.')\n\n        o.add_argument('-list-plans',\n                       action='store_true',\n                       help='List available plans.')\n\n        o.add_argument('-list-operating-systems',\n                       action='store_true',\n                       help='List available operating systems.')\n\n        o.add_argument('-list-spot-prices',\n                       action='store_true',\n                       help='List spot prices.')\n\n        o.add_argument('-list-facilities',\n                       action='store_true',\n                       help='List available facilities.')\n\n        o.add_argument('-list-devices',\n                       action='store_true',\n                       help='List devices under given project name.')\n\n        o.add_argument('-project',\n                       metavar='project',\n                       type=str,\n                       default='fuzzing',\n                       help='The project to perform operations on.')\n        o.add_argument('-tags',\n                       metavar='seq',\n                       nargs='+',\n                       type=str,\n                       help='Tags associated with the instance.')\n        o.add_argument('-region',\n                       metavar='region',\n                       type=str,\n                       default='nrt1',\n                       help='The facility in which the instance is going to run.')\n        o.add_argument('-os',\n                       metavar='name',\n                       type=str,\n                       default='ubuntu_18_04',\n                       help='The operating system for the created instance.')\n        o.add_argument('-plan',\n                       metavar='name',\n                       type=str,\n                       default='baremetal_0',\n                       help='The instance type to run.')\n        o.add_argument('-max-spot-price',\n                       metavar='#',\n                       type=float,\n                       default='0.05',\n                       help='Max price for spot instances.')\n        o.add_argument('-count',\n                       metavar='#',\n                       type=int,\n                       default='1',\n                       help='The amount of devices to be spawned.')\n        o.add_argument('-only',\n                       metavar='k=v',\n                       nargs='+',\n                       type=str,\n                       help='Filter instances by criterias.')\n        o.add_argument('-version',\n                       action='version',\n                       version='%(prog)s {}'.format(cls.VERSION),\n                       help=argparse.SUPPRESS)", "response": "Adds the command line arguments for the\nTaxonomy command line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(cls, args, settings=None, userdata=None):  # pylint: disable=too-many-branches,too-many-statements\n        # The command-line client uses Service Account authentication.\n        logger.info('Using Compute Engine credentials from %s', Focus.info(args.conf.name))\n        try:\n            key = json.loads(args.conf.read())\n        except ValueError as msg:\n            logger.error('Unable to parse %s: %s', args.conf.name, msg)\n            return 1\n\n        # Compute Engine Manager\n        try:\n            cluster = ComputeEngineManager(key['client_email'], args.conf.name, key['project_id'])\n            cluster.connect()\n            # Remove read |key| from memory which contains the private key.\n            del key\n        except ComputeEngineManagerException as msg:\n            logger.error(msg)\n            return 1\n\n        # Create one or many compute VMs.\n        if args.create:\n            if args.tags:\n                logger.info('Assigning the following tags to the instance: %r', args.tags)\n\n            container_declaration = args.declaration.read()\n            try:\n                disk = cluster.build_bootdisk(args.image, args.disk_size, args.disk_auto_delete)\n                conf = cluster.build_container_vm(container_declaration, disk,\n                                                  zone=args.zone,\n                                                  tags=args.tags,\n                                                  preemptible=args.preemptible)\n            except ComputeEngineManagerException as msg:\n                logging.error(msg)\n                return 1\n\n            logging.debug('VM Configuration: %r', conf)\n            try:\n                logging.info('Creating %d VM%s of type \"%s\" ...',\n                             args.count, Common.pluralize(args.count), args.size)\n                nodes = cluster.create(args.size, args.count, conf, image=args.image)\n                for node in nodes:\n                    logging.info('Node %s created and %s.', node.name, node.state)\n            except ComputeEngineManagerException as msg:\n                logging.error(msg)\n                return 1\n\n        # Run filters before dealing with any state routine.\n        nodes = []\n        if any([args.stop, args.start, args.reboot, args.terminate]):\n            nodes = cls.list(cls, cluster, args.zone, args.states, args.names, args.tags)\n\n        # Routines for other VM states.\n        if args.start:\n            try:\n                logger.info(\"Starting %d node%s ...\", len(nodes), Common.pluralize(nodes))\n                cluster.start(nodes)\n            except ComputeEngineManagerException as msg:\n                logger.error(msg)\n                return 1\n\n        if args.stop:\n            try:\n                logger.info(\"Stopping %d node%s ...\", len(nodes), Common.pluralize(nodes))\n                cluster.stop(nodes)\n            except ComputeEngineManagerException as msg:\n                logger.error(msg)\n                return 1\n\n        if args.reboot:\n            try:\n                logger.info(\"Rebooting %d node%s ...\", len(nodes), Common.pluralize(nodes))\n                cluster.reboot(nodes)\n            except ComputeEngineManagerException as msg:\n                logger.error(msg)\n                return 1\n\n        if args.terminate:\n            try:\n                logger.info(\"Terminating %d node%s ...\", len(nodes), Common.pluralize(nodes))\n                cluster.terminate_ex(nodes, True)\n            except ComputeEngineManagerException as msg:\n                logger.error(msg)\n                return 1\n\n        if args.list:\n            try:\n                nodes = cls.list(cls, cluster, args.zone, args.states, args.names, args.tags)\n                for node in nodes:\n                    logging.info('Node: %s is %s; IP: %s (%s); Preemtible: %s',\n                                 node.name, node.state,\n                                 Kurz.ips(node), Kurz.zone(node), Kurz.is_preemtible(node))\n            except ComputeEngineManagerException as msg:\n                logger.error(msg)\n                return 1\n\n        return 0", "response": "Main entry point of the compute engine module."}
