{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dateint_week_by_dateint(dateint, first_day='Monday'):\n    weekday_ix = dateint_to_weekday(dateint, first_day)\n    first_day_dateint = shift_dateint(dateint, -weekday_ix)\n    last_day_dateint = shift_dateint(first_day_dateint, 6)\n    return dateint_range(first_day_dateint, last_day_dateint)", "response": "Return a dateint range of the week the given dateint belongs to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the difference between two dateints in days.", "response": "def dateint_difference(dateint1, dateint2):\n    \"\"\"Return the difference between two dateints in days.\n\n    Arguments\n    ---------\n    dateint1 : int\n        An integer object decipting a specific calendaric day; e.g. 20161225.\n    dateint2 : int\n        An integer object decipting a specific calendaric day; e.g. 20161225.\n\n    Returns\n    -------\n    int\n        The difference between the two given dateints in days.\n    \"\"\"\n    dt1 = dateint_to_datetime(dateint1)\n    dt2 = dateint_to_datetime(dateint2)\n    delta = dt1 - dt2\n    return abs(delta.days)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef touch(fname, times=None):\n    fpath, f = os.path.split(fname)\n    if not os.path.exists(fpath):\n        os.makedirs(fpath)\n\n    with open(fname, 'a'):\n        os.utime(fname, times)", "response": "Creates an empty file at fname creating path if necessary\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copyFile(src, dest):\n    #Src Exists?\n    try:\n        if os.path.isfile(src):\n            dpath, dfile = os.path.split(dest)\n\n            if not os.path.isdir(dpath):\n                os.makedirs(dpath)\n\n            if not os.path.exists(dest):\n                touch(dest)\n            try:\n                shutil.copy2(src, dest)\n            # eg. src and dest are the same file\n            except shutil.Error as e:\n                logging.exception('Error: %s' % e)\n            # eg. source or destination doesn't exist\n            except IOError as e:\n                logging.exception('Error: %s' % e.strerror)\n    except:\n        logging.exception('Error: src to copy does not exist.')", "response": "Copies a source file to a destination file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing user notification message via terminal - notifier command.", "response": "def _terminal_notifier(title, message):\n    \"\"\" Shows user notification message via `terminal-notifier` command.\n\n        `title`\n            Notification title.\n        `message`\n            Notification message.\n        \"\"\"\n\n    try:\n        paths = common.extract_app_paths(['terminal-notifier'])\n    except ValueError:\n        pass\n\n    common.shell_process([paths[0], '-title', title, '-message', message])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows growl notification message via growlnotify command.", "response": "def _growlnotify(title, message):\n    \"\"\" Shows growl notification message via `growlnotify` command.\n\n        `title`\n            Notification title.\n        `message`\n            Notification message.\n        \"\"\"\n\n    try:\n        paths = common.extract_app_paths(['growlnotify'])\n    except ValueError:\n        return\n\n    common.shell_process([paths[0], '-t', title, '-m', message])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing a popup dialog message via System Events daemon.", "response": "def _osx_popup(title, message):\n    \"\"\" Shows a popup dialog message via System Events daemon.\n\n        `title`\n            Notification title.\n        `message`\n            Notification message.\n        \"\"\"\n\n    message = message.replace('\"', '\\\\\"')  # escape message\n\n    # build applescript\n    script = \"\"\"\n     tell application \"System Events\"\n       display dialog \"{0}\"\n     end tell\"\"\".format(message)\n\n    # run it\n    common.shell_process(['osascript', '-e', script])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dbus_notify(title, message):\n\n    try:\n        # fetch main account manager interface\n        bus = dbus.SessionBus()\n        obj = bus.get_object('org.freedesktop.Notifications',\n                             '/org/freedesktop/Notifications')\n        if obj:\n            iface = dbus.Interface(obj, 'org.freedesktop.Notifications')\n\n            if iface:\n                # dispatch notification message\n                iface.Notify('Focus', 0, '', title, message, [], {}, 5)\n\n    except dbus.exceptions.DBusException:\n        pass", "response": "Displays system notification message via dbus."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows system notification message according to system requirements.", "response": "def _notify(self, task, message):\n        \"\"\" Shows system notification message according to system requirements.\n\n            `message`\n                Status message.\n            \"\"\"\n\n        if self.notify_func:\n            message = common.to_utf8(message.strip())\n            title = common.to_utf8(u'Focus ({0})'.format(task.name))\n            self.notify_func(title, message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_option(self, option, block_name, message):\n\n        if option == 'show':\n            option = 'start_' + option\n\n        key = option.split('_', 1)[0]\n        self.messages[key] = message", "response": "Parse show end_show timer_show and show options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a list into a comma separated string for displaying select multiple values in emails.", "response": "def format_value(value):\n    \"\"\"\n    Convert a list into a comma separated string, for displaying\n    select multiple values in emails.\n    \"\"\"\n    if isinstance(value, list):\n        value = \", \".join([v.strip() for v in value])\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the form and handle submission.", "response": "def form_processor(request, page):\n    \"\"\"\n    Display a built form and handle submission.\n    \"\"\"\n    form = FormForForm(page.form, RequestContext(request),\n                       request.POST or None, request.FILES or None)\n    if form.is_valid():\n        url = page.get_absolute_url() + \"?sent=1\"\n        if is_spam(request, form, url):\n            return redirect(url)\n        attachments = []\n        for f in form.files.values():\n            f.seek(0)\n            attachments.append((f.name, f.read()))\n        entry = form.save()\n        subject = page.form.email_subject\n        if not subject:\n            subject = \"%s - %s\" % (page.form.title, entry.entry_time)\n        fields = [(v.label, format_value(form.cleaned_data[k]))\n                  for (k, v) in form.fields.items()]\n        context = {\n            \"fields\": fields,\n            \"message\": page.form.email_message,\n            \"request\": request,\n        }\n        email_from = page.form.email_from or settings.DEFAULT_FROM_EMAIL\n        email_to = form.email_to()\n        if email_to and page.form.send_email:\n            send_mail_template(subject, \"email/form_response\", email_from,\n                               email_to, context)\n        headers = None\n        if email_to:\n            # Add the email entered as a Reply-To header\n            headers = {'Reply-To': email_to}\n        email_copies = split_addresses(page.form.email_copies)\n        if email_copies:\n            send_mail_template(subject, \"email/form_response_copies\",\n                               email_from, email_copies, context,\n                               attachments=attachments, headers=headers)\n        form_valid.send(sender=request, form=form, entry=entry)\n        return redirect(url)\n    form_invalid.send(sender=request, form=form)\n    return {\"form\": form}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visible(self):\n        if not self.in_workspace():\n            return False\n\n        if not self.context.join_policy == \"self\":\n            return False\n\n        user = api.user.get_current()\n        workspace = IWorkspace(self.context.acquire_workspace())\n        if user.getUserName() in workspace.members:\n            return False\n\n        return True", "response": "Returns True if the join viewlet is visible if False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the resource is visible on the sharing view", "response": "def visible(self):\n        \"\"\"\n        Only shown on the sharing view\n        \"\"\"\n        context_state = api.content.get_view(context=self.context,\n                                             request=self.request,\n                                             name=\"plone_context_state\")\n        url = context_state.current_base_url()\n        return url.endswith('@@sharing')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef active_participant_policy(self):\n        key = self.context.participant_policy\n        policy = PARTICIPANT_POLICY.get(key)\n        return policy['title']", "response": "Get the title of the currently active participation policy"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bool_assignment(arg, patterns=None):\n    arg = str(arg)    # only eval type str\n    try:\n        if patterns is None:\n            patterns = (\n                (re.compile(r'^(true|false)$', flags=re.IGNORECASE), lambda x: x.lower() == 'true'),\n                (re.compile(r'^(yes|no)$', flags=re.IGNORECASE), lambda x: x.lower() == 'yes'),\n                (re.compile(r'^(y|n)$', flags=re.IGNORECASE), lambda x: x.lower() == 'y')\n            )\n        if not arg:\n            return ''    # default selected\n        else:\n            for pattern, func in patterns:\n                if pattern.match(arg):\n                    return func(arg)\n    except Exception as e:\n        raise e", "response": "This function returns a bool assignment for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts datetime. datetime to datetime object", "response": "def convert_strtime_datetime(dt_str):\n    \"\"\" Converts datetime isoformat string to datetime (dt) object\n\n    Args:\n        :dt_str (str): input string in '2017-12-30T18:48:00.353Z' form\n         or similar\n    Returns:\n        TYPE:  datetime object\n    \"\"\"\n    dt, _, us = dt_str.partition(\".\")\n    dt = datetime.datetime.strptime(dt, \"%Y-%m-%dT%H:%M:%S\")\n    us = int(us.rstrip(\"Z\"), 10)\n    return dt + datetime.timedelta(microseconds=us)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a datetime. timedelta object into a tuple of component time units", "response": "def convert_timedelta(duration):\n    \"\"\"\n    Summary:\n        Convert duration into component time units\n    Args:\n        :duration (datetime.timedelta): time duration to convert\n    Returns:\n        days, hours, minutes, seconds | TYPE: tuple (integers)\n    \"\"\"\n    days, seconds = duration.days, duration.seconds\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = (seconds % 60)\n    return days, hours, minutes, seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_dt_time(duration, return_iter=False):\n    try:\n        days, hours, minutes, seconds = convert_timedelta(duration)\n        if return_iter:\n            return days, hours, minutes, seconds\n        # string format conversions\n        if days > 0:\n            format_string = (\n                '{} day{}, {} hour{}'.format(\n                 days, 's' if days != 1 else '', hours, 's' if hours != 1 else ''))\n        elif hours > 1:\n            format_string = (\n                '{} hour{}, {} minute{}'.format(\n                 hours, 's' if hours != 1 else '', minutes, 's' if minutes != 1 else ''))\n        else:\n            format_string = (\n                '{} minute{}, {} sec{}'.format(\n                 minutes, 's' if minutes != 1 else '', seconds, 's' if seconds != 1 else ''))\n    except AttributeError as e:\n        logger.exception(\n            '%s: Type mismatch when converting timedelta objects (Code: %s)' %\n            (inspect.stack()[0][3], str(e)))\n    except Exception as e:\n        logger.exception(\n            '%s: Unknown error when converting datetime objects (Code: %s)' %\n            (inspect.stack()[0][3], str(e)))\n    return format_string", "response": "Convert timedelta objects to human readable format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary containing the os type detail distribution and home directory of the local operating system environment characteristics.", "response": "def get_os(detailed=False):\n    \"\"\"\n    Summary:\n        Retrieve local operating system environment characteristics\n    Args:\n        :user (str): USERNAME, only required when run on windows os\n    Returns:\n        TYPE: dict object containing key, value pairs describing\n        os information\n    \"\"\"\n    try:\n\n        os_type = platform.system()\n\n        if os_type == 'Linux':\n            os_detail = platform.uname()\n            distribution = platform.linux_distribution()\n            HOME = os.environ['HOME']\n            username = os.getenv('USER')\n        elif os_type == 'Windows':\n            username = os.getenv('username')\n            HOME = 'C:\\\\Users\\\\' + username\n        elif os_type == 'Java':\n            logger.warning('Unsupported OS. No information')\n    except OSError as e:\n        raise e\n    except Exception as e:\n        logger.exception(\n            '%s: problem determining local os environment %s' %\n            (inspect.stack()[0][3], str(e))\n            )\n    if detailed and os_type == 'Linux':\n        return {\n                'os_type': os_type,\n                'os_detail': os_detail,\n                'linux_distribution': distribution,\n                'HOME': HOME\n            }\n    elif detailed and os_type == 'Windows':\n        return {\n                'os_type': os_type,\n                'platform': platform,\n                'HOME': HOME\n            }\n    elif not detailed:\n        return {'os_type': os_type}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse and update local awscli config credentials with the user s credentials", "response": "def awscli_defaults(os_type=None):\n    \"\"\"\n    Summary:\n        Parse, update local awscli config credentials\n    Args:\n        :user (str):  USERNAME, only required when run on windows os\n    Returns:\n        TYPE: dict object containing key, value pairs describing\n        os information\n    \"\"\"\n\n    try:\n        if os_type is None:\n            os_type = platform.system()\n\n        if os_type == 'Linux':\n            HOME = os.environ['HOME']\n            awscli_credentials = HOME + '/.aws/credentials'\n            awscli_config = HOME + '/.aws/config'\n        elif os_type == 'Windows':\n            username = os.getenv('username')\n            awscli_credentials = 'C:\\\\Users\\\\' + username + '\\\\.aws\\\\credentials'\n            awscli_config = 'C:\\\\Users\\\\' + username + '\\\\.aws\\\\config'\n        elif os_type == 'Java':\n            logger.warning('Unsupported OS. No information')\n            HOME = os.environ['HOME']\n            awscli_credentials = HOME + '/.aws/credentials'\n            awscli_config = HOME + '/.aws/config'\n        alt_credentials = os.getenv('AWS_SHARED_CREDENTIALS_FILE')\n    except OSError as e:\n        logger.exception(\n            '%s: problem determining local os environment %s' %\n            (inspect.stack()[0][3], str(e))\n            )\n        raise e\n    return {\n                'awscli_defaults': {\n                    'awscli_credentials': awscli_credentials,\n                    'awscli_config': awscli_config,\n                    'alt_credentials': alt_credentials\n                }\n            }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_init(config_file, json_config_obj, config_dirname=None):\n    HOME = os.environ['HOME']\n    # client config dir\n    if config_dirname:\n        dir_path = HOME + '/' + config_dirname\n        if not os.path.exists(dir_path):\n            os.mkdir(dir_path)\n            os.chmod(dir_path, 0o755)\n    else:\n        dir_path = HOME\n    # client config file\n    r = export_json_object(\n            dict_obj=json_config_obj,\n            filename=dir_path + '/' + config_file\n        )\n    return r", "response": "This function creates local config from JSON seed template"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexports a dictionary object to block filesystem object", "response": "def export_json_object(dict_obj, filename=None):\n    \"\"\"\n    Summary:\n        exports object to block filesystem object\n\n    Args:\n        :dict_obj (dict): dictionary object\n        :filename (str):  name of file to be exported (optional)\n\n    Returns:\n        True | False Boolean export status\n\n    \"\"\"\n    try:\n        if filename:\n            try:\n                with open(filename, 'w') as handle:\n                    handle.write(json.dumps(dict_obj, indent=4, sort_keys=True))\n                    logger.info(\n                        '%s: Wrote %s to local filesystem location' %\n                        (inspect.stack()[0][3], filename))\n                handle.close()\n            except TypeError as e:\n                logger.warning(\n                    '%s: object in dict not serializable: %s' %\n                    (inspect.stack()[0][3], str(e)))\n        else:\n            json_str = json.dumps(dict_obj, indent=4, sort_keys=True)\n            print(highlight(json_str, lexers.JsonLexer(), formatters.TerminalFormatter()))\n            logger.info('%s: successful export to stdout' % inspect.stack()[0][3])\n            return True\n    except IOError as e:\n        logger.critical(\n            '%s: export_file_object: error writing to %s to filesystem. Error: %s' %\n            (inspect.stack()[0][3], filename, str(e)))\n        return False\n    else:\n        logger.info('export_file_object: successful export to %s' % filename)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_file_object(filename):\n    try:\n        handle = open(filename, 'r')\n        file_obj = handle.read()\n        dict_obj = json.loads(file_obj)\n\n    except IOError as e:\n        logger.critical(\n            'import_file_object: %s error opening %s' % (str(e), str(filename))\n        )\n        raise e\n    except ValueError:\n        logger.info(\n            '%s: import_file_object: %s not json. file object returned' %\n            (inspect.stack()[0][3], str(filename))\n        )\n        return file_obj    # reg file, not valid json\n    return dict_obj", "response": "Imports a file object from a json file"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the USERNAME k v parameters are in the baseline and suspect dict.", "response": "def json_integrity(baseline, suspect):\n    \"\"\"\n    Summary:\n        Validates baseline dict against suspect dict to ensure contain USERNAME\n        k,v parameters.\n    Args:\n        baseline (dict): baseline json structure\n        suspect (dict): json object validated against baseline structure\n    Returns:\n        Success (matches baseline) | Failure (no match), TYPE: bool\n    \"\"\"\n    try:\n        for k,v in baseline.items():\n            for ks, vs in suspect.items():\n                keys_baseline = set(v.keys())\n                keys_suspect = set(vs.keys())\n                intersect_keys = keys_baseline.intersection(keys_suspect)\n                added = keys_baseline - keys_suspect\n                rm = keys_suspect - keys_baseline\n                logger.info('keys added: %s, keys removed %s' % (str(added), str(rm)))\n                if keys_baseline != keys_suspect:\n                    return False\n    except KeyError as e:\n        logger.info(\n            'KeyError parsing pre-existing config (%s). Replacing config file' %\n            str(e))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if two dictionaries are in JSONintegrity", "response": "def json_integrity_multilevel(d1, d2):\n    \"\"\" still under development \"\"\"\n    keys = [x for x in d2]\n    for key in keys:\n        d1_keys = set(d1.keys())\n        d2_keys = set(d2.keys())\n        intersect_keys = d1_keys.intersection(d2_keys)\n        added = d1_keys - d2_keys\n        removed = d2_keys - d1_keys\n        modified = {o : (d1[o], d2[o]) for o in intersect_keys if d1[o] != d2[o]}\n        same = set(o for o in intersect_keys if d1[o] == d2[o])\n        if added == removed == set():\n            d1_values = [x for x in d1.values()][0]\n            print('d1_values: ' + str(d1_values))\n            d2_values = [x for x in d2.values()][0]\n            print('d2_values: ' + str(d2_values))\n            length = len(d2_values)\n            print('length = %d' % length)\n            pdb.set_trace()\n            if length > 1:\n                d1 = d1_values.items()\n                d2 = d2_values.items()\n        else:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the local config file and returns a dict of values contained in the file", "response": "def read_local_config(cfg):\n    \"\"\" Parses local config file for override values\n\n    Args:\n        :local_file (str):  filename of local config file\n\n    Returns:\n        dict object of values contained in local config file\n    \"\"\"\n    try:\n        if os.path.exists(cfg):\n            config = import_file_object(cfg)\n            return config\n        else:\n            logger.warning(\n                '%s: local config file (%s) not found, cannot be read' %\n                (inspect.stack()[0][3], str(cfg)))\n    except IOError as e:\n        logger.warning(\n            'import_file_object: %s error opening %s' % (str(e), str(cfg))\n        )\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef os_parityPath(path):\n    path = os.path.normpath(os.path.expanduser(path))\n    if path.startswith('\\\\'):\n        return 'C:' + path\n    return path", "response": "Converts unix paths to correct windows equivalents."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a formfield that can be used to display a Tweetable item for the given DBField.", "response": "def formfield_for_dbfield(self, db_field, **kwargs):\n        \"\"\"\n        Adds the \"Send to Twitter\" checkbox after the \"status\" field,\n        provided by any ``Displayable`` models. The approach here is\n        quite a hack, however the sane approach of using a custom\n        form with a boolean field defined, and then adding it to the\n        formssets attribute of the admin class fell apart quite\n        horrifically.\n        \"\"\"\n        formfield = super(TweetableAdminMixin,\n            self).formfield_for_dbfield(db_field, **kwargs)\n        if Api and db_field.name == \"status\" and get_auth_settings():\n            def wrapper(render):\n                def wrapped(*args, **kwargs):\n                    rendered = render(*args, **kwargs)\n                    label = _(\"Send to Twitter\")\n                    return mark_safe(rendered + FORMFIELD_HTML % label)\n                return wrapped\n            formfield.widget.render = wrapper(formfield.widget.render)\n        return formfield"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_model(self, request, obj, form, change):\n        super(TweetableAdminMixin, self).save_model(request, obj, form, change)\n        if Api and request.POST.get(\"send_tweet\", False):\n            auth_settings = get_auth_settings()\n            obj.set_short_url()\n            message = truncatechars(obj, 140 - len(obj.short_url) - 1)\n            api = Api(*auth_settings)\n            api.PostUpdate(\"%s %s\" % (message, obj.short_url))", "response": "Send a tweet with the title and short_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a command and raise an exception upon an error.", "response": "def command(cmd):\n    \"\"\"Execute command and raise an exception upon an error.\n\n      >>> 'README' in command('ls')\n      True\n      >>> command('nonexistingcommand')  #doctest: +ELLIPSIS\n      Traceback (most recent call last):\n      ...\n      SdistCreationError\n\n    \"\"\"\n    status, out = commands.getstatusoutput(cmd)\n    if status is not 0:\n        logger.error(\"Something went wrong:\")\n        logger.error(out)\n        raise SdistCreationError()\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of dictionaries containing the sources of the assessment.", "response": "def sources(\n            self):\n        \"\"\"*The results of the search returned as a python list of dictionaries*\n\n        **Usage:**\n\n            .. code-block:: python\n\n                sources = tns.sources\n        \"\"\"\n        sourceResultsList = []\n        sourceResultsList[:] = [dict(l) for l in self.sourceResultsList]\n        return sourceResultsList"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spectra(\n            self):\n        \"\"\"*The associated source spectral data*\n\n        **Usage:**\n\n            .. code-block:: python \n\n                sourceSpectra = tns.spectra\n        \"\"\"\n        specResultsList = []\n        specResultsList[:] = [dict(l) for l in self.specResultsList]\n        return specResultsList", "response": "Returns a list of dictionaries containing the associated source spectral data for the specified item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef files(\n            self):\n        \"\"\"*The associated source files*\n\n        **Usage:**\n\n            .. code-block:: python \n\n                sourceFiles = tns.files\n        \"\"\"\n        relatedFilesResultsList = []\n        relatedFilesResultsList[:] = [dict(l)\n                                      for l in self.relatedFilesResultsList]\n        return relatedFilesResultsList", "response": "Returns a list of dictionaries containing the related source files for the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of dictionaries containing the photometry associated with the source.", "response": "def photometry(\n            self):\n        \"\"\"*The associated source photometry*\n\n        **Usage:**\n\n            .. code-block:: python \n\n                sourcePhotometry = tns.photometry\n        \"\"\"\n        photResultsList = []\n        photResultsList[:] = [dict(l) for l in self.photResultsList]\n        return photResultsList"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef csv(\n            self,\n            dirPath=None):\n        \"\"\"*Render the results in csv format*\n\n        **Key Arguments:**\n            - ``dirPath`` -- the path to the directory to save the rendered results to. Default *None*\n\n        **Return:**\n            - `csvSources` -- the top-level transient data\n            - `csvPhot` -- all photometry associated with the transients\n            - `csvSpec` -- all spectral data associated with the transients\n            - `csvFiles`  -- all files associated with the matched transients found on the tns\n\n        **Usage:**\n\n            To render the results in csv format:\n\n            .. code-block:: python\n\n                csvSources, csvPhot, csvSpec, csvFiles  = tns.csv()\n                print csvSources\n\n            .. code-block:: text\n\n                TNSId,TNSName,discoveryName,discSurvey,raSex,decSex,raDeg,decDeg,transRedshift,specType,discMag,discMagFilter,discDate,objectUrl,hostName,hostRedshift,separationArcsec,separationNorthArcsec,separationEastArcsec\n                2016asf,SN2016asf,ASASSN-16cs,ASAS-SN,06:50:36.73,+31:06:45.36,102.6530,31.1126,0.021,SN Ia,17.1,V-Johnson,2016-03-06 08:09:36,http://wis-tns.weizmann.ac.il/object/2016asf,KUG 0647+311,,0.66,0.65,-0.13\n\n            You can save the results to file by passing in a directory path within which to save the files to. The four flavours of data (sources, photometry, spectra and files) are saved to separate files but all data can be assoicated with its transient source using the transient's unique `TNSId`.\n\n            .. code-block:: python\n\n                tns.csv(\"~/tns\")\n\n            .. image:: https://i.imgur.com/BwwqMBg.png\n                :width: 800px\n                :alt: csv output\n        \"\"\"\n\n        if dirPath:\n            p = self._file_prefix()\n            csvSources = self.sourceResults.csv(\n                filepath=dirPath + \"/\" + p + \"sources.csv\")\n            csvPhot = self.photResults.csv(\n                filepath=dirPath + \"/\" + p + \"phot.csv\")\n            csvSpec = self.specResults.csv(\n                filepath=dirPath + \"/\" + p + \"spec.csv\")\n            csvFiles = self.relatedFilesResults.csv(\n                filepath=dirPath + \"/\" + p + \"relatedFiles.csv\")\n        else:\n            csvSources = self.sourceResults.csv()\n            csvPhot = self.photResults.csv()\n            csvSpec = self.specResults.csv()\n            csvFiles = self.relatedFilesResults.csv()\n        return csvSources, csvPhot, csvSpec, csvFiles", "response": "Render the results of a single transient in csv format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json(\n            self,\n            dirPath=None):\n        \"\"\"*Render the results in json format*\n\n        **Key Arguments:**\n            - ``dirPath`` -- the path to the directory to save the rendered results to. Default *None*\n\n        **Return:**\n            - `jsonSources` -- the top-level transient data\n            - `jsonPhot` -- all photometry associated with the transients\n            - `jsonSpec` -- all spectral data associated with the transients\n            - `jsonFiles`  -- all files associated with the matched transients found on the tns\n\n        **Usage:**\n\n            To render the results in json format:\n\n            .. code-block:: python\n\n                jsonSources, jsonPhot, jsonSpec, jsonFiles  = tns.json()\n                print jsonSources\n\n            .. code-block:: text\n\n                [\n                    {\n                        \"TNSId\": \"2016asf\",\n                        \"TNSName\": \"SN2016asf\",\n                        \"decDeg\": 31.1126,\n                        \"decSex\": \"+31:06:45.36\",\n                        \"discDate\": \"2016-03-06 08:09:36\",\n                        \"discMag\": \"17.1\",\n                        \"discMagFilter\": \"V-Johnson\",\n                        \"discSurvey\": \"ASAS-SN\",\n                        \"discoveryName\": \"ASASSN-16cs\",\n                        \"hostName\": \"KUG 0647+311\",\n                        \"hostRedshift\": null,\n                        \"objectUrl\": \"http://wis-tns.weizmann.ac.il/object/2016asf\",\n                        \"raDeg\": 102.65304166666667,\n                        \"raSex\": \"06:50:36.73\",\n                        \"separationArcsec\": \"0.66\",\n                        \"separationEastArcsec\": \"-0.13\",\n                        \"separationNorthArcsec\": \"0.65\",\n                        \"specType\": \"SN Ia\",\n                        \"transRedshift\": \"0.021\"\n                    }\n                ]\n\n            You can save the results to file by passing in a directory path within which to save the files to. The four flavours of data (sources, photometry, spectra and files) are saved to separate files but all data can be assoicated with its transient source using the transient's unique `TNSId`.\n\n            .. code-block:: python\n\n                tns.json(\"~/tns\")\n\n            .. image:: https://i.imgur.com/wAHqARI.png\n                :width: 800px\n                :alt: json output\n        \"\"\"\n\n        if dirPath:\n            p = self._file_prefix()\n            jsonSources = self.sourceResults.json(\n                filepath=dirPath + \"/\" + p + \"sources.json\")\n            jsonPhot = self.photResults.json(\n                filepath=dirPath + \"/\" + p + \"phot.json\")\n            jsonSpec = self.specResults.json(\n                filepath=dirPath + \"/\" + p + \"spec.json\")\n            jsonFiles = self.relatedFilesResults.json(\n                filepath=dirPath + \"/\" + p + \"relatedFiles.json\")\n        else:\n            jsonSources = self.sourceResults.json()\n            jsonPhot = self.photResults.json()\n            jsonSpec = self.specResults.json()\n            jsonFiles = self.relatedFilesResults.json()\n        return jsonSources, jsonPhot, jsonSpec, jsonFiles", "response": "Render the results of a single transient exception in json format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef yaml(\n            self,\n            dirPath=None):\n        \"\"\"*Render the results in yaml format*\n\n        **Key Arguments:**\n            - ``dirPath`` -- the path to the directory to save the rendered results to. Default *None*\n\n        **Return:**\n            - `yamlSources` -- the top-level transient data\n            - `yamlPhot` -- all photometry associated with the transients\n            - `yamlSpec` -- all spectral data associated with the transients\n            - `yamlFiles`  -- all files associated with the matched transients found on the tns\n\n        **Usage:**\n\n            To render the results in yaml format:\n\n            .. code-block:: python\n\n                yamlSources, yamlPhot, yamlSpec, yamlFiles  = tns.yaml()\n                print yamlSources\n\n            .. code-block:: text\n\n                - TNSId: 2016asf\n                  TNSName: SN2016asf\n                  decDeg: 31.1126\n                  decSex: '+31:06:45.36'\n                  discDate: '2016-03-06 08:09:36'\n                  discMag: '17.1'\n                  discMagFilter: V-Johnson\n                  discSurvey: ASAS-SN\n                  discoveryName: ASASSN-16cs\n                  hostName: KUG 0647+311\n                  hostRedshift: null\n                  objectUrl: http://wis-tns.weizmann.ac.il/object/2016asf\n                  raDeg: 102.65304166666667\n                  raSex: '06:50:36.73'\n                  separationArcsec: '0.66'\n                  separationEastArcsec: '-0.13'\n                  separationNorthArcsec: '0.65'\n                  specType: SN Ia\n                  transRedshift: '0.021'\n\n            You can save the results to file by passing in a directory path within which to save the files to. The four flavours of data (sources, photometry, spectra and files) are saved to separate files but all data can be assoicated with its transient source using the transient's unique `TNSId`.\n\n            .. code-block:: python\n\n                tns.yaml(\"~/tns\")\n\n            .. image:: https://i.imgur.com/ZpJIC6p.png\n                :width: 800px\n                :alt: yaml output\n        \"\"\"\n\n        if dirPath:\n            p = self._file_prefix()\n            yamlSources = self.sourceResults.yaml(\n                filepath=dirPath + \"/\" + p + \"sources.yaml\")\n            yamlPhot = self.photResults.yaml(\n                filepath=dirPath + \"/\" + p + \"phot.yaml\")\n            yamlSpec = self.specResults.yaml(\n                filepath=dirPath + \"/\" + p + \"spec.yaml\")\n            yamlFiles = self.relatedFilesResults.yaml(\n                filepath=dirPath + \"/\" + p + \"relatedFiles.yaml\")\n        else:\n            yamlSources = self.sourceResults.yaml()\n            yamlPhot = self.photResults.yaml()\n            yamlSpec = self.specResults.yaml()\n            yamlFiles = self.relatedFilesResults.yaml()\n        return yamlSources, yamlPhot, yamlSpec, yamlFiles", "response": "Render the results of a single transient in yaml format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef markdown(\n            self,\n            dirPath=None):\n        \"\"\"*Render the results in markdown format*\n\n        **Key Arguments:**\n            - ``dirPath`` -- the path to the directory to save the rendered results to. Default *None*\n\n        **Return:**\n            - `markdownSources` -- the top-level transient data\n            - `markdownPhot` -- all photometry associated with the transients\n            - `markdownSpec` -- all spectral data associated with the transients\n            - `markdownFiles`  -- all files associated with the matched transients found on the tns\n\n        **Usage:**\n\n            To render the results in markdown table format:\n\n            .. code-block:: python\n\n                markdownSources, markdownPhot, markdownSpec, markdownFiles  = tns.markdown()\n                print markdownSources\n\n            .. code-block:: text\n\n                | TNSId    | TNSName    | discoveryName  | discSurvey  | raSex        | decSex        | raDeg     | decDeg   | transRedshift  | specType  | discMag  | discMagFilter  | discDate             | objectUrl                                     | hostName      | hostRedshift  | separationArcsec  | separationNorthArcsec  | separationEastArcsec  |\n                |:---------|:-----------|:---------------|:------------|:-------------|:--------------|:----------|:---------|:---------------|:----------|:---------|:---------------|:---------------------|:----------------------------------------------|:--------------|:--------------|:------------------|:-----------------------|:----------------------|\n                | 2016asf  | SN2016asf  | ASASSN-16cs    | ASAS-SN     | 06:50:36.73  | +31:06:45.36  | 102.6530  | 31.1126  | 0.021          | SN Ia     | 17.1     | V-Johnson      | 2016-03-06 08:09:36  | http://wis-tns.weizmann.ac.il/object/2016asf  | KUG 0647+311  |               | 0.66              | 0.65                   | -0.13                 |\n\n            You can save the results to file by passing in a directory path within which to save the files to. The four flavours of data (sources, photometry, spectra and files) are saved to separate files but all data can be assoicated with its transient source using the transient's unique `TNSId`.\n\n            .. code-block:: python\n\n                tns.markdown(\"~/tns\")\n\n            .. image:: https://i.imgur.com/AYLBQoJ.png\n                :width: 800px\n                :alt: markdown output\n        \"\"\"\n\n        if dirPath:\n            p = self._file_prefix()\n            markdownSources = self.sourceResults.markdown(\n                filepath=dirPath + \"/\" + p + \"sources.md\")\n            markdownPhot = self.photResults.markdown(\n                filepath=dirPath + \"/\" + p + \"phot.md\")\n            markdownSpec = self.specResults.markdown(\n                filepath=dirPath + \"/\" + p + \"spec.md\")\n            markdownFiles = self.relatedFilesResults.markdown(\n                filepath=dirPath + \"/\" + p + \"relatedFiles.md\")\n        else:\n            markdownSources = self.sourceResults.markdown()\n            markdownPhot = self.photResults.markdown()\n            markdownSpec = self.specResults.markdown()\n            markdownFiles = self.relatedFilesResults.markdown()\n        return markdownSources, markdownPhot, markdownSpec, markdownFiles", "response": "Render the results of a single transient object in markdown format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef table(\n            self,\n            dirPath=None):\n        \"\"\"*Render the results as an ascii table*\n\n        **Key Arguments:**\n            - ``dirPath`` -- the path to the directory to save the rendered results to. Default *None*\n\n        **Return:**\n            - `tableSources` -- the top-level transient data\n            - `tablePhot` -- all photometry associated with the transients\n            - `tableSpec` -- all spectral data associated with the transients\n            - `tableFiles`  -- all files associated with the matched transients found on the tns\n\n        **Usage:**\n\n            To render the results in ascii table format:\n\n            .. code-block:: python\n\n                tableSources, tablePhot, tableSpec, tableFiles  = tns.table()\n                print tableSources\n\n            .. code-block:: text\n\n                +----------+------------+----------------+-------------+--------------+---------------+-----------+----------+----------------+-----------+----------+----------------+----------------------+-----------------------------------------------+---------------+---------------+-------------------+------------------------+-----------------------+\n                | TNSId    | TNSName    | discoveryName  | discSurvey  | raSex        | decSex        | raDeg     | decDeg   | transRedshift  | specType  | discMag  | discMagFilter  | discDate             | objectUrl                                     | hostName      | hostRedshift  | separationArcsec  | separationNorthArcsec  | separationEastArcsec  |\n                +----------+------------+----------------+-------------+--------------+---------------+-----------+----------+----------------+-----------+----------+----------------+----------------------+-----------------------------------------------+---------------+---------------+-------------------+------------------------+-----------------------+\n                | 2016asf  | SN2016asf  | ASASSN-16cs    | ASAS-SN     | 06:50:36.73  | +31:06:45.36  | 102.6530  | 31.1126  | 0.021          | SN Ia     | 17.1     | V-Johnson      | 2016-03-06 08:09:36  | http://wis-tns.weizmann.ac.il/object/2016asf  | KUG 0647+311  |               | 0.66              | 0.65                   | -0.13                 |\n                +----------+------------+----------------+-------------+--------------+---------------+-----------+----------+----------------+-----------+----------+----------------+----------------------+-----------------------------------------------+---------------+---------------+-------------------+------------------------+-----------------------+\n\n            You can save the results to file by passing in a directory path within which to save the files to. The four flavours of data (sources, photometry, spectra and files) are saved to separate files but all data can be assoicated with its transient source using the transient's unique `TNSId`.\n\n            .. code-block:: python\n\n                tns.table(\"~/tns\")\n\n            .. image:: https://i.imgur.com/m09M0ho.png\n                :width: 800px\n                :alt: ascii files\n        \"\"\"\n\n        if dirPath:\n            p = self._file_prefix()\n            tableSources = self.sourceResults.table(\n                filepath=dirPath + \"/\" + p + \"sources.ascii\")\n            tablePhot = self.photResults.table(\n                filepath=dirPath + \"/\" + p + \"phot.ascii\")\n            tableSpec = self.specResults.table(\n                filepath=dirPath + \"/\" + p + \"spec.ascii\")\n            tableFiles = self.relatedFilesResults.table(\n                filepath=dirPath + \"/\" + p + \"relatedFiles.ascii\")\n        else:\n            tableSources = self.sourceResults.table()\n            tablePhot = self.photResults.table()\n            tableSpec = self.specResults.table()\n            tableFiles = self.relatedFilesResults.table()\n        return tableSources, tablePhot, tableSpec, tableFiles", "response": "Render the results of a single transient object in an ascii table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender the results of the TNS get_transient_transients method on the TNS database.", "response": "def mysql(\n            self,\n            tableNamePrefix=\"TNS\",\n            dirPath=None):\n        \"\"\"*Render the results as MySQL Insert statements*\n\n        **Key Arguments:**\n            - ``tableNamePrefix`` -- the prefix for the database table names to assign the insert statements to. Default *TNS*.\n            - ``dirPath`` -- the path to the directory to save the rendered results to. Default *None*\n\n        **Return:**\n            - `mysqlSources` -- the top-level transient data\n            - `mysqlPhot` -- all photometry associated with the transients\n            - `mysqlSpec` -- all spectral data associated with the transients\n            - `mysqlFiles`  -- all files associated with the matched transients found on the tns\n\n        **Usage:**\n\n            To render the results in mysql insert format:\n\n            .. code-block:: python\n\n                mysqlSources, mysqlPhot, mysqlSpec, mysqlFiles  = tns.mysql(\"TNS\")\n                print mysqlSources\n\n            .. code-block:: text\n\n                INSERT INTO `TNS_sources` (TNSId,TNSName,dateCreated,decDeg,decSex,discDate,discMag,discMagFilter,discSurvey,discoveryName,hostName,hostRedshift,objectUrl,raDeg,raSex,separationArcsec,separationEastArcsec,separationNorthArcsec,specType,transRedshift) VALUES (\"2016asf\" ,\"SN2016asf\" ,\"2016-09-20T11:22:13\" ,\"31.1126\" ,\"+31:06:45.36\" ,\"2016-03-06 08:09:36\" ,\"17.1\" ,\"V-Johnson\" ,\"ASAS-SN\" ,\"ASASSN-16cs\" ,\"KUG 0647+311\" ,null ,\"http://wis-tns.weizmann.ac.il/object/2016asf\" ,\"102.653041667\" ,\"06:50:36.73\" ,\"0.66\" ,\"-0.13\" ,\"0.65\" ,\"SN Ia\" ,\"0.021\")  ON DUPLICATE KEY UPDATE  TNSId=\"2016asf\", TNSName=\"SN2016asf\", dateCreated=\"2016-09-20T11:22:13\", decDeg=\"31.1126\", decSex=\"+31:06:45.36\", discDate=\"2016-03-06 08:09:36\", discMag=\"17.1\", discMagFilter=\"V-Johnson\", discSurvey=\"ASAS-SN\", discoveryName=\"ASASSN-16cs\", hostName=\"KUG 0647+311\", hostRedshift=null, objectUrl=\"http://wis-tns.weizmann.ac.il/object/2016asf\", raDeg=\"102.653041667\", raSex=\"06:50:36.73\", separationArcsec=\"0.66\", separationEastArcsec=\"-0.13\", separationNorthArcsec=\"0.65\", specType=\"SN Ia\", transRedshift=\"0.021\", updated=1, dateLastModified=NOW() ;\n\n            You can save the results to file by passing in a directory path within which to save the files to. The four flavours of data (sources, photometry, spectra and files) are saved to separate files but all data can be assoicated with its transient source using the transient's unique `TNSId`.\n\n            .. code-block:: python\n\n                tns.mysql(\"TNS\", \"~/tns\")\n\n            .. image:: https://i.imgur.com/CozySPW.png\n                :width: 800px\n                :alt: mysql output\n        \"\"\"\n        if dirPath:\n            p = self._file_prefix()\n\n            createStatement = \"\"\"\nCREATE TABLE `%(tableNamePrefix)s_sources` (\n  `primaryId` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'An internal counter',\n  `TNSId` varchar(20) NOT NULL,\n  `TNSName` varchar(20) DEFAULT NULL,\n  `dateCreated` datetime DEFAULT NULL,\n  `decDeg` double DEFAULT NULL,\n  `decSex` varchar(45) DEFAULT NULL,\n  `discDate` datetime DEFAULT NULL,\n  `discMag` double DEFAULT NULL,\n  `discMagFilter` varchar(45) DEFAULT NULL,\n  `discSurvey` varchar(100) DEFAULT NULL,\n  `discoveryName` varchar(100) DEFAULT NULL,\n  `objectUrl` varchar(200) DEFAULT NULL,\n  `raDeg` double DEFAULT NULL,\n  `raSex` varchar(45) DEFAULT NULL,\n  `specType` varchar(100) DEFAULT NULL,\n  `transRedshift` double DEFAULT NULL,\n  `updated` tinyint(4) DEFAULT '0',\n  `dateLastModified` datetime DEFAULT NULL,\n  `hostName` VARCHAR(100) NULL DEFAULT NULL,\n  `hostRedshift` DOUBLE NULL DEFAULT NULL, \n  `survey` VARCHAR(100) NULL DEFAULT NULL,\n  PRIMARY KEY (`primaryId`),\n  UNIQUE KEY `tnsid` (`TNSId`)\n) ENGINE=MyISAM AUTO_INCREMENT=0 DEFAULT CHARSET=latin1;\n            \"\"\" % locals()\n\n            mysqlSources = self.sourceResults.mysql(\n                tableNamePrefix + \"_sources\", filepath=dirPath + \"/\" + p + \"sources.sql\", createStatement=createStatement)\n\n            createStatement = \"\"\"\nCREATE TABLE `%(tableNamePrefix)s_photometry` (\n  `primaryId` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'An internal counter',\n  `TNSId` varchar(20) NOT NULL,\n  `dateCreated` datetime DEFAULT CURRENT_TIMESTAMP,\n  `exptime` double DEFAULT NULL,\n  `filter` varchar(100) DEFAULT NULL,\n  `limitingMag` tinyint(4) DEFAULT NULL,\n  `mag` double DEFAULT NULL,\n  `magErr` double DEFAULT NULL,\n  `magUnit` varchar(100) DEFAULT NULL,\n  `objectName` varchar(100) DEFAULT NULL,\n  `obsdate` datetime DEFAULT NULL,\n  `reportAddedDate` datetime DEFAULT NULL,\n  `suggestedType` varchar(100) DEFAULT NULL,\n  `survey` varchar(100) DEFAULT NULL,\n  `telescope` varchar(100) DEFAULT NULL,\n  `updated` tinyint(4) DEFAULT '0',\n  `dateLastModified` datetime DEFAULT NULL,\n  `remarks` VARCHAR(800) NULL DEFAULT NULL,\n  `sourceComment` VARCHAR(800) NULL DEFAULT NULL,\n  PRIMARY KEY (`primaryId`),\n  UNIQUE KEY `tnsid_survey_obsdate` (`TNSId`,`survey`,`obsdate`),\n  UNIQUE INDEX `u_tnsid_survey_obsdate` (`TNSId` ASC, `survey` ASC, `obsdate` ASC),\n  UNIQUE INDEX `u_tnsid_obsdate_objname` (`TNSId` ASC, `obsdate` ASC, `objectName` ASC)\n) ENGINE=MyISAM AUTO_INCREMENT=0 DEFAULT CHARSET=latin1;\n            \"\"\" % locals()\n\n            mysqlPhot = self.photResults.mysql(\n                tableNamePrefix + \"_photometry\", filepath=dirPath + \"/\" + p + \"phot.sql\", createStatement=createStatement)\n\n            createStatement = \"\"\"\nCREATE TABLE `%(tableNamePrefix)s_spectra` (\n  `primaryId` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'An internal counter',\n  `TNSId` varchar(45) NOT NULL,\n  `TNSuser` varchar(45) DEFAULT NULL,\n  `dateCreated` datetime DEFAULT CURRENT_TIMESTAMP,\n  `exptime` double DEFAULT NULL,\n  `obsdate` datetime DEFAULT NULL,\n  `reportAddedDate` datetime DEFAULT NULL,\n  `specType` varchar(100) DEFAULT NULL,\n  `survey` varchar(100) DEFAULT NULL,\n  `telescope` varchar(100) DEFAULT NULL,\n  `transRedshift` double DEFAULT NULL,\n  `updated` tinyint(4) DEFAULT '0',\n  `dateLastModified` datetime DEFAULT NULL,\n  `remarks` VARCHAR(800) NULL DEFAULT NULL,\n  `sourceComment` VARCHAR(800) NULL DEFAULT NULL,\n  PRIMARY KEY (`primaryId`),\n  UNIQUE KEY `u_tnsid_survey_obsdate` (`TNSId`,`survey`,`obsdate`),\n  UNIQUE KEY `u_id_user_obsdate` (`TNSId`,`TNSuser`,`obsdate`)\n) ENGINE=MyISAM AUTO_INCREMENT=0 DEFAULT CHARSET=latin1;\n            \"\"\" % locals()\n\n            mysqlSpec = self.specResults.mysql(\n                tableNamePrefix + \"_spectra\", filepath=dirPath + \"/\" + p + \"spec.sql\", createStatement=createStatement)\n\n            createStatement = \"\"\"\nCREATE TABLE `%(tableNamePrefix)s_files` (\n  `primaryId` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'An internal counter',\n  `TNSId` varchar(100) NOT NULL,\n  `dateCreated` datetime DEFAULT CURRENT_TIMESTAMP,\n  `dateObs` datetime DEFAULT NULL,\n  `filename` varchar(200) DEFAULT NULL,\n  `spec1phot2` tinyint(4) DEFAULT NULL,\n  `url` varchar(800) DEFAULT NULL,\n  `updated` tinyint(4) DEFAULT '0',\n  `dateLastModified` datetime DEFAULT NULL,\n  `comment` VARCHAR(800) NULL DEFAULT NULL,\n  PRIMARY KEY (`primaryId`),\n  UNIQUE KEY `tnsid_url` (`TNSId`,`url`)\n) ENGINE=MyISAM AUTO_INCREMENT=0 DEFAULT CHARSET=latin1;\n            \"\"\" % locals()\n\n            mysqlFiles = self.relatedFilesResults.mysql(\n                tableNamePrefix + \"_files\", filepath=dirPath + \"/\" + p + \"relatedFiles.sql\", createStatement=createStatement)\n        else:\n            mysqlSources = self.sourceResults.mysql(\n                tableNamePrefix + \"_sources\")\n            mysqlPhot = self.photResults.mysql(tableNamePrefix + \"_photometry\")\n            mysqlSpec = self.specResults.mysql(tableNamePrefix + \"_spectra\")\n            mysqlFiles = self.relatedFilesResults.mysql(\n                tableNamePrefix + \"_files\")\n        return mysqlSources, mysqlPhot, mysqlSpec, mysqlFiles"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _query_tns(self):\n        self.log.info('starting the ``get`` method')\n\n        sourceTable = []\n        photoTable = []\n        specTable = []\n        relatedFilesTable = []\n\n        # THIS stop IS TO KEEP TRACK OF THE TNS PAGINATION IF MANY RESULT PAGES\n        # ARE RETURNED\n        stop = False\n\n        sourceCount = 0\n        while not stop:\n\n            status_code, content, self._searchURL = self._get_tns_search_results()\n            if status_code != 200:\n                self.log.error(\n                    'cound not get the search reuslts from the TNS, HTML error code %(status_code)s ' % locals())\n                return None\n\n            if \"No results found\" in content:\n                print \"No results found\"\n                return sourceTable, photoTable, specTable, relatedFilesTable\n\n            if self._parse_transient_rows(content, True) < self.batchSize:\n                stop = True\n            else:\n                self.page += 1\n                thisPage = self.page\n                print \"Downloaded %(thisPage)s page(s) from the TNS. %(sourceCount)s transients parsed so far.\" % locals()\n                sourceCount += self.batchSize\n                print \"\\t\" + self._searchURL\n\n                timesleep.sleep(1)\n\n            # PARSE ALL ROWS RETURNED\n            for transientRow in self._parse_transient_rows(content):\n\n                # TOP LEVEL DISCOVERY CONTENT\n                sourceContent = transientRow.group()\n                discInfo, TNSId = self._parse_discovery_information(\n                    sourceContent)\n                sourceTable.append(discInfo)\n\n                # PHOTOMETERY\n                phot, relatedFiles = self._parse_photometry_data(\n                    sourceContent, TNSId)\n                photoTable += phot\n                relatedFilesTable += relatedFiles\n\n                # SPECTRA\n                spec, relatedFiles = self._parse_spectral_data(\n                    sourceContent, TNSId)\n                specTable += spec\n                relatedFilesTable += relatedFiles\n\n        # SORT BY SEPARATION FROM THE SEARCH COORDINATES\n        try:\n            sourceTable = sorted(sourceTable, key=itemgetter(\n                'separationArcsec'), reverse=False)\n        except:\n            pass\n\n        self.log.info('completed the ``get`` method')\n        return sourceTable, photoTable, specTable, relatedFilesTable", "response": "This method is called by the _get_tns_search_results method in order to get the TNS from the server and parse the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_tns_search_results(\n            self):\n        \"\"\"\n        *query the tns and result the response*\n        \"\"\"\n        self.log.info('starting the ``_get_tns_search_results`` method')\n\n        try:\n            response = requests.get(\n                url=\"http://wis-tns.weizmann.ac.il/search\",\n                params={\n                    \"page\": self.page,\n                    \"ra\": self.ra,\n                    \"decl\": self.dec,\n                    \"radius\": self.radiusArcsec,\n                    \"name\": self.name,\n                    \"internal_name\": self.internal_name,\n                    \"date_start[date]\": self.start,\n                    \"date_end[date]\": self.end,\n                    \"num_page\": self.batchSize,\n                    \"display[redshift]\": \"1\",\n                    \"display[hostname]\": \"1\",\n                    \"display[host_redshift]\": \"1\",\n                    \"display[source_group_name]\": \"1\",\n                    \"display[internal_name]\": \"1\",\n                    \"display[spectra_count]\": \"1\",\n                    \"display[discoverymag]\": \"1\",\n                    \"display[discmagfilter]\": \"1\",\n                    \"display[discoverydate]\": \"1\",\n                    \"display[discoverer]\": \"1\",\n                    \"display[sources]\": \"1\",\n                    \"display[bibcode]\": \"1\",\n                },\n            )\n\n        except requests.exceptions.RequestException:\n            print('HTTP Request failed')\n\n        self.log.info('completed the ``_get_tns_search_results`` method')\n        return response.status_code, response.content, response.url", "response": "query the tns and result the response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a file prefix based on the type of search for saving files to disk", "response": "def _file_prefix(\n            self):\n        \"\"\"*Generate a file prefix based on the type of search for saving files to disk*\n\n        **Return:**\n            - ``prefix`` -- the file prefix\n        \"\"\"\n        self.log.info('starting the ``_file_prefix`` method')\n\n        if self.ra:\n            now = datetime.now()\n            prefix = now.strftime(\"%Y%m%dt%H%M%S%f_tns_conesearch_\")\n        elif self.name:\n            prefix = self.name + \"_tns_conesearch_\"\n        elif self.internal_name:\n            prefix = self.internal_name + \"_tns_conesearch_\"\n        elif self.discInLastDays:\n            discInLastDays = str(self.discInLastDays)\n            now = datetime.now()\n            prefix = now.strftime(\n                discInLastDays + \"d_since_%Y%m%d_tns_conesearch_\")\n\n        self.log.info('completed the ``_file_prefix`` method')\n        return prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_transient_rows(\n            self,\n            content,\n            count=False):\n        \"\"\"* parse transient rows from the TNS result page content*\n\n        **Key Arguments:**\n            - ``content`` -- the content from the TNS results page.\n            - ``count`` -- return only the number of rows\n\n        **Return:**\n            - ``transientRows``\n        \"\"\"\n        self.log.info('starting the ``_parse_transient_rows`` method')\n\n        regexForRow = r\"\"\"\\n([^\\n]*?<a href=\"/object/.*?)(?=\\n[^\\n]*?<a href=\"/object/|<\\!\\-\\- /\\.section, /#content \\-\\->)\"\"\"\n\n        if count:\n            # A SINGLE SOURCE BLOCK\n            matchedSources = re.findall(\n                regexForRow,\n                content,\n                flags=re.S  # re.S\n            )\n            return len(matchedSources)\n\n        # A SINGLE SOURCE BLOCK\n        matchedSources = re.finditer(\n            regexForRow,\n            content,\n            flags=re.S  # re.S\n        )\n\n        self.log.info('completed the ``_parse_transient_rows`` method')\n        return matchedSources", "response": "Parse the transient rows from the TNS result page content and return the list of matched sources"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_discovery_information(\n            self,\n            content):\n        \"\"\"* parse discovery information from one row on the TNS results page*\n\n        **Key Arguments:**\n            - ``content`` -- a table row from the TNS results page.\n\n        **Return:**\n            - ``discoveryData`` -- dictionary of results\n            - ``TNSId`` -- the unique TNS id for the transient\n        \"\"\"\n        self.log.info('starting the ``_parse_discovery_information`` method')\n\n        # ASTROCALC UNIT CONVERTER OBJECT\n        converter = unit_conversion(\n            log=self.log\n        )\n\n        matches = re.finditer(\n            r\"\"\"<tr class=\"row-.*?\"><td class=\"cell-id\">(?P<tnsId>\\d*?)</td><td class=\"cell-name\"><a href=\"(?P<objectUrl>.*?)\">(?P<TNSName>.*?)</a></td><td class=\"cell-.*?<td class=\"cell-ra\">(?P<raSex>.*?)</td><td class=\"cell-decl\">(?P<decSex>.*?)</td><td class=\"cell-ot_name\">(?P<specType>.*?)</td><td class=\"cell-redshift\">(?P<transRedshift>.*?)</td><td class=\"cell-hostname\">(?P<hostName>.*?)</td><td class=\"cell-host_redshift\">(?P<hostRedshift>.*?)</td><td class=\"cell-source_group_name\">(?P<discSurvey>.*?)</td>.*?<td class=\"cell-internal_name\">(<a.*?>)?(?P<discoveryName>.*?)(</a>)?</td>.*?<td class=\"cell-discoverymag\">(?P<discMag>.*?)</td><td class=\"cell-disc_filter_name\">(?P<discMagFilter>.*?)</td><td class=\"cell-discoverydate\">(?P<discDate>.*?)</td><td class=\"cell-discoverer\">(?P<sender>.*?)</td>.*?</tr>\"\"\",\n            content,\n            flags=0  # re.S\n        )\n        discoveryData = []\n        for match in matches:\n            row = match.groupdict()\n            for k, v in row.iteritems():\n                row[k] = v.strip()\n                if len(v) == 0:\n                    row[k] = None\n            if row[\"transRedshift\"] == 0:\n                row[\"transRedshift\"] = None\n            if row[\"TNSName\"][0] in [\"1\", \"2\"]:\n                row[\"TNSName\"] = \"SN\" + row[\"TNSName\"]\n            row[\"objectUrl\"] = \"http://wis-tns.weizmann.ac.il\" + \\\n                row[\"objectUrl\"]\n\n            # CONVERT COORDINATES TO DECIMAL DEGREES\n            row[\"raDeg\"] = converter.ra_sexegesimal_to_decimal(\n                ra=row[\"raSex\"]\n            )\n            row[\"decDeg\"] = converter.dec_sexegesimal_to_decimal(\n                dec=row[\"decSex\"]\n            )\n\n            # IF THIS IS A COORDINATE SEARCH, ADD SEPARATION FROM\n            # ORIGINAL QUERY COORDINATES\n            if self.ra:\n                # CALCULATE SEPARATION IN ARCSEC\n                from astrocalc.coords import separations\n                calculator = separations(\n                    log=self.log,\n                    ra1=self.ra,\n                    dec1=self.dec,\n                    ra2=row[\"raDeg\"],\n                    dec2=row[\"decDeg\"],\n                )\n                angularSeparation, north, east = calculator.get()\n                row[\"separationArcsec\"] = angularSeparation\n                row[\"separationNorthArcsec\"] = north\n                row[\"separationEastArcsec\"] = east\n\n            if not row[\"discSurvey\"]:\n                row[\"survey\"] = row[\"sender\"]\n\n            del row[\"sender\"]\n            del row[\"tnsId\"]\n            row[\"TNSName\"] = row[\"TNSName\"].replace(\" \", \"\")\n            row[\"TNSId\"] = row[\"TNSName\"].replace(\n                \"SN\", \"\").replace(\"AT\", \"\")\n            TNSId = row[\"TNSId\"]\n\n            # ORDER THE DICTIONARY FOR THIS ROW OF RESULTS\n            orow = collections.OrderedDict()\n            keyOrder = [\"TNSId\", \"TNSName\", \"discoveryName\", \"discSurvey\", \"raSex\", \"decSex\", \"raDeg\", \"decDeg\",\n                        \"transRedshift\", \"specType\", \"discMag\", \"discMagFilter\", \"discDate\", \"objectUrl\", \"hostName\", \"hostRedshift\", \"separationArcsec\", \"separationNorthArcsec\", \"separationEastArcsec\"]\n            for k, v in row.iteritems():\n                if k not in keyOrder:\n                    keyOrder.append(k)\n            for k in keyOrder:\n                try:\n                    orow[k] = row[k]\n                except:\n                    self.log.info(\n                        \"`%(k)s` not found in the source data for %(TNSId)s\" % locals())\n                    pass\n            discoveryData.append(row)\n\n        self.log.info('completed the ``_parse_discovery_information`` method')\n        return discoveryData[0], TNSId", "response": "Parse the discovery information from one row on the TNS results page and return a dictionary of discovery information."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_photometry_data(\n            self,\n            content,\n            TNSId):\n        \"\"\"*parse photometry data from a row in the tns results content*\n\n        **Key Arguments:**\n             - ``content`` -- a table row from the TNS results page\n             - ``TNSId`` -- the tns id of the transient\n\n        **Return:**\n            - ``photData`` -- a list of dictionaries of the photometry data\n            - ``relatedFilesTable`` -- a list of dictionaries of transient photometry related files \n        \"\"\"\n        self.log.info('starting the ``_parse_photometry_data`` method')\n\n        photData = []\n        relatedFilesTable = []\n\n        # AT REPORT BLOCK\n        ATBlock = re.search(\n            r\"\"\"<tr class=[^\\n]*?AT reportings.*?(?=<tr class=[^\\n]*?Classification reportings|$)\"\"\",\n            content,\n            flags=re.S  # re.S\n        )\n\n        if ATBlock:\n            ATBlock = ATBlock.group()\n            reports = re.finditer(\n                r\"\"\"<tr class=\"row-[^\"]*\"><td class=\"cell-id\">.*?</table>\"\"\",\n                ATBlock,\n                flags=re.S  # re.S\n            )\n\n            relatedFiles = self._parse_related_files(ATBlock)\n\n            for r in reports:\n                header = re.search(\n                    r\"\"\"<tr class=\"row[^\"]*\".*?time_received\">(?P<reportAddedDate>[^<]*).*?user_name\">(?P<sender>[^<]*).*?reporter_name\">(?P<reporters>[^<]*).*?source_group_name\">(?P<surveyGroup>[^<]*).*?ra\">(?P<ra>[^<]*).*?decl\">(?P<dec>[^<]*).*?discovery_date\">(?P<obsDate>[^<]*).*?flux\">(?P<mag>[^<]*).*?filter_name\">(?P<magFilter>[^<]*).*?related_files\">(?P<relatedFiles>[^<]*).*?type_name\">(?P<suggestedType>[^<]*).*?hostname\">(?P<hostName>[^<]*).*?host_redshift\">(?P<hostRedshift>[^<]*).*?internal_name\">(?P<objectName>[^<]*).*?groups\">(?P<survey>[^<]*).*?remarks\">(?P<sourceComment>[^<]*)\"\"\",\n                    r.group(),\n                    flags=0  # re.S\n                )\n                try:\n                    header = header.groupdict()\n                except:\n                    print r.group()\n                header[\"TNSId\"] = TNSId\n\n                del header[\"reporters\"]\n                del header[\"surveyGroup\"]\n                del header[\"hostName\"]\n                del header[\"hostRedshift\"]\n                del header[\"mag\"]\n                del header[\"magFilter\"]\n                del header[\"obsDate\"]\n                del header[\"ra\"]\n                del header[\"dec\"]\n\n                if not self.comments:\n                    del header['sourceComment']\n                else:\n                    theseComments = header[\n                        \"sourceComment\"].split(\"\\n\")\n                    header[\"sourceComment\"] = \"\"\n                    for c in theseComments:\n                        header[\"sourceComment\"] += \" \" + c.strip()\n                    header[\"sourceComment\"] = header[\n                        \"sourceComment\"].strip().replace('\"', \"'\")[0:750]\n\n                phot = re.finditer(\n                    r\"\"\"<tr class=\"row\\-[^\"]*\".*?obsdate\">(?P<obsdate>[^<]*).*?flux\">(?P<mag>[^<]*).*?fluxerr\">(?P<magErr>[^<]*).*?limflux\">(?P<limitingMag>[^<]*).*?unit_name\">(?P<magUnit>[^<]*).*?filter_name\">(?P<filter>[^<]*).*?tel_inst\">(?P<telescope>[^<]*).*?exptime\">(?P<exptime>[^<]*).*?observer\">(?P<observer>[^<]*).*?-remarks\">(?P<remarks>[^<]*)\"\"\",\n                    r.group(),\n                    flags=0  # re.S\n                )\n                filesAppended = False\n                for p in phot:\n                    p = p.groupdict()\n                    del p[\"observer\"]\n\n                    if p[\"limitingMag\"] and not p[\"mag\"]:\n                        p[\"mag\"] = p[\"limitingMag\"]\n                        p[\"limitingMag\"] = 1\n                        p[\"remarks\"] = p[\"remarks\"].replace(\n                            \"[Last non detection]\", \"\")\n                    else:\n                        p[\"limitingMag\"] = 0\n\n                    if not self.comments:\n                        del p[\"remarks\"]\n\n                    p.update(header)\n\n                    if p[\"relatedFiles\"] and filesAppended == False:\n                        filesAppended = True\n                        for f in relatedFiles:\n                            # ORDER THE DICTIONARY FOR THIS ROW OF\n                            # RESULTS\n                            thisFile = collections.OrderedDict()\n                            thisFile[\"TNSId\"] = TNSId\n                            thisFile[\"filename\"] = f[\n                                \"filepath\"].split(\"/\")[-1]\n                            thisFile[\"url\"] = f[\"filepath\"]\n                            if self.comments:\n                                thisFile[\"comment\"] = f[\n                                    \"fileComment\"].replace(\"\\n\", \" \").strip().replace('\"', \"'\")[0:750]\n                            thisFile[\"dateObs\"] = p[\"obsdate\"]\n                            thisFile[\"spec1phot2\"] = 2\n                            relatedFilesTable.append(thisFile)\n\n                    if not p[\"survey\"] and not p[\"objectName\"]:\n                        p[\"survey\"] = p[\"sender\"]\n\n                    del p[\"relatedFiles\"]\n                    del p[\"sender\"]\n\n                    # ORDER THE DICTIONARY FOR THIS ROW OF RESULTS\n                    orow = collections.OrderedDict()\n                    keyOrder = [\"TNSId\", \"survey\", \"obsdate\", \"filter\", \"limitingMag\", \"mag\", \"magErr\",\n                                \"magUnit\", \"suggestedType\", \"telescope\", \"exptime\", \"reportAddedDate\"]\n                    for k, v in p.iteritems():\n                        if k not in keyOrder:\n                            keyOrder.append(k)\n                    for k in keyOrder:\n                        try:\n                            orow[k] = p[k]\n                        except:\n                            self.log.info(\n                                \"`%(k)s` not found in the source data for %(TNSId)s\" % locals())\n                            pass\n\n                    photData.append(orow)\n\n        self.log.info('completed the ``_parse_photometry_data`` method')\n        return photData, relatedFilesTable", "response": "parse photometry data from a table row in the TNS results page"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the contents of the content for related files and return a list of dictionaries of transient related files", "response": "def _parse_related_files(\n            self,\n            content):\n        \"\"\"*parse the contents for related files URLs and comments*\n\n        **Key Arguments:**\n            - ``content`` -- the content to parse.\n\n        **Return:**\n            - ``relatedFiles`` -- a list of dictionaries of transient related files \n        \"\"\"\n        self.log.info('starting the ``_parse_related_files`` method')\n\n        relatedFilesList = re.finditer(\n            r\"\"\"<td class=\"cell-filename\">.*?href=\"(?P<filepath>[^\"]*).*?remarks\">(?P<fileComment>[^<]*)\"\"\",\n            content,\n            flags=0  # re.S\n        )\n\n        relatedFiles = []\n        for f in relatedFilesList:\n            f = f.groupdict()\n            relatedFiles.append(f)\n\n        self.log.info('completed the ``_parse_related_files`` method')\n        return relatedFiles"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the spectral data from a table row in the TNS results page", "response": "def _parse_spectral_data(\n            self,\n            content,\n            TNSId):\n        \"\"\"*parse spectra data from a row in the tns results content*\n\n        **Key Arguments:**\n             - ``content`` -- a table row from the TNS results page\n             - ``TNSId`` -- the tns id of the transient\n\n        **Return:**\n            - ``specData`` -- a list of dictionaries of the spectral data\n            - ``relatedFilesTable`` -- a list of dictionaries of transient spectrum related files \n        \"\"\"\n        self.log.info('starting the ``_parse_spectral_data`` method')\n\n        specData = []\n        relatedFilesTable = []\n\n        # CLASSIFICATION BLOCK\n        classBlock = re.search(\n            r\"\"\"<tr class=[^\\n]*?Classification reportings.*$\"\"\",\n            content,\n            flags=re.S  # re.S\n        )\n\n        if classBlock:\n            classBlock = classBlock.group()\n\n            reports = re.finditer(\n                r\"\"\"<tr class=\"row-[^\"]*\"><td class=\"cell-id\">.*?</tbody>\\s*</table>\\s*</div></td> </tr>\\s*</tbody>\\s*</table>\\s*</div></td> </tr>\"\"\",\n                classBlock,\n                flags=re.S  #\n            )\n\n            relatedFiles = self._parse_related_files(classBlock)\n\n            for r in reports:\n\n                header = re.search(\n                    r\"\"\"<tr class=\"row.*?time_received\">(?P<reportAddedDate>[^<]*).*?user_name\">(?P<TNSuser>[^<]*).*?classifier_name\">(?P<reporters>[^<]*).*?source_group_name\">(?P<survey>[^<]*).*?-type\">(?P<specType>[^<]*).*?-redshift\">(?P<transRedshift>[^<]*).*?-related_files\">(?P<relatedFiles>[^<]*).*?-groups\">(?P<surveyGroup>[^<]*).*?-remarks\">(?P<sourceComment>[^<]*)</td>\"\"\",\n                    r.group(),\n                    flags=re.S  # re.S\n                )\n                if not header:\n                    continue\n\n                header = header.groupdict()\n                header[\"TNSId\"] = TNSId\n\n                del header[\"reporters\"]\n                del header[\"surveyGroup\"]\n                del header[\"survey\"]\n\n                if not self.comments:\n                    del header['sourceComment']\n                else:\n                    theseComments = header[\n                        \"sourceComment\"].split(\"\\n\")\n                    header[\"sourceComment\"] = \"\"\n                    for c in theseComments:\n                        header[\"sourceComment\"] += \" \" + c.strip()\n                    header[\"sourceComment\"] = header[\n                        \"sourceComment\"].strip().replace('\"', \"'\")[0:750]\n\n                spec = re.finditer(\n                    r\"\"\"<tr class=\"class-results-.*?-obsdate\">(?P<obsdate>[^<]*).*?-tel_inst\">(?P<telescope>[^<]*).*?-exptime\">(?P<exptime>[^<]*).*?-observer\">(?P<sender>[^<]*).*?-reducer\">(?P<reducer>[^<]*).*?-source_group_name\">(?P<survey>[^<]*).*?-asciifile\">(.*?<a href=\"(?P<filepath>[^\"]*)\".*?</a>)?.*?-fitsfile\">(.*?<a href=\"(?P<fitsFilepath>[^\"]*)\".*?</a>)?.*?-groups\">(?P<surveyGroup>[^<]*).*?-remarks\">(?P<remarks>[^<]*)\"\"\",\n                    r.group(),\n                    flags=0  # re.S\n                )\n                filesAppended = False\n                for s in spec:\n                    s = s.groupdict()\n                    del s[\"sender\"]\n                    del s[\"surveyGroup\"]\n                    del s[\"reducer\"]\n\n                    if not self.comments:\n                        del s[\"remarks\"]\n                    else:\n                        s[\"remarks\"] = s[\"remarks\"].replace('\"', \"'\")[0:750]\n\n                    s.update(header)\n\n                    if s[\"relatedFiles\"] and filesAppended == False:\n                        filesAppended = True\n                        for f in relatedFiles:\n                            # ORDER THE DICTIONARY FOR THIS ROW OF\n                            # RESULTS\n                            thisFile = collections.OrderedDict()\n                            thisFile[\"TNSId\"] = TNSId\n                            thisFile[\"filename\"] = f[\n                                \"filepath\"].split(\"/\")[-1]\n                            thisFile[\"url\"] = f[\"filepath\"]\n                            if self.comments:\n                                thisFile[\"comment\"] = f[\n                                    \"fileComment\"].replace(\"\\n\", \" \").strip()\n                            thisFile[\"dateObs\"] = s[\"obsdate\"]\n                            thisFile[\"spec1phot2\"] = 1\n                            relatedFilesTable.append(thisFile)\n\n                    for ffile in [s[\"filepath\"], s[\"fitsFilepath\"]]:\n                        if ffile:\n                            # ORDER THE DICTIONARY FOR THIS ROW OF\n                            # RESULTS\n                            thisFile = collections.OrderedDict()\n                            thisFile[\"TNSId\"] = TNSId\n                            thisFile[\"filename\"] = ffile.split(\n                                \"/\")[-1]\n                            thisFile[\"url\"] = ffile\n                            if self.comments:\n                                thisFile[\"comment\"] = \"\"\n                            thisFile[\"dateObs\"] = s[\"obsdate\"]\n                            thisFile[\"spec1phot2\"] = 1\n                            relatedFilesTable.append(thisFile)\n\n                    del s[\"filepath\"]\n                    del s[\"fitsFilepath\"]\n                    del s[\"relatedFiles\"]\n\n                    # ORDER THE DICTIONARY FOR THIS ROW OF RESULTS\n                    orow = collections.OrderedDict()\n                    keyOrder = [\"TNSId\", \"survey\", \"obsdate\", \"specType\", \"transRedshift\",\n                                \"telescope\", \"exptime\", \"reportAddedDate\", \"TNSuser\"]\n                    for k, v in s.iteritems():\n                        if k not in keyOrder:\n                            keyOrder.append(k)\n                    for k in keyOrder:\n                        try:\n                            orow[k] = s[k]\n                        except:\n                            self.log.info(\n                                \"`%(k)s` not found in the source data for %(TNSId)s\" % locals())\n                            pass\n\n                    specData.append(orow)\n\n        self.log.info('completed the ``_parse_spectral_data`` method')\n        return specData, relatedFilesTable"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tokenize_number(val, line):\n    try:\n        num = int(val)\n        typ = TokenType.int\n    except ValueError:\n        num = float(val)\n        typ = TokenType.float\n\n    return {'type': typ, 'value': num, 'line': line}", "response": "Parse val correctly into int or float."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef till(self):\n        pg = self.usr.getPage(\"http://www.neopets.com/market.phtml?type=till\")\n        \n        try:\n            return pg.find_all(text = \"Shop Till\")[1].parent.next_sibling.b.text.replace(\" NP\", \"\").replace(\",\", \"\")\n        except Exception:\n            logging.getLogger(\"neolib.shop\").exception(\"Could not grab shop till.\", {'pg': pg})\n            raise parseException", "response": "Queries the current shop till and returns the amount\n           \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef grabTill(self, nps):\n        if not int(nps):\n            return False\n            \n        pg = self.usr.getPage(\"http://www.neopets.com/market.phtml?type=till\")\n        form = pg.form(action=\"process_market.phtml\")\n        \n        form['amount'] = str(nps)\n        form.usePin = True\n        pg = form.submit()\n        \n        # If successful redirects to till page\n        if \"You currently have\" in pg.content:\n            return True\n        else:\n            logging.getLogger(\"neolib.shop\").exception(\"Could not grab shop till.\", {'pg': pg})\n            return False", "response": "Returns result\nalid if successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self):\n        pg = self.usr.getPage(\"http://www.neopets.com/market.phtml?type=your\")\n        \n        try:\n            self.name = pg.find_all(text = \"Shop Till\")[1].parent.parent.parent.previous_sibling.previous_sibling.text\n            self.size = pg.find_all(text = \"Shop Till\")[1].parent.parent.parent.previous_sibling.split(\"(size \")[1].replace(\")\", \"\")\n            \n            panel = pg.find(\"img\", {\"name\": \"keeperimage\"}).parent\n            \n            self.keeperName = panel.b.text.split(\" says \")[0]\n            self.keeperMessage = panel.b.text.split(\" says \")[1]\n            self.keeperImg = panel.img['src']\n            self.stock = panel.find_all(\"b\")[1].text\n            self.max = panel.find_all(\"b\")[2].text\n        except Exception:\n            logging.getLogger(\"neolib.shop\").exception(\"Could not parse shop details.\", {'pg': pg})\n            raise parseException\n        \n        self.inventory = UserShopBackInventory(self.usr, pg)\n        self.forms = self.inventory.forms", "response": "Loads the shop details and current inventory from the user s page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadHistory(self):\n        pg = self.usr.getPage(\"http://www.neopets.com/market.phtml?type=sales\")\\\n        \n        try:\n            rows = pg.find(\"b\", text = \"Date\").parent.parent.parent.find_all(\"tr\")\n            \n            # First and last row do not contain entries\n            rows.pop(0)\n            rows.pop(-1)\n            \n            self.history = []\n            for row in rows:\n                parts = row.find_all(\"td\")\n                dets = {}\n                \n                dets['date'] = parts[0].text\n                dets['item'] = parts[1].text\n                dets['buyer'] = parts[2].text\n                dets['price'] = parts[3].text\n                \n                self.history.append(dets)\n                \n            # Reverse the list to put it in order by date\n            self.history.reverse()\n        except Exception:\n            logging.getLogger(\"neolib.shop\").exception(\"Could not parse sales history.\", {'pg': pg})\n            raise parseException", "response": "Loads the shop sale history into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a string config value", "response": "def _get_config(self, section: str, key: str, fallback: str=object()) -> str:\n        \"\"\"\n        Gets a string config value\n        :param section: Section\n        :param key: Key\n        :param fallback: Optional fallback value\n        \"\"\"\n        return self._config.get(section, key, fallback=fallback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a float config value", "response": "def _get_config_float(self, section: str, key: str, fallback: float=object()) -> float:\n        \"\"\"\n        Gets a float config value\n        :param section: Section\n        :param key: Key\n        :param fallback: Optional fallback value\n        \"\"\"\n        return self._config.getfloat(section, key, fallback=fallback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an int config value", "response": "def _get_config_int(self, section: str, key: str, fallback: int=object()) -> int:\n        \"\"\"\n        Gets an int config value\n        :param section: Section\n        :param key: Key\n        :param fallback: Optional fallback value\n        \"\"\"\n        return self._config.getint(section, key, fallback=fallback)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_config_bool(self, section: str, key: str, fallback: bool=object()) -> bool:\n        return self._config.getboolean(section, key, fallback=fallback)", "response": "Gets a boolean config value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, url, data=None, params=None):\n        return self.request(\"get\", url, data, params)", "response": "Low - level GET request interface to mite. Takes a URL and optionally data and optionally params. Returns a dictionary containing the response data and params."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put(self, url, data=None, params=None):\n        return self.request(\"put\", url, data, params)", "response": "Low - level PUT request interface to mite. Takes a URL and optionally data. Either returns\n        the JSON body of the request. Either returns\n        the JSON body of the request. Either returns\n        the response of the request or raises a HttpException."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post(self, url, data=None, params=None):\n        return self.request(\"post\", url, data, params)", "response": "A low - level POST request interface to mite. Takes a URL to request\n        and optionally data to add to the request. Either returns\n        the JSON body of the request or raises a HttpException."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef patch(self, url, data=None, params=None):\n        return self.request(\"patch\", url, data, params)", "response": "Low - level PATCH request interface to mite. Takes a URL to request\n        and optionally data to add to the request. Either returns\n        the JSON body of the request or raises a HttpException."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, url, data=None, params=None):\n        return self.request(\"delete\", url, data, params)", "response": "A low - level DELETE request interface to mite. Takes a URL and optionally data and optionally params. Returns a dictionary containing the response data and the params of the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the daily time entries for a given date.", "response": "def get_daily(self, date=None):\n        \"\"\"\n        Get time entries for a date (defaults to today).\n        \"\"\"\n        if date == None:\n            return self.get(\"/daily.json\")\n        url = \"/daily/{}/{}/{}.json\".format(date.year, date.month, date.day)\n        return self.get(url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new time entry on Mite.", "response": "def create_entry(self, **kwargs):\n        \"\"\"\n        Creates a new time entry on Mite. Takes a data dictionary with the keys\n        `date_at` (a date string in `YYYY-MM-DD` format), `minutes` (an int),\n        `note` (the entry text), `user_id`, `project_id`, `service_id`, and\n        `locked`. All of them are optional.\n        \"\"\"\n        data = self._wrap_dict(\"time_entry\", kwargs)\n\n        return self.post(\"/time_entries.json\", data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edit_entry(self, id_, **kwargs):\n        data = self._wrap_dict(\"time_entry\", kwargs)\n\n        return self.patch(\"/time_entries/{}.json\".format(id_), data)", "response": "Edits a time entry by ID. Takes the same data as create_entry but\n        requires an ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a tracker for the time entry identified by id_.", "response": "def start_tracker(self, id_, **kwargs):\n        \"\"\"\n        Starts a tracker for the time entry identified by `id_`.\n        \"\"\"\n        data = None\n        if kwargs:\n            data = self._wrap_dict(\"tracker\",\n                self._wrap_dict(\"tracking_time_entry\", kwargs))\n        return self.patch(\"/tracker/{}.json\".format(id_), data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a customer with a name.", "response": "def create_customer(self, name, **kwargs):\n        \"\"\"\n        Creates a customer with a name. All other parameters are optional. They\n        are: `note`, `active_hourly_rate`, `hourly_rate`,\n        `hourly_rates_per_service`, and `archived`.\n        \"\"\"\n        data = self._wrap_dict(\"customer\", kwargs)\n        data[\"customer\"][\"name\"] = name\n        return self.post(\"/customers.json\", data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nedits a customer by ID. All fields available at creation can be updated .", "response": "def edit_customer(self, id_, **kwargs):\n        \"\"\"\n        Edits a customer by ID. All fields available at creation can be updated\n        as well. If you want to update hourly rates retroactively, set the\n        argument `update_hourly_rate_on_time_entries` to True.\n        \"\"\"\n        data = self._wrap_dict(\"customer\", kwargs)\n        return self.patch(\"/customers/{}.json\".format(id_), data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new project with a name.", "response": "def create_project(self, name, **kwargs):\n        \"\"\"\n        Creates a project with a name. All other parameters are optional. They\n        are: `note`, `customer_id`, `budget`, `budget_type`, \n        `active_hourly_rate`, `hourly_rate`, `hourly_rates_per_service`, and\n        `archived`.\n        \"\"\"\n        data = self._wrap_dict(\"project\", kwargs)\n        data[\"customer\"][\"name\"] = name\n        return self.post(\"/projects.json\", data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nediting a project by ID. All fields available at creation can be updated .", "response": "def edit_project(self, id_, **kwargs):\n        \"\"\"\n        Edits a project by ID. All fields available at creation can be updated\n        as well. If you want to update hourly rates retroactively, set the\n        argument `update_hourly_rate_on_time_entries` to True.\n        \"\"\"\n        data = self._wrap_dict(\"project\", kwargs)\n        return self.patch(\"/projects/{}.json\".format(id_), data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_service(self, name, **kwargs):\n        data = self._wrap_dict(\"service\", kwargs)\n        data[\"customer\"][\"name\"] = name\n        return self.post(\"/services.json\", data=data)", "response": "Creates a new service with a name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits a service by ID. All fields available at creation can be updated .", "response": "def edit_service(self, id_, **kwargs):\n        \"\"\"\n        Edits a service by ID. All fields available at creation can be updated\n        as well. If you want to update hourly rates retroactively, set the\n        argument `update_hourly_rate_on_time_entries` to True.\n        \"\"\"\n        data = self._wrap_dict(\"service\", kwargs)\n        return self.patch(\"/services/{}.json\".format(id_), data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the list of committed signatures", "response": "def get_committed_signatures(vcs):\n    \"\"\"Get the list of committed signatures\n\n    Args:\n        vcs (easyci.vcs.base.Vcs)\n\n    Returns:\n        list(basestring) - list of signatures\n    \"\"\"\n    committed_path = _get_committed_history_path(vcs)\n    known_signatures = []\n    if os.path.exists(committed_path):\n        with open(committed_path, 'r') as f:\n            known_signatures = f.read().split()\n    return known_signatures"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_staged_signatures(vcs):\n    staged_path = _get_staged_history_path(vcs)\n    known_signatures = []\n    if os.path.exists(staged_path):\n        with open(staged_path, 'r') as f:\n            known_signatures = f.read().split()\n    return known_signatures", "response": "Get the list of staged signatures\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd signature to the list of committed signatures", "response": "def commit_signature(vcs, user_config, signature):\n    \"\"\"Add `signature` to the list of committed signatures\n\n    The signature must already be staged\n\n    Args:\n        vcs (easyci.vcs.base.Vcs)\n        user_config (dict)\n        signature (basestring)\n\n    Raises:\n        NotStagedError\n        AlreadyCommittedError\n    \"\"\"\n    if signature not in get_staged_signatures(vcs):\n        raise NotStagedError\n    evidence_path = _get_committed_history_path(vcs)\n    committed_signatures = get_committed_signatures(vcs)\n    if signature in committed_signatures:\n        raise AlreadyCommittedError\n    committed_signatures.append(signature)\n    string = '\\n'.join(committed_signatures[-user_config['history_limit']:])\n    with open(evidence_path, 'w') as f:\n        f.write(string)\n    unstage_signature(vcs, signature)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd signature to the list of staged signatures", "response": "def stage_signature(vcs, signature):\n    \"\"\"Add `signature` to the list of staged signatures\n\n    Args:\n        vcs (easyci.vcs.base.Vcs)\n        signature (basestring)\n\n    Raises:\n        AlreadyStagedError\n    \"\"\"\n    evidence_path = _get_staged_history_path(vcs)\n    staged = get_staged_signatures(vcs)\n    if signature in staged:\n        raise AlreadyStagedError\n    staged.append(signature)\n    string = '\\n'.join(staged)\n    with open(evidence_path, 'w') as f:\n        f.write(string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unstage_signature(vcs, signature):\n    evidence_path = _get_staged_history_path(vcs)\n    staged = get_staged_signatures(vcs)\n    if signature not in staged:\n        raise NotStagedError\n    staged.remove(signature)\n    string = '\\n'.join(staged)\n    with open(evidence_path, 'w') as f:\n        f.write(string)", "response": "Unstages a signature from the list of staged signatures in the VCS."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear the test run history from this project.", "response": "def clear_history(vcs):\n    \"\"\"Clear (committed) test run history from this project.\n\n    Args:\n        vcs (easyci.vcs.base.Vcs)\n    \"\"\"\n    evidence_path = _get_committed_history_path(vcs)\n    if os.path.exists(evidence_path):\n        os.remove(evidence_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_encrpyted_path(original_path, surfix=default_surfix):\n    p = Path(original_path).absolute()\n    encrypted_p = p.change(new_fname=p.fname + surfix)\n    return encrypted_p.abspath", "response": "Find the output encrypted file path by adding a surfix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_decrpyted_path(encrypted_path, surfix=default_surfix):\n    surfix_reversed = surfix[::-1]\n\n    p = Path(encrypted_path).absolute()\n    fname = p.fname\n    fname_reversed = fname[::-1]\n    new_fname = fname_reversed.replace(surfix_reversed, \"\", 1)[::-1]\n    decrypted_p = p.change(new_fname=new_fname)\n    return decrypted_p.abspath", "response": "Find the original path of encrypted file or dir."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(src, dst, converter,\n              overwrite=False, stream=True, chunksize=1024**2, **kwargs):\n    \"\"\"\n    A file stream transform IO utility function.\n\n    :param src: original file path\n    :param dst: destination file path\n    :param converter: binary content converter function\n    :param overwrite: default False,\n    :param stream: default True, if True, use stream IO mode, chunksize has to\n      be specified.\n    :param chunksize: default 1MB\n    \"\"\"\n    if not overwrite:  # pragma: no cover\n        if Path(dst).exists():\n            raise EnvironmentError(\"'%s' already exists!\" % dst)\n\n    with open(src, \"rb\") as f_input:\n        with open(dst, \"wb\") as f_output:\n            if stream:\n                # fix chunksize to a reasonable range\n                if chunksize > 1024 ** 2 * 10:\n                    chunksize = 1024 ** 2 * 10\n                elif chunksize < 1024 ** 2:\n                    chunksize = 1024 ** 2\n\n                # write file\n                while 1:\n                    content = f_input.read(chunksize)\n                    if content:\n                        f_output.write(converter(content, **kwargs))\n                    else:\n                        break\n            else:  # pragma: no cover\n                f_output.write(converter(f_input.read(), **kwargs))", "response": "This function transforms a file from one file to another."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append(self, tweet):\n        c = self.connection.cursor()\n\n        last_tweet = c.execute(\"SELECT tweet from tweetlist where label='last_tweet'\").next()[0]\n\n        c.execute(\"INSERT INTO tweets(message,  previous_tweet, next_tweet) VALUES (?,?,NULL)\", (tweet, last_tweet))\n        tweet_id = c.lastrowid\n\n        # Set the current tweet as the last tweet\n        c.execute(\"UPDATE tweetlist SET tweet=? WHERE label='last_tweet'\", (tweet_id,))\n\n        # If there was no last_tweet, there was no first_tweet\n        # so make this the first tweet\n        if last_tweet is None:\n            c.execute(\"UPDATE tweetlist SET tweet=? WHERE label='first_tweet'\", (tweet_id,))\n        else:\n            # Update the last tweets reference to this one\n            c.execute(\"UPDATE tweets SET next_tweet = ? WHERE id= ? \", (tweet_id, last_tweet))\n\n        self.connection.commit()\n        c.close()", "response": "Add a tweet to the end of the list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pop(self):\n        c = self.connection.cursor()\n\n        first_tweet_id = c.execute(\"SELECT tweet from tweetlist where label='first_tweet'\").next()[0]\n\n        if first_tweet_id is None:\n            # No tweets are in the list, so return None\n            return None\n\n        tweet = c.execute(\"SELECT id, message, previous_tweet, next_tweet from tweets WHERE id=?\", (first_tweet_id,)).next()\n\n        # Update the first tweet reference\n        c.execute(\"UPDATE tweetlist SET tweet=? WHERE label='first_tweet'\", (tweet[3],))\n\n        # Update the \"next tweet\" if it exists\n        if tweet[3] is not None:\n            c.execute(\"UPDATE tweets SET previous_tweet=NULL WHERE id=?\", (tweet[3],))\n        else:\n            #This was the last tweet so NULL the last tweet reference.\n            c.execute(\"UPDATE tweetlist SET tweet=NULL WHERE label=?\", ('last_tweet',))\n        # Now remove the tweet from the list\n        c.execute(\"DELETE FROM tweets WHERE id=?\", (first_tweet_id,))\n\n        self.connection.commit()\n        c.close()\n\n        return tweet[1]", "response": "Return the first tweet in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npeeks at the first of the list without removing it.", "response": "def peek(self):\n        \"\"\"Peeks at the first of the list without removing it.\"\"\"\n        c = self.connection.cursor()\n        first_tweet_id = c.execute(\"SELECT tweet from tweetlist where label='first_tweet'\").next()[0]\n        if first_tweet_id is None:\n            # No tweets are in the list, so return None\n            return None\n\n        tweet = c.execute(\"SELECT message from tweets WHERE id=?\", (first_tweet_id,)).next()[0]\n\n        c.close()\n        return tweet"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a tweet from the list with the given id", "response": "def delete(self, tweet_id):\n        \"\"\"Deletes a tweet from the list with the given id\"\"\"\n        c = self.connection.cursor()\n\n        try:\n            tweet = c.execute(\"SELECT id, message, previous_tweet, next_tweet from tweets WHERE id=?\", (tweet_id,)).next()\n        except StopIteration:\n            raise ValueError(\"No tweets were found with that ID\")\n\n        # Update linked list references\n        c.execute(\"UPDATE tweets set next_tweet=? WHERE id=?\", (tweet[3], tweet[2]))\n        c.execute(\"UPDATE tweets set previous_tweet=? WHERE id=?\", (tweet[2], tweet[3]))\n\n        if tweet[3] is None:\n            c.execute(\"UPDATE tweetlist SET tweet=? WHERE label='last_tweet'\", (tweet[2],))\n\n        if tweet[2] is None:\n            c.execute(\"UPDATE tweetlist SET tweet=? WHERE label='first_tweet'\", (tweet[3],))\n\n\n        c.execute(\"DELETE from tweets WHERE id=?\", (tweet_id,))\n        self.connection.commit()\n        c.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines current time according to USE_TZ setting.", "response": "def usetz_now():\n    \"\"\"Determine current time depending on USE_TZ setting.\n\n    Affects Django 1.4 and above only. if `USE_TZ = True`, then returns\n    current time according to timezone, else returns current UTC time.\n\n    \"\"\"\n    USE_TZ = getattr(settings, 'USE_TZ', False)\n    if USE_TZ and DJANGO_VERSION >= '1.4':\n        return now()\n    else:\n        return datetime.utcnow()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_delta(self, now, then):\n        if now.__class__ is not then.__class__:\n            now = datetime.date(now.year, now.month, now.day)\n            then = datetime.date(then.year, then.month, then.day)\n        if now < then:\n            raise ValueError(\"Cannot determine moderation rules because date field is set to a value in the future\")\n        return now - then", "response": "Internal helper which will return a datetime. timedelta representing the time between now and then. Assumes that now and then are of the same type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining whether a given comment should be posted on the given object.", "response": "def allow(self, comment, content_object, request):\n        \"\"\"\n        Determine whether a given comment is allowed to be posted on\n        a given object.\n\n        Return ``True`` if the comment should be allowed, ``False\n        otherwise.\n\n        \"\"\"\n        if self.enable_field:\n            if not getattr(content_object, self.enable_field):\n                return False\n        if self.auto_close_field and self.close_after is not None:\n            close_after_date = getattr(content_object, self.auto_close_field)\n            if close_after_date is not None and self._get_delta(timezone.now(), close_after_date).days >= self.close_after:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef moderate(self, comment, content_object, request):\n        if self.auto_moderate_field and self.moderate_after is not None:\n            moderate_after_date = getattr(content_object, self.auto_moderate_field)\n            if moderate_after_date is not None and self._get_delta(timezone.now(), moderate_after_date).days >= self.moderate_after:\n                return True\n        return False", "response": "Determines whether a given comment should be moderated."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef email(self, comment, content_object, request):\n        if not self.email_notification:\n            return\n        recipient_list = [manager_tuple[1] for manager_tuple in settings.MANAGERS]\n        t = loader.get_template('comments/comment_notification_email.txt')\n        c = Context({ 'comment': comment,\n                      'content_object': content_object })\n        subject = '[%s] New comment posted on \"%s\"' % (get_current_site(request).name,\n                                                          content_object)\n        message = t.render(c)\n        send_mail(subject, message, settings.DEFAULT_FROM_EMAIL, recipient_list, fail_silently=True)", "response": "Send an email notification of a new comment to site staff when email notifications have been requested."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect the moderation methods to pre - and post - save signals from the comments model.", "response": "def connect(self):\n        \"\"\"\n        Hook up the moderation methods to pre- and post-save signals\n        from the comment models.\n\n        \"\"\"\n        signals.comment_will_be_posted.connect(self.pre_save_moderation, sender=comments.get_model())\n        signals.comment_was_posted.connect(self.post_save_moderation, sender=comments.get_model())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a model or a list of models for comment moderation using a particular moderation class.", "response": "def register(self, model_or_iterable, moderation_class):\n        \"\"\"\n        Register a model or a list of models for comment moderation,\n        using a particular moderation class.\n\n        Raise ``AlreadyModerated`` if any of the models are already\n        registered.\n\n        \"\"\"\n        if isinstance(model_or_iterable, ModelBase):\n            model_or_iterable = [model_or_iterable]\n        for model in model_or_iterable:\n            if model in self._registry:\n                raise AlreadyModerated(\n                    \"The model '%s' is already being moderated\" % model._meta.verbose_name\n                )\n            self._registry[model] = moderation_class(model)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unregister(self, model_or_iterable):\n        if isinstance(model_or_iterable, ModelBase):\n            model_or_iterable = [model_or_iterable]\n        for model in model_or_iterable:\n            if model not in self._registry:\n                raise NotModerated(\"The model '%s' is not currently being moderated\" % model._meta.module_name)\n            del self._registry[model]", "response": "Unregister a model or a list of models from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies any necessary pre - save moderation steps to comments.", "response": "def pre_save_moderation(self, sender, comment, request, **kwargs):\n        \"\"\"\n        Apply any necessary pre-save moderation steps to new\n        comments.\n\n        \"\"\"\n        model = comment.content_type.model_class()\n        if model not in self._registry:\n            return\n        content_object = comment.content_object\n        moderation_class = self._registry[model]\n\n        # Comment will be disallowed outright (HTTP 403 response)\n        if not moderation_class.allow(comment, content_object, request): \n            return False\n\n        if moderation_class.moderate(comment, content_object, request):\n            comment.is_public = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_save_moderation(self, sender, comment, request, **kwargs):\n        model = comment.content_type.model_class()\n        if model not in self._registry:\n            return\n        self._registry[model].email(comment, comment.content_object, request)", "response": "Applies any necessary post - save moderation steps to comments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(args):\n  # get options and arguments\n  ui = getUI(args)\n\n  if ui.optionIsSet(\"test\"):\n    # just run unit tests\n    unittest.main(argv=[sys.argv[0]])\n  elif ui.optionIsSet(\"help\"):\n    # just show help\n    ui.usage()\n  else:\n    verbose = (ui.optionIsSet(\"verbose\") is True) or DEFAULT_VERBOSITY\n\n    # header?\n    header = ui.optionIsSet(\"header\")\n\n    # get field value\n    field = ui.getValue(\"field\") - 1\n\n    # get output handle\n    out_fh = sys.stdout\n    if ui.optionIsSet(\"output\"):\n      out_fh = open(ui.getValue(\"output\"), \"w\")\n\n    # get input file-handle\n    in_fh = sys.stdin\n    if ui.hasArgument(0):\n      in_fh = open(ui.getArgument(0))\n\n    delim = DEFAULT_DELIM\n\n    # load data, do conversion, write out results.\n    data_table = DataTable()\n    data_table.load(in_fh, header, delim, verbose)\n    data_table.frame[field] =\\\n        correct_pvals(data_table.frame[field], verbose=verbose)\n    data_table.write(out_fh, delim, verbose)", "response": "This function is the entry point for the FDR script. It will run unit tests and convert the data into a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, in_fh, header=False, delimit=None, verbose=False):\n    self.clear()\n    if verbose:\n      sys.stderr.write(\"getting input...\\n\")\n\n    # figure out whether we need to open a file or not\n    in_strm = in_fh\n    if isinstance(in_strm, basestring):\n      in_strm = open(in_strm)\n\n    for line in in_strm:\n      line = line.strip()\n      if line == \"\":\n        continue\n      if header and self.header is None:\n        self.header = line.split(delimit)\n        continue\n      parts = line.split(delimit)\n      if self.frame != [] and len(parts) != len(self.frame):\n        raise IOError(\"Cannot handle ragged data frames\")\n      while len(self.frame) < len(parts):\n        self.frame.append([])\n      for i in range(0, len(parts)):\n        self.frame[i].append(parts[i])", "response": "Load this dataTable from a file or a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, strm, delim, verbose=False):\n    if verbose:\n      sys.stderr.write(\"outputing...\\n\")\n\n    # figure out whether we need to open a file or not\n    out_strm = strm\n    if isinstance(out_strm, basestring):\n      out_strm = open(out_strm)\n\n    if self.header is not None:\n      out_strm.write(delim.join(self.header))\n    max_col_len = len(max(self.frame, key=len))\n    for i in range(0, max_col_len):\n      for j in range(0, len(self.frame)):\n        if j != 0:\n          out_strm.write(delim)\n        out_strm.write(str(self.frame[j][i]))\n      out_strm.write(\"\\n\")", "response": "Write this data frame to a stream or file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattaching core filters to filterset", "response": "def attach_core_filters(cls):\n        \"\"\"\n        Attach core filters to filterset\n        \"\"\"\n        opts = cls._meta\n        base_filters = cls.base_filters.copy()\n        cls.base_filters.clear()\n        for name, filter_ in six.iteritems(base_filters):\n            if isinstance(filter_, AutoFilters):\n                field = filterset.get_model_field(opts.model, filter_.name)\n                filter_exclusion = filter_.extra.pop('drop', [])\n                for lookup_expr in utils.lookups_for_field(field):\n                    if lookup_expr not in filter_exclusion:\n                        new_filter = cls.filter_for_field(field, filter_.name, lookup_expr)\n                        # by convention use field name for filters with exact lookup_expr\n                        if lookup_expr != 'exact':\n                            filter_name = LOOKUP_SEP.join([name, lookup_expr])\n                        else:\n                            filter_name = name\n                        cls.base_filters[filter_name] = new_filter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef themeble(name, themes=None, global_context=None):\n    def wrap(obj):\n        context = global_context or inspect.stack()[1][0].f_globals\n\n        if name in context and not getattr(context[name], '__themeble', False):\n            raise RuntimeError(\n                'Name {} already exists in this context!'.format(name))\n\n        if ((themes and settings.CURRENT_THEME in themes) or\n                (themes is None and name not in context)):\n            context[name] = obj\n            obj.__themeble = True\n\n        return obj\n    return wrap", "response": "Decorator for registering objects with different themes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_object(self, subject_id, image_group_id, properties, fmri_data_id=None):\n        # Ensure that experiment name is given in property list.\n        if not datastore.PROPERTY_NAME in properties:\n            raise ValueError('missing experiment name')\n        elif properties[datastore.PROPERTY_NAME] is None:\n            raise ValueError('invalid experiment name')\n        # Create a new object identifier.\n        identifier = str(uuid.uuid4()).replace('-','')\n        # Create object handle and store it in database before returning it\n        obj = ExperimentHandle(\n            identifier,\n            properties,\n            subject_id,\n            image_group_id,\n            fmri_data_id=fmri_data_id\n        )\n        self.insert_object(obj)\n        return obj", "response": "Create an experiment object for the subject and image group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(self, document):\n        identifier = str(document['_id'])\n        active = document['active']\n        timestamp = datetime.datetime.strptime(document['timestamp'], '%Y-%m-%dT%H:%M:%S.%f')\n        properties = document['properties']\n        subject_id = document['subject']\n        image_group_id = document['images']\n        fmri_data_id = document['fmri'] if 'fmri' in document else None\n        return ExperimentHandle(\n            identifier,\n            properties,\n            subject_id,\n            image_group_id,\n            fmri_data_id=fmri_data_id,\n            timestamp=timestamp,\n            is_active=active\n        )", "response": "Create an experiment object from a JSON document retrieved from database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all experiments in the database.", "response": "def list_objects(self, query=None, limit=-1, offset=-1):\n        \"\"\"List of all experiments in the database. Overrides the super class\n        method to allow the returned object's property lists to be extended\n        with the run count.\n\n        Parameters\n        ----------\n        query : Dictionary\n            Filter objects by property-value pairs defined by dictionary.\n        limit : int\n            Limit number of items in the result set\n        offset : int\n            Set offset in list (order as defined by object store)\n\n        Returns\n        -------\n        ObjectListing\n        \"\"\"\n        # Call super class method to get the object listing\n        result = super(DefaultExperimentManager, self).list_objects(\n            query=query,\n            limit=limit,\n            offset=offset\n        )\n        # Run aggregate count on predictions if collection was given\n        if not self.coll_predictions is None:\n            # Get model run counts for active experiments. Experiments without\n            # runs will not be in the result\n            counts = {}\n            pipeline = [\n                { '$match': {'active': True}},\n                { '$group': { '_id': \"$experiment\", 'count': { '$sum': 1 } } }\n            ]\n            for doc in self.coll_predictions.aggregate(pipeline):\n                counts[doc['_id']] = doc['count']\n            # Set run count property for all experiments in the result set\n            for item in result.items:\n                if item.identifier in counts:\n                    item.properties[PROPERTY_RUN_COUNT] = counts[item.identifier]\n                else:\n                    item.properties[PROPERTY_RUN_COUNT] = 0\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dict(self, experiment):\n        # Get the basic Json object from the super class\n        json_obj = super(DefaultExperimentManager, self).to_dict(experiment)\n        # Add associated object references\n        json_obj['subject'] = experiment.subject_id\n        json_obj['images'] = experiment.image_group_id\n        if not experiment.fmri_data_id is None:\n            json_obj['fmri'] = experiment.fmri_data_id\n        return json_obj", "response": "Create a Json - like object for an experiment. Extends the basic\n        object with subject image group and functional data_id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassociating the fMRI object with the given experiment.", "response": "def update_fmri_data(self, identifier, fmri_data_id):\n        \"\"\"Associate the fMRI object with the identified experiment.\n\n        Parameters\n        ----------\n        identifier : string\n            Unique experiment object identifier\n        fmri_data_id : string\n            Unique fMRI data object identifier\n\n        Returns\n        -------\n        ExperimentHandle\n            Returns modified experiment object or None if no experiment with\n            the given identifier exists.\n        \"\"\"\n        # Get experiment to ensure that it exists\n        experiment = self.get_object(identifier)\n        if experiment is None:\n            return None\n        # Update fmri_data property and replace existing object with updated one\n        experiment.fmri_data_id = fmri_data_id\n        self.replace_object(experiment)\n        # Return modified experiment\n        return experiment"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads system configuration @rtype: ConfigParser", "response": "def config():\n    \"\"\"\n    Load system configuration\n    @rtype: ConfigParser\n    \"\"\"\n    cfg = ConfigParser()\n    cfg.read(os.path.join(os.path.dirname(os.path.realpath(ips_vagrant.__file__)), 'config/ipsv.conf'))\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprompts the user to select an option from a list of tuples.", "response": "def choice(opts, default=1, text='Please make a choice.'):\n    \"\"\"\n    Prompt the user to select an option\n    @param  opts:   List of tuples containing options in (key, value) format - value is optional\n    @type   opts:   list of tuple\n    @param  text:   Prompt text\n    @type   text:   str\n    \"\"\"\n    opts_len = len(opts)\n    opts_enum = enumerate(opts, 1)\n    opts = list(opts)\n\n    for key, opt in opts_enum:\n        click.echo('[{k}] {o}'.format(k=key, o=opt[1] if isinstance(opt, tuple) else opt))\n\n    click.echo('-' * 12)\n    opt = click.prompt(text, default, type=click.IntRange(1, opts_len))\n    opt = opts[opt - 1]\n    return opt[0] if isinstance(opt, tuple) else opt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef styled_status(enabled, bold=True):\n    return click.style('Enabled' if enabled else 'Disabled', 'green' if enabled else 'red', bold=bold)", "response": "Generates a styled status string for a single element"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a URL into a single domain.", "response": "def domain_parse(url):\n    \"\"\"\n    urlparse wrapper for user input\n    @type   url:    str\n    @rtype: urlparse.ParseResult\n    \"\"\"\n    url = url.lower()\n    if not url.startswith('http://') and not url.startswith('https://'):\n        url = '{schema}{host}'.format(schema='http://', host=url)\n    url = urlparse(url)\n    if not url.hostname:\n        raise ValueError('Invalid domain provided')\n\n    # Strip www prefix any additional URL data\n    url = urlparse('{scheme}://{host}'.format(scheme=url.scheme, host=url.hostname.lstrip('www.')))\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef http_session(cookies=None):\n    session = requests.Session()\n    if cookies is not False:\n        session.cookies.update(cookies or cookiejar())\n    session.headers.update({'User-Agent': 'ipsv/{v}'.format(v=ips_vagrant.__version__)})\n\n    return session", "response": "Generates a Requests session object for the given cookies."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cookiejar(name='session'):\n    log = logging.getLogger('ipsv.common.cookiejar')\n    spath = os.path.join(config().get('Paths', 'Data'), '{n}.txt'.format(n=name))\n    cj = cookielib.LWPCookieJar(spath)\n    log.debug('Attempting to load session file: %s', spath)\n    if os.path.exists(spath):\n        try:\n            cj.load()\n            log.info('Successfully loaded a saved session / cookie file')\n        except cookielib.LoadError as e:\n            log.warn('Session / cookie file exists, but could not be loaded', exc_info=e)\n\n    return cj", "response": "Returns a new CookieJar loaded from a saved session if available."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sendUserInvitationRevoked(self, context={}):\n    organization, invited, invitator = context['invite'].organization, context['invite'].invited, context['invite'].invitator\n    # invited user email\n    self.__init__(organization, async_mail=self.async_mail, override_receiver=invited.email, locale=invited.locale)\n    self.sendEmail('userInvitedRevoked-toUser', 'Your invitation to an organization has been revoked', context)\n\n    if organization.owner == invitator:\n      self.__init__(organization, async_mail=self.async_mail, override_receiver=organization.owner.email, locale=organization.owner.locale)\n      self.sendEmail('userInvitedRevoked-toOwnerInviter', 'You have revoked an user invitation', context)\n    else:\n      self.__init__(organization, async_mail=self.async_mail, override_receiver=organization.owner.email, locale=organization.owner.locale)\n      self.sendEmail('userInvitedRevoked-toOwner', 'An invitation to join your organization has been revoked', context)\n\n      self.__init__(organization, async_mail=self.async_mail, override_receiver=invitator.email, locale=invitator.locale)\n      self.sendEmail('userInvitedRevoked-toMemberInviter', 'You have revoked an user invitation', context)", "response": "Send an email to the user that the user is revoked"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sendUserLeft(self, context={}):\n    self.__init__(context['organization'], async_mail=self.async_mail, override_receiver=context['user'].email, locale=context['user'].locale)\n    self.sendEmail('userLeft-toUser', 'You have left an organization', context)\n\n    self.__init__(context['organization'], async_mail=self.async_mail, override_receiver=context['organization'].owner.email, locale=context['organization'].owner.locale)\n    self.sendEmail('userLeft-toOwner', 'An user has left an organization you own', context)", "response": "Send an email to the user that is left an organization"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of all users in the cluster", "response": "def all(self, start=0, amount=10):\n        \"\"\"\n        Return a list of all users\n        :rtype: list\n        \"\"\"\n        return self._get_json('user/all', start=start, amount=amount)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, username, password, email, full_name):\n        if all([username, password, email, full_name]):\n            r = requests.post(self._base + 'user/register', params={\n                'username': username,\n                'password_1': password,\n                'password_2': password,\n                'email': email,\n                'fullname': full_name\n            })\n            r.raise_for_status()\n        else:\n            raise Exception('None of the arguments may be \"None\"')", "response": "Registers a new user on the LEX"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nactivates a new registree on the LEX with given activation key.", "response": "def activate(self, key):\n        \"\"\"\n        Activates a new registree on the LEX with given activation key\n        :rtype: None\n        \"\"\"\n        url = self._base + 'user/activate'\n        r = requests.get(url, params={\n            'activation_key': key\n        })\n        r.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh_config(self):\n        '''\n        __NB__ This *must* be called from a *different* thread than the GUI/Gtk thread.\n        '''\n        from gi.repository import Clutter, Gst, GstVideo, ClutterGst\n        from path_helpers import path\n        from .warp import bounding_box_from_allocation\n\n        if self.config_requested is not None:\n            sink = ClutterGst.VideoSink.new(self.pipeline_actor.texture)\n            sink.set_property('sync', True)\n            sink.set_property('qos', True)\n\n            if self.record_path is not None:\n                record_path = path(self.record_path)\n                warp_path = record_path.parent.joinpath(record_path.namebase +\n                                                        '.h5')\n                # Parent allocation\n                parent_bbox = \\\n                    bounding_box_from_allocation(self.warp_actor\n                                                 .get_allocation_geometry())\n                # Child allocation\n                child_bbox = \\\n                    bounding_box_from_allocation(self.warp_actor.actor\n                                                 .get_allocation_geometry())\n                common_settings = dict(format='table', data_columns=True,\n                                       complib='zlib', complevel=6)\n                parent_bbox.to_hdf(str(warp_path), '/shape/parent',\n                                   **common_settings)\n                child_bbox.to_hdf(str(warp_path), '/shape/child',\n                                  **common_settings)\n                self.warp_actor.parent_corners.to_hdf(str(warp_path),\n                                                      '/corners/parent',\n                                                      **common_settings)\n                self.warp_actor.child_corners.to_hdf(str(warp_path),\n                                                     '/corners/child',\n                                                     **common_settings)\n            self.pipeline_manager.set_config(self.config_requested,\n                                             record_path=self.record_path,\n                                             sink=sink)\n            self.config_requested = None\n        return True", "response": "Refreshes the configuration of the current instance of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef joint_plot(x, y, marginalBins=50, gridsize=50, plotlimits=None, logscale_cmap=False, logscale_marginals=False, alpha_hexbin=0.75, alpha_marginals=0.75, cmap=\"inferno_r\", marginalCol=None, figsize=(8, 8), fontsize=8, *args, **kwargs):\n    with _plt.rc_context({'font.size': fontsize,}):\n        # definitions for the axes\n        hexbin_marginal_seperation = 0.01\n        left, width = 0.2, 0.65-0.1 # left = left side of hexbin and hist_x\n        bottom, height = 0.1, 0.65-0.1 # bottom = bottom of hexbin and hist_y\n        bottom_h = height + bottom + hexbin_marginal_seperation\n        left_h = width + left + hexbin_marginal_seperation\n        cbar_pos = [0.03, bottom, 0.05, 0.02+width]\n\n        rect_hexbin = [left, bottom, width, height]\n        rect_histx = [left, bottom_h, width, 0.2]\n        rect_histy = [left_h, bottom, 0.2, height]\n\n        # start with a rectangular Figure\n        fig = _plt.figure(figsize=figsize)\n\n        axHexBin = _plt.axes(rect_hexbin)\n        axHistx = _plt.axes(rect_histx)\n        axHisty = _plt.axes(rect_histy)\n        axHisty.set_xticklabels(axHisty.xaxis.get_ticklabels(), y=0, rotation=-90)\n        \n        # scale specific settings\n        if logscale_cmap == True:\n            hexbinscale = 'log'\n        else:\n            hexbinscale = None\n        if logscale_marginals == True:\n            scale='log'\n        else:\n            scale='linear'\n            \n\n        # set up colors \n        cmapOb = _mpl.cm.get_cmap(cmap)\n        cmapOb.set_under(color='white')\n        if marginalCol == None:\n            if logscale_cmap == True:\n                marginalCol = cmapOb(0.7)\n                cbarlabel = 'log10(N)'\n            else:\n                marginalCol = cmapOb(0.5)\n                cbarlabel = 'N'\n\n        # set up limits\n        if plotlimits == None:\n            xmin = x.min()\n            xmax = x.max()\n            ymin = y.min()\n            ymax = y.max()\n            if xmax > ymax:\n                plotlimits = xmax * 1.1\n            else:\n                plotlimits = ymax * 1.1\n\n        # the hexbin plot:\n        hb = axHexBin.hexbin(x, y, gridsize=gridsize, bins=hexbinscale, cmap=cmap, alpha=alpha_hexbin, extent=(-plotlimits, plotlimits, -plotlimits, plotlimits), *args, **kwargs)\n        axHexBin.axis([-plotlimits, plotlimits, -plotlimits, plotlimits])\n\n        cbaraxes = fig.add_axes(cbar_pos)  # This is the position for the colorbar\n        #cbar = _plt.colorbar(axp, cax = cbaraxes)\n        cbar = fig.colorbar(hb, cax = cbaraxes, drawedges=False) #, orientation=\"horizontal\"\n        cbar.solids.set_edgecolor(\"face\")\n        cbar.solids.set_rasterized(True)\n        cbar.solids.set_alpha(alpha_hexbin)\n        cbar.ax.set_yticklabels(cbar.ax.yaxis.get_ticklabels(), y=0, rotation=45)\n        cbar.set_label(cbarlabel, labelpad=-25, y=1.05, rotation=0)\n    \n        axHexBin.set_xlim((-plotlimits, plotlimits))\n        axHexBin.set_ylim((-plotlimits, plotlimits))\n        \n        # now determine bin size\n        binwidth = (2*plotlimits)/marginalBins\n        xymax = _np.max([_np.max(_np.fabs(x)), _np.max(_np.fabs(y))])\n        lim = plotlimits #(int(xymax/binwidth) + 1) * binwidth\n\n        bins = _np.arange(-lim, lim + binwidth, binwidth)\n        axHistx.hist(x, bins=bins, color=marginalCol, alpha=alpha_marginals, linewidth=0)\n        axHistx.set_yscale(value=scale)\n        axHisty.hist(y, bins=bins, orientation='horizontal', color=marginalCol, alpha=alpha_marginals, linewidth=0)\n        axHisty.set_xscale(value=scale)\n\n        _plt.setp(axHistx.get_xticklabels(), visible=False) # sets x ticks to be invisible while keeping gridlines\n        _plt.setp(axHisty.get_yticklabels(), visible=False) # sets x ticks to be invisible while keeping gridlines\n\n        axHistx.set_xlim(axHexBin.get_xlim())\n        axHisty.set_ylim(axHexBin.get_ylim())\n        \n    return fig, axHexBin, axHistx, axHisty, cbar", "response": "Plots some x and y data using hexbins along with a colorbar."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting 2 time traces, the top is the downsampled time trace the bottom is the full time trace.", "response": "def dynamic_zoom_plot(x, y, N, RegionStartSize=1000):\n    \"\"\"\n    plots 2 time traces, the top is the downsampled time trace\n    the bottom is the full time trace.\n\n    \n    \"\"\"\n    x_lowres = x[::N]\n    y_lowres = y[::N]\n    \n    ax1 = _plt.subplot2grid((2, 1), (0, 0), colspan=1)\n    ax2 = _plt.subplot2grid((2, 1), (1, 0))\n    \n    fig = ax1.get_figure()\n    _plt.subplots_adjust(bottom=0.25) # makes space at bottom for sliders\n    \n    CenterTime0 = len(x)/2\n    TimeWidth0 = len(x)/RegionStartSize\n    \n    l1, = ax1.plot(x_lowres, y_lowres, lw=2, color='red')\n    global r1\n    r1 = ax1.fill_between(x_lowres[int((CenterTime0 - TimeWidth0)/N) : int((CenterTime0 + TimeWidth0)/N)], min(y), max(y), facecolor='green', alpha=0.5)\n    l2, = ax2.plot(x, y, lw=2, color='red')\n    \n    \n    axcolor = 'lightgoldenrodyellow'\n    axCenterTime = _plt.axes([0.25, 0.1, 0.65, 0.03], facecolor=axcolor)\n    axTimeWidth = _plt.axes([0.25, 0.15, 0.65, 0.03], facecolor=axcolor)\n    \n    SliderCentreTime = Slider(axCenterTime, 'Center Time', 0, len(x), valinit=CenterTime0)\n    SliderTimeWidth = Slider(axTimeWidth, 'Time Width', 0, len(x), valinit=TimeWidth0)\n    \n    \n    def update(val):\n        TimeWidth = SliderTimeWidth.val\n        CentreTime = SliderCentreTime.val\n        LeftIndex = int(CentreTime-TimeWidth)\n        if LeftIndex < 0:\n            LeftIndex = 0\n        RightIndex = int(CentreTime+TimeWidth)\n        if RightIndex > len(x)-1:\n            RightIndex = len(x)-1\n        global r1\n        r1.remove()\n        r1 = ax1.fill_between(x[LeftIndex:RightIndex], min(y), max(y), facecolor='green', alpha=0.5)\n        l2.set_xdata(x[LeftIndex:RightIndex])\n        l2.set_ydata(y[LeftIndex:RightIndex])\n        ax2.set_xlim([x[LeftIndex], x[RightIndex]])\n        fig.canvas.draw_idle()\n    SliderCentreTime.on_changed(update)\n    SliderTimeWidth.on_changed(update)\n    \n    resetax = _plt.axes([0.8, 0.025, 0.1, 0.04])\n    button = Button(resetax, 'Reset', color=axcolor, hovercolor='0.975')\n    \n    \n    def reset(event):\n        SliderCentreTime.reset()\n        SliderTimeWidth.reset()\n    button.on_clicked(reset)    \n    \n    _plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_config(fname='.rdo.conf', start=None):\n    start = start or os.getcwd()\n    config_file = os.path.join(start, fname)\n    if os.path.isfile(config_file):\n        return config_file\n\n    parent, _ = os.path.split(start)\n    if parent == start:\n        raise Exception('Config file not found')\n\n    return find_config(fname, parent)", "response": "Find an rdo config file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticated_redirect(view_func=None, path=None):\n\n    default_path = getattr(settings, 'DEFAULT_AUTHENTICATED_PATH', 'dashboard')\n\n    if view_func is None:\n        return functools.partial(authenticated_redirect, path=path)\n\n    @functools.wraps(view_func)\n    def _wrapped_view(request, *args, **kwargs):\n        if path == request.path.replace('/', ''):\n            return redirect(default_path)\n\n        if request.user.is_authenticated():\n            return redirect(path or default_path)\n\n        return view_func(request, *args, **kwargs)\n    return _wrapped_view", "response": "Decorator for views that redirects to the default URL if the user is not authenticated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process(self, job_id):\n\n        self._logger.info(\n            '{:.2f}: Process job {}'.format(self._env.now, job_id)\n        )\n\n        # log time of commencement of service\n        self._observer.notify_service(time=self._env.now, job_id=job_id)\n\n        # draw a new service time\n        try:\n            service_time = next(self._service_time_generator)\n        except StopIteration:\n            # ERROR: no more service times\n            error_msg = ('Service time generator exhausted')\n            self._logger.error(error_msg)\n\n            # raise a different exception, as simpy uses StopIteration to\n            # signify end of process (generator)\n            raise GGCQServiceTimeStopIteration(error_msg)\n\n        # wait for the service time to pass\n        try:\n            self._logger.debug('Service time: {:.2f}'.format(service_time))\n        except:\n            pass\n\n        try:\n            yield self._env.timeout(service_time)\n\n        except TypeError:\n            # error: service time of wrong type\n            error_msg = (\n                \"service time '{}' has wrong type '{}'\".format(\n                    service_time, type(service_time).__name__\n                )\n            )\n            self._logger.error(error_msg)\n\n            # trigger exception\n            raise GGCQServiceTimeTypeError(error_msg)\n\n        except ValueError as exc:\n            if str(exc).startswith('Negative delay'):\n                # error: negative service time\n                error_msg = (\n                    \"negative service time {:.2f}\".format(\n                        service_time\n                    )\n                )\n                self._logger.error(error_msg)\n\n                # trigger exception\n                raise GGCQNegativeServiceTimeError(error_msg)\n            else:\n                raise\n\n        # job finished processing -> departing\n        self._logger.info(\n            '{:.2f}: Finished processing job {}'.format(self._env.now, job_id)\n        )\n        # log departure epoch\n        self._observer.notify_departure(time=self._env.now, job_id=job_id)", "response": "Process a single job by the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self):\n        inter_arrival_time = 0.0\n        while True:\n            # wait for next job to arrive\n            try:\n                yield self._env.timeout(inter_arrival_time)\n\n            except TypeError:\n                # error: arrival time of wrong type\n                error_msg = (\n                    \"arrival time '{}' has wrong type '{}'\".format(\n                        inter_arrival_time, type(inter_arrival_time).__name__\n                    )\n                )\n                self._logger.error(error_msg)\n\n                # trigger exception\n                raise GGCQArrivalTimeTypeError(error_msg)\n\n            except ValueError as exc:\n                if str(exc).startswith('Negative delay'):\n                    # error: negative arrival time\n                    error_msg = (\n                        \"negative arrival time {:.2f}\".format(\n                            inter_arrival_time\n                        )\n                    )\n                    self._logger.error(error_msg)\n\n                    # trigger exception\n                    raise GGCQNegativeArrivalTimeError(error_msg)\n                else:\n                    raise\n\n            # job has arrived\n            job_id = self._job_id\n            self._observer.notify_arrival(time=self._env.now, job_id=job_id)\n\n            # get job process\n            job = self._job_generator(job_id)\n\n            # submit job to queue\n            self._env.process(job)\n\n            # time for the next job to arrive\n            try:\n                inter_arrival_time = next(self._arrival_time_generator)\n                self._job_id += 1\n            except StopIteration:\n                # no more jobs to arrive -- exit process\n                self._env.exit()", "response": "Generator function that generates jobs according to the interarrival time distribution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a string of rules into a list of rules", "response": "def parse(cls, rule_string):\n        \"\"\"\n        returns a list of rules\n        a single line may yield multiple rules\n        \"\"\"\n        result = parser.parseString(rule_string)\n        rules = []\n        # breakout port ranges into multple rules\n\n        kwargs = {}\n\n        kwargs['address'] = result.ip_and_mask or None\n        kwargs['group'] = result.security_group or None\n        kwargs['group_name'] = result.group_name or None\n\n        for x,y in result.ports:\n            r = Rule(result.protocol, x, y, **kwargs)\n            rules.append(r)\n        return rules"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind_function(f, dispatcher, *accept_args, **accept_kwargs):\n    argspec = ArgSpec(None, *accept_args, **accept_kwargs)\n    mnd = MNDFunction(f, dispatcher, argspec)\n    f.__mnd__ = mnd\n    return f", "response": "Binds a function to a dispatcher."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind_instancemethod(m, dispatcher, *accept_args, **accept_kwargs):\n    argspec = ArgSpec(None, *accept_args, **accept_kwargs)\n    mnd = MNDMethod(m, dispatcher, argspec)\n    m.__dict__['__mnd__'] = mnd\n    return m", "response": "Binds a function to a dispatcher."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to bind a function to the dispatcher.", "response": "def handle(dispatcher, *accept_args, **accept_kwargs):\n    \"\"\"\n    :param dispatcher: dispatcher to recieve events from\n    :param accept_args:   args to match on\n    :param accept_kwargs: kwargs to match on\n\n    Creates an MNDFunction instance which containing the\n    argspec and adds the function to the dispatcher.\n    \"\"\"\n    def bind_function_later(f):\n        bind_function(f, dispatcher, *accept_args, **accept_kwargs)\n        return f\n    return bind_function_later"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bind_to(self, argspec, dispatcher):\n        self.bound_to[argspec.key].add((argspec, dispatcher))\n        dispatcher.bind(self.f, argspec)", "response": "Bind our function to a dispatcher"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunbind from dispatchers and target function.", "response": "def unbind(self):\n        \"\"\"\n        Unbind from dispatchers and target function.\n\n        :return: set of tuples containing [argspec, dispatcher]\n        \"\"\"\n        args_dispatchers = set()\n        f = self._wf()\n        if f is not None:\n            for ad_list in self.bound_to.values():\n                args_dispatchers.update(ad_list)\n                for argspec, dispatcher in ad_list:\n                    dispatcher.unbind(self.f, argspec)\n            del f.__dict__['__mnd__']\n        self.bound_to = {}\n        return args_dispatchers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts the codon usage table from the names in the sequence of the FASTA file.", "response": "def insert_taxon_in_new_fasta_file(self, aln):\n        \"\"\"primer4clades infers the codon usage table from the taxon names in the\n        sequences.\n\n        These names need to be enclosed by square brackets and be\n        present in the description of the FASTA sequence. The position is not\n        important. I will insert the names in the description in a new FASTA\n        file.\n\n        Returns:\n            Filename of modified FASTA file that includes the name of the taxon.\n        \"\"\"\n        new_seq_records = []\n        for seq_record in SeqIO.parse(aln, 'fasta'):\n            new_seq_record_id = \"[{0}] {1}\".format(self.taxon_for_codon_usage, seq_record.id)\n            new_seq_record = SeqRecord(seq_record.seq, id=new_seq_record_id)\n            new_seq_records.append(new_seq_record)\n\n        base_filename = os.path.splitext(aln)\n        new_filename = '{0}_modified{1}'.format(base_filename[0], base_filename[1])\n        SeqIO.write(new_seq_records, new_filename, \"fasta\")\n        return new_filename"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the results from primer4clades and generates a report.", "response": "def make_report_from_html_file(self, response_body, this_file):\n        \"\"\"Processes the results from primer4clades (a html file).\n\n        Makes a report based on the best possible primer pair (with highest\n        quality and longest amplicon).\n        \"\"\"\n        amplicon_tuples = self.get_amplicon_data_as_tuples(response_body)\n\n        best_amplicon = self.choose_best_amplicon(amplicon_tuples)\n\n        if best_amplicon is not None:\n            self.report += \"\"\"\\n\\n\\\n####################################################\n# Alignment {0}\n\"\"\".format(this_file)\n            self.report += self.format_amplicon(best_amplicon)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_primers(self, my_list):\n        new_list = []\n        n = 2\n        for i in range(0, len(my_list), n):\n            grouped_primers = my_list[i:i + n]\n            forward_primer = grouped_primers[0].split(\" \")\n            reverse_primer = grouped_primers[1].split(\" \")\n            formatted_primers = \">F_{0}\\n{1}\".format(forward_primer[1], forward_primer[0])\n            formatted_primers += \"\\n>R_{0}\\n{1}\".format(reverse_primer[1], reverse_primer[0])\n            new_list.append(formatted_primers)\n        return new_list", "response": "Group elements in list by certain number n"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the best amplicon from the list of amplicon tuples.", "response": "def choose_best_amplicon(self, amplicon_tuples):\n        \"\"\"Iterates over amplicon tuples and returns the one with highest quality\n        and amplicon length.\n        \"\"\"\n        quality = 0\n        amplicon_length = 0\n        best_amplicon = None\n\n        for amplicon in amplicon_tuples:\n            if int(amplicon[4]) >= quality and int(amplicon[5]) >= amplicon_length:\n                quality = int(amplicon[4])\n                amplicon_length = int(amplicon[5])\n                best_amplicon = amplicon\n\n        return best_amplicon"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run():\n\tparser = argparse.ArgumentParser()\n\tparser.add_argument(\n\t\t'--deps-def',\n\t\tdefault=data_lines_from_file(\"system deps.txt\")\n\t\t+ data_lines_from_file(\"build deps.txt\"),\n\t\thelp=\"A file specifying the dependencies (one per line)\",\n\t\ttype=data_lines_from_file, dest=\"spec_deps\")\n\tparser.add_argument(\n\t\t'--dep', action=\"append\", default=[],\n\t\thelp=\"A specific dependency (multiple allowed)\", dest=\"deps\")\n\tparser.add_argument(\n\t\t'command', type=shlex.split,\n\t\tdefault=shlex.split(\"python2.7 setup.py test\"),\n\t\thelp=\"Command to invoke in the context of the dependencies\")\n\tparser.add_argument(\n\t\t'--do-not-remove', default=False, action=\"store_true\",\n\t\thelp=\"Keep any installed packages\")\n\tparser.add_argument(\n\t\t'--aggressively-remove', default=False,\n\t\taction=\"store_true\",\n\t\thelp=\"When removing packages, also remove those automatically installed\"\n\t\t\" as dependencies\")\n\tparser.add_argument(\n\t\t'-l', '--log-level', default=logging.INFO,\n\t\ttype=log_level, help=\"Set log level (DEBUG, INFO, WARNING, ERROR)\")\n\targs = parser.parse_args()\n\tlogging.basicConfig(level=args.log_level)\n\tcontext = dependency_context(\n\t\targs.spec_deps + args.deps,\n\t\taggressively_remove=args.aggressively_remove)\n\twith context as to_remove:\n\t\tif args.do_not_remove:\n\t\t\tdel to_remove[:]\n\t\traise SystemExit(subprocess.Popen(args.command).wait())", "response": "A command in the context of the system dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls the supplied packages and yield the list of packages that were installed.", "response": "def dependency_context(package_names, aggressively_remove=False):\n\t\"\"\"\n\tInstall the supplied packages and yield. Finally, remove all packages\n\tthat were installed.\n\tCurrently assumes 'aptitude' is available.\n\t\"\"\"\n\tinstalled_packages = []\n\tlog = logging.getLogger(__name__)\n\ttry:\n\t\tif not package_names:\n\t\t\tlogging.debug('No packages requested')\n\t\tif package_names:\n\t\t\tlock = yg.lockfile.FileLock(\n\t\t\t\t'/tmp/.pkg-context-lock',\n\t\t\t\ttimeout=30 * 60)\n\t\t\tlog.info('Acquiring lock to perform install')\n\t\t\tlock.acquire()\n\t\t\tlog.info('Installing ' + ', '.join(package_names))\n\t\t\toutput = subprocess.check_output(\n\t\t\t\t['sudo', 'aptitude', 'install', '-y'] + package_names,\n\t\t\t\tstderr=subprocess.STDOUT,\n\t\t\t)\n\t\t\tlog.debug('Aptitude output:\\n%s', output)\n\t\t\tinstalled_packages = jaraco.apt.parse_new_packages(\n\t\t\t\toutput,\n\t\t\t\tinclude_automatic=aggressively_remove)\n\t\t\tif not installed_packages:\n\t\t\t\tlock.release()\n\t\t\tlog.info('Installed ' + ', '.join(installed_packages))\n\t\tyield installed_packages\n\texcept subprocess.CalledProcessError:\n\t\tlog.error(\"Error occurred installing packages\")\n\t\traise\n\tfinally:\n\t\tif installed_packages:\n\t\t\tlog.info('Removing ' + ','.join(installed_packages))\n\t\t\tsubprocess.check_call(\n\t\t\t\t['sudo', 'aptitude', 'remove', '-y'] + installed_packages,\n\t\t\t\tstdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n\t\t\t)\n\t\t\tlock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a tarball extract it change to that directory then remove it.", "response": "def tarball_context(url, target_dir=None, runner=None, pushd=pushd):\n\t\"\"\"\n\tGet a tarball, extract it, change to that directory, yield, then\n\tclean up.\n\t`runner` is the function to invoke commands.\n\t`pushd` is a context manager for changing the directory.\n\t\"\"\"\n\tif target_dir is None:\n\t\ttarget_dir = os.path.basename(url).replace('.tar.gz', '').replace(\n\t\t\t'.tgz', '')\n\tif runner is None:\n\t\trunner = functools.partial(subprocess.check_call, shell=True)\n\t# In the tar command, use --strip-components=1 to strip the first path and\n\t#  then\n\t#  use -C to cause the files to be extracted to {target_dir}. This ensures\n\t#  that we always know where the files were extracted.\n\trunner('mkdir {target_dir}'.format(**vars()))\n\ttry:\n\t\tgetter = 'wget {url} -O -'\n\t\textract = 'tar x{compression} --strip-components=1 -C {target_dir}'\n\t\tcmd = ' | '.join((getter, extract))\n\t\trunner(cmd.format(compression=infer_compression(url), **vars()))\n\t\twith pushd(target_dir):\n\t\t\tyield target_dir\n\tfinally:\n\t\trunner('rm -Rf {target_dir}'.format(**vars()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef infer_compression(url):\n\t# cheat and just assume it's the last two characters\n\tcompression_indicator = url[-2:]\n\tmapping = dict(\n\t\tgz='z',\n\t\tbz='j',\n\t\txz='J',\n\t)\n\t# Assume 'z' (gzip) if no match\n\treturn mapping.get(compression_indicator, 'z')", "response": "Infer the compression code for a tar.\n\t given a URL or filename."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef temp_dir(remover=shutil.rmtree):\n\ttemp_dir = tempfile.mkdtemp()\n\ttry:\n\t\tyield temp_dir\n\tfinally:\n\t\tremover(temp_dir)", "response": "Create a temporary directory context."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields the directory of the repo that is the target directory of the check out.", "response": "def repo_context(url, branch=None, quiet=True, dest_ctx=temp_dir):\n\t\"\"\"\n\tCheck out the repo indicated by url.\n\n\tIf dest_ctx is supplied, it should be a context manager\n\tto yield the target directory for the check out.\n\t\"\"\"\n\texe = 'git' if 'git' in url else 'hg'\n\twith dest_ctx() as repo_dir:\n\t\tcmd = [exe, 'clone', url, repo_dir]\n\t\tif branch:\n\t\t\tcmd.extend(['--branch', branch])\n\t\tdevnull = open(os.path.devnull, 'w')\n\t\tstdout = devnull if quiet else None\n\t\tsubprocess.check_call(cmd, stdout=stdout)\n\t\tyield repo_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the device name from the request.", "response": "def device_from_request(request):\n    \"\"\"\n    Determine's the device name from the request by first looking for an\n    overridding cookie, and if not found then matching the user agent.\n    Used at both the template level for choosing the template to load and\n    also at the cache level as a cache key prefix.\n    \"\"\"\n    from yacms.conf import settings\n    try:\n        # If a device was set via cookie, match available devices.\n        for (device, _) in settings.DEVICE_USER_AGENTS:\n            if device == request.COOKIES[\"yacms-device\"]:\n                return device\n    except KeyError:\n        # If a device wasn't set via cookie, match user agent.\n        try:\n            user_agent = request.META[\"HTTP_USER_AGENT\"].lower()\n        except KeyError:\n            pass\n        else:\n            try:\n                user_agent = user_agent.decode(\"utf-8\")\n                for (device, ua_strings) in settings.DEVICE_USER_AGENTS:\n                    for ua_string in ua_strings:\n                        if ua_string.lower() in user_agent:\n                            return device\n            except (AttributeError, UnicodeDecodeError, UnicodeEncodeError):\n                pass\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of templates returns the list of templates that are associated with the device.", "response": "def templates_for_device(request, templates):\n    \"\"\"\n    Given a template name (or list of them), returns the template names\n    as a list, with each name prefixed with the device directory\n    inserted before it's associate default in the list.\n    \"\"\"\n    from yacms.conf import settings\n    if not isinstance(templates, (list, tuple)):\n        templates = [templates]\n    device = device_from_request(request)\n    device_templates = []\n    for template in templates:\n        if device:\n            device_templates.append(\"%s/%s\" % (device, template))\n        if settings.DEVICE_DEFAULT and settings.DEVICE_DEFAULT != device:\n            default = \"%s/%s\" % (settings.DEVICE_DEFAULT, template)\n            device_templates.append(default)\n        device_templates.append(template)\n    return device_templates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the HTTP request body.", "response": "def body(self):\n        \"\"\" String from `wsgi.input`.\n        \"\"\"\n        if self._body is None:\n            if self._fieldstorage is not None:\n                raise ReadBodyTwiceError()\n\n            clength = int(self.environ('CONTENT_LENGTH') or 0)\n            self._body = self._environ['wsgi.input'].read(clength)\n            if isinstance(self._body, bytes):\n                self._body = self._body.decode('utf8')\n\n        return self._body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a cgi. FieldStorage object from the WSGI request body.", "response": "def fieldstorage(self):\n        \"\"\" `cgi.FieldStorage` from `wsgi.input`.\n        \"\"\"\n        if self._fieldstorage is None:\n            if self._body is not None:\n                raise ReadBodyTwiceError()\n\n            self._fieldstorage = cgi.FieldStorage(\n                environ=self._environ,\n                fp=self._environ['wsgi.input']\n            )\n\n        return self._fieldstorage"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the QUERY_STRING environment variable and return a dict of the parameters.", "response": "def params(self):\n        \"\"\" Parsed query string.\n        \"\"\"\n        if self._params is None:\n            self._params = self.arg_container()\n\n            data = compat.parse_qs(self.environ('QUERY_STRING') or '')\n            for k, v in data.items():\n                self._params[k] = v[0]\n\n        return self._params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data(self):\n        if self._data is None:\n            self._data = self.arg_container()\n\n            if isinstance(self.fieldstorage.value, list):\n                for k in self.fieldstorage.keys():\n                    fname = self.fieldstorage[k].filename\n                    if fname:\n                        self._data[k] = (fname, self.fieldstorage[k].file)\n\n                    else:\n                        self._data[k] = self.fieldstorage.getfirst(k)\n\n        return self._data", "response": "Values in request body."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the named pipe.", "response": "def drain(self, p):\n        '''Reads the named pipe.'''\n\n        self.logging.info('Started.')\n        fd = os.open(p, os.O_RDWR | os.O_NONBLOCK)\n        gevent_os.make_nonblocking(fd)\n\n        while self.loop():\n            try:\n                lines = gevent_os.nb_read(fd, 4096).splitlines()\n                if len(lines) == 0:\n                    sleep(0.5)\n                else:\n                    self.consume(lines)\n            except OSError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_xml(xml):\n        parsed = xml\n        if not isinstance(xml, MARCXMLRecord):\n            parsed = MARCXMLRecord(str(xml))\n\n        # check whether the document was deleted\n        if \"DEL\" in parsed.datafields:\n            raise DocumentNotFoundException(\"Document was deleted.\")\n\n        # i know, that this is not PEP8, but you dont want to see it without\n        # proper formating (it looks bad, really bad)\n        return EPeriodical(\n            url=parsed.get_urls(),\n            ISSN=parsed.get_ISSNs(),\n            nazev=parsed.get_name(),\n            anotace=None,  # TODO: read the annotation\n            podnazev=parsed.get_subname(),\n            id_number=parsed.controlfields.get(\"001\", None),\n            datumVydani=parsed.get_pub_date(),\n            mistoVydani=parsed.get_pub_place(),\n            internal_url=parsed.get_internal_urls(),\n            invalid_ISSNs=parsed.get_invalid_ISSNs(),\n            nakladatelVydavatel=parsed.get_publisher(),\n            ISSNSouboruPublikaci=parsed.get_linking_ISSNs(),\n        )", "response": "Converts a MARC XML string to a namedtuple of data about the EPublication."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, handler, name=None, exception_handlers=()):\n        self.route.append((name, handler, exception_handlers))", "response": "Add a handler to the route."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a handler with the Router.", "response": "def add(self, match, handler):\n        \"\"\"Register a handler with the Router.\n\n        :param match: The first argument passed to the :meth:`match` method\n            when checking against this handler.\n        :param handler: A callable or :class:`Route` instance that will handle\n            matching calls. If not a Route instance, will be wrapped in one.\n        \"\"\"\n        self.routes.append((match, (\n            Route(handler) if not isinstance(handler, Route)\n            else handler\n        )))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_annotated_data_x_y(timestamps, data, lbls):\n\n        timestamps = np.array(timestamps)\n\n        timestamp_step = timestamps[3]-timestamps[2]\n        current_new_timestamp = 0.0\n        new_timestamps = []\n\n        X = None\n        Y = []\n        classes = []\n\n        for i in range(0, len(timestamps)):\n\n            for lbl in lbls:\n                if lbl.start_seconds <= timestamps[i] < lbl.end_seconds:\n                    if X is None:\n                        X = data[i, :]\n                    else:\n                        X = np.vstack((X, data[i, :]))\n                    Y.append(lbl.label)\n                    new_timestamps.append(current_new_timestamp)\n                    current_new_timestamp += timestamp_step\n\n                    if lbl.label not in classes:\n                        classes.append(lbl.label)\n\n        return X, Y, classes, new_timestamps", "response": "Get the X Y and classes from the data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the list of audacity labels to a file.", "response": "def write_audacity_labels(audacity_labels, filename):\n        \"\"\"\n        :param audacity_labels: list containing audacity label objects\n        :return:\n        \"\"\"\n        with open(filename, \"w\") as f:\n            for label in audacity_labels:\n                f.write(\"%s\\t%s\\t%s\\n\" % (label.start_seconds, label.end_seconds, label.label))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload logger config from file", "response": "def load_config(filename=\"logging.ini\", *args, **kwargs):\n    \"\"\"\n    Load logger config from file\n    \n    Keyword arguments:\n    filename -- configuration filename (Default: \"logging.ini\")\n    *args -- options passed to fileConfig\n    **kwargs -- options passed to fileConfigg\n    \n    \"\"\"\n    logging.config.fileConfig(filename, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the default config dictionary and inits the logging system if requested", "response": "def default_config(level=logging.INFO, auto_init=True, new_formatter=False, **kwargs):\n    \"\"\"\n    Returns the default config dictionary and inits the logging system if requested\n    \n    Keyword arguments:\n    level -- loglevel of the console handler (Default: logging.INFO)\n    auto_init -- initialize the logging system with the provided config (Default: True)\n    **kwargs -- additional options for the logging system\n    \n    \"\"\"\n    formatters =  {\n        'color': {\n            '()': __name__ + '.ColorFormatter',\n            'format': '[%(levelname)s] %(message)s'\n        }\n    }\n\n    if new_formatter:\n        formatters =  {\n            'color': {\n                '()': __name__ + '.NewColorFormatter',\n                'format': '[{levelname}] {message}'\n            }\n        }\n\n    options = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': formatters,\n        'filters': {},\n        'handlers': {\n            'console': {\n                'class': 'logging.StreamHandler',\n                'formatter': 'color',\n                'level': level,#logging.getLevelName(level),\n                'stream': 'ext://sys.stderr',\n                }\n            },\n        'loggers': {\n            },\n        'root': {\n            'level': 'NOTSET',\n            'filters': [],\n            'handlers': ['console'],\n            }\n        }\n\n    options.update(kwargs)\n\n    if auto_init:\n        logging.config.dictConfig(options)\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scope_logger(cls):\n    cls.log = logging.getLogger('{0}.{1}'.format(cls.__module__, cls.__name__))\n    return cls", "response": "A class decorator for adding a class local logger to the current scope"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        self._finished.clear()\n        for line in iter(self.pipeReader.readline, ''):\n            logging.log(self.level, line.strip('\\n'))\n\n        self.pipeReader.close()\n        self._finished.set()", "response": "Run the thread logging everything."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, source, filepath=None):\n        # Set _path if source is a file-like object\n        try:\n            self._path = source.name\n        except AttributeError:\n            self._path = filepath\n\n        # Get source content either it's a string or a file-like object\n        try:\n            source_content = source.read()\n        except AttributeError:\n            source_content = source\n\n        # Parse and serialize given source\n        parser = TinycssSourceParser()\n        self._datas = parser.parse(source_content)\n\n        serializer = ManifestSerializer()\n        references = serializer.serialize(self._datas)\n\n        # Copy serialized metas\n        self.metas = serializer._metas\n\n        # Set every enabled rule as object attribute\n        for k, v in references.items():\n            self.set_rule(k, v)\n\n        return self._datas", "response": "Load source as manifest attributes and rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_rule(self, name, properties):\n        self._rule_attrs.append(name)\n        setattr(self, name, properties)", "response": "Set a rules as object attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_rule(self, name):\n        self._rule_attrs.remove(name)\n        delattr(self, name)", "response": "Removes a rule from the attribute list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes metas and reference attributes to a JSON string.", "response": "def to_json(self, indent=4):\n        \"\"\"\n        Serialize metas and reference attributes to a JSON string.\n\n        Keyword Arguments:\n            indent (int): Space indentation, default to ``4``.\n\n        Returns:\n            string: JSON datas.\n        \"\"\"\n        agregate = {\n            'metas': self.metas,\n        }\n\n        agregate.update({k: getattr(self, k) for k in self._rule_attrs})\n\n        return json.dumps(agregate, indent=indent)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, to, cc, subject, body, atts=None, delete=False):\n        email_cnt = MIMEMultipart()\n        email_cnt['From'] = Header(self.smtp_user, CHARSET_ENCODING)\n        email_cnt['To'] = Header(';'.join(to), CHARSET_ENCODING)\n        email_cnt['Cc'] = Header(';'.join(cc), CHARSET_ENCODING)\n        email_cnt['Subject'] = Header(subject, CHARSET_ENCODING)\n        email_cnt['Date'] = formatdate()\n        email_cnt.attach(MIMEText(body, 'html', CHARSET_ENCODING))\n\n        self.__add_att__(email_cnt, atts, delete)\n\n        try:\n            self.__login__()\n            self.smtp_conn.sendmail(self.smtp_user, to+cc, email_cnt.as_string())\n\n            with_att_msg = 'Empty'\n            if atts:\n                for i, att in enumerate(atts):\n                    atts[i] = att[att.startswith('/')+1:]\n\n                with_att_msg = ','.join(atts)\n                '''Flush memory\n                '''\n                atts[:] = []\n\n            logger.info('Send email[%s] success.', subject)\n            logger.info('To users: %s.', ','.join(to+cc))\n            logger.info('With attachments: %s.', with_att_msg)\n        except Exception as e:\n            raise SendEmailException(\"Send email[%s] failed!!! Case: %s\" % (subject, str(e)))", "response": "Send an email action."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestrict an address from the set of addresses this proxy is permitted to introduce.", "response": "def restrict(self, addr):\n        \"\"\"\n        Drop an address from the set of addresses this proxy is\n        permitted to introduce.\n\n        :param addr: The address to remove.\n        \"\"\"\n\n        # Remove the address from the set\n        ip_addr = _parse_ip(addr)\n        if ip_addr is None:\n            LOG.warn(\"Cannot restrict address %r from proxy %s: \"\n                     \"invalid address\" % (addr, self.address))\n        else:\n            self.excluded.add(addr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef accept(self, addr):\n\n        # Add the address to the set\n        ip_addr = _parse_ip(addr)\n        if ip_addr is None:\n            LOG.warn(\"Cannot add address %r to proxy %s: \"\n                     \"invalid address\" % (addr, self.address))\n        else:\n            self.accepted.add(addr)", "response": "Add an address to the set of addresses that this proxy is permitted to introduce."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self, proxy_ip, client_ip):\n\n        # First, look up the proxy\n        if self.pseudo_proxy:\n            proxy = self.pseudo_proxy\n        elif proxy_ip not in self.proxies:\n            return False\n        else:\n            proxy = self.proxies[proxy_ip]\n\n        # Now, verify that the client is valid\n        return client_ip in proxy", "response": "Checks that the given client IP is permitted to introduce the given proxy."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef requires_auth(func):\n    @six.wraps(func)\n    def wrapper(self, *args, **kwargs):\n        if self.token_expired:\n            self.authenticate()\n        return func(self, *args, **kwargs)\n    return wrapper", "response": "Decorator to check if the token has expired and performs authentication if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef headers(self):\n        self._headers.update(**{'Accept-Language': self.language})\n        if self.__token:\n            self._headers.update(\n                **{'Authorization': 'Bearer %s' % self.__token})\n        return self._headers", "response": "Provide access to updated headers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef token_expired(self):\n        if self._token_timer is None:\n            return True\n        return timeutil.is_newer_than(self._token_timer, timeutil.ONE_HOUR)", "response": "Provide access to flag indicating if token has expired."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprovides access to request session with local cache enabled.", "response": "def session(self):\n        \"\"\"Provide access to request session with local cache enabled.\"\"\"\n        if self._session is None:\n            self._session = cachecontrol.CacheControl(\n                requests.Session(),\n                cache=caches.FileCache('.tvdb_cache'))\n        return self._session"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef authenticate(self):\n        if self.__token:\n            try:\n                resp = self._refresh_token()\n            except exceptions.TVDBRequestException as err:\n                # if a 401 is the cause try to login\n                if getattr(err.response, 'status_code', 0) == 401:\n                    resp = self._login()\n                else:\n                    raise\n        else:\n            resp = self._login()\n\n        self.__token = resp.get('token')\n        self._token_timer = timeutil.utcnow()", "response": "Aquire authorization token for using thetvdb apis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for a series record or series record.", "response": "def search_series(self, **kwargs):\n        \"\"\"Provide the ability to search for a series.\n\n        .. warning::\n\n            authorization token required\n\n        The following search arguments currently supported:\n\n            * name\n            * imdbId\n            * zap2itId\n\n        :param kwargs: keyword arguments to search for series\n        :returns: series record or series records\n        :rtype: dict\n        \"\"\"\n        params = {}\n        for arg, val in six.iteritems(kwargs):\n            if arg in SERIES_BY:\n                params[arg] = val\n        resp = self._exec_request(\n            'search', path_args=['series'], params=params)\n        if cfg.CONF.tvdb.select_first:\n            return resp['data'][0]\n        return resp['data']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_episodes(self, series_id, **kwargs):\n        params = {'page': 1}\n        for arg, val in six.iteritems(kwargs):\n            if arg in EPISODES_BY:\n                params[arg] = val\n        return self._exec_request(\n            'series',\n            path_args=[series_id, 'episodes', 'query'], params=params)['data']", "response": "Returns a list of all episodes for a given series."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef intersectingPoint(self, p):\n    # perfect match\n    if p == self.data.mid:\n      return self.data.ends\n\n    if p > self.data.mid:\n      # we know all intervals in self.data begin before p (if they began after\n      # p, they would have not included mid) we just need to find those that\n      # end after p\n      endAfterP = [r for r in self.data.ends\n                   if (r.end >= p and not self.openEnded) or\n                   (r.end > p and self.openEnded)]\n      if self.right is not None:\n        endAfterP.extend(self.right.intersectingPoint(p))\n      return endAfterP\n\n    if p < self.data.mid:\n      # we know all intervals in self.data end after p (if they ended before p,\n      # they would have not included mid) we just need to find those that start\n      # before p\n      startBeforeP = [r for r in self.data.starts if r.start <= p]\n      if self.left is not None:\n        startBeforeP.extend(self.left.intersectingPoint(p))\n      return startBeforeP", "response": "get intervals in the tree that are intersected with a point p"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intersectingInterval(self, start, end):\n    # find all intervals in this node that intersect start and end\n    l = []\n    for x in self.data.starts:\n      xStartsAfterInterval = (x.start > end and not self.openEnded) or \\\n                             (x.start >= end and self.openEnded)\n      xEndsBeforeInterval = (x.end < start and not self.openEnded) or \\\n                            (x.end <= start and self.openEnded)\n      if ((not xStartsAfterInterval) and (not xEndsBeforeInterval)):\n        l.append(x)\n\n    # process left subtree (if we have one) if the requested interval begins\n    # before mid\n    if self.left is not None and start <= self.data.mid:\n      l += self.left.intersectingInterval(start, end)\n\n    # process right subtree (if we have one) if the requested interval ends\n    # after mid\n    if self.right is not None and end >= self.data.mid:\n      l += self.right.intersectingInterval(start, end)\n\n    return l", "response": "get intervals in the tree that are intersected by the given interval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator that will iterate over those objects in the tree which intersect the given interval", "response": "def intersectingIntervalIterator(self, start, end):\n    \"\"\"\n    Get an iterator which will iterate over those objects in the tree which\n    intersect the given interval - sorted in order of start index\n\n    :param start: find intervals in the tree that intersect an interval with\n                  with this start index (inclusive)\n    :param end:   find intervals in the tree that intersect an interval with\n                  with this end index (exclusive)\n    :return: an iterator that will yield intersected intervals\n    \"\"\"\n    items = self.intersectingInterval(start, end)\n    items.sort(key=lambda x: x.start)\n    for item in items:\n      yield item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initiate_tasks(self):\n        self.tasks_classes = TaskLoader().load_tasks(\n            paths=self.configuration[Configuration.ALGORITHM][Configuration.TASKS][Configuration.PATHS])", "response": "Loads all tasks from respective configuration option"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef instantiate_tasks(self):\n        self.tasks_instances = {}\n        for task_name, task_class in self.tasks_classes.items():\n            try:\n                self.tasks_instances[task_name] = task_class()\n            except Exception as ex:\n                if not self.configuration[Configuration.ALGORITHM][Configuration.IOSF]:\n                    raise GOSTaskException(\"An exception happened during the task instantiation.\"\n                                           \"{exception}\".format(exception=ex))", "response": "Instantiate all loaded tasks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_requirements(filename='requirements.txt'):\n    with open(filename) as f:\n        return [\n            line.rstrip().split('#')[0]\n            for line in f.readlines()\n            if not line.startswith('#')\n        ]", "response": "Get the contents of a file listing the requirements. txt file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a configure flag is set.", "response": "def _have(self, name=None):\n        \"\"\"Check if a configure flag is set.\n\n        If called without argument, it returns all HAVE_* items.\n\n        Example:\n\n            {% if have('netinet/ip.h') %}...{% endif %}\n        \"\"\"\n        if name is None:\n            return (\n                (k, v) for k, v  in self.env.items()\n                if k.startswith('HAVE_')\n            )\n        return self.env.get('HAVE_' + self.env_key(name)) == True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nspecifying a linker library.", "response": "def _lib(self, name, only_if_have=False):\n        \"\"\"Specify a linker library.\n\n        Example:\n\n            LDFLAGS={{ lib(\"rt\") }} {{ lib(\"pthread\", True) }}\n\n        Will unconditionally add `-lrt` and check the environment if the key\n        `HAVE_LIBPTHREAD` is set to be true, then add `-lpthread`.\n        \"\"\"\n        emit = True\n        if only_if_have:\n            emit = self.env.get('HAVE_LIB' + self.env_key(name))\n        if emit:\n            return '-l' + name\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a build option is enabled.", "response": "def _with(self, option=None):\n        \"\"\"Check if a build option is enabled.\n\n        If called without argument, it returns all WITH_* items.\n\n        Example:\n\n            {% if with('foo') %}...{% endif %}\n        \"\"\"\n        if option is None:\n            return (\n                (k, v) for k, v in self.env.items()\n                if k.startswith('WITH_')\n            )\n        return self.env.get('WITH_' + option.upper()) == True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pairs(iterable):\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return zip(a, b)", "response": "Returns an iterator yielding overlapping pairs from iterable"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the accepted or rejected codes list.", "response": "def set_codes(self, codes, reject=False):\n        \"\"\"\n        Set the accepted or rejected codes codes list.\n\n        :param codes: A list of the response codes.\n        :param reject: If True, the listed codes will be rejected, and\n                       the conversion will format as \"-\"; if False,\n                       only the listed codes will be accepted, and the\n                       conversion will format as \"-\" for all the\n                       others.\n        \"\"\"\n\n        self.codes = set(codes)\n        self.reject = reject"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef accept(self, code):\n\n        if code in self.codes:\n            return not self.reject\n        return self.reject", "response": "Determines whether the response code should be accepted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the character needs escaping.", "response": "def _needescape(c):\n        \"\"\"\n        Return True if character needs escaping, else False.\n        \"\"\"\n\n        return not ascii.isprint(c) or c == '\"' or c == '\\\\' or ascii.isctrl(c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms the desired Conversion.", "response": "def convert(self, request, response, data):\n        \"\"\"\n        Performs the desired Conversion.\n\n        :param request: The webob Request object describing the\n                        request.\n        :param response: The webob Response object describing the\n                         response.\n        :param data: The data dictionary returned by the prepare()\n                     method.\n\n        :returns: A string, the results of which are the desired\n                  conversion.\n        \"\"\"\n\n        client_addr = request.environ.get('REMOTE_ADDR', '-')\n        if (self.modifier.param != 'c' and\n                'bark.useragent_ip' in request.environ):\n            client_addr = request.environ['bark.useragent_ip']\n\n        return client_addr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms the desired Conversion.", "response": "def convert(self, request, response, data):\n        \"\"\"\n        Performs the desired Conversion.\n\n        :param request: The webob Request object describing the\n                        request.\n        :param response: The webob Response object describing the\n                         response.\n        :param data: The data dictionary returned by the prepare()\n                     method.\n\n        :returns: A string, the results of which are the desired\n                  conversion.\n        \"\"\"\n\n        # Chop up the URL\n        uri = urlparse.urlparse(request.url)\n\n        # If there's a password, recompute the URI without it\n        if uri.password:\n            netloc = \"%s:%s@\" % (uri.username or \"\", \"XXXXXXXX\")\n            if uri.hostname:\n                netloc += uri.hostname\n            if uri.port is not None:\n                netloc += \":%d\" % uri.port\n\n            uri = urlparse.ParseResult(uri[0], netloc, uri[2], uri[3],\n                                       uri[4], uri[5])\n\n        return self.escape(\"%s %s %s\" % (request.method, uri.geturl(),\n                                         request.environ['SERVER_PROTOCOL']))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform the desired Conversion.", "response": "def convert(self, request, response, data):\n        \"\"\"\n        Performs the desired Conversion.\n\n        :param request: The webob Request object describing the\n                        request.\n        :param response: The webob Response object describing the\n                         response.\n        :param data: The data dictionary returned by the prepare()\n                     method.\n\n        :returns: A string, the results of which are the desired\n                  conversion.\n        \"\"\"\n\n        # Notes are in bark.notes dictionary\n        return self.escape(request.environ.get('bark.notes', {}).get(\n            self.modifier.param, '-'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(self, request, response, data):\n\n        if self.modifier.param is None or self.modifier.param == 'pid':\n            return str(os.getpid())\n        elif self.modifier.param == 'tid':\n            return str(thread.get_ident())\n        elif self.modifier.param == 'hextid':\n            return hex(thread.get_ident())\n        return self.modifier.param", "response": "Performs the desired Conversion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert(self, request, response, data):\n\n        qstr = request.query_string\n\n        return self.escape('?%s' % qstr) if qstr else ''", "response": "Performs the desired Conversion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert(self, request, response, data):\n\n        # None specified\n        if request.remote_user is None:\n            return \"-\"\n        elif not request.remote_user:\n            # Empty string...\n            return '\"\"'\n        return self.escape(request.remote_user)", "response": "Performs the desired Conversion."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms the desired Conversion.", "response": "def convert(self, request, response, data):\n        \"\"\"\n        Performs the desired Conversion.\n\n        :param request: The webob Request object describing the\n                        request.\n        :param response: The webob Response object describing the\n                         response.\n        :param data: The data dictionary returned by the prepare()\n                     method.\n\n        :returns: A string, the results of which are the desired\n                  conversion.\n        \"\"\"\n\n        size = response.content_length\n        if not size:\n            size = \"-\" if self.conv_chr == 'b' else 0\n\n        return str(size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming the desired Conversion.", "response": "def convert(self, request, response, data):\n        \"\"\"\n        Performs the desired Conversion.\n\n        :param request: The webob Request object describing the\n                        request.\n        :param response: The webob Response object describing the\n                         response.\n        :param data: The data dictionary returned by the prepare()\n                     method.\n\n        :returns: A string, the results of which are the desired\n                  conversion.\n        \"\"\"\n\n        if self.modifier.param in (None, 'canonical', 'local'):\n            return str(request.environ['SERVER_PORT'])\n        elif self.modifier.param == 'remote':\n            return str(request.environ.get('REMOTE_PORT', '-'))\n\n        return \"-\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform the desired Conversion.", "response": "def convert(self, request, response, data):\n        \"\"\"\n        Performs the desired Conversion.\n\n        :param request: The webob Request object describing the\n                        request.\n        :param response: The webob Response object describing the\n                         response.\n        :param data: The data dictionary returned by the prepare()\n                     method.\n\n        :returns: A string, the results of which are the desired\n                  conversion.\n        \"\"\"\n\n        delta = time.time() - data['start']\n\n        if self.conv_chr == 'D':\n            delta *= 1000000\n\n        return str(int(delta))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert(self, request, response, data):\n\n        # Determine which time to use\n        fmtstr = self.modifier.param\n        if fmtstr is None:\n            log_time = data['start']\n        elif fmtstr == 'begin' or fmtstr.startswith('begin:'):\n            log_time = data['start']\n            if fmtstr == 'begin':\n                fmtstr = None\n            else:\n                fmtstr = fmtstr[len('begin:'):]\n        elif fmtstr == 'end' or fmtstr.startswith('end:'):\n            log_time = time.time()\n            if fmtstr == 'end':\n                fmtstr = None\n            else:\n                fmtstr = fmtstr[len('end:'):]\n        else:\n            log_time = data['start']\n\n        # Next, determine the format to use\n        if fmtstr is None:\n            fmtstr = \"[%d/%b/%Y:%H:%M:%S +0000]\"\n        elif fmtstr in ('sec', 'msec', 'usec', 'msec_frac', 'usec_frac'):\n            mult = 1\n            fld_len = 0\n\n            # Handle microseconds and milliseconds\n            if fmtstr.startswith('usec'):\n                mult = 1000000\n                fld_len = 6\n            elif fmtstr.startswith('msec'):\n                mult = 1000\n                fld_len = 3\n\n            # Adjust for request for fractions\n            if fmtstr.endswith('_frac'):\n                log_time = int((log_time * mult) - (int(log_time) * mult))\n            else:\n                log_time = int(log_time * mult)\n                fld_len = 0\n\n            # Return the formatted result\n            return \"%0*d\" % (fld_len, log_time)\n\n        return time.strftime(fmtstr, time.gmtime(log_time))", "response": "This method performs the desired conversion of the current object to the desired object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef submit(self):\n        u = urlparse(self.url)\n        \n        if not self.action:\n            self.action = self.url\n        elif self.action == u.path:\n            self.action = self.url\n        else:\n            if not u.netloc in self.action:\n                path = \"/\".join(u.path.split(\"/\")[1:-1])\n                if self.action.startswith(\"/\"):\n                    path = path + self.action\n                else:\n                    path = path + \"/\" + self.action\n                self.action = \"http://\" + u.netloc + \"/\" + path\n            \n        return self.usr.getPage(self.action, self.items, {'Referer': self.url}, self.usePin)", "response": "Posts the form s data and returns the resulting Page\n cacheManager Returns the resulting Page\n cacheManager"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __create(self, client_id, client_secret, calls, **kwargs):\n        params = {\n            'client_id': client_id,\n            'client_secret': client_secret,\n            'calls': calls\n        }\n        return self.make_call(self.__create, params, kwargs)", "response": "Method to create a new cluster entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute a hash code for the given dictionary that is safe for persistence round trips", "response": "def compute_hash(attributes, ignored_attributes=None):\n    \"\"\"\n    Computes a hash code for the given dictionary that is safe for persistence round trips \n    \"\"\"\n    ignored_attributes = list(ignored_attributes) if ignored_attributes else []\n    tuple_attributes = _convert(attributes.copy(), ignored_attributes)\n    hasher = hashlib.sha256(str(tuple_attributes).encode('utf-8', errors='ignore'))\n    return hasher.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SimpleRowColumn(field, *args, **kwargs):\n    if isinstance(field, basestring):\n        field = Field(field, *args, **kwargs)\n    return Row(\n        Column(field),\n    )", "response": "Shortcut for simple row with only a full column"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave and send the email", "response": "def save(self, commit=True):\n        \"\"\"Save and send\"\"\"\n        contact = super(ContactFormBase, self).save()\n        context = {'contact': contact}\n        context.update(get_site_metas())\n\n        subject = ''.join(render_to_string(self.mail_subject_template, context).splitlines())\n        content = render_to_string(self.mail_content_template, context)\n\n        send_mail(subject, content,\n                  settings.DEFAULT_FROM_EMAIL,\n                  settings.CONTACT_FORM_TO,\n                  fail_silently=not settings.DEBUG)\n\n        return contact"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bark_filter(global_conf, **local_conf):\n\n    # First, parse the configuration\n    conf_file = None\n    sections = {}\n    for key, value in local_conf.items():\n        # 'config' key causes a load of a configuration file; settings\n        # in the local_conf will override settings in the\n        # configuration file, however\n        if key == 'config':\n            conf_file = value\n        elif '.' in key:\n            sect, _sep, opt = key.partition('.')\n            sect_dict = sections.setdefault(sect, {})\n            sect_dict[opt] = value  # note: a string\n\n    # Now that we've loaded local_conf, process conf_file (if any)\n    if conf_file:\n        cp = ConfigParser.SafeConfigParser()\n        cp.read([conf_file])\n        for sect in cp.sections():\n            for opt, value in cp.options(sect):\n                sect_dict = sections.setdefault(sect, {})\n                # By using setdefault(), we allow local_conf to\n                # override the configuration file\n                sect_dict.setdefault(opt, value)\n\n    # OK, the configuration is all read; next step is to turn the\n    # configuration into logging handlers\n    handlers = {}\n    proxies = None\n    for sect, sect_dict in sections.items():\n        if sect == 'proxies':\n            # Reserved for proxy configuration\n            try:\n                proxies = bark.proxy.ProxyConfig(sect_dict)\n            except KeyError as exc:\n                LOG.warn(\"Cannot configure proxy handling: option %s is \"\n                         \"missing from the proxy configuration\" % exc)\n            continue  # Pragma: nocover\n\n        # First, determine the logging format\n        try:\n            format = bark.format.Format.parse(sect_dict.pop('format'))\n        except KeyError:\n            LOG.warn(\"No format specified for log %r; skipping.\" % sect)\n            continue\n\n        # Next, determine the handler type\n        handle_type = sect_dict.pop('type', 'file')\n\n        # Now, let's construct a handler; this will be a callable\n        # taking the formatted message to log\n        try:\n            handler = bark.handlers.get_handler(handle_type, sect, sect_dict)\n        except Exception as exc:\n            LOG.warn(\"Cannot load handler of type %r for log %r: %s\" %\n                     (handle_type, sect, exc))\n            continue\n\n        # We now have a handler and a format; bundle them up\n        handlers[sect] = (format, handler)\n\n    # Construct the wrapper which is going to instantiate the\n    # middleware\n    def wrapper(app):\n        return BarkMiddleware(app, handlers, proxies)\n\n    return wrapper", "response": "This function returns a function which returns an instance of BarkMiddleware. It will parse the global configuration file and then process the local configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes gunzipped binary data.", "response": "def decode(binary):\n    \"\"\"Decode (gunzip) binary data.\"\"\"\n    encoded = io.BytesIO(binary)\n    with gzip.GzipFile(mode='rb', fileobj=encoded) as file_:\n        decoded = file_.read()\n    return decoded"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencode gzip binary data.", "response": "def encode(binary):\n    \"\"\"Encode (gzip) binary data.\"\"\"\n    encoded = io.BytesIO()\n    gzip_file = dict(mode='wb', fileobj=encoded, compresslevel=LEVEL)\n    with gzip.GzipFile(**gzip_file) as file_:\n        file_.write(binary)\n    encoded.seek(0)\n    return encoded.read()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of blog posts that are filtered by tag year month author or category.", "response": "def blog_post_list(request, tag=None, year=None, month=None, username=None,\n                   category=None, template=\"blog/blog_post_list.html\",\n                   extra_context=None):\n    \"\"\"\n    Display a list of blog posts that are filtered by tag, year, month,\n    author or category. Custom templates are checked for using the name\n    ``blog/blog_post_list_XXX.html`` where ``XXX`` is either the\n    category slug or author's username if given.\n    \"\"\"\n    templates = []\n    blog_posts = BlogPost.objects.published(for_user=request.user)\n    if tag is not None:\n        tag = get_object_or_404(Keyword, slug=tag)\n        blog_posts = blog_posts.filter(keywords__keyword=tag)\n    if year is not None:\n        blog_posts = blog_posts.filter(publish_date__year=year)\n        if month is not None:\n            blog_posts = blog_posts.filter(publish_date__month=month)\n            try:\n                month = _(month_name[int(month)])\n            except IndexError:\n                raise Http404()\n    if category is not None:\n        category = get_object_or_404(BlogCategory, slug=category)\n        blog_posts = blog_posts.filter(categories=category)\n        templates.append(u\"blog/blog_post_list_%s.html\" %\n                          str(category.slug))\n    author = None\n    if username is not None:\n        author = get_object_or_404(User, username=username)\n        blog_posts = blog_posts.filter(user=author)\n        templates.append(u\"blog/blog_post_list_%s.html\" % username)\n\n    prefetch = (\"categories\", \"keywords__keyword\")\n    blog_posts = blog_posts.select_related(\"user\").prefetch_related(*prefetch)\n    blog_posts = paginate(blog_posts, request.GET.get(\"page\", 1),\n                          settings.BLOG_POST_PER_PAGE,\n                          settings.MAX_PAGING_LINKS)\n    context = {\"blog_posts\": blog_posts, \"year\": year, \"month\": month,\n               \"tag\": tag, \"category\": category, \"author\": author}\n    context.update(extra_context or {})\n    templates.append(template)\n    return TemplateResponse(request, templates, context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of blog posts feed views.", "response": "def blog_post_feed(request, format, **kwargs):\n    \"\"\"\n    Blog posts feeds - maps format to the correct feed view.\n    \"\"\"\n    try:\n        return {\"rss\": PostsRSS, \"atom\": PostsAtom}[format](**kwargs)(request)\n    except KeyError:\n        raise Http404()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npublish a message to the kombu broker", "response": "def publish(self, message_type, client_id, client_storage, *args, **kwargs):\n        \"\"\"\n        Publishes a message\n        Uses `self.pack` instead of 'msgpack' serializer on kombu for backend consistency\n        \"\"\"\n        if self.connection.connected:\n            message = self.exchange.Message(\n                self.pack(message_type, client_id, client_storage, args, kwargs))\n            self.exchange.publish(message, routing_key='')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self):\n        logger.info(\"Connecting to RabbitMQ on {broker_url}...\".format(\n            broker_url=self.broker_url))\n\n        super(RabbitMQSubscriber, self).connect()\n\n        q = Queue(exchange=self.exchange, exclusive=True, durable=False)\n\n        self.queue = q(self.connection.default_channel)\n        self.queue.declare()\n\n        self.thread = Thread(target=self.listen)\n        self.thread.setDaemon(True)\n        self.thread.start()", "response": "Connects to RabbitMQ and starts listening"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef listen(self):\n        with Consumer(self.connection, queues=self.queue, on_message=self.on_message,\n                      auto_declare=False):\n            for _ in eventloop(self.connection, timeout=1, ignore_timeouts=True):\n                    pass", "response": "Listen to messages in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_message(self, message):\n        message_type, client_id, client_storage, args, kwargs = self.unpack(\n            message.body)\n\n        self.dispatch_message(\n            message_type, client_id, client_storage, args, kwargs)\n\n        message.ack()", "response": "Handles a message from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main_loop(self):\n        while True:\n            for e in pygame.event.get():\n                self.handle_event(e)\n\n            self.step()\n            pygame.time.wait(5)", "response": "Runs the main game loop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_setting_with_envfallback(setting, default=None, typecast=None):\n    try:\n        from django.conf import settings\n    except ImportError:\n        return default\n    else:\n        fallback = getattr(settings, setting, default)\n        value = os.environ.get(setting, fallback)\n        if typecast:\n            value = typecast(value)\n        return value", "response": "Get the given setting and fall back to the default of not found in settings or os. environ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, event_name, *args, **kwargs):\n        for callback in self.callbacks[event_name]:\n            # Handle errors (and maybe return values)\n            callback(*args, **kwargs)", "response": "Method sends an event to all registered callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a list of file locations to the current list", "response": "def add_file_locations(self, file_locations=[]):\n        \"\"\"\n        Adds a list of file locations to the current list\n\n        Args:\n            file_locations: list of file location tuples\n        \"\"\"\n        if not hasattr(self, '__file_locations__'):\n            self.__file_locations__ = copy.copy(file_locations)\n        else:\n            self.__file_locations__ += copy.copy(file_locations)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset(self, **kwargs):\n        self.drop_all(**kwargs)\n        file_locations = self.__file_locations__\n        self.__file_locations__ = []\n        self.load(file_locations, **kwargs)", "response": "Reset the triplestore with all of the data\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, file_locations=[], **kwargs):\n        self.set_load_state(**kwargs)\n        if file_locations:\n            self.__file_locations__ += file_locations\n        else:\n            file_locations = self.__file_locations__\n        conn = self.__get_conn__(**kwargs)\n        if file_locations:\n            log.info(\"Uploading files to conn '%s'\", conn)\n        for item in file_locations:\n            log.info(\"loading '%s\", item)\n            if item[0] == 'directory':\n                self.load_directory(item[1], **kwargs)\n            elif item[0] == 'filepath':\n                kwargs['is_file'] = True\n                self.load_file(item[1],**kwargs)\n            elif item[0].startswith('package'):\n                log.info(\"package: %s\\nspec: %s\",\n                         item[1],\n                         importlib.util.find_spec(item[1]))\n                try:\n                    pkg_path = \\\n                            importlib.util.find_spec(\\\n                                    item[1]).submodule_search_locations[0]\n                except TypeError:\n                    pkg_path = importlib.util.find_spec(item[1]).origin\n                    pkg_path = os.path.split(pkg_path)[0]\n                if item[0].endswith('_all'):\n                    self.load_directory(pkg_path, **kwargs)\n                elif item[0].endswith('_file'):\n                    filepath = os.path.join(pkg_path, item[2])\n                    self.load_file(filepath, **kwargs)\n                else:\n                    raise NotImplementedError\n        self.loaded_files(reset=True)\n        self.loaded_times = self.load_times(**kwargs)", "response": "Loads the file locations into the triplestores\n facility"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_file(self, filepath, **kwargs):\n        log.setLevel(kwargs.get(\"log_level\", self.log_level))\n        filename = os.path.split(filepath)[-1]\n        if filename in self.loaded:\n            if self.loaded_times.get(filename,\n                    datetime.datetime(2001,1,1)).timestamp() \\\n                    < os.path.getmtime(filepath):\n                self.drop_file(filename, **kwargs)\n            else:\n                return\n        conn = self.__get_conn__(**kwargs)\n        conn.load_data(graph=getattr(__NSM__.kdr, filename).clean_uri,\n                       data=filepath,\n                       # log_level=logging.DEBUG,\n                       is_file=True)\n        self.__update_time__(filename, **kwargs)\n        log.warning(\"\\n\\tfile: '%s' loaded\\n\\tconn: '%s'\\n\\tpath: %s\",\n                    filename,\n                    conn,\n                    filepath)\n        self.loaded.append(filename)", "response": "loads a file into the defintion triplestore"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the passed in file from the connected triplestore", "response": "def drop_file(self, filename, **kwargs):\n        \"\"\" removes the passed in file from the connected triplestore\n\n        args:\n            filename: the filename to remove\n        \"\"\"\n        log.setLevel(kwargs.get(\"log_level\", self.log_level))\n        conn = self.__get_conn__(**kwargs)\n        result = conn.update_query(\"DROP GRAPH %s\" % \\\n                                   getattr(__NSM__.kdr, filename).sparql,\n                                   **kwargs)\n        # Remove the load time from the triplestore\n        conn.update_query(\"\"\"\n                DELETE\n                {{\n                   GRAPH {graph} {{ ?file dcterm:modified ?val }}\n                }}\n                WHERE\n                {{\n                    VALUES ?file {{ kdr:{file} }} .\n                    OPTIONAL {{\n                        GRAPH {graph} {{?file dcterm:modified ?val }}\n                    }}\n                }}\"\"\".format(file=filename, graph=\"kdr:load_times\"),\n                **kwargs)\n        self.loaded.remove(filename)\n        log.warning(\"Dropped file '%s' from conn %s\", filename, conn)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the load times for all of the definition files", "response": "def load_times(self, **kwargs):\n        \"\"\" get the load times for the all of the definition files\"\"\"\n        log.setLevel(kwargs.get(\"log_level\", self.log_level))\n        conn = self.__get_conn__(**kwargs)\n        try:\n            result = conn.query(\"\"\"\n                    SELECT ?file ?time\n                    {\n                        graph kdr:load_times {?s ?p ?time} .\n                        bind(REPLACE(str(?s),\n                            \"http://knowledgelinks.io/ns/data-resources/\",\n                            \"\")\n                             as ?file)\n                    }\"\"\", **kwargs)\n            loaded = {item['file']['value']: XsdDatetime(item['time']['value'])\n                      for item in result}\n            self.loaded = list(loaded)\n            self.loaded_times = loaded\n            log.setLevel(self.log_level)\n            return loaded\n        except requests.exceptions.ConnectionError:\n            log.warning(\"connection error with '%s'\", conn)\n            log.setLevel(self.log_level)\n            self.loaded = []\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_directory(self, directory, **kwargs):\n        log.setLevel(kwargs.get(\"log_level\", self.log_level))\n        conn = self.__get_conn__(**kwargs)\n        file_extensions = kwargs.get('file_extensions', conn.rdf_formats)\n        file_list = list_files(directory,\n                               file_extensions,\n                               kwargs.get('include_subfolders', False),\n                               include_root=True)\n        for file in file_list:\n            self.load_file(file[1], **kwargs)\n        log.setLevel(self.log_level)", "response": "loads all rdf files in a directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(fileobj, version=None):\n    magic = fileobj.read(5)\n    if magic[:4] != b\"TZif\":\n        raise ValueError(\"not a zoneinfo file\")\n    if version is None:\n        version = int(magic[4:]) if magic[4] else 0\n    fileobj.seek(20)\n    # Read the counts:\n    # [0] - The number of UT/local indicators stored in the file.\n    # [1] - The number of standard/wall indicators stored in the file.\n    # [2] - The number of leap seconds for which data entries are stored\n    #       in the file.\n    # [3] - The number of transition times for which data entries are\n    #       stored in the file.\n    # [4] - The number of local time types for which data entries are\n    #       stored in the file (must not be zero).\n    # [5] - The number of characters of time zone abbreviation strings\n    #  stored in the file.\n\n    (ttisgmtcnt, ttisstdcnt, leapcnt,\n     timecnt, typecnt, charcnt) = _read_counts(fileobj)\n    if version >= 2:\n        # Skip to the counts in the second header.\n        data_size = (5 * timecnt +\n                     6 * typecnt +\n                     charcnt +\n                     8 * leapcnt +\n                     ttisstdcnt +\n                     ttisgmtcnt)\n        fileobj.seek(data_size + 20, os.SEEK_CUR)\n        # Re-read the counts.\n        (ttisgmtcnt, ttisstdcnt, leapcnt,\n         timecnt, typecnt, charcnt) = _read_counts(fileobj)\n        ttfmt = 'q'\n    else:\n        ttfmt = 'i'\n\n    times = array(ttfmt)\n    times.fromfile(fileobj, timecnt)\n    if sys.byteorder != 'big':\n        times.byteswap()\n\n    type_indices = array('B')\n    type_indices.fromfile(fileobj, timecnt)\n\n    # Read local time types.\n    type_infos = []\n    for i in range(typecnt):\n        type_infos.append(struct.unpack(\">iBB\", fileobj.read(6)))\n\n    abbrs = fileobj.read(charcnt)\n\n    if version > 0:\n        # Skip to POSIX TZ string\n        fileobj.seek(12 * leapcnt + ttisstdcnt + ttisgmtcnt, os.SEEK_CUR)\n        posix_string = fileobj.read().strip().decode('ascii')\n    else:\n        posix_string = None\n\n    # Convert type_infos\n    for i, (gmtoff, isdst, abbrind) in enumerate(type_infos):\n        abbr = abbrs[abbrind:abbrs.find(0, abbrind)].decode()\n        type_infos[i] = (gmtoff, isdst, abbr)\n\n    return TZFileData(version, type_infos, times, type_indices, posix_string)", "response": "Read the TZFileData object from a binary file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert(data):\n    if isinstance(data, unicode):\n        return data.encode('utf-8')\n    elif isinstance(data, str):\n        return data\n    elif isinstance(data, collections.Mapping):\n        return dict(map(convert, data.iteritems()))\n    elif isinstance(data, collections.Iterable):\n        return type(data)(map(convert, data))\n    else:\n        return data", "response": "convert a standalone unicode string or iterable into byte strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_request(request, method, default_headers=None, **kwargs):\n    kwargs = convert(kwargs)\n    if not default_headers:\n        headers = dict(DEFAULT_HEADERS)\n    else:\n        headers = default_headers.copy()\n    if isinstance(request, HTTPRequest):\n        headers.update(request.headers)\n    if 'headers' in kwargs:\n        headers.update(kwargs.pop('headers'))\n    if isinstance(request, HTTPRequest):\n        request.method = method\n        request.headers.update(headers)\n    else:\n        request = HTTPRequest(request, method, headers)\n    if kwargs:\n        if method in ['GET', 'DELETE']:\n            request.url = \"{}?{}\".format(request.url, urllib.urlencode(kwargs))\n        elif method in ['POST', 'PUT']:\n            if request.headers['Content-Type'] == JSON_TYPE:\n                request.body = json.dumps(kwargs)\n            elif 'body' in kwargs:\n                request.body = kwargs['body']\n    return request", "response": "convert parameters into relevant parts of the HTTP request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_response(response):\n    if response.headers.get('Content-Type', JSON_TYPE).startswith(JSON_TYPE):\n        return ResponseObject(json.loads(response.body))\n    else:\n        return response.body", "response": "parse response and return a dictionary if the content type is json or application."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches a resource using the synchronous HTTP client", "response": "def sync_fetch(request, method, default_headers=None,\n               httpclient=None, **kwargs):\n    \"\"\"\n    fetch resource using the synchronous HTTPClient\n    :param request: HTTPRequest object or a url\n    :param method: HTTP method in string format, e.g. GET, POST\n    :param kwargs: query string entities or POST data\n    \"\"\"\n    updated_request = make_request(request, method, default_headers, **kwargs)\n    if not httpclient:\n        httpclient = HTTPClient()\n    rsp = httpclient.fetch(updated_request)\n    return parse_response(rsp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches resource using the asynchronous AsyncHTTPClient", "response": "def async_fetch(request, method, default_headers=None,\n                callback=None, httpclient=None, **kwargs):\n    \"\"\"\n    fetch resource using the asynchronous AsyncHTTPClient\n    :param request: HTTPRequest object or a url\n    :param method: HTTP method in string format, e.g. GET, POST\n    :param callback: callback function on the result. it is used\n    by the coroutine decorator.\n    :param kwargs: query string entities or POST data\n    \"\"\"\n    updated_request = make_request(request, method, default_headers, **kwargs)\n    if not httpclient:\n        httpclient = AsyncHTTPClient()\n    rsp = yield httpclient.fetch(updated_request)\n    raise Return(parse_response(rsp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_fetch_func(base_url, async, **kwargs):\n    if async:\n        client = AsyncHTTPClient(force_instance=True, defaults=kwargs)\n        return partial(async_fetch, httpclient=client)\n    else:\n        client = HTTPClient(force_instance=True, defaults=kwargs)\n        return partial(sync_fetch, httpclient=client)", "response": "make a fetch function based on conditions of\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking an HTTP request.", "response": "def http_resource(self, method, url, params=None, data=None):\n        \"\"\"\n        Makes an HTTP request.\n        \"\"\"\n\n        url = urllib_parse.urljoin(self.url, url)\n        url = url if url.endswith(\"/\") else url + \"/\"\n\n        headers = None\n\n        if method.lower() in self.unsupported_methods:\n            headers = {\"X-HTTP-Method-Override\": method.upper()}\n            method = \"POST\"\n\n        r = self.session.request(method, url, params=params, data=data, headers=headers)\n\n        r.raise_for_status()\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget authentication headers. If we have valid header data already, they immediately return it. If not, then get new authentication data. If we are currently in the process of getting the header data, put this request into a queue to be handled when the data are received. @returns: A deferred that will eventually be called back with the header data", "response": "def _getAuthHeaders(self):\n        \"\"\"\n        Get authentication headers. If we have valid header data already,\n        they immediately return it.\n        If not, then get new authentication data. If we are currently in\n        the process of getting the\n        header data, put this request into a queue to be handled when the\n        data are received.\n\n        @returns: A deferred that will eventually be called back with the\n                  header data\n        \"\"\"\n        def _handleAuthBody(body):\n            self.msg(\"_handleAuthBody: %(body)s\", body=body)\n\n            try:\n                body_parsed = json.loads(body)\n                access_token = body_parsed['access']['token']\n\n                tenant_id = access_token['tenant']['id'].encode('ascii')\n                auth_token = access_token['id'].encode('ascii')\n\n                self.auth_headers[\"X-Tenant-Id\"] = tenant_id\n                self.auth_headers[\"X-Auth-Token\"] = auth_token\n\n                self._state = self.AUTHENTICATED\n\n                self.msg(\"_handleAuthHeaders: found token %(token)s\"\n                         \" tenant id %(tenant_id)s\",\n                         token=self.auth_headers[\"X-Auth-Token\"],\n                         tenant_id=self.auth_headers[\"X-Tenant-Id\"])\n\n                # Callback all queued auth headers requests\n                while not self._headers_requests.empty():\n                    self._headers_requests.get().callback(self.auth_headers)\n\n            except ValueError:\n                # We received a bad response\n                return fail(MalformedJSONError(\"Malformed keystone\"\n                                               \" response received.\"))\n\n        def _handleAuthResponse(response):\n            if response.code == httplib.OK:\n                self.msg(\"_handleAuthResponse: %(response)s accepted\",\n                         response=response)\n                body = Deferred()\n                response.deliverBody(StringIOReceiver(body))\n                body.addCallback(_handleAuthBody)\n                return body\n            else:\n                self.msg(\"_handleAuthResponse: %(response)s rejected\",\n                         response=response)\n                return fail(\n                    KeystoneAuthenticationError(\"Keystone\"\n                                                \" authentication credentials\"\n                                                \" rejected\"))\n\n        self.msg(\"_getAuthHeaders: state is %(state)s\", state=self._state)\n\n        if self._state == self.AUTHENTICATED:\n            # We are authenticated, immediately succeed with the current\n            # auth headers\n            self.msg(\"_getAuthHeaders: succeed with %(headers)s\",\n                     headers=self.auth_headers)\n\n            return succeed(self.auth_headers)\n        elif (self._state == self.NOT_AUTHENTICATED or\n              self._state == self.AUTHENTICATING):\n            # We cannot satisfy the auth header request immediately,\n            # put it in a queue\n            self.msg(\"_getAuthHeaders: defer, place in queue\")\n            auth_headers_deferred = Deferred()\n            self._headers_requests.put(auth_headers_deferred)\n\n            if self._state == self.NOT_AUTHENTICATED:\n                self.msg(\"_getAuthHeaders: not authenticated, start\"\n                         \" authentication process\")\n                # We are not authenticated, and not in the process of\n                # authenticating.\n                # Set our state to AUTHENTICATING and begin the\n                # authentication process\n                self._state = self.AUTHENTICATING\n\n                d = self.agent.request('POST',\n                                       self.auth_url,\n                                       Headers({\n                                           \"Content-type\": [\"application/json\"]\n                                       }),\n                                       self._getAuthRequestBodyProducer())\n                d.addCallback(_handleAuthResponse)\n                d.addErrback(auth_headers_deferred.errback)\n\n            return auth_headers_deferred\n        else:\n            # Bad state, fail\n            return fail(RuntimeError(\"Invalid state encountered.\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(filetypes):\n    def decorator(clazz):\n        for ext in filetypes:\n            checkers.setdefault(ext, []).append(clazz)\n        return clazz\n    return decorator", "response": "Decorator to register a class as a checker for the given filetypes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if all found errors in paths are present.", "response": "def check(self, paths):\n        \"\"\"\n        Return list of error dicts for all found errors in paths.\n\n        The default implementation expects `tool`, and `tool_err_re` to be\n        defined.\n\n        tool: external binary to use for checking.\n        tool_err_re: regexp that can match output of `tool` -- must provide\n            a groupdict with at least \"filename\", \"lineno\", \"colno\",\n            and \"msg\" keys. See example checkers.\n        \"\"\"\n        if not paths:\n            return ()\n\n        cmd_pieces = [self.tool]\n        cmd_pieces.extend(self.tool_args)\n        return self._check_std(paths, cmd_pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the version number of the tool.", "response": "def get_version(cls):\n        \"\"\"\n        Return the version number of the tool.\n        \"\"\"\n        cmd_pieces = [cls.tool, '--version']\n        process = Popen(cmd_pieces, stdout=PIPE, stderr=PIPE)\n        out, err = process.communicate()\n        if err:\n            return ''\n        else:\n            return out.splitlines()[0].strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun command as a check on paths.", "response": "def _check_std(self, paths, cmd_pieces):\n        \"\"\"\n        Run `cmd` as a check on `paths`.\n        \"\"\"\n        cmd_pieces.extend(paths)\n        process = Popen(cmd_pieces, stdout=PIPE, stderr=PIPE)\n        out, err = process.communicate()\n        lines = out.strip().splitlines() + err.strip().splitlines()\n        result = []\n        for line in lines:\n            match = self.tool_err_re.match(line)\n            if not match:\n                if self.break_on_tool_re_mismatch:\n                    raise ValueError(\n                        'Unexpected `%s` output: %r' % (\n                            ' '.join(cmd_pieces),\n                            paths,\n                            line))\n                continue\n            vals = match.groupdict()\n\n            # All tools should at least give us line numbers, but only\n            # some give column numbers.\n            vals['lineno'] = int(vals['lineno'])\n            vals['colno'] = \\\n                int(vals['colno']) if vals['colno'] is not None else ''\n\n            result.append(vals)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and return a string suitable for the rankings field when given tuples of choices and rankings.", "response": "def create_ranking(ranking_tuples):\n        \"\"\"\n        Create and return a string suitable for the rankings\n        field when given tuples of choices and rankings.\n        Parameters:     ranking_tuples should be an iterable\n                            of tuples of form (choice, ranking)\n        \"\"\"\n        return \",\".join([str(r) for c, r in sorted(\n                ranking_tuples,\n                key=lambda x: x[0].pk\n                )])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize_ranking(ranking_tuples):\n        ranking_tuples = sorted(ranking_tuples, key=lambda x: x[1])\n        normalized = [(ranking_tuples.pop(0)[0], 0)]\n        while ranking_tuples:\n            current = ranking_tuples.pop(0)\n            normalized.append((\n                current[0],\n                normalized[-1][1] if current[1] == normalized[-1][1] \\\n                    else normalized[-1][1] + 1,\n                ))\n        return normalized", "response": "Normalizes the ranking of the available resource classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding and replace the special words according to the dictionary.", "response": "def replace(dict,line):\n    \"\"\"\n    Find and replace the special words according to the dictionary.\n\n    Parameters\n    ==========\n    dict : Dictionary\n        A dictionary derived from a yaml file. Source language as keys and the target language as values.\n    line : String\n        A string need to be processed.\n    \"\"\"\n    words = line.split()\n    new_line = \"\"\n\n    for word in words:\n        fst = word[0]\n        last = word[-1]\n        # Check if the word ends with a punctuation\n        if last == \",\" or last == \";\" or last == \".\":\n            clean_word = word[0:-1]\n            last = last + \" \"\n        elif last == \"]\":\n            clean_word = word[0:-1]\n        else:\n            clean_word = word\n            last = \" \"\n\n        # Check if the word starts with \"[\"\n        if fst == \"[\":\n            clean_word = clean_word[1:]\n        else:\n            clean_word = clean_word\n            fst = \"\"\n\n        find = dict.get(clean_word)\n\n        if find == None:\n            new_line = new_line + fst + str(clean_word) + last\n        else:\n            new_line = new_line + fst + str(find) + last\n            \n    return new_line"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntranslates a source file to a destination file in the selected language.", "response": "def translate(src_filename, dest_filename, dest_lang, src_lang='auto', specialwords_filename=''):\n    \"\"\"\n    Converts a source file to a destination file in the selected language.\n\n    Parameters\n    ==========\n    src_filename : String\n        Relative file path to the original MarkDown source file.\n    dest_filename : String\n        Relative file path to where the translated MarkDown file should go.\n    dest_lang : String\n        The language of the destination file. Must be the correct 2-letter ISO-639-1 abbreviation from https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n    src_lang : String (OPTIONAL)\n        The language of the source file. Only needed if the source file contains multiple languages. Like dest_lang, must be the correct ISO-639-1 abbreviation from https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n    specialwords_filename : String (OPTIONAL)\n        YAML file containing special translations of words. Must map a string of the translation direction (e.g. 'en_es') to a sequence of specially translated words.\n\n    Examples\n    ========\n    Suppose you have the following directory in English:\n    data/\n        doc_en.md\n        special.yaml\n\n    special.yaml is organized as follows:\n    en_es:\n      - tank : bote #TODO: add more/better translation examples\n\n    To translate it to Spanish:\n    >>> from aide_document import translate\n    >>> translate.translate('data/doc_en.md', 'data/doc_es.md', 'es', 'en', 'data/special.yaml')\n\n    The 4th parameter can be omitted if the source file has only one language, and the 5th can be omitted if there are no special translations.\n    \"\"\"\n    translator = Translator() # Initialize translator object\n\n    with open(src_filename) as srcfile, open(dest_filename, 'w') as destfile:\n\n        lines = srcfile.readlines()\n        specialwords_dict = {}\n\n        # If special words file exists, place special word mappings into specialwords_dict\n        if specialwords_filename != '':\n            with yaml.load(open(specialwords_filename)) as specialwords_fulllist:\n\n                # Gets source language if not passed through\n                if src_lang == 'auto':\n                    src_lang == str(translator.detect(lines[0]))[14:16]\n\n                # Attempts to add the correct dictionary of special words\n                try:\n                    specialwords_dict = specialwords_dict_full[src_lang + '_' + dest_lang]\n                except KeyError:\n                    print('Special words file doesn\\'t contain required language translation!')\n\n        # Parses each line for special cases and ignores them when translating\n        for line in lines:\n            line = line.strip()\n\n            # Parses for code blocks and ignores them entirely\n            if line.startswith(\"```\"):\n                line = line\n\n            else:\n                # Parses for URL's and file links and ignores them\n                if line.find(\"[\") != -1 and line.find(\"]\") != -1 and line.find(\"(\") != -1 and line.find(\")\") != -1:\n                    ignore_start = line.find(\"(\")\n                    ignore_end = line.find(\")\")\n                    head = replace(specialwords_dict,line[0:ignore_start])\n                    tail = replace(specialwords_dict,line[ignore_end+1:])\n                    head = translator.translate(head, dest_lang, src_lang).text\n                    tail = translator.translate(tail, dest_lang, src_lang).text\n                    line = head + line[ignore_start:ignore_end+1] + tail\n\n                # Translates normally if there are no special cases\n                else:\n                    line = translator.translate(line, dest_lang, src_lang).text\n\n            # Write to destination file\n            destfile.write(line + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_config(args):\n    options, _ = defaults.DEFAULT_OPTIONS.parse(args, ignore_errors=True)\n    read_config = not options.skip_default_config\n    cfg = CoverageReporterConfig(read_config)\n    for path in options.config_file:\n        cfg.read(path)\n    cfg.plugin_dirs.extend(options.plugin_dir)\n    cfg.plugins.extend(options.plugin)\n    return cfg", "response": "Method to get the correct configuration file for a set of command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a date return a datetime object that is the first day of the month.", "response": "def start_of_month(dt, d_years=0, d_months=0):\n    \"\"\"\n    Given a date, return a date first day of the month.\n    \n    @param dt: The date to base the return value upon.\n    @param d_years: Specify a delta in years to apply to date.\n    @param d_months: Specify a delta in months to apply to date.\n    \n    @see http://code.activestate.com/recipes/476197-first-last-day-of-the-month/\n    \"\"\"\n    y, m = dt.year + d_years, dt.month + d_months\n    a, m = divmod(m-1, 12)\n    return datetime(y+a, m+1, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn start and stop datetime for the quarter as defined by dt.", "response": "def quarter(dt):\n    \"\"\"\n    Return start/stop datetime for the quarter as defined by dt.\n    \"\"\"\n    quarters = rrule.rrule(\n       rrule.MONTHLY,\n       bymonth = (1, 4, 7, 10),\n       bysetpos = -1,\n       dtstart = datetime(dt.year, 1, 1),\n       count = 8\n    )\n    first_day = quarters.before(dt, True)\n    last_day = quarters.after(dt) - relativedelta.relativedelta(days=1)\n    return (first_day, last_day)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecorate a function object as deprecated.", "response": "def deprecated(f):\n    \"\"\"Decorate a function object as deprecated.\n\n    Work nicely with the @command and @subshell decorators.\n\n    Add a __deprecated__ field to the input object and set it to True.\n    \"\"\"\n    def inner_func(*args, **kwargs):\n        print(textwrap.dedent(\"\"\"\\\n                This command is deprecated and is subject to complete\n                removal at any later version without notice.\n                \"\"\"))\n        f(*args, **kwargs)\n    inner_func.__deprecated__ = True\n    inner_func.__doc__ = f.__doc__\n    inner_func.__name__ = f.__name__\n    if iscommand(f):\n        inner_func.__command__ = f.__command__\n    return inner_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef command(*commands, visible = True, internal = False, nargs = '*'):\n    # Strict checking of the nargs argument.\n    allowed_strs = {'*', '?', '+'}\n    err_str = textwrap.dedent('''\\\n            command: '{}' is invalid, must be a non-negative integer, a\n            list/set/tuple/range of non-negative integer, or one of {}\n            '''.format(nargs, allowed_strs))\n    if isinstance(nargs, str):\n        if not nargs in allowed_strs:\n            raise RuntimeError(err_str)\n    elif isinstance(nargs, int):\n        if nargs < 0:\n            raise RuntimeError(err_str)\n    else:\n        nargs = list(nargs)\n        for ele in nargs:\n            if not isinstance(ele, int) or ele < 0:\n                raise RuntimeError(err_str)\n\n    def decorated_func(f):\n        def inner_func(self, cmd, args):\n            # Check the number of args according to nargs.\n            n = len(args)\n            if isinstance(nargs, str):\n                if nargs == '*':\n                    pass\n                elif nargs == '?':\n                    if n > 1:\n                        self.error(\"{}: expect 0 or 1 argument, provided {}: {}\\n\".\n                                format(cmd, n, args))\n                        return\n                elif nargs == '+':\n                    if n == 0:\n                        self.error(\"{}: expect 1 or more arguments, provided {}: {}\\n\".\n                                format(cmd, n, args))\n                        return\n            elif isinstance(nargs, int):\n                if n != nargs:\n                        self.error(\"{}: expect {} arguments, provided {}: {}\\n\".\n                                format(cmd, nargs, n, args))\n                        return\n            else:\n                # nargs is already converted to a list.\n                if not n in nargs:\n                        self.error(\"{}: the number of arguments could be one of \"\n                                \"{}, provided {}: {}\\n\".\n                                format(cmd, nargs, n, args))\n                        return\n            return f(self, cmd, args)\n        inner_func.__name__ = f.__name__\n        inner_func.__doc__ = f.__doc__\n        inner_func.__command__ = {\n                'commands': list(commands),\n                'visible': visible,\n                'internal': internal,\n        }\n        # If f is deprecated, inner_func should also be deprecated. Do not use\n        # the deprecated() function directly, as that adds duplicate warning\n        # message.\n        if isdeprecated(f):\n            inner_func.__deprecated__ = True\n        return inner_func\n    return decorated_func", "response": "Decorator for the command methods."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecorates a function to be the helper function of commands. Arguments: commands: Names of command that should trigger this function object. --------------------------- Interface of helper methods: @helper('some-command') def help_foo(self, args): ''' Arguments: args: A list of arguments. Returns: A string that is the help message. ''' pass", "response": "def helper(*commands):\n    \"\"\"Decorate a function to be the helper function of commands.\n\n    Arguments:\n        commands: Names of command that should trigger this function object.\n\n    ---------------------------\n    Interface of helper methods:\n\n        @helper('some-command')\n        def help_foo(self, args):\n            '''\n            Arguments:\n                args: A list of arguments.\n\n            Returns:\n                A string that is the help message.\n            '''\n            pass\n    \"\"\"\n    def decorated_func(f):\n        f.__help_targets__ = list(commands)\n        return f\n    return decorated_func"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef completer(*commands):\n    def decorated_func(f):\n        f.__complete_targets__ = list(commands)\n        return f\n    return decorated_func", "response": "Decorate a function to be the completer function of commands."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecorate a function to conditionally launch a subshell.", "response": "def subshell(shell_cls, *commands, **kwargs):\n    \"\"\"Decorate a function to conditionally launch a _ShellBase subshell.\n\n    Arguments:\n        shell_cls: A subclass of _ShellBase to be launched.\n        commands: Names of command that should trigger this function object.\n        kwargs: The keyword arguments for the command decorator method.\n\n    -----------------------------\n    Interface of methods decorated by this decorator method:\n\n        @command(SomeShellClass, 'foo', 'bar')\n        def bar(self, cmd, args):\n            '''The command 'foo' invokes this method then launches the subshell.\n\n            Arguments:\n                cmd: A string, the name of the command that triggered this\n                    function. This is useful for knowing which command, in this\n                    case, 'foo' or 'bar', triggered this method.\n                args: The list of arguments passed along with the command.\n\n            Returns:\n                There are three categories of valid return values.\n                    None, False, or anything that evaluates to False: The\n                        subshell is not invoked. This is useful for making a\n                        command conditionally launch a subshell.\n                    String: A string will appended to the prompt string to\n                        uniquely identify the subshell.\n                    A 2-tuple of type (string, dict): The string will be\n                        appended to the prompt string. The dictionary stores the\n                        data passed to the subshell. These data are the context\n                        of the subshell. The parent shell must conform to the\n                        subhshell class in terms of which key-value pairs to\n                        pass to the subshell.\n            '''\n            pass\n    \"\"\"\n    def decorated_func(f):\n        def inner_func(self, cmd, args):\n            retval = f(self, cmd, args)\n            # Do not launch the subshell if the return value is None.\n            if not retval:\n                return\n            # Pass the context (see the doc string) to the subshell if the\n            # return value is a 2-tuple. Otherwise, the context is just an empty\n            # dictionary.\n            if isinstance(retval, tuple):\n                prompt, context = retval\n            else:\n                prompt = retval\n                context = {}\n            return self.launch_subshell(shell_cls, cmd, args,\n                    prompt = prompt, context = context)\n        inner_func.__name__ = f.__name__\n        inner_func.__doc__ = f.__doc__\n        obj = command(*commands, **kwargs)(inner_func) if commands else inner_func\n        obj.__launch_subshell__ = shell_cls\n        return obj\n    return decorated_func"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the doc string of this class.", "response": "def doc_string(cls):\n        \"\"\"Get the doc string of this class.\n\n        If this class does not have a doc string or the doc string is empty, try\n        its base classes until the root base class, _ShellBase, is reached.\n\n        CAVEAT:\n            This method assumes that this class and all its super classes are\n            derived from _ShellBase or object.\n        \"\"\"\n        clz = cls\n        while not clz.__doc__:\n            clz = clz.__bases__[0]\n        return clz.__doc__"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef launch_subshell(self, shell_cls, cmd, args, *, prompt = None, context =\n            {}):\n        \"\"\"Launch a subshell.\n\n        The doc string of the cmdloop() method explains how shell histories and\n        history files are saved and restored.\n\n        The design of the _ShellBase class encourage launching of subshells through\n        the subshell() decorator function. Nonetheless, the user has the option\n        of directly launching subshells via this method.\n\n        Arguments:\n            shell_cls: The _ShellBase class object to instantiate and launch.\n            args: Arguments used to launch this subshell.\n            prompt: The name of the subshell. The default, None, means\n                to use the shell_cls.__name__.\n            context: A dictionary to pass to the subshell as its context.\n\n        Returns:\n            'root': Inform the parent shell to keep exiting until the root shell\n                is reached.\n            'all': Exit the the command line.\n            False, None, or anything that are evaluated as False: Inform the\n                parent shell to stay in that parent shell.\n            An integer indicating the depth of shell to exit to. 0 = root shell.\n        \"\"\"\n        # Save history of the current shell.\n        readline.write_history_file(self.history_fname)\n\n        prompt = prompt if prompt else shell_cls.__name__\n        mode = _ShellBase._Mode(\n                shell = self,\n                cmd = cmd,\n                args = args,\n                prompt = prompt,\n                context = context,\n        )\n        shell = shell_cls(\n                batch_mode = self.batch_mode,\n                debug = self.debug,\n                mode_stack = self._mode_stack + [ mode ],\n                pipe_end = self._pipe_end,\n                root_prompt = self.root_prompt,\n                stdout = self.stdout,\n                stderr = self.stderr,\n                temp_dir = self._temp_dir,\n        )\n        # The subshell creates its own history context.\n        self.print_debug(\"Leave parent shell '{}'\".format(self.prompt))\n        exit_directive = shell.cmdloop()\n        self.print_debug(\"Enter parent shell '{}': {}\".format(self.prompt, exit_directive))\n\n        # Restore history. The subshell could have deleted the history file of\n        # this shell via 'history clearall'.\n        readline.clear_history()\n        if os.path.isfile(self.history_fname):\n            readline.read_history_file(self.history_fname)\n\n        if not exit_directive is True:\n            return exit_directive", "response": "Launch a subshell.\n\n        The doc string of the cmdloop() method explains how shell histories and\n        history files are saved and restored.\n\n        The design of the _ShellBase class encourage launching of subshells through\n        the subshell() decorator function. Nonetheless, the user has the option\n        of directly launching subshells via this method.\n\n        Arguments:\n            shell_cls: The _ShellBase class object to instantiate and launch.\n            args: Arguments used to launch this subshell.\n            prompt: The name of the subshell. The default, None, means\n                to use the shell_cls.__name__.\n            context: A dictionary to pass to the subshell as its context.\n\n        Returns:\n            'root': Inform the parent shell to keep exiting until the root shell\n                is reached.\n            'all': Exit the the command line.\n            False, None, or anything that are evaluated as False: Inform the\n                parent shell to stay in that parent shell.\n            An integer indicating the depth of shell to exit to. 0 = root shell."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a string in batch mode.", "response": "def batch_string(self, content):\n        \"\"\"Process a string in batch mode.\n\n        Arguments:\n            content: A unicode string representing the content to be processed.\n        \"\"\"\n        pipe_send, pipe_recv = multiprocessing.Pipe()\n        self._pipe_end = pipe_recv\n        proc = multiprocessing.Process(target = self.cmdloop)\n        for line in content.split('\\n'):\n            pipe_send.send(line)\n        pipe_send.close()\n        proc.start()\n        proc.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the main loop of the interactive shell.", "response": "def cmdloop(self):\n        \"\"\"Start the main loop of the interactive shell.\n\n        The preloop() and postloop() methods are always run before and after the\n        main loop, respectively.\n\n        Returns:\n            'root': Inform the parent shell to to keep exiting until the root\n                shell is reached.\n            'all': Exit all the way back the the command line shell.\n            False, None, or anything that are evaluated as False: Exit this\n                shell, enter the parent shell.\n            An integer: The depth of the shell to exit to. 0 = root shell.\n\n        History:\n\n            _ShellBase histories are persistently saved to files, whose name matches\n            the prompt string. For example, if the prompt of a subshell is\n            '(Foo-Bar-Kar)$ ', the name of its history file is s-Foo-Bar-Kar.\n            The history_fname property encodes this algorithm.\n\n            All history files are saved to the the directory whose path is\n            self._temp_dir. Subshells use the same temp_dir as their parent\n            shells, thus their root shell.\n\n            The history of the parent shell is saved and restored by the parent\n            shell, as in launch_subshell(). The history of the subshell is saved\n            and restored by the subshell, as in cmdloop().\n\n            When a subshell is started, i.e., when the cmdloop() method of the\n            subshell is called, the subshell will try to load its own history\n            file, whose file name is determined by the naming convention\n            introduced earlier.\n\n        Completer Delimiters:\n\n            Certain characters such as '-' could be part of a command. But by\n            default they are considered the delimiters by the readline library,\n            which causes completion candidates with those characters to\n            malfunction.\n\n            The old completer delimiters are saved before the loop and restored\n            after the loop ends. This is to keep the environment clean.\n        \"\"\"\n        self.print_debug(\"Enter subshell '{}'\".format(self.prompt))\n\n        # Save the completer function, the history buffer, and the\n        # completer_delims.\n        old_completer = readline.get_completer()\n        old_delims = readline.get_completer_delims()\n        new_delims = ''.join(list(set(old_delims) - set(_ShellBase._non_delims)))\n        readline.set_completer_delims(new_delims)\n\n        # Load the new completer function and start a new history buffer.\n        readline.set_completer(self.__driver_stub)\n        readline.clear_history()\n        if os.path.isfile(self.history_fname):\n            readline.read_history_file(self.history_fname)\n\n        # main loop\n        try:\n            # The exit_directive:\n            #       True        Leave this shell, enter the parent shell.\n            #       False       Continue with the loop.\n            #       'root'      Exit to the root shell.\n            #       'all'       Exit to the command line.\n            #       an integer  The depth of the shell to exit to. 0 = root\n            #                   shell. Negative number is taken as error.\n            self.preloop()\n            while True:\n                exit_directive = False\n                try:\n                    if self.batch_mode:\n                        line = self._pipe_end.recv()\n                    else:\n                        line = input(self.prompt).strip()\n                except EOFError:\n                    line = _ShellBase.EOF\n\n                try:\n                    exit_directive = self.__exec_line__(line)\n                except:\n                    self.stderr.write(traceback.format_exc())\n\n                if type(exit_directive) is int:\n                    if len(self._mode_stack) > exit_directive:\n                        break\n                    if len(self._mode_stack) == exit_directive:\n                        continue\n                if self._mode_stack and exit_directive == 'root':\n                    break\n                if exit_directive in { 'all', True, }:\n                    break\n        finally:\n            self.postloop()\n            # Restore the completer function, save the history, and restore old\n            # delims.\n            readline.set_completer(old_completer)\n            readline.write_history_file(self.history_fname)\n            readline.set_completer_delims(old_delims)\n\n        self.print_debug(\"Leave subshell '{}': {}\".format(self.prompt, exit_directive))\n\n        return exit_directive"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_line(self, line):\n        toks = shlex.split(line)\n        # Safe to index the 0-th element because this line would have been\n        # parsed by __exec_line__ if toks is an empty list.\n        return ( toks[0], [] if len(toks) == 1 else toks[1:] )", "response": "Parse a line of input."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __driver_stub(self, text, state):\n        origline = readline.get_line_buffer()\n        line = origline.lstrip()\n        if line and line[-1] == '?':\n            self.__driver_helper(line)\n        else:\n            toks = shlex.split(line)\n            return self.__driver_completer(toks, text, state)", "response": "Display help messages or invoke the proper completer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __driver_completer(self, toks, text, state):\n        if state != 0:\n            return self.__completion_candidates[state]\n\n        # Update the cache when this method is first called, i.e., state == 0.\n\n        # If the line is empty or the user is still inputing the first token,\n        # complete with available commands.\n        if not toks or (len(toks) == 1 and text == toks[0]):\n            try:\n                self.__completion_candidates = self.__complete_cmds(text)\n            except:\n                self.stderr.write('\\n')\n                self.stderr.write(traceback.format_exc())\n                self.__completion_candidates = []\n            return self.__completion_candidates[state]\n\n        # Otherwise, try to complete with the registered completer method.\n        cmd = toks[0]\n        args = toks[1:] if len(toks) > 1 else None\n        if text and args:\n            del args[-1]\n        if cmd in self._completer_map.keys():\n            completer_name = self._completer_map[cmd]\n            completer_method = getattr(self, completer_name)\n            try:\n                self.__completion_candidates = completer_method(cmd, args, text)\n            except:\n                self.stderr.write('\\n')\n                self.stderr.write(traceback.format_exc())\n                self.__completion_candidates = []\n        else:\n            self.__completion_candidates = []\n\n        return self.__completion_candidates[state]", "response": "Driver level completer.\n\n        Arguments:\n            toks: A list of tokens, tokenized from the original input line.\n            text: A string, the text to be replaced if a completion candidate is\n                chosen.\n            state: An integer, the index of the candidate out of the list of\n                candidates.\n\n        Returns:\n            A string, the candidate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __complete_cmds(self, text):\n        return [ name for name in self._cmd_map_visible.keys() if name.startswith(text) ]", "response": "Get the list of commands whose names start with a given text."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite help message to file.", "response": "def __get_help_message(self, toks):\n        \"\"\"Write help message to file.\n\n        Only called by the __driver_helper() method.\n\n        Looks for the help message in the following order:\n\n            1.  The helper method registered with this command via the @helper\n                decorator.\n            2.  The doc string of the registered method.\n            3.  A default help message basically saying 'no help found'.\n\n        Arguments:\n            toks: The list of command followed by its arguments.\n\n        Returns:\n            The help message.\n\n        Raises:\n             As this function is called via the readline complete callback, any\n             errors and exceptions are silently ignored.\n        \"\"\"\n        cmd = toks[0]\n        if cmd in self._helper_map.keys():\n            helper_name = self._helper_map[cmd]\n            helper_method = getattr(self, helper_name)\n            args = toks[1:] if len(toks) > 1 else []\n            return helper_method(cmd, args)\n\n        if cmd in self._cmd_map_all.keys():\n            name = self._cmd_map_all[cmd]\n            method = getattr(self, name)\n            if method.__doc__:\n                return textwrap.dedent(method.__doc__)\n\n        return textwrap.dedent('''\\\n                       No help message is found for:\n                       {}\n                       '''.format(textwrap.indent(\n                           subprocess.list2cmdline(toks), '    ')))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __build_cmd_maps(cls):\n        cmd_map_all = {}\n        cmd_map_visible = {}\n        cmd_map_internal = {}\n        for name in dir(cls):\n            obj = getattr(cls, name)\n            if iscommand(obj):\n                for cmd in getcommands(obj):\n                    if cmd in cmd_map_all.keys():\n                        raise PyShellError(\"The command '{}' already has cmd\"\n                                           \" method '{}', cannot register a\"\n                                           \" second method '{}'.\".format( \\\n                                                    cmd, cmd_map_all[cmd], obj.__name__))\n                    cmd_map_all[cmd] = obj.__name__\n                    if isvisiblecommand(obj):\n                        cmd_map_visible[cmd] = obj.__name__\n                    if isinternalcommand(obj):\n                        cmd_map_internal[cmd] = obj.__name__\n        return cmd_map_all, cmd_map_visible, cmd_map_internal", "response": "Build the mapping from command names to method names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __build_helper_map(cls):\n        ret = {}\n        for name in dir(cls):\n            obj = getattr(cls, name)\n            if ishelper(obj):\n                for cmd in obj.__help_targets__:\n                    if cmd in ret.keys():\n                        raise PyShellError(\"The command '{}' already has helper\"\n                                           \" method '{}', cannot register a\"\n                                           \" second method '{}'.\".format( \\\n                                                    cmd, ret[cmd], obj.__name__))\n                    ret[cmd] = obj.__name__\n        return ret", "response": "Build a mapping from command names to helper names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a mapping from command names to completer names.", "response": "def __build_completer_map(cls):\n        \"\"\"Build a mapping from command names to completer names.\n\n        One command name maps to at most one completer method.\n        Multiple command names can map to the same completer method.\n\n        Only used by __init__() to initialize self._cmd_map. MUST NOT be used\n        elsewhere.\n\n        Raises:\n            PyShellError: A command maps to multiple helper methods.\n        \"\"\"\n        ret = {}\n        for name in dir(cls):\n            obj = getattr(cls, name)\n            if iscompleter(obj):\n                for cmd in obj.__complete_targets__:\n                    if cmd in ret.keys():\n                        raise PyShellError(\"The command '{}' already has\"\n                                           \" complter\"\n                                           \" method '{}', cannot register a\"\n                                           \" second method '{}'.\".format( \\\n                                                    cmd, ret[cmd], obj.__name__))\n                    ret[cmd] = obj.__name__\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef operator_same_class(method):\n    def wrapper(self, other):\n        if not isinstance(other, self.__class__):\n            raise TypeError(\n                'unsupported operand types: \\'{0}\\' and \\'{1}\\''.format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return method(self, other)\n    return wrapper", "response": "Decorator that ensures the other parameter is of the same type as the self parameter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nintend to wrap operator methods, this decorator ensures a numeric type was passed. :param method: The method being decorated. :return: The wrapper to replace the method with.", "response": "def operator_numeric_type(method):\n    \"\"\"\n    Intended to wrap operator methods, this decorator ensures a numeric type\n    was passed.\n    \n    :param method: The method being decorated.\n    :return: The wrapper to replace the method with.\n    \"\"\"\n    def wrapper(self, other):\n        if not isinstance(other, _NUMERIC_TYPES):\n            raise TypeError(\n                'unsupported operand types: \\'{0}\\' and \\'{1}\\''.format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return method(self, other)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef python_2_format_compatible(method):\n    if six.PY3:\n        return method\n\n    def wrapper(self, format_spec):\n        formatted = method(self, format_spec)\n        if isinstance(format_spec, str):\n            # bytestring\n            return formatted.encode('utf-8')\n\n        # unicode\n        return formatted\n    return wrapper", "response": "A wrapper for the __format__ method in the order that they are in Python 2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef python_2_nonzero_compatible(klass):\n    if six.PY2:\n        if '__bool__' not in klass.__dict__:\n            raise ValueError(\n                '@python_2_nonzero_compatible cannot be applied to {0} because '\n                'it doesn\\'t define __bool__().'.format(klass.__name__))\n        klass.__nonzero__ = klass.__bool__\n    return klass", "response": "A class decorator that can be used to modify the class with __nonzero__."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a `__div__()` method to classes that define a `__floordiv__()` method, so division works in Python 2. Has no effect in Python 3. :param klass: The class to modify. Must define `__floordiv__()`. :return: The possibly patched class.", "response": "def python_2_div_compatible(klass):\n    \"\"\"\n    Adds a `__div__()` method to classes that define a `__floordiv__()` method,\n    so division works in Python 2. Has no effect in Python 3.\n\n    :param klass: The class to modify. Must define `__floordiv__()`.\n    :return: The possibly patched class.\n    \"\"\"\n    if six.PY2:\n        if '__floordiv__' not in klass.__dict__:\n            raise ValueError(\n                '@python_2_div_compatible cannot be applied to {0} because it '\n                'doesn\\'t define __floordiv__().'.format(klass.__name__))\n        klass.__div__ = klass.__floordiv__\n    return klass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind a review score from a given reviewer to a product.", "response": "def review_score(self, reviewer, product):\n        \"\"\"Find a review score from a given reviewer to a product.\n\n        Args:\n          reviewer: Reviewer i.e. an instance of :class:`ria.bipartite.Reviewer`.\n          product: Product i.e. an instance of :class:`ria.bipartite.Product`.\n\n        Returns:\n          A review object representing the review from the reviewer to the product.\n        \"\"\"\n        return self._g.retrieve_review(reviewer, product).score"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the dict as a model", "response": "def from_dict(cls: typing.Type[T], dikt) -> T:\n        \"\"\"Returns the dict as a model\"\"\"\n        return util.deserialize_model(dikt, cls)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_defs(self, cache=True):\n\n        log.debug(\" *** Started\")\n        cache = self.__use_cache__(cache)\n        if cache:\n            log.info(\" loading json cache\")\n            try:\n                with open(self.cache_filepath) as file_obj:\n                    self.results = json.loads(file_obj.read())\n            except FileNotFoundError:\n                self.results = []\n        if not cache or len(self.results) == 0:\n            log.info(\" NO CACHE, querying the triplestore\")\n            sparql = render_without_request(self.def_sparql,\n                                            graph=self.conn.graph,\n                                            prefix=self.nsm.prefix())\n            start = datetime.datetime.now()\n            log.info(\" Starting query\")\n            self.results = self.conn.query(sparql)\n            log.info(\"query complete in: %s | %s triples retrieved.\",\n                     (datetime.datetime.now() - start),\n                     len(self.results))\n            with open(self.cache_filepath, \"w\") as file_obj:\n                file_obj.write(json.dumps(self.results, indent=4))\n            with open(self.loaded_filepath, \"w\") as file_obj:\n                file_obj.write((json.dumps(self.conn.mgr.loaded)))", "response": "Gets the defitions of the current node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef conv_defs(self):\n\n        log.setLevel(self.log_level)\n        start = datetime.datetime.now()\n        log.debug(\" Converting to a Dataset: %s Triples\", len(self.results))\n        self.defs = RdfDataset(self.results,\n                               def_load=True,\n                               bnode_only=True)\n\n        # self.cfg.__setattr__('rdf_prop_defs', self.defs, True)\n        log.debug(\" conv complete in: %s\" % (datetime.datetime.now() - start))", "response": "Reads through the JSON object and converts them to a Dataset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make(self):\n        log.setLevel(self.log_level)\n        created = []\n        prop_list = [item for item in self.defs if item.type == 'uri']\n        log.debug(\" creating properties ... \")\n        for prop in prop_list:\n            make_property(self.defs[prop], prop, [])\n        log.info(\" property count: %s\", len(prop_list))", "response": "reads through the definitions and generates a python class for each resource class"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new class for each entry in the class_dict", "response": "def make(self):\n        \"\"\" reads through the definitions and generates an python class for each\n        definition \"\"\"\n        log.setLevel(self.log_level)\n        created = []\n        self.set_class_dict()\n        start = datetime.datetime.now()\n        log.info(\" # of classes to create: %s\" % len(self.class_dict))\n        log.debug(\" creating classes that are not subclassed\")\n\n        for name, cls_defs in self.class_dict.items():\n            # if name in ['bf_Organization', 'bf_Agent']:\n            #     pdb.set_trace()\n            if not self.class_dict[name].get('rdfs_subClassOf'):\n                created.append(name)\n                setattr(MODULE.rdfclass,\n                        name,\n                        types.new_class(name,\n                                        (RdfClassBase,),\n                                        {#'metaclass': RdfClassMeta,\n                                         'cls_defs': cls_defs}))\n        log.debug(\" created %s classes in: %s\",\n                  len(created),\n                  (datetime.datetime.now() - start))\n        for name in created:\n            del self.class_dict[name]\n        left = len(self.class_dict)\n        classes = []\n        while left > 0:\n            new = []\n            for name, cls_defs in self.class_dict.items():\n                # if name in ['bf_Organization', 'bf_Agent']:\n                    # pdb.set_trace()\n                parents = self.class_dict[name].get('rdfs_subClassOf')\n                if not parents:\n                    bases += (RdfClassBase, )\n                else:\n                    for parent in make_list(parents):\n                        bases = tuple()\n                        if parent in created or parent in classes:\n                            if parent in classes:\n                                bases += (RdfClassBase, )\n                            else:\n                                base = getattr(MODULE.rdfclass, parent)\n                                bases += (base,) + base.__bases__\n                if len(bases) > 0:\n                    created.append(name)\n                    setattr(MODULE.rdfclass,\n                            name,\n                            types.new_class(name,\n                                            bases,\n                                            {#'metaclass': RdfClassMeta,\n                                             'cls_defs': cls_defs}))\n            for name in created:\n                try:\n                    del self.class_dict[name]\n                except KeyError:\n                    pass\n            if left == len(self.class_dict):\n                # c_list = [self.class_dict[name].get('rdfs_subClassOf') \\\n                #           for name in self.class_dict]\n                missing_parents = []\n                for name in self.class_dict:\n                    missing_parents += \\\n                            self.class_dict[name].get('rdfs_subClassOf', [])\n                missing_parents = set(missing_parents)\n                still_valid = set([name for name in self.class_dict\n                                   if name not in missing_parents])\n                classes = list(missing_parents.difference(\\\n                            set(self.class_dict.keys())))\n                # classess = []\n                # for cl in c_list:\n                #     for item in cl:\n                #         classes.append(item)\n\n                for name in self.class_dict:\n                    if name in classes:\n                        classes.remove(name)\n                    for p_name in self.class_dict[name].get('rdfs_subClassOf',\n                                                            []).copy():\n                        if p_name in classes:\n                            self.class_dict[name]['rdfs_subClassOf'].remove(\\\n                                    p_name)\n                # pdb.set_trace()\n            left = len(self.class_dict)\n        # self.tie_properties(created)\n        log.info(\" created all classes in %s\",\n                 (datetime.datetime.now() - start))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads through the dataset and assigns the class_dict the key value pairs for the classes in the dataset.", "response": "def set_class_dict(self):\n        \"\"\" Reads through the dataset and assigns self.class_dict the key value\n            pairs for the classes in the dataset\n        \"\"\"\n\n        self.class_dict = {}\n        for name, cls_defs in self.defs.items():\n            def_type = set(cls_defs.get(self.rdf_type, []))\n            if name.type == 'bnode':\n                continue\n            # a class can be determined by checking to see if it is of an\n            # rdf_type listed in the classes_key or has a property that is\n            # listed in the inferred_key\n            if def_type.intersection(self.classes_key) or \\\n                    list([cls_defs.get(item) for item in self.inferred_key]):\n                self.class_dict[name] = cls_defs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning through the classess and ties the properties to the class", "response": "def tie_properties(self, class_list):\n        \"\"\" Runs through the classess and ties the properties to the class\n\n        args:\n            class_list: a list of class names to run\n        \"\"\"\n        log.setLevel(self.log_level)\n        start = datetime.datetime.now()\n        log.info(\" Tieing properties to the class\")\n        for cls_name in class_list:\n            cls_obj = getattr(MODULE.rdfclass, cls_name)\n            prop_dict = dict(cls_obj.properties)\n            for prop_name, prop_obj in cls_obj.properties.items():\n                setattr(cls_obj, prop_name, link_property(prop_obj, cls_obj))\n        log.info(\" Finished tieing properties in: %s\",\n                 (datetime.datetime.now() - start))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef julian_day(year, n):\n    if n > 59 and isleap(year):\n        n += 1\n    return datetime(year, 1, 1) + timedelta(n - 1)", "response": "Return the Julian day n in a given year."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dth_day_of_week_n(y, m, n, d):\n    if n == 5:\n        # Compute the last dow of the month.\n        y, m = next_month(y, m)\n        dt = datetime(y, m, 1) - timedelta(1)\n        # Move back to the given dow.\n        dt -= timedelta((dt.weekday() - d + 1) % 7)\n    else:\n        dt = datetime(y, m, 1)\n        dt += timedelta((d - dt.weekday() - 1) % 7 + 7 * (n - 1))\n    return dt", "response": "Return the next day of the week n of month m of the year d."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromutc(self, dt):\n\n        if not isinstance(dt, datetime):\n            raise TypeError(\"fromutc() requires a datetime argument\")\n        if dt.tzinfo is not self:\n            raise ValueError(\"dt.tzinfo is not self\")\n        dt = dt.replace(tzinfo=None)\n        if dt > self.posix_after:\n            dt = self.posix_rules.fromutc(dt.replace(tzinfo=self.posix_rules))\n            return dt.replace(tzinfo=self)\n        if dt < self.ut[1]:\n            tti = self.ti[0]\n            fold = 0\n        else:\n            idx = bisect.bisect_right(self.ut, dt)\n            assert self.ut[idx - 1] <= dt\n            assert idx == len(self.ut) or dt < self.ut[idx]\n            tti_prev, tti = self.ti[idx - 2:idx]\n            # Detect fold\n            shift = tti_prev[0] - tti[0]\n            fold = (shift > dt - self.ut[idx - 1])\n        dt += tti[0]\n        dt = dt.replace(tzinfo=self)\n        if fold:\n            return enfold(dt)\n        else:\n            return dt", "response": "datetime in UTC -> datetime in local time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing title from alternative location if not found.", "response": "def _parse_alt_title(html_chunk):\n    \"\"\"\n    Parse title from alternative location if not found where it should be.\n\n    Args:\n        html_chunk (obj): HTMLElement containing slice of the page with details.\n\n    Returns:\n        str: Book's title.\n    \"\"\"\n    title = html_chunk.find(\"img\", fn=has_param(\"alt\"))\n\n    if not title:\n        raise UserWarning(\"Can't find alternative title source!\")\n\n    return title[0].params[\"alt\"].strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse URL from alternative location if not found.", "response": "def _parse_alt_url(html_chunk):\n    \"\"\"\n    Parse URL from alternative location if not found where it should be.\n\n    Args:\n        html_chunk (obj): HTMLElement containing slice of the page with details.\n\n    Returns:\n        str: Book's URL.\n    \"\"\"\n    url_list = html_chunk.find(\"a\", fn=has_param(\"href\"))\n    url_list = map(lambda x: x.params[\"href\"], url_list)\n    url_list = filter(lambda x: not x.startswith(\"autori/\"), url_list)\n\n    if not url_list:\n        return None\n\n    return normalize_url(BASE_URL, url_list[0])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_title_url(html_chunk):\n    url = None\n    title_tags = html_chunk.match(\n        [\"div\", {\"class\": \"polozka_nazev\"}],\n        [\"a\", None, has_param(\"href\")]\n    )\n\n    if not title_tags:\n        return _parse_alt_title(html_chunk), _parse_alt_url(html_chunk)\n\n    title = title_tags[0]\n\n    url = normalize_url(BASE_URL, title.params[\"href\"])\n    title = title.getContent()\n\n    if not title:\n        title = _parse_alt_title(html_chunk)\n\n    return title, url", "response": "Parse title and url of the book."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing authors of the book.", "response": "def _parse_authors(html_chunk):\n    \"\"\"\n    Parse authors of the book.\n\n    Args:\n        html_chunk (obj): HTMLElement containing slice of the page with details.\n\n    Returns:\n        list: List of :class:`structures.Author` objects. Blank if no author \\\n              found.\n    \"\"\"\n    authors_tags = html_chunk.match(\n        [\"div\", {\"class\": \"polozka_autor\"}],\n        \"a\"\n    )\n\n    authors = []\n    for author_tag in authors_tags:\n        # get name\n        name = author_tag.getContent().strip()\n\n        # skip tags without name\n        if not name:\n            continue\n\n        # get url - if not found, set it to None\n        url = author_tag.params.get(\"href\", None)\n        if url:\n            url = normalize_url(BASE_URL, url)\n\n        authors.append(\n            Author(name, url)\n        )\n\n    return authors"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngoing thru html_chunk and try to locate content of the neighbor cell of the cell containing what.", "response": "def _parse_from_table(html_chunk, what):\n    \"\"\"\n    Go thru table data in `html_chunk` and try to locate content of the\n    neighbor cell of the cell containing `what`.\n\n    Returns:\n        str: Table data or None.\n    \"\"\"\n    ean_tag = html_chunk.find(\"tr\", fn=must_contain(\"th\", what, \"td\"))\n\n    if not ean_tag:\n        return None\n\n    return get_first_content(ean_tag[0].find(\"td\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the description of the book.", "response": "def _parse_description(html_chunk):\n    \"\"\"\n    Parse description of the book.\n\n    Args:\n        html_chunk (obj): HTMLElement containing slice of the page with details.\n\n    Returns:\n        str/None: Description as string or None if not found.\n    \"\"\"\n    description_tag = html_chunk.match(\n        [\"div\", {\"class\": \"kniha_detail_text\"}],\n        \"p\"\n    )\n\n    if not description_tag:\n        return None\n\n    description = get_first_content(description_tag)\n    description = description.replace(\"<br />\", \"\\n\")\n    description = description.replace(\"<br/>\", \"\\n\")\n\n    return dhtmlparser.removeTags(description).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse available informations about book from the book details page.", "response": "def _process_book(html_chunk):\n    \"\"\"\n    Parse available informations about book from the book details page.\n\n    Args:\n        html_chunk (obj): HTMLElement containing slice of the page with details.\n\n    Returns:\n        obj: :class:`structures.Publication` instance with book details.\n    \"\"\"\n    title, book_url = _parse_title_url(html_chunk)\n\n    # download page with details\n    data = DOWNER.download(book_url)\n    dom = dhtmlparser.parseString(\n        handle_encodnig(data)\n    )\n    details = dom.find(\"div\", {\"id\": \"kniha_detail\"})[0]\n\n    # required parameters\n    pub = Publication(\n        title=title,\n        authors=_parse_authors(html_chunk),\n        price=_parse_price(details),\n        publisher=\"CPress\"\n    )\n\n    # optional parameters\n    pub.optionals.URL = book_url\n    pub.optionals.EAN = _parse_ean(details)\n    pub.optionals.format = _parse_format(details)\n    pub.optionals.pub_date = _parse_date(details)\n    pub.optionals.description = _parse_description(details)\n\n    return pub"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets list of publication offered by cpress. cz.", "response": "def get_publications():\n    \"\"\"\n    Get list of publication offered by cpress.cz.\n\n    Returns:\n        list: List of :class:`.Publication` objects.\n    \"\"\"\n    data = DOWNER.download(URL)\n    dom = dhtmlparser.parseString(\n        handle_encodnig(data)\n    )\n\n    book_list = dom.find(\"div\", {\"class\": \"polozka\"})\n\n    books = []\n    for book in book_list:\n        books.append(\n            _process_book(book)\n        )\n\n    return books"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve(\n            self, configurable=None, scope=None, safe=None, besteffort=None\n    ):\n        \"\"\"Resolve all parameters.\n\n        :param Configurable configurable: configurable to use for foreign\n            parameter resolution.\n        :param dict scope: variables to use for parameter expression evaluation.\n        :param bool safe: safe execution (remove builtins functions).\n        :raises: Parameter.Error for any raised exception.\n        \"\"\"\n\n        if scope is None:\n            scope = self.scope\n\n        if safe is None:\n            safe = self.safe\n\n        if besteffort is None:\n            besteffort = self.besteffort\n\n        for category in self.values():\n\n            for param in category.values():\n\n                param.resolve(\n                    configurable=configurable, conf=self,\n                    scope=scope, safe=safe, besteffort=besteffort\n                )", "response": "Resolve all parameters in the foreign key system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef param(self, pname, cname=None, history=0):\n\n        result = None\n\n        category = None\n\n        categories = []  # list of categories containing input parameter name\n\n        for cat in self.values():\n\n            if pname in cat:\n\n                categories.append(cat)\n\n                if cname == cat.name:\n                    break\n\n        if cname is not None and (\n                not categories or categories[-1].name != cname\n        ):\n            raise NameError('Category {0} does not exist.'.format(cname))\n\n        categories = categories[:max(1, len(categories) - history)]\n\n        for category in categories:\n            if pname in category:\n                if result is None:\n                    result = category[pname].copy()\n\n                else:\n                    result.update(category[pname])\n\n        return result", "response": "Get a parameter from a specific parameter name and a specific parameter name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef numberify_data(self, source, start=1):\n        '''Return a dictionary with numberified data\n        Arguments:\n        source -- source of data(filename or a list)\n        start  -- starting index of numbering\n        '''\n        if type(source) is str:\n            try:\n                fd = open(source, 'r+')\n                data = fd.readlines()\n                for index, item in enumerate(data):\n                    data[index] = item.strip('\\n')\n                fd.close()\n            except IOError as e:\n                print 'I/O error({0}): {1}'.format(e.errno, e.strerror)\n                return False\n        elif type(source) is list:\n            data = source\n        else:\n            print 'Data error. Pass a filename or a list'\n            return False\n        return dict(list(enumerate(data, start)))", "response": "Return a dictionary with numberified data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apache_md5crypt(password, salt, magic='$apr1$'):\n    password = password.encode('utf-8')\n    salt = salt.encode('utf-8')\n    magic = magic.encode('utf-8')\n\n    m = md5()\n    m.update(password + magic + salt)\n\n    mixin = md5(password + salt + password).digest()\n    for i in range(0, len(password)):\n        m.update(mixin[i % 16])\n\n    i = len(password)\n    while i:\n        if i & 1:\n            m.update('\\x00')\n        else:\n            m.update(password[0])\n        i >>= 1\n\n    final = m.digest()\n\n    for i in range(1000):\n        m2 = md5()\n        if i & 1:\n            m2.update(password)\n        else:\n            m2.update(final)\n\n        if i % 3:\n            m2.update(salt)\n\n        if i % 7:\n            m2.update(password)\n\n        if i & 1:\n            m2.update(final)\n        else:\n            m2.update(password)\n\n        final = m2.digest()\n\n    itoa64 = './0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n\n    rearranged = ''\n    seq = ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5))\n    for a, b, c in seq:\n        v = ord(final[a]) << 16 | ord(final[b]) << 8 | ord(final[c])\n        for i in range(4):\n            rearranged += itoa64[v & 0x3f]\n            v >>= 6\n\n    v = ord(final[11])\n    for i in range(2):\n        rearranged += itoa64[v & 0x3f]\n        v >>= 6\n\n    return magic + salt + '$' + rearranged", "response": "Calculates the Apache - style MD5 hash of a password and salt."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_data_url(deployment_name,\n                 endpoint_type='juttle',\n                 token_manager=None,\n                 app_url=defaults.APP_URL):\n    \"\"\"\n    get the data url for a specified endpoint_type, currently supported types\n    are:\n\n     * http-import: for importing data points\n     * juttle: for running juttle programs\n\n    \"\"\"\n    deployment_details = deployments.get_deployment_details(deployment_name,\n                                                            token_manager=token_manager,\n                                                            app_url=app_url)\n\n    # use a random juttle endpoint\n    endpoints = []\n    for endpoint in deployment_details['endpoints']:\n        if endpoint_type in endpoint['type']:\n            endpoints.append(endpoint)\n\n    if len(endpoints) == 0:\n        raise JutException('No data engine currently configured for '\n                           'deployment \"%s\"' % deployment_name)\n\n    return random.choice(endpoints)['uri']", "response": "get the data url for a specified endpoint type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data_urls(deployment_name,\n                  endpoint_type='juttle',\n                  token_manager=None,\n                  app_url=defaults.APP_URL):\n    \"\"\"\n    get all of the data urls for a specified endpoint_type, currently supported types\n    are:\n\n     * http-import: for importing data points\n     * juttle: for running juttle programs\n\n    \"\"\"\n    deployment_details = deployments.get_deployment_details(deployment_name,\n                                                            token_manager=token_manager,\n                                                            app_url=app_url)\n\n    # use a random juttle endpoint\n    data_urls = []\n    for endpoint in deployment_details['endpoints']:\n        if endpoint_type in endpoint['type']:\n            data_urls.append(endpoint['uri'])\n\n    if len(data_urls) == 0:\n        raise JutException('No data engine currently configured for '\n                           'deployment \"%s\"' % deployment_name)\n\n    return data_urls", "response": "get all of the data urls for a specified endpoint type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the juttle data url", "response": "def get_juttle_data_url(deployment_name,\n                        token_manager=None,\n                        app_url=defaults.APP_URL):\n    \"\"\"\n    return the juttle data url\n\n    \"\"\"\n    return get_data_url(deployment_name,\n                        endpoint_type='juttle',\n                        app_url=app_url,\n                        token_manager=token_manager)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_import_data_url(deployment_name,\n                        token_manager=None,\n                        app_url=defaults.APP_URL):\n    \"\"\"\n    return the import data url\n\n    \"\"\"\n    return get_data_url(deployment_name,\n                        endpoint_type='http-import',\n                        app_url=app_url,\n                        token_manager=token_manager)", "response": "Get the import data url for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __wss_connect(data_url,\n                  token_manager,\n                  job_id=None):\n    \"\"\"\n    Establish the websocket connection to the data engine. When job_id is\n    provided we're basically establishing a websocket to an existing\n    program that was already started using the jobs API\n\n    job_id: job id of a running program\n    \"\"\"\n    url = '%s/api/v1/juttle/channel' % data_url.replace('https://', 'wss://')\n\n    token_obj = {\n        \"accessToken\": token_manager.get_access_token()\n    }\n\n    if job_id != None:\n        token_obj['job_id'] = job_id\n\n    if is_debug_enabled():\n        debug(\"connecting to %s\", url)\n\n    websocket = create_connection(url)\n    websocket.settimeout(10)\n\n    if is_debug_enabled():\n        debug(\"sent %s\", json.dumps(token_obj))\n\n    websocket.send(json.dumps(token_obj))\n    return websocket", "response": "Establish a websocket connection to the data engine."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_job(job_id,\n                deployment_name,\n                token_manager=None,\n                app_url=defaults.APP_URL,\n                persist=False,\n                websocket=None,\n                data_url=None):\n    \"\"\"\n    connect to a running Juttle program by job_id\n\n    \"\"\"\n\n    if data_url == None:\n        data_url = get_data_url_for_job(job_id,\n                                        deployment_name,\n                                        token_manager=token_manager,\n                                        app_url=app_url)\n\n    if websocket == None:\n        websocket = __wss_connect(data_url,\n                                  token_manager,\n                                  job_id=job_id)\n\n    pong = json.dumps({\n        'pong': True\n    })\n\n    if not persist:\n        job_finished = False\n\n        while not job_finished:\n            try:\n                data = websocket.recv()\n\n                if data:\n                    payload = json.loads(data)\n\n                    if is_debug_enabled():\n                        printable_payload = dict(payload)\n                        if 'points' in payload:\n                            # don't want to print out all the outputs when in\n                            # debug mode\n                            del printable_payload['points']\n                            printable_payload['points'] = 'NOT SHOWN'\n\n                        debug('received %s' % json.dumps(printable_payload))\n\n                    if 'ping' in payload.keys():\n                        # ping/pong (ie heartbeat) mechanism\n                        websocket.send(pong)\n\n                        if is_debug_enabled():\n                            debug('sent %s' % json.dumps(pong))\n\n                    if 'job_end' in payload.keys() and payload['job_end'] == True:\n                        job_finished = True\n\n                    if token_manager.is_access_token_expired():\n                        debug('refreshing access token')\n                        token_obj = {\n                            \"accessToken\": token_manager.get_access_token()\n                        }\n                        # refresh authentication token\n                        websocket.send(json.dumps(token_obj))\n\n                    if 'error' in payload:\n                        if payload['error'] == 'NONEXISTENT-JOB':\n                            raise JutException('Job \"%s\" no longer running' % job_id)\n\n                    # return all channel messages\n                    yield payload\n\n                else:\n                    debug('payload was \"%s\", forcing websocket reconnect' % data)\n                    raise IOError()\n\n            except IOError:\n                if is_debug_enabled():\n                    traceback.print_exc()\n                #\n                # We'll retry for just under 30s since internally we stop\n                # running non persistent programs after 30s of not heartbeating\n                # with the client\n                #\n                retry = 1\n                while retry <= 5:\n                    try:\n                        debug('network error reconnecting to job %s, '\n                              'try %s of 5' % (job_id, retry))\n                        websocket = __wss_connect(data_url, token_manager, job_id=job_id)\n                        break\n\n                    except socket.error:\n\n                        if is_debug_enabled():\n                            traceback.print_exc()\n\n                        retry += 1\n                        time.sleep(5)\n\n                debug('network error reconnecting to job %s, '\n                      'try %s of 5' % (job_id, retry))\n                websocket = __wss_connect(data_url, token_manager, job_id=job_id)\n\n    websocket.close()", "response": "Connect to a running Juttle program by job_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a juttle program through the juttle streaming API and return the various events that are part of running a Juttle program which include: * Initial job status details including information to associate multiple flowgraphs with their individual outputs (sinks): { \"status\": \"ok\", \"job\": { \"channel_id\": \"56bde5f0\", \"_start_time\": \"2015-10-03T06:59:49.233Z\", \"alias\": \"jut-tools program 1443855588\", \"_ms_begin\": 1443855589233, \"user\": \"0fbbd98d-cf33-4582-8ca1-15a3d3fee510\", \"timeout\": 5, \"id\": \"b973bce6\" }, \"now\": \"2015-10-03T06:59:49.230Z\", \"stats\": ... \"sinks\": [ { \"location\": { \"start\": { \"column\": 17, \"line\": 1, \"offset\": 16 }, \"end\": { \"column\": 24, \"line\": 1, \"offset\": 23 }, \"filename\": \"main\" }, \"name\": \"table\", \"channel\": \"sink237\", \"options\": { \"_jut_time_bounds\": [] } }, ... as many sinks as there are flowgrpahs in your program ] } * Each set of points returned along with the indication of which sink they belong to: { \"points\": [ array of points ], \"sink\": sink_id } * Error event indicating where in your program the error occurred { \"error\": true, payload with \"info\" and \"context\" explaining exact error } * Warning event indicating where in your program the error occurred { \"warning\": true, payload with \"info\" and \"context\" explaining exact warning } * ... juttle: juttle program to execute deployment_name: the deployment name to execute the program on persist: if set to True then we won't wait for response data and will disconnect from the websocket leaving the program running in the background if it is uses a background output (http://docs.jut.io/juttle-guide/#background_outputs) and therefore becomes a persistent job. token_manager: auth.TokenManager object app_url: optional argument used primarily for internal Jut testing", "response": "def run(juttle,\n        deployment_name,\n        program_name=None,\n        persist=False,\n        token_manager=None,\n        app_url=defaults.APP_URL):\n    \"\"\"\n    run a juttle program through the juttle streaming API and return the\n    various events that are part of running a Juttle program which include:\n\n        * Initial job status details including information to associate\n          multiple flowgraphs with their individual outputs (sinks):\n          {\n            \"status\": \"ok\",\n            \"job\": {\n              \"channel_id\": \"56bde5f0\",\n              \"_start_time\": \"2015-10-03T06:59:49.233Z\",\n              \"alias\": \"jut-tools program 1443855588\",\n              \"_ms_begin\": 1443855589233,\n              \"user\": \"0fbbd98d-cf33-4582-8ca1-15a3d3fee510\",\n              \"timeout\": 5,\n              \"id\": \"b973bce6\"\n            },\n            \"now\": \"2015-10-03T06:59:49.230Z\",\n            \"stats\": ...\n            \"sinks\": [\n              {\n                \"location\": {\n                  \"start\": {\n                    \"column\": 17,\n                    \"line\": 1,\n                    \"offset\": 16\n                  },\n                  \"end\": {\n                    \"column\": 24,\n                    \"line\": 1,\n                    \"offset\": 23\n                  },\n                  \"filename\": \"main\"\n                },\n                \"name\": \"table\",\n                \"channel\": \"sink237\",\n                \"options\": {\n                  \"_jut_time_bounds\": []\n                }\n              },\n              ... as many sinks as there are flowgrpahs in your program\n            ]\n           }\n\n        * Each set of points returned along with the indication of which sink\n          they belong to:\n          {\n            \"points\": [ array of points ],\n            \"sink\": sink_id\n          }\n\n        * Error event indicating where in your program the error occurred\n          {\n            \"error\": true,\n            payload with \"info\" and \"context\" explaining exact error\n          }\n\n        * Warning event indicating where in your program the error occurred\n          {\n            \"warning\": true,\n            payload with \"info\" and \"context\" explaining exact warning\n          }\n\n        * ...\n\n    juttle: juttle program to execute\n    deployment_name: the deployment name to execute the program on\n    persist: if set to True then we won't wait for response data and will\n             disconnect from the websocket leaving the program running in\n             the background if it is uses a background output\n             (http://docs.jut.io/juttle-guide/#background_outputs) and\n             therefore becomes a persistent job.\n    token_manager: auth.TokenManager object\n    app_url: optional argument used primarily for internal Jut testing\n    \"\"\"\n    headers = token_manager.get_access_token_headers()\n\n    data_url = get_juttle_data_url(deployment_name,\n                                   app_url=app_url,\n                                   token_manager=token_manager)\n\n    websocket = __wss_connect(data_url, token_manager)\n\n    data = websocket.recv()\n    channel_id_obj = json.loads(data)\n\n    if is_debug_enabled():\n        debug('got channel response %s', json.dumps(channel_id_obj))\n\n    channel_id = channel_id_obj['channel_id']\n    juttle_job = {\n        'channel_id': channel_id,\n        'alias': program_name,\n        'program': juttle\n    }\n\n    response = requests.post('%s/api/v1/jobs' % data_url,\n                             data=json.dumps(juttle_job),\n                             headers=headers)\n\n    if response.status_code != 200:\n        yield {\n            \"error\": True,\n            \"context\": response.json()\n        }\n        return\n\n    job_info = response.json()\n    # yield job_info so the caller to this method can figure out which sinks\n    # correlate to which flowgraphs\n    yield job_info\n    job_id = job_info['job']['id']\n\n    if is_debug_enabled():\n        debug('started job %s', json.dumps(job_info))\n\n    for data in connect_job(job_id,\n                            deployment_name,\n                            token_manager=token_manager,\n                            app_url=app_url,\n                            persist=persist,\n                            websocket=websocket,\n                            data_url=data_url):\n        yield data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_jobs(deployment_name,\n             token_manager=None,\n             app_url=defaults.APP_URL):\n    \"\"\"\n    return list of currently running jobs\n\n    \"\"\"\n    headers = token_manager.get_access_token_headers()\n    data_urls = get_data_urls(deployment_name,\n                              app_url=app_url,\n                              token_manager=token_manager)\n\n    jobs = []\n\n    for data_url in data_urls:\n        url = '%s/api/v1/jobs' % data_url\n        response = requests.get(url, headers=headers)\n\n        if response.status_code == 200:\n            # saving the data_url for the specific job so you know where to\n            # connect if you want to interact with that job\n            these_jobs = response.json()['jobs']\n\n            for job in these_jobs:\n                job['data_url'] = data_url\n\n            jobs += these_jobs\n        else:\n            raise JutException('Error %s: %s' % (response.status_code, response.text))\n\n    return jobs", "response": "get all jobs in the current environment"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_job_details(job_id,\n                    deployment_name,\n                    token_manager=None,\n                    app_url=defaults.APP_URL):\n    \"\"\"\n    return job details for a specific job id\n\n    \"\"\"\n\n    jobs = get_jobs(deployment_name,\n                    token_manager=token_manager,\n                    app_url=app_url)\n\n    for job in jobs:\n        if job['id'] == job_id:\n            return job\n\n    raise JutException('Unable to find job with id \"%s\"' % job_id)", "response": "Get details for a specific job id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_job(job_id,\n               deployment_name,\n               token_manager=None,\n               app_url=defaults.APP_URL):\n    \"\"\"\n    delete a job with a specific job id\n\n    \"\"\"\n    headers = token_manager.get_access_token_headers()\n    data_url = get_data_url_for_job(job_id,\n                                    deployment_name,\n                                    token_manager=token_manager,\n                                    app_url=app_url)\n\n    url = '%s/api/v1/jobs/%s' % (data_url, job_id)\n    response = requests.delete(url, headers=headers)\n\n    if response.status_code != 200:\n        raise JutException('Error %s: %s' % (response.status_code, response.text))", "response": "delete a job with a specific job id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prettify(root, encoding='utf-8'):\n    if isinstance(root, ElementTree.Element):\n        node = ElementTree.tostring(root, 'utf-8')\n    else:\n        node = root\n\n    # Hacky solution as it seems PyXML doesn't exist anymore... \n    return etree.tostring(etree.fromstring(node),\n                          pretty_print=True,\n                          xml_declaration=True,\n                          encoding='utf-8')", "response": "Return a pretty - printed XML string for the Element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding a list of lines from the input.", "response": "def lines(input):\n    \"\"\"Remove comments and empty lines\"\"\"\n    for raw_line in input:\n        line = raw_line.strip()\n        if line and not line.startswith('#'):\n            yield strip_comments(line)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exec_command(self, cmd, tmp_path, sudo_user, sudoable=False, executable='/bin/sh'):\n        ''' run a command on the local host '''\n\n        if not self.runner.sudo or not sudoable:\n            if executable:\n                local_cmd = [executable, '-c', cmd]\n            else:\n                local_cmd = cmd\n        else:\n            local_cmd, prompt = utils.make_sudo_cmd(sudo_user, executable, cmd)\n\n        vvv(\"EXEC %s\" % (local_cmd), host=self.host)\n        p = subprocess.Popen(local_cmd, shell=isinstance(local_cmd, basestring),\n                             cwd=self.runner.basedir, executable=executable or None,\n                             stdin=subprocess.PIPE,\n                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n        if self.runner.sudo and sudoable and self.runner.sudo_pass:\n            fcntl.fcntl(p.stdout, fcntl.F_SETFL,\n                        fcntl.fcntl(p.stdout, fcntl.F_GETFL) | os.O_NONBLOCK)\n            fcntl.fcntl(p.stderr, fcntl.F_SETFL,\n                        fcntl.fcntl(p.stderr, fcntl.F_GETFL) | os.O_NONBLOCK)\n            sudo_output = ''\n            while not sudo_output.endswith(prompt):\n                rfd, wfd, efd = select.select([p.stdout, p.stderr], [],\n                                              [p.stdout, p.stderr], self.runner.timeout)\n                if p.stdout in rfd:\n                    chunk = p.stdout.read()\n                elif p.stderr in rfd:\n                    chunk = p.stderr.read()\n                else:\n                    stdout, stderr = p.communicate()\n                    raise errors.AnsibleError('timeout waiting for sudo password prompt:\\n' + sudo_output)\n                if not chunk:\n                    stdout, stderr = p.communicate()\n                    raise errors.AnsibleError('sudo output closed while waiting for password prompt:\\n' + sudo_output)\n                sudo_output += chunk\n            p.stdin.write(self.runner.sudo_pass + '\\n')\n            fcntl.fcntl(p.stdout, fcntl.F_SETFL, fcntl.fcntl(p.stdout, fcntl.F_GETFL) & ~os.O_NONBLOCK)\n            fcntl.fcntl(p.stderr, fcntl.F_SETFL, fcntl.fcntl(p.stderr, fcntl.F_GETFL) & ~os.O_NONBLOCK)\n\n        stdout, stderr = p.communicate()\n        return (p.returncode, '', stdout, stderr)", "response": "run a command on the local host"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef put_file(self, in_path, out_path):\n        ''' transfer a file from local to local '''\n\n        vvv(\"PUT %s TO %s\" % (in_path, out_path), host=self.host)\n        if not os.path.exists(in_path):\n            raise errors.AnsibleFileNotFound(\"file or module does not exist: %s\" % in_path)\n        try:\n            shutil.copyfile(in_path, out_path)\n        except shutil.Error:\n            traceback.print_exc()\n            raise errors.AnsibleError(\"failed to copy: %s and %s are the same\" % (in_path, out_path))\n        except IOError:\n            traceback.print_exc()\n            raise errors.AnsibleError(\"failed to transfer file to %s\" % out_path)", "response": "transfer a file from local to local"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch_file(self, in_path, out_path):\n        vvv(\"FETCH %s TO %s\" % (in_path, out_path), host=self.host)\n        ''' fetch a file from local to local -- for copatibility '''\n        self.put_file(in_path, out_path)", "response": "fetch a file from local to local"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getPythonVarName(name):\n    return SUB_REGEX.sub('', name.replace('+', '_').replace('-', '_').replace('.', '_').replace(' ', '').replace('/', '_')).upper()", "response": "Get the python variable name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, text):\n        root = ET.fromstring(text)\n        for elm in root.findall('{http://www.iana.org/assignments}registry'):\n            for record in elm.findall('{http://www.iana.org/assignments}record'):\n                for fileElm in record.findall('{http://www.iana.org/assignments}file'):\n                    if fileElm.get('type') == 'template':\n                        mimeType = fileElm.text.strip()\n                        yield mimeType\n                        break", "response": "Parse the text content\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parsefile(self, filename):\n        with open(filename, 'rb') as fd:\n            return self.parse(fd.read())", "response": "Parse from the file containing the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(self):\n        self.log.debug('Testing for a valid login session')\n        # If our cookie jar is empty, we obviously don't have a valid login session\n        if not len(self.cookiejar):\n            return False\n\n        # Test our login session and make sure it's still active\n        return requests.get(self.TEST_URL, cookies=self.cookiejar).status_code == 200", "response": "Test if we have a valid login session set\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(self, username, password, remember=True):\n        self.log.debug('Processing login request')\n\n        self.browser.open(self.LOGIN_URL)\n        self.log.info('Login page loaded: %s', self.browser.title())\n\n        self.browser.select_form(nr=0)\n\n        # Set the fields\n        self.log.debug('Username: %s', username)\n        self.log.debug('Password: %s', (password[0] + '*' * (len(password) - 2) + password[-1]))\n        self.log.debug('Remember: %s', remember)\n        self.browser.form[self.USERNAME_FIELD] = username\n        self.browser.form[self.PASSWORD_FIELD] = password\n        self.browser.find_control(self.REMEMBER_FIELD).items[0].selected = remember\n\n        # Submit the request\n        self.browser.submit()\n        self.log.debug('Response code: %s', self.browser.response().code)\n\n        self.log.debug('== Cookies ==')\n        for cookie in self.cookiejar:\n            self.log.debug(cookie)\n            self.cookies[cookie.name] = cookie.value\n        self.log.debug('== End Cookies ==')\n\n        # Make sure we successfully logged in\n        if self.LOGIN_COOKIE not in self.cookies:\n            raise BadLoginException('No login cookie returned, this probably means an invalid login was provided')\n\n        # Should we save our login session?\n        if remember:\n            self.log.info('Saving login session to disk')\n            self.cookiejar.save()\n\n        self.log.info('Login request successful')\n        return self.cookiejar", "response": "Process a login request and return a new session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the libmarquise header to extract definitions.", "response": "def get_libmarquise_header():\n    \"\"\"Read the libmarquise header to extract definitions.\"\"\"\n    # Header file is packaged in the same place as the rest of the\n    # module.\n    header_path = os.path.join(os.path.dirname(__file__), \"marquise.h\")\n    with open(header_path) as header:\n        libmarquise_header_lines = header.readlines()\n\n    libmarquise_header_lines = [ line for line in libmarquise_header_lines if not line.startswith('#include ') and not line.startswith('#define ') ]\n    libmarquise_header_lines = [ line for line in libmarquise_header_lines if not line.startswith('#include ') ]\n    # We can't #include glib so FFI doesn't know what a GTree is. Leave it for\n    # later and let the C compiler resolve it when we call FFI.verify()\n    libmarquise_header_lines = [ line.replace(\"GTree *sd_hashes;\", \"...;\") for line in libmarquise_header_lines ]\n    return ''.join(libmarquise_header_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing the default behavior unless the object to be encoded has a strftime attribute.", "response": "def default(self, obj):  # pylint: disable=method-hidden\n        \"\"\"Use the default behavior unless the object to be encoded has a\n        `strftime` attribute.\"\"\"\n\n        if hasattr(obj, 'strftime'):\n            return obj.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n        elif hasattr(obj, 'get_public_dict'):\n            return obj.get_public_dict()\n        else:\n            return json.JSONEncoder.default(self, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the message is a taskotron message.", "response": "def taskotron_task(config, message, task=None):\n    \"\"\" Particular taskotron task\n\n    With this rule, you can limit messages to only those of particular\n    `taskotron <https://taskotron.fedoraproject.org/>`_ task.\n\n    You can specify several tasks by separating them with a comma ',',\n    i.e.: ``dist.depcheck,dist.rpmlint``.\n    \"\"\"\n\n    # We only operate on taskotron messages, first off.\n    if not taskotron_result_new(config, message):\n        return False\n\n    if not task:\n        return False\n\n    tasks = [item.strip().lower() for item in task.split(',')]\n    return message['msg']['task'].get('name').lower() in tasks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef taskotron_changed_outcome(config, message):\n\n    # We only operate on taskotron messages, first off.\n    if not taskotron_result_new(config, message):\n        return False\n\n    outcome = message['msg']['result'].get('outcome')\n    prev_outcome = message['msg']['result'].get('prev_outcome')\n\n    return prev_outcome is not None and outcome != prev_outcome", "response": "Return True if the task outcome has changed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef taskotron_task_outcome(config, message, outcome=None):\n\n    # We only operate on taskotron messages, first off.\n    if not taskotron_result_new(config, message):\n        return False\n\n    if not outcome:\n        return False\n\n    outcomes = [item.strip().lower() for item in outcome.split(',')]\n    return message['msg']['result'].get('outcome').lower() in outcomes", "response": "Return True if the message is in the taskotron task outcome."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef taskotron_release_critical_task(config, message):\n\n    # We only operate on taskotron messages, first off.\n    if not taskotron_result_new(config, message):\n        return False\n\n    task = message['msg']['task'].get('name')\n\n    return task in ['dist.depcheck', 'dist.upgradepath']", "response": "Return True if the message is a taskotron release critical task."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the given action and return a Future with the result.", "response": "def execute(action, io_loop=None):\n    \"\"\"Execute the given action and return a Future with the result.\n\n    The ``forwards`` and/or ``backwards`` methods for the action may be\n    synchronous or asynchronous. If asynchronous, that method must return a\n    Future that will resolve to its result.\n\n    See :py:func:`reversible.execute` for more details on the behavior of\n    ``execute``.\n\n    :param action:\n        The action to execute.\n    :param io_loop:\n        IOLoop through which asynchronous operations will be executed. If\n        omitted, the current IOLoop is used.\n    :returns:\n        A future containing the result of executing the action.\n    \"\"\"\n\n    if not io_loop:\n        io_loop = IOLoop.current()\n\n    output = Future()\n\n    def call():\n        try:\n            result = _execute(_TornadoAction(action, io_loop))\n        except Exception:\n            output.set_exc_info(sys.exc_info())\n        else:\n            output.set_result(result)\n\n    io_loop.add_callback(greenlet.greenlet(call).switch)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a triple to the dataset", "response": "def add_triple(self, sub, pred=None,  obj=None, **kwargs):\n        \"\"\" Adds a triple to the dataset\n\n            args:\n                sub: The subject of the triple or dictionary contaning a\n                     triple\n                pred: Optional if supplied in sub, predicate of the triple\n                obj:  Optional if supplied in sub, object of the triple\n\n            kwargs:\n                map: Optional, a ditionary mapping for a supplied dictionary\n                strip_orphans: Optional, remove triples that have an orphan\n                               blanknode as the object\n                obj_method: if \"list\" than the object will be returned in the\n                            form of a list\n        \"\"\"\n        self.__set_map__(**kwargs)\n        strip_orphans = kwargs.get(\"strip_orphans\", False)\n        obj_method = kwargs.get(\"obj_method\")\n        if isinstance(sub, DictClass) or isinstance(sub, dict):\n            pred = sub[self.pmap]\n            obj = sub[self.omap]\n            sub = sub[self.smap]\n\n        pred = pyrdf(pred)\n        obj = pyrdf(obj)\n        sub = pyrdf(sub)\n        # reference existing attr for bnodes and uris\n        if obj.type in self.relate_obj_types :\n            if strip_orphans and not self.get(obj):\n                return\n            obj = self.get(obj,obj)\n        try:\n            self[sub].add_property(pred, obj)\n        except KeyError:\n            self[sub] = RdfClassBase(sub, self, **kwargs)\n            self[sub].add_property(pred, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the dataset in an easy to read format", "response": "def view(self):\n        \"\"\" prints the dataset in an easy to read format \"\"\"\n        print(self.format(remove='bnode',\n                          sort=True,\n                          pretty=True,\n                          compress=True,\n                          output='json',\n                          add_ids=True))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef view_main(self):\n        print(self.format(remove='bnode',\n                          sort=True,\n                          pretty=True,\n                          compress=True,\n                          output='json',\n                          base_only = True,\n                          add_ids=True))", "response": "prints the dataset in an easy to read format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_data(self, data, **kwargs):\n        self.__set_map__(**kwargs)\n        start = datetime.datetime.now()\n        log.debug(\"Dataload stated\")\n        if isinstance(data, list):\n            data = self._convert_results(data, **kwargs)\n        class_types = self.__group_data__(data, **kwargs)\n\n        # generate classes and add attributes to the data\n        self._generate_classes(class_types, self.non_defined, **kwargs)\n        # add triples to the dataset\n        for triple in data:\n            self.add_triple(sub=triple, **kwargs)\n        log.debug(\"Dataload completed in '%s'\",\n                  (datetime.datetime.now() - start))", "response": "Bulk loads rdf data into the class object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_rmap_item(self, subj, pred, obj):\n        def add_item(self, subj, pred, obj):\n            try:\n                self.rmap[obj][pred].append(subj)\n            except KeyError:\n                try:\n                    self.rmap[obj][pred] = [subj]\n                except KeyError:\n                    self.rmap[obj] = {pred: [subj]}\n\n        if isinstance(obj, list):\n            for item in obj:\n                add_item(self, subj, pred, item)\n        else:\n            add_item(self, subj, pred, obj)", "response": "Adds a triple to the inverted dataset index"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _generate_classes(self, class_types, non_defined, **kwargs):\n        # kwargs['dataset'] = self\n        for class_type in class_types:\n            self[class_type[self.smap]] = self._get_rdfclass(class_type,\n                                                             **kwargs)\\\n                                                            (class_type,\n                                                             self,\n                                                             **kwargs)\n\n            self.add_rmap_item(self[class_type[self.smap]],\n                               class_type[self.pmap],\n                               class_type[self.omap])\n\n        for class_type in non_defined:\n            self[class_type] = RdfClassBase(class_type, self, **kwargs)\n            self.add_rmap_item(self[class_type], __a__, None)\n        self.__set_classes__\n        try:\n            self.base_class = self[self.base_uri]\n        except KeyError:\n            self.base_class = None", "response": "creates the class for each class in the data set"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_rdfclass(self, class_type, **kwargs):\n        def select_class(class_name):\n            \"\"\" finds the class in the rdfclass Module\"\"\"\n            try:\n                return getattr(MODULE.rdfclass, class_name.pyuri)\n            except AttributeError:\n                return RdfClassBase\n\n        if kwargs.get(\"def_load\"):\n            return RdfClassBase\n\n        if isinstance(class_type[self.omap], list):\n            bases = [select_class(class_name)\n                     for class_name in class_type[self.omap]]\n            bases = [base for base in bases if base != RdfClassBase]\n            if len(bases) == 0:\n                return RdfClassBase\n            elif len(bases) == 1:\n                return bases[0]\n            else:\n                bases = remove_parents(bases)\n                if len(bases) == 1:\n                    return bases[0]\n                else:\n                    name = \"_\".join(sorted(class_type[self.omap]))\n                    # if the the class has already been created return it\n                    if hasattr(MODULE.rdfclass, name):\n                        return getattr(MODULE.rdfclass, name)\n                    new_class = type(name,\n                                     tuple(bases),\n                                     {})\n                    new_class.hierarchy = list_hierarchy(class_type[self.omap][0],\n                                                         bases)\n                    new_class.class_names = sorted([base.__name__ \\\n                            for base in bases \\\n                            if base not in [RdfClassBase, dict]])\n                    setattr(MODULE.rdfclass, name, new_class)\n                    return new_class\n        else:\n            return select_class(class_type[self.omap])", "response": "returns the instanticated class from the class list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_non_defined(self, data, class_types):\n        subj_set = set([item[self.smap] for item in class_types])\n        non_def_set = set([item[self.smap] for item in data])\n        return list(non_def_set - subj_set)", "response": "Returns a list of URIs and blanknodes that are not defined within\n        the dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convert_results(self, data, **kwargs):\n\n        if kwargs.get(\"multiprocessing\", False):\n            m = mp.Manager()\n            output = m.Queue()\n            pdb.set_trace()\n            # processes = [mp.Process(target=convert_row_main,\n            #                         args=(row, output,))\n            #              for row in data]\n            # # Run processes\n            # for p in processes:\n            #     p.start()\n\n            # # Exit the completed processes\n            # for p in processes:\n            #     p.join()\n            # # Get process results from the output queue\n            # return [output.get() for p in processes]\n\n            pool = mp.Pool(processes=pool_size)\n            for i, row in enumerate(data):\n                for key, val in row.items():\n                    try:\n                        pool.apply(convert_row_main, args=(val, i, key, output,))\n                    except:\n                        pass #\n            # run = [pool.apply(convert_row_main, args=(row, i, output))\n            #        for i, row in enumerate(data)]\n            for item in output:\n                pdb.set_trace()\n            return output\n            # with multiprocessing.Pool(processes=pool_size) as pool:\n            #     results = [convert_row_main, (row,))\n            #                for row in data]\n            #     converted = [r.get() for r in results]\n            # return converted #pool_outputs\n        else:\n            return [{key:pyrdf(value) for key, value in row.items()}\n                    for row in data]", "response": "converts the results of a query to RdfDatatype instances"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_timedelta(cls, datetime_obj, duration):\n        if duration.total_seconds() > 0:\n            return TimeInterval(datetime_obj, datetime_obj + duration)\n        else:\n            return TimeInterval(datetime_obj + duration, datetime_obj)", "response": "Create a new TimeInterval object from a start point and a duration."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_startstop(sheet, startcell=None, stopcell=None):\n\n    start = StartStop(0, 0)     # row, col\n    stop = StartStop(sheet.nrows, sheet.ncols)\n\n    if startcell:\n        m = re.match(XLNOT_RX, startcell)\n        start.row = int(m.group(2)) - 1\n        start.col = letter2num(m.group(1), zbase=True)\n\n    if stopcell:\n        m = re.match(XLNOT_RX, stopcell)\n        stop.row = int(m.group(2))\n        # Stop number is exclusive\n        stop.col = letter2num(m.group(1), zbase=False)\n\n    return [start, stop]", "response": "Return two StartStop objects based on the sheet and startcell and stopcell."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the internal data range for reading from a table.", "response": "def prepread(sheet, header=True, startcell=None, stopcell=None):\n    \"\"\"Return four StartStop objects, defining the outer bounds of\n    header row and data range, respectively. If header is False, the\n    first two items will be None.\n\n    --> [headstart, headstop, datstart, datstop]\n\n    sheet: xlrd.sheet.Sheet instance\n        Ready for use.\n\n    header: bool or str\n        True if the defined data range includes a header with field\n        names. Else False - the whole range is data. If a string, it is\n        spread sheet style notation of the startcell for the header\n        (\"F9\"). The \"width\" of this record is the same as for the data.\n\n    startcell: str or None\n        If given, a spread sheet style notation of the cell where reading\n        start, (\"F9\").\n\n    stopcell: str or None\n        A spread sheet style notation of the cell where data end,\n        (\"F9\").\n\n   startcell and stopcell can both be None, either one specified or\n   both specified.\n\n   Note to self: consider making possible to specify headers in a column.\n\n    \"\"\"\n    datstart, datstop = _get_startstop(sheet, startcell, stopcell)\n    headstart, headstop = StartStop(0, 0), StartStop(0, 0)  # Holders\n\n    def typicalprep():\n        headstart.row, headstart.col = datstart.row, datstart.col\n        headstop.row, headstop.col = datstart.row + 1, datstop.col\n        # Tick the data start row by 1:\n        datstart.row += 1\n\n    def offsetheaderprep():\n        headstart.row, headstart.col = headrow, headcol\n        headstop.row = headrow + 1\n        headstop.col = headcol + (datstop.col - datstart.col)  # stop > start\n\n    if header is True:          # Simply the toprow of the table.\n        typicalprep()\n        return [headstart, headstop, datstart, datstop]\n    elif header:                # Then it is a string if not False. (\"F9\")\n        m = re.match(XLNOT_RX, header)\n        headrow = int(m.group(2)) - 1\n        headcol = letter2num(m.group(1), zbase=True)\n        if headrow == datstart.row and headcol == datstart.col:\n            typicalprep()\n            return [headstart, headstop, datstart, datstop]\n        elif headrow == datstart.row:\n            typicalprep()\n            offsetheaderprep()\n            return [headstart, headstop, datstart, datstop]\n        else:\n            offsetheaderprep()\n            return [headstart, headstop, datstart, datstop]\n    else:                       # header is False\n        return [None, None, datstart, datstop]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the channel names in a list suitable as an argument to ChannelPack s set_channel_names method.", "response": "def sheetheader(sheet, startstops, usecols=None):\n    \"\"\"Return the channel names in a list suitable as an argument to\n    ChannelPack's `set_channel_names` method. Return None if first two\n    StartStops are None.\n\n    This function is slightly confusing, because it shall be called with\n    the same parameters as sheet_asdict. But knowing that, it should be\n    convenient.\n\n    sheet: xlrd.sheet.Sheet instance\n        Ready for use.\n\n    startstops: list\n        Four StartStop objects defining the data to read. See\n        :func:`~channelpack.pullxl.prepread`, returning such a list.\n\n    usecols: str or sequence of ints or None\n        The columns to use, 0-based. 0 is the spread sheet column\n        \"A\". Can be given as a string also - 'C:E, H' for columns C, D,\n        E and H.\n    \"\"\"\n\n    headstart, headstop, dstart, dstop = startstops\n    if headstart is None:\n        return None\n    assert headstop.row - headstart.row == 1, ('Field names must be in '\n                                               'same row so far. Or '\n                                               'this is a bug')\n    header = []\n    # One need to make same offsets within start and stop as in usecols:\n    usecols = _sanitize_usecols(usecols)\n    cols = usecols or range(dstart.col, dstop.col)\n    headcols = [c + (headstart.col - dstart.col) for c in cols]\n\n    for col in headcols:\n        fieldname = sheet.cell(headstart.row, col).value\n        header.append(unicode(fieldname))\n\n    return header"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sheet_asdict(sheet, startstops, usecols=None):\n\n    _, _, start, stop = startstops\n    usecols = _sanitize_usecols(usecols)\n\n    if usecols is not None:\n        iswithin = start.col <= min(usecols) and stop.col > max(usecols)\n        mess = 'Column in usecols outside defined data range, got '\n        assert iswithin, mess + str(usecols)\n    else:                       # usecols is None.\n        usecols = tuple(range(start.col, stop.col))\n\n    # cols = usecols or range(start.col, stop.col)\n    D = dict()\n\n    for c in usecols:\n        cells = sheet.col(c, start_rowx=start.row, end_rowx=stop.row)\n        types = set([cell.ctype for cell in cells])\n\n        # Replace empty values with nan if appropriate:\n        if (not types - NANABLE) and xlrd.XL_CELL_NUMBER in types:\n            D[c] = np.array([np.nan if cell.value == '' else cell.value\n                             for cell in cells])\n        elif xlrd.XL_CELL_DATE in types:\n            dm = sheet.book.datemode\n            vals = []\n            for cell in cells:\n                if cell.ctype == xlrd.XL_CELL_DATE:\n                    dtuple = xlrd.xldate_as_tuple(cell.value, dm)\n                    vals.append(datetime.datetime(*dtuple))\n                elif cell.ctype in NONABLES:\n                    vals.append(None)\n                else:\n                    vals.append(cell.value)\n            D[c] = np.array(vals)\n        else:\n            vals = [None if cell.ctype in NONABLES else cell.value\n                    for cell in cells]\n            D[c] = np.array(vals)\n\n    return D", "response": "Read data from a spread sheet. Return the data in a dict with column numbers as keys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading data from a spread sheet. Return the data in a dict with column numbers as keys.", "response": "def sheet_asdict(fn, sheet=0, header=True, startcell=None, stopcell=None,\n                 usecols=None, chnames_out=None):\n    \"\"\"Read data from a spread sheet. Return the data in a dict with\n    column numbers as keys.\n\n    fn: str\n        The file to read from.\n\n    sheet: int or str\n        If int, it is the index for the sheet 0-based. Else the sheet\n        name.\n\n    header: bool or str\n        True if the defined data range includes a header with field\n        names. Else False - the whole range is data. If a string, it is\n        a spread sheet style notation of the startcell for the header\n        (\"F9\"). The \"width\" of this record is the same as for the data.\n\n\n    startcell: str or None\n        If given, a spread sheet style notation of the cell where reading\n        start, (\"F9\").\n\n    stopcell: str or None\n        A spread sheet style notation of the cell where data end,\n        (\"F9\").\n\n    usecols: str or seqence of ints\n        The columns to use, 0-based. 0 is the spread sheet column\n        \"A\". Can be given as a string also - 'C:E, H' for columns C, D,\n        E and H.\n\n    usecols: str or sequence of ints or None\n        The columns to use, 0-based. 0 is the spread sheet column\n        \"A\". Can be given as a string also - 'C:E, H' for columns C, D,\n        E and H.\n\n    chnames_out: list or None\n        If a list it will be populated with the channel names. The size\n        of the list will equal to the number of channel names extracted.\n        Whatever is in the list supplied will first be removed.\n\n    Values in the returned dict are numpy arrays. Types are set based on\n    the types in the spread sheet.\n    \"\"\"\n    book = xlrd.open_workbook(fn)\n    try:\n        sh = book.sheet_by_index(sheet)\n    except TypeError:\n        sh = book.sheet_by_name(sheet)\n\n    ss = prepread(sh, header=header, startcell=startcell, stopcell=stopcell)\n\n    chnames = sheetheader(sh, ss, usecols=usecols)\n\n    if chnames_out is not None and chnames is not None:\n        vals = list(chnames_out)\n        [chnames_out.remove(v) for v in vals]\n        chnames_out.extend(chnames)\n\n    return _sheet_asdict(sh, ss, usecols=usecols)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sanitize_usecols(usecols):\n\n    if usecols is None:\n        return None\n\n    try:\n        pats = usecols.split(',')\n        pats = [p.strip() for p in pats if p]\n    except AttributeError:\n        usecols = [int(c) for c in usecols]  # Make error if mix.\n        usecols.sort()\n        return tuple(usecols)   # Assume sane sequence of integers.\n\n    cols = []\n    for pat in pats:\n        if ':' in pat:\n            c1, c2 = pat.split(':')\n            n1 = letter2num(c1, zbase=True)\n            n2 = letter2num(c2, zbase=False)\n            cols += range(n1, n2)\n        else:\n            cols += [letter2num(pat, zbase=True)]\n\n    # Remove duplicates:\n    cols = list(set(cols))\n    cols.sort()\n    return tuple(cols)", "response": "Make a tuple of sorted integers and return it. Return None if usecols is None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert spreadsheet style column enumeration to a number.", "response": "def letter2num(letters, zbase=False):\n    \"\"\"A = 1, C = 3 and so on. Convert spreadsheet style column\n    enumeration to a number.\n\n    Answers:\n    A = 1, Z = 26, AA = 27, AZ = 52, ZZ = 702, AMJ = 1024\n\n    >>> from channelpack.pullxl import letter2num\n\n    >>> letter2num('A') == 1\n    True\n    >>> letter2num('Z') == 26\n    True\n    >>> letter2num('AZ') == 52\n    True\n    >>> letter2num('ZZ') == 702\n    True\n    >>> letter2num('AMJ') == 1024\n    True\n    >>> letter2num('AMJ', zbase=True) == 1023\n    True\n    >>> letter2num('A', zbase=True) == 0\n    True\n\n    \"\"\"\n\n    letters = letters.upper()\n    res = 0\n    weight = len(letters) - 1\n    assert weight >= 0, letters\n    for i, c in enumerate(letters):\n        assert 65 <= ord(c) <= 90, c  # A-Z\n        res += (ord(c) - 64) * 26**(weight - i)\n    if not zbase:\n        return res\n    return res - 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromxldate(xldate, datemode=1):\n\n    t = xlrd.xldate_as_tuple(xldate, datemode)\n    return datetime.datetime(*t)", "response": "Return a python datetime object from xldate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef language(fname, is_ext=False):\n\n    global _langmapping\n\n    # Normalize the fname so that it looks like an extension.\n    if is_ext:\n        fname = '.' + fname\n    _, ext = os.path.splitext(fname)\n\n    return _langmapping[ext]()", "response": "Returns an instance of the language class that fname is suited for."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef certify_printable(value, nonprintable=False, required=True):\n    certify_params(\n        (certify_bool, 'nonprintable', nonprintable),\n    )\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n    _certify_printable(\n        value=value,\n        nonprintable=nonprintable,\n        required=required,\n    )", "response": "Certifier for human readable ( printable ) values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncertify for human readable string values.", "response": "def certify_text(\n    value, min_length=None, max_length=None, nonprintable=True, required=True,\n):\n    \"\"\"\n    Certifier for human readable string values.\n\n    :param unicode value:\n        The string to be certified.\n    :param int min_length:\n        The minimum length of the string.\n    :param int max_length:\n        The maximum acceptable length for the string. By default, the length is not checked.\n    :param nonprintable:\n        Whether the string can contain non-printable characters. Non-printable characters are\n        allowed by default.\n    :param bool required:\n        Whether the value can be `None`. Defaults to True.\n    :raises CertifierTypeError:\n        The type is invalid\n    :raises CertifierValueError:\n        The value is invalid\n    \"\"\"\n    certify_params(\n        (_certify_int_param, 'max_length', max_length, dict(negative=False, required=False)),\n        (_certify_int_param, 'min_length', min_length, dict(negative=False, required=False)),\n        (certify_bool, 'nonprintable', nonprintable),\n    )\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, six.text_type):\n        raise CertifierTypeError(\n            message=\"expected unicode string, but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )\n\n    if min_length is not None and len(value) < min_length:\n        raise CertifierValueError(\n            message=\"{length} is shorter than minimum acceptable {min}\".format(\n                length=len(value), min=min_length),\n            value=value,\n            required=required,\n        )\n\n    if max_length is not None and len(value) > max_length:\n        raise CertifierValueError(\n            message=\"{length} is longer than maximum acceptable {max}\".format(\n                length=len(value), max=max_length),\n            value=value,\n            required=required,\n        )\n\n    _certify_printable(\n        value=value,\n        nonprintable=nonprintable,\n        required=required,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef certify_int(value, min_value=None, max_value=None, required=True):\n    certify_params(\n        (_certify_int_param, 'max_length', max_value, dict(negative=True, required=False)),\n        (_certify_int_param, 'min_length', min_value, dict(negative=True, required=False)),\n    )\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, six.integer_types):\n        raise CertifierTypeError(\n            message=\"expected integer, but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )\n\n    if min_value is not None and value < min_value:\n        raise CertifierValueError(\n            message=\"{value} is less than minimum acceptable {min}\".format(\n                value=value, min=min_value),\n            value=value,\n            required=required,\n        )\n\n    if max_value is not None and value > max_value:\n        raise CertifierValueError(\n            message=\"{value} is more than the maximum acceptable {max}\".format(\n                value=value, max=max_value),\n            value=value,\n            required=required,\n        )", "response": "Certifier for integer values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef certify_bool(value, required=True):\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, bool):\n        raise CertifierTypeError(\n            message=\"expected bool, but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )", "response": "Certifier for boolean values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef certify_bytes(value, min_length=None, max_length=None, required=True):\n    certify_params(\n        (_certify_int_param, 'min_value', min_length, dict(negative=False, required=False)),\n        (_certify_int_param, 'max_value', max_length, dict(negative=False, required=False)),\n    )\n\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, six.binary_type):\n        raise CertifierTypeError(\n            message=\"expected byte string, but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )\n\n    if min_length is not None and len(value) < min_length:\n        raise CertifierValueError(\n            message=\"{length} is shorter than minimum acceptable {min}\".format(\n                length=len(value), min=min_length),\n            value=value,\n            required=required,\n        )\n\n    if max_length is not None and len(value) > max_length:\n        raise CertifierValueError(\n            message=\"{length} is longer than maximum acceptable {max}\".format(\n                length=len(value), max=max_length),\n            value=value,\n            required=required,\n        )", "response": "Certifier for bytestring values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef certify_enum(value, kind=None, required=True):\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, kind):\n        raise CertifierTypeError(\n            message=\"expected {expected!r}, but value is of type {actual!r}\".format(\n                expected=kind.__name__, actual=value.__class__.__name__),\n            value=value,\n            required=required,\n        )", "response": "Certifier for enum values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef certify_enum_value(value, kind=None, required=True):\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    try:\n        kind(value)\n    except:  # noqa\n        raise CertifierValueError(\n            message=\"value {value!r} is not a valid member of {enum!r}\".format(\n                value=value, enum=kind.__name__),\n            value=value,\n            required=required,\n        )", "response": "Certifier for enum values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef certify_object(value, kind=None, required=True):\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, kind):\n        try:\n            name = value.__class__.__name__\n        except:  # noqa # pragma: no cover\n            name = type(value).__name__\n\n        try:\n            expected = kind.__class__.__name__\n        except:  # noqa # pragma: no cover\n            expected = type(kind).__name__\n\n        raise CertifierValueError(\n            message=\"Expected object {expected!r}, but got {actual!r}\".format(\n                expected=expected, actual=name),\n            value=value,\n            required=required,\n        )", "response": "Certifier for class object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncertifies for timestamp values.", "response": "def certify_timestamp(value, required=True):\n    \"\"\"\n    Certifier for timestamp (datetime) values.\n\n    :param value:\n        The value to be certified.\n    :param bool required:\n        Whether the value can be `None`. Defaults to True.\n    :raises CertifierTypeError:\n        The type is invalid\n    \"\"\"\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, datetime):\n        raise CertifierTypeError(\n            message=\"expected timestamp (datetime), but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncertifying for datetime. date values.", "response": "def certify_date(value, required=True):\n    \"\"\"\n    Certifier for datetime.date values.\n\n    :param value:\n        The value to be certified.\n    :param bool required:\n        Whether the value can be `None`  Defaults to True.\n    :raises CertifierTypeError:\n        The type is invalid\n    \"\"\"\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, date):\n        raise CertifierTypeError(\n            message=\"expected timestamp (date\u2202), but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncertifying for datetime. time values.", "response": "def certify_time(value, required=True):\n    \"\"\"\n    Certifier for datetime.time values.\n\n    :param value:\n        The value to be certified.\n    :param bool required:\n        Whether the value can be `None`  Defaults to True.\n    :raises CertifierTypeError:\n        The type is invalid\n    \"\"\"\n    if certify_required(\n        value=value,\n        required=required,\n    ):\n        return\n\n    if not isinstance(value, time):\n        raise CertifierTypeError(\n            message=\"expected timestamp (time), but value is of type {cls!r}\".format(\n                cls=value.__class__.__name__),\n            value=value,\n            required=required,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AsDict(self, dt=True):\n        data = {}\n        if self.name:\n            data['name'] = self.name\n            data['mlkshk_url'] = self.mlkshk_url\n        if self.profile_image_url:\n            data['profile_image_url'] = self.profile_image_url\n        if self.id:\n            data['id'] = self.id\n        if self.about:\n            data['about'] = self.about\n        if self.website:\n            data['website'] = self.website\n        if self.shakes:\n            data['shakes'] = [shk.AsDict(dt=dt) for shk in self.shakes]\n        data['shake_count'] = self.shake_count\n        return data", "response": "Returns a dictionary representation of this User instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a JSON string representation of this User instance.", "response": "def AsJsonString(self):\n        \"\"\"A JSON string representation of this User instance.\n\n        Returns:\n          A JSON string representation of this User instance\n        \"\"\"\n        return json.dumps(self.AsDict(dt=False), sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new User instance from a JSON dictionary.", "response": "def NewFromJSON(data):\n        \"\"\"\n        Create a new User instance from a JSON dict.\n\n        Args:\n            data (dict): JSON dictionary representing a user.\n\n        Returns:\n            A User instance.\n        \"\"\"\n        if data.get('shakes', None):\n            shakes = [Shake.NewFromJSON(shk) for shk in data.get('shakes')]\n        else:\n            shakes = None\n\n        return User(\n            id=data.get('id', None),\n            name=data.get('name', None),\n            profile_image_url=data.get('profile_image_url', None),\n            about=data.get('about', None),\n            website=data.get('website', None),\n            shakes=shakes)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AsDict(self, dt=True):\n        data = {}\n\n        if self.body:\n            data['body'] = self.body\n        if self.posted_at:\n            data['posted_at'] = self.posted_at\n        if self.user:\n            data['user'] = self.user.AsDict()\n\n        return data", "response": "Returns a dictionary representation of this Comment instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef NewFromJSON(data):\n        return Comment(\n            body=data.get('body', None),\n            posted_at=data.get('posted_at', None),\n            user=User.NewFromJSON(data.get('user', None))\n        )", "response": "Create a new Comment instance from a JSON dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AsDict(self, dt=True):\n        data = {}\n\n        if self.id:\n            data['id'] = self.id\n        if self.name:\n            data['name'] = self.name\n        if self.owner:\n            data['owner'] = self.owner.AsDict()\n        if self.url:\n            data['url'] = self.url\n        if self.thumbnail_url:\n            data['thumbnail_url'] = self.thumbnail_url\n        if self.description:\n            data['description'] = self.description\n        if self.type:\n            data['type'] = self.type\n\n        if dt:\n            if self.created_at:\n                data['created_at'] = self.created_at\n            if self.updated_at:\n                data['updated_at'] = self.updated_at\n        else:\n            if self.created_at:\n                data['created_at'] = self.created_at_iso\n            if self.updated_at:\n                data['updated_at'] = self.updated_at_iso\n\n        return data", "response": "Returns a dictionary representation of this Shake instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new Shake instance from a JSON dict.", "response": "def NewFromJSON(data):\n        \"\"\"\n        Create a new Shake instance from a JSON dict.\n\n        Args:\n            data (dict): JSON dictionary representing a Shake.\n\n        Returns:\n            A Shake instance.\n        \"\"\"\n        s = Shake(\n            id=data.get('id', None),\n            name=data.get('name', None),\n            url=data.get('url', None),\n            thumbnail_url=data.get('thumbnail_url', None),\n            description=data.get('description', None),\n            type=data.get('type', None),\n            created_at=data.get('created_at', None),\n            updated_at=data.get('updated_at', None)\n        )\n        if data.get('owner', None):\n            s.owner = User.NewFromJSON(data.get('owner', None))\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary representation of this object.", "response": "def AsDict(self, dt=True):\n        \"\"\"\n        A dict representation of this Shake instance.\n\n        The return value uses the same key names as the JSON representation.\n\n        Args:\n            dt (bool): If True, return dates as python datetime objects. If\n                False, return dates as ISO strings.\n\n        Return:\n          A dict representing this Shake instance\n        \"\"\"\n        data = {}\n\n        if self.sharekey:\n            data['sharekey'] = self.sharekey\n        if self.name:\n            data['name'] = self.name\n        if self.user:\n            data['user'] = self.user.AsDict()\n        if self.title:\n            data['title'] = self.title\n        if self.description:\n            data['description'] = self.description\n        if self.posted_at:\n            if dt:\n                data['posted_at'] = self.posted_at\n            else:\n                data['posted_at'] = self.posted_at_iso\n        if self.permalink:\n            data['permalink'] = self.permalink\n        if self.width:\n            data['width'] = self.width\n        if self.height:\n            data['height'] = self.height\n        if self.image_url:\n            data['image_url'] = self.image_url\n        if self.source_url:\n            data['source_url'] = self.source_url\n        data['views'] = self.views\n        data['likes'] = self.likes\n        data['saves'] = self.saves\n        data['comments'] = self.comments\n        data['nsfw'] = self.nsfw\n        data['saved'] = self.saved\n        data['liked'] = self.liked\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new SharedFile instance from a JSON dict.", "response": "def NewFromJSON(data):\n        \"\"\"\n        Create a new SharedFile instance from a JSON dict.\n\n        Args:\n            data (dict): JSON dictionary representing a SharedFile.\n\n        Returns:\n            A SharedFile instance.\n        \"\"\"\n        return SharedFile(\n            sharekey=data.get('sharekey', None),\n            name=data.get('name', None),\n            user=User.NewFromJSON(data.get('user', None)),\n            title=data.get('title', None),\n            description=data.get('description', None),\n            posted_at=data.get('posted_at', None),\n            permalink=data.get('permalink', None),\n            width=data.get('width', None),\n            height=data.get('height', None),\n            views=data.get('views', 0),\n            likes=data.get('likes', 0),\n            saves=data.get('saves', 0),\n            comments=data.get('comments', None),\n            nsfw=data.get('nsfw', False),\n            image_url=data.get('image_url', None),\n            source_url=data.get('source_url', None),\n            saved=data.get('saved', False),\n            liked=data.get('liked', False),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _start_tracer(self, origin):\n        tracer = self._tracer_class(log=self.log)\n        tracer.data = self.data\n        fn = tracer.start(origin)\n        self.tracers.append(tracer)\n        return fn", "response": "Start a new Tracer object and store it in self. tracers.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start(self):\n        origin = inspect.stack()[1][0]\n\n        self.reset()\n\n        # Install the tracer on this thread.\n        self._start_tracer(origin)", "response": "Start collecting trace information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating or gets an existing gauge.", "response": "def gauge(self, name, producer):\n        \"\"\"Creates or gets an existing gauge.\n\n        :param name: The name\n        :return: The created or existing gauge for the given name\n        \"\"\"\n        return self._get_or_add_stat(name, functools.partial(Gauge, producer))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stats(self):\n        def _get_value(stats):\n            try:\n                return Dict((k, _get_value(v)) for k, v in stats.items())\n            except AttributeError:\n                return Dict(stats.get_values())\n\n        return _get_value(self.stats)", "response": "Retrieves the current values of the metrics associated with this registry formatted as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _populate_ips_versions(self):\n        # Get a map of version ID's from our most recent IPS version\n        ips = IpsManager(self.ctx)\n        ips = ips.dev_version or ips.latest\n        with ZipFile(ips.filepath) as zip:\n            namelist = zip.namelist()\n\n            ips_versions_path = os.path.join(namelist[0], 'applications/core/data/versions.json')\n            if ips_versions_path not in namelist:\n                raise BadZipfile('Missing versions.json file')\n            self.ips_versions = json.loads(zip.read(ips_versions_path), object_pairs_hook=OrderedDict)\n            self.log.debug(\"%d version ID's loaded from latest IPS release\", len(self.ips_versions))", "response": "Populate the self. ips_versions attribute with the IPS version data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_zip(self, filepath):\n        with ZipFile(filepath) as zip:\n            namelist = zip.namelist()\n            if re.match(r'^\\d+/?$', namelist[0]):\n                self.log.debug('Developer Tools directory matched: %s', namelist[0])\n                version_id = namelist[0].strip('/')\n            else:\n                basename = os.path.basename(filepath)\n                match = re.match('^IPS_Developer_Tools_v(\\d+).zip$', basename)\n                if match:\n                    self.log.info('Could not parse dev_tools archive, pulling version id from filename instead')\n                    version_id = match.group(1)\n                else:\n                    self.log.error('No developer tools directory matched, unable to continue')\n                    raise BadZipfile('Unrecognized dev tools file format, aborting')\n\n            if version_id not in self.ips_versions:\n                raise BadZipfile('Unrecognized version ID (is the dev tools package newer than our latest IPS release?)')\n            version = self.ips_versions[version_id]\n\n            self.log.debug('Version matched: %s', version)\n            return Version(version, version_id)", "response": "Read an IPS installation zipfile and return the core version number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(data_path):\n        with open(data_path, \"r\") as data_file:\n            raw_data = data_file.read()\n\n        data_file.close()\n        return raw_data", "response": "Load the data from a file and return it as a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting and iterate through the datafile to extract genres tags and points and points.", "response": "def parse(self, data):\n        \"\"\"\n        Split and iterate through the datafile to extract genres, tags\n        and points.\n        \"\"\"\n\n        categories = data.split(\"\\n\\n\")\n        reference = {}\n        reference_points = {}\n        genre_index = []\n        tag_index = []\n\n        for category in categories:\n            entries = category.strip().split(\"\\n\")\n            entry_category, entry_points = self._parse_entry(entries[0].lower())\n\n            if entry_category.startswith(\"#\"):\n                continue\n\n            for entry in entries:\n                entry = entry.lower()\n                if not entry:\n                    continue\n\n                # Comment, ignore\n                if entry.startswith(\"#\"):\n                    continue\n\n                # Handle genre\n                if not entry.startswith(\"-\"):\n                    genre, points = self._parse_entry(entry)\n\n                    reference[genre] = entry_category\n                    reference_points[genre] = points\n                    genre_index.append(genre)\n\n                # Handle tag\n                else:\n                    tag = entry[1:]\n                    tag, points = self._parse_entry(tag, limit=9.5)\n\n                    reference[tag] = entry_category\n                    reference_points[tag] = points\n                    tag_index.append(tag)\n\n        self.reference = reference\n        self.genres = genre_index\n        self.tags = tag_index\n        self.points = reference_points"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_entry(entry, limit=10):\n\n        entry = entry.split(\",\")\n        label = entry[0]\n        points = limit\n\n        if len(entry) > 1:\n            proc = float(entry[1].strip())\n            points = limit * proc\n\n        return label, int(points)", "response": "Parse a tag name and number of points for ranking."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef current_site_id():\n\n    if hasattr(override_current_site_id.thread_local, \"site_id\"):\n        return override_current_site_id.thread_local.site_id\n\n    from yacms.utils.cache import cache_installed, cache_get, cache_set\n    request = current_request()\n    site_id = getattr(request, \"site_id\", None)\n    if request and not site_id:\n        site_id = request.session.get(\"site_id\", None)\n        if not site_id:\n            domain = request.get_host().lower()\n            if cache_installed():\n                # Don't use yacms's cache_key_prefix here, since it\n                # uses this very function we're in right now to create a\n                # per-site cache key.\n                bits = (settings.CACHE_MIDDLEWARE_KEY_PREFIX, domain)\n                cache_key = \"%s.site_id.%s\" % bits\n                site_id = cache_get(cache_key)\n            if not site_id:\n                try:\n                    site = Site.objects.get(domain__iexact=domain)\n                except Site.DoesNotExist:\n                    pass\n                else:\n                    site_id = site.id\n                    if cache_installed():\n                        cache_set(cache_key, site_id)\n    if not site_id:\n        site_id = os.environ.get(\"YACMS_SITE_ID\", settings.SITE_ID)\n    if request and site_id and not getattr(settings, \"TESTING\", False):\n        request.site_id = site_id\n    return site_id", "response": "Returns the ID of the current site in an anonymized manner."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_site_permission(user):\n    mw = \"yacms.core.middleware.SitePermissionMiddleware\"\n    if mw not in get_middleware_setting():\n        from warnings import warn\n        warn(mw + \" missing from settings.MIDDLEWARE - per site\"\n             \"permissions not applied\")\n        return user.is_staff and user.is_active\n    return getattr(user, \"has_site_permission\", False)", "response": "Checks if a user has staff - level access for the current site."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef host_theme_path():\n\n    # Set domain to None, which we'll then query for in the first\n    # iteration of HOST_THEMES. We use the current site_id rather\n    # than a request object here, as it may differ for admin users.\n    domain = None\n\n    for (host, theme) in settings.HOST_THEMES:\n        if domain is None:\n            domain = Site.objects.get(id=current_site_id()).domain\n        if host.lower() == domain.lower():\n            try:\n                __import__(theme)\n                module = sys.modules[theme]\n            except ImportError:\n                pass\n            else:\n                return os.path.dirname(os.path.abspath(module.__file__))\n    return \"\"", "response": "Returns the directory of the theme associated with the given host."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a template name or list of templates returns the list of templates that are available on the host.", "response": "def templates_for_host(templates):\n    \"\"\"\n    Given a template name (or list of them), returns the template names\n    as a list, with each name prefixed with the device directory\n    inserted into the front of the list.\n    \"\"\"\n    if not isinstance(templates, (list, tuple)):\n        templates = [templates]\n    theme_dir = host_theme_path()\n    host_templates = []\n    if theme_dir:\n        for template in templates:\n            host_templates.append(\"%s/templates/%s\" % (theme_dir, template))\n            host_templates.append(template)\n        return host_templates\n    return templates"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads an object from a data URI.", "response": "def read(url, **args):\n    \"\"\"Loads an object from a data URI.\"\"\"\n    info, data = url.path.split(',')\n    info = data_re.search(info).groupdict()\n    mediatype = info.setdefault('mediatype', 'text/plain;charset=US-ASCII')\n    if ';' in mediatype:\n        mimetype, params = mediatype.split(';', 1)\n        params = [p.split('=') for p in params.split(';')]\n        params = dict((k.strip(), v.strip()) for k, v in params)\n    else:\n        mimetype, params = mediatype, dict()\n    data = base64.b64decode(data) if info['base64'] else urllib.unquote(data)\n    return content_types.get(mimetype).parse(data, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(url, object_, **args):\n    default_content_type = ('text/plain', {'charset': 'US-ASCII'})\n    content_encoding = args.get('content_encoding', 'base64')\n    content_type, params = args.get('content_type', default_content_type)\n    data = content_types.get(content_type).format(object_, **params)\n    args['data'].write('data:{}'.format(content_type))\n    for param, value in params.items():\n        args['data'].write(';{}={}'.format(param, value))\n    if content_encoding == 'base64':\n        args['data'].write(';base64,{}'.format(base64.b64decode(data)))\n    else:\n        args['data'].write(',{}', urllib.quote(data))\n    args['data'].seek(0)", "response": "Writes an object to a data URI."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_anomalous_score(self):\n        old = self.anomalous_score\n\n        products = self._graph.retrieve_products(self)\n        self.anomalous_score = sum(\n            p.summary.difference(\n                self._graph.retrieve_review(self, p)) * self._credibility(p) - 0.5\n            for p in products\n        )\n\n        return abs(self.anomalous_score - old)", "response": "Update anomalous score.\n\n        New anomalous score is the summation of weighted differences\n        between current summary and reviews. The weights come from credibilities.\n\n        Therefore, the new anomalous score is defined as\n\n        .. math::\n\n            {\\\\rm anomalous}(r)\n            = \\\\sum_{p \\\\in P} \\\\mbox{review}(p) \\\\times \\\\mbox{credibility}(p) - 0.5\n\n        where :math:`P` is a set of products reviewed by this reviewer,\n        review(:math:`p`) and credibility(:math:`p`) are\n        review and credibility of product :math:`p`, respectively.\n\n        Returns:\n          absolute difference between old anomalous score and updated one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self):\n        res = super(BipartiteGraph, self).update()\n\n        max_v = None\n        min_v = float(\"inf\")\n        for r in self.reviewers:\n            max_v = max(max_v, r.anomalous_score)\n            min_v = min(min_v, r.anomalous_score)\n\n        width = max_v - min_v\n        if width:\n            for r in self.reviewers:\n                r.anomalous_score = (r.anomalous_score - min_v) / width\n\n        return res", "response": "Updates the anomalous scores and products summaries."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_bool(value):\n    if value is None:\n        return False\n    if value is True or value is False:\n        return value\n    boolean = str(value).strip().lower()\n    return boolean in ['true', 'yes', 'on', '1']", "response": "Convert a string to a boolean\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deprecated(new_fct_name, logger=None):\n    if logger is None:\n        logger = logging.getLogger(\"kodex\")\n    nfct_name = new_fct_name\n    def aux_deprecated(func):\n        \"\"\"This is a decorator which can be used to mark functions\n        as deprecated. It will result in a warning being emmitted\n        when the function is used.\"\"\"\n        def newFunc(*args, **kwargs):\n            msg = \"DeprecationWarning: use '%s' instead of '%s'.\" % (new_fct_name, func.__name__)\n            logger.warning(msg)\n            warnings.warn(msg, category=DeprecationWarning)\n            return func(*args, **kwargs)\n        newFunc.__name__ = func.__name__\n        newFunc.__doc__ = func.__doc__\n        newFunc.__dict__.update(func.__dict__)\n        return newFunc\n    return aux_deprecated", "response": "A decorator to mark a fct as deprecated."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef engine_schema(engine, out_names=None, filename=None, format=\"pdf\"):\n    import graphviz as pgv\n    #engine.validate()\n    dg = pgv.Digraph(format=format)\n    input_node_name = \"in\"\n    output_node_name = \"out\"\n    dg.node(input_node_name, label=input_node_name, shape=\"ellipse\")\n    block_source = {} # witch block is the source for witch data\n    for e_in_name in engine.in_name:\n        block_source[e_in_name] = input_node_name\n    # creation des sommets\n    for block in engine:\n        dg.node(block.name, label=' %s ' % block.name, shape=\"box\")\n    # creation des liens\n    for block in engine:\n        for in_name in block.in_name:\n            dg.edge(block_source[in_name], block.name,\n                label=\" %s \" % in_name,\n                #fontsize=10,\n            )\n        block_source[block.out_name] = block.name\n    \n    if out_names is None:\n        out_names = set([block.out_name for block in engine])\n    \n    if len(out_names):\n        dg.node(output_node_name, label=' %s ' % output_node_name, shape=\"ellipse\")\n        for out_name in out_names:\n            if out_name not in block_source:\n                raise ValueError(\"'%s' is not a generated data\" % out_name)\n            dg.edge(block_source[out_name], output_node_name,\n                label=\" %s \" % out_name,\n                #fontsize=10,\n            )\n    if filename:\n        dg.render(filename)\n    return dg", "response": "Build a graphviz schema of a reliure. Engine."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling documentation: `/user/register <https://www.wepay.com/developer/reference/user#register>`_, plus extra keyword parameter: :keyword bool batch_mode: turn on/off the batch_mode, see :class:`wepay.api.WePay` :keyword str batch_reference_id: `reference_id` param for batch call, see :class:`wepay.api.WePay` :keyword str api_version: WePay API version, see :class:`wepay.api.WePay` .. note :: This call is NOT supported by API versions older then '2014-01-08'.", "response": "def __register(self, client_id, client_secret, email, scope, first_name,\n                   last_name, original_ip, original_device, **kwargs):\n        \"\"\"Call documentation: `/user/register\n        <https://www.wepay.com/developer/reference/user#register>`_, plus\n        extra keyword parameter:\n        \n        :keyword bool batch_mode: turn on/off the batch_mode, see \n           :class:`wepay.api.WePay`\n\n        :keyword str batch_reference_id: `reference_id` param for batch call,\n           see :class:`wepay.api.WePay`\n\n        :keyword str api_version: WePay API version, see\n           :class:`wepay.api.WePay`\n\n        .. note ::\n\n            This call is NOT supported by API versions older then '2014-01-08'.\n\n        \"\"\"\n        params = {\n            'client_id': client_id, \n            'client_secret': client_secret, \n            'email': email, \n            'scope': scope, \n            'first_name': first_name,\n            'last_name': last_name, \n            'original_ip': original_ip, \n            'original_device': original_device\n        }\n        return self.make_call(self.__register, params, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __validate_cookie(self, mfa_id, cookie, **kwargs):\n        params = {\n            'mfa_id': mfa_id,\n            'cookie': cookie\n        }\n        return self.make_call(self.__validate_cookie, params, kwargs)", "response": "Method to validate a cookie for a user in a MFA."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __send_challenge(self, mfa_id, **kwargs):\n        params = {\n            'mfa_id': mfa_id\n        }\n        return self.make_call(self.__send_challenge, params, kwargs)", "response": "Send a challenge to the user MFA."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending default challenge for a specific key.", "response": "def __send_default_challenge(self, **kwargs):\n        \"\"\"Call documentation: `/user/mfa/send_default_challenge\n        <https://www.wepay.com/developer/reference/user-mfa#send_default_challenge>`_,\n        plus extra keyword parameter:\n        \n        :keyword bool batch_mode: turn on/off the batch_mode, see \n           :class:`wepay.api.WePay`\n\n        :keyword str batch_reference_id: `reference_id` param for batch call,\n           see :class:`wepay.api.WePay`\n\n        :keyword str api_version: WePay API version, see\n           :class:`wepay.api.WePay`\n\n        \"\"\"\n        params = {}\n        return self.make_call(self.__send_default_challenge, params, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __confirm(self, mfa_id, challenge, **kwargs):\n        params = {\n            'mfa_id': mfa_id,\n            'challenge': challenge\n        }\n        return self.make_call(self.__confirm, params, kwargs)", "response": "This method is used to confirm a user s user s MFA."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmodifies the user s internal state of a user s internal state.", "response": "def __modify(self, mfa_id, **kwargs):\n        \"\"\"Call documentation: `/user/mfa/modify\n        <https://www.wepay.com/developer/reference/user-mfa#modify>`_,\n        plus extra keyword parameter:\n        \n        :keyword bool batch_mode: turn on/off the batch_mode, see \n           :class:`wepay.api.WePay`\n\n        :keyword str batch_reference_id: `reference_id` param for batch call,\n           see :class:`wepay.api.WePay`\n\n        :keyword str api_version: WePay API version, see\n           :class:`wepay.api.WePay`\n\n        \"\"\"\n        params = {\n            'mfa_id': mfa_id\n        }\n        return self.make_call(self.__modify, params, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_basic_logger(level=logging.WARN, scope='reliure'):\n    logger = logging.getLogger(scope)\n    logger.setLevel(level)\n    # create console handler with a higher log level\n    ch = logging.StreamHandler()\n    ch.setLevel(level)\n    # create formatter and add it to the handlers\n    formatter = ColorFormatter('%(asctime)s:%(levelname)s:%(name)s:%(message)s')\n    ch.setFormatter(formatter)\n    # add the handlers to the logger\n    logger.addHandler(ch)   \n    return logger", "response": "return a basic logger that print on stdout msg from reliure lib\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the logging for an app using reliure lib and the app logger", "response": "def get_app_logger_color(appname, app_log_level=logging.INFO, log_level=logging.WARN, logfile=None):\n    \"\"\" Configure the logging for an app using reliure (it log's both the app and reliure lib)\n\n    :param appname: the name of the application to log\n    :parap app_log_level: log level for the app\n    :param log_level: log level for the reliure\n    :param logfile: file that store the log, time rotating file (by day), no if None\n    \"\"\"\n    # create lib handler\n    stderr_handler = logging.StreamHandler()\n    stderr_handler.setLevel(log_level)\n    # create formatter and add it to the handlers\n    name = \"reliure\"\n    name += \"_\"*(max(0, len(appname)-len(name)))\n    formatter = ColorFormatter('$BG-BLUE$WHITE%s$RESET:%%(asctime)s:$COLOR%%(levelname)s$RESET:$BOLD%%(name)s$RESET: %%(message)s' % name)\n    stderr_handler.setFormatter(formatter)\n    # get the logers it self\n    logger = logging.getLogger(\"reliure\")\n    logger.setLevel(logging.DEBUG)\n    # add the handlers to the loggers\n    logger.addHandler(stderr_handler)\n    \n    # create app handler\n    app_stderr_handler = logging.StreamHandler()\n    app_stderr_handler.setLevel(app_log_level)\n    # create formatter and add it to the handlers\n    app_formatter = ColorFormatter(\"$BG-CYAN$WHITE%s$RESET:%%(asctime)s:$COLOR%%(levelname)s$RESET:$BOLD%%(name)s$RESET: %%(message)s\" % appname.upper())\n    app_stderr_handler.setFormatter(app_formatter)\n    # get the logers it self\n    app_logger = logging.getLogger(appname)\n    app_logger.setLevel(logging.DEBUG)\n    # add the handlers to the loggers\n    app_logger.addHandler(app_stderr_handler)\n\n    if logfile is not None:\n        file_format = '%(asctime)s:%(levelname)s:%(name)s: %(message)s'\n        from logging.handlers import TimedRotatingFileHandler\n        file_handler = TimedRotatingFileHandler(logfile, when=\"D\", interval=1, backupCount=7)\n        file_handler.setFormatter(logging.Formatter(file_format))\n        # add the handlers to the loggers\n        logger.addHandler(file_handler)\n        # add the handlers to the loggers\n        app_logger.addHandler(file_handler)\n    return app_logger"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the created_by and last_modified_by fields based on the current admin user.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Save the created_by and last_modified_by fields based on the current admin user.\n        \"\"\"\n        if not self.instance.id:\n            self.instance.created_by = self.user\n        self.instance.last_modified_by = self.user\n        return super(ChangeableContentForm, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_urls(self):\n        urls = super(PageAdmin, self).get_urls()\n        my_urls = patterns('',\n            (r'^add/preview$', self.admin_site.admin_view(PagePreviewView.as_view())),\n            (r'^(?P<id>\\d+)/preview$', self.admin_site.admin_view(PagePreviewView.as_view())),\n            (r'^(?P<id>\\d+)/history/(\\d+)/preview$', self.admin_site.admin_view(PagePreviewView.as_view())),\n        )\n        return my_urls + urls", "response": "Add our preview view to our urls."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_template_names(self):\n        posted_name = self.request.POST.get('template_name')\n        if posted_name:\n            return [posted_name,]\n        else:\n            return super(PagePreviewView, self).get_template_names()", "response": "Return the page s specified template name or fallback if one hasn t been chosen."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post(self, request, *args, **kwargs):\n        self.object = self.get_object()\n        self.object.content = request.POST['content']\n        self.object.title = request.POST['title']\n\n        self.object = self._mark_html_fields_as_safe(self.object)\n        context = self.get_context_data(object=self.object)\n        return self.render_to_response(context, content_type=self.get_mimetype())", "response": "Accepts POST requests and substitute the data in for the page s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef redirect_stdout(self):\n        self.hijacked_stdout = sys.stdout\n        self.hijacked_stderr = sys.stderr\n        # 0 must be set as the buffer, otherwise lines won't get logged in time.\n        sys.stdout = open(self.hitch_dir.driverout(), \"ab\", 0)\n        sys.stderr = open(self.hitch_dir.drivererr(), \"ab\", 0)", "response": "Redirect stdout to file so that it can be tailed and aggregated with the other logs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nredirecting stdout and stderr back to screen.", "response": "def unredirect_stdout(self):\n        \"\"\"Redirect stdout and stderr back to screen.\"\"\"\n        if hasattr(self, 'hijacked_stdout') and hasattr(self, 'hijacked_stderr'):\n            sys.stdout = self.hijacked_stdout\n            sys.stderr = self.hijacked_stderr"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmocking moving forward or backward in time by shifting the system clock fed to the services tested.", "response": "def time_travel(self, datetime=None, timedelta=None, seconds=0, minutes=0, hours=0, days=0):\n        \"\"\"Mock moving forward or backward in time by shifting the system clock fed to the services tested.\n\n        Note that all of these arguments can be used together, individually or not at all. The time\n        traveled to will be the sum of all specified time deltas from datetime. If no datetime is specified,\n        the deltas will be added to the current time.\n\n        Args:\n            datetime (Optional[datetime]): Time travel to specific datetime.\n            timedelta (Optional[timedelta]): Time travel to 'timedelta' from now.\n            seconds (Optional[number]): Time travel 'seconds' seconds from now.\n            minutes (Optional[number]): Time travel 'minutes' minutes from now.\n            hours (Optional[number]): Time travel 'hours' hours from now.\n            days (Optional[number]): Time travel 'days' days from now.\n        \"\"\"\n        if datetime is not None:\n            self.timedelta = datetime - python_datetime.now()\n        if timedelta is not None:\n            self.timedelta = self.timedelta + timedelta\n        self.timedelta = self.timedelta + python_timedelta(seconds=seconds)\n        self.timedelta = self.timedelta + python_timedelta(minutes=minutes)\n        self.timedelta = self.timedelta + python_timedelta(hours=hours)\n        self.timedelta = self.timedelta + python_timedelta(days=days)\n        log(\"Time traveling to {}\\n\".format(humanize.naturaltime(self.now())))\n        faketime.change_time(self.hitch_dir.faketime(), self.now())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for an IPython kernel - nnnn. json filename message to appear in log.", "response": "def wait_for_ipykernel(self, service_name, timeout=10):\n        \"\"\"Wait for an IPython kernel-nnnn.json filename message to appear in log.\"\"\"\n        kernel_line = self._services[service_name].logs.tail.until(\n            lambda line: \"--existing\" in line[1], timeout=10, lines_back=5\n        )\n        return kernel_line.replace(\"--existing\", \"\").strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect_to_ipykernel(self, service_name, timeout=10):\n        kernel_json_file = self.wait_for_ipykernel(service_name, timeout=10)\n        self.start_interactive_mode()\n        subprocess.check_call([\n            sys.executable, \"-m\", \"IPython\", \"console\", \"--existing\", kernel_json_file\n        ])\n        self.stop_interactive_mode()", "response": "Connect to an IPython kernel as soon as its message is logged."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a graph of the DictCell subclass structure.", "response": "def build_class_graph(modules, klass=None, graph=None):\n        \"\"\" Builds up a graph of the DictCell subclass structure \"\"\"\n        if klass is None:\n            class_graph = nx.DiGraph()\n            for name, classmember in inspect.getmembers(modules, inspect.isclass):\n                if issubclass(classmember, Referent) and classmember is not Referent:\n                    TaxonomyCell.build_class_graph(modules, classmember, class_graph)\n            return class_graph\n        else:\n            parents = getattr(klass, '__bases__')\n            for parent in parents:\n                if parent != Referent:\n                    graph.add_edge(parent.__name__, klass.__name__)\n                    # store pointer to classes in property 'class'\n                    graph.node[parent.__name__]['class'] = parent\n                    graph.node[klass.__name__]['class'] = klass \n                    if issubclass(parent, Referent):\n                        TaxonomyCell.build_class_graph(modules, parent, graph)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cells_from_defaults(clz, jsonobj):\n        # convert strings to dicts\n        if isinstance(jsonobj, (str, unicode)):\n            jsonobj = json.loads(jsonobj)\n        \n        assert 'cells' in jsonobj, \"No cells in object\"\n       \n        domain = TaxonomyCell.get_domain()\n        cells = []\n        for num, cell_dna in enumerate(jsonobj['cells']):\n            assert 'kind' in cell_dna, \"No type definition\"\n            classgenerator = domain.node[cell_dna['kind']]['class']\n            cell = classgenerator()\n            cell['num'].merge(num)\n            for attr, val in cell_dna.items():\n                if not attr in ['kind']:\n                    cell[attr].merge(val)\n                    cells.append(cell)\n        return cells", "response": "Creates a referent instance of type json. kind and \n        initializes it to default values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_defaults(clz, defaults):\n        if isinstance(defaults, (str, unicode)):\n            defaults = json.loads(defaults)\n        \n        c = clz()\n        for attribute in defaults.keys():\n            if attribute in c:\n                value = defaults[attribute]\n                c[attribute].merge(value)\n        # in case any values were not specified, attempt to merge them with \n        # the settings provided by clz.random()\n        cr = clz.random()\n        for attribute, value in cr:\n            try:\n                c[attribute].merge(value)\n            except Contradiction:\n                pass\n        return c", "response": "Given a dictionary of defaults returns a new instance of the class and merges the defaults with the values provided by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets element types as a set.", "response": "def get_element_types(obj, **kwargs):\n    \"\"\"Get element types as a set.\"\"\"\n\n    max_iterable_length = kwargs.get('max_iterable_length', 10000)\n    consume_generator = kwargs.get('consume_generator', False)\n\n    if not isiterable(obj):\n        return None\n\n    if isgenerator(obj) and not consume_generator:\n        return None\n\n    t = get_types(obj, **kwargs)\n\n    if not t['too_big']:\n        if t['types']:\n            return \"Element types: {}\".format(', '.join([extract_type(t) for t in t['types']]))\n        else:\n            return None\n    else:\n        return \"Element types: {}\".format(', '.join([extract_type(t) for t in t['types']])) + \" (based on first {} elements.)\".format(max_iterable_length)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parseArgs(args):\n\n\t# If args is not a list\n\tif not isinstance(args, (list,tuple)):\n\t\traise ValueError('args is not a list or tuple')\n\n\t# Init the return value\n\tdRet\t= {}\n\n\t# Go through each argument\n\tfor s in args:\n\n\t\t# Check the string matches the format\n\t\toRes\t= re.match(u'^--([^=]+)(?:=(.+))?$', s)\n\n\t\t# If we have a match\n\t\tif oRes:\n\n\t\t\t# Store it by name and value\n\t\t\tmGroup2\t= oRes.group(2)\n\t\t\tdRet[oRes.group(1)]\t= (not mGroup2 and True or mGroup2)\n\n\t\t# Else add it to the unknowns\n\t\telse:\n\t\t\ttry:\t\t\t\tdRet['?'].append(s)\n\t\t\texcept KeyError:\tdRet['?'] = [s]\n\n\t# Return the dict\n\treturn dRet", "response": "Parse the arguments passed to the script\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef printHelp(script):\n\n\tprint 'Reconsider cli script copyright 2016 OuroborosCoding'\n\tprint ''\n\tprint script + ' --source=localhost:28015 --destination=somedomain.com:28015'\n\tprint script + ' --destination=somedomain.com:28015 --dbs=production,staging'\n\tprint ''\n\tprint 'Usage:'\n\tprint '  --source=[string]         A RethinkDB connection string representing the'\n\tprint '                            source host. Defaults to \"localhost:28015\"'\n\tprint '  --destination=[string]    A RethinkDB connection string representing the'\n\tprint '                            destination host. Required.'\n\tprint '  --db                      A single DB name, or a comma separated list of'\n\tprint '                            databases on the source which will be copied to the'\n\tprint '                            destination. Defaults to all DBs on the source'\n\tprint '                            host'\n\tprint '  --verbose                 Will print out what\\'s happening during the clone'\n\tprint '  --help                    Prints this message'\n\tprint ''\n\tprint 'A RethinkDB connection string is defined as: host[:port[:user[:password]]]'\n\tprint 'Valid:          localhost, localhost:28015, localhost:28015:root:asdf'\n\tprint 'Invalid:        localhost:root, 28015, root:asdf, localhost:root:asdf'", "response": "Print Help for the command line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating stats directory for storing stat files.", "response": "def _setup_dir(self, base_dir):\n        \"\"\" Creates stats directory for storing stat files.\n\n            `base_dir`\n                Base directory.\n            \"\"\"\n        stats_dir = self._sdir(base_dir)\n\n        if not os.path.isdir(stats_dir):\n            try:\n                os.mkdir(stats_dir)\n            except OSError:\n                raise errors.DirectorySetupFail()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_task(self, task):\n        if not task.duration:\n            return\n\n        self._setup_dir(task.base_dir)\n        stats_dir = self._sdir(task.base_dir)\n        duration = task.duration\n\n        while duration > 0:\n            # build filename\n            date = (datetime.datetime.now() -\n                    datetime.timedelta(minutes=duration))\n            date_str = date.strftime('%Y%m%d')\n            filename = os.path.join(stats_dir, '{0}.json'.format(date_str))\n\n            with open(filename, 'a+') as file_:\n                # fetch any existing data\n                try:\n                    file_.seek(0)\n                    data = json.loads(file_.read())\n                except (ValueError, OSError):\n                    data = {}\n\n                if not task.name in data:\n                    data[task.name] = 0\n\n                # how much total time for day\n                try:\n                    total_time = sum(int(x) for x in data.values())\n                    if total_time > MINS_IN_DAY:\n                        total_time = MINS_IN_DAY\n\n                except ValueError:\n                    total_time = 0\n\n                # constrain to single day\n                amount = duration\n                if amount + total_time > MINS_IN_DAY:\n                    amount = MINS_IN_DAY - total_time\n\n                    # invalid or broken state, bail\n                    if amount <= 0:\n                        break\n\n                data[task.name] += amount\n                duration -= amount\n\n                # write file\n                try:\n                    file_.seek(0)\n                    file_.truncate(0)\n                    file_.write(json.dumps(data))\n                except (ValueError, OSError):\n                    pass", "response": "Logs a task record to file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fuzzy_time_parse(self, value):\n\n        value = value.lower().strip()\n        today = datetime.date.today()\n\n        if value in ('today', 't'):\n            return today\n\n        else:\n            kwargs = {}\n\n            if value in ('y', 'yesterday'):\n                kwargs['days'] = -1\n\n            elif value in ('w', 'wk', 'week', 'last week'):\n                kwargs['days'] = -7\n\n            else:\n                # match days\n                match = re.match(r'(\\d+)\\s*(d|day|days)\\s*(ago)?$', value)\n                if match:\n                    kwargs['days'] = -int(match.groups(1)[0])\n\n                else:\n                    # match weeks\n                    match = re.match(r'(\\d+)\\s*(w|wk|week|weeks)\\s*(ago)?$',\n                                     value)\n                    if match:\n                        kwargs['weeks'] = -int(match.groups(1)[0])\n\n            if kwargs:\n                return today + datetime.timedelta(**kwargs)\n\n            return None", "response": "Parses a fuzzy time value into a meaningful interpretation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_stats(self, task, start_date):\n\n        stats = []\n        stats_dir = self._sdir(task.base_dir)\n        date = start_date\n        end_date = datetime.date.today()\n        delta = datetime.timedelta(days=1)\n\n        while date <= end_date:\n            date_str = date.strftime('%Y%m%d')\n            filename = os.path.join(stats_dir, '{0}.json'.format(date_str))\n\n            if os.path.exists(filename):\n                try:\n                    # fetch stats content\n                    with open(filename, 'r') as file_:\n                        data = json.loads(file_.read())\n\n                    # sort descending by time\n                    stats.append((date, sorted(data.iteritems(),\n                                               key=lambda x: x[1],\n                                               reverse=True)))\n\n                except (json.JSONDecodeError, OSError):\n                    pass\n\n            date += delta  # next day\n\n        return stats", "response": "Fetch statistics for given task and start range."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _print_stats(self, env, stats):\n\n        def _format_time(mins):\n            \"\"\" Generates formatted time string.\n                \"\"\"\n            mins = int(mins)\n\n            if mins < MINS_IN_HOUR:\n                time_str = '0:{0:02}'.format(mins)\n            else:\n                hours = mins // MINS_IN_HOUR\n                mins %= MINS_IN_HOUR\n\n                if mins > 0:\n                    time_str = '{0}:{1:02}'.format(hours, mins)\n                else:\n                    time_str = '{0}'.format(hours)\n\n            return time_str\n\n        if not stats:\n            env.io.write('No stats found.')\n            return\n\n        for date, tasks in stats:\n            env.io.write('')\n            total_mins = float(sum(v[1] for v in tasks))\n            env.io.write('[ {0} ]'.format(date.strftime('%Y-%m-%d')))\n            env.io.write('')\n\n            for name, mins in tasks:\n                # format time\n                time_str = _format_time(mins)\n\n                # generate stat line\n                line = '   {0:>5}'.format(time_str)\n                line += ' ({0:2.0f}%) - '.format(mins * 100.0 / total_mins)\n                if len(name) > 55:\n                    name = name[:55] + '...'\n                line += name\n                env.io.write(line)\n\n            # generate total line\n            env.io.write('_' * len(line))\n            time_str = _format_time(total_mins)\n            env.io.write('   {0:>5} (total)'.format(time_str))\n            env.io.write('')", "response": "Prints the statistics of the current user and the tasks in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, env, args):\n\n        start = self._fuzzy_time_parse(args.start)\n        if not start:\n            raise errors.FocusError(u'Invalid start period provided')\n\n        stats = self._get_stats(env.task, start)\n        self._print_stats(env, stats)", "response": "Prints task information.\n\n            `env`\n                Runtime ``Environment`` instance.\n            `args`\n                Arguments object from arg parser."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_executable(executable: str, *paths: str) -> typing.Optional[Path]:\n\n    if not executable.endswith('.exe'):\n        executable = f'{executable}.exe'\n\n    if executable in _KNOWN_EXECUTABLES:\n        return _KNOWN_EXECUTABLES[executable]\n\n    output = f'{executable}'\n\n    if not paths:\n        path = os.environ['PATH']\n        paths = tuple([str(Path(sys.exec_prefix, 'Scripts').absolute())] + path.split(os.pathsep))\n    executable_path = Path(executable).absolute()\n    if not executable_path.is_file():\n        for path_ in paths:\n            executable_path = Path(path_, executable).absolute()\n            if executable_path.is_file():\n                break\n        else:\n            _LOGGER.error('%s -> not found', output)\n            return None\n\n    _KNOWN_EXECUTABLES[executable] = executable_path\n    _LOGGER.info('%s -> %s', output, str(executable_path))\n    return executable_path", "response": "Find the path to an executable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling to create the work space", "response": "def create(self):\n        \"\"\"called to create the work space\"\"\"\n        self.logger.log(logging.DEBUG, 'os.mkdir %s', self.name)\n        os.mkdir(self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing object into a list of objects.", "response": "def parse_obj(obj):\n    \"\"\"\n    >>> parse_obj('bucket/key')\n    ('bucket', 'key')\n    >>> parse_obj('my-bucket/path/to/file.txt')\n    ('my-bucket', 'path/to/file.txt')\n    >>> parse_obj('s3://this_bucket/some/path.txt')\n    ('this_bucket', 'some/path.txt')\n    >>> parse_obj('https://s3.amazonaws.com/bucket/file.txt')\n    ('bucket', 'file.txt')\n    >>> parse_obj('http://the-bucket.s3.amazonaws.com/the/file.txt')\n    ('the-bucket', 'the/file.txt')\n    \"\"\"\n    obj = obj.lstrip('s3://')\n    if obj.startswith('http'):\n        url = urlparse.urlparse(obj)\n        if url.netloc == 's3.amazonaws.com':\n            path = url.path[1:]  # remove leading slash\n            bucket, key = path.split('/', 1)\n        else:\n            # bucket.s3.amazonaws.com form\n            bucket = url.netloc.split('.', 1)[0]\n            key = url.path[1:]\n    else:\n        bucket, key = obj.split('/', 1)\n    return bucket, key"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters two BED files and output them in a BED file.", "response": "def ambigFilter(in_fh1, in_fh2, out_fh1, out_fh2, verbose=False, best=False):\n  \"\"\"\n    @summary: take reads from in_fh1 and output to out_fh1 if they don't\n              appear also in in_fh2 (ditto for in_fh2)\n\n    @param in_fh1: BED formated stream of reads\n    @param in_fh2: BED formated stream of reads\n    @param out_fh1: Output reads that pass from in_fh1 to this stream\n    @param out_fh2: Output reads that pass from in_fh2 to this stream\n    @param verbose: output additional messages to sys.stderr if True\n    @param best: Given two items that have the same name, try to output the one\n                 with the best score\n\n    @return: None (out streams have BED format)\n  \"\"\"\n  for r1, r2 in BEDUniqueIterator(in_fh1, in_fh2, verbose, best, dropAfter=6):\n    if r1 is not None:\n      out_fh1.write(str(r1) + \"\\n\")\n    if r2 is not None:\n      out_fh2.write(str(r2) + \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bodycomp(mass, tbw, method='reilly', simulate=False, n_rand=1000):\n    '''Create dataframe with derived body composition values\n\n    Args\n    ----\n    mass: ndarray\n        Mass of the seal (kg)\n    tbw: ndarray\n        Total body water (kg)\n    method: str\n        name of method used to derive composition values\n    simulate: bool\n        switch for generating values with random noise\n    n_rand: int\n        number of density values to simulate\n\n    Returns\n    -------\n    field: pandas.Dataframe\n        dataframe containing columns for each body composition value\n\n    References\n    ----------\n    Reilly, J.J., Fedak, M.A., 1990. Measurement of the body composition of\n    living gray seals by hydrogen isotope dilution. Journal of Applied\n    Physiology 69, 885\u2013891.\n\n    Gales, R., Renouf, D., Noseworthy, E., 1994. Body composition of harp\n    seals. Canadian journal of zoology 72, 545\u2013551.\n    '''\n    import numpy\n    import pandas\n\n    if len(mass) != len(tbw):\n        raise SystemError('`mass` and `tbw` arrays must be the same length')\n\n    bc = pandas.DataFrame(index=range(len(mass)))\n\n    rnorm = lambda n, mu, sigma: numpy.random.normal(mu, sigma, n)\n\n    if method == 'reilly':\n        if simulate is True:\n            bc['ptbw'] = 100 * (tbw / mass)\n            bc['ptbf'] = 105.1 - (1.47 * bc['ptbw']) + rnorm(n_rand, 0, 1.1)\n            bc['ptbp'] = (0.42 * bc['ptbw']) - 4.75 + rnorm(n_rand, 0, 0.8)\n            bc['tbf'] = mass * (bc['ptbf'] / 100)\n            bc['tbp'] = mass * (bc['ptbp'] / 100)\n            bc['tba'] = 0.1 - (0.008 * mass) + \\\n                               (0.05 * tbw) + rnorm(0, 0.3, n_rand)\n            bc['tbge'] = (40.8 * mass) - (48.5 * tbw) - \\\n                          0.4 + rnorm(0, 17.2, n_rand)\n        else:\n            bc['ptbw'] = 100 * (tbw / mass)\n            bc['ptbf'] = 105.1 - (1.47 * bc['ptbw'])\n            bc['ptbp'] = (0.42 * bc['ptbw']) - 4.75\n            bc['tbf'] = mass * (bc['ptbf'] / 100)\n            bc['tbp'] = mass * (bc['ptbp'] / 100)\n            bc['tba'] = 0.1 - (0.008 * mass) + (0.05 * tbw)\n            bc['tbge'] = (40.8 * mass) - (48.5 * tbw) - 0.4\n    elif method == 'gales':\n        if simulate is True:\n            raise ValueError('Random error simulation is currently only '\n                'implemented for `method` `reilly`. `simulate` must be passed '\n                'as `False` when using `method` `gales`.')\n        else:\n            bc['ptbw'] = 100 * (tbw / mass)\n            bc['tbf'] = mass - (1.37 * tbw)\n            bc['tbp'] = 0.27 * (mass - bc['tbf'])\n            bc['tbge'] = (40.8 * mass) - (48.5 * tbw) - 0.4\n            bc['ptbf'] = 100 * (bc['tbf'] / mass)\n            bc['ptbp'] = 100 * (bc['tbp'] / mass)\n    else:\n        raise ValueError('`method` must be either `reilly` or `gales`, not '\n            '`{}`'.format(method))\n\n    return bc", "response": "Create dataframe with derived body composition values for the Seal and Total Body Water."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate body composition component percentages based on percent lipid and percent ash values.", "response": "def perc_bc_from_lipid(perc_lipid, perc_water=None):\n    '''Calculate body composition component percentages based on % lipid\n\n    Calculation of percent protein and percent ash are based on those presented\n    in Reilly and Fedak (1990).\n\n    Args\n    ----\n    perc_lipid: float or ndarray\n        1D array of percent lipid values from which to calculate body composition\n    perc_water: float or ndarray\n        1D array of percent water values from which to calculate body\n        composition (Default `None`). If no values are passed, calculations are\n        performed with values from Biuw et al. (2003).\n\n    Returns\n    -------\n    perc_water: float or ndarray\n        1D array of percent water values\n    perc_protein: float or ndarray\n        1D array of percent protein values\n    perc_ash: float or ndarray\n        1D array of percent ash values\n\n    References\n    ----------\n    Biuw, M., 2003. Blubber and buoyancy: monitoring the body condition of\n    free-ranging seals using simple dive characteristics. Journal of\n    Experimental Biology 206, 3405\u20133423. doi:10.1242/jeb.00583\n\n    Reilly, J.J., Fedak, M.A., 1990. Measurement of the body composition of\n    living gray seals by hydrogen isotope dilution. Journal of Applied\n    Physiology 69, 885\u2013891.\n    '''\n    import numpy\n\n    # Cast iterables to numpy arrays\n    if numpy.iterable(perc_lipid):\n        perc_lipid = numpy.asarray(perc_lipid)\n    if numpy.iterable(perc_water):\n        perc_water = numpy.asarray(perc_water)\n\n    if not perc_water:\n        # TODO check where `perc_water` values come from\n        perc_water   = 71.4966 - (0.6802721 * perc_lipid)\n\n    perc_protein = (0.42 * perc_water) - 4.75\n    perc_ash     = 100 - (perc_lipid + perc_water + perc_protein)\n\n    return perc_water, perc_protein, perc_ash"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nderives tissue density from lipids and densities of a base class", "response": "def lip2dens(perc_lipid, dens_lipid=0.9007, dens_prot=1.34, dens_water=0.994,\n        dens_ash=2.3):\n    '''Derive tissue density from lipids\n\n    The equation calculating animal density is from Biuw et al. (2003), and\n    default values for component densities are from human studies collected in\n    the book by Moore et al. (1963).\n\n    Args\n    ----\n    perc_lipid: float or ndarray\n        Percent lipid of body composition\n    dens_lipid: float\n        Density of lipid in animal (Default 0.9007 g/cm^3)\n    dens_prot: float\n        Density of protein in animal (Default 1.34 g/cm^3)\n    dens_water: float\n        Density of water in animal (Default 0.994 g/cm^3)\n    dens_ash: float\n        Density of ash in animal (Default 2.3 g/cm^3)\n\n    Returns\n    -------\n    dens_gcm3: float or ndarray\n        Density of seal calculated from percent compositions and densities of\n        components from Moore et al. (1963)\n\n    References\n    ----------\n    Biuw, M., 2003. Blubber and buoyancy: monitoring the body condition of\n    free-ranging seals using simple dive characteristics. Journal of\n    Experimental Biology 206, 3405\u20133423. doi:10.1242/jeb.00583\n\n    Moore FD, Oleson KH, McMurrery JD, Parker HV, Ball MR, Boyden CM. The Body\n    Cell Mass and Its Supporting Environment - The Composition in Health and\n    Disease. Philadelphia: W.B. Saunders Company; 1963. 535 p.\n    ISBN:0-7216-6480-6\n    '''\n    import numpy\n\n    # Cast iterables to numpy array\n    if numpy.iterable(perc_lipid):\n        perc_lipid = numpy.asarray(perc_lipid)\n\n    perc_water, perc_protein, perc_ash = perc_bc_from_lipid(perc_lipid)\n\n    dens_gcm3 = (dens_lipid * (0.01 * perc_lipid)) + \\\n                (dens_prot  * (0.01 * perc_protein)) + \\\n                (dens_water * (0.01 * perc_water)) + \\\n                (dens_ash   * (0.01 * perc_ash))\n\n    return dens_gcm3"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dens2lip(dens_gcm3, dens_lipid=0.9007, dens_prot=1.34, dens_water=0.994,\n        dens_ash=2.3):\n    '''Get percent composition of animal from body density\n\n    The equation calculating animal density is from Biuw et al. (2003), and\n    default values for component densities are from human studies collected in\n    the book by Moore et al. (1963).\n\n    Args\n    ----\n    dens_gcm3: float or ndarray\n        An array of seal densities (g/cm^3). The calculations only yield valid\n        percents with densities between 0.888-1.123 with other parameters left\n        as defaults.\n    dens_lipid: float\n        Density of lipid content in the animal (g/cm^3)\n    dens_prot: float\n        Density of protein content in the animal (g/cm^3)\n    dens_water: float\n        Density of water content in the animal (g/cm^3)\n    dens_ash: float\n        Density of ash content in the animal (g/cm^3)\n\n    Returns\n    -------\n    perc_all: pandas.DataFrame\n        Dataframe of components of body composition\n\n    References\n    ----------\n    Biuw, M., 2003. Blubber and buoyancy: monitoring the body condition of\n    free-ranging seals using simple dive characteristics. Journal of\n    Experimental Biology 206, 3405\u20133423. doi:10.1242/jeb.00583\n\n    Moore FD, Oleson KH, McMurrery JD, Parker HV, Ball MR, Boyden CM. The Body\n    Cell Mass and Its Supporting Environment - The Composition in Health and\n    Disease. Philadelphia: W.B. Saunders Company; 1963. 535 p.\n    ISBN:0-7216-6480-6\n    '''\n    import numpy\n\n    # Cast iterables to numpy array\n    if numpy.iterable(dens_gcm3):\n        dens_gcm3 = numpy.asarray(dens_gcm3)\n\n    # Numerators\n    ad_num =  -3.2248 * dens_ash\n    pd_num = -25.2786 * dens_prot\n    wd_num = -71.4966 * dens_water\n\n    # Denominators\n    ad_den = -0.034  * dens_ash\n    pd_den = -0.2857 * dens_prot\n    wd_den = -0.6803 * dens_water\n\n    perc_lipid = ((100 * dens_gcm3) + ad_num + pd_num + wd_num) / \\\n                        (dens_lipid + ad_den + pd_den + wd_den)\n\n    return perc_lipid", "response": "Get percent composition of animal from body density dens_gcm3 dens_prot dens_water and dens_ash"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef diff_speed(sw_dens=1.028, dens_gcm3=1.053, seal_length=300, seal_girth=200,\n        Cd=0.09):\n    '''Calculate terminal velocity of animal with a body size\n\n    Args\n    ----\n    sw_dens: float\n        Density of seawater (g/cm^3)\n    dens_gcm3: float\n        Density of animal (g/cm^3)\n    seal_length: float\n        Length of animal (cm)\n    seal_girth: float\n        Girth of animal (cm)\n    Cd: float\n        Drag coefficient of object in fluid, unitless\n\n    Returns\n    -------\n    Vt: float\n        Terminal velocity of animal with given body dimensions (m/s).\n\n    References\n    ----------\n    Biuw, M., 2003. Blubber and buoyancy: monitoring the body condition of\n    free-ranging seals using simple dive characteristics. Journal of\n    Experimental Biology 206, 3405\u20133423. doi:10.1242/jeb.00583\n\n    Vogel, S., 1994. Life in Moving Fluids: The Physical Biology of Flow.\n    Princeton University Press.\n    '''\n    import numpy\n\n    surf, vol = surf_vol(seal_length, seal_girth)\n\n    Fb = buoyant_force(dens_gcm3, vol, sw_dens)\n\n    x = 2 * (Fb/(Cd * sw_dens * (surf*1000)))\n\n    if x >= 0:\n        Vt = numpy.sqrt(x)\n    else:\n        Vt = -numpy.sqrt(-x)\n\n    return Vt", "response": "Calculate the terminal velocity of an animal with a given body size."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef surf_vol(length, girth):\n    '''Calculate the surface volume of an animal from its length and girth\n\n    Args\n    ----\n    length: float or ndarray\n        Length of animal (m)\n    girth: float or ndarray\n        Girth of animal (m)\n\n    Returns\n    -------\n    surf:\n        Surface area of animal (m^2)\n    vol: float or ndarray\n        Volume of animal (m^3)\n    '''\n    import numpy\n\n    a_r   = 0.01 * girth / (2 * numpy.pi)\n    stl_l = 0.01 * length\n    c_r   = stl_l / 2\n    e    = numpy.sqrt(1-(a_r**2/c_r**2))\n\n    surf = ((2*numpy.pi * a_r**2) + \\\n           (2*numpy.pi * ((a_r * c_r)/e)) * 1/(numpy.sin(e)))\n\n    vol  = (((4/3) * numpy.pi)*(a_r**2) * c_r)\n\n    return surf, vol", "response": "Calculate the surface volume of an animal from its length and girth."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calc_seal_volume(mass_kg, dens_kgm3, length=None, girth=None):\n    '''Calculate an animal's volume from mass and density or length and girth\n\n    Args\n    ----\n    mass_kg: float or ndarray\n        Mass of animal (kg)\n    dens_kgm3: float or ndarray\n        Density of animal (kg/m^3)\n    length: float or None\n        Length of animal. Default `None` (m)\n    girth: float or None\n        Girth of animal. Default `None` (m)\n\n    Returns\n    -------\n    vol_kgm3: float or ndarray\n        Volume of animal (m^3)\n    '''\n    if (length is not None) and (girth is not None):\n        _, seal_vol = surf_vol(length, girth)\n    else:\n        seal_vol = mass_kg / dens_kgm3\n\n    return seal_vol", "response": "Calculate an animal s volume from mass and density or length and girth."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a search for new Hue objects", "response": "def __find_new(self, hueobjecttype):\n        '''\n        Starts a search for new Hue objects\n        '''\n        assert hueobjecttype in ['lights', 'sensors'], \\\n            'Unsupported object type {}'.format(hueobjecttype)\n        url = '{}/{}'.format(self.API, hueobjecttype)\n        return self._request(\n            method='POST',\n            url=url\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of newly found Hue object", "response": "def __get_new(self, hueobjecttype):\n        '''\n        Get a list of newly found Hue object\n        '''\n        assert hueobjecttype in ['lights', 'sensors'], \\\n            'Unsupported object type {}'.format(hueobjecttype)\n        url = '{}/{}/new'.format(self.API, hueobjecttype)\n        return self._request(url=url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context_manager(self, default):\n        try:\n            self.stack.append(default)\n            yield default\n        finally:\n            if self.enforce_nesting:\n                if self.stack[-1] is not default:\n                    raise AssertionError(\n                        \"Nesting violated for default stack of %s objects\"\n                        % type(default))\n                self.stack.pop()\n            else:\n                self.stack.remove(default)", "response": "A context manager for manipulating a default stack."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print(*args, **kwargs):\n\n    # Pop out color and background values from kwargs\n    color_name = kwargs.pop('color', None)\n    bg_color = kwargs.pop('bg_color', None)\n    log_type = kwargs.pop('log_type', None)\n\n    # Check formats, create a list of text formats\n    txt_formats = kwargs.pop('text_format', [])\n    if sys.version_info[0] == 2:\n        str_type = basestring\n    elif sys.version_info[0] == 3:\n        str_type = str\n    else:\n        str_type = basestring\n    if isinstance(txt_formats, str_type):\n        txt_formats = [txt_formats]\n\n    # Check for file keyword\n    file_name = kwargs.get('file', sys.stdout)\n\n    # Check for foreground and background colors\n    if color_name or bg_color or log_type:\n        # Pop out the 'end' argument\n        end_ = kwargs.pop('end', \"\\n\")\n        kwargs['end'] = \"\"\n\n        # If log type argument is provided\n        if log_type:\n            if log_type not in log_types.keys():\n                print('Log type not valid!', log_type='error')\n                sys.exit(1)\n            if log_type == 'info':\n                __builtin__.print('\\033[{}m[INF] '.format(foreground_colors[log_types[log_type]]), file=file_name, end='')\n                __builtin__.print('\\033[0m', file=file_name, end='')\n            if log_type == 'warn':\n                __builtin__.print('\\033[{}m[WRN] '.format(foreground_colors[log_types[log_type]]), file=file_name, end='')\n                __builtin__.print('\\033[0m', file=file_name, end='')\n            if log_type == 'error':\n                __builtin__.print('\\033[{}m[ERR] '.format(foreground_colors[log_types[log_type]]), file=file_name, end='')\n                __builtin__.print('\\033[0m', file=file_name, end='')\n            if log_type == 'hint':\n                __builtin__.print('\\033[{}m[HNT] '.format(foreground_colors[log_types[log_type]]), file=file_name, end='')\n                __builtin__.print('\\033[0m', file=file_name, end='')\n            if log_type == 'debug':\n                __builtin__.print('\\033[{}m[DBG] '.format(foreground_colors[log_types[log_type]]), file=file_name, end='')\n                __builtin__.print('\\033[0m', file=file_name, end='')\n\n        # If foreground color argument is provided\n        if color_name:\n            if color_name not in foreground_colors.keys():\n                print('Invalid color code!', log_type='error')\n                sys.exit(1)\n            __builtin__.print('\\033[{}m'.format(foreground_colors[color_name]), file=file_name, end='')\n\n        # If background color argument is provided\n        if bg_color:\n            if bg_color not in background_colors.keys():\n                print('Invalid background color code!', log_type='error')\n                sys.exit(1)\n            __builtin__.print('\\033[{}m'.format(background_colors[bg_color]), file=file_name, end='')\n\n        # If text formats are provided\n        for txt_format in txt_formats:\n            __builtin__.print('\\033[{}m'.format(text_formats[txt_format]), file=file_name, end='')\n        # Print values\n        __builtin__.print(*args, **kwargs)\n        # Reset\n        __builtin__.print('\\033[0m',  file=file_name, end=end_)\n    else:\n        __builtin__.print(*args, **kwargs)", "response": "Print a single value to the console."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds in conditional args and then return all conn info.", "response": "def args2body(self, parsed_args, body=None):\n        \"\"\"Add in conditional args and then return all conn info.\"\"\"\n\n        if body is None:\n            body = {}\n        if parsed_args.dpd:\n            vpn_utils.validate_dpd_dict(parsed_args.dpd)\n            body['dpd'] = parsed_args.dpd\n        if parsed_args.local_ep_group:\n            _local_epg = neutronv20.find_resourceid_by_name_or_id(\n                self.get_client(), 'endpoint_group',\n                parsed_args.local_ep_group)\n            body['local_ep_group_id'] = _local_epg\n        if parsed_args.peer_ep_group:\n            _peer_epg = neutronv20.find_resourceid_by_name_or_id(\n                self.get_client(), 'endpoint_group',\n                parsed_args.peer_ep_group)\n            body['peer_ep_group_id'] = _peer_epg\n        return {self.resource: body}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_attribute_values(source, target, property_names):\n    if source is None:\n        raise ValueError('\"source\" must be provided.')\n    if target is None:\n        raise ValueError('\"target\" must be provided.')\n    if property_names is None:\n        raise ValueError('\"property_list\" must be provided.')\n    if (not hasattr(property_names, '__iter__') or\n            isinstance(property_names, str)):\n        raise ValueError(\n            '\"property_names\" must be a sequence type, such as list or set.')\n\n    for property_name in property_names:\n        if hasattr(source, property_name):\n            setattr(target, property_name, getattr(source, property_name))", "response": "Function to copy the values from a source object to a target object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _configure_logging(self):\n        self.log_level = ComponentCore.LOG_LEVEL_MAP.get(self.log_level,\n                                                         logging.ERROR)\n\n        # assign the windmill instance logger\n        self.log = logging.getLogger(self.service_name)\n        self.log.setLevel(self.log_level)\n\n        # cognate_configure log file output if necessary\n        if self.log_path:\n            file_path = self.log_path\n            if not self.log_path.endswith('.log'):\n                file_path = os.path.join(self.log_path,\n                                         self.service_name + '.log')\n\n            file_handler = WatchedFileHandler(file_path)\n            file_handler.setLevel(self.log_level)\n            file_handler.setFormatter(self._log_formatter())\n            self.log.addHandler(file_handler)\n\n        # if we are in verbose mode, the we send log output to console\n        if self.verbose:\n            # add the console logger for verbose mode\n            console_handler = logging.StreamHandler()\n            console_handler.setLevel(self.log_level)\n            console_handler.setFormatter(self._log_formatter())\n            self.log.addHandler(console_handler)\n\n        self.log.info('Logging configured for: %s', self.service_name)", "response": "This method configures the self. log entity for logging."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _execute_configuration(self, argv):\n        if argv is None:\n            argv = []  # just create an empty arg list\n\n        # ensure that sys.argv is not modified in case it was passed.\n        if argv is sys.argv:\n            argv = list(sys.argv)\n\n        # If this is the command line args directly passed, then we need to\n        # remove the first argument which is the python execution command.\n        # The first argument is the name of the executing python script.\n        if len(argv) > 0 and argv[0].endswith('.py'):\n            argv.pop(0)\n\n        # execute configuration_option method on all child classes of\n        # ComponentCore to gather all of the runtime options.\n        arg_parser = argparse.ArgumentParser(\n            formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n        self.invoke_method_on_children(func_name='cognate_options',\n                                       arg_parser=arg_parser)\n\n        # resolve configuration options necessary for runtime execution\n        property_list = []\n        # noinspection PyProtectedMember\n        for action in arg_parser._get_positional_actions():  # pylint: disable=protected-access\n            property_list.append(action.dest)\n            # noinspection PyProtectedMember\n        for action in arg_parser._get_optional_actions():  # pylint: disable=protected-access\n            property_list.append(action.dest)\n        property_list.remove('help')  # remove the help option\n\n        args = arg_parser.parse_args(argv)\n\n        # map the properties to attributes assigned to self instance\n        copy_attribute_values(source=args,\n                              target=self,\n                              property_names=property_list)\n\n        # now execute the configuration call on each base class\n        # in the class inheritance chain\n        self.invoke_method_on_children(func_name='cognate_configure',\n                                       args=args)\n\n        self.log.debug(\n            'Component service configuration complete with argv: %s', args)", "response": "This method is called by the command line interface to execute the configuration of the component."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self):\n        self.log.info('starting the ``get`` method')\n\n        # SPLIT THE LIST OF NAMES INTO BATCHES\n        self.theseBatches, self.theseBatchParams = self._split_incoming_queries_into_batches(\n            sources=self.uplist,\n            searchParams=self.searchParams\n        )\n\n        # PERFORM NAME QUERIES AGAINST NED\n        self._build_api_url_and_download_results()\n        self.results, self.headers = self._parse_the_ned_list_results()\n        self._output_results()\n\n        self.log.info('completed the ``get`` method')\n        return self.results", "response": "get the namesearch object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds api url and download results", "response": "def _build_api_url_and_download_results(\n            self):\n        \"\"\"\n        *build api url for NED to perform batch name queries*\n\n        **Key Arguments:**\n            # -\n\n        **Return:**\n            - None\n\n        .. todo::\n\n            - @review: when complete, clean _build_api_url_and_download_results method\n            - @review: when complete add logging\n        \"\"\"\n        self.log.info(\n            'starting the ``_build_api_url_and_download_results`` method')\n\n        baseUrl = \"https://ned.ipac.caltech.edu/cgi-bin/\"\n        command = \"gmd\"\n        urlParameters = {\n            \"delimiter\": \"bar\",\n            \"NO_LINKS\": \"1\",\n            \"nondb\": [\"row_count\", \"user_name_msg\", \"user_objname\"],\n            \"crosid\": \"objname\",\n            \"enotes\": \"objnote\",\n            \"position\": [\"ra,dec\", \"bhextin\", \"pretype\", \"z\", \"zunc\", \"zflag\"],\n            \"gadata\": [\"magnit\", \"sizemaj\", \"sizemin\", \"morphol\"],\n            \"attdat_CON\": [\"M\", \"S\", \"H\", \"R\", \"z\"],\n            \"distance_CON\": [\"mm\", \"dmpc\"],\n            \"attdat\": \"attned\"\n        }\n\n        queryBase = \"%(baseUrl)s%(command)s?uplist=\" % locals()\n        queryList = []\n\n        # BUILD THE LIST OF QUERIES\n        for batch in self.theseBatches:\n            thisLength = len(batch)\n            queryUrl = queryBase\n            # ADD NAMES\n            for thisIndex, thisName in enumerate(batch):\n                queryUrl = queryUrl + urllib.quote(thisName)\n                if thisIndex < thisLength - 1:\n                    queryUrl = queryUrl + \"%0D\"\n            # ADD PARAMETERS\n            for k, v in urlParameters.iteritems():\n                if isinstance(v, list):\n                    for item in v:\n                        queryUrl = queryUrl + \"&\" + \\\n                            k + \"=\" + urllib.quote(item)\n                else:\n                    queryUrl = queryUrl + \"&\" + k + \"=\" + urllib.quote(v)\n            queryList.append(queryUrl)\n\n        # PULL THE RESULT PAGES FROM NED\n        self.nedResults = multiobject_download(\n            urlList=queryList,\n            downloadDirectory=\"/tmp\",\n            log=self.log,\n            timeStamp=1,\n            timeout=3600,\n            concurrentDownloads=10,\n            resetFilename=False,\n            credentials=False,  # { 'username' : \"...\", \"password\", \"...\" }\n            longTime=True,\n            indexFilenames=True\n        )\n\n        for thisIndex, r in enumerate(self.nedResults):\n            if r == None:\n                thisUrl = queryList[thisIndex]\n                self.log.error(\n                    'cound not download NED results for URL %(thisUrl)s' % locals())\n                sys.exit(0)\n\n        self._convert_html_to_csv()\n\n        self.log.info(\n            'completed the ``_build_api_url_and_download_results`` method')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _output_results(\n            self):\n        \"\"\"\n        *output results*\n\n        **Key Arguments:**\n            # -\n\n        **Return:**\n            - None\n\n        .. todo::\n\n            - @review: when complete, clean _output_results method\n            - @review: when complete add logging\n        \"\"\"\n        self.log.info('starting the ``_output_results`` method')\n\n        content = \"\"\n        maxNameLen = 0\n\n        for r in self.results:\n            if maxNameLen < len(r[\"ned_name\"]):\n                maxNameLen = len(r[\"ned_name\"])\n\n        if len(self.results) == 0:\n            content += \"No resuls found\"\n        else:\n            thisHeader = \"| \"\n            thisLine = \"| \"\n            for head in self.headers:\n                if head == \"ned_name\":\n                    s = maxNameLen\n                else:\n                    s = self.resultSpacing\n                thisHeader += str(head).ljust(s,\n                                              ' ') + \" | \"\n                thisLine += \":\".ljust(s,\n                                      '-') + \" | \"\n            content += thisHeader\n            content += \"\\n\" + thisLine\n            for r in self.results:\n                thisRow = \"| \"\n                for head in self.headers:\n                    if head == \"ned_name\":\n                        s = maxNameLen\n                    else:\n                        s = self.resultSpacing\n                    thisRow += str(r[head]).ljust(s,\n                                                  ' ') + \" | \"\n                content += \"\\n\" + thisRow\n\n        if self.quiet == False:\n            print content\n        if self.outputFilePath:\n            import codecs\n            writeFile = codecs.open(\n                self.outputFilePath, encoding='utf-8', mode='w')\n            writeFile.write(content)\n            writeFile.close()\n\n        self.log.info('completed the ``_output_results`` method')\n        return None", "response": "This method writes the results to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the given action.", "response": "def execute(action):\n    \"\"\"\n    Execute the given action.\n\n    An action is any object with a ``forwards()`` and ``backwards()`` method.\n\n    .. code-block:: python\n\n        class CreateUser(object):\n\n            def __init__(self, userinfo):\n                self.userinfo = userinfo\n                self.user_id  = None\n\n            def forwards(self):\n                self.user_id = UserStore.create(userinfo)\n                return self.user_id\n\n            def backwards(self):\n                if self.user_id is not None:\n                    # user_id will be None if creation failed\n                    UserStore.delete(self.user_id)\n\n    If the ``forwards`` method succeeds, the action is considered successful.\n    If the method fails, the ``backwards`` method is called to revert any\n    effect it might have had on the system.\n\n    In addition to defining classes, actions may be built using the\n    :py:func:`reversible.action` decorator. Actions may be composed together\n    using the :py:func:`reversible.gen` decorator.\n\n    :param action:\n        The action to execute.\n    :returns:\n        The value returned by the ``forwards()`` method of the action.\n    :raises:\n        The exception raised by the ``forwards()`` method if rollback\n        succeeded. Otherwise, the exception raised by the ``backwards()``\n        method is raised.\n    \"\"\"\n    # TODO this should probably be a class to configure logging, etc. The\n    # global execute can refer to the \"default\" instance of the executor.\n    try:\n        return action.forwards()\n    except Exception:\n        log.exception('%s failed to execute. Rolling back.', action)\n        try:\n            action.backwards()\n        except Exception:\n            log.exception('%s failed to roll back.', action)\n            raise\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backwards(self, backwards):\n\n        if self._backwards is not None:\n            raise ValueError('Backwards action already specified.')\n\n        self._backwards = backwards\n        return backwards", "response": "Decorator to specify the backwards action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sphere_volume(R, n):\n    return ((np.pi ** (n / 2.0)) / scipy.special.gamma(n / 2.0 + 1)) * R ** n", "response": "Returns the volume of a sphere in an arbitrary number of dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the radius of a sphere in an arbitrary number of dimensions.", "response": "def sphere_radius(V, n):\n    \"\"\"Return the radius of a sphere in an arbitrary number of dimensions.\n\n    Parameters\n    ----------\n    V: array-like\n        Volume.\n    n: array-like\n        The number of dimensions of the space in which the sphere lives.\n\n    Returns\n    -------\n    R: array-like\n        Radius.\n    \"\"\"\n    return (((scipy.special.gamma(n / 2.0 + 1.0) * V) ** (1.0 / n)) /\n            np.sqrt(np.pi))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the radius of a spherocylinder in the specified volume.", "response": "def spherocylinder_radius(V, l):\n    \"\"\"Return the radius of a\n    [spherocylinder](http://en.wikipedia.org/wiki/Capsule_(geometry)).\n\n    Parameters\n    ----------\n    V: float\n        Volume.\n    l: float\n        Length of the cylinder section.\n\n    Returns\n    -------\n    R: float\n        Radius.\n    \"\"\"\n    return np.roots([4.0 / 3.0, l, 0, -V / np.pi])[-1].real"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the separation distance between two spheres.", "response": "def spheres_sep(ar, aR, br, bR):\n    \"\"\"Return the separation distance between two spheres.\n\n    Parameters\n    ----------\n    ar, br: array-like, shape (n,) in n dimensions\n        Coordinates of the centres of the spheres `a` and `b`.\n    aR, bR: float\n        Radiuses of the spheres `a` and `b`.\n\n    Returns\n    -------\n    d: float\n        Separation distance.\n        A negative value means the spheres intersect each other.\n    \"\"\"\n    return vector.vector_mag(ar - br) - (aR + bR)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns whether or not two spheres intersect each other.", "response": "def spheres_intersect(ar, aR, br, bR):\n    \"\"\"Return whether or not two spheres intersect each other.\n\n    Parameters\n    ----------\n    ar, br: array-like, shape (n,) in n dimensions\n        Coordinates of the centres of the spheres `a` and `b`.\n    aR, bR: float\n        Radiuses of the spheres `a` and `b`.\n\n    Returns\n    -------\n    intersecting: boolean\n        True if the spheres intersect.\n    \"\"\"\n    return vector.vector_mag_sq(ar - br) < (aR + bR) ** 2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef point_seg_sep(ar, br1, br2):\n    v = br2 - br1\n    w = ar - br1\n\n    c1 = np.dot(w, v)\n    if c1 <= 0.0:\n        return ar - br1\n\n    c2 = np.sum(np.square(v))\n    if c2 <= c1:\n        return ar - br2\n\n    b = c1 / c2\n    bc = br1 + b * v\n    return ar - bc", "response": "Return the minimum separation vector between a point and a line segment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the contents of the specified file.", "response": "def readfile(filename, binary=False):\n    \"\"\" Reads the contents of the specified file.\n\n        `filename`\n            Filename to read.\n        `binary`\n            Set to ``True`` to indicate a binary file.\n\n        Returns string or ``None``.\n        \"\"\"\n\n    if not os.path.isfile(filename):\n        return None\n\n    try:\n        flags = 'r' if not binary else 'rb'\n        with open(filename, flags) as _file:\n            return _file.read()\n\n    except (OSError, IOError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef writefile(filename, data, binary=False):\n    try:\n        flags = 'w' if not binary else 'wb'\n        with open(filename, flags) as _file:\n            _file.write(data)\n            _file.flush()\n            return True\n\n    except (OSError, IOError):\n        return False", "response": "Writes the provided data to the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the full path to executable in path matching provided name.", "response": "def which(name):\n    \"\"\" Returns the full path to executable in path matching provided name.\n\n        `name`\n            String value.\n\n        Returns string or ``None``.\n        \"\"\"\n\n    # we were given a filename, return it if it's executable\n    if os.path.dirname(name) != '':\n        if not os.path.isdir(name) and os.access(name, os.X_OK):\n            return name\n        else:\n            return None\n\n    # fetch PATH env var and split\n    path_val = os.environ.get('PATH', None) or os.defpath\n\n    # return the first match in the paths\n    for path in path_val.split(os.pathsep):\n        filename = os.path.join(path, name)\n\n        if os.access(filename, os.X_OK):\n            return filename\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_app_paths(values, app_should_exist=True):\n\n    def _osx_app_path(name):\n        \"\"\" Attempts to find the full application path for the name specified.\n\n            `name`\n                Application name.\n\n            Returns string or ``None``.\n            \"\"\"\n\n        # we use find because it is faster to traverse the\n        # hierachy for app dir.\n        cmd = ('find /Applications -type d '\n               '-iname \"{0}.app\" -maxdepth 4'.format(name))\n\n        data = shell_process(cmd)\n        if not data is None:\n            lines = str(data).split('\\n')\n\n            if lines:\n                bundle_dir = lines[0]\n                path = os.path.join(bundle_dir, 'Contents', 'MacOS', name)\n\n                if os.path.isfile(path) and os.access(path, os.X_OK):\n                    return path\n\n        return None\n\n    paths = set()\n\n    for value in values:\n        # split path into relevant tokens\n        parts = list(shlex.split(value))\n\n        # program name\n        name = parts[0]\n\n        # just the name, search bin paths\n        if os.path.dirname(name) == '':\n            path = which(name)\n\n            if not path:\n                # MacOS X, maybe it's an application name; let's try to build\n                # default application binary path\n                errmsg = u'\"{0}\" command does not exist'.format(name)\n\n                if IS_MACOSX:\n                    path = _osx_app_path(name)\n                    if not path:\n                        raise ValueError(errmsg)\n                else:\n                    raise ValueError(errmsg)  # no luck\n\n        else:\n            # relative to current working dir or full path\n            path = os.path.realpath(name)\n\n            if app_should_exist:\n                # should be a file or link and be executable\n                if os.path.isdir(path) or not os.access(path, os.X_OK):\n                    errmsg = u'\"{0}\" is not an executable file'.format(name)\n                    raise ValueError(errmsg)\n\n        # update program path\n        parts[0] = path\n\n        # quote params with spaces in value\n        parts[:] = ['\"{0}\"'.format(p.replace('\"', '\\\\\"'))\n                    if ' ' in p else p for p in parts]\n\n        # add flattened path\n        paths.add(' '.join(parts))\n\n    return list(paths)", "response": "Extracts application paths from the values provided."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshelling a process with the given shell command.", "response": "def shell_process(command, input_data=None, background=False, exitcode=False):\n    \"\"\" Shells a process with the given shell command.\n\n        `command`\n            Shell command to spawn.\n        `input_data`\n            String to pipe to process as input.\n        `background`\n            Set to ``True`` to fork process into background.\n            NOTE: This exits immediately with no result returned.\n        `exitcode`\n            Set to ``True`` to also return process exit status code.\n\n        if `exitcode` is ``False``, then this returns output string from\n        process or ``None`` if it failed.\n\n        otherwise, this returns a tuple with output string from process or\n        ``None`` if it failed and the exit status code.\n\n            Example::\n                (``None``, 1) <-- failed\n                ('Some data', 0) <-- success\n        \"\"\"\n\n    data = None\n\n    try:\n        # kick off the process\n        kwargs = {\n            'shell': isinstance(command, basestring),\n            'stdout': subprocess.PIPE,\n            'stderr': subprocess.PIPE\n        }\n        if not input_data is None:\n            kwargs['stdin'] = subprocess.PIPE\n        proc = subprocess.Popen(command, **kwargs)\n\n        # background exits without checking anything\n        if not background:\n            output, _ = proc.communicate(input_data)\n            retcode = proc.returncode\n\n            if retcode == 0:\n                data = str(output).rstrip()\n        else:\n            retcode = None\n\n            if input_data:\n                raise TypeError(u'Backgrounded does not support input data.')\n\n    except OSError as exc:\n        retcode = -exc.errno\n\n    if exitcode:\n        return data, retcode\n\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_utf8(buf, errors='replace'):\n\n    if isinstance(buf, unicode):\n        return buf.encode('utf-8', errors)\n\n    else:\n        return buf", "response": "Encodes a string into a UTF - 8 compatible ASCII string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_utf8(buf, errors='replace'):\n\n    if isinstance(buf, unicode):\n        return buf\n\n    else:\n        return unicode(buf, 'utf-8', errors)", "response": "Converts a UTF - 8 compatible ASCII string into a unicode object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, value, cfg=None):\n        if value is None and cfg:\n            if self.option_type == 'list':\n                value = cfg.get_list(self.name, None)\n            else:\n                value = cfg.get(self.name, None)\n\n        if value is None:\n            value = self.default\n        else:\n            parse_method = getattr(self, 'parse_%s' % (self.option_type), None)\n            if parse_method:\n                value = parse_method(value)\n        return value", "response": "Returns the value for this option from either cfg object or optparse option list preferring the option list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a path template and handler.", "response": "def add(self, *args):\n        \"\"\"Add a path template and handler.\n\n        :param name: Optional. If specified, allows reverse path lookup with\n            :meth:`reverse`.\n        :param template: A string or :class:`~potpy.template.Template`\n            instance used to match paths against. Strings will be wrapped in a\n            Template instance.\n        :param handler: A callable or :class:`~potpy.router.Route` instance\n            which will handle calls for the given path. See\n            :meth:`potpy.router.Router.add` for details.\n        \"\"\"\n        if len(args) > 2:\n            name, template = args[:2]\n            args = args[2:]\n        else:\n            name = None\n            template = args[0]\n            args = args[1:]\n        if isinstance(template, tuple):\n            template, type_converters = template\n            template = Template(template, **type_converters)\n        elif not isinstance(template, Template):\n            template = Template(template)\n        if name:\n            self._templates[name] = template\n        super(PathRouter, self).add(template, *args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reverse(self, *args, **kwargs):\n        (name,) = args\n        return self._templates[name].fill(**kwargs)", "response": "Look up a path by name and fill in the provided parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks for a method match.", "response": "def match(self, methods, request_method):\n        \"\"\"Check for a method match.\n\n        :param methods: A method or tuple of methods to match against.\n        :param request_method: The method to check for a match.\n        :returns: An empty :class:`dict` in the case of a match, or ``None``\n            if there is no matching handler for the given method.\n\n        Example:\n\n            >>> MethodRouter().match(('GET', 'HEAD'), 'HEAD')\n            {}\n            >>> MethodRouter().match('POST', 'DELETE')\n        \"\"\"\n        if isinstance(methods, basestring):\n            return {} if request_method == methods else None\n        return {} if request_method in methods else None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef humanize(t):\n    m, s = divmod(t, 60)\n    if s:\n        m += 1                 # ceil minutes \n    h, m = divmod(m, 60)\n    if m and h:\n        h += 1                 # ceil hours\n#    d, h = divmod(h, 24)\n\n    if h > 1:\n        res = 'in %d hours' % h\n    elif h == 1:\n        res = 'in an hour'\n    else:\n        if m > 1:\n            res = 'in %d minutes' % m\n        elif m == 1:\n            res = 'in a minute'\n        else:\n            res = 'now'\n    return res", "response": "print humanize for a time"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef coerce(self, value):\n        if hasattr(value, 'values') and hasattr(value, 'domain'):\n            return value\n        elif hasattr(value, '__iter__'):\n            # if the values are consistent with the comparison's domains, then\n            # copy them, otherwise, make a new domain with the values.\n            if all(map(lambda x: x in self.domain, value)):\n                return self._stem(self.domain, value)\n            else:\n                raise CellConstructionFailure(\"Cannot turn %s into a cell\" % (value))\n        elif value in self.domain:\n            return self._stem(self.domain, [value])\n        else:\n            raise CellConstructionFailure(\"Cannot turn %s into a cell\" % (value))", "response": "Coerces a value into a SetCell\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if two Cheap pointer tables have the same domain.", "response": "def same_domain(self, other):\n        \"\"\"\n        Cheap pointer comparison or symmetric difference operation\n        to ensure domains are the same\n        \"\"\"\n        return self.domain == other.domain or \\\n                len(self.domain.symmetric_difference(set(other.domain))) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_equal(self, other):\n        other = self.coerce(other)\n        return len(self.get_values().symmetric_difference(other.get_values())) == 0", "response": "True iff all members of self and other are the same as self."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if self and other are not empty and False otherwise.", "response": "def is_contradictory(self, other):\n        \"\"\"\n        What does it mean for a set to contradict another? If a merge results\n        in the empty set -- when both sets are disjoint.\n\n        CONTRADICTION: self = {4} other = {3}\n        NOT CONTRADICTION: self = {4} other = {3,4}\n        NOT CONTRADICTION: self = {3,4} other = {3}\n        \"\"\"\n        other = self.coerce(other)\n        # contradictory if both values are disjoint\n        return self.get_values().isdisjoint(other.get_values())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_entailed_by(self, other):\n        if not self.same_domain(other):\n            return False\n        \n        if not other.values:\n            if self.values:\n                # None can never entail -None\n                return False\n            else:\n                # None entails None\n                return True\n        \n        return not self.values or self.values.issuperset(other.values)", "response": "Returns True if self is entailed by other."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self, other):\n        other = self.coerce(other)\n        if self.is_equal(other):\n            # pick among dependencies\n            return self\n        elif other.is_entailed_by(self):\n            # other is a subset of self\n            return self\n        elif self.is_entailed_by(other):\n            # self is a subset of other.\n            self.values = other.values.copy()\n        elif self.is_contradictory(other):\n            raise Contradiction(\"Cannot merge set with %s\" % (str(other)))\n        else:\n            # merge mutual information\n            if self.values:\n                self.values = self.values.intersection(other.values)\n            else:\n                self.values = other.values.copy()\n        return self", "response": "Merge two sets of mutual information into this set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging two sets of mutual information.", "response": "def merge(self, other):\n        \"\"\"\n        We can merge unless the merge results in an empty set -- a\n        contradiction\n        \"\"\"\n        other = self.coerce(other)\n        if self.is_equal(other):\n            # pick among dependencies\n            return self\n        elif self.is_contradictory(other):\n            raise Contradiction(\"Cannot merge set with %s\" % (str(other)))\n        else:\n            # self may be a subset of other \n            # or other may be a subset of self\n            # merge mutual information\n            if self.values:\n                self.values = self.values.union(other.values)\n            else:\n                self.values = other.values.copy()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_indices():\n    doc = BeautifulSoup(urlopen(BASEURL))\n\n    divs = doc.select('.indices_txt')\n    if not divs:\n        return None\n\n    sibling = divs[1].nextSibling\n    if not sibling:\n        return None\n\n    data = sibling.nextSibling\n    if not data:\n        return None\n\n    # the indices are in an HTML comment\n    data = BeautifulSoup(data)\n\n    divs = data.select('.selected')\n    return map(lambda d: int(d.text), divs)", "response": "Return a list of 3 integers representing EU indices for yesterday today tomorrow and tomorrow."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_dir(directory):\n    if not os.access(directory, os.F_OK):\n        os.makedirs(directory)\n    return os.path.abspath(directory)", "response": "Create given directory if doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an experiment object with subject and image group.", "response": "def experiments_create(self, subject_id, image_group_id, properties):\n        \"\"\"Create an experiment object with subject, and image group. Objects\n        are referenced by their unique identifiers. The API ensure that at time\n        of creation all referenced objects exist. Referential consistency,\n        however, is currently not enforced when objects are deleted.\n\n        Expects experiment name in property list. Raises ValueError if no valid\n        name is given.\n\n        If any of the referenced objects do not exist a ValueError is thrown.\n\n        Parameters\n        ----------\n        subject_id : string\n            Unique identifier of subject\n        image_group_id : string\n            Unique identifier of image group\n        properties : Dictionary\n            Set of experiment properties. Is required to contain at least the\n            experiment name\n\n        Returns\n        -------\n        ExperimentHandle\n            Handle for created experiment object in database\n        \"\"\"\n        # Ensure that reference subject exists\n        if self.subjects_get(subject_id) is None:\n            raise ValueError('unknown subject: ' + subject_id)\n        # Ensure that referenced image group exists\n        if self.image_groups_get(image_group_id) is None:\n            raise ValueError('unknown image group: ' + image_group_id)\n        return self.experiments.create_object(subject_id, image_group_id, properties)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef experiments_fmri_create(self, experiment_id, filename):\n        # Get the experiment to ensure that it exist before we even create the\n        # functional data object\n        experiment = self.experiments_get(experiment_id)\n        if experiment is None:\n            return None\n        # Create functional data object from given file\n        fmri = self.funcdata.create_object(filename)\n        # Update experiment to associate it with created fMRI object. Assign\n        # result to experiment. Should the experiment have been deleted in\n        # parallel the result will be None\n        experiment = self.experiments.update_fmri_data(experiment_id, fmri.identifier)\n        if experiment is None:\n            # Delete fMRI object's data directory\n            shutil.rmtree(fmri.directory)\n            # Delete functional data object from databases\n            self.funcdata.delete_object(fmri.identifier, erase=True)\n            return None\n        else:\n            return funcdata.FMRIDataHandle(fmri, experiment_id)", "response": "Create a new fMRI object from a given file and associate it with the specified experiment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef experiments_fmri_delete(self, experiment_id):\n        # Get experiment fMRI to ensure that it exists\n        fmri = self.experiments_fmri_get(experiment_id)\n        if fmri is None:\n            return None\n        # Delete reference fMRI data object and set reference in experiment to\n        # None. If the result of delete fMRI object is None we return None.\n        # Alternatively, throw an exception to signal invalid database state.\n        fmri = self.funcdata.delete_object(fmri.identifier)\n        if not fmri is None:\n            self.experiments.update_fmri_data(experiment_id, None)\n        return funcdata.FMRIDataHandle(fmri, experiment_id)", "response": "Delete fMRI data object associated with given experiment."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload the fMRI data file associated with given experiment.", "response": "def experiments_fmri_download(self, experiment_id):\n        \"\"\"Download the fMRI data file associated with given experiment.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n\n        Returns\n        -------\n        FileInfo\n            Information about fMRI file on disk or None if experiment is\n            unknown or has no fMRI data associated with it\n        \"\"\"\n        # Get experiment fMRI to ensure that it exists\n        fmri = self.experiments_fmri_get(experiment_id)\n        if fmri is None:\n            return None\n        # Return information about fmRI data file\n        return FileInfo(\n            fmri.upload_file,\n            fmri.properties[datastore.PROPERTY_MIMETYPE],\n            fmri.properties[datastore.PROPERTY_FILENAME]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef experiments_fmri_get(self, experiment_id):\n        # Get experiment to ensure that it exists\n        experiment = self.experiments_get(experiment_id)\n        if experiment is None:\n            return None\n        # Check if experiment has fMRI data\n        if experiment.fmri_data_id is None:\n            return None\n        # Get functional data object handle from database.\n        func_data = self.funcdata.get_object(experiment.fmri_data_id)\n        # Create fMRI handle from functional data handle\n        return funcdata.FMRIDataHandle(func_data, experiment_id)", "response": "Get fMRI data object that is associated with the given experiment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef experiments_fmri_upsert_property(self, experiment_id, properties):\n        # Get experiment fMRI to ensure that it exists. Needed to get fMRI\n        # data object identifier for given experiment identifier\n        fmri = self.experiments_fmri_get(experiment_id)\n        if fmri is None:\n            return None\n        # Update properties for fMRI object using the object identifier\n        return self.funcdata.upsert_object_property(fmri.identifier, properties)", "response": "Upsert property of fMRI data object associated with given experiment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving list of all experiments in the object store.", "response": "def experiments_list(self, limit=-1, offset=-1):\n        \"\"\"Retrieve list of all experiments in the data store.\n\n        Parameters\n        ----------\n        limit : int\n            Limit number of results in returned object listing\n        offset : int\n            Set offset in list (order as defined by object store)\n\n        Returns\n        -------\n        ObjectListing\n            Listing of experiment handles\n        \"\"\"\n        return self.experiments.list_objects(limit=limit, offset=offset)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattach a given data file with a model run.", "response": "def experiments_predictions_attachments_create(self, experiment_id, run_id, resource_id, filename, mime_type=None):\n        \"\"\"Attach a given data file with a model run. The attached file is\n        identified by the resource identifier. If a resource with the given\n        identifier already exists it will be overwritten.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n        model_id : string\n            Unique identifier of model to run\n        resource_id : string\n            Unique attachment identifier\n        filename : string\n            Path to data file that is being attached. A copy of the file will\n            be created\n        mime_type : string, optional\n            File Mime type\n        Returns\n        -------\n        ModelRunHandle\n            Modified model run handle or None if no run with given identifier\n            exists\n        \"\"\"\n        # Get experiment to ensure that it exists\n        if self.experiments_get(experiment_id) is None:\n            return None\n        return self.predictions.create_data_file_attachment(\n            run_id,\n            resource_id,\n            filename,\n            mime_type=mime_type\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef experiments_predictions_attachments_delete(self, experiment_id, run_id, resource_id):\n        # Get experiment to ensure that it exists\n        if self.experiments_get(experiment_id) is None:\n            return False\n        return self.predictions.delete_data_file_attachment(run_id, resource_id)", "response": "Delete an attachment from a model run."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef experiments_predictions_attachments_download(self, experiment_id, run_id, resource_id):\n        # Get experiment to ensure that it exists\n        if self.experiments_get(experiment_id) is None:\n            return None\n        attachment, mime_type = self.predictions.get_data_file_attachment(\n            run_id,\n            resource_id\n        )\n        if attachment is None:\n            return  None\n        # Return information about the result file\n        return FileInfo(attachment, mime_type, os.path.basename(attachment))", "response": "Download a data file that has been attached with a successful model to a given resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating new model run for given experiment.", "response": "def experiments_predictions_create(self, experiment_id, model_id, argument_defs, name, arguments=None, properties=None):\n        \"\"\"Create new model run for given experiment.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n        model_id : string\n            Unique identifier of model to run\n        name : string\n            User-provided name for the model run\n        argument_defs : list(attribute.AttributeDefinition)\n            Definition of valid arguments for the given model\n        arguments : list(dict('name':...,'value:...')), optional\n            List of attribute instances\n        properties : Dictionary, optional\n            Set of model run properties.\n\n        Returns\n        -------\n        ModelRunHandle\n            Handle for created model run or None if experiment is unknown\n        \"\"\"\n        # Get experiment to ensure that it exists\n        if self.experiments_get(experiment_id) is None:\n            return None\n        # Return created model run\n        return self.predictions.create_object(\n            name,\n            experiment_id,\n            model_id,\n            argument_defs,\n            arguments=arguments,\n            properties=properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete given prediction for experiment.", "response": "def experiments_predictions_delete(self, experiment_id, run_id, erase=False):\n        \"\"\"Delete given prediction for experiment.\n\n        Raises ValueError if an attempt is made to delete a read-only resource.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n        run_id : string\n            Unique model run identifier\n        erase : Boolean, optional\n            If true, the model run will be deleted from the database. Used in\n            case the sco backend could not start a model run after the record\n            had already been created in the database.\n\n        Returns\n        -------\n        ModelRunHandle\n            Handle for deleted model run or None if unknown\n        \"\"\"\n        # Get model run to ensure that it exists\n        model_run = self.experiments_predictions_get(experiment_id, run_id)\n        if model_run is None:\n            return None\n        # Return resutl of deleting model run. Could also raise exception in\n        # case of invalid database state (i.e., prediction does not exist)\n        return self.predictions.delete_object(model_run.identifier, erase=erase)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef experiments_predictions_get(self, experiment_id, run_id):\n        # Get experiment to ensure that it exists\n        if self.experiments_get(experiment_id) is None:\n            return None\n        # Get predition handle to ensure that it exists\n        model_run = self.predictions.get_object(run_id)\n        if model_run is None:\n            return None\n        # Perform additional check that prediction is for given experiment\n        if experiment_id != model_run.experiment_id:\n            return None\n        # Return model run object\n        return model_run", "response": "Get prediction object with given identifier for given experiment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a prediction image set from a given tar archive that was produced as the result of a successful model run.", "response": "def experiments_predictions_image_set_create(self, experiment_id, run_id, filename):\n        \"\"\"Create a prediction image set from a given tar archive that was\n        produced as the result of a successful model run.\n\n        Returns None if the specified model run does not exist or did not\n        finish successfully. Raises a ValueError if the given file is invalid or\n        model run.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n        run_id : string\n            Unique model run identifier\n        filename : string\n            Path to uploaded image set archive file\n\n        Returns\n        -------\n        PredictionImageSetHandle\n            Handle for new prediction image set collection\n        \"\"\"\n        # Ensure that the model run exists and is in state SUCCESS\n        model_run = self.experiments_predictions_get(experiment_id, run_id)\n        if model_run is None:\n            return None\n        if not model_run.state.is_success:\n            raise ValueError('invalid run state: ' + str(model_run.state))\n        # Check if the file is a valid tar archive (based on suffix).\n        suffix = get_filename_suffix(filename, ARCHIVE_SUFFIXES)\n        if suffix is None:\n            # Not a valid file suffix\n            raise ValueError('invalid file suffix: ' + os.path.basename(os.path.normpath(filename)))\n        # Unpack the file to a temporary folder .\n        temp_dir = tempfile.mkdtemp()\n        try:\n            tf = tarfile.open(name=filename, mode='r')\n            tf.extractall(path=temp_dir)\n        except (tarfile.ReadError, IOError) as err:\n            # Clean up in case there is an error during extraction\n            shutil.rmtree(temp_dir)\n            raise ValueError(str(err))\n        # The list of prediction image sets\n        image_sets = []\n\n        # Parse the CSV file. For each image file use:\n        # img_obj = self.images.create_object(img_filename)\n        # to create an image file object in the database.\n\n        # Use file name as default object name\n        name = os.path.basename(os.path.normpath(filename))[:-len(suffix)]\n        # Create prediction image set\n        img_set = self.prediction_images.create_object(name, image_sets)\n        # Delete the temporary folder\n        shutil.rmtree(temp_dir)\n        return img_set"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef experiments_predictions_list(self, experiment_id, limit=-1, offset=-1):\n        # Get experiment to ensure that it exists\n        if self.experiments_get(experiment_id) is None:\n            return None\n        # Return list of predictions\n        return self.predictions.list_objects(\n            query={'experiment' : experiment_id},\n            limit=limit,\n            offset=offset\n        )", "response": "Returns a list of all predictions for given experiment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate state of given prediction to active.", "response": "def experiments_predictions_update_state_active(self, experiment_id, run_id):\n        \"\"\"Update state of given prediction to active.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n        run_id : string\n            Unique model run identifier\n\n        Returns\n        -------\n        ModelRunHandle\n            Handle for updated model run or None is prediction is undefined\n        \"\"\"\n        # Get prediction to ensure that it exists\n        model_run = self.experiments_predictions_get(experiment_id, run_id)\n        if model_run is None:\n            return None\n        # Update predition state\n        return self.predictions.update_state(\n            run_id,\n            modelrun.ModelRunActive()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef experiments_predictions_update_state_error(self, experiment_id, run_id, errors):\n        # Get prediction to ensure that it exists\n        model_run = self.experiments_predictions_get(experiment_id, run_id)\n        if model_run is None:\n            return None\n        # Update predition state\n        return self.predictions.update_state(\n            run_id,\n            modelrun.ModelRunFailed(errors)\n        )", "response": "Update state of given prediction to failed. Set error messages that generated by the failed run execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates state of given prediction to success. Create a function data resource for the given result file and associate it with the model run.", "response": "def experiments_predictions_update_state_success(self, experiment_id, run_id, result_file):\n        \"\"\"Update state of given prediction to success. Create a function data\n        resource for the given result file and associate it with the model run.\n\n        Parameters\n        ----------\n        experiment_id : string\n            Unique experiment identifier\n        run_id : string\n            Unique model run identifier\n        result_file : string\n            Path to model run result file\n\n        Returns\n        -------\n        ModelRunHandle\n            Handle for updated model run or None is prediction is undefined\n        \"\"\"\n        # Get prediction to ensure that it exists\n        model_run = self.experiments_predictions_get(experiment_id, run_id)\n        if model_run is None:\n            return None\n        # Create new resource for model run result\n        funcdata = self.funcdata.create_object(result_file)\n        # Update predition state\n        return self.predictions.update_state(\n            run_id,\n            modelrun.ModelRunSuccess(funcdata.identifier)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef experiments_predictions_upsert_property(self, experiment_id, run_id, properties):\n        # Get predition to ensure that it exists. Ensures that the combination\n        # of experiment and prediction identifier is valid.\n        if self.experiments_predictions_get(experiment_id, run_id) is None:\n            return None\n        # Return result of upsert for identifier model run\n        return self.predictions.upsert_object_property(run_id, properties)", "response": "Upsert property of a model run for an experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef images_create(self, filename):\n        # Check if file is a single image\n        suffix = get_filename_suffix(filename, image.VALID_IMGFILE_SUFFIXES)\n        if not suffix is None:\n            # Create image object from given file\n            return self.images.create_object(filename)\n        # The file has not been recognized as a valid image. Check if the file\n        # is a valid tar archive (based on suffix).\n        suffix = get_filename_suffix(filename, ARCHIVE_SUFFIXES)\n        if not suffix is None:\n            # Unpack the file to a temporary folder .\n            temp_dir = tempfile.mkdtemp()\n            try:\n                tf = tarfile.open(name=filename, mode='r')\n                tf.extractall(path=temp_dir)\n            except (tarfile.ReadError, IOError) as err:\n                # Clean up in case there is an error during extraction\n                shutil.rmtree(temp_dir)\n                raise ValueError(str(err))\n            # Get names of all files with valid image suffixes and create an\n            # object for each image object\n            group = []\n            for img_file in image.get_image_files(temp_dir, []):\n                img_obj = self.images.create_object(img_file)\n                folder = img_file[len(temp_dir):-len(img_obj.name)]\n                group.append(image.GroupImage(\n                    img_obj.identifier,\n                    folder,\n                    img_obj.name,\n                    img_obj.image_file\n                ))\n            # Create image group\n            name = os.path.basename(os.path.normpath(filename))[:-len(suffix)]\n            img_grp = self.image_groups.create_object(name, group, filename)\n            # Delete the temporary folder\n            shutil.rmtree(temp_dir)\n            return img_grp\n        else:\n            # Not a valid file suffix\n            raise ValueError('invalid file suffix: ' + os.path.basename(os.path.normpath(filename)))", "response": "Create and image file or image group object from the given file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef image_files_download(self, image_id):\n        # Retrieve image to ensure that it exist\n        img = self.image_files_get(image_id)\n        if img is None:\n            # Return None if image is unknown\n            return None\n        else:\n            # Reference and information for original uploaded file\n            return FileInfo(\n                img.image_file,\n                img.properties[datastore.PROPERTY_MIMETYPE],\n                img.properties[datastore.PROPERTY_FILENAME]\n            )", "response": "Get data file for given image identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve list of all images in the object store.", "response": "def image_files_list(self, limit=-1, offset=-1):\n        \"\"\"Retrieve list of all images in the data store.\n\n        Parameters\n        ----------\n        limit : int\n            Limit number of results in returned object listing\n        offset : int\n            Set offset in list (order as defined by object store)\n\n        Returns\n        -------\n        ObjectListing\n            Listing of image handles\n        \"\"\"\n        return self.images.list_objects(limit=limit, offset=offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef image_groups_download(self, image_group_id):\n        # Retrieve image group to ensure that it exist\n        img_grp = self.image_groups_get(image_group_id)\n        if img_grp is None:\n            # Return None if image group is unknown\n            return None\n        else:\n            # Reference and information for file image group was created from\n            return FileInfo(\n                img_grp.data_file,\n                img_grp.properties[datastore.PROPERTY_MIMETYPE],\n                img_grp.properties[datastore.PROPERTY_FILENAME]\n            )", "response": "Download data file for given image group identifier."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef image_group_images_list(self, image_group_id, limit=-1, offset=-1):\n        return self.image_groups.list_images(\n            image_group_id,\n            limit=limit,\n            offset=offset\n        )", "response": "List images in the given image group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image_groups_list(self, limit=-1, offset=-1):\n        return self.image_groups.list_objects(limit=limit, offset=offset)", "response": "Retrieve list of all image groups in the object store."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subjects_create(self, filename):\n        # Ensure that the file name has a valid archive suffix\n        if get_filename_suffix(filename, ARCHIVE_SUFFIXES) is None:\n            raise ValueError('invalid file suffix: ' + os.path.basename(os.path.normpath(filename)))\n        # Create subject from archive. Raises exception if file is not a valid\n        # subject archive\n        return self.subjects.upload_file(filename)", "response": "Create a new subject from given data files. Expects the file to be a availabe Freesurfer archive. Returns a handle for the created subject."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload a subject s data file and return a FileInfo object.", "response": "def subjects_download(self, subject_id):\n        \"\"\"Get data file for subject with given identifier.\n\n        Parameters\n        ----------\n        subject_id : string\n            Unique subject identifier\n\n        Returns\n        -------\n        FileInfo\n            Information about subject's data file on disk or None if identifier\n            is unknown\n        \"\"\"\n        # Retrieve subject to ensure that it exist\n        subject = self.subjects_get(subject_id)\n        if subject is None:\n            # Return None if subject is unknown\n            return None\n        else:\n            # Reference and information for original uploaded file\n            return FileInfo(\n                subject.data_file,\n                subject.properties[datastore.PROPERTY_MIMETYPE],\n                subject.properties[datastore.PROPERTY_FILENAME]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subjects_list(self, limit=-1, offset=-1):\n        return self.subjects.list_objects(limit=limit, offset=offset)", "response": "Retrieve list of all subjects in the object store."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef leland94(V, s, r, a, t, C=None, d=None, PosEq=False):\n\n    # subfunction for\n    def netcashpayout_by_dividend(r, d, s):\n        \"\"\"net cash payout proportional to the firm's asset value\n            for a given required dividend rate (p.1241)\n        \"\"\"\n        import math\n        s2 = s * s\n        tmp = r - d - 0.5 * s2\n        return (tmp + math.sqrt(tmp * tmp + 2.0 * s2 * r)) / s2\n\n    def optimal_coupon(V, r, a, t, X):\n        \"\"\"Coupon for the endogenous bankcruptcy case (pp.1222)\"\"\"\n        m = ((1.0 - t) * X / (r * (1.0 + X)))**X / (1.0 + X)\n        h = (1.0 + X + a * (1 - t) * X / t) * m\n        return V * ((1.0 + X) * h)**(-1.0 / X)\n\n    def positivenetworth_target(VB, V, a, A, X):\n        \"\"\"protected bond covenant with positive net worth requirement\"\"\"\n        return VB - A - ((1.0 - a) * VB - A) * (VB / V)**X\n\n    # (1a) Net Cash Payout 'X'\n    if d is None:\n        # Net cash Payout if 100% retained profits (p.1218)\n        X = (2.0 * r) / (s * s)\n    else:\n        # net cash payout proportional to the firm's asset value\n        # for a given required dividend rate (p.1241)\n        X = netcashpayout_by_dividend(r, d, s)\n\n    # (1b) Optimal coupon of the endogenous bankruptcy\n    #   case (p.1222ff.)\n    if C is None:\n        C = optimal_coupon(V, r, a, t, X)\n\n    # (1c) Wert der Annuitaet\n    A = C / r\n\n    # (2a) Level of bankruptcy VB (pp.1222)\n    VB = (1.0 - t) * C / (r + 0.5 * s * s)\n\n    # (2b) protected bond covenant with positive net worth\n    # requirement (pp.1233)\n    if PosEq:\n        from scipy.optimize import fsolve\n        VB = fsolve(func=positivenetworth_target, x0=VB, args=(V, a, A, X))\n        VB = float(VB)\n\n    # (3a) PV of $1 if bankruptcy (p.1219)\n    PV = (VB / V)**X\n\n    # (3b) Value of debt (p.1219)\n    D = A + ((1.0 - a) * VB - A) * PV\n\n    # (3c) Value of bankruptcy costs (p.1220)\n    B = a * VB * PV\n\n    # (3d) Value of tax benefit (p.1220)\n    T = t * A * (1.0 - PV)\n\n    # (3e) Total value of the firm, or Value of levered company (p.1221)\n    W = V + T - B\n\n    # (3f) Value of equity (p.1221)\n    E = W - D\n\n    # (4a) Leverage Ratio\n    lr = D / W\n\n    # (4b) Yield on Debt\n    yld = C / D\n\n    # (4c) Yield Spread in bp\n    sprd = (yld - r) * 10000.0\n\n    # return results\n    return D, E, W, T, B, VB, PV, lr, yld, sprd, X, C, A", "response": "Leland94 Capital Structure model"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_tarball(directory, name, version):\n    dir_contents = os.listdir(os.path.join(directory, 'dist'))\n    candidates = [tarball for tarball in dir_contents\n                  if tarball.endswith('.gz')\n                  and tarball.startswith(name + '-' + version)]\n    if not candidates:\n        logger.error(\"No recognizable distribution found for %s, version %s\",\n                     name, version)\n        logger.error(\"Contents of %s: %r\", directory, dir_contents)\n        return\n    if len(candidates) > 1:\n        # Should not happen.\n        logger.warn(\"More than one candidate distribution found: %r\",\n                    candidates)\n    tarball = candidates[0]\n    return os.path.join(directory, 'dist', tarball)", "response": "Find a matching tarball filename from dist directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef checkout_dirs(self):\n        directories = [os.path.join(self.base_directory, d)\n                       for d in os.listdir(self.base_directory)]\n        return [d for d in directories if os.path.isdir(d)]", "response": "Return directories inside the base directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef missing_tags(self, existing_sdists=None):\n        if existing_sdists is None:\n            existing_sdists = []\n        logger.debug(\"Existing sdists: %s\", existing_sdists)\n        if self._missing_tags is None:\n            missing = []\n            existing_sdists = sorted_versions(set(existing_sdists))\n            available = set(self.wrapper.vcs.available_tags())\n            available_tags = sorted_versions(available)\n            available_tags.reverse()\n            for tag in available_tags:\n                if tag.is_prerelease:\n                    logger.warn(\"Pre-release marker in tag: %s, ignoring\", tag)\n                    continue\n                if tag in existing_sdists:\n                    logger.debug(\n                        \"Tag %s is already available, not looking further\",\n                        tag)\n                    break\n                else:\n                    missing.append(tag)\n                    logger.debug(\"Tag %s is missing\", tag)\n            missing.reverse()\n            # Convert back to proper strings:\n            mapping = {}\n            for tag in available:\n                mapping[parse_version(tag)] = tag\n            self._missing_tags = [mapping[tag] for tag in missing]\n        logger.debug(\"Missing sdists: %s\", self._missing_tags)\n        return self._missing_tags", "response": "Return difference between existing sdists and available tags."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_sdist(self, tag):\n        logger.info(\"Making tempdir for %s with tag %s...\",\n                    self.package, tag)\n        self.wrapper.vcs.checkout_from_tag(tag)\n        # checkout_from_tag() chdirs to a temp directory that we need to clean up\n        # later.\n        self.temp_tagdir = os.path.realpath(os.getcwd())\n        logger.debug(\"Tag checkout placed in %s\", self.temp_tagdir)\n        python = sys.executable\n        logger.debug(command(\"%s setup.py sdist\" % python))\n        tarball = find_tarball(self.temp_tagdir, self.package, tag)\n        return tarball", "response": "Create an sdist and return the full file path of the. tar. gz."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cleanup(self):\n        shutil.rmtree(self.temp_tagdir)\n        # checkout_from_tag might operate on a subdirectory (mostly\n        # 'gitclone'), so cleanup the parent dir as well\n        parentdir = os.path.dirname(self.temp_tagdir)\n        # ensure we don't remove anything important\n        if os.path.basename(parentdir).startswith(self.package):\n            os.rmdir(parentdir)\n        os.chdir(self.start_directory)", "response": "Clean up temporary tag checkout dir."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_client(config_file=None, apikey=None, username=None, userpass=None,\n               service_url=None, verify_ssl_certs=None, select_first=None):\n    \"\"\"Configure the API service and creates a new instance of client.\n\n    :param str config_file: absolute path to configuration file\n    :param str apikey: apikey from thetvdb\n    :param str username: username used on thetvdb\n    :param str userpass: password used on thetvdb\n    :param str service_url: the url for thetvdb api service\n    :param str verify_ssl_certs: flag for validating ssl certs for\n                                 service url (https)\n    :param str select_first: flag for selecting first series from\n                             search results\n    :returns: tvdbapi client\n    :rtype: tvdbapi_client.api.TVDBClient\n    \"\"\"\n    from oslo_config import cfg\n\n    from tvdbapi_client import api\n\n    if config_file is not None:\n        cfg.CONF([], default_config_files=[config_file])\n    else:\n        if apikey is not None:\n            cfg.CONF.set_override('apikey', apikey, 'tvdb')\n        if username is not None:\n            cfg.CONF.set_override('username', username, 'tvdb')\n        if userpass is not None:\n            cfg.CONF.set_override('userpass', userpass, 'tvdb')\n        if service_url is not None:\n            cfg.CONF.set_override('service_url', service_url, 'tvdb')\n        if verify_ssl_certs is not None:\n            cfg.CONF.set_override('verify_ssl_certs', verify_ssl_certs, 'tvdb')\n        if select_first is not None:\n            cfg.CONF.set_override('select_first', select_first, 'tvdb')\n\n    return api.TVDBClient()", "response": "Configure the API service and creates a new instance of client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the connection to the LifeSOS ethernet interface.", "response": "def close(self) -> None:\n        \"\"\"Closes connection to the LifeSOS ethernet interface.\"\"\"\n\n        self.cancel_pending_tasks()\n\n        _LOGGER.debug(\"Disconnected\")\n        if self._transport:\n            self._transport.close()\n        self._is_connected = False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a command and return the response.", "response": "async def async_execute(self, command: Command, password: str = '',\n                            timeout: int = EXECUTE_TIMEOUT_SECS) -> Response:\n        \"\"\"\n        Execute a command and return response.\n\n        command:    the command instance to be executed\n        password:   if specified, will be used to execute this command (overriding any\n                    global password that may have been assigned to the property)\n        timeout:    maximum number of seconds to wait for a response\n        \"\"\"\n        if not self._is_connected:\n            raise ConnectionError(\"Client is not connected to the server\")\n        state = {\n            'command': command,\n            'event': asyncio.Event(loop=self._loop)\n        } # type: Dict[str, Any]\n        self._executing[command.name] = state\n        try:\n            self._send(command, password)\n            await asyncio.wait_for(state['event'].wait(), timeout)\n            return state['response']\n        finally:\n            self._executing[command.name] = None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef longest_service_name(self):\n        return max([len(service_handle.service.name) for service_handle in self.service_handles] + [0])", "response": "Length of the longest service name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays the user in a node.", "response": "def display_user(value, arg):\n    ''' Return 'You' if value is equal to arg.\n        Parameters:\n            value should be a userprofile\n            arg should be another user.\n        Ideally, value should be a userprofile from an object and arg the user logged in.\n    '''\n    if value.user == arg and arg.username != ANONYMOUS_USERNAME:\n        return \"You\"\n    else:\n        return value.user.get_full_name()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_all_threads_view(request):\n    ''' View of all threads. '''\n    threads = Thread.objects.all()\n\n    create_form = ThreadForm(\n        request.POST if \"submit_thread_form\" in request.POST else None,\n        profile=UserProfile.objects.get(user=request.user),\n        )\n\n    if create_form.is_valid():\n        thread = create_form.save()\n        return HttpResponseRedirect(reverse(\"threads:view_thread\",\n                                            kwargs={\"pk\": thread.pk}))\n    elif request.method == \"POST\":\n        messages.add_message(request, messages.ERROR, MESSAGES['THREAD_ERROR'])\n\n    return render_to_response('list_threads.html', {\n        'page_name': \"All Threads\",\n        \"create_form\": create_form,\n        'threads': threads,\n        }, context_instance=RequestContext(request))", "response": "View of all threads."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nview an individual thread.", "response": "def thread_view(request, pk):\n    ''' View an individual thread. '''\n    if request.is_ajax():\n        if not request.user.is_authenticated():\n            return HttpResponse(json.dumps(dict()),\n                                content_type=\"application/json\")\n        try:\n            user_profile = UserProfile.objects.get(user=request.user)\n        except UserProfile.DoesNotExist:\n            return HttpResponse(json.dumps(dict()),\n                                content_type=\"application/json\")\n        try:\n            thread = Thread.objects.get(pk=pk)\n        except Thread.DoesNotExist:\n            return HttpResponse(json.dumps(dict()),\n                                content_type=\"application/json\")\n        follow_form = FollowThreadForm(\n            request.POST if \"follow_thread\" in request.POST else None,\n            instance=thread,\n            profile=user_profile,\n        )\n        if follow_form.is_valid():\n            following = follow_form.save()\n            response = dict(\n                following=following,\n                num_of_followers=thread.followers.all().count()\n            )\n            return HttpResponse(json.dumps(response),\n                                content_type=\"application/json\")\n        raise Http404\n    userProfile = UserProfile.objects.get(user=request.user)\n    thread = get_object_or_404(Thread, pk=pk)\n    messages_list = Message.objects.filter(thread=thread)\n\n    follow_form = FollowThreadForm(\n        request.POST if \"follow_thread\" in request.POST else None,\n        instance=thread,\n        profile=userProfile,\n        )\n\n    if follow_form.is_valid():\n        following = follow_form.save()\n        if following:\n            message = \"You are now following this thread.\"\n        else:\n            message = \"You are no longer following this thread.\"\n        messages.add_message(request, messages.INFO, message)\n        return HttpResponseRedirect(reverse(\"threads:view_thread\",\n                                            kwargs={\"pk\": pk}))\n\n    edit_forms, delete_forms = [], []\n\n    for message in messages_list:\n        edit_message_form, delete_message_form = None, None\n        if message.owner == userProfile or userProfile.user.is_superuser:\n            edit_message_form = EditMessageForm(\n                request.POST if \"edit_message-{0}\".format(message.pk) in request.POST else None,\n                instance=message,\n                prefix=\"edit-{0}\".format(message.pk),\n                )\n            delete_message_form = DeleteMessageForm(\n                request.POST if \"delete_message-{0}\".format(message.pk) in request.POST else None,\n                instance=message,\n                )\n            if edit_message_form.is_valid():\n                edit_message_form.save()\n                messages.add_message(request, messages.INFO, \"Message updated.\")\n                return HttpResponseRedirect(reverse(\"threads:view_thread\", kwargs={\n                    \"pk\": pk,\n                    }))\n            if delete_message_form.is_valid():\n                thread = delete_message_form.save()\n                messages.add_message(request, messages.INFO, \"Message deleted.\")\n                if thread is None:\n                    return HttpResponseRedirect(reverse(\"threads:list_all_threads\"))\n                return HttpResponseRedirect(reverse(\"threads:view_thread\", kwargs={\n                    \"pk\": thread.pk,\n                    }))\n\n        edit_forms.append(edit_message_form)\n        delete_forms.append(delete_message_form)\n\n    edit_thread_form = None\n    if thread.owner == userProfile or request.user.is_superuser:\n        edit_thread_form = EditThreadForm(\n            request.POST if \"edit_thread\" in request.POST else None,\n            instance=thread,\n            )\n\n    add_message_form = MessageForm(\n        request.POST if \"add_message\" in request.POST else None,\n        profile=userProfile,\n        thread=thread,\n        )\n\n    if edit_thread_form and edit_thread_form.is_valid():\n        thread = edit_thread_form.save()\n        return HttpResponseRedirect(reverse(\"threads:view_thread\", kwargs={\n            \"pk\": thread.pk,\n            }))\n    elif add_message_form.is_valid():\n        add_message_form.save()\n        return HttpResponseRedirect(reverse('threads:view_thread', kwargs={\n            'pk': pk,\n            }))\n    elif request.method == \"POST\":\n        messages.add_message(request, messages.ERROR, MESSAGES['MESSAGE_ERROR'])\n\n\n    thread.views += 1\n    thread.save()\n\n    following = request.user in thread.followers.all()\n\n    return render_to_response('view_thread.html', {\n        'thread': thread,\n        'page_name': thread.subject,\n        'messages_list': zip(messages_list, edit_forms, delete_forms),\n        \"add_message_form\": add_message_form,\n        \"edit_thread_form\": edit_thread_form,\n        \"following\": following,\n        \"follow_form\": follow_form,\n        }, context_instance=RequestContext(request))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_user_threads_view(request, targetUsername):\n    ''' View of threads a user has created. '''\n    targetUser = get_object_or_404(User, username=targetUsername)\n    targetProfile = get_object_or_404(UserProfile, user=targetUser)\n    threads = Thread.objects.filter(owner=targetProfile)\n    page_name = \"{0}'s Threads\".format(targetUser.get_full_name())\n    create_form = ThreadForm(\n        request.POST if \"submit_thread_form\" in request.POST else None,\n        profile=UserProfile.objects.get(user=request.user),\n        prefix=\"create\",\n        )\n\n    if create_form.is_valid():\n        thread = create_form.save()\n        return HttpResponseRedirect(reverse(\"threads:view_thread\", kwargs={\"pk\": thread.pk}))\n    elif request.method == \"POST\":\n        messages.add_message(request, messages.ERROR, MESSAGES['THREAD_ERROR'])\n\n    return render_to_response('list_threads.html', {\n        'page_name': page_name,\n        'threads': threads,\n        \"create_form\": create_form,\n        'targetUsername': targetUsername,\n        }, context_instance=RequestContext(request))", "response": "View of threads a user has created."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_user_messages_view(request, targetUsername):\n    ''' View of threads a user has posted in. '''\n    targetUser = get_object_or_404(User, username=targetUsername)\n    targetProfile = get_object_or_404(UserProfile, user=targetUser)\n    user_messages = Message.objects.filter(owner=targetProfile)\n    thread_pks = list(set([i.thread.pk for i in user_messages]))\n    threads = Thread.objects.filter(pk__in=thread_pks)\n    page_name = \"Threads {0} has posted in\".format(targetUser.get_full_name())\n    return render_to_response('list_threads.html', {\n        'page_name': page_name,\n        'threads': threads,\n        'targetUsername': targetUsername,\n        }, context_instance=RequestContext(request))", "response": "View of threads a user has posted in."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_form(self, request, obj=None, **kwargs):\n        defaults = {}\n        if obj is None:\n            defaults['form'] = self.add_form\n        defaults.update(kwargs)\n        return super(SettingsAdmin, self).get_form(request, obj, **defaults)", "response": "Use special form during user creation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the content of the element pointed by the CSS selector or an empty string if the element is not found", "response": "def _css_select(soup, css_selector):\n        \"\"\" Returns the content of the element pointed by the CSS selector,\n        or an empty string if not found \"\"\"\n        selection = soup.select(css_selector)\n        if len(selection) > 0:\n            if hasattr(selection[0], 'text'):\n                retour = selection[0].text.strip()\n            else:\n                retour = \"\"\n        else:\n            retour = \"\"\n        return retour"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an authenticity_token mandatory for signing in", "response": "def get_authenticity_token(self, url=_SIGNIN_URL):\n        \"\"\" Returns an authenticity_token, mandatory for signing in \"\"\"\n        res = self.client._get(url=url, expected_status_code=200)\n        soup = BeautifulSoup(res.text, _DEFAULT_BEAUTIFULSOUP_PARSER)\n        selection = soup.select(_AUTHENTICITY_TOKEN_SELECTOR)\n        try:\n            authenticity_token = selection[0].get(\"content\")\n        except:\n            raise ValueError(\n                \"authenticity_token not found in {} with {}\\n{}\".format(\n                 _SIGNIN_URL, _AUTHENTICITY_TOKEN_SELECTOR, res.text))\n        return authenticity_token"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_surveys(self, url=_SURVEYS_URL):\n        res = self.client._get(url=url, expected_status_code=200)\n        soup = BeautifulSoup(res.text, _DEFAULT_BEAUTIFULSOUP_PARSER)\n        surveys_soup = soup.select(_SURVEYS_SELECTOR)\n        survey_list = []\n        for survey_soup in surveys_soup:\n            survey_name = _css_select(survey_soup, _SURVEY_NAME_SELECTOR)\n\n            try:\n                url = survey_soup.select(_SURVEY_URL_SELECTOR)[0][\"href\"]\n            except:\n                raise ValueError(\"Cannot get URL for the survey \\\nwith css selector {}\".format(_SURVEY_URL_SELECTOR))\n\n            try:\n                id = int(url.split(\"survey_id=\")[1].split(\"&\")[0])\n            except:\n                raise ValueError(\"Cannot extract id from URL {}\".format(\n                    url))\n\n            survey_location = _css_select(survey_soup,\n                                          _SURVEY_LOCATION_SELECTOR)\n            try:\n                survey_epoch = int(survey_soup.select(\n                    _SURVEY_DATE_SELECTOR)[0][\"epoch\"])\n                survey_date_obj = datetime.fromtimestamp(survey_epoch)\n                survey_date = _datetime_object_to_rfc_date_str(survey_date_obj)\n            except:\n                raise ValueError(\"Cannot get date for the survey \\\nwith css selector {}\".format(_SURVEY_DATE_SELECTOR))\n\n            survey_img_nb_and_size = survey_soup.select(\n                _SURVEY_IMG_NB_AND_SIZE_SELECTOR)\n\n            try:\n                survey_img_nb = survey_img_nb_and_size[0].text\n                survey_img_nb = int(survey_img_nb.split(\" \")[0])\n            except:\n                raise ValueError(\"Cannot get or convert image number, \\\nsurvey_img_nb_and_size = {}\".format(survey_img_nb_and_size))\n            try:\n                survey_size = survey_img_nb_and_size[1].text\n            except:\n                raise ValueError(\"Cannot get survey size, \\\nsurvey_img_nb_and_size = {}\".format(survey_img_nb_and_size))\n\n            sensor = _css_select(survey_soup, _SURVEY_SENSOR_SELECTOR)\n\n            survey = Survey(\n                id=id, name=survey_name, url=url,\n                date=survey_date, location=survey_location,\n                image_nb=survey_img_nb, size=survey_size, sensor=sensor)\n            survey_list.append(survey)\n        return survey_list", "response": "Function to get the surveys for the account"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a complete spore client and store it in the cache.", "response": "def get_client(name, description, base_url=None, middlewares=None,\n               reset=False):\n    \"\"\" Build a complete spore client and store it\n\n    :param name: name of the client\n    :param description: the REST API description as a file or URL\n    :param base_url: the base URL of the REST API\n    :param middlewares: middlewares to enable\n    :type middlewares: ordered list of 2-elements tuples -> (middleware_class, {\n        'predicate': ..., 'named_arg1': ..., 'named_arg2': ..., ...})\n    :param reset: regenerate or not the client\n\n\n    Example :\n\n        import britney_utils\n        from britney.middleware.format import Json\n        from britney.middleware.auth import Basic\n\n        is_json = lambda environ: environ['spore.format'] == 'json'\n\n        client = britney_utils.get_client('MyRestApi',\n            'http://my-rest-api.org/description.json',\n            base_url='http://rest-api.org/v2/',\n            middlewares=(\n                (Json, {'predicate': is_json}),\n                (Basic, {'username': 'toto', 'password': 'lala'})\n            ))\n    \"\"\"\n    if name in __clients and not reset:\n        return __clients[name]\n\n    middlewares = middlewares if middlewares is not None else []\n\n    try:\n        client = britney.spyre(description, base_url=base_url)\n    except (SporeClientBuildError, SporeMethodBuildError) as build_errors:\n        logging.getLogger('britney').error(str(build_errors))\n    else:\n        for middleware in middlewares:\n            kwargs = {}\n            if len(middleware) == 2:\n                kwargs = middleware[1]\n            predicate = kwargs.pop('predicate', None)\n            if predicate:\n                client.enable_if(predicate, middleware[0], **kwargs)\n            else:\n                client.enable(middleware[0], **kwargs)\n        __clients[name] = client\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isiterable(element, exclude=None):\n\n    # check for allowed type\n    allowed = exclude is None or not isinstance(element, exclude)\n    result = allowed and isinstance(element, Iterable)\n\n    return result", "response": "Check if input element is an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensureiterable(value, iterable=list, exclude=None):\n\n    result = value\n\n    if not isiterable(value, exclude=exclude):\n        result = [value]\n        result = iterable(result)\n\n    else:\n        result = iterable(value)\n\n    return result", "response": "Convert a value into an iterable if it is not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to get input iterable first item or default if iterable is empty.", "response": "def first(iterable, default=None):\n    \"\"\"Try to get input iterable first item or default if iterable is empty.\n\n    :param Iterable iterable: iterable to iterate on. Must provide the method\n        __iter__.\n    :param default: default value to get if input iterable is empty.\n    :raises TypeError: if iterable is not an iterable value.\n\n    :Example:\n\n    >>> first('tests')\n    't'\n    >>> first('', default='test')\n    'test'\n    >>> first([])\n    None\n    \"\"\"\n\n    result = default\n\n    # start to get the iterable iterator (raises TypeError if iter)\n    iterator = iter(iterable)\n    # get first element\n    try:\n        result = next(iterator)\n    except StopIteration: # if no element exist, result equals default\n        pass\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to get the last item in an iterable.", "response": "def last(iterable, default=None):\n    \"\"\"Try to get the last iterable item by successive iteration on it.\n\n    :param Iterable iterable: iterable to iterate on. Must provide the method\n        __iter__.\n    :param default: default value to get if input iterable is empty.\n    :raises TypeError: if iterable is not an iterable value.\n\n    :Example:\n\n    >>> last('tests')\n    's'\n    >>> last('', default='test')\n    'test'\n    >>> last([])\n    None\"\"\"\n\n    result = default\n\n    iterator = iter(iterable)\n\n    while True:\n        try:\n            result = next(iterator)\n\n        except StopIteration:\n            break\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef itemat(iterable, index):\n\n    result = None\n\n    handleindex = True\n\n    if isinstance(iterable, dict):\n        handleindex = False\n\n    else:\n        try:\n            result = iterable[index]\n        except TypeError:\n            handleindex = False\n\n    if not handleindex:\n        iterator = iter(iterable)\n\n        if index < 0:  # ensure index is positive\n            index += len(iterable)\n\n        while index >= 0:\n            try:\n                value = next(iterator)\n\n            except StopIteration:\n                raise IndexError(\n                    \"{0} index {1} out of range\".format(\n                        iterable.__class__, index\n                    )\n                )\n\n            else:\n                if index == 0:\n                    result = value\n                    break\n                index -= 1\n\n    return result", "response": "Try to get the item at index position in iterable after iterate on iterable items."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply a slice on input iterable.", "response": "def sliceit(iterable, lower=0, upper=None):\n    \"\"\"Apply a slice on input iterable.\n\n    :param iterable: object which provides the method __getitem__ or __iter__.\n    :param int lower: lower bound from where start to get items.\n    :param int upper: upper bound from where finish to get items.\n    :return: sliced object of the same type of iterable if not dict, or specific\n        object. otherwise, simple list of sliced items.\n    :rtype: Iterable\n    \"\"\"\n\n    if upper is None:\n        upper = len(iterable)\n\n    try:\n        result = iterable[lower: upper]\n\n    except TypeError:  # if iterable does not implement the slice method\n        result = []\n\n        if lower < 0:  # ensure lower is positive\n            lower += len(iterable)\n\n        if upper < 0:  # ensure upper is positive\n            upper += len(iterable)\n\n        if upper > lower:\n            iterator = iter(iterable)\n\n            for index in range(upper):\n                try:\n                    value = next(iterator)\n\n                except StopIteration:\n                    break\n\n                else:\n                    if index >= lower:\n                        result.append(value)\n\n    iterablecls = iterable.__class__\n    if not(isinstance(result, iterablecls) or issubclass(iterablecls, dict)):\n        try:\n            result = iterablecls(result)\n\n        except TypeError:\n            pass\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to hash input iterable in doing the sum of its content.", "response": "def hashiter(iterable):\n    \"\"\"Try to hash input iterable in doing the sum of its content if not\n    hashable.\n\n    Hash method on not iterable depends on type:\n\n    hash(iterable.__class__) + ...\n\n        - dict: sum of (hash(key) + 1) * (hash(value) + 1).\n        - Otherwise: sum of (pos + 1) * (hash(item) + 1).\"\"\"\n\n    result = 0\n\n    try:\n        result = hash(iterable)\n\n    except TypeError:\n\n        result = hash(iterable.__class__)\n\n        isdict = isinstance(iterable, dict)\n\n        for index, entry in enumerate(list(iterable)):\n            entryhash = hashiter(entry) + 1\n\n            if isdict:\n                entryhash *= hashiter(iterable[entry]) + 1\n\n            else:\n                entryhash *= index + 1\n\n            result += entryhash\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_python_path():\n    ################ > IMPORTS ################\n    import yaml\n\n    ## IMPORT THE YAML PYTHONPATH DICTIONARY ##\n    path = os.getcwd()\n\n    ################ >ACTION(S) ################\n    # READ THE ABSOLUTE PATH TO THE ROOT DIRECTORY OF THIS PROJECT\n    try:\n        stream = file(pathToYamlFile, 'r')\n        ppDict = yaml.load(stream)\n    except Exception, e:\n        print str(e)\n\n    # READ THE KEYS FROM THE YAML DICTIONARY AND APPEND TO PYTHONPATH\n    svnroot = ppDict[\"project_root\"]\n    pythonpaths = ppDict[\"python_path\"]\n    print \"Here's what has been appended to your pythonpath:\"\n    for k, v in pythonpaths.iteritems():\n        if v:\n            sys.path.append(svnroot + pythonpaths[k])\n            print \"\"\"%s\"\"\" % (svnroot + pythonpaths[k],)\n\n    return", "response": "This function sets the python path for the project modules"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_in_survey_parameters(\n    log,\n    pathToSettingsFile\n):\n    \"\"\"\n    *First reads in the mcs_settings.yaml file to determine the name of the settings file to read in the survey parameters.*\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``pathToSettingsFile`` -- path to the settings file for the simulation\n\n    **Return:**\n        - a tuple of settings lists and dictionaries\n    \"\"\"\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n    ## THIRD PARTY ##\n    import yaml\n    ## LOCAL APPLICATION ##\n\n    ############### VARIABLE ATTRIBUTES #############\n    ################ >ACTION(S) ################\n    # READ THE NAME OF THE SETTINGS FILE FOR THIS SIMULATION\n    try:\n        stream = file(pathToSettingsFile, 'r')\n        thisDict = yaml.load(stream)\n        stream.close()\n    except Exception, e:\n        print str(e)\n\n    # NOW READ IN THE USER SET MCS SETTINGS\n    try:\n        stream = file(pathToSettingsFile, 'r')\n        thisDict = yaml.load(stream)\n        stream.close()\n    except Exception, e:\n        print str(e)\n\n    allSettings = thisDict\n    programSettings = thisDict[\"Program Settings\"]\n\n    limitingMags = thisDict[\"Limiting Magnitudes\"]\n    # for key in limitingMags:\n    # log.debug('filter: %s, limit: %s' % (key, limitingMags[key]))\n\n    sampleNumber = thisDict[\"Simulation Sample\"]\n\n    peakMagnitudeDistributions = thisDict[\n        \"SN Absolute Peak-Magnitude Distributions\"]\n    #log.debug('snDistributions[magnitude] %s' % (snDistributions[\"magnitude\"],))\n    #log.debug('snDistributions[sigma] %s' % (snDistributions[\"sigma\"],))\n\n    relativeRatesSet = thisDict[\"Relative Rate Set to Use\"]\n    relativeSNRates = thisDict[\"Relative SN Rates\"][relativeRatesSet]\n    #log.debug('relativeSNRates %s' % (relativeSNRates,))\n    lowerReshiftLimit = thisDict[\"Lower Redshift Limit\"]\n    upperRedshiftLimit = thisDict[\"Upper Redshift Limit\"]\n    #log.debug('upperRedshiftLimit %s' % (upperRedshiftLimit,))\n    redshiftResolution = thisDict[\"Redshift Resolution\"]\n\n    extinctionSettings = thisDict[\"Extinctions\"]\n    extinctionType = extinctionSettings[\"constant or random\"]\n    extinctionConstant = extinctionSettings[\"constant E(b-v)\"]\n\n    hostExtinctionDistributions = extinctionSettings[\"host\"]\n    #log.debug('hostExtinctionDistributions %s' % (hostExtinctionDistributions,))\n    galacticExtinctionDistribution = extinctionSettings[\"galactic\"]\n    #log.debug('galacticExtinctionDistribution %s' % (galacticExtinctionDistribution,))\n\n    surveyCadenceSettings = thisDict[\"Survey Cadence\"]\n    #log.debug('surveyCadenceSettings %s' % (surveyCadenceSettings,))\n\n    explosionDaysFromSettings = thisDict[\"Explosion Days\"]\n    extendLightCurveTail = thisDict[\"Extend lightcurve tail?\"]\n\n    snLightCurves = thisDict[\"Lightcurves\"]\n    lightCurvePolyOrder = thisDict[\n        \"Order of polynomial used to fits lightcurves\"]\n    #log.debug('snlightCurves %s' % (snlightCurves,))\n\n    surveyArea = thisDict[\"Sky Area of the Survey (square degrees)\"]\n    CCSNRateFraction = thisDict[\"CCSN Progenitor Population Fraction of IMF\"]\n    transientToCCSNRateFraction = thisDict[\"Transient to CCSN Ratio\"]\n    extraSurveyConstraints = thisDict[\"Extra Survey Constraints\"]\n    restFrameFilter = thisDict[\"Rest Frame Filter for K-corrections\"]\n    kCorrectionTemporalResolution = thisDict[\n        \"K-correction temporal resolution (days)\"]\n    kCorPolyOrder = thisDict[\"Order of polynomial used to fits k-corrections\"]\n    kCorMinimumDataPoints = thisDict[\n        \"Minimum number of datapoints used to generate k-correction curve\"]\n    logLevel = thisDict[\"Level of logging required\"]\n\n    return (\n        allSettings,\n        programSettings,\n        limitingMags,\n        sampleNumber,\n        peakMagnitudeDistributions,\n        explosionDaysFromSettings,\n        extendLightCurveTail,\n        relativeSNRates,\n        lowerReshiftLimit,\n        upperRedshiftLimit,\n        redshiftResolution,\n        restFrameFilter,\n        kCorrectionTemporalResolution,\n        kCorPolyOrder,\n        kCorMinimumDataPoints,\n        extinctionType,\n        extinctionConstant,\n        hostExtinctionDistributions,\n        galacticExtinctionDistribution,\n        surveyCadenceSettings,\n        snLightCurves,\n        surveyArea,\n        CCSNRateFraction,\n        transientToCCSNRateFraction,\n        extraSurveyConstraints,\n        lightCurvePolyOrder,\n        logLevel)", "response": "Reads in the mcs_settings. yaml file to determine the name of the settings file for the simulation and returns a tuple of settings lists and dictionaries of the settings lists and the values of the survey parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef settings(\n    pathToSettingsFile,\n    dbConn=True,\n    log=True\n):\n    \"\"\"\n    *Create a connector to the database if required & setup logging*\n\n    **Key Arguments:**\n        - ``pathToOutputDirectory`` -- path to the outpur directory\n        - ``dbConn`` -- want a dbConn?\n        - ``logger`` -- want a logger?\n\n    **Return:**\n        - dbConn - database connection\n        - log - logger\n    \"\"\"\n    ################ > IMPORTS ################\n    # set_python_path()\n    import os\n    import dryxPython.mysql as m\n    import dryxPython.logs as l\n\n    ################ >SETTINGS ################\n    path = os.getcwd()\n\n    ################ >ACTION(S) ################\n    # READ THE PATH OF THIS MODULE TO - SANDBOX OR MARSHALL?\n    if dbConn:\n        dbConn = m.set_db_connection(pathToDBSettings)\n    if log:\n        log = l.setup_dryx_logging(pathToLoggingSettings)\n\n    return dbConn, log", "response": "This function creates a connector to the database if required & setup logging if required"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete all of the local mbox index and state files.", "response": "def clean_up(group, identifier, date):\n    \"\"\"Delete all of a groups local mbox, index, and state files.\n\n    :type group: str\n    :param group: group name\n\n    :type identifier: str\n    :param identifier: the identifier for the given group.\n\n    :rtype: bool\n    :returns: True\n\n    \"\"\"\n    #log.error('exception raised, cleaning up files.')\n    glob_pat = '{g}.{d}.mbox*'.format(g=group, d=date)\n    for f in glob(glob_pat):\n        #log.error('removing {f}'.format(f=f))\n        try:\n            os.remove(f)\n        except OSError:\n            continue\n    glob_pat = '{id}_state.json'.format(id=identifier)\n    for f in glob(glob_pat):\n        #log.error('removing {f}'.format(f=f))\n        try:\n            os.remove(f)\n        except OSError:\n            continue\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef utf8_encode_str(string, encoding='UTF-8'):\n    if not string:\n        return ''\n    src_enc = chardet.detect(string)['encoding']\n    try:\n        return string.decode(src_enc).encode(encoding)\n    except:\n        return string.decode('ascii', errors='replace').encode(encoding)", "response": "Attempt to detect the native encoding of string and re - encode the string to utf - 8."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inline_compress_chunk(chunk, level=1):\n    b = cStringIO.StringIO()\n    g = gzip.GzipFile(fileobj=b, mode='wb', compresslevel=level)\n    g.write(chunk)\n    g.close()\n    cc = b.getvalue()\n    b.close()\n    return cc", "response": "Compress a string using gzip."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a date string into a UTC date str i. e. yyyymmddhhmmss", "response": "def get_utc_iso_date(date_str):\n    \"\"\"Convert date str into a iso-formatted UTC date str, i.e.:\n    yyyymmddhhmmss\n\n    :type date_str: str\n    :param date_str: date string to be parsed.\n\n    :rtype: str\n    :returns: iso-formatted UTC date str.\n\n    \"\"\"\n    try:\n        utc_tuple = dateutil.parser.parse(date_str).utctimetuple()\n    except ValueError:\n        try:\n            date_str = ' '.join(date_str.split(' ')[:-1])\n            utc_tuple = dateutil.parser.parse(date_str).utctimetuple()\n        except ValueError:\n            date_str = ''.join(date_str.split('(')[:-1]).strip(')')\n            utc_tuple = dateutil.parser.parse(date_str).utctimetuple()\n    date_object = datetime.datetime.fromtimestamp(time.mktime(utc_tuple))\n    utc_date_str = ''.join([x for x in date_object.isoformat() if x not in '-T:'])\n    return utc_date_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of paths of git repos under the current directory.", "response": "def get_list_of_git_directories():\n    \"\"\"Returns a list of paths of git repos under the current directory.\"\"\"\n    dirs = [path[0] for path in list(os.walk('.')) if path[0].endswith('.git')]\n    dirs = ['/'.join(path.split('/')[:-1]) for path in dirs]\n    return sorted(dirs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the git status and git pull commands in threads and reports the results in a pretty table.", "response": "def run_git_concurrently(base_dir):\n    \"\"\"Runs the 'git status' and 'git pull' commands in threads and reports\n    the results in a pretty table.\"\"\"\n    os.chdir(base_dir)\n    git_dirs = get_list_of_git_directories()\n    print(\"Processing %d git repos: %s\" % (len(git_dirs), ', '.join(git_dirs)))\n\n    widgets = [Percentage(),\n               ' ', Bar(),\n               ' ', Counter(),\n               ' ', AdaptiveETA()]\n\n    pbar = ProgressBar(widgets=widgets, maxval=len(git_dirs))\n    pbar.start()\n\n    threads = {git_dir:GitPuller(git_dir) for git_dir in git_dirs}\n    for thread in threads.values():\n        thread.start()\n\n    while True:\n        pbar.update(len([t for t in threads.values() if not t.is_alive()]))\n        if all([not t.is_alive() for t in threads.values()]):\n            break\n        time.sleep(0.2)\n\n    table = PrettyTable([\"repo\", \"local\", \"pull\"])\n    table.align[\"repo\"] = \"l\"\n    table.align[\"local\"] = \"l\"\n    table.align[\"pull\"] = \"l\"\n\n    for git_dir in sorted(threads):\n        thread = threads[git_dir]\n        if thread.local_ok:\n            if thread.has_uncommitted_changes:\n                local_changes_text = colored(\n                    'Uncommitted changes', 'green', attrs=['bold'])\n            else:\n                local_changes_text = colored('OK', 'green')\n        else:\n            local_changes_text = colored('Problem', 'red')\n\n        if thread.git_pull_ok:\n            if thread.is_up_to_date:\n                pull_text = colored('OK', 'green')\n            else:\n                pull_text = colored('Changed', 'green', attrs=['bold'])\n        else:\n            pull_text = colored('Problem', 'red')\n\n        table.add_row([git_dir, local_changes_text, pull_text])\n\n    print(table)\n    for git_dir in sorted(threads):\n        if not threads[git_dir].git_pull_ok:\n            thread = threads[git_dir]\n            print colored('%s: ' % git_dir, 'red')\n            print thread.git_pull_output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch feature collections. The route for this endpoint is: ``/dossier/v1/<content_id>/search/<search_engine_name>``. ``content_id`` can be any *profile* content identifier. (This restriction may be lifted at some point.) Namely, it must start with ``p|``. ``engine_name`` corresponds to the search strategy to use. The list of available search engines can be retrieved with the :func:`v1_search_engines` endpoint. This endpoint returns a JSON payload which is an object with a single key, ``results``. ``results`` is a list of objects, where the objects each have ``content_id`` and ``fc`` attributes. ``content_id`` is the unique identifier for the result returned, and ``fc`` is a JSON serialization of a feature collection. There are also two query parameters: * **limit** limits the number of results to the number given. * **filter** sets the filtering function. The default filter function, ``already_labeled``, will filter out any feature collections that have already been labeled with the query ``content_id``.", "response": "def v1_search(request, response, visid_to_dbid, config,\n              search_engines, filters, cid, engine_name):\n    '''Search feature collections.\n\n    The route for this endpoint is:\n    ``/dossier/v1/<content_id>/search/<search_engine_name>``.\n\n    ``content_id`` can be any *profile* content identifier. (This\n    restriction may be lifted at some point.) Namely, it must start\n    with ``p|``.\n\n    ``engine_name`` corresponds to the search strategy to\n    use. The list of available search engines can be retrieved with the\n    :func:`v1_search_engines` endpoint.\n\n    This endpoint returns a JSON payload which is an object with a\n    single key, ``results``. ``results`` is a list of objects, where\n    the objects each have ``content_id`` and ``fc`` attributes.\n    ``content_id`` is the unique identifier for the result returned,\n    and ``fc`` is a JSON serialization of a feature collection.\n\n    There are also two query parameters:\n\n    * **limit** limits the number of results to the number given.\n    * **filter** sets the filtering function. The default\n      filter function, ``already_labeled``, will filter out any\n      feature collections that have already been labeled with the\n      query ``content_id``.\n    '''\n    db_cid = visid_to_dbid(cid)\n    try:\n        search_engine = search_engines[engine_name]\n    except KeyError as e:\n        bottle.abort(404, 'Search engine \"%s\" does not exist.' % e.message)\n    query = request.query if request.method == 'GET' else request.forms\n    search_engine = (config.create(search_engine)\n                           .set_query_id(db_cid)\n                           .set_query_params(query))\n    for name, filter in filters.items():\n        search_engine.add_filter(name, config.create(filter))\n    return search_engine.respond(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a single feature collection.", "response": "def v1_fc_get(visid_to_dbid, store, cid):\n    '''Retrieve a single feature collection.\n\n    The route for this endpoint is:\n    ``/dossier/v1/feature-collections/<content_id>``.\n\n    This endpoint returns a JSON serialization of the feature collection\n    identified by ``content_id``.\n    '''\n    fc = store.get(visid_to_dbid(cid))\n    if fc is None:\n        bottle.abort(404, 'Feature collection \"%s\" does not exist.' % cid)\n    return util.fc_to_json(fc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring a single feature collection.", "response": "def v1_fc_put(request, response, visid_to_dbid, store, cid):\n    '''Store a single feature collection.\n\n    The route for this endpoint is:\n    ``PUT /dossier/v1/feature-collections/<content_id>``.\n\n    ``content_id`` is the id to associate with the given feature\n    collection. The feature collection should be in the request\n    body serialized as JSON.\n\n    This endpoint returns status ``201`` upon successful storage.\n    An existing feature collection with id ``content_id`` is\n    overwritten.\n    '''\n    fc = FeatureCollection.from_dict(json.load(request.body))\n    store.put([(visid_to_dbid(cid), fc)])\n    response.status = 201"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef v1_random_fc_get(response, dbid_to_visid, store):\n    '''Retrieves a random feature collection from the database.\n\n    The route for this endpoint is:\n    ``GET /dossier/v1/random/feature-collection``.\n\n    Assuming the database has at least one feature collection,\n    this end point returns an array of two elements. The first\n    element is the content id and the second element is a\n    feature collection (in the same format returned by\n    :func:`dossier.web.routes.v1_fc_get`).\n\n    If the database is empty, then a 404 error is returned.\n\n    Note that currently, this may not be a uniformly random sample.\n    '''\n    # Careful, `store.scan()` would be obscenely slow here...\n    sample = streaming_sample(store.scan_ids(), 1, 1000)\n    if len(sample) == 0:\n        bottle.abort(404, 'The feature collection store is empty.')\n    return [dbid_to_visid(sample[0]), util.fc_to_json(store.get(sample[0]))]", "response": "Retrieves a random feature collection from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores a single label in the label store.", "response": "def v1_label_put(request, response, visid_to_dbid, config, label_hooks,\n                 label_store, cid1, cid2, annotator_id):\n    '''Store a single label.\n\n    The route for this endpoint is:\n    ``PUT /dossier/v1/labels/<content_id1>/<content_id2>/<annotator_id>``.\n\n    ``content_id`` are the ids of the feature collections to\n    associate. ``annotator_id`` is a string that identifies the\n    human that created the label. The value of the label should\n    be in the request body as one of the following three values:\n    ``-1`` for not coreferent, ``0`` for \"I don't know if they\n    are coreferent\" and ``1`` for coreferent.\n\n    Optionally, the query parameters ``subtopic_id1`` and\n    ``subtopic_id2`` may be specified. Neither, both or either may\n    be given. ``subtopic_id1`` corresponds to a subtopic in\n    ``content_id1`` and ``subtopic_id2`` corresponds to a subtopic\n    in ``content_id2``.\n\n    This endpoint returns status ``201`` upon successful storage.\n    Any existing labels with the given ids are overwritten.\n    '''\n    coref_value = CorefValue(int(request.body.read()))\n    lab = Label(visid_to_dbid(cid1), visid_to_dbid(cid2),\n                annotator_id, coref_value,\n                subtopic_id1=request.query.get('subtopic_id1'),\n                subtopic_id2=request.query.get('subtopic_id2'))\n    label_store.put(lab)\n    response.status = 201"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef v1_label_direct(request, response, visid_to_dbid, dbid_to_visid,\n                    label_store, cid, subid=None):\n    '''Return directly connected labels.\n\n    The routes for this endpoint are\n    ``/dossier/v1/label/<cid>/direct`` and\n    ``/dossier/v1/label/<cid>/subtopic/<subid>/direct``.\n\n    This returns all directly connected labels for ``cid``. Or, if\n    a subtopic id is given, then only directly connected labels for\n    ``(cid, subid)`` are returned.\n\n    The data returned is a JSON list of labels. Each label is a\n    dictionary with the following keys: ``content_id1``,\n    ``content_id2``, ``subtopic_id1``, ``subtopic_id2``,\n    ``annotator_id``, ``epoch_ticks`` and ``value``.\n    '''\n    lab_to_json = partial(label_to_json, dbid_to_visid)\n    ident = make_ident(visid_to_dbid(cid), subid)\n    labs = imap(lab_to_json, label_store.directly_connected(ident))\n    return list(paginate(request, response, labs))", "response": "Return all direct connected labels for a single node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns inferred negative labels.", "response": "def v1_label_negative_inference(request, response,\n                                visid_to_dbid, dbid_to_visid,\n                                label_store, cid):\n    '''Return inferred negative labels.\n\n    The route for this endpoint is:\n    ``/dossier/v1/label/<cid>/negative-inference``.\n\n    Negative labels are inferred by first getting all other content ids\n    connected to ``cid`` through a negative label. For each directly\n    adjacent ``cid'``, the connected components of ``cid`` and\n    ``cid'`` are traversed to find negative labels.\n\n    The data returned is a JSON list of labels. Each label is a\n    dictionary with the following keys: ``content_id1``,\n    ``content_id2``, ``subtopic_id1``, ``subtopic_id2``,\n    ``annotator_id``, ``epoch_ticks`` and ``value``.\n    '''\n    # No subtopics yet? :-(\n    lab_to_json = partial(label_to_json, dbid_to_visid)\n    labs = imap(lab_to_json,\n                label_store.negative_inference(visid_to_dbid(cid)))\n    return list(paginate(request, response, labs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef v1_folder_list(request, kvlclient):\n    '''Retrieves a list of folders for the current user.\n\n    The route for this endpoint is: ``GET /dossier/v1/folder``.\n\n    (Temporarily, the \"current user\" can be set via the\n    ``annotator_id`` query parameter.)\n\n    The payload returned is a list of folder identifiers.\n    '''\n    return sorted(imap(attrgetter('name'),\n                       ifilter(lambda it: it.is_folder(),\n                               new_folders(kvlclient, request).list('/'))))", "response": "Retrieves a list of folders for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a folder to the current user.", "response": "def v1_folder_add(request, response, kvlclient, fid):\n    '''Adds a folder belonging to the current user.\n\n    The route for this endpoint is: ``PUT /dossier/v1/folder/<fid>``.\n\n    If the folder was added successfully, ``201`` status is returned.\n\n    (Temporarily, the \"current user\" can be set via the\n    ``annotator_id`` query parameter.)\n    '''\n    fid = urllib.unquote(fid)\n    new_folders(kvlclient, request).put_folder(fid)\n    response.status = 201"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a list of subfolders in a folder for the current user.", "response": "def v1_subfolder_list(request, response, kvlclient, fid):\n    '''Retrieves a list of subfolders in a folder for the current user.\n\n    The route for this endpoint is:\n    ``GET /dossier/v1/folder/<fid>/subfolder``.\n\n    (Temporarily, the \"current user\" can be set via the\n    ``annotator_id`` query parameter.)\n\n    The payload returned is a list of subfolder identifiers.\n    '''\n    fid = urllib.unquote(fid)\n    try:\n        return sorted(imap(attrgetter('name'),\n                           ifilter(lambda it: it.is_folder(),\n                                   new_folders(kvlclient, request).list(fid))))\n    except KeyError:\n        response.status = 404\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a subtopic to a subfolder for the current user.", "response": "def v1_subfolder_add(request, response, kvlclient,\n                     fid, sfid, cid, subid=None):\n    '''Adds a subtopic to a subfolder for the current user.\n\n    The route for this endpoint is:\n    ``PUT /dossier/v1/folder/<fid>/subfolder/<sfid>/<cid>/<subid>``.\n\n    ``fid`` is the folder identifier, e.g., ``My_Folder``.\n\n    ``sfid`` is the subfolder identifier, e.g., ``My_Subtopic``.\n\n    ``cid`` and ``subid`` are the content id and subtopic id of the\n    subtopic being added to the subfolder.\n\n    If the subfolder does not already exist, it is created\n    automatically. N.B. An empty subfolder cannot exist!\n\n    If the subtopic was added successfully, ``201`` status is returned.\n\n    (Temporarily, the \"current user\" can be set via the\n    ``annotator_id`` query parameter.)\n    '''\n    if subid is not None:\n        assert '@' not in subid\n    path = [\n        urllib.unquote(fid),\n        urllib.unquote(sfid),\n        cid + (('@' + subid) if subid is not None else ''),\n    ]\n    path = '/'.join(path)\n    new_folders(kvlclient, request).put(path)\n    response.status = 201"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a list of items in a subfolder.", "response": "def v1_subtopic_list(request, response, kvlclient, fid, sfid):\n    '''Retrieves a list of items in a subfolder.\n\n    The route for this endpoint is:\n    ``GET /dossier/v1/folder/<fid>/subfolder/<sfid>``.\n\n    (Temporarily, the \"current user\" can be set via the\n    ``annotator_id`` query parameter.)\n\n    The payload returned is a list of two element arrays. The first\n    element in the array is the item's content id and the second\n    element is the item's subtopic id.\n    '''\n    path = urllib.unquote(fid) + '/' + urllib.unquote(sfid)\n    try:\n        items = []\n        for it in new_folders(kvlclient, request).list(path):\n            if '@' in it.name:\n                items.append(it.name.split('@'))\n            else:\n                items.append((it.name, None))\n        return items\n    except KeyError:\n        response.status = 404\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef v1_folder_delete(request, response, kvlclient,\n                     fid, sfid=None, cid=None, subid=None):\n    '''Deletes a folder, subfolder or item.\n\n    The routes for this endpoint are:\n\n    * ``DELETE /dossier/v1/folder/<fid>``\n    * ``DELETE /dossier/v1/folder/<fid>/subfolder/<sfid>``\n    * ``DELETE /dossier/v1/folder/<fid>/subfolder/<sfid>/<cid>``\n    * ``DELETE /dossier/v1/folder/<fid>/subfolder/<sfid>/<cid>/<subid>``\n    '''\n    new_folders(kvlclient, request).delete(make_path(fid, sfid, cid, subid))\n    response.status = 204", "response": "Delete a folder subfolder or item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef v1_folder_rename(request, response, kvlclient,\n                     fid_src, fid_dest, sfid_src=None, sfid_dest=None):\n    '''Rename a folder or a subfolder.\n\n    The routes for this endpoint are:\n\n    * ``POST /dossier/v1/<fid_src>/rename/<fid_dest>``\n    * ``POST /dossier/v1/<fid_src>/subfolder/<sfid_src>/rename/\n      <fid_dest>/subfolder/<sfid_dest>``\n    '''\n    src, dest = make_path(fid_src, sfid_src), make_path(fid_dest, sfid_dest)\n    new_folders(kvlclient, request).move(src, dest)\n    response.status = 200", "response": "Rename a folder or a subfolder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_query_param(url, param, value):\n    '''Returns a new URL with the given query parameter set to ``value``.\n\n    ``value`` may be a list.'''\n    scheme, netloc, path, qs, frag = urlparse.urlsplit(url)\n    params = urlparse.parse_qs(qs)\n    params[param] = value\n    qs = urllib.urlencode(params, doseq=True)\n    return urlparse.urlunsplit((scheme, netloc, path, qs, frag))", "response": "Returns a new URL with the given query parameter set to value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve input expression. This function is given such as template resolution function. For wrapping test for example. :param str expr: configuration expression to resolve. :param bool safe: if True (default), run safely execution context. :param bool tostr: format the result. :param dict scope: execution scope (contains references to expression objects). :param bool besteffort: if True (default), try to resolve unknown variable name with execution runtime. :return: resolved expression.", "response": "def resolver(\n        expr, safe=DEFAULT_SAFE, tostr=DEFAULT_TOSTR, scope=DEFAULT_SCOPE,\n        besteffort=DEFAULT_BESTEFFORT\n):\n    \"\"\"Resolve input expression.\n\n    This function is given such as template resolution function. For wrapping\n    test for example.\n\n    :param str expr: configuration expression to resolve.\n    :param bool safe: if True (default), run safely execution context.\n    :param bool tostr: format the result.\n    :param dict scope: execution scope (contains references to expression\n        objects).\n    :param bool besteffort: if True (default), try to resolve unknown variable\n        name with execution runtime.\n    :return: resolved expression.\"\"\"\n\n\n    raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _to_json(self):\r\n        return dict(( (k, v) for k, v in self.__dict__.iteritems() if k != 'server'))", "response": "Returns a dict of this object s properties so that it can be sent to the client"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef change_name(self, username):\r\n        self.release_name()\r\n\r\n        try:\r\n            self.server.register_name(username)\r\n        except UsernameInUseException:\r\n            logging.log(', '.join(self.server.registered_names))\r\n            self.server.register_name(self.name)\r\n            raise\r\n            \r\n        self.name = username", "response": "changes the username to given username raises exception if username is already used"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreleasing a name and add it to the list of names registered with this user", "response": "def release_name(self, username):\r\n        \"\"\" release a name and add it to the temp list \"\"\"\r\n        self.temp_names.append(username)\r\n        if self.is_username_used(username):\r\n            self.registered_names.remove(username)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the program :param language: :param filename: :param direct: :return:", "response": "def cli(filename, direct, language):\n    # TODO: Flesh this description out\n    \"\"\"\n    Runs the program\n    :param language:\n    :param filename:\n    :param direct:\n    :return:\n    \"\"\"\n    file_extension = filename.split(\".\")[-1]\n    if file_extension not in extensions.keys():\n        error = \"{} is not currently supported in Pyterp.\\n Pyterp currently only supports\" \\\n                \"the following types: {}\".format(file_extension, extensions.items())\n        raise RuntimeError(error)\n\n    if direct is not None and language is None:\n        raise click.BadOptionUsage('--language',\n                                   \"When running a program directly from string, you must specify the langauge \"\n                                   \"with the --language option: Valid options include [bf]\")\n    \"\"\"\n    TODO: Figure out how to best load each interpreter based on extension. Maybe a factory?\n    \"\"\"\n    interpreter = pyterp.Brainfuck(filename=filename, direct_input=direct)\n    interpreter.run()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a command using subprocess. Popen.", "response": "def _do_exec(self, cmd, args):\n        \"\"\"Execute a command using subprocess.Popen().\n        \"\"\"\n        if not args:\n            self.stderr.write(\"execute: empty command\\n\")\n            return\n        proc = subprocess.Popen(subprocess.list2cmdline(args),\n                shell = True, stdout = self.stdout)\n        proc.wait()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds candidates for the exit command.", "response": "def _complete_exit(self, cmd, args, text):\n        \"\"\"Find candidates for the 'exit' command.\"\"\"\n        if args:\n            return\n        return [ x for x in { 'root', 'all', } \\\n                if x.startswith(text) ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _do_history(self, cmd, args):\n        if args and args[0] == 'clear':\n            readline.clear_history()\n            readline.write_history_file(self.history_fname)\n        elif args and args[0] == 'clearall':\n            readline.clear_history()\n            shutil.rmtree(self._temp_dir, ignore_errors = True)\n            os.makedirs(os.path.join(self._temp_dir, 'history'))\n        else:\n            readline.write_history_file(self.history_fname)\n            with open(self.history_fname, 'r', encoding = 'utf8') as f:\n                self.stdout.write(f.read())", "response": "\\ A command that writes the history file to stdout."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _complete_history(self, cmd, args, text):\n        if args:\n            return\n        return [ x for x in { 'clear', 'clearall' } \\\n                if x.startswith(text) ]", "response": "Find candidates for the history command."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps the shell stack in a human friendly way.", "response": "def __dump_stack(self):\n        \"\"\"Dump the shell stack in a human friendly way.\n\n        An example output is:\n                0    PlayBoy\n                1    \u2514\u2500\u2500 foo-prompt: foo@[]\n                2        \u2514\u2500\u2500 karPROMPT: kar@[]\n                3            \u2514\u2500\u2500 DEBUG: debug@['shell']\n        \"\"\"\n        maxdepth = len(self._mode_stack)\n        maxdepth_strlen = len(str(maxdepth))\n        index_width = 4 - (-maxdepth_strlen) % 4 + 4\n        index_str = lambda i: '{:<{}d}'.format(i, index_width)\n\n        self.stdout.write(index_str(0) + self.root_prompt)\n        self.stdout.write('\\n')\n\n        tree_prefix = '\u2514\u2500\u2500 '\n        for i in range(maxdepth):\n            index_prefix = index_str(i + 1)\n            whitespace_prefix = ' ' * len(tree_prefix) * i\n            mode = self._mode_stack[i]\n            line = index_prefix + whitespace_prefix + \\\n                    tree_prefix + mode.prompt + \\\n                    ': {}@{}'.format(mode.cmd, mode.args)\n            self.stdout.write(line)\n            self.stdout.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays the help of the shell and its commands.", "response": "def _do_help(self, cmd, args):\n        \"\"\"Display doc strings of the shell and its commands.\n        \"\"\"\n        print(self.doc_string())\n        print()\n\n        # Create data of the commands table.\n        data_unsorted = []\n        cls = self.__class__\n        for name in dir(cls):\n            obj = getattr(cls, name)\n            if iscommand(obj):\n                cmds = []\n                for cmd in getcommands(obj):\n                    cmds.append(cmd)\n                cmd_str = ','.join(sorted(cmds))\n                doc_str = textwrap.dedent(obj.__doc__).strip() if obj.__doc__ else \\\n                        '(no doc string available)'\n                data_unsorted.append([cmd_str, doc_str])\n        data_sorted = sorted(data_unsorted, key = lambda x: x[0])\n        data = [['COMMANDS', 'DOC STRING']] + data_sorted\n\n        # Create the commands table.\n        table_banner = 'List of Available Commands'\n        table = terminaltables.SingleTable(data, table_banner)\n        table.inner_row_border = True\n        table.inner_heading_row_border = True\n        print(table.table)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gp_rdiff(version, nomed, noxerr, diffRel, divdNdy):\n  inDir, outDir = getWorkDirs()\n  inDir = os.path.join(inDir, version)\n  data, cocktail, medium, rhofo, vacrho = \\\n          OrderedDict(), OrderedDict(), OrderedDict(), OrderedDict(), OrderedDict()\n  #scale = { # QM14 (19 GeV skip later, factor here only informational)\n  #  '19.6': 1.0340571932983775, '200': 1.0, '39': 0.7776679085382481,\n  #  '27': 0.6412140408244136, '62.4': 0.9174700031778402\n  #}\n  scale = {\n      '19.6': 1.3410566491548412, '200': 1.1051002240771077,\n      '39': 1.2719203877292842, '27': 1.350873678084769,\n      '62.4': 1.2664666321635087\n  }\n  yunit = 1.0e-3 if not diffRel else 1.\n  for infile in os.listdir(inDir):\n    if infile == \"cocktail_contribs\": continue\n    energy = re.compile('\\d+').search(infile).group()\n    data_type = re.sub('%s\\.dat' % energy, '', infile)\n    energy = getEnergy4Key(energy)\n    file_url = os.path.join(inDir, infile)\n    data_import = np.loadtxt(open(file_url, 'rb'))\n    if data_type != 'data' and (\n        (version == 'QM14' and energy != '19.6') or version == 'LatestPatrickJieYi'\n    ):\n       data_import[:,(1,3,4)] /= scale[energy]\n    if version == 'LatestPatrickJieYi':\n        if data_type == 'data':\n            data_import = data_import[(data_import[:,0] > 0.14) & (data_import[:,0] < 1.0)]\n        else:\n            data_import = data_import[data_import[:,0] < 1.0]\n    if data_type == 'data': data[energy] = data_import\n    elif data_type == 'cocktail': cocktail[energy] = data_import\n    elif data_type == 'rho' or data_type == 'vacRho' or data_type == 'medium':\n        if noxerr and not diffRel: data_import[:,2:] = 0.\n        data_import[:,1] /= yunit\n        if data_type == 'rho':\n            mask = data_import[:,1] > 0.1\n            rhofo[energy] = data_import if diffRel else data_import[mask]\n        elif data_type == 'vacRho':\n            mask = (data_import[:,0] > 0.35) & (data_import[:,1] > 0.01)\n            vacrho[energy] = data_import if diffRel else data_import[mask]\n        elif not nomed and data_type == 'medium':\n            medium[energy] = data_import\n  nSetsData = len(data)\n\n  shift = { '19.6': '1e0', '27': '1e1', '39': '1e2', '62.4': '1e3', '200': '1e4'\n  } if not diffRel else {\n      '19.6': '1', '27': '8', '39': '50', '62.4': '200', '200': '900'\n  }\n  dataOrdered = OrderedDict()\n  for energy in sorted(data, key=float, reverse=True):\n    # data & bin edges\n    # getUArray propagates stat/syst errors separately internally but\n    # errors need to be doubled to retrieve correct errors\n    uData = getUArray(data[energy])\n    eData = getEdges(data[energy])\n    uCocktail = getUArray(cocktail[energy])\n    eCocktail = getEdges(cocktail[energy])\n    loop = [eData]\n    if energy in medium and diffRel:\n      uMedium = getUArray(medium[energy])\n      eMedium = getEdges(medium[energy])\n      loop.append(eMedium)\n    if energy in rhofo and diffRel:\n      uRho = getUArray(rhofo[energy])\n      eRho = getEdges(rhofo[energy])\n      loop.append(eRho)\n    if energy in vacrho and diffRel:\n      uVacRho = getUArray(vacrho[energy])\n      eVacRho = getEdges(vacrho[energy])\n      loop.append(eVacRho)\n    # loop data/medium bins\n    for l, eArr in enumerate(loop):\n      for i, (e0, e1) in enumzipEdges(eArr):\n        logging.debug('%s/%d> %g - %g:' % (energy, l, e0, e1))\n        # get cocktail sum in data bin range\n        # value+/-0.5*tot.uncert.\n        uCocktailSum = getCocktailSum(e0, e1, eCocktail, uCocktail)\n        if uCocktailSum == 0.: continue\n        # calc. difference and divide by data binwidth again\n        # + set data point\n        if l == 0:\n          uDiff = uData[i] # value+/-0.5*tot.uncert.\n          if diffRel:\n            uDiff /= uCocktailSum # value+/-0.5*tot.uncert.\n          else:\n            uDiff -= uCocktailSum\n            uDiff /= data[energy][i,2] * 2 * yunit\n          dp = [\n            data[energy][i,0], uDiff.nominal_value,\n            data[energy][i,2] if not noxerr else 0.,\n            getErrorComponent(uDiff, 'stat'),\n            getErrorComponent(uDiff, 'syst')\n          ]\n          key = ' '.join([energy, 'GeV'])\n          if noxerr:\n              if diffRel:\n                  key += ' {/Symbol \\264} %s' % shift[energy]\n              else:\n                  expon = shift[energy].split('e')[1]\n                  key += ' {/Symbol \\264} 10^{%s}' % expon\n        elif l == 1:\n          # only done if diffRel\n          uDiff = uMedium[i]\n          uDiff /= uCocktailSum\n          dp = [\n            medium[energy][i,0], uDiff.nominal_value+1,\n            medium[energy][i,2] if not noxerr else 0.,\n            0., 0. # both errors included in data points\n          ]\n          key = ' '.join([energy, 'GeV (Med.)'])\n        elif l == 2:\n          # only done if diffRel\n          uDiff = uRho[i]\n          uDiff /= uCocktailSum\n          dp = [\n            rhofo[energy][i,0], uDiff.nominal_value+1.,\n            rhofo[energy][i,2] if not noxerr else 0.,\n            0., 0. # both errors included in data points\n          ]\n          key = ' '.join([energy, 'GeV (RhoFO.)'])\n        elif l == 3:\n          # only done if diffRel\n          uDiff = uVacRho[i]\n          uDiff /= uCocktailSum\n          dp = [\n            vacrho[energy][i,0], uDiff.nominal_value+1.,\n            vacrho[energy][i,2] if not noxerr else 0.,\n            0., 0. # both errors included in data points\n          ]\n          key = ' '.join([energy, 'GeV (VacRho.)'])\n        # build list of data points\n        if diffRel or l == 0:\n          if dp[0] > 0.7425 and dp[0] < 0.825: continue # mask out omega region\n          if dp[0] > 0.97 and dp[0] < 1.0495: continue # mask out phi region\n        if key in dataOrdered:\n            dataOrdered[key] = np.vstack([dataOrdered[key], dp])\n        else:\n            dataOrdered[key] = np.array([ dp ])\n    if not diffRel:\n      if energy in medium:\n        dataOrdered[' '.join([energy, 'GeV (Med.)'])] = medium[energy]\n      if energy in rhofo:\n        dataOrdered[' '.join([energy, 'GeV (RhoFO.)'])] = rhofo[energy]\n      if energy in vacrho:\n        dataOrdered[' '.join([energy, 'GeV (VacRho.)'])] = vacrho[energy]\n\n  # make plot\n  nSets = len(dataOrdered)\n  nCats = 4\n  nSetsPlot = nSets/nCats if nSets > nSetsData else nSets\n  props = [\n    'lt 1 lw 4 ps 1.5 lc %s pt 18' % default_colors[i]\n      for i in reversed(range(nSetsPlot))\n  ]\n  titles = dataOrdered.keys()\n  if nSets > nSetsData:\n    props = zip_flat(props, *[\n        [\n            'with lines lt %d lw 4 lc %s' % (j+1, default_colors[i])\n            for i in reversed(range(nSetsPlot))\n        ]\n        for j in xrange(nCats-1)\n    ])\n    titles = zip_flat(dataOrdered.keys()[::nCats], *[ [''] * nSetsPlot for j in xrange(nCats-1) ])\n  global labels\n  labels = {\n    '{BES: STAR Preliminary}' if version == 'QM12Latest200' or \\\n      version == 'QM14' or version == 'LatestPatrickJieYi'\n    else 'STAR Preliminary': [\n        0.4 if diffRel else 0.2,0.09 if not diffRel and noxerr else 0.75,False\n    ],\n    '{200 GeV: PRL 113 022301' if version == 'QM12Latest200' \\\n      or version == 'QM14' or version == 'LatestPatrickJieYi'\n    else '': [0.4 if diffRel else 0.2,0.04 if not diffRel and noxerr else 0.7,False],\n  }\n  yr = [.6,2.5e3] if diffRel else [0.05,1.5e5]\n  if noxerr:\n      for k,d in dataOrdered.iteritems():\n          energy = getEnergy4Key(re.compile('\\d+').search(k).group())\n          d[:,(1,3,4)] *= float(shift[energy])\n  gpcalls = [\n      'object 1 rectangle back fc rgb \"grey\" from 0.75,%f to 0.825,%f' % \\\n      (1.7 if diffRel else 0.5, yr[1]),\n      'object 2 rectangle back fc rgb \"grey\" from 0.96,%f to 1.0495,%f' % \\\n      (1.7 if diffRel else 0.5, yr[1]),\n      'object 3 rectangle back fc rgb \"#C6E2FF\" from 0.4,%f to 0.75,%f' % \\\n      (1.7 if diffRel else 0.5, yr[1]),\n      'boxwidth 0.01 absolute',\n  ]\n  hline = 1. if diffRel else .5\n  lines = dict(\n      (('x=%g' % (hline*float(shift[energy]))), 'lc rgb \"black\" lw 4 lt 4')\n      for energy in shift\n  )\n  pseudo_point = np.array([[-1,1,0,0,0]])\n  make_plot(\n    data = dataOrdered.values() + [\n        pseudo_point, pseudo_point, pseudo_point, pseudo_point\n    ],\n    properties = props + [\n        'with lines lt %d lw 4 lc rgb \"black\"' % (lt+1)\n        for lt in xrange(nCats)\n    ],\n    titles = titles + [\n        'HMBT + QGP', 'BW/FO-{/Symbol \\162}', '{/Symbol \\162}/{/Symbol \\167} VacSF+FB+FO',\n        'baseline', #'%g%s' % (hline, ' {/Symbol \\264} 10^{-3}' if not diffRel else '')\n    ],\n    name = os.path.join(outDir, 'diff%s%s%s%s' % (\n      'Rel' if diffRel else 'Abs', version,\n      'NoMed' if nomed else '', 'NoXErr' if noxerr else ''\n    )),\n    xlabel = 'dielectron invariant mass, M_{ee} (GeV/c^{2})',\n    ylabel = 'Enhancement Ratio' if diffRel else 'Excess Yield / dM_{ee} ({/Symbol \\264} 10^{-3} (GeV/c^2)^{-1})',\n    #labels = labels,\n    xr = [0.18,0.97], yr = yr, ylog = True,\n    key = ['at graph 0.96,1.17', 'maxrows 3', 'width -4', 'nobox', 'samplen 0.9'],\n    lines = lines if noxerr else {},\n    gpcalls = gpcalls,\n    lmargin = 0.17, bmargin = 0.1, tmargin = 0.86, rmargin = 0.98,\n    size = '9in,11in', arrow_offset = 0.9, #arrow_length = 0.4,\n  )\n\n  if nomed or noxerr or version == 'QM12': return 'done'\n\n  # integrated enhancement factor\n  if diffRel:\n    enhance = {}\n    data_enhance, medium_enhance, rhofo_enhance, vacrho_enhance = None, None, None, None\n    for energy in sorted(data, key=float):\n      for systLMR in [False, True]:\n        suffix = str(energy)\n        uEnhanceData = getMassRangesSums(\n          data[energy], onlyLMR = True,\n          systLMR = systLMR, suffix = suffix\n        )\n        uEnhanceCocktail = getMassRangesSums(\n          cocktail[energy], onlyLMR = True,\n          systLMR = systLMR, suffix = suffix\n        )\n        if energy in medium:\n          uEnhanceMed = getMassRangesSums(\n            medium[energy], onlyLMR = True,\n            systLMR = systLMR, suffix = suffix\n          )\n        if energy in rhofo:\n          uEnhanceRhoFO = getMassRangesSums(\n            rhofo[energy], onlyLMR = True,\n            systLMR = systLMR, suffix = suffix\n          )\n        if energy in vacrho:\n          uEnhanceVacRho = getMassRangesSums(\n            vacrho[energy], onlyLMR = True,\n            systLMR = systLMR, suffix = suffix\n          )\n        if not systLMR: # uEnhance's are ufloats\n          uEnhanceData /= uEnhanceCocktail\n          dp = [\n              float(energy), uEnhanceData.nominal_value, 0,\n              getErrorComponent(uEnhanceData, 'stat'),\n              getErrorComponent(uEnhanceData, 'syst')\n          ]\n          if data_enhance is None: data_enhance = [ dp ]\n          else: data_enhance.append(dp)\n          if energy in medium:\n            uEnhanceMed /= uEnhanceCocktail\n            dpM = [ float(energy), uEnhanceMed.nominal_value+1., 0, 0, 0 ]\n            if medium_enhance is None: medium_enhance = [ dpM ]\n            else: medium_enhance.append(dpM)\n          if energy in rhofo:\n            uEnhanceRhoFO /= uEnhanceCocktail\n            dpM = [ float(energy), uEnhanceRhoFO.nominal_value+1., 0, 0, 0 ]\n            if rhofo_enhance is None: rhofo_enhance = [ dpM ]\n            else: rhofo_enhance.append(dpM)\n          if energy in vacrho:\n            uEnhanceVacRho /= uEnhanceCocktail\n            dpM = [ float(energy), uEnhanceVacRho.nominal_value+1., 0, 0, 0 ]\n            if vacrho_enhance is None: vacrho_enhance = [ dpM ]\n            else: vacrho_enhance.append(dpM)\n        else: # uEnhance's are dicts of ufloats\n          for k in uEnhanceData:\n            uEnhanceData[k] /= uEnhanceCocktail[k]\n            dp = [\n              float(energy), uEnhanceData[k].nominal_value, 0,\n              getErrorComponent(uEnhanceData[k], 'stat'),\n              getErrorComponent(uEnhanceData[k], 'syst')\n            ]\n            rngstr = k.split('_')[-1]\n            data_key = 'data_' + rngstr\n            if data_key not in enhance: enhance[data_key] = [ dp ]\n            else: enhance[data_key].append(dp)\n            if k in uEnhanceMed:\n              uEnhanceMed[k] /= uEnhanceCocktail[k]\n              dpM = [ float(energy), uEnhanceMed[k].nominal_value ]\n              med_key = 'model_' + rngstr\n              if med_key not in enhance: enhance[med_key] = [ dpM ]\n              else: enhance[med_key].append(dpM)\n            if k in uEnhanceRhoFO:\n              uEnhanceRhoFO[k] /= uEnhanceCocktail[k]\n              dpM = [ float(energy), uEnhanceRhoFO[k].nominal_value+1. ]\n              rhofo_key = 'rhofo_' + rngstr\n              if rhofo_key not in enhance: enhance[rhofo_key] = [ dpM ]\n              else: enhance[rhofo_key].append(dpM)\n            if k in uEnhanceVacRho:\n              uEnhanceVacRho[k] /= uEnhanceCocktail[k]\n              dpM = [ float(energy), uEnhanceVacRho[k].nominal_value+1. ]\n              vacrho_key = 'vacrho_' + rngstr\n              if vacrho_key not in enhance: enhance[vacrho_key] = [ dpM ]\n              else: enhance[vacrho_key].append(dpM)\n    xfacs = os.path.join(outDir, 'xfacs%s.dat' % version)\n    if os.path.exists(xfacs): os.remove(xfacs)\n    fSystLMR = open(xfacs, 'ab')\n    for k in sorted(enhance.keys()):\n      np.savetxt(fSystLMR, enhance[k], fmt = '%g', header = k, comments = '\\n\\n')\n    fSystLMR.close()\n    yr_upp = 4 if version == 'QM12Latest200' or version == 'QM14' else 7\n    if version == 'LatestPatrickJieYi': yr_upp = 5.5\n    #labels.update({\n    #    '{LMR: %.2f < M_{ee} < %.2f GeV/c^{2}}' % (eRanges[1], eRanges[2]): [0.4,0.15,False]\n    #})\n    make_plot(\n      data = [\n          pseudo_point, pseudo_point, pseudo_point,\n          np.array([[17.3,2.73,0,0.25,1.47]]),\n          np.array([[200,4.7,0,0.4,1.5]]),\n          np.array(enhance['data_0.15-0.75']),\n          np.array(enhance['data_0.4-0.75']),\n          np.array(medium_enhance),\n          np.array(rhofo_enhance), np.array(vacrho_enhance)\n      ],\n      properties = [\n          'lt 1 lw 4 ps 2 lc rgb \"white\" pt 19',\n          'lt 1 lw 4 ps 2 lc rgb \"white\" pt 20',\n          'lt 1 lw 4 ps 2 lc rgb \"white\" pt 18',\n          'lt 1 lw 4 ps 2 lc %s pt 19' % default_colors[1],\n          'lt 1 lw 4 ps 2 lc %s pt 20' % default_colors[3],\n          'lt 1 lw 4 ps 2 lc %s pt 18' % default_colors[4],\n          'lt 1 lw 4 ps 2 lc %s pt 18' % default_colors[0],\n          'with lines lt 2 lw 4 lc %s' % default_colors[-1],\n          'with lines lt 3 lw 4 lc %s' % default_colors[-1],\n          'with lines lt 4 lw 4 lc %s' % default_colors[-1],\n      ],\n      titles = [\n          'CERES Pb+Au', 'PHENIX Au+Au', 'STAR Au+Au',\n          '', '', '', '',\n          'HMBT + QGP', 'BW/FO-{/Symbol \\162}', '{/Symbol \\162}/{/Symbol \\167} VacSF+FB',\n      ],\n      name = os.path.join(outDir, 'enhance%s' % version),\n      xlabel = '{/Symbol \\326}s_{NN} (GeV)',\n      ylabel = 'LMR Enhancement Factor',\n      xlog = True, key = [ 'at graph 0.9,0.98', 'nobox', 'maxrows 4' ],\n      size = '10in,8in', bmargin = 0.13, tmargin = 0.92, rmargin = 0.99,\n      yr = [1.,yr_upp], xr = [14,220], gpcalls = [\n        'format x \"%g\"',\n        'xtics (10, 20,\"\" 30, 40,\"\" 50, 60,\"\" 70,\"\" 80,\"\" 90, 100, 200)',\n        'boxwidth 0.025 absolute',\n        'label 50 \"{/=18 0.2 < M_{ee} < 0.6 GeV/c^{2}}\" at 15.5,3 tc %s rotate center' % default_colors[1],\n        'label 51 \"{/=18 0.15 < M_{ee} < 0.75 GeV/c^{2}}\" at 180,4.2 tc %s rotate center' % default_colors[3],\n        'label 52 \"{/=18 0.4 < M_{ee} < 0.75 GeV/c^{2}}\" at 75,3.1 tc %s rotate by -20' % default_colors[0],\n        'label 53 \"{/=18 0.15 < M_{ee} < 0.75 GeV/c^{2}}\" at 50,1.2 tc %s' % default_colors[4]\n      ], #labels = labels\n    )\n    return 'done'\n\n  # integrated excess yield in mass ranges\n  excess = {}\n  for k, v in dataOrdered.iteritems():\n    suffix = ''\n    energy = getEnergy4Key(re.compile('\\d+').search(k).group())\n    if fnmatch(k, '*Med.*'):\n      suffix = '_Med'\n      if version != 'LatestPatrickJieYi' and energy == '27': continue # TODO\n    if fnmatch(k, '*RhoFO.*'): suffix = '_RhoFO'\n    if fnmatch(k, '*VacRho.*'): suffix = '_VacRho'\n    exc = getMassRangesSums(np.array(v), onlyLMR = True)\n    if divdNdy: exc /= dNdyPi0[energy] * 1e-2\n    dp = [\n        float(energy), exc.nominal_value, 0,\n        getErrorComponent(exc, 'stat'), getErrorComponent(exc, 'syst')\n    ]\n    if suffix == '_Med' and not diffRel and not divdNdy:\n        print dp\n    key = 'LMR' + suffix\n    if key not in excess: excess[key] = [ dp ]\n    else: excess[key].append(dp)\n  logging.debug(excess)\n  avdata = np.array(excess['LMR'])\n  avg = np.average(avdata[:,1], weights = avdata[:,3])\n  graph_data = [\n      np.array([\n          [ 7.7, avg, 0, 0, avdata[-1][-1]],\n          [ 19.6, avg, 0, 0, avdata[-1][-1]]\n      ]),\n      np.array([\n          [ 19.6, avg, 0, 0, 0], [ 200., avg, 0, 0, 0]\n      ]),\n      np.array([\n          [ 7.7, 2*avg, 0, 0, 0], [ 19.6, avg, 0, 0, 0],\n      ]),\n      np.array(excess['LMR']),\n  ]\n  props = [\n      'with filledcurves pt 0 lc %s lw 4 lt 2' % default_colors[8],\n      'with lines lc %s lw 4 lt 2' % default_colors[8],\n      'with lines lc %s lw 8 lt 2' % default_colors[1],\n      'lt 1 lw 4 ps 2 lc %s pt 18' % default_colors[0],\n  ]\n  tits = [\n      'BES-I extrapolation', '', 'model expectation', 'STAR Au+Au',\n  ]\n  if version != 'QM14':\n      graph_data += [\n          np.array(excess['LMR_Med']),\n          np.array(excess['LMR_VacRho']),\n          np.array(excess['LMR_RhoFO']),\n      ]\n      props += [\n          'with lines lt 2 lw 4 lc %s' % default_colors[-1],\n          'with lines lt 3 lw 4 lc %s' % default_colors[-1],\n          'with lines lt 4 lw 4 lc %s' % default_colors[-1],\n      ]\n      tits += [\n          'HMBT + QGP', '{/Symbol \\162}/{/Symbol \\167} VacSF+FB', 'BW/FO-{/Symbol \\162}',\n      ]\n  yr_upp = 4.5 if version == 'QM12Latest200' or version == 'QM14' else 7\n  if version == 'LatestPatrickJieYi': yr_upp = 2 if divdNdy else 2.\n  labels = {} if version != 'QM14' else labels\n  if divdNdy:\n    labels.update(dict((str(v), [float(k)*0.9,yr_upp*1.05,True]) for k,v in dNdyPi0.items()))\n    labels.update({ 'dN/dy|_{/Symbol \\\\160}': [100,yr_upp*1.05,True]})\n  gpcalls = [\n    'format x \"%g\"',\n    'xtics (7,10,20,\"\" 30, 40,\"\" 50, 60,\"\" 70,\"\" 80,\"\" 90, 100, 200)',\n    'boxwidth 0.025 absolute',\n  ]\n  if version == 'QM14':\n    labels.update({\n      '{LMR: %.2f < M_{ee} < %.2f GeV/c^{2}}' % (eRanges[1], eRanges[2]): [0.4,0.15,False],\n    })\n  else:\n    gpcalls.append('label 52 \"{/=18 0.4 < M_{ee} < 0.75 GeV/c^{2}}\" at 60,0.4 tc %s' % default_colors[0])\n  make_plot(\n    data = graph_data, properties = props, titles = tits,\n    name = os.path.join(outDir, 'excess%s%s' % (version,'DivdNdy' if divdNdy else '')),\n    xlabel = '{/Symbol \\326}s_{NN} (GeV)',\n    ylabel = 'LMR Excess Yield %s({/Symbol \\264} 10^{-%d})' % (\n        '/ dN/dy|_{/Symbol \\\\160}  ' if divdNdy else '', 5 if divdNdy else 3\n    ),\n    xlog = True, xr = [7,220], size = '10in,8in',\n    key = ['at graph 1.05,0.98', 'width -3', 'nobox', 'maxrows 3'],\n    bmargin = 0.13, tmargin = 0.92, rmargin = 0.99,\n    yr = [0,yr_upp], gpcalls = gpcalls, labels = labels,\n  )\n  return 'done'", "response": "example for ratio or difference plots using QM12 data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef of_bytes(self, py_bytes):\n        m = self.hash_algo()\n        m.update(py_bytes)\n        if self.return_int:\n            return int(m.hexdigest(), 16)\n        else:\n            return m.hexdigest()", "response": "Use default hash method to return hash value of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing default hash method to return hash value of a piece of string default setting use utf - 8 encoding.", "response": "def of_text(self, text, encoding=\"utf-8\"):\n        \"\"\"Use default hash method to return hash value of a piece of string\n        default setting use 'utf-8' encoding.\n        \"\"\"\n        m = self.hash_algo()\n        m.update(text.encode(encoding))\n        if self.return_int:\n            return int(m.hexdigest(), 16)\n        else:\n            return m.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef of_pyobj(self, pyobj):\n        m = self.hash_algo()\n        m.update(pickle.dumps(pyobj, protocol=self.pk_protocol))\n        if self.return_int:\n            return int(m.hexdigest(), 16)\n        else:\n            return m.hexdigest()", "response": "Use default hash method to return hash value of a piece of Python\n        picklable object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_spectra_from_file(\n        log,\n        pathToSpectrum,\n        convertLumToFlux=False):\n    \"\"\"\n    *Given a spectrum file this function shall convert the two columns (wavelength and luminosity) to a wavelegnth (wavelengthArray) and flux (fluxArray) array*\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``pathToSpectrum`` -- absolute path the the spectrum file\n\n    **Return:**\n        - None\n    \"\"\"\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n    import os\n    ## THIRD PARTY ##\n    import numpy as np\n    ## LOCAL APPLICATION ##\n    import dryxPython.astrotools as at\n\n    ################ > VARIABLE SETTINGS ######\n    ################ >ACTION(S) ################\n    # USE numPy TO EXTRACT THE DATA FROM FILE\n    pwd = os.getcwd()\n    log.debug('pwd %s' % (pwd,))\n    log.debug('pathToSpectrum %s' % (pathToSpectrum,))\n    data = np.genfromtxt(pathToSpectrum, skip_header=0, usecols=(0, 1))\n    wavelengthArray = data[:, 0]\n    # minWl = wavelengthArray.min()\n    # maxWl = wavelengthArray.max()\n    luminosityArray = data[:, 1]\n    # CONVERT TO FLUX:  F = L / 4*pi*(r**2)\n    if convertLumToFlux:\n        fluxArray = at.luminosity_to_flux(luminosityArray, 1e-5)\n    else:\n        fluxArray = luminosityArray\n\n    # DEBUG BLOCK\n    log.debug('pathToSpectrum: %s' % (pathToSpectrum,))\n    # for i in range(len(fluxArray)):\n    #     print \"\"\"%s\\t%s\\t%s\"\"\" % (wavelengthArray[i], luminosityArray[i], fluxArray[i] )\n    # print \"\\n\\n\\n\"\n    return wavelengthArray, fluxArray", "response": "This function extracts the spectrum from a file and returns the wavelength and flux arrays."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_filter_transmissions(log, filterList):\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n    ## THIRD PARTY ##\n    import matplotlib.pyplot as plt\n    import numpy as np\n    ## LOCAL APPLICATION ##\n\n    ################ > VARIABLE SETTINGS ######\n    ################ >ACTION(S) ################\n    for filterFile in filterList:\n        data = np.genfromtxt(filterFile)\n        plt.plot(data[:, 0], data[:, 1])\n\n    plt.show()\n    return", "response": "Plot the filters on a single plot"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the effective photometric frequency of a single spectrum and returns the frequency of the spectrum in the database.", "response": "def calcphot(log, wavelengthArray, fluxArray, obsmode, extrapolate=False):\n    \"\"\"\n    *Run calcphot on single spectrum and filter.*\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``wavelengthArray`` -- the array containing the wavelength range of the spectrum\n        - ``fluxArray`` -- the array contain the respective spectrum flux (as function of wavelength)\n        - ``obsmode`` -- the observation mode (generally a filter system and filter type, e.g. \"sdss,g\")\n        - ``extrapolate`` -- extrapolate spectra in database to cover the requested band-pass. Default *False*.\n\n    **Return:**\n        - None\n    \"\"\"\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n    ## THIRD PARTY ##\n    import pysynphot as syn\n    ## LOCAL APPLICATION ##\n\n    if extrapolate:\n        force = \"extrapolate\"\n    else:\n        force = None\n\n    ################ > VARIABLE SETTINGS ######\n    # Read in a spectrum from a file\n    sp = syn.ArraySpectrum(\n        wave=wavelengthArray, flux=fluxArray, waveunits='angstrom', fluxunits='flam')\n    bp = syn.ObsBandpass(obsmode)\n    obs = syn.Observation(sp, bp, force=force)\n    abMag = obs.effstim('abmag')\n\n    return abMag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plotLightCurves(\n        log,\n        lightCurves,\n        polyOrder,\n        pathToOutputDirectory):\n    \"\"\"\n    *plot lightcurve(s) given an list of magnitude, time pairs*\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``lightCurves`` -- list of magnitude, time numPy arrays\n        - ``polyOrder`` -- order of polynomial used to fit the model lightcurves extracted from spectra\n        - ``pathToOutputDirectory`` -- path to the output directory\n\n    **Return:**\n        - None\n    \"\"\"\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n    ## THIRD PARTY ##\n    import matplotlib.pyplot as plt\n    import numpy as np\n    ## LOCAL APPLICATION ##\n\n    resultsDict = {}\n    ################ > VARIABLE SETTINGS ######\n    ################ >ACTION(S) ################\n    ax = plt.subplot(111)\n    curveDict = {}\n    for curve in lightCurves:\n        x = curve[1]\n        y = curve[0]\n\n        # CAUSE LIGHTCURVE GENERATION TO FAIL IF LESS THAN 5 POINTS EXTRACTED\n        # FROM THE SPECTRA\n        if len(x) <= 4:\n            curveDict['poly'] = None\n            continue\n\n        order = polyOrder\n        poly = np.polyfit(x, y, order)\n        curveDict['poly'] = poly\n        pOrder = np.poly1d(poly)\n        polyString = \"mxxx[i] = \"\n        polyStringMd = \"\\\\\\\\(mag = \"\n        for i in range(0, order + 1):\n            if i > 0 and poly[i] > 0:\n                polyString += \"+\"\n                polyStringMd += \"+\"\n            polyString += \"\"\"%s*pow(i,%s) \"\"\" % (poly[i], order - i)\n            polyStringMd += \"\"\"%s*time^{%s} \"\"\" % (poly[i], order - i)\n        polyStringMd += \"\\\\\\\\)\"\n\n        xp = np.arange(int(min(x)), int(max(x)), 0.2)\n        ax.plot(x, y, '.', xp, pOrder(xp), '--')\n\n    title = curve[5]\n    # Shink current axis by 20%\n    box = ax.get_position()\n    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'size': 8})\n    ax.titlesize = 'medium'   # fontsize of the axes title\n    ax.labelsize = 'medium'  # fontsize of the x any y labels\n    plt.xlabel(\"Days Relative to Peak\")\n    plt.ylabel(\"Magnitude\")\n    plt.title(title, fontsize='small',\n              verticalalignment='bottom', linespacing=0.2)\n    ax.invert_yaxis()\n\n    fileName = pathToOutputDirectory + title.replace(\" \", \"_\") + \".png\"\n    # mdPlotLink = \"\"\"![%s_plot]\\n\\n[%s_plot]: %s\\n\\n\"\"\" % (title.replace(\" \", \"_\"), title.replace(\" \", \"_\"), fileName,)\n    # curveDict['mdLink'] = mdPlotLink\n    plt.savefig(fileName)\n    plt.clf()  # clear figure\n\n    return curveDict", "response": "This function plots the light curves for a single log and light curves in a single file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the k - correction polynoimal database for a set of redshifts.", "response": "def generate_kcorrection_polynomial_database(\n        log,\n        restFrameFilter,\n        pathToOutputDirectory,\n        kCorPolyOrder=3,\n        kCorMinimumDataPoints=3,\n        redshiftResolution=0.1,\n        redshiftLower=0.0,\n        redshiftUpper=1.0,\n        plot=False):\n    \"\"\"\n    *Generate the Kg* k-correction polynoimal for a range of redshifts given a list of spectra*\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``restFrameFilter`` -- the observed frame filter with which to calculate k-corrections with\n        - ``pathToOutputDirectory`` -- path to the output directory (provided by the user)\n        - ``kCorPolyOrder`` -- the order of the polynomials to fit\n        - ``kCorMinimumDataPoints`` -- Minimum number of datapoints used to generate k-correction curve\n        - ``redshiftResolution`` -- resolution of the k-correction database (at what redshift points do you want the k-corrections calculated)\n        - ``redshiftLower`` -- lower redshift in range of k-corrections to be calculated\n        - ``redshiftUpper`` -- upper redshift in range of k-corrections to be calculated\n        - ``plot`` -- plot the polynomial?\n\n    **Return:**\n        - None\n    \"\"\"\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n    import re\n    import os\n    ## THIRD PARTY ##\n    import pysynphot as syn\n    import yaml\n    ## LOCAL APPLICATION ##\n\n    mul = 1000\n    div = 1000.\n\n    fileName = pathToOutputDirectory + \"/transient_light_curves.yaml\"\n    stream = file(fileName, 'r')\n    generatedLCs = yaml.load(stream)\n    models = generatedLCs.keys()\n    filters = ['g', 'r', 'i', 'z']\n    # models = [\"he130\",]\n    for model in models:\n\n        for redshift in range(int(redshiftLower * mul), int(redshiftUpper * mul), int(redshiftResolution * mul)):\n            redshift = redshift / div\n\n            for ffilter in filters:\n                generate_single_kcorrection_polynomial(\n                    log,\n                    model=model,\n                    pathToOutputDirectory=pathToOutputDirectory,\n                    redshift=redshift,\n                    ffilter=ffilter,\n                    restFrameFilter=restFrameFilter,\n                    kCorPolyOrder=kCorPolyOrder,\n                    kCorMinimumDataPoints=kCorMinimumDataPoints,\n                    plot=plot)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclears cached items ( e. g. when model is reset.", "response": "def clearCache(self):\n        'Clears cached items (e.g., when model is reset).'\n        for attr in self.cacheItems:\n            if hasattr(self, attr):\n                delattr(self, attr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hazeDriver():\n  try:\n    (command, args) = findSubCommand(sys.argv)\n\n    # If we can't construct a subcommand from sys.argv, it'll still be able\n    # to find this haze driver script, and re-running ourself isn't useful.\n    if os.path.basename(command) == \"haze\":\n      print \"Could not find a subcommand for %s\" % \" \".join(sys.argv)\n      sys.exit(1)\n  except StandardError:\n    print \"Could not find a subcommand for %s\" % \" \".join(sys.argv)\n    sys.exit(1)\n  check_call([command] + args)", "response": "This function is called by hazeDriver. It will process the command line arguments and run the appropriate haze subcommand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit a string on the given separation character but respecting the double - quoted sections of the string.", "response": "def quoted_split(string, sep, quotes='\"'):\n    \"\"\"\n    Split a string on the given separation character, but respecting\n    double-quoted sections of the string.  Returns an iterator.\n\n    :param string: The string to split.\n    :param sep: The character separating sections of the string.\n    :param quotes: A string specifying all legal quote characters.\n\n    :returns: An iterator which will iterate over each element of the\n              string separated by the designated separator.\n    \"\"\"\n\n    # Initialize the algorithm\n    start = None\n    escape = False\n    quote = False\n\n    # Walk through the string\n    for i, c in enumerate(string):\n        # Save the start index\n        if start is None:\n            start = i\n\n        # Handle escape sequences\n        if escape:\n            escape = False\n\n        # Handle quoted strings\n        elif quote:\n            if c == '\\\\':\n                escape = True\n            elif c == quote:\n                quote = False\n\n        # Handle the separator\n        elif c == sep:\n            yield string[start:i]\n            start = None\n\n        # Handle quotes\n        elif c in quotes:\n            quote = c\n\n    # Yield the last part\n    if start is not None:\n        yield string[start:]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a content type into a tuple of the content type and a dictionary containing the content type parameters.", "response": "def parse_ctype(ctype):\n    \"\"\"\n    Parse a content type.\n\n    :param ctype: The content type, with corresponding parameters.\n\n    :returns: A tuple of the content type and a dictionary containing\n              the content type parameters.  The content type will\n              additionally be available in the dictionary as the '_'\n              key.\n    \"\"\"\n\n    result_ctype = None\n    result = {}\n    for part in quoted_split(ctype, ';'):\n        # Extract the content type first\n        if result_ctype is None:\n            result_ctype = part\n            result['_'] = part\n            continue\n\n        # OK, we have a 'key' or 'key=value' to handle; figure it\n        # out...\n        equal = part.find('=')\n        if equal > 0 and part.find('\"', 0, equal) < 0:\n            result[part[:equal]] = unquote(part[equal + 1:])\n        else:\n            # If equal > 0 but it's preceded by a \", it's seriously\n            # messed up, but go ahead and be liberal...\n            result[part] = True\n\n    # If we failed to parse a content type out, return an empty\n    # content type\n    if result_ctype is None:\n        result_ctype = ''\n\n    return result_ctype, result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _match_mask(mask, ctype):\n\n    # Handle the simple cases first\n    if '*' not in mask:\n        return ctype == mask\n    elif mask == '*/*':\n        return True\n    elif not mask.endswith('/*'):\n        return False\n\n    mask_major = mask[:-2]\n    ctype_major = ctype.split('/', 1)[0]\n    return ctype_major == mask_major", "response": "Determines if a content type mask matches a given content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef best_match(requested, allowed):\n\n    requested = [parse_ctype(ctype) for ctype in quoted_split(requested, ',')]\n\n    best_q = -1\n    best_ctype = ''\n    best_params = {}\n    best_match = '*/*'\n\n    # Walk the list of content types\n    for ctype in allowed:\n        # Compare to the accept list\n        for ctype_mask, params in requested:\n            try:\n                q = float(params.get('q', 1.0))\n            except ValueError:\n                # Bad quality value\n                continue\n\n            if q < best_q:\n                # Not any better\n                continue\n            elif best_q == q:\n                # Base on the best match\n                if best_match.count('*') <= ctype_mask.count('*'):\n                    continue\n\n            # OK, see if we have a match\n            if _match_mask(ctype_mask, ctype):\n                best_q = q\n                best_ctype = ctype\n                best_params = params\n                best_match = ctype_mask\n\n    # Return the best match\n    return best_ctype, best_params", "response": "Determine the best match for a content type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_key(log_prefix, result_dict, key, value, desc=\"parameter\"):\n\n    if key in result_dict:\n        LOG.warn(\"%s: Duplicate value for %s %r\" %\n                 (log_prefix, desc, key))\n        # Allow the overwrite\n\n    # Demand the value be quoted\n    if len(value) <= 2 or value[0] not in ('\"', \"'\") or value[0] != value[-1]:\n        LOG.warn(\"%s: Invalid value %r for %s %r\" %\n                 (log_prefix, value, desc, key))\n        return\n\n    # Save the value\n    result_dict[key] = value[1:-1]", "response": "Helper function to set a key value in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a version rule.", "response": "def _parse_version_rule(loader, version, verspec):\n    \"\"\"\n    Parse a version rule.  The first token is the name of the\n    application implementing that API version.  The remaining tokens\n    are key=\"quoted value\" pairs that specify parameters; these\n    parameters are ignored by AVersion, but may be used by the\n    application.\n\n    :param loader: An object with a get_app() method, which will be\n                   used to load the actual applications.\n    :param version: The version name.\n    :param verspec: The version text, described above.\n\n    :returns: A dictionary of three keys: \"app\" is the application;\n              \"name\" is the version identification string; and\n              \"params\" is a dictionary of parameters.\n    \"\"\"\n\n    result = dict(name=version, params={})\n    for token in quoted_split(verspec, ' ', quotes='\"\\''):\n        if not token:\n            continue\n\n        # Convert the application\n        if 'app' not in result:\n            result['app'] = loader.get_app(token)\n            continue\n\n        # What remains is key=\"quoted value\" pairs...\n        key, _eq, value = token.partition('=')\n\n        # Set the parameter key\n        _set_key('version.%s' % version, result['params'], key, value)\n\n    # Make sure we have an application\n    if 'app' not in result:\n        raise ImportError(\"Cannot load application for version %r\" % version)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse an alias rule.", "response": "def _parse_alias_rule(alias, alias_spec):\n    \"\"\"\n    Parse an alias rule.  The first token is the canonical name of the\n    version.  The remaining tokens are key=\"quoted value\" pairs that\n    specify parameters; these parameters are ignored by AVersion, but\n    may be used by the application.\n\n    :param alias: The alias name.\n    :param alias_spec: The alias text, described above.\n\n    :returns: A dictionary of three keys: \"alias\" is the alias name;\n              \"version\" is the canonical version identification\n              string; and \"params\" is a dictionary of parameters.\n    \"\"\"\n\n    result = dict(alias=alias, params={})\n    for token in quoted_split(alias_spec, ' ', quotes='\"\\''):\n        if not token:\n            continue\n\n        # Suck out the canonical version name\n        if 'version' not in result:\n            result['version'] = token\n            continue\n\n        # What remains is key=\"quoted value\" pairs...\n        key, _eq, value = token.partition('=')\n\n        # Set the parameter key\n        _set_key('alias.%s' % alias, result['params'], key, value)\n\n    # Make sure we have a canonical version\n    if 'version' not in result:\n        raise KeyError(\"Cannot determine canonical version for alias %r\" %\n                       alias)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a content type rule.", "response": "def _parse_type_rule(ctype, typespec):\n    \"\"\"\n    Parse a content type rule.  Unlike the other rules, content type\n    rules are more complex, since both selected content type and API\n    version must be expressed by one rule.  The rule is split on\n    whitespace, then the components beginning with \"type:\" and\n    \"version:\" are selected; in both cases, the text following the \":\"\n    character will be treated as a format string, which will be\n    formatted using a content parameter dictionary.  Components\n    beginning with \"param:\" specify key=\"quoted value\" pairs that\n    specify parameters; these parameters are ignored by AVersion, but\n    may be used by the application.\n\n    :param ctype: The content type the rule is for.\n    :param typespec: The rule text, described above.\n\n    :returns: An instance of TypeRule.\n    \"\"\"\n\n    params = {'param': {}}\n    for token in quoted_split(typespec, ' ', quotes='\"\\''):\n        if not token:\n            continue\n\n        tok_type, _sep, tok_val = token.partition(':')\n\n        # Validate the token type\n        if not tok_val:\n            LOG.warn(\"%s: Invalid type token %r\" % (ctype, token))\n            continue\n        elif tok_type not in ('type', 'version', 'param'):\n            LOG.warn(\"%s: Unrecognized token type %r\" % (ctype, tok_type))\n            continue\n\n        # Intercept 'param' clauses\n        if tok_type == 'param':\n            key, _eq, value = tok_val.partition('=')\n\n            # Set the parameter key\n            _set_key('type.%s' % ctype, params['param'], key, value)\n            continue\n\n        # Set the token value\n        _set_key('type.%s' % ctype, params, tok_type, tok_val,\n                 desc=\"token type\")\n\n    return TypeRule(ctype=params.get('type'),\n                    version=params.get('version'),\n                    params=params['param'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_ctype(self, ctype, orig_ctype=None):\n\n        if self.ctype is None:\n            self.ctype = ctype\n            self.orig_ctype = orig_ctype", "response": "Sets the content type of the current object. Will not override the value of\n            the content type that has already been determined."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process(self, request, result=None):\n\n        # Allocate a result and process all the rules\n        result = result if result is not None else Result()\n        self._proc_uri(request, result)\n        self._proc_ctype_header(request, result)\n        self._proc_accept_header(request, result)\n\n        return result", "response": "Process the rules for the request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _proc_uri(self, request, result):\n\n        if result:\n            # Result has already been fully determined\n            return\n\n        # First, determine the version based on the URI prefix\n        for prefix, version in self.uris:\n            if (request.path_info == prefix or\n                    request.path_info.startswith(prefix + '/')):\n                result.set_version(version)\n\n                # Update the request particulars\n                request.script_name += prefix\n                request.path_info = request.path_info[len(prefix):]\n                if not request.path_info:\n                    request.path_info = '/'\n                break\n\n        # Next, determine the content type based on the URI suffix\n        for format, ctype in self.formats.items():\n            if request.path_info.endswith(format):\n                result.set_ctype(ctype)\n\n                # Update the request particulars\n                request.path_info = request.path_info[:-len(format)]\n                break", "response": "Process the URI rules for the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the Content - Type header rules for the request.", "response": "def _proc_ctype_header(self, request, result):\n        \"\"\"\n        Process the Content-Type header rules for the request.  Only\n        the desired API version can be determined from those rules.\n\n        :param request: The Request object provided by WebOb.\n        :param result: The Result object to store the results in.\n        \"\"\"\n\n        if result:\n            # Result has already been fully determined\n            return\n\n        try:\n            ctype = request.headers['content-type']\n        except KeyError:\n            # No content-type header to examine\n            return\n\n        # Parse the content type\n        ctype, params = parse_ctype(ctype)\n\n        # Is it a recognized content type?\n        if ctype not in self.types:\n            return\n\n        # Get the mapped ctype and version\n        mapped_ctype, mapped_version = self.types[ctype](params)\n\n        # Update the content type header and set the version\n        if mapped_ctype:\n            request.environ['aversion.request_type'] = mapped_ctype\n            request.environ['aversion.orig_request_type'] = ctype\n            request.environ['aversion.content_type'] = \\\n                request.headers['content-type']\n            if self.overwrite_headers:\n                request.headers['content-type'] = mapped_ctype\n        if mapped_version:\n            result.set_version(mapped_version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the Accept header rules for the request.", "response": "def _proc_accept_header(self, request, result):\n        \"\"\"\n        Process the Accept header rules for the request.  Both the\n        desired API version and content type can be determined from\n        those rules.\n\n        :param request: The Request object provided by WebOb.\n        :param result: The Result object to store the results in.\n        \"\"\"\n\n        if result:\n            # Result has already been fully determined\n            return\n\n        try:\n            accept = request.headers['accept']\n        except KeyError:\n            # No Accept header to examine\n            return\n\n        # Obtain the best-match content type and its parameters\n        ctype, params = best_match(accept, self.types.keys())\n\n        # Is it a recognized content type?\n        if ctype not in self.types:\n            return\n\n        # Get the mapped ctype and version\n        mapped_ctype, mapped_version = self.types[ctype](params)\n\n        # Set the content type and version\n        if mapped_ctype:\n            result.set_ctype(mapped_ctype, ctype)\n        if mapped_version:\n            result.set_version(mapped_version)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_available_hashes():\n    if sys.version_info >= (3,2):\n        return hashlib.algorithms_available\n    elif sys.version_info >= (2,7) and sys.version_info < (3,0):\n        return hashlib.algorithms\n    else:\n        return 'md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512'", "response": "Returns a tuple of the available hashes for the current version of the system"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_defaults_for(session, user, only_for=None, detail_values=None):\n\n    detail_values = detail_values or {}\n\n    if not user.openid.endswith('.fedoraproject.org'):\n        log.warn(\"New user not from fedoraproject.org.  No defaults set.\")\n        return\n\n    # the openid is of the form USERNAME.id.fedoraproject.org\n    nick = user.openid.split('.')[0]\n\n    # TODO -- make the root here configurable.\n    valid_paths = fmn.lib.load_rules(root='fmn.rules')\n\n    def rule_maker(path, **kw):\n        \"\"\" Shorthand function, used inside loops below. \"\"\"\n        return fmn.lib.models.Rule.create_from_code_path(\n            session, valid_paths, path, **kw)\n\n    def contexts():\n        names = ['email', 'irc', 'sse']\n        if only_for:\n            names = [only_for.name]\n\n        for name in names:\n            context = fmn.lib.models.Context.get(session, name)\n            if context:\n                yield context\n            else:\n                log.warn(\"No such context %r is in the DB.\" % name)\n\n    # For each context, build one little and two big filters\n    for context in contexts():\n        pref = fmn.lib.models.Preference.load(session, user, context)\n        if not pref:\n            value = detail_values.get(context.name)\n            pref = fmn.lib.models.Preference.create(\n                session, user, context, detail_value=value)\n\n        # Add a filter that looks for packages of this user\n        filt = fmn.lib.models.Filter.create(\n            session, \"Events on packages that I own\")\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:user_package_filter\", fasnick=nick)\n\n        # If this is a message about a package of mine, **and** i'm responsible\n        # for it, then don't trigger this filter.  Rely on the previous one.\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:user_filter\",\n                      fasnick=nick,\n                      negated=True)\n\n        # Right off the bat, ignore all messages from non-primary kojis.\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:koji_instance\",\n                      instance=\"ppc,s390,arm\",\n                      negated=True)\n\n        # And furthermore, exclude lots of message types\n        for code_path in exclusion_packages + exclusion_mutual:\n            filt.add_rule(\n                session, valid_paths, \"fmn.rules:%s\" % code_path, negated=True)\n\n        pref.add_filter(session, filt, notify=True)\n        # END \"packages I own\"\n\n        # Add a filter that looks for this user\n        filt = fmn.lib.models.Filter.create(\n            session, \"Events referring to my username\")\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:user_filter\", fasnick=nick)\n\n        # Right off the bat, ignore all messages from non-primary kojis.\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:koji_instance\",\n                      instance=\"ppc,s390,arm\",\n                      negated=True)\n\n        # And furthermore exclude lots of message types\n        for code_path in exclusion_username + exclusion_mutual:\n            filt.add_rule(\n                session, valid_paths, \"fmn.rules:%s\" % code_path, negated=True)\n\n        pref.add_filter(session, filt, notify=True)\n        # END \"events references my username\"\n\n        # Add a taskotron filter\n        filt = fmn.lib.models.Filter.create(\n            session, \"Critical taskotron tasks on my packages\")\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:user_package_filter\",\n                      fasnick=nick)\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:taskotron_release_critical_task\")\n        filt.add_rule(session, valid_paths,\n                      \"fmn.rules:taskotron_task_particular_or_changed_outcome\",\n                      outcome='FAILED')\n        pref.add_filter(session, filt, notify=True)", "response": "Create a sizable amount of defaults for a new user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses the same ordering as TreeManager", "response": "def get_queryset(self):  # DROP_WITH_DJANGO15\n        \"\"\"Use the same ordering as TreeManager\"\"\"\n\n        args = (self.model._mptt_meta.tree_id_attr,\n                self.model._mptt_meta.left_attr)\n        method = 'get_query_set' if django.VERSION < (1, 6) else 'get_queryset'\n        return getattr(super(SectionManager, self), method)().order_by(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef item_related_name(self):\n        if not hasattr(self, '_item_related_name'):\n            many_to_many_rels = \\\n                get_section_many_to_many_relations(self.__class__)\n            if len(many_to_many_rels) != 1:\n                self._item_related_name = None\n            else:\n                self._item_related_name = many_to_many_rels[0].field.name\n        return self._item_related_name", "response": "Returns the name of the ManyToMany field on the item class pointing to this class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_item(self, item, field_name=None):\n        field_name = self._choose_field_name(field_name)\n        related_manager = getattr(item, field_name)\n        related_manager.add(self)", "response": "Add the item to the specified section."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_item(self, item, field_name=None):\n        field_name = self._choose_field_name(field_name)\n        related_manager = getattr(item, field_name)\n        related_manager.remove(self)", "response": "Removes the item from the specified section."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntoggle the section based on test_func.", "response": "def toggle_item(self, item, test_func, field_name=None):\n        \"\"\"\n        Toggles the section based on test_func.\n\n        test_func takes an item and returns a boolean. If it returns True, the\n        item will be added to the given section. It will be removed from the\n        section otherwise.\n\n        Intended for use with items of settings.ARMSTRONG_SECTION_ITEM_MODEL.\n        Behavior on other items is undefined.\n        \"\"\"\n        if test_func(item):\n            self.add_item(item, field_name)\n            return True\n        else:\n            self.remove_item(item, field_name)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef title(self, title=None):\n\n        if title is None:\n            return self._title\n        else:\n            if not isinstance(title, str):\n                raise TypeError(\"title must be str, not '%s'\" % str(title))\n            self._title = title", "response": "Returns or sets the chart s title."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef width(self, width=None):\n\n        if width is None:\n            return self._width\n        else:\n            if not is_numeric(width):\n                raise TypeError(\"width must be numeric, not '%s'\" % str(width))\n            self._width = width", "response": "Returns or sets the chart s width."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn or sets the chart s height.", "response": "def height(self, height=None):\n        \"\"\"Returns or sets (if a value is provided) the chart's height.\n\n        :param height: If given, the chart's height will be set to this.\"\"\"\n\n        if height is None:\n            return self._height\n        else:\n            if not is_numeric(height):\n                raise TypeError(\"height must be numeric, not '%s'\" % str(height))\n            self._height = height"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self):\n\n        canvas = Canvas(self.width(), self.height())\n        canvas.add_text(\n         self.width() / 2, 0, self.title(),\n         vertical_align=\"bottom\", name=\"title\"\n        )\n        return canvas", "response": "Renders the chart to an OmniCanvas canvas."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a Series to the chart.", "response": "def add_series(self, series):\n        \"\"\"Adds a :py:class:`.Series` to the chart.\n\n        :param Series series: The :py:class:`.Series` to add.\"\"\"\n\n        if not isinstance(series, Series):\n            raise TypeError(\"'%s' is not a Series\" % str(series))\n        self._all_series.append(series)\n        series._chart = self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_series(self, series):\n\n        if len(self.all_series()) == 1:\n            raise ValueError(\"Cannot remove last series from %s\" % str(self))\n        self._all_series.remove(series)\n        series._chart = None", "response": "Removes a series from the chart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef line(self, *args, **kwargs):\n\n        if \"color\" not in kwargs:\n            kwargs[\"color\"] = self.next_color()\n        series = LineSeries(*args, **kwargs)\n        self.add_series(series)", "response": "Adds a line series to the chart."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scatter(self, *args, **kwargs):\n\n        if \"color\" not in kwargs:\n            kwargs[\"color\"] = self.next_color()\n        series = ScatterSeries(*args, **kwargs)\n        self.add_series(series)", "response": "Adds a scatter series to the chart."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first series with the given name or None if no such series exists.", "response": "def get_series_by_name(self, name):\n        \"\"\"Returns the first :py:class:`.Series` of a given name, or ``None``.\n\n        :param str name: The name to search by.\"\"\"\n\n        if not isinstance(name, str):\n            raise TypeError(\n             \"Can only search series by str name, not '%s'\" % str(name)\n            )\n        for series in self.all_series():\n            if series.name() == name:\n                return series"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef x_label(self, x_label=None):\n\n        if x_label is None:\n            return self._x_label\n        else:\n            if not isinstance(x_label, str):\n                raise TypeError(\"x_label must be str, not '%s'\" % str(x_label))\n            self._x_label = x_label", "response": "Returns or sets the chart s x - axis label."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef y_label(self, y_label=None):\n\n        if y_label is None:\n            return self._y_label\n        else:\n            if not isinstance(y_label, str):\n                raise TypeError(\"y_label must be str, not '%s'\" % str(y_label))\n            self._y_label = y_label", "response": "Returns or sets the chart s y - axis label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn or sets the chart s horizontal_padding \\ n.", "response": "def horizontal_padding(self, padding=None):\n        \"\"\"Returns or sets (if a value is provided) the chart's horizontal\n        padding. This determines how much space will be on either side of the\n        display area, as a proportion of overall width, and should be a value\n        between 0 and 0.5\n\n        :param float padding: If given, the chart's horizontal_padding\\\n        will be set to this.\n        :raises ValueError: if a value outside of 0 < n < 0.5 is given.\n        :rtype: float\"\"\"\n\n        if padding is None:\n            return self._horizontal_padding\n        else:\n            if not isinstance(padding, float):\n                raise TypeError(\"padding must be float, not '%s'\" % str(padding))\n            if not 0 < padding < 0.5:\n                raise ValueError(\n                 \"padding must be between 0 and 0.5 (not inclusive), not '%s'\" % str(padding)\n                )\n            self._horizontal_padding = padding"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vertical_padding(self, padding=None):\n\n        if padding is None:\n            return self._vertical_padding\n        else:\n            if not isinstance(padding, float):\n                raise TypeError(\"padding must be float, not '%s'\" % str(padding))\n            if not 0 < padding < 0.5:\n                raise ValueError(\n                 \"padding must be between 0 and 0.5 (not inclusive), not '%s'\" % str(padding)\n                )\n            self._vertical_padding = padding", "response": "Returns or sets the chart s vertical_padding \\ n."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns or sets the lower limit of the x - axis of the current object.", "response": "def x_lower_limit(self, limit=None):\n        \"\"\"Returns or sets (if a value is provided) the value at which the\n        x-axis should start. By default this is zero (unless there are negative\n        values).\n\n        :param limit: If given, the chart's x_lower_limit will be set to this.\n        :raises ValueError: if you try to make the lower limit larger than the\\\n        upper limit.\"\"\"\n\n        if limit is None:\n            if self._x_lower_limit is None:\n                if self.smallest_x() < 0:\n                    if self.smallest_x() == self.largest_x():\n                        return int(self.smallest_x() - 1)\n                    else:\n                        return self.smallest_x()\n                else:\n                    return 0\n            else:\n                return self._x_lower_limit\n        else:\n            if not is_numeric(limit):\n                raise TypeError(\n                 \"lower x limit must be numeric, not '%s'\" % str(limit)\n                )\n            if limit >= self.largest_x():\n                raise ValueError(\n                 \"lower x limit must be less than upper limit (%s), not %s\" % (\n                  str(self.largest_x()), str(limit)\n                 )\n                )\n            self._x_lower_limit = limit"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef y_lower_limit(self, limit=None):\n\n        if limit is None:\n            if self._y_lower_limit is None:\n                if self.smallest_y() < 0:\n                    if self.smallest_y() == self.largest_y():\n                        return int(self.smallest_y() - 1)\n                    else:\n                        return self.smallest_y()\n                else:\n                    return 0\n            else:\n                return self._y_lower_limit\n        else:\n            if not is_numeric(limit):\n                raise TypeError(\n                 \"lower y limit must be numeric, not '%s'\" % str(limit)\n                )\n            if limit >= self.largest_y():\n                raise ValueError(\n                 \"lower y limit must be less than upper limit (%s), not %s\" % (\n                  str(self.largest_y()), str(limit)\n                 )\n                )\n            self._y_lower_limit = limit", "response": "Returns or sets the y - axis lower limit for the given base - level theCOOKIE is at. By default this is 0. If no limit is given the chart s y_lower_limit will be set to the largest y - axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef x_ticks(self, *ticks):\n\n        if ticks:\n            for tick in ticks:\n                if not is_numeric(tick):\n                    raise TypeError(\"'%s' is not a numeric tick\" % str(tick))\n            self._x_ticks = tuple(sorted(ticks))\n        else:\n            if self._x_ticks:\n                return self._x_ticks\n            else:\n                return determine_ticks(self.x_lower_limit(), self.x_upper_limit())", "response": "Returns the x - axis ticks for the given set of ticks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef y_ticks(self, *ticks):\n\n        if ticks:\n            for tick in ticks:\n                if not is_numeric(tick):\n                    raise TypeError(\"'%s' is not a numeric tick\" % str(tick))\n            self._y_ticks = tuple(sorted(ticks))\n        else:\n            if self._y_ticks:\n                return self._y_ticks\n            else:\n                return determine_ticks(self.y_lower_limit(), self.y_upper_limit())", "response": "Returns the y - axis ticks for which there are markers and grid lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the gridlines on or off for the x - ticks.", "response": "def x_grid(self, grid=None):\n        \"\"\"The horizontal lines that run accross the chart from the x-ticks.\n\n        If a boolean value is given, these gridlines will be turned on or off.\n        Otherwise, the method will return their current state.\n\n        :param bool grid: Turns the gridlines on or off.\n        :rtype: ``bool``\"\"\"\n\n        if grid is None:\n            return self._x_grid\n        else:\n            if not isinstance(grid, bool):\n                raise TypeError(\"grid must be boolean, not '%s'\" % grid)\n            self._x_grid = grid"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the vertical lines that run accross the chart from the y - ticks.", "response": "def y_grid(self, grid=None):\n        \"\"\"The vertical lines that run accross the chart from the y-ticks.\n\n        If a boolean value is given, these gridlines will be turned on or off.\n        Otherwise, the method will return their current state.\n\n        :param bool grid: Turns the gridlines on or off.\n        :rtype: ``bool``\"\"\"\n\n        if grid is None:\n            return self._y_grid\n        else:\n            if not isinstance(grid, bool):\n                raise TypeError(\"grid must be boolean, not '%s'\" % grid)\n            self._y_grid = grid"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef grid(self, grid):\n\n        if not isinstance(grid, bool):\n            raise TypeError(\"grid must be boolean, not '%s'\" % grid)\n        self._x_grid = self._y_grid = grid", "response": "Turns all gridlines on or off"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self):\n\n        canvas = Chart.create(self)\n\n        for index, series in enumerate(self.all_series(), start=1):\n            series.write_to_canvas(canvas, \"series%i\" % index)\n        canvas.add_rectangle(\n         0, 0, self.horizontal_padding() * canvas.width(), canvas.height(),\n         opacity=1,\n         line_width=0,\n         name=\"block-w\"\n        )\n        canvas.add_rectangle(\n         0, 0, canvas.width(), self.vertical_padding() * canvas.height(),\n         opacity=1,\n         line_width=0,\n         name=\"block-n\"\n        )\n        canvas.add_rectangle(\n         canvas.width() - (self.horizontal_padding() * canvas.width()), 0,\n         self.horizontal_padding() * canvas.width(), canvas.height(),\n         opacity=1,\n         line_width=0,\n         name=\"block-e\"\n        )\n        canvas.add_rectangle(\n         0, canvas.height() - (self.vertical_padding() * canvas.height()),\n         canvas.width(), self.vertical_padding() * canvas.height(),\n         opacity=1,\n         line_width=0,\n         name=\"block-s\"\n        )\n        title = canvas.graphics()[0]\n        while canvas.graphics().index(title) != len(canvas.graphics()) - 1:\n            canvas.move_graphic_forward(title)\n        canvas.graphics()[-1].y(self.vertical_padding() * canvas.height() * 0.5)\n        canvas.graphics()[-1].vertical_align(\"center\")\n\n        axes = canvas.add_rectangle(\n         self.horizontal_padding() * canvas.width(),\n         self.vertical_padding() * canvas.height(),\n         canvas.width() - (2 * self.horizontal_padding() * canvas.width()),\n         canvas.height() - (2 * self.vertical_padding() * canvas.height()),\n         name=\"axes\",\n         opacity=0\n        )\n\n        if self.x_label():\n            canvas.add_text(\n             canvas.width() / 2,\n             canvas.height() - (self.vertical_padding() * canvas.height() * 0.25),\n             self.x_label(),\n             name=\"x_label\"\n            )\n        y_label_x = self.horizontal_padding() * canvas.width() * 0.25\n        if self.y_label():\n            canvas.add_text(\n             y_label_x,\n             canvas.height() * 0.5,\n             self.y_label(),\n             rotation=(y_label_x, canvas.height() * 0.5, 270),\n             name=\"y_label\"\n            )\n        x_tick_series = Series(*[(tick, 0) for tick in self.x_ticks()])\n        x_tick_series._chart = self\n        x_tick_points = x_tick_series.canvas_points()\n        for index, tick in enumerate(x_tick_series.data()):\n            canvas.add_text(\n             x_tick_points[index][0],\n             canvas.height() - (self.vertical_padding() * canvas.height() * 0.75),\n             str(tick[0]),\n             name=\"xtick\"\n            )\n            if self.x_grid():\n                line = canvas.add_line(\n                 x_tick_points[index][0], canvas.height() * (1 - self.vertical_padding()),\n                 x_tick_points[index][0], canvas.height() * self.vertical_padding(),\n                 line_style=\"..\",\n                 line_color=\"#333333\",\n                 name=\"xgrid\"\n                )\n                while canvas.graphics()[0] is not line:\n                    canvas.move_graphic_backward(line)\n        y_tick_series = Series(*[(0, tick) for tick in self.y_ticks()])\n        y_tick_series._chart = self\n        y_tick_points = y_tick_series.canvas_points()\n        for index, tick in enumerate(y_tick_series.data()):\n            canvas.add_text(\n             self.horizontal_padding() * canvas.width() * 0.75,\n             y_tick_points[index][1],\n             str(tick[1]),\n             name=\"ytick\"\n            )\n            if self.y_grid():\n                line = canvas.add_line(\n                 canvas.width() * self.horizontal_padding(), y_tick_points[index][1],\n                 canvas.width() * (1 - self.horizontal_padding()), y_tick_points[index][1],\n                 line_style=\"..\",\n                 line_color=\"#333333\",\n                 name=\"ygrid\"\n                )\n                while canvas.graphics()[0] is not line:\n                    canvas.move_graphic_backward(line)\n        return canvas", "response": "Renders the chart to an OmniCanvas canvas. This object can then be saved or rendered as SVG."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the event loop.", "response": "def get_event_loop(self):\n        \"\"\"Get the event loop.\n\n        This may be None or an instance of EventLoop.\n        \"\"\"\n        if (self._event_loop is None and\n            threading.current_thread().name == 'MainThread'):\n            self._event_loop = self.new_event_loop()\n        return self._event_loop"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_event_loop(self, event_loop):\n        assert event_loop is None or isinstance(event_loop, AbstractEventLoop)\n        self._event_loop = event_loop", "response": "Set the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iiOfAny(instance, classes):\n    if type(classes) not in [list, tuple]:\n        classes = [classes]\n\n    return any(map(lambda x: type(instance).__name__ == x.__name__, classes))", "response": "Returns true if instance is instance of any of the classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reactToAMQPMessage(req, send_back):\n    if not _iiOfAny(req, REQUEST_TYPES):\n        raise ValueError(\n            \"Unknown type of request: '\" + str(type(req)) + \"'!\"\n        )\n\n    if _iiOfAny(req, CountRequest) and _iiOfAny(req.query, QUERY_TYPES):\n        return req.query.getCountResult()\n\n    elif _iiOfAny(req, SearchRequest) and _iiOfAny(req.query, QUERY_TYPES):\n        return req.query.getSearchResult()\n\n    elif _iiOfAny(req, ISBNValidationRequest):\n        ISBN = req.ISBN\n\n        if _iiOfAny(ISBN, ISBNQuery):\n            ISBN = ISBN.ISBN\n\n        return ISBNValidationResult(isbn_validator.is_valid_isbn(ISBN))\n\n    elif _iiOfAny(req, ExportRequest):\n        export.exportEPublication(req.epublication)\n        return ExportResult(req.epublication.ISBN)\n\n    raise ValueError(\n        \"Unknown type of request: '\" + str(type(req)) + \"' or query: '\" +\n        str(type(req.query)) + \"'!\"\n    )", "response": "React to given AMQP message."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getSearchResult(self):\n        xml = aleph.downloadMARCOAI(self.doc_id, self.library)\n\n        return SearchResult([\n            AlephRecord(\n                None,\n                self.library,\n                self.doc_id,\n                xml\n            )\n        ])", "response": "Returns a SearchResult object with the given doc_id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmonkey patching for original Datasette.", "response": "def patch_datasette():\n    \"\"\"\n    Monkey patching for original Datasette\n    \"\"\"\n\n    def inspect(self):\n        \" Inspect the database and return a dictionary of table metadata \"\n        if self._inspect:\n            return self._inspect\n\n        _inspect = {}\n        files = self.files\n\n        for filename in files:\n            self.files = (filename,)\n            path = Path(filename)\n            name = path.stem\n            if name in _inspect:\n                raise Exception(\"Multiple files with the same stem %s\" % name)\n            try:\n                _inspect[name] = self.original_inspect()[name]\n            except sqlite3.DatabaseError:\n                tables, views, dbtype = connectors.inspect(path)\n                _inspect[name] = {\n                    \"hash\": inspect_hash(path),\n                    \"file\": str(path),\n                    \"dbtype\": dbtype,\n                    \"tables\": tables,\n                    \"views\": views,\n                }\n\n        self.files = files\n        self._inspect = _inspect\n        return self._inspect\n\n    datasette.app.Datasette.original_inspect = datasette.app.Datasette.inspect\n    datasette.app.Datasette.inspect = inspect\n\n\n    async def execute(self, db_name, sql, params=None, truncate=False, custom_time_limit=None, page_size=None):\n        \"\"\"Executes sql against db_name in a thread\"\"\"\n        page_size = page_size or self.page_size\n\n        def is_sqlite3_conn():\n            conn = getattr(connections, db_name, None)\n            if not conn:\n                info = self.inspect()[db_name]\n                return info.get('dbtype', 'sqlite3') == 'sqlite3'\n            else:\n                return isinstance(conn, sqlite3.Connection)\n\n        def sql_operation_in_thread():\n            conn = getattr(connections, db_name, None)\n            if not conn:\n                info = self.inspect()[db_name]\n                conn = connectors.connect(info['file'], info['dbtype'])\n                setattr(connections, db_name, conn)\n\n            rows, truncated, description = conn.execute(\n                sql,\n                params or {},\n                truncate=truncate,\n                page_size=page_size,\n                max_returned_rows=self.max_returned_rows,\n            )\n            return Results(rows, truncated, description)\n\n        if is_sqlite3_conn():\n            return await self.original_execute(db_name, sql, params=params, truncate=truncate, custom_time_limit=custom_time_limit, page_size=page_size)\n        else:\n            return await asyncio.get_event_loop().run_in_executor(\n                self.executor, sql_operation_in_thread\n            )\n\n    datasette.app.Datasette.original_execute = datasette.app.Datasette.execute\n    datasette.app.Datasette.execute = execute"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bench(host, port, uri, method, headers, body, verbocity, http_version, protocol):\n    t1 = time.time()\n    s = create_connction(host, port, protocol)\n    t2 = time.time()\n\n    msg = \"%s %s HTTP/%s\\r\\n\" % (method, uri, http_version)\n    if body:\n        body='%s\\r\\n' % body\n        msg += \"Content-length: %s\\r\\n\" % len(body)\n    msg += headers\n    msg += \"\\r\\n\"\n    msg += \"\\r\\n\"\n    msg += body\n    if verbocity:\n        print msg\n    res = ''\n    t3 = time.time()\n    data = communicate(s, msg)\n    if verbocity:\n        if 'gzip' in data:\n            data = data.split(\"\\r\\n\\r\\n\", 1)\n            print data[0]\n            print\n            print data[1]\n        else:\n            print data\n    t4 = time.time()\n    res += \"%s,%s,ms,%s,ms,%s,ms\\n\" % (host, round((t4 - t1) * 1000.0, 3),\n                                       round((t2 - t1) * 1000.0, 3),\n                                       round((t4 - t3) * 1000.0, 3))\n    s.close()\n    return res", "response": "The benchmark method\n    :param host str: - host to run tests agains\n    :param port int: - port to connect\n    :param uri str: - URI to send in message\n    :param method str: - http method\n    :param headers str: - formatted headers for message\n    :param body str: - body of message\n    :param verbocity int [0-1]: - print extended output option\n    :param http_version str: - represetation of http protocol\n    :return\n        [list] results of benchmark:"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_connction(host, port, protocol):\n    ai_list = socket.getaddrinfo(host, port, socket.AF_UNSPEC,\n                                 socket.SOCK_STREAM)\n    for (family, socktype, proto, canon, sockaddr) in ai_list:\n        sock = socket.socket(family, socktype)\n        # WRAP SOCKET\n        if port == 443:\n            sock = ssl.wrap_socket(sock, ssl_version=protocol)\n        sock.connect(sockaddr)\n        return sock", "response": "Create a connection to a socket host and port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    parser = argparse.ArgumentParser(description='webBench is an alternative to ab in python')\n\n    parser.add_argument('-n', dest='requests', type=int,\n                        help='Number of requests to perform')\n    parser.add_argument('-c', dest='concurrency', type=int,\n                        help='Number of multiple requests to make at a time')\n    parser.add_argument('-d', dest='strbody', type=str, default='',\n                        help='String post body')\n    parser.add_argument('-p', dest='postfile', type=str, default='',\n                        help='File containing data to POST')\n    parser.add_argument('-u', dest='putfile', type=str, default='',\n                        help='File containing data to PUT')\n    parser.add_argument('-v', dest='verbosity', type=int, default=0,\n                        help='How much troubleshooting info to print')\n    parser.add_argument('-H', dest='header', action='append', default=[],\n                        help='Add Arbitrary header line, eg. \"Accept-Encoding: gzip\"\\n'\n                             'Inserted after all normal header lines. (repeatable)')\n    parser.add_argument('-e', dest='csv', type=str, default='',\n                        help='Output CSV file with percentages served')\n    parser.add_argument('-m', dest='method', type=str, default='GET',\n                        help='Method name')\n    parser.add_argument('-Z', dest='ciphersuite', type=str, default='',\n                        help='Specify SSL/TLS cipher suite (See openssl ciphers)')\n    parser.add_argument('-t', dest='http_version', default='1.1',\n                        help='Speofy HTTP versions (1.0, 1.1)')\n    parser.add_argument('-f', dest='protocol', default='SSLv23',\n                        help='Specify SSL/TLS protocol (SSLv23, SSLv2, SSLv3, TLSv1)')\n    parser.add_argument('url', metavar=\"URL\", type=str, help='URL of request')\n\n    # args = parser.parse_args([\"-c\", \"1\", \"-n\", \"1\", \"-v\", \"1\", \"-H\",\n    #                           \"Content-Type: application/x-www-form-urlencoded;charset=utf-8\",\n    #                           \"-H\", \"Host: upl.pa.dev\",\n    #                           \"-H\", \"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) \"\n    #                                 \"Gecko/20100101 Firefox/47.0\",\n    #                           \"-H\", \"Accept: application/json, text/plain, */*'\",\n    #                           \"-H 'Accept-Language: en-US,en;q=0.5\",\n    #                           \"-H\", \"Accept-Encoding: gzip, deflate, br\",\n    #                           \"-H\", \"X-XSRF-TOKEN: f005bad9fcec4dec745917b37b8495154f8eed0ed4fa220f3df3be79\"\n    #                                 \"b457a33c1f76696b6e33488d67cfa29d375d65c00813ca8b4c53cf39a3e7225d64610de7\",\n    #                           \"-H\", \"Referer: https://upl.pa.dev/\",\n    #                           \"-H\", \"Cookie: PHPSESSID=inhevvko89k92ls80skc7ii3h6; \"\n    #                                 \"idpSAMLSessionID=e8342db3073f8320f5a4089a9adc6cf6; \"\n    #                                 \"idpSAMLAuthToken=_b2a7d9935241b6b8862e2e393b26cc4d304e64c0b9; \"\n    #                                 \"spSAMLSessionID=870b591c8ff5ffde5b1a3dc7bc981c1a; \"\n    #                                 \"spSAMLAuthToken=_70f436ee6e64911a7fa6d03d0e3faa57b2d822b4c6; \"\n    #                                 \"XSRF-TOKEN=f005bad9fcec4dec745917b37b8495154f8eed0ed4fa220f3d\"\n    #                                 \"f3be79b457a33c1f76696b6e33488d67cfa29d375d65c00813ca8b4c53cf39a3\"\n    #                                 \"e7225d64610de7; \"\n    #                                 \"web_token=29380664226a1933f9c33684f5c81b5267cab4fcfb84ea44603d8d9b7\"\n    #                                 \"8529b7d22fc47c7011a7abf69358ff1a7dcc63c924513ab71eb22381689864fb1724292\",\n    #                           \"-H\", \"Connection: keep-alive\",\n    #                           \"-p\", \"/tmp/test.body\", \"https://upl.pa.dev/webapi/workspacefile/getProperties\"])\n    args = parser.parse_args()\n\n    if args.requests < args.concurrency:\n        print \"Requests should be bigger then concurrency\"\n        sys.exit(1)\n\n    protocols = {\n        'SSLv23': ssl.PROTOCOL_SSLv23,\n        'SSLv2': ssl.PROTOCOL_SSLv2,\n        'SSLv3': ssl.PROTOCOL_SSLv3,\n        'TLSv1': ssl.PROTOCOL_TLSv1\n    }\n\n    arguments = []\n    method = args.method\n    port = 443 if 'https' in args.url else 80\n    host = args.url[args.url.index(\"://\") + 3:]\n    uri = '/'\n    body = ''\n    headers = '\\r\\n'.join(args.header) if args.header else []\n    if '/' in host:\n        uri = '%s' % host[host.index(\"/\"):]\n        host = host[:host.index(\"/\")]\n    if args.strbody:\n        body = args.strbody\n        method = 'POST'\n    if args.postfile:\n        with open(args.postfile, 'r') as f:\n            body = f.read().strip()\n        method = 'POST'\n    elif args.putfile:\n        with open(args.putfile, 'r') as f:\n            body = f.read().strip()\n        method = 'PUT'\n    protocol = ssl.PROTOCOL_SSLv23 if args.protocol not in protocols else protocols[args.protocol]\n    print \"Starting benchmark for:\"\n    print \"%s %s %s\" % (method, args.url, args.http_version)\n    if args.verbosity:\n        if headers:\n            print \" Headers: \\n%s\" % headers\n            print\n        if body:\n            print \"Body: \\n%s\" % body\n    print\n    p = Pool(args.concurrency)\n    for each in range(args.requests):\n        arguments.append(dict(host=host, port=port, uri=uri, headers=headers,\n                              verbocity=True if args.verbosity else False,\n                              body=body, method=method, http_version=args.http_version,\n                              protocol=protocol))\n    print \"Staring test ... \"\n    result = []\n    start = time.time()\n    for each in p.imap_unordered(bench_wrapper, arguments):\n        result.append(each)\n        if start + 1 < time.time():\n            start = time.time()\n            print \"Remaining %s requests ... \" % (args.requests - len(result))\n    if args.csv:\n        with open(args.csv, 'w') as f:\n            f.write(\"\".join(result))\n    print\n    print\n    if args.verbosity:\n        print \"\".join(result)\n        print\n        print\n    req_time = []\n    connection_time = []\n    processing_time = []\n    for each in result:\n        if ',' in each:\n            tmp_res = each.split(',')\n            req_time.append(float(tmp_res[1]))\n            connection_time.append(float(tmp_res[3]))\n            processing_time.append(float(tmp_res[5]))\n\n    print 'Summary:'\n    print 'Failed Requests: %s ' % (args.requests - len(req_time))\n    print\n    print \"Percentile\\tConnection,ms\\tProcessing,ms\\tTotal,ms\"\n    some_chart = sorted(req_time)\n    le = len(some_chart)\n    for per in [0.5, 0.66, 0.75, 0.80, 0.90, 0.95, 0.98, 0.99]:\n        value = some_chart[int(per*float(le))]\n        index = req_time.index(value)\n        print \"%s %%\\t\\t%s\\t\\t%s\\t\\t%s\" % (per*100, connection_time[index], processing_time[index], req_time[index])\n    print \"%s %%\\t\\t%s\\t\\t%s\\t\\t%s\" % (100, max(connection_time), max(processing_time), max(req_time))\n    print", "response": "Mein methos of pybench executor"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a fedora. client. fas2. AccountSystem object if the provided configuration contains a FAS username and password.", "response": "def get_fas(config):\n    \"\"\" Return a fedora.client.fas2.AccountSystem object if the provided\n    configuration contains a FAS username and password.\n    \"\"\"\n    global _FAS\n    if _FAS is not None:\n        return _FAS\n\n    # In some development environments, having fas_credentials around is a\n    # pain.. so, let things proceed here, but emit a warning.\n    try:\n        creds = config['fas_credentials']\n    except KeyError:\n        log.warn(\"No fas_credentials available.  Unable to query FAS.\")\n        return None\n\n    default_url = 'https://admin.fedoraproject.org/accounts/'\n\n    _FAS = AccountSystem(\n        creds.get('base_url', default_url),\n        username=creds['username'],\n        password=creds['password'],\n        cache_session=False,\n        insecure=creds.get('insecure', False)\n    )\n\n    return _FAS"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the list of users who have commit on a package.", "response": "def get_packagers_of_package(config, package):\n    \"\"\" Retrieve the list of users who have commit on a package.\n\n    :arg config: a dict containing the fedmsg config\n    :arg package: the package you are interested in.\n    :return: a set listing all the fas usernames that have some ACL on package.\n    \"\"\"\n\n    if not _cache.is_configured:\n        _cache.configure(**config['fmn.rules.cache'])\n\n    key = cache_key_generator(get_packagers_of_package, package)\n    creator = lambda: _get_pkgdb2_packagers_for(config, package)\n    return _cache.get_or_create(key, creator)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_packages_of_user(config, username, flags):\n\n    if not _cache.is_configured:\n        _cache.configure(**config['fmn.rules.cache'])\n\n    packages = []\n\n    groups = get_groups_of_user(config, get_fas(config), username)\n    owners = [username] + ['group::' + group for group in groups]\n\n    for owner in owners:\n        key = cache_key_generator(get_packages_of_user, owner)\n        creator = lambda: _get_pkgdb2_packages_for(config, owner, flags)\n        subset = _cache.get_or_create(key, creator)\n        packages.extend(subset)\n\n    return set(packages)", "response": "Retrieve the list of packages where the specified user has some ACL."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the list of users in the specified group.", "response": "def get_user_of_group(config, fas, groupname):\n    ''' Return the list of users in the specified group.\n\n    :arg config: a dict containing the fedmsg config\n    :arg fas: a fedora.client.fas2.AccountSystem object instanciated and loged\n        into FAS.\n    :arg groupname: the name of the group for which we want to retrieve the\n        members.\n    :return: a list of FAS user members of the specified group.\n    '''\n\n    if not _cache.is_configured:\n        _cache.configure(**config['fmn.rules.cache'])\n\n    key = cache_key_generator(get_user_of_group, groupname)\n    def creator():\n        if not fas:\n            return set()\n        return set([u.username for u in fas.group_members(groupname)])\n    return _cache.get_or_create(key, creator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_groups_of_user(config, fas, username):\n    ''' Return the list of (pkgdb) groups to which the user belongs.\n\n    :arg config: a dict containing the fedmsg config\n    :arg fas: a fedora.client.fas2.AccountSystem object instanciated and loged\n        into FAS.\n    :arg username: the name of a user for which we want to retrieve groups\n    :return: a list of FAS groups to which the user belongs.\n    '''\n\n    if not _cache.is_configured:\n        _cache.configure(**config['fmn.rules.cache'])\n\n    key = cache_key_generator(get_groups_of_user, username)\n\n    def creator():\n        if not fas:\n            return []\n        results = []\n        for group in fas.person_by_username(username).get('memberships', []):\n            if group['group_type'] == 'pkgdb':\n                results.append(group.name)\n        return results\n\n    return _cache.get_or_create(key, creator)", "response": "Return the list of groups to which the user belongs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of usernames for a given message.", "response": "def msg2usernames(msg, **config):\n    ''' Return cached fedmsg.meta.msg2usernames(...) '''\n\n    if not _cache.is_configured:\n        _cache.configure(**config['fmn.rules.cache'])\n\n    key = \"|\".join(['usernames', msg['msg_id']]).encode('utf-8')\n    creator = lambda: fedmsg.meta.msg2usernames(msg, **config)\n    return _cache.get_or_create(key, creator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delist(target):\n    ''' for any \"list\" found, replace with a single entry if the list has exactly one entry '''\n    result = target\n    if type(target) is dict:\n        for key in target:\n            target[key] = delist(target[key])\n    if type(target) is list:\n        if len(target)==0:\n            result = None\n        elif len(target)==1:\n            result = delist(target[0])\n        else:\n            result = [delist(e) for e in target]\n    return result", "response": "Removes any list found replace with a single entry if the list has exactly one entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value_output(value, quote_method='all', none_handle='strict'):\n    '''\n    Format types:\n    'all'.\n       (default) everything is embraced with quotes\n    'needed'.\n       Quote only if needed. Values are on placed in quotes if:\n       a. the value contains a quote\n       b. there is whitespace at the beginning or end of string\n    'none'.\n       Quote nothing.\n    '''\n    p = str(value)\n    if value is None:\n        if none_handle=='strict':\n            return \"\"\n        elif none_handle=='empty':\n            return ' \"\"'\n        elif none_handle=='None':\n            p = \"None\"\n        else:\n            raise \"none handler \"+str(none_handle)+\" not recognized\"\n    if quote_method=='all':\n        return ' \"'+p+'\"'\n    elif quote_method=='by_need':\n        if len(p)!=len(p.strip()):\n            return ' \"'+p+'\"'\n        if '\"' in p:\n            return ' \"'+p+'\"'\n        return \" \"+p\n    elif quote_method=='none':\n        return \" \"+p\n    else:\n        raise \"quote method \"+str(quote_method)+\" not recognized\"\n    return", "response": "Return a string representation of the value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef schema_rolne_check(doc, schema):\n    '''\n    CHECK THE DOCUMENT AGAINST IT'S SCHEMA\n    \n    returns: cleaned-up-document, error_list\n    '''\n    import standard_types as st\n    error_list = []\n    #\n    # PASS ONE: FORWARD CHECK OF DOC\n    #\n    # this pass verifies that each entry in the document\n    # has a corresponding entry in the schema\n    #\n    exclusive_flag = True\n    if schema.list_names(\"#!MARDS_schema_en_1.0\"):\n        if schema[\"#!MARDS_schema_en_1.0\"].get_value(\"exclusive\")==\"false\":\n            exclusive_flag = False\n    if exclusive_flag:\n        # print \"jj\", schema\n        el = check_schema_coverage(doc, schema)\n        error_list.extend(el)\n    #\n    # PASS TWO: REQUIREMENTS CHECK OF SCHEMA\n    #\n    # this pass verifies that any 'required' entries in the\n    # schema are met. It auto-inserts if allowed. Otherwise,\n    # it adds an error.\n    el = sub_schema_requirements(doc, schema)\n    error_list.extend(el)\n    #\n    # PASS THREE: TREATMENT CHECKS\n    #\n    el = sub_schema_treatments(doc, schema)\n    error_list.extend(el)\n    #\n    # PASS FOUR: TYPE CHECKS AND NORMALIZATION\n    #\n    el = st.apply_schema_types(doc, schema)\n    error_list.extend(el)\n    #\n    #\n    # PASS FIVE: RAISE_ERROR CHECKS\n    #\n    el = sub_schema_raises(doc, schema)\n    error_list.extend(el)\n    #\n    return doc, error_list", "response": "This function checks that the given document is valid for the given schema and returns a cleaned - up - document and an error list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_schema_coverage(doc, schema):\n    '''\n    FORWARD CHECK OF DOCUMENT\n    \n    This routine looks at each element in the doc, and makes sure there\n    is a matching 'name' in the schema at that level.\n    '''\n    error_list = []\n    to_delete = []\n    for entry in doc.list_tuples():\n        (name, value, index, seq) = entry\n        temp_schema = schema_match_up(doc, schema)\n        if not name in temp_schema.list_values(\"name\"):\n            error_list.append( (\"[error]\", \"doc\", seq, \"a name of '{}' not found in schema\".format(name)) )\n            to_delete.append(seq)\n        else:\n            # check subs\n            el = check_schema_coverage(doc[name, value, index], temp_schema[\"name\", name])\n            error_list.extend(el)\n    for seq in to_delete:\n        doc.seq_delete(seq)\n    return error_list", "response": "FORWARD CHECK OF DOCUMENT\n    \n    This routine checks that the given document contains a matching name in the schema at that level."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a doc and a schema return a copy that implements the match", "response": "def schema_match_up(doc, schema):\n    '''\n    SCHEMA mini-recompile for:\n\n      each SEARCH then MATCH function\n      each TYPE then CHOICE function\n    \n    given the doc, it returns a schema copy that implements the match\n    '''\n    copy = schema.copy(seq_prefix=\"\", seq_suffix=\"\")\n    copy = _schema_match_up_search(doc, copy)\n    copy = _schema_match_up_type_choice(doc, copy)\n    return copy"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all raise_error raise_warning and raise_log elements in a document.", "response": "def sub_schema_raises(doc, schema):\n    '''\n    Look for \"raise_error\", \"raise_warning\", and \"raise_log\"\n    \n    '''\n    error_list = []\n    temp_schema = schema_match_up(doc, schema)\n    for msg in temp_schema.list_values(\"raise_error\"):\n        error_list.append( (\"[error]\", \"doc\", doc.seq, \"'{}'\".format(msg)) )\n    for msg in temp_schema.list_values(\"raise_warning\"):\n        error_list.append( (\"[warning]\", \"doc\", doc.seq, \"'{}'\".format(msg)) )\n    for msg in temp_schema.list_values(\"raise_log\"):\n        error_list.append( (\"[log]\", \"doc\", doc.seq, \"'{}'\".format(msg)) )\n    for entry in doc:\n        if temp_schema.has((\"name\", entry.name)):\n            el = sub_schema_raises(entry, temp_schema[\"name\", entry.name])\n            error_list.extend(el)\n    return error_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a new time sample into the database with the given information.", "response": "def create(cls, file, module, cls_name, func, elapsed):\n        \"\"\"Inserts a new time sample into the database with the given information.\n        \n        :param file: The file the sample is from\n        :type file: str\n        :param module: The module the sample is from\n        :type module: str\n        :param cls_name: The name of the class the sample is from\n        :type cls_name: str\n        :param func: The name of the function the sample is from\n        :type func: str\n        :param elapsed: The elapsed time in seconds\n        :type elapsed: float\n        \n        \"\"\"\n        q = \"INSERT INTO {} VALUES('{}', '{}', '{}', '{}', {})\"\n        SqliteConnection.get().execute(q.format(cls.meta['table'],\n                                                file,\n                                                module,\n                                                cls_name,\n                                                func,\n                                                elapsed))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nindicating whether or not the given row contains valid data.", "response": "def is_valid_row(cls, row):\n        \"\"\"Indicates whether or not the given row contains valid data.\"\"\"\n        for k in row.keys():\n            if row[k] is None:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cursor(cls):\n        db = SqliteConnection.get()\n        db.row_factory = sqlite3.Row\n        return db.cursor()", "response": "Return a message list cursor that returns sqlite3. Row objects"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_slowest_files(cls, num=10):\n        cur = cls.get_cursor()\n        q = (\n            \"SELECT file, SUM(elapsed) as sum_elapsed FROM {} GROUP BY file\"\n            \" ORDER BY sum_elapsed DESC LIMIT {}\"\n        )\n        cur.execute(q.format(cls.meta['table'], num))\n        result = cur.fetchall()\n        # Don't return the weird invalid row if no tests were run\n        if not all([cls.is_valid_row(x) for x in result]):\n            return []\n        return result", "response": "Returns the slowest num files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the total time taken across all results.", "response": "def get_total_time(cls):\n        \"\"\"Returns the total time taken across all results.\n        \n        :rtype: float\n        \"\"\"\n        cur = cls.get_cursor()\n        q = \"SELECT SUM(elapsed) FROM {}\"\n        cur.execute(q.format(cls.meta['table']))\n        result = cur.fetchone()['SUM(elapsed)']\n        return result if result else 0.0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput the CREDO logo at the bottom right of the current figure.", "response": "def putlogo(figure=None):\n    \"\"\"Puts the CREDO logo at the bottom right of the current figure (or\n    the figure given by the ``figure`` argument if supplied).\n    \"\"\"\n    ip = get_ipython()\n    if figure is None:\n        figure=plt.gcf()\n    curraxis= figure.gca()\n    logoaxis = figure.add_axes([0.89, 0.01, 0.1, 0.1], anchor='NW')\n    logoaxis.set_axis_off()\n    logoaxis.xaxis.set_visible(False)\n    logoaxis.yaxis.set_visible(False)\n    logoaxis.imshow(credo_logo)\n    figure.subplots_adjust(right=0.98)\n    figure.sca(curraxis)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_header(self, header_string):\n        header_content = header_string.strip().split('\\t')\n        if len(header_content) != self._snv_enum.HEADER_LEN.value:\n            raise MTBParserException(\n                \"Only {} header columns found, {} expected!\"\n                .format(len(header_content), self._snv_enum.HEADER_LEN.value))\n        counter = 0\n        for column in header_content:\n            for enum_type in self._snv_enum:\n                if column == enum_type.value:\n                    self._header_to_column_mapping[enum_type.name] = counter\n                    continue\n            counter+=1\n\n        if len(self._header_to_column_mapping) != self._snv_enum.HEADER_LEN.value:\n            debug_string = self._header_to_column_mapping.keys()\n            raise MTBParserException(\"Parsing incomplete: Not all columns have been \"\n                    \"matched to speficied column types. Identified {} columns, but expected {}. {}\"\n                    .format(len(self._header_to_column_mapping), self._snv_enum.HEADER_LEN.value, debug_string))", "response": "Parses the header and determines the column type and column index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_content(self, snv_entries):\n        if len(snv_entries) == 1:\n            return\n        for line in snv_entries[1:]:\n            info_dict = self._map_info_to_col(line)\n            self._snv_list.append(SNVItem(**info_dict))", "response": "Parses the content of the SNV entries into a list of SNVItems."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubscribing the user to the list of newsletters", "response": "def subscribe(email, **kwargs):\n    \"\"\"\n    :param email: The email address of the user to add to the mailing list\n    :param kwargs: Keyword arguments to pass to the individual newsletter provider\n\n    This function acts as an alias to one of two functions, depending on your setup. If you use\n    `Celery <http://www.celeryproject.org/>`_,\n    this function will perform the API calls asynchronously. Otherwise the process will take place\n    on the same thread.\n    \"\"\"\n    if 'djcelery' in settings.INSTALLED_APPS:\n        subscribe_task.delay(\n            email,\n            **kwargs\n        )\n    else:\n        subscribe_task(\n            email,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_function(chaining, routine):\n\n    def processing(*args, **kwargs):\n        \"\"\"Execute routine with input args and kwargs and add reuslt in\n        chaining.___.\n\n        :param tuple args: routine varargs.\n        :param dict kwargs: routine kwargs.\n        :return: chaining chaining.\n        :rtype: Chaining\n        \"\"\"\n\n        result = routine(*args, **kwargs)\n        chaining.___.append(result)\n\n        return chaining\n\n    return processing", "response": "Return a function which returns a Chaining\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_function_list(self, routines):\n\n    def processing(*args, **kwargs):\n        \"\"\"Execute routines with input args and kwargs and add result in\n        chaining.___.\n\n        :param tuple args: routines varargs.\n        :param dict kwargs: routines kwargs.\n        :return: chaining chaining.\n        :rtype: Chaining\n        \"\"\"\n\n        results = [None] * len(routines)\n        for index, routine in enumerate(routines):\n            if isinstance(routine, Exception):\n                result = routine\n            else:\n                try:\n                    result = routine(*args, **kwargs)\n                except AttributeError as excp:\n                    result = excp\n            results[index] = result\n        self.___.append(results)\n\n        return self\n\n    return processing", "response": "Return a function that processes a list of routines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef actions(obj, **kwargs):\n    if 'exclude' in kwargs:\n        kwargs['exclude'] = kwargs['exclude'].split(',')\n    actions = obj.get_actions(**kwargs)\n    if isinstance(actions, dict):\n        actions = actions.values()\n    buttons = \"\".join(\"%s\" % action.render() for action in actions)\n    return '<div class=\"actions\">%s</div>' % buttons", "response": "Returns the HTML for the actions available for an object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing a model registry with a list of model definitions in Json - like format.", "response": "def init_registry(mongo, model_defs, clear_collection=False):\n    \"\"\"Initialize a model registry with a list of model definitions in Json\n    format.\n\n    Parameters\n    ----------\n    mongo : scodata.MongoDBFactory\n        Connector for MongoDB\n    model_defs : list()\n        List of model definitions in Json-like format\n    clear_collection : boolean\n        If true, collection will be dropped before models are created\n    \"\"\"\n    # Create model registry\n    registry = SCOEngine(mongo).registry\n    # Drop collection if clear flag is set to True\n    if clear_collection:\n        registry.clear_collection()\n    for i in range(len(model_defs)):\n        model = registry.from_dict(model_defs[i])\n        registry.register_model(\n            model.identifier,\n            model.properties,\n            model.parameters,\n            model.outputs,\n            model.connector\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_models(self, limit=-1, offset=-1):\n        return self.registry.list_models(limit=limit, offset=offset)", "response": "Get a list of models in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_model(self, model_id, properties, parameters, outputs, connector):\n        # Validate the given connector information\n        self.validate_connector(connector)\n        # Connector information is valid. Ok to register the model. Will raise\n        # ValueError if model with given identifier exists. Catch duplicate\n        # key error to transform it into a ValueError\n        try:\n            return self.registry.register_model(\n                model_id,\n                properties,\n                parameters,\n                outputs,\n                connector\n            )\n        except DuplicateKeyError as ex:\n            raise ValueError(str(ex))", "response": "Register a new model with the engine."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_model(self, model_run, run_url):\n        # Get model to verify that it exists and to get connector information\n        model = self.get_model(model_run.model_id)\n        if model is None:\n            raise ValueError('unknown model: ' + model_run.model_id)\n        # By now there is only one connector. Use the buffered connector to\n        # avoid closed connection exceptions\n        RabbitMQConnector(model.connector).run_model(model_run, run_url)", "response": "Execute the given model run."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_model_connector(self, model_id, connector):\n        # Validate the given connector information\n        self.validate_connector(connector)\n        # Connector information is valid. Ok to update the model.\n        return self.registry.update_connector(model_id, connector)", "response": "Update the connector information for a given model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate a given connector. Raises ValueError if the connector is not valid.", "response": "def validate_connector(self, connector):\n        \"\"\"Validate a given connector. Raises ValueError if the connector is not\n        valid.\n\n        Parameters\n        ----------\n        connector : dict\n            Connection information\n        \"\"\"\n        if not 'connector' in connector:\n            raise ValueError('missing connector name')\n        elif connector['connector'] != CONNECTOR_RABBITMQ:\n            raise ValueError('unknown connector: ' + str(connector['connector']))\n        # Call the connector specific validator. Will raise a ValueError if\n        # given connector information is invalid\n        RabbitMQConnector.validate(connector)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_model(self, model_run, run_url):\n        # Open connection to RabbitMQ server. Will raise an exception if the\n        # server is not running. In this case we raise an EngineException to\n        # allow caller to delete model run.\n        try:\n            credentials = pika.PlainCredentials(self.user, self.password)\n            con = pika.BlockingConnection(pika.ConnectionParameters(\n                host=self.host,\n                port=self.port,\n                virtual_host=self.virtual_host,\n                credentials=credentials\n            ))\n            channel = con.channel()\n            channel.queue_declare(queue=self.queue, durable=True)\n        except pika.exceptions.AMQPError as ex:\n            err_msg = str(ex)\n            if err_msg == '':\n                err_msg = 'unable to connect to RabbitMQ: ' + self.user + '@'\n                err_msg += self.host + ':' + str(self.port)\n                err_msg += self.virtual_host + ' ' + self.queue\n            raise EngineException(err_msg, 500)\n        # Create model run request\n        request = RequestFactory().get_request(model_run, run_url)\n        # Send request\n        channel.basic_publish(\n            exchange='',\n            routing_key=self.queue,\n            body=json.dumps(request.to_dict()),\n            properties=pika.BasicProperties(\n                delivery_mode = 2, # make message persistent\n            )\n        )\n        con.close()", "response": "Run the model run by sending a request to RabbitMQ queue containing the model run end experiment identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates entry in run request buffer.", "response": "def run_model(self, model_run, run_url):\n        \"\"\"Create entry in run request buffer.\n\n        Parameters\n        ----------\n        model_run : ModelRunHandle\n            Handle to model run\n        run_url : string\n            URL for model run information\n        \"\"\"\n        # Create model run request\n        request = RequestFactory().get_request(model_run, run_url)\n        # Write request and connector information into buffer\n        self.collection.insert_one({\n            'connector' : self.connector,\n            'request' : request.to_dict()\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_request(self, model_run, run_url):\n        return ModelRunRequest(\n            model_run.identifier,\n            model_run.experiment_id,\n            run_url\n        )", "response": "Create request object to run model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit_error(url, user, project, area, description,\n                 extra=None, default_message=None):\n    \"\"\"Celery task for submitting errors asynchronously.\n\n    :param url: string URL for bugzscout\n    :param user: string fogbugz user to designate when submitting\n                 via bugzscout\n    :param project: string fogbugz project to designate for cases\n    :param area: string fogbugz area to designate for cases\n    :param description: string description for error\n    :param extra: string details for error\n    :param default_message: string default message to return in responses\n    \"\"\"\n    LOG.debug('Creating new BugzScout instance.')\n    client = bugzscout.BugzScout(\n        url, user, project, area)\n\n    LOG.debug('Submitting BugzScout error.')\n    client.submit_error(\n        description, extra=extra, default_message=default_message)", "response": "Submit an error to the bugzscout server asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_depth_first(nodes, func, depth=0, as_dict=False, parents=None):\n    '''\n    Given a structure such as the application menu layout described above, we\n    may want to apply an operation to each entry to create a transformed\n    version of the structure.\n\n    For example, let's convert all entries in the application menu layout from\n    above to upper-case:\n\n    >>> pprint(apply_depth_first(menu_actions, lambda node, parents, nodes: node.upper()))\n    [('FILE',\n      ['LOAD', 'SAVE', ('QUIT', ['QUIT WITHOUT SAVING', 'SAVE AND QUIT'])]),\n     ('EDIT', ['COPY', 'PASTE', ('FILL', ['DOWN', 'SERIES'])])]\n\n    Here we used the `apply_depth_first` function to apply a `lambda` function\n    to each entry to compute the upper-case value corresponding to each node/key.\n\n\n    `as_dict`\n    ---------\n\n    To make traversing the structure easier, the output may be expressed as a\n    nested `OrderedDict` structure.  For instance, let's apply the upper-case\n    transformation from above, but this time with `as_dict=True`:\n\n    >>> result = apply_depth_first(menu_actions, as_dict=True, \\\n    ...                            func=lambda node, parents, nodes: node.upper())\n\n    >>> type(result)\n    <class 'collections.OrderedDict'>\n\n    Here we see that the result is an ordered dictionary.  Moreover, we can\n    look up the transformed `\"File\"` entry based on the original key/node\n    value.  Since an entry may contain children, each entry is wrapped as a\n    `namedtuple` with `item` and `children` attributes.\n\n    >>> type(result['File'])\n    <class 'nested_structures.Node'>\n    >>> result['File'].item\n    'FILE'\n    >>> type(result['File'].children)\n    <class 'collections.OrderedDict'>\n\n    If an entry has children, the `children` attribute is an `OrderedDict`.\n    Otherwise, the `children` is set to `None`.\n\n    Given the information from above, we can look up the `\"Load\"` child entry\n    of the `\"File\"` entry.\n\n    >>> result['File'].children['Load']\n    Node(item='LOAD', children=None)\n\n    Similarly, we can look up the `\"Save and quit\"` child entry of the `\"Quit\"`\n    entry.\n\n    >>> result['File'].children['Quit'].children['Save and quit']\n    Node(item='SAVE AND QUIT', children=None)\n\n    Note that this function *(i.e., `apply_depth_first`)* could be used to,\n    e.g., create a menu GUI item for each entry in the structure.  This would\n    decouple the description of the layout from the GUI framework used.\n    '''\n    if as_dict:\n        items = OrderedDict()\n    else:\n        items = []\n\n    if parents is None:\n        parents = []\n\n    node_count = len(nodes)\n    for i, node in enumerate(nodes):\n        first = (i == 0)\n        last = (i == (node_count - 1))\n        if isinstance(node, tuple):\n            node, nodes = node\n        else:\n            nodes = []\n\n        item = func(node, parents, nodes, first, last, depth)\n        item_parents = parents + [node]\n        if nodes:\n            children = apply_depth_first(nodes, func,\n                                         depth=depth + 1,\n                                         as_dict=as_dict,\n                                         parents=item_parents)\n        else:\n            children = None\n\n        if as_dict:\n            items[node] = Node(item, children)\n        elif nodes:\n            items.append((item, children))\n        else:\n            items.append(item)\n    return items", "response": "Given a list of nodes and a function that applies a function to each entry in the tree and returns a transformed version of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_dict_depth_first(nodes, func, depth=0, as_dict=True, parents=None, pre=None, post=None):\n    '''\n    This function is similar to the `apply_depth_first` except that it operates\n    on the `OrderedDict`-based structure returned from `apply_depth_first` when\n    `as_dict=True`.\n\n    Note that if `as_dict` is `False`, the result of this function is given in\n    the entry/tuple form.\n    '''\n    if as_dict:\n        items = OrderedDict()\n    else:\n        items = []\n\n    if parents is None:\n        parents = []\n\n    node_count = len(nodes)\n    for i, (k, node) in enumerate(nodes.iteritems()):\n        first = (i == 0)\n        last = (i == (node_count - 1))\n        if pre is not None:\n            pre(k, node, parents, first, last, depth)\n        item = func(k, node, parents, first, last, depth)\n        item_parents = parents + [(k, node)]\n        if node.children is not None:\n            children = apply_dict_depth_first(node.children, func,\n                                              depth=depth + 1,\n                                              as_dict=as_dict,\n                                              parents=item_parents,\n                                              pre=pre, post=post)\n        else:\n            children = None\n        if post is not None:\n            post(k, node, parents, first, last, depth)\n        if as_dict:\n            items[k] = Node(item, children)\n        elif children:\n            items.append((item, children))\n        else:\n            items.append(item)\n    return items", "response": "This function operates on the OrderedDict - based structure returned from apply_depth_first."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef collect(nested_nodes, transform=None):\n    '''\n    Return list containing the result of the `transform` function applied to\n    each item in the supplied list of nested nodes.\n\n    A custom transform function may be applied to each entry during the\n    flattening by specifying a function through the `transform` keyword\n    argument.  The `transform` function will be passed the following arguments:\n\n     - `node`: The node/key of the entry.\n     - `parents`: The node/key of the parents as a `list`.\n     - `nodes`: The children of the entry.\n\n    By default, the `transform` function simply returns the node/key, resulting\n    in a flattened version of the original nested nodes structure.\n    '''\n    items = []\n\n    if transform is None:\n        transform = lambda node, parents, nodes, *args: node\n\n    def __collect__(node, parents, nodes, first, last, depth):\n        items.append(transform(node, parents, nodes, first, last, depth))\n\n    apply_depth_first(nested_nodes, __collect__)\n    return items", "response": "Returns a list containing the result of the transform function applied to each item in the supplied list of nested nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_name_to_id(func_, *args, **kwargs):\n    assert isinstance(args[0], dict)\n    args[0][PRIMARY_KEY] = args[0].get(PRIMARY_FIELD, \"\")\n    return func_(*args, **kwargs)", "response": "Wrap a function to put the Name field into the ID field"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wrap_split_big_content(func_, *args, **kwargs):\n    obj_dict = args[0]\n    if len(obj_dict[CONTENT_FIELD]) < MAX_PUT:\n        obj_dict[PART_FIELD] = False\n        return func_(*args, **kwargs)\n    else:\n        return _perform_chunking(func_, *args, **kwargs)", "response": "Wrap the function to split the content into smaller binary blobs before inserting\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _only_if_file_not_exist(func_, *args, **kwargs):\n    obj_dict = args[1]\n    conn = args[-1]\n    try:\n        RBF.get(obj_dict[PRIMARY_FIELD]).pluck(PRIMARY_FIELD).run(conn)\n        err_str = \"Duplicate primary key `Name`: {}\".format(obj_dict[PRIMARY_FIELD])\n        err_dict = {'errors': 1,\n                    'first_error':  err_str}\n        return err_dict\n    except r.errors.ReqlNonExistenceError:\n        return func_(*args, **kwargs)", "response": "Only if the file does not exist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_guess_content_type(func_, *args, **kwargs):\n    assert isinstance(args[0], dict)\n    if not args[0].get(CONTENTTYPE_FIELD, None):\n        content = args[0].get(CONTENT_FIELD, b\"\")\n        try:\n            args[0][CONTENTTYPE_FIELD] = magic.from_buffer(content)\n        except magic.MagicException:  # pragma: no cover\n            args[0][CONTENTTYPE_FIELD] = MockMagic.DEFAULT_MAGIC\n    return func_(*args, **kwargs)", "response": "Wrap the function to guess the content type of the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap the content of a node into a binary node if needed.", "response": "def wrap_content_as_binary_if_needed(func_, *args, **kwargs):\n    \"\"\"\n    destination (rethinkdb) needs the id field as primary key\n    put the Name field into the ID field\n    :param func_:\n    :param args:\n    :param kwargs:\n    :return:\n    \"\"\"\n    assert isinstance(args[0], dict)\n    try:\n        args[0][CONTENT_FIELD] = BINARY(args[0].get(CONTENT_FIELD, b\"\"))\n    except (r.errors.ReqlDriverCompileError, AttributeError):  # pragma: no cover\n        pass  # toss in the object as string\n    return func_(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports a class dynamically from a full import path.", "response": "def import_class(import_path):\n    \"\"\"\n    Imports a class dynamically from a full import path.\n    \"\"\"\n    if not '.' in import_path:\n        raise IncorrectImportPath(\n            \"Invalid Python-style import path provided: {0}.\".format(\n                import_path\n            )\n        )\n\n    path_bits = import_path.split('.')\n    mod_path = '.'.join(path_bits[:-1])\n    klass_name = path_bits[-1]\n\n    try:\n        mod = importlib.import_module(mod_path)\n    except ImportError:\n        raise IncorrectImportPath(\n            \"Could not import module '{0}'.\".format(mod_path)\n        )\n\n    try:\n        klass = getattr(mod, klass_name)\n    except AttributeError:\n        raise IncorrectImportPath(\n            \"Imported module '{0}' but could not find class '{1}'.\".format(\n                mod_path,\n                klass_name\n            )\n        )\n\n    return klass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef probe(self, hosts):\n        '''\n        .. seealso:: :attr:`probe`\n        '''\n\n        def __send_probe(host):\n            ping = self.m(\n                '',\n                cmdd=dict(\n                    cmd=' '.join([\n                        self.__ping_cmd,\n                        self.__num,\n                        self.__net_if,\n                        self.__packetsize,\n                        host\n                    ])\n                ),\n                critical=False,\n                verbose=False\n            )\n\n            up = True if ping.get('returncode') == 0 else False\n            self.__probe_results[host] = {'up': up}\n\n            if up:\n                p = ping.get('out')\n\n                loss = _search(rxlss, p)\n                ms = _findall(rxmst, p)\n                rtt = _search(rxrtt, p)\n\n                if loss:\n                    loss = loss.group('loss')\n                self.__probe_results[host].update(dict(\n                    ms=ms,\n                    loss=loss,\n                    rtt=rtt.groupdict()\n                ))\n\n        hosts = to_list(hosts)\n        pool_size = (\n            len(hosts)\n            if len(hosts) <= self.__max_pool_size else\n            self.__max_pool_size\n        )\n\n        pool = _Pool(pool_size)\n        pool.map(__send_probe, hosts)\n        pool.close()\n        pool.join()", "response": "probe for a list of hosts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary with the status of the current n - hosts.", "response": "def status(self):\n        '''\n        :returns:\n            A dictionary with the following:\n\n        * 'num': Total number of hosts already probed\n        * 'up': Number of hosts up\n        * 'down': Number of hosts down\n        * 'ratio': Ratio between 'up'/'down' as float\n\n        Ratio:\n\n        * ``100%`` up == `1.0`\n        * ``10%`` up == `0.1`\n        * ``0%`` up == `0.0`\n        '''\n\n        num = len(self.probe)\n        up = len([h for h in self.probe if self.probe[h]['up']])\n        ratio = up/num if num != 0 else 0  # over 9000!\n\n        return dict(num=num, up=up, down=num-up, ratio=ratio)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a restclients. models. HfsAccounts object on the given uwnetid", "response": "def get_hfs_accounts(netid):\n    \"\"\"\n    Return a restclients.models.hfs.HfsAccounts object on the given uwnetid\n    \"\"\"\n    url = ACCOUNTS_URL.format(uwnetid=netid)\n    response = get_resource(url)\n    return _object_from_json(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _timedelta_from_elements(elements):\n    days = sum((\n        elements['days'],\n        _months_to_days(elements.get('months', 0)),\n        _years_to_days(elements.get('years', 0))\n    ))\n\n    return datetime.timedelta(days=days,\n                              hours=elements.get('hours', 0),\n                              minutes=elements.get('minutes', 0),\n                              seconds=elements.get('seconds', 0))", "response": "Returns a timedelta from a dict of date elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _year_month_delta_from_elements(elements):\n    return divmod(\n        (int(elements.get('years', 0)) * MONTHS_IN_YEAR) +\n        elements.get('months', 0),\n        MONTHS_IN_YEAR\n    )", "response": "Return a tuple of years months from a dict of date elements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next(self):\n        if self._records_iter >= len(self._records):\n            raise StopIteration\n        self._records_iter += 1\n        return self._records[self._records_iter - 1]", "response": "Return the next record in this batch in out - of - order."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn formatted str. :param format: one of 'json', 'csv' are supported", "response": "def formatted_str(self, format):\n        \"\"\"Return formatted str.\n\n        :param format: one of 'json', 'csv' are supported\n        \"\"\"\n        assert(format in ('json', 'csv'))\n        ret_str_list = []\n        for rec in self._records:\n            if format == 'json':\n                ret_str_list.append('{')\n                for i in xrange(len(rec)):\n                    colname, colval = self._rdef[i].name, rec[i]\n                    ret_str_list.append('\"%s\":\"%s\"' % (colname, str(colval).replace('\"', r'\\\"')))\n                    ret_str_list.append(',')\n                ret_str_list.pop()  # drop last comma\n                ret_str_list.append('}%s' % (os.linesep))\n            elif format == 'csv':\n                for i in xrange(len(rec)):\n                    colval = rec[i]\n                    ret_str_list.append('\"%s\"' % (str(colval).replace('\"', r'\\\"')))\n                    ret_str_list.append(',')\n                ret_str_list.pop()  # drop last comma\n                ret_str_list.append('%s' % (os.linesep))\n            else:\n                assert(False)\n        return ''.join(ret_str_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_file(self, filename):\n        result = []\n        with open(filename, 'r') as f:\n            lines = f.read().split('\\n')\n            for line in lines:\n                nocomment = line.strip().split('#')[0].strip()\n                if nocomment:\n                    result.append(nocomment)\n        return result", "response": "Return the lines from the given file ignoring lines that start with\n        comments"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_(self, table, alias=None):\n        if isinstance(table, str):\n            table = [[table, alias]]\n        self.raw_tables = table\n        return self", "response": "Establece el origen de datos y un alias opcionalmente."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef group_by(self, *args):\n        if len(args) == 1:\n            self.raw_fields_group = args[0].split(',')\n        else:\n            self.raw_fields_group = list(args)\n        return self", "response": "Indica los campos para agrupaci\u00f3n\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a SQL query string for the related record set.", "response": "def result(self, *args, **kwargs):\n        \"\"\"\n        Construye la consulta SQL\n        \"\"\"\n        prettify = kwargs.get('pretty', False)\n        self.__prepareData__()\n        sql = 'SELECT '\n        sql +=  ', '.join(self.fields)\n        \n        if len(self.tables) > 0:\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n            sql +=  'FROM '\n            sql +=  ', '.join(self.tables)\n        if self.where_criteria.size() > 0:\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n            sql +=  'WHERE '\n            sql +=  self.where_criteria.result()\n        if len(self.group_fields) > 0:\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n            sql +=  'GROUP BY '\n            sql +=  ', '.join(self.group_fields)\n        if len(self.order_by_fields) > 0:\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n            sql +=  'ORDER BY '\n            sql +=  ', '.join(self.order_by_fields)\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef where(self, field, value = None, operator = None):\n        if field is None:\n            return self\n        conjunction = None\n        if value is None and isinstance(field, dict):\n            for f,v in field.items():\n                if self.where_criteria.size() > 0:\n                    conjunction = 'AND'\n                self.where_criteria.append(expressions.ConditionExpression(f, v, operator=operator, conjunction=conjunction))\n                \n        else:\n            if self.where_criteria.size() > 0:\n                    conjunction = 'AND'\n            self.where_criteria.append(expressions.ConditionExpression(field, value, operator=operator, conjunction=conjunction))\n        return self", "response": "A method to add a condition to the where_criteria list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef result(self, *args, **kwargs):\n        prettify = kwargs.get('pretty', False)\n\n        sql = 'DELETE %s %s' % (self._type, self._class)\n        \n        if prettify:\n            sql += '\\n'\n        else:\n            sql += ' '\n\n        if self.where_criteria.size() > 0:\n            sql +=  'WHERE '\n            sql +=  self.where_criteria.result()\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n        \n        return sql", "response": "SQL DELETE a single entry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_(self, From):\n        if self._type.lower() != 'edge':\n            raise ValueError('Cannot set From/To to non-edge objects')\n        self._from = From\n        return self", "response": "Set the From attribute of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the to attribute of the From object.", "response": "def to(self, to):\n        \"\"\"\n        [Edge-only] especifica el destino del lado\n        \"\"\"\n        if self._type.lower() != 'edge':\n            raise ValueError('Cannot set From/To to non-edge objects')\n        self._to = to\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a value to the content of the current object", "response": "def set(self, field, value = None):\n        \"\"\"\n        [Edge|Vertex] establece datos del recurso\n        \"\"\"\n        if value is None and isinstance(field, dict):\n            self.content(field)\n        if field and value:\n            self.data[field] = value\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the SQL statement that creates the record.", "response": "def result(self, *args, **kwargs):\n        \"\"\"\n        Construye la consulta SQL\n        \"\"\"\n        prettify = kwargs.get('pretty', False)\n\n        sql = 'CREATE %s %s' % (self._type, self._class)\n        \n        if prettify:\n            sql += '\\n'\n        else:\n            sql += ' '\n\n        if self._type.lower() == 'edge':\n            sql += \" FROM %s TO %s \" % (self._from, self._to)\n        \n        if self._cluster:\n            sql += 'CLUSTER %s' % self._cluster\n            if prettify:\n                sql += '\\n'\n            else:\n                sql += ' '\n        \n        if self.data:\n            sql += 'CONTENT ' + json.dumps(self.data)\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate or updates an existing issue in the store.", "response": "def create_or_update_issue(self, title, body, culprit, labels, **kwargs):\n        '''Creates or comments on existing issue in the store.\n\n        :params title: title for the issue\n        :params body: body, the content of the issue\n        :params culprit: string used to identify the cause of the issue,\n            also used for aggregation\n        :params labels: (optional) list of labels attached to the issue\n        :returns: issue object\n        :rtype: :class:`exreporter.stores.github.GithubIssue`\n        '''\n        issues = self.search(q=culprit, labels=labels)\n        self.time_delta = kwargs.pop('time_delta')\n        self.max_comments = kwargs.pop('max_comments')\n\n        if issues:\n            latest_issue = issues.pop(0)\n            return self.handle_issue_comment(\n                issue=latest_issue, title=title, body=body, **kwargs)\n        else:\n            return self.create_issue(\n                title=title, body=body, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for issues in Github.", "response": "def search(self, q, labels, state='open,closed', **kwargs):\n        \"\"\"Search for issues in Github.\n\n        :param q: query string to search\n        :param state: state of the issue\n        :returns: list of issue objects\n        :rtype: list\n\n        \"\"\"\n        search_result = self.github_request.search(q=q, state=state, **kwargs)\n        if search_result['total_count'] > 0:\n            return list(\n                map(lambda issue_dict: GithubIssue(\n                    github_request=self.github_request, **issue_dict),\n                    search_result['items'])\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_issue_comment(self, issue, title, body, **kwargs):\n        if self._is_time_delta_valid(issue.updated_time_delta):\n            if issue.comments_count < self.max_comments:\n                issue.comment(body=body)\n                return issue\n            else:\n                return self.create_issue(title=title, body=body, **kwargs)", "response": "Decides whether to comment or create a new issue when trying to comment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_issue(self, title, body, labels=None):\n        kwargs = self.github_request.create(\n            title=title, body=body, labels=labels)\n        return GithubIssue(github_request=self.github_request, **kwargs)", "response": "Creates a new issue in Github."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of seconds ago the issue was updated from current time.", "response": "def updated_time_delta(self):\n        \"\"\"Returns the number of seconds ago the issue was updated from current time.\n        \"\"\"\n        local_timezone = tzlocal()\n        update_at = datetime.datetime.strptime(self.updated_at, '%Y-%m-%dT%XZ')\n        update_at_utc = pytz.utc.localize(update_at)\n        update_at_local = update_at_utc.astimezone(local_timezone)\n        delta = datetime.datetime.now(local_timezone) - update_at_local\n        return int(delta.total_seconds())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging the state of issue to open.", "response": "def open_issue(self):\n        \"\"\"Changes the state of issue to 'open'.\n        \"\"\"\n        self.github_request.update(issue=self, state='open')\n        self.state = 'open'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef comment(self, body):\n        self.github_request.comment(issue=self, body=body)\n\n        if self.state == 'closed':\n            self.open_issue()\n        return self", "response": "Adds a comment to the issue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, title, body, labels):\n        url = \"https://api.github.com/repos/{}/{}/issues\".format(\n            self.user, self.repo)\n\n        data = {\n            'title': title,\n            'body': body,\n        }\n\n        if labels:\n            data.update({'labels': labels})\n\n        response = self.session.post(url, json.dumps(data))\n\n        assert response.status_code == 201\n        return json.loads(response.content)", "response": "Create an issue in Github."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comment(self, issue, body):\n        url = issue.comments_url\n        data = {'body': body}\n\n        response = self.session.post(url, json.dumps(data))\n        assert response.status_code == 201\n\n        return json.loads(response.content)", "response": "Comment on existing issue on Github."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates an existing issue on Github.", "response": "def update(self, issue, **kwargs):\n        \"\"\"Update an existing issue on Github.\n        For JSON data returned by Github refer:\n        https://developer.github.com/v3/issues/#edit-an-issue\n\n        :param issue: object existing issue\n        :returns: dict of JSON data returned by Github.\n        :rtype: `dict`\n\n        \"\"\"\n        url = issue.url\n\n        response = self.session.patch(url, json.dumps(kwargs))\n\n        assert response.status_code == 200\n        return json.loads(response.content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for issues in Github.", "response": "def search(self, q, state, labels):\n        \"\"\"Search for issues in Github.\n        For JSON data returned by Github refer:\n        https://developer.github.com/v3/search/#search-issues\n\n        :param q: query string for search\n        :param state: the states of the issue\n        :param labels: labels of the issue\n        :returns: dictionary of JSON data returned by Github\n        :rtype: `dict`\n\n        \"\"\"\n        # TODO: add support for search with labels\n        labels = ['\"{}\"'.format(label) for label in labels]\n        q = \"'{}'+state:{}+label:{}\".format(\n            q, '+state:'.join(state.split(',')), ','.join(labels))\n        sort = \"updated\"\n\n        url = \"https://api.github.com/search/\"\\\n              \"issues?q={}+repo:{}/{}&sort={}\".format(\n                  q, self.user, self.repo, sort)\n\n        response = self.session.get(url)\n        assert response.status_code == 200\n        return json.loads(response.content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile(self):\n        if self._compiled:\n            return\n\n        self.decodable_properties = set()\n        self.encodable_properties = set()\n        self.inherited_dynamic = None\n        self.inherited_sealed = None\n        self.bases = []\n\n        self.exclude_attrs = set(self.exclude_attrs or [])\n        self.readonly_attrs = set(self.readonly_attrs or [])\n        self.static_attrs = list(self.static_attrs or [])\n        self.static_attrs_set = set(self.static_attrs)\n        self.proxy_attrs = set(self.proxy_attrs or [])\n\n        self.sealed = util.is_class_sealed(self.klass)\n\n        if self.external:\n            self._checkExternal()\n            self._finalise_compile()\n\n            # this class is external so no more compiling is necessary\n            return\n\n        if hasattr(self.klass, '__slots__'):\n            self.decodable_properties.update(self.klass.__slots__)\n            self.encodable_properties.update(self.klass.__slots__)\n\n        for k, v in self.klass.__dict__.iteritems():\n            if not isinstance(v, property):\n                continue\n\n            if v.fget:\n                self.encodable_properties.update([k])\n\n            if v.fset:\n                self.decodable_properties.update([k])\n            else:\n                self.readonly_attrs.update([k])\n\n        mro = inspect.getmro(self.klass)[1:]\n\n        for c in mro:\n            self._compile_base_class(c)\n\n        self.getCustomProperties()\n\n        self._finalise_compile()", "response": "This function compiles the alias into a form that can be used to create the class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a C { dict } of attributes that can be encoded even if it is empty.", "response": "def getEncodableAttributes(self, obj, codec=None):\n        \"\"\"\n        Must return a C{dict} of attributes to be encoded, even if its empty.\n\n        @param codec: An optional argument that will contain the encoder\n            instance calling this function.\n        @since: 0.5\n        \"\"\"\n        if not self._compiled:\n            self.compile()\n\n        if self.is_dict:\n            return dict(obj)\n\n        if self.shortcut_encode and self.dynamic:\n            return obj.__dict__.copy()\n\n        attrs = {}\n\n        if self.static_attrs:\n            for attr in self.static_attrs:\n                attrs[attr] = getattr(obj, attr, pyamf.Undefined)\n\n        if not self.dynamic:\n            if self.non_static_encodable_properties:\n                for attr in self.non_static_encodable_properties:\n                    attrs[attr] = getattr(obj, attr)\n\n            return attrs\n\n        dynamic_props = util.get_properties(obj)\n\n        if not self.shortcut_encode:\n            dynamic_props = set(dynamic_props)\n\n            if self.encodable_properties:\n                dynamic_props.update(self.encodable_properties)\n\n            if self.static_attrs:\n                dynamic_props.difference_update(self.static_attrs)\n\n            if self.exclude_attrs:\n                dynamic_props.difference_update(self.exclude_attrs)\n\n        for attr in dynamic_props:\n            attrs[attr] = getattr(obj, attr)\n\n        if self.proxy_attrs is not None and attrs and codec:\n            context = codec.context\n\n            for k, v in attrs.copy().iteritems():\n                if k in self.proxy_attrs:\n                    attrs[k] = context.getProxyForObject(v)\n\n        if self.synonym_attrs:\n            missing = object()\n\n            for k, v in self.synonym_attrs.iteritems():\n                value = attrs.pop(k, missing)\n\n                if value is missing:\n                    continue\n\n                attrs[v] = value\n\n        return attrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of attributes that can be applied to the object obj.", "response": "def getDecodableAttributes(self, obj, attrs, codec=None):\n        \"\"\"\n        Returns a dictionary of attributes for C{obj} that has been filtered,\n        based on the supplied C{attrs}. This allows for fine grain control\n        over what will finally end up on the object or not.\n\n        @param obj: The object that will recieve the attributes.\n        @param attrs: The C{attrs} dictionary that has been decoded.\n        @param codec: An optional argument that will contain the decoder\n            instance calling this function.\n        @return: A dictionary of attributes that can be applied to C{obj}\n        @since: 0.5\n        \"\"\"\n        if not self._compiled:\n            self.compile()\n\n        changed = False\n\n        props = set(attrs.keys())\n\n        if self.static_attrs:\n            missing_attrs = self.static_attrs_set.difference(props)\n\n            if missing_attrs:\n                raise AttributeError('Static attributes %r expected '\n                    'when decoding %r' % (missing_attrs, self.klass))\n\n            props.difference_update(self.static_attrs)\n\n        if not props:\n            return attrs\n\n        if not self.dynamic:\n            if not self.decodable_properties:\n                props = set()\n            else:\n                props.intersection_update(self.decodable_properties)\n\n            changed = True\n\n        if self.readonly_attrs:\n            props.difference_update(self.readonly_attrs)\n            changed = True\n\n        if self.exclude_attrs:\n            props.difference_update(self.exclude_attrs)\n            changed = True\n\n        if self.proxy_attrs is not None and codec:\n            context = codec.context\n\n            for k in self.proxy_attrs:\n                try:\n                    v = attrs[k]\n                except KeyError:\n                    continue\n\n                attrs[k] = context.getObjectForProxy(v)\n\n        if self.synonym_attrs:\n            missing = object()\n\n            for k, v in self.synonym_attrs.iteritems():\n                value = attrs.pop(k, missing)\n\n                if value is missing:\n                    continue\n\n                attrs[v] = value\n\n        if not changed:\n            return attrs\n\n        a = {}\n\n        [a.__setitem__(p, attrs[p]) for p in props]\n\n        return a"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef applyAttributes(self, obj, attrs, codec=None):\n        if not self._compiled:\n            self.compile()\n\n        if self.shortcut_decode:\n            if self.is_dict:\n                obj.update(attrs)\n\n                return\n\n            if not self.sealed:\n                obj.__dict__.update(attrs)\n\n                return\n\n        else:\n            attrs = self.getDecodableAttributes(obj, attrs, codec=codec)\n\n        util.set_attrs(obj, attrs)", "response": "Applies the collection of attributes to an object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createInstance(self, codec=None):\n        if type(self.klass) is type:\n            return self.klass.__new__(self.klass)\n\n        return self.klass()", "response": "Creates an instance of the klass."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a letter to a specific country.", "response": "def send_letter(self, file_list, destination='DE', duplex=True, color=False, user_transaction=None,\n                    gogreen=False,test_environment=False):\n        \"\"\"\n        Send pdf-File\n        :param file_list: list of files\n        :param destination: country code of the destination country\n        :param duplex: send letter in duplex\n        :param color: send letter with color or black/white\n        :param user_transaction: custom transaction id\n        :param test_environment: Enable Test-Mode\n        :return: Letter-ID if letter was sended successfully, else None\n        \"\"\"\n\n        idx = 0\n        last = len(file_list) - 1\n        multiple_files = True if len(file_list) > 1 else False\n        letter_id = None\n        for file in file_list:\n            files = {'file': file}\n            if idx == 0:\n                data = {\n                    'settings[destination]': destination,\n                    'settings[simplex]': 'NONE' if duplex else 'ALL',\n                    'settings[color]': 'ALL' if color else 'NONE',\n                    'settings[user_transaction]': user_transaction,\n                    'settings[test_environment]': test_environment,\n                    'settings[gogreen]': True if gogreen else False,\n                    'incomplete': True if multiple_files else False\n                }\n                send_req = self._make_post_request('letters', data=data, files=files)\n\n                if send_req:\n                    if not multiple_files:\n                        return json.loads(send_req)['id']\n                    else:\n                        letter_id = json.loads(send_req)['id']\n                else:\n                    return send_req\n\n            if idx > 0:\n                if idx == last:\n                    self._make_patch_request('letters/{}'.format(letter_id), data={'incomplete': False}, files=files)\n                else:\n                    self._make_patch_request('letters/{}'.format(letter_id), data={'incomplete': True}, files=files)\n\n            idx += 1\n        return letter_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the status of a particular letter", "response": "def get_letter_status(self, pixelletter_id):\n        \"\"\"\n        :param pixelletter_id: ID of the letter\n        :return: dict containing status of the requested letter\n        \"\"\"\n        letter_status = self._make_get_request('letters/{}'.format(pixelletter_id))\n\n        if letter_status:\n            return json.loads(letter_status)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_letter_as_pdf(self, pixelletter_id):\n        pdf_letter = self._make_get_request('letters/{}.pdf'.format(pixelletter_id))\n\n        if pdf_letter:\n            return pdf_letter\n\n        return None", "response": "Get specified letter by letter ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget specified letter as image", "response": "def get_letter_as_image(self, pixelletter_id):\n        \"\"\"\n        Get specified letter as image\n        :param pixelletter_id: ID of the letter\n        :return: JPG-Letter-Unicode-String if successful else None\n        \"\"\"\n        image_letter = self._make_get_request('letters/previews/{}_1.jpg'.format(pixelletter_id))\n\n        if image_letter:\n            return image_letter\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cancel_letter(self, pixelletter_id):\n        cancel_request = self._make_delete_request('letters/{}'.format(pixelletter_id))\n        status = json.loads(cancel_request)['status']\n\n        if status == 200:\n            return True\n\n        return False", "response": "Cancel the specified letter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting points with dates.", "response": "def plot_date(datasets, **kwargs):\n    \"\"\"Plot points with dates.\n\n    datasets can be Dataset object or list of Dataset.\n    \"\"\"\n\n    defaults = {\n        'grid': True,\n        'xlabel': '',\n        'ylabel': '',\n        'title': '',\n        'output': None,\n        'figsize': (8, 6),\n    }\n    plot_params = {\n        'color': 'b',\n        'ls': '',\n        'alpha': 0.75,\n    }\n    _update_params(defaults, plot_params, kwargs)\n    if isinstance(datasets, Dataset):\n        datasets = [datasets]\n\n    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n    color = plot_params.pop('color')\n    try:\n        del colors[colors.index(color)]\n        colors.insert(0, color)\n    except IndexError:\n        pass\n    colors = cycle(colors)\n\n    fig, ax = plt.subplots()\n    fig.set_size_inches(*defaults['figsize'])\n    fig.autofmt_xdate()\n    ax.autoscale_view()\n\n    for dataset in datasets:\n        if isinstance(dataset, Dataset):\n            dates = list(dataset.get_column_by_type(dataset.DATE))\n            values = list(dataset.get_column_by_type(dataset.NUM))\n            label = dataset.name\n        else:\n            dates, values = dataset\n            label = ''\n        dates = date2num(dates)\n        color = next(colors)\n        plt.plot_date(dates, values, color=color, label=label, **plot_params)\n\n    plt.xlabel(defaults['xlabel'])\n    plt.ylabel(defaults['ylabel'])\n    plt.title(defaults['title'])\n    plt.grid(defaults['grid'])\n\n    plt.legend(loc='best', prop={'size': 10})\n    filename = defaults['output'] or get_tmp_file_name('.png')\n    plt.savefig(filename)\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all TableAction elements defined for this table.", "response": "def actions(self):\n        \"\"\"\n        List of :class:`TableAction` elements defined for this table\n        \"\"\"\n        actions = []\n        for a in dir(self):\n            a = getattr(self, a)\n            if isinstance(a, TableAction):\n                actions.append(a)\n\n        # We are not caching this because array len should be low enough\n        actions.sort(key=lambda action: action.creation_counter)\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall each function in self. _actions after setting self. _event.", "response": "def call_actions(self, event, *args, **kwargs):\n        \"\"\"Call each function in self._actions after setting self._event.\"\"\"\n        self._event = event\n\n        for func in self._actions:\n            func(event, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ok(self) -> Option[T]:\n        return Option.Some(cast(T, self._val)) if self._is_ok else cast(Option[T], NONE)", "response": "Converts from Result to Option [ T ] if self is an ok result."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef err(self) -> Option[E]:\n        return cast(Option[E], NONE) if self._is_ok else Option.Some(cast(E, self._val))", "response": "Converts from Result to Option [ E ]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map(self, op: Callable[[T], U]) -> 'Union[Result[U, E], Result[T, E]]':\n        return self._type.Ok(op(cast(T, self._val))) if self._is_ok else self", "response": "Applies a function to the contained : meth:`Result. Ok value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flatmap(self, op: 'Callable[[T], Result[U, E]]') -> 'Result[U, E]':\n        return op(cast(T, self._val)) if self._is_ok else cast('Result[U, E]', self)", "response": "Applies a function to the contained Result. Ok value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply a function to the contained Result. Err value.", "response": "def map_err(self, op: Callable[[E], F]) -> 'Union[Result[T, F], Result[T, E]]':\n        \"\"\"\n        Applies a function to the contained :meth:`Result.Err` value.\n\n        Args:\n            op: The function to apply to the :meth:`Result.Err` value.\n\n        Returns:\n            A :class:`Result` with its error value as the function result\n            if `self` is a :meth:`Result.Err` value, otherwise returns\n            `self`.\n\n        Examples:\n            >>> Ok(1).map_err(lambda x: x * 2)\n            Ok(1)\n            >>> Err(1).map_err(lambda x: x * 2)\n            Err(2)\n        \"\"\"\n        return self if self._is_ok else cast(\n            'Result[T, F]',\n            self._type.Err(op(cast(E, self._val)))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunwraps the result of a KATCP command.", "response": "def unwrap(self) -> T:\n        \"\"\"\n        Returns the success value in the :class:`Result`.\n\n        Returns:\n            The success value in the :class:`Result`.\n\n        Raises:\n            ``ValueError`` with the message provided by the error value\n             if the :class:`Result` is a :meth:`Result.Err` value.\n\n        Examples:\n            >>> Ok(1).unwrap()\n            1\n            >>> try:\n            ...     Err(1).unwrap()\n            ... except ValueError as e:\n            ...     print(e)\n            1\n        \"\"\"\n        if self._is_ok:\n            return cast(T, self._val)\n        raise ValueError(self._val)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the success value in the Result or optb.", "response": "def unwrap_or(self, optb: T) -> T:\n        \"\"\"\n        Returns the success value in the :class:`Result` or ``optb``.\n\n        Args:\n            optb: The default return value.\n\n        Returns:\n            The success value in the :class:`Result` if it is a\n            :meth:`Result.Ok` value, otherwise ``optb``.\n\n        Notes:\n            If you wish to use a result of a function call as the default,\n            it is recommnded to use :meth:`unwrap_or_else` instead.\n\n        Examples:\n            >>> Ok(1).unwrap_or(2)\n            1\n            >>> Err(1).unwrap_or(2)\n            2\n        \"\"\"\n        return cast(T, self._val) if self._is_ok else optb"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unwrap_or_else(self, op: Callable[[E], U]) -> Union[T, U]:\n        return cast(T, self._val) if self._is_ok else op(cast(E, self._val))", "response": "Returns the sucess value in the Result or computes a default\n        from the error value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the success value of the current object.", "response": "def expect(self, msg) -> T:\n        \"\"\"\n        Returns the success value in the :class:`Result` or raises\n        a ``ValueError`` with a provided message.\n\n        Args:\n            msg: The error message.\n\n        Returns:\n            The success value in the :class:`Result` if it is\n            a :meth:`Result.Ok` value.\n\n        Raises:\n            ``ValueError`` with ``msg`` as the message if the\n            :class:`Result` is a :meth:`Result.Err` value.\n\n        Examples:\n            >>> Ok(1).expect('no')\n            1\n            >>> try:\n            ...     Err(1).expect('no')\n            ... except ValueError as e:\n            ...     print(e)\n            no\n        \"\"\"\n        if self._is_ok:\n            return cast(T, self._val)\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unwrap_err(self) -> E:\n        if self._is_ok:\n            raise ValueError(self._val)\n        return cast(E, self._val)", "response": "Unwraps the error value in a Result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expect_err(self, msg) -> E:\n        if self._is_ok:\n            raise ValueError(msg)\n        return cast(E, self._val)", "response": "Returns the error value in a : class:`Result`, or raises a : class:`ValueError with the provided message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_query_notes(query_str, first_line=False):\n    lines = query_str.split(\"\\n\")\n    started = False\n    parts = []\n    for line in lines:\n        line = line.strip()\n        if line.startswith(\"#\"):\n            parts.append(line)\n            started = True\n            if first_line:\n                break\n        if started and line and not line.startswith(\"#\"):\n            break\n    return \"\\n\".join(parts)", "response": "Reads the query string and returns the Comments from the header that are not in the header"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the data in hex format and return a sequence of rows.", "response": "def hexdump(data, cols=8, folded=False, stream=False, offset=0, header=False):\n    \"\"\"\n    yields the rows of the hex dump\n\n    Arguments:\n        data -- data to dump\n        cols -- number of octets per row\n        folded -- fold long ranges of equal bytes\n        stream -- dont use len on data\n\n    >>> from string import ascii_uppercase\n    >>> print('\\\\n'.join(hexdump(\"\".join(chr(i) for i in range(256)))))\n    00: 00 01 02 03 04 05 06 07 ........\n    08: 08 09 0A 0B 0C 0D 0E 0F ........\n    10: 10 11 12 13 14 15 16 17 ........\n    18: 18 19 1A 1B 1C 1D 1E 1F ........\n    20: 20 21 22 23 24 25 26 27  !\"#$%&'\n    28: 28 29 2A 2B 2C 2D 2E 2F ()*+,-./\n    30: 30 31 32 33 34 35 36 37 01234567\n    38: 38 39 3A 3B 3C 3D 3E 3F 89:;<=>?\n    40: 40 41 42 43 44 45 46 47 @ABCDEFG\n    48: 48 49 4A 4B 4C 4D 4E 4F HIJKLMNO\n    50: 50 51 52 53 54 55 56 57 PQRSTUVW\n    58: 58 59 5A 5B 5C 5D 5E 5F XYZ[\\]^_\n    60: 60 61 62 63 64 65 66 67 `abcdefg\n    68: 68 69 6A 6B 6C 6D 6E 6F hijklmno\n    70: 70 71 72 73 74 75 76 77 pqrstuvw\n    78: 78 79 7A 7B 7C 7D 7E 7F xyz{|}~.\n    80: 80 81 82 83 84 85 86 87 ........\n    88: 88 89 8A 8B 8C 8D 8E 8F ........\n    90: 90 91 92 93 94 95 96 97 ........\n    98: 98 99 9A 9B 9C 9D 9E 9F ........\n    A0: A0 A1 A2 A3 A4 A5 A6 A7 ........\n    A8: A8 A9 AA AB AC AD AE AF ........\n    B0: B0 B1 B2 B3 B4 B5 B6 B7 ........\n    B8: B8 B9 BA BB BC BD BE BF ........\n    C0: C0 C1 C2 C3 C4 C5 C6 C7 ........\n    C8: C8 C9 CA CB CC CD CE CF ........\n    D0: D0 D1 D2 D3 D4 D5 D6 D7 ........\n    D8: D8 D9 DA DB DC DD DE DF ........\n    E0: E0 E1 E2 E3 E4 E5 E6 E7 ........\n    E8: E8 E9 EA EB EC ED EE EF ........\n    F0: F0 F1 F2 F3 F4 F5 F6 F7 ........\n    F8: F8 F9 FA FB FC FD FE FF ........\n\n    >>> print('\\\\n'.join(hexdump(ascii_uppercase)))\n    00: 41 42 43 44 45 46 47 48 ABCDEFGH\n    08: 49 4A 4B 4C 4D 4E 4F 50 IJKLMNOP\n    10: 51 52 53 54 55 56 57 58 QRSTUVWX\n    18: 59 5A                   YZ\n    >>> print('\\\\n'.join(hexdump(ascii_uppercase, stream=True)))\n    00000: 41 42 43 44 45 46 47 48 ABCDEFGH\n    00008: 49 4A 4B 4C 4D 4E 4F 50 IJKLMNOP\n    00010: 51 52 53 54 55 56 57 58 QRSTUVWX\n    00018: 59 5A                   YZ\n    >>> print('\\\\n'.join(hexdump(ascii_uppercase + \"0\"*256, folded=True)))\n    000: 41 42 43 44 45 46 47 48 ABCDEFGH\n    008: 49 4A 4B 4C 4D 4E 4F 50 IJKLMNOP\n    010: 51 52 53 54 55 56 57 58 QRSTUVWX\n    018: 59 5A 30 30 30 30 30 30 YZ000000\n         *\n    118: 30 30                   00\n    >>> print('\\\\n'.join(hexdump(ascii_uppercase + \"0\"*256, folded=True, stream=True)))\n    00000: 41 42 43 44 45 46 47 48 ABCDEFGH\n    00008: 49 4A 4B 4C 4D 4E 4F 50 IJKLMNOP\n    00010: 51 52 53 54 55 56 57 58 QRSTUVWX\n    00018: 59 5A 30 30 30 30 30 30 YZ000000\n           *\n    00118: 30 30                   00\n    >>> print('\\\\n'.join(hexdump(ascii_uppercase, cols=16)))\n    00: 41 42 43 44 45 46 47 48 49 4A 4B 4C 4D 4E 4F 50 ABCDEFGHIJKLMNOP\n    10: 51 52 53 54 55 56 57 58 59 5A                   QRSTUVWXYZ\n    \"\"\"\n    last_byte = None\n    fold = False\n\n    # determine index width\n    if not stream:\n        size = len(data)\n        hexlen = len(hex(offset + size - 1)) - 2\n        offset_fmt = '{{:0{}X}}: '.format(hexlen)\n        if header:\n            line = ' ' * (hexlen + 2)\n            for i in range(min(cols, size + offset)):\n                line += '{:2X} '.format(i)\n            yield line.rstrip()\n    else:\n        size = None\n        hexlen = 5\n        offset_fmt = '{:05X}: '\n        if header:\n            line = ' ' * (5 + 2)\n            for i in range(cols):\n                line += '{:2X} '.format(i)\n            yield line.rstrip()\n\n    # convert input into iter if needed\n    if hasattr(data, 'read'):\n        def _tmp():\n            return data.read(1)\n        data_iter = iter(_tmp, '')\n    else:\n        data_iter = iter(data)\n\n    run = True\n    while run:\n        line = offset_fmt.format(offset - (offset % cols))\n        # ASCII dump\n        string = ''\n        skipped = 0\n        prefix = (offset % cols)\n\n        # padding\n        if offset % cols != 0:\n            line += '   ' * prefix\n            string += ' ' * prefix\n\n        try:\n            for _ in range(cols - (offset % cols)):\n                byte = next(data_iter)\n                # byte is equal to previous => count range of equal bytes\n                if last_byte == byte:\n                    skipped += 1\n                last_byte = byte\n                offset += 1\n                if isinstance(byte, str):\n                    bval = ord(byte)\n                elif isinstance(byte, int):\n                    bval = byte\n                    if 31 < bval < 127:\n                        byte = chr(bval)\n                else:\n                    bval = list(byte)[0]\n                    if 31 < bval < 127:\n                        byte = chr(bval)\n\n                if 31 < bval < 127:\n                    string += byte\n                else:\n                    string += '.'\n                line += '{:02X} '.format(bval)\n        except StopIteration:\n            run = False\n\n        # if folding is requested\n        if folded:\n            # all bytes are equal to the last byte of the previous block\n            if skipped == cols:\n                # show * the first time\n                if not fold:\n                    yield ' ' * (hexlen + 2) + '*'\n                fold = True\n                continue\n            else:\n                fold = False\n\n        # padding\n        if offset % cols != 0:\n            line += '   ' * (cols - (offset % cols))\n\n        # yield only if no StopIteration was thrown or bytes are remaining\n        if offset % cols != 0 or run:\n            line += string\n            yield line.rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a structure to stdout", "response": "def print_struct(struct, ident=0):\n    \"\"\"\n    >>> from ctypes import *\n    >>> class Test(Structure):\n    ...     _fields_ = [('foo', c_int)]\n    ... \n    >>> class Test2(Structure):\n    ...     _fields_ = [('foo', Test), ('bar', c_int)]\n    ... \n    >>> t = Test2()\n    >>> t.foo.foo = 2\n    >>> t.bar = 1\n    >>> print_struct(t)\n    foo: \n     foo: 2\n    bar: 1\n    \"\"\"\n    if not isinstance(struct, (str, bytes, list, tuple)) and hasattr(struct, '__getitem__'): # array\n        print('[')\n        for item in struct:\n            print(\" \"*ident, end=' ')\n            print_struct(item, ident+1)\n        print(\" \"*ident + \"]\")\n    elif not hasattr(struct, '_fields_'):\n        print(struct)\n    else:\n        if ident:\n            print()\n\n        for name, _ in struct._fields_:\n            print(\" \"*ident + \"{}:\".format(name), end=' ')\n            print_struct(getattr(struct, name), ident+1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes url for the user - name API", "response": "def make_url(*args, **kwargs):\n    \"\"\"\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\", token=\"api_token\")\n    'https://host/api/users/user-name/projects?token=api_token'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects/\", token=\"api_token\")\n    'https://host/api/users/user-name/projects/?token=api_token'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\", \"/\", token=\"api_token\")\n    'https://host/api/users/user-name/projects/?token=api_token'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\", [(\"token\", \"api_token\"), (\"aaa\", \"bbb\")])\n    'https://host/api/users/user-name/projects?token=api_token&aaa=bbb'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects/\", [(\"token\", \"api_token\"), (\"aaa\", \"bbb\")])\n    'https://host/api/users/user-name/projects/?token=api_token&aaa=bbb'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\", [(\"token\", \"api_token\"), (\"aaa\", \"bbb\")], other=\"value\")\n    'https://host/api/users/user-name/projects?token=api_token&aaa=bbb&other=value'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects/\", [(\"token\", \"api_token\"), (\"aaa\", \"bbb\")], other=\"value\")\n    'https://host/api/users/user-name/projects/?token=api_token&aaa=bbb&other=value'\n    >>> make_url(\"https://host/api\")\n    'https://host/api'\n    >>> make_url(\"https://host/api/\")\n    'https://host/api/'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\")\n    'https://host/api/users/user-name/projects'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects/\")\n    'https://host/api/users/user-name/projects/'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\", 12345)\n    'https://host/api/users/user-name/projects/12345'\n    >>> make_url(\"https://host/api\", \"users\", \"user-name\", \"projects\", 12345, \"/\")\n    'https://host/api/users/user-name/projects/12345/'\n    \"\"\"\n    if len(args) == 1 and len(kwargs) == 0:\n        # Return a single string unaltered\n        return args[0]\n\n    temp_args = unpack_args(*args)\n    temp_arg_count = len(temp_args)\n\n    # Handle list of tuples as last of array arguments\n    if temp_arg_count > 1 and isinstance(temp_args[-1], list):\n        path_fragments = temp_args[0 : -1]\n        query_string = urllib.urlencode(temp_args[-1] + kwargs.items())\n    elif temp_arg_count > 1 and isinstance(temp_args[-1], dict):\n        path_fragments = temp_args[0 : -1]\n        query_string = urllib.urlencode(temp_args[-1].items() + kwargs.items())\n    else:\n        path_fragments = temp_args\n        query_string = urllib.urlencode(kwargs)\n\n    path_fragments = map(str, path_fragments)\n    has_trailing_slash = path_fragments[-1].endswith(\"/\")\n    path_fragments = filter(lambda f: len(f) > 0, map(lambda f: f.strip(\"/\"), path_fragments))\n    base_url = \"/\".join(path_fragments)\n\n    if has_trailing_slash:\n        base_url += \"/\"\n\n    parts = list(urlparse.urlparse(base_url))\n    parts[4] = query_string\n    return urlparse.urlunparse(parts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns true if user can cloak as other_user", "response": "def can_cloak_as(user, other_user):\n    \"\"\"\n    Returns true if `user` can cloak as `other_user`\n    \"\"\"\n    # check to see if the user is allowed to do this\n    can_cloak = False\n    try:\n        can_cloak = user.can_cloak_as(other_user)\n    except AttributeError as e:\n        try:\n            can_cloak = user.is_staff\n        except AttributeError as e:\n            pass\n\n    return can_cloak"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_project(self, name):\n        uri = '{base}/{project}'.format(base=self.BASE_URI, project=name)\n        resp = self._client.get(uri, model=models.Project)\n\n        return resp", "response": "Retetrives project information by name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bugs(self, project, status=None):\n        uri = '{base}/{project}'.format(base=self.BASE_URI, project=project)\n        parameters = {'ws.op': 'searchTasks'}\n\n        if status:\n            parameters['status'] = status\n\n        resp = self._client.get(uri, model=models.Bug, is_collection=True,\n                                params=parameters)\n\n        return resp", "response": "Retreives a List of bugs for a given project."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves a single bug by its Launchpad id.", "response": "def get_bug_by_id(self, bug_id):\n        \"\"\" Retrieves a single bug by it's Launchpad bug_id\n\n            :param bug_id: The Launchpad id for the bug.\n        \"\"\"\n        uri = '{base}/bugs/{bug_id}'.format(base=self.BASE_URI, bug_id=bug_id)\n        resp = self._client.get(uri, model=models.Bug)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef retrieve(cat_name, mw_instance='https://en.wikipedia.org', types=['page', 'subcat', 'file'], clean_subcat_names=False):\n    cmtype = f'&cmtype={\"|\".join(types)}'\n    base_url = f'{mw_instance}/w/api.php?action=query&format=json&list=categorymembers&cmtitle={cat_name}&cmlimit=500{cmtype}'\n    cont = ''\n\n    result = []\n\n    while True:\n        url = f'{base_url}&cmcontinue={cont}'\n        r = requests.get(url, timeout=30)\n        r.raise_for_status()\n        r_json = r.json()\n\n        if 'query' in r_json:\n            for item in r_json['query']['categorymembers']:\n                title = item['title']\n                if clean_subcat_names and ':' in title:\n                    # cut away ':' and evertyhing before\n                    index_sep = title.index(':')\n                    title = title[index_sep + 1:]\n                # spaces need to be converted in links\n                link = f'{mw_instance}/wiki/{title.replace(\" \", \"_\")}'\n                result.append({'name': title, 'link': link})\n\n        if 'continue' not in r_json:\n            break\n        else:\n            cont = r_json['continue']['cmcontinue']\n\n    return result", "response": "Retrieve pages that belong to a given category."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransitions to a non - standard state", "response": "def transition(prior_state, next_state):\n    \"\"\"\n    Transitions to a non-standard state\n\n    Raises InvalidStateTransition if next_state is not allowed.\n\n    :param prior_state: <str>\n    :param next_state: <str>\n    :return: <str>\n    \"\"\"\n    if next_state not in STATES[prior_state][TRANSITION]:\n        acceptable = STATES[prior_state][TRANSITION]\n        err = \"cannot {}->{} may only {}->{}\".format(prior_state,\n                                                     next_state,\n                                                     prior_state,\n                                                     acceptable)\n        raise InvalidStateTransition(err)\n    return next_state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, filename):\n        params = {\n            \"v\": 'dreambox',\n            \"kolejka\": \"false\",\n\n            \"nick\": \"\",\n            \"pass\": \"\",\n\n            \"napios\": sys.platform,\n            \"l\": self.language.upper(),\n\n            \"f\": self.prepareHash(filename),\n        }\n        params['t'] = self.discombobulate(params['f'])\n\n        url = self.url_base + urllib.urlencode(params)\n\n        subs = urllib.urlopen(url).read()\n\n        if subs.startswith('brak pliku tymczasowego'):\n            raise NapiprojektException('napiprojekt.pl API error')\n\n        if subs[0:4] != 'NPc0':\n            # napiprojekt keeps subtitles in cp1250\n            # ... but, sometimes they are in utf8\n            for cdc in ['cp1250', 'utf8']:\n                try:\n                    return codecs.decode(subs, cdc)\n                except:\n                    pass", "response": "returns subtitles as string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares napiprojekt scrambled hash", "response": "def discombobulate(self, filehash):\n        \"\"\" prepare napiprojekt scrambled hash \"\"\"\n\n        idx = [0xe, 0x3, 0x6, 0x8, 0x2]\n        mul = [2, 2, 5, 4, 3]\n        add = [0, 0xd, 0x10, 0xb, 0x5]\n\n        b = []\n        for i in xrange(len(idx)):\n            a = add[i]\n            m = mul[i]\n            i = idx[i]\n\n            t = a + int(filehash[i], 16)\n            v = int(filehash[t:t + 2], 16)\n            b.append((\"%x\" % (v * m))[-1])\n\n        return ''.join(b)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exists(self):\n        t = self.wait_timeout\n        self.wait_timeout = 0\n        try:\n            self.reload()\n            return True\n        except NoSuchElementException:\n            return False\n        finally:\n            self.wait_timeout = t", "response": "Checks if the element exists in the DOM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_displayed(self):\n        t = self.wait_timeout\n        self.wait_timeout = 0\n        try:\n            return super(PageElement, self).is_displayed()\n        except NoSuchElementException:\n            return False\n        finally:\n            self.wait_timeout = t", "response": "Return True if the element is displayed otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True id at least one element is displayed otherwise False.", "response": "def is_displayed(self):\n        \"\"\"\n        :return: True id at least one element is displayed, otherwise False.\n                Ignore implicit and element timeouts and execute immediately.\n        \"\"\"\n        t = self.wait_timeout\n        self.wait_timeout = 0\n        try:\n            self.reload()\n            return any(e.is_displayed() for e in self)\n        finally:\n            self.wait_timeout = t"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes sure that given user has an email associated with their account", "response": "def user_has_email(username):\n    \"\"\" make sure, that given user has an email associated \"\"\"\n    user = api.user.get(username=username)\n    if not user.getProperty(\"email\"):\n        msg = _(\n            \"This user doesn't have an email associated \"\n            \"with their account.\"\n        )\n        raise Invalid(msg)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef workspaces_provider(context):\n    catalog = api.portal.get_tool(name=\"portal_catalog\")\n    workspaces = catalog(portal_type=\"ploneintranet.workspace.workspacefolder\")\n    current = api.content.get_uuid(context)\n\n    terms = []\n    for ws in workspaces:\n        if current != ws[\"UID\"]:\n            terms.append(SimpleVocabulary.createTerm(\n                ws[\"UID\"], ws[\"UID\"], ws[\"Title\"]))\n\n    return SimpleVocabulary(terms)", "response": "create a vocab of all workspaces in this site"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef live_weather(self, live_weather):\n        summary = live_weather['currently']['summary']\n        self.summary(summary)\n        click.echo()", "response": "Prints the live weather in a pretty format"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the ASCII Icon", "response": "def summary(self, summary):\n        \"\"\"Prints the ASCII Icon\"\"\"\n        if summary is not None:\n            if summary == 'Clear':\n                click.secho(\"\"\"\n\n   ________                    \\  |  /\n  / ____/ /__  ____ ______       .-.\n / /   / / _ \\/ __ `/ ___/    \u2012 (   ) \u2012\n/ /___/ /  __/ /_/ / /           `-\u1fbf\n\\____/_/\\___/\\__,_/_/          /  |  \\\\\n\n                \"\"\", fg=self.colors.YELLOW)\n                click.echo()\n\n            elif summary == 'Partly Cloudy':\n                click.secho(\"\"\"\n\n    ____             __  __         ________                __\n   / __ \\____ ______/ /_/ /_  __   / ____/ /___  __  ______/ /_  __    \\  |  /\n  / /_/ / __ `/ ___/ __/ / / / /  / /   / / __ \\/ / / / __  / / / /      .-.\n / ____/ /_/ / /  / /_/ / /_/ /  / /___/ / /_/ / /_/ / /_/ / /_/ /    \u2012 (  .-.\n/_/    \\__,_/_/   \\__/_/\\__, /   \\____/_/\\____/\\__,_/\\__,_/\\__, /        `(   ).\n                       /____/                             /____/       / (___(__)\n\n                \"\"\", fg=self.colors.WHITE)\n\n            elif summary == 'Flurries':\n                click.secho(\"\"\"\n\n    ________                _                  .--.\n   / ____/ /_  ____________(_)__  _____     .-(    ).\n  / /_  / / / / / ___/ ___/ / _ \\/ ___/    (___.__)__)\n / __/ / / /_/ / /  / /  / /  __(__  )      *      *\n/_/   /_/\\__,_/_/  /_/  /_/\\___/____/          *\n\n                \"\"\", fg=self.colors.BLUE)\n                click.echo()\n\n            elif summary == 'Overcast' or summary == 'Mostly Cloudy':\n                click.secho(\"\"\"\n\n   ____                                  __\n  / __ \\_   _____  ______________ ______/ /_       .--.\n / / / / | / / _ \\/ ___/ ___/ __ `/ ___/ __/     .(    ).-.\n/ /_/ /| |/ /  __/ /  / /__/ /_/ (__  ) /_      (___.__(   ).\n\\____/ |___/\\___/_/   \\___/\\__,_/____/\\__/            (___(__)\n\n                \"\"\", fg=self.colors.WHITE)\n                click.echo()\n\n            elif summary == 'Snow':\n                click.secho(\"\"\"\n\n   _____                            .--.\n  / ___/____  ____ _      __     .-(    ).\n  \\__ \\/ __ \\/ __ \\ | /| / /    (___.__)__)\n ___/ / / / / /_/ / |/ |/ /      *   *   *\n/____/_/ /_/\\____/|__/|__/         *   *\n\n                \"\"\", fg=self.colors.BLUE)\n                click.echo()\n\n            elif summary == 'Light Snow':\n                click.secho(\"\"\"\n\n    __    _       __    __    _____\n   / /   (_)___ _/ /_  / /_  / ___/____  ____ _      __       .--.\n  / /   / / __ `/ __ \\/ __/  \\__ \\/ __ \\/ __ \\ | /| / /    .-(    ).\n / /___/ / /_/ / / / / /_   ___/ / / / / /_/ / |/ |/ /    (___.__)__)\n/_____/_/\\__, /_/ /_/\\__/  /____/_/ /_/\\____/|__/|__/       *  *  *\n        /____/\n                \"\"\", fg=self.colors.BLUE)\n                click.echo()\n\n            elif summary == 'Light Rain' or summary == 'Drizzle':\n                click.secho(\"\"\"\n\n    __    _       __    __     ____        _\n   / /   (_)___ _/ /_  / /_   / __ \\____ _(_)___       .--.\n  / /   / / __ `/ __ \\/ __/  / /_/ / __ `/ / __ \\   .-(    ).\n / /___/ / /_/ / / / / /_   / _, _/ /_/ / / / / /  (___.__)__)\n/_____/_/\\__, /_/ /_/\\__/  /_/ |_|\\__,_/_/_/ /_/     /  /  /\n        /____/\n\n                \"\"\", fg=self.colors.BLUE)\n\n            elif summary == 'Rain':\n                click.secho(\"\"\"\n\n    ____        _\n   / __ \\____ _(_)___       .--.\n  / /_/ / __ `/ / __ \\   .-(    ).\n / _, _/ /_/ / / / / /  (___.__)__)\n/_/ |_|\\__,_/_/_/ /_/     /  /  /\n\n                \"\"\", fg=self.colors.BLUE)\n\n            else:\n                click.secho(\"{:=^62}\".format(str(summary)), fg=self.colors.GREEN)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch a collection of all JSON files for a given service.", "response": "def get_available_options(self, service_name):\n        \"\"\"\n        Fetches a collection of all JSON files for a given service.\n\n        This checks user-created files (if present) as well as including the\n        default service files.\n\n        Example::\n\n            >>> loader.get_available_options('s3')\n            {\n                '2013-11-27': [\n                    '~/.boto-overrides/s3-2013-11-27.json',\n                    '/path/to/kotocore/data/aws/resources/s3-2013-11-27.json',\n                ],\n                '2010-10-06': [\n                    '/path/to/kotocore/data/aws/resources/s3-2010-10-06.json',\n                ],\n                '2007-09-15': [\n                    '~/.boto-overrides/s3-2007-09-15.json',\n                ],\n            }\n\n        :param service_name: The name of the desired service\n        :type service_name: string\n\n        :returns: A dictionary of api_version keys, with a list of filepaths\n            for that version (in preferential order).\n        :rtype: dict\n        \"\"\"\n        options = {}\n\n        for data_dir in self.data_dirs:\n            # Traverse all the directories trying to find the best match.\n            service_glob = \"{0}-*.json\".format(service_name)\n            path = os.path.join(data_dir, service_glob)\n            found = glob.glob(path)\n\n            for match in found:\n                # Rip apart the path to determine the API version.\n                base = os.path.basename(match)\n                bits = os.path.splitext(base)[0].split('-', 1)\n\n                if len(bits) < 2:\n                    continue\n\n                api_version = bits[1]\n                options.setdefault(api_version, [])\n                options[api_version].append(match)\n\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a collection of possible service options returns the full path to the best matching JSON file.", "response": "def get_best_match(self, options, service_name, api_version=None):\n        \"\"\"\n        Given a collection of possible service options, selects the best match.\n\n        If no API version is provided, the path to the most recent API version\n        will be returned. If an API version is provided & there is an exact\n        match, the path to that version will be returned. If there is no exact\n        match, an attempt will be made to find a compatible (earlier) version.\n\n        In all cases, user-created files (if present) will be given preference\n        over the default included versions.\n\n        :param options: A dictionary of options. See\n            ``.get_available_options(...)``.\n        :type options: dict\n\n        :param service_name: The name of the desired service\n        :type service_name: string\n\n        :param api_version: (Optional) The desired API version to load\n        :type service_name: string\n\n        :returns: The full path to the best matching JSON file\n        \"\"\"\n        if not options:\n            msg = \"No JSON files provided. Please check your \" + \\\n                  \"configuration/install.\"\n            raise NoResourceJSONFound(msg)\n\n        if api_version is None:\n            # Give them the very latest option.\n            best_version = max(options.keys())\n            return options[best_version][0], best_version\n\n        # They've provided an api_version. Try to give them exactly what they\n        # requested, falling back to the best compatible match if no exact\n        # match can be found.\n        if api_version in options:\n            return options[api_version][0], api_version\n\n        # Find the best compatible match. Run through in descending order.\n        # When we find a version that's lexographically less than the provided\n        # one, run with it.\n        for key in sorted(options.keys(), reverse=True):\n            if key <= api_version:\n                return options[key][0], key\n\n        raise NoResourceJSONFound(\n            \"No compatible JSON could be loaded for {0} ({1}).\".format(\n                service_name,\n                api_version\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, service_name, api_version=None, cached=True):\n        # Fetch from the cache first if it's there.\n        if cached:\n            if service_name in self._loaded_data:\n                if api_version in self._loaded_data[service_name]:\n                    return self._loaded_data[service_name][api_version]\n\n        data = {}\n        options = self.get_available_options(service_name)\n        match, version = self.get_best_match(\n            options,\n            service_name,\n            api_version=api_version\n        )\n\n        with open(match, 'r') as json_file:\n            data = json.load(json_file)\n            # Embed where we found it from for debugging purposes.\n            data['__file__'] = match\n            data['api_version'] = version\n\n        if cached:\n            self._loaded_data.setdefault(service_name, {})\n            self._loaded_data[service_name][api_version] = data\n\n        return data", "response": "Loads the JSON for a service."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering the arguments for command - line invocation.", "response": "def render_args(arglst, argdct):\n    '''Render arguments for command-line invocation.\n\n    arglst: A list of Argument objects (specifies order)\n    argdct: A mapping of argument names to values (specifies rendered values)\n    '''\n    out = ''\n    \n    for arg in arglst:\n        if arg.name in argdct:\n            rendered = arg.render(argdct[arg.name])\n            if rendered:\n                out += ' '\n                out += rendered\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(argv):\n    input_file = \"\"\n    output_file = \"\"\n    monitor = None\n    formula = None\n    trace = None\n    iformula = None\n    itrace = None\n    isys = None\n    online = False\n    fuzzer = False\n    l2m = False\n    debug = False\n    rounds = 1\n    server_port = 8080\n    webservice = False\n\n    help_str_extended = \"fodtlmon V 0.1 .\\n\" + \\\n                        \"For more information see fodtlmon home page\\n Usage : mon.py [OPTIONS] formula trace\" + \\\n                        \"\\n  -h \\t--help          \" + \"\\t display this help and exit\" + \\\n                        \"\\n  -i \\t--input= [file] \" + \"\\t the input file\" + \\\n                        \"\\n  -o \\t--output= [path]\" + \"\\t the output file\" + \\\n                        \"\\n  -f \\t--formula       \" + \"\\t the formula\" + \\\n                        \"\\n     \\t--iformula      \" + \"\\t path to file that contains the formula\" + \\\n                        \"\\n  -t \\t--trace         \" + \"\\t the trace\" + \\\n                        \"\\n     \\t--itrace        \" + \"\\t path to file that contains the trace\" + \\\n                        \"\\n  -1 \\t--ltl           \" + \"\\t use LTL monitor\" + \\\n                        \"\\n     \\t--l2m           \" + \"\\t call ltl2mon also\" + \\\n                        \"\\n  -2 \\t--fotl          \" + \"\\t use FOTL monitor\" + \\\n                        \"\\n  -3 \\t--dtl           \" + \"\\t use DTL monitor\" + \\\n                        \"\\n  -4 \\t--fodtl         \" + \"\\t use FODTL monitor\" + \\\n                        \"\\n     \\t--sys= [file]   \" + \"\\t Run a system from json file\" + \\\n                        \"\\n     \\t--rounds= int   \" + \"\\t Number of rounds to run in the system\" + \\\n                        \"\\n  -z \\t--fuzzer        \" + \"\\t run fuzzing tester\" + \\\n                        \"\\n  -d \\t--debug         \" + \"\\t enable debug mode\" + \\\n                        \"\\n     \\t--server        \" + \"\\t start web service\" + \\\n                        \"\\n     \\t--port= int     \" + \"\\t server port number\" + \\\n                        \"\\n\\nReport fodtlmon bugs to walid.benghabrit@mines-nantes.fr\" + \\\n                        \"\\nfodtlmon home page: <https://github.com/hkff/fodtlmon>\" + \\\n                        \"\\nfodtlmon is a free software released under GPL 3\"\n\n    # Checking options\n    try:\n        opts, args = getopt.getopt(argv[1:], \"hi:o:f:t:1234zd\",\n                                   [\"help\", \"input=\", \"output=\", \"trace=\", \"formula=\" \"ltl\", \"fotl\", \"dtl\",\n                                    \"fodtl\", \"sys=\", \"fuzzer\", \"itrace=\", \"iformula=\", \"rounds=\", \"l2m\", \"debug\",\n                                    \"server\", \"port=\"])\n    except getopt.GetoptError:\n        print(help_str_extended)\n        sys.exit(2)\n\n    if len(opts) == 0:\n        print(help_str_extended)\n\n    # Handling options\n    for opt, arg in opts:\n        if opt in (\"-h\", \"--help\"):\n            print(help_str_extended)\n            sys.exit()\n        elif opt in (\"-i\", \"--input\"):\n            input_file = arg\n        elif opt in (\"-o\", \"--output\"):\n            output_file = arg\n        elif opt in (\"-1\", \"--ltl\"):\n            monitor = Ltlmon\n        elif opt in (\"-2\", \"--fotl\"):\n            monitor = Fotlmon\n        elif opt in (\"-3\", \"--dtl\"):\n            monitor = Dtlmon\n        elif opt in (\"-4\", \"--fodtl\"):\n            monitor = Fodtlmon\n        elif opt in (\"-f\", \"--formula\"):\n            formula = arg\n        elif opt in (\"-t\", \"--trace\"):\n            trace = arg\n        elif opt in \"--sys\":\n            isys = arg\n        elif opt in \"--rounds\":\n            rounds = int(arg)\n        elif opt in (\"-z\", \"--fuzzer\"):\n            fuzzer = True\n        elif opt in \"--iformula\":\n            iformula = arg\n        elif opt in \"--itrace\":\n            itrace = arg\n        elif opt in \"--l2m\":\n            l2m = True\n        elif opt in (\"-d\", \"--debug\"):\n            debug = True\n        elif opt in \"--server\":\n            webservice = True\n        elif opt in \"--port\":\n            server_port = int(arg)\n\n    if webservice:\n        Webservice.start(server_port)\n        return\n\n    if fuzzer:\n        if monitor is Ltlmon:\n            run_ltl_tests(monitor=\"ltl\", alphabet=[\"P\"], constants=[\"a\", \"b\", \"c\"], trace_lenght=10000, formula_depth=5,\n                          formula_nbr=10000, debug=debug)\n        elif monitor is Dtlmon:\n            run_dtl_tests()\n        return\n\n    if itrace is not None:\n        with open(itrace, \"r\") as f:\n            trace = f.read()\n\n    if iformula is not None:\n        with open(iformula, \"r\") as f:\n            formula = f.read()\n\n    if isys is not None:\n        with open(isys, \"r\") as f:\n            js = f.read()\n            s = System.parseJSON(js)\n            for x in range(rounds):\n                s.run()\n        return\n\n    # print(argv)\n    if None not in (monitor, trace, formula):\n        tr = Trace().parse(trace)\n        fl = eval(formula[1:]) if formula.startswith(\":\") else FodtlParser.parse(formula)\n        mon = monitor(fl, tr)\n        res = mon.monitor(debug=debug)\n        print(\"\")\n        print(\"Trace        : %s\" % tr)\n        print(\"Formula      : %s\" % fl)\n        print(\"Code         : %s\" % fl.toCODE())\n        print(\"PPrint       : %s\" % fl.prefix_print())\n        print(\"TSPASS       : %s\" % fl.toTSPASS())\n        print(\"LTLFO        : %s\" % fl.toLTLFO())\n        print(\"Result       : %s\" % res)\n        if l2m:\n            print(fl.toLTLFO())\n            res = ltlfo2mon(fl.toLTLFO(), tr.toLTLFO())\n            print(\"ltl2mon : %s\" % res)", "response": "Main function for the main mon. py script."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of network interfaces info with this format", "response": "def getifaddrs():\n    \"\"\"\n    Return a list of network interfaces info, with this format:\n\n    {\n        'interface_name':\n            {\n                'ipv6': [{'scope': 5L,\n                          'netmask': 'ffff:ffff:ffff:ffff::',\n                          'addr': 'fe80::34f2:7dff:fe69:7c18'}],\n                'hw': [{'addr': '36:f2:7d:69:7c:18'}],\n                'ipv4': [{'netmask': '255.255.255.0', 'addr': '10.0.3.1'}]},\n            },\n        ...\n    }\n    \"\"\"\n    class ifa_ifu_u(Union):\n        _fields_ = [\n            (\"ifu_broadaddr\", c_void_p),\n            (\"ifu_dstaddr\", c_void_p)\n        ]\n\n    class ifaddrs(Structure):\n        _fields_ = [\n            (\"ifa_next\", c_void_p),\n            (\"ifa_name\", c_char_p),\n            (\"ifa_flags\", c_uint),\n            (\"ifa_addr\", c_void_p),\n            (\"ifa_netmask\", c_void_p),\n            (\"ifa_ifu\", ifa_ifu_u),\n            (\"ifa_data\", c_void_p)\n        ]\n\n    # AF_UNKNOWN / generic\n    if platform.startswith(\"darwin\") or platform.startswith(\"freebsd\"):\n        class sockaddr(Structure):\n            _fields_ = [\n                (\"sa_len\", c_uint8),\n                (\"sa_family\", c_uint8),\n                (\"sa_data\", c_uint8 * 14)\n            ]\n    else:\n        class sockaddr(Structure):\n            _fields_ = [\n                (\"sa_family\", c_uint16),\n                (\"sa_data\", c_uint8 * 14)\n            ]\n\n    # AF_INET / IPv4\n    class in_addr(Union):\n        _fields_ = [\n            (\"s_addr\", c_uint32),\n        ]\n\n    class sockaddr_in(Structure):\n        _fields_ = [\n            (\"sin_family\", c_short),\n            (\"sin_port\", c_ushort),\n            (\"sin_addr\", in_addr),\n            (\"sin_zero\", c_char * 8),  # padding\n        ]\n\n    # AF_INET6 / IPv6\n    class in6_u(Union):\n        _fields_ = [\n            (\"u6_addr8\", c_uint8 * 16),\n            (\"u6_addr16\", c_uint16 * 8),\n            (\"u6_addr32\", c_uint32 * 4)\n        ]\n\n    class in6_addr(Union):\n        _fields_ = [\n            (\"in6_u\", in6_u),\n        ]\n\n    class sockaddr_in6(Structure):\n        _fields_ = [\n            (\"sin6_family\", c_short),\n            (\"sin6_port\", c_ushort),\n            (\"sin6_flowinfo\", c_uint32),\n            (\"sin6_addr\", in6_addr),\n            (\"sin6_scope_id\", c_uint32),\n        ]\n\n    # AF_PACKET / Linux\n    class sockaddr_ll(Structure):\n        _fields_ = [\n            (\"sll_family\", c_uint16),\n            (\"sll_protocol\", c_uint16),\n            (\"sll_ifindex\", c_uint32),\n            (\"sll_hatype\", c_uint16),\n            (\"sll_pktype\", c_uint8),\n            (\"sll_halen\", c_uint8),\n            (\"sll_addr\", c_uint8 * 8)\n        ]\n\n    # AF_LINK / BSD|OSX\n    class sockaddr_dl(Structure):\n        _fields_ = [\n            (\"sdl_len\", c_uint8),\n            (\"sdl_family\", c_uint8),\n            (\"sdl_index\", c_uint16),\n            (\"sdl_type\", c_uint8),\n            (\"sdl_nlen\", c_uint8),\n            (\"sdl_alen\", c_uint8),\n            (\"sdl_slen\", c_uint8),\n            (\"sdl_data\", c_uint8 * 46)\n        ]\n\n    families = {\n        AF_INET: 'ipv4',\n        AF_INET6: 'ipv6',\n        AF_PACKET: 'hw'\n    }\n\n    libc = CDLL(\"libc.so.6\")\n    ptr = c_void_p(None)\n    result = libc.getifaddrs(pointer(ptr))\n    if result:\n        return None\n    ifa = ifaddrs.from_address(ptr.value)\n    result = {}\n\n    while ifa:\n        name = ifa.ifa_name\n#       name = ifa.ifa_name.decode('UTF-8') # use this for python3\n\n        if name not in result:\n            result[name] = {}\n\n        sa = sockaddr.from_address(ifa.ifa_addr)\n\n        if sa.sa_family not in result[name]:\n            result[name][families[sa.sa_family]] = []\n\n        data = {}\n\n        if sa.sa_family == AF_INET:\n            if ifa.ifa_addr is not None:\n                si = sockaddr_in.from_address(ifa.ifa_addr)\n                data['addr'] = inet_ntop(si.sin_family, si.sin_addr)\n            if ifa.ifa_netmask is not None:\n                si = sockaddr_in.from_address(ifa.ifa_netmask)\n                data['netmask'] = inet_ntop(si.sin_family, si.sin_addr)\n\n        if sa.sa_family == AF_INET6:\n            if ifa.ifa_addr is not None:\n                si = sockaddr_in6.from_address(ifa.ifa_addr)\n                data['addr'] = inet_ntop(si.sin6_family, si.sin6_addr)\n                if data['addr'].startswith('fe80:'):\n                    data['scope'] = si.sin6_scope_id\n            if ifa.ifa_netmask is not None:\n                si = sockaddr_in6.from_address(ifa.ifa_netmask)\n                data['netmask'] = inet_ntop(si.sin6_family, si.sin6_addr)\n\n        if sa.sa_family == AF_PACKET:\n            if ifa.ifa_addr is not None:\n                si = sockaddr_ll.from_address(ifa.ifa_addr)\n                addr = \"\"\n                for i in range(si.sll_halen):\n                    addr += \"%02x:\" % si.sll_addr[i]\n                addr = addr[:-1]\n                data['addr'] = addr\n\n        if len(data) > 0:\n            result[name][families[sa.sa_family]].append(data)\n\n        if ifa.ifa_next:\n            ifa = ifaddrs.from_address(ifa.ifa_next)\n        else:\n            break\n\n    libc.freeifaddrs(ptr)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the webhook URL for posting webhook data to the specified data source.", "response": "def get_webhook_url(deployment_name,\n                    space='default',\n                    data_source='webhook',\n                    token_manager=None,\n                    app_url=defaults.APP_URL,\n                    **fields):\n    \"\"\"\n    return the webhook URL for posting webhook data to\n\n    \"\"\"\n\n    import_url = data_engine.get_import_data_url(deployment_name,\n                                                 app_url=app_url,\n                                                 token_manager=token_manager)\n\n    api_key = deployments.get_apikey(deployment_name,\n                                     token_manager=token_manager,\n                                     app_url=app_url)\n\n    fields_string = '&'.join(['%s=%s' % (key, value)\n                              for (key, value) in fields.items()])\n    return '%s/api/v1/import/webhook/?space=%s&data_source=%sk&apikey=%s&%s' % \\\n           (import_url, space, data_source, api_key, fields_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntruncates HTML string preserving tag structure and character entities.", "response": "def truncatehtml(string, length, ellipsis='...'):\n    \"\"\"Truncate HTML string, preserving tag structure and character entities.\"\"\"\n    length = int(length)\n    output_length = 0\n    i = 0\n    pending_close_tags = {}\n    \n    while output_length < length and i < len(string):\n        c = string[i]\n\n        if c == '<':\n            # probably some kind of tag\n            if i in pending_close_tags:\n                # just pop and skip if it's closing tag we already knew about\n                i += len(pending_close_tags.pop(i))\n            else:\n                # else maybe add tag\n                i += 1\n                match = tag_end_re.match(string[i:])\n                if match:\n                    tag = match.groups()[0]\n                    i += match.end()\n  \n                    # save the end tag for possible later use if there is one\n                    match = re.search(r'(</' + tag + '[^>]*>)', string[i:], re.IGNORECASE)\n                    if match:\n                        pending_close_tags[i + match.start()] = match.groups()[0]\n                else:\n                    output_length += 1 # some kind of garbage, but count it in\n                    \n        elif c == '&':\n            # possible character entity, we need to skip it\n            i += 1\n            match = entity_end_re.match(string[i:])\n            if match:\n                i += match.end()\n\n            # this is either a weird character or just '&', both count as 1\n            output_length += 1\n        else:\n            # plain old characters\n            \n            skip_to = string.find('<', i, i + length)\n            if skip_to == -1:\n                skip_to = string.find('&', i, i + length)\n            if skip_to == -1:\n                skip_to = i + length\n                \n            # clamp\n            delta = min(skip_to - i,\n                        length - output_length,\n                        len(string) - i)\n\n            output_length += delta\n            i += delta\n                        \n    output = [string[:i]]\n    if output_length == length:\n        output.append(ellipsis)\n\n    for k in sorted(pending_close_tags.keys()):\n        output.append(pending_close_tags[k])\n\n    return \"\".join(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all regions with no gateless regions from a list of regions.", "response": "def remove_regions_with_no_gates(regions):\n    \"\"\" Removes all Jove regions from a list of regions.\n\n    :param regions: A list of tuples (regionID, regionName)\n    :type regions: list\n\n    :return: A list of regions minus those in jove space\n    :rtype: list\n    \"\"\"\n\n    list_of_gateless_regions = [\n        (10000004, 'UUA-F4'),\n        (10000017, 'J7HZ-F'),\n        (10000019, 'A821-A'),\n    ]\n\n    for gateless_region in list_of_gateless_regions:\n        if gateless_region in regions:\n            regions.remove(gateless_region)\n\n    return regions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dict_if(self, *args):\n        call_args = list(args)\n        do_cond = call_args.pop(0)\n        do_if = call_args.pop(0)\n        do_else = ''\n\n        if len(call_args):\n            do_else = call_args.pop()\n        return do_if if self.truth(do_cond) else do_else", "response": "Returns the arguments in the list joined by STR.\n            IF = CONDITION DO = IF ELSE = IF"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _dict_repeat(self, *args):\n        call_args = list(args)\n        do_count = call_args.pop(0)\n        do_thing = call_args.pop(0)\n        do_out = []\n\n        for i in range(int(do_count)):\n            do_out.append(do_thing())\n        return ''.join(do_out)", "response": "Return a dictionary of do_count times with do_thing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef istrue(self, *args):\n        def is_true(val):\n            if val is True:\n                return True\n            val = str(val).lower().strip()\n            return val in ('true', 'yes', '1')\n        return all(self._arg_factory(is_true, args))", "response": "Strict test for true value test."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef types(self, *args):\n        return ', '.join(['{0}({1})'.format(type(arg).__name__, arg) for arg in args])", "response": "Used for debugging returns type of each arg.\n            TYPES ARG_1 ARG_N\n           ... ARG_N\n           ... ARG_N\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shuffle(self, *args):\n        call_args = list(args)\n        self.random.shuffle(call_args)\n        return ''.join(call_args)", "response": "Shuffles all arguments and returns them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ipglob(self, *args):\n        call_args = list(args)\n        return self.random.choice(IPGlob(call_args.pop(0)))", "response": "Returns a random address from within the given ip global\n            IPGLOB : GLOB\n        IPGLOB : GLOB\n        IPGLOB : GLOB\n        IPGLOB : GLOB\n        IPGLOB : GLOB\n        IPGLOB : *..*.*"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a random address from within the given range of two addresses IPRANGE start end - > ''", "response": "def iprange(self, *args):\n        \"\"\"Returns a random address from within the given range of two addresses\n            IPRANGE:start,end\n\n        %{IPRANGE:10.0.0.0/8,} -> ''\n        \"\"\"\n        call_args = list(args)\n        return self.random.choice(IPRange(call_args.pop(0), call_args.pop(0)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ipcidr(self, *args):\n        call_args = list(args)\n        return self.random.choice(IPNetwork(call_args.pop(0)))", "response": "Returns a random ip from within the given cidr notation\n            IPCIDR : cidr - > ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random int between - sys. maxint and sys. maxint", "response": "def int(self, *args):\n        \"\"\"Returns a random int between -sys.maxint and sys.maxint\n            INT\n\n        %{INT} -> '1245123'\n        %{INT:10} -> '10000000'\n        %{INT:10,20} -> '19'\n        \"\"\"\n        return self.random.randint(*self._arg_defaults(args, [-sys.maxint, sys.maxint], int))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge a configuration in file with current configuration", "response": "def merge_conf_file(self, result, conf_file_path):\n        \"Merge a configuration in file with current configuration\"\n        conf = parse_conf_file(conf_file_path)\n        conf_file_name = os.path.splitext(os.path.basename(conf_file_path))[0]\n        result_part = result\n\n        if not conf_file_name in File.TOP_LEVEL_CONF_FILES \\\n            and (\n                not \"top_level\" in self._options\n                or not self._options[\"top_level\"]):\n            for key_part in conf_file_name.split('.'):\n                if not key_part in result_part:\n                    result_part[key_part] = {}\n                result_part = result_part[key_part]\n\n        return merge_conf(result_part, conf)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction wrapper to signalize that a login is required.", "response": "def require_login(func):\n    \"\"\"\n    Function wrapper to signalize that a login is required.\n    \"\"\"\n\n    @wraps(func)\n    def decorated(*args, **kwargs):\n        auth = request.authorization\n        if not auth:\n            return authenticate()\n\n        user = session.query(User).filter(\n            User.name == auth.username\n        ).first()\n        if user and user.check(auth.password):\n            g.user = user\n            return func(*args, **kwargs)\n        else:\n            return authenticate()\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef require_admin(func):\n\n    @wraps(func)\n    @require_login\n    def decorated(*args, **kwargs):\n        user = current_user()\n        if user and user.is_admin:\n            return func(*args, **kwargs)\n        else:\n            return Response(\n                'Forbidden', 403\n            )\n\n    return decorated", "response": "Decorator that requires admin user to access this resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_change_mode(text,change):\r\n  \"returns 'add' 'delete' or 'internal'. see comments to update_changes for more details.\"\r\n  # warning: some wacky diff logic (in python, probably in JS too) is making some adds / deletes look like replacements (see notes at bottom of diff.py)\r\n  if len(change.deltas)>1: return 'internal'\r\n  # todo below: why are blank deltas getting sent? is it a new seg thing? I'm picking 'add' because it has to be in some category and add is most likely next if this is a new seg.\r\n  elif not change.deltas: return 'add'\r\n  delta,=change.deltas # intentional crash if len(deltas)!=1\r\n  if delta.a==delta.b and delta.a==len(text): return 'add'\r\n  elif delta.b==len(text) and len(delta.text)==0: return 'delete'\r\n  else: return 'internal'", "response": "returns add delete or internal. see comments to update_changes for more details."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a Change diffing the two strings", "response": "def mkchange(text0,text1,version,mtime):\r\n  \"return a Change diffing the two strings\"\r\n  return Change(version,mtime,ucrc(text1),diff.word_diff(text0,text1))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_changes(changes,newtext,change):\r\n  \"decide whether to compact the newest change into the old last; return new change list. assumes changes is safe to mutate.\\\r\n  note: newtext MUST be the result of applying change to changes, and is only passed to save doing the computation again.\"\r\n  # the criteria for a new version are:\r\n  # 1. mode change (modes are adding to end, deleting from end, internal edits)\r\n  # 2. length changed by more than 256 chars (why power of 2? why not)\r\n  # 3. time delta > COMPACTION_TIME_THRESH\r\n  if not changes: return [change] # todo(awinter): needs test case\r\n  if change.utc-changes[-1].utc>COMPACTION_TIME_THRESH:\r\n    changes.append(change)\r\n    return changes\r\n  base=reduce(apply_change,changes[:-1],'')\r\n  final=apply_change(base,changes[-1])\r\n  prev_mode=detect_change_mode(base,changes[-1])\r\n  cur_mode=detect_change_mode(final,change)\r\n  if prev_mode==cur_mode and abs(len(newtext)-len(final)<COMPACTION_LEN_THRESH):\r\n    changes[-1]=mkchange(base,newtext,change.version,change.utc)\r\n  else: changes.append(change)\r\n  return changes", "response": "decide whether to compact the newest change into the old last ; return new change list. assumes changes is safe to mutate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_splice(a,splice):\r\n  \"mutate a *and* return it. a as list, splice as diff.Delta.\"\r\n  a[splice.a:splice.b]=splice.text # text isn't always text. See diff comments.\r\n  return a", "response": "mutate a and return it. a as list splice as diff. Delta."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pkeys(self,parent,field):\r\n    \"returns a list of pkey tuples by combining parent[field] with our attrs\"\r\n    template=[(parent[k] if k is not None else None) for k in self.pkey]\r\n    inull=template.index(None)\r\n    def mk(x):\r\n      \"helper for constructing pkey tuples in a list comp\"\r\n      template[inull]=x\r\n      return tuple(template)\r\n    val=parent[field]\r\n    if self.getter is not None: return map(mk,self.getter(val))\r\n    elif isinstance(val,VDList): return map(mk,val.generate())\r\n    else: raise NotImplementedError(type(val))", "response": "returns a list of pkey tuples by combining parent [ field with our attrs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_resources(client):\n    wildcard = Keys.DISPENSER.format('*')\n    pattern = re.compile(Keys.DISPENSER.format('(.*)'))\n    return [pattern.match(d).group(1)\n            for d in client.scan_iter(wildcard)]", "response": "Detect dispensers and return corresponding resources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfollow publications involved with resources.", "response": "def follow(resources, **kwargs):\n    \"\"\" Follow publications involved with resources. \"\"\"\n    # subscribe\n    client = redis.Redis(decode_responses=True, **kwargs)\n    resources = resources if resources else find_resources(client)\n    channels = [Keys.EXTERNAL.format(resource) for resource in resources]\n    if resources:\n        subscription = Subscription(client, *channels)\n\n    # listen\n    while resources:\n        try:\n            message = subscription.listen()\n            if message['type'] == 'message':\n                print(message['data'])\n        except KeyboardInterrupt:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlock resources from the command line for example for maintenance.", "response": "def lock(resources, *args, **kwargs):\n    \"\"\" Lock resources from the command line, for example for maintenance. \"\"\"\n    # all resources are locked if nothing is specified\n    if not resources:\n        client = redis.Redis(decode_responses=True, **kwargs)\n        resources = find_resources(client)\n\n    if not resources:\n        return\n\n    # create one process per pid\n    locker = Locker(**kwargs)\n    while len(resources) > 1:\n        pid = os.fork()\n        resources = resources[:1] if pid else resources[1:]\n\n    # at this point there is only one resource - lock it down\n    resource = resources[0]\n    try:\n        print('{}: acquiring'.format(resource))\n        with locker.lock(resource, label='lock tool'):\n            print('{}: locked'.format(resource))\n            try:\n                signal.pause()\n            except KeyboardInterrupt:\n                print('{}: released'.format(resource))\n    except KeyboardInterrupt:\n        print('{}: canceled'.format(resource))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets the sequence of resources in the cluster.", "response": "def reset(resources, *args, **kwargs):\n    \"\"\" Remove dispensers and indicators for idle resources. \"\"\"\n    test = kwargs.pop('test', False)\n    client = redis.Redis(decode_responses=True, **kwargs)\n    resources = resources if resources else find_resources(client)\n\n    for resource in resources:\n        # investigate sequences\n        queue = Queue(client=client, resource=resource)\n        values = client.mget(queue.keys.indicator, queue.keys.dispenser)\n        try:\n            indicator, dispenser = map(int, values)\n        except TypeError:\n            print('No such queue: \"{}\".'.format(resource))\n            continue\n\n        # do a bump if there appears to be a queue\n        if dispenser - indicator + 1:\n            queue.message('Reset tool bumps.')\n            indicator = queue.bump()\n\n        # do not reset when there is still a queue\n        size = dispenser - indicator + 1\n        if size:\n            print('\"{}\" is in use by {} user(s).'.format(resource, size))\n            continue\n\n        # reset, except when someone is incoming\n        with client.pipeline() as pipe:\n            try:\n                pipe.watch(queue.keys.dispenser)\n                if test:\n                    time.sleep(0.02)\n                pipe.multi()\n                pipe.delete(queue.keys.dispenser, queue.keys.indicator)\n                pipe.execute()\n            except redis.WatchError:\n                print('Activity detected for \"{}\".'.format(resource))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status(resources, *args, **kwargs):\n    template = '{:<50}{:>10}'\n    client = redis.Redis(decode_responses=True, **kwargs)\n\n    # resource details\n    for loop, resource in enumerate(resources):\n        # blank between resources\n        if loop:\n            print()\n\n        # strings needed\n        keys = Keys(resource)\n        wildcard = keys.key('*')\n\n        # header\n        template = '{:<50}{:>10}'\n        indicator = client.get(keys.indicator)\n        if indicator is None:\n            continue\n        print(template.format(resource, indicator))\n        print(SEPARATOR)\n\n        # body\n        numbers = sorted([keys.number(key)\n                          for key in client.scan_iter(wildcard)])\n        for number in numbers:\n            label = client.get(keys.key(number))\n            print(template.format(label, number))\n\n    if resources:\n        return\n\n    # show a more general status report for all available queues\n    resources = find_resources(client)\n    if resources:\n        dispensers = (Keys.DISPENSER.format(r) for r in resources)\n        indicators = (Keys.INDICATOR.format(r) for r in resources)\n        combinations = zip(client.mget(dispensers), client.mget(indicators))\n        sizes = (int(dispenser) - int(indicator) + 1\n                 for dispenser, indicator in combinations)\n\n        # print sorted results\n        print(template.format('Resource', 'Queue size'))\n        print(SEPARATOR)\n        for size, resource in sorted(zip(sizes, resources), reverse=True):\n            print(template.format(resource, size))", "response": "Print status report for zero or more resources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and adds a text node with the given name and value.", "response": "def _create_text_node(self, root, name, value, cdata=False):\n        '''\n        Creates and adds a text node\n        @param root:Element Root element\n        @param name:str Tag name\n        @param value:object Text value\n        @param cdata:bool A value indicating whether to use CDATA or not.\n        @return:Node\n        '''\n        if is_empty_or_none(value):\n            return\n\n        if type(value) == date:\n            value = date_to_string(value)\n\n        if type(value) == datetime:\n            value = datetime_to_string(value)\n\n        if isinstance(value, Decimal):\n            value = \"0\" if not value else str(value)\n\n        tag = root.ownerDocument.createElement(name)\n        value = value.decode('utf-8')\n        if cdata:\n            tag.appendChild(root.ownerDocument.createCDATASection(value))\n        else:\n            tag.appendChild(root.ownerDocument.createTextNode(value))\n\n        return root.appendChild(tag)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_string(self, indent=\"\", newl=\"\", addindent=\"\"):\n        '''\n        Returns a string representation of the XMLi element.\n        @return: str\n        '''\n        buf = StringIO()\n        self.to_xml().writexml(buf, indent=indent, addindent=addindent,\n                               newl=newl)\n        return buf.getvalue()", "response": "Returns a string representation of the XMLi element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __createElementNS(self, root, uri, name, value):\n        '''\n        Creates and returns an element with a qualified name and a name space\n        @param root:Element Parent element\n        @param uri:str Namespace URI\n        @param tag:str Tag name.\n        '''\n        tag = root.ownerDocument.createElementNS(to_unicode(uri),\n                                                 to_unicode(name))\n        tag.appendChild(root.ownerDocument\n                        .createCDATASection(to_unicode(value)))\n        return root.appendChild(tag)", "response": "Creates and returns an element with a qualified name and a name space\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_xml(self, root):\n        '''\n        Returns a DOM element contaning the XML representation of the\n        ExtensibleXMLiElement\n        @param root:Element Root XML element.\n        @return: Element\n        '''\n        if not len(self.__custom_elements):\n            return\n\n        for uri, tags in self.__custom_elements.items():\n            prefix, url = uri.split(\":\", 1)\n            for name, value in tags.items():\n                self.__createElementNS(root, url, prefix + \":\" + name, value)\n\n        return root", "response": "Returns a DOM element contaning the XML representation of the\n        ExtensibleXMLiElement\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the current address.", "response": "def duplicate(self):\n        '''\n        Returns a copy of the current address.\n        @returns: Address\n        '''\n        return self.__class__(street_address=self.street_address,\n                              city=self.city, zipcode=self.zipcode,\n                              state=self.state, country=self.country)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a DOM Element containing the XML representation of the address.", "response": "def to_xml(self, name=\"address\"):\n        '''\n        Returns a DOM Element containing the XML representation of the\n        address.\n        @return:Element\n        '''\n        for n, v in {\"street_address\": self.street_address, \"city\": self.city,\n                     \"country\": self.country}.items():\n            if is_empty_or_none(v):\n                raise ValueError(\"'%s' attribute cannot be empty or None.\" % n)\n\n        doc = Document()\n        root = doc.createElement(name)\n        self._create_text_node(root, \"streetAddress\", self.street_address, True)\n        self._create_text_node(root, \"city\", self.city, True)\n        self._create_text_node(root, \"zipcode\", self.zipcode)\n        self._create_text_node(root, \"state\", self.state, True)\n        self._create_text_node(root, \"country\", self.country)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of the current contact element.", "response": "def duplicate(self):\n        '''\n        Returns a copy of the current contact element.\n        @returns: Contact\n        '''\n        return self.__class__(name=self.name, identifier=self.identifier,\n                              phone=self.phone, require_id=self.__require_id,\n                              address=self.address.duplicate())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_xml(self, tag_name=\"buyer\"):\n        '''\n        Returns an XMLi representation of the object.\n        @param tag_name:str Tag name\n        @return: Element\n        '''\n        for n, v in {\"name\": self.name, \"address\": self.address}.items():\n            if is_empty_or_none(v):\n                raise ValueError(\"'%s' attribute cannot be empty or None.\" % n)\n\n        if self.__require_id and is_empty_or_none(self.identifier):\n            raise ValueError(\"identifier attribute cannot be empty or None.\")\n\n        doc = Document()\n        root = doc.createElement(tag_name)\n        self._create_text_node(root, \"id\", self.identifier)\n        self._create_text_node(root, \"name\", self.name, True)\n        if self.phone:\n            self._create_text_node(root, \"phone\", self.phone, True)\n        root.appendChild(self.address.to_xml())\n        return root", "response": "Returns an XMLi representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an XMLi representation of the shipping details.", "response": "def to_xml(self):\n        '''\n        Returns an XMLi representation of the shipping details.\n        @return: Element\n        '''\n        for n, v in {\"recipient\": self.recipient}.items():\n            if is_empty_or_none(v):\n                raise ValueError(\"'%s' attribute cannot be empty or None.\" % n)\n\n        doc = Document()\n        root = doc.createElement(\"shipping\")\n        root.appendChild(self.recipient.to_xml(\"recipient\"))\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __set_identifier(self, value):\n        '''\n        Sets the ID of the invoice.\n        @param value:str\n        '''\n        if not value or not len(value):\n            raise ValueError(\"Invalid invoice ID\")\n\n        self.__identifier = value", "response": "Sets the ID of the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __set_status(self, value):\n        '''\n        Sets the status of the invoice.\n        @param value:str\n        '''\n        if value not in [INVOICE_DUE, INVOICE_PAID, INVOICE_CANCELED,\n                         INVOICE_IRRECOVERABLE]:\n            raise ValueError(\"Invalid invoice status\")\n\n        self.__status = value", "response": "Sets the status of the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __set_date(self, value):\n        '''\n        Sets the invoice date.\n        @param value:datetime\n        '''\n        value = date_to_datetime(value)\n        if value > datetime.now() + timedelta(hours=14, minutes=1): #More or less 14 hours from now in case the submitted date was local\n            raise ValueError(\"Date cannot be in the future.\")\n\n        if self.__due_date and value.date() > self.__due_date:\n            raise ValueError(\"Date cannot be posterior to the due date.\")\n\n        self.__date = value", "response": "Sets the invoice date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __set_due_date(self, value):\n        '''\n        Sets the due date of the invoice.\n        @param value:date\n        '''\n        if type(value) != date:\n            raise ValueError('Due date must be an instance of date.')\n\n        if self.__date.date() and value < self.__date.date():\n            raise ValueError(\"Due date cannot be anterior to the invoice \" \\\n                             \"date.\")\n\n        self.__due_date = value", "response": "Sets the due date of the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the total discounts of this group.", "response": "def compute_discounts(self, precision=None):\n        '''\n        Returns the total discounts of this group.\n        @param precision: int Number of decimals\n        @return: Decimal\n        '''\n        return sum([group.compute_discounts(precision) for group\n                    in self.__groups])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the total amount of taxes for this group.", "response": "def compute_taxes(self, precision=None):\n        '''\n        Returns the total amount of taxes for this group.\n        @param precision: int Number of decimal places\n        @return: Decimal\n        '''\n        return sum([group.compute_taxes(precision) for group in self.__groups])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_payments(self, precision=None):\n        '''\n        Returns the total amount of payments made to this invoice.\n        @param precision:int Number of decimal places\n        @return: Decimal\n        '''\n        return quantize(sum([payment.amount for payment in self.__payments]),\n                        precision)", "response": "Returns the total amount of payments made to this invoice."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the total of the invoice with a defined decimal precision", "response": "def compute_total(self, precision=None):\n        '''\n        Gets the total of the invoice with a defined decimal precision\n        @param precision: int Number of decimal places\n        @return: Decimal\n        '''\n        return quantize(sum([group.compute_total(precision) for group\n                             in self.__groups]), places=precision) or ZERO"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef duplicate(self):\n        '''\n        Returns a copy of the current group, including its lines.\n        @returns: Group\n        '''\n        instance = self.__class__(identifier=self.identifier,\n                                  name=self.name, description=self.description,\n                                  currency=self.currency, status=self.status,\n                                  date=self.date, due_date=self.due_date,\n                                  terms=self.terms,\n                                  seller=self.seller.duplicate(),\n                                  buyer=self.buyer.duplicate(),\n                                  shipping=self.shipping.duplicate(),\n                                  mentions=self.mentions,)\n        for group in self.groups:\n            instance.groups.append(group.duplicate())\n        for method in self.deliveries:\n            instance.deliveries.append(method.duplicate())\n        for payment in self.payments:\n            instance.payments.append(payment.duplicate())\n\n        return instance", "response": "Returns a copy of the current group including its lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a DOM element containing the XML representation of the invoice.", "response": "def to_xml(self):\n        '''\n        Returns a DOM element containing the XML representation of the invoice\n        @return:Element\n        '''\n        if not len(self.groups):\n            raise InvoiceError(\"An invoice must have at least one group \" \\\n                                   \"of lines.\")\n\n        for n, v in {\"identifier\": self.identifier,\n                     \"name\": self.name, \"currency\": self.currency,\n                     \"seller\": self.seller, \"buyer\":self.buyer,\n                     \"status\": self.status, \"date\": self.date,\n                     \"due_date\": self.due_date, \"identifier\": self.identifier,\n                     \"mentions\": self.mentions, 'domain': self.domain}.items():\n            if is_empty_or_none(v):\n                raise InvoiceError(\"'%s' attribute cannot be empty or \" \\\n                                       \"None.\" % n)\n\n        total_invoice = self.total\n        total_payments = sum([payment.amount for payment in self.payments])\n        if total_payments > total_invoice:\n            raise InvoiceError('The sum of the payments declared ' \\\n                                   '(%f %s) can\\'t be superior to the ' \\\n                                   'total of the invoice (%f %s).' %\n                                   (total_payments, self.currency,\n                                    total_invoice, self.currency))\n        if self.status == INVOICE_PAID and total_payments < total_invoice:\n            raise InvoiceError('The invoice can only be marked as paid ' \\\n                                   'if the sum of its payments (%f %s) is ' \\\n                                   'equal to its total (%f %s).' %\n                                   (total_payments, self.currency,\n                                    total_invoice, self.currency))\n\n        doc = Document()\n        root = doc.createElement(\"invoice\")\n        root.setAttribute('xmlns', DEFAULT_NAMESPACE)\n        root.setAttribute(\"domain\", self.domain)\n        root.setAttribute(\"version\", XMLi_VERSION)\n        root.setAttribute(\"agent\", AGENT)\n\n        #Adding custom elements\n        super(Invoice, self).to_xml(root)\n\n        self._create_text_node(root, \"id\", self.identifier)\n        self._create_text_node(root, \"name\", self.name, True)\n        self._create_text_node(root, \"description\", self.description, True)\n        self._create_text_node(root, \"date\", self.date)\n        self._create_text_node(root, \"dueDate\", self.due_date)\n        self._create_text_node(root, \"currency\", self.currency)\n        self._create_text_node(root, \"status\", self.status)\n        root.appendChild(self.seller.to_xml(\"seller\"))\n        root.appendChild(self.buyer.to_xml(\"buyer\"))\n        if self.__shipping:\n            root.appendChild(self.shipping.to_xml())\n        self._create_text_node(root, \"terms\", self.terms, True)\n        self._create_text_node(root, \"mentions\", self.mentions, True)\n\n        if len(self.__payments):\n            payments = doc.createElement(\"payments\")\n            for payment in self.__payments:\n                payments.appendChild(payment.to_xml())\n            root.appendChild(payments)\n\n        if len(self.deliveries):\n            deliveries = doc.createElement('deliveries')\n            for delivery in self.__deliveries:\n                deliveries.appendChild(delivery.to_xml())\n            root.appendChild(deliveries)\n\n        body = doc.createElement(\"body\")\n        root.appendChild(body)\n\n        groups = doc.createElement(\"groups\")\n        body.appendChild(groups)\n        for group in self.__groups:\n            if not issubclass(group.__class__, Group):\n                raise InvoiceError('group of type %s is not an instance ' \\\n                                       'or a subclass of %s' %\n                                       (group.__class__.__name__,\n                                        Group.__name__))\n            groups.appendChild(group.to_xml())\n\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a signed version of the invoice.", "response": "def to_signed_str(self, private, public, passphrase=None):\n        '''\n        Returns a signed version of the invoice.\n        @param private:file Private key file-like object\n        @param public:file Public key file-like object\n        @param passphrase:str Private key passphrase if any.\n        @return: str\n        '''\n        from pyxmli import xmldsig\n        try:\n            from Crypto.PublicKey import RSA\n        except ImportError:\n            raise ImportError('PyCrypto 2.5 or more recent module is ' \\\n                              'required to enable XMLi signing.\\n' \\\n                              'Please visit: http://pycrypto.sourceforge.net/')\n            \n        if not isinstance(private, RSA._RSAobj):\n            private = RSA.importKey(private.read(), passphrase=passphrase)\n        \n        if not isinstance(public, RSA._RSAobj):\n            public = RSA.importKey(public.read())\n            \n        return to_unicode(xmldsig.sign(to_unicode(self.to_string()),\n                                       private, public))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __set_method(self, value):\n        '''\n        Sets the method to use.\n        @param value: str\n        '''\n        if value not in [DELIVERY_METHOD_EMAIL, DELIVERY_METHOD_SMS,\n                         DELIVERY_METHOD_SNAILMAIL]:\n            raise ValueError(\"Invalid deliveries method '%s'\" % value)\n\n        self.__method = value", "response": "Sets the method to use."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __set_status(self, value):\n        '''\n        Sets the deliveries status of this method.\n        @param value: str\n        '''\n        if value not in [DELIVERY_METHOD_STATUS_PENDING,\n                         DELIVERY_METHOD_STATUS_SENT,\n                         DELIVERY_METHOD_STATUS_CONFIRMED,\n                         DELIVERY_METHOD_STATUS_BOUNCED]:\n            raise ValueError(\"Invalid deliveries method status '%s'\" % value)\n\n        self.__status = value", "response": "Sets the deliveries status of this method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef duplicate(self):\n        '''\n        Returns a copy of this deliveries method.\n        @return: DeliveryMethod\n        '''\n        return self.__class__(self.method, self.status, self.date, self.ref)", "response": "Returns a copy of this deliveries method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a DOM representation of the deliveries method", "response": "def to_xml(self):\n        '''\n        Returns a DOM representation of the deliveries method\n        @returns: Element\n        '''\n        for n, v in { \"method\": self.method, \"status\": self.status,\n                     \"date\":self.date}.items():\n            if is_empty_or_none(v):\n                raise DeliveryMethodError(\"'%s' attribute cannot be \" \\\n                                       \"empty or None.\" % n)\n\n        doc = Document()\n        root = doc.createElement(\"delivery\")\n        super(DeliveryMethod, self).to_xml(root)\n        self._create_text_node(root, \"method\", self.method)\n        self._create_text_node(root, \"status\", self.status)\n        self._create_text_node(root, \"reference\", self.ref, True)\n        self._create_text_node(root, \"date\", self.date)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the amount of the payment operation.", "response": "def __set_amount(self, value):\n        '''\n        Sets the amount of the payment operation.\n        @param value:float\n        '''\n        try:\n            self.__amount = quantize(Decimal(str(value)))\n        except:\n            raise ValueError('Invalid amount value')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the amount of the payment.", "response": "def __set_method(self, value):\n        '''\n        Sets the amount of the payment.\n        '''\n        if value not in [PAYMENT_METHOD_OTHER, PAYMENT_METHOD_CARD,\n                         PAYMENT_METHOD_CHEQUE, PAYMENT_METHOD_CASH, ]:\n            raise ValueError('Invalid amount value')\n\n        self.__method = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __set_date(self, value):\n        '''\n        Sets the date of the payment.\n        @param value:datetime\n        '''\n        if not issubclass(value.__class__, date):\n            raise ValueError('Invalid date value')\n\n        self.__date = value", "response": "Sets the date of the payment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of the current group including its lines.", "response": "def duplicate(self):\n        '''\n        Returns a copy of the current group, including its lines.\n        @returns: Group\n        '''\n        return self.__class__(amount=self.amount, date=self.date,\n                              method=self.method, ref=self.ref)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a DOM representation of the payment.", "response": "def to_xml(self):\n        '''\n        Returns a DOM representation of the payment.\n        @return: Element\n        '''\n        for n, v in { \"amount\": self.amount, \"date\": self.date,\n                     \"method\":self.method}.items():\n            if is_empty_or_none(v):\n                raise PaymentError(\"'%s' attribute cannot be empty or \" \\\n                                       \"None.\" % n)\n\n        doc = Document()\n        root = doc.createElement(\"payment\")\n        super(Payment, self).to_xml(root)\n        self._create_text_node(root, \"amount\", self.amount)\n        self._create_text_node(root, \"method\", self.method)\n        self._create_text_node(root, \"reference\", self.ref, True)\n        self._create_text_node(root, \"date\", self.date)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_discounts(self, precision=None):\n        '''\n        Returns the total amount of discounts of this group.\n        @param precision:int Total amount of discounts\n        @return: Decimal\n        '''\n        return sum([line.compute_discounts(precision) for line in self.__lines])", "response": "Computes the total amount of discounts of this group."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the total amount of taxes of this group.", "response": "def compute_taxes(self, precision=None):\n        '''\n        Returns the total amount of taxes of this group.\n        @param precision:int Total amount of discounts\n        @return: Decimal\n        '''\n        return sum([line.compute_taxes(precision) for line in self.__lines])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_total(self, precision=None):\n        '''\n        Gets the total of the invoice with a defined decimal precision\n        @param precision: int Number of decimal places\n        @return: Decimal\n        '''\n        return quantize(sum([line.compute_total(precision) for line\n                             in self.__lines]), places=precision) or ZERO", "response": "Gets the total of the invoice with a defined decimal precision"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef duplicate(self):\n        '''\n        Returns a copy of the current group, including its lines.\n        @returns: Group\n        '''\n        instance = self.__class__(name=self.name, description=self.description)\n        for line in self.lines:\n            instance.lines.append(line.duplicate())\n        return instance", "response": "Returns a copy of the current group including its lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_xml(self):\n        '''\n        Returns a DOM representation of the group.\n        @return: Element\n        '''\n        if not len(self.lines):\n            raise GroupError(\"A group must at least have one line.\")\n\n        doc = Document()\n        root = doc.createElement(\"group\")\n        super(Group, self).to_xml(root)\n        self._create_text_node(root, \"name\", self.name, True)\n        self._create_text_node(root, \"description\", self.description, True)\n\n        lines = doc.createElement(\"lines\")\n        root.appendChild(lines)\n        for line in self.__lines:\n            if not issubclass(line.__class__, Line):\n                raise GroupError('line of type %s is not an instance ' \\\n                                     'or a subclass of %s' %\n                                     (line.__class__.__name__, Line.__name__))\n            lines.appendChild(line.to_xml())\n\n        return root", "response": "Returns a DOM representation of the group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the unit of the line.", "response": "def __set_unit(self, value):\n        '''\n        Sets the unit of the line.\n        @param value:str\n        '''\n        if value in UNITS:\n            value = value.upper()\n\n        self.__unit = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __set_quantity(self, value):\n        '''\n        Sets the quantity\n        @param value:str\n        '''\n        try:\n            if value < 0:\n                raise ValueError()\n\n            self.__quantity = Decimal(str(value))\n        except ValueError:\n            raise ValueError(\"Quantity must be a positive number\")", "response": "Sets the quantity of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __set_unit_price(self, value):\n        '''\n        Sets the unit price\n        @param value:str\n        '''\n        try:\n            if value < 0:\n                raise ValueError()\n\n            self.__unit_price = Decimal(str(value))\n        except ValueError:\n            raise ValueError(\"Unit Price must be a positive number\")", "response": "Sets the unit price of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_discounts(self, precision=None):\n        '''\n        Returns the total amount of discounts for this line with a specific\n        number of decimals.\n        @param precision:int number of decimal places\n        @return: Decimal\n        '''\n        gross = self.compute_gross(precision)\n        return min(gross,\n                   sum([d.compute(gross, precision) for d in self.__discounts]))", "response": "Computes the total amount of discounts for this line with a specific\n        number of decimals."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_taxes(self, precision=None):\n        '''\n        Returns the total amount of taxes for this line with a specific \n        number of decimals\n        @param precision: int Number of decimal places\n        @return: Decimal\n        '''\n        base = self.gross - self.total_discounts\n        return quantize(sum([t.compute(base, precision) for t in self.__taxes]),\n                        precision)", "response": "Computes the total amount of taxes for this line with a specific \n        number of decimals\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the total of the invoice with a defined decimal precision", "response": "def compute_total(self, precision=None):\n        '''\n        Gets the total of the invoice with a defined decimal precision\n        @param precision: int Number of decimal places\n        @return: Decimal\n        '''\n        return quantize((self.compute_gross(precision) +\n                        self.compute_taxes(precision) -\n                        self.compute_discounts(precision)),\n                        places=precision)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of the current Line including its taxes and discounts.", "response": "def duplicate(self):\n        '''\n        Returns a copy of the current Line, including its taxes and discounts\n        @returns: Line.\n        '''\n        instance = self.__class__(name=self.name, description=self.description,\n                                  unit=self.unit, quantity=self.quantity,\n                                  date=self.date, unit_price=self.unit_price,\n                                  gin=self.gin, gtin=self.gtin, sscc=self.sscc)\n        for tax in self.taxes:\n            instance.taxes.append(tax.duplicate())\n        for discount in self.discounts:\n            instance.discounts.append(discount.duplicate())\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a DOM representation of the line.", "response": "def to_xml(self):\n        '''\n        Returns a DOM representation of the line.\n        @return: Element\n        '''\n        for n, v in {\"name\": self.name, \"quantity\": self.quantity,\n                     \"unit_price\": self.unit_price}.items():\n            if is_empty_or_none(v):\n                raise LineError(\"'%s' attribute cannot be empty or None.\" %\n                                    n)\n\n        doc = Document()\n        root = doc.createElement(\"line\")\n        super(Line, self).to_xml(root)\n        self._create_text_node(root, \"date\", self.date)\n        self._create_text_node(root, \"name\", self.name, True)\n        self._create_text_node(root, \"description\", self.description, True)\n        self._create_text_node(root, \"quantity\", self.quantity)\n        self._create_text_node(root, \"unitPrice\", self.unit_price)\n        self._create_text_node(root, \"unit\", self.unit)\n        self._create_text_node(root, \"gin\", self.gin)\n        self._create_text_node(root, \"gtin\", self.gtin)\n        self._create_text_node(root, \"sscc\", self.sscc)\n\n        if len(self.__discounts):\n            discounts = root.ownerDocument.createElement(\"discounts\")\n            root.appendChild(discounts)\n            for discount in self.__discounts:\n                if not issubclass(discount.__class__, Discount):\n                    raise LineError('discount of type %s is not an ' \\\n                                    'instance or a subclass of %s' %\n                                    (discount.__class__.__name__,\n                                     Discount.__name__))\n                discounts.appendChild(discount.to_xml())\n\n        if len(self.__taxes):\n            taxes = root.ownerDocument.createElement(\"taxes\")\n            root.appendChild(taxes)\n            for tax in self.__taxes:\n                if not issubclass(tax.__class__, Tax):\n                    raise LineError('tax of type %s is not an instance ' \\\n                                        'or a subclass of %s' %\n                                        (tax.__class__.__name__, Tax.__name__))\n                taxes.appendChild(tax.to_xml())\n\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __set_interval(self, value):\n        '''\n        Sets the treatment interval\n        @param value:Interval\n        '''\n        if not isinstance(self, Interval):\n            raise ValueError(\"'value' must be of type Interval\")\n\n        self.__interval = value", "response": "Sets the treatment interval\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __set_name(self, value):\n        '''\n        Sets the name of the treatment.\n        @param value:str\n        '''\n        if not value or not len(value):\n            raise ValueError(\"Invalid name.\")\n\n        self.__name = value", "response": "Sets the name of the treatment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __set_rate_type(self, value):\n        '''\n        Sets the rate type.\n        @param value:str\n        '''\n        if value not in [RATE_TYPE_FIXED, RATE_TYPE_PERCENTAGE]:\n            raise ValueError(\"Invalid rate type.\")\n\n        self.__rate_type = value", "response": "Sets the rate type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of the current treatment.", "response": "def duplicate(self):\n        '''\n        Returns a copy of the current treatment.\n        @returns: Treatment.\n        '''\n        return self.__class__(name=self.name, description=self.description,\n                              rate_type=self.rate_type, rate=self.rate,\n                              interval=self.interval)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute(self, base, precision=None):\n        '''\n        Computes the amount of the treatment.\n        @param base:float Gross\n        @return: Decimal\n        '''\n        if base <= ZERO:\n            return ZERO\n\n        if self.rate_type == RATE_TYPE_FIXED:\n            if not self.interval or base >= self.interval.lower:\n                return quantize(self.rate, precision)\n            return ZERO\n\n        if not self.interval:\n            return quantize(base * self.rate / 100, precision)\n\n        if base > self.interval.lower:\n            base = min(base, self.interval.upper) - self.interval.lower\n            return quantize(base * self.rate / 100, precision)\n\n        return ZERO", "response": "Computes the amount of the treatment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a DOM representation of the line treatment.", "response": "def to_xml(self, name):\n        '''\n        Returns a DOM representation of the line treatment.\n        @return: Element\n        '''\n        for n, v in {\"rate_type\": self.rate_type,\n                     \"rate\": self.rate,\n                     \"name\": self.name,\n                     \"description\": self.description}.items():\n            if is_empty_or_none(v):\n                raise TreatmentError(\"'%s' attribute cannot be empty \" \\\n                                         \"or None.\" % n)\n\n        doc = Document()\n        root = doc.createElement(name)\n        root.setAttribute(\"type\", self.rate_type)\n        root.setAttribute(\"name\", to_unicode(self.name))\n        root.setAttribute(\"description\", to_unicode(self.description))\n        if self.interval:\n            root.setAttribute(\"base\", self.interval)\n        root.appendChild(doc.createTextNode(to_unicode(self.rate)))\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute(self, base, *args, **kwargs):\n        '''\n        Returns the value of the discount.\n        @param base:float Computation base.\n        @return: Decimal\n        '''\n        return min(base, super(Discount, self).compute(base, *args, **kwargs))", "response": "Returns the value of the discount."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, request, **cleaned_data):\n        if Site._meta.installed:\n            site = Site.objects.get_current()\n        else:\n            site = RequestSite(request)\n            \n        create_user = RegistrationProfile.objects.create_inactive_user\n        new_user = create_user(\n            cleaned_data['username'],\n            cleaned_data['email'],\n            cleaned_data['password1'],\n            site,\n            send_email=False\n        )\n        new_user.first_name = cleaned_data['first_name']\n        new_user.last_name = cleaned_data['last_name']\n        new_user.save()\n        \n        user_info = UserInfo(\n            user=new_user,\n            company=cleaned_data['company'],\n            function=cleaned_data['function'],\n            address=cleaned_data['address'],\n            postal_code=cleaned_data['postal_code'],\n            city=cleaned_data['city'],\n            country=cleaned_data['country'],\n            phone=cleaned_data['phone'],\n        )\n        user_info.save()\n        \n        send_activation_email(new_user, site, user_info)\n        send_activation_pending_email(new_user, site, user_info)\n        \n        signals.user_registered.send(sender=self.__class__, user=new_user, request=request)\n        \n        return new_user", "response": "This method creates a new User object and adds it to the database and sends an activation email and a resume of the new user info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding handler from registered rules omento", "response": "def match(self, method, path):\n        \"\"\"find handler from registered rules\n\n        Example:\n\n            handler, params = match('GET', '/path')\n\n        \"\"\"\n        segments = path.split('/')\n        while len(segments):\n            index = '/'.join(segments)\n            if index in self.__idx__:\n                handler, params = self.match_rule(method, path,\n                                                  self.__idx__[index])\n                if handler:\n                    return handler, params\n            segments.pop()\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_for(self, handler, **kwargs):\n        if type(handler) is not str:\n            handler = handler.__qualname__\n        if handler not in self.__reversedidx__:\n            return None\n        pattern = self.__reversedidx__[handler].pattern.lstrip('^').rstrip('$')\n        path = self.param_macher.sub(lambda m: str(kwargs.pop(m.group(1))),\n                                     pattern)\n        if kwargs:\n            path = \"%s?%s\" % (path, parse.urlencode(kwargs))\n        return path", "response": "construct path for a given handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_indent(text):\n    indent = 0\n    for c in text:\n        if c is '\\t':\n            raise ValueError()\n        if c is not ' ':\n            return indent,text[indent:]\n        indent += 1\n    return indent,''", "response": "Calculates the indent of the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_line(text):\n    indent,text = calculate_indent(text)\n    results = line_parser.parseString(text, parseAll=True).asList()\n    return indent,results[0]", "response": "Parses a line of text into a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield the lines of a file in order of indentation and value", "response": "def iter_lines(f):\n    \"\"\"\n    :param f:\n    :type f: file\n    :return:\n    \"\"\"\n    linenum = 1\n    try:\n        for text in f.readlines():\n            # ignore lines that consist entirely of whitespace\n            if text.isspace():\n                continue\n            indent,value = parse_line(text)\n            yield linenum,indent,value\n            linenum += 1\n    except:\n        raise ParserError(linenum, 0, '', 'failed to parse line')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_prefix(self):\n        if self.prefix is not None:\n            value = self.prefix.rstrip('_')\n        else:\n            module_path_parts = self.__module_path_split[:-1]\n            if module_path_parts[-1] == 'conf':\n                module_path_parts.pop()\n            value = '_'.join(module_path_parts)\n        self._prefix = value.upper()", "response": "Sets the _prefix attribute of the object based on the object s module path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the relevant values from the defaults module and saves them to the self. _defaults attribute.", "response": "def _load_defaults(self):\n        \"\"\"\n        Called by ``__init__()`` to create a dictionary of the relevant\n        values from the associated defaults module, and save it to the\n        object's ``_defaults`` attribute to improve lookup performance.\n        Only variables with upper-case names are included.\n\n        :raises: ImportError\n\n        It is assumed that the defaults module is defined in the same directory\n        as ``settings.py`` where the settings helper class is defined. But,\n        in cases where this differs, developers can specify an alternative\n        import path using the ``defaults_path`` class attribute for their\n        helper class.\n        \"\"\"\n        self._defaults_module_path = self.defaults_path or \\\n            '.'.join(self.__module_path_split[:-1]) + \".defaults\"\n\n        module = self._do_import(self._defaults_module_path)\n        self._defaults = {\n            k: v for k, v in module.__dict__.items()\n            if k.isupper()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreparing the deprecation data for the AppSettingDeprecation class.", "response": "def _prepare_deprecation_data(self):\n        \"\"\"\n        Cycles through the list of AppSettingDeprecation instances set on\n        ``self.deprecations`` and prepulates two new dictionary attributes:\n\n        ``self._deprecated_settings``:\n            Uses the deprecated setting names themselves as the keys. Used to\n            check whether a request is for a deprecated setting.\n\n        ``self._renamed_settings``:\n            Uses the 'replacement setting' names as keys (where supplied).\n            Used to allow the helper to temporarily support override settings\n            defined using the old name, when the values for the new setting are\n            requested.\n        \"\"\"\n        if not isinstance(self.deprecations, (list, tuple)):\n            raise IncorrectDeprecationsValueType(\n                \"'deprecations' must be a list or tuple, not a {}.\"\n                .format(type(self.deprecations).__name__)\n            )\n\n        self._deprecated_settings = {}\n        self._replacement_settings = defaultdict(list)\n\n        for item in self.deprecations:\n            item.prefix = self.get_prefix()\n\n            if not self.in_defaults(item.setting_name):\n                raise InvalidDeprecationDefinition(\n                    \"There is an issue with one of your setting deprecation \"\n                    \"definitions. '{setting_name}' could not be found in \"\n                    \"{defaults_module_path}. Please ensure a default value \"\n                    \"remains there until the end of the setting's deprecation \"\n                    \"period.\".format(\n                        setting_name=item.setting_name,\n                        defaults_module_path=self._defaults_module_path,\n                    )\n                )\n\n            if item.setting_name in self._deprecated_settings:\n                raise DuplicateDeprecationError(\n                    \"The setting name for each deprecation definition must be \"\n                    \"unique, but '{setting_name}' has been used more than once \"\n                    \"for {helper_class}.\".format(\n                        setting_name=item.setting_name,\n                        helper_class=self.__class__.__name__,\n                    )\n                )\n\n            self._deprecated_settings[item.setting_name] = item\n\n            if item.replacement_name:\n\n                if not self.in_defaults(item.replacement_name):\n                    raise InvalidDeprecationDefinition(\n                        \"There is an issue with one of your settings \"\n                        \"deprecation definitions. '{replacement_name}' is not \"\n                        \"a valid replacement for '{setting_name}', as no such \"\n                        \"value can be found in {defaults_module_path}.\"\n                        .format(\n                            replacement_name=item.replacement_name,\n                            setting_name=item.setting_name,\n                            defaults_module_path=self._defaults_module_path,\n                        )\n                    )\n\n                self._replacement_settings[item.replacement_name].append(item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the internal caches to the default values.", "response": "def reset_caches(self, **kwargs):\n        \"\"\"\n        Called by ``__init__()`` to initialise the caches for a helper instance.\n        It is also called by Django's ``setting_changed`` signal to clear the\n        caches when changes to settings are made.\n\n        Although it requires slightly more memory, separate dictionaries are\n        used for raw values, models, modules and other objects to help with\n        lookup performance for each type.\n        \"\"\"\n        self._raw_cache = {}\n        self._models_cache = {}\n        self._modules_cache = {}\n        self._objects_cache = {}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwarn if a deprecated setting value is requested.", "response": "def _warn_if_deprecated_setting_value_requested(\n        self, setting_name, warn_only_if_overridden, suppress_warnings,\n        warning_stacklevel,\n    ):\n        \"\"\"\n        get(), get_object(), get_model() and get_module() must all check\n        whether a requested app setting is deprecated. This method allows\n        the helper to do that in a DRY/consistent way.\n        \"\"\"\n        if(\n            not suppress_warnings and\n            not warn_only_if_overridden and\n            setting_name in self._deprecated_settings\n        ):\n            depr = self._deprecated_settings[setting_name]\n            depr.warn_if_deprecated_setting_value_requested(warning_stacklevel + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_raw_value(self, setting_name, accept_deprecated='',\n                       warn_if_overridden=False, suppress_warnings=False,\n                       warning_stacklevel=3):\n        \"\"\"\n        Returns the original/raw value for an app setting with the name\n        ``setting_name``, exactly as it has been defined in the defaults\n        module or a user's Django settings.\n\n        If the requested setting is deprecated, ``warn_if_overridden`` is\n        ``True``, and the setting is overridden by a user, a suitable\n        deprecation warning is raised to help inform them of the change.\n\n        If the requested setting replaces a single deprecated setting, and no\n        user defined setting is defined using the new name, the method will\n        look for a user defined setting using the deprecated setting name, and\n        return that if found. A deprecation warning will also be raised.\n\n        If the requested setting replaces multiple deprecated settings, the\n        ``accept_deprecated`` keyword argument can be used to specify which of\n        those deprecated settings to accept as the value if defined by a user.\n\n        If no override value was found in the Django setting, then the\n        relevant value from the defaults module is returned.\n        \"\"\"\n        if not self.in_defaults(setting_name):\n            self._raise_invalid_setting_name_error(setting_name)\n\n        if self.is_overridden(setting_name):\n            if(\n                warn_if_overridden and not suppress_warnings and\n                setting_name in self._deprecated_settings\n            ):\n                depr = self._deprecated_settings[setting_name]\n                depr.warn_if_overridden(warning_stacklevel)\n            return self.get_user_defined_value(setting_name)\n\n        if setting_name in self._replacement_settings:\n            deprecations = self._replacement_settings[setting_name]\n            for item in deprecations:\n                if(\n                    (len(deprecations) == 1 or item.setting_name == accept_deprecated) and\n                    self.is_overridden(item.setting_name)\n                ):\n                    if not suppress_warnings:\n                        item.warn_if_user_using_old_setting_name(warning_stacklevel)\n                    return self.get_user_defined_value(item.setting_name)\n        return self.get_default_value(setting_name)", "response": "Internal method to get the value of an app setting with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, setting_name, warn_only_if_overridden=False,\n            accept_deprecated='', suppress_warnings=False,\n            enforce_type=None, check_if_setting_deprecated=True,\n            warning_stacklevel=3):\n        \"\"\"\n        Returns a setting value for the setting named by ``setting_name``. The\n        returned value is actually a reference to the original setting value,\n        so care should be taken to avoid setting the result to a different\n        value.\n\n        :param setting_name:\n            The name of the app setting for which a value is required.\n        :type setting_name: str (e.g. \"SETTING_NAME\")\n        :param warn_only_if_overridden:\n            If the setting named by ``setting_name`` is deprecated, a value of\n            ``True`` can be provided to silence the immediate deprecation\n            warning that is otherwise raised by default. Instead, a\n            (differently worded) deprecation warning will be raised, but only\n            when the setting is overriden.\n        :type warn_only_if_overridden: bool\n        :param accept_deprecated:\n            If the setting named by ``setting_name`` replaces multiple\n            deprecated settings, the ``accept_deprecated`` keyword argument can\n            be used to specify which of those deprecated settings to accept as\n            an override value.\n\n            Where the requested setting replaces only a single deprecated\n            setting, override values for that deprecated setting will be\n            accepted automatically, without having to specify anything.\n        :type accept_deprecated: str (e.g. \"DEPRECATED_SETTING_NAME\")\n        :param suppress_warnings:\n            Use this to prevent the raising of any deprecation warnings that\n            might otherwise be raised. It may be more useful to use\n            ``warn_only_if_overridden`` instead.\n        :type suppress_warnings: bool\n        :param enforce_type:\n            When a setting value of a specific type is required, this can be\n            used to apply some basic validation at the time of retrieval. If\n            supplied, and setting value is found not to be an instance of the\n            supplied type, a ``SettingValueTypeInvalid`` error will be raised.\n\n            In cases where more than one type of value is accepted, a tuple of\n            acceptable types can be provided.\n        :type enforce_type: A type (class), or tuple of types\n        :param check_if_setting_deprecated:\n            Can be used to disable the check that usually happens at the\n            beginning of the method to identify whether the setting named by\n            ``setting_name`` is deprecated, and conditionally raise a warning.\n            This can help to improve efficiency where the same check has\n            already been made.\n        :type check_if_setting_deprecated: bool\n        :param warning_stacklevel:\n            When raising deprecation warnings related to the request, this\n            value is passed on as ``stacklevel`` to Python's\n            ``warnings.warn()`` method, to help give a more accurate indication\n            of the code that caused the warning to be raised.\n        :type warning_stacklevel: int\n        :raises: UnknownSettingNameError, SettingValueTypeInvalid\n\n        Instead of calling this method directly, developers are generally\n        encouraged to use the direct attribute shortcut, which is a\n        syntactically much cleaner way to request values using the default\n        options. For example, the the following lines are equivalent::\n\n            appsettingshelper.SETTING_NAME\n            appsettingshelper.get('SETTING_NAME')\n        \"\"\"\n        if check_if_setting_deprecated:\n            self._warn_if_deprecated_setting_value_requested(\n                setting_name, warn_only_if_overridden, suppress_warnings,\n                warning_stacklevel)\n\n        cache_key = self._make_cache_key(setting_name, accept_deprecated)\n        if cache_key in self._raw_cache:\n            return self._raw_cache[cache_key]\n\n        result = self._get_raw_value(\n            setting_name,\n            accept_deprecated=accept_deprecated,\n            warn_if_overridden=warn_only_if_overridden,\n            suppress_warnings=suppress_warnings,\n            warning_stacklevel=warning_stacklevel + 1,\n        )\n\n        if enforce_type and not isinstance(result, enforce_type):\n            if isinstance(enforce_type, tuple):\n                msg = (\n                    \"The value is expected to be one of the following types, \"\n                    \"but a value of type '{current_type}' was found: \"\n                    \"{required_types}.\"\n                )\n                text_format_kwargs = dict(\n                    current_type=type(result).__name__,\n                    required_types=enforce_type,\n                )\n            else:\n                msg = (\n                    \"The value is expected to be a '{required_type}', but a \"\n                    \"value of type '{current_type}' was found.\"\n                )\n                text_format_kwargs = dict(\n                    current_type=type(result).__name__,\n                    required_type=enforce_type.__name__,\n                )\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueTypeInvalid,\n                default_value_error_class=DefaultValueTypeInvalid,\n                additional_text=msg,\n                **text_format_kwargs\n            )\n        self._raw_cache[cache_key] = result\n        return result", "response": "Returns a value for the named app setting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Django model string referenced by an app setting.", "response": "def get_model(self, setting_name, warn_only_if_overridden=False,\n                  accept_deprecated='', suppress_warnings=False,\n                  warning_stacklevel=3):\n        \"\"\"\n        Returns a Django model referenced by an app setting where the value is\n        expected to be a valid 'model string' in the format:\n        \"app_label.model_name\".\n\n        :param setting_name:\n            The name of the app setting for which a value is required.\n        :type setting_name: str (e.g. \"SETTING_NAME\")\n        :param warn_only_if_overridden:\n            If the setting named by ``setting_name`` is deprecated, a value of\n            ``True`` can be provided to silence the immediate deprecation\n            warning that is otherwise raised by default. Instead, a\n            (differently worded) deprecation warning will be raised, but only\n            when the setting is overriden.\n        :type warn_only_if_overridden: bool\n        :param accept_deprecated:\n            If the setting named by ``setting_name`` replaces multiple\n            deprecated settings, the ``accept_deprecated`` keyword argument can\n            be used to specify which of those deprecated settings to accept as\n            an override value.\n\n            Where the requested setting replaces only a single deprecated\n            setting, override values for that deprecated setting will be\n            accepted automatically, without having to specify anything.\n        :type accept_deprecated: str (e.g. \"DEPRECATED_SETTING_NAME\")\n        :param suppress_warnings:\n            Use this to prevent the raising of any deprecation warnings that\n            might otherwise be raised. It may be more useful to use\n            ``warn_only_if_overridden`` instead.\n        :type suppress_warnings: bool\n        :param warning_stacklevel:\n            When raising deprecation warnings related to the request, this\n            value is passed on as ``stacklevel`` to Python's\n            ``warnings.warn()`` method, to help give a more accurate indication\n            of the code that caused the warning to be raised.\n        :type warning_stacklevel: int\n        :raises:\n            UnknownSettingNameError, SettingValueTypeInvalid,\n            SettingValueFormatInvalid, SettingValueNotImportable\n\n        Instead of calling this method directly, developers are generally\n        encouraged to use the ``models`` attribute shortcut, which is a\n        syntactically much cleaner way to request values using the default\n        options. For example, the the following lines are equivalent::\n\n            appsettingshelper.models.SETTING_NAME\n            appsettingshelper.get_model('SETTING_NAME')\n\n        \"\"\"\n        self._warn_if_deprecated_setting_value_requested(\n            setting_name, warn_only_if_overridden, suppress_warnings,\n            warning_stacklevel)\n\n        cache_key = self._make_cache_key(setting_name, accept_deprecated)\n        if cache_key in self._models_cache:\n            return self._models_cache[cache_key]\n\n        raw_value = self.get(\n            setting_name,\n            enforce_type=str,\n            accept_deprecated=accept_deprecated,\n            check_if_setting_deprecated=False,\n            warn_only_if_overridden=warn_only_if_overridden,\n            suppress_warnings=suppress_warnings,\n            warning_stacklevel=warning_stacklevel + 1,\n        )\n\n        try:\n            from django.apps import apps  # delay import until needed\n            result = apps.get_model(raw_value)\n            self._models_cache[cache_key] = result\n            return result\n        except ValueError:\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueFormatInvalid,\n                default_value_error_class=DefaultValueFormatInvalid,\n                additional_text=(\n                    \"Model strings should match the format 'app_label.Model', \"\n                    \"which '{value}' does not adhere to.\"\n                ),\n                value=raw_value,\n            )\n        except LookupError:\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueNotImportable,\n                default_value_error_class=DefaultValueNotImportable,\n                additional_text=(\n                    \"The model '{value}' does not appear to be installed.\"\n                ),\n                value=raw_value\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_module(self, setting_name, warn_only_if_overridden=False,\n                   accept_deprecated='', suppress_warnings=False,\n                   warning_stacklevel=3):\n        \"\"\"\n        Returns a Python module referenced by an app setting where the value is\n        expected to be a valid, absolute Python import path, defined as a\n        string (e.g. \"myproject.app.custom_module\").\n\n        :param setting_name:\n            The name of the app setting for which a value is required.\n        :type setting_name: str (e.g. \"SETTING_NAME\")\n        :param warn_only_if_overridden:\n            If the setting named by ``setting_name`` is deprecated, a value of\n            ``True`` can be provided to silence the immediate deprecation\n            warning that is otherwise raised by default. Instead, a\n            (differently worded) deprecation warning will be raised, but only\n            when the setting is overriden.\n        :type warn_only_if_overridden: bool\n        :param accept_deprecated:\n            If the setting named by ``setting_name`` replaces multiple\n            deprecated settings, the ``accept_deprecated`` keyword argument can\n            be used to specify which of those deprecated settings to accept as\n            an override value.\n\n            Where the requested setting replaces only a single deprecated\n            setting, override values for that deprecated setting will be\n            accepted automatically, without having to specify anything.\n        :type accept_deprecated: str (e.g. \"DEPRECATED_SETTING_NAME\")\n        :param suppress_warnings:\n            Use this to prevent the raising of any deprecation warnings that\n            might otherwise be raised. It may be more useful to use\n            ``warn_only_if_overridden`` instead.\n        :type suppress_warnings: bool\n        :param warning_stacklevel:\n            When raising deprecation warnings related to the request, this\n            value is passed on as ``stacklevel`` to Python's\n            ``warnings.warn()`` method, to help give a more accurate indication\n            of the code that caused the warning to be raised.\n        :type warning_stacklevel: int\n        :raises:\n            UnknownSettingNameError, SettingValueTypeInvalid,\n            SettingValueNotImportable\n\n        Instead of calling this method directly, developers are generally\n        encouraged to use the ``modules`` attribute shortcut, which is a\n        syntactically much cleaner way to request values using the default\n        options. For example, the the following lines are equivalent::\n\n            appsettingshelper.modules.SETTING_NAME\n            appsettingshelper.get_module('SETTING_NAME')\n\n        \"\"\"\n        self._warn_if_deprecated_setting_value_requested(\n            setting_name, warn_only_if_overridden, suppress_warnings,\n            warning_stacklevel)\n\n        cache_key = self._make_cache_key(setting_name, accept_deprecated)\n        if cache_key in self._modules_cache:\n            return self._modules_cache[cache_key]\n\n        raw_value = self.get(\n            setting_name,\n            enforce_type=str,\n            accept_deprecated=accept_deprecated,\n            check_if_setting_deprecated=False,\n            warn_only_if_overridden=warn_only_if_overridden,\n            suppress_warnings=suppress_warnings,\n            warning_stacklevel=warning_stacklevel + 1,\n        )\n\n        try:\n            result = self._do_import(raw_value)\n            self._modules_cache[cache_key] = result\n            return result\n        except ImportError:\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueNotImportable,\n                default_value_error_class=DefaultValueNotImportable,\n                additional_text=(\n                    \"No module could be found matching the path '{value}'. \"\n                    \"Please use a full (not relative) import path in the \"\n                    \"format: 'project.app.module'.\"\n                ),\n                value=raw_value\n            )", "response": "Returns the Python module that is referenced by the app setting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a python class method or other object referenced by an app setting.", "response": "def get_object(self, setting_name, warn_only_if_overridden=False,\n                   accept_deprecated='', suppress_warnings=False,\n                   warning_stacklevel=3):\n        \"\"\"\n        Returns a python class, method, or other object referenced by an app\n        setting where the value is expected to be a valid, absolute Python\n        import path, defined as a string (e.g. \"myproject.app.module.MyClass\").\n\n        :param setting_name:\n            The name of the app setting for which a value is required.\n        :type setting_name: str (e.g. \"SETTING_NAME\")\n        :param warn_only_if_overridden:\n            If the setting named by ``setting_name`` is deprecated, a value of\n            ``True`` can be provided to silence the immediate deprecation\n            warning that is otherwise raised by default. Instead, a\n            (differently worded) deprecation warning will be raised, but only\n            when the setting is overriden.\n        :type warn_only_if_overridden: bool\n        :param accept_deprecated:\n            If the setting named by ``setting_name`` replaces multiple\n            deprecated settings, the ``accept_deprecated`` keyword argument can\n            be used to specify which of those deprecated settings to accept as\n            an override value.\n\n            Where the requested setting replaces only a single deprecated\n            setting, override values for that deprecated setting will be\n            accepted automatically, without having to specify anything.\n        :type accept_deprecated: str (e.g. \"DEPRECATED_SETTING_NAME\")\n        :param suppress_warnings:\n            Use this to prevent the raising of any deprecation warnings that\n            might otherwise be raised. It may be more useful to use\n            ``warn_only_if_overridden`` instead.\n        :type suppress_warnings: bool\n        :param warning_stacklevel:\n            When raising deprecation warnings related to the request, this\n            value is passed on as ``stacklevel`` to Python's\n            ``warnings.warn()`` method, to help give a more accurate indication\n            of the code that caused the warning to be raised.\n        :type warning_stacklevel: int\n        :raises:\n            UnknownSettingNameError, SettingValueTypeInvalid,\n            SettingValueFormatInvalid, SettingValueNotImportable\n\n        Instead of calling this method directly, developers are generally\n        encouraged to use the ``objects`` attribute shortcut, which is a\n        syntactically much cleaner way to request values using the default\n        options. For example, the the following lines are equivalent::\n\n            appsettingshelper.objects.SETTING_NAME\n            appsettingshelper.get_object('SETTING_NAME')\n\n        \"\"\"\n        self._warn_if_deprecated_setting_value_requested(\n            setting_name, warn_only_if_overridden, suppress_warnings,\n            warning_stacklevel)\n\n        cache_key = self._make_cache_key(setting_name, accept_deprecated)\n        if cache_key in self._objects_cache:\n            return self._objects_cache[cache_key]\n\n        raw_value = self.get(\n            setting_name,\n            enforce_type=str,\n            accept_deprecated=accept_deprecated,\n            check_if_setting_deprecated=False,\n            warn_only_if_overridden=warn_only_if_overridden,\n            suppress_warnings=suppress_warnings,\n            warning_stacklevel=warning_stacklevel + 1,\n        )\n        try:\n            module_path, object_name = raw_value.rsplit(\".\", 1)\n        except ValueError:\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueFormatInvalid,\n                default_value_error_class=DefaultValueFormatInvalid,\n                additional_text=(\n                    \"'{value}' is not a valid object import path. Please use \"\n                    \"a full (not relative) import path with the object name \"\n                    \"at the end, for example: 'project.app.module.object'.\"\n                ),\n                value=raw_value\n            )\n        try:\n            result = getattr(self._do_import(module_path), object_name)\n            self._objects_cache[cache_key] = result\n            return result\n        except ImportError:\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueNotImportable,\n                default_value_error_class=DefaultValueNotImportable,\n                additional_text=(\n                    \"No module could be found matching the path \"\n                    \"'{module_path}'. Please use a full (not relative) import \"\n                    \"path with the object name at the end, for example: \"\n                    \"'project.app.module.object'.\"\n                ),\n                module_path=module_path,\n            )\n        except AttributeError:\n            self._raise_setting_value_error(\n                setting_name=setting_name,\n                user_value_error_class=OverrideValueNotImportable,\n                default_value_error_class=DefaultValueNotImportable,\n                additional_text=(\n                    \"No object could be found in {module_path} matching the \"\n                    \"name '{object_name}'.\"\n                ),\n                module_path=module_path,\n                object_name=object_name,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True when the new setting with the name setting_name is a replacement for the deprecated setting.", "response": "def is_value_from_deprecated_setting(self, setting_name, deprecated_setting_name):\n        \"\"\"\n        Helps developers to determine where the settings helper got it's value\n        from when dealing with settings that replace deprecated settings.\n\n        Returns ``True`` when the new setting (with the name ``setting_name``)\n        is a replacement for a deprecated setting (with the name\n        ``deprecated_setting_name``) and the user is using the deprecated\n        setting in their Django settings to override behaviour.\n        \"\"\"\n        if not self.in_defaults(setting_name):\n            self._raise_invalid_setting_name_error(setting_name)\n        if not self.in_defaults(deprecated_setting_name):\n            self._raise_invalid_setting_name_error(deprecated_setting_name)\n        if deprecated_setting_name not in self._deprecated_settings:\n            raise ValueError(\n                \"The '%s' setting is not deprecated. When using \"\n                \"settings.is_value_from_deprecated_setting(), the deprecated \"\n                \"setting name should be supplied as the second argument.\" %\n                deprecated_setting_name\n            )\n        if(\n            not self.is_overridden(setting_name) and\n            setting_name in self._replacement_settings\n        ):\n            deprecations = self._replacement_settings[setting_name]\n            for item in deprecations:\n                if(\n                    item.setting_name == deprecated_setting_name and\n                    self.is_overridden(item.setting_name)\n                ):\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a parser and composer of a format.", "response": "def register(self, type, parser, composer, **meta):\n        \"\"\"Registers a parser and composer of a format.\n\n        You can use this method to overwrite existing formats.\n\n        :param type: The unique name of the format\n        :param parser: The method to parse data as the format\n        :param composer: The method to compose data as the format\n        :param meta: The extra information associated with the format\n        \"\"\"\n        self.registered_formats[type] = {\n            'parser': parser,\n            'composer': composer,\n            'meta': meta,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a parser of a format.", "response": "def register_parser(self, type, parser, **meta):\n        \"\"\"Registers a parser of a format.\n\n        :param type: The unique name of the format\n        :param parser: The method to parse data as the format\n        :param meta: The extra information associated with the format\n        \"\"\"\n        try:\n            self.registered_formats[type]['parser'] = parser\n        except KeyError:\n            self.registered_formats[type] = {'parser': parser}\n        if meta:\n            self.register_meta(type, **meta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_composer(self, type, composer, **meta):\n        try:\n            self.registered_formats[type]['composer'] = composer\n        except KeyError:\n            self.registered_formats[type] = {'composer': composer}\n        if meta:\n            self.register_meta(type, **meta)", "response": "Registers a composer of a format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_meta(self, type, **meta):\n        try:\n            self.registered_formats[type]['meta'] = meta\n        except KeyError:\n            self.registered_formats[type] = {'meta': meta}", "response": "Registers extra _meta_ information about a format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parser(self, type, **meta):\n        def decorator(f):\n            self.register_parser(type, f)\n            if meta:\n                self.register_meta(type, **meta)\n            return f\n        return decorator", "response": "Decorator to register a method as the parser of a format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef composer(self, type, **meta):\n        def decorator(f):\n            self.register_composer(type, f)\n            if meta:\n                self.register_meta(type, **meta)\n            return f\n        return decorator", "response": "Decorator to register a method as the composer of a format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(self, type, data):\n        try:\n            return self.registered_formats[type]['parser'](data)\n        except KeyError:\n            raise NotImplementedError(\"No parser found for \"\n                                      \"type '{type}'\".format(type=type))", "response": "Parse text as a format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomposing text as a format.", "response": "def compose(self, type, data):\n        \"\"\"Compose text as a format.\n\n        :param type: The unique name of the format\n        :param data: The text to compose as the format\n        \"\"\"\n        try:\n            return self.registered_formats[type]['composer'](data)\n        except KeyError:\n            raise NotImplementedError(\"No composer found for \"\n                                      \"type '{type}'\".format(type=type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert(self, type_from, type_to, data):\n        try:\n            return self.compose(type_to, self.parse(type_from, data))\n        except Exception as e:\n            raise ValueError(\n                \"Couldn't convert '{from_}' to '{to}'. Possibly \"\n                \"because the parser of '{from_}' generates a \"\n                \"data structure incompatible with the composer \"\n                \"of '{to}'. This is the original error: \\n\\n\"\n                \"{error}: {message}\".format(from_=type_from, to=type_to,\n                                            error=e.__class__.__name__,\n                                            message=e.message))", "response": "Parses data from one format and composes with another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef meta(self, type):\n        try:\n            return self.registered_formats[type].get('meta')\n        except KeyError:\n            raise NotImplementedError(\"No format registered with type \"\n                                      \"'{type}'\".format(type=type))", "response": "Retreived meta information of a format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discover_json(self):\n        try:\n            import simplejson as json\n        except ImportError:\n            import json\n        self.register('json', json.loads, json.dumps)", "response": "Discovers the JSON format and registers it if available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndiscovering the YAML format and registers it if available.", "response": "def discover_yaml(self):\n        \"\"\"Discovers the YAML format and registers it if available.\n\n        Install YAML support via PIP::\n\n            pip install PyYAML\n        \"\"\"\n        try:\n            import yaml\n            self.register('yaml', yaml.load, yaml.dump)\n        except ImportError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_domain(clz, dag):\n        logging.info(\"Setting domain for poset %s\" % clz.__name__)\n        if nx.number_of_nodes(dag) == 0:\n            raise CellConstructionFailure(\"Empty DAG structure.\")\n            \n        if not nx.is_directed_acyclic_graph(dag):\n            raise CellConstructionFailure(\"Must be directed and acyclic\")\n\n        if not nx.is_weakly_connected(dag):\n            raise CellConstructionFailure(\"Must be connected\")\n        clz.domain_map[clz] = dag", "response": "Sets the domain for a class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_boundaries(self):\n        if not self.__values_computed:\n            self.__compute_values()\n        return set(self.upper), set(self.lower)", "response": "Returns just the upper and lower boundaries of the most general positive\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_upper_bound(self):\n        nub = set()\n        for root in self.roots - self.upper:\n            found = False\n            for up in self.upper - self.roots:\n                domain = self.get_domain()\n                if has_path(domain, root, up):\n                    found = True\n                    break\n            if not found:\n                nub.add(root)\n        return nub | (self.upper - self.roots)", "response": "Compute the upper boundary of the entry set."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines whether two Partial Orderings share the same generalization as this one.", "response": "def is_domain_equal(self, other):\n        \"\"\"\n        Computes whether two Partial Orderings have the same generalization\n        structure.\n        \"\"\"\n        domain = self.get_domain()\n        other_domain = other.get_domain()\n        # if they share the same instance of memory for the domain\n        if domain == other_domain:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing whether two Partial Orderings contain the same information.", "response": "def is_equal(self, other):\n        \"\"\"\n        Computes whether two Partial Orderings contain the same information\n        \"\"\"\n        if not (hasattr(other, 'get_domain') or hasattr(other, 'upper') or hasattr(other, 'lower')):\n            other = self.coerce(other)\n        if self.is_domain_equal(other)  \\\n            and len(self.upper.symmetric_difference(other.upper)) == 0 \\\n            and len(self.lower.symmetric_difference(other.lower)) == 0:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_entailed_by(self, other):\n\n        \n        if not self.is_domain_equal(other):\n            return False\n        \n        \"\"\"        \n        First we compare the similarity between upper bounds, \n         (1) if Self's upper bound is empty, Other's upper bound will always\n            be as or more specific.\n         (2) if Self's upper bound is a subset of Other's, Other will always\n            be as or more specific.\n            \n         To prove the other has a more specific upper bound, we eliminate\n            cases where it does not.  The first condition ensures the above\n            two cases are not true.   Then, for each element in Other's upper\n            bound (that is not in Self's),\n            \n         (3) if, for all elements in other's upper bound, we cannot find a member\n           in the complete upper bound that is more general (has path from self[i]\n           to other[j]), we return False, indicating Other does not entail\n           Self.\n        \"\"\"\n        domain = self.get_domain()\n        self_full_upper = self.compute_upper_bound()\n        if not (len(self.upper) == 0 \\\n             or other.upper.issuperset(self.upper)):\n            for self_up in self_full_upper - other.upper:\n                found = False\n                # find a more specific member for each member\n                # of self.upper that's not in other.upper\n                for other_up in other.upper - self_full_upper:\n                    if has_path(domain, self_up, other_up):\n                        found = True\n                        break\n                if found:\n                    break\n                else:\n                    return False  # none was found     \n        \"\"\"        \n        Other must also share the same or more general 'lower' bound. \n\n         (3) if, for all elements in other's lower bound, we cannot find a member\n           in the complete upper bound that is more general (has path from self[i]\n           to other[j]), we stop.\n\n        \"\"\"\n        if not (len(self.lower) == 0 \\\n            or self.lower.issubset(other.lower)):\n            for self_lo in self.lower - other.lower:\n                found = False\n                for other_lo in other.lower - self.lower:\n                    if has_path(domain, self_lo, other_lo):\n                        found =True\n                        break\n                if found:\n                    break\n                else:\n                    return False  # none was found\n                    \n        # if we got this far, we should have an entailment!\n        return True", "response": "Returns True iff self and other are entailed by other."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the two sets are the same.", "response": "def is_contradictory(self, other):\n        \"\"\"\n        Does the merge yield the empty set? \n        \"\"\"\n        if not self.is_domain_equal(other):\n            return True\n        # what would happen if the two were combined? \n        test_lower = self.lower.union(other.lower)\n        test_upper = self.upper.union(other.upper)\n        # if there is a path from lower to upper nodes, we're in trouble:\n        domain = self.get_domain()\n        for low in test_lower:\n            for high in test_upper:\n                if low != high and has_path(domain, low, high):\n                    return True\n        # lastly, build a merged ordering and see if it has 0 members\n        test = self.__class__()\n        test.lower = test_lower\n        test.upper = test_upper\n        return len(test) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncoerce this domain to a new domain s cell.", "response": "def coerce(self, other, is_positive=True):\n        \"\"\"\n        Only copies a pointer to the new domain's cell\n        \"\"\"\n        if hasattr(other, 'get_domain') and hasattr(other, 'lower') and hasattr(other, 'upper'):\n            if self.is_domain_equal(other):\n                return other\n            else:\n                msg = \"Cannot merge partial orders with different domains!\"\n                raise CellConstructionFailure(msg)\n        if isinstance(other, LinearOrderedCell):\n            # convert other's domain to a chain/dag\n            # first ensure domain has same size and elements\n            raise NotImplemented(\"Please Implement me!\")\n        domain = self.get_domain()\n        if other in domain:\n            c = self.__class__()\n            if not is_positive:\n                # add value to lower (negative example)\n                c.lower = set([other])\n                c.upper = set()\n            else:\n                # add value to upper (positive example)\n                c.upper = set([other])\n                c.lower = set()\n            return c\n        else:       \n            raise CellConstructionFailure(\"Could not coerce value that is\"+\n                    \" outside order's domain . (Other = %s) \" % (str(other),))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge two partial order entries into this one.", "response": "def merge(self, other, is_positive=True):\n        \"\"\" Combines the partial order with either (1) a value in the partial \n        order's domain, or (2) another partial order with the same domain.\n\n        When combining with a value, an optional `is_positive` parameter can\n        be set to False, meaning that the merged value should be excluded.\n        \"\"\"\n        other = self.coerce(other, is_positive)\n        # the above coercion forces equal domains, and raises an \n        # exception otherwise\n        if self.is_equal(other):\n            pass\n        elif other.is_entailed_by(self):\n            # this is the case where the other contains all of the values\n            # we have and more, so we don't gain anything by keeping it around\n            pass  # do nothing\n        elif self.is_entailed_by(other):\n            # TODO: what if other has a size of 0, do we still merge?\n            # replace self with other\n            self.lower = other.lower\n            self.upper = other.upper\n            self.__values_computed = False\n            return self\n        elif self.is_contradictory(other):\n            raise Contradiction(\"Cannot merge partial orders\")\n        else:\n            # merge the two\n            def add_single_value(val, is_positive):\n                if not is_positive:\n                    # lower generalization boundaries\n                    # replace val with its parents\n                    if not val in self.lower:\n                        self.lower.add(val)\n                        self.__values_computed = False        \n                else:\n                    # raise specialization boundaries\n                    if not val in self.upper:\n                        self.upper.add(val)\n                        self.__values_computed = False\n\n            for general in other.upper:\n                add_single_value(general, True)\n            for specific in other.lower:\n                add_single_value(specific, False)\n\n        if len(self) == 0:\n            raise Contradiction(\"Partial Ordering has No Members\")\n            \n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_refinement_options(self):\n        domain = self.get_domain()\n        for upper_value in self.upper:\n            for suc in domain.successors(upper_value):\n                yield suc", "response": "Returns the possible specializations for the upper values in the taxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_relaxation_options(self):\n        domain = self.get_domain()\n        for upper_value in self.upper:\n            for suc in domain.predecessors(upper_value):\n                yield suc", "response": "Returns the possible generalizations for the upper values in the taxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a DOT graphviz file of the domain structure and returns the filename", "response": "def to_dotfile(self):\n        \"\"\" Writes a DOT graphviz file of the domain structure, and returns the filename\"\"\"\n        domain = self.get_domain()\n        filename = \"%s.dot\" % (self.__class__.__name__)\n        nx.write_dot(domain, filename)\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef error_handler_404(request):\n    from django.template import Context, loader\n    from django.http import HttpResponseServerError\n\n    t = loader.get_template('404.html')\n    return HttpResponseServerError(t.render(Context({\n        'request': request,\n        'settings': settings,\n    })))", "response": "500 error handler which includes request in the context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the url to redirect to.", "response": "def get_redirect_url(self, **kwargs):\n        \"\"\"\n        Redirect to request parameter 'next' or to referrer if url is not defined. \n        \"\"\"\n        if self.request.REQUEST.has_key('next'): \n            return self.request.REQUEST.get('next')\n        url = RedirectView.get_redirect_url(self, **kwargs)\n        if url:\n            return url\n        return self.request.META.get('HTTP_REFERER')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_to_response(self, context=False):\n        f = self.openfile()\n        wrapper = FileWrapper(f)\n        response = HttpResponse(wrapper, content_type=self.content_type())\n        self.headers(response)\n        return response", "response": "Send file to client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the keyword arguments for instantiating the form.", "response": "def get_form_kwargs(self):\n        \"\"\"\n        Returns the keyword arguments for instantiating the form.\n        \"\"\"\n        kwargs = super(FormAcceptsRequestMixin, self).get_form_kwargs()\n        if self.form_accepts_request:\n            kwargs.update({'request': self.request})\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the given context to a response using the response_class for this view.", "response": "def render_to_response(self, context, **response_kwargs):\n        \"\"\"\n        Returns a response, using the `response_class` for this\n        view, with a template rendered with the given context.\n\n        If any keyword arguments are provided, they will be\n        passed to the constructor of the response class.\n        \"\"\"\n        return HttpResponse(json.dumps(context, cls=JSON_ENCODER), \n                            content_type='application/json',\n                            **response_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the date for this request.", "response": "def get_date(self):\n        \"\"\"\n        Return (date_list, items, extra_context) for this request.\n        \"\"\"\n        year = self.get_year()\n        month = self.get_month()\n        day = self.get_day()\n\n        return _date_from_string(year, self.get_year_format(),\n                                 month, self.get_month_format(),\n                                 day, self.get_day_format())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies value is derived from whether user has a verification hash", "response": "def clean(self):\n        \"\"\"Verified value is derived from whether user has a verification hash\"\"\"\n        result = super(User, self).clean()\n        result['verified'] = 'verification_hash' not in self._resource\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the user s email is unique", "response": "def check_unique(self):\n        \"\"\"Check the user's email is unique\"\"\"\n        emails = yield self.view.values(key=self.email)\n        user_id = getattr(self, 'id', None)\n        users = {x for x in emails if x != user_id and x}\n\n        if users:\n            raise exceptions.ValidationError(\n                \"User with email '{}' already exists\".format(self.email))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_admin(cls, email, password, **kwargs):\n        data = {\n            'email': email,\n            'password': cls.hash_password(password),\n            'has_agreed_to_terms': True,\n            'state': State.approved,\n            'role': cls.roles.administrator.value,\n            'organisations': {}\n        }\n        data.update(**kwargs)\n\n        user = cls(**data)\n        yield user._save()\n\n        raise Return(user)", "response": "Create an approved global administrator"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhashes a plain text password", "response": "def hash_password(plain_text):\n        \"\"\"Hash a plain text password\"\"\"\n        # NOTE: despite the name this is a one-way hash not a reversible cypher\n        hashed = pbkdf2_sha256.encrypt(plain_text, rounds=8000, salt_size=10)\n        return unicode(hashed)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the user s password and save to the database", "response": "def change_password(self, previous, new_password):\n        \"\"\"\n        Change the user's password and save to the database\n\n        :param previous: plain text previous password\n        :param new_password: plain text new password\n        :raises: ValidationError\n        \"\"\"\n        if not self.verify_password(previous):\n            raise exceptions.Unauthorized('Incorrect password')\n\n        if len(new_password) < options.min_length_password:\n            msg = ('Passwords must be at least {} characters'\n                   .format(options.min_length_password))\n            raise exceptions.ValidationError(msg)\n\n        if len(new_password) > options.max_length_password:\n            msg = ('Passwords must be at no more than {} characters'\n                   .format(options.max_length_password))\n            raise exceptions.ValidationError(msg)\n\n        self.password = self.hash_password(new_password)\n        yield self._save()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login(cls, email, password):\n        try:\n            doc = yield cls.view.first(key=email, include_docs=True)\n        except couch.NotFound:\n            raise exceptions.Unauthorized('Unknown email address')\n\n        user = cls(**doc['doc'])\n\n        verified = user.verify_password(password)\n        if not verified:\n            raise exceptions.Unauthorized('Invalid password')\n\n        token = yield Token.create(user)\n        raise Return((user, token.id))", "response": "Log in a user by email and password."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify(cls, user_id, verification_hash):\n        user = yield cls.get(user_id)\n\n        # If user does not have verification hash then this means they have already been verified\n        if 'verification_hash' not in user._resource:\n            raise Return(user)\n\n        if user.verification_hash != verification_hash:\n            raise exceptions.ValidationError('Invalid verification hash')\n\n        del user.verification_hash\n        yield user._save()\n\n        raise Return(user)", "response": "Verify a user using the verification hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nis the user a system administrator?", "response": "def is_admin(self):\n        \"\"\"Is the user a system administrator\"\"\"\n        return self.role == self.roles.administrator.value and self.state == State.approved"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nam the user a reseller", "response": "def is_reseller(self):\n        \"\"\"is the user a reseller\"\"\"\n        return self.role == self.roles.reseller.value and self.state == State.approved"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_org_admin(self, organisation_id):\n        return (self._has_role(organisation_id, self.roles.administrator) or\n                self.is_admin())", "response": "Is the user authorized to administrate the organisation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_user(self, organisation_id):\n        return (self._has_role(organisation_id, self.roles.user) or\n                self.is_org_admin(organisation_id))", "response": "Is the user valid and approved in this organisation?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the user s role for the organisation", "response": "def _has_role(self, organisation_id, role):\n        \"\"\"Check the user's role for the organisation\"\"\"\n        if organisation_id is None:\n            return False\n\n        try:\n            org = self.organisations.get(organisation_id, {})\n            user_role = org.get('role')\n            state = org.get('state')\n        except AttributeError:\n            return False\n\n        return user_role == role.value and state == State.approved.name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove an organisation from all users", "response": "def remove_organisation_from_all(cls, organisation_id):\n        \"\"\"Remove an organisation from all users\"\"\"\n        users = yield views.organisation_members.get(key=organisation_id,\n                                                     include_docs=True)\n        users = [x['doc'] for x in users['rows']]\n        for user in users:\n            user['organisations'][organisation_id]['state'] = State.deactivated.name\n\n        db = cls.db_client()\n        yield db.save_docs(users)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef valid(cls, token, **kwargs):\n        try:\n            token = yield cls.get(token)\n        except couch.NotFound:\n            raise Return(False)\n\n        raise Return(token.ttl >= datetime.utcnow())", "response": "Check if a token exists and has not expired"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply seeds and arguments to the garden for use during the harvest", "response": "def plant(self, *seeds, **arguments):\n        \"\"\"Applys seeds and arguments\n        to the garden for use during the harvest\n        \"\"\"\n        map(self._clean, seeds)\n        self.network_kwargs.update(arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _harvest_validate(self, userkwargs):\n        # the valideer to parse the\n        # user arguemnts when watering\n        parser = {}\n\n        userkwargs.update(self.network_kwargs)\n        # a simple set of original provided argument keys (used in IGNORES)\n        original_kwargs = set(map(lambda k: k.split('_')[1] if k.find('_')>-1 else k, userkwargs.keys()))\n        # list of columns that are required from seeds\n        requires = []\n\n        # -------------\n        # Clean up Aggs\n        # -------------\n        for key in userkwargs.keys():\n            # agg example: \"avg_total\", \"max_tax\"\n            if key.find('_') > 0:\n                agg, base = tuple(key.split('_'))\n                if base in userkwargs:\n                    if type(userkwargs[base]) is not list:\n                        userkwargs[base] = [(None, userkwargs[base])]\n                    userkwargs[base].append( (agg, userkwargs.pop(key)) )\n                else:\n                    userkwargs[base] = [(agg, userkwargs.pop(key))]\n\n        # -----------------\n        # Process Arguments\n        # -----------------\n        for key, seed in self.arguments.iteritems():\n            # --------------\n            # Argument Alias\n            # --------------\n            if seed.get('alias') and key in userkwargs:\n                # pop the value form the user kwargs (to change the key later)\n                value = userkwargs.pop(key) if key in userkwargs else NotImplemented\n                # for duplicate keys\n                oldkey = key+\"\"\n                # change the key\n                key = seed.get('alias')\n                # change the seed\n                seed = get(self.arguments, seed.get('alias'))\n                # set the new key:value\n                if value is not NotImplemented:\n                    if key in userkwargs:\n                        raise valideer.ValidationError(\"Argument alias already specified for `%s` via `%s`\" % (oldkey, key), oldkey)\n                    userkwargs[key] = value\n\n            # can provide multiple arguments\n            if key.endswith('[]'):\n                multi = True\n                key = key[:-2]\n            else:\n                multi = False\n\n            # get value(s) from user\n            if key in userkwargs:\n                value = userkwargs.pop(key)\n            elif seed.get('copy'):\n                value = userkwargs.get(seed.get('copy'))\n            else:\n                value = seed.get('default')\n\n            # no argument provided, lets continue)\n            if value is None or value == []:\n                if seed.get('required'):\n                    raise valideer.ValidationError(\"missing required property: %s\" % key, key)\n                else:\n                    continue\n\n            # add requires\n            requires.extend(array(get(seed, 'requires', [])))\n\n            # -----------\n            # Inheritance\n            # -----------\n            # not permited from arguements yet. would need to happen above the \"\"PROCESS ARGUMENT\"\" block\n            # self._inherit(*array(get(seed, 'inherit', [])))\n\n            if type(value) is list and type(value[0]) is tuple:\n                # complex\n                for v in value:\n                    ud, pd = self._harvest_args(key, seed, v, multi)\n                    userkwargs.update(ud)\n                    parser.update(pd)\n            else:\n                ud, pd = self._harvest_args(key, seed, value, multi)\n                userkwargs.update(ud)\n                parser.update(pd)\n\n        # ------------\n        # Ignored Keys\n        # ------------\n        for seed in self.seeds:\n            ignores = set(array(get(seed, 'ignore')))\n            if ignores:\n                if ignores & original_kwargs:\n                    if not get(seed, 'silent'):\n                        additionals = ignores & original_kwargs\n                        raise valideer.ValidationError(\"additional properties: %s\" % \",\".join(additionals), additionals)\n                [userkwargs.pop(key) for key in ignores if key in userkwargs]\n\n        # -------------------------\n        # Custom Operators (part 1)\n        # -------------------------\n        operators = {}\n        for key, value in userkwargs.items():\n            rk = key\n            agg = None\n            if key.find('_')>-1:\n                agg, rk = tuple(key.split('_'))\n            seed = self.arguments.get(rk, self.arguments.get(rk+'[]'))\n            if seed:\n                if type(value) is list:\n                    operators[key] = []\n                    # need to remove the operator for validating\n                    new_values = []\n                    for v in value:\n                        operator, v = self._operator(v, *seed.get('column', \"\").rsplit(\"::\", 1))\n                        new_values.append(v)\n                        operators[key].append((agg, operator) if agg else operator)\n                    userkwargs[key] = new_values\n                else:\n                    operator, value = self._operator(value, *seed.get('column', \"\").rsplit(\"::\", 1))\n                    operators[key] = (agg, operator) if agg else operator\n                    userkwargs[key] = value\n\n        # -----------------\n        # Plant Sort Method\n        # -----------------\n        if 'sortby' in userkwargs:\n            seed = self.arguments.get(userkwargs['sortby'].lower(), self.arguments.get(userkwargs['sortby'].lower()+'[]'))\n            if seed:\n                seed['id'] = str(userkwargs['sortby'].lower())\n\n        for r in set(requires):\n            if userkwargs.get(r) is None:\n                raise valideer.ValidationError(\"required property not set: %s\" % r, r)\n\n        # --------\n        # Validate\n        # --------\n        parser = valideer.parse(parser, additional_properties=False)\n        validated = parser.validate(userkwargs, adapt=self.navigator.adapter())\n        validated.update(self.network_kwargs)\n        #   operators                   validated\n        # --------------------------- | --------------------------------\n        # {                           {\n        #   \"type\": [\"!\", \"!\"],         \"type\": ['a', 'b'],\n        #   \"total\": \"<\",               \"total\": \"50\",\n        #   \"tax\": (\"avg, \">\"),         \"tax\": \"1\",\n        #   \"time\": None                \"time\": \"2014\"\n        # }                           }\n        return operators, validated", "response": "Validate and Plant user provided arguments and return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a seed and applies it to the garden", "response": "def _clean(self, seed):\n        \"\"\"Takes a seed and applies it to the garden\n        \"\"\"\n        seed = deepcopy(seed)\n        # inherit any other figures\n        self._inherit(*array(get(seed, 'inherit', [])))\n        # merge the seed arguments\n        if '&arguments' in seed:\n            self.arguments = merge(self.arguments, seed.pop('&arguments'))\n\n        elif 'arguments' in seed:\n            self.arguments = seed.pop('arguments')\n        # append the seed\n        self.seeds.append(seed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_base_mimetypes(self):\n        for t in self.type_instances:\n            if t.custom_mime:\n                continue\n\n            yield t.mime, (t, None, None)", "response": "Generate the base mimetypes as described by non customized document\n        types."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the p - value t - score t - score and standard error of the CV errors of two models and returns the p - value t - score t - score and mu - value", "response": "def crossvalidation_stats(errors1, errors2):\n    \"\"\"Paired difference test\n    of the CV errors of two models\n\n    Parameters:\n    -----------\n    errors1 : ndarray\n        The CV errors model 1\n\n    errors2 : ndarray\n        The CV errors model 2\n\n    Returns:\n    --------\n    pvalue : float\n        Two-sided P-value if the differences between err1 and err2\n        are significant\n\n    tscore : float\n        t-statistics\n\n    se : float\n        Standard Error of the CV-Error-Difference\n\n    mu : float\n        The average difference between err1 and err2\n\n    \"\"\"\n    # load modules\n    import numpy as np\n    import scipy.stats\n    import warnings\n\n    # Number of blocks\n    K = errors1.shape[0]\n\n    # display warnings\n    if K < 30:\n        warnings.warn((\n            \"The number of blocks is K<30 what is insufficient \"\n            \"for conducting a t-Test to compare both models! \"\n            \"K=40 is suggested.\"))\n\n    # difference between errors\n    delta = errors1 - errors2\n\n    # the average difference\n    mu = np.mean(delta)\n\n    # Standard Error of the CV-Error-Difference\n    #   se = np.sqrt(np.sum((delta-np.mean(delta))**2)/K)\n    se = np.std(delta)\n\n    # t-statistics\n    tscore = mu / se\n\n    # Two-sided P-value\n    pvalue = scipy.stats.t.sf(np.abs(tscore), K - 1) * 2\n\n    # done\n    return pvalue, tscore, se, mu"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef badRequestMethod(self, environ, start_response):\n        response = \"400 Bad Request\\n\\nTo access this PyAMF gateway you \" \\\n            \"must use POST requests (%s received)\" % environ['REQUEST_METHOD']\n\n        start_response('400 Bad Request', [\n            ('Content-Type', 'text/plain'),\n            ('Content-Length', str(len(response))),\n            ('Server', gateway.SERVER_NAME),\n        ])\n\n        return [response]", "response": "Return HTTP 400 Bad Request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncollecting potential migration modules and load them", "response": "def collect(self):\n        \"\"\"\n        Walks self.migration_home and load all potential migration modules\n        \"\"\"\n        for root, dirname, files in walk(self.migration_home):\n            for file_name in file_filter(files, \"*.py\"):\n                file_name = file_name.replace('.py', '')\n                file = None\n                try:\n                    if file_name == '__init__':\n                        continue\n                    file, pathname, description = find_module(\n                        file_name, [root])\n                    load_module(file_name, file, pathname, description)\n                finally:\n                    if file is not None:\n                        file.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new(self, name):\n        #XXX:dc: assert that the name is somewhat sane and follows python\n        # naming conventions\n        next_id = 0\n        cls_name = '_'.join((name, next_id))\n        with open(pjoin(self.migration_home, name), \"w+\") as new_migration:\n            print >> new_migration, migration_tmpl.format(\n                cls_name=cls_name, migration_name=name)", "response": "Create a new migration with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the refugee. ini file for the given directory.", "response": "def init(self, directory):\n        \"\"\"\n        Drops the essential goods for running migrations into a given\n        directory. Really any directory and config file could be used. For now\n        the default layout will be::\n\n            directory/\n                __init__.py\n                refugee.ini\n                migrations/\n                    __init__.py\n                    <named migration>.py\n\n        :param directory: top level directory to place the migrations under\n        \"\"\"\n        #XXX:dc: are these good defaults?\n        path = pjoin(directory, 'migrations')\n        makedirs(path)\n        with open(pjoin(directory, 'refugee.ini'), 'w+') as conf:\n            print >> conf, configuration_tmpl.format(path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun all registered migrations in the given direction", "response": "def run_all(self, direction):\n        \"\"\"\n        Runs all registered migrations\n\n        :param direction: Can be on of two values, UP or DOWN\n        \"\"\"\n        for key in sorted(migration_registry.keys):\n            self.run(key, direction)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, migration_name, direction):\n        if not self.engine:\n            raise AttributeError(\"No engine configured for MigrationManager\")\n\n        connection = self.engine.connect()\n        trans = connection.begin()\n        try:\n            migration = migration_registry[migration_name]()\n            if migration.preflight():\n                trans = connection.begin()\n\n            if direction == Direction.UP:\n                migration.up(connection)\n            elif direction == Direction.DOWN:\n                migration.down(connection)\n            else:\n                raise UnknowDirectionError\n\n            if migration.check():\n                trans.commit()\n            else:\n                raise MigrationError(\"Migration failed consistency checks\")\n        except Exception, e:\n            trans.rollback()\n            #XXX:dc: do more to introspect why we failed\n            raise e", "response": "Runs the registered migration in the given direction"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload - URL from Maven", "response": "def maven_url(self):\n        '''\n        Download-URL from Maven\n        '''\n        return '{prefix}/{path}/{artifact}/{version}/{filename}'.format(\n            prefix   = MAVEN_PREFIX,\n            path     = '/'.join(self.group.split('.')),\n            artifact = self.artifact,\n            version  = self.version,\n            filename = self.filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_to(self, folder):\n        '''\n        Download into a folder\n        '''\n        urlretrieve(self.maven_url, os.path.join(folder, self.filename))", "response": "Download into a folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef radar_factory(num_vars, frame='circle'):\n    # calculate evenly-spaced axis angles\n    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n    # rotate theta such that the first axis is at the top\n    theta += np.pi/2\n\n    def draw_poly_patch(self):\n        verts = unit_poly_verts(theta)\n        return plt.Polygon(verts, closed=True, edgecolor='k')\n\n    def draw_circle_patch(self):\n        # unit circle centered on (0.5, 0.5)\n        return plt.Circle((0.5, 0.5), 0.5)\n\n    patch_dict = {'polygon': draw_poly_patch, 'circle': draw_circle_patch}\n    if frame not in patch_dict:\n        raise ValueError('unknown value for `frame`: %s' % frame)\n\n    class RadarAxes(PolarAxes):\n\n        name = 'radar'\n        # use 1 line segment to connect specified points\n        RESOLUTION = 1\n        # define draw_frame method\n        draw_patch = patch_dict[frame]\n\n        def fill(self, *args, **kwargs):\n            \"\"\"Override fill so that line is closed by default\"\"\"\n            closed = kwargs.pop('closed', True)\n            return super(RadarAxes, self).fill(closed=closed, *args, **kwargs)\n\n        def plot(self, *args, **kwargs):\n            \"\"\"Override plot so that line is closed by default\"\"\"\n            lines = super(RadarAxes, self).plot(*args, **kwargs)\n            for line in lines:\n                self._close_line(line)\n\n        def _close_line(self, line):\n            x, y = line.get_data()\n            # FIXME: markers at x[0], y[0] get doubled-up\n            if x[0] != x[-1]:\n                x = np.concatenate((x, [x[0]]))\n                y = np.concatenate((y, [y[0]]))\n                line.set_data(x, y)\n\n        def set_varlabels(self, labels):\n            self.set_thetagrids(np.degrees(theta), labels)\n\n        def _gen_axes_patch(self):\n            return self.draw_patch()\n\n        def _gen_axes_spines(self):\n            if frame == 'circle':\n                return PolarAxes._gen_axes_spines(self)\n            # The following is a hack to get the spines (i.e. the axes frame)\n            # to draw correctly for a polygon frame.\n\n            # spine_type must be 'left', 'right', 'top', 'bottom', or `circle`.\n            spine_type = 'circle'\n            verts = unit_poly_verts(theta)\n            # close off polygon by repeating first vertex\n            verts.append(verts[0])\n            path = Path(verts)\n\n            spine = Spine(self, spine_type, path)\n            spine.set_transform(self.transAxes)\n            return {'polar': spine}\n\n    register_projection(RadarAxes)\n    return theta", "response": "Create a radar chart with num_vars axes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn vertices of a unit polygon for subplot axes.", "response": "def unit_poly_verts(theta):\n    \"\"\"Return vertices of polygon for subplot axes.\n\n    This polygon is circumscribed by a unit circle centered at (0.5, 0.5)\n    \"\"\"\n    x0, y0, r = [0.5] * 3\n    verts = [(r*np.cos(t) + x0, r*np.sin(t) + y0) for t in theta]\n    return verts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_logging_factories(loader):\n    loader.register_factory(logging.Logger, LoggerFactory)\n    loader.register_factory(logging.Handler, LoggingHandlerFactory)", "response": "Registers default logging factories for logging standard package."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall documentation: `/preapproval/create <https://www.wepay.com/developer/reference/preapproval#create>`_, plus extra keyword parameters: :keyword str access_token: will be used instead of instance's ``access_token``, with ``batch_mode=True`` will set `authorization` param to it's value. :keyword bool batch_mode: turn on/off the batch_mode, see :class:`wepay.api.WePay` :keyword str batch_reference_id: `reference_id` param for batch call, see :class:`wepay.api.WePay` :keyword str api_version: WePay API version, see :class:`wepay.api.WePay`", "response": "def __create(self, short_description, period, **kwargs):\n        \"\"\"Call documentation: `/preapproval/create\n        <https://www.wepay.com/developer/reference/preapproval#create>`_, plus\n        extra keyword parameters:\n\n        :keyword str access_token: will be used instead of instance's\n           ``access_token``, with ``batch_mode=True`` will set `authorization`\n           param to it's value.\n\n        :keyword bool batch_mode: turn on/off the batch_mode, see\n           :class:`wepay.api.WePay`\n\n        :keyword str batch_reference_id: `reference_id` param for batch call,\n           see :class:`wepay.api.WePay`\n\n        :keyword str api_version: WePay API version, see\n           :class:`wepay.api.WePay`\n\n        \"\"\"\n        params = {\n            'short_description': short_description,\n            'period': period\n        }\n        return self.make_call(self.__create, params, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncancel a preapproval from a specific preapproval.", "response": "def __cancel(self, preapproval_id, **kwargs):\n        \"\"\"Call documentation: `/preapproval/cancel\n        <https://www.wepay.com/developer/reference/preapproval#cancel>`_, plus\n        extra keyword parameters:\n\n        :keyword str access_token: will be used instead of instance's\n           ``access_token``, with ``batch_mode=True`` will set `authorization`\n           param to it's value.\n\n        :keyword bool batch_mode: turn on/off the batch_mode, see\n           :class:`wepay.api.WePay`\n\n        :keyword str batch_reference_id: `reference_id` param for batch call,\n           see :class:`wepay.api.WePay`\n\n        :keyword str api_version: WePay API version, see\n           :class:`wepay.api.WePay`\n\n        \"\"\"\n        params = {\n            'preapproval_id': preapproval_id\n        }\n        return self.make_call(self.__cancel, params, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __modify(self, preapproval_id, **kwargs):\n        params = {\n            'preapproval_id': preapproval_id\n        }\n        return self.make_call(self.__modify, params, kwargs)", "response": "Modify the internal state of a specific preapproval."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_subscription(self, channel, callback_function):\n        if channel not in CHANNELS:\n            CHANNELS.append(channel)\n            SUBSCRIPTIONS[channel] = [callback_function]\n        else:\n            SUBSCRIPTIONS[channel].append(callback_function)\n        # If a channel gets added after subscription has already been called\n        # call subscribe on the individual channel, here.\n        if self._subscribed:\n            _LOGGER.info(\"New channel added after main subscribe call.\")\n            self._pubnub.subscribe().channels(channel).execute()", "response": "Add a channel to subscribe to and a callback function to run when the channel receives an update."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a new thread timer to keep the keep_alive_function running every keep_alive seconds.", "response": "def _run_keep_alive(self):\n        \"\"\"\n        Start a new thread timer to keep the keep_alive_function running\n        every keep_alive seconds.\n        \"\"\"\n        threading.Timer(self._keep_alive, self._run_keep_alive).start()\n        _LOGGER.info(\"Polling the API\")\n        # This may or may not return something\n        self._keep_alive_function()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop all pubnub operations and unsubscribe from the topic.", "response": "def unsubscribe(self):\n        \"\"\"\n        Completly stop all pubnub operations.\n        \"\"\"\n        _LOGGER.info(\"PubNub unsubscribing\")\n        self._pubnub.unsubscribe_all()\n        self._pubnub.stop()\n        self._pubnub = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsubscribes to the channel list.", "response": "def _subscribe(self):\n        \"\"\"\n        Start the subscription to the channel list.\n        If self._keep_alive_function isn't None start timer thread to\n        run self._keep_alive_function every self._keep_alive amount of seconds.\n        \"\"\"\n        _LOGGER.info(\"PubNub subscribing\")\n        self._pubnub.subscribe().channels(CHANNELS).execute()\n        if self._keep_alive_function is not None:\n            threading.Timer(self._keep_alive, self._run_keep_alive).start()\n        self._subscribed = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when a new message is received on one of the subscribed to channels.", "response": "def message(self, pubnub, message):\n        \"\"\"\n        Called when a new message is recevied on one of the subscribed\n        to channels.\n        Proccess the message and call the channels callback function(s).\n        \"\"\"\n        try:\n            json_data = json.dumps(message.message.get('data'))\n        except AttributeError:\n            json_data = message.message\n        for func in SUBSCRIPTIONS[message.channel]:\n            # This means pubnub couldn't get the current state of the channel\n            # The pull_url is the location to pull the current state from.\n            # Returning None here to have the calling program handle this.\n            if 'pull_url' in json_data:\n                func(None)\n            else:\n                func(json.loads(json_data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clone(self, klass=None, memo=None, **kwargs):\n        obj = Empty()\n        obj.__class__ = klass or self.__class__\n\n        obj.resource = self.resource\n\n        obj.filters = self.filters.copy()\n        obj.order_by = self.order_by\n\n        obj.low_mark = self.low_mark\n        obj.high_mark = self.high_mark\n\n        obj.__dict__.update(kwargs)\n\n        return obj", "response": "Creates a copy of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_limits(self, low=None, high=None):\n        if high is not None:\n            if self.high_mark is not None:\n                self.high_mark = min(self.high_mark, self.low_mark + high)\n            else:\n                self.high_mark = self.low_mark + high\n        if low is not None:\n            if self.high_mark is not None:\n                self.low_mark = min(self.high_mark, self.low_mark + low)\n            else:\n                self.low_mark = self.low_mark + low", "response": "Adjusts the limits on the rows retrieved."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef results(self, limit=100):\n        limited = True if self.high_mark is not None else False\n        rmax = self.high_mark - self.low_mark if limited else None\n        rnum = 0\n\n        params = self.get_params()\n        params[\"offset\"] = self.low_mark\n        params[\"limit\"] = limit\n\n        while not limited and rmax is None or rnum < rmax:\n            if limited or rmax is not None:\n                rleft = rmax - rnum\n                params[\"limit\"] = rleft if rleft < limit else limit\n\n            r = self.resource._meta.api.http_resource(\"GET\", self.resource._meta.resource_name, params=params)\n            data = self.resource._meta.api.resource_deserialize(r.text)\n\n            if not limited:\n                rmax = data[\"meta\"][\"total_count\"]\n\n            if data[\"meta\"][\"total_count\"] < rmax:\n                rmax = data[\"meta\"][\"total_count\"]\n\n            params[\"offset\"] = data[\"meta\"][\"offset\"] + data[\"meta\"][\"limit\"]\n\n            for item in data[\"objects\"]:\n                rnum += 1\n                yield item", "response": "Yields the results from the API efficiently handling pagination and passing all paramaters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self):\n        uris = [obj[\"resource_uri\"] for obj in self.results()]\n        data = self.resource._meta.api.resource_serialize({\"objects\": [], \"deleted_objects\": uris})\n        self.resource._meta.api.http_resource(\"PATCH\", self.resource._meta.resource_name, data=data)\n\n        return len(uris)", "response": "Deletes the results of this query and issues a PATCH against the list uri of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_count(self):\n        params = self.get_params()\n        params[\"offset\"] = self.low_mark\n        params[\"limit\"] = 1\n\n        r = self.resource._meta.api.http_resource(\"GET\", self.resource._meta.resource_name, params=params)\n        data = self.resource._meta.api.resource_deserialize(r.text)\n\n        number = data[\"meta\"][\"total_count\"]\n\n        # Apply offset and limit constraints manually, since using limit/offset\n        # in the API doesn't change the total_count output.\n        number = max(0, number - self.low_mark)\n        if self.high_mark is not None:\n            number = min(number, self.high_mark - self.low_mark)\n\n        return number", "response": "Gets the total_count using the current filter constraints."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterator(self):\n\n        for item in self.query.results():\n            obj = self.resource(**item)\n\n            yield obj", "response": "An iterator over the results from applying this QuerySet to the api."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of records in the current QuerySet.", "response": "def count(self):\n        \"\"\"\n        Returns the number of records as an integer.\n\n        If the QuerySet is already fully cached this simply returns the length\n        of the cached results set to avoid an api call.\n        \"\"\"\n        if self._result_cache is not None and not self._iter:\n            return len(self._result_cache)\n\n        return self.query.get_count()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, *args, **kwargs):\n        clone = self.filter(*args, **kwargs)\n\n        if self.query.can_filter():\n            clone = clone.order_by()\n\n        num = len(clone)\n\n        if num == 1:\n            return clone._result_cache[0]\n        if not num:\n            raise self.resource.DoesNotExist(\n                \"%s matching query does not exist. \"\n                \"Lookup parameters were %s\" %\n                (self.resource._meta.resource_name, kwargs))\n\n        raise self.resource.MultipleObjectsReturned(\n            \"get() returned more than one %s -- it returned %s! \"\n            \"Lookup parameters were %s\" %\n            (self.resource._meta.resource_name, num, kwargs))", "response": "Performs the query and returns a single object matching the given keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new object with the given kwargs saves it to the api and returning the created object.", "response": "def create(self, **kwargs):\n        \"\"\"\n        Creates a new object with the given kwargs, saving it to the api\n        and returning the created object.\n        \"\"\"\n        obj = self.resource(**kwargs)\n        obj.save(force_insert=True)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_or_create(self, **kwargs):\n        assert kwargs, \"get_or_create() must be passed at least one keyword argument\"\n\n        defaults = kwargs.pop(\"defaults\", {})\n        lookup = kwargs.copy()\n\n        try:\n            return self.get(**lookup), False\n        except self.resource.DoesNotExist:\n            params = dict([(k, v) for k, v in kwargs.items()])\n            params.update(defaults)\n\n            obj = self.create(**params)\n            return obj, True", "response": "Gets an object with the given kwargs creating one if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the records in the current QuerySet.", "response": "def delete(self):\n        \"\"\"\n        Deletes the records in the current QuerySet.\n        \"\"\"\n        assert self.query.can_filter(), \"Cannot use 'limit' or 'offset' with delete.\"\n\n        del_query = self._clone()\n\n        # Disable non-supported fields.\n        del_query.query.clear_ordering()\n\n        return del_query.query.delete()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new QuerySet with the args ANDed to the existing set.", "response": "def filter(self, **kwargs):\n        \"\"\"\n        Returns a new QuerySet instance with the args ANDed to the existing\n        set.\n        \"\"\"\n        if kwargs:\n            assert self.query.can_filter(), \"Cannot filter a query once a slice has been taken.\"\n\n        clone = self._clone()\n        clone.query.add_filters(**kwargs)\n\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new QuerySet with the ordering changed.", "response": "def order_by(self, field_name=None):\n        \"\"\"\n        Returns a new QuerySet instance with the ordering changed.\n        \"\"\"\n        assert self.query.can_filter(), \"Cannot reorder a query once a slice has been taken.\"\n\n        clone = self._clone()\n        clone.query.clear_ordering()\n\n        if field_name is not None:\n            clone.query.add_ordering(field_name)\n\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _fill_cache(self, num=None):\n        if self._iter:\n            try:\n                for i in range(num or ITER_CHUNK_SIZE):\n                    self._result_cache.append(next(self._iter))\n            except StopIteration:\n                self._iter = None", "response": "Fill the result cache with num entries."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exclude(source, keys, *, transform=None):\n  check = keys if callable(keys) else lambda key: key in keys\n  return {key: transform(source[key]) if transform else source[key]\n          for key in source if not check(key)}", "response": "Returns a dictionary excluding keys from a source dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pick(source, keys, *, transform=None):\n  check = keys if callable(keys) else lambda key: key in keys\n  return {key: transform(source[key]) if transform else source[key]\n          for key in source if check(key)}", "response": "Returns a dictionary including only specified keys from a source dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an object to JSON via the defaults set with register_json_default.", "response": "def json_default(obj):\n  \"\"\"Convert an object to JSON, via the defaults set with register_json_default.\n\n  :obj: the object to convert\n  \"\"\"\n  for default in _JSON_DEFAULTS:\n    if default[0](obj):\n      return default[1](obj)\n  raise TypeError(repr(obj) + \" is not JSON serializable\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_json(obj, pretty=False):\n  sort_keys = False\n  indent = None\n  separators = (\",\", \":\")\n\n  if isinstance(pretty, tuple):\n    sort_keys, indent, separators = pretty\n  elif pretty is True:\n    sort_keys = True\n    indent = 2\n    separators = (\", \", \": \")\n\n  return json.dumps(obj, sort_keys=sort_keys, indent=indent, separators=separators,\n                    default=json_default)", "response": "Converts an object to JSON using the default values specified in register_json_default."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_value(obj, name):\n  if obj is None:\n    return (False, None)\n  elif isinstance(obj, dict):\n    return (name in obj, obj.get(name))\n  elif hasattr(obj, name):\n    return (True, getattr(obj, name))\n  elif hasattr(obj, \"__getitem__\") and hasattr(obj, \"__contains__\") and name in obj:\n    return (True, obj[name])\n  else:\n    return (False, None)", "response": "A flexible method for getting values from objects by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value(obj, name, fallback=None):\n  present, value = has_value(obj, name)\n  if present:\n    return value\n  else:\n    if callable(fallback):\n      return fallback()\n    else:\n      return fallback", "response": "Returns the value of the object with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_value(obj, name, value):\n  if hasattr(obj, \"__setitem__\"):\n    obj[name] = value\n  else:\n    setattr(obj, name, value)", "response": "A flexible method for setting a value on an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef with_defaults(method, nparams, defaults=None):\n  args = [None] * nparams if not defaults else defaults + max(nparams - len(defaults), 0) * [None]\n  return method(*args)", "response": "Call method with nparams positional parameters all non - specified defaults are passed None."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delegate(from_owner, to_owner, methods):\n  for method in methods:\n    _delegate(from_owner, to_owner, method)", "response": "Creates methods on from_owner to call through to methods on to_owner."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _delegate(from_owner, to_owner, method):\n  dgate = lambda self, *args, **kwargs: getattr(getattr(self, to_owner), method)(*args, **kwargs)\n  dgate.__name__ = method\n  dgate.__doc__ = \"Delegates to {0}.{1}: {2}\".format(to_owner, method, method.__doc__)\n  setattr(from_owner, method, dgate)", "response": "Creates a method on from_owner to calls through to the same method on to_owner."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flatten_dict(source, ancestors=None):\n  if not ancestors:\n    ancestors = ()\n  for key in source:\n    if isinstance(source[key], dict):\n      yield from flatten_dict(source[key], ancestors + (key, ))\n    else:\n      yield (ancestors + (key, ), source[key])", "response": "Flattens a dictionary into a list of tuples where key is a tuple of ancestor keys and value is a tuple of ancestor keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_file_object(filename, mode=\"r\"):\n  if filename is None:\n    if mode.startswith(\"r\"):\n      yield sys.stdin\n    else:\n      yield sys.stdout\n  else:\n    with open(filename, mode) as fobj:\n      yield fobj", "response": "Context manager for a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_methods(extension_name):\n    extension = get_extension(extension_name)\n    methods = {}\n    for name, i in inspect.getmembers(extension):\n        if hasattr(i, 'nago_access'):\n            api_name = i.nago_name\n            methods[api_name] = i\n    return methods", "response": "Return all methods in a nago_vagrant extension that have nago_access set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate a package name or a path specification into a real file system pathname.", "response": "def package_to_directory(package_path: str) -> str:\n    \"\"\"\n    Translate a package/path specification into a real file system pathname.\n\n    :param package_path: a package name or a package/path specification like\n        ``package.subpackage/directory/subdirectory``\n    :return: the translated path name\n    :raises ImportError: if the package cannot be imported\n    :raises LookupError: if the directory does not exist\n\n    \"\"\"\n    if '/' in package_path:\n        pkgname, subpath = package_path.split('/', 1)\n    else:\n        pkgname, subpath = package_path, ''\n\n    module = import_module(pkgname)\n    path = Path(module.__spec__.origin).parent / subpath\n    if path.exists():\n        if path.is_dir():\n            return str(path)\n        else:\n            raise LookupError('{} is not a directory'.format(path))\n    else:\n        raise LookupError('{} does not exist'.format(path))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting column arguments to integers.", "response": "def column_converter(string):\n    \"\"\"\n    Converts column arguments to integers.\n\n    - Accepts columns in form of INT, or the range INT-INT.\n    - Returns a list of one or more integers.\n    \"\"\"\n    column = string.strip(',')\n    if '-' in column:\n        column_range = map(int, column.split('-'))\n        # For decreasing ranges, increment the larger value, reverse the\n        # passing to range (so it will accept the input), and finally\n        # reverse the output ([::-1])\n        if column_range[0] > column_range[1]:\n            column_range[0] += 1\n            return [i for i in range(*column_range[::-1])][::-1]\n        # For normal ranges, increment the larger value.\n        column_range[1] += 1\n        return [i for i in range(*column_range)]\n    if ',' in column:\n        columns = column.split(',')\n        return map(int, columns)\n    return [int(column)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the column is the minimum between the largest column asked and the max column available in the line.", "response": "def check_columns(column, line, columns):\n    \"\"\"\n    Make sure the column is the minimum between the largest column asked\n    for and the max column available in the line.\n    \"\"\"\n    return column <= min(len(line), max(columns))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Kargs2Attr( ):\n    \n    \"\"\"\n    This Decorator Will:\n     Read **kwargs key and add it to current Object-class ClassTinyDecl under current\n     name readed from **kwargs key name. \n            \n    \"\"\"\n    def decorator( func ):\n        def inner( **kwargs ):\n          for ItemName in kwargs.keys():\n            setattr( __builtins__, ItemName , kwargs[ItemName] )\n          func( **kwargs )\n        return inner\n    return decorator", "response": "This decorator is used to add attributes to the object - class under current\n name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an error message based on the last traceback and the request that was sent.", "response": "def generate_error(request, cls, e, tb, include_traceback=False):\n    \"\"\"\n    Builds an L{ErrorMessage<pyamf.flex.messaging.ErrorMessage>} based on the\n    last traceback and the request that was sent.\n    \"\"\"\n    import traceback\n\n    if hasattr(cls, '_amf_code'):\n        code = cls._amf_code\n    else:\n        code = cls.__name__\n\n    details = None\n    rootCause = None\n\n    if include_traceback:\n        details = traceback.format_exception(cls, e, tb)\n        rootCause = e\n\n    faultDetail = None\n    faultString = None\n\n    if hasattr(e, 'message'):\n        faultString = unicode(e.message)\n    elif hasattr(e, 'args') and e.args:\n        if isinstance(e.args[0], pyamf.python.str_types):\n            faultString = unicode(e.args[0])\n\n    if details:\n        faultDetail = unicode(details)\n\n    return messaging.ErrorMessage(\n        messageId=generate_random_id(),\n        clientId=generate_random_id(),\n        timestamp=calendar.timegm(time.gmtime()),\n        correlationId=request.messageId,\n        faultCode=code,\n        faultString=faultString,\n        faultDetail=faultDetail,\n        extendedData=details,\n        rootCause=rootCause)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buildErrorResponse(self, request, error=None):\n        if error is not None:\n            cls, e, tb = error\n        else:\n            cls, e, tb = sys.exc_info()\n\n        return generate_error(request, cls, e, tb, self.gateway.debug)", "response": "Builds an error response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a fatal error and exits the application.", "response": "def panic(self, *args):\n        \"\"\"\n        Creates a fatal error and exit\n        \"\"\"\n        self._err(\"fatal\", *args)\n        if self.test_errs_mode is False:  # pragma: no cover\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a warning message", "response": "def warning(self, *args) -> \"Err\":\n        \"\"\"\n        Creates a warning message\n        \"\"\"\n        error = self._create_err(\"warning\", *args)\n        print(self._errmsg(error))\n        return error"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info(self, *args) -> \"Err\":\n        error = self._create_err(\"info\", *args)\n        print(self._errmsg(error))\n        return error", "response": "Creates an info message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef debug(self, *args) -> \"Err\":\n        error = self._create_err(\"debug\", *args)\n        print(self._errmsg(error))\n        return error", "response": "Creates a debug message and prints it to stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an error object and add it to the internal list of errors.", "response": "def _create_err(self, errclass: str, *args) -> \"Err\":\n        \"\"\"\n        Create an error\n        \"\"\"\n        error = self._new_err(errclass, *args)\n        self._add(error)\n        return error"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an error object and adds it to the internal list of errors.", "response": "def _err(self, errclass: str=\"error\", *args) -> \"Err\":\n        \"\"\"\n        Creates an error\n        \"\"\"\n        error = self._new_err(errclass, *args)\n        if self.log_errs is True:\n            sep = \" \"\n            if self.log_format == \"csv\":\n                sep = \",\"\n            msg = str(datetime.now()) + sep + \\\n                self._errmsg(error, msgformat=self.log_format)\n            self.logger.error(msg)\n        print(self._errmsg(error))\n        self._add(error)\n        return error"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _new_err(self, errclass: str, *args) -> 'Err':\n        # get the message or exception\n        ex, msg = self._get_args(*args)\n        # construct the error\n        # handle exception\n        ftb = None  # type: str\n        function = None  # type: str\n        errtype = None  # type: str\n        file = None  # type: str\n        line = None  # type: int\n        code = None  # type: str\n        ex_msg = None  # type: str\n        caller = None  # type: str\n        caller_msg = None  # type: str\n\n        st = inspect.stack()\n\n        if ex is not None:\n            # get info from exception\n            errobj, ex_msg, tb = sys.exc_info()\n            tb = traceback.extract_tb(tb)\n            file, line, function, code = tb[-1]\n            # if called from an external lib\n            if len(tb) > 1:\n                file, line, caller, code = tb[0]\n            else:\n                call_stack = []\n                for c in st:\n                    call_stack.append(c[3])\n                caller = self._get_caller(call_stack, function)\n\n            internals = [\n                \"err\",\n                \"_new_err\",\n                \"fatal\",\n                \"warning\",\n                \"debug\",\n                \"info\",\n                \"<module>\"]  \n            if caller == function or caller in internals:\n                caller = None\n            # handle messages\n            if msg is not None:\n                caller_msg = msg\n                msg = str(ex_msg)\n            else:\n                msg = str(ex_msg)\n            ftb = traceback.format_exc()\n            errtype = errobj.__name__\n        if function is None:\n            # for el in st:\n            #   print(el)\n            function = st[3][3]\n            if function == \"<module>\":\n                function = None\n        # init error object\n        date = datetime.now()\n        error = Err(\n            function,\n            date,\n            msg,\n            errtype,\n            errclass,\n            line,\n            file,\n            code,\n            ftb,\n            ex,\n            caller,\n            caller_msg)\n        return error", "response": "Create a new error object from an exception or message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats the error message s headline", "response": "def _headline(self, error, i: int) -> str:\n        \"\"\"\n        Format the error message's headline\n        \"\"\"\n        msgs = Msg()\n        # get the error title\n        if error.errclass == \"fatal\":\n            msg = msgs.fatal(i)\n        elif error.errclass == \"warning\":\n            msg = msgs.warning(i)\n        elif error.errclass == \"info\":\n            msg = msgs.info(i)\n        elif error.errclass == \"debug\":\n            msg = msgs.debug(i)\n        elif error.errclass == \"via\":\n            msg = msgs.via(i)\n        else:\n            msg = msgs.error(i)\n        # function name\n        if error.function is not None:\n            msg += \" from \" + colors.bold(error.function)\n        if error.caller is not None:\n            msg += \" called from \" + colors.bold(error.caller)\n        if error.caller_msg is not None:\n            msg += \"\\n\" + error.caller_msg\n        if error.function is not None and error.msg is not None:\n            msg += \": \"\n        else:\n            msg = msg + \" \"\n        if error.errtype is not None:\n            msg += error.errtype + \" : \"\n        if error.msg is not None:\n            msg += error.msg\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _errmsg(self, error: \"Err\", tb: bool=False, i: int=None,\n                msgformat: str=\"terminal\") -> str:\n        \"\"\"\n        Get the error message\n        \"\"\"\n        if msgformat == \"terminal\":\n            msg = self._headline(error, i)\n            if error.ex is not None:\n                msg += \"\\n\" + \"line \" + colors.bold(str(error.line))\n                msg += \": \" + colors.yellow(error.code)\n                msg += \"\\n\" + str(error.file)\n                if self.errs_traceback is True or tb is True:\n                    if error.tb is not None:\n                        msg += \"\\n\" + error.tb\n        elif msgformat == \"csv\":\n            sep = \",\"\n            msg = error.msg + sep\n            msg += str(error.line) + sep + error.code + sep\n            msg += str(error.file)\n        elif msgformat == \"text\":\n            sep = \",\"\n            msg = error.msg\n            if error.ex is not None:\n                msg += sep + str(error.line) + sep + error.code + sep\n                msg += str(error.file) + sep         \n                if self.errs_traceback is True or tb is True:\n                    if error.tb is not None:\n                        msg += sep + error.tb\n        elif msgformat == \"dict\":\n            msg = {\"date\": datetime.now()}\n            if error.ex is not None:\n                msg[\"msg\"] = error.msg\n                msg[\"line\"] = error.line\n                msg[\"code\"] = error.code\n                msg[\"file\"] = error.file         \n                if self.errs_traceback is True or tb is True:\n                    if error.tb is not None:\n                        msg[\"traceback\"] = error.tb\n        return msg", "response": "Return the error message in the format specified by msgformat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the errors trace with tracebacks", "response": "def _print_errs(self):\n        \"\"\"\n        Prints the errors trace with tracebacks\n        \"\"\"\n        i = 0\n        for error in self.errors:\n            print(self._errmsg(error, tb=True, i=i))\n            # for spacing\n            if self.errs_traceback is False:\n                print()\n            i += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add(self, error: \"Err\"):\n        if self.trace_errs is True:\n            self.errors.append(error)", "response": "Adds an error to the trace if required."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_caller(self, callers: List[str], function: str) -> str:\n        is_next = False\n        for c in callers:\n            if is_next is True:\n                return c\n            if function == c:\n                is_next = True", "response": "Get the caller function from the provided function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_args(self, *args) -> (Exception, str):\n        ex = None\n        msg = None\n        for arg in args:\n            if isinstance(arg, str):\n                msg = arg\n            elif isinstance(arg, Exception):\n                ex = arg\n        return ex, msg", "response": "Returns exception and message from the provided arguments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the errors trace if there are some errors", "response": "def trace(self):\n        \"\"\"\n        Print the errors trace if there are some errors\n        \"\"\"\n        if len(self.errors) > 0:\n            numerrs = len(self.errors)\n            print(\"========= Trace (\" + str(numerrs) + \") =========\")\n        self._print_errs()\n        self.errors = []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef via(self, *args):\n        error = None\n        if len(self.errors) > 0:\n            error = self._err(\"via\", *args)\n        return error", "response": "Creates an empty error to record in the stack"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new migration and add it to the database", "response": "def __create_translation_migration(self):\n        \"\"\" Create an empty migration \"\"\"\n        migrations_dir = os.path.join(self.BASE_DIR, self.app_name + \"/migrations/\")\n        dependency_migration = os.path.basename(max(glob.iglob(migrations_dir + '*.py'), key=os.path.getctime)).replace(\n            \".py\", \"\")\n        \"\"\"\n        If there's no migration before this, which is unlikely to happen, then create a migration without dependencies\n        \"\"\"\n        if \"__init__\" in dependency_migration:\n            dependency_migration = \"\"\n        \"\"\" Make an empty migration \"\"\"\n        call_command('makemigrations', self.app_name, \"--empty\")\n        \"\"\" Get last migration name and edit it, adding the new code \"\"\"\n        last_migration_file = max(glob.iglob(migrations_dir + '*.py'), key=os.path.getctime)\n        new_lines = self.__create_translation_lines()\n        translation_type_lines = self.__create_translation_type_lines()\n        if len(dependency_migration) > 0:\n            dependency_string = \"('%(app_name)s', '%(dependency)s'),\" % {'app_name': self.app_name,\n                                                                         'dependency': dependency_migration}\n        else:\n            dependency_string = \"\"\n        try:\n            if len(new_lines) > 0:\n                with open(last_migration_file, 'w+') as file:\n                    file.write(self.migration_string % {\n                        'django_version': django.get_version(),\n                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n                        'translation_strings': \"\\n\".join(new_lines),\n                        'tags_to_remove': \", \".join('\"{0}\"'.format(tag) for tag in self.updated_translations),\n                        'dependency_string': dependency_string,\n                        'app_name': 'translation_server',\n                        'translation_type_strings': \"\\n\".join(translation_type_lines),\n                        'translation_types_to_remove': \", \".join(\n                            '\"{0}\"'.format(tag) for tag in self.updated_translation_types),\n                    })\n            else:\n                os.remove(last_migration_file)\n                self.stdout.write(self.style.NOTICE(\"There was no new translations to make migrations\"))\n                return\n        except Exception as error:\n            os.remove(last_migration_file)\n            raise error\n        else:\n            self.__update_translation()\n            self.stdout.write(self.style.SUCCESS(\"Translation migration file create successfully\"))\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_local_path(directory, create_dir=False):\n    if not os.path.exists(directory) and create_dir is True:\n        os.makedirs(directory)\n\n    if not os.path.exists(directory) and create_dir is False:\n        raise AttributeError(\"Path '%s' does not exist, to make it pass create_dir=True to rinocloud.set_local_path\" % directory)\n\n    if os.path.isdir(directory):\n        rinocloud.path = directory\n\n    return directory", "response": "Sets the path for local saving of information"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef task(name=None, t=INFO, *args, **kwargs):\n\n    def c_run(name, f, t, args, kwargs):\n        def run(*largs, **lkwargs):\n            thread = __get_current_thread()\n            old_name = __THREAD_PARAMS[thread][__THREAD_PARAMS_FNAME_KEY]\n            __THREAD_PARAMS[thread][__THREAD_PARAMS_FNAME_KEY] = name\n\n            r = log(name, f, t, largs, lkwargs, *args, **kwargs)\n\n            __THREAD_PARAMS[thread][__THREAD_PARAMS_FNAME_KEY] = old_name\n            return r\n\n        return run\n\n    if callable(name):\n        f = name\n        name = f.__name__\n\n        return c_run(name, f, t, args, kwargs)\n\n    if name == None:\n        def wrapped(f):\n            name = f.__name__\n            return c_run(name, f, t, args, kwargs)\n\n        return wrapped\n    else:\n        return lambda f: c_run(name, f, t, args, kwargs)", "response": "Decorator for creating a new task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef progress_task(name=None, t=INFO, max_value=100, *args, **kwargs):\n    return task(name=name, t=t, init_progress=True, max_value=max_value,\n                *args, **kwargs)", "response": "A task decorator that creates a progress bar for a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning set of string names of current available Splunk KV collections", "response": "def current_kv_names(self):\n        \"\"\"Return set of string names of current available Splunk KV collections\"\"\"\n        return current_kv_names(self.sci, self.username, self.appname, request=self._request)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, CachableItem):\n        cached_item = self.mapper.get(CachableItem)\n        r = self.request('get',\n            self.url+\"storage/collections/data/\"+self.collname+'/'+cached_item.getId(),\n            data={'output_mode': 'json'})\n        if r.ok:\n            # we need to update the object with the values found in the cache area\n            data = r.json()\n            for name in self.mapper.mapper:\n                setattr(cached_item, name, data[name])\n            return cached_item\n        return None", "response": "Returns current ICachedItem for ICachableItem or None if not cached"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntruing if cached information requires update for ICachableItem", "response": "def isDirty(self, CachableItem):\n        \"\"\"True if cached information requires update for ICachableItem\"\"\"\n        _cachedItem = self.get(CachableItem)\n        if not _cachedItem:\n            return True\n        _newCacheItem = self.mapper.get(CachableItem)\n        return False if _cachedItem == _newCacheItem else True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the cache area with latest item information returning if cache updates were required.", "response": "def cache(self, CachableItem):\n        \"\"\"Updates caches area with latest item information returning\n           ICachedItem if cache updates were required.\n\n           Issues ICacheObjectCreatedEvent, and ICacheObjectModifiedEvent for\n           ICacheArea/ICachableItem combo.\n        \"\"\"\n        _cachedItem = self.get(CachableItem)\n        if not _cachedItem:\n            _cachedItem = self.mapper.get(CachableItem)\n            self._add(_cachedItem)\n            logger.debug(\"new cachable item added to Splunk KV cache area {id: %s, type: %s}\", str(_cachedItem.getId()), str(_cachedItem.__class__))\n            notify(CacheObjectCreatedEvent(_cachedItem, self))\n            return _cachedItem\n        else:\n            _newCacheItem = self.mapper.get(CachableItem)\n            if _cachedItem != _newCacheItem:\n                logger.debug(\"Cachable item modified in Splunk KV cache area {id: %s, type: %s}\", str(_newCacheItem.getId()), str(_newCacheItem.__class__))\n                self._update(_newCacheItem)\n                notify(CacheObjectModifiedEvent(_newCacheItem, self))\n                return _newCacheItem\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the cache area and returns number of items updated with all available entries in ICachableSource", "response": "def import_source(self, CachableSource):\n        \"\"\"Updates cache area and returns number of items updated with all\n           available entries in ICachableSource\n        \"\"\"\n        _count = 0\n        self._import_source_items_id_list = set() # used to help speed up trim()\n        for item in CachableSource.items():\n            self._import_source_items_id_list.add(item.getId())\n            if self.cache(item):\n                _count += 1\n        return _count"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete all entries in the cache area", "response": "def reset(self):\n        \"\"\"Deletes all entries in the cache area\"\"\"\n        if self.collname not in self.current_kv_names():\n            return # nothing to do\n        # we'll simply delete the entire collection and then re-create it.\n        r = self.request('delete',\n                         self.url+\"storage/collections/data/\"+self.collname)\n        r.raise_for_status()\n        self.initialize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the Splunk Key Value Collection", "response": "def initialize(self):\n        \"\"\"Instantiates the cache area to be ready for updates\"\"\"\n        if self.collname not in self.current_kv_names():\n            r = self.request('post',\n                             self.url+\"storage/collections/config\",\n                             headers={'content-type': 'application/json'},\n                             data={'name': self.collname})\n            r.raise_for_status()\n        # initialize schema\n        re = self.request('post',\n                          self.url+\"storage/collections/config/\"+self.collname,\n                          headers = {'content-type': 'application/json'},\n                          data=self.schema)\n        re.raise_for_status()\n        logger.info(\"initialized Splunk Key Value Collection %s with schema %s\"\\\n                        % (self.collname, str(self.schema)))\n        if self.collname not in self.current_kv_names():\n            raise EnvironmentError('expected %s in list of kv collections %s' % (self.collname, str(self.current_kv_names())))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_model(t_output_every, output_dir=None, m=None, force_resume=True,\n              **iterate_args):\n    \"\"\"Convenience function to combine making a Runner object, and\n    running it for some time.\n\n    Parameters\n    ----------\n    m: Model\n        Model to run.\n    iterate_args:\n        Arguments to pass to :meth:`Runner.iterate`.\n    Others:\n        see :class:`Runner`.\n\n    Returns\n    -------\n    r: Runner\n        runner object after it has finished running for the required time.\n    \"\"\"\n    r = runner.Runner(output_dir, m, force_resume)\n    print(r)\n    r.iterate(t_output_every=t_output_every, **iterate_args)\n    return r", "response": "Convenience function to combine making a Runner object and run it for some time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resume_runs(dirnames, t_output_every, t_upto, parallel=False):\n    run_model_partial = partial(run_model, t_output_every, force_resume=True,\n                                t_upto=t_upto)\n    run_func(run_model_partial, dirnames, parallel)", "response": "Resume many models and run."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_kwarg_scan(ModelClass, model_kwarg_sets,\n                   t_output_every, t_upto,\n                   force_resume=True, parallel=False):\n    \"\"\"Run many models with the same parameters but variable `field`.\n\n    For each `val` in `vals`, a new model will be made, and run up to a time.\n    The output directory is automatically generated from the model arguments.\n\n    Parameters\n    ----------\n    ModelClass: type\n        A class or factory function that returns a model object by\n        calling `ModelClass(model_kwargs)`\n    model_kwarg_sets: list[dict]\n        List of argument sets, each of which can instantiate a model.\n    t_output_every: float\n        see :class:`Runner`.\n    t_upto: float\n        Run each model until the time is equal to this\n    parallel: bool\n        Whether or not to run the models in parallel, using the Multiprocessing\n        library. If `True`, the number of concurrent tasks will be equal to\n        one less than the number of available cores detected.\n    \"\"\"\n    task_runner = _TaskRunner(ModelClass, t_output_every, t_upto, force_resume)\n    run_func(task_runner, model_kwarg_sets, parallel)", "response": "Runs many models with the same parameters but variable field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun many models with a range of parameter sets.", "response": "def run_field_scan(ModelClass, model_kwargs, t_output_every, t_upto, field,\n                   vals, force_resume=True, parallel=False):\n    \"\"\"Run many models with a range of parameter sets.\n\n    Parameters\n    ----------\n    ModelClass: callable\n        A class or factory function that returns a model object by\n        calling `ModelClass(model_kwargs)`\n    model_kwargs: dict\n        See `ModelClass` explanation.\n    t_output_every: float\n        see :class:`Runner`.\n    t_upto: float\n        Run each model until the time is equal to this\n    field: str\n        The name of the field to be varied, whose values are in `vals`.\n    vals: array_like\n        Iterable of values to use to instantiate each Model object.\n    parallel: bool\n        Whether or not to run the models in parallel, using the Multiprocessing\n        library. If `True`, the number of concurrent tasks will be equal to\n        one less than the number of available cores detected.\n    \"\"\"\n    model_kwarg_sets = [dict(model_kwargs, field=val) for val in vals]\n    run_kwarg_scan(ModelClass, model_kwarg_sets,\n                   t_output_every, t_upto, force_resume, parallel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubscribe to a newsletter list.", "response": "def subscribe(request):\n    \"\"\"\n    Takes POST data (``email`` and optional ``next`` fields), submitting the ``email`` field to\n    the newsletter provider for subscription to a mailing list, and redirecting the user to the value\n    of ``next`` (this can also be provided in the querystring), or the homepage if no follow-on URL is\n    supplied, with a message in the ``django.contrib.messages`` queue to let them know it was successful.\n    \n    If the email address is invalid or the subscription process was unsuccessful, the user is redirected\n    to the follow-on URL and a message placed in the ``django.contrib.messages`` queue letting them know\n    what the issue was.\n    \"\"\"\n    \n    email = request.POST.get('email')\n    next = request.POST.get('next', request.GET.get('next', '/'))\n    valid = False\n    \n    if not email:\n        messages.error(request, u'Please enter your email address')\n    else:\n        try:\n            validate_email(email)\n            valid = True\n        except ValidationError:\n            messages.error(request, u'Please enter a valid email address')\n    \n    if valid:\n        shortcuts.subscribe(email, list_id = 'newsletter')\n        messages.success(request, u'Thanks for subscribing to our newsletter.')\n    \n    return HttpResponseRedirect(next)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a date object for the given age.", "response": "def age_to_date(age):\n    \"\"\"\n        \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u0442 \u0432\u043e\u0437\u0440\u0430\u0441\u0442 \u0432 \u0433\u043e\u0434 \u0440\u043e\u0436\u0434\u0435\u043d\u0438\u044f. (\u0414\u043b\u044f \u0444\u0438\u043b\u044c\u0442\u0440\u0430\u0446\u0438\u0438 \u043f\u043e \u0434\u0430\u0442\u0435 \u0440\u043e\u0436\u0434\u0435\u043d\u0438\u044f)\n    \"\"\"\n    today = datetime.date.today()\n    date = datetime.date(today.year - age - 1, today.month, today.day) + datetime.timedelta(days=1)\n    return date"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_date_ranges_intersection(t1start, t1end, t2start, t2end):\n    return (t1start <= t2start <= t1end) or (t2start <= t1start <= t2end)", "response": "Return True if two date ranges are in the same range."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef configure(logger=None):\n    global LOGGER\n    if logger is None:\n        LOGGER = logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n    else:\n        LOGGER = logger", "response": "Pass stump a logger to use."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ret(f, *args, **kwargs):\n    kwargs.update({'print_return': True})\n    return _stump(f, *args, **kwargs)", "response": "Automatically log progress on function entry and exit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pre(f, *args, **kwargs):\n    kwargs.update({'prefix_only': True})\n    return _stump(f, *args, **kwargs)", "response": "Automatically log progress on function entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(f, *args, **kwargs):\n    kwargs.update({'postfix_only': True})\n    return _stump(f, *args, **kwargs)", "response": "Automatically log progress on function exit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef debug_pre(f, *args, **kwargs):\n    kwargs.update({'log': logging.DEBUG})\n    kwargs.update({'prefix_only': True})\n    return _stump(f, *args, **kwargs)", "response": "Automatically log progress on function entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef warning_ret(f, *args, **kwargs):\n    kwargs.update({'log': logging.WARNING})\n    kwargs.update({'print_return': True})\n    return _stump(f, *args, **kwargs)", "response": "Automatically log progress on function entry and exit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef error_pre(f, *args, **kwargs):\n    kwargs.update({'log': logging.ERROR})\n    kwargs.update({'prefix_only': True})\n    return _stump(f, *args, **kwargs)", "response": "Automatically log progress on function entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the full name of the log entry.", "response": "def get_full_name(self):\n        \"\"\"\n        Returns the first_name plus the last_name, with a space in between.\n        \"\"\"\n        full_name = '{first_name} {last_name}'.format(first_name=self.first_name, last_name=self.last_name)\n        return full_name.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a temporary sandbox directory", "response": "def create_sandbox(name='healthybox'):\n    \"\"\"\n    Create a temporary sandbox directory\n    :param name: name of the directory to create\n    :return: The directory created\n    \"\"\"\n    sandbox = tempfile.mkdtemp(prefix=name)\n    if not os.path.isdir(sandbox):\n        os.mkdir(sandbox)\n\n    return sandbox"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads an unzips a package to the sandbox", "response": "def download_package_to_sandbox(sandbox, package_url):\n    \"\"\"\n    Downloads an unzips a package to the sandbox\n    :param sandbox: temporary directory name\n    :param package_url: link to package download\n    :returns: name of unzipped package directory\n    \"\"\"\n\n    response = requests.get(package_url)\n\n    package_tar = os.path.join(sandbox, 'package.tar.gz')\n\n    with open(package_tar, 'w') as f:\n        f.write(response.content)\n\n    os.chdir(sandbox)\n\n    with tarfile.open('package.tar.gz', 'r:gz') as tf:\n        tf.extractall()\n\n    directory = [d for d in os.listdir(sandbox) if os.path.isdir(d)][0]\n\n    return os.path.join(sandbox, directory)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_map(uri, url_root):\n    # TODO: Building the Map each time this is called seems like it could be more effiecent.\n    result = []\n    try:\n        result = db.execute(text(fetch_query_string('select_route_where_dynamic.sql'))).fetchall()\n    except OperationalError as err:\n        current_app.logger.error(\"OperationalError: %s\", err)\n        return (None, None)\n    if result:\n        #routes = result.as_dict()\n        #(routes, col_names) = rowify(result, c.description)\n        #current_app.logger.debug( [x['rule'] for x in routes] )\n        rules = map( lambda r: Rule(r['rule'], endpoint='dynamic'), result )\n        d_map = Map( rules )\n        map_adapter = d_map.bind(url_root)\n        #current_app.logger.debug(uri)\n        try:\n            (rule, rule_kw) = map_adapter.match(path_info=uri, return_rule=True)\n            #current_app.logger.debug(rule)\n            return (str(rule), rule_kw)\n        except HTTPException:\n            pass\n    return (None, {})", "response": "check if a URI is in a dynamic URL and return a tuple of the rule and kw."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nroute shortcode works a lot like rendering a page based on the url or route. This allows inserting in rendered HTML within another page. Activate it with the 'shortcodes' template filter. Within the content use the chill route shortcode: \"[chill route /path/to/something/]\" where the '[chill' and ']' are the shortcode starting and ending tags. And 'route' is this route handler that takes one argument which is the url.", "response": "def route_handler(context, content, pargs, kwargs):\n    \"\"\"\n    Route shortcode works a lot like rendering a page based on the url or\n    route.  This allows inserting in rendered HTML within another page.\n\n    Activate it with the 'shortcodes' template filter. Within the content use\n    the chill route shortcode: \"[chill route /path/to/something/]\" where the\n    '[chill' and ']' are the shortcode starting and ending tags. And 'route' is\n    this route handler that takes one argument which is the url.\n    \"\"\"\n    (node, rule_kw) = node_from_uri(pargs[0])\n\n    if node == None:\n        return u\"<!-- 404 '{0}' -->\".format(pargs[0])\n\n    rule_kw.update( node )\n    values = rule_kw\n    values.update( request.form.to_dict(flat=True) )\n    values.update( request.args.to_dict(flat=True) )\n    values['method'] = request.method\n    noderequest = values.copy()\n    noderequest.pop('node_id')\n    noderequest.pop('name')\n    noderequest.pop('value')\n\n    rendered = render_node(node['id'], noderequest=noderequest, **values)\n\n    if rendered:\n        if not isinstance(rendered, (str, unicode, int, float)):\n            # return a json string\n            return encoder.encode(rendered)\n\n        return rendered\n\n    # Nothing to show, so nothing found\n    return \"<!-- 404 '{0}' -->\".format(pargs[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef page_uri_handler(context, content, pargs, kwargs):\n    uri = pargs[0]\n    return url_for('.page_uri', uri=uri)", "response": "This is the main handler for the page_uri template filter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_aliyun_config(name, default=None):\n    '''\n    Get configuration variable from environment variable or\n    or django settings.py\n    '''\n    config = os.environ.get(name, getattr(settings, name, default))\n    if config is not None:\n        if isinstance(config, str):\n            return config.strip()\n        else:\n            return config\n    else:\n        raise ImproperlyConfigured(\n            'Can not get config for {} either in environment'\n            'variable or in settings.py'.format(name))", "response": "Get configuration variable from environment variable or django settings. py\n    or django settings. py"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tweets_for(query_type, args, per_user=None):\n    lookup = {\"query_type\": query_type, \"value\": args[0]}\n    try:\n        tweets = Tweet.objects.get_for(**lookup)\n    except TwitterQueryException:\n        return []\n    if per_user is not None:\n        _tweets = defaultdict(list)\n        for tweet in tweets:\n            if len(_tweets[tweet.user_name]) < per_user:\n                _tweets[tweet.user_name].append(tweet)\n        tweets = sum(_tweets.values(), [])\n        tweets.sort(key=lambda t: t.created_at, reverse=True)\n    if len(args) > 1 and str(args[-1]).isdigit():\n        tweets = tweets[:int(args[-1])]\n    return tweets", "response": "Retrieve tweets for a user list or search term."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tweets_default(*args):\n    query_type = settings.TWITTER_DEFAULT_QUERY_TYPE\n    args = (settings.TWITTER_DEFAULT_QUERY,\n            settings.TWITTER_DEFAULT_NUM_TWEETS)\n    per_user = None\n    if query_type == QUERY_TYPE_LIST:\n        per_user = 1\n    return tweets_for(query_type, args, per_user=per_user)", "response": "Returns a list of tweets for the default settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a single item from the ROSTER.", "response": "def _download(uri, user, password):\n    '''\n    # FIXME DOCS\n    '''\n    if user and password:\n        logr.debug('AUTH {} at {}'.format(user, uri))\n        cookieJar = cookielib.CookieJar()\n\n        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookieJar))\n        opener.addheaders = [(\"User-agent\", \"Mozilla/5.0 (compatible)\")]\n        urllib2.install_opener(opener)\n\n        form = dict()\n        form['roster-email'] = user\n        form['roster-pw'] = password\n    else:\n        form = []\n\n    return urllib2.urlopen(uri, urllib.urlencode(form)).read()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract users from a list.", "response": "def extract(list_name, base_url, list_config=None, user=None, password=None):\n    '''\n    # FIXME DOCS\n    '''\n    if not (base_url and list_name):\n        raise RuntimeError(\n            \"base_url [{}] and list_name [{}] can not be NULL\".format(\n                base_url, list_name))\n\n    list_config = list_config or {}\n    assert isinstance(list_config, dict)\n\n    logr.debug(\n        '[{}] {}: {}'.format(base_url, list_name, user))\n\n    list_url = \"{}/roster/{}\".format(base_url, list_name)\n\n    content = _download(list_url, user, password)\n\n    # Check for and report any errors return in the HTML\n    check_h2(content, 'Error')\n\n    # source contain list members page content\n    users = re.findall(r'(?<=>)(\\S* at \\S*|\\S*@\\S*)(?=<\\/a>)', content)\n    users = ['@'.join(u.split(' at ')) if ' at ' in u else u\n             for u in users]\n\n    return users"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding a bytestring provided by argparse into unicode.", "response": "def decode_cli_arg(arg):\n    \"\"\"\n    Turn a bytestring provided by `argparse` into unicode.\n\n    :param arg: The bytestring to decode.\n    :return: The argument as a unicode object.\n    :raises ValueError: If arg is None.\n    \"\"\"\n    if arg is None:\n        raise ValueError('Argument cannot be None')\n\n    if sys.version_info.major == 3:\n        # already decoded\n        return arg\n\n    return arg.decode(sys.getfilesystemencoding())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_level_from_vebosity(verbosity):\n    if verbosity == 0:\n        return logging.WARNING\n    if verbosity == 1:\n        return logging.INFO\n    return logging.DEBUG", "response": "Get the logging module log level from a verbosity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef round_two_non_zero_dp(decimal):\n    log10 = decimal.log10().to_integral_exact(rounding=ROUND_FLOOR) \\\n        if decimal else 0\n    div = Decimal(10) ** (Decimal(1) - log10) if log10 < 0 else Decimal(100)\n    return (decimal * div).to_integral_exact(rounding=ROUND_HALF_UP) / div", "response": "Rounds a number to the first two non - zero decimal places."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_rich_char(prompt=u'', term=None):\n\n    if not term:\n        term = terminfo.load_terminfo()\n\n    iterator = get_char(prompt)\n    for c in iterator:\n        try:\n            raise_if_start_escape_sequence(c)\n            \n            if is_char_printable(c):\n                yield PrintableChar(c)\n            else:\n                yield ControlKey(c)\n        \n        except StartEscapeSequenceException as e:\n            # We use a cicle because the input may be in the form\n            # ESC-ESC-* rest of the sequence\n            while True:\n                try:\n                    sequence = consume_escape_sequence(iterator, c)\n                    yield EscapeSequence(term.detect(sequence))\n                    break\n                except StartEscapeSequenceException as e:\n                    c = e.value\n\n    raise StopIteration", "response": "Iterator that returns the next meaningful input given to a terminal."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consume_escape_sequence(iterator, starter):\n\n    seq = [u'['] if is_char_single_character_csi(starter) else [next(iterator)]\n    raise_if_start_escape_sequence(seq[-1])\n\n    if seq[-1] == u'[':\n        seq.append(next(iterator))\n        raise_if_start_escape_sequence(seq[-1])\n        while not (64 <= ord(seq[-1]) <= 126 or seq[-1] == 36):\n            seq.append(next(iterator))\n            raise_if_start_escape_sequence(seq[-1])\n    elif seq[-1] == u'O': # read 1 more byte\n        seq.append(next(iterator))\n        raise_if_start_escape_sequence(seq[-1])\n    else:\n        pass\n\n    return u'\\x1b' + u''.join(seq)", "response": "Given an input iterator and the character that started an escape sequence consume the whole escape sequence and return it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the current cursor position.", "response": "def get_cursor_position():\n    \"\"\"Write an escape sequence to ask for the current cursor position.\n    Since the result is written on the standard input, this function\n    should not be used if you expect that your input has been pasted,\n    because the characters in the buffer would be read before the\n    answer about the cursor.\"\"\"\n    \n    # \"cursor position report\" in ECMA-48.\n    it = get_char(u'\\x1b[6n')\n    sequence = consume_escape_sequence(it, next(it))\n\n    # sequence format is \\x1b[<row>;<col>R\n    return tuple(int(x) for x in sequence[2:-1].split(u';'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading and compile a template.", "response": "def get_template(self, path):\n        \"\"\" Load and compile template. \"\"\"\n\n        if self.options['debug'] and self.options['cache_size']:\n            return self.cache.get(path, self.cache_template(path))\n        return self.load_template(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_frame(self, data, state):\n\n        # Convert the data to bytes\n        frame = six.binary_type(data)\n\n        # Clear the buffer\n        del data[:]\n\n        # Return the frame\n        return frame", "response": "Converts the data buffer into a single frame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting a single frame from the data buffer.", "response": "def to_frame(self, data, state):\n        \"\"\"\n        Extract a single frame from the data buffer.  The consumed\n        data should be removed from the buffer.  If no complete frame\n        can be read, must raise a ``NoFrames`` exception.\n\n        :param data: A ``bytearray`` instance containing the data so\n                     far read.\n        :param state: An instance of ``FramerState``.  If the buffer\n                      contains a partial frame, this object can be\n                      used to store state information to allow the\n                      remainder of the frame to be read.\n\n        :returns: A frame.  The frame may be any object.  The stock\n                  framers always return bytes.\n        \"\"\"\n\n        # If we've read all the data, let the caller know\n        if state.chunk_remaining <= 0:\n            raise exc.NoFrames()\n\n        # OK, how much data do we send on?\n        data_len = min(state.chunk_remaining, len(data))\n\n        # Extract that data from the buffer\n        frame = six.binary_type(data[:data_len])\n        del data[:data_len]\n\n        # Update the state\n        state.chunk_remaining -= data_len\n\n        # Return the frame\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts a single frame from the data buffer.", "response": "def to_frame(self, data, state):\n        \"\"\"\n        Extract a single frame from the data buffer.  The consumed\n        data should be removed from the buffer.  If no complete frame\n        can be read, must raise a ``NoFrames`` exception.\n\n        :param data: A ``bytearray`` instance containing the data so\n                     far read.\n        :param state: An instance of ``FramerState``.  If the buffer\n                      contains a partial frame, this object can be\n                      used to store state information to allow the\n                      remainder of the frame to be read.\n\n        :returns: A frame.  The frame may be any object.  The stock\n                  framers always return bytes.\n        \"\"\"\n\n        # Find the next newline\n        data_len = data.find(b'\\n')\n\n        if data_len < 0:\n            # No line to extract\n            raise exc.NoFrames()\n\n        # Track how much to exclude\n        frame_len = data_len + 1\n\n        # Are we to exclude carriage returns?\n        if (self.carriage_return and data_len and\n                data[data_len - 1] == ord(b'\\r')):\n            data_len -= 1\n\n        # Extract the frame\n        frame = six.binary_type(data[:data_len])\n        del data[:frame_len]\n\n        # Return the frame\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract a single frame from the data buffer.", "response": "def to_frame(self, data, state):\n        \"\"\"\n        Extract a single frame from the data buffer.  The consumed\n        data should be removed from the buffer.  If no complete frame\n        can be read, must raise a ``NoFrames`` exception.\n\n        :param data: A ``bytearray`` instance containing the data so\n                     far read.\n        :param state: An instance of ``FramerState``.  If the buffer\n                      contains a partial frame, this object can be\n                      used to store state information to allow the\n                      remainder of the frame to be read.\n\n        :returns: A frame.  The frame may be any object.  The stock\n                  framers always return bytes.\n        \"\"\"\n\n        # First, determine the length we're looking for\n        length = state.length\n        if length is None:\n            # Try decoding a length from the data buffer\n            length = self.decode_length(data, state)\n\n        # Now, is there enough data?\n        if len(data) < length:\n            state.length = length\n            raise exc.NoFrames()\n\n        # Extract the frame\n        frame = six.binary_type(data[:length])\n        del data[:length]\n\n        # Update the state\n        state.length = None\n\n        # Return the frame\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a single frame into bytes that can be transmitted on the stream.", "response": "def to_bytes(self, frame, state):\n        \"\"\"\n        Convert a single frame into bytes that can be transmitted on\n        the stream.\n\n        :param frame: The frame to convert.  Should be the same type\n                      of object returned by ``to_frame()``.\n        :param state: An instance of ``FramerState``.  This object may\n                      be used to track information across calls to the\n                      method.\n\n        :returns: Bytes that may be transmitted on the stream.\n        \"\"\"\n\n        # Generate the bytes from the frame\n        frame = six.binary_type(frame)\n        return self.encode_length(frame, state) + frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts and decode a length from the data buffer.", "response": "def decode_length(self, data, state):\n        \"\"\"\n        Extract and decode a frame length from the data buffer.  The\n        consumed data should be removed from the buffer.  If the\n        length data is incomplete, must raise a ``NoFrames``\n        exception.\n\n        :param data: A ``bytearray`` instance containing the data so\n                     far read.\n        :param state: An instance of ``FramerState``.  If the buffer\n                      contains a partial encoded length, this object\n                      can be used to store state information to allow\n                      the remainder of the length to be read.\n\n        :returns: The frame length, as an integer.\n        \"\"\"\n\n        # Do we have enough data yet?\n        if len(data) < self.fmt.size:\n            raise exc.NoFrames()\n\n        # Extract the length\n        length = self.fmt.unpack(six.binary_type(data[:self.fmt.size]))[0]\n        del data[:self.fmt.size]\n\n        # Return the length\n        return length"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract a single frame from the data buffer.", "response": "def to_frame(self, data, state):\n        \"\"\"\n        Extract a single frame from the data buffer.  The consumed\n        data should be removed from the buffer.  If no complete frame\n        can be read, must raise a ``NoFrames`` exception.\n\n        :param data: A ``bytearray`` instance containing the data so\n                     far read.\n        :param state: An instance of ``FramerState``.  If the buffer\n                      contains a partial frame, this object can be\n                      used to store state information to allow the\n                      remainder of the frame to be read.\n\n        :returns: A frame.  The frame may be any object.  The stock\n                  framers always return bytes.\n        \"\"\"\n\n        # Find the next packet start\n        if not state.frame_start:\n            # Find the begin sequence\n            idx = data.find(self.begin)\n            if idx < 0:\n                # Couldn't find one\n                raise exc.NoFrames()\n\n            # Excise the begin sequence\n            del data[:idx + len(self.begin)]\n\n        # Now see if we can find the end sequence\n        idx = data.find(self.end)\n        if idx < 0:\n            # We've found the start, but don't have the end yet\n            state.frame_start = True\n            raise exc.NoFrames()\n\n        # Extract the frame\n        frame = six.binary_type(data[:idx])\n        del data[:idx + len(self.end)]\n\n        # Update the state\n        state.frame_start = False\n\n        # Unstuff the frame and return it\n        return self.prefix.join(frame.split(self.nop))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a single frame into bytes that can be transmitted on the stream.", "response": "def to_bytes(self, frame, state):\n        \"\"\"\n        Convert a single frame into bytes that can be transmitted on\n        the stream.\n\n        :param frame: The frame to convert.  Should be the same type\n                      of object returned by ``to_frame()``.\n        :param state: An instance of ``FramerState``.  This object may\n                      be used to track information across calls to the\n                      method.\n\n        :returns: Bytes that may be transmitted on the stream.\n        \"\"\"\n\n        # Generate and return the frame\n        return (self.begin +\n                self.nop.join(six.binary_type(frame).split(self.prefix)) +\n                self.end)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_frame(self, data, state):\n\n        # Find the next null byte\n        data_len = data.find(b'\\0')\n\n        if data_len < 0:\n            # No full frame yet\n            raise exc.NoFrames()\n\n        # Track how much to exclude\n        frame_len = data_len + 1\n\n        # Decode the data\n        frame = six.binary_type(self.variant.decode(\n            six.binary_type(data[:data_len])))\n        del data[:frame_len]\n\n        # Return the frame\n        return frame", "response": "Extracts a single frame from the data buffer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_bytes(self, frame, state):\n\n        # Encode the frame and append the delimiter\n        return six.binary_type(self.variant.encode(\n            six.binary_type(frame))) + b'\\0'", "response": "Convert a single frame into bytes that can be transmitted on the stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess a file of rest and return json", "response": "def interpret(self, infile):\n        \"\"\" Process a file of rest and return json \"\"\"\n\n        # need row headings\n        data = pandas.read_csv(infile)\n\n        # FIXME find the right foo\n        return json.dumps(data.foo())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming binary search on sorted list data for target. Returns the index of the first element in data.", "response": "def binary_search(data, target, lo=0, hi=None):\n    \"\"\"\n    Perform binary search on sorted list data for target. Returns int\n    representing position of target in data.\n    \"\"\"\n    hi = hi if hi is not None else len(data)\n    mid = (lo + hi) // 2\n    if hi < 2 or hi > len(data) or target > data[-1] or target < data[0]:\n        return -1\n    if data[mid] > target:\n        return binary_search(data, target, lo=lo, hi=mid)\n    elif data[mid] < target:\n        return binary_search(data, target, lo=(mid + 1), hi=hi)\n    elif data[mid] == target:\n        return mid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new(self, user_id, tokens=None, user_data=None, valid_until=None,\n            client_ip=None, encoding='utf-8'):\n        \"\"\"Creates a new authentication ticket.\n\n        Args:\n            user_id: User id to store in ticket (stored in plain text)\n            tokens: Optional sequence of token strings to store in the ticket\n                (stored in plain text).\n            user_data: Optional user data to store in the ticket (string like\n                object stored in plain text)\n            valid_until: Expiration time of ticket as a integer (typically\n                time.time() + seconds).\n            client_ip: Optional string or ip_address.IPAddress of the client.\n            encoding: Optional encoding type that is used when hashing the\n                strings passed to the function\n\n        Returns:\n            A ticket string that can later be used to identify the user\n        \"\"\"\n        if valid_until is None:\n            valid_until = int(time.time()) + TicketFactory._DEFAULT_TIMEOUT\n        else:\n            valid_until = int(valid_until)\n\n        # Make sure we dont have any exclamations in the user_id\n        user_id = ulp.quote(user_id)\n\n        # Create a comma seperated list of tokens\n        token_str = ''\n        if tokens:\n            # Escape characters in our tokens\n            token_str = ','.join((ulp.quote(t) for t in tokens))\n\n        # Encode our user data (a string)\n        user_str = '' if not user_data else ulp.quote(user_data)\n\n        # Get our address\n        ip = self._DEFAULT_IP if client_ip is None else ip_address(client_ip)\n\n        # Create our digest\n        data0 = bytes([ip.version]) + ip.packed + pack(\">I\", valid_until)\n        data1 = ('\\0'.join((user_id, token_str, user_str))).encode(encoding)\n        digest = self._hexdigest(data0, data1)\n\n        # digest + timestamp as an eight character hexadecimal + userid\n        parts = ('{0}{1:08x}{2}'.format(digest, valid_until, user_id),\n                 token_str, user_str)\n        return '!'.join(parts)", "response": "Creates a new authentication ticket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, ticket, client_ip=None, now=None, encoding='utf-8'):\n        parts = self.parse(ticket)\n\n        # Check if our ticket matches\n        new_ticket = self.new(*(parts[1:]), client_ip=client_ip, encoding=encoding)\n\n        if new_ticket[:self._hash.digest_size * 2] != parts.digest:\n            raise TicketDigestError(ticket)\n\n        if now is None:\n            now = time.time()\n\n        if parts.valid_until <= now:\n            raise TicketExpired(ticket)\n\n        return parts", "response": "Validates the passed ticket and raises a TicketParseError if ticket is invalid or if ticket is expired or if ticket is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the passed ticket and returns a tuple containing the digest user_id valid_until tokens and user_data fields", "response": "def parse(self, ticket):\n        \"\"\"Parses the passed ticket, returning a tuple containing the digest,\n        user_id, valid_until, tokens, and user_data fields\n        \"\"\"\n        if len(ticket) < self._min_ticket_size():\n            raise TicketParseError(ticket, 'Invalid ticket length')\n\n        digest_len = self._hash.digest_size * 2\n        digest = ticket[:digest_len]\n\n        try:\n            time_len = 8\n            time = int(ticket[digest_len:digest_len + time_len], 16)\n        except:\n            raise TicketParseError(ticket, 'Invalid time field')\n\n        parts = ticket[digest_len + time_len:].split('!')\n        if len(parts) != 3:\n            raise TicketParseError(ticket, 'Missing parts')\n\n        user_id = ulp.unquote(parts[0])\n        tokens = ()\n        if parts[1]:\n            tokens = tuple((ulp.unquote(t) for t in parts[1].split(',')))\n\n        user_data = ulp.unquote(parts[2])\n\n        return TicketInfo(digest, user_id, tokens, user_data, time)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract from a given table a tree for word length and optionally flatten the tree.", "response": "def from_table(cls, table, length, prefix=0, flatten=False):\n        \"\"\"\n        Extract from the given table a tree for word length, taking only\n        prefixes of prefix length (if greater than 0) into account to compute\n        successors.\n        \n        :param table: the table to extract the tree from;\n        :param length: the length of words generated by the extracted tree;\n                       greater or equal to 1;\n        :param prefix: if greater than 0, the length of the prefixes used for\n                       computing successors;\n        :param flatten: whether to flatten the table or not;\n        :return: the tree corresponding to words of length from table.\n        \"\"\"\n        # Build the expanded tree with necessary suffix and length\n        tree = defaultdict(dict)  # The tree\n        pending = {(\">\", 0)}  # The nodes to expand\n        while pending:\n            suffix, size = pending.pop()\n            if size < length:\n                choices = table.weighted_choices(suffix, exclude={\"<\"},\n                                                 flatten=flatten)\n                # The word length is not reached yet, expand\n                for successor, weight in choices.items():\n                    expanded = suffix + successor\n                    if prefix > 0:\n                        expanded = expanded[-prefix:]\n                    new_node = (expanded, size + 1)\n                    tree[(suffix, size)][new_node] = weight\n                    pending.add(new_node)\n            else:\n                choices = table.weighted_choices(suffix, flatten=flatten)\n                # The word length is reached, only add < if present\n                if \"<\" in choices:\n                    tree[(suffix, size)][(\"<\", size + 1)] = 1\n                else:\n                    tree[(suffix, size)] = dict()\n        return cls(cls.trim_tree(tree))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving dead branches of tree that are not part of any other tree.", "response": "def trim_tree(tree):\n        \"\"\"\n        Remove the dead branches of tree, that is, the resulting tree accepts\n        the same language as the original one (that is, the same words that end\n        with the < character), but parts of the tree that lead to nothing are\n        removed.\n\n        :param tree: the tree;\n        :return: the tree without dead branches.\n        \"\"\"\n        # Remove empty nodes\n        new_tree = {k: v for k, v in tree.items() if v}\n        # Remove missing successors\n        new_tree = {k: {successor: weight for successor, weight in v.items()\n                        if successor in new_tree or successor[0] == \"<\"}\n                    for k, v in new_tree.items()}\n        while tree != new_tree:\n            tree = new_tree\n            # Remove empty nodes\n            new_tree = {k: v for k, v in tree.items() if v}\n            # Remove missing successors\n            new_tree = {k: {successor: weight\n                            for successor, weight in v.items()\n                            if successor in new_tree or successor[0] == \"<\"}\n                        for k, v in new_tree.items()}\n        return new_tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random word from this tree.", "response": "def random_word(self, *args, **kwargs):\n        \"\"\"\n        Return a random word from this tree. The length of the word depends on\n        the this tree.\n\n        :return: a random word from this tree.\n\n        args and kwargs are ignored.\n        \"\"\"\n        word = \"\"\n        current = (\">\", 0)\n        while current[0] != \"<\":\n            choices = self[current]\n            choice = random_weighted_choice(choices)\n            current = choice\n            word += current[0][-1]\n        return word[:-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all the mount points of the current partition.", "response": "def mount_points(self):\n        \"\"\"\n        Iterator of partition's mount points obtained by reading /proc/mounts.\n        Returns empty list if /proc/mounts is not readable or if there are no\n        mount points.\n        \"\"\"\n        aliases = self.aliases\n        try:\n            return [e.mdir for e in mounts() if e.dev in aliases]\n        except (OSError, IOError):\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the disk usage information for the partition in : py : class : Fstat format.", "response": "def stat(self):\n        \"\"\"\n        Return disk usage information for the partition in :py:class:`Fstat`\n        format. If disk usage information is not available, then ``None`` is\n        returned. Disk usage information is only available for regular\n        filesystems that are mounted.\n        \"\"\"\n        try:\n            # Always use the last mount point because it's a very common\n            # situation when mount points are moved, or sotorage is\n            # double-mounted. Last mount point is always the newest.\n            mp = self.mount_points[-1]\n        except IndexError:\n            return None\n        stat = os.statvfs(mp)\n        free = stat.f_frsize * stat.f_bavail\n        total = stat.f_frsize * stat.f_blocks\n        used = total - free\n        used_pct = round(used / total * 100)\n        free_pct = 100 - used_pct\n        return Fstat(total, used, free, used_pct, free_pct)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef partitions(self):\n        if not self._partitions:\n            self._partitions = [Partition(d, self)\n                                for d in self.device.children]\n        return self._partitions", "response": "Returns an iterable containing disk s partition objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naliasing for UBI volume. This propery evaluates to device node itself plus the ``'ubi${INDEX}:${LABEL}'`` string. The latter is used to identify the device in /proc/mounts table, and is not really an alias.", "response": "def aliases(self):\n        \"\"\"\n        Aliases for UBI volume. This propery evaluates to device node itself\n        plus the ``'ubi${INDEX}:${LABEL}'`` string. The latter is used to\n        identify the device in /proc/mounts table, and is not really an alias.\n        \"\"\"\n        return ['ubi{}:{}'.format(self.device.parent.sys_number, self.label),\n                self.node]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattempting to purchase a user shop item returns result alid", "response": "def buy(self):\n        \"\"\" Attempts to purchase a user shop item, returns result\n        \n        Uses the associated user and buyURL to attempt to purchase the user shop item. Returns\n        whether or not the item was successfully bought. \n           \n        Returns\n           bool - True if successful, false otherwise\n        \"\"\"\n        # Buy the item\n        pg = self.usr.getPage(\"http://www.neopets.com/\" + self.buyURL, vars = {'Referer': 'http://www.neopets.com/browseshop.phtml?owner=' + self.owner})\n        \n        # If it was successful a redirect to the shop is sent\n        if \"(owned by\" in pg.content:\n                return True\n        elif \"does not exist in this shop\" in pg.content:\n                return False\n        else:\n            logging.getLogger(\"neolib.item\").exception(\"Unknown message when attempting to buy user shop item.\", {'pg': pg})\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the info page to fill in the property cache.", "response": "def fetch(self, cache=None):\n        \"\"\"Query the info page to fill in the property cache.\n\n        Return a dictionary with the fetched properties and values.\n\n        \"\"\"\n        self.reset()\n        soup = get(self.url).soup\n        details = soup.find(id=\"detailsframe\")\n        getdef = lambda s: [elem\n                for elem in details.find(\"dt\",\n                text=re.compile(s)).next_siblings\n                if elem.name == 'dd'][0]\n        getdefstring = lambda s: getdef(s).string.strip()\n        info = {\n            \"title\": details.find(id=\"title\").string.strip(),\n            \"type\": getdefstring(\"Type:\"),\n            \"files\": getdefstring(\"Files:\"),\n            \"size\": getdefstring(\"Size:\"),\n            \"uploaded\": getdefstring(\"Uploaded:\"),\n            \"submitter\": getdef(\"By:\").parent.find(\"a\", href=re.compile(\"user\")).string.strip(),\n            \"seeders\": getdefstring(\"Seeders:\"),\n            \"leechers\": getdefstring(\"Leechers:\"),\n            \"comments\": details.find(id=\"NumComments\").string.strip(),\n            \"link\": details.find(\"a\", href=re.compile(\"^magnet\\:\"))['href'].strip(),\n        }\n        if self._use_cache(cache):\n            self._attrs = info\n        self._fetched = True\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, item, cache=None):\n        if item not in self._keys:\n            raise KeyError(item)\n        if self._use_cache(cache) and (self._fetched or\n                item in self._attrs):\n            return self._attrs[item]\n        info = self.fetch(cache=cache)\n        return info[item]", "response": "Lookup a torrent info property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning torrent properties as a dictionary.", "response": "def as_dict(self, cache=None, fetch=True):\n        \"\"\"Return torrent properties as a dictionary.\n\n        Set the cache flag to False to disable the cache. On the other hand,\n        set the fetch flag to False to avoid fetching data if it's not cached.\n\n        \"\"\"\n        if not self._fetched and fetch:\n            info = self.fetch(cache)\n        elif self._use_cache(cache):\n            info = self._attrs.copy()\n        else:\n            info = {}\n        info.update(url=self.url)\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_users_of_group(config, group):\n    if not group:\n        return set()\n    fas = fmn.rules.utils.get_fas(config)\n    return fmn.rules.utils.get_user_of_group(config, fas, group)", "response": "Utility to query fas for users of a group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fas_group_member_filter(config, message, group=None, *args, **kw):\n    if not group:\n        return False\n    fasusers = _get_users_of_group(config, group)\n    msgusers = fmn.rules.utils.msg2usernames(message, **config)\n    return bool(fasusers.intersection(msgusers))", "response": "Filter out messages that are part of a FAS group."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_package_filter(config, message, fasnick=None, *args, **kw):\n\n    fasnick = kw.get('fasnick', fasnick)\n    if fasnick:\n        msg_packages = fmn.rules.utils.msg2packages(message, **config)\n        if not msg_packages:\n            # If the message has no packages associated with it, there's no\n            # way that \"one of them\" is going to happen to belong to this user,\n            # so let's not waste our time doing the somewhat expensive call out\n            # to pkgdb on the next line to check.\n            return False\n        usr_packages = fmn.rules.utils.get_packages_of_user(\n            config, fasnick, all_acls)\n        return usr_packages.intersection(msg_packages)\n\n    return False", "response": "A particular user s packages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering for packages that are related to a particular user", "response": "def user_package_commit_filter(config, message, fasnick=None, *args, **kw):\n    \"\"\" A particular user's packages (commit acl)\n\n    This rule includes messages that relate to packages where the\n    specified user has commit ACLs.\n    \"\"\"\n\n    fasnick = kw.get('fasnick', fasnick)\n    if fasnick:\n        msg_packages = fmn.rules.utils.msg2packages(message, **config)\n        if not msg_packages:\n            # If the message has no packages associated with it, there's no\n            # way that \"one of them\" is going to happen to belong to this user,\n            # so let's not waste our time doing the somewhat expensive call out\n            # to pkgdb on the next line to check.\n            return False\n        usr_packages = fmn.rules.utils.get_packages_of_user(\n            config, fasnick, only_commit)\n        return usr_packages.intersection(msg_packages)\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef package_filter(config, message, package=None, *args, **kw):\n\n    package = kw.get('package', package)\n    if package:\n        return package in fmn.rules.utils.msg2packages(message, **config)", "response": "A specific package filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef package_regex_filter(config, message, pattern=None, *args, **kw):\n\n    pattern = kw.get('pattern', pattern)\n    if pattern:\n        packages = fmn.rules.utils.msg2packages(message, **config)\n        regex = fmn.rules.utils.compile_regex(pattern.encode('utf-8'))\n        return any([regex.search(p.encode('utf-8')) for p in packages])", "response": "Filter out packages that match a regular expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters out messages that match a regular expression pattern", "response": "def regex_filter(config, message, pattern=None, *args, **kw):\n    \"\"\" All messages matching a regular expression\n\n    Use this rule to include messages that bear a certain pattern.\n    This can be anything that appears anywhere in the message (for instance,\n    you could combine this with rules for wiki updates or Ask Fedora changes\n    to alert yourself of activity in your area of expertise).\n\n    (*i.e., (beefy miracle)*).\n    \"\"\"\n\n    pattern = kw.get('pattern', pattern)\n    if pattern:\n        regex = fmn.rules.utils.compile_regex(pattern.encode('utf-8'))\n        return bool(regex.search(\n            fedmsg.encoding.dumps(message['msg']).encode('utf-8')\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an option to the object.", "response": "def add_option(self, opt_name, otype, hidden=False):\n        \"\"\" Add an option to the object\n\n        :param opt_name: option name\n        :type opt_name: str\n        :param otype: option type\n        :type otype: subclass of :class:`.GenericType`\n        :param hidden: if True the option will be hidden\n        :type hidden: bool\n        \"\"\"\n        if self.has_option(opt_name):\n            raise ValueError(\"The option is already present !\")\n        opt = ValueOption.FromType(opt_name, otype)\n        opt.hidden = hidden\n        self._options[opt_name] = opt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting description of the component options", "response": "def print_options(self):\n        \"\"\" print description of the component options\n        \"\"\"\n        summary = []\n        for opt_name, opt in self.options.items():\n            if opt.hidden:\n                continue\n            summary.append(opt.summary())\n        print(\"\\n\".join(summary))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_option_value(self, opt_name, value, parse=False):\n        if not self.has_option(opt_name):\n            raise ValueError(\"Unknow option name (%s)\" % opt_name)\n        self._options[opt_name].set(value, parse=parse)", "response": "Set the value of one option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclearing the stored option value.", "response": "def clear_option_value(self, opt_name):\n        \"\"\" Clear the stored option value (so the default will be used)\n\n        :param opt_name: option name\n        :type opt_name: str\n        \"\"\"\n        if not self.has_option(opt_name):\n            raise ValueError(\"Unknow option name (%s)\" % opt_name)\n        self._options[opt_name].clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value of an option in the current session", "response": "def get_option_value(self, opt_name):\n        \"\"\" Return the value of a given option\n        \n        :param opt_name: option name\n        :type opt_name: str\n        \n        :returns: the value of the option\n        \"\"\"\n        if not self.has_option(opt_name):\n            raise ValueError(\"Unknow option name (%s)\" % opt_name)\n        return self._options[opt_name].value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_option_default(self, opt_name, default_val):\n        if not self.has_option(opt_name):\n            raise ValueError(\"Unknow option name (%s)\" % opt_name)\n        self._options[opt_name].default = default_val", "response": "Change the default value of an option in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef force_option_value(self, opt_name, value):\n        if not self.has_option(opt_name):\n            raise ValueError(\"Unknow option name (%s)\" % opt_name)\n        self._options[opt_name].default = value # also change the value\n        self._options[opt_name].hidden = True", "response": "force the default value of an option."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_option_default(self, opt_name):\n        if not self.has_option(opt_name):\n            raise ValueError(\"Unknow option name (%s)\" % opt_name)\n        return self._options[opt_name].default", "response": "Returns the default value of an option"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the options of the current component from a dictionary of values.", "response": "def set_options_values(self, options, parse=False, strict=False):\n        \"\"\" Set the options from a dict of values (in string).\n        \n        :param option_values: the values of options (in format `{\"opt_name\": \"new_value\"}`)\n        :type option_values: dict\n        :param parse: whether to parse the given value\n        :type parse: bool\n        :param strict: if True the given `option_values` dict should only \n         contains existing options (no other key)\n        :type strict: bool\n        \"\"\"\n        if strict:\n            for opt_name in options.keys():\n                if not self.has_option(opt_name):\n                    raise ValueError(\"'%s' is not a option of the component\" % opt_name)\n                elif self.option_is_hidden(opt_name):\n                    raise ValueError(\"'%s' is hidden, you can't set it\" % opt_name)\n        for opt_name, opt in self._options.items():\n            if opt.hidden:\n                continue\n            if opt_name in options:\n                opt.set(options[opt_name], parse=parse)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_options_values(self, hidden=False):\n        values = {}\n        for opt_name, opt in self._options.items():\n            if hidden or not opt.hidden:\n                values[opt_name] = opt.value\n        return values", "response": "returns a dictionary of all options values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the options and returns a dict of all options values", "response": "def parse_options(self, option_values):\n        \"\"\" Set the options (with parsing) and returns a dict of all options values\n        \"\"\"\n        self.set_options_values(option_values, parse=True)\n        return self.get_options_values(hidden=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary of all options in the current session.", "response": "def get_options(self, hidden=False):\n        \"\"\"\n        :param hidden: whether to return hidden options\n        :type hidden: bool\n        :returns: dictionary of all options (with option's information)\n        :rtype: dict\n        \"\"\"\n        return dict((opt['name'], opt) for opt in self.get_ordered_options(hidden=hidden))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of options pre - serialised by the user.", "response": "def get_ordered_options(self, hidden=False):\n        \"\"\"\n        :param hidden: whether to return hidden option\n        :type hidden: bool\n        :returns: **ordered** list of options pre-serialised (as_dict)\n        :rtype: list `[opt_dict, ...]`\n        \"\"\"\n        return [opt.as_dict() for opt in self.options.values() \\\n                                            if hidden or (not opt.hidden)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check(call_fct):\n        # wrap the method\n        @wraps(call_fct)\n        def checked_call(self, *args, **kwargs):\n            self.set_options_values(kwargs, parse=False, strict=True)\n            options_values = self.get_options_values(hidden=True)\n            return call_fct(self, *args, **options_values)\n        # add a flag on the new method to indicate that it is 'checked'\n        checked_call._checked = True\n        checked_call._no_check = call_fct\n        return checked_call", "response": "Decorator for optionable __call__ method\n        It check the given option values\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loadtxt(fn, **kwargs):\n    global PP\n    PP = PatternPull(fn)\n    txtargs = PP.loadtxtargs()\n    txtargs.update(kwargs)      # Let kwargs dominate.\n    return np.loadtxt(fn, **txtargs)", "response": "Study the text data file fn. Call numpys loadtxt with keyword arguments based on the study."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadtxt_asdict(fn, **kwargs):\n\n    kwargs.update(unpack=True)\n    d = loadtxt(fn, **kwargs)\n    if len(np.shape(d)) == 2:\n        keys = kwargs.get('usecols', None) or range(len(d))\n        D = dict([(k, v) for k, v in zip(keys, d)])\n    elif len(np.shape(d)) == 1:\n        keys = kwargs.get('usecols', None) or [0]\n        D = dict([(keys[0], d)])\n    else:\n        raise Exception('Unknown dimension of loaded data.')\n\n    return D", "response": "Return what is returned from loadtxt as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_rows(self, fo):\n\n        rows = []\n        for i in range(NUMROWS):\n            line = fo.readline()\n            if not line:\n                break\n            rows += [line]\n\n        return rows", "response": "Return the lines in the file as a list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_matches(self):\n\n        try:\n            self.fn = self.fo.name\n            rows = self.file_rows(self.fo)\n            self.fo.seek(0)\n\n        except AttributeError:\n            with open(self.fn) as fo:\n                rows = self.file_rows(fo)\n\n        matches_p = []\n        matches_c = []\n        for line in rows:\n            cnt = len(re.findall(DATPRX, line))\n            matches_p.append(cnt)\n            cnt = len(re.findall(DATCRX, line))\n            matches_c.append(cnt)\n\n        self.rows = rows        # Is newlines in the end a problem?\n        self.matches_p = matches_p\n        self.matches_c = matches_c", "response": "Set the matches_p matches_c and rows attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the number of rows to skip based on the decimal delimiter decdel.", "response": "def rows2skip(self, decdel):\n        \"\"\"\n        Return the number of rows to skip based on the decimal delimiter\n        decdel.\n\n        When each record start to have the same number of matches, this\n        is where the data starts. This is the idea. And the number of\n        consecutive records to have the same number of matches is to be\n        EQUAL_CNT_REQ.\n        \"\"\"\n\n        if decdel == '.':\n            ms = self.matches_p\n        elif decdel == ',':\n            ms = self.matches_c\n        # else make error...\n\n        cnt = row = 0\n\n        for val1, val2 in zip(ms, ms[1:]):\n            # val2 is one element ahead.\n            row += 1\n            if val2 == val1 != 0:  # 0 is no matches, so it doesn't count.\n                cnt += 1\n            else:\n                cnt = 0\n\n            if cnt == EQUAL_CNT_REQ:\n                break\n        else:\n            # print 'No break-out for', decdel, 'cnt:', cnt\n            pass\n\n        self.cnt = cnt\n        return row - EQUAL_CNT_REQ"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_decdel_rts(self):\n\n        lnr = max(self.rows2skip(','), self.rows2skip('.')) + 1\n        # If EQUAL_CNT_REQ was not met, raise error. Implement!\n        if self.cnt > EQUAL_CNT_REQ:\n            raise PatternError('Did not find ' + str(EQUAL_CNT_REQ) +\n                               ' data rows with equal data pattern in file: ' +\n                               self.fn)\n        elif self.cnt < EQUAL_CNT_REQ:  # Too few rows\n            raise PatternError('Less than', str(EQUAL_CNT_REQ) +\n                               'data rows in', self.fn + '?',\n                               '\\nTry lower the EQUAL_CNT_REQ')\n        if self.matches_p[lnr] <= self.matches_c[lnr]:\n            self.decdel = '.'   # If equal, assume decimal point is used.\n            self.datrx = DATPRX\n        else:\n            self.decdel = ','        # Assume the lesser count is correct.\n            self.datrx = DATCRX\n\n        self.rts = self.rows2skip(self.decdel)", "response": "Figure out the decimal seperator and rows to skip and set the corresponding attributes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiguring out the data delimiter.", "response": "def study_datdel(self):\n        \"\"\"Figure out the data delimiter.\"\"\"\n\n        nodigs = r'(\\D+)'\n\n        line = self.rows[self.rts + 1]  # Study second line of data only.\n        digs = re.findall(self.datrx, line)\n\n        # if any of the numbers contain a '+' in it, it need to be escaped\n        # before used in the pattern:\n        digs = [dig.replace('+', r'\\+') for dig in digs]\n\n        pat = nodigs.join(digs)\n        m = re.search(pat, line)\n        groups = m.groups()\n\n        # If the count of data on the row is 1, the groups tuple (the\n        # data delimiters) is empty.\n        if not groups:\n            self.datdelgroups = groups\n            return              # self.datdel remain None.\n\n        rpt_cnt = groups.count(groups[0])\n\n        if rpt_cnt != len(groups):\n            self.warnings.append('Warning, data seperator not consistent.')\n\n        if groups[0].strip():\n            # If a delimiter apart from white space is included, let that be\n            # the delimiter for numpys loadtxt.\n            self.datdel = groups[0].strip()\n        elif groups[0] == '\\t':\n            # If specifically a tab as delimiter, use that.\n            self.datdel = groups[0]\n        # For other white space delimiters, let datdel remain None.\n\n        # work-around for the event that numbers clutters the channel names and\n        # rts is one number low:\n        res = [dat.strip() for dat in self.rows[self.rts].split(self.datdel)\n               if dat.strip()]\n        if not all([re.match(self.datrx, dat) for dat in res]):\n            self.rts += 1\n            # print 'DEBUG: rts was adjusted with 1'\n\n        # Keep the groups for debug:\n        self.datdelgroups = groups"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dict of keyword arguments to provide to numpys loadtxt based on the resulting attributes.", "response": "def loadtxtargs(self):\n        \"\"\"Return a dict (kwargs) to provide to numpys loadtxt, based on the\n        resulting attributes.\n\n        The usecols attribute is set to be all columns in the file. This\n        is done because some data file exporters put an (extra) data\n        delimiter just after last data on each row. This is not\n        expected by numpys loadtxt, but it's not a problem if the usecols\n        item is set.\"\"\"\n\n        d = dict()\n        d.update(delimiter=self.datdel, skiprows=self.rts)\n\n        if self.decdel == '.':\n            # First valid row of data.\n            cols = range(self.matches_p[self.rts + 1])\n        else:\n            cols = range(self.matches_c[self.rts + 1])\n            # Converter needed for float, decdel is comma:\n            convd = {}\n            for i in cols:\n                convd[i] = _floatit\n                d.update(converters=convd)\n        d.update(usecols=cols)\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nattempt to extract the channel names from the data file. Return a list with names. Return None on failed attempt.", "response": "def channel_names(self, usecols=None):\n        \"\"\"Attempt to extract the channel names from the data\n        file. Return a list with names. Return None on failed attempt.\n\n        usecols: A list with columns to use. If present, the returned\n        list will include only names for columns requested. It will\n        align with the columns returned by numpys loadtxt by using the\n        same keyword (usecols).\n        \"\"\"\n\n        # Search from [rts - 1] and up (last row before data). Split respective\n        # row on datdel. Accept consecutive elements starting with alphas\n        # character after strip. If the count of elements equals the data count\n        # on row rts + 1, accept it as the channel names.\n\n        if self.decdel == '.':\n            datcnt = self.matches_p[self.rts]\n        elif self.decdel == ',':\n            datcnt = self.matches_c[self.rts]\n\n        if usecols and max(usecols) >= datcnt:\n            mess = ' Max column index is '\n            raise IndexError(str(usecols) + mess + str(datcnt - 1))\n\n        names = None\n        if not self.rts:                        # Only data.\n            return None\n\n        # From last row before data and up.\n        for row in self.rows[self.rts - 1::-1]:\n            # datdel might be None, (whitespace)\n            splitlist = row.split(self.datdel)\n            for i, word in enumerate(splitlist):\n                if not word.strip().startswith(ALPHAS):\n                    break\n                elif i + 1 == datcnt:  # Accept\n                    names = [ch.strip() for ch in splitlist[:datcnt]]\n                    break\n            if names:\n                break\n\n        if usecols:\n            names = [names[i] for i in sorted(usecols)]\n\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef align(s1,s2,test=False):\n    import operator\n    from Bio import pairwise2\n    alignments = pairwise2.align.localms(s1.upper(),s2.upper(),1,-1,-5,-5)\n    if test:\n        print(alignments)\n    alignsymb=np.nan\n    score=np.nan\n    sorted_alignments = sorted(alignments, key=operator.itemgetter(2))\n    for a in alignments:\n        alignstr=pairwise2.format_alignment(*a)\n        alignsymb=alignstr.split('\\n')[1]\n        score=a[2]\n        if test:\n            print(alignstr)\n        break\n    return alignsymb,score", "response": "Creates pairwise local alignment between seqeunces."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister the given instance as implementation for a class interface.", "response": "def register(self, cls, instance):\n        \"\"\"\n        Register the given instance as implementation for a class interface\n        \"\"\"\n        if not issubclass(cls, DropletInterface):\n            raise TypeError('Given class is not a NAZInterface subclass: %s'\n                            % cls)\n\n        if not isinstance(instance, cls):\n            raise TypeError('Given instance does not implement the class: %s'\n                            % instance)\n\n        if instance.name in self.INSTANCES_BY_NAME:\n            if self.INSTANCES_BY_NAME[instance.name] != instance:\n                raise ValueError('Given name is registered '\n                                 'by other instance: %s' % instance.name)\n\n        self.INSTANCES_BY_INTERFACE[cls].add(instance)\n        self.INSTANCES_BY_NAME[instance.name] = instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_logger(log_level, path, logger_name='giganews'):\n    FmtString = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n\n    log = logging.getLogger(logger_name)\n    log.setLevel(logging.DEBUG)\n\n    fh = logging.FileHandler(path)\n    ch = logging.StreamHandler()\n\n    #fh.setLevel(log_level)\n    fh.setLevel(logging.INFO)\n    ch.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(FmtString)\n    fh.setFormatter(formatter)\n    ch.setFormatter(formatter)\n\n    log.addHandler(fh)\n    log.addHandler(ch)\n    return log", "response": "Convenience function to quickly configure any level of\n    logging to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stream_tap(callables, stream):\n    for item in stream:\n        for caller in callables:\n            caller(item)\n        yield item", "response": "Calls each callable with each item in the stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef selected(self, interrupt=False):\n        self.ao2.output(self.get_title(), interrupt=interrupt)", "response": "This object has been selected."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize_rdf(update_graph, signing):\n    '''Tweak rdflib's pretty-xml serialization of update_graph into\n    the \"indentical\" representation as defined in http://mzl.la/x4XF6o\n    '''\n    unsorted_s = update_graph.serialize(format = 'pretty-xml')\n    unsorted_s = unsorted_s.replace('xmlns:rdf', 'xmlns:RDF')\n    unsorted_s = unsorted_s.replace('rdf:', 'RDF:')\n    unsorted_s = unsorted_s.replace('RDF:about', 'about')\n    unsorted_s = unsorted_s.split('\\n')\n    start, end = unsorted_s[0:5], unsorted_s[-2:]\n    unsorted_s = unsorted_s[5:-2]\n    if signing:\n        unsorted_s = [line[2:] for line in unsorted_s]\n        unsorted_s.append('')\n    sorting_s = []\n    prev_leading_spaces = -2\n    for line in unsorted_s:\n        leading_spaces = len(line) - len(line.lstrip())\n        if leading_spaces > prev_leading_spaces:\n            sorting_s.append([line])\n        elif leading_spaces == prev_leading_spaces:\n            sorting_s[-1].append(line)\n        elif leading_spaces < prev_leading_spaces:\n            tmp_line = sorting_s.pop()\n            tmp_line = '\\n'.join(sorted(tmp_line))\n            tmp_line = [sorting_s[-1].pop(), tmp_line, line]\n            tmp_line = '\\n'.join(tmp_line)\n            sorting_s[-1].append(tmp_line)\n        prev_leading_spaces = leading_spaces\n    if signing:\n        sorted_s = '\\n'.join(sorting_s[0])\n    else:\n        sorted_s = []\n        sorted_s.extend(start)\n        sorted_s.extend(sorting_s[0])\n        sorted_s.extend(end)\n        sorted_s = '\\n'.join(sorted_s)\n    return sorted_s", "response": "Tweak rdflib s pretty - xml serialization of update_graph into\n    the indentical representation as defined in http://mzl. la / x4XF6o\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of a header key. Replaces existing value if replace is True.", "response": "def header(self, k, v, replace=True):\n        \"\"\" Sets header value. Replaces existing value if `replace` is True.\n        Otherwise create a list of existing values and `v`\n\n        :param k: Header key\n        :param v: Header value\n        :param replace: flag for setting mode.\n        :type k: str\n        :type v: str\n        :type replace: bool\n        \"\"\"\n        if replace:\n            self._headers[k] = [v]\n\n        else:\n            self._headers.setdefault(k, []).append(v)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a cookie value.", "response": "def cookie(self, k, v, expires=None, domain=None, path='/', secure=False):\n        \"\"\" Sets cookie value.\n\n        :param k: Name for cookie value\n        :param v: Cookie value\n        :param expires: Cookie expiration date\n        :param domain: Cookie domain\n        :param path: Cookie path\n        :param secure: Flag for `https only`\n        :type k: str\n        :type v: str\n        :type expires: datetime.datetime\n        :type domain: str\n        :type path: str\n        :type secure: bool\n        \"\"\"\n        ls = ['{}={}'.format(k, v)]\n\n        if expires is not None:\n            dt = format_date_time(mktime(expires.timetuple()))\n            ls.append('expires={}'.format(dt))\n\n        if domain is not None:\n            ls.append('domain={}'.format(domain))\n\n        if path is not None:\n            ls.append('path={}'.format(path))\n\n        if secure:\n            ls.append('secure')\n\n        return self.header('Set-Cookie', '; '.join(ls), False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild and return a decorator that will decorate all methods in the class.", "response": "def decorate_all_methods(decorator):\n  \"\"\"\n  Build and return a decorator that will decorate all class members.\n\n  This will apply the passed decorator to all of the methods in the decorated\n  class, except the __init__ method, when a class is decorated with it.\n  \"\"\"\n  def decorate_class(cls):\n    for name, m in inspect.getmembers(cls, inspect.ismethod):\n      if name != \"__init__\":\n        setattr(cls, name, decorator(m))\n    return cls\n  return decorate_class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef just_in_time_method(func):\n\n  if not inspect.ismethod:\n    raise MetaError(\"oops\")\n\n  def wrapper(self, *args, **kwargs):\n    if self.item is None:\n      self.item = self.factory[self.key]\n    return getattr(self.item, func.__name__)(*args, **kwargs)\n  return wrapper", "response": "This is a dcorator for methods that are just in - time. It is a dcorator for methods that are just in - time. It is a dcorator for methods that are just in - time. It is a dcorator for methods that are just in - time. It is a dcorator for methods that are just in - time."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fill(self):\n    try:\n      self._head = self._iterable.next()\n    except StopIteration:\n      self._head = None", "response": "Advance the iterator without returning the old head."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fill(self):\n    prev = self._head\n    super(AutoApplyIterator, self)._fill()\n    if self._head is not None:\n      self.on_next(self._head, prev)", "response": "Advance the iterator without returning the old head."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an accelerator to the list of accelerators.", "response": "def AddAccelerator(self, modifiers, key, action):\n \"\"\"\n Add an accelerator.\n \n Modifiers and key follow the same pattern as the list used to create wx.AcceleratorTable objects.\n \"\"\"\n newId = wx.NewId()\n self.Bind(wx.EVT_MENU, action, id = newId)\n self.RawAcceleratorTable.append((modifiers, key, newId))\n self.SetAcceleratorTable(wx.AcceleratorTable(self.RawAcceleratorTable))\n return newId"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_config(lines, module=None):\n    if module is None:\n        module = _calling_scope(2)\n    lines = IndentChecker(lines)\n    path_router = PathRouter()\n    for depth, line in lines:\n        if depth > 0:\n            raise SyntaxError('unexpected indent')\n        name, path, types = parse_path_spec(line)\n        if types:\n            template_arg = (path, dict(\n                (k, find_object(module, v))\n                for k, v in types.iteritems()\n            ))\n        else:\n            template_arg = path\n        handler = read_handler_block(lines, module)\n        path_router.add(name, template_arg, handler)\n    return path_router", "response": "Parse a config file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_config(name='urls.conf'):\n    module = _calling_scope(2)\n    config = resource_stream(module.__name__, name)\n    return parse_config(config, module)", "response": "Load a config file from a resource file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a placeholder for the specified name by applying the instance s format strings.", "response": "def to_placeholder(self, name=None, db_type=None):\n    \"\"\"Returns a placeholder for the specified name, by applying the instance's format strings.\n\n    :name: if None an unamed placeholder is returned, otherwise a named placeholder is returned.\n    :db_type: if not None the placeholder is typecast.\n    \"\"\"\n    if name is None:\n      placeholder = self.unnamed_placeholder\n    else:\n      placeholder = self.named_placeholder.format(name)\n\n    if db_type:\n      return self.typecast(placeholder, db_type)\n    else:\n      return placeholder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the iterable as a SQL tuple.", "response": "def to_tuple(self, iterable, surround=\"()\", joiner=\", \"):\n    \"\"\"Returns the iterable as a SQL tuple.\"\"\"\n    return \"{0}{1}{2}\".format(surround[0], joiner.join(iterable), surround[1])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_expression(self, lhs, rhs, op):\n    if op == \"raw\":\n      # TODO: This is not documented\n      return lhs\n    elif op == \"between\":\n      return \"{0} between {1} and {2}\".format(lhs, *rhs)\n    elif op == \"in\":\n      return \"{0} in {1}\".format(lhs, self.to_tuple(rhs))\n    elif op.startswith(\"not(\") and op.endswith(\")\"):\n      return \"not ({0} {1} {2})\".format(lhs, op[4:-1].strip(), rhs)\n    else:\n      return \"{0} {1} {2}\".format(lhs, op.strip(), rhs)", "response": "Builds a binary sql expression from lhs rhs and operator op."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms an operator to a string.", "response": "def transform_op(self, op, value):\n    \"\"\"For comparisons, if the value is None (null), the '=' operator must be replaced with ' is '\n    and the '!=' operator must be replaced with ' is not '. This function handles that conversion.\n    It's up to the caller to call this function only on comparisons and not on assignments.\n    \"\"\"\n    if value is None:\n      if _EQ_RE.match(op):\n        return \"is\"\n      elif _NEQ_RE.match(op):\n        return \"is not\"\n\n    return op"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds out a series of value comparisions.", "response": "def value_comparisons(self, values, comp=\"=\", is_assignment=False):\n    \"\"\"Builds out a series of value comparisions.\n\n    :values: can either be a dictionary, in which case the return will compare a name to a named\n    placeholder, using the comp argument. I.E. values = {\"first_name\": \"John\", \"last_name\": \"Smith\"}\n    will return [\"first_name = %(first_name)s\", \"last_name = %(last_name)s\"].\n\n    Otherwise values will be assumed to be an iterable of 2- or 3-tuples in the form\n    (column, value[, operator]). When operator is not specified, it will fallback to comp. So for\n    instance values = [(\"first_name\", \"John\"), (\"id\", (10, 100), \"between\")] will return\n    [\"first_name = %s\", \"id between %s and %s \"].\n\n    :is_assigment: if False, transform_op will be called on each operator.\n    \"\"\"\n    if isinstance(values, dict):\n      if self.sort_columns:\n        keys = sorted(values.keys())\n      else:\n        keys = list(values.keys())\n\n      params = zip(keys, [self.to_placeholder(k) for k in keys])\n      return [\n        self.to_expression(\n          i[0],\n          i[1],\n          comp if is_assignment else self.transform_op(comp, values[i[0]]))\n        for i in params]\n    else:\n      if self.sort_columns:\n        values = sorted(values, key=operator.itemgetter(0))\n      comps = []\n      for val in values:\n        lhs = val[0]\n        op = val[2] if len(val) == 3 else comp\n        if op == \"raw\":\n          rhs = None\n        elif op == \"between\":\n          rhs = (self.to_placeholder(), self.to_placeholder())\n        elif op == \"in\":\n          rhs = [self.to_placeholder() for i in val[1]]\n        else:\n          rhs = self.to_placeholder()\n          if not is_assignment:\n            op = self.transform_op(op, val[1])\n\n        comps.append(self.to_expression(lhs, rhs, op))\n      return comps"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef join_comparisons(self, values, joiner, *, is_assignment=False, comp=\"=\"):\n    if isinstance(values, str):\n      return values\n    else:\n      return joiner.join(self.value_comparisons(values, comp, is_assignment))", "response": "Generates comparisons with the value_comparisions method and joins them with joiner."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the constraints into a tuple.", "response": "def parse_constraints(self, constraints, joiner=\" and \", *, is_assignment=False, comp=\"=\"):\n    \"\"\"Parses constraints into a (sql, params) tuple.\n\n    :constraints: can either be a dict, an enumerable with a sql string and params, an enumerable of\n    2- or 3-tuples, or just a string.\n\n    If is_assignment is false, transform_op will be called on each comparison operator.\n    \"\"\"\n    if constraints is None:\n      return (None, None)\n    elif isinstance(constraints, dict):\n      return (\n        self.join_comparisons(constraints, joiner, is_assignment=is_assignment, comp=comp),\n        self.get_params(constraints))\n    elif isinstance(constraints, (list, tuple)):\n      if len(constraints) == 2 and isinstance(constraints[0], str):\n        return (constraints[0], constraints[1])\n      else:\n        return (\n          self.join_comparisons(constraints, joiner, is_assignment=is_assignment, comp=comp),\n          self.get_params(constraints))\n    elif isinstance(constraints, str):\n      return (constraints, None)\n    else:\n      raise TypeError(\n        \"constraints must be None, str, dict, list or tuple. Is {0}\".format(\n          type(constraints).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the params to be executed from a list of values.", "response": "def get_params(self, values):\n    \"\"\"Gets params to be passed to execute from values.\n\n    :values: can either be a dict, in which case it will be returned as is, or can be an enumerable\n    of 2- or 3-tuples. This will return an enumerable of the 2nd values, and in the case of some\n    operators such as 'in' and 'between' the values will be specially handled.\n    \"\"\"\n    if values is None:\n      return None\n    elif isinstance(values, dict):\n      return values\n    elif isinstance(values, (list, tuple)):\n      params = []\n      for val in values:\n        if len(val) == 2:\n          params.append(val[1])\n        else:\n          if val[2] in (\"in\", \"between\"):\n            params.extend(val[1])\n          else:\n            params.append(val[1])\n      return params\n    elif isinstance(values, str):\n      return None\n    else:\n      raise TypeError(\n        \"values must be None, a dict, list or tuple, is {0}\".format(type(values).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_find_all_query(self, table_name, constraints=None, *, columns=None, order_by=None,\n                         limiting=(None, None)):\n    \"\"\"Builds a find query.\n\n    :limiting: if present must be a 2-tuple of (limit, offset) either of which can be None.\n    \"\"\"\n    where, params = self.parse_constraints(constraints)\n\n    if columns:\n      if isinstance(columns, str):\n        pass\n      else:\n        columns = \", \".join(columns)\n    else:\n      columns = \"*\"\n\n    if order_by:\n      order = \" order by {0}\".format(order_by)\n    else:\n      order = \"\"\n\n    paging = \"\"\n    if limiting is not None:\n      limit, offset = limiting\n      if limit is not None:\n        paging += \" limit {0}\".format(limit)\n      if offset is not None:\n        paging += \" offset {0}\".format(offset)\n\n    return (\"select {0} from {1} where {2}{3}{4}\".format(\n      columns,\n      table_name,\n      where or \"1 = 1\",\n      order,\n      paging\n    ), params)", "response": "Builds a find query for all tables in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pretty_print(rows, keyword, domain):\n    if isinstance(rows, dict):\n        pretty_print_domain(rows, keyword, domain)\n    elif isinstance(rows, list):\n        pretty_print_zones(rows)", "response": "Pretty print the data for a single resource item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints the domain of the current ISO.", "response": "def pretty_print_domain(rows, keyword, domain):\n    \"\"\"\n    Arguments:\n\n        rows:    get response data\n        keyword: search keyword\n\n    \"\"\"\n    if len(rows.get('records')) == 0:\n        return None\n\n    # six columns; priority, name, content, ttl, change_date, type\n    header_l = ['prio', 'name', 'content',\n                'ttl', 'change date', 'type']\n    # 0->4, 1->0, 2->2, 3->3, 4->5, 5->1\n    header_l_sorted = ['name', 'type', 'content',\n                       'ttl', 'prio', 'change date']\n    header_l_sorted.reverse()\n\n    cols_width = [len(i) for i in header_l]\n\n    \"\"\"\n    if key == 'change_date':\n        value = datetime.fromtimestamp(\n            int(row_d.get(key))).strftime(\"%Y%m%d-%H%M%S\")\n            \"\"\"\n\n    cw_, soa = get_columns_width(rows.get('records'),\n                                 cols_width, True)\n\n    # sorted as name, type, content, ttl, priority, change_date\n    cols_width_sorted = [cw_[1], cw_[5], cw_[2],\n                         cw_[3], cw_[0], cw_[4]]\n\n    if isinstance(soa, dict):\n        soa_s = ('zone:        ' + soa.get('name') + '\\n' +\n                 'SOA record:  ' + soa.get('content') + '\\n' +\n                 'ttl:         ' + soa.get('ttl') + '\\n' +\n                 'change date: ' + soa.get('change_date'))\n        domain = soa.get('name')\n        print(soa_s)\n\n    print domain\n\n    if keyword != 'SOA':\n        print_header(cols_width_sorted, header_l_sorted, len(domain))\n        str_value = ''\n        for row in rows.get('records'):\n            if row.get('type') == 'SOA':\n                pass\n            else:\n                # name\n                if row.get('name'):\n                    str_value = get_row_s(row, 'name',\n                                          cols_width_sorted[0],\n                                          domain=domain)\n                    sys.stdout.write(\"|%s\" % str_value)\n                # type\n                if row.get('type'):\n                    str_value = get_row_s(row, 'type',\n                                          cols_width_sorted[1])\n                    sys.stdout.write(\"|%s\" % str_value)\n                # content\n                if row.get('content'):\n                    str_value = get_row_s(row, 'content',\n                                          cols_width_sorted[2])\n                    sys.stdout.write(\"|%s\" % str_value)\n                # ttl\n                if row.get('ttl'):\n                    str_value = get_row_s(row, 'ttl',\n                                          cols_width_sorted[3])\n                    sys.stdout.write(\"|%s\" % str_value)\n                # priority\n                if row.get('priority') is None:\n                    val = {'priority': '-'}\n                else:\n                    val = row.copy()\n                str_value = get_row_s(val, 'priority',\n                                      cols_width_sorted[4])\n                sys.stdout.write(\"|%s\" % str_value)\n                if row.get('change_date') is None:\n                    val = {'change_date': '-'}\n                else:\n                    val = row.copy()\n                str_value = get_row_s(val, 'change_date',\n                                      cols_width_sorted[5])\n                print(\"|%s|\" % str_value)\n\n        print_bottom(cols_width_sorted, len(domain))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_status(self):\n\n        def validate_namespace(self):\n            if not self.has_namespace(self.namespace):\n                log.warning(format_multiline([\"\",\n                                              \"\"\"\\tnamespace '{}' does not\n                                              exist. Creating namespace\"\"\"],\n                                              self.namespace))\n                self.create_namespace(self.namespace)\n\n        if self.url:\n            return True\n        try:\n            result = requests.get(self._make_url(self.namespace,\n                                                 self.ext_url,\n                                                 check_status_call=True))\n            self.url = self.ext_url\n            validate_namespace(self)\n            return True\n        except requests.exceptions.ConnectionError:\n            pass\n        try:\n            result = requests.get(self._make_url(self.namespace,\n                                                 self.local_url,\n                                                 check_status_call=True))\n            log.warning(\"Url '%s' not connecting. Using local_url '%s'\" % \\\n                     (self.ext_url, self.local_url))\n            self.url = self.local_url\n            validate_namespace(self)\n            return True\n        except requests.exceptions.ConnectionError:\n            self.url = None\n            log.warning(\"Unable to connect using urls: %s\" % set([self.ext_url,\n                                                               self.local_url]))\n            return False", "response": "checks the status of the current instance of the object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a sparql query and returns the results", "response": "def query(self,\n              sparql,\n              mode=\"get\",\n              namespace=None,\n              rtn_format=\"json\",\n              **kwargs):\n        \"\"\"\n        Runs a sparql query and returns the results\n\n        Args:\n        -----\n            sparql: the sparql query to run\n            namespace: the namespace to run the sparql query against\n            mode: ['get'(default), 'update'] the type of sparql query\n            rtn_format: ['json'(default), 'xml'] format of query results\n\n        Kwargs:\n        -------\n            debug(bool): If True sets logging level to debug\n        \"\"\"\n        namespace = pick(namespace, self.namespace)\n        if kwargs.get(\"log_level\"):\n            log.setLevel(kwargs['log_level'])\n        if kwargs.get(\"debug\"):\n            log.setLevel(logging.DEBUG)\n        if rtn_format not in self.qry_formats:\n            raise KeyError(\"rtn_format was '%s'. Allowed values are %s\" % \\\n                           (rtn_format, self.qry_results_formats))\n        url = self._make_url(namespace)\n        if 'prefix' not in sparql.lower():\n            sparql = \"%s\\n%s\" % (NSM.prefix(), sparql)\n\n\n        if mode == \"get\":\n\n            data = {\"query\": sparql} #, \"format\": rtn_format}\n        elif mode == \"update\":\n            data = {\"update\": sparql}\n        else:\n            raise NotImplementedError(\"'mode' != to ['get', 'update']\")\n\n        headers = {'Accept': self.qry_formats[rtn_format]}\n        start = datetime.datetime.now()\n        try:\n            result = requests.post(url, data=data, headers=headers)\n        except requests.exceptions.ConnectionError:\n            result = requests.post(self._make_url(namespace, self.local_url),\n                                   data=data,\n                                   headers=headers)\n        log.debug(format_multiline([\"\",\n                                    \"url='{url}'\",\n                                    \"\"\"mode='{mode}', namespace='{namespace}',\n                                    rtn_format='{rtn_format}'\"\"\",\n                                    \"**** SPAQRL QUERY ****\",\n                                    \"\",\n                                    \"{sparql}\",\n                                    \"Query Time: {q_time}\"],\n                                   url=url,\n                                   mode=mode,\n                                   namespace=namespace,\n                                   rtn_format=rtn_format,\n                                   sparql=sparql,\n                                   q_time=(datetime.datetime.now()-start),\n                                   **kwargs))\n\n        if result.status_code == 200:\n            try:\n                if rtn_format == \"json\":\n                    bindings = result.json().get('results',\n                                                 {}).get('bindings', [])\n                elif rtn_format == 'xml':\n                    xml_doc = etree.XML(result.text)\n                    bindings = xml_doc.findall(\"results/bindings\")\n                else:\n                    bindings = result.text\n                try:\n                    log.debug(\"result count: %s\", len(bindings))\n                except TypeError:\n                    pass\n                return bindings\n            except json.decoder.JSONDecodeError:\n                if mode == 'update':\n                    return BeautifulSoup(result.text, 'lxml').get_text()\n                return result.text\n        else:\n            raise SyntaxError(\"%s\\n\\n%s\\n\\n%s\" % (sparql,\n                    add_sparql_line_nums(sparql),\n                    result.text[result.text.find(\"java.\"):]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads data into blazegraph", "response": "def load_data(self,\n                  data,\n                  datatype=\"ttl\",\n                  namespace=None,\n                  graph=None,\n                  is_file=False,\n                  **kwargs):\n        \"\"\"\n        Loads data via file stream from python to triplestore\n\n        Args:\n        -----\n          data: The data or filepath to load\n          datatype(['ttl', 'xml', 'rdf']): the type of data to load\n          namespace: the namespace to use\n          graph: the graph to load the data to.\n          is_file(False): If true python will read the data argument as a\n              filepath, determine the datatype from the file extension,\n              read the file and send it to blazegraph as a datastream\n        \"\"\"\n        log.setLevel(kwargs.get(\"log_level\", self.log_level))\n        time_start = datetime.datetime.now()\n        datatype_map = {\n            'ttl': 'text/turtle',\n            'xml': 'application/rdf+xml',\n            'rdf': 'application/rdf+xml',\n            'nt': 'text/plain'\n        }\n        if is_file:\n            datatype = data.split(os.path.extsep)[-1]\n            file_name = data\n            log.debug('starting data load of %s', file_name)\n            data = open(data, 'rb').read()\n        else:\n            try:\n                data = data.encode('utf-8')\n            except AttributeError:\n                # data already encoded\n                pass\n        try:\n            content_type = datatype_map[datatype]\n        except KeyError:\n            raise NotImplementedError(\"'%s' is not an implemented data format\",\n                                      datatype)\n        context_uri = pick(graph, self.graph)\n        result = requests.post(url=self._make_url(namespace),\n                               headers={\"Content-Type\": content_type},\n                               params={\"context-uri\": context_uri},\n                               data=data)\n        if result.status_code == 200:\n            if is_file:\n                log.info (\" loaded %s into blazegraph - %s\",\n                          file_name,\n                          self.format_response(result.text))\n            else:\n                log.info(\" loaded data - %s\", self.format_response(result.text))\n            log.setLevel(self.log_level)\n            return result\n        else:\n            raise SyntaxError(result.text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads the data from a local file into the Triplestore that is stored locally in the files directory that is available locally to blazegraph.", "response": "def load_local_file(self, file_path, namespace=None, graph=None, **kwargs):\n        \"\"\" Uploads data to the Blazegraph Triplestore that is stored in files\n            in directory that is available locally to blazegraph\n\n            args:\n                file_path: full path to the file\n                namespace: the Blazegraph namespace to load the data\n                graph: uri of the graph to load the data. Default is None\n\n            kwargs:\n                container_dir: the directory as seen by blazegraph - defaults to\n                        instance attribute if not passed\n        \"\"\"\n        time_start = datetime.datetime.now()\n        url = self._make_url(namespace)\n        params = {}\n        if graph:\n            params['context-uri'] = graph\n        new_path = []\n        container_dir = pick(kwargs.get('container_dir'), self.container_dir)\n        if container_dir:\n            new_path.append(self.container_dir)\n        new_path.append(file_path)\n        params['uri'] = \"file:///%s\" % os.path.join(*new_path)\n        log.debug(\" loading %s into blazegraph\", file_path)\n        result = requests.post(url=url, params=params)\n        if result.status_code > 300:\n            raise SyntaxError(result.text)\n        log.info(\"loaded '%s' in time: %s blazegraph response: %s\",\n                 file_path,\n                 datetime.datetime.now() - time_start,\n                 self.format_response(result.text))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntests to see if the namespace exists", "response": "def has_namespace(self, namespace):\n        \"\"\" tests to see if the namespace exists\n\n        args:\n            namespace: the name of the namespace\n        \"\"\"\n        result = requests.get(self._make_url(namespace))\n        if result.status_code == 200:\n            return True\n        elif result.status_code == 404:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new namespace in the triplestore.", "response": "def create_namespace(self, namespace=None, params=None):\n        \"\"\" Creates a namespace in the triplestore\n\n        args:\n            namespace: the name of the namspace to create\n            params: Dictionary of Blazegraph paramaters. defaults are:\n\n                    {'axioms': 'com.bigdata.rdf.axioms.NoAxioms',\n                     'geoSpatial': False,\n                     'isolatableIndices': False,\n                     'justify': False,\n                     'quads': False,\n                     'rdr': False,\n                     'textIndex': False,\n                     'truthMaintenance': False}\n        \"\"\"\n        namespace = pick(namespace, self.namespace)\n        params = pick(params, self.namespace_params)\n        if not namespace:\n            raise ReferenceError(\"No 'namespace' specified\")\n        _params = {'axioms': 'com.bigdata.rdf.axioms.NoAxioms',\n                   'geoSpatial': False,\n                   'isolatableIndices': False,\n                   'justify': False,\n                   'namespace': namespace,\n                   'quads': True,\n                   'rdr': False,\n                   'textIndex': False,\n                   'truthMaintenance': False}\n        if params:\n            _params.update(params)\n        content_type = \"text/plain\"\n        url = self._make_url(\"prepareProperties\").replace(\"/sparql\", \"\")\n        params = [\"%s=%s\" % (map_val,\n                             json.dumps(_params[map_key]).replace(\"\\\"\", \"\")) \\\n                  for map_key, map_val in self.ns_property_map.items()]\n        params = \"\\n\".join(params)\n        result = requests.post(url=url,\n                               headers={\"Content-Type\": content_type},\n                               data=params)\n        data = result.text\n        content_type = \"application/xml\"\n        url = self._make_url(\"x\").replace(\"/x/sparql\", \"\")\n        result = requests.post(url=url,\n                               headers={\"Content-Type\": content_type},\n                               data=data)\n        if result.status_code == 201:\n            log.warning(result.text)\n            return result.text\n        else:\n            raise RuntimeError(result.text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_namespace(self, namespace):\n\n        # if not self.has_namespace(namespace):\n        #     return \"Namespace does not exists\"\n\n        # log = logging.getLogger(\"%s.%s\" % (self.log_name,\n        #                                    inspect.stack()[0][3]))\n        # log.setLevel(self.log_level)\n\n        url = self._make_url(namespace).replace(\"/sparql\", \"\")\n        result = requests.delete(url=url)\n        if result.status_code == 200:\n            log.critical(result.text)\n            return result.text\n        raise RuntimeError(result.text)", "response": "Delete a namespace from the triplestore"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the REST Url based on the supplied namespace and url.", "response": "def _make_url(self, namespace=None, url=None, **kwargs):\n        \"\"\" Creates the REST Url based on the supplied namespace\n\n        args:\n            namespace: string of the namespace\n        kwargs:\n            check_status_call: True/False, whether the function is called from\n                    check_status. Used to avoid recurrsion error\n        \"\"\"\n        if not kwargs.get(\"check_status_call\"):\n            if not self.url:\n                self.check_status\n        rtn_url = self.url\n        if url:\n            rtn_url = url\n        if rtn_url is None:\n            rtn_url = self.ext_url\n        namespace = pick(namespace, self.namespace)\n        if namespace:\n            rtn_url = os.path.join(rtn_url.replace(\"sparql\", \"\"),\n                                   \"namespace\",\n                                   namespace,\n                                   \"sparql\").replace(\"\\\\\", \"/\")\n        elif not rtn_url.endswith(\"sparql\"):\n            rtn_url = os.path.join(rtn_url, \"sparql\").replace(\"\\\\\", \"/\")\n        return rtn_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reset_namespace(self, namespace=None, params=None):\n        log = logging.getLogger(\"%s.%s\" % (self.log_name,\n                                           inspect.stack()[0][3]))\n        log.setLevel(self.log_level)\n        namespace = pick(namespace, self.namespace)\n        params = pick(params, self.namespace_params)\n        log.warning(\" Reseting namespace '%s' at host: %s\",\n                 namespace,\n                 self.url)\n        try:\n            self.delete_namespace(namespace)\n        except RuntimeError:\n            pass\n        self.create_namespace(namespace, params)", "response": "Will delete and recreate the specified namespace\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading data to the Triplestore that is stored in files that are in a local directory.", "response": "def bulk_load(self, **kwargs):\n        \"\"\" Uploads data to the Blazegraph Triplestore that is stored in files\n            that are in a local directory\n\n            kwargs:\n                file_directory: a string path to the file directory\n                file_extensions: a list of file extensions to filter\n                        example ['xml', 'rdf']. If none include all files\n                include_subfolders: as implied\n                namespace: the Blazegraph namespace to load the data\n                graph: uri of the graph to load the data. Default is None\n                create_namespace: False(default) or True will create the\n                        namespace if it does not exist\n        \"\"\"\n        namespace = kwargs.get('namespace', self.namespace)\n        graph = kwargs.get('graph', self.graph)\n        if kwargs.get('reset') == True:\n            self.reset_namespace()\n        file_directory = kwargs.get('file_directory', self.local_directory)\n        file_extensions = kwargs.get('file_extensions', self.rdf_formats)\n        root_dir = kwargs.get('root_dir', self.local_directory)\n        file_list = list_files(file_directory,\n                               file_extensions,\n                               kwargs.get('include_subfolders', True),\n                               include_root=kwargs.get('include_root', False),\n                               root_dir=root_dir)\n        path_parts = [' ']\n        if self.container_dir:\n            path_parts.append(self.container_dir)\n        file_or_dirs = \",\".join([os.path.join(os.path.join(*path_parts),file[1])\n                                 for file in file_list]).strip()\n        file_or_dirs = \"/alliance_data\"\n        _params = BULK_LOADER_PARAMS.copy()\n        params = {\n                    'namespace': kwargs.get('namespace', self.namespace),\n                    'file_or_dirs': file_or_dirs,\n                 }\n\n        _params.update(params)\n        time_start = datetime.datetime.now()\n\n        log.info(\" starting load of '%s' files into namespace '%s'\",\n                 len(file_list),\n                 params['namespace'])\n        new_params = {key: json.dumps(value) \\\n                      for key, value in _params.items() \\\n                      if not isinstance(value, str)}\n        new_params.update({key: value \\\n                           for key, value in _params.items() \\\n                           if isinstance(value, str)})\n        data = BULK_LOADER_XML.format(**new_params)\n        log.debug(data)\n        url = os.path.join(self.url, 'dataloader')\n        result = requests.post(url=url,\n                               headers={\"Content-Type\": 'application/xml'},\n                               data=data)\n        failed_list = list_files(file_directory,\n                                 ['fail'],\n                                 kwargs.get('include_subfolders', True),\n                                 include_root=kwargs.get('include_root', False),\n                                 root_dir=root_dir)\n        failed_list = [file for file in failed_list \\\n                       if file[0].split(\".\")[-2] in file_extensions]\n        good_list = list_files(file_directory,\n                               ['good'],\n                               kwargs.get('include_subfolders', True),\n                               include_root=kwargs.get('include_root', False),\n                               root_dir=root_dir)\n        log.info(\" bulk_load results: %s\\nThe following files successfully loaded: \\n\\t%s\",\n                 result.text,\n                 \"\\n\\t\".join([os.path.splitext(file[1])[0] \\\n                              for file in good_list]))\n        if failed_list:\n            log.warning(\"The following files failed to load:\\n\\t%s\",\n                     \"\\n\\t\".join([file[1] for file in failed_list]))\n            log.info(\" Attempting load via alt method ***\")\n            for file in failed_list:\n                os.rename(os.path.join(root_dir, file[1]),\n                          os.path.join(root_dir, os.path.splitext(file[1])[0]))\n                self.load_local_file(os.path.splitext(file[1])[0],\n                                     namespace,\n                                     graph)\n        # restore file names\n        files = list_files(file_directory,\n                           ['good','fail'],\n                           kwargs.get('include_subfolders', True),\n                           include_root=kwargs.get('include_root', False),\n                           root_dir=root_dir)\n        [os.rename(os.path.join(root_dir, file[1]),\n                   os.path.join(root_dir, os.path.splitext(file[1])[0])) \\\n         for file in files]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tree_render(request, upy_context, vars_dictionary):\n    page = upy_context['PAGE']\n    return render_to_response(page.template.file_name, vars_dictionary, context_instance=RequestContext(request))", "response": "This function renders the tree template defined in the page passed in arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef view_500(request, url=None):\n    res = render_to_response(\"500.html\", context_instance=RequestContext(request))\n    res.status_code = 500\n    return res", "response": "view_500 returns a 500 http response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef favicon(request):\n    favicon = u\"{}tree/images/favicon.ico\".format(settings.STATIC_URL)\n    try:\n        from seo.models import MetaSite\n        site = MetaSite.objects.get(default=True)\n        return HttpResponseRedirect(site.favicon.url)\n    except:\n        return HttpResponseRedirect(favicon)", "response": "It returns favicon s location"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(arguments=None):\n    # setup the command-line util settings\n    su = tools(\n        arguments=arguments,\n        docString=__doc__,\n        logLevel=\"WARNING\",\n        options_first=True,\n        projectName=\"sloancone\",\n        tunnel=False\n    )\n    arguments, settings, log, dbConn = su.setup()\n\n    # tab completion for raw_input\n    readline.set_completer_delims(' \\t\\n;')\n    readline.parse_and_bind(\"tab: complete\")\n    readline.set_completer(tab_complete)\n\n    # unpack remaining cl arguments using `exec` to setup the variable names\n    # automatically\n    for arg, val in arguments.iteritems():\n        if arg[0] == \"-\":\n            varname = arg.replace(\"-\", \"\") + \"Flag\"\n        else:\n            varname = arg.replace(\"<\", \"\").replace(\">\", \"\")\n        if isinstance(val, str) or isinstance(val, unicode):\n            exec(varname + \" = '%s'\" % (val,))\n        else:\n            exec(varname + \" = %s\" % (val,))\n        if arg == \"--dbConn\":\n            dbConn = val\n        log.debug('%s = %s' % (varname, val,))\n\n    ## START LOGGING ##\n    startTime = times.get_now_sql_datetime()\n    log.info(\n        '--- STARTING TO RUN THE cl_utils.py AT %s' %\n        (startTime,))\n\n    # set options interactively if user requests\n    if \"interactiveFlag\" in locals() and interactiveFlag:\n\n        # load previous settings\n        moduleDirectory = os.path.dirname(__file__) + \"/resources\"\n        pathToPickleFile = \"%(moduleDirectory)s/previousSettings.p\" % locals()\n        try:\n            with open(pathToPickleFile):\n                pass\n            previousSettingsExist = True\n        except:\n            previousSettingsExist = False\n        previousSettings = {}\n        if previousSettingsExist:\n            previousSettings = pickle.load(open(pathToPickleFile, \"rb\"))\n\n        # x-raw-input\n        # x-boolean-raw-input\n        # x-raw-input-with-default-value-from-previous-settings\n\n        # save the most recently used requests\n        pickleMeObjects = []\n        pickleMe = {}\n        theseLocals = locals()\n        for k in pickleMeObjects:\n            pickleMe[k] = theseLocals[k]\n        pickle.dump(pickleMe, open(pathToPickleFile, \"wb\"))\n\n    # CALL FUNCTIONS/OBJECTS\n\n    # call the worker function\n    if search:\n        cs = cone_search(\n            log=log,\n            ra=ra,\n            dec=dec,\n            searchRadius=float(arcsecRadius),\n            nearest=nearestFlag,\n            outputFormat=outputFormat,\n            galaxyType=galaxyType\n        )\n        results = cs.get()\n        print results\n\n    # covered = True | False | 999 (i.e. not sure)\n    if covered:\n        check = check_coverage(\n            log=log,\n            ra=ra,\n            dec=dec\n        ).get()\n        print check\n\n    if \"dbConn\" in locals() and dbConn:\n        dbConn.commit()\n        dbConn.close()\n    ## FINISH LOGGING ##\n    endTime = times.get_now_sql_datetime()\n    runningTime = times.calculate_time_difference(startTime, endTime)\n    log.info('-- FINISHED ATTEMPT TO RUN THE cl_utils.py AT %s (RUNTIME: %s) --' %\n             (endTime, runningTime, ))\n\n    return", "response": "This is the main function used by the cl_utils. py module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(arguments=None):\n    # setup the command-line util settings\n    su = tools(\n        arguments=arguments,\n        docString=__doc__,\n        logLevel=\"DEBUG\",\n        options_first=False,\n        projectName=\"sloancone\",\n        tunnel=False\n    )\n    arguments, settings, log, dbConn = su.setup()\n\n    # tab completion for raw_input\n    readline.set_completer_delims(' \\t\\n;')\n    readline.parse_and_bind(\"tab: complete\")\n    readline.set_completer(tab_complete)\n\n    # unpack remaining cl arguments using `exec` to setup the variable names\n    # automatically\n    for arg, val in arguments.iteritems():\n        if arg[0] == \"-\":\n            varname = arg.replace(\"-\", \"\") + \"Flag\"\n        else:\n            varname = arg.replace(\"<\", \"\").replace(\">\", \"\")\n        if isinstance(val, str) or isinstance(val, unicode):\n            exec(varname + \" = '%s'\" % (val,))\n        else:\n            exec(varname + \" = %s\" % (val,))\n        if arg == \"--dbConn\":\n            dbConn = val\n        log.debug('%s = %s' % (varname, val,))\n\n    ## START LOGGING ##\n    startTime = times.get_now_sql_datetime()\n    log.info(\n        '--- STARTING TO RUN THE cl_utils.py AT %s' %\n        (startTime,))\n\n    # set options interactively if user requests\n    if \"interactiveFlag\" in locals() and interactiveFlag:\n\n        # load previous settings\n        moduleDirectory = os.path.dirname(__file__) + \"/resources\"\n        pathToPickleFile = \"%(moduleDirectory)s/previousSettings.p\" % locals()\n        try:\n            with open(pathToPickleFile):\n                pass\n            previousSettingsExist = True\n        except:\n            previousSettingsExist = False\n        previousSettings = {}\n        if previousSettingsExist:\n            previousSettings = pickle.load(open(pathToPickleFile, \"rb\"))\n\n        # x-raw-input\n        # x-boolean-raw-input\n        # x-raw-input-with-default-value-from-previous-settings\n\n        # save the most recently used requests\n        pickleMeObjects = []\n        pickleMe = {}\n        theseLocals = locals()\n        for k in pickleMeObjects:\n            pickleMe[k] = theseLocals[k]\n        pickle.dump(pickleMe, open(pathToPickleFile, \"wb\"))\n\n    # CALL FUNCTIONS/OBJECTS\n\n    if \"dbConn\" in locals() and dbConn:\n        dbConn.commit()\n        dbConn.close()\n    ## FINISH LOGGING ##\n    endTime = times.get_now_sql_datetime()\n    runningTime = times.calculate_time_difference(startTime, endTime)\n    log.info('-- FINISHED ATTEMPT TO RUN THE cl_utils.py AT %s (RUNTIME: %s) --' %\n             (endTime, runningTime, ))\n\n    return", "response": "This function is the main function used by the cl_utils. py module. It is used by the cl_utils. py module to run the cl_utils. py script."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self):\n        username = self.cleaned_data.get(\"username\")\n        password = self.cleaned_data.get(\"password\")\n        self._user = authenticate(username=username, password=password)\n        if self._user is None:\n            raise forms.ValidationError(\n                             ugettext(\"Invalid username/email and password\"))\n        elif not self._user.is_active:\n            raise forms.ValidationError(ugettext(\"Your account is inactive\"))\n        return self.cleaned_data", "response": "Authenticate the given username and password and store the authenticated user for returning via save."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_username(self):\n        username = self.cleaned_data.get(\"username\")\n        if username.lower() != slugify(username).lower():\n            raise forms.ValidationError(\n                ugettext(\"Username can only contain letters, numbers, dashes \"\n                         \"or underscores.\"))\n        lookup = {\"username__iexact\": username}\n        try:\n            User.objects.exclude(id=self.instance.id).get(**lookup)\n        except User.DoesNotExist:\n            return username\n        raise forms.ValidationError(\n                            ugettext(\"This username is already registered\"))", "response": "Ensure the username doesn t exist and contain invalid chars."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_password2(self):\n        password1 = self.cleaned_data.get(\"password1\")\n        password2 = self.cleaned_data.get(\"password2\")\n\n        if password1:\n            errors = []\n            if password1 != password2:\n                errors.append(ugettext(\"Passwords do not match\"))\n            if len(password1) < settings.ACCOUNTS_MIN_PASSWORD_LENGTH:\n                errors.append(\n                        ugettext(\"Password must be at least %s characters\") %\n                        settings.ACCOUNTS_MIN_PASSWORD_LENGTH)\n            if errors:\n                self._errors[\"password1\"] = self.error_class(errors)\n        return password2", "response": "Ensure the password fields are equal, and match the minimum\n        length defined by ``ACCOUNTS_MIN_PASSWORD_LENGTH``."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean_email(self):\n        email = self.cleaned_data.get(\"email\")\n        qs = User.objects.exclude(id=self.instance.id).filter(email=email)\n        if len(qs) == 0:\n            return email\n        raise forms.ValidationError(\n                                ugettext(\"This email is already registered\"))", "response": "Ensure the email address is not already registered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the user and return a new User instance.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Create the new user. If no username is supplied (may be hidden\n        via ``ACCOUNTS_PROFILE_FORM_EXCLUDE_FIELDS`` or\n        ``ACCOUNTS_NO_USERNAME``), we generate a unique username, so\n        that if profile pages are enabled, we still have something to\n        use as the profile's slug.\n        \"\"\"\n\n        kwargs[\"commit\"] = False\n        user = super(ProfileForm, self).save(*args, **kwargs)\n        try:\n            self.cleaned_data[\"username\"]\n        except KeyError:\n            if not self.instance.username:\n                try:\n                    username = (\"%(first_name)s %(last_name)s\" %\n                                self.cleaned_data).strip()\n                except KeyError:\n                    username = \"\"\n                if not username:\n                    username = self.cleaned_data[\"email\"].split(\"@\")[0]\n                qs = User.objects.exclude(id=self.instance.id)\n                user.username = unique_slug(qs, \"username\", slugify(username))\n        password = self.cleaned_data.get(\"password1\")\n        if password:\n            user.set_password(password)\n        elif self._signup:\n            try:\n                user.set_unusable_password()\n            except AttributeError:\n                # This could happen if using a custom user model that\n                # doesn't inherit from Django's AbstractBaseUser.\n                pass\n        user.save()\n\n        try:\n            profile = get_profile_for_user(user)\n            profile_form = self.get_profile_fields_form()\n            profile_form(self.data, self.files, instance=profile).save()\n        except ProfileNotConfigured:\n            pass\n\n        if self._signup:\n            if (settings.ACCOUNTS_VERIFICATION_REQUIRED or\n                    settings.ACCOUNTS_APPROVAL_REQUIRED):\n                user.is_active = False\n                user.save()\n            else:\n                token = default_token_generator.make_token(user)\n                user = authenticate(uidb36=int_to_base36(user.id),\n                                    token=token,\n                                    is_active=True)\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding a list of articles from the given issue.", "response": "def get_articles(self, issue=''):\n        \"\"\"\n\t\t\tYields a list of articles from the given issue.\n        \"\"\"\t\n\t\t\n\t\t\n\tsoup = get_soup() # get soup of all articles \n\tissues = soup.find_all('ul')\n\t\t\n\t# validating and assigning default value for issue\n\tif not type(issue) is int or issue < 0 :\n\t\tissue = 1\n\tif issue > len(issues):\n\t\tissue = len(issues)\t\t\n\t\t\n\t# considering latest article is last element \t\t\n\tarticles = issues[len(issues)-issue].find_all('a') \n\tmArticles = []\n\tfor article in articles:\n\t\tmArticle = {}\n\t\tmArticle['link'] = article.get('href')[1:]\n\t\tmArticle['title'] = article.find('li').contents[0].strip()\n\t\tmArticle['author'] = article.find('span').contents[0].encode('utf8')\n\t\tmArticles.append(mArticle)\n\treturn mArticles"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fromLink(self, link):\n\t\tsoup = get_article_soup(link)\n\t\thead = soup.find_all('article',class_='')[0]\n\t\tparts = link.split('/')\n\t\tid = '%s-%s'%(parts[0],parts[-1])\n\t\tissue = parts[0].split('-')[-1]\n\t\t\n\t\t#fetching head\n\t\ttitle = head.find(\"h1\").contents[0] if head.find(\"h1\") else ''\n\t\ttagline = head.find(\"h2\").contents[0] if head.find(\"h2\") else ''\n\t\t\n\t\tbody = '' #fetching body\n\t\tif len(soup.find_all('article',class_='main-body')) > 0:\n\t\t\tbody = soup.find_all('article',class_='main-body')[0].find(class_='inner')\n\t\t\t\n\t\tauthor =  '' #fetching author\n\t\tif len(soup.find_all('aside')) > 0:\n\t\t\t\taside = soup.find_all('aside')[0] if soup.find_all('aside')[0] else ''\n\t\t\t\tauthor = Author.from_soup(aside)\n\t\treturn Article(id=id,title=title,tagline=tagline,body=body,issue=issue,link='http://thezine.biz/%s'%link,author=author)", "response": "Method. Fetches article data from given link and builds the object\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_soup(self,author,soup):\n\t\temail = soup.find('span',class_='icon icon-mail').findParent('a').get('href').split(':')[-1]  if soup.find('span',class_='icon icon-mail') else ''\n\t\tfacebook = soup.find('span',class_='icon icon-facebook').findParent('a').get('href') if soup.find('span',class_='icon icon-facebook') else ''\n\t\ttwitter = soup.find('span',class_='icon icon-twitter-3').findParent('a').get('href') if soup.find('span',class_='icon icon-twitter-3') else ''\n\t\tlink = soup.find('span',class_='icon icon-link').findParent('a').get('href') if soup.find('span',class_='icon icon-link') else ''\n\t\treturn Contact(email,facebook,twitter,link)", "response": "This method fetches contact data from given soup and builds the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays all locally cached versions available for installation.", "response": "def cli(ctx, resource):\n    \"\"\"\n    Displays all locally cached <resource> versions available for installation.\n\n    \\b\n    Available resources:\n        ips (default)\n        dev_tools\n    \"\"\"\n    log = logging.getLogger('ipsv.setup')\n    assert isinstance(ctx, Context)\n\n    resource = str(resource).lower()\n\n    if resource == 'ips':\n        resource = IpsManager(ctx)\n        for r in resource.versions.values():\n            click.secho(r.version.vstring, bold=True)\n        return\n\n    if resource in ('dev_tools', 'dev tools'):\n        resource = DevToolsManager(ctx)\n        for r in resource.versions.values():\n            click.secho('{v} ({id})'.format(v=r.version.vstring, id=r.version.vid), bold=True)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind all genres in text.", "response": "def find(self, text):\n        \"\"\"\n        Return a list of genres found in text.\n        \"\"\"\n\n        genres = []\n        text = text.lower()\n\n        category_counter = Counter()\n        counter = Counter()\n\n        for genre in self.db.genres:\n            found = self.contains_entity(genre, text)\n            if found:\n                counter[genre] += found\n\n                category = self.db.reference[genre]\n                points = self.db.points[genre]\n                points *= found\n\n                # Add bonus points if additional terms points to category\n                if category_counter[category] > 0:\n                    points += 1\n\n                category_counter[category] += points\n\n        for tag in self.db.tags:\n            found = self.contains_entity(tag, text)\n            if found:\n                category = self.db.reference[tag]\n\n                if not counter[category]:\n                    counter[category] += found\n\n                points = self.db.points[tag]\n                points *= found\n                category_counter[category] += points\n\n        if not category_counter:\n            return genres\n\n        main_category = category_counter.most_common(1)[0][0]\n\n        # Convert counter to a flat list of genres, sorted by count\n        sorted_genres = [ite for ite, it in counter.most_common()]\n\n        for genre in sorted_genres:\n            insert = True\n\n            if self.unique_category:\n                if not self.db.reference[genre] == main_category:\n                    insert = False\n\n            if insert:\n                genres.append(genre)\n\n        return genres"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef contains_entity(entity, text):\n\n        try:\n            entity = re.escape(entity)\n            entity = entity.replace(\"\\ \", \"([^\\w])?\")\n            pattern = \"(\\ |-|\\\\\\|/|\\.|,|^)%s(\\ |\\-|\\\\\\|/|\\.|,|$)\" % entity\n            found = len(re.findall(pattern, text, re.I | re.M))\n        except Exception as e:\n            found = False\n\n        return found", "response": "Return True if the text contains the entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jsonify(result, format=False):\n    ''' format JSON output (uncompressed or uncompressed) '''\n\n    result2 = result.copy()\n    if format:\n        return json.dumps(result2, sort_keys=True, indent=4)\n    else:\n        return json.dumps(result2, sort_keys=True)", "response": "format JSON output (uncompressed or uncompressed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_tree_file(tree, hostname, buf):\n    ''' write something into treedir/hostname '''\n\n    # TODO: might be nice to append playbook runs per host in a similar way\n    # in which case, we'd want append mode.\n    path = os.path.join(tree, hostname)\n    fd = open(path, \"w+\")\n    fd.write(buf)\n    fd.close()", "response": "write something into treedir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_executable(path):\n    '''is the given path executable?'''\n    return (stat.S_IXUSR & os.stat(path)[stat.ST_MODE]\n            or stat.S_IXGRP & os.stat(path)[stat.ST_MODE]\n            or stat.S_IXOTH & os.stat(path)[stat.ST_MODE])", "response": "is the given path executable?"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_writeable_dir(tree):\n    ''' make sure a directory exists and is writeable '''\n\n    if tree != '/':\n        tree = os.path.realpath(os.path.expanduser(tree))\n    if not os.path.exists(tree):\n        try:\n            os.makedirs(tree)\n        except (IOError, OSError), e:\n            exit(\"Could not make dir %s: %s\" % (tree, e))\n    if not os.access(tree, os.W_OK):\n        exit(\"Cannot write to path %s\" % tree)", "response": "make sure a directory exists and is writeable"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path_dwim(basedir, given):\n    '''\n    make relative paths work like folks expect.\n    '''\n\n    if given.startswith(\"/\"):\n        return given\n    elif given.startswith(\"~/\"):\n        return os.path.expanduser(given)\n    else:\n        return os.path.join(basedir, given)", "response": "make relative paths work like folks expect.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_json(raw_data):\n    ''' this version for module return data only '''\n\n    orig_data = raw_data\n\n    # ignore stuff like tcgetattr spewage or other warnings\n    data = filter_leading_non_json_lines(raw_data)\n\n    try:\n        return json.loads(data)\n    except:\n        # not JSON, but try \"Baby JSON\" which allows many of our modules to not\n        # require JSON and makes writing modules in bash much simpler\n        results = {}\n        try:\n            tokens = shlex.split(data)\n        except:\n            print \"failed to parse json: \"+ data\n            raise\n\n        for t in tokens:\n            if t.find(\"=\") == -1:\n                raise errors.AnsibleError(\"failed to parse: %s\" % orig_data)\n            (key,value) = t.split(\"=\", 1)\n            if key == 'changed' or 'failed':\n                if value.lower() in [ 'true', '1' ]:\n                    value = True\n                elif value.lower() in [ 'false', '0' ]:\n                    value = False\n            if key == 'rc':\n                value = int(value)\n            results[key] = value\n        if len(results.keys()) == 0:\n            return { \"failed\" : True, \"parsed\" : False, \"msg\" : orig_data }\n        return results", "response": "this version for module return data only"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a yaml file to a data structure", "response": "def parse_yaml_from_file(path):\n    ''' convert a yaml file to a data structure '''\n\n    try:\n        data = file(path).read()\n        return parse_yaml(data)\n    except IOError:\n        raise errors.AnsibleError(\"file not found: %s\" % path)\n    except yaml.YAMLError, exc:\n        if hasattr(exc, 'problem_mark'):\n            mark = exc.problem_mark\n            if mark.line -1 >= 0:\n                before_probline = data.split(\"\\n\")[mark.line-1]\n            else:\n                before_probline = ''\n            probline = data.split(\"\\n\")[mark.line]\n            arrow = \" \" * mark.column + \"^\"\n            msg = \"\"\"Syntax Error while loading YAML script, %s\nNote: The error may actually appear before this position: line %s, column %s\n\n%s\n%s\n%s\"\"\" % (path, mark.line + 1, mark.column + 1, before_probline, probline, arrow)\n        else:\n            # No problem markers means we have to throw a generic\n            # \"stuff messed up\" type message. Sry bud.\n            msg = \"Could not parse YAML. Check over %s again.\" % path\n        raise errors.AnsibleYAMLValidationFailed(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_kv(args):\n    ''' convert a string of key/value items to a dict '''\n\n    options = {}\n    if args is not None:\n        # attempting to split a unicode here does bad things\n        vargs = shlex.split(str(args), posix=True)\n        for x in vargs:\n            if x.find(\"=\") != -1:\n                k, v = x.split(\"=\",1)\n                options[k]=v\n    return options", "response": "convert a string of key = value items to a dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges hash b into a", "response": "def merge_hash(a, b):\n    ''' merges hash b into a\n    this means that if b has key k, the resulting has will have a key k\n    which value comes from b\n    said differently, all key/value combination from b will override a's '''\n\n    # and iterate over b keys\n    for k, v in b.iteritems():\n        if k in a and isinstance(a[k], dict):\n            # if this key is a hash and exists in a\n            # we recursively call ourselves with \n            # the key value of b\n            a[k] = merge_hash(a[k], v)\n        else:\n            # k is not in a, no need to merge b, we just deecopy\n            # or k is not a dictionnary, no need to merge b either, we just deecopy it\n            a[k] = v\n    # finally, return the resulting hash when we're done iterating keys\n    return a"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn MD5 hex digest of local file.", "response": "def md5(filename):\n    ''' Return MD5 hex digest of local file, or None if file is not present. '''\n\n    if not os.path.exists(filename):\n        return None\n    digest = _md5()\n    blocksize = 64 * 1024\n    infile = open(filename, 'rb')\n    block = infile.read(blocksize)\n    while block:\n        digest.update(block)\n        block = infile.read(blocksize)\n    infile.close()\n    return digest.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _gitinfo():\n    ''' returns a string containing git branch, commit id and commit date '''\n    result = None\n    repo_path = os.path.join(os.path.dirname(__file__), '..', '..', '..', '.git')\n\n    if os.path.exists(repo_path):\n        # Check if the .git is a file. If it is a file, it means that we are in a submodule structure.\n        if os.path.isfile(repo_path):\n            try:\n                gitdir = yaml.load(open(repo_path)).get('gitdir')\n                # There is a posibility the .git file to have an absolute path.\n                if os.path.isabs(gitdir):\n                    repo_path = gitdir\n                else:\n                    repo_path = os.path.join(repo_path.split('.git')[0], gitdir)\n            except (IOError, AttributeError):\n                return ''\n        f = open(os.path.join(repo_path, \"HEAD\"))\n        branch = f.readline().split('/')[-1].rstrip(\"\\n\")\n        f.close()\n        branch_path = os.path.join(repo_path, \"refs\", \"heads\", branch)\n        if os.path.exists(branch_path):\n            f = open(branch_path)\n            commit = f.readline()[:10]\n            f.close()\n            date = time.localtime(os.stat(branch_path).st_mtime)\n            if time.daylight == 0:\n                offset = time.timezone\n            else:\n                offset = time.altzone\n            result = \"({0} {1}) last updated {2} (GMT {3:+04d})\".format(branch, commit,\n                time.strftime(\"%Y/%m/%d %H:%M:%S\", date), offset / -36)\n    else:\n        result = ''\n    return result", "response": "returns a string containing git branch commit id and commit date"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an options parser for any ansible script", "response": "def base_parser(constants=C, usage=\"\", output_opts=False, runas_opts=False,\n    async_opts=False, connect_opts=False, subset_opts=False):\n    ''' create an options parser for any ansible script '''\n\n    parser = SortedOptParser(usage, version=version(\"%prog\"))\n    parser.add_option('-v','--verbose', default=False, action=\"callback\",\n        callback=increment_debug, help=\"verbose mode (-vvv for more)\")\n\n    parser.add_option('-f','--forks', dest='forks', default=constants.DEFAULT_FORKS, type='int',\n        help=\"specify number of parallel processes to use (default=%s)\" % constants.DEFAULT_FORKS)\n    parser.add_option('-i', '--inventory-file', dest='inventory',\n        help=\"specify inventory host file (default=%s)\" % constants.DEFAULT_HOST_LIST,\n        default=constants.DEFAULT_HOST_LIST)\n    parser.add_option('-k', '--ask-pass', default=False, dest='ask_pass', action='store_true',\n        help='ask for SSH password')\n    parser.add_option('--private-key', default=C.DEFAULT_PRIVATE_KEY_FILE, dest='private_key_file',\n        help='use this file to authenticate the connection')\n    parser.add_option('-K', '--ask-sudo-pass', default=False, dest='ask_sudo_pass', action='store_true',\n        help='ask for sudo password')\n    parser.add_option('-M', '--module-path', dest='module_path',\n        help=\"specify path(s) to module library (default=%s)\" % constants.DEFAULT_MODULE_PATH,\n        default=None)\n\n    if subset_opts:\n        parser.add_option('-l', '--limit', default=constants.DEFAULT_SUBSET, dest='subset',\n            help='further limit selected hosts to an additional pattern')\n\n    parser.add_option('-T', '--timeout', default=constants.DEFAULT_TIMEOUT, type='int',\n        dest='timeout',\n        help=\"override the SSH timeout in seconds (default=%s)\" % constants.DEFAULT_TIMEOUT)\n\n    if output_opts:\n        parser.add_option('-o', '--one-line', dest='one_line', action='store_true',\n            help='condense output')\n        parser.add_option('-t', '--tree', dest='tree', default=None,\n            help='log output to this directory')\n\n    if runas_opts:\n        parser.add_option(\"-s\", \"--sudo\", default=False, action=\"store_true\",\n            dest='sudo', help=\"run operations with sudo (nopasswd)\")\n        parser.add_option('-U', '--sudo-user', dest='sudo_user', help='desired sudo user (default=root)',\n            default=None)   # Can't default to root because we need to detect when this option was given\n        parser.add_option('-u', '--user', default=constants.DEFAULT_REMOTE_USER,\n            dest='remote_user',\n            help='connect as this user (default=%s)' % constants.DEFAULT_REMOTE_USER)\n\n    if connect_opts:\n        parser.add_option('-c', '--connection', dest='connection',\n                          default=C.DEFAULT_TRANSPORT,\n                          help=\"connection type to use (default=%s)\" % C.DEFAULT_TRANSPORT)\n\n    if async_opts:\n        parser.add_option('-P', '--poll', default=constants.DEFAULT_POLL_INTERVAL, type='int',\n            dest='poll_interval',\n            help=\"set the poll interval if using -B (default=%s)\" % constants.DEFAULT_POLL_INTERVAL)\n        parser.add_option('-B', '--background', dest='seconds', type='int', default=0,\n            help='run asynchronously, failing after X seconds (default=N/A)')\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_leading_non_json_lines(buf):\n    '''\n    used to avoid random output from SSH at the top of JSON output, like messages from\n    tcagetattr, or where dropbear spews MOTD on every single command (which is nuts).\n\n    need to filter anything which starts not with '{', '[', ', '=' or is an empty line.\n    filter only leading lines since multiline JSON is valid.\n    '''\n\n    filtered_lines = StringIO.StringIO()\n    stop_filtering = False\n    for line in buf.splitlines():\n        if stop_filtering or \"=\" in line or line.startswith('{') or line.startswith('['):\n            stop_filtering = True\n            filtered_lines.write(line + '\\n')\n    return filtered_lines.getvalue()", "response": "This function filters out leading non - JSON lines from a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compile_when_to_only_if(expression):\n    '''\n    when is a shorthand for writing only_if conditionals.  It requires less quoting\n    magic.  only_if is retained for backwards compatibility.\n    '''\n\n    # when: set $variable\n    # when: unset $variable\n    # when: failed $json_result\n    # when: changed $json_result\n    # when: int $x >= $z and $y < 3\n    # when: int $x in $alist\n    # when: float $x > 2 and $y <= $z\n    # when: str $x != $y\n\n    if type(expression) not in [ str, unicode ]:\n        raise errors.AnsibleError(\"invalid usage of when_ operator: %s\" % expression)\n    tokens = expression.split()\n    if len(tokens) < 2:\n        raise errors.AnsibleError(\"invalid usage of when_ operator: %s\" % expression)\n\n    # when_set / when_unset\n    if tokens[0] in [ 'set', 'unset' ]:\n        tcopy = tokens[1:]\n        for (i,t) in enumerate(tokens[1:]):\n            if t.find(\"$\") != -1:\n                tcopy[i] = \"is_%s('''%s''')\" % (tokens[0], t)\n            else:\n                tcopy[i] = t\n        return \" \".join(tcopy)\n\n\n\n    # when_failed / when_changed\n    elif tokens[0] in [ 'failed', 'changed' ]:\n        tcopy = tokens[1:]\n        for (i,t) in enumerate(tokens[1:]):\n            if t.find(\"$\") != -1:\n                tcopy[i] = \"is_%s(%s)\" % (tokens[0], t)\n            else:\n                tcopy[i] = t\n        return \" \".join(tcopy)\n\n\n\n    # when_integer / when_float / when_string\n    elif tokens[0] in [ 'integer', 'float', 'string' ]:\n        cast = None\n        if tokens[0] == 'integer':\n            cast = 'int'\n        elif tokens[0] == 'string':\n            cast = 'str'\n        elif tokens[0] == 'float':\n            cast = 'float'\n        tcopy = tokens[1:]\n        for (i,t) in enumerate(tokens[1:]):\n            if t.find(\"$\") != -1:\n                # final variable substitution will happen in Runner code\n                tcopy[i] = \"%s('''%s''')\" % (cast, t)\n            else:\n                tcopy[i] = t\n        return \" \".join(tcopy)\n\n    # when_boolean\n    elif tokens[0] in [ 'bool', 'boolean' ]:\n        tcopy = tokens[1:]\n        for (i, t) in enumerate(tcopy):\n            if t.find(\"$\") != -1:\n                tcopy[i] = \"(is_set('''%s''') and '''%s'''.lower() not in ('false', 'no', 'n', 'none', '0', ''))\" % (t, t)\n        return \" \".join(tcopy)\n\n    else:\n        raise errors.AnsibleError(\"invalid usage of when_ operator: %s\" % expression)", "response": "Compiles a conditional expression to a only_if statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_sudo_cmd(sudo_user, executable, cmd):\n    # Rather than detect if sudo wants a password this time, -k makes\n    # sudo always ask for a password if one is required.\n    # Passing a quoted compound command to sudo (or sudo -s)\n    # directly doesn't work, so we shellquote it with pipes.quote()\n    # and pass the quoted string to the user's shell.  We loop reading\n    # output until we see the randomly-generated sudo prompt set with\n    # the -p option.\n    randbits = ''.join(chr(random.randint(ord('a'), ord('z'))) for x in xrange(32))\n    prompt = '[sudo via ansible, key=%s] password: ' % randbits\n    sudocmd = '%s -k && %s %s -S -p \"%s\" -u %s %s -c %s' % (\n        C.DEFAULT_SUDO_EXE, C.DEFAULT_SUDO_EXE, C.DEFAULT_SUDO_FLAGS,\n        prompt, sudo_user, executable or '$SHELL', pipes.quote(cmd))\n    return ('/bin/sh -c ' + pipes.quote(sudocmd), prompt)", "response": "helper function for creating sudo commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables cookie synchronization with specified browser returns result", "response": "def sync(self, browser):\n        \"\"\" Enables cookie synchronization with specified browser, returns result\n           \n        Returns\n           bool - True if successful, false otherwise\n        \"\"\"\n        BrowserCookies.loadBrowsers()\n        if not browser in BrowserCookies.browsers:\n                return False\n        \n        self.browserSync = True\n        self.browser = browser\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self):\n        # Code to load all attributes\n        for prop in dir(self):\n            if getattr(self, prop) == None: continue\n            if not prop in self.configVars: continue\n            \n            # Special handling for some attributes\n            if prop == \"session\":\n                pic = pickle.dumps(getattr(self, prop).cookies)\n                comp = zlib.compress(pic)\n                enc = base64.b64encode(comp)\n                self.config[prop] = enc.decode()\n                continue\n                    \n            if prop == \"password\" and not self.savePassword: continue\n            if prop == \"password\":\n                s = hashlib.md5(self.username.encode()).hexdigest()\n                p = base64.b64encode(getattr(self, prop).encode()) + s.encode()\n                self.config[prop] = p.decode()\n                continue\n                \n            self.config[prop] = str(getattr(self, prop))\n                \n        if 'password' in self.config and not self.savePassword: del self.config.password\n        self.config.write()\n        self.__loadConfig()", "response": "Saves all user attributes to the user s configuration and writes configuration\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrequests and returns a page using the user s session and POST data.", "response": "def getPage(self, url, postData = None, vars = None, usePin = False):\n        \"\"\" Requests and returns a page using the user's session\n        \n        If useRef is set to true, automatically appends a referer using\n        the user's last page to the request. If usePin is set to true,\n        automatically appends the user's pin to the POST data. If browser\n        sync is enabled, automatically retrieves and uses the browser's\n        most up to date cookies for the request and attempts to save the\n        updated cookies to the browser's cookie database. If useHooks is\n        set to true, delivers the resulting Page object to each hook\n        function for processing. Finally, returns the requested page.\n        \n        Parameters\n           url (str) -- URL of remote page\n           postData (dict) -- POST data to send with request\n           vars (dict) -- Additional HTTP Header variables to send with request\n           usePin (bool) -- Whether or not to send the user's pin with the request\n           \n        Returns\n           Page -- Requested page\n           \n        Raises\n           neopetsOfflineException\n        \"\"\"\n        # If using a referer is desired and one has not already been supplied, \n        # then set the referer to the user's last visited page.\n        if self.useRef and len(self.lastPage) > 0:\n            if not vars: vars = {'Referer': self.lastPage}\n            elif not \"Referer\" in vars: vars['Referer'] = self.lastPage\n            \n        self.lastPage = url\n        \n        if usePin:\n            if self.pin:\n                # All forms that require a pin share the same variable name of 'pin'\n                postData['pin'] = str(self.pin)\n        \n        if bool(self.browserSync):\n            self.__syncCookies()\n        \n        pg = Page(url, usr=self, postData=postData, vars=vars, proxy=self.proxy)\n        \n        if self.browserSync:\n            self.__writeCookies()\n        \n        if \"http://images.neopets.com/homepage/indexbak_oops_en.png\" in pg.content:\n            raise neopetsOfflineException\n        \n        if self.useHooks:\n            for hook in self.hooks:\n                self, pg = hook(self, pg)\n        return pg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if an item is in the gitignore file and adds it if it is not in the gitignore file and removes it if it is not in the gitignore file", "response": "def mod_git_ignore(directory, ignore_item, action):\n    \"\"\" checks if an item is in the specified gitignore file and adds it if it\n    is not in the file\n    \"\"\"\n    if not os.path.isdir(directory):\n        return\n    ignore_filepath = os.path.join(directory,\".gitignore\")\n    if not os.path.exists(ignore_filepath):\n        items = []\n    else:\n        with open(ignore_filepath) as ig_file:\n            items = ig_file.readlines()\n    # strip and clean the lines\n    clean_items  = [line.strip(\"\\n\").strip() for line in items]\n    clean_items = make_list(clean_items)\n    if action == \"add\":\n        if ignore_item not in clean_items:\n            with open(ignore_filepath, \"w\") as ig_file:\n                clean_items.append(ignore_item)\n                ig_file.write(\"\\n\".join(clean_items) + \"\\n\")\n    elif action == \"remove\":\n        with open(ignore_filepath, \"w\") as ig_file:\n            for i, value in enumerate(clean_items):\n                if value != ignore_item.lower():\n                    ig_file.write(items[i])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef monitor_running_process(context: RunContext):\n    while True:\n        capture_output_from_running_process(context)\n\n        if context.process_finished():\n            context.return_code = context.command.returncode\n            break\n\n        if context.process_timed_out():\n            context.return_code = -1\n            raise ProcessTimeoutError(\n                exe_name=context.exe_short_name,\n                timeout=context.timeout,\n            )", "response": "Runs an infinite loop that waits for the running process to exit on its or time out."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting base elements of the input elt.", "response": "def base_elts(elt, cls=None, depth=None):\n    \"\"\"Get bases elements of the input elt.\n\n    - If elt is an instance, get class and all base classes.\n    - If elt is a method, get all base methods.\n    - If elt is a class, get all base classes.\n    - In other case, get an empty list.\n\n    :param elt: supposed inherited elt.\n    :param cls: cls from where find attributes equal to elt. If None,\n        it is found as much as possible. Required in python3 for function\n        classes.\n    :type cls: type or list\n    :param int depth: search depth. If None (default), depth is maximal.\n    :return: elt bases elements. if elt has not base elements, result is empty.\n    :rtype: list\n    \"\"\"\n\n    result = []\n\n    elt_name = getattr(elt, '__name__', None)\n\n    if elt_name is not None:\n\n        cls = [] if cls is None else ensureiterable(cls)\n\n        elt_is_class = False\n\n        # if cls is None and elt is routine, it is possible to find the cls\n        if not cls and isroutine(elt):\n\n            if hasattr(elt, '__self__'):  # from the instance\n\n                instance = get_method_self(elt)  # get instance\n\n                if instance is None and PY2:  # get base im_class if PY2\n                    cls = list(elt.im_class.__bases__)\n\n                else:  # use instance class\n                    cls = [instance.__class__]\n\n        # cls is elt if elt is a class\n        elif isclass(elt):\n            elt_is_class = True\n            cls = list(elt.__bases__)\n\n        if cls:  # if cls is not empty, find all base classes\n\n            index_of_found_classes = 0  # get last visited class index\n            visited_classes = set(cls)  # cache for visited classes\n            len_classes = len(cls)\n\n            if depth is None:  # if depth is None, get maximal value\n                depth = -1  # set negative value\n\n            while depth != 0 and index_of_found_classes != len_classes:\n                len_classes = len(cls)\n\n                for index in range(index_of_found_classes, len_classes):\n                    _cls = cls[index]\n\n                    for base_cls in _cls.__bases__:\n                        if base_cls in visited_classes:\n                            continue\n\n                        else:\n                            visited_classes.add(base_cls)\n                            cls.append(base_cls)\n                index_of_found_classes = len_classes\n                depth -= 1\n\n            if elt_is_class:\n                # if cls is elt, result is classes minus first class\n                result = cls\n\n            elif isroutine(elt):\n\n                # get an elt to compare with found element\n                if ismethod(elt):\n                    elt_to_compare = get_method_function(elt)\n                else:\n                    elt_to_compare = elt\n\n                for _cls in cls:  # for all classes\n                    # get possible base elt\n                    b_elt = getattr(_cls, elt_name, None)\n\n                    if b_elt is not None:\n                        # compare funcs\n                        if ismethod(b_elt):\n                            bec = get_method_function(b_elt)\n                        else:\n                            bec = b_elt\n                        # if matching, add to result\n                        if bec is elt_to_compare:\n                            result.append(b_elt)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to get elt embedding elements.", "response": "def find_embedding(elt, embedding=None):\n    \"\"\"Try to get elt embedding elements.\n\n    :param embedding: embedding element. Must have a module.\n\n    :return: a list of [module [,class]*] embedding elements which define elt.\n    :rtype: list\n    \"\"\"\n\n    result = []  # result is empty in the worst case\n\n    # start to get module\n    module = getmodule(elt)\n\n    if module is not None:  # if module exists\n\n        visited = set()  # cache to avoid to visit twice same element\n\n        if embedding is None:\n            embedding = module\n\n        # list of compounds elements which construct the path to elt\n        compounds = [embedding]\n\n        while compounds:  # while compounds elements exist\n            # get last compound\n            last_embedding = compounds[-1]\n            # stop to iterate on compounds when last embedding is elt\n            if last_embedding == elt:\n                result = compounds  # result is compounds\n                break\n\n            else:\n                # search among embedded elements\n                for name in dir(last_embedding):\n                    # get embedded element\n                    embedded = getattr(last_embedding, name)\n\n                    try:  # check if embedded has already been visited\n                        if embedded not in visited:\n                            visited.add(embedded)  # set it as visited\n\n                        else:\n                            continue\n\n                    except TypeError:\n                        pass\n\n                    else:\n\n                        # get embedded module\n                        embedded_module = getmodule(embedded)\n                        # and compare it with elt module\n                        if embedded_module is module:\n                            # add embedded to compounds\n                            compounds.append(embedded)\n                            # end the second loop\n                            break\n\n                else:\n                    # remove last element if no coumpound element is found\n                    compounds.pop(-1)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmap a single character to Latin.", "response": "def map_rus_to_lat(char):\n    \"\"\" \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u0442 \u0440\u0443\u0441\u0441\u043a\u0438\u0435 \u0441\u0438\u043c\u0432\u043e\u043b\u044b \u0432 \u0442\u0430\u043a\u0438\u0435 \u0436\u0435 (\u043f\u043e \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u0438\u044e) \u043b\u0430\u0442\u0438\u043d\u0441\u043a\u0438\u0435 \"\"\"\n    map_dict = {\n        u'\u0415': u'E',\n        u'\u0422': u'T',\n        u'\u0423': u'Y',\n        u'\u041e': u'O',\n        u'\u0420': u'P',\n        u'\u0410': u'A',\n        u'\u041d': u'H',\n        u'\u041a': u'K',\n        u'\u0425': u'X',\n        u'\u0421': u'C',\n        u'\u0412': u'B',\n        u'\u041c': u'M',\n    }\n    # \u0435\u0441\u043b\u0438 \u0431\u0443\u043a\u0432\u0430 \u0435\u0441\u0442\u044c \u0432 \u0441\u043f\u0438\u0441\u043a\u0435 \u0440\u0443\u0441\u0441\u043a\u0438\u0445 \u0441\u0438\u0432\u043e\u043b\u043e\u0432, \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0435\u0435 \u0432 \u043b\u0430\u0442\u0438\u043d\u0441\u043a\u0438\u0439 \u0434\u0432\u043e\u0439\u043d\u0438\u043a\n    if char in map_dict:\n        return map_dict[char]\n    else:\n        return char"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the current user in the order they are connected.", "response": "def configure(username, password, domain):\n    \"\"\"\n    Initial configuration. Used to specify your username, password and domain.\n    Configuration is stored in ~/.accountable/config.yaml.\n    \"\"\"\n    art = r'''\nWelcome!                                __        ___.   .__\n_____    ____  ____  ____  __ __  _____/  |______ \\_ |__ |  |   ____\n\\__  \\ _/ ___\\/ ___\\/  _ \\|  |  \\/    \\   __\\__  \\ | __ \\|  | _/ __ \\\n / __ \\\\  \\__\\  \\__(  <_> )  |  /   |  \\  |  / __ \\| \\_\\ \\  |_\\  ___/\n(____  /\\___  >___  >____/|____/|___|  /__| (____  /___  /____/\\___  >\n     \\/     \\/    \\/                 \\/          \\/    \\/          \\/\n     '''\n    click.secho(art, fg='blue')\n    Config(username=username, password=password, domain=domain)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef projects(accountable):\n    projects = accountable.metadata()['projects']\n    headers = sorted(['id', 'key', 'self'])\n    rows = [[v for k, v in sorted(p.items()) if k in headers] for p in projects]\n    rows.insert(0, headers)\n    print_table(SingleTable(rows))", "response": "List all projects in the accountable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting all issue types in a given project.", "response": "def issuetypes(accountable, project_key):\n    \"\"\"\n    List all issue types. Optional parameter to list issue types by a given\n    project.\n    \"\"\"\n    projects = accountable.issue_types(project_key)\n    headers = sorted(['id', 'name', 'description'])\n    rows = []\n    for key, issue_types in sorted(projects.items()):\n        for issue_type in issue_types:\n            rows.append(\n                [key] + [v for k, v in sorted(issue_type.items())\n                         if k in headers]\n            )\n    rows.insert(0, ['project_key'] + headers)\n    print_table(SingleTable(rows))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all a project s components.", "response": "def components(accountable, project_key):\n    \"\"\"\n    Returns a list of all a project's components.\n    \"\"\"\n    components = accountable.project_components(project_key)\n    headers = sorted(['id', 'name', 'self'])\n    rows = [[v for k, v in sorted(component.items()) if k in headers]\n            for component in components]\n    rows.insert(0, headers)\n    print_table(SingleTable(rows))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createissue(accountable, options):\n    issue = accountable.issue_create(options)\n    headers = sorted(['id', 'key', 'self'])\n    rows = [headers, [itemgetter(header)(issue) for header in headers]]\n    print_table(SingleTable(rows))", "response": "Create new issue.\n    Prints a table of issue details."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef checkoutbranch(accountable, options):\n    issue = accountable.checkout_branch(options)\n    headers = sorted(['id', 'key', 'self'])\n    rows = [headers, [itemgetter(header)(issue) for header in headers]]\n    print_table(SingleTable(rows))", "response": "Checkout a branch of the current issue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist metadata for a given issue key.", "response": "def issue(ctx, accountable, issue_key):\n    \"\"\"\n    List metadata for a given issue key.\n    \"\"\"\n    accountable.issue_key = issue_key\n    if not ctx.invoked_subcommand:\n        issue = accountable.issue_meta()\n        headers = issue.keys()\n        rows = [headers, [v for k, v in issue.items()]]\n        print_table(SingleTable(rows))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating an existing issue.", "response": "def update(accountable, options):\n    \"\"\"\n    Update an existing issue.\n    \"\"\"\n    issue = accountable.issue_update(options)\n    headers = issue.keys()\n    rows = [headers, [v for k, v in issue.items()]]\n    print_table(SingleTable(rows))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef comments(accountable):\n    comments = accountable.issue_comments()\n    headers = sorted(['author_name', 'body', 'updated'])\n\n    if comments:\n        rows = [[v for k, v in sorted(c.items()) if k in headers]\n                for c in comments]\n        rows.insert(0, headers)\n        print_table(SingleTable(rows))\n    else:\n        click.secho('No comments found for {}'.format(\n            accountable.issue_key\n        ), fg='red')", "response": "Lists all comments for a given issue key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addcomment(accountable, body):\n\n    r = accountable.issue_add_comment(body)\n    headers = sorted(['author_name', 'body', 'updated'])\n    rows = [[v for k, v in sorted(r.items()) if k in headers]]\n    rows.insert(0, headers)\n    print_table(SingleTable(rows))", "response": "Adds a comment to the issue key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all worklogs for a given issue key.", "response": "def worklog(accountable):\n    \"\"\"\n    List all worklogs for a given issue key.\n    \"\"\"\n    worklog = accountable.issue_worklog()\n    headers = ['author_name', 'comment', 'time_spent']\n    if worklog:\n        rows = [[v for k, v in sorted(w.items()) if k in headers]\n                for w in worklog]\n        rows.insert(0, headers)\n        print_table(SingleTable(rows))\n    else:\n        click.secho(\n            'No worklogs found for {}'.format(accountable.issue_key),\n            fg='red'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transitions(accountable):\n    transitions = accountable.issue_transitions().get('transitions')\n    headers = ['id', 'name']\n    if transitions:\n        rows = [[v for k, v in sorted(t.items()) if k in headers]\n                for t in transitions]\n        rows.insert(0, headers)\n        print_table(SingleTable(rows))\n    else:\n        click.secho(\n            'No transitions found for {}'.format(accountable.issue_key),\n            fg='red'\n        )", "response": "List all possible transitions for a given issue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dotransition(accountable, transition_id):\n    t = accountable.issue_do_transition(transition_id)\n    if t.status_code == 204:\n        click.secho(\n            'Successfully transitioned {}'.format(accountable.issue_key),\n            fg='green'\n        )", "response": "Transition the given issue to the provided ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a user search for the given query.", "response": "def users(accountable, query):\n    \"\"\"\n    Executes a user search for the given query.\n    \"\"\"\n    users = accountable.users(query)\n    headers = ['display_name', 'key']\n    if users:\n        rows = [[v for k, v in sorted(u.items()) if k in headers]\n                for u in users]\n        rows.insert(0, headers)\n        print_table(SingleTable(rows))\n    else:\n        click.secho('No users found for query {}'.format(\n            query\n        ), fg='red')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns types with guessed DST saves", "response": "def guess_saves(zone, data):\n    \"\"\"Return types with guessed DST saves\"\"\"\n    saves = {}\n    details = {}\n    for (time0, type0), (time1, type1) in pairs(data.times):\n        is_dst0 = bool(data.types[type0][1])\n        is_dst1 = bool(data.types[type1][1])\n        if (is_dst0, is_dst1) == (False, True):\n            shift = data.types[type1][0] - data.types[type0][0]\n            if shift:\n                saves.setdefault(type1, set()).add(shift)\n                details[type1, shift] = (time0, time1)\n        elif (is_dst0, is_dst1) == (True, False):\n            shift = data.types[type0][0] - data.types[type1][0]\n            if shift:\n                saves.setdefault(type0, set()).add(shift)\n                details[type0, shift] = (time0, time1)\n\n    types = data.types[:]\n    for i, (offset, save, abbr) in enumerate(data.types):\n        if save:\n            guesses = saves.get(i, set())\n            if not guesses:\n                print(\"No save value guesses for type %d (%r) in zone %s.\" %\n                      (i, types[i][-1], zone))\n                guess = timedelta(hours=1)\n            elif len(guesses) == 1:\n                guess = guesses.pop()\n            else:\n                print(\"Multiple save value guesses for type %d in zone %s.\" %\n                      (i, zone))\n                for g in guesses:\n                    d = details[i, g]\n                    print(\"   \", g, *d)\n                guess = min(g for g in guesses if g)\n            types[i] = (offset, guess, abbr)\n    return types"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrestructuring data about a blob for output.", "response": "def prepare(data):\n    \"\"\"Restructure/prepare data about a blob for output.\"\"\"\n    result = {}\n    result[\"mode\"] = data.get(\"mode\")\n    result[\"path\"] = data.get(\"path\")\n    result[\"type\"] = data.get(\"type\")\n    result[\"sha\"] = data.get(\"sha\")\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the SHA of a commit s tree.", "response": "def get_commit_tree(profile, sha):\n    \"\"\"Get the SHA of a commit's tree.\n\n    Args:\n\n        profile\n            A profile generated from ``simplygithub.authentication.profile``.\n            Such profiles tell this module (i) the ``repo`` to connect to,\n            and (ii) the ``token`` to connect with.\n\n        sha\n            The SHA of a commit.\n\n    Returns:\n        The SHA of the commit's tree.\n\n    \"\"\"\n    data = commits.get_commit(profile, sha)\n    tree = data.get(\"tree\")\n    sha = tree.get(\"sha\")\n    return sha"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_files_in_tree(profile, sha):\n    data = trees.get_tree(profile, sha)\n    tree = data.get(\"tree\")\n    blobs = [x for x in tree if x.get(\"type\") == \"blob\"]\n    return blobs", "response": "Get the files in a tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a file from a tree.", "response": "def remove_file_from_tree(tree, file_path):\n    \"\"\"Remove a file from a tree.\n\n    Args:\n\n        tree\n            A list of dicts containing info about each blob in a tree.\n\n        file_path\n            The path of a file to remove from a tree.\n\n    Returns:\n        The provided tree, but with the item matching the specified\n        file_path removed.\n\n    \"\"\"\n    match = None\n    for item in tree:\n        if item.get(\"path\") == file_path:\n            match = item\n            break\n    if match:\n        tree.remove(match)\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a file to a tree.", "response": "def add_file_to_tree(tree, file_path, file_contents, is_executable=False):\n    \"\"\"Add a file to a tree.\n\n    Args:\n\n        tree\n            A list of dicts containing info about each blob in a tree.\n\n        file_path\n            The path of the new file in the tree.\n\n        file_contents\n            The (UTF-8 encoded) contents of the new file.\n\n        is_executable\n            If ``True``, the new file will get executable permissions (0755).\n            Otherwise, it will get 0644 permissions.\n\n    Returns:\n        The provided tree, but with the new file added.\n\n    \"\"\"\n    record = {\n        \"path\": file_path,\n        \"mode\": \"100755\" if is_executable else \"100644\",\n        \"type\": \"blob\",\n        \"content\": file_contents,\n        }\n    tree.append(record)\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_files_in_branch(profile, branch_sha):\n    tree_sha = get_commit_tree(profile, branch_sha)\n    files = get_files_in_tree(profile, tree_sha)\n    tree = [prepare(x) for x in files]\n    return tree", "response": "Get all files in a branch s tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_file(\n        profile,\n        branch,\n        file_path,\n        file_contents,\n        is_executable=False,\n        commit_message=None):\n    \"\"\"Add a file to a branch.\n\n    Args:\n\n        profile\n            A profile generated from ``simplygithub.authentication.profile``.\n            Such profiles tell this module (i) the ``repo`` to connect to,\n            and (ii) the ``token`` to connect with.\n\n        branch\n            The name of a branch.\n\n        file_path\n            The path of the new file in the tree.\n\n        file_contents\n            The (UTF-8 encoded) contents of the new file.\n\n        is_executable\n            If ``True``, the new file will get executable permissions (0755).\n            Otherwise, it will get 0644 permissions.\n\n        commit_message\n            A commit message to give to the commit.\n\n    Returns:\n        A dict with data about the branch's new ref (it includes the new SHA\n        the branch's HEAD points to, after committing the new file).\n\n    \"\"\"\n    branch_sha = get_branch_sha(profile, branch)\n    tree = get_files_in_branch(profile, branch_sha)\n    new_tree = add_file_to_tree(tree, file_path, file_contents, is_executable)\n    data = trees.create_tree(profile, new_tree)\n    sha = data.get(\"sha\")\n    if not commit_message:\n        commit_message = \"Added \" + file_path + \".\"\n    parents = [branch_sha]\n    commit_data = commits.create_commit(profile, commit_message, sha, parents)\n    commit_sha = commit_data.get(\"sha\")\n    ref_data = refs.update_ref(profile, \"heads/\" + branch, commit_sha)\n    return ref_data", "response": "Adds a file to a branch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_file(profile, branch, file_path, commit_message=None):\n    branch_sha = get_branch_sha(profile, branch)\n    tree = get_files_in_branch(profile, branch_sha)\n    new_tree = remove_file_from_tree(tree, file_path)\n    data = trees.create_tree(profile, new_tree)\n    sha = data.get(\"sha\")\n    if not commit_message:\n        commit_message = \"Deleted \" + file_path + \".\"\n    parents = [branch_sha]\n    commit_data = commits.create_commit(profile, commit_message, sha, parents)\n    commit_sha = commit_data.get(\"sha\")\n    ref_data = refs.update_ref(profile, \"heads/\" + branch, commit_sha)\n    return ref_data", "response": "Removes a file from a branch."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a file from a branch.", "response": "def get_file(profile, branch, file_path):\n    \"\"\"Get a file from a branch.\n\n    Args:\n\n        profile\n            A profile generated from ``simplygithub.authentication.profile``.\n            Such profiles tell this module (i) the ``repo`` to connect to,\n            and (ii) the ``token`` to connect with.\n\n        branch\n            The name of a branch.\n\n        file_path\n            The path of the file to fetch.\n\n    Returns:\n        The (UTF-8 encoded) content of the file, as a string.\n\n    \"\"\"\n    branch_sha = get_branch_sha(profile, branch)\n    tree = get_files_in_branch(profile, branch_sha)\n    match = None\n    for item in tree:\n        if item.get(\"path\") == file_path:\n            match = item\n            break\n    file_sha = match.get(\"sha\")\n    blob = blobs.get_blob(profile, file_sha)\n    content = blob.get(\"content\")\n    decoded_content = b64decode(content)\n    return decoded_content.decode(\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make(self):\n        try:\n                \n            # Create the lock file\n            self.mkfile(self.lock_file)\n        except Exception as e:\n            self.die('Failed to generate lock file: {}'.format(str(e)))", "response": "Make the lock file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(self):\n        ''' activates the connection object '''\n\n        if not HAVE_ZMQ:\n            raise errors.AnsibleError(\"zmq is not installed\")\n        \n        # this is rough/temporary and will likely be optimized later ...\n        self.context = zmq.Context()\n        socket = self.context.socket(zmq.REQ)\n        addr = \"tcp://%s:%s\" % (self.host, self.port)\n        socket.connect(addr)\n        self.socket = socket    \n\n        return self", "response": "activates the connection object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command on the remote host", "response": "def exec_command(self, cmd, tmp_path, sudo_user, sudoable=False, executable='/bin/sh'):\n        ''' run a command on the remote host '''\n\n        vvv(\"EXEC COMMAND %s\" % cmd)\n\n        if self.runner.sudo and sudoable:\n            raise errors.AnsibleError(\"fireball does not use sudo, but runs as whoever it was initiated as.  (That itself is where to use sudo).\")\n\n        data = dict(\n            mode='command',\n            cmd=cmd,\n            tmp_path=tmp_path,\n            executable=executable,\n        )\n        data = utils.jsonify(data)\n        data = utils.encrypt(self.key, data)\n        self.socket.send(data)\n        \n        response = self.socket.recv()\n        response = utils.decrypt(self.key, response)\n        response = utils.parse_json(response)\n\n        return (response.get('rc',None), '', response.get('stdout',''), response.get('stderr',''))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put_file(self, in_path, out_path):\n\n        ''' transfer a file from local to remote '''\n        vvv(\"PUT %s TO %s\" % (in_path, out_path), host=self.host)\n\n        if not os.path.exists(in_path):\n            raise errors.AnsibleFileNotFound(\"file or module does not exist: %s\" % in_path)\n        data = file(in_path).read()\n        data = base64.b64encode(data)\n\n        data = dict(mode='put', data=data, out_path=out_path)\n        # TODO: support chunked file transfer\n        data = utils.jsonify(data)\n        data = utils.encrypt(self.key, data)\n        self.socket.send(data)\n\n        response = self.socket.recv()\n        response = utils.decrypt(self.key, response)\n        response = utils.parse_json(response)", "response": "transfer a file from local to remote"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching a remote file to the specified path", "response": "def fetch_file(self, in_path, out_path):\n        ''' save a remote file to the specified path '''\n        vvv(\"FETCH %s TO %s\" % (in_path, out_path), host=self.host)\n\n        data = dict(mode='fetch', in_path=in_path)\n        data = utils.jsonify(data)\n        data = utils.encrypt(self.key, data)\n        self.socket.send(data)\n\n        response = self.socket.recv()\n        response = utils.decrypt(self.key, response)\n        response = utils.parse_json(response)\n        response = response['data']\n        response = base64.b64decode(response)        \n\n        fh = open(out_path, \"w\")\n        fh.write(response)\n        fh.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _serializeNT(data):\n    if isinstance(data, list):\n        return [_serializeNT(item) for item in data]\n\n    elif isinstance(data, tuple) and hasattr(data, \"_fields\"):  # is namedtuple\n        serialized = _serializeNT(dict(data._asdict()))\n        serialized[\"__nt_name\"] = data.__class__.__name__\n\n        return serialized\n\n    elif isinstance(data, tuple):\n        return tuple(_serializeNT(item) for item in data)\n\n    elif isinstance(data, dict):\n        return {\n            key: _serializeNT(data[key])\n            for key in data\n        }\n\n    return data", "response": "Serialize namedtuples and other basic python types to dictionary with\n getTerminal properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iiOfAny(instance, classes):\n    if type(classes) not in [list, tuple]:\n        classes = [classes]\n\n    return any(\n        type(instance).__name__ == cls.__name__\n        for cls in classes\n    )", "response": "Returns True if instance is instance of any of the classes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fasta(self, loc, mask='mask'):\n        \n        l = libdna.parse_loc(loc)\n        \n        print('>{}'.format(l))\n        print(self.dna(l, mask=mask))", "response": "Prints a fasta representation of a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreverse complement the sequence of a set of attributes.", "response": "def rev_comp(dna):\n        \"\"\"\n        Parameters\n        ----------\n        dna : bytearray\n            dna sequence to be reverse complemented\n        \"\"\"\n        \n        i2 = len(dna) - 1\n        \n        l = len(dna) // 2\n        \n        for i in range(0, l):\n            b = DNA_COMP_DICT[dna[i]]\n            dna[i] = DNA_COMP_DICT[dna[i2]]\n            dna[i2] = b\n            i2 -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads data from a 1 bit file where each byte encodes 8 bases.", "response": "def _read1bit(d, l, offset=False):\n        \"\"\"\n        Read data from a 1 bit file where each byte encodes 8 bases.\n        \n        Parameters\n        ----------\n        d : array\n            byte array\n        l : tuple\n            chr, start, end\n        \n        Returns\n        -------\n        list\n            list of 1s and 0s of length equal to the number of bases in\n            the location.\n        \"\"\"\n\n        s = l.start - 1\n\n        length = l.end - l.start + 1\n\n        ret = [0] * length\n        \n        if offset:\n            bi = s // 8\n        else:\n            bi = 0\n            \n        for i in range(0, length):\n            block = s % 8\n            \n            if block == 0:\n                v = (d[bi] >> 7)\n            elif block == 1:\n                v = (d[bi] >> 6)\n            elif block == 2:\n                v = (d[bi] >> 5)\n            elif block == 3:\n                v = (d[bi] >> 4)\n            elif block == 4:\n                v = (d[bi] >> 3)\n            elif block == 5:\n                v = (d[bi] >> 2)\n            elif block == 6:\n                v = (d[bi] >> 1)\n            else:\n                v = d[bi]\n                bi += 1\n            \n            # Only care about the lowest bit\n            v &= 1\n            \n            ret[i] = v\n            \n            s += 1\n    \n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a 2bit file and return a list of base chars.", "response": "def _read2bit(d, l, offset=False):\n        \"\"\"\n        Read DNA from a 2bit file where each base is encoded in 2bit \n        (4 bases per byte).\n        \n        Parameters\n        ----------\n        d:\n        l : tuple\n            Location tuple\n        \n        Returns\n        -------\n        list\n            Array of base chars\n        \"\"\"\n        \n        s = l.start - 1\n        \n        ret = bytearray([0] * l.length) #[]\n        \n        if offset:\n            bi = s // 4\n        else:\n            bi = 0\n        \n        for i in range(0, l.length):\n            block = s % 4\n            \n            if block == 0:\n                v = (d[bi] >> 6)\n            elif block == 1:\n                v = (d[bi] >> 4)\n            elif block == 2:\n                v = (d[bi] >> 2)\n            else:\n                v = d[bi]\n                \n                # Reached end of byte so we are moving into the next byte\n                bi += 1\n            \n            # Only care about the lowest 2 bits\n            v &= 3\n            \n            ret[i] = DNA_UC_DECODE_DICT[v]\n                \n            s += 1\n            \n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a DNA from a 2bit file where each base is encoded in 2bit .", "response": "def _read_dna(self, l, lowercase=False):\n        \"\"\"\n        Read DNA from a 2bit file where each base is encoded in 2bit \n        (4 bases per byte).\n        \n        Parameters\n        ----------\n        l : tuple\n            Location tuple\n        \n        Returns\n        -------\n        list\n            Array of base chars\n        \"\"\"\n        \n        file = os.path.join(self.dir, l.chr + \".dna.2bit\")\n        \n        print(file)\n        \n        if not os.path.exists(file):\n            return bytearray([])\n       \n        f = open(file, 'rb')\n        f.seek((l.start - 1) // 4)\n        # read bytes into buffer\n        data = f.read(l.length // 4 + 2)\n        f.close()\n        \n        return DNA2Bit._read2bit(data, l)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_1bit_file(file, l):\n        \n        f = open(file, 'rb')\n        f.seek((l.start - 1) // 8)\n        # read length + 2 because we need the extra byte in case the start\n        # position lies mid way through a byte. Imagine a sequence 10 bp long\n        # starting at position 4. 10 // 8 + 1 = 2 bytes of data required to\n        # store this. Since we pick the closest byte as the start, this will\n        # be position 0 (4 // 8 = 0). The length is 2 bytes spanning bytes 0\n        # and 1, but because of the start at 3, our sequence spans byte 3 so\n        # we need to buffer an extra byte for cases where the start does not\n        # match the start of a byte\n        data = f.read(l.length // 8 + 2)\n        f.close()\n        return data", "response": "Read data from 1 bit file into array\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the N mask from 1 bit file to convert bases to N.", "response": "def _read_n(self, l, ret):\n        \"\"\"\n        Reads 'N' mask from 1 bit file to convert bases to 'N'. In the\n        2 bit file, 'N' or any other invalid base is written as 'A'.\n        Therefore the 'N' mask file is required to correctly identify where\n        invalid bases are.\n        \n        Parameters\n        ----------\n        l : tuple\n            location\n        ret : list\n            List of bases which will be modified in place.\n        \"\"\"\n        \n        file = os.path.join(self.dir, l.chr + \".n.1bit\")\n        \n        if not os.path.exists(file):\n            return\n        \n        data = DNA2Bit._read_1bit_file(file, l)\n        \n        d = DNA2Bit._read1bit(data, l)\n        \n        for i in range(0, len(ret)):\n            if d[i] == 1:\n                ret[i] = DNA_N_UC"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the mask from 1 bit file to convert bases to lowercase or upper.", "response": "def _read_mask(self, l, ret, mask='upper'):\n        \"\"\"\n        Reads mask from 1 bit file to convert bases to identify poor quality\n        bases that will either be converted to lowercase or 'N'. In the\n        2 bit file, 'N' or any other invalid base is written as 'A'.\n        Therefore the 'N' mask file is required to correctly identify where\n        invalid bases are.\n        \n        Parameters\n        ----------\n        l : tuple\n            location\n        ret : list\n            list of bases which will be modified in place\n        mask : str, optional\n            Either 'upper', 'lower', or 'n'. If 'lower', poor quality bases \n            will be converted to lowercase.\n        \"\"\"\n        \n        if mask.startswith('u'):\n            return\n         \n        file = os.path.join(self.__dir, l.chr + \".mask.1bit\")\n             \n        if not os.path.exists(file):\n            return\n        \n        data = DNA2Bit._read_1bit_file(file, l)\n        \n        d = DNA2Bit._read1bit(data, l)\n        \n        if mask.startswith('l'):\n            for i in range(0, len(ret)):\n                if d[i] == 1:\n                    ret[i] = DNA_UC_TO_LC_MAP[ret[i]] #ret[i].lower()\n        else:\n            # Use N as mask\n            for i in range(0, len(ret)):\n                if d[i] == 1:\n                    ret[i] = DNA_N_UC"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the DNA for a location.", "response": "def dna(self, loc, mask='lower', rev_comp=False, lowercase=False):\n        \"\"\"\n        Returns the DNA for a location.\n        \n        Parameters\n        ----------\n        mask : str, optional\n            Indicate whether masked bases should be represented as is\n            ('upper'), lowercase ('lower'), or as N ('n')\n        lowercase : bool, optional\n            Indicates whether sequence should be displayed as upper or\n            lowercase. Default is False so sequence is uppercase. Note that\n            this only affects the reference DNA and does not affect the\n            mask.\n        \n        Returns\n        -------\n        list\n            List of base chars.\n        \"\"\"\n        \n        l = libdna.parse_loc(loc)\n            \n        ret = self._read_dna(l, lowercase=lowercase)\n        \n        self._read_n(l, ret)\n            \n        self._read_mask(l, ret, mask=mask)\n        \n        if rev_comp:\n            DNA2Bit._rev_comp(ret)\n        \n        ret = ret.decode('utf-8')\n        \n        if lowercase:\n            ret = ret.lower()\n      \n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_read_pair_seq(self, r1, r2):\n        \n        s1 = r1.pos # + 1\n            \n        # end of first read\n        e1 = s1 + r1.length - 1\n    \n        # start of second read\n        s2 = r2.pos # + 1\n        \n        e2 = s2 + r2.length - 1\n    \n        inner = s2 - e1 - 1\n    \n        if inner >= 0:\n            seq = self.dna((r1.chr, s1, e2))\n        else:\n            # Reads overlap so concatenate the first read with the\n            # portion of the second read that is not overlapping\n            # (inner is negative so flip sign for array indexing)\n            seq = r1.seq + r2.seq[-inner:]\n            \n        return seq", "response": "Merge the sequence of two reads into one continuous read."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_dna(self, l, lowercase=False):\n        \n        file = os.path.join(self.dir, l.chr + \".dna.2bit\")\n        \n        if not os.path.exists(file):\n            return []\n\n        if file != self.__file:\n            print('Caching {}...'.format(file))\n            self.__file = file\n            # Load file into memory\n            f = open(file, 'rb')\n            self.__data = f.read()\n            f.close()\n            \n            \n        return DNA2Bit._read2bit(self.__data, l, offset=True)", "response": "Read a DNA from a 2bit file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the N mask from 1 bit file to convert bases to N.", "response": "def _read_n(self, l, ret):\n        \"\"\"\n        Reads 'N' mask from 1 bit file to convert bases to 'N'. In the\n        2 bit file, 'N' or any other invalid base is written as 'A'.\n        Therefore the 'N' mask file is required to correctly identify where\n        invalid bases are.\n        \n        Parameters\n        ----------\n        l : tuple\n            location\n        ret : list\n            List of bases which will be modified in place.\n        \"\"\"\n        \n        file = os.path.join(self.dir, l.chr + \".n.1bit\")\n        \n        if not os.path.exists(file):\n            return\n        \n        if file != self.__n_file:\n            print('Caching {}...'.format(file))\n            f = open(file, 'rb')\n            self.__n_data = f.read()\n            f.close()\n            self.__n_file = file\n        \n        d = DNA2Bit._read1bit(self.__n_data, l, offset=True)\n        \n        for i in range(0, len(ret)):\n            if d[i] == 1:\n                ret[i] = DNA_N_UC"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_mask(self, l, ret, mask='upper'):\n        \n        if mask.startswith('u'):\n            return\n         \n        file = os.path.join(self.dir, l.chr + \".mask.1bit\")\n             \n        if not os.path.exists(file):\n            return\n        \n        if file != self.__mask_file:\n            print('Caching {}...'.format(file))\n            f = open(file, 'rb')\n            self.__mask_data = f.read()\n            f.close()\n            self.__mask_file = file\n        \n        d = DNA2Bit._read1bit(self.__mask_data, l, offset=True)\n        \n        if mask.startswith(l):\n            for i in range(0, len(ret)):\n                if d[i] == 1:\n                    ret[i] = DNA_UC_TO_LC_MAP[ret[i]] #ret[i].lower()\n        else:\n            # Use N as mask\n            for i in range(0, len(ret)):\n                if d[i] == 1:\n                    ret[i] = DNA_N_UC", "response": "Reads the mask file and converts bases to lowercase or upper."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshorts circuit for adding the value to the internal collection.", "response": "def _short_circuit(value=None):\n    \"\"\"\n    Add the `value` to the `collection` by modifying the collection to be\n    either a dict or list depending on what is already in the collection and\n    value.\n    Returns the collection with the value added to it.\n\n    Clean up by removing single item array and single key dict.\n    ['abc'] -> 'abc'\n    [['abc']] -> 'abc'\n    [{'abc':123},{'def':456}] -> {'abc':123,'def':456}\n    [{'abc':123},{'abc':456}] -> [{'abc':123,'abc':456}] # skip for same set keys\n    [[{'abc':123},{'abc':456}]] -> [{'abc':123,'abc':456}]\n    \"\"\"\n    if not isinstance(value, list):\n        return value\n    if len(value) == 0:\n        return value\n    if len(value) == 1:\n        if not isinstance(value[0], list):\n            return value[0]\n        else:\n            if len(value[0]) == 1:\n                return value[0][0]\n            else:\n                return value[0]\n    else:\n        value = filter(None, value)\n        # Only checking first item and assumin all others are same type\n        if isinstance(value[0], dict):\n            if set(value[0].keys()) == set(value[1].keys()):\n                return value\n            elif max([len(x.keys()) for x in value]) == 1:\n                newvalue = {}\n                for v in value:\n                    key = v.keys()[0]\n                    newvalue[key] = v[key]\n                return newvalue\n            else:\n                return value\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _query(_node_id, value=None, **kw):\n    \"Look up value by using Query table\"\n    query_result = []\n    try:\n        query_result = db.execute(text(fetch_query_string('select_query_from_node.sql')), **kw).fetchall()\n    except DatabaseError as err:\n        current_app.logger.error(\"DatabaseError: %s, %s\", err, kw)\n        return value\n    #current_app.logger.debug(\"queries kw: %s\", kw)\n    #current_app.logger.debug(\"queries value: %s\", value)\n    current_app.logger.debug(\"queries: %s\", query_result)\n    if query_result:\n        values = []\n        for query_name in [x['name'] for x in query_result]:\n            if query_name:\n                result = []\n                try:\n                    current_app.logger.debug(\"query_name: %s\", query_name)\n                    #current_app.logger.debug(\"kw: %s\", kw)\n                    # Query string can be insert or select here\n                    #statement = text(fetch_query_string(query_name))\n                    #params = [x.key for x in statement.params().get_children()]\n                    #skw = {key: kw[key] for key in params}\n                    #result = db.execute(statement, **skw)\n                    result = db.execute(text(fetch_query_string(query_name)), **kw)\n                    current_app.logger.debug(\"result query: %s\", result.keys())\n                except (DatabaseError, StatementError) as err:\n                    current_app.logger.error(\"DatabaseError (%s) %s: %s\", query_name, kw, err)\n                if result and result.returns_rows:\n                    result = result.fetchall()\n                    #values.append(([[dict(zip(result.keys(), x)) for x in result]], result.keys()))\n                    #values.append((result.fetchall(), result.keys()))\n                    #current_app.logger.debug(\"fetchall: %s\", values)\n                    if len(result) == 0:\n                        values.append(([], []))\n                    else:\n                        current_app.logger.debug(\"result: %s\", result)\n                        # There may be more results, but only interested in the\n                        # first one. Use the older rowify method for now.\n                        # TODO: use case for rowify?\n                        values.append(rowify(result, [(x, None) for x in result[0].keys()]))\n                        #current_app.logger.debug(\"fetchone: %s\", values)\n        value = values\n    #current_app.logger.debug(\"value: %s\", value)\n    return value", "response": "Look up value by using Query table"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a template is assigned to it and render that with the value", "response": "def _template(node_id, value=None):\n    \"Check if a template is assigned to it and render that with the value\"\n    result = []\n    select_template_from_node = fetch_query_string('select_template_from_node.sql')\n    try:\n        result = db.execute(text(select_template_from_node), node_id=node_id)\n        template_result = result.fetchone()\n        result.close()\n        if template_result and template_result['name']:\n            template = template_result['name']\n\n            if isinstance(value, dict):\n                return render_template(template, **value)\n            else:\n                return render_template(template, value=value)\n    except DatabaseError as err:\n        current_app.logger.error(\"DatabaseError: %s\", err)\n\n    # No template assigned to this node so just return the value\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_node(_node_id, value=None, noderequest={}, **kw):\n    \"Recursively render a node's value\"\n    if value == None:\n        kw.update( noderequest )\n        results = _query(_node_id, **kw)\n        current_app.logger.debug(\"results: %s\", results)\n        if results:\n            values = []\n            for (result, cols) in results:\n                if set(cols) == set(['node_id', 'name', 'value']):\n                    for subresult in result:\n                        #if subresult.get('name') == kw.get('name'):\n                            # This is a link node\n                        current_app.logger.debug(\"sub: %s\", subresult)\n                        name = subresult['name']\n                        if noderequest.get('_no_template'):\n                            # For debugging or just simply viewing with the\n                            # operate script we append the node_id to the name\n                            # of each. This doesn't work with templates.\n                            name = \"{0} ({1})\".format(name, subresult['node_id'])\n                        values.append( {name: render_node( subresult['node_id'], noderequest=noderequest, **subresult )} )\n                #elif 'node_id' and 'name' in cols:\n                #    for subresult in result:\n                #        current_app.logger.debug(\"sub2: %s\", subresult)\n                #        values.append( {subresult.get('name'): render_node( subresult.get('node_id'), **subresult )} )\n                else:\n                    values.append( result )\n\n            value = values\n\n    value = _short_circuit(value)\n    if not noderequest.get('_no_template'):\n        value = _template(_node_id, value)\n\n    return value", "response": "Recursively render a node s value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_terminfo(terminal_name=None, fallback='vt100'):\n\n    terminal_name = os.getenv('TERM')\n    if not terminal_name:\n        if not fallback:\n            raise TerminfoError('Environment variable TERM is unset and no fallback was requested')\n        else:\n            terminal_name = fallback\n   \n    if os.getenv('TERMINFO'):\n        # from man terminfo(5):\n        #   if the environment variable TERMINFO is set, \n        #   only that directory is searched\n        terminfo_locations = [os.getenv('TERMINFO')]\n    else:\n        terminfo_locations = [] # from most to least important\n\n        if os.getenv('TERMINFO_DIRS'):\n            for i in os.getenv('TERMINFO_DIRS').split(':'):\n                # from man terminfo(5)\n                #   An empty directory name is interpreted as /usr/share/terminfo.\n                terminfo_locations.append(i or '/usr/share/terminfo')\n\n        terminfo_locations += [\n            os.path.expanduser('~/.terminfo'),\n            '/etc/terminfo',\n            '/usr/local/ncurses/share/terminfo',\n            '/lib/terminfo',\n            '/usr/share/terminfo'\n        ]\n\n        # remove duplicates preserving order\n        terminfo_locations = list(OrderedDict.fromkeys(terminfo_locations))\n\n    terminfo_path = None\n    for dirpath in terminfo_locations:\n        path = os.path.join(dirpath, terminal_name[0], terminal_name)\n        if os.path.exists(path):\n            terminfo_path = path\n            break\n\n    if not path:\n        raise TerminfoError(\"Couldn't find a terminfo file for terminal '%s'\" % terminal_name)\n\n    from terminfo_index import BOOLEAN_CAPABILITIES, NUMBER_CAPABILITIES, STRING_CAPABILITIES\n\n    data = open(terminfo_path, 'rb').read()\n\n    # header (see man term(5), STORAGE FORMAT)\n    header = struct.unpack('<hhhhhh', data[:12]) # 2 bytes == 1 short integer \n    magic_number  = header[0] # the magic number (octal 0432)\n    size_names    = header[1] # the size, in bytes, of the names section\n    size_booleans = header[2] # the number of bytes in the boolean section\n    num_numbers   = header[3] # the number of short integers in the numbers section\n    num_offsets   = header[4] # the number of offsets (short integers) in the strings section\n    size_strings  = header[5] # the size, in bytes, of the string table\n\n    if magic_number != 0o432:\n        raise TerminfoError('Bad magic number')\n \n    # sections indexes\n\n    idx_section_names    = 12\n    idx_section_booleans = idx_section_names + size_names\n    idx_section_numbers  = idx_section_booleans + size_booleans\n\n    if idx_section_numbers % 2 != 0:\n        idx_section_numbers += 1 # must start on an even byte\n\n    idx_section_strings  = idx_section_numbers + 2 * num_numbers\n    idx_section_string_table = idx_section_strings + 2 * num_offsets\n\n    # terminal names\n    terminal_names = data[idx_section_names:idx_section_booleans].decode('ascii')\n    terminal_names = terminal_names[:-1].split('|') # remove ASCII NUL and split\n\n    terminfo = Terminfo(terminal_names[0], terminal_names[1:])\n\n    # booleans\n    for i, idx in enumerate(range(idx_section_booleans, idx_section_booleans + size_booleans)):\n        cap = BooleanCapability(*BOOLEAN_CAPABILITIES[i], value=data[i] == b'\\x00')\n        terminfo.booleans[cap.variable] = cap\n\n    # numbers\n    numbers = struct.unpack('<'+'h' * num_numbers, data[idx_section_numbers:idx_section_strings])\n    for i,strnum in enumerate(numbers):\n        cap = NumberCapability(*NUMBER_CAPABILITIES[i], value=strnum)\n        terminfo.numbers[cap.variable] = cap\n\n    # strings\n    offsets = struct.unpack('<'+'h' * num_offsets, data[idx_section_strings:idx_section_string_table])\n\n    idx = 0\n    for offset in offsets:\n        k = 0\n        string = []\n        while True and offset != -1:\n            char = data[idx_section_string_table + offset + k:idx_section_string_table + offset + k + 1]\n            if char == b'\\x00':\n                break\n\n            string.append(char.decode('iso-8859-1'))\n            k += 1\n        string = u''.join(string)\n        \n        cap = StringCapability(*STRING_CAPABILITIES[idx], value=string)\n        terminfo.strings[cap.variable] = cap\n\n        idx += 1\n\n    terminfo._reset_index()\n\n    return terminfo", "response": "Load a terminfo file for a given terminal."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, name):\n        # `name` is most likely a capname, so we try that first\n        for i in (self._by_capname, self._by_var, self._by_tcap_code):\n            if i.get(name):\n                return i.get(name)\n        else:\n            raise TerminfoError(\"'%s' is not a valid terminfo entry\" % name)", "response": "Get the escape code associated to a terminfo entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetecting the current version of the current version of the current version of the current version of the current version of the current version of the current version of the current version of the current version of the current version of the version.", "response": "def detect(self, escape_code):\n        import re\n\n        \"\"\"\n        str_params = '%(%' + \\\n            r'|[-+*/m&\\|cisl^=><AO!~]|p[1-9]|[Pg][a-zA-Z]' + \\\n            r'|((:?[-+# ])?([0-9]+(\\.[0-9]+)?)?[doxXs])' + \\\n            r\"|('c'|\\{[0-9]+\\})\" + \\\n            r\"|(\\?.*?;)\" + \\\n        ')'\n        \"\"\"\n\n        cap = self._by_escape_code.get(escape_code, UnknownCapability())\n        cap.value = escape_code\n\n        \"\"\"\n        pattern = re.compile(str_params)\n        simplified = pattern.sub('', escape_code)\n        print(repr(simplified))\n        \"\"\"\n\n        #return self._by_escape_code.get(escape_code)\n        return cap"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting list of model run resources from a SCO - API.", "response": "def get_run_listing(listing_url, offset, limit, properties):\n    \"\"\"Get list of experiment resources from a SCO-API.\n\n    Parameters\n    ----------\n    listing_url : string\n        url for experiments run listing.\n    offset : int\n        Starting offset for returned list items\n    limit : int\n        Limit the number of items in the result\n    properties : List(string)\n        List of additional object properties to be included for items in\n        the result\n\n    Returns\n    -------\n    List(scoserv.ModelRunDescriptor)\n        List of model run descriptors\n    \"\"\"\n    # Create listing query based on given arguments\n    query = [\n        QPARA_OFFSET + '=' + str(offset),\n        QPARA_LIMIT + '=' + str(limit)\n    ]\n    # Ensure that the run state is included in the listing as attribute\n    props = ['state']\n    # Add properties argument if property list is not None and not empty\n    if not properties is None:\n        for prop in properties:\n            if not prop in props:\n                props.append(prop)\n    query.append(QPARA_ATTRIBUTES + '=' + ','.join(props))\n    # Add query to Url.\n    url = listing_url + '?' + '&'.join(query)\n    # Get subject listing Url for given SCO-API and decorate it with\n    # given listing arguments. Then retrieve listing from SCO-API.\n    json_obj = JsonResource(url).json\n    # Convert result into a list of resource handles and return the result\n    resources = []\n    for element in json_obj['items']:\n        resource = ModelRunDescriptor(element)\n        # Add additional properties to resource if list is given\n        if not properties is None:\n            resource.properties = {}\n            for prop in properties:\n                if prop in element:\n                    resource.properties[prop] = element[prop]\n        resources.append(resource)\n    return resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new experiment using the given SCO - API create experiment Url.", "response": "def create(url, name, subject_id, image_group_id, properties):\n        \"\"\"Create a new experiment using the given SCO-API create experiment Url.\n\n        Parameters\n        ----------\n        url : string\n            Url to POST experiment create request\n        name : string\n            User-defined name for experiment\n        subject_id : string\n            Unique identifier for subject at given SCO-API\n        image_group_id : string\n            Unique identifier for image group at given SCO-API\n        properties : Dictionary\n            Set of additional properties for created experiment. Argument may be\n            None. Given name will override name property in this set (if present).\n\n        Returns\n        -------\n        string\n            Url of created experiment resource\n        \"\"\"\n        # Create list of key,value-pairs representing experiment properties for\n        # request. The given name overrides the name in properties (if present).\n        obj_props = [{'key':'name','value':name}]\n        if not properties is None:\n            # Catch TypeErrors if properties is not a list.\n            try:\n                for key in properties:\n                    if key != 'name':\n                        obj_props.append({'key':key, 'value':properties[key]})\n            except TypeError as ex:\n                raise ValueError('invalid property set')\n        # Create request body and send POST request to given Url\n        body = {\n            'subject' : subject_id,\n            'images' : image_group_id,\n            'properties' : obj_props\n        }\n        try:\n            req = urllib2.Request(url)\n            req.add_header('Content-Type', 'application/json')\n            response = urllib2.urlopen(req, json.dumps(body))\n        except urllib2.URLError as ex:\n            raise ValueError(str(ex))\n        # Get experiment self reference from successful response\n        return references_to_dict(json.load(response)['links'])[REF_SELF]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new model run with given name arguments and properties.", "response": "def run(self, model_id, name, arguments={}, properties=None):\n        \"\"\"Create a new model run with given name, arguments, and properties.\n        Parameters\n        ----------\n        model_id : string\n            Unique model identifier\n        name : string\n            User-defined name for experiment\n        arguments : Dictionary\n            Dictionary of arguments for model run\n        properties : Dictionary, optional\n            Set of additional properties for created mode run.\n\n        Returns\n        -------\n        scoserv.ModelRunHandle\n            Handle for local copy of created model run resource\n        \"\"\"\n        return self.sco.experiments_predictions_create(\n            model_id,\n            name,\n            self.links[REF_EXPERIMENTS_RUNS_CREATE],\n            arguments=arguments,\n            properties=properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef runs(self, offset=0, limit=-1, properties=None):\n        return get_run_listing(\n            self.runs_url,\n            offset=offset,\n            limit=limit,\n            properties=properties\n        )", "response": "Get a list of model run descriptors associated with this expriment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlike map but also chains the results.", "response": "def imapchain(*a, **kwa):\r\n    \"\"\" Like map but also chains the results. \"\"\"\r\n\r\n    imap_results = map( *a, **kwa )\r\n    return itertools.chain( *imap_results )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iapply(function, *iterables):\r\n\r\n    iterables = map(iter, iterables)\r\n    while True:\r\n        args = [next(it) for it in iterables]\r\n        if function is None:\r\n            yield tuple(args)\r\n        else:\r\n            function(*args)\r\n            yield args[0]", "response": "Like itertools. iapply but returns the iterable s item / iterables instead."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iskip( value, iterable ):\r\n\r\n    for e in iterable:\r\n        if value is None:\r\n            if e is None:\r\n                continue\r\n        elif e == value:\r\n            continue\r\n        yield e", "response": "Returns an iterator that skips all values in iterable that match the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unique(iterable):\r\n\r\n    yielded = set()\r\n    for i in iterable:\r\n        if i in yielded:\r\n            continue\r\n        yield i\r\n        yielded.add(i)", "response": "Returns an iterator that yields each element only once."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats command along with any arguments ready to be sent.", "response": "def format(self, password: str = '') -> str:\n        \"\"\"Format command along with any arguments, ready to be sent.\"\"\"\n        return MARKER_START + \\\n            self.name + \\\n            self.action + \\\n            self.args + \\\n            password + \\\n            MARKER_END"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef args(self) -> str:\n        value = self._value\n        if not value:\n            value = datetime.now()\n        return value.strftime('%y%m%d%w%H%M')", "response": "Provides arguments for the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef args(self) -> str:\n        return '{}{}'.format(\n            to_ascii_hex(self._group_number, 2),\n            to_ascii_hex(self._unit_number, 2))", "response": "Provides arguments for the command."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef args(self) -> str:\n        return '{}{}{}{}{}'.format(\n            to_ascii_hex(self._index, 2),\n            to_ascii_hex(self._group_number, 2),\n            to_ascii_hex(self._unit_number, 2),\n            to_ascii_hex(int(self._enable_status), 4),\n            to_ascii_hex(int(self._switches), 4))", "response": "Provides arguments for the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprovides arguments for the command.", "response": "def args(self) -> str:\n        \"\"\"Provides arguments for the command.\"\"\"\n        return '{}{}{}{}{}{}{}{}{}{}{}'.format(\n            to_ascii_hex(self._index, 2),\n            to_ascii_hex(self._group_number, 2),\n            to_ascii_hex(self._unit_number, 2),\n            to_ascii_hex(int(self._enable_status), 4),\n            to_ascii_hex(int(self._switches), 4),\n            to_ascii_hex(self._current_status, 2),\n            to_ascii_hex(self._down_count, 2),\n            to_ascii_hex(encode_value_using_ma(self._message_attribute, self._current_reading), 2),\n            to_ascii_hex(encode_value_using_ma(self._message_attribute, self._high_limit), 2),\n            to_ascii_hex(encode_value_using_ma(self._message_attribute, self._low_limit), 2),\n            to_ascii_hex(int(self._special_status), 2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef args(self) -> str:\n        return '{}{}{}'.format(\n            ChangeSpecialDeviceCommand.args,\n            to_ascii_hex(encode_value_using_ma(self._message_attribute,\n                                               self._control_high_limit), 2),\n            to_ascii_hex(encode_value_using_ma(self._message_attribute,\n                                               self._control_low_limit), 2))", "response": "Provides arguments for the command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lint(to_lint):\n    exit_code = 0\n    for linter, options in (('pyflakes', []), ('pep8', [])):\n        try:\n            output = local[linter](*(options + to_lint))\n        except commands.ProcessExecutionError as e:\n            output = e.stdout\n\n        if output:\n            exit_code = 1\n            print \"{0} Errors:\".format(linter)\n            print output\n\n    output = hacked_pep257(to_lint)\n    if output:\n        exit_code = 1\n        print \"Docstring Errors:\".format(linter.upper())\n        print output\n\n    sys.exit(exit_code)", "response": "Run all linters against a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck for presence of docstrings but ignore some of the options and options.", "response": "def hacked_pep257(to_lint):\n    \"\"\"\n    Check for the presence of docstrings, but ignore some of the options\n    \"\"\"\n    def ignore(*args, **kwargs):\n        pass\n\n    pep257.check_blank_before_after_class = ignore\n    pep257.check_blank_after_last_paragraph = ignore\n    pep257.check_blank_after_summary = ignore\n    pep257.check_ends_with_period = ignore\n    pep257.check_one_liners = ignore\n    pep257.check_imperative_mood = ignore\n\n    original_check_return_type = pep257.check_return_type\n\n    def better_check_return_type(def_docstring, context, is_script):\n        \"\"\"\n        Ignore private methods\n        \"\"\"\n        def_name = context.split()[1]\n        if def_name.startswith('_') and not def_name.endswith('__'):\n            original_check_return_type(def_docstring, context, is_script)\n\n    pep257.check_return_type = better_check_return_type\n\n    errors = []\n    for filename in to_lint:\n        with open(filename) as f:\n            source = f.read()\n            if source:\n                errors.extend(pep257.check_source(source, filename))\n    return '\\n'.join([str(error) for error in sorted(errors)])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_meta(request):\n    context_extras = {}\n    if not request.is_ajax() and hasattr(request, 'upy_context') and request.upy_context['PAGE']:\n        context_extras['PAGE'] = request.upy_context['PAGE']\n        context_extras['NODE'] = request.upy_context['NODE']\n    return context_extras", "response": "Sets the meta information of the current page and node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading virtualenv package from pypi and return response that can be read and written to file", "response": "def download_virtualenv(version, dldir=None):\n    '''\n    Download virtualenv package from pypi and return response that can be\n    read and written to file\n\n    :param str version: version to download or latest version if None\n    :param str dldir: directory to download into or None for cwd\n    '''\n    dl_url = PYPI_DL_URL.format(VER=version)\n    filename = basename(dl_url)\n    if dldir:\n        dl_path = join(dldir, filename)\n    else:\n        dl_path = filename\n    data = urlopen(PYPI_DL_URL.format(VER=version))\n    with open(dl_path, 'wb') as fh:\n        fh.write(data.read())\n    return dl_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_virtualenv(venvpath, venvargs=None):\n    '''\n    Run virtualenv from downloaded venvpath using venvargs\n    If venvargs is None, then 'venv' will be used as the virtualenv directory\n\n    :param str venvpath: Path to root downloaded virtualenv package(must contain\n        virtualenv.py)\n    :param list venvargs: Virtualenv arguments to pass to virtualenv.py\n    '''\n    cmd = [join(venvpath, 'virtualenv.py')]\n    venv_path = None\n    if venvargs:\n        cmd += venvargs\n        venv_path = abspath(venvargs[-1])\n    else:\n        cmd += ['venv']\n    p = subprocess.Popen(cmd)\n    p.communicate()", "response": "Create a new virtual environment from a downloaded virtualenv path using venvargs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bootstrap_vi(version=None, venvargs=None):\n    '''\n    Bootstrap virtualenv into current directory\n\n    :param str version: Virtualenv version like 13.1.0 or None for latest version\n    :param list venvargs: argv list for virtualenv.py or None for default\n    '''\n    if not version:\n        version = get_latest_virtualenv_version()\n    tarball = download_virtualenv(version)\n    p = subprocess.Popen('tar xzvf {0}'.format(tarball), shell=True)\n    p.wait()\n    p = 'virtualenv-{0}'.format(version)\n    create_virtualenv(p, venvargs)", "response": "Bootstraps a virtualenv into current directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compose_path(pub, uuid_url=False):\n    if uuid_url:\n        return join(\n            \"/\",\n            UUID_DOWNLOAD_KEY,\n            str(pub.uuid)\n        )\n\n    return join(\n        \"/\",\n        DOWNLOAD_KEY,\n        basename(pub.file_pointer),\n        basename(pub.filename)\n    )", "response": "Compose absolute path for given Publication instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomposes absolute path for given tree.", "response": "def compose_tree_path(tree, issn=False):\n    \"\"\"\n    Compose absolute path for given `tree`.\n\n    Args:\n        pub (obj): :class:`.Tree` instance.\n        issn (bool, default False): Compose URL using ISSN.\n\n    Returns:\n        str: Absolute path of the tree, without server's address and protocol.\n    \"\"\"\n    if issn:\n        return join(\n            \"/\",\n            ISSN_DOWNLOAD_KEY,\n            basename(tree.issn)\n        )\n\n    return join(\n        \"/\",\n        PATH_DOWNLOAD_KEY,\n        quote_plus(tree.path).replace(\"%2F\", \"/\"),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compose_full_url(pub, uuid_url=False):\n    url = compose_path(pub, uuid_url)\n\n    if WEB_PORT == 80:\n        return \"%s://%s%s\" % (_PROTOCOL, WEB_ADDR, url)\n\n    return \"%s://%s:%d%s\" % (_PROTOCOL, WEB_ADDR, WEB_PORT, url)", "response": "Compose full url for given pub with protocol server s address and port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompose full url for given tree.", "response": "def compose_tree_url(tree, issn_url=False):\n    \"\"\"\n    Compose full url for given `tree`, with protocol, server's address and\n    port.\n\n    Args:\n        tree (obj): :class:`.Tree` instance.\n        issn_url (bool, default False): Compose URL using ISSN.\n\n    Returns:\n        str: URL of the tree\n    \"\"\"\n    url = compose_tree_path(tree, issn_url)\n\n    if WEB_PORT == 80:\n        return \"%s://%s%s\" % (_PROTOCOL, WEB_ADDR, url)\n\n    return \"%s://%s:%d%s\" % (_PROTOCOL, WEB_ADDR, WEB_PORT, url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the input into an encoded C String", "response": "def new_cstr(self, input, null_if_empty=True):\n        \"\"\"\n        Converts the input into an encoded C String (NUL-terminated)\n        :param input: The python string\n        :param null_if_empty: If the input is empty, return NULL rather\n            than the empty string\n        :return: The C string\n        \"\"\"\n        if input:\n            enc = input.encode('utf-8')\n        else:\n            enc = ''.encode('utf-8')\n        if not enc:\n            if null_if_empty:\n                return self._ffi.NULL\n        try:\n            return self._cache[enc]\n        except KeyError:\n            cstr = self._ffi.new('char[]', enc)\n            self._cache[enc] = cstr\n            return cstr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the input into a raw C buffer and returns it and the length of the input.", "response": "def new_cbuf(self, input, null_if_empty=True):\n        \"\"\"\n        Converts the input into a raw C buffer\n        :param input: The input\n        :param null_if_empty: If the input is empty\n        :return: A tuple of buffer,length\n        \"\"\"\n        if not isinstance(input, bytes) and input:\n            input = input.encode('utf-8')\n        if not input and null_if_empty:\n            return self._ffi.NULL, 0\n\n        cbuf = self._ffi.new('char[]', input)\n        self._bufs.append(cbuf)\n        return cbuf, len(input)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepareClasses(locals):\n    for (name, forgetter) in locals.items():\n        if not (type(forgetter) is types.TypeType and\n                issubclass(forgetter, Forgetter)):\n            # Only care about Forgetter objects\n            continue\n\n        # Resolve classes\n        for (key, userclass) in forgetter._userClasses.items():\n            if type(userclass) is types.StringType:\n                # resolve from locals\n                resolved = locals[userclass]\n                forgetter._userClasses[key] = resolved\n\n        forgetter._tables = {}\n        # Update all fields with proper names\n        for (field, sqlfield) in forgetter._sqlFields.items():\n            forgetter._sqlFields[field] = forgetter._checkTable(sqlfield)\n\n        newLinks = []\n        for linkpair in forgetter._sqlLinks:\n            (link1, link2) = linkpair\n            link1=forgetter._checkTable(link1)\n            link2=forgetter._checkTable(link2)\n            newLinks.append((link1, link2))\n\n        forgetter._sqlLinks = newLinks\n        forgetter._prepared = True", "response": "Prepare all Forgetter classes in the local module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generateFromTables(tables, cursor, getLinks=1, code=0):\n    curs = cursor()\n    forgetters = {}\n    class _Wrapper(forgetSQL.Forgetter):\n        _autosave = False\n        pass\n    _Wrapper.cursor = cursor\n    for table in tables:\n        # capitalize the table name to make it look like a class\n        name = table.capitalize()\n        # Define the class by instanciating the meta class to\n        # the given name (requires Forgetter to be new style)\n        forgetter = _Wrapper.__class__(name, (_Wrapper,), {})\n        # Register it\n        forgetters[name] = forgetter\n        forgetter._sqlTable = table\n        forgetter._sqlLinks = {}\n        forgetter._sqlFields = {}\n        forgetter._shortView = ()\n        forgetter._descriptions = {}\n        forgetter._userClasses = {}\n\n        # Get columns\n        curs.execute(\"SELECT * FROM %s LIMIT 1\" % table)\n        columns = [column[0] for column in curs.description]\n        # convert to dictionary and register in forgetter\n        for column in columns:\n            forgetter._sqlFields[column] = column\n\n    if getLinks:\n        # Try to find links between tables (!)\n        # Note the big O factor with this ...\n\n        for (tableName, forgetter) in forgetters.items():\n            for (key, column) in forgetter._sqlFields.items():\n                # A column refering to another table would most likely\n                # be called otherColumnID or just otherColumn. We'll\n                # lowercase below when performing the test.\n                possTable = re.sub(r'_?id$', '', column)\n\n                # all tables (ie. one of the forgetters) are candidates\n                foundLink = False\n                for candidate in forgetters.keys():\n                    if candidate.lower() == possTable.lower():\n                        if possTable.lower() == tableName.lower():\n                            # It's our own primary key!\n                            forgetter._sqlPrimary = (column,)\n                            break\n\n                        # Woooh! First - let's replace 'blapp_id' with 'blapp'\n                        # as the attribute name to indicate that it would\n                        # contain the Blapp instance, not just\n                        # some ID.\n                        del forgetter._sqlFields[key]\n                        forgetter._sqlFields[possTable] = column\n\n                        # And.. we'll need to know which class we refer to\n                        forgetter._userClasses[possTable] = candidate\n                        break # we've found our candidate\n\n    if code:\n        if code['module'] == \"MySQLdb\":\n            code['class'] = 'forgetSQL.MysqlForgetter'\n        else:\n            code['class'] = 'forgetSQL.Forgetter'\n        code['date'] = time.strftime('%Y-%m-%d')\n        print '''\n\"\"\"Database wrappers %(database)s\nAutogenerated by forgetsql-generate %(date)s.\n\"\"\"\n\nimport forgetSQL\n\n#import %(module)s\n\nclass _Wrapper(%(class)s):\n    \"\"\"Just a simple wrapper class so that you may\n    easily change stuff for all forgetters. Typically\n    this involves subclassing MysqlForgetter instead.\"\"\"\n\n    # Only save changes on .save()\n    _autosave = False\n\n    # Example database connection (might lack password)\n    #_dbModule = %(module)s\n    #_dbConnection = %(module)s.connect(%(connect)s)\n    #def cursor(cls):\n    #    return cls._dbConnection.cursor()\n    #cursor = classmethod(cursor)\n\n''' % code\n        items = forgetters.items()\n        items.sort()\n        for (name, forgetter) in items:\n            print \"class %s(_Wrapper):\" % name\n            for (key, value) in forgetter.__dict__.items():\n                if key.find('__') == 0:\n                    continue\n                nice = pprint.pformat(value)\n                # Get some indention\n                nice = nice.replace('\\n', '\\n             ' + ' '*len(key))\n                print '        %s = ' % key, nice\n            print \"\"\n        print '''\n\n# Prepare them all. We need to send in our local\n# namespace.\nforgetSQL.prepareClasses(locals())\n'''\n    else:\n        prepareClasses(forgetters)\n        return forgetters", "response": "Generates python code for the given list of tables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the ID of the current object.", "response": "def _setID(self, id):\n        \"\"\"Set the ID, ie. the values for primary keys.\n\n        id can be either a list, following the\n        _sqlPrimary, or some other type, that will be set\n        as the singleton ID (requires 1-length sqlPrimary).\n        \"\"\"\n        if type(id) in (types.ListType, types.TupleType):\n            try:\n                for key in self._sqlPrimary:\n                    value = id[0]\n                    self.__dict__[key] = value\n                    id = id[1:] # rest, go revursive\n            except IndexError:\n                raise 'Not enough id fields, required: %s' % len(self._sqlPrimary)\n        elif len(self._sqlPrimary) <= 1:\n            # It's a simple value\n            key = self._sqlPrimary[0]\n            self.__dict__[key] = id\n        else:\n            raise 'Not enough id fields, required: %s' % len(self._sqlPrimary)\n        self._new = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the ID values as a tuple annotated by sqlPrimary", "response": "def _getID(self):\n        \"\"\"Get the ID values as a tuple annotated by sqlPrimary\"\"\"\n        id = []\n        for key in self._sqlPrimary:\n            value = self.__dict__[key]\n            if isinstance(value, Forgetter):\n                # It's another object, we store only the ID\n                if value._new:\n                    # It's a new object too, it must be saved!\n                    value.save()\n                try:\n                    (value,) = value._getID()\n                except:\n                    raise \"Unsupported: Part %s of %s primary key is a reference to %s, with multiple-primary-key %s \" % (key, self.__class__, value.__class__, value)\n            id.append(value)\n        return id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _resetID(self):\n        # Dirty.. .=))\n        self._setID((None,) * len(self._sqlPrimary))\n        self._new = True", "response": "Reset all ID fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits a field from _sqlFields into table column.", "response": "def _checkTable(cls, field):\n        \"\"\"Split a field from _sqlFields into table, column.\n\n        Registers the table in cls._tables, and returns a fully\n        qualified table.column (default table: cls._sqlTable)\n        \"\"\"\n        # Get table part\n        try:\n            (table, field) = field.split('.')\n        except ValueError:\n            table = cls._sqlTable\n        # clean away white space\n        table = table.strip()\n        field = field.strip()\n        # register table\n        cls._tables[table] = None\n        # and return in proper shape\n        return table + '.' + field"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets all fields of the object to None.", "response": "def reset(self):\n        \"\"\"Reset all fields, almost like creating a new object.\n\n        Note: Forgets changes you have made not saved to database!\n        (Remember: Others might reference the object already, expecting\n        something else!) Override this method if you add properties not\n        defined in _sqlFields.\n        \"\"\"\n        self._resetID()\n        self._new = None\n        self._updated = None\n        self._changed = None\n        self._values = {}\n        # initially create fields\n        for field in self._sqlFields.keys():\n            self._values[field] = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, id=None):\n        if id is not None:\n            # We are asked to change our ID to something else\n            self.reset()\n            self._setID(id)\n        if not self._new and self._validID():\n            self._loadDB()\n        self._updated = time.time()", "response": "Load from database. Old values will be discarded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave to database if anything has changed since last load", "response": "def save(self):\n        \"\"\"Save to database if anything has changed since last load\"\"\"\n        if ( self._new or\n            (self._validID() and self._changed) or\n            (self._updated and self._changed > self._updated) ):\n            # Don't save if we have not loaded existing data!\n            self._saveDB()\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        (sql, ) = self._prepareSQL(\"DELETE\")\n        curs = self.cursor()\n        curs.execute(sql, self._getID())\n        curs.close()\n        self.reset()", "response": "Mark this object for deletion in the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _prepareSQL(cls, operation=\"SELECT\", where=None, selectfields=None, orderBy=None):\n        # Normalize parameter for later comparissions\n        operation = operation.upper()\n        # Convert where to a list if it is a string\n        if type(where) in (types.StringType, types.UnicodeType):\n            where = (where,)\n        if orderBy is None:\n            orderBy = cls._orderBy\n\n        if operation in ('SELECT', 'SELECTALL'):\n            # Get the object fields and sql fields in the same\n            # order to be able to reconstruct later.\n            fields = []\n            sqlfields = []\n            for (field, sqlfield) in cls._sqlFields.items():\n                if selectfields is None or field in selectfields:\n                    fields.append(field)\n                    sqlfields.append(sqlfield)\n            if not fields:\n                # dirrrrrty!\n                raise \"\"\"ERROR: No fields defined, cannot create SQL.\nMaybe sqlPrimary is invalid?\nFields asked: %s\nMy fields: %s\"\"\" % (selectfields, cls._sqlFields)\n\n            sql = \"SELECT\\n    \"\n            sql += ', '.join(sqlfields)\n            sql += \"\\nFROM\\n    \"\n            tables = cls._tables.keys()\n            if not tables:\n                raise \"REALITY ERROR: No tables defined\"\n            sql += ', '.join(tables)\n            tempWhere = [\"%s=%s\" % linkPair for linkPair in cls._sqlLinks]\n            # this MUST be here.\n            if operation <> 'SELECTALL':\n                for key in cls._sqlPrimary:\n                    tempWhere.append(cls._sqlFields[key] + \"=%s\")\n            if where:\n                tempWhere += where\n            if(tempWhere):\n                # Make sure to use paranteses in case someone has used\n                # ORs in the WHERE-list..\n                sql += \"\\nWHERE\\n (\"\n                sql += ') AND\\n    ('.join(tempWhere)\n                sql += ')'\n            if operation == 'SELECTALL' and orderBy:\n                sql += '\\nORDER BY\\n    '\n                if type(orderBy) in (types.TupleType, types.ListType):\n                    orderBy = [cls._sqlFields[x] for x in orderBy]\n                    orderBy = ',\\n     '.join(orderBy)\n                else:\n                    orderBy = cls._sqlFields[orderBy]\n                sql += orderBy\n            return (sql, fields)\n\n        elif operation in ('INSERT', 'UPDATE'):\n            if operation == 'UPDATE':\n                sql = 'UPDATE %s SET\\n    ' % cls._sqlTable\n            else:\n                sql = 'INSERT INTO %s (\\n    ' % cls._sqlTable\n\n            set = []\n            fields = []\n            sqlfields = []\n            for (field, sqlfield) in cls._sqlFields.items():\n                if operation == 'UPDATE' and field in cls._sqlPrimary:\n                    continue\n                if sqlfield.find(cls._sqlTable + '.') == 0:\n                    # It's a local field, chop of the table part\n                    sqlfield = sqlfield[len(cls._sqlTable)+1:]\n                    fields.append(field)\n                    sqlfields.append(sqlfield)\n                    set.append(sqlfield + '=%s')\n            if operation == 'UPDATE':\n                sql += ',\\n    '.join(set)\n                sql += '\\nWHERE\\n    '\n                tempWhere = []\n                for key in cls._sqlPrimary:\n                    tempWhere.append(cls._sqlFields[key] + \"=%s\")\n                    fields.append(key)\n                sql += ' AND\\n    '.join(tempWhere)\n            else:\n                sql += ',\\n    '.join(sqlfields)\n                sql += ')\\nVALUES (\\n    '\n                sql += ',\\n    '.join(('%s',) * len(sqlfields))\n                sql += ')'\n\n            return (sql, fields)\n\n        elif operation == 'DELETE':\n            sql = 'DELETE FROM ' + cls._sqlTable + ' WHERE '\n            if where:\n                sql += \" AND\\n    \".join(where)\n            else:\n                for key in cls._sqlPrimary:\n                    tempWhere = []\n                    for key in cls._sqlPrimary:\n                        tempWhere.append(cls._sqlFields[key] + \"=%s\")\n                sql += ' AND\\n    '.join(tempWhere)\n            return (sql, )\n        else:\n            raise \"Unknown operation\", operation", "response": "Return a SQL string for the given operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the next sequence number for insertion in the table.", "response": "def _nextSequence(cls, name=None):\n        \"\"\"Return a new sequence number for insertion in self._sqlTable.\n\n        Note that if your sequences are not named\n        tablename_primarykey_seq    (ie. for table 'blapp' with primary\n        key 'john_id', sequence name blapp_john_id_seq) you must give\n        the full sequence name as an optional argument to _nextSequence)\n        \"\"\"\n        if not name:\n            name = cls._sqlSequence\n        if not name:\n            # Assume it's tablename_primarykey_seq\n            if len(cls._sqlPrimary) <> 1:\n                raise \"Could not guess sequence name for multi-primary-key\"\n            primary = cls._sqlPrimary[0]\n            name = '%s_%s_seq' % (cls._sqlTable, primary.replace('.','_'))\n            # Don't have . as a tablename or column name! =)\n        curs = cls.cursor()\n        curs.execute(\"SELECT nextval('%s')\" % name)\n        value = curs.fetchone()[0]\n        curs.close()\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _loadFromRow(self, result, fields, cursor):\n        position = 0\n        for elem in fields:\n            value = result[position]\n            valueType = cursor.description[position][1]\n            if hasattr(self._dbModule, 'BOOLEAN') and \\\n                       valueType == self._dbModule.BOOLEAN and \\\n                       (value is not True or value is not False):\n                # convert to a python boolean\n                value = value and True or False\n            if value and self._userClasses.has_key(elem):\n                userClass = self._userClasses[elem]\n                # create an instance\n                value = userClass(value)\n\n            self._values[elem] = value\n            position += 1", "response": "Load from a database row described by fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _loadDB(self):\n        if not self._validID():\n            raise NotFound, self._getID()\n        (sql, fields) = self._prepareSQL(\"SELECT\")\n        curs = self.cursor()\n        curs.execute(sql, self._getID())\n        result = curs.fetchone()\n        if not result:\n            curs.close()\n            raise NotFound, self._getID()\n        self._loadFromRow(result, fields, curs)\n        curs.close()\n        self._updated = time.time()", "response": "Connect to the database to load myself"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _saveDB(self):\n        # We're a \"fresh\" copy now\n        self._updated = time.time()\n        if self._new:\n            operation = 'INSERT'\n            if not self._validID():\n                self._setID(self._nextSequence())\n            # Note that we assign this ID to our self\n            # BEFORE possibly saving any of our attribute\n            # objects that might be new as well. This means\n            # that they might have references to us, as long\n            # as the database does not require our existence\n            # yet.\n            #\n            # Since mysql does not have Sequences, this will\n            # not work as smoothly there. See class\n            # MysqlForgetter below.\n        else:\n            operation = 'UPDATE'\n        (sql, fields) = self._prepareSQL(operation)\n        values = []\n        for field in fields:\n            value = getattr(self, field)\n            # First some dirty datatype hacks\n            if DateTime and type(value) == DateTime.DateTimeType:\n                # stupid psycopg does not support it's own return type..\n                # lovely..\n                value = str(value)\n            if DateTime and type(value) == DateTime.DateTimeDeltaType:\n                # Format delta as days, hours, minutes seconds\n                # NOTE: includes value.second directly to get the\n                # whole floating number\n                value = value.strftime(\"%d %H:%M:\") + str(value.second)\n            if value is True or value is False:\n                # We must store booleans as 't' and 'f' ...\n                value = value and 't' or 'f'\n            if isinstance(value, Forgetter):\n                # It's another object, we store only the ID\n                if value._new:\n                    # It's a new object too, it must be saved!\n                    value.save()\n                try:\n                    (value,) = value._getID()\n                except:\n                    raise \"Unsupported: Can't reference multiple-primary-key: %s\" % value\n            values.append(value)\n        cursor = self.cursor()\n        cursor.execute(sql, values)\n        # cursor.commit()\n        cursor.close()\n        self._new = False\n        self._changed = None", "response": "Save the current object into the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve all the objects.", "response": "def getAll(cls, where=None, orderBy=None):\n        \"\"\"Retrieve all the objects.\n\n        If a list of ``where`` clauses are given, they will be AND-ed\n        and will limit the search.\n\n        This will not load everything out from the database, but will\n        create a large amount of objects with only the ID inserted.  The\n        data will be loaded from the objects when needed by the regular\n        load()-autocall.\n        \"\"\"\n        ids = cls.getAllIDs(where, orderBy=orderBy)\n        # Instansiate a lot of them\n        if len(cls._sqlPrimary) > 1:\n            return [cls(*id) for id in ids]\n        else:\n            return [cls(id) for id in ids]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getAllIterator(cls, where=None, buffer=100,\n                                         useObject=None, orderBy=None):\n        \"\"\"Retrieve every object as an iterator.\n\n        Possibly limitted by the where list of clauses that will be\n        AND-ed.\n\n        Since an iterator is returned, only ``buffer`` rows are loaded\n        from the database at once. This is useful if you need\n        to process all objects.\n\n        If useObject is given, this object is returned each time, but\n        with new data. This can be used to avoid creating many new\n        objects when only one object is needed each time.\n        \"\"\"\n        (sql, fields) = cls._prepareSQL(\"SELECTALL\", where, orderBy=orderBy)\n        curs = cls.cursor()\n        fetchedAt = time.time()\n        curs.execute(sql)\n\n        # We might start eating memory at this point\n\n        def getNext(rows=[]):\n            forgetter = cls\n            if not rows:\n                rows += curs.fetchmany(buffer)\n            if not rows:\n                curs.close()\n                return None\n            row = rows[0]\n            del rows[0]\n            try:\n                idPositions = [fields.index(key) for key in cls._sqlPrimary]\n            except ValueError:\n                raise \"Bad sqlPrimary, should be a list or tuple: %s\" % cls._sqlPrimary\n            ids = [row[pos] for pos in idPositions]\n            if useObject:\n                result = useObject\n                result.reset()\n                result._setID(ids)\n            else:\n                result = forgetter(*ids)\n            result._loadFromRow(row, fields, curs)\n            result._updated = fetchedAt\n            return result\n\n        return iter(getNext, None)", "response": "Retrieve every object in the database as an iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAllIDs(cls, where=None, orderBy=None):\n        (sql, fields) = cls._prepareSQL(\"SELECTALL\", where,\n                                        cls._sqlPrimary, orderBy=orderBy)\n        curs = cls.cursor()\n        curs.execute(sql)\n        # We might start eating memory at this point\n        rows = curs.fetchall()\n        curs.close()\n        result = []\n        idPositions = [fields.index(key) for key in cls._sqlPrimary]\n        for row in rows:\n            ids = [row[pos] for pos in idPositions]\n            if len(idPositions) > 1:\n                ids = tuple(ids)\n            else:\n                ids = ids[0]\n            result.append((ids))\n        return result", "response": "Retrive all the IDs possibly matching the where clauses."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a list of all possible instances of this class.", "response": "def getAllText(cls, where=None, SEPERATOR=' ', orderBy=None):\n        \"\"\"Retrieve a list of of all possible instances of this class.\n\n        The list is composed of tuples in the format (id, description) -\n        where description is a string composed by the fields from\n        cls._shortView, joint with SEPERATOR.\n        \"\"\"\n        (sql, fields) = cls._prepareSQL(\"SELECTALL\", where, orderBy=orderBy)\n        curs = cls.cursor()\n        curs.execute(sql)\n        # We might start eating memory at this point\n        rows = curs.fetchall()\n        curs.close()\n        result = []\n        idPositions = [fields.index(key) for key in cls._sqlPrimary]\n        shortPos = [fields.index(short) for short in cls._shortView]\n        for row in rows:\n            ids = [row[pos] for pos in idPositions]\n            if len(idPositions) > 1:\n                ids = tuple(ids)\n            else:\n                ids = ids[0]\n            text = SEPERATOR.join([str(row[pos]) for pos in shortPos])\n            result.append((ids, text))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the children of this object that links to me.", "response": "def getChildren(self, forgetter, field=None, where=None, orderBy=None):\n        \"\"\"Return the children that links to me.\n\n        That means that I have to be listed in their _userClasses\n        somehow. If field is specified, that field in my children is\n        used as the pointer to me. Use this if you have multiple fields\n        referring to my class.\n        \"\"\"\n        if type(where) in (types.StringType, types.UnicodeType):\n            where = (where,)\n\n        if not field:\n            for (i_field, i_class) in forgetter._userClasses.items():\n                if isinstance(self, i_class):\n                    field = i_field\n                    break # first one found is ok :=)\n        if not field:\n            raise \"No field found, check forgetter's _userClasses\"\n        sqlname = forgetter._sqlFields[field]\n        myID = self._getID()[0] # assuming single-primary !\n\n        whereList = [\"%s='%s'\" % (sqlname, myID)]\n        if where:\n            whereList.extend(where)\n        return forgetter.getAll(whereList, orderBy=orderBy)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the object to the database.", "response": "def _saveDB(self):\n        \"\"\"Overloaded - we don't have nextval() in mysql\"\"\"\n        # We're a \"fresh\" copy now\n        self._updated = time.time()\n        if self._new:\n            operation = 'INSERT'\n        else:\n            operation = 'UPDATE'\n        (sql, fields) = self._prepareSQL(operation)\n        values = []\n        for field in fields:\n            value = getattr(self, field)\n            if isinstance(value, Forgetter):\n                # It's another object, we store only the ID\n                if value._new:\n                    # It's a new object too, it must be saved!\n                    value.save()\n                try:\n                    (value,) = value._getID()\n                except:\n                    raise \"Can't reference multiple-primary-key: %s\" % value\n            values.append(value)\n        cursor = self.cursor()\n        cursor.execute(sql, values)\n        # cursor.commit()\n\n        if not self._validID():\n            if not len(self._getID()) == 1:\n                raise \"Can't retrieve auto-inserted ID for multiple-primary-key\"\n            # Here's the mysql magic to get the new ID\n            self._setID(cursor.insert_id())\n        cursor.close()\n        self._new = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hide_address(func):\n  @wraps(func)\n  def _impl(self, instance):\n    # We pop address field to avoid AttributeError on default Serializer.to_representation\n    if instance.hidden_address:\n      for i, field in enumerate(self._readable_fields):\n        if field.field_name == \"address\":\n          address = self._readable_fields.pop(i)\n\n      ret = func(self, instance)\n      self._readable_fields.insert(i, address) # Put address back\n\n      request = self.context[\"request\"]\n\n      # Check if user is organization member\n      is_organization_member = False\n      try:\n        if instance.organization is not None:\n          is_organization_member = (request.user in instance.organization.members.all())\n      except Organization.DoesNotExist: # pragma: no cover\n        pass\n\n\n      # Add address representation\n      if request.user == instance.owner or is_organization_member:\n        ret[\"address\"] = self.fields[\"address\"].to_representation(instance.address)\n      else:\n        ret[\"address\"] = None\n    else:\n      ret = func(self, instance)\n\n    return ret\n  return _impl", "response": "Decorator to hide the address field if the Project has hidden_address == True\n      It hides the address field if the Project has hidden_address == False\n      It is used to decorate Serializer. to_representation method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse to decorate Serializer.to_representation method. It sets the field \"current_user_is_applied\" if the user is applied to the project", "response": "def add_current_user_is_applied_representation(func):\n  \"\"\" Used to decorate Serializer.to_representation method.\n      It sets the field \"current_user_is_applied\" if the user is applied to the project\n  \"\"\"\n  @wraps(func)\n  def _impl(self, instance):\n    # We pop current_user_is_applied field to avoid AttributeError on default Serializer.to_representation\n    ret = func(self, instance)\n\n    user = self.context[\"request\"].user\n    applied = False\n    if not user.is_anonymous():\n      try:\n        applied = models.Apply.objects.filter(user=user, project=instance).count() > 0\n      except:\n        pass\n\n    ret[\"current_user_is_applied\"] = applied\n\n    return ret\n  return _impl"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uninstall_bash_completion(self, script_name=None, dest=\"~/.bashrc\"):\n        '''remove line to activate bash_completion for given script_name from given dest\n\n        You can use this for letting the user uninstall bash_completion::\n\n            from argdeco import command, main\n\n            @command(\"uninstall-bash-completion\",\n                arg('--dest', help=\"destination\", default=\"~/.bashrc\")\n            )\n            def uninstall_bash_completion(dest):\n                main.uninstall_bash_completion(dest=dest)\n        '''\n        if 'USERPROFILE' in os.environ and 'HOME' not in os.environ:\n            os.environ['HOME'] = os.environ['USERPROFILE']\n        dest = expanduser(dest)\n        if script_name is None:\n            script_name = sys.argv[0]\n        lines = []\n        remove_line = 'register-python-argcomplete %s' % script_name\n        with open(dest, 'r') as f:\n            for line in f:\n                if line.strip().startswith('#'):\n                    lines.append(line)\n                    continue\n\n                if remove_line in line: continue\n                lines.append(line)\n        with open(dest, 'w') as f:\n            f.write(''.join(lines))", "response": "uninstall bash_completion for given script_name from given dest"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef install_bash_completion(self, script_name=None, dest=\"~/.bashrc\"):\n        '''add line to activate bash_completion for given script_name into dest\n\n        You can use this for letting the user install bash_completion::\n\n            from argdeco import command, main\n\n            @command(\"install-bash-completion\",\n                arg('--dest', help=\"destination\", default=\"~/.bashrc\")\n            )\n            def install_bash_completion(dest):\n                main.install_bash_completion(dest=dest)\n\n        '''\n        if 'USERPROFILE' in os.environ and 'HOME' not in os.environ:\n            os.environ['HOME'] = os.environ['USERPROFILE']\n        dest = expanduser(dest)\n        if script_name is None:\n            script_name = sys.argv[0]\n\n        self.uninstall_bash_completion(script_name=script_name, dest=dest)\n        with open(dest, 'a') as f:\n            f.write('eval \"$(register-python-argcomplete %s)\"\\n' % script_name)", "response": "install bash_completion for given script_name into dest"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the arguments depending on the type of HTTP method.", "response": "def _fetch_arguments(handler, method):\n    \"\"\"Get the arguments depending on the type of HTTP method.\"\"\"\n\n    if method.__name__ == 'get':\n        arguments = {}\n        for key, value in six.iteritems(handler.request.arguments):\n            # Tornado supports comma-separated lists of values in\n            # parameters. We're undoing that here, and if a list\n            # is expected the _validate method can handle it.\n            if isinstance(value, list):\n                arguments[key] = ','.join(value)\n            else:\n                arguments[key] = value\n    else:  # post, put, patch, delete?\n        arguments = handler.get_post_arguments()\n\n    return arguments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply validators in sequence to a value.", "response": "def _apply_validator_chain(chain, value, handler):\n    \"\"\"Apply validators in sequence to a value.\"\"\"\n\n    if hasattr(chain, 'validate'):  # not a list\n        chain = [chain, ]\n\n    for validator in chain:\n        if hasattr(validator, 'validate'):\n            value = validator.validate(value, handler)\n        else:\n            raise web.HTTPError(500)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_arguments(self, method, parameters):\n\n    # TODO: Consider raising an exception if there are extra arguments.\n\n    arguments = _fetch_arguments(self, method)\n\n    arg_dict = {}\n    errors = []\n    for key, properties in parameters:\n        if key in arguments:\n            value = arguments[key]\n            try:\n                arg_dict[key] = _apply_validator_chain(\n                    properties.get('validators', []), value, self)\n            except validators.ValidationError as err:\n                errors.append(err)\n        else:\n            if properties.get('required', False):\n                raise web.HTTPError(\n                    400,\n                    ('Missing required parameter: %s'\n                     % (key, ))\n                    )\n            else:\n                if properties.get('default', None) is not None:\n                    arg_dict[key] = properties['default']\n                else:\n                    arg_dict[key] = None\n    if errors:\n        raise web.HTTPError(400, 'There were %s errors' % len(errors))\n\n    return arg_dict", "response": "Parse arguments to method returning a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove the checkerboard matrix over the main diagonal of the similarity matrix one sample at a time. :param kernel_type: :param thresh: :param similarity_matrix: :param kernel_width: the size of one quarter of the checkerboard matrix :return: peaks and convolution values", "response": "def checkerboard_matrix_filtering(similarity_matrix, kernel_width, kernel_type=\"default\", thresh=0.25):\n\n    \"\"\"\n    Moving the checkerboard matrix over the main diagonal of the similarity matrix one sample at a time.\n\n    :param kernel_type:\n    :param thresh:\n    :param similarity_matrix:\n    :param kernel_width: the size of one quarter of the checkerboard matrix\n    :return: peaks and convolution values\n    \"\"\"\n\n    checkerboard_matrix = get_checkerboard_matrix(kernel_width, kernel_type)\n\n    # The values calculated in this step are starting from the 'kernel_width' position and ending\n    # at length - kernel_width\n    d = []\n    for i in range(0, similarity_matrix.shape[0] - 2 * kernel_width):\n        base = similarity_matrix[i:i + kernel_width * 2, i:i + kernel_width * 2]\n        d.append(np.sum(np.multiply(base, checkerboard_matrix)))\n\n    # The missing values from 0 to kernel_width are calculated here\n    top_left_d = []\n    for i in range(0, kernel_width):\n        base = similarity_matrix[0:i + kernel_width, 0:i + kernel_width]\n        top_left_d.append(np.sum(np.multiply(base, checkerboard_matrix[kernel_width - i:, kernel_width - i:])))\n\n    # The missing kernel_width values at the bottom right are set to 0\n    convolution_values = top_left_d + d + [0 for i in range(0, kernel_width)]\n\n    # peaks = find_peaks_cwt(convolution_values, np.arange(1, peak_range))\n    peaks = peakutils.indexes(convolution_values, thres=thresh)\n\n    peaks = [0] + list(peaks) + [len(convolution_values)-1]\n    return peaks, convolution_values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the mode of the current user if it is in CONSOLE or STDOUT", "response": "def mode_assignment(arg):\n    \"\"\"\n    Translates arg to enforce proper assignment\n    \"\"\"\n    arg = arg.upper()\n    stream_args = ('STREAM', 'CONSOLE', 'STDOUT')\n    try:\n        if arg in stream_args:\n            return 'STREAM'\n        else:\n            return arg\n    except Exception:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_object(self, obj):\n        obj.save()\n        try:\n            save_object(obj, editor=self)\n        except DisciplineException:\n            pass", "response": "Save an object with Discipline\n        Only argument is a Django object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting an object with Discipline Only argument is a Django object. Analogous to Editor. save_object.", "response": "def delete_object(self, obj, post_delete=False):\n        \"\"\"Delete an object with Discipline\n\n        Only argument is a Django object. Analogous to Editor.save_object.\n        \"\"\"\n        # Collect related objects that will be deleted by cascading\n        links = [rel.get_accessor_name() for rel in \\\n                 obj._meta.get_all_related_objects()]\n        # Recursively delete each of them\n        for link in links:\n            objects = getattr(obj, link).all()\n            for o in objects:\n                self.delete_object(o, post_delete)\n        # Delete the actual object\n        self._delete_object(obj, post_delete)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _description(self):\n\n        inst = self.timemachine.presently\n\n        if self.action_type == \"dl\":\n            return \"Deleted %s\" % inst.content_type.name\n        elif self.action_type == \"cr\":\n            return \"Created %s\" % inst._object_type_html()\n        else:\n            return \"Modified %s\" % inst._object_type_html()", "response": "A concise html explanation of this Action."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_timemachine(self):\n        if not self.__timemachine:\n            self.__timemachine = TimeMachine(\n                self.object_uid,\n                step = self.id,\n            )\n\n        return self.__timemachine.at(self.id)", "response": "Return a TimeMachine for the object on which this action was \n        performed and at the time of this action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_is_revertible(self):\n\n        # If it was already reverted\n        if self.reverted:\n            return False\n\n        errors = []\n        inst = self.timemachine\n        \n        if inst.fields != inst.presently.fields or \\\n           inst.foreignkeys != inst.presently.foreignkeys:\n           self.__undo_errors = [\n               \"Cannot undo action %s. The database schema\"\n               \" for %s has changed\"\n                % (self.id,\n                   inst.content_type.name,)]\n           return False\n\n\n        if self.action_type in [\"dl\", \"md\"]:\n            # If undoing deletion, make sure it actually doesn't exist\n            if self.action_type == \"dl\" and inst.presently.exists:\n                errors.append(\n                    \"Cannot undo action %d: the %s you are trying to\"\n                    \" recreate already exists\"\n                    % (self.id,\n                       inst.content_type.name,))\n            # The only problem we can have by reversing this action\n            # is that some of its foreignkeys could be pointing to\n            # objects that have since been deleted.\n            check_here = inst.at_previous_action\n            for field in inst.foreignkeys:\n                fk = check_here.get_timemachine_instance(field)\n                # If the ForeignKey doesn't have a value\n                if not fk: continue\n                if not fk.exists:\n                    errors.append(\n                        \"Cannot undo action %s: the %s used to link to\"\n                        \" a %s that has since been deleted\"\n                        % (self.id,\n                           inst.content_type.name,\n                           fk.content_type.name,))\n\n        else: # self.action_type == \"cr\"\n            # Make sure it actually exists\n            if not self.timemachine.presently.exists:\n                errors.append(\n                    \"Cannot undo action %s: the %s you are trying\"\n                    \" to delete doesn't currently exist\"\n                    % (self.id, inst.content_type.name,))\n            # The only problem we can have by undoing this action is\n            # that it could have foreignkeys pointed to it, so deleting\n            # it will cause deletion of other objects\n            else:\n                links = [rel.get_accessor_name() \n                         for rel in \\\n                         inst.get_object()._meta.get_all_related_objects()]\n                for link in links:\n                    objects = getattr(inst.get_object(), link).all()\n                    for rel in objects:\n                        errors.append(\n                           \"Cannot undo action %s: you are trying to\"\n                           \" delete a %s that has a %s pointing to it\" %\n                           (self.id, \n                            inst.content_type.name,\n                            ContentType.objects.get_for_model(rel.__class__),))\n\n        self.__undo_errors = errors\n        return (len(errors) == 0)", "response": "Returns a boolean representing whether this Action is revertible or not."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef undo(self, editor):\n        inst = self.timemachine\n        if not self.is_revertible:\n            raise DisciplineException(\"You tried to undo a non-revertible action! \"\n                               \"Check action.is_revertible and action.undo_errors\"\n                               \" before trying to undo.\")\n\n        if self.action_type == \"dl\":\n            obj = inst.restore()\n            self.reverted = save_object(obj, editor)\n            self.save()\n        elif self.action_type == \"md\":\n            # Restore as it was *before* the modification\n            obj = inst.at_previous_action.restore()\n            self.reverted = save_object(obj, editor)\n            self.save()\n        else:\n            editor.delete_object(inst.get_object())\n            # This is safe from race conditions but still a pretty inelegant\n            # solution. I can't figure out a different way to find the last action\n            # for now\n            self.reverted = DeletionCommit.objects.filter(\n                object_uid = self.object_uid\n            ).order_by(\"-action__id\")[0].action\n            self.save()", "response": "Create a new Action that undos the effects of this one or more accurately reverts the object of this Action to the state\n            at which it was right before the Action took place."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning html saying whether this Action is reverted by another one or reverts another one.", "response": "def _status(self):\n        \"\"\"Return html saying whether this Action is reverted by another\n        one or reverts another one.\"\"\"\n        text = \"\"\n        # Turns out that is related field in null, Django\n        # doesn't even make it a property of the object\n        # http://code.djangoproject.com/ticket/11920\n        if hasattr(self, \"reverts\"):\n            text += '(reverts <a href=\"%s\">%s</a>)<br/>' % (\n                self.reverts.get_absolute_url(),\n                self.reverts.id\n            )\n        if self.reverted:\n            text += '(reverted in <a href=\"%s\">%s</a>)<br/>' % (\n                self.reverted.get_absolute_url(),\n                self.reverted.id\n            )\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _details(self, nohtml=False):\n        text = \"\"\n        inst = self.timemachine\n\n        # If deleted or created, show every field, otherwise only\n        # the modified\n        if self.action_type in (\"dl\",\"cr\",):\n            fields = inst.fields + inst.foreignkeys\n        else: fields = [i.key for i in self.modification_commits.all()]\n\n        for field in fields:\n            if not nohtml:\n                text += \"<strong>%s</strong>: \" % field\n            else:\n                text += \"%s: \" % field\n\n            # If modified, show what it was like one step earlier\n            if self.action_type == \"md\":\n                if not nohtml:\n                    text += \"%s &#8594; \" % \\\n                            inst.at_previous_action._field_value_html(field)\n                else:\n                    text += \"%s -> \" % \\\n                            inst.at_previous_action._field_value_text(field)\n\n            if not nohtml:\n                text += \"%s<br/>\" % inst._field_value_html(field)\n            else:\n                text += \"%s\\n\" % inst._field_value_text(field)\n\n        return text", "response": "Return the html representation of the Action."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the information of the object that doesn t change at different points in time", "response": "def __update_information(self):\n        \"\"\"Gether information that doesn't change at different points in\n        time\"\"\"\n\n        info = {}\n\n        info[\"actions_count\"] = Action.objects.count()\n        \n        info[\"creation_times\"] = []\n        info[\"deletion_times\"] = []\n\n        info[\"content_type\"] = None\n\n        # Find object type and when it was created\n\n        for ccommit in CreationCommit.objects.filter(object_uid=self.uid):\n            info[\"creation_times\"].append(ccommit.action.id)\n        info[\"creation_times\"].sort()\n\n        for dcommit in DeletionCommit.objects.filter(object_uid=self.uid):\n            info[\"deletion_times\"].append(dcommit.action.id)\n        info[\"deletion_times\"].sort()\n\n        try:\n            info[\"content_type\"] = ccommit.content_type\n        except NameError:\n            raise DisciplineException(\"You tried to make a TimeMachine out of\"\n                               \" an object that doesn't exist!\")\n\n        self.info = info\n\n        for key in info.keys():\n            setattr(self, key, info[key])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a TimeMachine for the same object at a different time.", "response": "def at(self, step):\n        \"\"\"Return a TimeMachine for the same object at a different time.\n\n        Takes an integer argument representing the id field of an Action.\n        Returns the TimeMachine at the time of that Action. (Less ambiguously:\n        at the time right after the Action.\n\n        \"\"\"\n        return TimeMachine(\n            self.uid,\n            step = step,\n            info = copy.deepcopy(self.info)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the last modcommit of the given field.", "response": "def _get_modcommit(self, key):\n        \"\"\"Return the last modcommit of the given field. If no\n        modcommit exists (for example after a migration that created\n        new fields) returns None.\n        \"\"\"\n        try:\n            return ModificationCommit.objects.filter(\n                object_uid = self.uid,\n                key = key,\n                action__id__lte = self.step\n            ).order_by(\"-action__id\")[0]\n        except IndexError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the value of a field.", "response": "def get(self, key):\n        \"\"\"Return the value of a field.\n        \n        Take a string argument representing a field name, return the value of\n        that field at the time of this TimeMachine. When restoring a \n        ForeignKey-pointer object that doesn't exist, raise \n        DisciplineException\n\n        \"\"\"\n        modcommit = self._get_modcommit(key)\n        if not modcommit: return None\n        # If this isn't a ForeignKey, then just return the value\n        if key not in self.foreignkeys:\n            return cPickle.loads(str(modcommit.value))\n        # If it is, then return the object instance\n        try:\n            return TimeMachine(uid = modcommit.value).get_object()\n        except self.content_type.DoesNotExist:\n            raise DisciplineException(\"When restoring a ForeignKey, the \" \\\n                \"%s %s was not found.\" % (self.content_type.name, self.uid))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a TimeMachine instance for a related object.", "response": "def get_timemachine_instance(self, key):\n        \"\"\"Return a TimeMachine for a related object.\n\n        Take a string argument representing a ForeignKey field name, find what\n        object was related to this one at the time of this TimeMachine and \n        return a TimeMachine for that related object.\n\n        \"\"\"\n        modcommit = self._get_modcommit(key)\n        if not modcommit: \n            return None\n        return TimeMachine(uid = modcommit.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the object of this TimeMachine", "response": "def get_object(self):\n        \"\"\"Return the object of this TimeMachine\"\"\"\n        return self.content_type.model_class().objects.get(uid = self.uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestores all of the object attributes to the attributes. Return the Django object.", "response": "def restore(self, nosave=False):\n        \"\"\"Restore all of the object attributes to the attributes. Return the\n        Django object.\n        \"\"\"\n        if self.exists:\n            obj = self.content_type.model_class().objects.get(uid=self.uid)\n        else:\n            obj = self.content_type.model_class()(uid=self.uid)\n        for field in self.fields + self.foreignkeys:\n            obj.__setattr__(field, self.get(field))\n        if not nosave: obj.save()\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the admin url of the object.", "response": "def url(self):\n        \"\"\"Return the admin url of the object.\"\"\"\n        return urlresolvers.reverse(\n            \"admin:%s_%s_change\" % (self.content_type.app_label,\n                                    self.content_type.model),\n            args = (self.get_object().uid,))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _object_type_html(self):\n\n        if self.exists:\n            return \"<a href=\\\"%s\\\">%s</a>\" % (self.url(), \n                                              self.content_type.name,)\n        else:\n            return \"<s>%s</s>\" % self.content_type.name", "response": "Return an html admin link with the object s type as text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _object_name_html(self):\n        if self.presently.exists:\n            url = self.url()\n            return \"<a href=\\\"%s\\\">%s</a>\" % (url,\n                                              unicode(self.get_object()),)\n        else:\n            return \"(deleted)\"", "response": "Return an html admin link with the object s name as text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _field_value_html(self, field):\n        if field in self.fields:\n            return unicode(self.get(field))\n        else:\n            return self.get_timemachine_instance(field)._object_name_html()", "response": "Return the html representation of the value of the given field"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _field_value_text(self, field):\n        if field in self.fields:\n            return unicode(self.get(field))\n        else:\n            return self.get_timemachine_instance(field)._object_name_text()", "response": "Return the html representation of the value of the given field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_for_content_type(self, ct):\n        try:\n            return json.loads(self.state)[ct.app_label][ct.model]\n        except KeyError:\n            return None", "response": "Return the schema for the given ContentType object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef html_state(self):\n        ret = \"\"\n        state = json.loads(self.state)\n        for (app, appstate) in state.items():\n            for (model, modelstate) in appstate.items():\n                ret += \"<p>%s.models.%s</p>\" % (app, model,)\n                ret += \"<ul>\"\n                for field in modelstate[\"fields\"] + [\"uid\"]:\n                    ret += \"<li>%s</li>\" % field\n                for fk in modelstate[\"foreignkeys\"]:\n                    ret += \"<li>%s (foreign key)</li>\" % fk\n                ret += \"</ul>\"\n        return ret", "response": "Display state in HTML format for the admin form."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting pitch roll and heading during the descent and ascent dive phases of dives from tag dta", "response": "def plot_prh_des_asc(p, r, h, asc, des):\n    '''Plot pitch, roll, and heading during the descent and ascent dive phases\n\n    Args\n    ----\n    p: ndarray\n        Derived pitch data\n    r: ndarray\n        Derived roll data\n    h: ndarray\n        Derived heading data\n    des: ndarray\n        boolean mask for slicing descent phases of dives from tag dta\n    asc: ndarray\n        boolean mask for slicing asccent phases of dives from tag dta\n    '''\n    import matplotlib.pyplot as plt\n    import numpy\n\n    from . import plotutils\n\n    # Convert boolean mask to indices\n    des_ind = numpy.where(des)[0]\n    asc_ind = numpy.where(asc)[0]\n\n    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex='col')\n\n    ax1.title.set_text('Pitch')\n    ax1 = plotutils.plot_noncontiguous(ax1, p, des_ind, _colors[0], 'descents')\n    ax1 = plotutils.plot_noncontiguous(ax1, p, asc_ind, _colors[1], 'ascents')\n\n    ax1.title.set_text('Roll')\n    ax2 = plotutils.plot_noncontiguous(ax2, r, des_ind, _colors[0], 'descents')\n    ax2 = plotutils.plot_noncontiguous(ax2, r, asc_ind, _colors[1], 'ascents')\n\n    ax1.title.set_text('Heading')\n    ax3 = plotutils.plot_noncontiguous(ax3, h, des_ind, _colors[0], 'descents')\n    ax3 = plotutils.plot_noncontiguous(ax3, h, asc_ind, _colors[1], 'ascents')\n\n    for ax in [ax1, ax2, ax3]:\n        ax.legend(loc=\"upper right\")\n\n    plt.ylabel('Radians')\n    plt.xlabel('Samples')\n\n    plt.show()\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting original and low - pass filtered PRH data.", "response": "def plot_prh_filtered(p, r, h, p_lf, r_lf, h_lf):\n    '''Plot original and low-pass filtered PRH data\n\n    Args\n    ----\n    p: ndarray\n        Derived pitch data\n    r: ndarray\n        Derived roll data\n    h: ndarray\n        Derived heading data\n    p_lf: ndarray\n        Low-pass filtered pitch data\n    r_lf: ndarray\n        Low-pass filtered roll data\n    h_lf: ndarray\n        Low-pass filtered heading data\n    '''\n    import numpy\n\n    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex='col')\n\n    #rad2deg = lambda x: x*180/numpy.pi\n\n    ax1.title.set_text('Pitch')\n    ax1.plot(range(len(p)), p, color=_colors[0], linewidth=_linewidth,\n            label='original')\n    ax1.plot(range(len(p_lf)), p_lf, color=_colors[1], linewidth=_linewidth,\n            label='filtered')\n\n    ax2.title.set_text('Roll')\n    ax2.plot(range(len(r)), r, color=_colors[2], linewidth=_linewidth,\n            label='original')\n    ax2.plot(range(len(r_lf)), r_lf, color=_colors[3], linewidth=_linewidth,\n            label='filtered')\n\n    ax3.title.set_text('Heading')\n    ax3.plot(range(len(h)), h, color=_colors[4], linewidth=_linewidth,\n            label='original')\n    ax3.plot(range(len(h_lf)), h_lf, color=_colors[5], linewidth=_linewidth,\n            label='filtered')\n\n    plt.ylabel('Radians')\n    plt.xlabel('Samples')\n    for ax in [ax1, ax2, ax3]:\n        ax.legend(loc=\"upper right\")\n\n    plt.show()\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots the swim speed during experimental indices", "response": "def plot_swim_speed(exp_ind, swim_speed):\n    '''Plot the swim speed during experimental indices\n\n    Args\n    ----\n    exp_ind: ndarray\n        Indices of tag data where experiment is active\n    swim_speed: ndarray\n        Swim speed data at sensor sampling rate\n    '''\n    import numpy\n\n    fig, ax = plt.subplots()\n\n    ax.title.set_text('Swim speed from depth change and pitch angle (m/s^2')\n    ax.plot(exp_ind, swim_speed, linewidth=_linewidth, label='speed')\n    ymax = numpy.ceil(swim_speed[~numpy.isnan(swim_speed)].max())\n    ax.set_ylim(0, ymax)\n    ax.legend(loc='upper right')\n\n    plt.show()\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, skey, sdesc,\n             sdict=None, loaders=None, merge=False, writeback=False):\n        '''\n        Loads a dictionary into current settings\n\n        :param skey:\n            Type of data to load. Is be used to reference the data \\\n            in the files sections within settings\n        :param sdesc:\n            Either filename of yaml-file to load or further description of \\\n            imported data when `sdict` is used\n        :param dict sdict:\n            Directly pass data as dictionary instead of loading \\\n            it from a yaml-file. \\\n            Make sure to set `skey` and `sdesc` accordingly\n        :param list loaders:\n            Append custom loaders to the YAML-loader.\n        :param merge:\n            Merge received data into current settings or \\\n            place it under `skey` within meta\n        :param writeback:\n            Write back loaded (and merged/imported) result back \\\n            to the original file. \\\n            This is used to generate the summary files\n        :returns:\n            The loaded (or directly passed) content\n\n        .. seealso:: |yaml_loaders|\n        '''\n\n        y = sdict if sdict else read_yaml(sdesc, add_constructor=loaders)\n        if y and isinstance(y, dict):\n            if not sdict:\n                self.__settings['files'].update({skey: sdesc})\n            if merge:\n                self.__settings = dict_merge(self.__settings, y)\n            else:\n                self.__settings[skey] = y\n            shell_notify(\n                'load %s data and %s it into settings' % (\n                    'got' if sdict else 'read',\n                    'merged' if merge else 'imported'\n                ),\n                more=dict(skey=skey, sdesc=sdesc,\n                          merge=merge, writeback=writeback),\n                verbose=self.__verbose\n            )\n        if writeback and y != self.__settings:\n            write_yaml(sdesc, self.__settings)\n        return y", "response": "Loads a dictionary into current settings and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode(stream, strict=True):\n    if not isinstance(stream, util.BufferedByteStream):\n        stream = util.BufferedByteStream(stream)\n\n    # read the version\n    version = stream.read(2)\n\n    if version != HEADER_VERSION:\n        raise pyamf.DecodeError('Unknown SOL version in header')\n\n    # read the length\n    length = stream.read_ulong()\n\n    if strict and stream.remaining() != length:\n        raise pyamf.DecodeError('Inconsistent stream header length')\n\n    # read the signature\n    signature = stream.read(10)\n\n    if signature != HEADER_SIGNATURE:\n        raise pyamf.DecodeError('Invalid signature')\n\n    length = stream.read_ushort()\n    root_name = stream.read_utf8_string(length)\n\n    # read padding\n    if stream.read(3) != PADDING_BYTE * 3:\n        raise pyamf.DecodeError('Invalid padding read')\n\n    decoder = pyamf.get_decoder(stream.read_uchar())\n    decoder.stream = stream\n\n    values = {}\n\n    while 1:\n        if stream.at_eof():\n            break\n\n        name = decoder.readString()\n        value = decoder.readElement()\n\n        # read the padding\n        if stream.read(1) != PADDING_BYTE:\n            raise pyamf.DecodeError('Missing padding byte')\n\n        values[name] = value\n\n    return (root_name, values)", "response": "Decodes a SOL stream. Lstrict ensures that the stream is as spec\n    compatible as possible."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode(name, values, strict=True, encoding=pyamf.AMF0):\n    encoder = pyamf.get_encoder(encoding)\n    stream = encoder.stream\n\n    # write the header\n    stream.write(HEADER_VERSION)\n\n    if strict:\n        length_pos = stream.tell()\n\n    stream.write_ulong(0)\n\n    # write the signature\n    stream.write(HEADER_SIGNATURE)\n\n    # write the root name\n    name = name.encode('utf-8')\n\n    stream.write_ushort(len(name))\n    stream.write(name)\n\n    # write the padding\n    stream.write(PADDING_BYTE * 3)\n    stream.write_uchar(encoding)\n\n    for n, v in values.iteritems():\n        encoder.serialiseString(n)\n        encoder.writeElement(v)\n\n        # write the padding\n        stream.write(PADDING_BYTE)\n\n    if strict:\n        stream.seek(length_pos)\n        stream.write_ulong(stream.remaining() - 4)\n\n    stream.seek(0)\n\n    return stream", "response": "Generates a SharedObject encoded stream based on the name and values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(name_or_file):\n    f = name_or_file\n    opened = False\n\n    if isinstance(name_or_file, basestring):\n        f = open(name_or_file, 'rb')\n        opened = True\n    elif not hasattr(f, 'read'):\n        raise ValueError('Readable stream expected')\n\n    name, values = decode(f.read())\n    s = SOL(name)\n\n    for n, v in values.iteritems():\n        s[n] = v\n\n    if opened is True:\n        f.close()\n\n    return s", "response": "Loads a NC object from a file or file - object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a SON object to a file or file - like object.", "response": "def save(sol, name_or_file, encoding=pyamf.AMF0):\n    \"\"\"\n    Writes a L{SOL} object to C{name_or_file}.\n\n    @param name_or_file: Name of file or file-object to write to.\n    @param encoding: AMF encoding type.\n    \"\"\"\n    f = name_or_file\n    opened = False\n\n    if isinstance(name_or_file, basestring):\n        f = open(name_or_file, 'wb+')\n        opened = True\n    elif not hasattr(f, 'write'):\n        raise ValueError('Writable stream expected')\n\n    f.write(encode(sol.name, sol, encoding=encoding).getvalue())\n\n    if opened:\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_once(self, timeout=0.01):\n        try:\n            event = self.recv(timeout)\n            if event:\n                event_t = event[0]\n                event_c = event[1]\n\n                if event_t == 'JOIN':\n                    self.on_join(event_c[0], event_c[1])\n                elif event_t == 'PART':\n                    self.on_part(event_c[0], event_c[1], event_c[2])\n                elif event_t == 'PRIVMSG':\n                    if event_c[1] in self.channels.keys():\n                        self.on_chanmsg(event_c[0], event_c[1], event_c[2])\n                    else:\n                        self.on_privmsg(event_c[0], event_c[2])\n                elif event_t == 'NOTICE':\n                    if event_c[1] in self.channels.keys():\n                        self.on_channotice(event_c[0], event_c[1], event_c[2])\n                    else:\n                        self.on_privnotice(event_c[0], event_c[2])\n                elif event_t == 'CTCP':\n                    if event_c[1] in self.channels.keys():\n                        self.on_chanctcp(event_c[0], event_c[1], event_c[2])\n                    else:\n                        self.on_privctcp(event_c[0], event_c[2])\n                elif event_t == 'CTCP_REPLY':\n                    self.on_ctcp_reply(event_c[0], event_c[2])\n                elif event_t == 'MODE':\n                    if event_c[0][0] == self.current_nick:\n                        self.on_umode(event_c[1])\n                    else:\n                        self.on_cmode(event_c[0], event_c[1], event_c[2])\n                elif event_t == 'KICK':\n                    self.on_kick(event_c[0], event_c[1], event_c[2], \\\n                    event_c[3])\n                elif event_t == 'INVITE':\n                    self.on_invite(event_c[0], event_c[2])\n                elif event_t == 'NICK':\n                    self.on_nick(event_c[0], event_c[1])\n                elif event_t == 'TOPIC':\n                    self.on_topic(event_c[0], event_c[1], event_c[2])\n                elif event_t == 'QUIT':\n                    self.on_quit(event_c[0], event_c[1])\n                elif event_t == 'LUSERS':\n                    self.on_lusers(event_c)\n                elif event_t == 'ERROR':\n                    self.on_error(event_c[0])\n                elif event_t == 'UNKNOWN':\n                    self.on_unknown(event_c[0])\n\n        except self.LurklibError as exception:\n            self.on_exception(exception)", "response": "Handles an event and calls it s handler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling events and calls their handler for infinity.", "response": "def mainloop(self):\n        \"\"\"\n        Handles events and calls their handler for infinity.\n        \"\"\"\n        while self.keep_going:\n            with self.lock:\n                if self.on_connect and not self.readable(2):\n                    self.on_connect()\n                    self.on_connect = None\n                if not self.keep_going:\n                    break\n                self.process_once()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef migrate_user(instance):\n    instance._resource.pop('verified', None)\n\n    if 'role' in instance._resource:\n        return instance\n\n    global_org = instance.organisations.pop('global', {})\n    instance.role = global_org.get('role', perch.User.roles.default.value)\n\n    return instance", "response": "Move User. organisations to top - level property and remove\n    verified flag"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_conf(filename):\n\n  f, ext = os.path.splitext(filename)\n  ext = ext.lower()\n\n  if ext == \"conf\" or ext == \"ini\":\n    # python config via config parser\n\n    config = ConfigParser()\n    config.optionxform=str\n    config.read(filename)\n    rv = {}\n    for section in config.sections():\n      rv[section] = {}\n      for key,value in config.items(section):\n        rv[section][key] = value.strip('\"').strip(\"'\").decode(\"string_escape\")\n    return rv\n  else:\n    # other type of config, use munge\n    if munge_config:\n      src = munge_config.parse_url(filename)\n      return src.cls().load(open(filename)).get(\"vodka\")\n    else:\n      raise Exception(\"'%s' type of config encountered, install munge\" % ext)", "response": "Return dict object for *. conf file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_cell(self, cell, coords, cell_mode=CellMode.cooked):\n    # pylint: disable=too-many-return-statements\n    if cell_mode == CellMode.cooked:\n      if cell.ctype == xlrd.XL_CELL_BLANK:\n        return None\n\n      if cell.ctype == xlrd.XL_CELL_BOOLEAN:\n        return cell.value\n\n      if cell.ctype == xlrd.XL_CELL_DATE:\n        if self.handle_ambiguous_date:\n          try:\n            return self._parse_date(cell.value)\n          except xlrd.xldate.XLDateAmbiguous:\n            return self.handle_ambiguous_date(cell.value)\n        else:\n          return self._parse_date(cell.value)\n\n      if cell.ctype == xlrd.XL_CELL_EMPTY:\n        return None\n\n      if cell.ctype == xlrd.XL_CELL_ERROR:\n        return cell.value\n\n      if cell.ctype == xlrd.XL_CELL_NUMBER:\n        return cell.value\n\n      if cell.ctype == xlrd.XL_CELL_TEXT:\n        return cell.value\n\n      raise ValueError(\"Unhandled cell type {0}\".format(cell.ctype))\n    else:\n      return cell", "response": "Parses a cell according to the cell. ctype."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merged_cell_ranges(self):\n    for rlo, rhi, clo, chi in self.raw_sheet.merged_cells:\n      yield ((clo, rlo), (chi, rhi))", "response": "Generates the sequence of cell ranges in the format of a merged cell."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_note(self, coords):\n    col, row = coords\n    note = self.raw_sheet.cell_note_map.get((row, col))\n    return note.text if note else None", "response": "Get the note for the cell at the given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_date(self, cell_value):\n    date_tuple = xlrd.xldate_as_tuple(cell_value, self.raw_sheet.book.datemode)\n    return self.tuple_to_datetime(date_tuple)", "response": "Attempts to parse a cell_value as a date."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reqfile(filepath):\n    result = []\n    import re\n    url_re = re.compile(\".+:.+#egg=(.+)\")\n    with open(filepath, \"r\") as f:\n        for line in f:\n            line = line.strip()\n            if not line or line.startswith(\"#\"):\n                continue\n            mo = url_re.match(line)\n            if mo is not None:\n                line = mo.group(1)\n            result.append(line)\n    return result", "response": "Turns a text file into a list of lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_args(cls):\n        cls.parser = argparse.ArgumentParser()\n        cls.parser.add_argument(\n            \"symbol\", help=\"Symbol for horizontal line\", nargs=\"*\")\n        cls.parser.add_argument(\n            \"--color\", \"-c\", help=\"Color of the line\", default=None, nargs=1)\n        cls.parser.add_argument(\n            \"--version\", \"-v\", action=\"version\", version=\"0.13\")\n\n        return cls.parser", "response": "Method to parse command line arguments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the command line arguments and run the script", "response": "def run_args(self):\n        \"\"\"\n        Pass in the parsed args to the script\n        \"\"\"\n        self.arg_parser = self._parse_args()\n        self.args = self.arg_parser.parse_args()\n        color_name = self.args.color\n        if color_name is not None:\n            color_name = color_name[0]\n        symbol = self.args.symbol\n        try:\n            self.tr(symbol, color_name)\n        except InvalidColorException:\n            print(\"Invalid Color Name!\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _term_size(self):\n        for fd in (0, 1, 2):\n            try:\n                return self._ioctl_GWINSZ(fd)\n            except:\n                pass\n        # try os.ctermid()\n        try:\n            fd = os.open(os.ctermid(), os.O_RDONLY)\n            try:\n                return self._ioctl_GWINSZ(fd)\n            finally:\n                os.close(fd)\n        except:\n            pass\n        # try `stty size`\n        try:\n            return tuple(int(x) for x in os.popen(\"stty size\", \"r\").read().split())\n        except:\n            pass\n        # try environment variables\n        try:\n            return tuple(int(os.getenv(var)) for var in (\"LINES\", \"COLUMNS\"))\n        except:\n            pass\n        # i give up. return default.\n        return (25, 80)", "response": "Method returns lines and columns according to terminal size"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd entry permanently to local cache.", "response": "def cache_add(self, resource_url, cache_id):\n        \"\"\"Add entry permanently to local cache.\n\n        Parameters\n        ----------\n        resource_url : string\n            Resource Url\n        cache_id : string\n            Unique cache identifier for resource\n        \"\"\"\n        # Add entry to cache index\n        self.cache[resource_url] = cache_id\n        # Write cache index content to database file\n        with open(self.db_file, 'w') as f:\n            for resource in self.cache:\n                f.write(resource + '\\t' + self.cache[resource] + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cache_clear(self):\n        # Delete content of local cache directory\n        for f in os.listdir(self.directory):\n            f = os.path.join(self.directory, f)\n            if os.path.isfile(f):\n                os.remove(f)\n            elif os.path.isdir(f):\n                shutil.rmtree(f)\n        # Empty cache index\n        self.cache = {}", "response": "Clear local cache by deleting all cached resources and their\n        downloaded files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_api_references(self, api_url=None):\n        # Get subject listing Url for SCO-API\n        if not api_url is None:\n            url = api_url\n        else:\n            url = self.api_url\n        # Check if API references are in local cache. If not send GET request\n        # and add the result to the local cache\n        if not url in self.apis:\n            self.apis[url] = sco.references_to_dict(\n                sco.JsonResource(url).json[sco.REF_LINKS]\n            )\n        return self.apis[url]", "response": "Get set of HATEOAS references for the given SCO - API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new experiment at the given SCO - API. Subject and image group reference existing resources at the SCO - API.", "response": "def experiments_create(self, name, subject_id, image_group_id, api_url=None, properties=None):\n        \"\"\"Create a new experiment at the given SCO-API. Subject and image\n        group reference existing resources at the SCO-API.\n\n        Parameters\n        ----------\n        name : string\n            User-defined name for experiment\n        subject_id : string\n            Unique identifier for subject at given SCO-API\n        image_group_id : string\n            Unique identifier for image group at given SCO-API\n        api_url : string, optional\n            Base Url of SCO-API where experiment will be created\n        properties : Dictionary, optional\n            Set of additional properties for created experiment. The given\n            experiment name will override an existing name property in this set.\n\n        Returns\n        -------\n        scoserv.ExperimentHandle\n            Handle for local copy of created experiment resource\n        \"\"\"\n        # Create experiment and return handle for created resource\n        return self.experiments_get(\n            ExperimentHandle.create(\n                self.get_api_references(api_url)[sco.REF_EXPERIMENTS_CREATE],\n                name,\n                subject_id,\n                image_group_id,\n                properties=properties\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets handle for experiment resource at given Url.", "response": "def experiments_get(self, resource_url):\n        \"\"\"Get handle for experiment resource at given Url.\n\n        Parameters\n        ----------\n        resource_url : string\n            Url for experiment resource at SCO-API\n\n        Returns\n        -------\n        scoserv.ExperimentHandle\n            Handle for local copy of experiment resource\n        \"\"\"\n        # Get resource directory, Json representation, active flag, and cache id\n        obj_dir, obj_json, is_active, cache_id = self.get_object(resource_url)\n        # Create experiment handle. Will raise an exception if resource is not\n        # in cache and cannot be downloaded.\n        experiment = ExperimentHandle(obj_json, self)\n        # Add resource to cache if not exists\n        if not cache_id in self.cache:\n            self.cache_add(resource_url, cache_id)\n        # Return experiment handle\n        return experiment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget list of experiment resources from a SCO - API.", "response": "def experiments_list(self, api_url=None, offset=0, limit=-1, properties=None):\n        \"\"\"Get list of experiment resources from a SCO-API.\n\n        Parameters\n        ----------\n        api_url : string, optional\n            Base Url of the SCO-API. Uses default API if argument not present.\n        offset : int, optional\n            Starting offset for returned list items\n        limit : int, optional\n            Limit the number of items in the result\n        properties : List(string)\n            List of additional object properties to be included for items in\n            the result\n\n        Returns\n        -------\n        List(scoserv.ResourceHandle)\n            List of resource handles (one per image group in the listing)\n        \"\"\"\n        # Get subject listing Url for given SCO-API and return the retrieved\n        # resource listing\n        return sco.get_resource_listing(\n            self.get_api_references(api_url)[sco.REF_EXPERIMENTS_LISTING],\n            offset,\n            limit,\n            properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload given data file as fMRI for given experiment with given Url. Returns the created fmri resource.", "response": "def experiments_fmri_create(self, experiment_url, data_file):\n        \"\"\"Upload given data file as fMRI for experiment with given Url.\n\n        Parameters\n        ----------\n        experiment_url : string\n            Url for experiment resource\n        data_file: Abs. Path to file on disk\n            Functional data file\n\n        Returns\n        -------\n        scoserv.FunctionalDataHandle\n            Handle to created fMRI resource\n        \"\"\"\n        # Get the experiment\n        experiment = self.experiments_get(experiment_url)\n        # Upload data\n        FunctionalDataHandle.create(\n            experiment.links[sco.REF_EXPERIMENTS_FMRI_CREATE],\n            data_file\n        )\n        # Get new fmri data handle and return it\n        return self.experiments_get(experiment_url).fmri_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets handle for functional fMRI resource at given Url.", "response": "def experiments_fmri_get(self, resource_url):\n        \"\"\"Get handle for functional fMRI resource at given Url.\n\n        Parameters\n        ----------\n        resource_url : string\n            Url for fMRI resource at SCO-API\n\n        Returns\n        -------\n        scoserv.FunctionalDataHandle\n            Handle for funcrional MRI data resource\n        \"\"\"\n        # Get resource directory, Json representation, active flag, and cache id\n        obj_dir, obj_json, is_active, cache_id = self.get_object(resource_url)\n        # Create image group handle. Will raise an exception if resource is not\n        # in cache and cannot be downloaded.\n        fmri_data = FunctionalDataHandle(obj_json, obj_dir)\n        # Add resource to cache if not exists\n        if not cache_id in self.cache:\n            self.cache_add(resource_url, cache_id)\n        # Return functional data handle\n        return fmri_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef experiments_predictions_create(self, model_id, name, api_url, arguments={}, properties=None):\n        # Create experiment and return handle for created resource\n        return self.experiments_predictions_get(\n            ModelRunHandle.create(\n                api_url,\n                model_id,\n                name,\n                arguments,\n                properties=properties\n            )\n        )", "response": "Create a new model run at the given SCO - API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef experiments_predictions_get(self, resource_url):\n        # Get resource directory, Json representation, active flag, and cache id\n        obj_dir, obj_json, is_active, cache_id = self.get_object(resource_url)\n        # Create model run handle. Will raise an exception if resource is not\n        # in cache and cannot be downloaded.\n        run = ModelRunHandle(obj_json, obj_dir, self)\n        # Add resource to cache if not exists\n        if not cache_id in self.cache:\n            self.cache_add(resource_url, cache_id)\n        # Return model run handle\n        return run", "response": "Get handle for model run resource at given Url."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets list of experiments run listing.", "response": "def experiments_predictions_list(self, listing_url, offset=0, limit=-1, properties=None):\n        \"\"\"Get list of experiment resources from a SCO-API.\n\n        Parameters\n        ----------\n        listing_url : string\n            url for experiments run listing.\n        offset : int, optional\n            Starting offset for returned list items\n        limit : int, optional\n            Limit the number of items in the result\n        properties : List(string)\n            List of additional object properties to be included for items in\n            the result\n\n        Returns\n        -------\n        List(scoserv.ModelRunDescriptor)\n            List of model run descriptors\n        \"\"\"\n        return sco.get_run_listing(\n            listing_url,\n            offset=offset,\n            limit=limit,\n            properties=properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_object(self, resource_url):\n        # Check if resource is in local cache. If not, create a new cache\n        # identifier and set is_cached flag to false\n        if resource_url in self.cache:\n            cache_id = self.cache[resource_url]\n        else:\n            cache_id = str(uuid.uuid4())\n        # The local cahce directory for resource is given by cache identifier\n        obj_dir = os.path.join(self.directory, cache_id)\n        # File for local copy of object's Json representation\n        f_json = os.path.join(obj_dir, '.json')\n        # Object active flag\n        is_active = True\n        # Read the remote resource representation\n        try:\n            obj_json = sco.JsonResource(resource_url).json\n            # Save local copy of Json object. Create local resource directory if\n            # it doesn't exist\n            if not os.path.isdir(obj_dir):\n                os.mkdir(obj_dir)\n            with open(f_json, 'w') as f:\n                json.dump(obj_json, f)\n        except ValueError as ex:\n            # If the resource does not exists but we have a local copy then read\n            # object from local disk. Set is_active flag to false. Raise\n            # ValueError if no local copy exists\n            if os.path.isfile(f_json):\n                with open(f_json, 'r') as f:\n                    obj_json = json.load(f)\n                is_active = False\n            else:\n                raise ex\n        # Return object directory, Json, active flag, and cache identifier\n        return obj_dir, obj_json, is_active, cache_id", "response": "Get remote resource information. Creates a local directory for the resource if this is the first access to the resource. Downloads the remote resource Json representation and writes it into a. json file in the local cache directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image_groups_create(self, filename, api_url=None, options=None, properties=None):\n        # Create image group and return handle for created resource\n        return self.image_groups_get(\n            ImageGroupHandle.create(\n                self.get_api_references(api_url)[sco.REF_IMAGE_GROUPS_CREATE],\n                filename,\n                options,\n                properties\n            )\n        )", "response": "Creates a new image group at given SCO - API by uploading local file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget handle for image group resource at given Url.", "response": "def image_groups_get(self, resource_url):\n        \"\"\"Get handle for image group resource at given Url.\n\n        Parameters\n        ----------\n        resource_url : string\n            Url for image group resource at SCO-API\n\n        Returns\n        -------\n        scoserv.ImageGroupHandle\n            Handle for local copy of image group resource\n        \"\"\"\n        # Get resource directory, Json representation, active flag, and cache id\n        obj_dir, obj_json, is_active, cache_id = self.get_object(resource_url)\n        # Create image group handle. Will raise an exception if resource is not\n        # in cache and cannot be downloaded.\n        image_group = ImageGroupHandle(obj_json, obj_dir)\n        # Add resource to cache if not exists\n        if not cache_id in self.cache:\n            self.cache_add(resource_url, cache_id)\n        # Return image group handle\n        return image_group"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget list of image group resources from a SCO - API.", "response": "def image_groups_list(self, api_url=None, offset=0, limit=-1, properties=None):\n        \"\"\"Get list of image group resources from a SCO-API.\n\n        Parameters\n        ----------\n        api_url : string, optional\n            Base Url of the SCO-API. Uses default API if argument not present.\n        offset : int, optional\n            Starting offset for returned list items\n        limit : int, optional\n            Limit the number of items in the result\n        properties : List(string)\n            List of additional object properties to be included for items in\n            the result\n\n        Returns\n        -------\n        List(scoserv.ResourceHandle)\n            List of resource handles (one per image group in the listing)\n        \"\"\"\n        # Get subject listing Url for given SCO-API and return the retrieved\n        # resource listing\n        return sco.get_resource_listing(\n            self.get_api_references(api_url)[sco.REF_IMAGE_GROUPS_LIST],\n            offset,\n            limit,\n            properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef models_get(self, resource_url):\n        # Get resource directory, Json representation, active flag, and cache id\n        obj_dir, obj_json, is_active, cache_id = self.get_object(resource_url)\n        # Create model handle.\n        model = ModelHandle(obj_json)\n        # Add resource to cache if not exists\n        if not cache_id in self.cache:\n            self.cache_add(resource_url, cache_id)\n        # Return subject handle\n        return model", "response": "Get handle for model resource at given Url."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of model resources from a SCO - API.", "response": "def models_list(self, api_url=None, offset=0, limit=-1, properties=None):\n        \"\"\"Get list of model resources from a SCO-API.\n\n        Parameters\n        ----------\n        api_url : string, optional\n            Base Url of the SCO-API. Uses default API if argument not present.\n        offset : int, optional\n            Starting offset for returned list items\n        limit : int, optional\n            Limit the number of items in the result\n        properties : List(string)\n            List of additional object properties to be included for items in\n            the result\n\n        Returns\n        -------\n        List(scoserv.ResourceHandle)\n            List of resource handles (one per model in the listing)\n        \"\"\"\n        # Get subject listing Url for given SCO-API and return the retrieved\n        # resource listing\n        return sco.get_resource_listing(\n            self.get_api_references(api_url)[sco.REF_MODELS_LIST],\n            offset,\n            limit,\n            properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an anatomy subject at given SCO - API by uploading local file.", "response": "def subjects_create(self, filename, api_url=None, properties=None):\n        \"\"\"Create new anatomy subject at given SCO-API by uploading local file.\n        Expects an tar-archive containing a FreeSurfer anatomy.\n\n        Parameters\n        ----------\n        filename : string\n            Path to tar-archive on local disk\n        api_url : string, optional\n            Base Url of SCO-API where subject will be created\n        properties : Dictionary, optional\n            Set of additional properties for created subject\n\n        Returns\n        -------\n        scoserv.SubjectHandle\n            Handle for local copy of created image group resource\n        \"\"\"\n        # Create image group and return handle for created resource\n        return self.subjects_get(\n            SubjectHandle.create(\n                self.get_api_references(api_url)[sco.REF_SUBJECTS_CREATE],\n                filename,\n                properties\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subjects_get(self, resource_url):\n        # Get resource directory, Json representation, active flag, and cache id\n        obj_dir, obj_json, is_active, cache_id = self.get_object(resource_url)\n        # Create subject handle. Will raise an exception if resource is not\n        # in cache and cannot be downloaded.\n        subject = SubjectHandle(obj_json, obj_dir)\n        # Add resource to cache if not exists\n        if not cache_id in self.cache:\n            self.cache_add(resource_url, cache_id)\n        # Return subject handle\n        return subject", "response": "Get handle for subject resource at given Url."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets list of subject resources from a SCO - API.", "response": "def subjects_list(self, api_url=None, offset=0, limit=-1, properties=None):\n        \"\"\"Get list of subject resources from a SCO-API.\n\n        Parameters\n        ----------\n        api_url : string, optional\n            Base Url of the SCO-API. Uses default API if argument not present.\n        offset : int, optional\n            Starting offset for returned list items\n        limit : int, optional\n            Limit the number of items in the result\n        properties : List(string)\n            List of additional object properties to be included for items in\n            the result\n\n        Returns\n        -------\n        List(scoserv.ResourceHandle)\n            List of resource handles (one per subject in the listing)\n        \"\"\"\n        # Get subject listing Url for given SCO-API and return the retrieved\n        # resource listing\n        return sco.get_resource_listing(\n            self.get_api_references(api_url)[sco.REF_SUBJECTS_LIST],\n            offset,\n            limit,\n            properties\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new disposable client.", "response": "def create_disposable(clientInfo, config = {}):\n    \"\"\"\n    Create a new disposable client.\n    \"\"\"\n    response = requests.put(\n        _format_url(\n            _extend(DEFAULT_CONFIG, config), \n            OAUTH2_ROOT + 'disposable'),\n        json = clientInfo)\n    \n    if response.status_code != 200:\n        return None\n    else:\n        body = response.json() \n        return Blotre({\n            'client_id': body['id'],\n            'client_secret': body['secret'],\n            'code': body['code']\n        }, config = config)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_existing_disposable_app(file, clientInfo, conf):\n    if not os.path.isfile(file):\n        return None\n    else:\n        data = None\n        with open(file, 'r') as f:\n            data = json.load(f)\n        if not 'client' in data or not 'creds' in data:\n            return None\n        return _BlotreDisposableApp(file,\n            data['client'],\n            creds = data['creds'],\n            config = conf)", "response": "Attempt to load an existing VEA app from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to redeem a one time code on the client.", "response": "def _try_redeem_disposable_app(file, client):\n    \"\"\"\n    Attempt to redeem a one time code registred on the client.\n    \"\"\"\n    redeemedClient = client.redeem_onetime_code(None)\n    if redeemedClient is None:\n        return None\n    else:\n        return _BlotreDisposableApp(file,\n            redeemedClient.client,\n            creds = redeemedClient.creds,\n            config = redeemedClient.config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_app_is_valid(client):\n    try:\n        if 'refresh_token' in client.creds:\n            client.exchange_refresh_token()\n        else:\n            existing.get_token_info()\n        return True\n    except TokenEndpointError as e:\n        return False", "response": "Check to see if the app has valid creds."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a disposable app.", "response": "def create_disposable_app(clientInfo, config={}):\n    \"\"\"\n    Use an existing disposable app if data exists or create a new one\n    and persist the data.\n    \"\"\"\n    file = _get_disposable_app_filename(clientInfo)\n    existing = _get_existing_disposable_app(file, clientInfo, config)\n    if existing:\n        if _check_app_is_valid(existing):\n            return existing\n        else:\n            print(\"Existing client has expired, must recreate.\")\n        \n    return _create_new_disposable_app(file, clientInfo, config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_creds(self, newCreds):\n        self.creds = newCreds\n        self.on_creds_changed(newCreds)\n        return self", "response": "Manually update the current creds."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a stream path into it s normalized form.", "response": "def normalize_uri(self, uri):\n        \"\"\"Convert a stream path into it's normalized form.\"\"\"\n        return urllib.quote(\n            re.sub(r\"\\s\", '+', uri.strip().lower()),\n            safe = '~@#$&()*!+=:),.?/\\'')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_authorization_url(self):\n        return self._format_url(\n            OAUTH2_ROOT + 'authorize',\n            query = {\n                'response_type': 'code',\n                'client_id': self.client.get('client_id', ''),\n                'redirect_uri': self.client.get('redirect_uri', '')\n            })", "response": "Get the authorization Url for the current client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbasing exchange of data for an access_token.", "response": "def _access_token_endpoint(self, grantType, extraParams={}):\n        \"\"\"\n        Base exchange of data for an access_token.\n        \"\"\"\n        response = requests.post(\n            self._format_url(OAUTH2_ROOT + 'access_token'),\n            data = _extend({\n                'grant_type': grantType,\n                'client_id': self.client.get('client_id', ''),\n                'client_secret': self.client.get('client_secret', ''),\n                'redirect_uri': self.client.get('redirect_uri', '')\n            }, extraParams))\n        \n        data = response.json()\n        if 'error' in data or 'error_description' in data:\n            raise _token_error_from_data(data)\n        else:\n            return self.set_creds(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_token_info(self):\n        response = requests.get(\n            self._format_url(OAUTH2_ROOT + 'token_info', {\n                'token': self.creds['access_token']\n            }))\n        data = response.json()\n        if response.status_code != 200:\n            raise _token_error_from_data(data)\n        else:\n            return data", "response": "Get information about the current access token."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_auth_headers(self, base):\n        if 'access_token' in self.creds:\n            return _extend(base, {\n                'authorization': 'Bearer ' + self.creds['access_token']\n            })\n        return base", "response": "Attach the acces_token to a request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the response was due to an expired access token.", "response": "def _is_expired_response(self, response):\n        \"\"\"\n        Check if the response failed because of an expired access token.\n        \"\"\"\n        if response.status_code != 401:\n            return False\n        challenge = response.headers.get('www-authenticate', '')\n        return 'error=\"invalid_token\"' in challenge"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_request(self, type, path, args, noRetry=False):\n        response = getattr(requests, type)(path, headers = self._add_auth_headers(_JSON_HEADERS), **args)\n        if response.status_code == 200 or response.status_code == 201:\n            return response.json()\n        elif not noRetry and self._is_expired_response(response) \\\n          and 'refresh_token' in self.creds:\n            try:\n                self.exchange_refresh_token()\n            except TokenEndpointError:\n                raise _rest_error_from_response(response)\n            return self._make_request(type, path, args, noRetry = True)\n        raise _rest_error_from_response(response)", "response": "Makes a request to Blotre. nco_cache_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_child(self, streamId, childId, options={}):\n        return self.get('stream/' + streamId + '/children/' + childId, options)", "response": "Get the child of a stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef options(self, parser, env=os.environ):\n        super(PerfDumpPlugin, self).options(parser, env=env)\n        parser.add_option(\"\", \"--perfdump-html\", dest=\"perfdump_html_file\",\n                          help=\"Set destination for HTML report output\")", "response": "Handle parsing additional command - line options"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring this plugin using the given options", "response": "def configure(self, options, conf):\n        \"\"\"Configure this plugin using the given options\"\"\"\n        super(PerfDumpPlugin, self).configure(options, conf)\n        if not self.enabled:\n            return\n        try:\n            self.html_output_file = options.perfdump_html_file\n        except:\n            pass\n        self.db = SqliteConnection.get(self.database_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays the slowest setups and tests and writes the HTML report to the given stream.", "response": "def report(self, stream):\n        \"\"\"Displays the slowest tests\"\"\"\n        self.db.commit()\n\n        stream.writeln()\n        self.draw_header(stream, \"10 SLOWEST SETUPS\")\n        self.display_slowest_setups(stream)\n\n        stream.writeln()\n        self.draw_header(stream, \"10 SLOWEST TESTS\")\n        self.display_slowest_tests(stream)\n        stream.writeln()\n\n        if self.html_output_file:\n            HtmlReport.write(self.html_output_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndrawing a header with underline", "response": "def draw_header(self, stream, header):\n        \"\"\"Draw header with underline\"\"\"\n        stream.writeln('=' * (len(header) + 4))\n        stream.writeln('| ' + header + ' |')\n        stream.writeln('=' * (len(header) + 4))\n        stream.writeln()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of words that are found in the text.", "response": "def find(self, sought, view='lemma'):\n        '''\n        Returns a word instance for the hit if the \"sought\" word is found in the text.\n        Per default the \"lemma\" view of the words is compared.\n        You can specify the desired view with the optional \"view\" option.\n        '''\n        hits = []\n        for sentence in self._sentences:\n            hits += sentence.find(sought, view)\n        return hits"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(self, sought, view='lemma'):\n        '''\n        Returns a word instance for the hit if the \"sought\" word is found in the sentence.\n        Per default the \"lemma\" view of the words is compared.\n        You can specify the desired view with the optional \"view\" option.\n        '''\n        for word in self.wordlist:\n            if sought == word.views[view]:\n                yield word", "response": "Yields a word instance for the hit if the sought word is found in the sentence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef word(self, position):\n        '''\n        Returns the word instance at the given position in the sentence, None if not found.\n        '''\n        if 0 <= position < len(self.wordlist):\n            return self.wordlist[position]\n        else:\n            log.warn('position \"{}\" is not in sentence of length \"{}\"!'.format(position, len(self.wordlist)))\n            raise IndexError()", "response": "Returns the word instance at the given position in the sentence None if not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subsentence(self):\n        '''\n        Returns the subsentence that contains this word, otherwise the whole sentence.\n        TODO\n        '''\n        subsentence = []\n        for word in self.sentence()[:self._position:-1]:\n            # left search\n            pass\n        for word in self.sentence()[:self._position]:\n            # right search\n            pass", "response": "Returns the subsentence that contains this word otherwise the whole sentence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef neighbors(self):\n        '''\n        Returns the left and right neighbors as Word instance.\n        If the word is the first one in the sentence only the right neighbor is returned and vice versa.\n        '''\n        if len(self._sentence) == 1:\n            return {\n                'left': None,\n                'right': None\n            }\n        else:\n            p = self._position\n            if -1 < p < len(self._sentence):\n                if 0 == self._position:\n                    return {\n                        'left': None,\n                        'right': self._sentence.word(p+1)\n                    }\n                elif 0 < self._position < len(self._sentence) - 1:\n                    return {\n                        'left':  self._sentence.word(p-1),\n                        'right': self._sentence.word(p+1)\n                    }\n                else:\n                    return {\n                        'left': self._sentence.word(p-1),\n                        'right': None\n                    }\n            else:\n                raise IndexError()", "response": "Returns the left and right neighbors as Word instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hrepr_with_resources(self, obj, **cfg):\n        res = self(obj, **cfg)\n        res.resources = self.resources\n        return res", "response": "This is equivalent to hrepr but adds the resources to the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef acquire_resources(self, source):\n        if source not in self.consulted:\n            self.consulted.add(source)\n            if isinstance(source, Tag):\n                res = source\n            else:\n                res = source(self.H)\n            if res is None:\n                res = set()\n            elif isinstance(res, (list, tuple)):\n                res = set(res)\n            elif isinstance(res, Tag):\n                res = {res}\n            self.resources |= res", "response": "Store the resources returned by source."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the standard representation of an object.", "response": "def stdrepr(self, obj, *, cls=None, tag='span'):\n        \"\"\"\n        Standard representation for objects, used when there is no\n        handler for its type in type_handlers on the HRepr object,\n        and no __hrepr__ method on obj. For an object of class 'klass',\n        the result is:\n\n        ``<span class=\"hrepr-klass\">{escape(str(obj))}</span>``\n\n        Where ``{escape(str(obj))}`` is the HTML-escaped string representation\n        of the object.\n\n        Args:\n            obj: The object to represent.\n            cls (optional): The class name for the representation. If None,\n                stdrepr will use ``'hrepr-' + obj.__class__.___name__``\n            tag (optional): The tag for the representation, defaults to\n                'span'.\n        \"\"\"\n        if cls is None:\n            cls = f'hrepr-{obj.__class__.__name__}'\n        return getattr(self.H, tag)[cls](str(obj))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stdrepr_short(self, obj, *, cls=None, tag='span'):\n        cls_name = obj.__class__.__name__\n        if cls is None:\n            cls = f'hrepr-short-{cls_name}'\n        return getattr(self.H, tag)[cls](f'<{cls_name}>')", "response": "Return the standard short representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stdrepr_iterable(self, obj, *,\n                         cls=None, before=None, after=None):\n        \"\"\"\n        Helper function to represent iterables. StdHRepr calls this on\n        lists, tuples, sets and frozensets, but NOT on iterables in general.\n        This method may be called to produce custom representations.\n\n        Arguments:\n            obj (iterable): The iterable to represent.\n            cls (optional): The class name for the representation. If None,\n                stdrepr will use ``'hrepr-' + obj.__class__.___name__``\n            before (optional): A string or a Tag to prepend to the elements.\n            after (optional): A string or a Tag to append to the elements.\n        \"\"\"\n        if cls is None:\n            cls = f'hrepr-{obj.__class__.__name__}'\n        children = [self(a) for a in obj]\n        return self.titled_box((before, after), children, 'h', 'h')[cls]", "response": "Returns the standard representation of the given iterable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch a MySQL CLI session for the specified IPS installation.", "response": "def cli(ctx, dname, site):\n    \"\"\"\n    Launches a MySQL CLI session for the database of the specified IPS installation.\n    \"\"\"\n    assert isinstance(ctx, Context)\n    log = logging.getLogger('ipsv.mysql')\n\n    dname = domain_parse(dname).hostname\n    domain = Session.query(Domain).filter(Domain.name == dname).first()\n\n    # No such domain\n    if not domain:\n        click.secho('No such domain: {dn}'.format(dn=dname), fg='red', bold=True, err=True)\n        return\n\n    site_name = site\n    site = Site.get(domain, site_name)\n\n    # No such site\n    if not site:\n        click.secho('No such site: {site}'.format(site=site_name), fg='red', bold=True, err=True)\n        return\n\n    # Connect to the MySQL database and exit\n    log.info('Connecting to MySQL database: {db}'.format(db=site.db_name))\n    log.debug('MySQL host: {host}'.format(host=site.db_host))\n    log.debug('MySQL username: {user}'.format(user=site.db_user))\n    log.debug('MySQL password: {pwd}'.format(pwd=site.db_pass))\n\n    os.execl(\n        '/usr/bin/mysql',\n        '/usr/bin/mysql',\n        '--database={db}'.format(db=site.db_name),\n        '--user={user}'.format(user=site.db_user),\n        '--password={pwd}'.format(pwd=site.db_pass)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef target_query(plugin, port, location):\n    return ((r.row[PLUGIN_NAME_KEY] == plugin) &\n            (r.row[PORT_FIELD] == port) &\n            (r.row[LOCATION_FIELD] == location))", "response": "prepared ReQL for target"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a set of EnumValue objects with specified names and optionally orders.", "response": "def enums(*names):\n    \"\"\"Returns a set of `EnumValue` objects with specified names and optionally orders.\n\n    Values in an enumeration must have unique names and be either all ordered or all unordered.\n\n    \"\"\"\n    if len(names) != len(list(set(names))):\n        raise TypeError(\"Names in an enumeration must be unique\")\n\n    item_types = set(True if isinstance(x, tuple) else False for x in names)\n    if len(item_types) == 2:\n        raise TypeError(\"Mixing of ordered and unordered enumeration items is not allowed\")\n    else:\n        is_ordered = item_types.pop() is True\n        if not is_ordered:\n            names = [(None, x) for x in names]\n        return [EnumValue(name, order) for order, name in names]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngo defer style cleanups--in reality, just a convenience wrapper over try-finally", "response": "def deferred_cleanup(fn):\n    \"\"\"Go defer style cleanups--in reality, just a convenience wrapper over try-finally\"\"\"\n    @functools.wraps(fn)\n    def ret(*args, **kwargs):\n        defers = []\n        try:\n            ret = fn(lambda *args: defers.extend(args), *args, **kwargs)\n        finally:\n            for defer in reversed(defers):\n                defer()\n        return ret\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, args=None):\n        # TODO: Add tests to how command line arguments are passed in\n        raw_args = self.__parser.parse_args(args=args)\n        args = vars(raw_args)\n        cmd = args.pop('cmd')\n        if hasattr(cmd, '__call__'):\n            cmd(**args)", "response": "Applicatin starting point.\n\n        This will run the associated method/function/module or print a help\n        list if it's an unknown keyword or the syntax is incorrect.\n\n        Keyword arguments:\n        args -- Custom application arguments (default sys.argv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a human readable time string into seconds.", "response": "def to_seconds(string):\n    \"\"\"\n    Converts a human readable time string into seconds.\n\n    Accepts:\n    - 's': seconds\n    - 'm': minutes\n    - 'h': hours\n    - 'd': days\n\n    Examples:\n    >>> to_seconds('1m30s')\n    90\n    >>> to_seconds('5m')\n    300\n    >>> to_seconds('1h')\n    3600\n    >>> to_seconds('1h30m')\n    5400\n    >>> to_seconds('3d')\n    259200\n    >>> to_seconds('42x')\n    Traceback (most recent call last):\n     ...\n    ValueError\n    \"\"\"\n\n    units = {\n        's': 1,\n        'm': 60,\n        'h': 60 * 60,\n        'd': 60 * 60 * 24\n    }\n\n    match = re.search(r'(?:(?P<d>\\d+)d)?(?:(?P<h>\\d+)h)?(?:(?P<m>\\d+)m)?(?:(?P<s>\\d+)s)?', string)\n\n    if not match or not any(match.groups()):\n        raise ValueError\n\n    total = 0\n    for unit, seconds in units.iteritems():\n        if match.group(unit) is not None:\n            total += int(match.group(unit)) * seconds\n\n    return total"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef slice_reStructuredText(input, output):\n\n    LOGGER.info(\"{0} | Slicing '{1}' file!\".format(slice_reStructuredText.__name__, input))\n    file = File(input)\n    file.cache()\n\n    slices = OrderedDict()\n    for i, line in enumerate(file.content):\n        search = re.search(r\"^\\.\\. \\.(\\w+)\", line)\n        if search:\n            slices[search.groups()[0]] = i + SLICE_ATTRIBUTE_INDENT\n\n    index = 0\n    for slice, slice_start in slices.iteritems():\n        slice_file = File(os.path.join(output, \"{0}.{1}\".format(slice, OUTPUT_FILES_EXTENSION)))\n        LOGGER.info(\"{0} | Outputing '{1}' file!\".format(slice_reStructuredText.__name__, slice_file.path))\n        slice_end = index < (len(slices.values()) - 1) and slices.values()[index + 1] - SLICE_ATTRIBUTE_INDENT or \\\n                    len(file.content)\n\n        for i in range(slice_start, slice_end):\n            skip_line = False\n            for item in CONTENT_DELETION:\n                if re.search(item, file.content[i]):\n                    LOGGER.info(\"{0} | Skipping Line '{1}' with '{2}' content!\".format(slice_reStructuredText.__name__,\n                                                                                       i,\n                                                                                       item))\n                    skip_line = True\n                    break\n\n            if skip_line:\n                continue\n\n            line = file.content[i]\n            for pattern, value in STATEMENT_SUBSTITUTE.iteritems():\n                line = re.sub(pattern, value, line)\n\n            search = re.search(r\"-  `[\\w ]+`_ \\(([\\w\\.]+)\\)\", line)\n            if search:\n                LOGGER.info(\"{0} | Updating Line '{1}' link: '{2}'!\".format(slice_reStructuredText.__name__,\n                                                                            i,\n                                                                            search.groups()[0]))\n                line = \"-  :ref:`{0}`\\n\".format(search.groups()[0])\n            slice_file.content.append(line)\n\n        slice_file.write()\n        index += 1\n\n    return True", "response": "Slice a reStructuredText file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx, dname, site):\n    assert isinstance(ctx, Context)\n\n    dname = domain_parse(dname).hostname\n    domain = Session.query(Domain).filter(Domain.name == dname).first()\n    if not domain:\n        click.secho('No such domain: {dn}'.format(dn=dname), fg='red', bold=True, err=True)\n        return\n\n    site_name = site\n    site = Site.get(domain, site_name)\n    if not site:\n        click.secho('No such site: {site}'.format(site=site_name), fg='red', bold=True, err=True)\n        return\n\n    p = Echo('Constructing paths and configuration files...')\n    site.enable()\n    p.done()\n\n    # Restart Nginx\n    p = Echo('Restarting web server...')\n    FNULL = open(os.devnull, 'w')\n    subprocess.check_call(['service', 'nginx', 'restart'], stdout=FNULL, stderr=subprocess.STDOUT)\n    p.done()", "response": "Enable the site under the specified domain"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute the read command.", "response": "def read(self, cmd_args):\n\t\n\t\t\"\"\"\n\t\tExecute Vagrant read command.\n\t\t\n\t\t:param list cmd_args:\n\t\t   Command argument list.\n\t\t\"\"\"\n\t\t\n\t\targs = [\n\t\t\t\"vagrant\",\n\t\t\t\"--machine-readable\"\n\t\t]\n\t\targs.extend(cmd_args)\n\t\tproc = subprocess.Popen(args, stdout=subprocess.PIPE)\n\t\tfor line in proc.stdout.readlines():\n\t\t\tif len(line) == 0:\n\t\t\t\tbreak\n\t\t\tyield line.decode(\"UTF-8\").rsplit(\",\")\n\t\tproc.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes Vagrant write command.", "response": "def write(self, cmd_args):\n\t\n\t\t\"\"\"\n\t\tExecute Vagrant write command.\n\t\t\n\t\t:param list cmd_args:\n\t\t   Command argument list.\n\t\t\"\"\"\n\t\t\n\t\targs = [\n\t\t\t\"vagrant\"\n\t\t]\n\t\targs.extend(cmd_args)\n\t\tsubprocess.call(args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the current box is available for the calling user.", "response": "def available(self, context):\n\t\n\t\t\"\"\"\n\t\tBox is available for the calling user.\n\t\t\n\t\t:param resort.engine.execution.Context context:\n\t\t   Current execution context.\n\t\t\"\"\"\n\t\t\n\t\tif self.__available is None:\n\t\t\tavail = False\n\t\t\tname = context.resolve(self.__name)\n\t\t\tfor box in self.__box_list():\n\t\t\t\tif box[\"name\"] == name and box[\"version\"] == \"0\":\n\t\t\t\t\tavail = True\n\t\t\t\t\tbreak\n\t\t\tself.__available = avail\n\t\treturn self.__available"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, context):\n\t\n\t\t\"\"\"\n\t\tAdd Vagrant box to the calling user.\n\t\t\n\t\t:param resort.engine.execution.Context context:\n\t\t   Current execution context.\n\t\t\"\"\"\n\t\t\n\t\tself.write([\n\t\t\t\"box\",\n\t\t\t\"add\",\n\t\t\t\"--name\", context.resolve(self.__name),\n\t\t\tself.__path(context)\n\t\t])", "response": "Insert a new Vagrant box to the calling user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes Vagrant read command on instance placed into configuration directory.", "response": "def read(self, context, cmd_args):\n\t\n\t\t\"\"\"\n\t\tExecute Vagrant read command on instance placed into configuration\n\t\tdirectory.\n\t\t\n\t\t:param resort.engine.execution.Context context:\n\t\t   Current execution context.\n\t\t:param list cmd_args:\n\t\t   Command argument list.\n\t\t\"\"\"\n\t\t\n\t\ttry:\n\t\t\tcurrent_dir = os.getcwd()\n\t\t\tos.chdir(context.resolve(self.__config_dir))\n\t\t\targs = []\n\t\t\targs.extend(cmd_args)\n\t\t\targs.append(context.resolve(self.__name))\n\t\t\tyield from super().read(args)\n\t\tfinally:\n\t\t\tos.chdir(current_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the state of the instance.", "response": "def state(self, context):\n\t\n\t\t\"\"\"\n\t\tGet instance state.\n\t\t\n\t\t:param resort.engine.execution.Context context:\n\t\t   Current execution context.\n\t\t:rtype:\n\t\t   str\n\t\t:return:\n\t\t   Instance state name.\n\t\t\"\"\"\n\t\t\n\t\tstate = None\n\t\tfor line in self.read(context, [\n\t\t\t\"status\",\n\t\t\tcontext.resolve(self.__name)\n\t\t]):\n\t\t\tif line[2] == \"state\":\n\t\t\t\tstate = line[3].strip()\n\t\treturn state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef available(self, context):\n\t\n\t\t\"\"\"\n\t\tCheck availability.\n\t\t\n\t\t:param resort.engine.execution.Context context:\n\t\t   Current execution context.\n\t\t:rtype:\n\t\t   bool\n\t\t:return:\n\t\t   Availability value.\n\t\t\"\"\"\n\t\tif self.__available is None:\n\t\t\tstate = self.__inst.state(context)\n\t\t\tself.__available = state is not None and state != \"not_created\"\n\t\treturn self.__available", "response": "Returns True if the current execution context is available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self):\n        response = requests.get(self.URL, cookies=self.cookiejar)\n        self.log.debug('Response code: %s', response.status_code)\n        if response.status_code != 200:\n            raise HtmlParserError\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        com_pattern = re.compile('\\((.+)\\)')\n\n        package_list = soup.find('ul', {'id': 'package_list'})\n        package_items = package_list.find_all('li')\n\n        licenses = []\n        for item in package_items:\n            div = item.find('div', {'class': 'product_info'})\n            a = div.find('a')\n            licenses.append(\n                LicenseMeta(\n                    div.find('span', {'class': 'desc'}).text,\n                    a.get('href'),\n                    com_pattern.search(a.text).group(1)\n                )\n            )\n\n        return licenses", "response": "Fetch all licenses associated with our account"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting courses from a user.", "response": "def courses(self) -> list:\n        \"\"\"\n        \u53d6\u5f97\u8ab2\u7a0b\u5217\u8868\n        \"\"\"\n        try:\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/Login', timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u53d6\u51fa\u8ab2\u7a0b\u540d\u7a31\n            result = []\n            for tag in soup.find_all('font'):\n                result.append(tag.get_text())\n            # \u56de\u50b3\u7d50\u679c\n            return result\n\n        except requests.exceptions.Timeout:\n            return [\"Timeout\"]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef active(self) -> bool:\n        try:\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/TopMenu', timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u56de\u50b3\u662f\u5426\u70ba\u767b\u5165\u6210\u529f\u624d\u770b\u5f97\u5230\u7684\u7db2\u9801\n            return soup.find('a').get_text().strip() == '\u7dda\u4e0a\u8003\u8a66'\n\n        except requests.exceptions.Timeout:\n            return None", "response": "Check if the user is active"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlogging-in to the Alerting API.", "response": "def login(self, username: str, password: str, course: int) -> requests.Response:\n        \"\"\"\n        \u767b\u5165\u8ab2\u7a0b\n        \"\"\"\n        try:\n            # \u64cd\u4f5c\u6240\u9700\u8cc7\u8a0a\n            payload = {\n                'name': username,\n                'passwd': password,\n                'rdoCourse': course\n            }\n            # \u56de\u50b3\u5617\u8a66\u767b\u5165\u7684\u56de\u61c9\n            return self.__session.post(\n                self.__url + '/Login', data=payload, timeout=0.5, verify=False)\n\n        except requests.exceptions.Timeout:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_question(self, number: str=None) -> dict:\n        try:\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/HomeworkBoard', timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u6574\u7406\u984c\u76ee\u8cc7\u8a0a\n            questions = {}\n            for tag in soup.find_all('tr'):\n                # \u53bb\u9664\u6a19\u984c\u5217\n                if tag.find('a') == None:\n                    continue\n\n                # \u5132\u5b58\u984c\u76ee\u8cc7\u8a0a\n                questions[tag.find('a').get_text().strip()] = {\n                    # \u7e73\u4ea4\u671f\u9650\n                    'deadline': tag.find_all('td')[3].get_text().strip(),\n                    # \u662f\u5426\u5df2\u7d93\u904e\u671f\u9650\n                    'expired': tag.find_all('td')[4].get_text().strip() == '\u671f\u9650\u5df2\u904e',\n                    # \u662f\u5426\u7e73\u4ea4\n                    'status': tag.find_all('td')[6].get_text().strip() == '\u5df2\u7e73',\n                    # \u7a0b\u5f0f\u8a9e\u8a00\u7a2e\u985e\n                    'language': tag.find_all('td')[5].get_text().strip(),\n                }\n            # \u56de\u50b3\u7d50\u679c\n            if number != None:\n                return questions.get(number)\n            else:\n                return questions\n\n        except requests.exceptions.Timeout:\n            return {\n                \"Timeout\": {\n                    'deadline': \"Timeout\",\n                    'expired': False,\n                    'status': False,\n                    'language': \"Timeout\",\n                }\n            }", "response": "Get a single question from the HomeworkBoard."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_question_content(self, number: str) -> str:\n        try:\n            # \u64cd\u4f5c\u6240\u9700\u8cc7\u8a0a\n            params = {\n                'hwId': number\n            }\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/showHomework', params=params, timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u8655\u7406\u984c\u76ee\u5167\u5bb9\u7684 \\r\n            result = ''\n            content = soup.find('body').get_text().replace('\u7e73\u4ea4\u4f5c\u696d', '').strip()\n            for line in content.split('\\r'):\n                result += line.strip() + '\\n'\n            # \u56de\u50b3\u7d50\u679c\n            return result\n\n        except requests.exceptions.Timeout:\n            return \"Timeout\"", "response": "Get question content from a specific number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget question passers from a number.", "response": "def get_question_passers(self, number: str) -> list:\n        \"\"\"\n        \u53d6\u5f97\u8ab2\u7a0b\u4e2d\u7279\u5b9a\u984c\u76ee\u901a\u904e\u8005\u5217\u8868\n        \"\"\"\n        try:\n            # \u64cd\u4f5c\u6240\u9700\u8cc7\u8a0a\n            params = {\n                'HW_ID': number\n            }\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/success.jsp', params=params, timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u6574\u7406\u901a\u904e\u8005\u8cc7\u8a0a\n            passers = []\n            for tag in soup.find_all('tr'):\n                # \u53d6\u5f97\u901a\u904e\u8005\u5b78\u865f\n                passer = tag.get_text().replace('\\n', '').strip()\n                # \u8df3\u904e\u6a19\u984c\u5217\n                if passer != '\u5b78\u865f':\n                    passers.append(passer)\n            # \u56de\u50b3\u7d50\u679c\n            return passers\n\n        except requests.exceptions.Timeout:\n            return [\"Timeout\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_password(self, password: str) -> bool:\n        try:\n            # \u64cd\u4f5c\u6240\u9700\u8cc7\u8a0a\n            payload = {\n                'pass': password,\n                'submit': 'sumit'\n            }\n            # \u4fee\u6539\u5bc6\u78bc\n            response = self.__session.post(\n                self.__url + '/changePasswd', data=payload, timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u56de\u50b3\u7d50\u679c\n            return str(soup.find('body')).split()[-2].strip() == 'Success'\n\n        except requests.exceptions.Timeout:\n            return None", "response": "Update the password of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post_question_answer(self, number: str, description: str, file_path: str) -> bool:\n        try:\n            # \u64cd\u4f5c\u6240\u9700\u8cc7\u8a0a\n            params = {\n                'hwId': number\n            }\n            data = {\n                'FileDesc': description\n            }\n            files = {\n                'hwFile': open(file_path, 'rb')\n            }\n            # \u4e0a\u50b3\u4f5c\u696d\n            self.__session.get(self.__url + '/upLoadHw',\n                               params=params, timeout=0.5, verify=False)\n            response = self.__session.post(\n                self.__url + '/upLoadFile', data=data, files=files, timeout=0.5)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u56de\u50b3\u7d50\u679c\n            return soup.find('body').get_text().strip() != '\u60a8\u6c92\u6709\u4e0a\u50b3\u6a94\u6848 \u8acb\u91cd\u65b0\u64cd\u4f5c'\n\n        except requests.exceptions.Timeout:\n            return False", "response": "Post question answer to a specific number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the notice from the Alien", "response": "def get_notice(self) -> dict:\n        \"\"\"\n        \u53d6\u5f97\u516c\u5e03\u6b04\u8a0a\u606f\u5217\u8868\n        \"\"\"\n        try:\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/MessageBoard', timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u6574\u7406\u516c\u5e03\u6b04\u8a0a\u606f\u5217\u8868\n            notices = {}\n            for tag in soup.find_all('tr'):\n                # \u8df3\u904e\u6a19\u984c\u5217\n                if tag.find('a') != None:\n                    title = tag.find('a').get_text().strip()\n                    date = tag.find_all('td')[1].get_text().strip()\n                    notices[date] = title\n            # \u56de\u50b3\u7d50\u679c\n            return notices\n\n        except requests.exceptions.Timeout:\n            return {\"Timeout\": \"Timeout\"}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the notice content", "response": "def get_notice_content(self, time: str) -> str:\n        \"\"\"\n        \u53d6\u5f97\u516c\u5e03\u6b04\u7279\u5b9a\u8a0a\u606f\u5167\u5bb9\n        \"\"\"\n        try:\n            # \u53d6\u5f97\u8cc7\u6599\n            response = self.__session.get(\n                self.__url + '/showArticle?time=' + time, timeout=0.5, verify=False)\n            soup = BeautifulSoup(response.text, 'html.parser')\n            # \u56de\u50b3\u7d50\u679c\n            return soup.find('pre').get_text().strip().replace('\\r', '')\n\n        except requests.exceptions.Timeout:\n            return \"Timeout\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_notices(self):\n        result = []\n        # \u53d6\u5f97\u516c\u5e03\u6b04\u8a0a\u606f\u5217\u8868\n        for date, title in self.get_notice().items():\n            content = self.get_notice_content(date)\n            result.append([date, title, content])\n        # \u56de\u50b3\u7d50\u679c\n        return result", "response": "[deprecated] \u5efa\u8b70\u4f7f\u7528\u65b9\u6cd5 `get_notice()` \u53ca `get_notice_content()`"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all questions in the current user.", "response": "def list_questions(self):\n        \"\"\"\n        [deprecated] \u5efa\u8b70\u4f7f\u7528\u65b9\u6cd5 `get_question()`\n        \"\"\"\n        # \u53d6\u5f97\u65b0 API \u7684\u7d50\u679c\n        data = self.get_question()\n        # \u5be6\u4f5c\u76f8\u5bb9\u7684\u7d50\u69cb\n        result = {}\n        for number in data:\n            # \u7e73\u4ea4\u671f\u9650\n            deadline = data[number]['deadline']\n            # \u662f\u5426\u5df2\u7d93\u904e\u671f\u9650\n            expired = '\u671f\u9650\u5df2\u5230' if data[number]['expired'] else '\u671f\u9650\u672a\u5230'\n            # \u662f\u5426\u7e73\u4ea4\n            status = '\u5df2\u7e73' if data[number]['status'] else '\u672a\u7e73'\n            # \u7a0b\u5f0f\u8a9e\u8a00\u7a2e\u985e\n            language = data[number]['language']\n            # \u5132\u5b58\u984c\u76ee\u8cc7\u8a0a\n            result[number] = [deadline, expired, status, language]\n        # \u56de\u50b3\u7d50\u679c\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_app_status(system_key):\n    if invalid_system_key(system_key):\n        raise InvalidSystemKey(\n            \"Invalid system key in get_app_status({})\".format(system_key))\n\n    url = get_appstatus_url(system_key)\n    response = DAO.getURL(url, {})\n    response_data = str(response.data)\n    if response.status != 200:\n        raise DataFailureException(url, response.status, response_data)\n\n    if len(response.data) == 0:\n        is_cached = (type(response) == restclients_core.models.MockHttp)\n        raise Exception(\n            \"{} Unexpected Response Data: {}, from cache: {}\".format(\n                url, response_data, str(is_cached)))\n\n    status = parse_statuses(response_data)\n    return status", "response": "Get Undergraduate application status"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngathers the hint arguments for datanommer based on the rules.", "response": "def gather_hinting(config, rules, valid_paths):\n    \"\"\" Construct hint arguments for datanommer from a list of rules. \"\"\"\n\n\n    hinting = collections.defaultdict(list)\n    for rule in rules:\n        root, name = rule.code_path.split(':', 1)\n        info = valid_paths[root][name]\n\n        if info['hints-callable']:\n            # Call the callable hint to get its values\n            result = info['hints-callable'](config=config, **rule.arguments)\n\n            # If the rule is inverted, but the hint is not invertible, then\n            # there is no hinting we can provide.  Carry on.\n            if rule.negated and not info['hints-invertible']:\n                continue\n\n            for key, values in result.items():\n                # Negate the hint if necessary\n                key = 'not_' + key if rule.negated else key\n                hinting[key].extend(values)\n\n        # Then, finish off with all the other ordinary, non-callable hints\n        for key, value in info['datanommer-hints'].items():\n\n            # If the rule is inverted, but the hint is not invertible, then\n            # there is no hinting we can provide.  Carry on.\n            if rule.negated and not info['hints-invertible']:\n                continue\n\n            # Otherwise, construct the inverse hint if necessary\n            key = 'not_' + key if rule.negated else key\n\n            # And tack it on.\n            hinting[key] += value\n\n    log.debug('gathered hinting %r', hinting)\n    return hinting"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the command line arguments and returns a Namespace with arguments.", "response": "def _parse_args():\n    \"\"\"\n    Parses the command line arguments.\n\n    :return: Namespace with arguments.\n    :rtype: Namespace\n    \"\"\"\n    parser = argparse.ArgumentParser(description='rain - a new sort of automated builder.')\n    \n    parser.add_argument('action', help='what shall we do?', default='build', nargs='?',\n                        choices=['build',\n                                 'ls',\n                                 'keep'] + removal_cmds)\n\n    parser.add_argument('-c', '--count', type=int, default=1,\n                        help='a count of items on which to operate. [default: %(default)s]')\n\n    parser.add_argument('--keep', type=int, default=-1,\n                        help='how many builds should we keep around? [default: %(default)s]')\n\n    parser.add_argument('-v', '--verbose', action='count', default=0, help='Be more verbose. (can be repeated)')\n\n    parser.add_argument('--version', default=False, action='store_true',\n                        help='print version number and exit. [default: %(default)s]')\n\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a HTML list with items from a feed.", "response": "def generate_feed_list(feed, amount=None, list_class=None, li_class=None, list_type='ul'):\n    \"\"\"Generates a HTML list with items from a feed\n\n    :param feed: The feed to generate the list from.\n    :type feed: Feed\n    :param amount: The amount of items to show.\n    :type amount: int\n    :param ul_class: The <ul> or <ol> class to use.\n    :type ul_class: str\n    :param li_class: The <li> class to use.\n    :type li_class: str\n    :param list_type: The list type to use. Defaults to 'ul'\n    :type list_type: str\n    :raises:  ValueError\n    \"\"\"\n\n    if feed.feed_type == 'twitter':\n        ret = ['<%s class=\"%s\">' % (list_type, list_class or 'tweet-list')]\n        tweets = feed.tweets.all()\n        if amount:\n            if not int(amount):\n                raise ValueError('Amount must be a number')\n            tweets = tweets[:amount]\n        for t in tweets:\n            ret.append(\n                '<li class=\"%s\">'\n                '<div class=\"tweet-profile-picture\">'\n                '<img src=\"%s\" alt=\"Twitter profile picture of %s\" width=\"48\" height=\"48\" /></div>'\n                '<div class=\"tweet-body\">%s</div></li>' % (li_class or 'tweet', t.profile_image_url, t.from_user_name, t.text))\n    if feed.feed_type == 'rss':\n        ret = ['<%s class=\"%s\">' % (list_type, list_class or 'rss-list')]\n        rss_items = feed.rss_items.all()\n        if amount:\n            if not int(amount):\n                raise ValueError('Amount must be a number')\n            rss_items = rss_items[:amount]\n        for t in rss_items:\n            ret.append(\n                '<li class=\"%s\">'\n                '<div class=\"rss-item-body\">%s</div></li>' % (li_class or 'rss-item', t.description))\n    ret.append('</%s>' % list_type)\n    return ''.join(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clone(source, destination, dbs = None, verbose = False):\n\n\t# If the source is not a valid dict\n\tif not isinstance(source, dict):\n\t\traise ValueError('source must be a dict')\n\n\t# Open a connection to the source instance\n\ttry:\n\t\toSource\t= r.connect(**source)\n\n\t# Catch possible error\n\texcept r.errors.RqlDriverError:\n\t\tsys.stderr.write('Can not connect to source host: ' + str(source) + '\\n')\n\t\treturn False\n\n\t# If the destination is not a valid dict\n\tif not isinstance(destination, dict):\n\t\traise ValueError('destination must be a dict')\n\n\t# Open a connection to the destination instance\n\ttry:\n\t\toDest\t= r.connect(**destination)\n\n\t# Catch possible error\n\texcept r.errors.RqlDriverError:\n\t\tsys.stderr.write('Can not connect to destination host: ' + str(destination) + '\\n')\n\t\treturn False\n\n\t# Get all the DBs on the source\n\tlSourceDBs\t= r.db_list().run(oSource)\n\n\t# If no DBs were specified\n\tif not dbs:\n\t\tdbs\t= lSourceDBs\n\n\t# If the DBs were sent as a list (no tables specified)\n\tif isinstance(dbs, (list,tuple)):\n\t\tdbs\t= {s:None for s in dbs}\n\n\t# Go through each DB listed\n\tfor sDB,lTables in dbs.iteritems():\n\n\t\t# DBs can't have spaces, so we assume we want to rename the DB if there is one\n\t\tif ' ' in sDB:\n\t\t\tsDB, sCopyDB = sDB.split(' ')\n\t\telse:\n\t\t\tsCopyDB = sDB\n\n\t\t# If the DB doesn't exist in the source\n\t\tif sDB not in lSourceDBs:\n\t\t\tsys.stderr.write('No such DB \"%s\" on the source host\\n' % sDB)\n\t\t\tcontinue\n\n\t\t# Check if the DB exists on the destination\n\t\tif r.db_list().contains(sCopyDB).run(oDest):\n\t\t\tsys.stderr.write('DB \"%s\" already exists on the destination host\\n\"' % sDB)\n\t\t\tcontinue\n\n\t\t# If verbose mode is on\n\t\tif verbose:\n\t\t\tsys.stdout.write('Processing DB \"%s\"\\n' % sDB)\n\n\t\t# Create the DB on the destination host\n\t\tr.db_create(sCopyDB).run(oDest)\n\n\t\t# Get all the tables in the DB\n\t\tlSourceTables\t= r.db(sDB).table_list().run(oSource)\n\n\t\t# If no tables were specified\n\t\tif not lTables:\n\t\t\tlTables\t= lSourceTables\n\n\t\t# Go through each Table\n\t\tfor sTable in lTables:\n\n\t\t\t# If the DB doesn't exist in the source\n\t\t\tif sTable not in lSourceTables:\n\t\t\t\tsys.stderr.write('No such Table \"%s.%s\" on the source host\\n' % (sDB,sTable))\n\t\t\t\tcontinue\n\n\t\t\t# If verbose mode is on\n\t\t\tif verbose:\n\n\t\t\t\t# Output\n\t\t\t\tsys.stdout.write('  Processing Table \"%s\": [%s] 0%%' % (sTable, (' ' * _PROGRESS_TICKS)))\n\n\t\t\t\t# Get the number of documents in the table\n\t\t\t\tfTotal\t= float(r.db(sDB).table(sTable).count().run(oSource))\n\n\t\t\t\t# Calculate the block size\n\t\t\t\tfBlock\t= fTotal / _PROGRESS_TICKS\n\n\t\t\t\t# Init the count and the ticks\n\t\t\t\tiCount\t= 0\n\t\t\t\tiTicks\t= 0\n\n\t\t\t# Get the primary key of the table\n\t\t\tsKeyField\t= r.db(sDB).table(sTable).info().run(oSource)['primary_key']\n\n\t\t\t# Create the Table\n\t\t\tr.db(sCopyDB).table_create(sTable, primary_key=sKeyField).run(oDest)\n\n\t\t\t# Get the list of indexes\n\t\t\tlIndexes\t= r.db(sDB).table(sTable).index_status().run(oSource)\n\n\t\t\t# Create each index\n\t\t\tfor dIndex in lIndexes:\n\n\t\t\t\t# Pull out the name\n\t\t\t\tsName\t= dIndex['index']\n\n\t\t\t\t# Pull out the fields\n\t\t\t\toMatches\t= _INDEX_REGEX.findall(dIndex['query'])\n\n\t\t\t\t# If there's only one field\n\t\t\t\tif len(oMatches) == 1:\n\n\t\t\t\t\t# Create a single field index\n\t\t\t\t\tr.db(sCopyDB).table(sTable).index_create(oMatches[0][0]).run(oDest)\n\n\t\t\t\t# Else if the index is comprised of multiple fields\n\t\t\t\telse:\n\n\t\t\t\t\t# Pull out each field\n\t\t\t\t\tlFields\t= []\n\t\t\t\t\tfor tMatch in oMatches:\n\t\t\t\t\t\tlFields.append(r.row[tMatch[1]])\n\n\t\t\t\t\t# Create a multi-index field\n\t\t\t\t\tr.db(sCopyDB).table(sTable).index_create(sName, lFields).run(oDest)\n\n\t\t\t# Copy the data one document at a time\n\t\t\tfor dDoc in r.db(sDB).table(sTable).run(oSource):\n\n\t\t\t\t# Copy the document to the destination\n\t\t\t\tr.db(sCopyDB).table(sTable).insert(dDoc).run(oDest)\n\n\t\t\t\t# If verbose mode is on\n\t\t\t\tif verbose:\n\n\t\t\t\t\t# Increment the count\n\t\t\t\t\tiCount\t+= 1\n\n\t\t\t\t\t# Get the number of ticks\n\t\t\t\t\tiTemp\t= int(round(float(iCount) / fBlock))\n\n\t\t\t\t\t# If the ticks are more than the previous\n\t\t\t\t\tif iTemp > iTicks:\n\t\t\t\t\t\tiTicks\t= iTemp\n\n\t\t\t\t\t\t# Output\n\t\t\t\t\t\tsys.stdout.write('\\r  Processing Table \"%s\": [%s%s] %d%%' % (\n\t\t\t\t\t\t\tsTable,\n\t\t\t\t\t\t\t('=' * iTicks),\n\t\t\t\t\t\t\t(' ' * (_PROGRESS_TICKS - iTicks)),\n\t\t\t\t\t\t\t(iTicks * 4)\n\t\t\t\t\t\t))\n\t\t\t\t\t\tsys.stdout.flush()\n\n\t\t\t# If verbose mode is on\n\t\t\tif verbose:\n\n\t\t\t\t# Output\n\t\t\t\tsys.stdout.write('\\r  Processing Table \"%s\": [%s] 100%%\\n' % (sTable, ('=' * _PROGRESS_TICKS)))", "response": "This function is used to clone one or many tables from one host to another."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the file and yield chucks of chunk_size bytes.", "response": "def chunks(f, chunk_size=None):\n    \"\"\"\n    Read the file and yield chucks of ``chunk_size`` bytes.\n    \"\"\"\n    if not chunk_size:\n        chunk_size = 64 * 2 ** 10\n\n    if hasattr(f, \"seek\"):\n        f.seek(0)\n\n    while True:\n        data = f.read(chunk_size)\n        if not data:\n            break\n        yield data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, name, content):\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        name = self.get_available_name(name)\n        name = self._save(name, content)\n\n        # Store filenames with forward slashes, even on Windows\n        return name.replace(\"\\\\\", \"/\")", "response": "Saves new content to the file specified by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_available_name(self, name):\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, add an underscore and a number (before\n        # the file extension, if one exists) to the filename until the generated\n        # filename doesn't exist.\n        count = itertools.count(1)\n        while self.exists(name):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, \"%s_%s%s\" % (file_root, next(count), file_ext))\n\n        return name", "response": "Returns a filename that s free on the target storage system and and\n        available for new content to be written to."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a banner from a text file.", "response": "def print_banner(filename: str, template: str = DEFAULT_BANNER_TEMPLATE) -> None:\n    \"\"\"\n    Print text file to output.\n\n    :param filename: Which file to print.\n    :param template: Format string which specified banner arrangement.\n    :return: Does not return anything\n    \"\"\"\n    if not os.path.isfile(filename):\n        logger.warning(\"Can't find logo banner at %s\", filename)\n        return\n\n    with open(filename, \"r\") as f:\n        banner = f.read()\n\n    formatted_banner = template.format(banner)\n    print(formatted_banner)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the best - fit rotation matrix that rotates from_coord to to_coord.", "response": "def get_best_fit_rot_mat(from_coord, to_coord):\r\n    \"\"\"\r\n    Compute best-fit rotation matrix.\r\n\r\n    The best-fit rotation matrix rotates from_coord such that the RMSD\r\n    between the 2 sets of coordinates are minimized after the rotation.\r\n\r\n    Parameters\r\n    ----------\r\n    from_coord, to_coord : np.array\r\n        Nx3 coordinate arrays, where N is the number of atoms. The\r\n        from_coord will rotated such that the rotation will minimize\r\n        the RMSD between the rotated from_coord and to_coord.\r\n\r\n    Returns\r\n    -------\r\n    np.array\r\n        3x3 rotation matrix\r\n    \"\"\"\r\n    superimpose_inst.set(to_coord.astype('float64'),\r\n                         from_coord.astype('float64'))\r\n    superimpose_inst.run()\r\n\r\n    return superimpose_inst.get_rotran()[0].T"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a pretty - printed string for a feature Currently implemented", "response": "def repr_feature(feature, max_keys=100, indent=8, lexigraphic=False):\n    '''\n    generate a pretty-printed string for a feature\n\n    Currently implemented:\n      * StringCounter\n\n    @max_keys: truncate long counters\n\n    @indent: indent multi-line displays by this many spaces\n\n    @lexigraphic: instead of sorting counters by count (default), sort\n    keys lexigraphically\n    '''\n    if isinstance(feature, (str, bytes)):\n        try:\n            ustr = feature.decode('utf8')\n            return ustr\n        except:\n            # failure to decode, not actually utf8, other binary data\n            return repr(feature)\n\n    if isinstance(feature, StringCounter):\n        return repr_stringcounter(feature, max_keys, indent, lexigraphic)\n    elif isinstance(feature, unicode):\n        return feature\n    else:\n        return repr(feature)\n\n    assert False, 'internal logic failure, no branch taken'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef detailed_view(fc, features_to_show=None, max_keys=100, lexigraphic=False,\n                  display_only=True):\n    '''\n    returns a pretty-printed string describing a\n    :class:`dossier.fc.FeatureCollection`.\n\n    @features_to_show: list of features to include, defaults to None\n    meaning include all.\n\n    @lexigraphic: passed to repr_feature\n\n    @display_only: if DISPLAY_PREFIX versions of features are present, only show those. (default True)\n    '''\n    if '#NAME' in fc:\n        top_lines = ['NAME: %s' % key_sorted_dict_str( fc.get('#NAME') )]\n    elif '#NOM' in fc:\n        top_lines = ['NOM: %s' % key_sorted_dict_str( fc.get('#NOM') )]\n    elif 'NAME' in fc:\n        top_lines = ['NAME: %s' % key_sorted_dict_str( fc.get('NAME') )]\n    elif 'NOM' in fc:\n        top_lines = ['NOM: %s' % key_sorted_dict_str( fc.get('NOM') )]\n    else:\n        top_lines = ['no-NAME, no-NOM']\n    bottom_lines = []\n    feature_names = fc.keys()\n    display_only = _check_display_only(display_only, feature_names)\n    feature_names.sort()\n    hidden_count = 0\n    for key in feature_names:\n        if display_only and (not key.startswith(FeatureCollection.DISPLAY_PREFIX)):\n            hidden_count += 1\n            continue\n        if key in fc and fc[key]:\n            if features_to_show and key not in features_to_show:\n                continue\n            repr = repr_feature(fc[key], max_keys=max_keys, lexigraphic=lexigraphic)\n            if '\\n' in repr:\n                ## save these for the end\n                # use four spaces, smaller than indent=8 above\n                bottom_lines.append( '    %s: %s' % (key, repr) )\n            else:\n                top_lines.append( '    %s: %s' % (key, repr))\n    if hidden_count:\n        bottom_lines.append('    (and %s hidden features)' % (hidden_count,))\n    return '\\n'.join(top_lines + bottom_lines)", "response": "Returns a pretty - printed string describing a feature collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef only_specific_multisets(ent, multisets_to_show):\n    '''\n    returns a pretty-printed string for specific features in a FeatureCollection\n    '''\n    out_str = []\n    for mset_name in multisets_to_show:\n        for key, count in ent[mset_name].items():\n            out_str.append( '%s - %d: %s' % (mset_name, count, key) )\n    return '\\n'.join(out_str)", "response": "returns a pretty - printed string for specific features in a FeatureCollection"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef emit(self, action, payload):\n        url = self.get_emit_api(action)\n        headers = {\n            'User-Agent': 'rio/%s' % VERSION,\n            'X-Rio-Protocol': '1',\n        }\n        args = dict(\n            url=url,\n            json=payload,\n            headers=headers,\n            timeout=self.timeout,\n        )\n        resp = requests.post(**args)\n        data = resp.json()\n        is_success = resp.status_code == 200\n        result = dict(\n            is_success=is_success,\n            message=data['message'],\n        )\n        if result['is_success']:\n            result.update(\n                event_uuid=data['event']['uuid'],\n                task_id=data['task']['id'],\n            )\n        return result", "response": "Emit action with payload via requests. post."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _real_re_compile(self, *args, **kwargs):\n        try:\n            return _real_re_compile(*args, **kwargs)\n        except re.error as e:\n            # raise InvalidPattern instead of re.error as this gives a\n            # cleaner message to the user.\n            raise InvalidPattern('\"' + args[0] + '\" ' +str(e))", "response": "Thunk over to the original re. compile"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_image_json(text):\n    image_details = json.loads(text)\n    if image_details.get('Images') is not None:\n        try:\n            image_details = image_details.get('Images')[0]\n        except IndexError:\n            image_details = None\n    return image_details", "response": "Parses AWS describe command output of AWS describe commands and returns the first item in array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_regions(self):\n        for region in self.aws_regions:\n            if region not in aws_regions:\n                print \"Error: Specified region: {} is not a valid aws_region\".format(region)\n                print \"Valid regions are: {}\".format(aws_regions)", "response": "Validate the user specified regions are valid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nattempt to import an AMI image from AWS ec2", "response": "def validate_ec2_action(self):\n        \"\"\"\n        Attempt to validate that the provided user has permissions to import an AMI\n        :return:\n        \"\"\"\n        import_cmd = 'aws ec2 import-image --dry-run --profile {} --region {}'\\\n            .format(self.aws_project, self.aws_regions[0])\n        print \"Attempting ec2 import dry run: {}\".format(import_cmd)\n        try:\n            subprocess.check_output(shlex.split(import_cmd), stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            if \"(DryRunOperation)\" in e.output:\n                # If it failed because of a dry run (what we asked for) then this except can be ignored\n                print \"Dry run operation successful!\"\n                return\n            print \"Error: {}\".format(e.output)\n            print \"It doesn't seem like your user has the required permissions to import an ami image from s3\"\n            sys.exit(5)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the s3 bucket exists and if it is valid.", "response": "def validate_bucket(self):\n        \"\"\"\n        Do a quick check to see if the s3 bucket is valid\n        :return:\n        \"\"\"\n        s3_check_cmd = \"aws s3 ls s3://{} --profile '{}' --region '{}'\".format(self.bucket_name, self.aws_project,\n                                                                               self.aws_regions[0])\n        print \"Checking for s3 bucket\"\n        try:\n            subprocess.check_output(shlex.split(s3_check_cmd))\n        except subprocess.CalledProcessError as e:\n            print \"Error: {}\".format(e)\n            print \"Unable to query s3 bucket: {}. Validate that it exists, and your user has sufficient permissions\"\\\n                .format(self.bucket_name)\n            sys.exit(5)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_image_id_by_name(self, ami_name, region='us-east-1'):\n        image_details = None\n        detail_query_attempts = 0\n\n        while image_details is None:\n            describe_cmd = \"aws ec2 describe-images --filters 'Name=name,Values={}' --profile '{}' --region {}\"\\\n                .format(ami_name, self.aws_project, region)\n            res = subprocess.check_output(shlex.split(describe_cmd))\n\n            print \"describe command returned: {}\".format(res)\n\n            image_details = parse_image_json(res)\n            if not image_details:\n                if detail_query_attempts > 5:\n                    print \"Tried to get image details 5 times and failed, exiting\"\n                    raise Exception(\"Unable to get AMI image id from AWS using the image name\")\n                time.sleep(10)\n                print \"No images defined returned yet, will try another query\"\n                detail_query_attempts += 1\n\n        image_id = image_details['ImageId']\n        print \"located image id: {}\".format(image_id)\n        return image_id", "response": "Locate an AMI image id by name in a particular region"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying an AMI from the default region to the desired name and region.", "response": "def copy_ami_to_new_name(self, ami_id, new_name, source_region='us-east-1'):\n        \"\"\"\n        Copies an AMI from the default region and name to the desired name and region\n        :param ami_id: ami id to copy\n        :param new_name: name of the new ami to create\n        :param source_region: the source region of the ami to copy\n        \"\"\"\n\n        new_image_ids = []\n\n        for region in self.aws_regions:\n            copy_img_cmd = \"aws ec2 copy-image --source-image-id {} --profile {} --source-region {} --region {} --name {}\"\\\n                .format(ami_id, self.aws_project, source_region, region, new_name)\n            res = subprocess.check_output(shlex.split(copy_img_cmd))\n\n            print \"Copy cmd returned: {}\".format(res)\n\n            new_image_id = json.loads(res).get('ImageId')\n            new_image_ids.append((new_image_id, region))\n\n            print \"new image Id is: {}\".format(new_image_id)\n\n        print \"monitoring the copies for the following regions/id : {}\".format(new_image_ids)\n        for tupp in new_image_ids:\n            image_id = tupp[0]\n            image_region = tupp[1]\n            self.wait_for_copy_available(image_id, image_region)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deregister_image(self, ami_id, region='us-east-1'):\n        deregister_cmd = \"aws ec2 --profile {} --region {} deregister-image --image-id {}\"\\\n            .format(self.aws_project, region, ami_id)\n        print \"De-registering old image, now that the new one exists.\"\n        print \"De-registering cmd: {}\".format(deregister_cmd)\n        res = subprocess.check_output(shlex.split(deregister_cmd))\n        print \"Response: {}\".format(res)\n        print \"Not monitoring de-register command\"", "response": "Deregisters an AMI from the local cache"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for the newly copied AMI to become available", "response": "def wait_for_copy_available(self, image_id, region):\n        \"\"\"\n        Wait for the newly copied ami to become available\n        :param image_id: image id to monitor\n        :param region: region to monitor copy\n        \"\"\"\n        waiting = True\n\n        describe_image_cmd = \"aws ec2 --profile {} --region {} --output json describe-images --image-id {}\"\\\n            .format(self.aws_project, region, image_id)\n        while waiting:\n            res = subprocess.check_output(shlex.split(describe_image_cmd))\n            print \"described image returned: {}\".format(res)\n            image_json = parse_image_json(res)\n            image_state = image_json['State']\n            if image_state == 'available':\n                print \"Copied AMI is renamed and ready to use!\"\n                return\n            elif image_state == 'failed':\n                print \"Copied AMI failed for some reason...\"\n                sys.exit(5)\n            else:\n                print \"image state is currently: {}\".format(image_state)\n                print \"Sleeping for 30 seconds...\"\n                time.sleep(30)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rename_image(self, ami_name, new_ami_name, source_region='us-east-1'):\n        print \"Re-naming/moving AMI to desired name and region\"\n        image_id = self.get_image_id_by_name(ami_name, source_region)\n        self.copy_ami_to_new_name(image_id, new_ami_name, source_region)\n        self.deregister_image(image_id, source_region)", "response": "Method which renames an AMI by copying to a new ami with a new name and removing it from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_config_file(self, vmdk_location, description):\n        description = description\n        format = \"vmdk\"\n        user_bucket = {\n            \"S3Bucket\": self.bucket_name,\n            \"S3Key\": vmdk_location\n        }\n        parent_obj = {'Description': description, 'Format': format, 'UserBucket': user_bucket}\n        obj_list = [parent_obj]\n\n        temp_fd, temp_file = tempfile.mkstemp()\n        print 'creating tmp file for {} at {}'.format(vmdk_location, temp_file)\n\n        with os.fdopen(temp_fd, 'w') as f:\n            json.dump(obj_list, f)\n        return temp_fd, temp_file", "response": "Create the aws import config file for the VMDK holding the specified vmdk_location and description."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the ec2 import command and returns the import task id", "response": "def run_ec2_import(self, config_file_location, description, region='us-east-1'):\n        \"\"\"\n        Runs the command to import an uploaded vmdk to aws ec2\n        :param config_file_location: config file of import param location\n        :param description: description to attach to the import task\n        :return: the import task id for the given ami\n        \"\"\"\n        import_cmd = \"aws ec2 import-image --description '{}' --profile '{}' --region '{}' --output 'json'\" \\\n                     \" --disk-containers file://{}\"\\\n            .format(description, self.aws_project, region, config_file_location)\n        try:\n            res = subprocess.check_output(shlex.split(import_cmd), stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            print \"Error importing to ec2\"\n            print \"output: {}\".format(e.output)\n            sys.exit(5)\n\n        print \"got res: {}\".format(res)\n        res_json = json.loads(res)\n        task_running, import_id = self.check_task_status_and_id(res_json)\n        return import_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads the vmdk file to s3", "response": "def upload_to_s3(self, region='us-east-1'):\n        \"\"\"\n        Uploads the vmdk file to aws s3\n        :param file_location: location of vmdk\n        :return:\n        \"\"\"\n        s3_import_cmd = \"aws s3 cp {} s3://{} --profile '{}' --region {}\".format(self.upload_file, self.bucket_name,\n                                                                                 self.aws_project, region)\n        print \"Uploading to bucket {} in s3 with the cmd: {}\".format(self.bucket_name, s3_import_cmd)\n        # s3 upload puts DL progress to stderr\n        s3_upload = subprocess.Popen(shlex.split(s3_import_cmd), stderr=subprocess.PIPE)\n        while True:\n            progress = s3_upload.stderr.readline()\n            if progress == '' and s3_upload.poll() is not None:\n                break\n            if progress:\n                print (progress)\n        rc = s3_upload.poll()\n        if rc != 0:\n            raise subprocess.CalledProcessError(rc)\n        print \"Upload completed successfully\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmonitoring the status of aws import and wait for it to complete", "response": "def wait_for_import_to_complete(self, import_id, region='us-east-1'):\n        \"\"\"\n        Monitors the status of aws import, waiting for it to complete, or error out\n        :param import_id: id of import task to monitor\n        \"\"\"\n        task_running = True\n        while task_running:\n            import_status_cmd = \"aws ec2 --profile {}  --region '{}' --output 'json' describe-import-image-tasks --import-task-ids {}\".format(self.aws_project, region, import_id)\n            res = subprocess.check_output(shlex.split(import_status_cmd))\n            print \"Current status: {}\".format(res)\n            res_json = json.loads(res)\n            task_running, image_id = self.check_task_status_and_id(res_json)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_task_status_and_id(task_json):\n        if task_json.get('ImportImageTasks') is not None:\n            task = task_json['ImportImageTasks'][0]\n        else:\n            task = task_json\n\n        current_status = task['Status']\n        image_id = task['ImportTaskId']\n        if current_status == 'completed':\n            print \"The import has completed succesfully as ID: {}\".format(image_id)\n            return False, image_id\n        elif current_status == 'deleting':\n            print \"The import job has been cancelled for some reason\"\n            return False, None\n        elif current_status == 'deleted':\n            print \"The import job was cancelled\"\n            return False, None\n        else:\n            print \"The current import job for id {} status is: {}\".format(image_id, current_status)\n            print \"sleeping for 30 seconds\"\n            time.sleep(30)\n            return True, image_id", "response": "Read status of import json and parse it to get image id and status"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_vmdk(self):\n        # Set the inital upload to be the first region in the list\n        first_upload_region = self.aws_regions[0]\n\n        print \"Initial AMI will be created in: {}\".format(first_upload_region)\n        self.upload_to_s3(region=first_upload_region)\n        # If the upload was successful, the name to reference for import is now the basename\n        description = \"AMI upload of: {}\".format(os.path.basename(self.upload_file))\n        temp_fd, file_location = self.create_config_file(os.path.basename(self.upload_file), description)\n        import_id = self.run_ec2_import(file_location, description, first_upload_region)\n        self.wait_for_import_to_complete(import_id)\n        self.rename_image(import_id, self.ami_name, source_region=first_upload_region)\n        return import_id", "response": "This function takes a vmdk and creates an AMI and returns the import_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_params(func, *args, **kwargs):\n    params = dict(zip(func.func_code.co_varnames[:len(args)], args))\n    if func.func_defaults:\n        params.update(dict(zip(\n            func.func_code.co_varnames[-len(func.func_defaults):],\n            func.func_defaults)))\n    params.update(kwargs)\n\n    return params", "response": "Turn an argument list into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecorate **viewfunc ** to require HTTP auth on the view.", "response": "def authenticated(viewfunc):\n    \"\"\"Decorate **viewfunc** with this decorator to require HTTP auth on the\n    view.\"\"\"\n    @wraps(viewfunc)\n    def wrapper(*args, **kwargs):\n        ctx = stack.top\n        if ctx and hasattr(ctx, 'htauth'):\n            auth_header = request.headers.get('Authorization', None)\n            if not auth_header:\n                return _unauthorized_response()\n\n            if not auth_header.startswith('Basic '):\n                raise RuntimeError('Flask-HTAuth supports only Basic auth.')\n\n            auth_header = auth_header.replace('Basic ', '')\n            auth_header = base64.b64decode(auth_header)\n            username, password = auth_header.split(':', 1)\n\n            if not username in ctx.htauth['users']:\n                return _unauthorized_response()\n\n            if not check_password(password, ctx.htauth['users'][username]):\n                return _unauthorized_response()\n\n            g.htauth_user = username\n\n        return viewfunc(*args, **kwargs)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_type(name, obj, expected_type):\n    if not isinstance(obj, expected_type):\n        raise TypeError(\n            '\"%s\" must be an a %s' % (name, expected_type.__name__)\n        )", "response": "Raise a TypeError if the object is not of expected type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _import_module(module_name):\n    fromlist = []\n    dot_position = module_name.rfind('.')\n    if dot_position > -1:\n        fromlist.append(\n            module_name[dot_position+1:len(module_name)]\n        )\n\n    # Import module\n    module = __import__(module_name, globals(), locals(), fromlist, 0)\n\n    return module", "response": "Imports the module dynamically by module_name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that the arguments to create are valid.", "response": "def _verify_create_args(module_name, class_name, static):\n    \"\"\" Verifies a subset of the arguments to create() \"\"\"\n    # Verify module name is provided\n    if module_name is None:\n        raise InvalidServiceConfiguration(\n            'Service configurations must define a module'\n        )\n\n    # Non-static services must define a class\n    if not static and class_name is None:\n        tmpl0 = 'Non-static service configurations must define a class: '\n        tmpl1 = 'module is %s'\n        raise InvalidServiceConfiguration((tmpl0 + tmpl1) % module_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, module_name, class_name,\n               args=None, kwargs=None, factory_method=None,\n               factory_args=None, factory_kwargs=None, static=False,\n               calls=None):\n        \"\"\" Initializes an instance of the service \"\"\"\n        if args is None:\n            args = []\n        if kwargs is None:\n            kwargs = {}\n        if factory_args is None:\n            factory_args = []\n        if factory_kwargs is None:\n            factory_kwargs = {}\n        if static is None:\n            static = False\n\n        # Verify\n        _verify_create_args(module_name, class_name, static)\n\n        # Import\n        module = _import_module(module_name)\n\n        # Instantiate\n        service_obj = self._instantiate(module, class_name,\n                                        args, kwargs, static)\n        # Factory?\n        if factory_method is not None:\n            service_obj = self._handle_factory_method(service_obj,\n                                                      factory_method,\n                                                      factory_args,\n                                                      factory_kwargs)\n        # Extra Calls\n        if calls is not None and isinstance(calls, list):\n            self._handle_calls(service_obj, calls)\n\n        # Return\n        return service_obj", "response": "Creates an instance of the specified class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_from_dict(self, dictionary):\n        # Defaults\n        args = []\n        kwargs = {}\n        factory_method = None\n        factory_args = []\n        factory_kwargs = {}\n        static = False\n        calls = None\n\n        # Check dictionary for arguments\n        if 'args' in dictionary:\n            args = dictionary['args']\n\n        if 'kwargs' in dictionary:\n            kwargs = dictionary['kwargs']\n\n        if 'factory-method' in dictionary:\n            factory_method = dictionary['factory-method']\n\n        if 'factory-args' in dictionary:\n            factory_args = dictionary['factory-args']\n\n        if 'factory-kwargs' in dictionary:\n            factory_kwargs = dictionary['factory-kwargs']\n\n        if 'static' in dictionary:\n            static = dictionary['static']\n\n        if 'calls' in dictionary:\n            calls = dictionary['calls']\n\n        return self.create(\n            dictionary['module'],\n            dictionary['class'],\n            args=args,\n            kwargs=kwargs,\n            factory_method=factory_method,\n            factory_args=factory_args,\n            factory_kwargs=factory_kwargs,\n            static=static,\n            calls=calls\n        )", "response": "Initializes an instance from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_instantiated_service(self, name):\n        if name not in self.instantiated_services:\n            raise UninstantiatedServiceException\n        return self.instantiated_services[name]", "response": "Get instantiated service by name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace index in list with service name", "response": "def _replace_service_arg(self, name, index, args):\n        \"\"\" Replace index in list with service \"\"\"\n        args[index] = self.get_instantiated_service(name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _replace_scalars_in_args(self, args):\n        _check_type('args', args, list)\n        new_args = []\n        for arg in args:\n            if isinstance(arg, list):\n                to_append = self._replace_scalars_in_args(arg)\n            elif isinstance(arg, dict):\n                to_append = self._replace_scalars_in_kwargs(arg)\n            elif isinstance(arg, string_types):\n                to_append = self._replace_scalar(arg)\n            else:\n                to_append = arg\n            new_args.append(to_append)\n        return new_args", "response": "Replace scalars in arguments list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace scalars in keyed arguments dictionary", "response": "def _replace_scalars_in_kwargs(self, kwargs):\n        \"\"\" Replace scalars in keyed arguments dictionary \"\"\"\n        _check_type('kwargs', kwargs, dict)\n\n        new_kwargs = {}\n        for (name, value) in iteritems(kwargs):\n            if isinstance(value, list):\n                new_kwargs[name] = self._replace_scalars_in_args(value)\n            elif isinstance(value, dict):\n                new_kwargs[name] = self._replace_scalars_in_kwargs(value)\n            elif isinstance(value, string_types):\n                new_kwargs[name] = self._replace_scalar(value)\n            else:\n                new_kwargs[name] = value\n        return new_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _replace_services_in_args(self, args):\n        _check_type('args', args, list)\n\n        new_args = []\n        for arg in args:\n            if isinstance(arg, list):\n                new_args.append(self._replace_services_in_args(arg))\n            elif isinstance(arg, dict):\n                new_args.append(self._replace_services_in_kwargs(arg))\n            elif isinstance(arg, string_types):\n                new_args.append(self._replace_service(arg))\n            else:\n                new_args.append(arg)\n        return new_args", "response": "Replace service references in arguments list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _replace_services_in_kwargs(self, kwargs):\n        _check_type('kwargs', kwargs, dict)\n\n        new_kwargs = {}\n        for (name, value) in iteritems(kwargs):\n            if isinstance(value, list):\n                new_kwargs[name] = self._replace_services_in_args(value)\n            elif isinstance(value, dict):\n                new_kwargs[name] = self._replace_services_in_kwargs(value)\n            elif isinstance(value, string_types):\n                new_kwargs[name] = self._replace_service(value)\n            else:\n                new_kwargs[name] = value\n        return new_kwargs", "response": "Replace services in keyed arguments dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets scalar value by name", "response": "def get_scalar_value(self, name):\n        \"\"\" Get scalar value by name \"\"\"\n        if name not in self.scalars:\n            raise InvalidServiceConfiguration(\n                'Invalid Service Argument Scalar \"%s\" (not found)' % name\n            )\n        new_value = self.scalars.get(name)\n        return new_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _replace_scalar(self, scalar):\n        if not is_arg_scalar(scalar):\n            return scalar\n        name = scalar[1:]\n        return self.get_scalar_value(name)", "response": "Replace scalar name with scalar value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the factory method of a class instance.", "response": "def _handle_factory_method(self, service_obj, method_name,\n                               args=None, kwargs=None):\n        \"\"\"\" Returns an object returned from a factory method \"\"\"\n        if args is None:\n            args = []\n        if kwargs is None:\n            kwargs = {}\n\n        _check_type('args', args, list)\n        _check_type('kwargs', kwargs, dict)\n\n        # Replace args\n        new_args = self._replace_scalars_in_args(args)\n        new_kwargs = self._replace_scalars_in_kwargs(kwargs)\n\n        return getattr(service_obj, method_name)(*new_args, **new_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the call on the service object.", "response": "def _handle_calls(self, service_obj, calls):\n        \"\"\" Performs method calls on service object \"\"\"\n\n        for call in calls:\n            method = call.get('method')\n            args = call.get('args', [])\n            kwargs = call.get('kwargs', {})\n\n            _check_type('args', args, list)\n            _check_type('kwargs', kwargs, dict)\n\n            if method is None:\n                raise InvalidServiceConfiguration(\n                    'Service call must define a method.'\n                )\n\n            new_args = self._replace_scalars_in_args(args)\n            new_kwargs = self._replace_scalars_in_kwargs(kwargs)\n            getattr(service_obj, method)(*new_args, **new_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _repr_html_(self):\n        nbreset = f'<style>{css_nbreset}</style>'\n        resources = ''.join(map(str, self.resources))\n        return f'<div>{nbreset}{resources}<div class=\"hrepr\">{self}</div></div>'", "response": "Return the HTML representation of this element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_page(self):\n        H = HTML()\n        utf8 = H.meta({'http-equiv': 'Content-type'},\n                      content=\"text/html\",\n                      charset=\"UTF-8\")\n        return H.inline(H.raw('<!DOCTYPE html>'),\n                        H.html(H.head(utf8, *self.resources),\n                               H.body(self)))", "response": "Wrap this Tag as a self - contained webpage."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_client(instance):\n    neutron_client = utils.get_client_class(\n        API_NAME,\n        instance._api_version[API_NAME],\n        API_VERSIONS,\n    )\n    instance.initialize()\n    url = instance._url\n    url = url.rstrip(\"/\")\n    client = neutron_client(username=instance._username,\n                            project_name=instance._project_name,\n                            password=instance._password,\n                            region_name=instance._region_name,\n                            auth_url=instance._auth_url,\n                            endpoint_url=url,\n                            endpoint_type=instance._endpoint_type,\n                            token=instance._token,\n                            auth_strategy=instance._auth_strategy,\n                            insecure=instance._insecure,\n                            ca_cert=instance._ca_cert,\n                            retries=instance._retries,\n                            raise_errors=instance._raise_errors,\n                            session=instance._session,\n                            auth=instance._auth)\n    return client", "response": "Creates a neutron client."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Client(api_version, *args, **kwargs):\n    neutron_client = utils.get_client_class(\n        API_NAME,\n        api_version,\n        API_VERSIONS,\n    )\n    return neutron_client(*args, **kwargs)", "response": "Return an neutron client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _getSuperFunc(self, s, func):\n\n        return getattr(super(self.cls(), s), func.__name__)", "response": "Return the super function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns make in sphinx s docs directory.", "response": "def _doc_make(*make_args):\n    \"\"\"Run make in sphinx' docs directory.\n\n    :return: exit code\n    \"\"\"\n    if sys.platform == 'win32':\n        # Windows\n        make_cmd = ['make.bat']\n    else:\n        # Linux, Mac OS X, and others\n        make_cmd = ['make']\n    make_cmd.extend(make_args)\n\n    # Account for a stupid Python \"bug\" on Windows:\n    # <http://bugs.python.org/issue15533>\n    with cwd(DOCS_DIRECTORY):\n        retcode = subprocess.call(make_cmd)\n    return retcode"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coverage():\n    try:\n        import pytest_cov  # NOQA\n    except ImportError:\n        print_failure_message(\n            'Install the pytest coverage plugin to use this task, '\n            \"i.e., `pip install pytest-cov'.\")\n        raise SystemExit(1)\n    import pytest\n    pytest.main(PYTEST_FLAGS + [\n        '--cov', CODE_DIRECTORY,\n        '--cov-report', 'term-missing',\n        '--junit-xml', 'test-report.xml',\n        TESTS_DIRECTORY])", "response": "Run tests and show test coverage report."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef doc_watch():\n    try:\n        from watchdog.events import FileSystemEventHandler\n        from watchdog.observers import Observer\n    except ImportError:\n        print_failure_message('Install the watchdog package to use this task, '\n                              \"i.e., `pip install watchdog'.\")\n        raise SystemExit(1)\n\n    class RebuildDocsEventHandler(FileSystemEventHandler):\n        def __init__(self, base_paths):\n            self.base_paths = base_paths\n\n        def dispatch(self, event):\n            \"\"\"Dispatches events to the appropriate methods.\n            :param event: The event object representing the file system event.\n            :type event: :class:`watchdog.events.FileSystemEvent`\n            \"\"\"\n            for base_path in self.base_paths:\n                if event.src_path.endswith(base_path):\n                    super(RebuildDocsEventHandler, self).dispatch(event)\n                    # We found one that matches. We're done.\n                    return\n\n        def on_modified(self, event):\n            print_failure_message('Modification detected. Rebuilding docs.')\n            # # Strip off the path prefix.\n            # import os\n            # if event.src_path[len(os.getcwd()) + 1:].startswith(\n            #         CODE_DIRECTORY):\n            #     # sphinx-build doesn't always pick up changes on code files,\n            #     # even though they are used to generate the documentation. As\n            #     # a workaround, just clean before building.\n            doc_html()\n            print_success_message('Docs have been rebuilt.')\n\n    print_success_message(\n        'Watching for changes in project files, press Ctrl-C to cancel...')\n    handler = RebuildDocsEventHandler(get_project_files())\n    observer = Observer()\n    observer.schedule(handler, path='.', recursive=True)\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n        observer.join()", "response": "Watch for changes in the docs and rebuild HTML docs when changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef doc_open():\n    doc_index = os.path.join(DOCS_DIRECTORY, 'build', 'html', 'index.html')\n    if sys.platform == 'darwin':\n        # Mac OS X\n        subprocess.check_call(['open', doc_index])\n    elif sys.platform == 'win32':\n        # Windows\n        subprocess.check_call(['start', doc_index], shell=True)\n    elif sys.platform == 'linux2':\n        # All freedesktop-compatible desktops\n        subprocess.check_call(['xdg-open', doc_index])\n    else:\n        print_failure_message(\n            \"Unsupported platform. Please open `{0}' manually.\".format(\n                doc_index))", "response": "Build the HTML docs and open them in a web browser."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all paver - defined tasks.", "response": "def get_tasks():\n    \"\"\"Get all paver-defined tasks.\"\"\"\n    from paver.tasks import environment\n    for tsk in environment.get_tasks():\n        print(tsk.shortname)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a NodeService object from options.", "response": "def makeService(self, options):\n        \"\"\" Construct a Node Server\n        \"\"\"\n        return NodeService(\n            port=options['port'],\n            host=options['host'],\n            broker_host=options['broker_host'],\n            broker_port=options['broker_port'],\n            debug=options['debug']\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the field name of the object.", "response": "def result(self):\n        \"\"\"\n        Construye la expresion\n        \"\"\" \n        field = re.sub(REGEX_CLEANER, '', self.field_name)\n\n        if self.alias:\n            alias = re.sub(REGEX_CLEANER, '', self.alias)\n            return \"%s AS %s\" % (field, alias)\n        else:\n            return field"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string representation of the entry.", "response": "def result(self):\n        \"\"\"\n        Construye la expresion\n        \"\"\" \n        \n        field = re.sub(REGEX_CLEANER, '', self.field)\n\n        try:\n            value = float(self.value)\n        except TypeError:\n        \tvalue = \"(%s)\" % ( \"', '\".join(self.value) )\n        except ValueError:\n            value = str(self.value) \\\n                .replace(\"\\\\\", r\"\\\\\") \\\n                .replace('\"', r'\\\"') \\\n                .replace(\"'\", r\"\\'\")\n\n            value = \"'%s'\" % value\n        \n        res = \"%s %s %s\" % (field, self.operator, value)\n\n        if self.conjunction:\n            res = \"%s %s\" % (self.conjunction, res)\n        \n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints key from a running instance s metadata", "response": "def awsReadInstanceTag():\n  \"\"\"Print key from a running instance's metadata\"\"\"\n  parser = argparse.ArgumentParser()\n\n  parser.add_argument(\"--tag\",\n                      dest=\"tag\",\n                      required=True,\n                      help=\"Which instance tag to read\")\n\n  cli = parser.parse_args()\n  print haze.ec2.readMyEC2Tag(tagName=cli.tag)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, **kwargs):\n        if 'timestamp' not in kwargs:\n            kwargs['timestamp'] = datetime.datetime.utcnow().isoformat()\n        if 'version' not in kwargs:\n            kwargs['version'] = \"Not Defined\" #bibcat.__version__\n        # log.debug(\"kwargs: %s\", pprint.pformat({k:v for k, v in kwargs.items()\n        #                                         if k != \"dataset\"}))\n        # log.debug(\"parents: %s\", self.parents)\n        for map_key, triple_map in self.triple_maps.items():\n            if map_key not in self.parents:\n                self.execute(triple_map, **kwargs)", "response": "Run method iterates through triple maps and calls execute\n            method"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_context(self):\n        results = self.rml.query(\"\"\"\n                SELECT ?o {\n                    {\n                        ?s rr:class ?o\n                    } UNION {\n                        ?s rr:predicate ?o\n                    }\n                }\"\"\")\n        namespaces = [Uri(row[0]).value[0]\n                      for row in results\n                      if isinstance(row[0], rdflib.URIRef)]\n        self.context = {ns[0]: ns[1] for ns in namespaces if ns[0]}", "response": "Reads throught the namespaces in the RML and generates a context for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_list_predicates(self):\n        results = self.rml.query(\"\"\"\n                SELECT DISTINCT ?subj_class ?list_field\n                {\n                    ?bn rr:datatype rdf:List .\n                    ?bn rr:predicate ?list_field .\n                    ?s ?p ?bn .\n                    ?s rr:subjectMap ?sm_bn .\n                    ?sm_bn rr:class ?subj_class .\n                }\"\"\")\n        list_preds = [(Uri(row[0]).sparql, Uri(row[1]).sparql)\n                      for row in results]\n        array_fields = {}\n        for tup in list_preds:\n            try:\n                array_fields[tup[0]].append(tup[1])\n            except KeyError:\n                array_fields[tup[0]] = [tup[1]]\n        self.array_fields = array_fields", "response": "Sets the array_fields attribute of the object that should be used to store the list of items that should be used to store the list of items that should be used to store the items in the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef json_ld(self, output, **kwargs):\n        raw_json_ld = output.serialize(format='json-ld',\n                                       context=self.context).decode()\n        # if there are fields that should be returned as arrays convert all\n        # non-array fields to an array\n        if not self.array_fields:\n            return raw_json_ld\n        json_data = json.loads(raw_json_ld)\n        for i, item in enumerate(json_data['@graph']):\n            if item.get(\"@type\") in self.array_fields:\n                test_flds = self.array_fields[item['@type']]\n                for key, val in item.items():\n                    if key in test_flds and not isinstance(val, list):\n                        json_data['@graph'][i][key] = [val]\n        # print(json.dumps(json_data, indent=4))\n        return json.dumps(json_data, indent=4)", "response": "Returns the json - ld formated result\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, triple_map, output, **kwargs):\n        subject = self.generate_term(term_map=triple_map.subjectMap,\n                                     **kwargs)\n        start_size = len(output)\n        all_subjects = []\n        for pred_obj_map in triple_map.predicateObjectMap:\n            predicate = pred_obj_map.predicate\n            if pred_obj_map.template is not None:\n                object_ = self.generate_term(term_map=pred_obj_map, **kwargs)\n                if len(str(object)) > 0:\n                    output.add((\n                        subject,\n                        predicate,\n                        object_))\n\n            if pred_obj_map.parentTriplesMap is not None:\n                self.__handle_parents__(\n                    parent_map=pred_obj_map.parentTriplesMap,\n                    subject=subject,\n                    predicate=predicate,\n                    **kwargs)\n            if pred_obj_map.reference is not None:\n                object_ = self.generate_term(term_map=pred_obj_map,\n                                             **kwargs)\n                if object_ and len(str(object_)) > 0:\n                    output.add((subject, predicate, object_))\n            if pred_obj_map.constant is not None:\n                output.add((subject, predicate, pred_obj_map.constant))\n        finish_size = len(output)\n        if finish_size > start_size:\n            output.add((subject,\n                             NS_MGR.rdf.type.rdflib,\n                             triple_map.subjectMap.class_))\n            all_subjects.append(subject)\n        return all_subjects", "response": "Method executes mapping between CSV source and RDF\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, triple_map, output, **kwargs):\n        subjects = []\n        logical_src_iterator = str(triple_map.logicalSource.iterator)\n        json_object = kwargs.get('obj', self.source)\n        # Removes '.' as a generic iterator, replace with '@'\n        if logical_src_iterator == \".\":\n            results = [None,]\n        else:\n            json_path_exp = jsonpath_ng.parse(logical_src_iterator)\n            results = [r.value for r in json_path_exp.find(json_object)][0]\n        for row in results:\n            subject = self.generate_term(term_map=triple_map.subjectMap,\n                                         **kwargs)\n            for pred_obj_map in triple_map.predicateObjectMap:\n                predicate = pred_obj_map.predicate\n                if pred_obj_map.template is not None:\n                    output.add((\n                        subject,\n                        predicate,\n                        self.generate_term(term_map=pred_obj_map, **kwargs)))\n\n                if pred_obj_map.parentTriplesMap is not None:\n                    self.__handle_parents__(\n                        output,\n                        parent_map=pred_obj_map.parentTriplesMap,\n                        subject=subject,\n                        predicate=predicate,\n                        obj=row,\n                        **kwargs)\n                if pred_obj_map.reference is not None:\n                    ref_exp = jsonpath_ng.parse(str(pred_obj_map.reference))\n                    found_objects = [r.value for r in ref_exp.find(row)]\n                    for obj in found_objects:\n                        if rdflib.term._is_valid_uri(obj):\n                            rdf_obj = rdflib.URIRef(str(obj))\n                        else:\n                            rdf_obj = rdflib.Literal(str(obj))\n                        output.add((subject, predicate, rdf_obj))\n                if pred_obj_map.constant is not None:\n                    output.add((subject,\n                                     predicate,\n                                     pred_obj_map.constant))\n            subjects.append(subject)\n        return subjects", "response": "Method executes mapping between JSON source and RDF object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, source, **kwargs):\n        kwargs['output'] = self.__graph__()\n        if isinstance(source, str):\n            import json\n            source = json.loads(source)\n        self.source = source\n        super(JSONProcessor, self).run(**kwargs)\n        self.output = kwargs['output']\n        return output", "response": "Method takes a JSON source and any keywords and transforms from Lean BIBFRAME 2. 0 triples\n            to Lean BIBFRAME 2. 0 triples\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, xml, **kwargs):\n        kwargs['output'] = self.__graph__()\n        if isinstance(xml, str):\n            try:\n                self.source = etree.XML(xml)\n            except ValueError:\n                try:\n                    self.source = etree.XML(xml.encode())\n                except:\n                    raise ValueError(\"Cannot run error {}\".format(sys.exc_info()[0]))\n        else:\n            self.source = xml\n        super(XMLProcessor, self).run(**kwargs)\n        self.output = kwargs['output']\n        return kwargs['output']", "response": "Method takes either an etree. ElementTree or raw XML text\n        as the first argument."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the query and return the result.", "response": "def execute(self, triple_map, output, **kwargs):\n        \"\"\"Execute \"\"\"\n        subjects = []\n        if NS_MGR.ql.JSON.rdflib in \\\n                triple_map.logicalSource.reference_formulations:\n            output_format = \"json\"\n        else:\n            output_format = \"xml\"\n        if 'limit' not in kwargs:\n            kwargs['limit'] = self.limit\n        if 'offset' not in kwargs:\n            kwargs['offset'] = self.offset\n        # log.debug(\"triple_map.logicalSource: \\n%s\",\n                  # pprint.pformat(triple_map.logicalSource.__dict__))\n        iterator = str(triple_map.logicalSource.iterator)\n        start = datetime.datetime.now()\n        key, json_query = None, None\n        # pdb.set_trace()\n        if hasattr(triple_map.logicalSource, 'json_query') \\\n                and self.use_json_qry:\n            key = kwargs.get(str(triple_map.logicalSource.json_key))\n            if not key:\n                key =[val for val in kwargs.values() \\\n                      if isinstance(val, rdflib.URIRef)][0]\n            json_query = triple_map.logicalSource.json_query\n            bindings = kwargs['dataset'].json_qry(json_query, {'$': key})\n        else:\n            sparql = PREFIX + triple_map.logicalSource.query.format(**kwargs)\n            bindings = self.__get_bindings__(sparql, output_format)\n        for binding in bindings:\n            if key:\n                try:\n                    entity_raw = binding.subject.rdflib\n                except AttributeError:\n                    entity_raw = binding\n            else:\n                entity_raw = binding.get(iterator)\n            if isinstance(entity_raw, (rdflib.URIRef,\n                                       rdflib.BNode,\n                                       BaseRdfDataType)):\n                entity = entity_raw\n            else:\n                raw_value = entity_raw.get('value')\n                if entity_raw.get('type').startswith('bnode'):\n                    entity = BlankNode(raw_value)\n                else:\n                    entity = Uri(raw_value)\n            if triple_map.subjectMap.class_ is not None:\n                sub = entity\n                if isinstance(entity, BaseRdfDataType):\n                    sub = entity.rdflib\n                output.add((sub,\n                                 NS_MGR.rdf.type.rdflib,\n                                 triple_map.subjectMap.class_))\n            # pdb.set_trace()\n            for pred_obj_map in triple_map.predicateObjectMap:\n                predicate = pred_obj_map.predicate\n                kwargs[iterator] = entity\n\n                if pred_obj_map.parentTriplesMap is not None:\n                    self.__handle_parents__(\n                            output=output,\n                            parent_map=pred_obj_map.parentTriplesMap,\n                            subject=entity,\n                            predicate=predicate,\n                            **kwargs)\n                    continue\n                if pred_obj_map.reference is not None:\n                    ref_key = str(pred_obj_map.reference)\n                    if pred_obj_map.json_query:\n                        # if pred_obj_map.json_query ==\"$.schema_logo\":\n                        # pdb.set_trace()\n                        if ref_key in binding:\n                            for item in binding[ref_key]:\n                                output.add((entity,\n                                                 predicate,\n                                                 item.rdflib))\n                            continue\n                    else:\n                        if ref_key in binding:\n                            object_ = __get_object__(\n                                binding[ref_key])\n                            output.add((entity, predicate, object_))\n                        continue\n                if pred_obj_map.constant is not None:\n                    if isinstance(entity, BaseRdfDataType):\n                        entity = entity.rdflib\n                    output.add(\n                        (entity, predicate, pred_obj_map.constant))\n                    continue\n\n                json_query = None\n                if pred_obj_map.json_query and self.use_json_qry:\n                    json_query = pred_obj_map.json_query\n                    start = datetime.datetime.now()\n                    # pdb.set_trace()\n                    # if str(pred_obj_map.predicate) == \"http://purl.org/dc/terms/creator\":\n                    #     pdb.set_trace()\n                    pre_obj_bindings = kwargs['dataset'].json_qry(json_query,\n                                                                  {'$': entity})\n                else:\n                    sparql_query = PREFIX + pred_obj_map.query.format(**kwargs)\n                    pre_obj_bindings = self.__get_bindings__(sparql_query,\n                                                             output_format)\n\n                for row in pre_obj_bindings:\n                    if json_query and self.use_json_qry:\n                        if isinstance(entity, BaseRdfDataType):\n                            entity = entity.rdflib\n                        output.add((entity, predicate, row.rdflib))\n                    else:\n                        object_ = __get_object__(row)\n                        if object_ is None:\n                            continue\n                        if isinstance(entity, BaseRdfDataType):\n                            entity = entity.rdflib\n                        output.add((entity, predicate, object_))\n            subjects.append(entity)\n        return subjects"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, message, _sender=None):\n        if not _sender:\n            context = get_context()\n            if context:\n                _sender = context.ref\n        if self._cell:\n            if not self._cell.stopped:\n                self._cell.receive(message, _sender)\n                return\n            else:\n                self._cell = None\n        if not self.is_local:\n            if self.uri.node != self.node.nid:\n                self.node.send_message(message, remote_ref=self, sender=_sender)\n            else:\n                self._cell = self.node.guardian.lookup_cell(self.uri)\n                self.is_local = True\n                self._cell.receive(message, _sender)\n        else:\n            if self.node and self.node.guardian:\n                cell = self.node.guardian.lookup_cell(self.uri)\n                if cell:\n                    cell.receive(message, _sender)  # do NOT set self._cell--it will never be unset and will cause a memleak\n                    return\n            if ('_watched', ANY) == message:\n                message[1].send(('terminated', self), _sender=self)\n            elif (message == ('terminated', ANY) or message == ('_unwatched', ANY) or message == ('_node_down', ANY) or\n                  message == '_stop' or message == '_kill' or message == '__done'):\n                pass\n            else:\n                Events.log(DeadLetter(self, message, _sender))", "response": "Sends a message to the actor represented by this Ref."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning just those errors associated with security", "response": "def security_errors(self):\n        \"\"\"Return just those errors associated with security\"\"\"\n        errors = ErrorDict()\n        for f in [\"honeypot\", \"timestamp\", \"security_hash\"]:\n            if f in self.errors:\n                errors[f] = self.errors[f]\n        return errors"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean_security_hash(self):\n        security_hash_dict = {\n            'content_type': self.data.get(\"content_type\", \"\"),\n            'object_pk': self.data.get(\"object_pk\", \"\"),\n            'timestamp': self.data.get(\"timestamp\", \"\"),\n        }\n        expected_hash = self.generate_security_hash(**security_hash_dict)\n        actual_hash = self.cleaned_data[\"security_hash\"]\n        if not constant_time_compare(expected_hash, actual_hash):\n            raise forms.ValidationError(\"Security hash check failed.\")\n        return actual_hash", "response": "Check the security hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking sure the timestamp isn t too far in the past.", "response": "def clean_timestamp(self):\n        \"\"\"Make sure the timestamp isn't too far (> 2 hours) in the past.\"\"\"\n        ts = self.cleaned_data[\"timestamp\"]\n        if time.time() - ts > (2 * 60 * 60):\n            raise forms.ValidationError(\"Timestamp check failed\")\n        return ts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_security_data(self):\n        timestamp = int(time.time())\n        security_dict = {\n            'content_type': str(self.target_object._meta),\n            'object_pk': str(self.target_object._get_pk_val()),\n            'timestamp': str(timestamp),\n            'security_hash': self.initial_security_hash(timestamp),\n        }\n        return security_dict", "response": "Generate a dict of security data for initial data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the initial security hash from self. content_object and a UNIX timestamp.", "response": "def initial_security_hash(self, timestamp):\n        \"\"\"\n        Generate the initial security hash from self.content_object\n        and a (unix) timestamp.\n        \"\"\"\n\n        initial_security_dict = {\n            'content_type': str(self.target_object._meta),\n            'object_pk': str(self.target_object._get_pk_val()),\n            'timestamp': str(timestamp),\n        }\n        return self.generate_security_hash(**initial_security_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a HMAC security hash from the provided info.", "response": "def generate_security_hash(self, content_type, object_pk, timestamp):\n        \"\"\"\n        Generate a HMAC security hash from the provided info.\n        \"\"\"\n        info = (content_type, object_pk, timestamp)\n        key_salt = \"django.contrib.forms.CommentSecurityForm\"\n        value = \"-\".join(info)\n        return salted_hmac(key_salt, value).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_comment_object(self):\n        if not self.is_valid():\n            raise ValueError(\"get_comment_object may only be called on valid forms\")\n\n        CommentModel = self.get_comment_model()\n        new = CommentModel(**self.get_comment_create_data())\n        new = self.check_for_duplicate_comment(new)\n\n        return new", "response": "Returns a new Comment object based on the information in this object s form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_comment_create_data(self):\n        user_model = get_user_model()\n        return dict(\n            content_type=ContentType.objects.get_for_model(self.target_object),\n            object_pk=force_text(self.target_object._get_pk_val()),\n            text=self.cleaned_data[\"text\"],\n            user=user_model.objects.latest('id'),\n            post_date=timezone.now(),\n            site_id=settings.SITE_ID,\n            is_public=True,\n            is_removed=False,\n        )", "response": "Returns the dict of data to be used to create a comment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_for_duplicate_comment(self, new):\n        possible_duplicates = self.get_comment_model()._default_manager.using(\n            self.target_object._state.db\n        ).filter(\n            content_type=new.content_type,\n            object_pk=new.object_pk\n        )\n        for old in possible_duplicates:\n            if old.post_date.date() == new.post_date.date() and old.text == new.text:\n                return old\n\n        return new", "response": "Check that a submitted comment isn t a duplicate."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that the comment doesn t contain any PROFANITIES_LIST.", "response": "def clean_comment(self):\n        \"\"\"\n        If COMMENTS_ALLOW_PROFANITIES is False, check that the comment doesn't\n        contain anything in PROFANITIES_LIST.\n        \"\"\"\n        comment = self.cleaned_data[\"text\"]\n        if settings.COMMENTS_ALLOW_PROFANITIES is False:\n            bad_words = [w for w in settings.PROFANITIES_LIST if w in comment.lower()]\n            if bad_words:\n                raise forms.ValidationError(ungettext(\n                    \"Watch your mouth! The word %s is not allowed here.\",\n                    \"Watch your mouth! The words %s are not allowed here.\",\n                    len(bad_words)) % get_text_list(\n                        ['\"%s%s%s\"' % (i[0], '-'*(len(i)-2), i[-1])\n                         for i in bad_words], ugettext('and')))\n        return comment"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_honeypot(self):\n        value = self.cleaned_data[\"honeypot\"]\n        if value:\n            raise forms.ValidationError(self.fields[\"honeypot\"].label)\n        return value", "response": "Check that nothing s been entered into the honeypot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef include_original(dec):\n    def meta_decorator(method):\n        \"\"\"Yo dawg, I heard you like decorators...\"\"\"\n        # pylint: disable=protected-access\n        decorator = dec(method)\n        decorator._original = method\n        return decorator\n    return meta_decorator", "response": "Decorate decorators so they include a copy of the original function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending hello to device", "response": "def sendhello(self):\r\n        try:\r\n            # send hello\r\n            cli_hello_msg = \"<hello>\\n\" +\\\r\n                            \"  <capabilities>\\n\" +\\\r\n                            \"    <capability>urn:ietf:params:netconf:base:1.0</capability>\\n\" +\\\r\n                            \"  </capabilities>\\n\" +\\\r\n                            \"</hello>\\n\"\r\n            self._cParams.set('cli_hello', cli_hello_msg)\r\n            self._hConn.sendmsg(cli_hello_msg)\r\n\r\n            # recv hello\r\n            ser_hello_msg = self._hConn.recvmsg()\r\n            self._cParams.set('ser_hello', ser_hello_msg)\r\n        except:\r\n            print 'BNClient: Call sendhello fail'\r\n            sys.exit()\r\n\r\n        \"\"\" end of function exchgcaps \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a message to the server", "response": "def sendrpc(self, argv=[]):\r\n        self._aArgv += argv\r\n        _operation = ''\r\n        try:\r\n            self._cParams.parser(self._aArgv, self._dOptions)\r\n\r\n            # set rpc operation handler\r\n            while self._cParams.get('operation') not in rpc.operations.keys():\r\n                self._cParams.set('operation', raw_input(\"Enter RPC Operation:\\n%s:\" % rpc.operations.keys()))\r\n\r\n            _operation = self._cParams.get('operation')\r\n            self._hRpcOper = rpc.operations[_operation](opts=self._dOptions)\r\n            # input missing operation parameters\r\n            self._hRpcOper.fill(params=self._cParams.get())\r\n\r\n            send_msg = self._hRpcOper.readmsg(self._cParams.get())\r\n            self._cParams.set('messageid', self._cParams.get('messageid')+1)\r\n            self._hConn.sendmsg(send_msg)\r\n            self._cParams.set('sendmsg', send_msg)\r\n\r\n            recv_msg = self._hConn.recvmsg()\r\n            self._cParams.set('recvmsg', recv_msg)\r\n            self._hRpcOper.parsemsg(self._cParams.get())\r\n            self._hRpcOper.writemsg(self._cParams.get())\r\n\r\n            # reset operation params\r\n            self._cParams.reset()\r\n        except:\r\n            if _operation != 'close-session':\r\n                print 'BNClient: Call sendrpc%s fail' % (' <'+_operation+'>' if len(_operation) else '')\r\n            sys.exit()\r\n\r\n        \"\"\" end of function exchgmsg \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_templatetags():\n    from turboengine.conf import settings\n    from google.appengine.ext.webapp import template\n    for python_file in settings.TEMPLATE_PATH:\n        template.register_template_library(python_file)", "response": "Register templatetags defined in settings as basic templatetags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_hosts(self, pattern=\"all\"):\n\n        # process patterns\n        if isinstance(pattern, list):\n            pattern = ';'.join(pattern)\n        patterns = pattern.replace(\";\",\":\").split(\":\")\n        hosts = self._get_hosts(patterns)\n\n        # exclude hosts not in a subset, if defined\n        if self._subset:\n            subset = self._get_hosts(self._subset)\n            hosts.intersection_update(subset)\n\n        # exclude hosts mentioned in any restriction (ex: failed hosts)\n        if self._restriction is not None:\n            hosts = [ h for h in hosts if h.name in self._restriction ]\n        if self._also_restriction is not None:\n            hosts = [ h for h in hosts if h.name in self._also_restriction ]\n\n        return sorted(hosts, key=lambda x: x.name)", "response": "get hosts matching a pattern string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_hosts(self, pattern):\n\n        (name, enumeration_details) = self._enumeration_info(pattern)\n        hpat = self._hosts_in_unenumerated_pattern(name)\n        hpat = sorted(hpat, key=lambda x: x.name)\n\n        return set(self._apply_ranges(pattern, hpat))", "response": "Returns a set of hosts that match a particular pattern."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an enumeration of the entries in the cache entry.", "response": "def _enumeration_info(self, pattern):\n        \"\"\"\n        returns (pattern, limits) taking a regular pattern and finding out\n        which parts of it correspond to start/stop offsets.  limits is\n        a tuple of (start, stop) or None\n        \"\"\"\n\n        if not \"[\" in pattern or pattern.startswith('~'):\n            return (pattern, None)\n        (first, rest) = pattern.split(\"[\")\n        rest = rest.replace(\"]\",\"\")\n        if \"-\" in rest:\n            (left, right) = rest.split(\"-\",1)\n            return (first, (left, right))\n        else:\n            return (first, (rest, rest))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all of the hosts that match pat", "response": "def _apply_ranges(self, pat, hosts):\n        \"\"\"\n        given a pattern like foo, that matches hosts, return all of hosts\n        given a pattern like foo[0:5], where foo matches hosts, return the first 6 hosts\n        \"\"\" \n\n        (loose_pattern, limits) = self._enumeration_info(pat)\n        if not limits:\n            return hosts\n\n        (left, right) = limits\n        enumerated = enumerate(hosts)\n        if left == '':\n            left = 0\n        if right == '':\n            right = 0\n        left=int(left)\n        right=int(right)\n        enumerated = [ h for (i,h) in enumerated if i>=left and i<=right ]\n        return enumerated"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _hosts_in_unenumerated_pattern(self, pattern):\n\n        hosts = {}\n        # ignore any negative checks here, this is handled elsewhere\n        pattern = pattern.replace(\"!\",\"\").replace(\"&\", \"\")\n\n        groups = self.get_groups()\n        for group in groups:\n            for host in group.get_hosts():\n                if pattern == 'all' or self._match(group.name, pattern) or self._match(host.name, pattern):\n                    hosts[host.name] = host\n        return sorted(hosts.values(), key=lambda x: x.name)", "response": "Get all hosts that match the pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restrict_to(self, restriction):\n        if type(restriction) != list:\n            restriction = [ restriction ]\n        self._restriction = restriction", "response": "Restrict list operations to the hosts given in restriction."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestricts the set of entries that are also available to the given resource.", "response": "def also_restrict_to(self, restriction):\n        \"\"\"\n        Works like restict_to but offers an additional restriction.  Playbooks use this\n        to implement serial behavior.\n        \"\"\"\n        if type(restriction) != list:\n            restriction = [ restriction ]\n        self._also_restriction = restriction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subset(self, subset_pattern):\n        if subset_pattern is None:\n            self._subset = None\n        else:\n            subset_pattern = subset_pattern.replace(',',':')\n            self._subset = subset_pattern.replace(\";\",\":\").split(\":\")", "response": "Sets the subset of the inventory results to a subset of inventory that matches a given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbeing the inventory come from a file?", "response": "def is_file(self):\n        \"\"\" did inventory come from a file? \"\"\"\n        if not isinstance(self.host_list, basestring):\n            return False\n        return os.path.exists(self.host_list)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeploying the given package.", "response": "def deploy(self, package=None):\n        \"\"\" If package is none, use `deployment_package.default()` \"\"\"\n        if package is None:\n            package = deployment_package.default()\n        package.deploy()\n        if self.proper_name in installed_functions():\n            self.update(package)\n        else:\n            self.install(package)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(tag, end_tag=None):\n\n    def register_function(function):\n        tagmap[tag] = {'func': function, 'endtag': end_tag}\n        if end_tag:\n            tagmap['endtags'].append(end_tag)\n        return function\n\n    return register_function", "response": "Decorator for registering shortcode functions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_time_param(t):\n\n    if type(t) is str:\n        if not ISO.match(t):\n            raise ValueError('Date string \"%s\" does not match ISO8601 format' %\n                             (t))\n        return t\n    else:\n        return t.isoformat()", "response": "Checks whether a string sent in matches the ISO8601 format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_iso_stamp(t, tz=None):\n\n    if t is None:\n        return None\n\n    dt = dateutil.parser.parse(t)\n    if tz is not None:\n        timezone = pytz.timezone(tz)\n        if dt.tzinfo is None:\n            dt = timezone.localize(dt)\n    return dt", "response": "Convert a string in ISO8601 form into a Datetime object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the name of the weekday after the given weekday name.", "response": "def next_weekday(weekday):\n    \"\"\"Returns the name of the weekday after the given weekday name.\"\"\"\n    ix = WEEKDAYS.index(weekday)\n    if ix == len(WEEKDAYS)-1:\n        return WEEKDAYS[0]\n    return WEEKDAYS[ix+1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name of the weekday before the given weekday name.", "response": "def prev_weekday(weekday):\n    \"\"\"Returns the name of the weekday before the given weekday name.\"\"\"\n    ix = WEEKDAYS.index(weekday)\n    if ix == 0:\n        return WEEKDAYS[len(WEEKDAYS)-1]\n    return WEEKDAYS[ix-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef workdays(first_day=None):\n    if first_day is None:\n        first_day = 'Monday'\n    ix = _lower_weekdays().index(first_day.lower())\n    return _double_weekdays()[ix:ix+5]", "response": "Returns a list of workday names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef weekdays(first_day=None):\n    if first_day is None:\n        first_day = 'Monday'\n    ix = _lower_weekdays().index(first_day.lower())\n    return _double_weekdays()[ix:ix+7]", "response": "Returns a list of weekday names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if successful False otherwise.", "response": "def getPrice(self, searches):\n        \"\"\" Prices all quest items and returns result\n        \n        Searches the shop wizard x times (x being number given in searches) for each\n        quest item and finds the lowest price for each item. Combines all item prices\n        and sets KitchenQuest.npSpent to the final value. Returns whether or not this\n        process was successful. \n           \n        Parameters:\n           searches (int) -- The number of times to search the Shop Wizard for each quest item\n           \n        Returns\n           bool - True if successful, otherwise False\n        \"\"\"\n        totalPrice = 0\n        \n        for item in self.items:\n            res = ShopWizard.priceItem(self.usr, item.name, searches, ShopWizard.RETLOW)\n            \n            if not res:\n                self.failedItem = item.name\n                return False\n            \n            item.price, item.owner, item.id = res\n            totalPrice += item.price\n            \n        self.npSpent = totalPrice\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nattempting to buy all quest items returns result alid", "response": "def buyQuestItems(self):\n        \"\"\" Attempts to buy all quest items, returns result\n           \n        Returns\n           bool - True if successful, otherwise False\n        \"\"\"\n        for item in self.items:\n            us = UserShopFront(self.usr, item.owner, item.id, str(item.price))\n            us.loadInventory()\n            \n            if not item.name in us.inventory:\n                return False\n                \n            if not us.inventory[item.name].buy():\n                return False\n                \n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef submitQuest(self):\n        \n        form = pg.form(action=\"kitchen2.phtml\")\n        pg = form.submit()\n        \n        if \"Woohoo\" in pg.content:\n            try:\n                self.prize = pg.find(text = \"The Chef waves his hands, and you may collect your prize...\").parent.parent.find_all(\"b\")[-1].text\n            except Exception:\n                logging.getLogger(\"neolib.quest\").exception(\"Failed to parse kitchen quest prize\", {'pg': pg})\n                raise parseException\n                \n            return True\n        else:\n            logging.getLogger(\"neolib.quest\").info(\"Failed to complete kitchen quest\", {'pg': pg})\n            return False", "response": "Submits the active quest returns result\nalid"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef youtube(no_controls, no_autoplay, store, store_name, youtube_url):\n    old_url_colour = 'blue'\n    new_url_colour = 'green'\n    echo('Format --> {0}: {1}'.format(\n        style('Original URL/Stored Title', fg=old_url_colour),\n        style('New URL', fg=new_url_colour)\n    ))\n    for url in youtube_url:\n        new_url = convert_youtube_url(url, no_controls, no_autoplay)\n        if store:\n            if store_name is not None:\n                url = store_name\n            store_data({url: new_url})\n        echo('{}: {}'.format(\n            style(url, fg=old_url_colour),\n            style(new_url, fg=new_url_colour)\n        ))", "response": "Convert a Youtube URL so that Helium can handle it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list():\n    for name, url in get_all_data().items():\n        echo('{}: {}'.format(\n            style(name, fg='blue'),\n            style(url, fg='green')\n        ))", "response": "List all of the stored URLs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget class by its name within a package structure.", "response": "def get_class_by_path(class_path: str, is_module: Optional[bool] = False) -> type:\n    \"\"\"\n    Get class by its name within a package structure.\n\n    :param class_path: E.g. brandt.some.module.ClassName\n    :param is_module: Whether last item is module rather than class name\n    :return: Class ready to be instantiated.\n    \"\"\"\n\n    if is_module:\n        try:\n            backend_module = importlib.import_module(class_path)\n        except ImportError:\n            logger.warning(\"Can't import backend with name `%s`\", class_path)\n            raise\n        else:\n            return backend_module\n\n    module_name, class_name = class_path.rsplit('.', 1)\n\n    try:\n        backend_module = importlib.import_module(module_name)\n    except ImportError:\n        logger.error(\"Can't import backend with name `%s`\", module_name)\n        raise\n\n    try:\n        backend_class = getattr(backend_module, class_name)\n    except AttributeError:\n        logger.error(\"Can't get backend class `%s` from `%s`\", class_name, module_name)\n        raise\n\n    return backend_class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_submodule_list(package_path: str) -> Tuple[ModuleDescription, ...]:\n    pkg = importlib.import_module(package_path)\n\n    subs = (\n        ModuleDescription(\n            name=modname,\n            path=\"{}.{}\".format(package_path, modname), is_package=ispkg\n        )\n        for importer, modname, ispkg in pkgutil.iter_modules(pkg.__path__)\n    )\n    result = tuple(subs)\n    return result", "response": "Get list of submodules for some package by its path. E. g. pkg. subpackage."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun parallel execution of futures and return a dictionary of the results.", "response": "async def parallel_results(future_map: Sequence[Tuple]) -> Dict:\n    \"\"\"\n    Run parallel execution of futures and return mapping of their results to the provided keys.\n    Just a neat shortcut around ``asyncio.gather()``\n\n    :param future_map: Keys to futures mapping, e.g.: ( ('nav', get_nav()), ('content, get_content()) )\n    :return: Dict with futures results mapped to keys {'nav': {1:2}, 'content': 'xyz'}\n    \"\"\"\n    ctx_methods = OrderedDict(future_map)\n    fs = list(ctx_methods.values())\n    results = await asyncio.gather(*fs)\n    results = {\n        key: results[idx] for idx, key in enumerate(ctx_methods.keys())\n    }\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef positive_int(integer_string: str, strict: bool = False, cutoff: Optional[int] = None) -> int:\n    ret = int(integer_string)\n    if ret < 0 or (ret == 0 and strict):\n        raise ValueError()\n    if cutoff:\n        ret = min(ret, cutoff)\n    return ret", "response": "Cast a string to a strictly positive integer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef choices_from_enum(source: Enum) -> Tuple[Tuple[Any, str], ...]:\n    result = tuple((s.value, s.name.title()) for s in source)\n    return result", "response": "Takes an Enum and returns a tuple that can be used in Django s Fields choices attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the key_or_keypath is inside the dictionary.", "response": "def contains(self, key_or_keypath):\n        \"\"\" Allows the 'in' operator to work for checking if a particular key (or keypath)\n        is inside the dictionary. \"\"\"\n        if isinstance(key_or_keypath, list):\n            if len(key_or_keypath) == 0:\n                # empty list is root\n                return False\n            val = self \n            next_key = None\n            for next_key in key_or_keypath:\n                if next_key in val:\n                    val = val[next_key]\n                else:\n                    return False\n            return True\n        else:\n            return key_or_keypath in self.__dict__['p']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value at the end of a keypath or None if no such key is found.", "response": "def get_value_from_path(self, keypath):\n        \"\"\"\n        Returns the value at the end of keypath (or None)\n        keypath is a list of keys, e.g., [\"key\", \"subkey\", \"subsubkey\"]\n        \"\"\"\n        if isinstance(keypath, list):\n            if len(keypath) == 0:\n                # empty list is root\n                return \n            val = self \n            for next_key in keypath:\n                val = val[next_key]\n            return val\n        else:\n            return self.__dict__['p'][keypath]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if all of self s keys and values are in and within other s COOKIES.", "response": "def is_entailed_by(self, other):\n        \"\"\"\n        Whether all of self's keys (and values) are in (and within) other's\n        \"\"\"\n        for (s_key, s_val) in self:\n            if s_key in other:\n                if not other[s_key].entails(s_val):\n                    return False\n            else:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_contradictory(self, other):\n        if not isinstance(other, DictCell):\n            raise Exception(\"Incomparable\")\n        for key, val in self:\n            if key in other.__dict__['p'] \\\n                    and val.is_contradictory(other.__dict__['p'][key]):\n                return True\n        return False", "response": "Returns True if the two DictCells are unmergeable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if two DictCells are equal.", "response": "def is_equal(self, other):\n        \"\"\" Two DictCells are equal when they share ALL Keys,  and all of their \n        is_equal() methods return True.  This ensures substructure equality.\n        \"\"\"\n        if not isinstance(other, DictCell):\n            return False\n        for (this, that) in itertools.izip_longest(self, other):\n            if this[0] != that[0]:\n                # compare key names\n                return False\n            if not this[1].is_equal(that[1]):\n                # compare cells\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge two complex structures by recursively merging their parts.", "response": "def merge(self, other):\n        \"\"\"\n        Merges two complex structures (by recursively merging their parts).\n        Missing-parts do not trigger contradictions.\n        \"\"\"\n        if not isinstance(other, DictCell):\n            raise Exception(\"Incomparable\")\n        if self.is_equal(other):\n            # pick among dependencies\n            return self\n        elif other.is_entailed_by(self):\n            return self\n        elif self.is_entailed_by(other):\n            self.__dict__['p'] = other.__dict__['p'].copy()\n        elif not self.is_contradictory(other):\n            # partial information in both, add from other\n            for o_key, o_val in other:\n                if not o_key in self.__dict__['p']:\n                    self.__dict__['p'][o_key] = o_val\n                else:\n                    self.__dict__['p'][o_key].merge(o_val)\n        else:\n            raise Contradiction(\"Dictionaries are contractory, cannot Merge\")\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_dict(self):\n        output = {}\n        for key, value in self.__dict__['p'].iteritems():\n            if value is None or isinstance(value, SIMPLE_TYPES):\n                output[key] = value\n            elif hasattr(value, 'to_dot'):\n                output[key] = value.to_dot()\n            elif hasattr(value, 'to_dict'):\n                output[key] = value.to_dict()\n            elif isinstance(value, datetime.date):\n                # Convert date/datetime to ms-since-epoch (\"new Date()\").\n                ms = time.mktime(value.utctimetuple()) * 1000\n                ms += getattr(value, 'microseconds', 0) / 1000\n                output[key] = int(ms)\n            elif isinstance(value, dict):\n                output[key] = []\n            else:\n                raise ValueError('cannot encode ' + repr(key))\n\n        return output", "response": "This method converts the DictCell into a python dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a LaTeX representation of the attribute - value matrix.", "response": "def to_latex(self):\n        \"\"\" Returns a LaTeX representation of an attribute-value matrix \"\"\"\n        latex = r\"[{} \" \n        for attribute, value in self:\n            if attribute in ['speaker_model', 'is_in_commonground']: continue\n            value_l = value.to_latex()\n            if value_l == \"\": continue\n            latex += \"{attribute:<15} &  {value:<20} \\\\\\\\ \\n\".format(attribute=attribute, value=value_l)\n        latex += \"]\\n\"\n        return latex"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_of_month(d, d_years=0, d_months=0):\n    y, m = d.year + d_years, d.month + d_months\n    a, m = divmod(m-1, 12)\n    return date(y+a, m+1, 1)", "response": "Given a date d return a date first day of the month."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of business days between two inclusive dates.", "response": "def business_days(start, stop):\n    \"\"\"\n    Return business days between two inclusive dates - ignoring public holidays.\n    \n    Note that start must be less than stop or else 0 is returned.\n    \n    @param start: Start date\n    @param stop: Stop date\n    @return int\n    \"\"\"\n    dates=rrule.rruleset()\n    # Get dates between start/stop (which are inclusive)\n    dates.rrule(rrule.rrule(rrule.DAILY, dtstart=start, until=stop))\n    # Exclude Sat/Sun \n    dates.exrule(rrule.rrule(rrule.DAILY, byweekday=(rrule.SA, rrule.SU), dtstart=start)) \n    return dates.count()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef days(start, stop):\n    dates=rrule.rruleset()\n    # Get dates between start/stop (which are inclusive)\n    dates.rrule(rrule.rrule(rrule.DAILY, dtstart=start, until=stop))\n    return dates.count()", "response": "Return the number of days between start & stop"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of anniversaries periods between start and finish.", "response": "def get_anniversary_periods(start, finish, anniversary=1):\n    \"\"\"\n    Return a list of anniversaries periods between start and finish. \n    \"\"\"\n    import sys\n    current = start\n    periods = []\n    while current <= finish:\n        (period_start, period_finish) = date_period(DATE_FREQUENCY_MONTHLY, anniversary, current)\n        current = period_start + relativedelta(months=+1)\n        period_start = period_start if period_start > start else start\n        period_finish = period_finish if period_finish < finish else finish\n        periods.append((period_start, period_finish))\n    return periods"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple with start stop dates.", "response": "def date_period(frequency, anniversary, now=None):\n    \"\"\"\n    Retrieve a date period given a day of month.\n    \n    For example, if the period is month:15 and now is equal\n    to 2012-11-22 then this method will return the following:\n    \n        (date(2012, 11, 15), date(2012, 12, 14)) \n    \n    Other examples:\n        monthly:1 with now 2012-12-1 would return: (date(2012, 11, 1), date(2012, 12, 1))\n    \n    @param now: A date used to determine some point within a date period.\n    @return tuple with date start and stop dates.\n    @raise MaxAnniversaryDayError\n    @raise DateFrequencyError\n    \"\"\"\n    if frequency != DATE_FREQUENCY_MONTHLY:\n        raise DateFrequencyError(\"Only monthly date frequency is supported - not '%s'\" % (frequency))\n    \n    if anniversary > 28:\n        raise MaxAnniversaryDayError(\"'%s' is greater than maximum allowed anniversary day 28.\" % anniversary)\n    \n    if not now:\n        now = date.now()\n   \n    if now.day >= anniversary:\n        start = date(now.year, now.month, anniversary)\n        stop = start + relativedelta(months=+1) + relativedelta(days=-1)\n    else:\n        stop = date(now.year, now.month, anniversary)\n        start = stop + relativedelta(months=-1)\n        stop = stop  + relativedelta(days=-1)\n    return (start, stop,)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exact_anniversaries(frequency, anniversary, start, finish):\n    if frequency != DATE_FREQUENCY_MONTHLY:\n        raise DateFrequencyError(\"Only monthly date frequency is supported - not '%s'\" % (frequency))\n    \n    if start.day != anniversary:\n        return False\n\n    periods = 0\n    current = start\n    while current <= finish:\n        period_end = current + relativedelta(months=+1, days=-1)\n        if period_end <= finish:\n            periods += 1\n        else:\n            return False\n        current = current + relativedelta(months=+1)\n    return periods", "response": "Returns the number of exact anniversaries for a given month."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quarter(d):\n    from django_toolkit.datetime_util import quarter as datetime_quarter\n    first_date, last_date = datetime_quarter(datetime(d.year, d.month, d.day))\n    return first_date.date(), last_date.date()", "response": "Return start and stop datetime for the quarter as defined by dt."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the previous quarter for a date", "response": "def previous_quarter(d):\n    \"\"\"\n    Retrieve the previous quarter for dt\n    \"\"\"\n    from django_toolkit.datetime_util import quarter as datetime_quarter\n    return quarter( (datetime_quarter(datetime(d.year, d.month, d.day))[0] + timedelta(days=-1)).date() )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, script):\n\t\n\t\t\"\"\"\n\t\tExecute script.\n\t\t\n\t\t:param str script:\n\t\t   Script to be executed.\n\t\t\"\"\"\n\t\t\n\t\ttry:\n\t\t\tconn = self.__connect()\n\t\t\tconn.cursor().execute(script)\n\t\t\tconn.commit()\n\t\tfinally:\n\t\t\tconn.close()", "response": "Execute a SQL script."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply database changes. :param resort.engine.execution.Context context: Current execution context.", "response": "def insert(self, context):\n\t\n\t\t\"\"\"\n\t\tApplies database changes.\n\t\t\n\t\t:param resort.engine.execution.Context context:\n\t\t   Current execution context.\n\t\t\"\"\"\n\t\t\n\t\tscript_path = context.resolve(self.__script_path)\n\t\tbuf = io.StringIO()\n\t\tself.__preprocess(script_path, buf)\n\t\tbuf.seek(0)\n\t\tself.__conn.execute(buf.read())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_workshift_profile(sender, instance, created, **kwargs):\n    '''\n    Function to add a workshift profile for every User that is created.\n    Parameters:\n        instance is an of UserProfile that was just saved.\n    '''\n    if instance.user.username == ANONYMOUS_USERNAME or \\\n       instance.status != UserProfile.RESIDENT:\n        return\n\n    try:\n        semester = Semester.objects.get(current=True)\n    except (Semester.DoesNotExist, Semester.MultipleObjectsReturned):\n        pass\n    else:\n        profile, created = WorkshiftProfile.objects.get_or_create(\n            user=instance.user,\n            semester=semester,\n        )\n        if created:\n            utils.make_workshift_pool_hours(\n                semester=semester,\n                profiles=[profile],\n            )", "response": "Function to add a workshift profile for every User that is just saved."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_field_changed(instance, old_instance, field_name, update_fields=None):\n    if update_fields is not None and field_name not in update_fields:\n        return False\n\n    return getattr(instance, field_name) != getattr(old_instance, field_name)", "response": "Checks if a field has changed prior to the instance being saved."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplaying the match. This match simulator iterates through two lists of random numbers 25 times, one for each team, comparing the numbers and awarding a point to the team with the higher number. The team with more points at the end of the lists wins and is recorded in the winner field. If the result is a draw, the winner field is set to None. @return: The winner (or None if the result is a draw) @rtype: An object that can be converted to a string or NoneType", "response": "def play(self):\n        \"\"\"Play the match.\n\n        This match simulator iterates through two lists of random numbers\n        25 times, one for each team, comparing the numbers and awarding a point\n        to the team with the higher number. The team with more points at the\n        end of the lists wins and is recorded in the winner field. If the result\n        is a draw, the winner field is set to None.\n\n        @return: The winner (or None if the result is a draw)\n        @rtype: An object that can be converted to a string or NoneType\n        \"\"\"\n        score1 = 0\n        score2 = 0\n        for __ in range(25):\n            num1 = random.randint(0, 100)\n            num2 = random.randint(0, 100)\n            if num1 > num2:\n                score1 += 1\n            elif num2 > num1:\n                score2 += 1\n        if score1 > score2:\n            self.winner = self.team1\n            self.loser = self.team2\n            self.drawn = False\n        elif score2 > score1:\n            self.winner = self.team2\n            self.loser = self.team1\n            self.drawn = False\n        else:\n            self.winner = None\n            self.loser = None\n            self.drawn = True\n        self.score1 = score1\n        self.score2 = score2\n        return self.winner"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new logger with the specified name.", "response": "def create_logger(name, formatter=None, handler=None, level=None):\n    \"\"\"\n    Returns a new logger for the specified name.\n    \"\"\"\n    logger = logging.getLogger(name)\n\n    #: remove existing handlers\n    logger.handlers = []\n\n    #: use a standard out handler\n    if handler is None:\n        handler = logging.StreamHandler(sys.stdout)\n\n    #: set the formatter when a formatter is given\n    if formatter is not None:\n        handler.setFormatter(formatter)\n\n    #: set DEBUG level if no level is specified\n    if level is None:\n        level = logging.DEBUG\n\n    handler.setLevel(level)\n    logger.setLevel(level)\n    logger.addHandler(handler)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_calendar(campus, resp_fragment, calendar_dict, parent):\n    for record in resp_fragment:\n        if re.match(r'Internal Event Actions', record['Name']) or\\\n                re.match(r'Migrated .*', record['Name']):\n            continue\n        trumba_cal = TrumbaCalendar()\n        trumba_cal.calendarid = record['ID']\n        trumba_cal.campus = campus\n        if parent is None:\n            trumba_cal.name = record['Name']\n        else:\n            trumba_cal.name = \"%s >> %s\" % (parent, record['Name'])\n\n        if not _is_valid_calendarid(record['ID']):\n            logger.warn(\n                \"InvalidCalendarId %s, entry skipped!\" % trumba_cal)\n            continue\n\n        calendar_dict[trumba_cal.calendarid] = trumba_cal\n        if record['ChildCalendars'] is not None and\\\n                len(record['ChildCalendars']) > 0:\n            _load_calendar(campus,\n                           record['ChildCalendars'],\n                           calendar_dict,\n                           trumba_cal.name)", "response": "Load calendars from the response fragment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_permissions(campus, calendarid, resp_fragment, permission_list):\n    for record in resp_fragment:\n        if not _is_valid_email(record['Email']):\n            # skip the non UW users\n            continue\n        perm = Permission()\n        perm.calendarid = calendarid\n        perm.campus = campus\n        perm.uwnetid = _extract_uwnetid(record['Email'])\n        perm.level = record['Level']\n        perm.name = str(record['Name'])\n        permission_list.append(perm)", "response": "Load the permissions from the response fragment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef splitpreserve(s,redelim=r'\\s'):\r\n  'split, but preserves the delimiter so the string can be reassembled with double-spaces (etc) intact'\r\n  pattern='[^%s]*%s*'%(redelim,redelim)\r\n  return re.findall(pattern,s)", "response": "split but preserves the delimiter so the string can be reassembled with double - spaces intact"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef applydiff(tokens,deltas):\r\n  \"tokens can be a string or a list of strings.\\\r\n  deltas is [Delta,...]. Delta.text is actually a tokenlist of the same type as tokens (string or list of string).\\\r\n  If tokens & tokenslist are strings, must be unicode for the offsets to match what JS produces.\\\r\n    (If they're lists, it doesn't matter; the offsets are relative to the lists, not internal to the strings).\"\r\n  sizechange=0\r\n  for a,b,replace in deltas:\r\n    tokens=tokens[:a+sizechange]+replace+tokens[b+sizechange:]\r\n    sizechange+=len(replace)-(b-a)\r\n  return tokens", "response": "tokens can be a string or a list of strings. deltas is [ Delta... ]. text is actually a tokenlist of the same type as tokens."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef splitstatus(a,statusfn):\r\n  'split sequence into subsequences based on binary condition statusfn. a is a list, returns list of lists'\r\n  groups=[]; mode=None\r\n  for elt,status in zip(a,map(statusfn,a)):\r\n    assert isinstance(status,bool)\r\n    if status!=mode: mode=status; group=[mode]; groups.append(group)\r\n    group.append(elt)\r\n  return groups", "response": "split sequence into subsequences based on binary condition statusfn. a is a list returns list of lists"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ungroupslice(groups,gslice):\r\n  'this is a helper for contigsub.'\r\n  'coordinate transform: takes a match from seqingroups() and transforms to ungrouped coordinates'\r\n  eltsbefore=0\r\n  for i in range(gslice[0]): eltsbefore+=len(groups[i])-1\r\n  x=eltsbefore+gslice[1]; return [x-1,x+gslice[2]-1]", "response": "this is a helper for contigsub."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef contigsub(a,b):\r\n  'find longest common substring. return its slice coordinates (in a and b; see last line) or None if not found'\r\n  'a and b are token lists'\r\n  common=commonelts(a,b); groupsa=groupelts(a,common); groupsb=groupelts(b,common)\r\n  bestmatch=[None,None,0]; bslice=None\r\n  for i in range(len(groupsb)):\r\n    if not groupsb[i][0]: continue\r\n    if len(groupsb[i])-1<=bestmatch[2]: continue # this whole segment can't beat our best match so far\r\n    for j in range(len(groupsb[i])):\r\n      match=seqingroups(groupsa,groupsb[i][j:])\r\n      if match and match[2]>bestmatch[2]: bestmatch=match; bslice=[i,j,match[2]]\r\n      if match and match[2]>=(len(groupsb[i])/2.0): break # i.e. this is as good as we're going to get for groupsb[i], skip the rest. TODO: write a test for this\r\n  return None if not bestmatch[2] else (ungroupslice(groupsa,bestmatch),ungroupslice(groupsb,bslice))", "response": "find longest common substring. return its slice coordinates in a and b or None if not found"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake diff run on separated words and convert the deltas to character offsets", "response": "def translate_diff(origtext,deltas):\r\n  'take diff run on separated words and convert the deltas to character offsets'\r\n  lens=[0]+cumsum(map(len,splitpreserve(origtext))) # [0] at the head for like 'length before'\r\n  return [Delta(lens[a],lens[b],''.join(replace)) for a,b,replace in deltas]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef word_diff(a,b):\r\n  'do diff on words but return character offsets'\r\n  return translate_diff(a,rediff(splitpreserve(a),splitpreserve(b)))", "response": "do diff on words but return character offsets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef checkdiff(a,b,sp=True):\r\n  'take diff of a to b, apply to a, return the applied diff so external code can check it against b'\r\n  if sp: a=splitpreserve(a); b=splitpreserve(b)\r\n  res=applydiff(a,rediff(a,b))\r\n  if sp: res=''.join(res)\r\n  return res", "response": "take diff of a to b return the applied diff so external code can check it against b"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(cls, source, *, transform_args=None):\n    if transform_args is None:\n      transform_args = cls.transform_args\n\n    return cls(get_obj(source, *transform_args))", "response": "Create an instance of the class from the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map(cls, sources, *, transform_args=None):\n    for idx, source in enumerate(sources):\n      try:\n        yield cls.create(source, transform_args=transform_args)\n      except Exception as ex:\n        raise Exception(\"An error occurred with item {0}\".format(idx)) from ex", "response": "Generates instances from the given sources using either cls. transform_args or transform_args\n    argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the object to the database.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Set the current site ID, and ``is_public`` based on the setting\n        ``COMMENTS_DEFAULT_APPROVED``.\n        \"\"\"\n        if not self.id:\n            self.is_public = settings.COMMENTS_DEFAULT_APPROVED\n            self.site_id = current_site_id()\n        super(ThreadedComment, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that the rating is in the range min and max values.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Validate that the rating falls between the min and max values.\n        \"\"\"\n        valid = map(str, settings.RATINGS_RANGE)\n        if str(self.value) not in valid:\n            raise ValueError(\"Invalid rating. %s is not in %s\" % (self.value,\n                \", \".join(valid)))\n        super(Rating, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding mutually exclusive switch arguments.", "response": "def add_mutex_switch(parser, dest, arguments=set(), default=None,\n                         single_arg=False, required=False):\n        \"\"\"Adds mutually exclusive switch arguments.\n\n        Args:\n            arguments: a dictionary that maps switch name to helper text. Use\n                sets to skip help texts.\n        \"\"\"\n\n        if default is not None:\n            assert default in arguments\n\n        if isinstance(arguments, set):\n            arguments = {k: None for k in arguments}\n\n        if not single_arg:\n            mg = parser.add_mutually_exclusive_group(required=required)\n\n            for name, help_text in arguments.items():\n                kwargs = {\n                    \"action\": \"store_const\",\n                    \"dest\": dest,\n                    \"const\": name,\n                    \"help\": help_text\n                }\n\n                if default == name:\n                    kwargs[\"default\"] = name\n\n                mg.add_argument(\"--{}\".format(name), **kwargs)\n\n            return mg\n        else:\n            kwargs = {\n                \"dest\": dest,\n                \"type\": str,\n                \"default\": default,\n                \"help\": \"\\n\".join(\"{}: {}\".format(k, v)\n                                  for k, v in arguments.items()),\n                \"choices\": list(arguments.keys())\n            }\n\n            return parser.add_argument(\"--{}\".format(dest), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a directory path is a link or junction.", "response": "def _islinklike(dir_path):\n    '''\n    Parameters\n    ----------\n    dir_path : str\n        Directory path.\n\n    Returns\n    -------\n    bool\n        ``True`` if :data:`dir_path` is a link *or* junction.\n    '''\n    dir_path = ph.path(dir_path)\n    if platform.system() == 'Windows':\n        if dir_path.isjunction():\n            return True\n    elif dir_path.islink():\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving list of revisions for active Conda environment.", "response": "def _save_action(extra_context=None):\n    '''\n    Save list of revisions revisions for active Conda environment.\n\n    .. versionchanged:: 0.18\n        Compress action revision files using ``bz2`` to save disk space.\n\n    Parameters\n    ----------\n    extra_context : dict, optional\n        Extra content to store in stored action revision.\n\n    Returns\n    -------\n    path_helpers.path, dict\n        Path to which action was written and action object, including list of\n        revisions for active Conda environment.\n    '''\n    # Get list of revisions to Conda environment since creation.\n    revisions_js = ch.conda_exec('list', '--revisions', '--json',\n                                 verbose=False)\n    revisions = json.loads(revisions_js)\n    # Save list of revisions to `/etc/microdrop/plugins/actions/rev<rev>.json`\n    # See [wheeler-microfluidics/microdrop#200][i200].\n    #\n    # [i200]: https://github.com/wheeler-microfluidics/microdrop/issues/200\n    action = extra_context.copy() if extra_context else {}\n    action['revisions'] = revisions\n    action_path = (MICRODROP_CONDA_ACTIONS\n                   .joinpath('rev{}.json.bz2'.format(revisions[-1]['rev'])))\n    action_path.parent.makedirs_p()\n    # Compress action file using bz2 to save disk space.\n    with bz2.BZ2File(action_path, mode='w') as output:\n        json.dump(action, output, indent=2)\n    return action_path, action"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove broken links in MICRODROP_CONDA_PLUGINS enabled directory.", "response": "def _remove_broken_links():\n    '''\n    Remove broken links in `<conda prefix>/etc/microdrop/plugins/enabled/`.\n\n    Returns\n    -------\n    list\n        List of links removed (if any).\n    '''\n    enabled_dir = MICRODROP_CONDA_PLUGINS.joinpath('enabled')\n    if not enabled_dir.isdir():\n        return []\n\n    broken_links = []\n    for dir_i in enabled_dir.walkdirs(errors='ignore'):\n        if platform.system() == 'Windows':\n            if dir_i.isjunction() and not dir_i.readlink().isdir():\n                # Junction/link target no longer exists.\n                broken_links.append(dir_i)\n        else:\n            raise NotImplementedError('Unsupported platform')\n\n    removed_links = []\n    for link_i in broken_links:\n        try:\n            link_i.unlink()\n        except:\n            pass\n        else:\n            removed_links.append(link_i)\n    return removed_links"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef available_packages(*args, **kwargs):\n    '''\n    Query available plugin packages based on specified Conda channels.\n\n    Parameters\n    ----------\n    *args\n        Extra arguments to pass to Conda ``search`` command.\n\n    Returns\n    -------\n    dict\n        .. versionchanged:: 0.24\n            All Conda packages beginning with ``microdrop.`` prefix from all\n            configured channels.\n\n        Each *key* corresponds to a package name.\n\n        Each *value* corresponds to a ``list`` of dictionaries, each\n        corresponding to an available version of the respective package.\n\n        For example:\n\n            {\n              \"microdrop.dmf-device-ui-plugin\": [\n                ...\n                {\n                  ...\n                  \"build_number\": 0,\n                  \"channel\": \"microdrop-plugins\",\n                  \"installed\": true,\n                  \"license\": \"BSD\",\n                  \"name\": \"microdrop.dmf-device-ui-plugin\",\n                  \"size\": 62973,\n                  \"version\": \"2.1.post2\",\n                  ...\n                },\n                ...],\n                ...\n            }\n    '''\n    # Get list of available MicroDrop plugins, i.e., Conda packages that start\n    # with the prefix `microdrop.`.\n    try:\n        plugin_packages_info_json = ch.conda_exec('search', '--json',\n                                                  '^microdrop\\.', verbose=False)\n        return json.loads(plugin_packages_info_json)\n    except RuntimeError, exception:\n        if 'CondaHTTPError' in str(exception):\n            logger.warning('Could not connect to Conda server.')\n        else:\n            logger.warning('Error querying available MicroDrop plugins.',\n                           exc_info=True)\n    except Exception, exception:\n        logger.warning('Error querying available MicroDrop plugins.',\n                       exc_info=True)\n    return {}", "response": "Query available plugin packages based on specified Conda channels."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install(plugin_name, *args, **kwargs):\n    '''\n    Install plugin packages based on specified Conda channels.\n\n    .. versionchanged:: 0.19.1\n        Do not save rollback info on dry-run.\n\n    .. versionchanged:: 0.24\n        Remove channels argument.  Use Conda channels as configured in Conda\n        environment.\n\n        Note that channels can still be explicitly set through :data:`*args`.\n\n    Parameters\n    ----------\n    plugin_name : str or list\n        Plugin package(s) to install.\n\n        Version specifiers are also supported, e.g., ``package >=1.0.5``.\n    *args\n        Extra arguments to pass to Conda ``install`` command.\n\n    Returns\n    -------\n    dict\n        Conda installation log object (from JSON Conda install output).\n    '''\n    if isinstance(plugin_name, types.StringTypes):\n        plugin_name = [plugin_name]\n\n    # Perform installation\n    conda_args = (['install', '-y', '--json'] + list(args) + plugin_name)\n    install_log_js = ch.conda_exec(*conda_args, verbose=False)\n    install_log = json.loads(install_log_js.split('\\x00')[-1])\n    if 'actions' in install_log and not install_log.get('dry_run'):\n        # Install command modified Conda environment.\n        _save_action({'conda_args': conda_args, 'install_log': install_log})\n        logger.debug('Installed plugin(s): ```%s```', install_log['actions'])\n    return install_log", "response": "Installs plugin packages based on specified Conda channels."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore current revision of Conda environment according to most recent action.", "response": "def rollback(*args, **kwargs):\n    '''\n    Restore previous revision of Conda environment according to most recent\n    action in :attr:`MICRODROP_CONDA_ACTIONS`.\n\n    .. versionchanged:: 0.18\n        Add support for action revision files compressed using ``bz2``.\n\n    .. versionchanged:: 0.24\n        Remove channels argument.  Use Conda channels as configured in Conda\n        environment.\n\n        Note that channels can still be explicitly set through :data:`*args`.\n\n    Parameters\n    ----------\n    *args\n        Extra arguments to pass to Conda ``install`` roll-back command.\n\n    Returns\n    -------\n    int, dict\n        Revision after roll back and Conda installation log object (from JSON\n        Conda install output).\n\n    See also\n    --------\n\n    `wheeler-microfluidics/microdrop#200 <https://github.com/wheeler-microfluidics/microdrop/issues/200>`\n    '''\n    action_files = MICRODROP_CONDA_ACTIONS.files()\n    if not action_files:\n        # No action files, return current revision.\n        logger.debug('No rollback actions have been recorded.')\n        revisions_js = ch.conda_exec('list', '--revisions', '--json',\n                                     verbose=False)\n        revisions = json.loads(revisions_js)\n        return revisions[-1]['rev']\n    # Get file associated with most recent action.\n    cre_rev = re.compile(r'rev(?P<rev>\\d+)')\n    action_file = sorted([(int(cre_rev.match(file_i.namebase).group('rev')),\n                           file_i) for file_i in\n                          action_files if cre_rev.match(file_i.namebase)],\n                         reverse=True)[0]\n    # Do rollback (i.e., install state of previous revision).\n    if action_file.ext.lower() == '.bz2':\n        # Assume file is compressed using bz2.\n        with bz2.BZ2File(action_file, mode='r') as input_:\n            action = json.load(input_)\n    else:\n        # Assume it is raw JSON.\n        with action_file.open('r') as input_:\n            action = json.load(input_)\n    rollback_revision = action['revisions'][-2]\n    conda_args = (['install', '--json'] + list(args) +\n                  ['--revision', str(rollback_revision)])\n    install_log_js = ch.conda_exec(*conda_args, verbose=False)\n    install_log = json.loads(install_log_js.split('\\x00')[-1])\n    logger.debug('Rolled back to revision %s', rollback_revision)\n    return rollback_revision, install_log"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uninstall(plugin_name, *args):\n    '''\n    Uninstall plugin packages.\n\n    Plugin packages must have a directory with the same name as the package in\n    the following directory:\n\n        <conda prefix>/share/microdrop/plugins/available/\n\n    Parameters\n    ----------\n    plugin_name : str or list\n        Plugin package(s) to uninstall.\n    *args\n        Extra arguments to pass to Conda ``uninstall`` command.\n\n    Returns\n    -------\n    dict\n        Conda uninstallation log object (from JSON Conda uninstall output).\n    '''\n    if isinstance(plugin_name, types.StringTypes):\n        plugin_name = [plugin_name]\n\n    available_path = MICRODROP_CONDA_SHARE.joinpath('plugins', 'available')\n    for name_i in plugin_name:\n        plugin_module_i = name_i.split('.')[-1].replace('-', '_')\n        plugin_path_i = available_path.joinpath(plugin_module_i)\n        if not _islinklike(plugin_path_i) and not plugin_path_i.isdir():\n            raise IOError('Plugin `{}` not found in `{}`'\n                          .format(name_i, available_path))\n        else:\n            logging.debug('[uninstall] Found plugin `%s`', plugin_path_i)\n\n    # Perform uninstall operation.\n    conda_args = ['uninstall', '--json', '-y'] + list(args) + plugin_name\n    uninstall_log_js = ch.conda_exec(*conda_args, verbose=False)\n    # Remove broken links in `<conda prefix>/etc/microdrop/plugins/enabled/`,\n    # since uninstall may have made one or more packages unavailable.\n    _remove_broken_links()\n    logger.debug('Uninstalled plugins: ```%s```', plugin_name)\n    return json.loads(uninstall_log_js.split('\\x00')[-1])", "response": "Uninstalls the specified plugin packages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenable installed plugin package.", "response": "def enable_plugin(plugin_name):\n    '''\n    Enable installed plugin package(s).\n\n    Each plugin package must have a directory with the same name as the package\n    in the following directory:\n\n        <conda prefix>/share/microdrop/plugins/available/\n\n    Parameters\n    ----------\n    plugin_name : str or list\n        Plugin package(s) to enable.\n\n    Returns\n    -------\n    dict\n        Dictionary containing a flag for each plugin name:\n\n         - ``False`` iff the plugin was already enabled.\n         - ``True`` iff it was just enabled now.\n\n    Raises\n    ------\n    IOError\n        If plugin is not installed to ``<conda prefix>/share/microdrop/plugins/available/``.\n    '''\n    if isinstance(plugin_name, types.StringTypes):\n        plugin_name = [plugin_name]\n        singleton = True\n    else:\n        singleton = False\n\n    # Conda-managed plugins\n    shared_available_path = MICRODROP_CONDA_SHARE.joinpath('plugins',\n                                                           'available')\n    # User-managed plugins\n    etc_available_path = MICRODROP_CONDA_ETC.joinpath('plugins', 'available')\n\n    available_paths = (etc_available_path, shared_available_path)\n    plugin_paths = []\n    for name_i in plugin_name:\n        for available_path_j in available_paths:\n            plugin_path_ij = available_path_j.joinpath(name_i)\n            if not _islinklike(plugin_path_ij) and plugin_path_ij.isdir():\n                logger.debug('Found plugin directory: `%s`', plugin_path_ij)\n                break\n        else:\n            raise IOError('Plugin `{}` not found in `{}` or `{}`'\n                          .format(name_i, *available_paths))\n        plugin_paths.append(plugin_path_ij)\n\n    # All specified plugins are available.\n\n    # Link all specified plugins in\n    # `<conda prefix>/etc/microdrop/plugins/enabled/` (if not already linked).\n    enabled_path = MICRODROP_CONDA_PLUGINS.joinpath('enabled')\n    enabled_path.makedirs_p()\n\n    # Set flag for each plugin: `False` iff the plugin was already enabled,\n    # `True` iff it was just enabled now.\n    enabled_now = {}\n    for plugin_path_i in plugin_paths:\n        plugin_link_path_i = enabled_path.joinpath(plugin_path_i.name)\n        if not plugin_link_path_i.exists():\n            if platform.system() == 'Windows':\n                plugin_path_i.junction(plugin_link_path_i)\n            else:\n                plugin_path_i.symlink(plugin_link_path_i)\n            logger.debug('Enabled plugin directory: `%s` -> `%s`',\n                         plugin_path_i, plugin_link_path_i)\n            enabled_now[plugin_path_i.name] = True\n        else:\n            logger.debug('Plugin already enabled: `%s` -> `%s`', plugin_path_i,\n                         plugin_link_path_i)\n            enabled_now[plugin_path_i.name] = False\n    return enabled_now if not singleton else enabled_now.values()[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisabling all specified plugins from the internal list of modules.", "response": "def disable_plugin(plugin_name):\n    '''\n    Disable plugin package(s).\n\n    Parameters\n    ----------\n    plugin_name : str or list\n        Plugin package(s) to disable.\n\n    Raises\n    ------\n    IOError\n        If plugin is not enabled.\n    '''\n    if isinstance(plugin_name, types.StringTypes):\n        plugin_name = [plugin_name]\n\n    # Verify all specified plugins are currently enabled.\n    enabled_path = MICRODROP_CONDA_PLUGINS.joinpath('enabled')\n    for name_i in plugin_name:\n        plugin_path_i = enabled_path.joinpath(name_i)\n        if not _islinklike(plugin_path_i) and not plugin_path_i.isdir():\n            raise IOError('Plugin `{}` not found in `{}`'\n                          .format(name_i, enabled_path))\n\n    # All specified plugins are enabled.\n\n    # Remove all specified plugins from\n    # `<conda prefix>/etc/microdrop/plugins/enabled/`.\n    for name_i in plugin_name:\n        plugin_link_path_i = enabled_path.joinpath(name_i)\n        plugin_link_path_i.unlink()\n        logger.debug('Disabled plugin `%s` (i.e., removed `%s`)',\n                     plugin_path_i, plugin_link_path_i)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(*args, **kwargs):\n    '''\n    Update installed plugin package(s).\n\n    Each plugin package must have a directory (**NOT** a link) containing a\n    ``properties.yml`` file with a ``package_name`` value in the following\n    directory:\n\n        <conda prefix>/share/microdrop/plugins/available/\n\n    Parameters\n    ----------\n    *args\n        Extra arguments to pass to Conda ``install`` command.\n\n        See :func:`install`.\n    package_name : str or list, optional\n        Name(s) of MicroDrop plugin Conda package(s) to update.\n\n        By default, all installed packages are updated.\n    **kwargs\n        See :func:`install`.\n\n    Returns\n    -------\n    dict\n        Conda installation log object (from JSON ``conda install`` output).\n\n    Notes\n    -----\n    Only actual plugin directories are considered when updating (i.e., **NOT**\n    directory links).\n\n    This permits, for example, linking of a plugin into the ``available``\n    plugins directory during development without risking overwriting during an\n    update.\n\n    Raises\n    ------\n    RuntimeError\n        If one or more installed plugin packages cannot be updated.\n\n        This can happen, for example, if the plugin package is not available in\n        any of the specified Conda channels.\n\n    See also\n    --------\n    :func:`installed_plugins`\n    '''\n    package_name = kwargs.pop('package_name', None)\n\n    # Only consider **installed** plugins (see `installed_plugins()` docstring).\n    installed_plugins_ = installed_plugins(only_conda=True)\n    if installed_plugins_:\n        plugin_packages = [plugin_i['package_name']\n                           for plugin_i in installed_plugins_]\n        if package_name is None:\n            package_name = plugin_packages\n        elif isinstance(package_name, types.StringTypes):\n            package_name = [package_name]\n        logger.info('Installing any available updates for plugins: %s',\n                    ','.join('`{}`'.format(package_name_i)\n                             for package_name_i in package_name))\n        # Attempt to install plugin packages.\n        try:\n            install_log = install(package_name, *args, **kwargs)\n        except RuntimeError, exception:\n            if 'CondaHTTPError' in str(exception):\n                raise IOError('Error accessing update server.')\n            else:\n                raise\n        if 'actions' in install_log:\n            logger.debug('Updated plugin(s): ```%s```', install_log['actions'])\n        return install_log\n    else:\n        return {}", "response": "Update installed plugin packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_plugin(package_name, include_available=False):\n    '''\n    Import MicroDrop plugin.\n\n    Parameters\n    ----------\n    package_name : str\n        Name of MicroDrop plugin Conda package.\n    include_available : bool, optional\n        If ``True``, import from all available plugins (not just **enabled**\n        ones).\n\n        By default, only the ``<conda>/etc/microdrop/plugins/enabled``\n        directory is added to the Python import paths (if necessary).\n\n        If ``True``, also add the ``<conda>/share/microdrop/plugins/available``\n        directory to the Python import paths.\n\n    Returns\n    -------\n    module\n        Imported plugin module.\n    '''\n    available_plugins_dir = MICRODROP_CONDA_SHARE.joinpath('plugins',\n                                                           'available')\n    enabled_plugins_dir = MICRODROP_CONDA_ETC.joinpath('plugins', 'enabled')\n    search_paths = [enabled_plugins_dir]\n    if include_available:\n        search_paths += [available_plugins_dir]\n    for dir_i in search_paths:\n        if dir_i not in sys.path:\n            sys.path.insert(0, dir_i)\n    module_name = package_name.split('.')[-1].replace('-', '_')\n    return importlib.import_module(module_name)", "response": "Imports a plugin from the given package name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of properties corresponding to each available plugin that is a conda package.", "response": "def installed_plugins(only_conda=False):\n    '''\n    .. versionadded:: 0.20\n\n    Parameters\n    ----------\n    only_conda : bool, optional\n        Only consider plugins that are installed **as Conda packages**.\n\n        .. versionadded:: 0.22\n\n    Returns\n    -------\n    list\n        List of properties corresponding to each available plugin that is\n        **installed**.\n\n        .. versionchanged:: 0.22\n\n            If :data:`only_conda` is ``False``, a plugin is assumed to be\n            *installed* if it is present in the\n            ``share/microdrop/plugins/available`` directory **and** is a\n            **real** directory (i.e., not a link).\n\n            If :data:`only_conda` is ``True``, only properties for plugins that\n            are installed **as Conda packages** are returned.\n    '''\n    available_path = MICRODROP_CONDA_SHARE.joinpath('plugins', 'available')\n    if not available_path.isdir():\n        return []\n    installed_plugins_ = []\n    for plugin_path_i in available_path.dirs():\n        # Only process plugin directory if it is *not a link*.\n        if not _islinklike(plugin_path_i):\n            # Read plugin package info from `properties.yml` file.\n            try:\n                with plugin_path_i.joinpath('properties.yml').open('r') as input_:\n                    properties_i = yaml.load(input_.read())\n            except:\n                logger.info('[warning] Could not read package info: `%s`',\n                            plugin_path_i.joinpath('properties.yml'),\n                            exc_info=True)\n            else:\n                properties_i['path'] = plugin_path_i.realpath()\n                installed_plugins_.append(properties_i)\n\n    if only_conda:\n        # Only consider plugins that are installed **as Conda packages**.\n        try:\n            package_names = [plugin_i['package_name']\n                             for plugin_i in installed_plugins_]\n            conda_package_infos = ch.package_version(package_names,\n                                                     verbose=False)\n        except ch.PackageNotFound, exception:\n            # At least one specified plugin package name did not correspond to an\n            # installed Conda package.\n            logger.warning(str(exception))\n            conda_package_infos = exception.available\n        # Extract name from each Conda plugin package.\n        installed_package_names = set([package_i['name']\n                                       for package_i in conda_package_infos])\n        return [plugin_i for plugin_i in installed_plugins_\n                if plugin_i['package_name'] in installed_package_names]\n    else:\n        # Return all available plugins.\n        return installed_plugins_"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of properties corresponding to each plugin that is enabled in the Conda environment.", "response": "def enabled_plugins(installed_only=True):\n    '''\n    .. versionadded:: 0.21\n\n    Parameters\n    ----------\n    installed_only : bool, optional\n        Only consider enabled plugins that are installed in the Conda\n        environment.\n\n    Returns\n    -------\n    list\n        List of properties corresponding to each plugin that is **enabled**.\n\n        If :data:`installed_only` is True``, only consider plugins:\n\n         1. Present in the ``etc/microdrop/plugins/enabled`` directory as a\n            link/junction to a **real** directory (i.e., not a link) in the\n            ``share/microdrop/plugins/available`` directory.\n         2. Matching the name of a package in the Conda environment.\n\n        If :data:`installed_only` is ``False``, consider all plugins present in\n        the ``etc/microdrop/plugins/enabled`` directory as either a *real*\n        directory or a link/junction.\n\n    '''\n    enabled_path = MICRODROP_CONDA_PLUGINS.joinpath('enabled')\n    if not enabled_path.isdir():\n        return []\n\n    # Construct list of property dictionaries, one per enabled plugin\n    # directory.\n    enabled_plugins_ = []\n    for plugin_path_i in enabled_path.dirs():\n        if not installed_only or _islinklike(plugin_path_i):\n            # Enabled plugin path is either **a link to an installed plugin**\n            # or call explicitly specifies that plugins that are not installed\n            # should still be considered.\n\n            # Read plugin package info from `properties.yml` file.\n            try:\n                with plugin_path_i.joinpath('properties.yml').open('r') as input_:\n                    properties_i = yaml.load(input_.read())\n            except:\n                logger.info('[warning] Could not read package info: `%s`',\n                            plugin_path_i.joinpath('properties.yml'),\n                            exc_info=True)\n                continue\n            else:\n                properties_i['path'] = plugin_path_i.realpath()\n                enabled_plugins_.append(properties_i)\n\n    if installed_only:\n        # Only consider enabled plugins that are installed in the Conda\n        # environment.\n        try:\n            # Attempt to look up installed Conda package info for each enabled\n            # plugin.\n            package_names = [properties_i['package_name']\n                             for properties_i in enabled_plugins_]\n            installed_info = ch.package_version(package_names, verbose=False)\n        except ch.PackageNotFound, exception:\n            # Failed to find a corresponding installed Conda package for at\n            # least one enabled plugin.\n            logger.warning(str(exception))\n            available_names = set([package_i['name']\n                                   for package_i in exception.available])\n            # Only return list of enabled plugins that have a corresponding\n            # Conda package installed.\n            return [properties_i for properties_i in enabled_plugins_\n                    if properties_i['package_name'] in available_names]\n\n    # Return list of all enabled plugins, regardless of whether or not they\n    # have corresponding Conda packages installed.\n    return enabled_plugins_"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attach_related(self, filename=None, content=None, mimetype=None):\n        if isinstance(filename, MIMEBase):\n            assert content == mimetype == None\n            self.related_attachments.append(filename)\n        else:\n            assert content is not None\n            self.related_attachments.append((filename, content, mimetype))", "response": "Adds a file with the given filename and content to the message attachments."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattaches a file from the filesystem to the cache.", "response": "def attach_related_file(self, path, mimetype=None):\n        \"\"\"Attaches a file from the filesystem.\"\"\"\n        filename = os.path.basename(path)\n        content = open(path, 'rb').read()\n        self.attach_related(filename, content, mimetype)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_related_attachment(self, filename, content, mimetype=None):\n        attachment = super(EmailMultiRelated, self)._create_attachment(filename, content, mimetype)\n        if filename:\n            mimetype = attachment['Content-Type']\n            del(attachment['Content-Type'])\n            del(attachment['Content-Disposition'])\n            attachment.add_header('Content-Disposition', 'inline', filename=filename)\n            attachment.add_header('Content-Type', mimetype, name=filename)\n            attachment.add_header('Content-ID', '<%s>' % filename)\n        return attachment", "response": "Convert the filename content mimetype triple into a MIME attachment object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_dat_file(self):\n        output = \"## {}\\n\".format(self.name)\n        try:\n            kwargs_items = self.kwargs.iteritems()\n        except AttributeError:\n            kwargs_items = self.kwargs.items()\n        for key, val in kwargs_items:\n            if val is \"l\":\n                output += \"#l {}=\\n\".format(str(key))\n            elif val is \"f\" or True:\n                output += \"#f {}=\\n\".format(str(key))\n        comment = \"## \" + \"\\t\".join([\"col{\" + str(i) + \":d}\"\n                                     for i in range(self.argnum)])\n        comment += \"\\n\"\n        rangeargnum = range(self.argnum)\n        output += comment.format(*rangeargnum)\n        if os.path.isfile(self.location_dat):\n            files = glob.glob(self.location_dat + \"*\")\n            count = 2\n            while (\n                    (self.location_dat + str(count) in files)\n                  ) and (count <= 10):\n                count += 1\n            os.rename(self.location_dat, self.location_dat + str(count))\n        dat_file = open(self.location_dat, \"wb\")\n        dat_file.write(output)\n        dat_file.close()", "response": "Create and write empty data file in the data directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse data and save to pickle or hickle", "response": "def parse_data_to_internal(self, data=None):\n        \"\"\"\n        Parse data and save to pickle/hickle\n        \"\"\"\n        if data is None:\n            data = parse.getdata(open(self.location_dat, \"rb\"),\n                                 argnum=self.argnum, close=True)\n        if self.filetype is \"pickle\":\n            pickle.dump(data, open(self.location_internal, \"wb\"))\n        elif self.filetype is \"hickle\":\n            import hickle\n            hickle.dump(data, open(self.location_internal, \"wb\"))\n        else:\n            raise ValueError(\n                \"Invalid filetype {} (must be {} or {})\".format(\n                    self.filetype, \"pickle\", \"hickle\"\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting internal data that is saved in pickle or hickle", "response": "def get_internal_data(self):\n        \"\"\"\n        Get data that is saved in pickle/hickle\n        \"\"\"\n        if self.filetype is \"pickle\":\n            return pickle.load(open(self.location_internal, \"rb\"))\n        elif self.filetype is \"hickle\":\n            import hickle\n            return hickle.load(open(self.location_internal, \"rb\"))\n        else:\n            raise ValueError(\n                \"Invalue filetype {} (must be {} or {})\".format(\n                    self.filetype, \"pickle\", \"hickle\"\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the data to the internal file.", "response": "def save_to_internal(self, data):\n        \"\"\"save\n        \"\"\"\n        if self.filetype is \"pickle\":\n            pickle.dump(data, open(self.location_internal, \"wb\"))\n        elif self.filetype is \"hickle\":\n            import hickle\n            hickle.dump(data, open(self.location_internal, \"wb\"))\n        else:\n            raise ValueError(\n                \"Invalid filetype {} (must be {} or {})\".format(\n                    self.filetype, \"pickle\", \"hickle\"\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_data_to_internal(self, data=None):\n        if data is None:\n            f = open(self.location_dat, \"rb\")\n            data = {\n                \"PMCA SPECTRUM\": {},\n                \"DATA\": [],\n                \"DP5 CONFIGURATION\": {},\n                \"DPP STATUS\": {}\n            }\n            delimiter = {\n                \"PMCA SPECTRUM\": \" - \",\n                \"DP5 CONFIGURATION\": \"=\",\n                \"DPP STATUS\": \":\"\n            }\n            comments = {\n                \"PMCA SPECTRUM\": None,\n                \"DP5 CONFIGURATION\": \";\",\n                \"DPP STATUS\": None\n            }\n            for e in f:\n                if \"<<\" in e:\n                    if \"<<END>>\" in e:\n                        current = None\n                    elif \"<<PMCA SPECTRUM>>\" in e:\n                        current = \"PMCA SPECTRUM\"\n                    elif \"<<DATA>>\" in e:\n                        current = \"DATA\"\n                    elif \"<<DP5 CONFIGURATION>>\" in e:\n                        current = \"DP5 CONFIGURATION\"\n                    elif \"<<DPP STATUS>>\" in e:\n                        current = \"DPP STATUS\"\n                    elif \"<<ROI>>\" in e:\n                        current = \"ROI\"\n                else:\n                    if current == \"DATA\":\n                        data[\"DATA\"].append(float(e))\n                    elif current == \"ROI\":\n                        continue\n                    elif current is not None:\n                        e = e.split(\"\\r\\n\")[0]\n                        if comments[current] is not None:\n                            e = e.split(comments[current], 1)[0]\n                        e_list = e.split(delimiter[current], 1)\n                        data[current][e_list[0]] = e_list[1]\n            f.close()\n        self.save_to_internal(data)", "response": "parse to internal data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_data_to_internal(self, data=None):\n        if data is None:\n            kwargs = self.kwargs\n            data = np.loadtxt(\n                open(self.location_dat, \"rb\"), **kwargs\n            )\n        if self.filetype is \"pickle\":\n            pickle.dump(data, open(self.location_internal, \"wb\"))\n        elif self.filetype is \"hickle\":\n            import hickle\n            hickle.dump(data, open(self.location_internal, \"wb\"))\n        else:\n            raise ValueError(\n                \"Invalid filetype {} (must be {} or {})\".format(\n                    self.filetype, \"pickle\", \"hickle\"\n                )\n            )", "response": "Use numpy loadtxt\n            to parse data into internal data structures."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all instances of a given type", "response": "def _get_all(self, _type):\n        \"\"\" Gets all instances implementing type <_type> \"\"\"\n        if _type not in self.modules:\n            raise ValueError(\"No such module, %s\" % _type)\n        if not self.insts_implementing.get(_type, None):\n            raise ValueError(\"No instance implementing %s\" % _type)\n        return self.insts_implementing[_type]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_a(self, _type):\n        tmp = self._get_all(_type)\n        ret = pick(tmp)\n        if len(tmp) != 1:\n            self.l.warn((\"get_a: %s all implement %s; \" +\n                         \"picking %s\") % (tmp, _type, ret))\n        return ret", "response": "Gets an instance of type <_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn whether there is an instance implementing _type", "response": "def got_a(self, _type):\n        \"\"\" Returns whether there is an instance implementing <_type>\n        \"\"\"\n        if _type not in self.modules:\n            raise ValueError(\"No such module, %s\" % _type)\n        return (_type in self.insts_implementing and\n                self.insts_implementing[_type])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets or creates an instance of type _type", "response": "def _get_or_create_a(self, _type):\n        \"\"\" Gets or creates an instance of type <_type> \"\"\"\n        self.l.debug(\"get_or_create_a: %s\" % _type)\n        stack = [Manager.GoCa_Plan(self, {_type: ()})]\n        while stack:\n            p = stack.pop()\n            if p.finished:\n                p.execute()\n                return p.get_a(_type)\n            for c in p.branches():\n                stack.append(c)\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the settings of an instance with the dictionary of settings.", "response": "def update_instance(self, name, settings):\n        \"\"\" Updates settings of instance <name> with the\n            dictionary <settings>. \"\"\"\n        if name not in self.insts:\n            raise ValueError(\"There's no instance named %s\" % name)\n        if 'module' in settings:\n            raise ValueError((\"Can't change module of existing instan\"\n                              + \"ce %s\") % name)\n        self.l.info('update instance %-15s' % (name))\n        for k, v in six.iteritems(settings):\n            self.change_setting(name, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an instance of the specified moduleName with the given settings.", "response": "def create_instance(self, name, moduleName, settings):\n        \"\"\" Creates an instance of <moduleName> at <name> with\n            <settings>. \"\"\"\n        if name in self.insts:\n            raise ValueError(\"There's already an instance named %s\" %\n                             name)\n        if moduleName not in self.modules:\n            raise ValueError(\"There's no module %s\" % moduleName)\n        md = self.modules[moduleName]\n        deps = dict()\n        for k, v in six.iteritems(md.deps):\n            if k not in settings:\n                settings[k] = self._get_or_create_a(v.type)\n            if settings[k] is None:\n                if not v.allow_null:\n                    raise ValueError(\"`null' not allowed for %s\" % k)\n            elif settings[k] not in self.insts:\n                raise ValueError(\"No such instance %s\" % settings[k])\n            else:\n                settings[k] = self.insts[settings[k]].object\n                deps[k] = settings[k]\n        for k, v in six.iteritems(md.vsettings):\n            if k not in settings:\n                settings[k] = v.default\n                if v.default is None:\n                    self.l.warn('%s:%s not set' % (name, k))\n        self.l.info('create_instance %-15s %s' % (name, md.implementedBy))\n        cl = get_by_path(md.implementedBy)\n        il = logging.getLogger(name)\n        obj = cl(settings, il)\n        self.register_instance(name, moduleName, obj, settings, deps)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_setting(self, instance_name, key, raw_value):\n        ii = self.insts[instance_name]\n        mo = self.modules[ii.module]\n        if key in mo.deps:\n            if raw_value not in self.insts:\n                raise ValueError(\"No such instance %s\" % raw_value)\n            vii = self.insts[raw_value]\n            vmo = self.modules[vii.module]\n            if not (mo.deps[key].type in vmo.inherits or\n                    mo.deps[key].type == vii.module):\n                raise ValueError(\"%s isn't a %s\" % (\n                    raw_value, mo.deps[key].type))\n            value = vii.object\n        elif key in mo.vsettings:\n            value = self.valueTypes[mo.vsettings[key].type](\n                raw_value)\n        else:\n            raise ValueError(\"No such settings %s\" % key)\n        self.l.info(\"Changing %s.%s to %s\" % (instance_name,\n                                              key,\n                                              raw_value))\n        ii.settings[key] = value\n        ii.object.change_setting(key, value)", "response": "Change the value of a specific key in an instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup(self, app):\n        super().setup(app)\n\n        if isinstance(self.cfg.template_folders, str):\n            self.cfg.template_folders = [self.cfg.template_folders]\n\n        else:\n            self.cfg.template_folders = list(self.cfg.template_folders)\n\n        self.ctx_provider(lambda: {'app': self.app})\n        self.env = Environment(debug=app.cfg.DEBUG, **self.cfg)", "response": "Setup the plugin from an application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register(self, func):\n        if callable(func):\n            self.functions[func.__name__] = func\n        return func", "response": "Register a function to templates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, path, **context):\n        funcs = self.functions\n        ctx = dict(self.functions, jdebug=lambda: dict(\n            (k, v) for k, v in ctx.items() if k not in funcs and k != 'jdebug'))\n        for provider in self.providers:\n            _ctx = yield from provider()\n            ctx.update(_ctx)\n        ctx.update(context)\n        template = self.env.get_template(path)\n        return self.env.render(template, **ctx)", "response": "Render a template with context."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_template(self, path):\n        if not path.startswith('/'):\n            for folder in self.options['template_folders']:\n                fullpath = op.join(folder, path)\n                if op.exists(fullpath):\n                    path = fullpath\n                    break\n            else:\n                raise JadeException('Template doesnt exist: %s' % path)\n\n        with open(path, 'rb') as f:\n            source = f.read().decode(self.options['encoding'])\n\n        return ExtendCompiler(\n            pyjade.parser.Parser(source).parse(), pretty=self.options['pretty'],\n            env=self, compileDebug=True\n        )", "response": "Load and compile a template."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_size(self, data_size):\n        if len(str(data_size)) > self.first:\n            raise ValueError(\n              'Send size is too large for message size-field width!')\n        \n        self.data_size = data_size", "response": "Set the data slice size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_mp(cls, file_pointer, _mft_config=None):\n        '''The initialization process takes a file like object \"file_pointer\"\n        and loads it in the internal structures. \"use_cores\" can be definied\n        if multiple cores are to be used. The \"size\" argument is the size\n        of the MFT entries. If not provided, the class will try to auto detect\n        it.\n        '''\n        import multiprocessing\n        import queue\n\n        mft_config = _mft_config if _mft_config is not None else MFT.mft_config\n        mft_entry_size = mft_config[\"entry_size\"]\n        #self.entries = {}\n\n        if not mft_entry_size:\n            mft_entry_size = MFT._find_mft_size(file_pointer)\n        file_size = _get_file_size(file_pointer)\n        if (file_size % mft_entry_size):\n            #TODO error handling (file size not multiple of mft size)\n            MOD_LOGGER.error(\"Unexpected file size. It is not multiple of the MFT entry size.\")\n\n        end = int(file_size / mft_entry_size)\n\n        #setup the multiprocessing stuff\n        queue_size = 10\n        n_processes = 3\n        manager = multiprocessing.Manager()\n        buffer_queue_in = manager.Queue(queue_size)\n        buffer_queue_out = manager.Queue(queue_size)\n        entries = manager.dict()\n        temp_entries = manager.list()\n        processes = [multiprocessing.Process(target=MFT._load_entry, args=(mft_config, buffer_queue_in, buffer_queue_out, entries, temp_entries)) for i in range(n_processes)]\n        for p in processes:\n            p.start()\n        for i in range(queue_size):\n            buffer_queue_out.put(bytearray(mft_entry_size))\n        #start the game\n        for i in range(0, end):\n            try:\n                data_buffer = buffer_queue_out.get(timeout=1)\n                file_pointer.readinto(data_buffer)\n                buffer_queue_in.put((i, data_buffer))\n                #print(\"adding\", i)\n            except queue.Empty as e:\n                print(\"DAMN\")\n                raise\n\n        for i in range(queue_size):\n            buffer_queue_in.put((-1, None))\n        for p in processes:\n            p.join()\n        print(\"LOADING DONE\")\n\n        #process the temporary list and add it to the \"model\"\n        for entry in temp_entries:\n            base_record_ref = entry.header.base_record_ref\n            if base_record_ref in entries: #if the parent entry has been loaded\n                if MFT._is_related(entries[base_record_ref], entry):\n                    entries[base_record_ref].copy_attributes(entry)\n                else: #can happen when you have an orphan entry\n                    entries[i] = entry", "response": "Loads the MFT entries from a file - like object file_pointer and creates the internal structures."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of the tree that contains all dives in a minimum dive threshold.", "response": "def finddives2(depths, min_dive_thresh=10):\n    '''Find dives in depth data below a minimum dive threshold\n\n    Args\n    ----\n    depths: ndarray\n        Datalogger depth measurements\n    min_dive_thresh: float\n        Minimum depth threshold for which to classify a dive\n\n    Returns\n    -------\n    dives: ndarray\n        Dive summary information in a numpy record array\n\n        *Columns*:\n\n        * dive_id\n        * start_idx\n        * stop_idx\n        * dive_dur\n        * depth_max\n        * depth_max_i\n        * depth_min\n        * depth_min_i\n        * depth_mean\n        * comp_mean\n\n    dive_mask: ndarray\n        Boolean mask array over depth data. Cells with `True` are dives and\n        cells with `False` are not.\n    '''\n    import numpy\n    import pandas\n\n    from . import utils\n\n    # Get start and stop indices for each dive above `min_dive_thresh`\n    condition = depths > min_dive_thresh\n    ind_start, ind_end = utils.contiguous_regions(condition)\n\n    n_dives = len(ind_start)\n\n    dive_mask = numpy.zeros(len(depths), dtype=bool)\n\n    dtypes = numpy.dtype([('dive_id', int),\n                          ('start_idx', int),\n                          ('stop_idx', int),\n                          ('dive_dur', int),\n                          ('depth_max', float),\n                          ('depth_max_idx', float),\n                          ('depth_min', float),\n                          ('depth_min_idx', float),\n                          ('depth_mean', float),\n                          ('comp_mean', float),])\n\n    dive_data = numpy.zeros(n_dives, dtype=dtypes)\n\n    for i in range(n_dives):\n        dive_mask[ind_start[i]:ind_end[i]] = True\n        dive_depths                   = depths[ind_start[i]:ind_end[i]]\n        dive_data['dive_id'][i]       = i\n        dive_data['start_idx'][i]     = ind_start[i]\n        dive_data['stop_idx'][i]      = ind_end[i]\n        dive_data['dive_dur'][i]      = ind_end[i] - ind_start[i]\n        dive_data['depth_max'][i]     = dive_depths.max()\n        dive_data['depth_max_idx'][i] = numpy.argmax(dive_depths)\n        dive_data['depth_min'][i]     = dive_depths.min()\n        dive_data['depth_min_idx'][i] = numpy.argmin(dive_depths)\n        dive_data['depth_mean'][i]    = numpy.mean(dive_depths)\n        # TODO Supposedly time of deepest dive... doesn't appear to be that\n        dive_data['comp_mean'][i]     = numpy.mean(1 + (1/(0.1*dive_depths)))\n\n    # Filter any dives with an endpoint with an index beyond bounds of array\n    dive_data = dive_data[dive_data['stop_idx'] < len(depths)]\n\n    # Create pandas data frame with following columns, init'd with nans\n    dives = pandas.DataFrame(dive_data)\n\n    return dives, dive_mask"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_des_asc2(depths, dive_mask, pitch, cutoff, fs, order=5):\n    '''Get boolean masks of descents and ascents in the depth data\n\n    Args\n    ----\n    dive_mask: ndarray\n        Boolean mask array over depth data. Cells with `True` are dives and\n        cells with `False` are not.\n    pitch: ndarray\n        Pitch angle in radians\n    cutoff: float\n        Cutoff frequency at which signal will be filtered\n    fs: float\n        Sampling frequency\n    order: int\n        Order of butter filter to apply\n\n    Returns\n    -------\n    des_mask: ndarray\n        Boolean mask of descents in the depth data\n    asc_mask: ndarray\n        Boolean mask of ascents in the depth data\n    '''\n    import numpy\n\n    from . import dsp\n\n    asc_mask = numpy.zeros(len(depths), dtype=bool)\n    des_mask = numpy.zeros(len(depths), dtype=bool)\n\n    b, a = dsp.butter_filter(cutoff, fs, order, 'low')\n    dfilt = dsp.butter_apply(b, a, depths)\n\n    dp = numpy.hstack([numpy.diff(dfilt), 0])\n\n    asc_mask[dive_mask] = dp[dive_mask] < 0\n    des_mask[dive_mask] = dp[dive_mask] > 0\n\n    # Remove descents/ascents withough a corresponding ascent/descent\n    des_mask, asc_mask = rm_incomplete_des_asc(des_mask, asc_mask)\n\n    return des_mask, asc_mask", "response": "Get boolean masks of descents and ascents in the depth data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets boolean mask of regions in depths the animal is at the bottom", "response": "def get_bottom(depths, des_mask, asc_mask):\n    '''Get boolean mask of regions in depths the animal is at the bottom\n\n    Args\n    ----\n    des_mask: ndarray\n        Boolean mask of descents in the depth data\n    asc_mask: ndarray\n        Boolean mask of ascents in the depth data\n\n    Returns\n    -------\n    BOTTOM: ndarray (n,4)\n        Indices and depths for when the animal is at the bottom\n\n        *Index positions*:\n\n        0. start ind\n        1. depth at start\n        2. stop ind\n        3. depth at stop\n    '''\n    import numpy\n\n    from . import utils\n\n    # Get start/stop indices for descents and ascents\n    des_start, des_stop = utils.contiguous_regions(des_mask)\n    asc_start, asc_stop = utils.contiguous_regions(asc_mask)\n\n    # Bottom time is at stop of descent until start of ascent\n    bottom_len = min(len(des_stop), len(asc_start))\n    bottom_start = des_stop[:bottom_len]\n    bottom_stop  = asc_start[:bottom_len]\n\n    BOTTOM = numpy.zeros((len(bottom_start),4), dtype=float)\n\n    # Time (seconds) at start of bottom phase/end of descent\n    BOTTOM[:,0] = bottom_start\n\n    # Depth (m) at start of bottom phase/end of descent\n    BOTTOM[:,1] = depths[bottom_start]\n\n    # Time (seconds) at end of bottom phase/start of asscent\n    BOTTOM[:,2] = bottom_stop\n\n    # Depth (m) at end of bottom phase/start of descent\n    BOTTOM[:,3] = depths[bottom_stop]\n\n    return BOTTOM"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_phase(n_samples, des_mask, asc_mask):\n    '''Get the directional phase sign for each sample in depths\n\n    Args\n    ----\n    n_samples: int\n        Length of output phase array\n    des_mask: numpy.ndarray, shape (n,)\n        Boolean mask of values where animal is descending\n    asc_mask: numpy.ndarray, shape(n,)\n        Boolean mask of values where animal is ascending\n\n    Returns\n    -------\n    phase: numpy.ndarray, shape (n,)\n        Signed integer array values representing animal's dive phase\n\n        *Phases*:\n\n        *  0: neither ascending/descending\n        *  1: ascending\n        * -1: descending.\n    '''\n    import numpy\n\n    phase = numpy.zeros(n_samples, dtype=int)\n    phase[asc_mask] =  1\n    phase[des_mask] = -1\n\n    return phase", "response": "Get the directional phase sign for each sample in depths\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreserves a temporary file for future use. This is useful if you want to get a temporary file name, write to it in the future and ensure that if an exception is thrown the temporary file is removed.", "response": "def tempfilename(**kwargs):\n    \"\"\"\n    Reserve a temporary file for future use.\n\n    This is useful if you want to get a temporary file name, write to it in the\n    future and ensure that if an exception is thrown the temporary file is removed.\n    \"\"\"\n    kwargs.update(delete=False)\n    try:\n        f = NamedTemporaryFile(**kwargs)\n        f.close()\n        yield f.name\n    except Exception:\n        if os.path.exists(f.name):\n            # Ensure we clean up after ourself\n            os.unlink(f.name)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef control_high_limit(self) -> Optional[Union[int, float]]:\n        return self._get_field_value(SpecialDevice.PROP_CONTROL_HIGH_LIMIT)", "response": "Control high limit setting for a special sensor. For LS - 10 base units only Control high limit for a special sensor. For LS - 20 base units only Control high limit for a special sensor. For LS - 10 base units only Control high limit for a special sensor. For LS - 20 base units only Control high limit for a special sensor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the Control Low Limit setting for a special sensor.", "response": "def control_low_limit(self) -> Optional[Union[int, float]]:\n        \"\"\"\n        Control low limit setting for a special sensor.\n\n        For LS-10/LS-20 base units only.\n        \"\"\"\n        return self._get_field_value(SpecialDevice.PROP_CONTROL_LOW_LIMIT)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef current_reading(self) -> Optional[Union[int, float]]:\n        return self._get_field_value(SpecialDevice.PROP_CURRENT_READING)", "response": "Current reading for a special sensor."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the high limit setting for a special sensor.", "response": "def high_limit(self) -> Optional[Union[int, float]]:\n        \"\"\"\n        High limit setting for a special sensor.\n\n        For LS-10/LS-20 base units this is the alarm high limit.\n        For LS-30 base units, this is either alarm OR control high limit,\n        as indicated by special_status ControlAlarm bit flag.\n        \"\"\"\n        return self._get_field_value(SpecialDevice.PROP_HIGH_LIMIT)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlow limit setting for a special sensor.", "response": "def low_limit(self) -> Optional[Union[int, float]]:\n        \"\"\"\n        Low limit setting for a special sensor.\n\n        For LS-10/LS-20 base units this is the alarm low limit.\n        For LS-30 base units, this is either alarm OR control low limit,\n        as indicated by special_status ControlAlarm bit flag.\n        \"\"\"\n        return self._get_field_value(SpecialDevice.PROP_LOW_LIMIT)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the device with the specified ID.", "response": "def get(self, device_id: int) -> Optional[Device]:\n        \"\"\"Get device using the specified ID, or None if not found.\"\"\"\n        return self._devices.get(device_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a test train validation from the corpora given and saves it as a YAML file.", "response": "def make_ttv_yaml(corpora, path_to_ttv_file, ttv_ratio=DEFAULT_TTV_RATIO, deterministic=False):\n    \"\"\" Create a test, train, validation from the corpora given and saves it as a YAML filename.\n\n        Each set will be subject independent, meaning that no one subject can have data in more than one\n        set\n\n    # Arguments;\n        corpora: a list of the paths to corpora used (these have to be formatted accoring to notes.md)\n        path_to_ttv_file: the path to where the YAML file be be saved\n        ttv_ratio: a tuple (e.g. (1,4,4) of the relative sizoe of each set)\n        deterministic: whether or not to shuffle the resources around when making the set.\n    \"\"\"\n    dataset = get_dataset(corpora)\n    data_sets = make_ttv(dataset, ttv_ratio=ttv_ratio, deterministic=deterministic)\n\n    def get_for_ttv(key):\n        return (\n            data_sets['test'][key],\n            data_sets['train'][key],\n            data_sets['validation'][key]\n        )\n\n    test, train, validation = get_for_ttv('paths')\n\n    number_of_files_for_each_set = list(get_for_ttv('number_of_files'))\n\n    number_of_subjects_for_each_set = [len(x) for x in get_for_ttv('subjects')]\n\n    dict_for_yaml = {\n        'split': number_of_files_for_each_set,\n        'subject_split': number_of_subjects_for_each_set,\n        \"test\": test,\n        \"train\": train,\n        \"validation\": validation\n    }\n\n    with open(path_to_ttv_file, 'w') as f:\n        yaml.dump(dict_for_yaml, f, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new set of test train and validation sets for a single set of files.", "response": "def make_ttv(dataset, ttv_ratio=DEFAULT_TTV_RATIO, deterministic=False, limit_per_set=None):\n    \"\"\"\n    Return a dict of test,train,validation sets with information regarding the split (lists of paths to data).\n\n    Currently only separates by subjectID.\n\n    Prioitises having a diverse set than a well fitting set. This means that the\n    'knapsacking' is done by subjects with the least videos first, so that each set can have\n    as many different subjects in as possible. If shuffle is set to true, the set is shuffled, which means this property does not hold\n\n    returns {\n        'subjects': list of subjectIDs in the set\n        'number_of_files': number of files the set has\n        'expected_size' : (ttv_ratio * number_of_resources) or the limit_per_set (if not None),\n        'paths': list of paths to the files\n    }\n    \"\"\"\n    sizes_and_ids = [(len(dataset[key]), key) for key in dataset]\n    number_of_resources = sum([x[0] for x in sizes_and_ids])\n\n\n    # Get the smallest first\n    sizes_and_ids.sort()\n    if not deterministic:\n        random.shuffle(sizes_and_ids)\n\n    # normalise ttv_ratio\n    ttv_ratio = [float(x) / sum(ttv_ratio) for x in ttv_ratio]\n\n    data_sets = {}\n\n    for key, ratio in zip(['test', 'train', 'validation'], ttv_ratio):\n        expected_size = min(limit_per_set * ratio, (ratio * number_of_resources)) \\\n            if limit_per_set is not None else (ratio * number_of_resources)\n\n        data_sets[key] = {\n            'subjects': [],\n            'number_of_files': 0,\n            'expected_size': expected_size\n        }\n\n\n    set_names = list(data_sets.keys())\n    i = 0\n    while len(sizes_and_ids) > 0:\n        if limit_per_set is not None:\n            # if all the sets have more than the limit\n            if all(map(lambda x: x['number_of_files'] >= x['expected_size'], data_sets.values())):\n                break\n        i += 1\n        s = data_sets[set_names[i % len(set_names)]]\n        if s['number_of_files'] < s['expected_size']:\n            size, subjectID = sizes_and_ids.pop(0)\n            s['subjects'].append(subjectID)\n            s['number_of_files'] += size\n\n    def get_filenames(subjects):\n        return sum(list(map(lambda x: dataset[x], subjects)), [])\n\n    # turn subjectIDs into paths to files\n    for data_set in data_sets:\n        s = data_sets[data_set]\n        s['paths'] = get_filenames(s['subjects'])\n\n    return data_sets"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of subjectID - > path_to_resource", "response": "def get_dataset(corpora):\n    \"\"\"\n    Return a dictionary of subjectID -> [path_to_resource].\n    \"\"\"\n    # TODO: make filter methods for the files\n\n    def make_posix_path(dirpath, filename):\n        dirpath = posixpath.sep.join(dirpath.split(os.sep))\n        return posixpath.join(dirpath, filename)\n\n    wav_files_in_corpora = filter(\n        lambda x: x.endswith('.wav'),\n        sum(\n            [list(map(lambda x: make_posix_path(corpus, x), os.listdir(corpus))) for corpus in corpora],\n            []\n        ),\n    )\n\n    dataset = {}\n    for wav_file in wav_files_in_corpora:\n        subjectID = os.path.split(wav_file)[-1].split('.')[0].split('_')[0]\n\n        if subjectID in dataset:\n            dataset[subjectID].append(wav_file)\n        else:\n            dataset[subjectID] = [wav_file]\n\n    return dataset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the user config file", "response": "def load_user_config(vcs):\n    \"\"\"Load the user config\n\n    Args:\n        vcs (easyci.vcs.base.Vcs) - the vcs object for the current project\n\n    Returns:\n        dict - the config\n\n    Raises:\n        ConfigFormatError\n        ConfigNotFoundError\n    \"\"\"\n    config_path = os.path.join(vcs.path, 'eci.yaml')\n    if not os.path.exists(config_path):\n        raise ConfigNotFoundError\n    with open(config_path, 'r') as f:\n        try:\n            config = yaml.safe_load(f)\n        except yaml.YAMLError:\n            raise ConfigFormatError\n    if not isinstance(config, dict):\n        raise ConfigFormatError\n    for k, v in _default_config.iteritems():\n        config.setdefault(k, v)\n    for k, v in _config_types.iteritems():\n        if not isinstance(config[k], v):\n            raise ConfigFormatError\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expose_request(func):\n    if not python.callable(func):\n        raise TypeError(\"func must be callable\")\n\n    if isinstance(func, types.UnboundMethodType):\n        setattr(func.im_func, '_pyamf_expose_request', True)\n    else:\n        setattr(func, '_pyamf_expose_request', True)\n\n    return func", "response": "A decorator that adds an expose_request flag to the underlying function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a C { dict of valid method callables for the underlying service object.", "response": "def getMethods(self):\n        \"\"\"\n        Gets a C{dict} of valid method callables for the underlying service\n        object.\n        \"\"\"\n        callables = {}\n\n        for name in dir(self.service):\n            method = getattr(self.service, name)\n\n            if name.startswith('_') or not python.callable(method):\n                continue\n\n            callables[name] = method\n\n        return callables"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a service to the internal list of services.", "response": "def addService(self, service, name=None, description=None,\n        authenticator=None, expose_request=None, preprocessor=None):\n        \"\"\"\n        Adds a service to the gateway.\n\n        @param service: The service to add to the gateway.\n        @type service: C{callable}, class instance, or a module\n        @param name: The name of the service.\n        @type name: C{str}\n        @raise pyamf.remoting.RemotingError: Service already exists.\n        @raise TypeError: C{service} cannot be a scalar value.\n        @raise TypeError: C{service} must be C{callable} or a module.\n        \"\"\"\n        if isinstance(service, (int, long, float, basestring)):\n            raise TypeError(\"Service cannot be a scalar value\")\n\n        allowed_types = (types.ModuleType, types.FunctionType, types.DictType,\n            types.MethodType, types.InstanceType, types.ObjectType)\n\n        if not python.callable(service) and not isinstance(service, allowed_types):\n            raise TypeError(\"Service must be a callable, module, or an object\")\n\n        if name is None:\n            # TODO: include the module in the name\n            if isinstance(service, (type, types.ClassType)):\n                name = service.__name__\n            elif isinstance(service, types.FunctionType):\n                name = service.func_name\n            elif isinstance(service, types.ModuleType):\n                name = service.__name__\n            else:\n                name = str(service)\n\n        if name in self.services:\n            raise remoting.RemotingError(\"Service %s already exists\" % name)\n\n        self.services[name] = ServiceWrapper(service, description,\n            authenticator, expose_request, preprocessor)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef removeService(self, service):\n        for name, wrapper in self.services.iteritems():\n            if service in (name, wrapper.service):\n                del self.services[name]\n                return\n\n        raise NameError(\"Service %r not found\" % (service,))", "response": "Removes a service from the internal cache."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a service based on the message.", "response": "def getServiceRequest(self, request, target):\n        \"\"\"\n        Returns a service based on the message.\n\n        @raise UnknownServiceError: Unknown service.\n        @param request: The AMF request.\n        @type request: L{Request<pyamf.remoting.Request>}\n        @rtype: L{ServiceRequest}\n        \"\"\"\n        try:\n            return self._request_class(\n                request.envelope, self.services[target], None)\n        except KeyError:\n            pass\n\n        try:\n            sp = target.split('.')\n            name, meth = '.'.join(sp[:-1]), sp[-1]\n\n            return self._request_class(\n                request.envelope, self.services[name], meth)\n        except (ValueError, KeyError):\n            pass\n\n        raise UnknownServiceError(\"Unknown service %s\" % target)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn request processor. @param request: The AMF message. @type request: L{Request<remoting.Request>}", "response": "def getProcessor(self, request):\n        \"\"\"\n        Returns request processor.\n\n        @param request: The AMF message.\n        @type request: L{Request<remoting.Request>}\n        \"\"\"\n        if request.target == 'null' or not request.target:\n            from pyamf.remoting import amf3\n\n            return amf3.RequestProcessor(self)\n        else:\n            from pyamf.remoting import amf0\n\n            return amf0.RequestProcessor(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mustExposeRequest(self, service_request):\n        expose_request = service_request.service.mustExposeRequest(service_request)\n\n        if expose_request is None:\n            if self.expose_request is None:\n                return False\n\n            return self.expose_request\n\n        return expose_request", "response": "Returns True if the underlying http request should be exposed as the\n            first argument to the method call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getAuthenticator(self, service_request):\n        auth = service_request.service.getAuthenticator(service_request)\n\n        if auth is None:\n            return self.authenticator\n\n        return auth", "response": "Gets an authenticator callable based on the service_request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticateRequest(self, service_request, username, password, **kwargs):\n        authenticator = self.getAuthenticator(service_request)\n\n        if authenticator is None:\n            return True\n\n        args = (username, password)\n\n        if hasattr(authenticator, '_pyamf_expose_request'):\n            http_request = kwargs.get('http_request', None)\n            args = (http_request,) + args\n\n        return authenticator(*args) == True", "response": "Process an authentication request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a preprocessor function based on the service_request.", "response": "def getPreprocessor(self, service_request):\n        \"\"\"\n        Gets a preprocessor callable based on the service_request. This is\n        granular, looking at the service method first, then at the service\n        level and finally to see if there is a global preprocessor function\n        for the gateway. Returns C{None} if one could not be found.\n        \"\"\"\n        preproc = service_request.service.getPreprocessor(service_request)\n\n        if preproc is None:\n            return self.preprocessor\n\n        return preproc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef callServiceRequest(self, service_request, *args, **kwargs):\n        if self.mustExposeRequest(service_request):\n            http_request = kwargs.get('http_request', None)\n            args = (http_request,) + args\n\n        return service_request(*args)", "response": "Executes the service_request with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nschedules a function to be run by workers on the specified queue.", "response": "def schedule_function(queue_name, function_name, *args, **kwargs):\n    \"\"\"\n    Schedule a function named `function_name` to be run by workers on\n    the queue `queue_name` with *args and **kwargs as specified by that\n    function.\n    \"\"\"\n    body = create_request_body(function_name, *args, **kwargs)\n    if getattr(settings, 'BEANSTALK_DISPATCH_EXECUTE_SYNCHRONOUSLY', False):\n        execute_function(json.loads(body))\n    else:\n        connection = boto.connect_sqs(\n            settings.BEANSTALK_DISPATCH_SQS_KEY,\n            settings.BEANSTALK_DISPATCH_SQS_SECRET)\n        queue = connection.get_queue(queue_name)\n        if not queue:\n            queue = connection.create_queue(queue_name)\n        message = boto.sqs.message.Message()\n        message.set_body(body)\n        queue.write(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a function on a node.", "response": "def execute_function(function_request):\n    \"\"\"\n    Given a request created by\n    `beanstalk_dispatch.common.create_request_body`, executes the\n    request.  This function is to be run on a beanstalk worker.\n    \"\"\"\n    dispatch_table = getattr(settings, 'BEANSTALK_DISPATCH_TABLE', None)\n\n    if dispatch_table is None:\n        raise BeanstalkDispatchError('No beanstalk dispatch table configured')\n    for key in (FUNCTION, ARGS, KWARGS):\n        if key not in function_request.keys():\n            raise BeanstalkDispatchError(\n                'Please provide a {} argument'.format(key))\n\n    function_path = dispatch_table.get(\n        function_request[FUNCTION], ''\n    )\n\n    if function_path:\n        runnable = locate(function_path)\n        if not runnable:\n            raise BeanstalkDispatchError(\n                'Unable to locate function: {}'.format(function_path))\n\n        args = function_request[ARGS]\n        kwargs = function_request[KWARGS]\n        if inspect.isclass(runnable):\n            if issubclass(runnable, SafeTask):\n                task = runnable()\n            else:\n                raise BeanstalkDispatchError(\n                    'Requested task is not a SafeTask subclass: {}'.format(\n                        function_request[FUNCTION]))\n        else:\n            task = SafeTask()\n            task.run = runnable\n        task.process(*args, **kwargs)\n    else:\n        raise BeanstalkDispatchError(\n            'Requested function not found: {}'.format(\n                function_request[FUNCTION]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the minimum and maximum value for this config value.", "response": "def set_limits(self, min_: typing.Optional[float] = None, max_: typing.Optional[float] = None):\n        \"\"\"\n        Sets limits for this config value\n\n        If the resulting integer is outside those limits, an exception will be raised\n\n        :param min_: minima\n        :param max_: maxima\n        \"\"\"\n        self._min, self._max = min_, max_"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node_input():\n    try:\n        node = int(raw_input(\"Node id: \"))\n    except ValueError:\n        node = INVALID_NODE\n        print 'invalid node id: %s' % node\n    return node", "response": "Get a valid node id from the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an existing node id by name or id.", "response": "def existing_node_input():\n    \"\"\"\n    Get an existing node id by name or id.\n\n    Return -1 if invalid\n    \"\"\"\n    input_from_user = raw_input(\"Existing node name or id: \")\n    node_id = INVALID_NODE\n\n    if not input_from_user:\n        return node_id\n\n    # int or str?\n    try:\n        parsed_input = int(input_from_user)\n    except ValueError:\n        parsed_input = input_from_user\n\n    if isinstance(parsed_input, int):\n        result = db.execute(text(fetch_query_string('select_node_from_id.sql')),\n                node_id=parsed_input).fetchall()\n        if result:\n            node_id = int(result[0]['node_id'])\n    else:\n        result = db.execute(text(fetch_query_string('select_node_from_name.sql')),\n                node_name=parsed_input).fetchall()\n        if result:\n            if len(result) == 1:\n                print 'Node id: {node_id}\\nNode name: {name}'.format(**result[0])\n                print '-------------'\n                node_id = result[0]['node_id']\n            else:\n                print 'Multiple nodes found with the name: {0}'.format(parsed_input)\n                for item in result:\n                    print '{node_id}: {name} = {value}'.format(**item)\n                node_selection = raw_input('Enter a node id from this list or enter \"?\" to render all or \"?<node>\" for a specific one.')\n                if node_selection:\n                    node_selection_match = re.match(r\"\\?(\\d)*\", node_selection)\n                    if node_selection_match:\n                        if node_selection_match.groups()[0]:\n                            value = render_node(int(node_selection_match.groups()[0]), noderequest={'_no_template':True}, **result[0])\n                            print safe_dump(value, default_flow_style=False)\n                        else:\n                            for item in result:\n                                value = render_node(item['node_id'], noderequest={'_no_template':True}, **item)\n                                print 'Node id: {0}'.format(item['node_id'])\n                                print safe_dump(value, default_flow_style=False)\n                                print '---'\n                        node_id = node_input()\n                    else:\n                        try:\n                            node_id = int(node_selection)\n                        except ValueError:\n                            node_id = INVALID_NODE\n                            print 'invalid node id: %s' % node\n\n    return node_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_value_for_node(node_id):\n    value = None\n    result = []\n    try:\n        result = db.execute(text(fetch_query_string('select_node_from_id.sql')), node_id=node_id).fetchall()\n    except DatabaseError as err:\n        current_app.logger.error(\"DatabaseError: %s\", err)\n\n    if result:\n        kw = dict(zip(result[0].keys(), result[0].values()))\n        value = render_node(node_id, noderequest={'_no_template':True}, **kw)\n\n    return value", "response": "Wrap render_node for usage in operate scripts. Returns without template\n    rendered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmanage an existing collection node.", "response": "def mode_collection():\n    \"\"\"\n    Manage an existing collection node.\n    \"\"\"\n    print globals()['mode_collection'].__doc__\n    collection_node_id = existing_node_input()\n    value = render_value_for_node(collection_node_id)\n    if not value:\n        return None\n    print \"Collection length: {0}\".format(len(value))\n    print safe_dump(value, default_flow_style=False)\n\n    item_attr_list = []\n    if len(value):\n        for key in value.items()[0][1].keys():\n            m = re.match(r'(.*) \\((\\d+)\\)', key)\n            item_attr_list.append(m.group(1))\n\n    selection = True\n    while selection:\n        selection = select([\n            'View collection',\n            'Add item',\n            'Add attribute',\n            'Remove item',\n            'Remove attribute',\n            'Purge collection'\n            ])\n        if selection == 'View collection':\n            print safe_dump(value, default_flow_style=False)\n        elif selection == 'Purge collection':\n            confirm = raw_input(\"Delete all {0} items and their {1} attributes from the collection? y/n\\n\".format(len(value.keys()), len(item_attr_list)))\n            if confirm == 'y':\n                delete_node(node_id=collection_node_id)\n                purge_collection(value.keys())\n        elif selection == 'Remove item':\n            item_node_id = existing_node_input()\n            if item_node_id < 0:\n                return\n            value = render_value_for_node(item_node_id)\n            print safe_dump(value, default_flow_style=False)\n            confirm = raw_input(\"Delete this node and it's attributes? y/n\\n\").format(len(value.keys()), len(item_attr_list))\n            if confirm == 'y':\n                delete_node(node_id=item_node_id)\n                purge_collection(value.keys())\n\n        elif selection == 'Add item':\n            result = select_node(node_id=collection_node_id)\n            collection_name = result[0].get('name')\n\n            add_item_with_attributes_to_collection(\n                    collection_name=collection_name,\n                    collection_node_id=collection_node_id,\n                    item_attr_list=item_attr_list)\n        elif selection == 'Remove attribute':\n            print \"Select the attribute that will be removed:\"\n            attribute_selection = select(item_attr_list)\n            if attribute_selection:\n                confirm = raw_input(\"Delete attribute '{0}' from all {1} items in the collection? y/n\\n\".format(attribute_selection, len(value.keys())))\n                if confirm == 'y':\n                    for item_key, item in value.items():\n                        for key in item.keys():\n                            m = re.match(r'(.*) \\((\\d+)\\)', key)\n                            if m.group(1) == attribute_selection:\n                                delete_node(node_id=m.group(2))\n                                break\n        elif selection == 'Add attribute':\n            item_attr = raw_input(\"Add a collection item attribute name: \")\n            if item_attr:\n                item_index = 0\n                for item_key, item in value.items():\n                    item_index += 1\n                    m = re.match(r'(.*) \\((\\d+)\\)', item_key)\n                    item_value = render_value_for_node(m.group(2))\n                    print \"item {0} of {1} items\".format(item_index, len(value))\n                    print safe_dump(item_value, default_flow_style=False)\n\n                    new_attr_value = raw_input(\"Enter item attribute value for '{0}': \".format(item_attr))\n                    # set value to none if it's an empty string\n                    new_attr_value = new_attr_value if len(new_attr_value) else None\n                    item_attr_node_id = insert_node(name=item_attr, value=new_attr_value)\n\n                    insert_node_node(node_id=m.group(2), target_node_id=item_attr_node_id)\n        # Update the value after each operation\n        value = render_value_for_node(collection_node_id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mode_new_collection():\n\n    print globals()['mode_new_collection'].__doc__\n    collection_name = raw_input(\"Collection name: \")\n    item_attr_list = []\n    collection_node_id = None\n    if collection_name:\n        collection_node_id = insert_node(name=collection_name, value=None)\n        insert_query(name='select_link_node_from_node.sql', node_id=collection_node_id)\n        item_attr = True\n        while item_attr:\n            item_attr = raw_input(\"Add a collection item attribute name: \")\n            if item_attr:\n                item_attr_list.append(item_attr)\n\n    # if no collection name then exit\n    selection = collection_name\n\n    while selection:\n        selection = select([\n            'Add item',\n            ])\n        if selection == 'Add item':\n            # create item\n            add_item_with_attributes_to_collection(\n                    collection_name=collection_name,\n                    collection_node_id=collection_node_id,\n                    item_attr_list=item_attr_list)\n\n    if collection_node_id:\n        print \"Added collection name '{0}' with node id: {1}\".format(collection_name, collection_node_id)", "response": "Create a new collection of items with common attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mode_database_functions():\n    \"Select a function to perform from chill.database\"\n\n    print globals()['mode_database_functions'].__doc__\n    selection = True\n    database_functions = [\n            'init_db',\n            'insert_node',\n            'insert_node_node',\n            'delete_node',\n            'select_node',\n            'insert_route',\n            'insert_query',\n            'add_template_for_node',\n            'fetch_query_string',\n            ]\n    while selection:\n        choices = database_functions + [\n            'help',\n            ]\n        selection = select(choices)\n\n        if selection:\n            print globals().get(selection).__doc__\n        if selection == 'init_db':\n            confirm = raw_input(\"Initialize new database y/n? [n] \")\n            if confirm == 'y':\n                init_db()\n        elif selection == 'insert_node':\n            name = raw_input(\"Node name: \")\n            value = raw_input(\"Node value: \")\n            node = insert_node(name=name, value=value or None)\n            print \"name: %s \\nid: %s\" % (name, node)\n\n        elif selection == 'insert_query':\n            sqlfile = choose_query_file()\n            if sqlfile:\n                node = existing_node_input()\n                if node >= 0:\n                    insert_query(name=sqlfile, node_id=node)\n                    print \"adding %s to node id: %s\" % (sqlfile, node)\n\n        elif selection == 'insert_node_node':\n            print \"Add parent node id\"\n            node = existing_node_input()\n            print \"Add target node id\"\n            target_node = existing_node_input()\n            if node >= 0 and target_node >= 0:\n                insert_node_node(node_id=node, target_node_id=target_node)\n\n        elif selection == 'delete_node':\n            node = existing_node_input()\n            if node >= 0:\n                delete_node(node_id=node)\n\n        elif selection == 'select_node':\n            node = existing_node_input()\n            if node >= 0:\n                result = select_node(node_id=node)\n                print safe_dump(dict(zip(result[0].keys(), result[0].values())), default_flow_style=False)\n\n        elif selection == 'insert_route':\n            path = raw_input('path: ')\n            weight = raw_input('weight: ') or None\n            method = raw_input('method: ') or 'GET'\n            node = existing_node_input()\n            if node >= 0:\n                insert_route(path=path, node_id=node, weight=weight, method=method)\n        elif selection == 'add_template_for_node':\n            folder = current_app.config.get('THEME_TEMPLATE_FOLDER')\n            choices = map(os.path.basename,\n                        glob(os.path.join(folder, '*'))\n                        )\n            choices.sort()\n            templatefile = select(choices)\n            if templatefile:\n                node = existing_node_input()\n                if node >= 0:\n                    add_template_for_node(name=templatefile, node_id=node)\n                    print \"adding %s to node id: %s\" % (templatefile, node)\n\n        elif selection == 'fetch_query_string':\n            sqlfile = choose_query_file()\n            if sqlfile:\n                sql = fetch_query_string(sqlfile)\n                print sql\n\n        elif selection == 'help':\n            print \"------\"\n            for f in database_functions:\n                print \"\\n** %s **\" % f\n                print globals().get(f).__doc__\n            print \"------\"\n        else:\n            pass", "response": "Select a function to perform from chill. database"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef operate_menu():\n    \"Select between these operations on the database\"\n\n    selection = True\n    while selection:\n\n        print globals()['operate_menu'].__doc__\n        selection = select([\n            'chill.database functions',\n            'execute sql file',\n            'render_node',\n            'New collection',\n            'Manage collection',\n            'Add document for node',\n            'help',\n            ])\n        if selection == 'chill.database functions':\n            mode_database_functions()\n        elif selection == 'execute sql file':\n            print \"View the sql file and show a fill in the blanks interface with raw_input\"\n            sqlfile = choose_query_file()\n            if not sqlfile:\n                # return to the menu choices if not file picked\n                selection = True\n            else:\n                sql_named_placeholders_re = re.compile(r\":(\\w+)\")\n                sql = fetch_query_string(sqlfile)\n                placeholders = set(sql_named_placeholders_re.findall(sql))\n                print sql\n                data = {}\n                for placeholder in placeholders:\n                    value = raw_input(placeholder + ': ')\n                    data[placeholder] = value\n\n                result = []\n                try:\n                    result = db.execute(text(sql), data)\n                except DatabaseError as err:\n                    current_app.logger.error(\"DatabaseError: %s\", err)\n\n                if result and result.returns_rows:\n                    result = result.fetchall()\n                    print result\n                    if not result:\n                        print 'No results.'\n                    else:\n                        kw = result[0]\n\n                        if 'node_id' in kw:\n                            print 'render node %s' % kw['node_id']\n                            value = render_node(kw['node_id'], **kw)\n                            print safe_dump(value, default_flow_style=False)\n                        else:\n                            #print safe_dump(rowify(result, [(x, None) for x in result[0].keys()]), default_flow_style=False)\n                            print safe_dump([dict(zip(x.keys(), x.values())) for x in result], default_flow_style=False)\n\n        elif selection == 'render_node':\n            print globals()['render_node'].__doc__\n            node_id = existing_node_input()\n\n            value = render_value_for_node(node_id)\n            print safe_dump(value, default_flow_style=False)\n\n        elif selection == 'New collection':\n            mode_new_collection()\n        elif selection == 'Manage collection':\n            mode_collection()\n        elif selection == 'Add document for node':\n            folder = current_app.config.get('DOCUMENT_FOLDER')\n            if not folder:\n                print \"No DOCUMENT_FOLDER configured for the application.\"\n            else:\n                choices = map(os.path.basename,\n                            glob(os.path.join(folder, '*'))\n                            )\n                choices.sort()\n                if len(choices) == 0:\n                    print \"No files found in DOCUMENT_FOLDER.\"\n                else:\n                    filename = select(choices)\n                    if filename:\n                        defaultname = os.path.splitext(filename)[0]\n                        nodename = raw_input(\"Enter name for node [{0}]: \".format(defaultname)) or defaultname\n                        node = insert_node(name=nodename, value=filename)\n                        print \"Added document '%s' to node '%s' with id: %s\" % (filename, nodename, node)\n        elif selection == 'help':\n            print \"------\"\n            print __doc__\n            print \"------\"\n        else:\n            print 'Done'", "response": "Select between these operations on the database"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef safe_service(attr, default_value=None):\n    '''A **method** decorator for creating safe services.\n\n    Given an attribute name, this returns a decorator for creating\n    safe services. Namely, if a service that is not yet available is\n    requested (like a database connection), then ``safe_service`` will\n    log any errors and set the given attribute to ``default_value``.\n\n    :param str attr: attribute name\n    :param object default_value: default value to set\n    :rtype: decorator\n    '''\n    def _(fun):\n        @functools.wraps(fun)\n        def run(self):\n            try:\n                return fun(self)\n            except:\n                logger.error(traceback.format_exc())\n                setattr(self, attr, default_value)\n        return run\n    return _", "response": "A decorator for creating safe services. Given an attribute name this returns a decorator for creating safe services."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a thread local property.", "response": "def thread_local_property(name):\n    '''Creates a thread local ``property``.'''\n    name = '_thread_local_' + name\n\n    def fget(self):\n        try:\n            return getattr(self, name).value\n        except AttributeError:\n            return None\n\n    def fset(self, value):\n        getattr(self, name).value = value\n\n    return property(fget=fget, fset=fset)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a thread local :class : dossier. web. Tags client.", "response": "def tags(self):\n        'Return a thread local :class:`dossier.web.Tags` client.'\n        if self._tags is None:\n            config = global_config('dossier.tags')\n            self._tags = self.create(Tags, config=config)\n        return self._tags"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a thread local : class : dossier. store. Store client.", "response": "def store(self):\n        '''Return a thread local :class:`dossier.store.Store` client.'''\n        if self._store is None:\n            config = global_config('dossier.store')\n            self._store = self.create(ElasticStore, config=config)\n        return self._store"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a thread local : class : dossier. label. LabelStore client.", "response": "def label_store(self):\n        '''Return a thread local :class:`dossier.label.LabelStore` client.'''\n        if self._label_store is None:\n            config = global_config('dossier.label')\n            if 'kvlayer' in config:\n                kvl = kvlayer.client(config=config['kvlayer'])\n                self._label_store = LabelStore(kvl)\n            else:\n                self._label_store = self.create(LabelStore, config=config)\n        return self._label_store"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kvlclient(self):\n        '''Return a thread local ``kvlayer`` client.'''\n        if self._kvlclient is None:\n            self._kvlclient = kvlayer.client()\n        return self._kvlclient", "response": "Return a thread local kvlayer client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndivide the task according to the number of workers.", "response": "def divide(self, data_source_factory):\n        \"\"\"Divides the task according to the number of workers.\"\"\"\n        data_length = data_source_factory.length()\n        data_interval_length = data_length / self.workers_number() + 1\n\n        current_index = 0\n        self.responses = []\n        while current_index < data_length:\n            self.responses.append(0)\n            offset = current_index\n            limit = min((data_length - current_index, data_interval_length))\n            yield data_source_factory.part(limit, offset)\n            current_index += limit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending tasks to workers and awaits the responses.", "response": "def map(self, data_source_factory, timeout=0, on_timeout=\"local_mode\"):\n        \"\"\"Sends tasks to workers and awaits the responses.\n        When all the responses are received, reduces them and returns the result.\n\n        If timeout is set greater than 0, producer will quit waiting for workers when time has passed.\n        If on_timeout is set to \"local_mode\", after the time limit producer will run tasks locally.\n        If on_timeout is set to \"fail\", after the time limit producer raise TimeOutException.\n        \"\"\"\n        def local_launch():\n            print \"Local launch\"\n            return self.reduce_fn(\n                        self.map_fn(data_source_factory.build_data_source())\n                    )\n\n        if self.local_mode:\n            return local_launch()\n\n        for index, factory in enumerate(self.divide(data_source_factory)):\n            self.unprocessed_request_num += 1\n            self.logging.info(\"Sending %d-th message with %d elements\" % (index + 1, factory.length()))\n            self.logging.info(\"len(data) = %d\" % len(pickle.dumps(factory)))\n            self.channel.basic_publish(exchange='',\n                                       routing_key=self.routing_key(),\n                                       properties=pika.BasicProperties(\n                                           reply_to=self.callback_queue,\n                                           correlation_id=\"_\".join((self.correlation_id, str(index))),\n                                       ),\n                                       body=pickle.dumps(factory))\n\n        self.logging.info(\"Waiting...\")\n\n        time_limit_exceeded = [False]\n\n        def on_timeout_func():\n            print \"Timeout!!\"\n            self.logging.warning(\"Timeout!\")\n            time_limit_exceeded[0] = True\n\n        if timeout > 0:\n            self.timer = Timer(timeout, on_timeout_func)\n            self.timer.start()\n\n        while self.unprocessed_request_num:\n            if time_limit_exceeded[0]:\n                if on_timeout == \"local_mode\":\n                    return local_launch()\n\n                assert on_timeout == \"fail\", \"Invalid value for on_timeout: %s\" % on_timeout\n                raise TimeOutException()\n\n            self.connection.process_data_events()\n\n        self.logging.info(\"Responses: %s\" % str(self.responses))\n        return self.reduce_fn(self.responses)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lock(self, *args):\n        if not args:\n            args = [self.model]\n        cursor = connection.cursor()\n        tables = \", \".join(['%s WRITE' % connection.ops.quote_name(model._meta.db_table) for model in args])\n        logger.debug('LOCK TABLES %s' % tables)\n        cursor.execute(\"LOCK TABLES %s\" % tables)\n        row = cursor.fetchone()\n        return row", "response": "Locks the object model table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunlock all tables in the database.", "response": "def unlock(self):\n        \"\"\"\n        Unlock the table(s)\n        \"\"\"\n        cursor = connection.cursor()\n        cursor.execute(\"UNLOCK TABLES\")\n        logger.debug('Unlocked tables')\n        row = cursor.fetchone()\n        return row"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dict with false - values removed", "response": "def _orderedCleanDict(attrsObj):\n    \"\"\"\n    -> dict with false-values removed\n\n    Also evaluates attr-instances for false-ness by looking at the values of their properties\n    \"\"\"\n    def _filt(k, v):\n        if attr.has(v):\n            return not not any(attr.astuple(v))\n        return not not v\n\n    return attr.asdict(attrsObj,\n        dict_factory=OrderedDict,\n        recurse=False,\n        filter=_filt)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrepresent an OpenAPIOperation object.", "response": "def representCleanOpenAPIOperation(dumper, data):\n    \"\"\"\n    Unpack nonstandard attributes while representing an OpenAPIOperation\n    \"\"\"\n    dct = _orderedCleanDict(data)\n    if '_extended' in dct:\n        for k, ext in list(data._extended.items()):\n            dct[k] = ext\n        del dct['_extended']\n\n    return dumper.yaml_representers[type(dct)](dumper, dct)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrepresent an OpenAPIPathItem by removing the _operations key and converting the values to their corresponding OpenAPIPathItem objects.", "response": "def representCleanOpenAPIPathItem(dumper, data):\n    \"\"\"\n    Unpack operation key/values before representing an OpenAPIPathItem\n    \"\"\"\n    dct = _orderedCleanDict(data)\n    if '_operations' in dct:\n        items = sorted(data._operations.items())\n        for k, op in items:\n            dct[k] = op\n        del dct['_operations']\n\n    return dumper.yaml_representers[type(dct)](dumper, dct)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef representCleanOpenAPIParameter(dumper, data):\n    dct = _orderedCleanDict(data)\n    # We are using \"in_\" as a key for the \"in\" parameter, since in is a Python keyword.\n    # To represent it correctly, we then have to swap \"in_\" for \"in\".\n    # So we do an item-by-item copy of the dct so we don't change the order when\n    # making this swap.\n    d2 = OrderedDict()\n    for k, v in dct.copy().items():\n        if k == 'in_':\n            d2['in'] = v\n        else:\n            d2[k] = v\n\n    return dumper.yaml_representers[type(d2)](dumper, d2)", "response": "Represent an OpenAPIParameter with a clean dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef representCleanOpenAPIObjects(dumper, data):\n    dct = _orderedCleanDict(data)\n\n    return dumper.yaml_representers[type(dct)](dumper, dct)", "response": "Produce a representation of an OpenAPI object removing empty attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mediaTypeHelper(mediaType):\n    def _innerHelper(data=None):\n        \"\"\"\n        Create a Responses object that contains a MediaType entry of the specified mediaType\n\n        Convenience function for the most common cases where you need an instance of Responses\n        \"\"\"\n        ret = OpenAPIResponses()\n        if data is None:\n            data = {}\n        ret.default.content[mediaType] = data\n        return ret\n    return _innerHelper", "response": "Returns a function that creates a Responses object that contains a MediaType entry of the specified mediaType"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ensure_config_file_exists():\n    config_file = Path(ELIBConfig.config_file_path).absolute()\n    if not config_file.exists():\n        raise ConfigFileNotFoundError(ELIBConfig.config_file_path)", "response": "Ensures that the config file exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the set of checkers that are relevant to the given path.", "response": "def _relevant_checkers(self, path):\n        \"\"\"\n        Get set of checkers for the given path.\n\n        TODO: currently this is based off the file extension.  We would like to\n        honor magic bits as well, so that python binaries, shell scripts, etc\n        but we're not guaranteed that `path` currently exists on the filesystem\n        -- e.g. when version control for historical revs is used.\n        \"\"\"\n        _, ext = os.path.splitext(path)\n        ext = ext.lstrip('.')\n        return checkers.checkers.get(ext, [])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _resolve_paths(self, *paths):\n        result = set()\n        for path in paths:\n            if os.path.isdir(path):\n                for dirpath, _, filenames in os.walk(path):\n                    for filename in filenames:\n                        path = os.path.join(dirpath, filename)\n                        if path.startswith('.'):\n                            path = path[1:].lstrip('/')\n                        if not self._should_ignore(path):\n                            result.add(path)\n            else:\n                result.add(path)\n        return result", "response": "Resolve paths into a set of filenames to check."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints information about checkers and their external tools.", "response": "def _list_checkers(self):\n        \"\"\"\n        Print information about checkers and their external tools.\n\n        Currently only works properly on systems with the `which` tool\n        available.\n        \"\"\"\n        classes = set()\n        for checker_group in checkers.checkers.itervalues():\n            for checker in checker_group:\n                classes.add(checker)\n\n        max_width = 0\n        for clazz in classes:\n            max_width = max(max_width, len(clazz.tool), len(clazz.__name__))\n\n        for clazz in sorted(classes):\n            status, _ = commands.getstatusoutput('which %s' % clazz.tool)\n            result = 'missing' if status else 'installed'\n            version = '' if status else clazz.get_version()\n            print '%s%s%s%s' % (\n                clazz.__name__.ljust(max_width + 1),\n                clazz.tool.ljust(max_width + 1),\n                result.ljust(max_width + 1),\n                version,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _should_ignore(self, path):\n        for ignore in self.options.ignores:\n            if fnmatch.fnmatch(path, ignore):\n                return True\n        return False", "response": "Return True iff path should be ignored."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef legacy_notes_view(request):\n    notes = TeacherNote.objects.all()\n    note_count = notes.count()\n    paginator = Paginator(notes, 100)\n\n    page = request.GET.get('page')\n    try:\n        notes = paginator.page(page)\n    except PageNotAnInteger:\n        notes = paginator.page(1)\n    except EmptyPage:\n        notes = paginator.page(paginator.num_pages)\n    return render_to_response(\n        'teacher_notes.html',\n        {'page_name': \"Legacy Notes\",\n         'notes': notes,\n         'note_count': note_count,},\n        context_instance=RequestContext(request)\n    )", "response": "View to see legacy notes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nviews to see legacy events.", "response": "def legacy_events_view(request):\n    \"\"\"\n    View to see legacy events.\n    \"\"\"\n    events = TeacherEvent.objects.all()\n    event_count = events.count()\n    paginator = Paginator(events, 100)\n\n    page = request.GET.get('page')\n    try:\n        events = paginator.page(page)\n    except PageNotAnInteger:\n        events = paginator.page(1)\n    except EmptyPage:\n        events = paginator.page(paginator.num_pages)\n    return render_to_response(\n        'teacher_events.html',\n        {'page_name': \"Legacy Events\",\n         'events': events,\n         'event_count': event_count,},\n        context_instance=RequestContext(request)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef legacy_requests_view(request, rtype):\n    if not rtype in ['food', 'maintenance']:\n        raise Http404\n    requests_dict = [] # [(req, [req_responses]), (req2, [req2_responses]), ...]\n    requests = TeacherRequest.objects.filter(request_type=rtype)\n    request_count = requests.count()\n    paginator = Paginator(requests, 50)\n\n    page = request.GET.get('page')\n    try:\n        requests = paginator.page(page)\n    except PageNotAnInteger:\n        requests = paginator.page(1)\n    except EmptyPage:\n        requests = paginator.page(paginator.num_pages)\n    for req in requests:\n        requests_dict.append(\n            (req, TeacherResponse.objects.filter(request=req),)\n        )\n    return render_to_response(\n        'teacher_requests.html',\n        {'page_name': \"Legacy {rtype} Requests\".format(rtype=rtype.title()),\n         'requests_dict': requests_dict,\n         'requests': requests,\n         'request_type': rtype.title(),\n         'request_count': request_count,},\n        context_instance=RequestContext(request)\n    )", "response": "View to see legacy requests of rtype request type which should be either\n    food or maintenance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_command_orig(cmd):\n    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    if process.returncode == 0:\n        os.killpg(os.getpgid(pro.pid), signal.SIGTERM)\n    else:\n        raise BadRCError(\"Bad rc (%s) for cmd '%s': %s\" % (process.returncode, cmd, stdout + stderr))\n    return stdout", "response": "Run command and return stdout and stderr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_short_url(self):\r\n        return reverse('post_short_url', args=(self.forum.slug, self.slug, self.id))", "response": "Returns the short version of the topic url"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget count of total pages Get count of total pages", "response": "def page_count(self):\r\n        \"\"\"\r\n        Get count of total pages\r\n        \"\"\"\r\n        postcount = self.post_set.count()\r\n        max_pages = (postcount / get_paginate_by())\r\n        if postcount % get_paginate_by() != 0:\r\n            max_pages += 1\r\n        return max_pages"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_image(self):\r\n        posts_with_images = self.post_set.filter(image__gt='')\r\n        if posts_with_images:\r\n            return posts_with_images[0].image", "response": "Gets the first image from the post set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the URL to the post.", "response": "def post_url(self):\r\n        \"\"\"\r\n        Determine which page this post lives on within the topic\r\n        and return link to anchor within that page\r\n        \"\"\"\r\n        topic = self.topic\r\n        topic_page = topic.post_set.filter(id__lt=self.id).count() / get_paginate_by() + 1\r\n        return \"{0}page{1}/#post-{2}\".format(topic.get_short_url(), topic_page, self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next(self):\n        if self._cur_col >= len(self._rec):\n            self._cur_col = 0\n            raise StopIteration\n        col = self._rec[self._cur_col]\n        self._cur_col += 1\n        return col", "response": "Return the next column in the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if type of record is allowed by recorddef.", "response": "def _chk_type(recdef, rec):\n        \"\"\"Checks if type of `rec` matches `recdef`\n        :param recdef: instance of RecordDef\n        :param rec:    instance of Record\n        :raises:       `TypeError`\n        \"\"\"\n        if len(recdef) != len(rec):\n            raise TypeError(\"Number of columns (%d) is different from RecordDef (%d)\" % (len(rec), len(recdef)))\n\n        for i in xrange(len(recdef)):\n            try:\n                def_type = recdef[i].type\n                col_type = Type.equivalent_relshell_type(rec[i])\n                if col_type != def_type:\n                    raise TypeError(\"Column %d has mismatched type:  Got '%s' [%s] ; Expected [%s]\" %\n                                    (i, rec[i], col_type, def_type))\n            except AttributeError as e:\n                # recdef[i].type is not defined, then any relshell type is allowed\n                try:\n                    Type.equivalent_relshell_type(rec[i])\n                except NotImplementedError as e:\n                    raise TypeError(\"%s\" % (e))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to parse vague not likely machine - readable description and return first token which contains enough numbers in it.", "response": "def _parse_summaryRecordSysNumber(summaryRecordSysNumber):\n    \"\"\"\n    Try to parse vague, not likely machine-readable description and return\n    first token, which contains enough numbers in it.\n    \"\"\"\n    def number_of_digits(token):\n        digits = filter(lambda x: x.isdigit(), token)\n        return len(digits)\n\n    tokens = map(\n        lambda x: remove_hairs(x, r\" .,:;<>(){}[]\\/\"),\n        summaryRecordSysNumber.split()\n    )\n\n    # pick only tokens that contains 3 digits\n    contains_digits = filter(lambda x: number_of_digits(x) > 3, tokens)\n\n    if not contains_digits:\n        return \"\"\n\n    return contains_digits[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_xml(xml):\n        hasAcquisitionFields = False\n        acquisitionFields = []\n        ISBNAgencyFields = []\n        descriptiveCatFields = []\n        descriptiveCatReviewFields = []\n        subjectCatFields = []\n        subjectCatReviewFields = []\n        isClosed = False\n        summaryRecordSysNumber = \"\"\n        parsedSummaryRecordSysNumber = \"\"\n        isSummaryRecord = False\n        contentOfFMT = \"\"\n\n        parsed = xml\n        if not isinstance(xml, MARCXMLRecord):\n            parsed = MARCXMLRecord(str(xml))\n\n        # handle FMT record\n        if \"FMT\" in parsed.controlfields:\n            contentOfFMT = parsed[\"FMT\"]\n\n            if contentOfFMT == \"SE\":\n                isSummaryRecord = True\n\n        if \"HLD\" in parsed.datafields or \"HLD\" in parsed.controlfields:\n            hasAcquisitionFields = True\n\n            if \"STZ\" in parsed.datafields:\n                acquisitionFields.extend(parsed[\"STZa\"])\n                acquisitionFields.extend(parsed[\"STZb\"])\n\n        def sign_and_author(sign):\n            \"\"\"\n            Sign is stored in ISTa, author's name is in ISTb.\n\n            Sign is MarcSubrecord obj with pointers to other subrecords, so it\n            is possible to pick references to author's name from signs.\n            \"\"\"\n            return [sign.replace(\" \", \"\")] + sign.other_subfields.get(\"b\", [])\n\n        # look for catalogization fields\n        for orig_sign in parsed[\"ISTa\"]:\n            sign = orig_sign.replace(\" \", \"\")  # remove spaces\n\n            if sign.startswith(\"jp2\"):\n                descriptiveCatFields.extend(sign_and_author(orig_sign))\n            elif sign.startswith(\"jr2\"):\n                descriptiveCatReviewFields.extend(sign_and_author(orig_sign))\n            elif sign.startswith(\"vp\"):\n                subjectCatFields.extend(sign_and_author(orig_sign))\n            elif sign.startswith(\"vr\"):\n                subjectCatReviewFields.extend(sign_and_author(orig_sign))\n            elif sign.startswith(\"ii2\"):\n                ISBNAgencyFields.extend(sign_and_author(orig_sign))\n\n        # look whether the record was 'closed' by catalogizators\n        for status in parsed[\"BASa\"]:\n            if status == \"90\":\n                isClosed = True\n\n        # if multiple PJM statuses are present, join them together\n        status = \"\\n\".join([x for x in parsed[\"PJMa\"]])\n\n        # detect link to 'new' record, if the old one was 'closed'\n        if status.strip():\n            summaryRecordSysNumber = status\n            parsedSummaryRecordSysNumber = _parse_summaryRecordSysNumber(\n                summaryRecordSysNumber\n            )\n\n        return SemanticInfo(\n            hasAcquisitionFields=hasAcquisitionFields,\n            acquisitionFields=acquisitionFields,\n            ISBNAgencyFields=ISBNAgencyFields,\n            descriptiveCatFields=descriptiveCatFields,\n            descriptiveCatReviewFields=descriptiveCatReviewFields,\n            subjectCatFields=subjectCatFields,\n            subjectCatReviewFields=subjectCatReviewFields,\n            isClosed=isClosed,\n            isSummaryRecord=isSummaryRecord,\n            contentOfFMT=contentOfFMT,\n            parsedSummaryRecordSysNumber=parsedSummaryRecordSysNumber,\n            summaryRecordSysNumber=summaryRecordSysNumber,\n        )", "response": "Returns a new instance of the class. SemanticInfo class with information from the given MarcXML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commandify(use_argcomplete=False, exit=True, *args, **kwargs):\n    '''Turns decorated functions into command line args\n\n    Finds the main_command and all commands and generates command line args\n    from these.'''\n    parser = CommandifyArgumentParser(*args, **kwargs)\n    parser.setup_arguments()\n    if use_argcomplete:\n        try:\n            import argcomplete\n        except ImportError:\n            print('argcomplete not installed, please install it.')\n            parser.exit(status=2)\n        # Must happen between setup_arguments() and parse_args().\n        argcomplete.autocomplete(parser)\n    args = parser.parse_args()\n    if exit:\n        parser.dispatch_commands()\n        parser.exit(0)\n    else:\n        return parser.dispatch_commands()", "response": "Turns decorated functions into command line args\n    Finds the main_command and all commands and generates command line args\n    from these."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_command_args(self, command, args):\n        '''Work out the command arguments for a given command'''\n        command_args = {}\n        command_argument_names =\\\n            command.__code__.co_varnames[:command.__code__.co_argcount]\n\n        for varname in command_argument_names:\n            if varname == 'args':\n                command_args['args'] = args\n            elif varname in self.provide_args:\n                command_args[varname] = self.provide_args[varname]\n            else:\n                command_args[varname] = getattr(args, varname)\n        return command_args", "response": "Work out the command arguments for a given command"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef example_exc_handler(tries_remaining, exception, delay):\n\n    print >> stderr, \"Caught '{0}', {1} tries remaining, \\\n    sleeping for {2} seconds\".format(exception, tries_remaining, delay)", "response": "Example exception handler; prints a warning to stderr.\n\n    tries_remaining: The number of tries remaining.\n    exception: The exception instance which was raised."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _checkretry(self, mydelay, condition, tries_remaining, data):\n\n        result = mydelay\n\n        if self.condition & condition and tries_remaining > 0:\n\n            # hook data with tries_remaining and mydelay\n            if self.hook is not None:\n                self.hook(data, condition, tries_remaining, mydelay)\n            # wait mydelay seconds\n            sleep(mydelay)\n            result *= self.backoff  # increment mydelay with this backoff\n\n        elif condition is Retries.ON_ERROR:\n            raise data  # raise data if no retries and on_error\n\n        else:  # else Nonify mydelay to prevent callee function to stop\n            result = None\n\n        return result", "response": "Check if input parameters allow to retries function execution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget hash key from args and kwargs.", "response": "def _getkey(self, args, kwargs):\n        \"\"\"Get hash key from args and kwargs.\n\n        args and kwargs must be hashable.\n\n        :param tuple args: called vargs.\n        :param dict kwargs: called keywords.\n        :return: hash(tuple(args) + tuple((key, val) for key in sorted(kwargs)).\n        :rtype: int.\"\"\"\n\n        values = list(args)\n\n        keys = sorted(list(kwargs))\n\n        for key in keys:\n            values.append((key, kwargs[key]))\n\n        result = hash(tuple(values))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting result parameters. :param result: cached result. :raises: ValueError if result is not cached. :return: args and kwargs registered with input result. :rtype: tuple", "response": "def getparams(self, result):\n        \"\"\"Get result parameters.\n\n        :param result: cached result.\n        :raises: ValueError if result is not cached.\n        :return: args and kwargs registered with input result.\n        :rtype: tuple\"\"\"\n\n        for key in self._cache:\n            if self._cache[key][2] == result:\n                args, kwargs, _ = self._cache[key]\n                return args, kwargs\n\n        else:\n            raise ValueError('Result is not cached')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef coerce(value):\n        if isinstance(value, BoolCell):\n            return value\n        elif isinstance(value, Cell):\n            raise CellConstructionFailure(\"Cannot convert %s to BoolCell\" % \\\n                    type(value))\n        elif value in [1, T]:\n            return BoolCell(T)\n        elif value in [0, -1, F]:\n            return BoolCell(F)\n        elif value in [None, U]:\n            return BoolCell(U)\n        else:\n            raise CoercionFailure(\"Don't know how to coerce %d to Bool\" % \\\n                    (value))", "response": "Coerce a value into a Bit / Propositional form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_entailed_by(self, other):\n        other = BoolCell.coerce(other)\n        if self.value == U or other.value == self.value:\n            return True\n        return False", "response": "Returns True if the other is as or more specific than self."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge(self, other):\n        other = BoolCell.coerce(other)\n        if self.is_equal(other):\n            # pick among dependencies\n            return self\n        elif other.is_entailed_by(self):\n            return self\n        elif self.is_entailed_by(other):\n            self.value = other.value\n        elif self.is_contradictory(other):\n            raise Contradiction(\"Cannot merge T and F\")\n        else:\n            raise Exception\n        return self", "response": "Merges two BoolCells into this one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _makeResult(self):\n        return [reporter(self.stream, self.descriptions, self.verbosity) for reporter in self.resultclass]", "response": "instantiates the result class reporters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef module_can_run_parallel(test_module: unittest.TestSuite) -> bool:\n        for test_class in test_module:\n            # if the test is already failed, we just don't filter it\n            # and let the test runner deal with it later.\n            if hasattr(unittest.loader, '_FailedTest'):  # import failure in python 3.4.5+\n                # noinspection PyProtectedMember\n                if isinstance(test_class, unittest.loader._FailedTest):\n                    continue\n\n            if not isinstance(test_class, collections.Iterable):  # likely an import failure in python 3.4.4-\n                # before python 3.4.5, test import failures were not serializable.\n                # We are unable to be sure that this is a module import failure, but it very likely is\n                # if this is the case, we'll just run this locally and see\n                raise TestClassNotIterable()\n\n            for test_case in test_class:\n                return not getattr(sys.modules[test_case.__module__], \"__no_parallel__\", False)", "response": "Checks if a given module of tests can be run on parallel."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef class_can_run_parallel(test_class: unittest.TestSuite) -> bool:\n        for test_case in test_class:\n            return not getattr(test_case, \"__no_parallel__\", False)", "response": "Checks if a given class of tests can be run in parallel or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints the test summary of the current instance of the class.", "response": "def print_summary(self, result, time_taken):\n        \"\"\"\n        Prints the test summary, how many tests failed, how long it took, etc\n\n        :param result: result class to use to print summary\n        :param time_taken: the time all tests took to run\n        \"\"\"\n        if hasattr(result, \"separator2\"):\n            self.stream.writeln(result.separator2)\n\n        self.stream.writeln(\"Ran {number_of_tests} test{s} in {time:.3f}s\\n\".format(\n            number_of_tests=result.testsRun, s=\"s\" if result.testsRun != 1 else \"\", time=time_taken\n        ))\n\n        info = []\n        if not result.wasSuccessful():\n            self.stream.write(\"FAILED\")\n\n            if result.failures:\n                info.append(\"failures={}\".format(len(result.failures)))\n            if result.errors:\n                info.append(\"errors={}\".format(len(result.errors)))\n        else:\n            self.stream.write(\"OK\")\n\n        if result.skipped:\n            info.append(\"skipped={}\".format(len(result.skipped)))\n        if result.expectedFailures:\n            info.append(\"expected failures={}\".format(len(result.expectedFailures)))\n        if result.unexpectedSuccesses:\n            info.append(\"unexpected successes={}\".format(len(result.unexpectedSuccesses)))\n\n        if info:\n            self.stream.writeln(\" ({})\".format(\", \".join(info)))\n        else:\n            self.stream.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, test: unittest.TestSuite):\n        start_time = time.time()\n        process = []\n        resource_manager = multiprocessing.Manager()\n        results_queue = resource_manager.Queue()\n        tasks_running = resource_manager.BoundedSemaphore(self.process_number)\n\n        test_suites, local_test_suites = self.collect_tests(test)\n\n        results_collector = ResultCollector(\n            self.stream, self.descriptions, self.verbosity,\n            result_queue=results_queue, test_results=self._makeResult(),\n            tests=test_suites\n        )\n\n        results_collector.start()\n\n        for index, suite in enumerate(test_suites):\n            tasks_running.acquire()\n            x = self.Process(index, suite, results_queue, tasks_running)\n            x.start()\n            process.append(x)\n\n        local_test_suites.run(results_collector)\n\n        for i in process:\n            i.join()\n\n        results_queue.join()\n        results_collector.end_collection()\n        results_collector.join()\n\n        results_collector.printErrors()\n        self.print_summary(results_collector, time.time() - start_time)\n\n        return results_collector", "response": "This method will create one process per test case whenever possible and run them concurrently."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_templates(path: Path) -> List[str]:\n    '''List all files in ``templates`` directory, including all subdirectories.\n\n    The resulting list contains UNIX-like relative paths starting with ``templates``.\n    '''\n\n    result = []\n\n    for item in path.glob('**/*'):\n        if item.is_file() and not item.name.startswith('_'):\n            result.append(item.relative_to(path.parent).as_posix())\n\n    return result", "response": "List all files in templates directory including all subdirectories."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates another Collection of the same class and with same state butical entries.", "response": "def clone_with_new_elements(\n            self,\n            new_elements,\n            drop_keywords=set([]),\n            rename_dict={},\n            extra_kwargs={}):\n        \"\"\"\n        Create another Collection of the same class and with same state but\n        possibly different entries. Extra parameters to control which keyword\n        arguments get passed to the initializer are necessary since derived\n        classes have different constructors than the base class.\n        \"\"\"\n        kwargs = dict(\n            elements=new_elements,\n            distinct=self.distinct,\n            sort_key=self.sort_key,\n            sources=self.sources)\n        for name in drop_keywords:\n            kwargs.pop(name)\n        for old_name, new_name in rename_dict.items():\n            kwargs[new_name] = kwargs.pop(old_name)\n        kwargs.update(extra_kwargs)\n        return self.__class__(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the single source name for a variant collection if it is unique otherwise raises an error.", "response": "def source(self):\n        \"\"\"\n        Returns the single source name for a variant collection if it is unique,\n        otherwise raises an error.\n        \"\"\"\n        if len(self.sources) == 0:\n            raise ValueError(\"No source associated with %s\" % self.__class__.__name__)\n        elif len(self.sources) > 1:\n            raise ValueError(\"Multiple sources for %s\" % self.__class__.__name__)\n        return list(self.sources)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all filenames in the source directory.", "response": "def filenames(self):\n        \"\"\"\n        Assuming sources are paths to VCF or MAF files, trim their directory\n        path and return just the file names.\n        \"\"\"\n        return [os.path.basename(source) for source in self.sources if source]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef short_string(self):\n        source_str = \"\"\n        if self.sources:\n            source_str = \" from '%s'\" % \",\".join(self.sources)\n        return \"<%s%s with %d elements>\" % (\n            self.__class__.__name__,\n            source_str,\n            len(self))", "response": "Return a string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef groupby(self, key_fn):\n        result_dict = defaultdict(list)\n\n        for x in self:\n            result_dict[key_fn(x)].append(x)\n\n        # convert result lists into same Collection type as this one\n        return {\n            k: self.clone_with_new_elements(elements)\n            for (k, elements)\n            in result_dict.items()\n        }", "response": "Returns a dict of lists grouped by effect or variant key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multi_groupby(self, key_fn):\n        result_dict = defaultdict(list)\n\n        for x in self:\n            for key in key_fn(x):\n                result_dict[key].append(x)\n\n        # convert result lists into same Collection type as this one\n        return {\n            k: self.clone_with_new_elements(elements)\n            for (k, elements)\n            in result_dict.items()\n        }", "response": "Like groupby but expect the key_fn to return multiple keys for each element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_any_above_threshold(\n            self,\n            multi_key_fn,\n            value_dict,\n            threshold,\n            default_value=0.0):\n        \"\"\"Like filter_above_threshold but `multi_key_fn` returns multiple\n        keys and the element is kept if any of them have a value above\n        the given threshold.\n\n        Parameters\n        ----------\n        multi_key_fn : callable\n            Given an element of this collection, returns multiple keys\n            into `value_dict`\n\n        value_dict : dict\n            Dict from keys returned by `extract_key_fn` to float values\n\n        threshold : float\n            Only keep elements whose value in `value_dict` is above this\n            threshold.\n\n        default_value : float\n            Value to use for elements whose key is not in `value_dict`\n        \"\"\"\n        def filter_fn(x):\n            for key in multi_key_fn(x):\n                value = value_dict.get(key, default_value)\n                if value > threshold:\n                    return True\n            return False\n        return self.filter(filter_fn)", "response": "Like filter_above_threshold but returns a new collection with only the elements whose value is above threshold."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef curl(url, params=None, auth=None, req_type='GET', data=None, headers=None, timeout=None, use_gzip=True, use_stream=False):\n  post_req = [\"POST\", \"PUT\"]\n  get_req = [\"GET\", \"DELETE\"]\n\n  if params is not None:\n    url += \"?\" + urlencode(params)\n\n  if req_type not in post_req + get_req:\n    raise IOError(\"Wrong request column_type \\\"%s\\\" passed\" % req_type)\n\n  _headers = {}\n  handler_chain = []\n  req_args = {\n    \"headers\": _headers\n  }\n  # process content\n  if req_type in post_req and data is not None:\n    _data, __header = __parse_content(data)\n    _headers.update(__header)\n    _headers[\"Content-Length\"] = len(_data)\n    req_args[\"data\"] = _data\n\n  # process gzip and deflate\n  if use_gzip:\n    if \"Accept-Encoding\" in _headers:\n      if \"gzip\" not in _headers[\"Accept-Encoding\"]:\n        _headers[\"Accept-Encoding\"] += \", gzip, x-gzip, deflate\"\n    else:\n      _headers[\"Accept-Encoding\"] = \"gzip, x-gzip, deflate\"\n\n  if auth is not None and auth.force is False:\n    manager = HTTPPasswordMgrWithDefaultRealm()\n    manager.add_password(None, url, auth.user, auth.password)\n    handler_chain.append(HTTPBasicAuthHandler(manager))\n\n  if auth is not None and auth.force:\n    _headers.update(auth.headers)\n\n  if headers is not None:\n    _headers.update(headers)\n\n  director = build_opener(*handler_chain)\n  req = Request(url, **req_args)\n  req.get_method = lambda: req_type\n\n  try:\n    if timeout is not None:\n      return CURLResponse(director.open(req, timeout=timeout), is_stream=use_stream)\n    else:\n      return CURLResponse(director.open(req), is_stream=use_stream)\n  except URLError as e:\n    if isinstance(e, HTTPError):\n      raise e\n    else:\n      raise TimeoutError", "response": "Make a request to the web resource at url."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a AddEvent object from a string representation.", "response": "def from_str(string):\n        \"\"\"Generate a `AddEvent` object from a string\n        \"\"\"\n        match = re.match(r'^ADD (\\w+)$', string)\n        if match:\n            return AddEvent(match.group(1))\n        else:\n            raise EventParseError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_str(string):\n        match = re.match(r'^START READING (\\w+) FROM \\w+ (\\d+)$', string)\n        if match:\n            return SetReadingEvent(match.group(1), int(match.group(2)))\n        else:\n            raise EventParseError", "response": "Generate a SetReadingEvent object from a string representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a ReadEvent object from a string representation.", "response": "def from_str(string):\n        \"\"\"Generate a `ReadEvent` object from a string\n        \"\"\"\n        match = re.match(r'^READ (\\w+) FOR (\\d+) \\w+S$', string)\n        if match:\n            return ReadEvent(match.group(1), int(match.group(2)))\n        else:\n            raise EventParseError"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a SetFinishedEvent object from a string representation.", "response": "def from_str(string):\n        \"\"\"Generate a `SetFinishedEvent` object from a string\n        \"\"\"\n        match = re.match(r'^FINISH READING (\\w+)$', string)\n        if match:\n            return SetFinishedEvent(match.group(1))\n        else:\n            raise EventParseError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a SetFinishedEvent object from a string representation.", "response": "def from_str(string):\n        \"\"\"Generate a `SetFinishedEvent` object from a string\n        \"\"\"\n        match = re.match(r'^UPDATE (.+)$', string)\n        if match:\n            parsed_date = dateutil.parser.parse(match.group(1), ignoretz=True)\n            return UpdateEvent(parsed_date)\n        else:\n            raise EventParseError"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake sqparse2. ColX Table", "response": "def field_default(colx, table_name, tables_dict):\n  \"takes sqparse2.ColX, Table\"\n  if colx.coltp.type.lower() == 'serial':\n    x = sqparse2.parse('select coalesce(max(%s),-1)+1 from %s' % (colx.name, table_name))\n    return sqex.run_select(x, tables_dict, Table)[0]\n  elif colx.not_null: raise NotImplementedError('todo: not_null error')\n  else: return toliteral(colx.default)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply defaults to missing cols for a row that s being inserted", "response": "def apply_defaults(self, row, tables_dict):\n    \"apply defaults to missing cols for a row that's being inserted\"\n    return [\n      emergency_cast(colx, field_default(colx, self.name, tables_dict) if v is Missing else v)\n      for colx,v in zip(self.fields,row)\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_youtube_url(youtube_url, no_controls, autoplay):\n    for section in youtube_url.split('&'):\n        if 'list' in section:\n            playlist_id = section.split('list=')[1]\n            break\n    return (\n        'https://www.youtube.com/embed/videoseries?{0}&{1}&'\n        'loop=1&html5=1&showinfo=0&listType=playlist&list={2}'.format(\n            '' if autoplay else 'autoplay=1',\n            'controls=0' if no_controls else '',\n            str(playlist_id)\n        )\n    )", "response": "This function converts a Youtube URL to a correct Youtube URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an error to bugzscout.", "response": "def submit_error(self, description, extra=None, default_message=None):\n        \"\"\"Send an error to bugzscout.\n\n        Sends a request to the fogbugz URL for this instance. If a case exists\n        with the **same** description, a new occurrence will be added to that\n        case. It is advisable to remove personal info from the description for\n        that reason. Account ids, emails, request ids, etc, will make the\n        occurrence counting builtin to bugzscout less useful. Those values\n        should go in the extra parameter, though, so the developer\n        investigating the case has access to them.\n\n        When extra is not specified, bugzscout will increase the number of\n        occurrences for the case with the given description, but it will not\n        include an entry for it (unless it is a new case).\n\n        :param description: string description for error\n        :param extra: string details for error\n        :param default_message: string default message to return in responses\n        \"\"\"\n        req_data = {'ScoutUserName':       self.user,\n                    'ScoutProject':        self.project,\n                    'ScoutArea':           self.area,\n\n                    # When this matches, cases are grouped together.\n                    'Description':         description,\n                    'Extra':               extra,\n\n                    # 1 forces a new bug to be created.\n                    'ForceNewBug':         0,\n                    'ScoutDefaultMessage': default_message,\n\n                    # 0 sends XML response, 1 sends HTML response.\n                    'FriendlyResponse':    0,\n                    }\n\n        LOG.debug('Making bugzscout request to {0} with body {1}'.format(\n            self.url, req_data))\n        resp = requests.post(self.url, data=req_data)\n        LOG.debug('Response from bugzscout request: {0} body:\\n{1}'.format(\n            resp, resp.content))\n\n        if resp.ok:\n            LOG.info('Successfully submitted error to bugzscout.')\n        else:\n            LOG.warn('Failed to submit error to bugzscout: {0}'.format(\n                resp.reason))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore the output from the decorated function in the cache and pull it from the cache on future invocations without rerunning. Normally, the value will be stored under a key which takes into account all of the parameters that are passed into it, thereby caching different invocations separately. If you specify a key, all invocations will be cached under that key, and different invocations will return the same value, which may be unexpected. So, be careful! If the cache is disabled, the decorated function will just run normally. Unlike the other functions in this module, you must pass a custom cache_obj to this() in order to operate on the non-global cache. This is because of wonky behavior when using decorator.decorator from a class method. :param func: (expensive?) function to decorate :param cache_obj: cache to a specific object (for use from the cache object itself) :param key: optional key to store the value under :param ttl: optional expiry to apply to the cached value :param *args: arg tuple to pass to the decorated function :param **kwargs: kwarg dict to pass to the decorated function", "response": "def this(func, cache_obj=CACHE_OBJ, key=None, ttl=None, *args, **kwargs):\n    \"\"\"\n    Store the output from the decorated function in the cache and pull it\n    from the cache on future invocations without rerunning.\n\n    Normally, the value will be stored under a key which takes into account\n    all of the parameters that are passed into it, thereby caching different\n    invocations separately. If you specify a key, all invocations will be\n    cached under that key, and different invocations will return the same\n    value, which may be unexpected. So, be careful!\n\n    If the cache is disabled, the decorated function will just run normally.\n\n    Unlike the other functions in this module, you must pass a custom cache_obj\n    to this() in order to operate on the non-global cache. This is because of\n    wonky behavior when using decorator.decorator from a class method.\n\n    :param func: (expensive?) function to decorate\n    :param cache_obj: cache to a specific object (for use from the cache object itself)\n    :param key: optional key to store the value under\n    :param ttl: optional expiry to apply to the cached value\n    :param *args: arg tuple to pass to the decorated function\n    :param **kwargs: kwarg dict to pass to the decorated function\n    \"\"\"\n    key = key or (func.__name__ + str(args) + str(kwargs))\n    if cache_obj.has(key):\n        return cache_obj.get(key)\n    value = func(*args, **kwargs)\n    cache_obj.upsert(key, value, ttl)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has(self, key):\n        if not self.options.enabled:\n            return CACHE_DISABLED\n        ret = key in self._dict.keys() and not self._dict[key].is_expired()\n        logger.debug('has({}) == {}'.format(repr(key), ret))\n        return ret", "response": "Check if a key is in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms an upsert on the cache", "response": "def upsert(self, key, value, ttl=None):\n        \"\"\"\n        Perform an upsert on the cache\n\n        Returns CACHE_DISABLED if the cache is disabled\n        Returns True on successful operation\n\n        :param key: key to store the value under\n        :param value: value to cache\n        :param ttl: optional expiry in seconds (defaults to None)\n        \"\"\"\n        if not self.options.enabled:\n            return CACHE_DISABLED\n        logger.debug('upsert({}, {}, ttl={})'.format(repr(key), repr(value), ttl))\n        self._dict[key] = MicrocacheItem(value, ttl)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, key, default=CACHE_MISS):\n        if not self.options.enabled:\n            return CACHE_DISABLED\n        ret = default\n        if self.has(key):\n            ret = self._dict[key].value\n        logger.debug('get({}, default={}) == {}'.format(repr(key), repr(default), repr(ret)))\n        return ret", "response": "Get a value out of the cache with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self, key=None):\n        if not self.options.enabled:\n            return CACHE_DISABLED\n        logger.debug('clear(key={})'.format(repr(key)))\n        if key is not None and key in self._dict.keys():\n            del self._dict[key]\n            logger.info('cache cleared for key: ' + repr(key))\n        elif not key:\n            for cached_key in [k for k in self._dict.keys()]:\n                del self._dict[cached_key]\n            logger.info('cache cleared for ALL keys')\n        return True", "response": "Clear a cache entry or all cache entries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling the cache and clear its contents", "response": "def disable(self, clear_cache=True):\n        \"\"\"\n        Disable the cache and clear its contents\n\n        :param clear_cache: clear the cache contents as well as disabling (defaults to True)\n        \"\"\"\n        logger.debug('disable(clear_cache={})'.format(clear_cache))\n        if clear_cache:\n            self.clear()\n        self.options.enabled = False\n        logger.info('cache disabled')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of key value pairs of the non - expired items in the cache optionally filtered by a root path.", "response": "def items(self, path_root=None):\n        \"\"\"\n        Returns a list of key / value pairs of the non-expired items in the cache, optionally filtered by a root path.\n\n        :param path_root: path to filter by\n        :return: list(tuple(key, value))\n        \"\"\"\n        keys = list(self._dict.keys())\n        keys.sort()\n        ret = []\n\n        for key in keys:\n            # filter out expired items\n            if self._dict[key].is_expired():\n                continue\n\n            # filter out keys that do not match the root path\n            if path_root and not key.startswith(path_root):\n                continue\n\n            ret.append((key, self._dict[key].value))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef temporarily_disabled(self):\n        old_setting = self.options.enabled\n        self.disable(clear_cache=False)\n        try:\n            yield\n        finally:\n            self.options.enabled = old_setting", "response": "Temporarily disable the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef temporarily_enabled(self):\n        old_setting = self.options.enabled\n        self.enable()\n        try:\n            yield\n        finally:\n            self.options.enabled = old_setting", "response": "Temporarily enable the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef chunks(it, n):\n    for first in it:\n        yield [first] + list(itertools.islice(it, n - 1))", "response": "Split an iterator into chunks with n elements each."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning the url for protocol prefix trailing slash and replaces special characters with the given replacement.", "response": "def clean_url(url, replacement='_'):\n        \"\"\"\n        Cleans the url for protocol prefix and trailing slash and replaces special characters\n        with the given replacement.\n\n        :param url: The url of the request.\n        :param replacement: A string that is used to replace special characters.\n        \"\"\"\n        cleaned = re.sub(r'/$', '', re.sub(r'https?://', '', url))\n        for character in '/ _ ? & : ; %'.split():\n            cleaned = cleaned.replace(character, replacement)\n        return cleaned"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a filename on the form current - working - directory prefix. txt.", "response": "def get_filename(self, prefix, url):\n        \"\"\"\n        Creates a file path on the form: current-working-directory/prefix/cleaned-url.txt\n\n        :param prefix: The prefix from the .get() and .put() methods.\n        :param url: The url of the request.\n        :return: The created path.\n        \"\"\"\n        return '{}.txt'.format(os.path.join(os.getcwd(), prefix, self.clean_url(url)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(resource, previous=None, migrations_path=None):\n    if migrations_path:\n        file_path = migrate.create(resource, previous_version=previous, package=migrations_path)\n    else:\n        file_path = migrate.create(resource, previous_version=previous)\n\n    click.secho('Created migration file: ' + file_path, fg='green')", "response": "Create an empty migration for a resource"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning migrations on the registry", "response": "def run(migrations_path=None, url=None, port=None):\n    \"\"\"Run migrations\"\"\"\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n\n    if url:\n        url = str(url).rstrip('/')\n        options.url_registry_db = url\n\n    if port:\n        options.db_port = int(port)\n\n    if migrations_path:\n        migrations = migrate.collect(migrations_path)\n    else:\n        migrations = migrate.collect()\n\n    func = partial(migrate.run_migrations, migrations)\n    IOLoop.instance().run_sync(func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_address_delete(self, sender, instance, **kwargs):\n    objects = self.find_associated_with_address(instance)\n\n    # this is not called as django will delete associated project/address\n    # triggering handle_delete\n    for obj in objects: # pragma: no cover\n      self.handle_delete(obj.__class__, obj)", "response": "Custom handler for address delete"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_job_and_work_delete(self, sender, instance, **kwargs):\n    self.handle_delete(instance.project.__class__, instance.project)", "response": "Custom handler for job and work delete"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_m2m(self, sender, instance, **kwargs):\n    self.handle_save(instance.__class__, instance)", "response": "Handle many to many relationships"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle many to many relationships for user field", "response": "def handle_m2m_user(self, sender, instance, **kwargs):\n    \"\"\" Handle many to many relationships for user field \"\"\"\n    self.handle_save(instance.user.__class__, instance.user)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_associated_with_address(self, instance):\n    objects = []\n    objects += list(Project.objects.filter(address=instance))\n    objects += list(Organization.objects.filter(address=instance))\n\n    return objects", "response": "Returns list with projects and organizations associated with given address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrefreshing a Google OAuth token.", "response": "def refresh_token(token, session=None):\n    \"\"\"Refresh Google OAuth token.\n\n    :param OAuthToken token:\n      the token to refresh\n\n    :param requests.Session session:\n      Optional `requests` session to use.\n    \"\"\"\n    session = session or HTTP_SESSION\n    refresh_data = dict(\n        refresh_token=token.refresh_token,\n        client_id=token.consumer_key,\n        client_secret=token.consumer_secret,\n        grant_type='refresh_token'\n    )\n    resp = session.post(REFRESH_TOKEN_URL, data=refresh_data)\n    resp_json = resp.json()\n    if 'error' in resp_json:\n        message = resp_json['error']\n        description = resp_json.get('error_description', '')\n        if any(description):\n            message = u'{}: {}'.format(message, description)\n        raise OAuthTokenExpiredError(message)\n    return OAuthToken(\n        access_token=resp_json['access_token'],\n        refresh_token=token.refresh_token,\n        consumer_key=token.consumer_key,\n        consumer_secret=token.consumer_secret\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the token information for the given OAuth token.", "response": "def token_info(token, refresh=True, refresh_cb=None, session=None):\n    \"\"\"\n    :param OAuthToken token\n\n    :param bool refresh:\n      whether to attempt to refresh the OAuth token if it expired.\n      default is `True`.\n\n    :param refresh_cb:\n      If specified, a callable object which is given the new token\n      in parameter if it has been refreshed.\n\n    :param requests.Session session:\n      Optional `requests` session to use.\n\n    :return:\n      token information. see\n      https://developers.google.com/identity/protocols/OAuth2UserAgent#tokeninfo-validation\n      - `scope`: this field is not a space-delimited set of scopes\n         but a real Python `set`.\n      - `token`: additional field that provides the `OAuthToken`\n      - `refreshed`: boolean that will tell if the token has been refreshed\n    :rtype: nameddict\n    \"\"\"\n    session = session or HTTP_SESSION\n    params = dict(access_token=token.access_token)\n    resp = session.get(TOKEN_INFO_URL, params=params)\n    if resp.status_code != 200:\n        if refresh:\n            token = refresh_token(token, session=session)\n            if refresh_cb is not None:\n                try:\n                    refresh_cb(token)\n                except Exception:\n                    LOGGER.exception('OAuth token refresh callback failed')\n            info = token_info(token, refresh=False, session=session)\n            info.update(refreshed=True)\n            return info\n        raise OAuthTokenRefreshRequiredError()\n    info = __coerce_token_info(resp.json())\n    info.update(token=token, refreshed=False)\n    return nameddict(info)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_tex_table(inputlist, outputfile, close=False, fmt=None,\n                   **kwargs):\n    \"\"\"\n    Parse table from inputlist\n\n    Args:\n        inputlist: list\n            List to parse\n        outputfile: file\n            .tex file to write\n        fmt: dictionary\n            key: integer\n                column index starting with 0\n            values: string\n                format string. eg \"{:g}\"\n        **kwargs:\n            nonestring: string\n                string when objecttype is None\n   Returns:\n        None\n    \"\"\"\n    output_str = \"\"\n    if fmt is None:\n        fmt = {}\n    for row in inputlist:\n        for key, val in enumerate(row):\n            if val is None:\n                output_str += r'\\text{{{}}}'.format(\n                    str(kwargs.get(\"nonestring\", \"None\"))\n                )\n            else:\n                # get default\n                if np.isscalar(val):\n                    temp_str_fmt = \"$\\\\num{{\" + fmt.get(\n                        key, \"{:g}\") + \"}}$\"\n                else:\n                    temp_str_fmt = fmt.get(key, \"{}\")\n                temp_str = temp_str_fmt.format(val).replace(\"+\", \"\")\n            output_str += temp_str + \"&\"\n        output_str = output_str[:-1]\n        output_str += \"\\\\\\\\\\n\"\n    outputfile.write(output_str)\n    if close:\n        outputfile.close()", "response": "Parse a list of nonestrings into a TeX table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_root_logger_from_verbosity(verbosity=0):\n    kwargs = {}\n    if verbosity == 1:\n        kwargs.update(level=logging.INFO)\n    elif verbosity > 1:\n        kwargs.update(level=logging.DEBUG)\n\n    set_root_logger(**kwargs)", "response": "Configure root logger according to both application settings\n    and verbosity level."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_root_logger(config=None, **kwargs):\n    config = config or app_config\n    logging_config = config.get('logging') or {}\n    kwargs.setdefault('level', logging_config.get('level'))\n    kwargs.setdefault('format', logging_config.get('format'))\n    logging.basicConfig(**kwargs)", "response": "Set root logger for the application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_loggers_from_config(config=None):\n    config = config or app_config.logging\n    for lname, lconfig in config.get('loggers', {}).iteritems():\n        if 'level' in lconfig:\n            level = getattr(logging, lconfig.level)\n            assert isinstance(level, int)\n            logger = logging.getLogger(lname)\n            logger.setLevel(level)", "response": "Set loggers configuration according to the logging section of Docido configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self):\n        if self._data is None:\n            # reset after possible parsing failure\n            self.__init__(self.tokens)\n            return self._parse()\n        else:\n            return self._data", "response": "Return parsed data structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves forward n tokens in the stream.", "response": "def _increment(self, n=1):\n        \"\"\"Move forward n tokens in the stream.\"\"\"\n        if self._cur_position >= self.num_tokens-1:\n            self._cur_positon = self.num_tokens - 1\n            self._finished = True\n        else:\n            self._cur_position += n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nincrement over whitespace counting characters.", "response": "def _skip_whitespace(self):\n        \"\"\"Increment over whitespace, counting characters.\"\"\"\n        i = 0\n        while self._cur_token['type'] is TT.ws and not self._finished:\n            self._increment()\n            i += 1\n\n        return i"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the token stream into a nice dictionary data structure.", "response": "def _parse(self):\n        \"\"\"Parse the token stream into a nice dictionary data structure.\"\"\"\n        while self._cur_token['type'] in (TT.ws, TT.lbreak):\n            self._skip_whitespace()\n            self._skip_newlines()\n\n        self._data = self._parse_value()\n\n        return self._data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_value(self):\n        indent = 0\n        while self._cur_token['type'] is TT.ws:\n            indent = self._skip_whitespace()\n            self._skip_newlines()\n\n        if self._cur_token['type'] is TT.id:\n            return self._parse_key(indent)\n        elif self._cur_token['type'] is TT.hyphen:\n            self._increment()\n            if self._cur_token['type'] is TT.hyphen:\n                self._increment()\n                return []\n            else:\n                return self._parse_object_list()\n        else:\n            # TODO: single comma gives empty list\n            return self._parse_literal_list(indent)", "response": "Parse the value of a key - value pair."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a series of key - value pairs.", "response": "def _parse_key(self, indent):\n        \"\"\"Parse a series of key-value pairs.\"\"\"\n        data = {}\n\n        new_indent = indent\n        while not self._finished and new_indent == indent:\n            self._skip_whitespace()\n            cur_token = self._cur_token\n            if cur_token['type'] is TT.id:\n                key = cur_token['value']\n                next_token = self._nth_token()\n                if next_token['type'] is TT.colon:\n                    self._increment(2)  # move past the ':'\n                    # whitespace before a newline is not important\n                    # whitespace after a newline is important\n                    self._skip_whitespace()\n                    self._skip_newlines()\n                    data[key] = self._parse_value()\n                else:\n                    raise ParseError(\"':'\", next_token)\n            else:\n                if cur_token['type'] is TT.hyphen:\n                    return data\n                else:\n                    raise ParseError(\"identifier or '-'\", cur_token)\n\n            if self.tokens[self._cur_position - 1]['type'] is not TT.lbreak:\n                # skip whitespace at the end of the line\n                self._skip_whitespace()\n                self._skip_newlines()\n\n            # find next indentation level without incrementing\n            new_indent = 0\n            temp_position = self._cur_position\n            while (\n                temp_position < self.num_tokens-1 and\n                self.tokens[temp_position]['type'] is TT.ws\n            ):\n                temp_position += 1\n                new_indent += 1\n\n        if indent == 0 or new_indent < indent:\n            return data\n        else:\n            raise Exception(\n                \"Parser screwed up, increase of indent on line {} should \"\n                \"have been caught by _parse_value().\".format(\n                    cur_token['line']\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a list of data structures.", "response": "def _parse_object_list(self):\n        \"\"\"Parse a list of data structures.\"\"\"\n        array = []\n\n        indent = 0\n        while not self._finished:\n            self._skip_newlines()\n            if self._cur_token['type'] is TT.ws:\n                while self._cur_token['type'] is TT.ws:\n                    indent = self._skip_whitespace()\n                    self._skip_newlines()\n            elif self._cur_token['type'] is TT.id:\n                array.append(self._parse_key(indent))\n            elif self._cur_token['type'] is TT.hyphen:\n                self._increment()\n                if self._cur_token['type'] is not TT.hyphen or self._finished:\n                    return array\n                else:\n                    self._increment()\n            else:\n                raise ParseError('something different', self._cur_token)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_literal_list(self, indent):\n        if self._cur_token['type'] not in self._literals:\n            raise Exception(\n                \"Parser failed, _parse_literal_list was called on non-literal\"\n                \" {} on line {}.\".format(\n                    repr(self._cur_token['value']), self._cur_token['line']\n                )\n            )\n\n        # find next token after whitespace without incrementing\n        temp_position = self._cur_position\n        while (\n            temp_position < self.num_tokens-1 and (\n                self.tokens[temp_position]['type'] is TT.ws or\n                self.tokens[temp_position]['type'] in self._literals\n            )\n        ):\n            temp_position += 1\n        next_token = self.tokens[temp_position]\n\n        # end of stream\n        if next_token['type'] is TT.ws:\n            return self._cur_token['value']\n        elif next_token['type'] is TT.comma:\n            return self._parse_comma_list()\n        elif next_token['type'] is TT.lbreak:\n            while (\n                temp_position < self.num_tokens-1 and\n                self.tokens[temp_position]['type'] in (TT.lbreak, TT.ws)\n            ):\n                temp_position += 1\n            if self.tokens[temp_position]['type'] in self._literals:\n                return self._parse_newline_list(indent)\n            else:\n                rval = self._cur_token['value']\n                self._increment()\n                return rval\n        else:\n            rval = self._cur_token['value']\n            self._increment()\n            return rval", "response": "Parse a list of literals."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a comma seperated list.", "response": "def _parse_comma_list(self):\n        \"\"\"Parse a comma seperated list.\"\"\"\n        if self._cur_token['type'] not in self._literals:\n            raise Exception(\n                \"Parser failed, _parse_comma_list was called on non-literal\"\n                \" {} on line {}.\".format(\n                    repr(self._cur_token['value']), self._cur_token['line']\n                )\n            )\n\n        array = []\n        while self._cur_token['type'] in self._literals and not self._finished:\n            array.append(self._cur_token['value'])\n            self._increment()\n            self._skip_whitespace()\n            if self._cur_token['type'] is TT.comma:\n                self._increment()\n                self._skip_whitespace()\n            elif (\n                not self._finished and\n                self._cur_token['type'] not in (TT.ws, TT.lbreak)\n            ):\n                raise ParseError('comma or newline', self._cur_token)\n\n        return array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_newline_list(self, indent):\n        if self._cur_token['type'] not in self._literals:\n            raise Exception(\n                \"Parser failed, _parse_newline_list was called on non-literal\"\n                \" {} on line {}.\".format(\n                    repr(self._cur_token['value']), self._cur_token['line']\n                )\n            )\n\n        array = []\n        new_indent = indent\n        while not self._finished:\n            if new_indent < indent:\n                break\n            elif new_indent == indent:\n                while self._cur_token['type'] is TT.lbreak:\n                    self._skip_newlines()\n                    self._skip_whitespace()\n                # look ahead to see if it's a comma seperated list\n                temp_position = self._cur_position\n                while (\n                    temp_position < self.num_tokens-1 and\n                    (\n                        self.tokens[temp_position]['type'] is TT.ws or\n                        self.tokens[temp_position]['type'] in self._literals\n                    )\n                ):\n                    temp_position += 1\n\n                if self.tokens[temp_position]['type'] is TT.comma:\n                    array.append(self._parse_comma_list())\n                else:\n                    if self._cur_token['type'] is not TT.hyphen:\n                        array.append(self._cur_token['value'])\n                    elif self._nth_token()['type'] is TT.hyphen:\n                        # two consecutive '-'s\n                        array.append([])\n                        self._increment()\n                    self._increment()\n            else:  # new_indent > indent\n                while self._cur_token['type'] is TT.lbreak:\n                    self._skip_newlines()\n                    self._skip_whitespace()\n                array.append(self._parse_newline_list(new_indent))\n\n            self._skip_whitespace()\n            if (\n                not self._finished and\n                self._cur_token['type'] not in (TT.lbreak, TT.hyphen)\n            ):\n                raise ParseError('newline', self._cur_token)\n\n            temp_position = self._cur_position\n            new_indent = 0\n            while (\n                temp_position < self.num_tokens-1 and\n                self.tokens[temp_position]['type'] in (TT.lbreak, TT.ws)\n            ):\n                if self.tokens[temp_position]['type'] is TT.lbreak:\n                    new_indent = 0\n                else:\n                    new_indent += 1\n                temp_position += 1\n\n        return array", "response": "Parse a newline seperated list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling general message exits.", "response": "def exit(self, status=0, message=None):\n        \"\"\" Handle general message exits (e.g. version).\n            \"\"\"\n        if message:\n            raise HelpBanner(message.strip(), code=status)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstripping out { redundant subcommand section.", "response": "def format_help(self):\n        \"\"\" Strip out { } redundant subcommand section.\n            \"\"\"\n        help_msg = super(FocusArgParser, self).format_help()\n        return re.sub(r'\\{.+\\}', '', help_msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_help(self, env, args):\n\n        if args:\n            # command help (focus help [command])\n            # get command plugin registered for command\n            active = env.task.active\n            plugin_obj = registration.get_command_hook(args[0], active)\n\n            if plugin_obj:\n                parser = self._get_plugin_parser(plugin_obj)\n                raise HelpBanner(parser.format_help(), code=0)\n\n        return False", "response": "Handles showing help information for arguments provided."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the command string passed by the user and returns True if the command was successfully executed.", "response": "def _handle_command(self, command, env, args):\n        \"\"\" Handles calling appropriate command plugin based on the arguments\n            provided.\n\n            `command`\n                Command string.\n            `env`\n                Runtime ``Environment`` instance.\n            `args`\n                List of argument strings passed.\n\n            Returns ``False`` if nothing handled.\n\n            * Raises ``HelpBanner`` exception if mismatched command arguments.\n            \"\"\"\n        # get command plugin registered for command\n        # note, we're guaranteed to have a command string by this point\n        plugin_obj = registration.get_command_hook(command, env.task.active)\n\n        # check if plugin is task-specific or has option hooks implying\n        # task-specific behavior\n        if plugin_obj and not env.task.active:\n            if plugin_obj.task_only or plugin_obj.options:\n                plugin_obj = None\n\n        if plugin_obj:\n            # plugin needs root, setup root access via sudo\n            if plugin_obj.needs_root:\n                registration.setup_sudo_access(plugin_obj)\n\n            # parse arguments\n            parser = self._get_plugin_parser(plugin_obj)\n            parsed_args = parser.parse_args(args)\n\n            # run plugin\n            plugin_obj.execute(env, parsed_args)\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates base argument parser.", "response": "def _get_parser(self, env):\n        \"\"\" Creates base argument parser.\n\n            `env`\n                Runtime ``Environment`` instance.\n\n            * Raises ``HelpBanner`` exception when certain conditions apply.\n\n            Returns ``FocusArgumentParser`` object.\n            \"\"\"\n\n        version_str = 'focus version ' + __version__\n        usage_str = 'focus [-h] [-v] [--no-color] <command> [<args>]'\n\n        # setup parser\n        parser = FocusArgParser(description=(\"Command-line productivity tool \"\n                                             \"for improved task workflows.\"),\n                                epilog=(\"See 'focus help <command>' for more \"\n                                        \"information on a specific command.\"),\n                                usage=usage_str)\n\n        parser.add_argument('-v', '--version', action='version',\n                            version=version_str)\n        parser.add_argument('--no-color', action='store_true',\n                            help='disables colors')\n\n        # fetch command plugins\n        commands = []\n        active = env.task.active\n        command_hooks = registration.get_registered(command_hooks=True,\n                                                    task_active=active)\n\n        # extract command name and docstrings as help text\n        for plugin in command_hooks:\n            help_text = (plugin.__doc__ or '').strip().rstrip('.').lower()\n            commands.append((plugin.command, help_text))\n        commands.sort(key=lambda x: x[0])  # command ordered\n\n        # install subparsers\n        subparsers = parser.add_subparsers(title='available commands')\n\n        # install 'help' subparser\n        help_parser = subparsers.add_parser('help', add_help=False)\n        help_parser.set_defaults(func=self._handle_help)\n\n        # install 'version' subparser\n        version_parser = subparsers.add_parser('version', add_help=False)\n\n        def _print_version(env, args):\n            env.io.write(version_str)\n            return True\n        version_parser.set_defaults(func=_print_version)\n\n        # install command subparsers based on registered command plugins.\n        # this allows for focus commands (e.g. focus on [...])\n\n        for command, help_ in commands:\n            cmd_parser = subparsers.add_parser(command, help=help_,\n                                               add_help=False)\n\n            # use wrapper to bind command value and passthru to _handle_command\n            # when executed later\n            def _run(command):\n                def _wrapper(env, args):\n                    return self._handle_command(command, env, args)\n                return _wrapper\n            cmd_parser.set_defaults(func=_run(command))\n\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a plugin argument parser.", "response": "def _get_plugin_parser(self, plugin_obj):\n        \"\"\" Creates a plugin argument parser.\n\n            `plugin_obj`\n                ``Plugin`` object.\n\n            Returns ``FocusArgParser`` object.\n            \"\"\"\n\n        prog_name = 'focus ' + plugin_obj.command\n        desc = (plugin_obj.__doc__ or '').strip()\n\n        parser = FocusArgParser(prog=prog_name, description=desc)\n        plugin_obj.setup_parser(parser)\n\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting basic flags and command plugins. env Runtime Environment instance instance.", "response": "def execute(self, env):\n        \"\"\" Executes basic flags and command plugins.\n\n            `env`\n                Runtime ``Environment`` instance.\n\n            * Raises ``FocusError`` exception when certain conditions apply.\n            \"\"\"\n\n        # parse args\n        parser = self._get_parser(env)\n        parsed_args, cmd_args = parser.parse_known_args(env.args)\n\n        # disable colors\n        if parsed_args.no_color:\n            env.io.set_colored(False)\n\n        # run command handler passing any remaining args\n        if not parsed_args.func(env, cmd_args):\n            raise HelpBanner(parser.format_help())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit a RST file text in two parts. The title argument determine the split point.", "response": "def _split_chglog(path, title):\n    \"\"\"Split a RST file text in two parts. The title argument determine the\n    split point. The given title goes in the bottom part. If the title is not\n    found everything goes in the top part.\n\n    Return a tuple with the top and bottom parts.\n    \"\"\"\n\n    with path.open() as f:\n        doc = f.readlines()\n\n    has_title = False\n\n    for idx, curr_line in enumerate(doc):\n\n        if title in curr_line:\n            prev_line = doc[idx - 1] if idx - 1 < len(doc) else \"\\n\"\n            next_line = doc[idx + 1] if idx + 1 < len(doc) else None\n\n            if is_title(prev_line, curr_line, next_line):\n                idx = idx if prev_line == \"\\n\" else idx - 1\n                has_title = True\n                break\n\n    if has_title:\n        top, bottom = doc[:idx], doc[idx:]\n    else:\n        top, bottom = doc, []\n\n    return \"\".join(top), \"\".join(bottom)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a Procfile from a string.", "response": "def loads(content):\n    \"\"\"Load a Procfile from a string.\"\"\"\n    lines = _group_lines(line for line in content.split('\\n'))\n    lines = [\n        (i, _parse_procfile_line(line))\n        for i, line in lines if line.strip()\n    ]\n    errors = []\n    # Reject files with duplicate process types (no sane default).\n    duplicates = _find_duplicates(((i, line[0]) for i, line in lines))\n    for i, process_type, j in duplicates:\n        errors.append(''.join([\n                'Line %d: duplicate process type \"%s\": ',\n                'already appears on line %d.',\n            ]) % (i + 1, process_type, j + 1)\n        )\n    # Reject commands with duplicate variables (no sane default).\n    for i, line in lines:\n        process_type, env = line[0], line[2]\n        duplicates = _find_duplicates(((0, var[0]) for var in env))\n        for _, variable, _ in duplicates:\n            errors.append(''.join([\n                    'Line %d: duplicate variable \"%s\" ',\n                    'for process type \"%s\".',\n                ]) % (i + 1, variable, process_type)\n            )\n    # Done!\n    if errors:\n        raise ValueError(errors)\n    return {k: {'cmd': cmd, 'env': dict(env)} for _, (k, cmd, env) in lines}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn true iff an email is activated by default. Returns false if an email has been disabled in settings. py athorian", "response": "def is_email_enabled(email):\n  \"\"\" Emails are activated by default. Returns false\n      if an email has been disabled in settings.py\n  \"\"\"\n  s = get_settings(string=\"OVP_EMAILS\")\n  email_settings = s.get(email, {})\n\n  enabled = True\n  if email_settings.get(\"disabled\", False):\n    enabled = False\n\n  return enabled"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_email_subject(email, default):\n  s = get_settings(string=\"OVP_EMAILS\")\n  email_settings = s.get(email, {})\n\n  title = email_settings.get(\"subject\", default)\n\n  return _(title)", "response": "Returns the email subject"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load(self, graph, source):\n        try:\n            return graph.load(source)\n        except:\n            pass\n        try:\n            return graph.load(source, format='n3')\n        except:\n            pass\n        try:\n            return graph.load(source, format='nt')\n        except:\n            raise Exception(\"Could not load {} as either RDF/XML, N3 or NTriples\".format(source))", "response": "Load a single object from a source."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef md_to_pdf(input_name, output_name):\n\n    if output_name[-4:] == '.pdf':\n        os.system(\"pandoc \" + input_name + \" -o \" + output_name)\n    else:\n        os.system(\"pandoc \" + input_name + \" -o \" + output_name + \".pdf\" )", "response": "Converts an input MarkDown file to a PDF of the given output name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef docx_to_md(input_name, output_name):\n\n    if output_name[-5:] == '.docx':\n        os.system(\"pandoc \" + input_name + \" -o \" + output_name)\n    else:\n        os.system(\"pandoc \" + input_name + \" -o \" + output_name + \".docx\" )", "response": "Converts an input docx file to MarkDown file of the given output name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting given sequence of expressions and stores results in the specified base object.", "response": "def expect(*exprs):\n    \"\"\"Tests given sequence of conditions and stores results.\n    \n    Parameters\n    ----------\n    exprs: bool or tuple of (bool, str)\n        Variable number of expressions evaluated. If a tuple first element is \n        expression evaluated, second is the message displayed on failure in the report.   \n    \"\"\"\n\n    # Catch case of only two arguments where one is expr and other is msg\n    if len(exprs) == 2 and (isinstance(exprs[0], (bool, np.bool_)) and isinstance(exprs[1], str)):\n        if not exprs[0]:\n            _log_failure(arg_num=0, msg=exprs[1])\n    else:\n        for i, arg in enumerate(exprs):\n            if isinstance(arg, (bool, np.bool_)):\n                # Just an epression on its own \n                if not arg:\n                    _log_failure(arg_num=i)\n            elif isinstance(arg, (list, tuple)):\n                if len(arg) != 2:\n                    raise ValueError('Arguments to \"expect\" are invalid. They must be either an expression,'\n                                     ' or a tuple of length two as (expression, error_message)')\n                expr, msg = arg\n                if not expr:\n                    _log_failure(arg_num=i, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint details of logged failures in expect function Formula", "response": "def report_failures(error=False, display=True, clear=True):\n    \"\"\" Print details of logged failures in expect function\n\n    If no failures are detected, None is returned by the function.\n\n    Parameters\n    ----------\n    error:bool\n        If true, will raise an Expectation of type 'FaliedValidationError' instead of printing to console\n    display: bool\n        If True, will print the failure report to console as well as returning it as a string. If \n        error = True do nothing.\n    clear: bool\n        If True, all logged failured will be cleared after being reported. \n\n    Returns\n    -------\n    string \n        The string formated failure report.\n    list of dict\n        The failed expectations. Each dictionary contains the keys:\n            idx - the number of the failed expectation in the list starting at one, \n            expression - Code that is evaluated\n            file - the file name where the validation function was defined, \n            funcname - the name of the validation function, \n            line - the line of the validation function that the expression was on\n            msg - the error message associated with the expression, if there was one. \n    \"\"\"\n        \n    global _failed_expectations\n\n    output = []\n\n    # Copy as failures are returned \n    all_failed_expectations = _failed_expectations[:]\n\n    if all_failed_expectations:\n\n        output.append('\\nFailed Expectations: %s\\n\\n' % len(all_failed_expectations))\n\n        for i, failure in enumerate(all_failed_expectations, start=1):\n\n            report_line = '{idx}: File {file}, line {line}, in {funcname}()\\n    \"{expression}\" is not True\\n'\n\n            if failure['msg']:\n                report_line += '        -- {msg}\\n'\n\n            report_line += '\\n'\n\n            failure['idx'] = i\n            output.append(report_line.format(**failure))\n\n        if clear:\n            _failed_expectations = []\n    else:\n        output.append(\"All expectations met.\")\n\n    if error:\n        raise FailedValidationError(\"\\n\" + ''.join(output))\n    elif display:\n        print(''.join(output))\n    \n    if all_failed_expectations:\n        return (''.join(output), all_failed_expectations)\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _log_failure(arg_num, msg=None):\n\n    # stack() returns a list of frame records\n    #   0 is the _log_failure() function\n    #   1 is the expect() function \n    #   2 is the function that called expect(), that's what we want\n    #\n    # a frame record is a tuple like this:\n    #   (frame, filename, line, funcname, contextlist, index)\n    # we're only interested in the first 4. \n    frame,  filename, file_lineno, funcname = inspect.stack()[2][:4]\n    # Note that a frame object should be deleted once used to be safe and stop possible \n    # memory leak from circular referencing \n    try:\n        frame_source_lines, frame_start_lineno = (inspect.getsourcelines(frame)) \n    finally:\n        del frame\n\n    filename = os.path.basename(filename)\n\n    # Build abstract syntax tree from source of frame\n    source_ast = ast.parse(''.join(frame_source_lines))\n\n    # Locate the executed expect function \n    func_body = source_ast.body[0].body\n\n    map_lineno_to_node = {}\n    for idx, node in enumerate(func_body):\n        map_lineno_to_node[node.lineno] = node\n    \n    last_lineno = file_lineno - frame_start_lineno + 1\n\n    element_idx = [x for x in map_lineno_to_node.keys() if x <= last_lineno]\n    element_idx = max(element_idx)\n\n    expect_function_ast = map_lineno_to_node[element_idx]\n\n    # Return the source code of the numbered argument\n    arg = expect_function_ast.value.args[arg_num]\n    line = arg.lineno\n    if isinstance(arg, (ast.Tuple, ast.List)):\n        expr = astor.to_source(arg.elts[0])\n    else:\n        expr = astor.to_source(arg)\n\n    filename = os.path.basename(filename)\n\n    failure_info = {'file': filename, 'line': line, 'funcname': funcname, 'msg': msg, 'expression': expr}\n\n    _failed_expectations.append(failure_info)", "response": "Retrace stack and log the failed expresion information"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_name(self, name, create_dir=False):\n\n        # check if the file exists\n        exists = os.path.exists(os.path.join(self._path, name))\n\n        self.filepath = os.path.join(self._path, name)\n        if exists is False and create_dir is True:\n            os.makedirs(self.filepath)\n\n        self.name = name\n        return self.name", "response": "Sets the name of the file to be saved."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_argument(self, name, value_type, item_help, default=None):\n    if value_type and value_type not in self.__restricted_types:\n      raise ArgumentException(\"Named argument couldn't have {} type\".format(value_type.__name__))\n\n    if default is not None and not isinstance(default, value_type):\n      raise ArgumentException(\"Invalid default type for argument\".format(name))\n\n    if value_type is bool and default is None:\n      default = False\n\n    self._args.update({\n      name: ModuleArgumentItem(name, value_type, item_help, default)\n    })\n    return self", "response": "Adds an argument to the arguments list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary of all default arguments.", "response": "def default_arguments(self):\n    \"\"\"\n    :rtype dict\n    :rtype dict\n    \"\"\"\n    d = OrderedDict()\n\n    for arg in self._default_args:\n      d.update({arg.name: arg})\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a default argument to the arguments list.", "response": "def add_default_argument(self, name, value_type, item_help, default=None):\n    \"\"\"\n    :type name str\n    :type value_type Type\n    :type item_help str\n    :type default Type\n    :rtype ModuleArgumentsBuilder\n    \"\"\"\n    if value_type not in self.__restricted_default_types:\n      raise ArgumentException(\"Positional(default) argument couldn't have {} type\".format(value_type.__name__))\n\n    if self.__is_default_arg_flag_used and default is None:\n      raise ArgumentException(\"After defining first default Positional argument, rest should have default value too\".format(value_type.__name__))\n    elif default is not None:\n      self.__is_default_arg_flag_used = True\n\n      if not isinstance(default, value_type):\n        raise ArgumentException(\"Invalid default type for argument\".format(name))\n\n    self._default_args.append(ModuleArgumentItem(name, value_type, item_help, default=default))\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_default_arguments(self, default_args_sample):\n    parsed_arguments_dict = {}\n    default_arguments = list(self._arguments.default_arguments.values())\n    expected_length = len(default_arguments)\n    real_length = len(default_args_sample)\n\n    default_args_count = len([item for item in default_arguments if item.default is not None])\n\n    if not self._arguments.has_optional_default_argument and (default_args_sample is None or expected_length != real_length):\n      raise ArgumentException(\"Command require {} positional argument(s), found {}\".format(\n        expected_length,\n        real_length\n      ))\n    elif self._arguments.has_optional_default_argument and default_args_sample is not None and real_length < expected_length - default_args_count:\n      raise ArgumentException(\"Command require {} or {} positional argument(s), found {}\".format(\n        expected_length,\n        expected_length - default_args_count,\n        real_length\n      ))\n\n    for index in range(0, expected_length):\n      arg_meta = default_arguments[index]\n      \"\"\":type arg_meta ModuleArgumentItem\"\"\"\n      try:\n        arg = default_args_sample[index]\n      except IndexError:\n        arg = arg_meta.default\n\n      try:\n        if arg_meta.value_type is not None:\n          arg = self.__convert_value_to_type(arg, arg_meta.value_type)\n\n        parsed_arguments_dict[arg_meta.name] = arg\n      except (TypeError, ValueError):\n        raise ArgumentException(\"Invalid argument type - expected {}, got {}\".format(arg_meta.value_type.__name__, type(arg).__name__))\n\n    return parsed_arguments_dict", "response": "Parses the default arguments from the command line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_arguments(self, conf):\n    parsed_arguments_dict = {}\n    arguments = self._arguments.arguments\n\n    for arg_name in arguments:\n      arg_meta = arguments[arg_name]\n      \"\"\":type arg_meta ModuleArgumentItem\"\"\"\n      try:\n        if arg_meta.value_type is not None:\n          arg = self.__convert_value_to_type(conf.get(arg_name), arg_meta.value_type)\n        else:\n          arg = conf.get(arg_name)\n      except KeyError:\n        if arg_meta.default is None:\n          raise ArgumentException(\"Command require \\\"{}\\\" argument to be set\".format(arg_name))\n\n        # ToDo: check default value passed from user?\n        arg = arg_meta.default\n\n      parsed_arguments_dict[arg_name] = arg\n    return parsed_arguments_dict", "response": "Parses the arguments from the configuration and returns a dictionary of the arguments that are parsed into the command s output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a help string for the given command.", "response": "def generate_help(self, filename=\"\", command=\"\"):\n    \"\"\"\n    :type command str\n    \"\"\"\n    \"{} [{}]\\n\\n\".format(filename, \"|\".join(self.available_command_list))\n    help_str = \"\"\"Available commands:\n\n    \"\"\"\n\n    command_list = self.available_command_list if command == \"\" else [command]\n\n    for command in command_list:\n      cmd_meta = self.get_command_metainfo(command)\n      \"\"\":type cmd_meta ModuleMetaInfo\"\"\"\n\n      if cmd_meta is None:\n        continue\n\n      args = {}\n      args.update(cmd_meta.get_arguments_builder().arguments)\n      args.update(cmd_meta.get_arguments_builder().default_arguments)\n\n      cmd_arguments_help = {name: value.item_help for name, value in args.items() if value.item_help}\n\n      if len(cmd_arguments_help) > 0:\n        help_str += \"\"\"\n        {cmd} [{args}] - {cmd_help}\n\n        Argument details:\n        {arg_details}\n\n\n        \"\"\".format(\n          cmd=command,\n          args=\" | \".join(cmd_arguments_help.keys()),\n          cmd_help=cmd_meta.help,\n          arg_details=\"\\n\".join([\"{} - {}\".format(k, v) for k, v in cmd_arguments_help.items()])\n        )\n\n      else:\n        help_str += \"\"\"\n        {cmd} - {cmd_help}\"\"\".format(\n          cmd=command,\n          cmd_help=cmd_meta.help\n        )\n\n    return help_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a command in the order that they were passed in.", "response": "def execute_command(self, default_arg_list=None, **kwargs):\n    \"\"\"\n    :type default_arg_list list\n    :type kwargs dict\n    \"\"\"\n    _custom_func_arguments = set()\n\n    if default_arg_list is None or len(default_arg_list) == 0:\n      raise NoCommandException(\"No command passed, unable to continue\")\n\n    command_name = default_arg_list.pop(0)\n    if command_name not in self._modules.keys():\n      raise NoCommandException(\"No such command '{}' found, unable to continue\".format(command_name))\n\n    command = self._modules[command_name]\n    entry_point = command[\"entry_point\"]\n    class_path = command[\"classpath\"]\n    metainfo = command[\"metainfo\"]\n    \"\"\":type metainfo ModuleMetaInfo\"\"\"\n\n    try:\n      args = metainfo.parse_default_arguments(default_arg_list)\n      args.update(metainfo.parse_arguments(kwargs))\n\n      f_args = entry_point.__code__.co_varnames[:entry_point.__code__.co_argcount]\n\n      if len(f_args) - len(set(f_args) & _custom_func_arguments) != len(set(args.keys()) & set(f_args)):\n        raise ArgumentException(\"Function \\\"{}\\\" from module {} doesn't implement all arguments in the signature\".format(\n          entry_point.__name__, class_path\n        ))\n\n      entry_point(**args)\n    except ArgumentException as e:\n      raise NoCommandException(\"Application arguments exception: {}\\n\".format(str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(self, configuration):\n    _custom_func_arguments = {\"conf\"}\n    filename = os.path.basename(os.path.abspath(sys.argv[0]))\n\n    default_arg_list = [item for item in configuration.get(\"default\") if len(item.strip()) != 0]\n    if len(default_arg_list) == 0:\n      sys.stdout.write(self.generate_help(filename=filename))\n      return\n\n    command_name = default_arg_list.pop(0)\n    if command_name not in self._modules.keys():\n      sys.stdout.write(self.generate_help(filename=filename))\n      return\n\n    command = self._modules[command_name]\n    entry_point = command[\"entry_point\"]\n    class_path = command[\"classpath\"]\n    metainfo = command[\"metainfo\"]\n    \"\"\":type metainfo ModuleMetaInfo\"\"\"\n\n    try:\n      args = metainfo.parse_default_arguments(default_arg_list)\n      args.update(metainfo.parse_arguments(configuration))\n\n      f_args = entry_point.__code__.co_varnames[:entry_point.__code__.co_argcount]\n\n      if len(f_args) - len(set(f_args) & _custom_func_arguments) != len(set(args.keys()) & set(f_args)):\n        raise ArgumentException(\"Function \\\"{}\\\" from module {} doesn't implement all arguments in the signature\".format(\n          entry_point.__name__, class_path\n        ))\n\n      if \"conf\" in f_args:\n        args[\"conf\"] = configuration\n\n      entry_point(**args)\n    except ArgumentException as e:\n      sys.stdout.write(\"Application arguments exception: {}\\n\".format(str(e)))\n      return", "response": "Main function for the main function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dispatk(keyer):\n    calls = {}\n\n    def _dispatk(main):\n        def register(*keys):\n            def _register(spec):\n                for key in keys:\n                    if key in calls:\n                        raise ValueError(\n                            \"function already registered for %r\"\n                            % (main.__name__, key))\n\n                    calls[key] = spec\n\n                return spec\n\n            return _register\n\n        @wraps(main)\n        def run(*args, **kwargs):\n            return calls.get(keyer(*args, **kwargs), main)(*args, **kwargs)\n\n        run.register = register\n\n        return run\n\n    return _dispatk", "response": "This is a generic function that returns a function that can be used to register a new object for a specific key. It returns a function that can be used to register a new object for a specific key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(debug=False, host='127.0.0.1'):\n    if debug:\n        debug = True\n    nago.protocols.httpserver.app.run(debug=debug, host=host)", "response": "starts a nago agent"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses command line arguments and return a tuple of args and otherthings", "response": "def parse_known_args():\n    \"\"\" Parse command line arguments\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-V', '--version',\n                        action='store_true',\n                        dest='version',\n                        help='Print the version number and exit')\n    mutually_exclusive_group = parser.add_mutually_exclusive_group()\n    mutually_exclusive_group.add_argument(\n        '-v', '--verbose',\n        action='store_true',\n        help='Show verbose information.'\n        ' Higher verbosity can be selected by --verbosity flag')\n    parser.add_argument('-o', '--old',\n                        type=str,\n                        help='Old word to be replaced')\n    parser.add_argument('-n', '--new', type=str, help='New replacement word')\n    parser.add_argument('-d', '--dry-run', action='store_true', help='Dry Run')\n\n    args, otherthings = parser.parse_known_args()\n    return args, otherthings"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    args, otherthings = parse_known_args()\n\n    if args.version:\n        print_version()\n        return 0\n\n    verbosity = 0\n    if args.verbose:\n        verbosity = 1\n\n    far = Far(verbosity=verbosity)\n\n    if args.dry_run:\n        far.dry_run(old=args.old)\n    else:\n        far.find_and_replace(old=args.old, new=args.new)", "response": "Main entry point for the\n    command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a path to the overlay filesytem.", "response": "def add(self, path):\n        \"\"\"Add a path to the overlay filesytem.\n\n        Any filesystem operation involving the this path or any sub-paths\n        of it will be transparently redirected to temporary root dir.\n\n        @path: An absolute path string.\n        \"\"\"\n        if not path.startswith(os.sep):\n            raise ValueError(\"Non-absolute path '{}'\".format(path))\n        path = path.rstrip(os.sep)\n        while True:\n            self._paths[path] = None\n            path, _ = os.path.split(path)\n            if path == os.sep:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fchown(self, real, fileno, uid, gid):\n        path = self._fake_path(self._path_from_fd(fileno))\n        self._chown_common(path, uid, gid)", "response": "Run fake fchown code if fileno points to a sub - path of our tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_grammatically_correct_vocabulary_subset(self, text,\n                                                    sent_filter='combined'):\n        \"\"\"\n        Returns a subset of a given vocabulary based on whether its\n        terms are \"grammatically correct\".\n        \"\"\"\n        tokens = word_tokenize(text)\n        sent_tokens = get_partial_sentence(tokens)\n\n        if not sent_tokens:\n            return self.vocabulary\n\n        if sent_filter == 'combined':\n            if len(sent_tokens) < 2:\n                return self.get_bigram_filtered_vocab(sent_tokens)\n\n            combined_filters = self.get_pos_filtered_vocab(sent_tokens) + \\\n                self.get_trigram_filtered_vocab(sent_tokens) + \\\n                self.get_bigram_filtered_vocab(sent_tokens)\n            return combined_filters\n\n        if sent_filter == 'pos' and len(sent_tokens) > 1:\n            return self.get_pos_filtered_vocab(sent_tokens)\n        elif sent_filter == 'bigram' or len(sent_tokens) < 2:\n            return self.get_bigram_filtered_vocab(sent_tokens)\n        elif sent_filter == 'trigram':\n            return self.get_trigram_filtered_vocab(sent_tokens)", "response": "Returns a subset of a given vocabulary based on whether its\n        terms are grammatically correct."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a queryset of nodes in tree order.", "response": "def get_queryset(self, *args, **kwargs):\n        \"\"\"\n        Ensures that this manager always returns nodes in tree order.\n        \"\"\"\n        qs = super(TreeManager, self).get_queryset(*args, **kwargs)\n\n        # Restrict operations to pages on the current site if needed\n        if settings.PAGES_HIDE_SITES and settings.PAGES_USE_SITE_ID:\n            return qs.order_by(self.tree_id_attr, self.left_attr).filter(sites=settings.SITE_ID)\n        else:\n            return qs.order_by(self.tree_id_attr, self.left_attr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_site(self, site_id=None):\n        if settings.PAGES_USE_SITE_ID:\n            if not site_id:\n                site_id = settings.SITE_ID\n            return self.get_queryset().filter(sites=site_id)\n        return self.all()", "response": "Return a QuerySet of pages that are published on the site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an installer for the given version.", "response": "def installer(cv, ctx, site, force=False):\n    \"\"\"\n    Installer factory\n    @param  cv:     Current version (The version of IPS we are installing)\n    @type   cv:     ips_vagrant.common.version.Version\n    @type   ctx:    ips_vagrant.cli.Context\n    @param  site:   The IPS Site we are installing\n    @type   site:   ips_vagrant.models.sites.Site\n    @param  force:  Overwrite existing files / databases\n    @type   force:  bool\n    @return:    Installer instance\n    @rtype:     ips_vagrant.installer.latest.Installer\n    \"\"\"\n    log = logging.getLogger('ipsv.installer')\n    log.info('Loading installer for IPS %s', cv)\n    iv = None\n    for v in versions:\n        vstring = '.'.join(map(str, v)) if v else 'latest'\n        # cvstring = '.'.join(map(str, cv)) if cv else 'latest'\n        log.debug('Checking if version %s >= %s', vstring, cv.vstring)\n        if (v is None) or (v >= cv.vtuple):\n            log.debug('Changing installer version to %s', vstring)\n            iv = v\n\n    log.info('Returning installer version %s', '.'.join(map(str, iv)) if iv else 'latest')\n    return versions[iv](ctx, site, force)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef center_start(r, window_size):\n  res = copy.copy(r)\n  res.end = res.start + window_size / 2\n  res.start = res.end - window_size\n  return res", "response": "Center a region on its start and expand it to window_size bases."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncenter a region on its end and expand it to window_size bases.", "response": "def center_end(r, window_size):\n  \"\"\"\n  Center a region on its end and expand it to window_size bases.\n\n  :return: the new region.\n  \"\"\"\n  res = copy.copy(r)\n  res.start = res.end - window_size / 2\n  res.end = res.start + window_size\n  return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef center_middle(r, window_size):\n  res = copy.copy(r)\n  mid = res.start + (len(res) / 2)\n  res.start = mid - (window_size / 2)\n  res.end = res.start + window_size\n  return res", "response": "Center a region on its middle and expand it to window_size bases."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming an input genomic region into one suitable for the profile. :param region: input region to transform. :param window_center: which part of the input region to center on. :param window_size: how large the resultant region should be. :return: a new genomic interval on the same chromosome, centered on the <window_center> (e.g. 3' end) of the input region and resized to be window_size long.", "response": "def transform_locus(region, window_center, window_size):\n  \"\"\"\n  transform an input genomic region into one suitable for the profile.\n\n  :param region:         input region to transform.\n  :param window_center:  which part of the input region to center on.\n  :param window_size:    how large the resultant region should be.\n  :return: a new genomic interval on the same chromosome, centered on the\n           <window_center> (e.g. 3' end) of the input region and resized to\n           be window_size long.\n  \"\"\"\n  if window_center == CENTRE:\n    region.transform_center(window_size)\n  else:\n    raise ValueError(\"Don't know how to do this transformation: \" +\n                     window_center)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the percent identity of a column.", "response": "def pid(col, ignore_gaps=False):\n  \"\"\"\n  Compute the percent identity of a an alignment column.\n\n  Define PID as the frequency of the most frequent nucleotide in the column.\n\n  :param col:         an alignment column; a dictionary where keys are seq.\n                      names and values are the nucleotide in the column for\n                      that sequence.\n  :param ignore_gaps: if True, do not count gaps towards the total number of\n                      sequences in the column (i.e. the denominator of the\n                      fraction).\n  :raise ValueError: if the column contains only gaps.\n  \"\"\"\n  hist = {}\n  total = 0\n  found_non_gap = False\n  for v in col.values():\n    if v == sequence.GAP_CHAR:\n      if ignore_gaps:\n        continue\n      else:\n        total += 1\n    else:\n      found_non_gap = True\n      if v not in hist:\n        hist[v] = 0\n      hist[v] += 1\n      total += 1\n  if not found_non_gap:\n    raise ValueError(\"Cannot determine PID of column with only gaps\")\n  return max(hist.values()) / float(total)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef conservtion_profile_pid(region, genome_alignment,\n                            mi_seqs=MissingSequenceHandler.TREAT_AS_ALL_GAPS,\n                            species=None):\n  \"\"\"\n  build a conservation profile for the given region using the genome alignment.\n\n  The scores in the profile will be the percent of bases identical to the\n  reference sequence.\n\n  :param miss_seqs: how to treat sequence with no actual sequence data for\n                    the column.\n  :return: a list of the same length as the region where each entry is the\n           PID at the corresponding locus.\n  \"\"\"\n  res = []\n  s = region.start if region.isPositiveStrand() else region.end - 1\n  e = region.end if region.isPositiveStrand() else region.start - 1\n  step = 1 if region.isPositiveStrand() else -1\n  for i in range(s, e, step):\n    try:\n      col = genome_alignment.get_column(region.chrom, i, mi_seqs, species)\n      res.append(pid(col))\n    except NoSuchAlignmentColumnError:\n      res.append(None)\n    except NoUniqueColumnError:\n      res.append(None)\n\n  return res", "response": "Build a conservation profile for a given region using the genome alignment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new list of values to a list of rolling means.", "response": "def merge_profile(mean_profile, new_profile):\n  \"\"\"Add a new list of values to a list of rolling means.\"\"\"\n  for i in range(0, len(mean_profile)):\n    if new_profile[i] is None:\n      continue\n    mean_profile[i].add(new_profile[i])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing a BED file and produce conservation of conservation using whole - genome alignment.", "response": "def processBED(fh, genome_alig, window_size, window_centre,\n               mi_seqs=MissingSequenceHandler.TREAT_AS_ALL_GAPS, species=None,\n               verbose=False):\n  \"\"\"\n  Process BED file, produce profile of conservation using whole genome alig.\n\n  :param fh:\n  :param genome_alig:   the whole-genome alignment to use to compute\n                        conservation scores\n  :param window_size:   length of the profile.\n  :param window_center: which part of each interval to place at the center\n                        of the profile. Acceptable values are in the module\n                        constant WINDOW_CENTRE_OPTIONS.\n  :param miss_seqs:     how to treat sequence with no actual sequence data for\n                        the column.\n  :param verbose:       if True, output progress messages to stderr.\n\n  :return:\n  \"\"\"\n  mean_profile = []\n  while len(mean_profile) < window_size:\n    mean_profile.append(RollingMean())\n\n  for e in BEDIterator(fh, verbose=verbose, scoreType=float,\n                       sortedby=ITERATOR_SORTED_START):\n    # figure out which interval to look at...\n    transform_locus(e, window_centre, window_size)\n    new_profile = conservtion_profile_pid(e, genome_alig, mi_seqs, species)\n    merge_profile(mean_profile, new_profile)\n  return [m.mean for m in mean_profile]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getUI(prog_name, args):\n  longDescription = \"Given a set of BED intervals, compute a profile of \" +\\\n                    \"conservation by averaging over all intervals using a \" +\\\n                    \"whole genome alignment to a set of relevent species.\" +\\\n                    \"\\n\\n\" +\\\n                    \"Usage: \" + prog_name + \" [options] regions.bed \" +\\\n                    \"genome-alig species\" +\\\n                    \"\\n\\n\" +\\\n                    \"genome-alig can be either a single MAF file, or a \" +\\\n                    \"directory of MAF files. In the latter case, the \" +\\\n                    \"directory may also optionally contain index files for \" +\\\n                    \"the alignment files.\"\n  shortDescription = longDescription\n\n  ui = CLI(prog_name, shortDescription, longDescription)\n  # gotta have two args -- MAF dir/file and BED regions.\n  # Input by stdin not allowed\n  ui.minArgs = 3\n  ui.maxArgs = 4\n  ui.addOption(Option(short=\"o\", long=\"output\", argName=\"filename\",\n                      description=\"output to given file, else stdout\",\n                      required=False, type=str))\n  ui.addOption(Option(short=\"w\", long=\"window\", argName=\"size\",\n                      description=\"size of window to compute around each \" +\n                                  \"interval; \" +\n                                  str(DEFAULT_WINDOW_SIZE) +\n                                  \" to use whole interval. \" +\n                                  \"Default \" + str(DEFAULT_WINDOW_SIZE),\n                      required=False, type=int))\n  ui.addOption(Option(short=\"e\", long=\"extensions\", argName=\"extension\",\n                      description=\"if genome-alig specifies a directory, \" +\n                                  \"treat files with this extension as \" +\n                                  \"alignment files.\", required=False,\n                                  type=str))\n  ui.addOption(Option(short=\"i\", long=\"index-extensions\", argName=\"extension\",\n                      description=\"if genome-alig specifies a directory, \" +\n                                  \"treat files with this extension as \" +\n                                  \"index files for alignments.\",\n                                  required=False, type=str))\n  ui.addOption(Option(short=\"f\", long=\"fail-no-index\",\n                      description=\"fail if an alignment file without an \" +\n                                  \"index is found; otherwise index-less \" +\n                                  \"alignment files are loaded whole (which \" +\n                                  \"might be slow if they're large, and \" +\n                                  \"might require a lot of memory)\",\n                      default=False, required=False))\n  ui.addOption(Option(short=\"m\", long=\"missing\", argName=\"strategy\",\n                      description=\"how to treat missing sequences in \" +\n                                  \"blocks. Options are \" +\n                                  \", \".join([str(x.name) for x in\n                                             MissingSequenceHandler]),\n                                  required=False, type=str))\n  ui.addOption(Option(short=\"s\", long=\"species\", argName=\"species\",\n                      description=\"consider only these species. Default is \" +\n                                  \"all.\", required=False, type=str))\n  ui.addOption(Option(short=\"v\", long=\"verbose\",\n                      description=\"output additional messages to stderr \" +\n                                  \"about run (default: \" +\n                                  str(DEFAULT_VERBOSITY) + \")\",\n                      default=DEFAULT_VERBOSITY, required=False))\n  ui.addOption(Option(short=\"h\", long=\"help\",\n                      description=\"show this help message \", special=True))\n  ui.addOption(Option(short=\"u\", long=\"test\",\n                      description=\"run unit tests \", special=True))\n\n  ui.parseCommandLine(args)\n  return ui", "response": "Build and return a user interface object for this script."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess the command line arguments of this script and dispatch.", "response": "def main(args, prog_name):\n  \"\"\"Process the command line arguments of this script and dispatch.\"\"\"\n  # get options and arguments\n  ui = getUI(prog_name, args)\n\n  if ui.optionIsSet(\"test\"):\n    # just run unit tests\n    unittest.main(argv=[sys.argv[0]])\n  elif ui.optionIsSet(\"help\"):\n    # just show help\n    ui.usage()\n  else:\n    verbose = (ui.optionIsSet(\"verbose\") is True) or DEFAULT_VERBOSITY\n\n    # get output handle\n    out_fh = sys.stdout\n    if ui.optionIsSet(\"output\"):\n      out_fh = open(ui.getValue(\"output\"), \"w\")\n\n    # get window size...\n    window_size = DEFAULT_WINDOW_SIZE\n    if ui.optionIsSet(\"window\"):\n      window_size = ui.getValue(\"window\")\n\n    # get the window anchoring location\n    windowCentre = DEFAULT_WINDOW_CENTRE\n    if ui.optionIsSet(\"centre\"):\n      windowCentre = ui.getValue(\"centre\")\n      if windowCentre not in WINDOW_CENTRE_OPTIONS:\n        sys.stderr.write(\"un-recognised window anchor position: \" +\n                         str(windowCentre) + \"\\n\")\n        sys.exit(1)\n\n    args = ui.getAllArguments()\n    assert(len(args) == 3 or len(args) == 4)\n    region_fn = ui.getArgument(0)\n    ga_path = ui.getArgument(1)\n    index_fn = None\n    if len(args) == 3:\n      spec = ui.getArgument(2)\n    else:\n      index_fn = ui.getArgument(2)\n      spec = ui.getArgument(3)\n\n    extensions = (ui.getValue(\"extensions\").strip().split(\",\") if\n                  ui.optionIsSet(\"extensions\") else None)\n    index_extensions = (ui.getValue(\"index-extensions\").strip().split(\",\") if\n                        ui.optionIsSet(\"index-extensions\") else None)\n    fail_no_index = ui.optionIsSet(\"fail-no-index\")\n    mi_seqs = (MissingSequenceHandler[ui.getValue(\"missing\")]\n               if ui.optionIsSet(\"missing\")\n               else MissingSequenceHandler.TREAT_AS_ALL_GAPS)\n    species = ([x.strip() for x in ui.getValue(\"species\").split(\",\")] if\n               ui.optionIsSet(\"species\") else None)\n\n    # build the genome alignment\n    alig = (load_just_in_time_genome_alignment(ga_path, spec, extensions,\n                                               index_extensions, fail_no_index,\n                                               verbose)\n            if os.path.isdir(ga_path)\n            else build_genome_alignment_from_file(ga_path, spec, index_fn,\n                                                  verbose))\n\n    # get the profile and write it to the output stream\n    profile = processBED(open(region_fn), alig, window_size, CENTRE,\n                         mi_seqs, species, verbose)\n    out_fh.write(\"\\n\\n\" + \", \".join(str(x) for x in profile) + \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_error(context: RunContext) -> int:\n\n    if context.return_code != 0:\n        if context.mute:\n            context.result_buffer += f': command failed: {context.return_code}'\n        else:\n            context.result_buffer += f'{context.cmd_as_string}: command failed: {context.return_code}'\n\n        _LOGGER_PROCESS.error(context.result_buffer)\n        _LOGGER_PROCESS.error(repr(context))\n\n        if not context.failure_ok:\n            _exit(context)\n    else:\n        if context.mute:\n            context.result_buffer += f': success: {context.return_code}'\n        else:\n            context.result_buffer += f'{context.cmd_as_string}: success: {context.return_code}'\n        _LOGGER_PROCESS.info(context.result_buffer)\n\n    return context.return_code", "response": "Checks the return code of a run after a sub - process exits."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(cmd: str,\n        *paths: str,\n        cwd: str = '.',\n        mute: bool = False,\n        filters: typing.Optional[typing.Union[typing.Iterable[str], str]] = None,\n        failure_ok: bool = False,\n        timeout: float = _DEFAULT_PROCESS_TIMEOUT,\n        ) -> typing.Tuple[str, int]:\n    \"\"\"\n    Executes a command and returns the result\n\n    Args:\n        cmd: command to execute\n        paths: paths to search executable in\n        cwd: working directory (defaults to \".\")\n        mute: if true, output will not be printed\n        filters: gives a list of partial strings to filter out from the output (stdout or stderr)\n        failure_ok: if False (default), a return code different than 0 will exit the application\n        timeout: sub-process timeout\n\n    Returns: command output\n    \"\"\"\n\n    filters = _sanitize_filters(filters)\n\n    exe_path, args_list = _parse_cmd(cmd, *paths)\n\n    context = RunContext(  # type: ignore\n        exe_path=exe_path,\n        capture=sarge.Capture(),\n        failure_ok=failure_ok,\n        mute=mute,\n        args_list=args_list,\n        paths=paths,\n        cwd=cwd,\n        timeout=timeout,\n        filters=filters,\n    )\n\n    if mute:\n        context.result_buffer += f'{context.cmd_as_string}'\n    else:\n        _LOGGER_PROCESS.info('%s: running', context.cmd_as_string)\n\n    context.start_process()\n    monitor_running_process(context)\n    check_error(context)\n\n    return context.process_output_as_str, context.return_code", "response": "Executes a command and returns the output of the process"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self, domain=None):\n        # pylint: disable=arguments-differ\n        if domain:\n            return self._list(domain)\n        url = \"{base}\".format(\n            base=\"domains\"\n        )\n        domains = self.core.get(url)\n        res = []\n        for dom in domains:\n            domain_uuid = dom.get('identifier')\n            url = \"{base}\".format(\n                base=self.local_base_url\n            )\n            param = {\n                'domainUuid': domain_uuid\n            }\n            encode = urllib.urlencode(param)\n            if encode:\n                url += \"?\"\n                url += encode\n            res += self.core.list(url)\n        return res", "response": "Workaround to list data by domain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconsole script for certify_dict.", "response": "def cli_certify_complex_dict(\n    config, schema, key_certifier, value_certifier, allow_extra,\n    include_collections, value,\n):\n    \"\"\"Console script for certify_dict.\"\"\"\n    schema = load_json_pickle(schema, config)\n    key_certifier = create_certifier(load_json_pickle(key_certifier, config))\n    value_certifier = create_certifier(load_json_pickle(value_certifier, config))\n\n    execute_cli_command(\n        'dict',\n        config,\n        lambda x: load_json_pickle(x, config),\n        certify_dict,\n        value,\n        allow_extra=allow_extra,\n        include_collections=include_collections,\n        key_certifier=key_certifier,\n        required=config['required'],\n        schema=schema,\n        value_certifier=value_certifier,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nput the object into a file URL.", "response": "def write(url, content, **args):\n    \"\"\"Put the object/collection into a file URL.\"\"\"\n    with HTTPSResource(url, **args) as resource:\n        resource.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntests ONLY: this is called if run from command line", "response": "def main(argv=None):\n    '''TEST ONLY: this is called if run from command line'''\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i','--input_file', required=True)\n    parser.add_argument('--input_file_format', default='sequence')\n    parser.add_argument('--input_data_type', default='json')\n    parser.add_argument('--input_separator', default='\\t')\n    parser.add_argument('-o','--output_dir', required=True)\n    parser.add_argument('--output_file_format', default='sequence')\n    parser.add_argument('--output_data_type', default='json')\n    parser.add_argument('--output_separator', default='\\t')\n    args=parser.parse_args()\n\n    # can be inconvenient to specify tab on the command line\n    args.input_separator = \"\\t\" if args.input_separator=='tab' else args.input_separator\n    args.output_separator = \"\\t\" if args.output_separator=='tab' else args.output_separator\n\n    sc = SparkContext(appName=\"fileUtil\")\n    fUtil = FileUtil(sc)\n\n    ## CONFIG LOAD\n    input_kwargs = {\"file_format\": args.input_file_format,\n                   \"data_type\": args.input_data_type}\n    parse_kwargs = {\"separator\": args.input_separator}\n    load_kwargs = merge_dicts(input_kwargs, parse_kwargs)\n    \n    ## LOAD\n    rdd = fUtil.load_file(args.input_file, **load_kwargs)\n\n    ## CONFIG SAVE\n    output_kwargs = {\"file_format\": args.output_file_format,\n                     \"data_type\": args.output_data_type}\n    emit_kwargs = {\"separator\": args.output_separator}\n    save_kwargs = merge_dicts(output_kwargs, emit_kwargs)\n\n    ## SAVE\n    fUtil.save_file(rdd, args.output_dir, **save_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a CSV file into a RDD of tuples. Each tuple is returned by the first column is taken from first column id as string and the second column is taken from first column id as string.", "response": "def _load_text_csv_file(self, filename, separator=',', **kwargs):\n        \"\"\"Return a pair RDD where key is taken from first column, remaining columns are named after their column id as string\"\"\"\n        rdd_input = self.sc.textFile(filename)\n\n        def load_csv_record(line):\n            input_stream = StringIO.StringIO(line)\n            reader = csv.reader(input_stream, delimiter=',')\n            # key in first column, remaining columns 1..n become dict key values\n            payload = reader.next()\n            key = payload[0]\n            rest = payload[1:]\n            # generate dict of \"1\": first value, \"2\": second value, ...\n            d = {}\n            for (cell,i) in izip(rest, range(1,1+len(rest))):\n                d[str(i)] = cell\n            # just in case, add \"0\": key\n            d[\"0\"] = key\n            return (key, d)\n\n        rdd_parsed = rdd_input.map(load_csv_record)\n        return rdd_parsed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config(config_spec):\n        config_file = None\n        if config_spec.startswith(\"http\"):\n            # URL: fetch it\n            config_file = urllib.urlopen(config_spec)\n        else:\n            # string: open file with that name\n            config_file = open(config_spec)\n        config = json.load(config_file)\n        # Close any open files\n        try:\n            config_file.close()\n        except:\n            pass\n        return config", "response": "Like get_json_config but does not parse result as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset the internal state of the object", "response": "def reset(self):\n        \"\"\"set sensible defaults\"\"\"\n        self.start = 1\n        self.count = None\n        self.end = None\n        self.stride = 1\n        self.format = \"%d\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_kv_args(self, args):\n        for arg in [\"start\", \"end\", \"count\", \"stride\"]:\n            try:\n                arg_raw = args.pop(arg, None)\n                if arg_raw is None:\n                    continue\n                arg_cooked = int(arg_raw, 0)\n                setattr(self, arg, arg_cooked)\n            except ValueError:\n                raise AnsibleError(\n                    \"can't parse arg %s=%r as integer\"\n                        % (arg, arg_raw)\n                )\n            if 'format' in args:\n                self.format = args.pop(\"format\")\n        if args:\n            raise AnsibleError(\n                \"unrecognized arguments to with_sequence: %r\"\n                % args.keys()\n            )", "response": "parse key - value style arguments"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_simple_args(self, term):\n        match = SHORTCUT.match(term)\n        if not match:\n            return False\n\n        _, start, end, _, stride, _, format = match.groups()\n\n        if start is not None:\n            try:\n                start = int(start, 0)\n            except ValueError:\n                raise AnsibleError(\"can't parse start=%s as integer\" % start)\n        if end is not None:\n            try:\n                end = int(end, 0)\n            except ValueError:\n                raise AnsibleError(\"can't parse end=%s as integer\" % end)\n        if stride is not None:\n            try:\n                stride = int(stride, 0)\n            except ValueError:\n                raise AnsibleError(\"can't parse stride=%s as integer\" % stride)\n\n        if start is not None:\n            self.start = start\n        if end is not None:\n            self.end = end\n        if stride is not None:\n            self.stride = stride\n        if format is not None:\n            self.format = format", "response": "parse the shortcut forms return True or False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nanalyzing headers from file or raw messages", "response": "def parse_headers(self, use_cookies, raw):\n        \"\"\"\n        analyze headers from file or raw messages\n\n        :return: (url, dat)\n        :rtype:\n        \"\"\"\n        if not raw:\n            packet = helper.to_str(helper.read_file(self.fpth))\n        else:\n            packet = raw\n        dat = {}\n\n        pks = [x for x in packet.split('\\n') if x.replace(' ', '')]\n        url = pks[0].split(' ')[1]\n\n        for i, cnt in enumerate(pks[1:]):\n            arr = cnt.split(':')\n            if len(arr) < 2:\n                continue\n            arr = [x.replace(' ', '') for x in arr]\n            _k, v = arr[0], ':'.join(arr[1:])\n            dat[_k] = v\n\n        if use_cookies:\n            try:\n                self.fmt_cookies(dat.pop('Cookie'))\n            except:\n                pass\n        self.headers = dat\n        self.url = 'https://{}{}'.format(self.headers.get('Host'), url)\n        return url, dat"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fmt_cookies(self, ck):\n        cks = {}\n        for c in ck.split(';'):\n            a = c.split('=')\n            if len(a) != 2:\n                continue\n            cks[a[0].replace(' ', '')] = a[1].replace(' ', '')\n        self.cookies = cks", "response": "Formats the cookies field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse the url for creation of domain and fetch cookies", "response": "def spawn(self, url, force_spawn=False):\n        \"\"\"use the url for creation of domain and fetch cookies\n\n        - init cache dir by the url domain as ``<base>/domain``\n        - save the cookies to file ``<base>/domain/cookie.txt``\n        - init ``headers.get/post/json`` with response info\n        - init ``site_dir/site_raw/site_media``\n\n        :param url:\n        :type url:\n        :param force_spawn:\n        :type force_spawn:\n        :return:\n        :rtype:\n        \"\"\"\n        _url, domain = self.get_domain_home_from_url(url)\n        if not _url:\n            return False\n\n        self.cache['site_dir'] = os.path.join(self.cache['base'], self.domain)\n        for k in ['raw', 'media']:\n            self.cache['site_' + k] = os.path.join(self.cache['site_dir'], k)\n            helper.mkdir_p(self.cache['site_' + k], True)\n\n        ck_pth = os.path.join(self.cache['site_dir'], 'cookie.txt')\n        helper.mkdir_p(ck_pth)\n\n        name = os.path.join(self.cache['site_raw'], 'homepage')\n        # not force spawn and file ok\n        if not force_spawn and helper.is_file_ok(name):\n            # zlog.debug('{} exist!'.format(name))\n            self.sess.cookies = self.load_cookies(ck_pth)\n            return True\n        else:\n            zlog.debug('{} not exist!'.format(name))\n\n        res = self.sess.get(url, headers=self.__header__)\n        if res.status_code != 200:\n            return False\n        if res:\n            helper.write_file(res.content, name)\n        # self.load(url)\n\n        for k, v in self.headers.items():\n            self.headers[k] = res.request.headers\n\n        self.dump_cookies(cookies=self.sess.cookies, save_to=ck_pth)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses url for domain and homepage", "response": "def get_domain_home_from_url(self, url):\n        \"\"\" parse url for domain and homepage\n\n        :param url: the req url\n        :type url: str\n        :return: (homepage, domain)\n        :rtype:\n        \"\"\"\n        p = parse.urlparse(url)\n        if p.netloc:\n            self.domain = p.netloc\n            self.homepage = '{}://{}'.format(p.scheme, p.netloc)\n            return self.homepage, p.netloc\n        else:\n            return '', ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps the url to the cache id", "response": "def map_url_to_cache_id(self, url):\n        \"\"\"use of the url resource location as cached id\n\n        e.g.: ``<domain>/foo/bar/a.html => <base>/domain/foo/bar/a.html``\n\n        - map the url to local file\n\n        :param url:\n        :type url:\n        :return:\n        :rtype:\n        \"\"\"\n        base, _ = self.get_domain_home_from_url(url)\n\n        if base == '':\n            # invalid url\n            _sub_page = ''\n        elif base == url or base + '/' == url:\n            # homepage\n            _sub_page = 'homepage'\n        else:\n            # sub page\n            _sub_page = url.replace(base, '').split('/')\n            _sub_page = '/'.join([x for x in _sub_page if x])\n\n        if _sub_page:\n            full_name = os.path.join(self.cache['site_raw'], _sub_page)\n            return full_name\n        else:\n            return _sub_page"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the list of tasks according the urls dict.", "response": "def gen_tasks(self, urls):\n        \"\"\" according the urls gen {name:'', url:''} dict.\n        :param urls:\n        :type urls:\n        :return:\n        :rtype:\n        \"\"\"\n        tasks = []\n        if isinstance(urls, list):\n            for url in urls:\n                dat = {\n                    'url': url,\n                    'name': url.split('/')[-1]\n                }\n                if not self.overwrite and helper.is_file_ok(dat['name']):\n                    self.result['skip'] += 1\n                else:\n                    tasks.append(dat)\n        elif isinstance(urls, dict):\n            # {k: v} => k is name, v is url value\n            for k, v in urls.items():\n                dat = {\n                    'url': v,\n                    'name': k,\n                }\n                if not self.overwrite and helper.is_file_ok(dat['name']):\n                    self.result['skip'] += 1\n                else:\n                    tasks.append(dat)\n        else:\n            raise CrawlerParamsError('urls should be list/dict')\n        return tasks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_sess_get(self, url):\n        try:\n            res = self.sess.get(url, headers=self.headers['get'], timeout=self.timeout)\n            if res.status_code == 200:\n                return res.content\n        except (requests.ReadTimeout, requests.ConnectTimeout, requests.ConnectionError) as _:\n            zlog.error('failed of: {} with error: {}'.format(url, _))", "response": "get url by requests synchronized\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches the url raw info from cache first try get from Internet", "response": "def load(self, url, use_cache=True, show_log=False):\n        \"\"\"fetch the url ``raw info``, use cache first, if no cache hit, try get from Internet\n\n        :param url:\n        :type url:\n        :param use_cache:\n        :type use_cache:\n        :param show_log:\n        :type show_log:\n        :return: the ``raw info`` of the url\n        :rtype: ``str``\n        \"\"\"\n        _name = self.map_url_to_cache_id(url)\n        raw = ''\n        hit = False\n\n        if use_cache:\n            hit = True\n            raw = self.load_from_cache(_name)\n\n        if not raw:\n            if show_log:\n                zlog.debug('from cache got nothing {}'.format(_name))\n            raw = self.do_sess_get(url)\n            if raw:\n                helper.write_file(raw, _name)\n\n        # if not raw:\n        #     hit = True\n        #     raw = self.load_from_cache(_name)\n        if show_log:\n            zlog.debug('[{}:{:>8}] get {}'.format('Cache' if hit else 'Net', len(raw), url))\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sync_save(self, res, overwrite=False):\n        if not isinstance(res, dict):\n            raise CrawlerParamsError('res must be dict')\n\n        url_, file_name = res.get('url', ''), res.get('name', '')\n        if not url_ or not file_name:\n            raise CrawlerParamsError('url&name is needed!')\n\n        # log.debug('Sync {}'.format(res.get('name')))\n        # not overwrite and file exists\n        if not overwrite and helper.is_file_ok(file_name):\n            return True\n\n        cnt = self.do_sess_get(url_)\n        # get res failed\n        if not cnt:\n            return False\n\n        with open(file_name, 'wb') as f:\n            f.write(cnt)\n        zlog.debug('Sync Done {}'.format(res.get('name')))\n        return True", "response": "save res to local synchronized\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def crawl_raw(self, res):\n        cnt = await self.async_get(res)\n        if cnt:\n            loop_ = asyncio.get_event_loop()\n            await loop_.run_in_executor(None, self.write_hd, res.get('name'), cnt)\n            return True\n        else:\n            return False", "response": "crawl the raw doc and save it asynchronous."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def _sem_crawl(self, sem, res):\n        async with sem:\n            st_ = await self.crawl_raw(res)\n            if st_:\n                self.result['ok'] += 1\n            else:\n                self.result['fail'] += 1\n\n            # take a little gap\n            await asyncio.sleep(random.randint(0, 1))", "response": "use semaphore encapsulate the crawl_media \\ nwith async crawl"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def crawl(self, urls, sem):\n        tasks = [\n            self._sem_crawl(sem, x)\n            for x in urls\n        ]\n\n        tasks_iter = asyncio.as_completed(tasks)\n\n        fk_task_iter = tqdm.tqdm(\n            tasks_iter,\n            total=len(tasks),\n            desc=' \u2708',\n            # desc='\u2708 {}/{}'.format(self.result['ok'], self.result['fail'])\n        )\n        for co_ in fk_task_iter:\n            await co_", "response": "Crawls the nacite entries in the given list of urls and returns the nacite entries in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_import_module(path, default=None):\n    if path is None:\n        return default\n    \n    dot = path.rindex('.')\n    module_name = path[:dot]\n    class_name = path[dot + 1:]\n    try:\n        _class = getattr(import_module(module_name), class_name)\n        return _class\n    except (ImportError, AttributeError):\n        warnings.warn('%s cannot be imported' % path, RuntimeWarning)\n    return default", "response": "Try to import the specified module from the given Python path and return the object or None if import fails."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef querystring_update(request, **kwargs):\n    updated = request.GET.copy()\n    for k, v in kwargs.items():\n        updated[k] = v\n\n    return updated.urlencode()", "response": "Output a URL - encoded querystring updated with key : values from kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef json_decoder(content, *args, **kwargs):\n    if not content:\n        return None\n    json_value = content.decode()\n    return json.loads(json_value)", "response": "Json decoder parser for the base class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that a value is a valid version string.", "response": "def bump_option_validator(ctx, param, value):\n    \"\"\"In case a value is provided checks that it is a valid version string. If\n    is not thrown :class:`click.UsageError`.\n\n    Return a :class:`~braulio.version.Version` object or **None**.\n    \"\"\"\n\n    if value:\n        try:\n            value = Version(value)\n        except ValueError:\n            ctx.fail(f\"{x_mark} {value} is not a valid version string\")\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef changelog_file_option_validator(ctx, param, value):\n\n    path = Path(value)\n\n    if not path.exists():\n        filename = click.style(path.name, fg=\"blue\", bold=True)\n        ctx.fail(\n            \"\\n\"\n            f\" {x_mark} Unable to find {filename}\\n\"\n            '   Run \"$ brau init\" to create one'\n        )\n\n    return path", "response": "Checks that the given file path exists in the current working directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that a commit template has the new version placeholder.", "response": "def message_option_validator(ctx, param, value):\n    \"\"\"A commit template must have the **{new_version}** placeholder.\"\"\"\n\n    if not value or \"{new_version}\" not in value:\n        ctx.fail(\"Missing {new_version} placeholder in \" f\"{value}.\")\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating that the current version of a node is a valid version string.", "response": "def current_version_option_validator(ctx, param, value):\n    \"\"\"If a version string is provided, validates it. Otherwise it tries\n    to determine the current version from the last Git tag that matches\n    ``tag_pattern`` option.\n\n    Return a :class:`~braulio.version.Version` object or **None**.\n    \"\"\"\n\n    current_version = None\n\n    if value:\n        try:\n            current_version = Version(value)\n        except ValueError:\n            ctx.fail(f\"{value} is not a valid version string\")\n\n    # Look for the last git tag for the curren version\n    git = Git()\n    tag_pattern = ctx.params[\"tag_pattern\"]\n    versions = tag_analyzer(git.tags, tag_pattern, Version)\n\n    # User provided current version. Try to find a tag that match it.\n    if current_version:\n        for version in versions:\n            if version == current_version:\n                current_version = version\n                break\n    elif versions:\n        current_version = versions[0]\n\n    ctx.params[\"current_tag\"] = current_version.tag if current_version else None\n    ctx.params[\"versions\"] = versions\n\n    return current_version"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that a given string has all the required placeholders.", "response": "def label_pattern_option_validator(ctx, param, value):\n    \"\"\"Checks that a given string has all the required placeholders. The\n    possible placeholders are **{type}**, **{scope}** and **{subject}**.\n\n    ``{type}`` are always required, ``{scope}`` is optional and\n    ``{subject}`` are required only when ``label_position`` option is set to\n    ``header``.\n\n    If the pattern is invalid, raises :class:`click.UsageError`.\n    \"\"\"\n\n    missings = []\n    label_position = ctx.params[\"label_position\"]\n\n    if \"{type}\" not in value:\n        missings.append(style(\"{type}\", fg=\"red\", bold=True))\n\n    if label_position == \"header\" and \"{subject}\" not in value:\n        missings.append(style(\"{subject}\", fg=\"red\", bold=True))\n\n    if missings:\n        message = \"\\n\"\n\n        for placeholder in missings:\n            message += f\"  {x_mark} Missing {placeholder} placeholder.\\n\"\n\n        ctx.fail(message)\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef release(\n    ctx,\n    bump,\n    bump_type,\n    commit_flag,\n    message,\n    tag_flag,\n    confirm_flag,\n    changelog_file,\n    files,\n    label_pattern,\n    label_position,\n    tag_pattern,\n    current_version,\n    stage,\n    merge_pre,\n    current_tag=None,\n    versions=None,\n):\n\n    \"\"\"Release a new version.\n\n    Determines the next version by inspecting commit messages, updates the\n    changelog, commit the changes and tag the repository with the new version.\n    \"\"\"\n    # If there isn't a current version, assume version 0.0.0\n    current_version = current_version or Version()\n\n    git = Git()\n    from_tag = current_tag.name if current_tag else None\n\n    # Delimiter of the block to be removed from the changelog file\n    remove_pre_chglog = None\n\n    # Look for the last final release version if the user want it\n    if merge_pre and current_version.stage != \"final\":\n        remove_pre_chglog = [current_version.string]\n\n        for version in versions:\n            if version.stage == \"final\":\n                from_tag = version.tag.name\n                remove_pre_chglog.append(version.string)\n                break\n\n    commit_list = git.log(_from=from_tag)\n\n    msg(f'{label(\"Current version\")} {current_version}')\n    msg(f'{label(\"Commits found\")} {len(commit_list)} since last release')\n\n    if not commit_list:\n        click.echo(\" \u203a Nothing to release.\")\n        ctx.exit()\n\n    semantic_commits = commit_analyzer(commit_list, label_pattern, label_position)\n\n    release_data = ReleaseDataTree(semantic_commits)\n\n    bump_version_to = None\n\n    # --bump, --major, --minor, --patch or commit message based version\n    # are taken into account only if the current version is in final stage.\n    if current_version.stage == \"final\":\n\n        # --bump have precedence over any of --major, --minor or --patch\n        bump_version_to = bump.string if bump else bump_type\n\n        # Any manual bump have precedence over commit message based versions.\n        bump_version_to = bump_version_to or release_data.bump_version_to\n\n    try:\n        new_version = get_next_version(current_version, bump_version_to, stage)\n    except ValueError as e:\n        ctx.fail(e)\n\n    if not new_version:\n        msg(\"The release of a lower versions is not supported for now.\")\n        ctx.abort()\n\n    new_tag_name = tag_pattern.format(version=new_version.string)\n\n    msg(f'{label(\"New version\")} {new_version}')\n    msg(f'{label(\"Changelog file\")} {changelog_file.name}')\n\n    # Messages about what tasks will be performed\n    msg(\"Braulio will perform the next tasks :\")\n    msg(f\"        Update {len(files) + 1} files.\", prefix=\"\")\n    msg(\"        Add a release commit.\", prefix=\"\", silence=not commit_flag)\n    msg(\n        f\"        Tag the repository with {new_tag_name}\",\n        prefix=\"\",\n        silence=not tag_flag,\n    )\n\n    msg(\"\", prefix=\"\")  # Print just a new line\n\n    if confirm_flag or click.confirm(f\"{prefix_mark}Continue?\"):\n\n        msg(\"Update changelog \", nl=False)\n\n        update_chglog(\n            changelog_file,\n            new_version=new_version,\n            current_version=current_version,\n            release_data=release_data,\n            remove=remove_pre_chglog,\n        )\n\n        msg(check_mark, prefix=\"\")\n\n        try:\n            update_files(files, str(current_version), str(new_version))\n        except ValueError as e:\n            click.echo(e)\n            ctx.abort()\n\n        if commit_flag:\n            message_args = {\"new_version\": new_version.string}\n\n            if \"{current_version}\" in message:\n                message_args[\"current_version\"] = current_version.string\n\n            commit_message = message.format(**message_args)\n\n            msg(f\"Add commit: {commit_message}\", nl=False)\n\n            files = [str(changelog_file)] + list(files)\n            git.commit(commit_message, files=files)\n            msg(f\" {check_mark}\", prefix=\"\")\n\n        if tag_flag:\n            msg(f\"Add tag {new_tag_name}\", nl=False)\n            git.tag(new_tag_name)\n            msg(f\" {check_mark}\", prefix=\"\")\n\n        if \"current_version\" in ctx.obj.cfg_file_options:\n            update_config_file(\"current_version\", new_version.string)\n\n        msg(f\"Version {new_version} released successfully\", suffix=\" \ud83c\udf89\")", "response": "Release a new version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef layout(self, indent='    '):\n\n\n\t\tself.__indent(self.head, indent)\n\t\tself.__indent(self.meta, indent)\n\t\tself.__indent(self.stylesheet, indent)\n\t\tself.__indent(self.header, indent)\n\t\tself.__indent(self.body, indent, initial=3)\n\t\tself.__indent(self.footer, indent)\n\t\tself.__indent(self.body_pre_docinfo, indent, initial=3)\n\t\tself.__indent(self.docinfo, indent)", "response": "This will indent each new tag in the body by given number of spaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing the intervention screen.", "response": "def main():\n    \"\"\"\n    Show the intervention screen.\n    \"\"\"\n    application = Application(sys.argv, ignore_close=not SKIP_FILTER)\n\n    platform.hide_cursor()\n\n    with open(resource_filename(__name__, 'intervention.css')) as css:\n        application.setStyleSheet(css.read())\n\n    # exec() is required for objc so we must use spawn\n    # multiprocessing.set_start_method('spawn')\n\n    # target = do_nothing\n\n    # if sys.platform == 'darwin' and not SKIP_FILTER:\n    #     from filters import filter_input\n    #     target = filter_input\n\n    # pool = multiprocessing.Pool(1)  # pylint: disable=not-callable\n\n    # def filter_input_done_cb(ignored):\n    #     application.closeAllWindows()\n\n    # result = pool.apply_async(target, callback=filter_input_done_cb)\n\n    # pylint: disable=unused-variable\n    @atexit.register\n    def exit_handler():\n        \"\"\"\n        Clean up.\n        \"\"\"\n        logging.info('atexit triggered')\n\n        platform.show_cursor()\n\n    #     # terminate the pool so we don't sit forever waiting on our get()\n    #     logging.info('Terminating pool...')\n    #     pool.terminate()\n\n    #     logging.info('Joining pool...')\n    #     pool.join()\n\n    #     logging.info('Retrieving result...')\n    #     try:\n    #         # raise any exceptions raised by the input filtering code\n    #         result.get(0)\n    #     except multiprocessing.TimeoutError:\n    #         logging.info('Timed out waiting for result.')\n\n    # def duration_reached():\n    #     logging.info('Duration reached, exiting...')\n\n    #     sys.exit(0)\n\n    # Run for DURATION and then exit\n    # QtCore.QTimer.singleShot(DURATION, duration_reached)\n\n    application.run()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a style name to an ansi escape code string.", "response": "def style_to_ansi_code(style):\n    \"\"\"\n    :param style: A style name\n    :type style: string\n    :returns: A string containing one or more ansi escape codes that are\n              used to render the given style.\n    :type return: string\n    \"\"\"\n    ret = ''\n    for attr_name in _styles[style]:\n        # allow stuff that has found it's way through ansi_code_pattern\n        ret += codes.get(attr_name, attr_name)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start_filesystem(mountpoint,\n                     config=None):  # pragma: no cover\n    \"\"\"\n    prgramatically mount this filesystem to some mount point\n    :param mountpoint:\n    :param config:\n    :return:\n    \"\"\"\n    if has_fuse:\n        if not config:\n            config = BrainStoreConfig()\n        FUSE(BrainStore(config), mountpoint, foreground=True)\n    else:\n        raise ImportError(err_str)", "response": "start a new filesystem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, path, mode):  # pragma: no cover\n        # print(\"create {}\".format(path))\n        now_time = time()\n        with self.attr_lock:\n            base = NoStat()\n            base.staged = True\n            base.st_mode = stat.S_IFREG | OBJ_PERMISSION\n            base.st_nlink = 1\n            base.st_size = -1\n            self.attr[path] = {TIMESTAMP_KEY: now_time,\n                               BASE_KEY: base,\n                               STAGED_KEY: BytesIO()}\n        return mode", "response": "Create a new file in the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite data to a file.", "response": "def write(self, path, data, offset, fh):  # pragma: no cover\n        \"\"\"\n        This is a readonly filesystem right now\n        \"\"\"\n        # print(\"write {}\".format(path))\n        with self.attr_lock:\n            base = self.attr[path][BASE_KEY]\n            staged = self.attr[path][STAGED_KEY]\n            if not staged.closed:\n                base.st_size += len(data)\n                staged.write(data)\n        return len(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _cleanup(self):  # pragma: no cover\n        need_to_delete = []  # can't delete from a dict while iterating\n        with self.attr_lock:\n            now_time = time()\n            for path in self.cache:\n                if now_time - self.attr[path][TIMESTAMP_KEY] >= MAX_CACHE_TIME:\n                    need_to_delete.append(path)\n            for path in need_to_delete:\n                del self.attr[path]\n                del self.cache[path]", "response": "Cleans up data that s been in the cache for a while\n        should be called from an async OS call like release? to not impact user\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate arguments and return a new object.", "response": "def validate_args(args):\n    '''\n    Apply custom validation and actions based on parsed arguments.\n\n    Parameters\n    ----------\n    args : argparse.Namespace\n        Result from ``parse_args`` method of ``argparse.ArgumentParser``\n        instance.\n\n    Returns\n    -------\n    argparse.Namespace\n        Reference to input ``args``, which have been validated/updated.\n    '''\n    logging.basicConfig(level=getattr(logging, args.log_level.upper()))\n\n    if getattr(args, 'command', None) == 'install':\n        if args.requirements_file and not args.requirements_file.isfile():\n            print >> sys.stderr, ('Requirements file not available: {}'\n                                    .format(args.requirements_file))\n            raise SystemExit(-1)\n        elif not args.plugin and not args.requirements_file:\n            print >> sys.stderr, ('Requirements file or at least one plugin '\n                                  'must be specified.')\n            raise SystemExit(-2)\n    if hasattr(args, 'server_url'):\n        logger.debug('Using MicroDrop index server: \"%s\"', args.server_url)\n        args.server_url = SERVER_URL_TEMPLATE % args.server_url\n    if all([args.plugins_directory is None,\n            args.config_file is None]):\n        args.plugins_directory = get_plugins_directory()\n    elif args.plugins_directory is None:\n        args.config_file = args.config_file.realpath()\n        args.plugins_directory = get_plugins_directory(config_path=\n                                                       args.config_file)\n    else:\n        args.plugins_directory = args.plugins_directory.realpath()\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of Event s detected from differences in state between the current snapshot and the Kindle Library.", "response": "def detect_events(self, max_attempts=3):\n        \"\"\"Returns a list of `Event`s detected from differences in state\n        between the current snapshot and the Kindle Library.\n\n        `books` and `progress` attributes will be set with the latest API\n        results upon successful completion of the function.\n\n        Returns:\n            If failed to retrieve progress, None\n            Else, the list of `Event`s\n        \"\"\"\n        # Attempt to retrieve current state from KindleAPI\n        for _ in xrange(max_attempts):\n            try:\n                with KindleCloudReaderAPI\\\n                        .get_instance(self.uname, self.pword) as kcr:\n                    self.books = kcr.get_library_metadata()\n                    self.progress = kcr.get_library_progress()\n            except KindleAPIError:\n                continue\n            else:\n                break\n        else:\n            return None\n\n        # Calculate diffs from new progress\n        progress_map = {book.asin: self.progress[book.asin].locs[1]\n                                                for book in self.books}\n        new_events = self._snapshot.calc_update_events(progress_map)\n\n        update_event = UpdateEvent(datetime.now().replace(microsecond=0))\n        new_events.append(update_event)\n\n        self._event_buf.extend(new_events)\n        return new_events"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies all outstanding Events to the internal state .", "response": "def commit_events(self):\n        \"\"\"Applies all outstanding `Event`s to the internal state\n        \"\"\"\n        # Events are sorted such that, when applied in order, each event\n        # represents a logical change in state. That is, an event never requires\n        # future events' data in order to be parsed.\n        # e.g. All ADDs must go before START READINGs\n        #      All START READINGs before all READs\n        for event in sorted(self._event_buf):\n            self.store.record_event(event)\n            self._snapshot.process_event(event)\n        self._event_buf = []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_registry_names(self, registry):\n        return ', '.join(\n            f.__name__ if not isinstance(f, tuple) else f[0].__name__\n            for f in getattr(self, registry, []))", "response": "Returns a string of functions names for a given registry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef receiver(self, func=None, json=False):\n        self.receivers.append((func, json))", "response": "Registers a receiver function\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sender(self, func, routing=None, routing_re=None):\n        if routing and not isinstance(routing, list):\n            routing = [routing]\n\n        if routing_re:\n            if not isinstance(routing_re, list):\n                routing_re = [routing_re]\n            routing_re[:] = [re.compile(r) for r in routing_re]\n\n        self.senders.append((func, routing, routing_re))", "response": "Registers a sender function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call_closers(self, client, clients_list):\n        for func in self.closers:\n            func(client, clients_list)", "response": "Calls closers callbacks with the given client and list of clients_list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes a message from the cache", "response": "def publish(self, message_type=ON_SEND, client_id=None, client_storage=None,\n                *args, **kwargs):\n        \"\"\"\n        Publishes a message\n        \"\"\"\n        self.publisher.publish(\n            message_type, client_id, client_storage, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the websocket server.", "response": "def run_websocket_server(self, host='localhost', port=9090, debug=False):\n        \"\"\"\n        Runs websocket server\n        \"\"\"\n        from .server import MeaseWebSocketServerFactory\n\n        websocket_factory = MeaseWebSocketServerFactory(\n            mease=self, host=host, port=port, debug=debug)\n        websocket_factory.run_server()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncrosses Validation Parameters: ----------- fitfunc : function A function that wraps the model/algorithm, has 1 data variable as input argument, and returns the estimated coefficients, model parameters, weights, etc. evalfunc : function A function pointer to an evaluation, fitness, cost, etc. function that returns an error, score, etc. metric data : ndarray The data i.e. target variable and predictors in one common python variable, e.g. `data=np.c_[y, X]` K : int Number of blocks idxmat : ndarray See below. If provided the block are not shuffled again. random_state : int For oxyba.block_idxmat_shuffle Returns: -------- errors : ndarray The CV errors per validation block (i.e. the result of the fitness function fo reach block) coeffs : ndarray The estimated coefficients for each training subsample (i.e. all blocks except the validation blocks) idxmat : ndarray The shuffled row indicies for each block. The row indicies assigned to each block are stored in the columns.", "response": "def crossvalidation_loop(fitfunc, evalfunc, data,\n                         K=None, idxmat=None, random_state=None):\n    \"\"\"Cross Validation\n\n    Parameters:\n    -----------\n    fitfunc : function\n        A function that wraps the model/algorithm, has 1 data\n        variable as input argument, and returns the estimated\n        coefficients, model parameters, weights, etc.\n\n    evalfunc : function\n        A function pointer to an evaluation, fitness, cost, etc.\n        function that returns an error, score, etc. metric\n\n    data : ndarray\n        The data i.e. target variable and predictors in one\n        common python variable, e.g. `data=np.c_[y, X]`\n\n    K : int\n        Number of blocks\n\n    idxmat : ndarray\n        See below. If provided the block are not shuffled again.\n\n    random_state : int\n        For oxyba.block_idxmat_shuffle\n\n    Returns:\n    --------\n    errors : ndarray\n        The CV errors per validation block\n        (i.e. the result of the fitness function fo reach block)\n\n    coeffs : ndarray\n        The estimated coefficients for each training subsample\n        (i.e. all blocks except the validation blocks)\n\n    idxmat : ndarray\n        The shuffled row indicies for each block. The row indicies\n        assigned to each block are stored in the columns.\n\n    \"\"\"\n    import oxyba as ox\n    import numpy as np\n    import warnings\n\n    # shuffle K blocks from the N row indicies\n    if idxmat is None:\n        if K is None:\n            raise Exception('Number of blocks K>1 is required')\n        N = data.shape[0]  # number of observations\n        idxmat, _ = ox.block_idxmat_shuffle(N, K, random_state)\n    else:\n        K = idxmat.shape[1]\n\n    # display warnings\n    if K < 30:\n        warnings.warn((\n            \"The number of blocks is K<30 and will supply an \"\n            \"insufficient number of for t-Test (model comparision) \"\n            \"in oxyba.crossvalidation_stats! K=40 is suggested.\"))\n    if int(idxmat.shape[0]) < 30:\n        warnings.warn((\n            \"The blocksize is int(N/K)<30 and the fitness score of \"\n            \"the validation blocks might be insufficient.\"))\n\n    # declare lists\n    errors = []\n    coeffs = []\n\n    # loop over all blocks\n    for b in range(K):\n        # temporary store indicies when using block b for validation\n        idx_train, idx_valid = ox.block_idxmat_sets(idxmat, b)\n\n        # estimate with all blocks that are not block b\n        c = fitfunc(data[idx_train, :])\n        coeffs.append(c)\n\n        # compute error of validation block\n        e = evalfunc(data[idx_valid, :], c)\n        errors.append(e)\n\n    # done\n    return np.array(errors), np.array(coeffs), idxmat"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stackclimber(height=0):           # http://stackoverflow.com/a/900404/48251\n    caller = inspect.stack()[height+1]\n    scope = caller[0].f_globals\n    path = scope['__name__'].split('__main__')[0].strip('.')\n    if path == '':\n        if scope['__package__']:\n            path = scope['__package__']\n        else:\n            path = os.path.basename(sys.argv[0]).split('.')[0]\n    return path", "response": "Return the name of the caller s module."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflattens nested lists to single - level list does not split strings", "response": "def flatten_list(l):\n    \"\"\" Nested lists to single-level list, does not split strings\"\"\"\n    return list(chain.from_iterable(repeat(x,1) if isinstance(x,str) else x for x in l))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef si_prefix(value):\n    #standard si prefixes\n    prefixes = ['y','z','a','f','p','n','u','m','','k','M','G','T','P','E','Z','Y']\n\n    from math import log\n    #closest 1000 exponent\n    if value == 0: return (value, \"\")\n    exp = int(log(value,1000)//1) + 8\n    if exp < 0: exp = 0\n    if exp > 16: exp = 16\n    return (value*1000**(-(exp-8)), prefixes[exp])", "response": "A standard si prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef levenshtein_distance_metric(a, b):\n    return (levenshtein_distance(a, b) / (2.0 * max(len(a), len(b), 1)))", "response": "Compute the Levenshtein distance metric."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next_tokens_in_sequence(observed, current):\n    idx = 0\n    for word in current:\n        if observed[idx:].count(word) != 0:\n            found_pos = observed.index(word, idx)\n            idx = max(idx + 1, found_pos)\n        # otherwise, don't increment idx\n    if idx < len(observed):\n        return observed[idx:]\n    else:\n        return []", "response": "Given the observed list of tokens and the current list of tokens finds out what should be next emitted word\n "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef choose(n, k):\n    if 0 <= k <= n:\n        ntok = 1\n        ktok = 1\n        for t in xrange(1, min(k, n - k) + 1):\n            ntok *= n\n            ktok *= t\n            n -= 1\n        return ntok // ktok\n    else:\n        return 0", "response": "A fast way to calculate binomial coefficients by Andrew Dalke."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncoerces a value to an interval cell or subclass.", "response": "def coerce(value):\n        \"\"\"\n        Takes a number (float, int) or a two-valued integer and returns the\n        [low, high] in the standard interval form\n        \"\"\"\n        is_number = lambda x: isinstance(x, (int, float, complex)) #is x an instance of those things\n        if isinstance(value, IntervalCell) or issubclass(value.__class__,IntervalCell): \n            #if intervalcell or subclass, return the subclass\n            return value\n        elif is_number(value):\n            return IntervalCell(value, value)\n        elif hasattr(value, 'low') and hasattr(value, 'high'):\n            # duck type\n            assert value.low <= value.high, \"Invalid low/high in %s\" % str(value)\n            return value\n        elif isinstance(value, (list, tuple)) and all(map(is_number, value)):\n            if len(value) == 1:\n                low, high = value[0], value[0]\n            elif len(value) == 2:\n                low, high = value\n            else:\n                low, high = min(value), max(value)\n            if high < low:\n                raise Contradiction(\"Low must be lte High\") \n            return IntervalCell(low, high)\n        else:\n            raise Exception(\"Don't know how to coerce %s\" % (type(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if self and other can be coexisted False otherwise.", "response": "def is_contradictory(self, other):\n        \"\"\"\n        Whether other and self can coexist\n        \"\"\"\n        other = IntervalCell.coerce(other)\n        assert other.low <= other.high, \"Low must be <= high\"\n        if max(other.low, self.low) <= min(other.high, self.high):\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_entailed_by(self, other):\n        other = IntervalCell.coerce(other)\n        return other.low >= self.low and other.high <= self.high", "response": "Return True if self is entailed by other."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_equal(self, other):\n        other = IntervalCell.coerce(other)\n        return other.low == self.low and other.high == self.high", "response": "Check if two intervals are the same as this one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge(self, other):\n        other = IntervalCell.coerce(other)\n        if self.is_equal(other):\n            # pick among dependencies\n            return self\n        elif other.is_entailed_by(self):\n            return self\n        elif self.is_entailed_by(other):\n            self.low, self.high = other.low, other.high\n        elif self.is_contradictory(other):\n            #import traceback\n            #for line in traceback.format_stack(): print line.strip()\n\n            raise Contradiction(\"Cannot merge [%0.2f, %0.2f] with [%0.2f, %0.2f]\" \\\n                    % (self.low, self.high, other.low, other.high))\n        else:\n            # information in both\n            self.low = max(self.low, other.low)\n            self.high = min(self.high, other.high)\n        return self", "response": "Merges two intervals into this one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map(self, other, function):\n        other = IntervalCell.coerce(other)\n        # check the arity of the function\n        import inspect\n        arity = len(inspect.getargspec(function).args)\n\n        if arity == 2:\n            combos = [function(self.low, other.low),\n                      function(self.low, other.high),\n                      function(self.high, other.low),\n                      function(self.high, other.high)]\n            return IntervalCell(min(combos), max(combos))\n        else:\n            raise Exception(\"Cannot apply function of arity %i \" % (arity))", "response": "Applies a mathematic function to the interval arithmetic template."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_latex(self):\n        if self.low == self.high:\n            if self.low * 10 % 10 == 0:\n                return \"{0:d}\".format(int(self.low))\n            else:\n                return \"{0:0.2f}\".format(self.low)\n        else:\n            t = \"\"\n            if self.low == -np.inf:\n                t += r\"(-\\infty, \"\n            elif self.low * 10 % 10 == 0:\n                t += r\"[{0:d}, \".format(int(self.low))\n            else:\n                t += r\"[{0:0.2f}, \".format(self.low)\n            if self.high == np.inf:\n                t += r\"\\infty)\"\n            elif self.high * 10 % 10 == 0:\n                t += r\"{0:d}]\".format(int(self.high))\n            else:\n                t += r\"{0:0.2f}]\".format(self.high)\n            return t", "response": "Returns an interval representation of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    args = parse_respect_args(sys.argv[1:])\n    if validate_username(args['<username>']):\n        print(\"processing...\")\n    else:\n        print(\"@\"+args['<username>'], \"is not a valid username.\")\n        print(\"Username may only contain alphanumeric ASCII characters or \"\n              \"dashes and cannot begin with a dash.\")\n        return\n    try:\n        r = requests.get(urljoin(GITHUB_USERS, args['<username>']))\n    except ConnectionErrorException as e:\n        print('Connection Error from requests. Request again, please.')\n        print(e)\n\n    if r.status_code == 404 or r.status_code == 403:\n        session = login(401, args=args)\n        return dispatch(args, r, session)\n\n    elif r.status_code == 200:\n        return dispatch(args, response=r)\n    else:\n        raise UnknownStausCodeException", "response": "This is the main entry point for the getRespect command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _comment_system_for_file(contents):\n    if contents[0] == \"#\":\n        return FileCommentSystem(begin=\"#\", middle=\"\", end=\"\", single=\"#\")\n    elif contents[:2] == \"/*\":\n        return FileCommentSystem(begin=\"/*\", middle=\"*\", end=\"*/\", single=\"//\")\n    elif contents[:2] == \"//\":\n        return FileCommentSystem(begin=\"//\", middle=\"//\", end=\"\", single=\"//\")\n    elif contents[:3] == \"rem\":\n        return FileCommentSystem(begin=\"rem\",\n                                 middle=\"rem\",\n                                 end=\"\",\n                                 single=\"rem\")\n    else:\n        raise RuntimeError(\"Couldn't detect comment \"\n                           \"system from {0}\".format(contents[:3]))", "response": "For file contents return the comment system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _split_line_with_offsets(line):\n    for delimiter in re.finditer(r\"[\\.,:\\;](?![^\\s])\", line):\n        span = delimiter.span()\n        line = line[:span[0]] + \" \" + line[span[1]:]\n\n    for delimiter in re.finditer(r\"[\\\"'\\)\\]\\}>](?![^\\.,\\;:\\\"'\\)\\]\\}>\\s])\",\n                                 line):\n        span = delimiter.span()\n        line = line[:span[0]] + \" \" + line[span[1]:]\n\n    for delimiter in re.finditer(r\"(?<![^\\.,\\;:\\\"'\\(\\[\\{<\\s])[\\\"'\\(\\[\\{<]\",\n                                 line):\n        span = delimiter.span()\n        line = line[:span[0]] + \" \" + line[span[1]:]\n\n    # Treat hyphen separated words as separate words\n    line = line.replace(\"-\", \" \")\n\n    # Remove backticks\n    line = line.replace(\"`\", \" \")\n\n    for match in re.finditer(r\"[^\\s]+\", line):\n        content = match.group(0)\n        if content.strip() != \"\":\n            yield (match.span()[0], content)", "response": "Split a line by delimiter but yield tuples of word and offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all words in dictionary file as set.", "response": "def read_dictionary_file(dictionary_path):\n    \"\"\"Return all words in dictionary file as set.\"\"\"\n    try:\n        return _user_dictionary_cache[dictionary_path]\n    except KeyError:\n        if dictionary_path and os.path.exists(dictionary_path):\n            with open(dictionary_path, \"rt\") as dict_f:\n                words = set(re.findall(r\"(\\w[\\w']*\\w|\\w)\",\n                                       \" \".join(dict_f.read().splitlines())))\n                return words\n\n        return set()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef valid_words_set(path_to_user_dictionary=None,\n                    user_dictionary_words=None):\n    \"\"\"Get a set of valid words.\n\n    If :path_to_user_dictionary: is specified, then the newline-separated\n    words in that file will be added to the word set.\n    \"\"\"\n    def read_file(binary_file):\n        \"\"\"Read a binary file for its text lines.\"\"\"\n        return binary_file.read().decode(\"ascii\").splitlines()\n\n    try:\n        valid = _valid_words_cache[path_to_user_dictionary]\n        return valid\n    except KeyError:\n        words = set()\n        with resource_stream(\"polysquarelinter\", \"en_US.txt\") as words_file:\n            words |= set([\"\".join(l).lower() for l in read_file(words_file)])\n\n        if path_to_user_dictionary:\n            # Add both case-sensitive and case-insensitive variants\n            # of words in user dictionary as they may be checked as\n            # though they are a regular word and a technical word.\n            words |= set([w.lower() for w in user_dictionary_words])\n            words |= user_dictionary_words\n\n        _valid_words_cache[path_to_user_dictionary] = words\n        return words", "response": "Get a set of valid words."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a word graph file and open it in memory.", "response": "def _create_word_graph_file(name, file_storage, word_set):\n    \"\"\"Create a word graph file and open it in memory.\"\"\"\n    word_graph_file = file_storage.create_file(name)\n    spelling.wordlist_to_graph_file(sorted(list(word_set)),\n                                    word_graph_file)\n    return copy_to_ram(file_storage).open_file(name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _spellchecker_for(word_set,\n                      name,\n                      spellcheck_cache_path=None,\n                      sources=None):\n    \"\"\"Get a whoosh spellchecker for :word_set:.\n\n    The word graph for this spellchecker will be stored on-disk with\n    the unique-name :name: in :spellcheck_cache_path:, if it exists.\n    This allows for much faster loading of word graphs after they have been\n    pre-populated.\n\n    :sources: is a list of filenames which will be checked to see if they\n    are newer than the stored word graph. If they are newer, then the word\n    graph gets repopulated.\n    \"\"\"\n    assert \"/\" not in name and \"\\\\\" not in name\n\n    if _spellchecker_cache.get(name, None) is not None:\n        return _spellchecker_cache[name].corrector\n\n    # Check the modification time of all the paths in :sources: to see\n    # if they've been modified since the cache file was created. If so,\n    # delete the cache file. This will cause it to be regenerated.\n    #\n    # Note that this relies on an implementation detail in whoosh, namely\n    # that the cache file is always stored at spellcheck_cache_path/name.\n    if spellcheck_cache_path:\n\n        # Ensure that the directory has been created\n        try:\n            os.makedirs(spellcheck_cache_path)\n        except OSError as error:\n            if error.errno != errno.EEXIST:  # suppress(PYC90)\n                raise error\n\n        graph_path = os.path.realpath(spellcheck_cache_path)\n        file_storage = FileStorage(graph_path)\n\n        preexisting_cache = os.path.abspath(os.path.join(spellcheck_cache_path,\n                                                         name))\n        if os.path.exists(preexisting_cache):\n            cache_mtime = os.path.getmtime(preexisting_cache)\n            for source in sources:\n                source_path = os.path.realpath(source)\n                if not os.path.exists(source_path):\n                    continue\n\n                if os.path.getmtime(source_path) > cache_mtime:\n                    file_storage.delete_file(name)\n                    break\n\n        try:\n            word_graph = copy_to_ram(file_storage).open_file(name)\n        except (IOError, NameError):\n            word_graph = _create_word_graph_file(name, file_storage, word_set)\n\n    else:\n        ram_storage = RamStorage()\n        word_graph = _create_word_graph_file(name, ram_storage, word_set)\n\n    reader = fst.GraphReader(word_graph)\n    corrector = spelling.GraphCorrector(reader)\n    _spellchecker_cache[name] = SpellcheckerCacheEntry(corrector, reader)\n    return corrector", "response": "Get a whoosh spellchecker for a given word set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_nonspellcheckable_tokens(line, block_out_regexes=None):\n    all_block_out_regexes = [\n        r\"[^\\s]*:[^\\s]*[/\\\\][^\\s]*\",\n        r\"[^\\s]*[/\\\\][^\\s]*\",\n        r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]+\\b\"\n    ] + (block_out_regexes or list())\n\n    for block_regex in all_block_out_regexes:\n        for marker in re.finditer(block_regex, line):\n            spaces = \" \" * (marker.end() - marker.start())\n            line = line[:marker.start()] + spaces + line[marker.end():]\n\n    return line", "response": "Return line with paths urls and emails filtered out."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all contents in spellcheckable chunks from contents.", "response": "def _shadow_contents_from_chunks(contents, chunks, block_out_regexes=None):\n    \"\"\"Remove all contents in spellcheckable :chunks: from contents.\"\"\"\n    shadow_contents = [list(l) for l in contents]\n    for chunk in chunks:\n        char_offset = chunk.column\n        line_offset = 0\n\n        for index, line in enumerate(chunk.data):\n            # Block out entire chunk range from shadow_contents\n            for character_in_line in range(0, len(line)):\n                shadow_line = chunk.line + line_offset\n                shadow_char = char_offset + character_in_line\n                shadow_contents[shadow_line][shadow_char] = 0\n\n            # Also block out certain regexps from this chunk\n            line = filter_nonspellcheckable_tokens(line,\n                                                   block_out_regexes)\n            chunk.data[index] = line\n\n            line_offset += 1\n            char_offset = 0\n\n    return shadow_contents"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _chunk_from_ranges(contents_lines,\n                       start_line_index,\n                       start_column_index,\n                       end_line_index,\n                       end_column_index):\n    \"\"\"Create a _ChunkInfo from a range of lines and columns.\n\n    :contents_lines: is the raw lines of a file.\n    \"\"\"\n    # If the start and end line are the same we have to compensate for\n    # that by subtracting start_column_index from end_column_index\n    if start_line_index == end_line_index:\n        end_column_index -= start_column_index\n\n    lines = contents_lines[start_line_index:end_line_index + 1]\n    lines[0] = lines[0][start_column_index:]\n    lines[-1] = lines[-1][:end_column_index]\n\n    return _ChunkInfo(start_line_index,\n                      start_column_index,\n                      lines)", "response": "Create a _ChunkInfo from a range of lines and columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrue if token is at column.", "response": "def _token_at_col_in_line(line, column, token, token_len=None):\n    \"\"\"True if token is at column.\"\"\"\n    if not token_len:\n        token_len = len(token)\n\n    remaining_len = len(line) - column\n\n    return (remaining_len >= token_len and\n            line[column:column + token_len] == token)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _maybe_append_chunk(chunk_info, line_index, column, contents, chunks):\n    if chunk_info:\n        chunks.append(_chunk_from_ranges(contents,\n                                         chunk_info[0],\n                                         chunk_info[1],\n                                         line_index,\n                                         column))", "response": "Append a chunk_info to the list of chunks if it is set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_spellcheckable_chunks(contents,\n                                comment_system):\n    \"\"\"Given some contents for a file, find chunks that can be spellchecked.\n\n    This applies the following rules:\n     1. If the comment system comments individual lines, that whole line\n        can be spellchecked from the point of the comment\n     2. If a comment-start marker or triple quote is found, keep going\n        until a comment end marker or matching triple quote is found.\n     3. In both cases, ignore anything in triple backticks.\n    \"\"\"\n    state = InTextParser()\n    comment_system_transitions = CommentSystemTransitions(comment_system)\n\n    chunks = []\n    for line_index, line in enumerate(contents):\n        column = 0\n        line_len = len(line)\n        escape_next = False\n\n        # We hit a new line. If we were waiting until the end of the line\n        # then add a new chunk in here\n        (state,\n         column_delta,\n         chunk_info) = state.get_transition(line,\n                                            line_index,\n                                            0,\n                                            False,\n                                            comment_system_transitions)\n        _maybe_append_chunk(chunk_info,\n                            line_index - 1,\n                            len(contents[line_index - 1]),\n                            contents,\n                            chunks)\n        column += column_delta\n\n        while column < line_len:\n            # Check if the next character should be considered as escaped. That\n            # only happens if we are not escaped and the current character is\n            # a backslash.\n            is_escaped = escape_next\n            escape_next = not is_escaped and line[column] == \"\\\\\"\n\n            (state,\n             column_delta,\n             chunk_info) = state.get_transition(line,\n                                                line_index,\n                                                column,\n                                                is_escaped,\n                                                comment_system_transitions)\n\n            _maybe_append_chunk(chunk_info,\n                                line_index,\n                                column,\n                                contents,\n                                chunks)\n            column += column_delta\n\n    last_line_index = len(contents) - 1\n    (state,\n     column_delta,\n     chunk_info) = state.get_transition(contents[-1],\n                                        last_line_index,\n                                        len(contents[-1]),\n                                        False,\n                                        comment_system_transitions,\n                                        eof=True)\n    _maybe_append_chunk(chunk_info,\n                        last_line_index,\n                        len(contents[last_line_index]),\n                        contents,\n                        chunks)\n\n    return chunks", "response": "Given some contents for a file find all the spellcheckable chunks that can be spellchecked."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _split_into_symbol_words(sym):\n    punc = r\"[\\s\\-\\*/\\+\\.,:\\;=\\)\\(\\[\\]\\{\\}<>\\|\\?&\\^\\$@]\"\n    words = [w.strip() for w in re.split(punc, sym)]\n    return words", "response": "Split a technical looking word into a set of symbols."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a set of technical words from a list of shadow contents.", "response": "def technical_words_from_shadow_contents(shadow_contents):\n    \"\"\"Get a set of technical words from :shadow_contents:.\n\n    :shadow_contents: is an array of shadow contents, as returned by\n    spellcheckable_and_shadow_contents.\n    \"\"\"\n    technical_words = set()\n    for line in shadow_contents:\n        # \"Fix up\" the shadow line by replacing zeros with spaces.\n        line = \"\".join([(lambda c: \" \" if c == 0 else c)(c) for c in line])\n        for sym in _split_into_symbol_words(line):\n            if len(sym) and re.compile(_VALID_SYMBOL_WORDS).match(sym):\n                technical_words |= set([sym])\n\n    return technical_words"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _error_if_word_invalid(word,\n                           valid_words_dictionary,\n                           technical_words_dictionary,\n                           line_offset,\n                           col_offset):\n    \"\"\"Return SpellcheckError if this non-technical word is invalid.\"\"\"\n    word_lower = word.lower()\n    valid_words_result = valid_words_dictionary.corrections(word_lower)\n\n    if technical_words_dictionary:\n        technical_words_result = technical_words_dictionary.corrections(word)\n    else:\n        # No technical words available to make an otherwise invalid\n        # result value.\n        technical_words_result = Dictionary.Result(False, list())\n\n    if not valid_words_result.valid and not technical_words_result.valid:\n        return SpellcheckError(word,\n                               line_offset,\n                               col_offset,\n                               valid_words_result.suggestions,\n                               SpellcheckError.InvalidWord)", "response": "Return SpellcheckError if this non - technical word is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns SpellcheckError if this symbol is not used in the code.", "response": "def _error_if_symbol_unused(symbol_word,\n                            technical_words_dictionary,\n                            line_offset,\n                            col_offset):\n    \"\"\"Return SpellcheckError if this symbol is not used in the code.\"\"\"\n    result = technical_words_dictionary.corrections(symbol_word,\n                                                    distance=5,\n                                                    prefix=0)\n    if not result.valid:\n        return SpellcheckError(symbol_word,\n                               line_offset,\n                               col_offset,\n                               result.suggestions,\n                               SpellcheckError.TechnicalWord)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spellcheck_region(region_lines,\n                      valid_words_dictionary=None,\n                      technical_words_dictionary=None,\n                      user_dictionary_words=None):\n    \"\"\"Perform spellcheck on each word in :region_lines:.\n\n    Each word will be checked for existence in :valid_words_dictionary:.\n    If it is not in :valid_words_dictionary: then corrections will be\n    suggested.\n\n    If the word isn't one which is an ordinary word, then it will be checked\n    against the available symbols in :technical_words_dictionary: . If it is\n    not in :technical_words_dictionary: then corrections will be suggested.\n    \"\"\"\n    user_dictionary_words = user_dictionary_words or set()\n    spellcheckable_words_regex = re.compile(_SPELLCHECKABLE_WORDS)\n\n    line_offset = 0\n    for line in region_lines:\n        for col_offset, word in _split_line_with_offsets(line):\n            word = word.strip()\n            if len(word) == 0:\n                continue\n\n            # If this word exists in the user dictionary, then always allow\n            # it, even if it might be technical in nature\n            if word in user_dictionary_words:\n                continue\n\n            if (valid_words_dictionary and\n                    spellcheckable_words_regex.match(word)):\n                error = _error_if_word_invalid(word,\n                                               valid_words_dictionary,\n                                               technical_words_dictionary,\n                                               line_offset,\n                                               col_offset)\n\n                if error:\n                    yield error\n\n            # Check for symbols appearing in comments or\n            # docstrings.\n            elif technical_words_dictionary:\n                for symbol_word in _split_into_symbol_words(word):\n                    if not re.compile(_VALID_SYMBOL_WORDS).match(symbol_word):\n                        continue\n\n                    error = _error_if_symbol_unused(symbol_word,\n                                                    technical_words_dictionary,\n                                                    line_offset,\n                                                    col_offset)\n\n                    if error:\n                        yield error\n\n        line_offset += 1", "response": "Spellcheck a set of words in a region."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the new state of the comment parser.", "response": "def from_text(self, line, line_index, column, is_escaped):\n        \"\"\"Return the new state of the comment parser.\"\"\"\n        begin = self._begin\n        end = self._end\n        single = self._single\n\n        single_len = len(single)\n        start_len = len(begin)\n\n        if _token_at_col_in_line(line, column, single, single_len):\n            return (STATE_IN_COMMENT,\n                    (line_index, column + single_len),\n                    ParserState.EOL)\n        elif _token_at_col_in_line(line, column, begin, start_len):\n            return (STATE_IN_COMMENT,\n                    (line_index, column + single_len),\n                    end)\n        elif ((_token_at_col_in_line(line, column, \"\\\"\") or\n               _token_at_col_in_line(line, column, \"'\")) and\n              not _is_escaped(line, column, is_escaped)):\n            # Check here to see whether this is a quote or if this\n            # is a spellcheckable line\n            if (_token_at_col_in_line(line, column, \"\\\"\\\"\\\"\") or\n                    _token_at_col_in_line(line, column, \"'''\")):\n                return (STATE_IN_COMMENT,\n                        (line_index, column + 3),\n                        line[column:column + 3])\n            else:\n                return (STATE_IN_QUOTE,\n                        (line_index, column + 1),\n                        line[column:column + 1])\n\n        return (STATE_IN_TEXT,\n                (0, 0),\n                None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a base ParserState.", "response": "def get_transition(self,  # suppress(too-many-arguments)\n                       line,\n                       line_index,\n                       column,\n                       is_escaped,\n                       comment_system_transitions,\n                       eof=False):\n        \"\"\"Return a parser state, a move-ahead amount, and an append range.\n\n        If this parser state should terminate and return back to\n        the TEXT state, then return that state and also any corresponding\n        chunk that would have been yielded as a result.\n        \"\"\"\n        raise NotImplementedError(\"\"\"Cannot instantiate base ParserState\"\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting transition from InTextParser.", "response": "def get_transition(self,  # suppress(too-many-arguments)\n                       line,\n                       line_index,\n                       column,\n                       is_escaped,\n                       comment_system_transitions,\n                       eof=False):\n        \"\"\"Get transition from InTextParser.\"\"\"\n        parser_transition = {\n            STATE_IN_COMMENT: InCommentParser,\n            STATE_IN_QUOTE: InQuoteParser\n        }\n\n        (state,\n         start_state_from,\n         waiting_until) = comment_system_transitions.from_text(line,\n                                                               line_index,\n                                                               column,\n                                                               is_escaped)\n\n        # We need to move ahead by a certain number of characters\n        # if we hit a new state\n        if state != STATE_IN_TEXT:\n            return (parser_transition[state](start_state_from,\n                                             waiting_until),\n                    start_state_from[1] - column,\n                    None)\n        else:\n            return (self, 1, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_transition(self,  # suppress(too-many-arguments)\n                       line,\n                       line_index,\n                       column,\n                       is_escaped,\n                       comment_system_transitions,\n                       eof=False):\n        \"\"\"Get transition from DisabledParser.\"\"\"\n        # If we are at the beginning of a line, to see if we should\n        # disable processing from this point onward and get out - this will\n        # happen if we reach the end of some comment block that doesn't have\n        # an explicit end marker. We can't detect line endings here because\n        # we want a disabled region to continue across multiple lines.\n        if (column == 0 and\n                comment_system_transitions.should_terminate_now(\n                    line,\n                    self._resume_waiting_for\n                )):\n            return (InTextParser(), 0, None)\n\n        # Need to be a bit careful here, since we need to check what the\n        # disabled parser was waiting for and disable on that, too.\n        if (_token_at_col_in_line(line,\n                                  column,\n                                  \"```\",\n                                  3) and\n                not _is_escaped(line, column, is_escaped)):\n            # Hit a disable token, so we resume the old parser\n            return (self._resume_parser((line_index, column + 3),\n                                        self._resume_waiting_for),\n                    3,\n                    None)\n        elif self._resume_waiting_for != ParserState.EOL:\n            wait_until_len = len(self._resume_waiting_for)\n            if (_token_at_col_in_line(line,\n                                      column,\n                                      self._resume_waiting_for,\n                                      wait_until_len) and\n                    not _is_escaped(line, column, is_escaped)):\n\n                # Skip ahead to end of this token\n                return (InTextParser(),\n                        len(self._waiting_until),\n                        None)\n        elif eof:\n            # We hit the end of the file and were still in a comment\n            # state. Grab everything up to here.\n            return (InTextParser(), 0, None)\n\n        # Move ahead by one character otherwise\n        return (self, 1, None)", "response": "Get transition from DisabledParser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_transition(self,  # suppress(too-many-arguments)\n                       line,\n                       line_index,\n                       column,\n                       is_escaped,\n                       comment_system_transitions,\n                       eof=False):\n        \"\"\"Get transition from InCommentParser.\"\"\"\n        del comment_system_transitions\n\n        if (_token_at_col_in_line(line,\n                                  column,\n                                  \"```\",\n                                  3) and\n                not _is_escaped(line, column, is_escaped)):\n            # Hit a disable token, so resume the last parser\n            return (DisabledParser((line_index, column + 3),\n                                   self.__class__,\n                                   self._waiting_until), 3, self._started_at)\n        elif self._waiting_until != ParserState.EOL:\n            wait_until_len = len(self._waiting_until)\n            if (_token_at_col_in_line(line,\n                                      column,\n                                      self._waiting_until,\n                                      wait_until_len) and\n                    not _is_escaped(line, column, is_escaped)):\n\n                # Skip ahead to end of this token\n                return (InTextParser(),\n                        len(self._waiting_until),\n                        self._started_at)\n        elif self._waiting_until == ParserState.EOL and column == 0:\n            # We hit a new line and the state ends here. Return\n            # corresponding state\n            return (InTextParser(), 0, self._started_at)\n        elif eof:\n            # We hit the end of the file and were still in a comment\n            # state. Grab everything up to here.\n            return (InTextParser(), 0, self._started_at)\n\n        # Move ahead by one character otherwise\n        return (self, 1, None)", "response": "Get the next state transition from the parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets transition from InQuoteParser.", "response": "def get_transition(self,  # suppress(too-many-arguments)\n                       line,\n                       line_index,\n                       column,\n                       is_escaped,\n                       *args,\n                       **kwargs):\n        \"\"\"Get transition from InQuoteParser.\"\"\"\n        del line_index\n        del args\n        del kwargs\n\n        wait_until_len = len(self._waiting_until)\n        if (_token_at_col_in_line(line,\n                                  column,\n                                  self._waiting_until,\n                                  wait_until_len) and\n                not _is_escaped(line, column, is_escaped)):\n            return (InTextParser(), 1, None)\n\n        return (self, 1, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the corrections for a word.", "response": "def corrections(self, word, prefix=1, distance=2):\n        \"\"\"Get corrections for word, if word is an invalid word.\n\n        :prefix: is the number of characters the prefix of the word must\n        have in common with the suggested corrections.\n\n        :distance: is the character distance the corrections may have between\n        the input word. This limits the number of available corrections\n        but decreases the correction search space.\n\n        The return value of this function is a Result tuple, with the\n        :valid: member indicating whether the input word is a valid one and\n        :suggestions: member containing a list of suggestions.\n        \"\"\"\n        if word not in self._words:\n            return Dictionary.Result(False,\n                                     self._corrector.suggest(word,\n                                                             prefix=prefix,\n                                                             maxdist=distance))\n        else:\n            return Dictionary.Result(True, list())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_dom(data):\n    if not isinstance(data, dhtmlparser.HTMLElement):\n        data = dhtmlparser.parseString(\n            utils.handle_encodnig(data)\n        )\n\n    dhtmlparser.makeDoubleLinked(data)\n\n    return data", "response": "Creates doublelinked DOM from data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _locate_element(dom, el_content, transformer=None):\n    return dom.find(\n        None,\n        fn=utils.content_matchs(el_content, transformer)\n    )", "response": "Find element containing el_content in dom."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind location of elements matching patterns specified in matches.", "response": "def _match_elements(dom, matches):\n    \"\"\"\n    Find location of elements matching patterns specified in `matches`.\n\n    Args:\n        dom (obj): HTMLElement DOM tree.\n        matches (dict): Structure: ``{\"var\": {\"data\": \"match\", ..}, ..}``.\n\n    Returns:\n        dict: Structure: ``{\"var\": {\"data\": HTMLElement_obj, ..}, ..}``\n    \"\"\"\n    out = {}\n    for key, content in matches.items():\n        pattern = content[\"data\"].strip()\n        if \"\\n\" in pattern:\n            pattern = pattern.split()\n            transformer = lambda x: x.strip().split()\n        else:\n            transformer = lambda x: x.strip()\n\n        matching_elements = _locate_element(\n            dom,\n            pattern,\n            transformer=transformer\n        )\n\n        not_found_msg = content.get(\"notfoundmsg\", \"\").replace(\"$name\", key)\n        if not not_found_msg.strip():\n            not_found_msg = \"Can't locate variable '%s' with content '%s'!\" % (\n                key,\n                pattern,\n            )\n        content[\"notfoundmsg\"] = not_found_msg\n\n        # in case of multiple elements, find only elements with propert tagname\n        tagname = content.get(\"tagname\", \"\").strip().lower()\n        if tagname:\n            matching_elements = filter(\n                lambda x: x.getTagName().strip().lower() == tagname,\n                matching_elements\n            )\n\n        if not matching_elements:\n            raise UserWarning(not_found_msg)\n\n        if len(matching_elements) > 1:\n            raise UserWarning(\n                \"Ambigious content '%s'!\" % content\n                + \"Content was found in multiple elements!\"\n            )\n\n        out[key] = matching_elements[0]\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _collect_paths(element):\n    output = []\n\n    # look for element by parameters - sometimes the ID is unique\n    path = vectors.el_to_path_vector(element)\n    root = path[0]\n    params = element.params if element.params else None\n    match = root.find(element.getTagName(), params)\n\n    if len(match) == 1:\n        output.append(\n            PathCall(\"find\", 0, [element.getTagName(), params])\n        )\n\n    # look for element by neighbours\n    output.extend(path_patterns.neighbours_pattern(element))\n\n    # look for elements by patterns - element, which parent has tagname, and\n    # which parent has tagname ..\n    output.extend(path_patterns.predecesors_pattern(element, root))\n\n    index_backtrack = []\n    last_index_backtrack = []\n    params_backtrack = []\n    last_params_backtrack = []\n\n    # look for element by paths from root to element\n    for el in reversed(path):\n        # skip root elements\n        if not el.parent:\n            continue\n\n        tag_name = el.getTagName()\n        match = el.parent.wfind(tag_name).childs\n        index = match.index(el)\n\n        index_backtrack.append(\n            PathCall(\"wfind\", index, [tag_name])\n        )\n        last_index_backtrack.append(\n            PathCall(\"wfind\", index - len(match), [tag_name])\n        )\n\n        # if element has some parameters, use them for lookup\n        if el.params:\n            match = el.parent.wfind(tag_name, el.params).childs\n            index = match.index(el)\n\n            params_backtrack.append(\n                PathCall(\"wfind\", index, [tag_name, el.params])\n            )\n            last_params_backtrack.append(\n                PathCall(\"wfind\", index - len(match), [tag_name, el.params])\n            )\n        else:\n            params_backtrack.append(\n                PathCall(\"wfind\", index, [tag_name])\n            )\n            last_params_backtrack.append(\n                PathCall(\"wfind\", index - len(match), [tag_name])\n            )\n\n    output.extend([\n        Chained(reversed(params_backtrack)),\n        Chained(reversed(last_params_backtrack)),\n        Chained(reversed(index_backtrack)),\n        Chained(reversed(last_index_backtrack)),\n    ])\n\n    return output", "response": "Collect all possible paths which leads to element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_working_path(dom, path, element):\n    def i_or_none(el, i):\n        \"\"\"\n        Return ``el[i]`` if the list is not blank, or None otherwise.\n\n        Args:\n            el (list, tuple): Any indexable object.\n            i (int): Index.\n\n        Returns:\n            obj: Element at index `i` if `el` is not blank, or ``None``.\n        \"\"\"\n        if not el:\n            return None\n\n        return el[i]\n\n    # map decoders of all paths to one dictionary to make easier to call them\n    path_functions = {\n        \"find\": lambda el, index, params:\n            i_or_none(el.find(*params), index),\n        \"wfind\": lambda el, index, params:\n            i_or_none(el.wfind(*params).childs, index),\n        \"match\": lambda el, index, params:\n            i_or_none(el.match(*params), index),\n        \"left_neighbour_tag\": lambda el, index, neigh_data:\n            i_or_none(\n                el.find(\n                    neigh_data.tag_name,\n                    neigh_data.params,\n                    fn=utils.has_neigh(*neigh_data.fn_params, left=True)\n                ),\n                index\n            ),\n        \"right_neighbour_tag\": lambda el, index, neigh_data:\n            i_or_none(\n                el.find(\n                    neigh_data.tag_name,\n                    neigh_data.params,\n                    fn=utils.has_neigh(*neigh_data.fn_params, left=False)\n                ),\n                index\n            ),\n    }\n\n    # call all decoders and see what you get from them\n    el = None\n    if isinstance(path, PathCall):\n        el = path_functions[path.call_type](dom, path.index, path.params)\n    elif isinstance(path, Chained):\n        for path in path.chain:\n            dom = path_functions[path.call_type](dom, path.index, path.params)\n            if not dom:\n                return False\n        el = dom\n    else:\n        raise UserWarning(\n            \"Unknown type of path parameters! (%s)\" % str(path)\n        )\n\n    if not el:\n        return False\n\n    # test whether returned item is the item we are looking for\n    return el.getContent().strip() == element.getContent().strip()", "response": "Checks whether the path is working and returns the element if it is."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses examples select only paths that works for every example select best paths with highest priority.", "response": "def select_best_paths(examples):\n    \"\"\"\n    Process `examples`, select only paths that works for every example. Select\n    best paths with highest priority.\n\n    Args:\n        examples (dict): Output from :func:`.read_config`.\n\n    Returns:\n        list: List of :class:`.PathCall` and :class:`.Chained` objects.\n    \"\"\"\n    possible_paths = {}  # {varname: [paths]}\n\n    # collect list of all possible paths to all existing variables\n    for example in examples:\n        dom = _create_dom(example[\"html\"])\n        matching_elements = _match_elements(dom, example[\"vars\"])\n\n        for key, match in matching_elements.items():\n            if key not in possible_paths:  # TODO: merge paths together?\n                possible_paths[key] = _collect_paths(match)\n\n    # leave only paths, that works in all examples where, are required\n    for example in examples:\n        dom = _create_dom(example[\"html\"])\n        matching_elements = _match_elements(dom, example[\"vars\"])\n\n        for key, paths in possible_paths.items():\n            if key not in matching_elements:\n                continue\n\n            possible_paths[key] = filter(\n                lambda path: _is_working_path(\n                    dom,\n                    path,\n                    matching_elements[key]\n                ),\n                paths\n            )\n\n    priorities = [\n        \"find\",\n        \"left_neighbour_tag\",\n        \"right_neighbour_tag\",\n        \"wfind\",\n        \"match\",\n        \"Chained\"\n    ]\n    priorities = dict(map(lambda x: (x[1], x[0]), enumerate(priorities)))\n\n    # sort all paths by priority table\n    for key in possible_paths.keys():\n        possible_paths[key] = list(sorted(\n            possible_paths[key],\n            key=lambda x: priorities.get(x.call_type, 100)\n        ))\n\n    return possible_paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _assert_obj_type(pub, name=\"pub\", obj_type=DBPublication):\n    if not isinstance(pub, obj_type):\n        raise InvalidType(\n            \"`%s` have to be instance of %s, not %s!\" % (\n                name,\n                obj_type.__name__,\n                pub.__class__.__name__\n            )\n        )", "response": "Ensures that the given object is instance of the given obj_type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_publication(pub):\n    _assert_obj_type(pub)\n\n    _get_handler().store_object(pub)\n\n    return pub.to_comm(light_request=True)", "response": "Save the given publication into database and into proper indexes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_fields(fields):\n    def process_item(value):\n        if not isinstance(value, NUMERIC_TYPES):\n            if isinstance(value, six.string_types):\n                # encode utf-8 to unicode, if necessary\n                return force_text(value)\n            else:\n                if isinstance(value, dict):\n                    return prepare_fields(value)\n                elif isinstance(value, list):\n                    return list(map(process_item, value))\n\n                return six.text_type(value)\n        return value\n\n    return dict((key, process_item(value))\n                for key, value\n                in fields.items())", "response": "Prepare the fields for the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear_dir(self):\n        for snapshot in output_utils.get_filenames(self.output_dir):\n            if snapshot.endswith('.pkl'):\n                os.remove(snapshot)", "response": "Clear the output directory of all output files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_snapshot_time(self, output_every=None, t_output_every=None):\n        if t_output_every is not None:\n            output_every = int(round(t_output_every // self.model.dt))\n        return not self.model.i % output_every", "response": "Determine whether or not the model s iteration number is one - time snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the model for a number of iterations expressed in a number of options.", "response": "def iterate(self,\n                n=None, n_upto=None, t=None, t_upto=None,\n                output_every=None, t_output_every=None):\n        \"\"\"Run the model for a number of iterations, expressed in a number\n        of options.\n        Only one iteration argument should be passed.\n        Only one output arguments should be passed.\n\n        Parameters\n        ----------\n        n: int\n            Run the model for `n` iterations from its current point.\n        n_upto: int\n            Run the model so that its iteration number is at\n            least `n_upto`.\n        t: float\n            Run the model for `t` time from its current point.\n        t_upto: float\n            Run the model so that its time is\n            at least `t_upto`.\n\n        output_every: int\n            How many iterations should elapse between making model snapshots.\n        t_upto: float\n            How much time should elapse between making model snapshots.\n        \"\"\"\n        if t is not None:\n            t_upto = self.model.t + t\n        if t_upto is not None:\n            n_upto = int(round(t_upto // self.model.dt))\n        if n is not None:\n            n_upto = self.model.i + n\n\n        while self.model.i <= n_upto:\n            if self.is_snapshot_time(output_every, t_output_every):\n                self.make_snapshot()\n            self.model.iterate()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting a snapshot of the current model state in a file inside the output directory with a name determined by its iteration number.", "response": "def make_snapshot(self):\n        \"\"\"Output a snapshot of the current model state, as a pickle of the\n        `Model` object in a file inside the output directory, with a name\n        determined by its iteration number.\n        \"\"\"\n        filename = join(self.output_dir, '{:010d}.pkl'.format(self.model.i))\n        output_utils.model_to_file(self.model, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the contents of an object.", "response": "def _do_print(self, cmd, args):\n        \"\"\"\\\n        Display symbols.\n            p               Display names of inspectable objects.\n            p <id>          Display the content of an object.\n        \"\"\"\n        name = args[0].strip()\n        if not name:\n            self.stderr.write('TODO: Display names of inspectable objects.\\n')\n            return\n        try:\n            code = textwrap.dedent(r'''\n                    self.stdout.write(name + ':\\n' + textwrap.indent(pprint.pformat({}), '    ') + '\\n')\n                    ''').format(name).strip()\n            eval(code, globals(), locals())\n        except NameError:\n            self.stderr.write(\"p: name '{}' is not defined\\n\".format(name))\n        self.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _do_eval(self, cmd, args):\n        code = args[0].lstrip()\n        if not code:\n            self.stderr.write('e: cannot evalutate empty expression\\n')\n            return\n        try:\n            eval(code)\n        except:\n            self.stderr.write('''When executing code '{}', the following error was raised:\\n\\n'''.format(code))\n            self.stderr.write(textwrap.indent(traceback.format_exc(), '    '))", "response": "\\ n\\ n Evaluate python code.\n            e"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_line(self, line):\n        line = line.lstrip()\n        toks = shlex.split(line)\n        cmd = toks[0]\n        arg = line[len(cmd):]\n        return cmd, [ arg, ]", "response": "Parse a line of a debug shell into a tuple of cmd args"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind(self, **kwargs):\n        '''\n        creates a copy of the object without the\n        cached results and with the given keyword\n        arguments as properties.\n        '''\n        d = dict(self.__dict__)\n        for k in d.keys():\n            if k[0] == '_':\n                del d[k]\n            elif k.startswith('obj_'):\n                d[k] = d[k].bind(**kwargs)\n        d.update(kwargs)\n        return self.__class__(**d)", "response": "Creates a copy of the object with the given keyword\n        arguments as properties."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, name, *subkey):\n        if subkey == []:\n            return self.get_atomic(name)\n        else:\n            return self.get_subkey(name, tuple(subkey))", "response": "Retrieves a data item from the cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef val(self, name):\n        v = getattr(self, name)\n        if hasattr(v, 'retrieve_value'):\n            v = v.retrieve_value(self.__dict__)\n        return v", "response": "Retrieves a value from the object with the given name substituting actual\n        values for ConfigValue templates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_by_pat(self, name, mode='r', **kwargs):\n        '''\n        opens the file for the pattern given by *name*,\n        substituting the object's properties and the\n        additional keyword arguments given.\n        '''\n        fname = self.fname_by_pat(name, **kwargs)\n        if mode == 'w':\n            print >>sys.stderr, \"Write[%s]: %s\" % (name, fname)\n        else:\n            print >>sys.stderr, \"Open[%s]: %s\" % (name, fname)\n        return file(fname, mode)", "response": "opens the file for the pattern given by name and returns the file object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef harvest_collection(community_name):\n    url = zenodo_harvest_url(community_name)\n    r = requests.get(url)\n    r.status_code\n    xml_content = r.content\n\n    return Datacite3Collection.from_collection_xml(xml_content)", "response": "Harvest a Zenodo community s record metadata."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a URL for the Zenodo Community s metadata.", "response": "def zenodo_harvest_url(community_name, format='oai_datacite3'):\n    \"\"\"Build a URL for the Zenodo Community's metadata.\n\n    Parameters\n    ----------\n    community_name : str\n        Zenodo community identifier.\n    format : str\n        OAI-PMH metadata specification name. See https://zenodo.org/dev.\n        Currently on ``oai_datacite3`` is supported.\n\n    Returns\n    -------\n    url : str\n        OAI-PMH metadata URL.\n    \"\"\"\n    template = 'http://zenodo.org/oai2d?verb=ListRecords&' \\\n               'metadataPrefix={metadata_format}&set=user-{community}'\n    return template.format(metadata_format=format,\n                           community=community_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pluralize(value, item_key):\n    v = value[item_key]\n    if not isinstance(v, list):\n        # Force a singular value to be a list\n        return [v]\n    else:\n        return v", "response": "Force the value of a datacite3 key to be a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_collection_xml(cls, xml_content):\n        xml_dataset = xmltodict.parse(xml_content, process_namespaces=False)\n        # Unwrap the record list when harvesting a collection's datacite 3\n        xml_records = xml_dataset['OAI-PMH']['ListRecords']['record']  # NOQA\n        return cls(xml_records)", "response": "Build a : class ~zenodio. harvest. Datacite3Collection from a Zenodo OAI - PMH XML content."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authors(self):\n        creators = _pluralize(self._r['creators'], 'creator')\n        authors = [Author.from_xmldict(c) for c in creators]\n        return authors", "response": "List of : class : ~zenodio. harvest. Author \\ s corresponding to creators in the Datacite schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef abstract_html(self):\n        descriptions = _pluralize(self._r['descriptions'], 'description')\n        for desc in descriptions:\n            if desc['@descriptionType'] == 'Abstract':\n                return desc['#text']", "response": "Abstract text marked up with HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndates when the DOI was issued (:class:`datetime.datetime.Datetime`).", "response": "def issue_date(self):\n        \"\"\"Date when the DOI was issued (:class:`datetime.datetime.Datetime`).\n        \"\"\"\n        dates = _pluralize(self._r['dates'], 'date')\n        for date in dates:\n            if date['@dateType'] == 'Issued':\n                return datetime.datetime.strptime(date['#text'], '%Y-%m-%d')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_xmldict(cls, xml_dict):\n        name = xml_dict['creatorName']\n\n        kwargs = {}\n        if 'affiliation' in xml_dict:\n            kwargs['affiliation'] = xml_dict['affiliation']\n\n        return cls(name, **kwargs)", "response": "Create an Author object from a datacite3 metadata converted by\n        xmltodict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getZernike(self, index):\n        if index not in list(self._dictCache.keys()):\n            self._dictCache[index]= self._polar(index, self._rhoMap,\n                                                self._thetaMap)\n        return self._dictCache[index]", "response": "getZernike\n            returns a numpy array representing the index - th Zernike polynomial in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_fields_to_dict(fields):\n    if not fields:\n        return {}\n    try:\n        int(list(dict(fields).values())[0])\n    except (TypeError, ValueError):\n        fields = dict(zip(fields, [1] * len(fields)))\n    return fields", "response": "Convert a list of search fields to a dict of fields mapped to weights."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef published(self, for_user=None):\n        from yacms.core.models import CONTENT_STATUS_PUBLISHED\n        if for_user is not None and for_user.is_staff:\n            return self.all()\n        return self.filter(\n            Q(publish_date__lte=now()) | Q(publish_date__isnull=True),\n            Q(expiry_date__gte=now()) | Q(expiry_date__isnull=True),\n            Q(status=CONTENT_STATUS_PUBLISHED))", "response": "Return items with a published status and\n            whose publish and expiry dates fall before and after the current date when specified."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, query, search_fields=None):\n\n        # ### DETERMINE FIELDS TO SEARCH ###\n\n        # Use search_fields arg if given, otherwise use search_fields\n        # initially configured by the manager class.\n        if search_fields:\n            self._search_fields = search_fields_to_dict(search_fields)\n        if not self._search_fields:\n            return self.none()\n\n        # ### BUILD LIST OF TERMS TO SEARCH FOR ###\n\n        # Remove extra spaces, put modifiers inside quoted terms.\n        terms = \" \".join(query.split()).replace(\"+ \", \"+\")     \\\n                                       .replace('+\"', '\"+')    \\\n                                       .replace(\"- \", \"-\")     \\\n                                       .replace('-\"', '\"-')    \\\n                                       .split('\"')\n        # Strip punctuation other than modifiers from terms and create\n        # terms list, first from quoted terms and then remaining words.\n        terms = [(\"\" if t[0:1] not in \"+-\" else t[0:1]) + t.strip(punctuation)\n            for t in terms[1::2] + \"\".join(terms[::2]).split()]\n        # Remove stop words from terms that aren't quoted or use\n        # modifiers, since words with these are an explicit part of\n        # the search query. If doing so ends up with an empty term\n        # list, then keep the stop words.\n        terms_no_stopwords = [t for t in terms if t.lower() not in\n            settings.STOP_WORDS]\n        get_positive_terms = lambda terms: [t.lower().strip(punctuation)\n            for t in terms if t[0:1] != \"-\"]\n        positive_terms = get_positive_terms(terms_no_stopwords)\n        if positive_terms:\n            terms = terms_no_stopwords\n        else:\n            positive_terms = get_positive_terms(terms)\n        # Append positive terms (those without the negative modifier)\n        # to the internal list for sorting when results are iterated.\n        if not positive_terms:\n            return self.none()\n        else:\n            self._search_terms.update(positive_terms)\n\n        # ### BUILD QUERYSET FILTER ###\n\n        # Create the queryset combining each set of terms.\n        excluded = [reduce(iand, [~Q(**{\"%s__icontains\" % f: t[1:]}) for f in\n            self._search_fields.keys()]) for t in terms if t[0:1] == \"-\"]\n        required = [reduce(ior, [Q(**{\"%s__icontains\" % f: t[1:]}) for f in\n            self._search_fields.keys()]) for t in terms if t[0:1] == \"+\"]\n        optional = [reduce(ior, [Q(**{\"%s__icontains\" % f: t}) for f in\n            self._search_fields.keys()]) for t in terms if t[0:1] not in \"+-\"]\n        queryset = self\n        if excluded:\n            queryset = queryset.filter(reduce(iand, excluded))\n        if required:\n            queryset = queryset.filter(reduce(iand, required))\n        # Optional terms aren't relevant to the filter if there are\n        # terms that are explicitly required.\n        elif optional:\n            queryset = queryset.filter(reduce(ior, optional))\n        return queryset.distinct()", "response": "Build a queryset matching words in the given search query."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclone the current instance.", "response": "def _clone(self, *args, **kwargs):\n        \"\"\"\n        Ensure attributes are copied to subsequent queries.\n        \"\"\"\n        for attr in (\"_search_terms\", \"_search_fields\", \"_search_ordered\"):\n            kwargs[attr] = getattr(self, attr)\n        return super(SearchableQuerySet, self)._clone(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nordering the results by the given field names.", "response": "def order_by(self, *field_names):\n        \"\"\"\n        Mark the filter as being ordered if search has occurred.\n        \"\"\"\n        if not self._search_ordered:\n            self._search_ordered = len(self._search_terms) > 0\n        return super(SearchableQuerySet, self).order_by(*field_names)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating over the results of this SearchableQuerySet and decorate each result with the number of occurrences of terms.", "response": "def iterator(self):\n        \"\"\"\n        If search has occurred and no ordering has occurred, decorate\n        each result with the number of search terms so that it can be\n        sorted by the number of occurrence of terms.\n\n        In the case of search fields that span model relationships, we\n        cannot accurately match occurrences without some very\n        complicated traversal code, which we won't attempt. So in this\n        case, namely when there are no matches for a result (count=0),\n        and search fields contain relationships (double underscores),\n        we assume one match for one of the fields, and use the average\n        weight of all search fields with relationships.\n        \"\"\"\n        results = super(SearchableQuerySet, self).iterator()\n        if self._search_terms and not self._search_ordered:\n            results = list(results)\n            for i, result in enumerate(results):\n                count = 0\n                related_weights = []\n                for (field, weight) in self._search_fields.items():\n                    if \"__\" in field:\n                        related_weights.append(weight)\n                    for term in self._search_terms:\n                        field_value = getattr(result, field, None)\n                        if field_value:\n                            count += field_value.lower().count(term) * weight\n                if not count and related_weights:\n                    count = int(sum(related_weights) / len(related_weights))\n                results[i].result_count = count\n            return iter(results)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the search fields mapped to weights as a dict.", "response": "def get_search_fields(self):\n        \"\"\"\n        Returns the search field names mapped to weights as a dict.\n        Used in ``get_queryset`` below to tell ``SearchableQuerySet``\n        which search fields to use. Also used by ``DisplayableAdmin``\n        to populate Django admin's ``search_fields`` attribute.\n\n        Search fields can be populated via\n        ``SearchableManager.__init__``, which then get stored in\n        ``SearchableManager._search_fields``, which serves as an\n        approach for defining an explicit set of fields to be used.\n\n        Alternatively and more commonly, ``search_fields`` can be\n        defined on models themselves. In this case, we look at the\n        model and all its base classes, and build up the search\n        fields from all of those, so the search fields are implicitly\n        built up from the inheritence chain.\n\n        Finally if no search fields have been defined at all, we\n        fall back to any fields that are ``CharField`` or ``TextField``\n        instances.\n        \"\"\"\n        search_fields = self._search_fields.copy()\n        if not search_fields:\n            for cls in reversed(self.model.__mro__):\n                super_fields = getattr(cls, \"search_fields\", {})\n                search_fields.update(search_fields_to_dict(super_fields))\n        if not search_fields:\n            search_fields = []\n            for f in self.model._meta.fields:\n                if isinstance(f, (CharField, TextField)):\n                    search_fields.append(f.name)\n            search_fields = search_fields_to_dict(search_fields)\n        return search_fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a manager to the given model and name.", "response": "def contribute_to_class(self, model, name):\n        \"\"\"\n        Newer versions of Django explicitly prevent managers being\n        accessed from abstract classes, which is behaviour the search\n        API has always relied on. Here we reinstate it.\n        \"\"\"\n        super(SearchableManager, self).contribute_to_class(model, name)\n        setattr(model, name, ManagerDescriptor(self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search(self, *args, **kwargs):\n        if not settings.SEARCH_MODEL_CHOICES:\n            # No choices defined - build a list of leaf models (those\n            # without subclasses) that inherit from Displayable.\n            models = [m for m in apps.get_models()\n                      if issubclass(m, self.model)]\n            parents = reduce(ior, [set(m._meta.get_parent_list())\n                                   for m in models])\n            models = [m for m in models if m not in parents]\n        elif getattr(self.model._meta, \"abstract\", False):\n            # When we're combining model subclasses for an abstract\n            # model (eg Displayable), we only want to use models that\n            # are represented by the ``SEARCH_MODEL_CHOICES`` setting.\n            # Now this setting won't contain an exact list of models\n            # we should use, since it can define superclass models such\n            # as ``Page``, so we check the parent class list of each\n            # model when determining whether a model falls within the\n            # ``SEARCH_MODEL_CHOICES`` setting.\n            search_choices = set()\n            models = set()\n            parents = set()\n            errors = []\n            for name in settings.SEARCH_MODEL_CHOICES:\n                try:\n                    model = apps.get_model(*name.split(\".\", 1))\n                except LookupError:\n                    errors.append(name)\n                else:\n                    search_choices.add(model)\n            if errors:\n                raise ImproperlyConfigured(\"Could not load the model(s) \"\n                        \"%s defined in the 'SEARCH_MODEL_CHOICES' setting.\"\n                        % \", \".join(errors))\n\n            for model in apps.get_models():\n                # Model is actually a subclasses of what we're\n                # searching (eg Displayabale)\n                is_subclass = issubclass(model, self.model)\n                # Model satisfies the search choices list - either\n                # there are no search choices, model is directly in\n                # search choices, or its parent is.\n                this_parents = set(model._meta.get_parent_list())\n                in_choices = not search_choices or model in search_choices\n                in_choices = in_choices or this_parents & search_choices\n                if is_subclass and (in_choices or not search_choices):\n                    # Add to models we'll seach. Also maintain a parent\n                    # set, used below for further refinement of models\n                    # list to search.\n                    models.add(model)\n                    parents.update(this_parents)\n            # Strip out any models that are superclasses of models,\n            # specifically the Page model which will generally be the\n            # superclass for all custom content types, since if we\n            # query the Page model as well, we will get duplicate\n            # results.\n            models -= parents\n        else:\n            models = [self.model]\n        all_results = []\n        user = kwargs.pop(\"for_user\", None)\n        for model in models:\n            try:\n                queryset = model.objects.published(for_user=user)\n            except AttributeError:\n                queryset = model.objects.get_queryset()\n            all_results.extend(queryset.search(*args, **kwargs))\n        return sorted(all_results, key=lambda r: r.result_count, reverse=True)", "response": "Proxy to queryset s search method for the manager s model and any related models that inherit from Displayable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_map(self, for_user=None, **kwargs):\n        class Home:\n            title = _(\"Home\")\n        home = Home()\n        setattr(home, \"get_absolute_url\", home_slug)\n        items = {home.get_absolute_url(): home}\n        for model in apps.get_models():\n            if issubclass(model, self.model):\n                for item in (model.objects.published(for_user=for_user)\n                                  .filter(**kwargs)\n                                  .exclude(slug__startswith=\"http://\")\n                                  .exclude(slug__startswith=\"https://\")):\n                    items[item.get_absolute_url()] = item\n        return items", "response": "Returns a dictionary of urls mapped to Displayable subclass\n        instances including fake homepage instance if none exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the name for a model.", "response": "def get_name(model_id):\n    \"\"\"\n    Get the name for a model.\n\n    :returns str: The model's name.  If the id has no associated name, then \"id = {ID} (no name)\" is returned.\n    \"\"\"\n    name = _names.get(model_id)\n    if name is None:\n        name = 'id = %s (no name)' % str(model_id)\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_logger(cls, *name, **kwargs):\n        return cls(getLogger(_normalize_name(name)),\n                   kwargs.get('extra', None))", "response": "Construct a new KvLoggerAdapter which encapsulates\n            the logger specified by name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefine a new logger function that will log given values with the given log level.", "response": "def define_logger_func(self, level, field_names, default=NO_DEFAULT,\n                           filters=None, include_exc_info=False):\n        \"\"\"Define a new logger function that will log the given arguments\n        with the given predefined keys.\n\n        :param level:\n            The log level to use for each call.\n        :param field_names:\n            Set of predefined keys.\n        :param default:\n            A default value for each key.\n        :param filters:\n            Additional filters for treating given arguments.\n        :param include_exc_info:\n            Include a stack trace with the log.  Useful for the ``ERROR``\n            log level.\n        :return:\n            A function that will log given values with the predefined\n            keys and the given log level.\n        \"\"\"\n        kv_formatter = KvFormatter(field_names, default, filters)\n        return lambda *a, **kw: self._log(level, kv_formatter(*a, **kw),\n                                          include_exc_info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log(self, level, *args, **kwargs):\n        return self._log_kw(level, args, kwargs)", "response": "Delegate a log call to the underlying logger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelegate a call to the underlying logger.", "response": "def exception(self, *args, **kwargs):\n        \"\"\"Delegate a exception call to the underlying logger.\"\"\"\n        return self._log_kw(ERROR, args, kwargs, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(self):\n        try:\n            self.telnet = Telnet(self.host, self.port)\n            time.sleep(1)\n            self.get()\n            self.get('login admin admin')\n            self.update()\n        except socket.gaierror:\n            self.telnet = None\n            LOGGER.error(\"Cannot connect to %s (%d)\",\n                         self.host, self.retries)", "response": "Simple connect to the Telnet instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating all the switch values", "response": "def update(self):\n        \"\"\" Update all the switch values \"\"\"\n\n        self.states = [bool(int(x)) for x in self.get('port list') or '0000']"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends and receive a command to get the current state of the user.", "response": "def get(self, command=None):\n        \"\"\"\n        Interface function to send and receive decoded bytes\n        Retries the connect [self.retries] times\n\n        \"\"\"\n\n        try:\n            assert self.telnet\n            with self.lock:\n                if command:\n                    if not command.endswith('\\r\\n'):\n                        command += '\\r\\n'\n                    LOGGER.debug('%s: sending %r', self.host, command)\n                    self.telnet.write(command.encode())\n\n                res = self.telnet.read_until('\\r\\n'.encode()).decode()\n                LOGGER.debug('%s: received %r', self.host, res)\n                if res.split()[0] not in ('100', '250'):\n                    LOGGER.warn('command error: %r', res)\n                    return None\n                return res.split()[1]\n\n        except (AssertionError):\n            self.connect()\n\n        except (EOFError, socket.gaierror, BrokenPipeError):\n            LOGGER.error(\"Cannot get answer from %s (%d)\",\n                         self.host, self.retries)\n            if self.retries > 0:\n                self.retries -= 1\n                self.connect()\n                return self.get(command)\n            else:\n                self.retries = Netio.MAX_RETRIES\n                return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_user_details(self, response):\n        user = response\n\n        # Rename to what psa expects\n        fullname = user.get('name', None)\n        if fullname:\n            user['fullname'] = fullname\n            user.pop('name')\n\n        # Get profile photo url if any\n        profilephoto_id = user.get('profilephoto', None)\n        if profilephoto_id:\n            profilephoto_url = '{}/userinfo/v1/user/media/{}'.format(self.API_URL, profilephoto_id)\n            user['profilephoto_url'] = profilephoto_url\n\n        return user", "response": "Get user details from Dataportenco."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_correct_audience(self, audience):\n        \"Assert that Dataporten sends back our own client id as audience\"\n        client_id, _ = self.get_key_and_secret()\n        if audience != client_id:\n            raise AuthException('Wrong audience')", "response": "Assert that Dataporten sends back our own client id as audience"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload user data from service", "response": "def user_data(self, access_token, *args, **kwargs):\n        \"\"\"Loads user data from service\"\"\"\n        url = '{}/userinfo'.format(self.BASE_URL)\n        response = self.get_json(\n            url,\n            headers={'Authorization': 'Bearer ' + access_token},\n        )\n        self.check_correct_audience(response['audience'])\n\n        userdata = response['user']\n        return userdata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_user_details(self, response):\n        user = super(DataportenEmailOAuth2, self).get_user_details(response)\n        user['username'] = user['email']\n        return user", "response": "Get user details from DataportenEmailOAuth2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_details(self, response):\n        user = super(DataportenFeideOAuth2, self).get_user_details(response)\n        sec_userids = user['userid_sec']\n        for userid in sec_userids:\n            usertype, username = userid.split(':')\n            if usertype == 'feide':\n                user['username'] = username\n                break\n        return user", "response": "Get user details from DataportenFeideOAuth2"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the human readable representation for a list of choices.", "response": "def ChoiceHumanReadable(choices, choice):\n    \"\"\"\n    Return the human readable representation for a list of choices.\n    \n    @see https://docs.djangoproject.com/en/dev/ref/models/fields/#choices\n    \"\"\"\n    if choice == None: raise NoChoiceError()\n    for _choice in choices:\n        if _choice[0] == choice:\n            return _choice[1]\n    raise NoChoiceMatchError(\"The choice '%s' does not exist in '%s'\" % (choice, \", \".join([choice[0] for choice in choices])))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_db_prep_value(self, value, connection=None, prepared=False):\n        if not value:\n            return\n        if prepared:\n            return value\n        else:\n            assert(isinstance(value, list) or isinstance(value, tuple))\n            return self.separator.join([unicode(s) for s in value])", "response": "Returns field s value prepared for interacting with the database\n            backend."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the user s SDB inventory Raises parseException Loads the user s SDB forms Raises parseException", "response": "def load(self):\n        \"\"\" Loads the user's SDB inventory\n           \n        Raises\n           parseException\n        \"\"\"\n        self.inventory = SDBInventory(self.usr)\n        self.forms = self.inventory.forms"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self):\n        for x in range(1, self.inventory.pages + 1):\n            if self._hasPageChanged(x):\n                form = self._updateForm(x)\n                form.usePin = True\n                pg = form.submit()\n                \n                # Success redirects to SDB page\n                if \"Your Safety Deposit Box\" in pg.content:\n                    return True\n                else:\n                    logging.getLogger(\"neolib.shop\").exception(\"Could not verify if SDB inventory was updated.\", {'pg': pg})\n                    return False", "response": "Upates the user s SDB inventory with the items that have changed. Returns True if successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_series(self, key=None, tags=[], attrs={}):\n\n        body = protocol.make_series_key(key, tags, attrs)\n        resp = self.session.post(endpoint.SERIES_ENDPOINT, body)\n        return resp", "response": "Create a new series with an optional string key. A list of tags and a map of attributes can also be optionally supplied."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a series according to the given criteria.", "response": "def delete_series(self, keys=None, tags=None, attrs=None,\n                      allow_truncation=False):\n        \"\"\"Delete a series according to the given criteria.\n\n        **Note:** for the key argument, the filter will return the *union* of\n        those values.  For the tag and attr arguments, the filter will return\n        the *intersection* of those values.\n\n        :param keys: filter by one or more series keys\n        :type keys: list or string\n        :param tags: filter by one or more tags\n        :type tags: list or string\n        :param dict attrs: filter by one or more key-value attributes\n        :param bool allow_truncation: whether to allow full deletion of a\n                                      database. Default is False.\n        :rtype: :class:`tempodb.response.Response` object\"\"\"\n\n        params = {\n            'key': keys,\n            'tag': tags,\n            'attr': attrs,\n            'allow_truncation': str(allow_truncation).lower()\n        }\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([endpoint.SERIES_ENDPOINT, url_args])\n        resp = self.session.delete(url)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a series object from TempoDB given its key.", "response": "def get_series(self, key):\n        \"\"\"Get a series object from TempoDB given its key.\n\n        :param string key: a string name for the series\n        :rtype: :class:`tempodb.response.Response` with a\n                :class:`tempodb.protocol.objects.Series` data payload\"\"\"\n\n        url = make_series_url(key)\n        resp = self.session.get(url)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of all series matching the given criteria.", "response": "def list_series(self, keys=None, tags=None, attrs=None,\n                    limit=1000):\n        \"\"\"Get a list of all series matching the given criteria.\n\n        **Note:** for the key argument, the filter will return the *union* of\n        those values.  For the tag and attr arguments, the filter will return\n        the *intersection* of those values.\n\n        :param keys: filter by one or more series keys\n        :type keys: list or string\n        :param tags: filter by one or more tags\n        :type tags: list or string\n        :param dict attrs: filter by one or more key-value attributes\n        :rtype: :class:`tempodb.protocol.cursor.SeriesCursor` with an\n                iterator over :class:`tempodb.protocol.objects.Series`\n                objects\"\"\"\n\n        params = {\n            'key': keys,\n            'tag': tags,\n            'attr': attrs,\n            'limit': limit\n        }\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([endpoint.SERIES_ENDPOINT, url_args])\n        resp = self.session.get(url)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates a series with new attributes.", "response": "def update_series(self, series):\n        \"\"\"Update a series with new attributes.  This does not change\n        any of the data written to this series. The recommended workflow for\n        series updates is to pull a Series object down using the\n        :meth:`get_series` method, change its attributes, then pass it into\n        this method.\n\n        :param series: the series to update\n        :type series: `tempodb.protocol.Series` object\n        :rtype: :class:`tempodb.response.Response` object with the updated\n                :class:`tempodb.protocol.objects.Series` as the data payload\"\"\"\n\n        url = make_series_url(series.key)\n\n        resp = self.session.put(url, series.to_json())\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_data(self, key, start=None, end=None, rollup=None,\n                  period=None, interpolationf=None, interpolation_period=None,\n                  tz=None, limit=1000):\n        \"\"\"Read data from a series given its ID or key.  Start and end times\n        must be supplied.  They can either be ISO8601 encoded strings (i.e.\n        2012-01-08T00:21:54.000+0000) or Python Datetime objects, which will\n        be converted for you.\n\n        The rollup parameter is optional and can include string values such\n        as \"sum\" and \"avg\".  Below is a list of valid rollup functions:\n\n            * count\n            * sum\n            * mult\n            * min\n            * max\n            * stddev\n            * ss\n            * range\n            * percentile,N (where N is what percentile to calculate)\n\n        This will apply a rollup function to your raw dataset.  The\n        optional period parameter will downsample your data according to the\n        given resolution (\"1min\", \"2day\", etc).\n\n        The optional interpolation parameters can be used to resample your\n        data to a regular interval interpolation_period according to an\n        interpolation function interpolationf. Valid values for\n        interpolation_period are the same as for the period parameter, and\n        valid values for interpolationf include \"zoh\" and \"linear\".\n\n        Finally, the optional tz parameter can be used to specify a time zone\n        for your output.  Please see\n        `here <https://tempo-db.com/docs/api/timezone/>`_ for a list of a\n        valid timezone values.\n\n        :param string key: the series key to use\n        :param start: the start time for the data points\n        :type start: string or Datetime\n        :param end: the end time for the data points\n        :type end: string or Datetime\n        :param string rollup: (optional) the name of a rollup function to use\n        :param string period: (optional) downsampling rate for the data\n        :param string interpolationf: (optional) an interpolation function\n                                      to run over the series\n        :param string interpolation_period: (optional) the period to\n                                            interpolate data into\n        :param string tz: (optional) the timezone to place the data into\n        :rtype: :class:`tempodb.protocol.cursor.DataPointCursor` with an\n                iterator over :class:`tempodb.protocol.objects.DataPoint`\n                objects\"\"\"\n\n        url = make_series_url(key)\n        url = urlparse.urljoin(url + '/', 'segment')\n\n        vstart = check_time_param(start)\n        vend = check_time_param(end)\n        params = {\n            'start': vstart,\n            'end': vend,\n            'rollup.fold': rollup,\n            'rollup.period': period,\n            'interpolation.function': interpolationf,\n            'interpolation.period': interpolation_period,\n            'tz': tz,\n            'limit': limit\n        }\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([url, url_args])\n        resp = self.session.get(url)\n        return resp", "response": "Read data from a series given its ID or key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a summary for the series from start to end.", "response": "def get_summary(self, key, start, end, tz=None):\n        \"\"\"Get a summary for the series from *start* to *end*.  The summary is\n        a map containing keys *count*, *min*, *max*, *mean*, *sum*, and\n        *stddev*.\n\n        :param string key: the series key to use\n        :param start: the start time for the data points\n        :type start: string or Datetime\n        :param end: the end time for the data points\n        :type end: string or Datetime\n        :param string tz: (optional) the timezone to place the data into\n        :rtype: :class:`tempodb.response.Response` with a\n                :class:`tempodb.protocol.objects.SeriesSummary` data payload\"\"\"\n\n        url = make_series_url(key)\n        url = urlparse.urljoin(url + '/', 'summary')\n\n        vstart = check_time_param(start)\n        vend = check_time_param(end)\n        params = {\n            'start': vstart,\n            'end': vend,\n            'tz': tz\n        }\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([url, url_args])\n        resp = self.session.get(url)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aggregate_data(self, start, end, aggregation, keys=[], tags=[],\n                       attrs={}, rollup=None, period=None, interpolationf=None,\n                       interpolation_period=None, tz=None, limit=1000):\n        \"\"\"Read data from multiple series according to a filter and apply a\n        function across all the returned series to put the datapoints together\n        into one aggregrate series.\n\n        See the :meth:`list_series` method for a description of how the filter\n        criteria are applied, and the :meth:`read_data` method for how to\n        work with the start, end, and tz parameters.\n\n        Valid aggregation functions are the same as valid rollup functions.\n\n        :param string aggregation: the aggregation to perform\n        :param keys: (optional) filter by one or more series keys\n        :type keys: list or string\n        :param tags: (optional) filter by one or more tags\n        :type tags: list or string\n        :param dict attrs: (optional) filter by one or more key-value\n                           attributes\n        :param start: the start time for the data points\n        :type start: string or Datetime\n        :param end: the end time for the data points\n        :type end: string or Datetime\n        :param string rollup: (optional) the name of a rollup function to use\n        :param string period: (optional) downsampling rate for the data\n        :param string interpolationf: (optional) an interpolation function\n                                      to run over the series\n        :param string interpolation_period: (optional) the period to\n                                            interpolate data into\n        :param string tz: (optional) the timezone to place the data into\n        :rtype: :class:`tempodb.protocol.cursor.DataPointCursor` with an\n                iterator over :class:`tempodb.protocol.objects.DataPoint`\n                objects\"\"\"\n\n        url = 'segment'\n\n        vstart = check_time_param(start)\n        vend = check_time_param(end)\n        params = {\n            'start': vstart,\n            'end': vend,\n            'key': keys,\n            'tag': tags,\n            'attr': attrs,\n            'aggregation.fold': aggregation,\n            'rollup.fold': rollup,\n            'rollup.period': period,\n            'interpolation.function': interpolationf,\n            'interpolation.period': interpolation_period,\n            'tz': tz,\n            'limit': limit\n        }\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([url, url_args])\n        resp = self.session.get(url)\n        return resp", "response": "Read data from multiple series according to a filter and apply a aggregate function across all the returned series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a set of datapoints into a series by its key. For now the tags and attributes arguments are ignored.", "response": "def write_data(self, key, data, tags=[], attrs={}):\n        \"\"\"Write a set a datapoints into a series by its key.  For now,\n        the tags and attributes arguments are ignored.\n\n        :param string key: the series to write data into\n        :param list data: a list of DataPoints to write\n        :rtype: :class:`tempodb.response.Response` object\"\"\"\n\n        url = make_series_url(key)\n        url = urlparse.urljoin(url + '/', 'data')\n\n        #revisit later if there are server changes to take these into\n        #account\n        #params = {\n        #    'tag': tag,\n        #    'attr': attr,\n        #}\n        #url_args = endpoint.make_url_args(params)\n        #url = '?'.join([url, url_args])\n\n        dlist = [d.to_dictionary() for d in data]\n        body = json.dumps(dlist)\n        resp = self.session.post(url, body)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a set a datapoints into multiple series by key or series ID.", "response": "def write_multi(self, data):\n        \"\"\"Write a set a datapoints into multiple series by key or series ID.\n        Each :class:`tempodb.protocol.objects.DataPoint` object should have\n        either a key or id attribute set that indicates which series it will\n        be written into::\n\n            [\n                {\"t\": \"2012-...\", \"key\": \"foo\", \"v\": 1},\n                {\"t\": \"2012-...\", \"id\": \"bar\", \"v\": 1}\n            ]\n\n        If a non-existent key or ID is passed in, a series will be created\n        for that key/ID and the data point written in to the new series.\n\n        :param list data: a list of DataPoints to write\n        :rtype: :class:`tempodb.response.Response` object\"\"\"\n\n        url = 'multi/'\n\n        dlist = [d.to_dictionary() for d in data]\n        body = json.dumps(dlist)\n        resp = self.session.post(url, body)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef single_value(self, key, ts=None, direction=None):\n\n        url = make_series_url(key)\n        url = urlparse.urljoin(url + '/', 'single')\n\n        if ts is not None:\n            vts = check_time_param(ts)\n        else:\n            vts = None\n\n        params = {\n            'ts': vts,\n            'direction': direction\n        }\n\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([url, url_args])\n        resp = self.session.get(url)\n        return resp", "response": "Return a single value for a series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a single value for multiple series.", "response": "def multi_series_single_value(self, keys=None, ts=None, direction=None,\n                                  attrs={}, tags=[]):\n        \"\"\"Return a single value for multiple series.  You can supply a\n        timestamp as the ts argument, otherwise the search defaults to the\n        current time.\n\n        The direction argument can be one of \"exact\", \"before\", \"after\", or\n        \"nearest\".\n\n        The id, key, tag, and attr arguments allow you to filter for series.\n        See the :meth:`list_series` method for an explanation of their use.\n\n        :param string keys: (optional) a list of keys for the series to use\n        :param ts: (optional) the time to begin searching from\n        :type ts: ISO8601 string or Datetime object\n        :param string direction: criterion for the search\n        :param tags: filter by one or more tags\n        :type tags: list or string\n        :param dict attrs: filter by one or more key-value attributes\n        :rtype: :class:`tempodb.protocol.cursor.SingleValueCursor` with an\n                iterator over :class:`tempodb.protocol.objects.SingleValue`\n                objects\"\"\"\n\n        url = 'single/'\n        if ts is not None:\n            vts = check_time_param(ts)\n        else:\n            vts = None\n\n        params = {\n            'key': keys,\n            'tag': tags,\n            'attr': attrs,\n            'ts': vts,\n            'direction': direction\n        }\n\n        url_args = endpoint.make_url_args(params)\n        url = '?'.join([url, url_args])\n        resp = self.session.get(url)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allow_resource_access(self, resource_name, when=None):\n        # The period strings of interest to us\n        period_strs = self.get_period_strs(when)\n\n        # Get the pool and limits for the pool.\n        pool = self.pool_for_resource(resource_name)\n        limits = self.get_limits_for_pool(pool)\n\n        resource_size = self.resource_size(resource_name)\n\n        # Record the access attempt.\n        for period, period_str in period_strs.items():\n            aggregate_size = self.cache.incrbyfloat(\n                \"ATTEMPT:%s:%s\" % (period_str, pool), resource_size)\n            log.debug(\"allow_resource_access(%r): ATTEMPT:%s:%s=%s\",\n                      resource_name, period_str, pool, aggregate_size)\n\n        del period_str\n\n        # A list of things we need to undo from Redis if we breach a limit.\n        undo_actions = []\n\n        # Check for limit breaches.\n        for period, period_str in period_strs.items():\n            limit = limits.get(period)\n            key = \"ALLOWED:%s:%s\" % (period_str, pool)\n            result = self.cache.incrbyfloat(key, resource_size)\n            undo_actions.append((key, -resource_size))\n            log.debug(\"allow_resource_access(%r): ALLOWED:%s:%s=%s\",\n                      resource_name, period_str, pool, result)\n\n            if limit and result > limit:\n                log.debug(\"allow_resource_access(%r): Limit %s would be \"\n                          \"breached: limit=%s, result=%s\", resource_name,\n                          period, limit, result)\n\n                for key, incr in undo_actions:\n                    self.cache.incrbyfloat(key, incr)\n\n                return False\n\n        log.debug(\"allow_resource_access(%r): No limits breached; allowed\",\n                  resource_name)\n        return True", "response": "Allow access to the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the size of the resource in the cache.", "response": "def resource_size(self, resource_name): # pylint: disable=R0201\n        \"\"\"\n        meterer.resource_size(resource_name) -> int\n\n        Retrieve the size of the given resource.\n        \"\"\"\n        cached_size = self.get_cached_resource_size(resource_name)\n        if cached_size is not None:\n            return cached_size[\"size\"]\n\n        # Not cached or cache timeout exceeded. Get the actual size and record\n        # it in the cache.\n        actual_size = self.get_actual_resource_size(resource_name)\n        self.set_cached_resource_size(resource_name, actual_size)\n        return actual_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_limits_for_pool(self, pool):\n        pool_limits = self.cache.get(\"LIMIT:%s\" % pool)\n        if pool_limits is None:\n            return {}\n\n        return json_loads(pool_limits)", "response": "Returns the limits for the given pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_limits_for_pool(self, pool, **kw):\n        pool_limits = {}\n\n        for time_period in [\"year\", \"month\", \"week\", \"day\", \"hour\"]:\n            if time_period not in kw:\n                continue\n\n            limit = kw.pop(time_period)\n            if limit is not None and not isinstance(limit, (float, int)):\n                raise TypeError(\"%s must be a float or int or None\",\n                                time_period)\n            pool_limits[time_period] = limit\n\n        if kw:\n            raise ValueError(\"Unknown time periods specified: %s\" %\n                             \", \".join(kw.keys()))\n\n        self.cache.set(\"LIMIT:%s\" % pool, json_dumps(pool_limits))\n        return", "response": "Sets the limits for the given pool."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the size of the resource in bytes.", "response": "def get_cached_resource_size(self, resource_name):\n        \"\"\"\n        meterer.get_cached_resource_size(resource_name) -> dict\n\n        Retrieve cached information about the given resource. The resulting\n        dict has the following structure:\n        {\n            \"size\": int,                # Size of the resource\n            \"recorded_time\": float,     # Unix timestamp when this was generated\n        }\n        \"\"\"\n        size_data = self.cache.get(\"SIZE:%s\" % resource_name)\n        if size_data is None:\n            return None\n\n        return json_loads(size_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the size of the resource in bytes.", "response": "def set_cached_resource_size(self, resource_name, size):\n        \"\"\"\n        meterer.set_cached_resource_size(resource_name)\n\n        Set cached information about the given resource.\n        \"\"\"\n        size_data = json_dumps({\"size\": size, \"recorded_time\": time()})\n        self.cache.set(\n            \"SIZE:%s\" % resource_name, size_data,\n            ex=self.size_cache_timeout)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the period strings for the specified time.", "response": "def get_period_strs(self, now=None):\n        \"\"\"\n        meterer.get_period_strings()\n\n        Return the period strings for the specified time (defaulting to the\n        current time if not specified).\n        \"\"\"\n        if now is None:\n            now = self.dt.utcnow()\n\n        year_str = \"%04d\" % now.year\n        month_str = \"%04d-%02d\" % (now.year, now.month)\n        day_str = \"%04d-%02d-%02d\" % (now.year, now.month, now.day)\n        hour_str = \"%04d-%02d-%02dT%02d\" % (\n            now.year, now.month, now.day, now.hour)\n\n        # Note: The week number may be in the previous year during the last\n        # days of the year.\n        isocal = now.isocalendar()\n        week_str = \"%04d-W%02d\" % (isocal[0], isocal[1])\n\n        return {\n            \"year\": year_str,\n            \"month\": month_str,\n            \"day\": day_str,\n            \"hour\": hour_str,\n            \"week\": week_str,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a connection to the LifeSOS ethernet interface.", "response": "async def async_open(self) -> None:\n        \"\"\"Opens connection to the LifeSOS ethernet interface.\"\"\"\n\n        await self._loop.create_connection(\n            lambda: self,\n            self._host,\n            self._port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the abbr2long from file", "response": "def load_abbr(abbr_file=ABBREVIATION_FILE):\n    \"\"\"\n    Load the abbr2long from file\n    \"\"\"\n    abbr2long = dict()\n    with open(abbr_file) as f:\n        lines = f.read().split('\\n')\n        for line in lines:\n            m = re.match(r'(\\w+)\\t(.+)', line)\n            if m:\n                abbr2long[m.group(1)] = m.group(2)\n    return abbr2long"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the term_freq from spell_file", "response": "def load_spelling(spell_file=SPELLING_FILE):\n    \"\"\"\n    Load the term_freq from spell_file\n    \"\"\"\n    with open(spell_file) as f:\n        tokens = f.read().split('\\n')\n        size = len(tokens)\n        term_freq = {token: size - i for i, token in enumerate(tokens)}\n    return term_freq"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the search_freq from JSON file", "response": "def load_search_freq(fp=SEARCH_FREQ_JSON):\n    \"\"\"\n    Load the search_freq from JSON file\n    \"\"\"\n    try:\n        with open(fp) as f:\n            return Counter(json.load(f))\n    except FileNotFoundError:\n        return Counter()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tokenize(s):\n    s = re.sub(r'(?a)(\\w+)\\'s', r'\\1', s) # clean the 's from Crohn's disease\n    #s = re.sub(r'(?a)\\b', ' ', s) # split the borders of chinese and english chars\n\n    split_pattern = r'[{} ]+'.format(re.escape(STOPCHARS))\n    tokens = [token for token in re.split(split_pattern, s) if not set(token) <= set(string.punctuation)]\n    return tokens", "response": "Tokenize a string into a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef invert_index(source_dir, index_url=INDEX_URL, init=False):\n    raw_index = defaultdict(list)\n    for base, dir_list, fn_list in os.walk(source_dir):\n        for fn in fn_list:\n            fp = os.path.join(base, fn)\n            code = fn\n            with open(fp) as f:\n                tokens = f.read().strip().split('\\n')\n                for token in tokens:\n                    raw_index[token].append(code)\n    index = Shove(store=index_url)\n    if init:\n        index.clear()\n    index.update(raw_index)\n    index.sync()\n    return index", "response": "Builds the invert index from give source_dir Output a Shove object built on the store_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_spelling(token_folder, spelling_file):\n    token_pattern = r'[a-z]{3,}'\n    tokens = []\n    for base, dirlist, fnlist in os.walk(token_folder):\n        for fn in fnlist:\n            fp = os.path.join(base, fn)\n            with open(fp) as f:\n                toks = re.findall(token_pattern, f.read())\n                tokens.extend(toks)\n\n    token_ranked, _ = zip(*Counter(tokens).most_common())\n    with open(spelling_file, 'w') as f:\n        f.write('\\n'.join(token_ranked))", "response": "Generate the spelling correction file form token_folder and save to spelling_file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting k hints for given code_list", "response": "def get_hints(code_list, k=10, hint_folder=HINT_FOLDER, current_tokens=None):\n    \"\"\"\n    Fetch first k hints for given code_list\n    \"\"\"\n\n    def hint_score(v, size):\n        \"\"\"\n        The formula for hint score\n        \"\"\"\n        return 1.0 - abs(v / (size + 1) - 0.5)\n\n    if len(code_list) <= 1:\n        return [], []\n\n    if current_tokens is None:\n        current_tokens = []\n\n    size = min(len(code_list), MAX_HINT_SMAPLING_SIZE)\n    sample = random.sample(code_list, size)\n    hint_list = []\n    capital_dict = {}\n\n    for code in sample:\n        path = gen_path(hint_folder, code)\n        fp = os.path.join(path, code)\n        try:\n            with open(fp) as f:\n                hints = set(f.read().strip().split('\\n'))\n                hint_list.extend([h.lower() for h in hints])\n                capital_dict.update({hint.lower(): hint for hint in hints})\n        except FileNotFoundError:\n            logging.warning(\"FileNotFoundError: No such file: %r\" % fp )\n    document_freq = Counter(hint_list)\n    score = [(capital_dict[k], hint_score(v, size)) \\\n             for k, v in document_freq.items() if k not in current_tokens]\n    if len(score) == 0:\n        return [], []\n    score.sort(key=lambda x: x[1], reverse=True)\n    hints, scores = tuple(list(zip(*score[:k])))\n    return hints, scores"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch(index, tokens):\n    if len(tokens) == 0:\n        return set()\n    return set.intersection(*[set(index.get(token, [])) for token in tokens])", "response": "Fetch the codes from given tokens\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the snippets from a list of code_list", "response": "def get_snippets(code_list, base=SNIPPET_FOLDER):\n    \"\"\"\n    Get the snippets\n    \"\"\"\n    output = []\n    for code in code_list:\n        path = gen_path(base, code)\n        fp = os.path.join(path, code)\n        try:\n            with open(fp) as f:\n                output.append(f.read())\n        except FileNotFoundError:\n            output.append('')\n            logging.warning(\"FileNotFoundError: No such file: %r\" % fp )\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning tokens the edit distance of which is one from the given token", "response": "def _ed1(token):\n    \"\"\"\n    Return tokens the edit distance of which is one from the given token\n    \"\"\"\n    insertion = {letter.join([token[:i], token[i:]]) for letter in string.ascii_lowercase for i in range(1, len(token) + 1)}\n    deletion = {''.join([token[:i], token[i+1:]]) for i in range(1, len(token) + 1)}\n    substitution = {letter.join([token[:i], token[i+1:]]) for letter in string.ascii_lowercase for i in range(1, len(token) + 1)}\n    transposition = {''.join([token[:i], token[i+1:i+2],  token[i:i+1], token[i+2:]]) for i in range(1, len(token)-1)}\n    return set.union(insertion, deletion, substitution, transposition)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncorrecting a single token according to the term_freq", "response": "def _correct(token, term_freq):\n    \"\"\"\n    Correct a single token according to the term_freq\n    \"\"\"\n    if token.lower() in term_freq:\n        return token\n    e1 = [t for t in _ed1(token) if t in term_freq]\n    if len(e1) > 0:\n        e1.sort(key=term_freq.get)\n        return e1[0]\n    e2 = [t for t in _ed2(token) if t in term_freq]\n    if len(e2) > 0:\n        e2.sort(key=term_freq.get)\n        return e2[0]\n    return token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef correct(tokens, term_freq):\n    log = []\n    output = []\n    for token in tokens:\n        corrected = _correct(token, term_freq)\n        if corrected != token:\n            log.append((token, corrected))\n        output.append(corrected)\n    return output, log", "response": "Correct a list of tokens according to the term_freq\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef result_sort_key(response_item):\n    code, snippet = response_item\n\n    snippet_length = len(snippet)\n    freq = search_freq.get(code, 0)\n    beta = 0.05\n    score = math.log(freq * 0.05 + 1) / (snippet_length + 1)\n\n    return score", "response": "This function returns the sort key for the search results\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for the given query in the given snippet_folder.", "response": "def search(index, query, snippet_folder=SNIPPET_FOLDER, term_freq=term_freq):\n    \"\"\"\n    The highest level of search function\n    \"\"\"\n    fallback_log = []\n    code_list = []\n    tokens = tokenize(query)\n    tokens, abbr_log = abbr_expand(tokens)\n    tokens, correct_log = correct(tokens, term_freq)\n    tokens = lemmatize(tokens)\n    tokens = filterout(tokens)\n    while len(tokens) > 0: # Fallback mechanism\n        code_list = fetch(index, tokens)\n        if len(code_list) > 0:\n            break\n        tokens.sort(key=lambda tk:len(index.get(tk, [])))\n        remove = tokens.pop()\n        fallback_log.append(remove)\n    snippets = get_snippets(code_list, snippet_folder)\n    hints, hint_scores = get_hints(code_list, current_tokens=tokens)\n    response = list(zip(code_list, snippets))\n    response.sort(key=result_sort_key, reverse=True)\n\n    # Count search_frequency\n    if len(response) <= MAX_RESULT: # the respone can be shown in one page\n        search_freq.update(code_list)\n        with open(SEARCH_FREQ_JSON, 'w') as f:\n            json.dump(search_freq, f, indent=2)\n\n    return response, tokens, hints, hint_scores, \\\n           abbr_log, correct_log, fallback_log"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all the ServiceProvider configuration files found in the configuration folders", "response": "def list_available_providers(self):\n        \"\"\"\n        Lists all the ServiceProvider configuration files found in the configuration folders\n        :return: \n        \"\"\"\n        providers = []\n\n        if self.alternative_config_dir:\n            for f in os.listdir(os.path.join(self.alternative_config_dir, self.CLOUD_PROVIDERS_DIR)):\n                if os.path.splitext(f)[1] in ['.conf', '.json']:\n                    try:\n                        n = os.path.join(self.alternative_config_dir, self.CLOUD_PROVIDERS_DIR, f)\n                        providers.append(ServiceProviderConfiguration(n))\n                    except ControllerConfigurationException:\n                        pass\n\n\n        for f in os.listdir(os.path.join(self.default_config_dir, self.CLOUD_PROVIDERS_DIR)):\n            if os.path.splitext(f)[1] in ['.conf', '.json']:\n                try:\n                    n = os.path.join(self.default_config_dir, self.CLOUD_PROVIDERS_DIR, f)\n                    providers.append(ServiceProviderConfiguration(n))\n                except ControllerConfigurationException:\n                    pass\n\n        return providers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all the available Benchmarks configuration files in the configuration folders that are available in the configuration folders that are not in the alternative configuration folders.", "response": "def list_available_tools(self):\n        \"\"\"\n        Lists all the Benchmarks configuration files found in the configuration folders\n        :return: \n        \"\"\"\n        benchmarks = []\n\n        if self.alternative_config_dir:\n            for n in glob.glob(os.path.join(self.alternative_config_dir, self.BENCHMARKS_DIR, '*.conf')):\n                benchmarks.append(BenchmarkToolConfiguration(n))\n\n        for n in glob.glob(os.path.join(self.default_config_dir, self.BENCHMARKS_DIR, '*.conf')):\n            benchmarks.append(BenchmarkToolConfiguration(n))\n\n        return benchmarks"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_storage_config_file(self):\n        if self.alternative_config_dir:\n            file = os.path.join(self.alternative_config_dir, self.STORAGE_CONFIG_FILE)\n            if os.path.isfile(file):\n                return file\n\n            file = os.path.join(self.alternative_config_dir, self.STORAGE_JSON_CONFIG_FILE)\n            if os.path.isfile(file):\n                return file\n\n        file = os.path.join(self.default_config_dir, self.STORAGE_CONFIG_FILE)\n        if os.path.isfile(file):\n            return file\n\n        file = os.path.join(self.default_config_dir, self.STORAGE_JSON_CONFIG_FILE)\n        if os.path.isfile(file):\n            return file\n\n        raise ControllerConfigurationException('Storage configuration file not found')", "response": "Returns the configuration file for the storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate form. Return True if Django validates the form, the username obeys the parameters, and passwords match. Return False otherwise.", "response": "def is_valid(self):\n        ''' Validate form.\n        Return True if Django validates the form, the username obeys the parameters, and passwords match.\n        Return False otherwise.\n        '''\n        if not super(ProfileRequestForm, self).is_valid():\n            return False\n        validity = True\n        if self.cleaned_data['password'] != self.cleaned_data['confirm_password']:\n            form_add_error(self, 'password', \"Passwords don't match.\")\n            form_add_error(self, 'confirm_password', \"Passwords don't match.\")\n            validity = False\n        return validity"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate form. Return True if Django validates the form, the username obeys the parameters, and passwords match. Return False otherwise.", "response": "def is_valid(self):\n        ''' Validate form.\n        Return True if Django validates the form, the username obeys the parameters, and passwords match.\n        Return False otherwise.\n        '''\n        if not super(AddUserForm, self).is_valid():\n            return False\n        first_name = self.cleaned_data['first_name']\n        last_name = self.cleaned_data['last_name']\n        if User.objects.filter(first_name=first_name, last_name=last_name).count():\n            non_field_error = \"A profile for {0} {1} already exists with username {2}.\" \\\n              .format(first_name, last_name,\n                      User.objects.get(first_name=first_name, last_name=last_name).username)\n            form_add_error(self, '__all__', non_field_error)\n            return False\n        if self.cleaned_data['user_password'] != self.cleaned_data['confirm_password']:\n            form_add_error(self, 'user_password', \"Passwords don't match.\")\n            form_add_error(self, 'confirm_password', \"Passwords don't match.\")\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate form. Return True if Django validates the form, the username obeys the parameters, and passwords match. Return False otherwise.", "response": "def is_valid(self):\n        ''' Validate form.\n        Return True if Django validates the form, the username obeys the parameters, and passwords match.\n        Return False otherwise.\n        '''\n        if not super(DeleteUserForm, self).is_valid():\n            return False\n        if self.user == self.request.user:\n            self._errors[\"__all__\"] = self.error_class([MESSAGES['SELF_DELETE']])\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _do_connection(self, wgt, sig, func):\n        #new style  (we use this)\n        #self.btn_name.clicked.connect(self.on_btn_name_clicked)\n        #old style\n        #self.connect(self.btn_name, SIGNAL('clicked()'), self.on_btn_name_clicked)\n\n        if hasattr(self, wgt):\n            wgtobj = getattr(self, wgt)\n            if hasattr(wgtobj, sig):\n                sigobj = getattr(wgtobj, sig)\n                if isinstance(sigobj, Signal):\n                    sigobj.connect(func)\n                    return 0\n        return 1", "response": "Make a connection between a GUI widget and a callable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing a list of widget names.", "response": "def _process_list(self, l):\n        \"\"\"\n        Processes a list of widget names.\n\n        If any name is between `` then it is supposed to be a regex.\n        \"\"\"\n        if hasattr(self, l):\n            t = getattr(self, l)\n\n            def proc(inp):\n                w = inp.strip()\n\n                if w.startswith('`'):\n                    r = re.compile(w[1:-1])\n                    return [u for u in [m.group() for m in [r.match(x) for x in dir(self)] if m] if isinstance(getattr(self, u), QObject)]\n                else:\n                    return [w]\n\n            return list(set([y for x in map(proc, t.split(',')) for y in x]))\n\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auto_connect(self):\n        for o in dir(self):\n            if o.startswith('_on_') and '__' in o:\n                func = getattr(self, o)\n                wgt, sig = o.split('__')\n                if self._do_connection(wgt[4:], sig, func):\n                    print('Failed to connect', o)\n\n            if o.startswith('_when_') and '__' in o:\n                func = getattr(self, o)\n                lst, sig = o.split('__')\n                lst = self._process_list(lst[5:])  #5 to keep _ at beggining\n                for w in lst:\n                    if self._do_connection(w, sig, func):\n                        print('Failed to connect', o)", "response": "Connect between every member function to a GUI signal and every widget whose name is in format _on_ + _when_ + _group1 + _when_ + _group1 + _when_ + _group1 + _when_ group1 + _when_ group1 + _when_ group1 + _when_ group1 + _when_ group1 + _when_ group1 + _when_ group1 + _when_ group1 + _when_ group1."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_signals_and_slots(self):\n        for i in xrange(self.metaObject().methodCount()):\n             m = self.metaObject().method(i)\n             if m.methodType() == QMetaMethod.MethodType.Signal:\n                 print(\"SIGNAL: sig=\", m.signature(), \"hooked to nslots=\", self.receivers(SIGNAL(m.signature())))\n             elif m.methodType() == QMetaMethod.MethodType.Slot:\n                 print(\"SLOT: sig=\", m.signature())", "response": "Prints all active Signal and Slots and Signal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_all_signals(self):\n        for o in dir(self):\n            obj= getattr(self, o)\n            #print o, type(obj)\n            div = False\n            for c in dir(obj):\n                cobj = getattr(obj, c)\n                if isinstance(cobj, Signal):\n                    print('def _on_{}__{}(self):'.format(o, c))\n                    div = True\n\n            if div: print('-'*30)", "response": "Prints out every signal available for this widget and childs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self, name, mode='rb'):\n        self.request = urlopen(self.url)\n        if self.algorithm:\n            self.hash = hashlib.new(self.algorithm)\n        return self", "response": "Opens the specified file from the storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlook for files in the app directories.", "response": "def find(self, path, all=False):\n        '''\n        Looks for files in the app directories.\n        '''\n        found = os.path.join(settings.STATIC_ROOT, path)\n        if all:\n            return [found]\n        else:\n            return found"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interrupt(self):\n\t\tif(self.device.read(9) & 0x01):\n\t\t\tself.handle_request()\n\t\tself.device.clear_IR()", "response": "Handle an interrupt from the RendererDevice."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put_char(self, char, r, g, b):\n\t\tr, g, b = r & 0xff, g & 0xff, b & 0xff\n\t\tif(char == 0):\n\t\t\tchar = \" \"\n\n\t\tif(char == \"\\r\"):\n\t\t\tself.cursor[1] = 0\n\t\t\treturn\n\t\tif(char == \"\\t\"):\n\t\t\tfor i in range(8):\n\t\t\t\tself.put_char(\" \", r, g, b)\n\t\t\treturn\n\t\t\n\t\tif(self.max_chars_per_col > self.cursor[0]):\n\t\t\tif(char == \"\\n\"):\n\t\t\t\tself.cursor[1] = 0\n\t\t\t\tself.cursor[0] += 1\n\t\t\t\treturn\n\n\t\t\tif(self.max_chars_per_line > self.cursor[1]):\n\t\t\t\tself.char_buffer[self.cursor[0]][self.cursor[1]] = (char, r, g, b)\n\t\t\t\tself.cursor[1] += 1\n\t\t\telse:\n\t\t\t\tself.cursor[0] += 1\n\t\t\t\tself.cursor[1] = 0\n\t\t\t\tself.char_buffer[self.cursor[0]][self.cursor[1]] = (char, r, g, b)\n\t\t\t\tself.cursor[1] += 1\n\t\t\tself.draw_char_screen()\n\t\telse:\n\t\t\tself.char_buffer.append([(\" \", 0xff, 0xff, 0xff) for i in range(self.max_chars_per_line)])\n\t\t\tself.cursor[0] -= 1\n\t\t\tself.put_char(char, r, g, b)", "response": "This method puts a character into the character buffer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_char_screen(self):\n\t\tself.screen = Image.new(\"RGB\", (self.height, self.width))\n\t\tself.drawer = ImageDraw.Draw(self.screen)\n\n\t\tfor sy, line in enumerate(self.char_buffer):\n\t\t\tfor sx, tinfo in enumerate(line):\n\t\t\t\tself.drawer.text((sx * 6, sy * 9), tinfo[0], fill=tinfo[1:])\n\t\tself.output_device.interrupt()", "response": "Draws the output buffered in the char_buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a command to the CLI - specify args as you would to the CLI - specify args as you would to the CLI - add_func", "response": "def add_func(self, callback, names, *args):\n        \"\"\"Adds a command to the CLI - specify args as you would to\n        argparse.ArgumentParser.add_argument()\n        \"\"\"\n\n        if isinstance(names, list):\n            for name in names:\n                self.add_func(callback, name, *args)\n                self.aliases[name] = names\n        elif isinstance(names, str):\n            if names in self.cmds or names in self.clis:\n                raise ValueError('Attempting to overwrite cmd or extern CLI: %s' % names)\n            parser = argparse.ArgumentParser(prog=names)\n            for cmd, spec in args:\n                parser.add_argument(cmd, **spec)\n            self.cmds[names] = (callback, parser)\n        else:\n            raise TypeError(\"Command must be specified by str name or list of names\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_cli(self, prefix, other_cli):\n        if prefix not in self.clis and prefix not in self.cmds:\n            self.clis[prefix] = other_cli\n        else:\n            raise ValueError('Attempting to overwrite cmd or extern CLI: %s' % prefix)", "response": "Adds the functionality of the other CLI to this one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to run the given command with the given arguments", "response": "def _dispatch(self, cmd, args):\n        \"\"\"Attempt to run the given command with the given arguments\n        \"\"\"\n        if cmd in self.clis:\n            extern_cmd, args = args[0], args[1:]\n            self.clis[cmd]._dispatch(extern_cmd, args)\n        else:\n            if cmd in self.cmds:\n                callback, parser = self.cmds[cmd]\n                try:\n                    p_args = parser.parse_args(args)\n                except SystemExit:\n                    return\n                callback(**dict(filter(lambda p:p[1] != None, p_args._get_kwargs())))\n            else:\n                self._invalid_cmd(command=cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing line from CLI read loop and execute provided command", "response": "def exec_cmd(self, cmdstr):\n        \"\"\"Parse line from CLI read loop and execute provided command\n        \"\"\"\n        parts = cmdstr.split()\n        if len(parts):\n            cmd, args = parts[0], parts[1:]\n            self._dispatch(cmd, args)\n        else:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_help(self):\n        seen_aliases = set()\n        print('-'*80)\n        for cmd in sorted(self.cmds):\n            if cmd not in self.builtin_cmds:\n                if cmd not in seen_aliases:\n                    if cmd in self.aliases:\n                        seen_aliases.update(self.aliases[cmd])\n                        disp = '/'.join(self.aliases[cmd])\n                    else:\n                        disp = cmd\n                    _, parser = self.cmds[cmd]\n                    usage = parser.format_usage()\n                    print('%s: %s' % (disp, ' '.join(usage.split()[2:])))\n        print('External CLIs: %s' % ', '.join(sorted(self.clis)))", "response": "Prints usage of all registered commands collapsing aliases\n        into one record"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_finder(self, manager, package_name):\n        filename = '{env_path}/results.json'.format(env_path=manager.env_path)\n        subprocess.call([\n            manager.venv_python, self._finder_path, package_name, filename\n        ])\n\n        # Load results into this context\n        json_str = open(filename, 'r').read()\n        return json.loads(json_str)", "response": "Execute finder script within the temporary venv context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over all rules of a given class and generate ConvertedRule objects for each one.", "response": "def _iterClass(cls, prefix=''):\n    \"\"\"\n    Descend a Klein()'s url_map, and generate ConvertedRule() for each one\n    \"\"\"\n    iterableRules = [(prefix, cls, cls.app.url_map.iter_rules())]\n    for prefix, currentClass, i in iter(iterableRules):\n        for rule in i:\n            converted = dumpRule(currentClass, rule, prefix)\n            if converted.branch:\n                continue\n\n            if converted.subKlein:\n                clsDown = namedAny(converted.subKlein)\n                iterableRules.append((converted.rulePath, clsDown, clsDown.app.url_map.iter_rules()))\n\n            yield converted"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps all urls branching from a class as OpenAPI 3 documentation", "response": "def urltool(classqname, filt, reverse):\n    \"\"\"\n    Dump all urls branching from a class as OpenAPI 3 documentation\n\n    The class must be given as a FQPN which points to a Klein() instance.\n\n    Apply optional [FILT] as a regular expression searching within urls. For\n    example, to match all urls beginning with api, you might use '^/api'\n    \"\"\"\n    filt = re.compile(filt or '.*')\n\n    rootCls = namedAny(classqname)\n    rules = list(_iterClass(rootCls))\n    arr = []\n    for item in sorted(rules):\n        if item.subKlein:\n            continue\n\n        matched = filt.search(item.rulePath)\n        matched = not matched if reverse else matched\n        if matched:\n            arr.append(tuple(item.toOpenAPIPath()))\n\n    openapi3 = openapi.OpenAPI()\n    for pathPath, pathItem in arr:\n        if pathPath in openapi3.paths:\n            openapi3.paths[pathPath].merge(pathItem)\n        else:\n            openapi3.paths[pathPath] = pathItem\n    print(yaml.dump(openapi3, default_flow_style=False))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a rule into an in - between representation of it.", "response": "def dumpRule(serviceCls, rule, prefix):\n    \"\"\"\n    Create an in-between representation of the rule, so we can eventually convert it to OpenAPIPathItem with OpenAPIOperation(s)\n    \"\"\"\n    rulePath = prefix + rule.rule\n    rulePath = re.sub('/{2,}', '/', rulePath)\n\n    cor = ConvertedRule(\n            rulePath=rulePath,\n            operationId=rule.endpoint\n            )\n\n    # look for methods\n    for meth in sorted(rule.methods or []):\n        cor.methods.append(meth)\n\n    # edit _branch operationId to provide the true method name\n    origEP = cor.operationId\n    if origEP.endswith('_branch'):\n        origEP = origEP[:-7]\n        cor.branch = True\n    cor.operationId = '%s.%s' % (serviceCls.__name__, origEP)\n    # get the actual method so we can inspect it for extension attributes\n    meth = getattr(serviceCls, origEP)\n\n    if hasattr(meth, '_subKleinQname'):\n        cor.subKlein = meth._subKleinQname\n\n    cor.doco = OpenAPIExtendedDocumentation.fromObject(meth, decode=True)\n    return cor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef literal_unicode_representer(dumper, data):\n    if '\\n' in data:\n        return dumper.represent_scalar(u'tag:yaml.org,2002:str', data, style='|')\n    else:\n        return dumper.represent_scalar(u'tag:yaml.org,2002:str', data)", "response": "Return a string representation of the given data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap_job_cursor(func_, *args, **kwargs):\n    assert isinstance(args[0], str)\n    assert isinstance(args[1], (str, type(None)))\n    assert isinstance(args[2], (str, type(None)))\n    if args[2] and not args[1]:\n        raise ValueError(\"Must specify location if using port.\")\n    return func_(*args, **kwargs)", "response": "Decorator for _jobs_cursor function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap rethinkdb specific errors as builtin / Brain errors", "response": "def wrap_rethink_errors(func_, *args, **kwargs):\n    \"\"\"\n    Wraps rethinkdb specific errors as builtin/Brain errors\n\n    :param func_: <function> to call\n    :param args:  <tuple> positional arguments\n    :param kwargs: <dict> keyword arguments\n    :return: inherits from the called function\n    \"\"\"\n    try:\n        return func_(*args, **kwargs)\n    except WRAP_RETHINK_ERRORS as reql_err:\n        raise ValueError(str(reql_err))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps a function to connect to the last connection in the sequence of functions.", "response": "def wrap_connection(func_, *args, **kwargs):\n    \"\"\"\n    conn (connection) must be the last positional argument\n    in all wrapped functions\n\n    :param func_: <function> to call\n    :param args:  <tuple> positional arguments\n    :param kwargs: <dict> keyword arguments\n    :return:\n    \"\"\"\n    if not args[-1]:\n        new_args = list(args)\n        new_args[-1] = connect()\n        args = tuple(new_args)\n    return func_(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the url with changed parameters", "response": "def qurl(url, add=None, exclude=None, remove=None):\n    \"\"\"\n    Returns the url with changed parameters\n    \"\"\"\n    urlp = list(urlparse(url))\n    qp = parse_qsl(urlp[4])\n\n    # Add parameters\n    add = add if add else {}\n    for name, value in add.items():\n        if isinstance(value, (list, tuple)):\n            # Append mode\n            value = [smart_str(v) for v in value]\n            qp = [p for p in qp if p[0] != name or p[1] not in value]\n            qp.extend([(name, smart_str(val)) for val in value])\n        else:\n            # Set mode\n            qp = [p for p in qp if p[0] != name]\n            qp.append((name, smart_str(value)))\n\n    # Exclude parameters\n    exclude = exclude if exclude else {}\n    for name, value in exclude.items():\n        if not isinstance(value, (list, tuple)):\n            value = [value]\n        value = [smart_str(v) for v in value]\n        qp = [p for p in qp if p[0] != name or p[1] not in value]\n\n    # Remove parameters\n    remove = remove if remove else []\n    for name in remove:\n        qp = [p for p in qp if p[0] != name]\n\n    urlp[4] = urlencode(qp, True)\n    return urlunparse(urlp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclips an adaptor sequence from the end of the read.", "response": "def clip_adaptor(read, adaptor):\n  \"\"\"\n  Clip an adaptor sequence from this sequence. We assume it's in the 3'\n  end. This is basically a convenience wrapper for clipThreePrime. It\n  requires 8 out of 10 of the first bases in the adaptor sequence to match\n  for clipping to occur.\n\n  :param adaptor: sequence to look for. We only use the first 10 bases;\n                  must be a full Sequence object, not just a string.\n  \"\"\"\n  missmatches = 2\n  adaptor = adaptor.truncate(10)\n  read.clip_end(adaptor, len(adaptor) - missmatches)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether this sequence contains adaptor.", "response": "def contains_adaptor(read, adaptor):\n  \"\"\"\n  Check whether this sequence contains adaptor contamination. If it exists,\n  we assume it's in the 3' end. This function requires 8 out of 10 of the\n  first bases in the adaptor sequence to match for an occurrence to be\n  reported.\n\n  :param adaptor: sequence to look for. We only use first 10 bases; must be\n                  a full Sequence object, not just string.\n  :return: True if there is an occurence of <adaptor>, False otherwise\n  \"\"\"\n  origSeq = read.sequenceData\n  clip_adaptor(read, adaptor)\n  res = False\n  if read.sequenceData != origSeq:\n    res = True\n  read.sequenceData = origSeq\n  return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef truncate(self, size):\n    if size > len(self):\n      raise NGSReadError(\"Trying to truncate NGS read to size \" + str(size) +\n                         \", but read is only \" + str(len(self)) +\n                         \" nucleotides long\")\n    if size < 0:\n      raise NGSReadError(\"Trying to truncate NGS read to size less than 0\")\n\n    self.trimRight(len(self) - size)", "response": "truncate this fastqSequence in - place so it is only <size > nucleotides"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving amount nucleotides from the right side of the sequence.", "response": "def trimRight(self, amount):\n    \"\"\"\n      Trim this fastqSequence in-place by removing <amount> nucleotides from\n      the 3' end (right end).\n\n      :param amount: the number of nucleotides to trim from the right-side of\n                     this sequence.\n    \"\"\"\n    if amount == 0:\n      return\n    self.sequenceData = self.sequenceData[:-amount]\n    self.seq_qual = self.seq_qual[:-amount]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the amount nucleotides from the left side of the sequence.", "response": "def trimLeft(self, amount):\n    \"\"\"\n      Trim this fastqSequence in-place by removing <amount> nucleotides from\n      the 5' end (left end).\n\n      :param amount: the number of nucleotides to trim from the left-side of\n                     this sequence.\n    \"\"\"\n    if amount == 0:\n      return\n    self.sequenceData = self.sequenceData[amount:]\n    self.sequenceQual = self.sequenceQual[amount:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the relative quality score for a given base call at a given index.", "response": "def getRelativeQualityScore(self, i, score_type=\"ILLUMINA_PHRED_PLUS_33\"):\n    \"\"\"\n    Get the realtive quality score (i.e. the phred quality score) for a given\n    base.\n\n    :raise: NGSReadError if the index is less than 0 or more than l-1 where l\n            is the length of the read; NGSReadError if the encoded quality\n            score at the given location is outside the expected range;\n            NGSReadError if the read has no quality string; NGSReadError if\n            sepficied encoding scheme is unknown.\n    \"\"\"\n    # error out if no quality string, or index is out of range\n    if self.seq_qual is None:\n      raise NGSReadError(\"Error finding realtive quality for base call at \" +\n                         \"location \" + str(i) + \" in read \" + self.name +\n                         \"; read has no quality string\")\n    if i < 0 or i > self.seq_qual:\n      raise NGSReadError(\"Error finding relative quality for base call at \" +\n                         \"location \" + str(i) + \" in read \" + self.name +\n                         \"; outside of range for read with quality score \" +\n                         \"string of length \" + str(len(self.seq_qual)))\n\n    val = self.seq_qual[i]\n    if score_type == \"ILLUMINA_PHRED_PLUS_33\":\n      return ord(val) - self.LOWSET_SCORE_ILL_18_PHRD_33\n    elif score_type == \"ILLUMINA_PHRED_PLUS_64\":\n      return ord(val) - self.LOWSET_SCORE\n    else:\n      raise NGSReadError(\"Unknown score type: \" + score_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse_complement(self, is_RNA=None):\n    Sequence.reverseComplement(self, is_RNA)\n    self.seq_qual = self.seq_qual[::-1]", "response": "Reverse complement this read in - place."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit this read into two halves.", "response": "def split(self, point=None):\n    \"\"\"\n    Split this read into two halves. Original sequence is left unaltered.\n\n    The name of the resultant reads will have '.1' and '.2' appended to the\n    name from the original read.\n\n    :param point: the point (index, starting from 0) at which to split this\n                  read -- everything before this index will be placed into the\n                  first sequence, and everything at or after this index will be\n                  placed in the second resultant sequence. If None\n                  (the default), then we split in the middle; if the original\n                  size is not a multiple of 2, the extra nucleotide is placed\n                  into the second resultant sequence. Must be >= 0\n                  and <= length of sequence.\n    :return: two NGSRead objects which correspond to the split of this\n             sequence.\n    \"\"\"\n    if point is None:\n      point = len(self) / 2\n    if point < 0:\n      raise NGSReadError(\"Cannot split read at index less than 0 \" +\n                         \"(index provided: \" + str(point) + \")\")\n    if point > len(self):\n      raise NGSReadError(\"Cannot split read at index greater than read \" +\n                         \"length (index provided: \" + str(point) + \")\")\n\n    r1 = NGSRead(self.sequenceData[:point], self.name + \".1\",\n                 self.seq_qual[:point])\n    r2 = NGSRead(self.sequenceData[point:], self.name + \".2\",\n                 self.seq_qual[point:])\n    return r1, r2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging two sequences into a single FastqSequence object.", "response": "def merge(self, other, forceMerge=False):\n    \"\"\"\n      Merge two reads by concatenating their sequence data and their\n      quality data (<self> first, then <other>); <self> and <other> must have\n      the same sequence name. A new merged FastqSequence object is returned;\n      <Self> and <other> are left unaltered.\n\n      :param other: the other sequence to merge with self.\n      :param forceMerge: force the merge to occur, even if sequences names\n                         don't match. In this case, <self> takes precedence.\n      :return: A new FastqSequence that represents the merging of <self> and\n               <other>\n      :raise: FastqSequenceError if the sequences names do not match, and the\n              forceMerge parameter is not set.\n    \"\"\"\n    if self.sequenceName != other.sequenceName and not forceMerge:\n      raise NGSReadError(\"cannot merge \" + self.sequenceName + \" with \" +\n                         other.sequenceName + \" -- different \" +\n                         \"sequence names\")\n\n    name = self.sequenceName\n    seq = self.sequenceData + other.sequenceData\n    qual = self.sequenceQual + other.sequenceQual\n\n    return NGSReadError(name, seq, qual)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string representation of this NGS read in FastQ format", "response": "def to_fastq_str(self):\n    \"\"\"\n    :return: string representation of this NGS read in FastQ format\n    \"\"\"\n    return \"@\" + self.name + \"\\n\" + self.sequenceData +\\\n           \"\\n\" + \"+\" + self.name + \"\\n\" + self.seq_qual"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that the WebSocket connection is open.", "response": "async def ensure_open(self) -> None:\n        \"\"\"\n        Check that the WebSocket connection is open.\n\n        Raise :exc:`~websockets.exceptions.ConnectionClosed` if it isn't.\n\n        \"\"\"\n        # Handle cases from most common to least common for performance.\n        if self.state is State.OPEN:\n            # If self.transfer_data_task exited without a closing handshake,\n            # self.close_connection_task may be closing it, going straight\n            # from OPEN to CLOSED.\n            if self.transfer_data_task.done():\n                await asyncio.shield(self.close_connection_task)\n                raise ConnectionClosed(\n                    self.close_code, self.close_reason\n                ) from self.transfer_data_exc\n            else:\n                return\n\n        if self.state is State.CLOSED:\n            raise ConnectionClosed(\n                self.close_code, self.close_reason\n            ) from self.transfer_data_exc\n\n        if self.state is State.CLOSING:\n            # If we started the closing handshake, wait for its completion to\n            # get the proper close code and status. self.close_connection_task\n            # will complete within 4 or 5 * close_timeout after close(). The\n            # CLOSING state also occurs when failing the connection. In that\n            # case self.close_connection_task will complete even faster.\n            await asyncio.shield(self.close_connection_task)\n            raise ConnectionClosed(\n                self.close_code, self.close_reason\n            ) from self.transfer_data_exc\n\n        # Control may only reach this point in buggy third-party subclasses.\n        assert self.state is State.CONNECTING\n        raise InvalidState(\"WebSocket connection isn't established yet\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def transfer_data(self) -> None:\n        try:\n            while True:\n                message = await self.read_message()\n\n                # Exit the loop when receiving a close frame.\n                if message is None:\n                    break\n\n                # Wait until there's room in the queue (if necessary).\n                if self.max_queue is not None:\n                    while len(self.messages) >= self.max_queue:\n                        self._put_message_waiter = self.loop.create_future()\n                        try:\n                            await self._put_message_waiter\n                        finally:\n                            self._put_message_waiter = None\n\n                # Put the message in the queue.\n                self.messages.append(message)\n\n                # Notify recv().\n                if self._pop_message_waiter is not None:\n                    self._pop_message_waiter.set_result(None)\n                    self._pop_message_waiter = None\n\n        except asyncio.CancelledError as exc:\n            self.transfer_data_exc = exc\n            # If fail_connection() cancels this task, avoid logging the error\n            # twice and failing the connection again.\n            raise\n\n        except WebSocketProtocolError as exc:\n            self.transfer_data_exc = exc\n            self.fail_connection(1002)\n\n        except (ConnectionError, EOFError) as exc:\n            # Reading data with self.reader.readexactly may raise:\n            # - most subclasses of ConnectionError if the TCP connection\n            #   breaks, is reset, or is aborted;\n            # - IncompleteReadError, a subclass of EOFError, if fewer\n            #   bytes are available than requested.\n            self.transfer_data_exc = exc\n            self.fail_connection(1006)\n\n        except UnicodeDecodeError as exc:\n            self.transfer_data_exc = exc\n            self.fail_connection(1007)\n\n        except PayloadTooBig as exc:\n            self.transfer_data_exc = exc\n            self.fail_connection(1009)\n\n        except Exception as exc:\n            # This shouldn't happen often because exceptions expected under\n            # regular circumstances are handled above. If it does, consider\n            # catching and handling more exceptions.\n            logger.error(\"Error in data transfer\", exc_info=True)\n\n            self.transfer_data_exc = exc\n            self.fail_connection(1011)", "response": "Coroutine to read incoming messages and put them in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a single message from the connection.", "response": "async def read_message(self) -> Optional[Data]:\n        \"\"\"\n        Read a single message from the connection.\n\n        Re-assemble data frames if the message is fragmented.\n\n        Return ``None`` when the closing handshake is started.\n\n        \"\"\"\n        frame = await self.read_data_frame(max_size=self.max_size)\n\n        # A close frame was received.\n        if frame is None:\n            return None\n\n        if frame.opcode == OP_TEXT:\n            text = True\n        elif frame.opcode == OP_BINARY:\n            text = False\n        else:  # frame.opcode == OP_CONT\n            raise WebSocketProtocolError(\"Unexpected opcode\")\n\n        # Shortcut for the common case - no fragmentation\n        if frame.fin:\n            return frame.data.decode(\"utf-8\") if text else frame.data\n\n        # 5.4. Fragmentation\n        chunks: List[Data] = []\n        max_size = self.max_size\n        if text:\n            decoder_factory = codecs.getincrementaldecoder(\"utf-8\")\n            # https://github.com/python/typeshed/pull/2752\n            decoder = decoder_factory(errors=\"strict\")  # type: ignore\n            if max_size is None:\n\n                def append(frame: Frame) -> None:\n                    nonlocal chunks\n                    chunks.append(decoder.decode(frame.data, frame.fin))\n\n            else:\n\n                def append(frame: Frame) -> None:\n                    nonlocal chunks, max_size\n                    chunks.append(decoder.decode(frame.data, frame.fin))\n                    max_size -= len(frame.data)\n\n        else:\n            if max_size is None:\n\n                def append(frame: Frame) -> None:\n                    nonlocal chunks\n                    chunks.append(frame.data)\n\n            else:\n\n                def append(frame: Frame) -> None:\n                    nonlocal chunks, max_size\n                    chunks.append(frame.data)\n                    max_size -= len(frame.data)\n\n        append(frame)\n\n        while not frame.fin:\n            frame = await self.read_data_frame(max_size=max_size)\n            if frame is None:\n                raise WebSocketProtocolError(\"Incomplete fragmented message\")\n            if frame.opcode != OP_CONT:\n                raise WebSocketProtocolError(\"Unexpected opcode\")\n            append(frame)\n\n        # mypy cannot figure out that chunks have the proper type.\n        return (\"\" if text else b\"\").join(chunks)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def read_data_frame(self, max_size: int) -> Optional[Frame]:\n        # 6.2. Receiving Data\n        while True:\n            frame = await self.read_frame(max_size)\n\n            # 5.5. Control Frames\n            if frame.opcode == OP_CLOSE:\n                # 7.1.5.  The WebSocket Connection Close Code\n                # 7.1.6.  The WebSocket Connection Close Reason\n                self.close_code, self.close_reason = parse_close(frame.data)\n                # Echo the original data instead of re-serializing it with\n                # serialize_close() because that fails when the close frame is\n                # empty and parse_close() synthetizes a 1005 close code.\n                await self.write_close_frame(frame.data)\n                return None\n\n            elif frame.opcode == OP_PING:\n                # Answer pings.\n                ping_hex = frame.data.hex() or \"[empty]\"\n                logger.debug(\n                    \"%s - received ping, sending pong: %s\", self.side, ping_hex\n                )\n                await self.pong(frame.data)\n\n            elif frame.opcode == OP_PONG:\n                # Acknowledge pings on solicited pongs.\n                if frame.data in self.pings:\n                    # Acknowledge all pings up to the one matching this pong.\n                    ping_id = None\n                    ping_ids = []\n                    while ping_id != frame.data:\n                        ping_id, pong_waiter = self.pings.popitem(last=False)\n                        ping_ids.append(ping_id)\n                        pong_waiter.set_result(None)\n                    pong_hex = binascii.hexlify(frame.data).decode() or \"[empty]\"\n                    logger.debug(\n                        \"%s - received solicited pong: %s\", self.side, pong_hex\n                    )\n                    ping_ids = ping_ids[:-1]\n                    if ping_ids:\n                        pings_hex = \", \".join(\n                            binascii.hexlify(ping_id).decode() or \"[empty]\"\n                            for ping_id in ping_ids\n                        )\n                        plural = \"s\" if len(ping_ids) > 1 else \"\"\n                        logger.debug(\n                            \"%s - acknowledged previous ping%s: %s\",\n                            self.side,\n                            plural,\n                            pings_hex,\n                        )\n                else:\n                    pong_hex = binascii.hexlify(frame.data).decode() or \"[empty]\"\n                    logger.debug(\n                        \"%s - received unsolicited pong: %s\", self.side, pong_hex\n                    )\n\n            # 5.6. Data Frames\n            else:\n                return frame", "response": "Read a single data frame from the connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a single frame from the connection.", "response": "async def read_frame(self, max_size: int) -> Frame:\n        \"\"\"\n        Read a single frame from the connection.\n\n        \"\"\"\n        frame = await Frame.read(\n            self.reader.readexactly,\n            mask=not self.is_client,\n            max_size=max_size,\n            extensions=self.extensions,\n        )\n        logger.debug(\"%s < %r\", self.side, frame)\n        return frame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def write_close_frame(self, data: bytes = b\"\") -> None:\n        # Test and set the connection state before sending the close frame to\n        # avoid sending two frames in case of concurrent calls.\n        if self.state is State.OPEN:\n            # 7.1.3. The WebSocket Closing Handshake is Started\n            self.state = State.CLOSING\n            logger.debug(\"%s - state = CLOSING\", self.side)\n\n            # 7.1.2. Start the WebSocket Closing Handshake\n            await self.write_frame(True, OP_CLOSE, data, _expected_state=State.CLOSING)", "response": "Write a close frame to the current connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def keepalive_ping(self) -> None:\n        if self.ping_interval is None:\n            return\n\n        try:\n            while True:\n                await asyncio.sleep(self.ping_interval, loop=self.loop)\n\n                # ping() cannot raise ConnectionClosed, only CancelledError:\n                # - If the connection is CLOSING, keepalive_ping_task will be\n                #   canceled by close_connection() before ping() returns.\n                # - If the connection is CLOSED, keepalive_ping_task must be\n                #   canceled already.\n                ping_waiter = await self.ping()\n\n                if self.ping_timeout is not None:\n                    try:\n                        await asyncio.wait_for(\n                            ping_waiter, self.ping_timeout, loop=self.loop\n                        )\n                    except asyncio.TimeoutError:\n                        logger.debug(\"%s ! timed out waiting for pong\", self.side)\n                        self.fail_connection(1011)\n                        break\n\n        except asyncio.CancelledError:\n            raise\n\n        except Exception:\n            logger.warning(\"Unexpected exception in keepalive ping task\", exc_info=True)", "response": "Send a Ping frame and wait for a Pong frame."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def close_connection(self) -> None:\n        try:\n            # Wait for the data transfer phase to complete.\n            if hasattr(self, \"transfer_data_task\"):\n                try:\n                    await self.transfer_data_task\n                except asyncio.CancelledError:\n                    pass\n\n            # Cancel the keepalive ping task.\n            if hasattr(self, \"keepalive_ping_task\"):\n                self.keepalive_ping_task.cancel()\n\n            # A client should wait for a TCP close from the server.\n            if self.is_client and hasattr(self, \"transfer_data_task\"):\n                if await self.wait_for_connection_lost():\n                    return\n                logger.debug(\"%s ! timed out waiting for TCP close\", self.side)\n\n            # Half-close the TCP connection if possible (when there's no TLS).\n            if self.writer.can_write_eof():\n                logger.debug(\"%s x half-closing TCP connection\", self.side)\n                self.writer.write_eof()\n\n                if await self.wait_for_connection_lost():\n                    return\n                logger.debug(\"%s ! timed out waiting for TCP close\", self.side)\n\n        finally:\n            # The try/finally ensures that the transport never remains open,\n            # even if this coroutine is canceled (for example).\n\n            # If connection_lost() was called, the TCP connection is closed.\n            # However, if TLS is enabled, the transport still needs closing.\n            # Else asyncio complains: ResourceWarning: unclosed transport.\n            if self.connection_lost_waiter.done() and not self.secure:\n                return\n\n            # Close the TCP connection. Buffers are flushed asynchronously.\n            logger.debug(\"%s x closing TCP connection\", self.side)\n            self.writer.close()\n\n            if await self.wait_for_connection_lost():\n                return\n            logger.debug(\"%s ! timed out waiting for TCP close\", self.side)\n\n            # Abort the TCP connection. Buffers are discarded.\n            logger.debug(\"%s x aborting TCP connection\", self.side)\n            # mypy thinks self.writer.transport is a BaseTransport, not a Transport.\n            self.writer.transport.abort()  # type: ignore\n\n            # connection_lost() is called quickly after aborting.\n            await self.wait_for_connection_lost()", "response": "Closes the TCP connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def wait_for_connection_lost(self) -> bool:\n        if not self.connection_lost_waiter.done():\n            try:\n                await asyncio.wait_for(\n                    asyncio.shield(self.connection_lost_waiter),\n                    self.close_timeout,\n                    loop=self.loop,\n                )\n            except asyncio.TimeoutError:\n                pass\n        # Re-check self.connection_lost_waiter.done() synchronously because\n        # connection_lost() could run between the moment the timeout occurs\n        # and the moment this coroutine resumes running.\n        return self.connection_lost_waiter.done()", "response": "Wait until the TCP connection is closed or self. close_timeout elapses."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfail the WebSocket connection with the specified code and reason.", "response": "def fail_connection(self, code: int = 1006, reason: str = \"\") -> None:\n        \"\"\"\n        7.1.7. Fail the WebSocket Connection\n\n        This requires:\n\n        1. Stopping all processing of incoming data, which means cancelling\n           :attr:`transfer_data_task`. The close code will be 1006 unless a\n           close frame was received earlier.\n\n        2. Sending a close frame with an appropriate code if the opening\n           handshake succeeded and the other side is likely to process it.\n\n        3. Closing the connection. :meth:`close_connection` takes care of\n           this once :attr:`transfer_data_task` exits after being canceled.\n\n        (The specification describes these steps in the opposite order.)\n\n        \"\"\"\n        logger.debug(\n            \"%s ! failing %s WebSocket connection with code %d\",\n            self.side,\n            self.state.name,\n            code,\n        )\n\n        # Cancel transfer_data_task if the opening handshake succeeded.\n        # cancel() is idempotent and ignored if the task is done already.\n        if hasattr(self, \"transfer_data_task\"):\n            self.transfer_data_task.cancel()\n\n        # Send a close frame when the state is OPEN (a close frame was already\n        # sent if it's CLOSING), except when failing the connection because of\n        # an error reading from or writing to the network.\n        # Don't send a close frame if the connection is broken.\n        if code != 1006 and self.state is State.OPEN:\n\n            frame_data = serialize_close(code, reason)\n\n            # Write the close frame without draining the write buffer.\n\n            # Keeping fail_connection() synchronous guarantees it can't\n            # get stuck and simplifies the implementation of the callers.\n            # Not drainig the write buffer is acceptable in this context.\n\n            # This duplicates a few lines of code from write_close_frame()\n            # and write_frame().\n\n            self.state = State.CLOSING\n            logger.debug(\"%s - state = CLOSING\", self.side)\n\n            frame = Frame(True, OP_CLOSE, frame_data)\n            logger.debug(\"%s > %r\", self.side, frame)\n            frame.write(\n                self.writer.write, mask=self.is_client, extensions=self.extensions\n            )\n\n        # Start close_connection_task if the opening handshake didn't succeed.\n        if not hasattr(self, \"close_connection_task\"):\n            self.close_connection_task = self.loop.create_task(self.close_connection())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nraise ConnectionClosed in pending keepalive pings.", "response": "def abort_keepalive_pings(self) -> None:\n        \"\"\"\n        Raise ConnectionClosed in pending keepalive pings.\n\n        They'll never receive a pong once the connection is closed.\n\n        \"\"\"\n        assert self.state is State.CLOSED\n        exc = ConnectionClosed(self.close_code, self.close_reason)\n        exc.__cause__ = self.transfer_data_exc  # emulate raise ... from ...\n\n        for ping in self.pings.values():\n            ping.set_exception(exc)\n\n        if self.pings:\n            pings_hex = \", \".join(\n                binascii.hexlify(ping_id).decode() or \"[empty]\"\n                for ping_id in self.pings\n            )\n            plural = \"s\" if len(self.pings) > 1 else \"\"\n            logger.debug(\n                \"%s - aborted pending ping%s: %s\", self.side, plural, pings_hex\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connection_made(self, transport: asyncio.BaseTransport) -> None:\n        logger.debug(\"%s - event = connection_made(%s)\", self.side, transport)\n        # mypy thinks transport is a BaseTransport, not a Transport.\n        transport.set_write_buffer_limits(self.write_limit)  # type: ignore\n        super().connection_made(transport)", "response": "Configure high - water limit and low - water limit for the given transport."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the EOF received.", "response": "def eof_received(self) -> bool:\n        \"\"\"\n        Close the transport after receiving EOF.\n\n        Since Python 3.5, `:meth:~StreamReaderProtocol.eof_received` returns\n        ``True`` on non-TLS connections.\n\n        See http://bugs.python.org/issue24539 for more information.\n\n        This is inappropriate for websockets for at least three reasons:\n\n        1. The use case is to read data until EOF with self.reader.read(-1).\n           Since websockets is a TLV protocol, this never happens.\n\n        2. It doesn't work on TLS connections. A falsy value must be\n           returned to have the same behavior on TLS and plain connections.\n\n        3. The websockets protocol has its own closing handshake. Endpoints\n           close the TCP connection after sending a close frame.\n\n        As a consequence we revert to the previous, more useful behavior.\n\n        \"\"\"\n        logger.debug(\"%s - event = eof_received()\", self.side)\n        super().eof_received()\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connection_lost(self, exc: Optional[Exception]) -> None:\n        logger.debug(\"%s - event = connection_lost(%s)\", self.side, exc)\n        self.state = State.CLOSED\n        logger.debug(\"%s - state = CLOSED\", self.side)\n        if not hasattr(self, \"close_code\"):\n            self.close_code = 1006\n        if not hasattr(self, \"close_reason\"):\n            self.close_reason = \"\"\n        logger.debug(\n            \"%s x code = %d, reason = %s\",\n            self.side,\n            self.close_code,\n            self.close_reason or \"[no reason]\",\n        )\n        self.abort_keepalive_pings()\n        # If self.connection_lost_waiter isn't pending, that's a bug, because:\n        # - it's set only here in connection_lost() which is called only once;\n        # - it must never be canceled.\n        self.connection_lost_waiter.set_result(None)\n        super().connection_lost(exc)", "response": "7. 1. 4. The WebSocket Connection is Closed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_request(headers: Headers) -> str:\n    raw_key = bytes(random.getrandbits(8) for _ in range(16))\n    key = base64.b64encode(raw_key).decode()\n    headers[\"Upgrade\"] = \"websocket\"\n    headers[\"Connection\"] = \"Upgrade\"\n    headers[\"Sec-WebSocket-Key\"] = key\n    headers[\"Sec-WebSocket-Version\"] = \"13\"\n    return key", "response": "Builds a handshake request to send to the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking a handshake request and returns the key which must be used to build the response.", "response": "def check_request(headers: Headers) -> str:\n    \"\"\"\n    Check a handshake request received from the client.\n\n    If the handshake is valid, this function returns the ``key`` which must be\n    passed to :func:`build_response`.\n\n    Otherwise it raises an :exc:`~websockets.exceptions.InvalidHandshake`\n    exception and the server must return an error like 400 Bad Request.\n\n    This function doesn't verify that the request is an HTTP/1.1 or higher GET\n    request and doesn't perform Host and Origin checks. These controls are\n    usually performed earlier in the HTTP request handling code. They're the\n    responsibility of the caller.\n\n    \"\"\"\n    connection = sum(\n        [parse_connection(value) for value in headers.get_all(\"Connection\")], []\n    )\n\n    if not any(value.lower() == \"upgrade\" for value in connection):\n        raise InvalidUpgrade(\"Connection\", \", \".join(connection))\n\n    upgrade = sum([parse_upgrade(value) for value in headers.get_all(\"Upgrade\")], [])\n\n    # For compatibility with non-strict implementations, ignore case when\n    # checking the Upgrade header. It's supposed to be 'WebSocket'.\n    if not (len(upgrade) == 1 and upgrade[0].lower() == \"websocket\"):\n        raise InvalidUpgrade(\"Upgrade\", \", \".join(upgrade))\n\n    try:\n        s_w_key = headers[\"Sec-WebSocket-Key\"]\n    except KeyError:\n        raise InvalidHeader(\"Sec-WebSocket-Key\")\n    except MultipleValuesError:\n        raise InvalidHeader(\n            \"Sec-WebSocket-Key\", \"more than one Sec-WebSocket-Key header found\"\n        )\n\n    try:\n        raw_key = base64.b64decode(s_w_key.encode(), validate=True)\n    except binascii.Error:\n        raise InvalidHeaderValue(\"Sec-WebSocket-Key\", s_w_key)\n    if len(raw_key) != 16:\n        raise InvalidHeaderValue(\"Sec-WebSocket-Key\", s_w_key)\n\n    try:\n        s_w_version = headers[\"Sec-WebSocket-Version\"]\n    except KeyError:\n        raise InvalidHeader(\"Sec-WebSocket-Version\")\n    except MultipleValuesError:\n        raise InvalidHeader(\n            \"Sec-WebSocket-Version\", \"more than one Sec-WebSocket-Version header found\"\n        )\n\n    if s_w_version != \"13\":\n        raise InvalidHeaderValue(\"Sec-WebSocket-Version\", s_w_version)\n\n    return s_w_key"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a handshake response to send to the client.", "response": "def build_response(headers: Headers, key: str) -> None:\n    \"\"\"\n    Build a handshake response to send to the client.\n\n    ``key`` comes from :func:`check_request`.\n\n    \"\"\"\n    headers[\"Upgrade\"] = \"websocket\"\n    headers[\"Connection\"] = \"Upgrade\"\n    headers[\"Sec-WebSocket-Accept\"] = accept(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks a handshake response received from the server.", "response": "def check_response(headers: Headers, key: str) -> None:\n    \"\"\"\n    Check a handshake response received from the server.\n\n    ``key`` comes from :func:`build_request`.\n\n    If the handshake is valid, this function returns ``None``.\n\n    Otherwise it raises an :exc:`~websockets.exceptions.InvalidHandshake`\n    exception.\n\n    This function doesn't verify that the response is an HTTP/1.1 or higher\n    response with a 101 status code. These controls are the responsibility of\n    the caller.\n\n    \"\"\"\n    connection = sum(\n        [parse_connection(value) for value in headers.get_all(\"Connection\")], []\n    )\n\n    if not any(value.lower() == \"upgrade\" for value in connection):\n        raise InvalidUpgrade(\"Connection\", \" \".join(connection))\n\n    upgrade = sum([parse_upgrade(value) for value in headers.get_all(\"Upgrade\")], [])\n\n    # For compatibility with non-strict implementations, ignore case when\n    # checking the Upgrade header. It's supposed to be 'WebSocket'.\n    if not (len(upgrade) == 1 and upgrade[0].lower() == \"websocket\"):\n        raise InvalidUpgrade(\"Upgrade\", \", \".join(upgrade))\n\n    try:\n        s_w_accept = headers[\"Sec-WebSocket-Accept\"]\n    except KeyError:\n        raise InvalidHeader(\"Sec-WebSocket-Accept\")\n    except MultipleValuesError:\n        raise InvalidHeader(\n            \"Sec-WebSocket-Accept\", \"more than one Sec-WebSocket-Accept header found\"\n        )\n\n    if s_w_accept != accept(key):\n        raise InvalidHeaderValue(\"Sec-WebSocket-Accept\", s_w_accept)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a list of parameters for some compression parameters.", "response": "def _build_parameters(\n    server_no_context_takeover: bool,\n    client_no_context_takeover: bool,\n    server_max_window_bits: Optional[int],\n    client_max_window_bits: Optional[Union[int, bool]],\n) -> List[ExtensionParameter]:\n    \"\"\"\n    Build a list of ``(name, value)`` pairs for some compression parameters.\n\n    \"\"\"\n    params: List[ExtensionParameter] = []\n    if server_no_context_takeover:\n        params.append((\"server_no_context_takeover\", None))\n    if client_no_context_takeover:\n        params.append((\"client_no_context_takeover\", None))\n    if server_max_window_bits:\n        params.append((\"server_max_window_bits\", str(server_max_window_bits)))\n    if client_max_window_bits is True:  # only in handshake requests\n        params.append((\"client_max_window_bits\", None))\n    elif client_max_window_bits:\n        params.append((\"client_max_window_bits\", str(client_max_window_bits)))\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract_parameters(\n    params: Sequence[ExtensionParameter], *, is_server: bool\n) -> Tuple[bool, bool, Optional[int], Optional[Union[int, bool]]]:\n    \"\"\"\n    Extract compression parameters from a list of ``(name, value)`` pairs.\n\n    If ``is_server`` is ``True``, ``client_max_window_bits`` may be provided\n    without a value. This is only allow in handshake requests.\n\n    \"\"\"\n    server_no_context_takeover: bool = False\n    client_no_context_takeover: bool = False\n    server_max_window_bits: Optional[int] = None\n    client_max_window_bits: Optional[Union[int, bool]] = None\n\n    for name, value in params:\n\n        if name == \"server_no_context_takeover\":\n            if server_no_context_takeover:\n                raise DuplicateParameter(name)\n            if value is None:\n                server_no_context_takeover = True\n            else:\n                raise InvalidParameterValue(name, value)\n\n        elif name == \"client_no_context_takeover\":\n            if client_no_context_takeover:\n                raise DuplicateParameter(name)\n            if value is None:\n                client_no_context_takeover = True\n            else:\n                raise InvalidParameterValue(name, value)\n\n        elif name == \"server_max_window_bits\":\n            if server_max_window_bits is not None:\n                raise DuplicateParameter(name)\n            if value in _MAX_WINDOW_BITS_VALUES:\n                server_max_window_bits = int(value)\n            else:\n                raise InvalidParameterValue(name, value)\n\n        elif name == \"client_max_window_bits\":\n            if client_max_window_bits is not None:\n                raise DuplicateParameter(name)\n            if is_server and value is None:  # only in handshake requests\n                client_max_window_bits = True\n            elif value in _MAX_WINDOW_BITS_VALUES:\n                client_max_window_bits = int(value)\n            else:\n                raise InvalidParameterValue(name, value)\n\n        else:\n            raise InvalidParameterName(name)\n\n    return (\n        server_no_context_takeover,\n        client_no_context_takeover,\n        server_max_window_bits,\n        client_max_window_bits,\n    )", "response": "Extracts compression parameters from a list of extension parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode an incoming frame.", "response": "def decode(self, frame: Frame, *, max_size: Optional[int] = None) -> Frame:\n        \"\"\"\n        Decode an incoming frame.\n\n        \"\"\"\n        # Skip control frames.\n        if frame.opcode in CTRL_OPCODES:\n            return frame\n\n        # Handle continuation data frames:\n        # - skip if the initial data frame wasn't encoded\n        # - reset \"decode continuation data\" flag if it's a final frame\n        if frame.opcode == OP_CONT:\n            if not self.decode_cont_data:\n                return frame\n            if frame.fin:\n                self.decode_cont_data = False\n\n        # Handle text and binary data frames:\n        # - skip if the frame isn't encoded\n        # - set \"decode continuation data\" flag if it's a non-final frame\n        else:\n            if not frame.rsv1:\n                return frame\n            if not frame.fin:  # frame.rsv1 is True at this point\n                self.decode_cont_data = True\n\n            # Re-initialize per-message decoder.\n            if self.remote_no_context_takeover:\n                self.decoder = zlib.decompressobj(wbits=-self.remote_max_window_bits)\n\n        # Uncompress compressed frames. Protect against zip bombs by\n        # preventing zlib from decompressing more than max_length bytes\n        # (except when the limit is disabled with max_size = None).\n        data = frame.data\n        if frame.fin:\n            data += _EMPTY_UNCOMPRESSED_BLOCK\n        max_length = 0 if max_size is None else max_size\n        data = self.decoder.decompress(data, max_length)\n        if self.decoder.unconsumed_tail:\n            raise PayloadTooBig(\n                f\"Uncompressed payload length exceeds size limit (? > {max_size} bytes)\"\n            )\n\n        # Allow garbage collection of the decoder if it won't be reused.\n        if frame.fin and self.remote_no_context_takeover:\n            del self.decoder\n\n        return frame._replace(data=data, rsv1=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode an outgoing frame.", "response": "def encode(self, frame: Frame) -> Frame:\n        \"\"\"\n        Encode an outgoing frame.\n\n        \"\"\"\n        # Skip control frames.\n        if frame.opcode in CTRL_OPCODES:\n            return frame\n\n        # Since we always encode and never fragment messages, there's no logic\n        # similar to decode() here at this time.\n\n        if frame.opcode != OP_CONT:\n            # Re-initialize per-message decoder.\n            if self.local_no_context_takeover:\n                self.encoder = zlib.compressobj(\n                    wbits=-self.local_max_window_bits, **self.compress_settings\n                )\n\n        # Compress data frames.\n        data = self.encoder.compress(frame.data) + self.encoder.flush(zlib.Z_SYNC_FLUSH)\n        if frame.fin and data.endswith(_EMPTY_UNCOMPRESSED_BLOCK):\n            data = data[:-4]\n\n        # Allow garbage collection of the encoder if it won't be reused.\n        if frame.fin and self.local_no_context_takeover:\n            del self.encoder\n\n        return frame._replace(data=data, rsv1=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_response_params(\n        self,\n        params: Sequence[ExtensionParameter],\n        accepted_extensions: Sequence[\"Extension\"],\n    ) -> PerMessageDeflate:\n        \"\"\"\n        Process response parameters.\n\n        Return an extension instance.\n\n        \"\"\"\n        if any(other.name == self.name for other in accepted_extensions):\n            raise NegotiationError(f\"Received duplicate {self.name}\")\n\n        # Request parameters are available in instance variables.\n\n        # Load response parameters in local variables.\n        (\n            server_no_context_takeover,\n            client_no_context_takeover,\n            server_max_window_bits,\n            client_max_window_bits,\n        ) = _extract_parameters(params, is_server=False)\n\n        # After comparing the request and the response, the final\n        # configuration must be available in the local variables.\n\n        # server_no_context_takeover\n        #\n        #   Req.    Resp.   Result\n        #   ------  ------  --------------------------------------------------\n        #   False   False   False\n        #   False   True    True\n        #   True    False   Error!\n        #   True    True    True\n\n        if self.server_no_context_takeover:\n            if not server_no_context_takeover:\n                raise NegotiationError(\"Expected server_no_context_takeover\")\n\n        # client_no_context_takeover\n        #\n        #   Req.    Resp.   Result\n        #   ------  ------  --------------------------------------------------\n        #   False   False   False\n        #   False   True    True\n        #   True    False   True - must change value\n        #   True    True    True\n\n        if self.client_no_context_takeover:\n            if not client_no_context_takeover:\n                client_no_context_takeover = True\n\n        # server_max_window_bits\n\n        #   Req.    Resp.   Result\n        #   ------  ------  --------------------------------------------------\n        #   None    None    None\n        #   None    8\u2264M\u226415  M\n        #   8\u2264N\u226415  None    Error!\n        #   8\u2264N\u226415  8\u2264M\u2264N   M\n        #   8\u2264N\u226415  N<M\u226415  Error!\n\n        if self.server_max_window_bits is None:\n            pass\n\n        else:\n            if server_max_window_bits is None:\n                raise NegotiationError(\"Expected server_max_window_bits\")\n            elif server_max_window_bits > self.server_max_window_bits:\n                raise NegotiationError(\"Unsupported server_max_window_bits\")\n\n        # client_max_window_bits\n\n        #   Req.    Resp.   Result\n        #   ------  ------  --------------------------------------------------\n        #   None    None    None\n        #   None    8\u2264M\u226415  Error!\n        #   True    None    None\n        #   True    8\u2264M\u226415  M\n        #   8\u2264N\u226415  None    N - must change value\n        #   8\u2264N\u226415  8\u2264M\u2264N   M\n        #   8\u2264N\u226415  N<M\u226415  Error!\n\n        if self.client_max_window_bits is None:\n            if client_max_window_bits is not None:\n                raise NegotiationError(\"Unexpected client_max_window_bits\")\n\n        elif self.client_max_window_bits is True:\n            pass\n\n        else:\n            if client_max_window_bits is None:\n                client_max_window_bits = self.client_max_window_bits\n            elif client_max_window_bits > self.client_max_window_bits:\n                raise NegotiationError(\"Unsupported client_max_window_bits\")\n\n        return PerMessageDeflate(\n            server_no_context_takeover,  # remote_no_context_takeover\n            client_no_context_takeover,  # local_no_context_takeover\n            server_max_window_bits or 15,  # remote_max_window_bits\n            client_max_window_bits or 15,  # local_max_window_bits\n            self.compress_settings,\n        )", "response": "Processes the response parameters and returns an extension instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing request parameters and return response params and an extension instance.", "response": "def process_request_params(\n        self,\n        params: Sequence[ExtensionParameter],\n        accepted_extensions: Sequence[\"Extension\"],\n    ) -> Tuple[List[ExtensionParameter], PerMessageDeflate]:\n        \"\"\"\n        Process request parameters.\n\n        Return response params and an extension instance.\n\n        \"\"\"\n        if any(other.name == self.name for other in accepted_extensions):\n            raise NegotiationError(f\"Skipped duplicate {self.name}\")\n\n        # Load request parameters in local variables.\n        (\n            server_no_context_takeover,\n            client_no_context_takeover,\n            server_max_window_bits,\n            client_max_window_bits,\n        ) = _extract_parameters(params, is_server=True)\n\n        # Configuration parameters are available in instance variables.\n\n        # After comparing the request and the configuration, the response must\n        # be available in the local variables.\n\n        # server_no_context_takeover\n        #\n        #   Config  Req.    Resp.\n        #   ------  ------  --------------------------------------------------\n        #   False   False   False\n        #   False   True    True\n        #   True    False   True - must change value to True\n        #   True    True    True\n\n        if self.server_no_context_takeover:\n            if not server_no_context_takeover:\n                server_no_context_takeover = True\n\n        # client_no_context_takeover\n        #\n        #   Config  Req.    Resp.\n        #   ------  ------  --------------------------------------------------\n        #   False   False   False\n        #   False   True    True (or False)\n        #   True    False   True - must change value to True\n        #   True    True    True (or False)\n\n        if self.client_no_context_takeover:\n            if not client_no_context_takeover:\n                client_no_context_takeover = True\n\n        # server_max_window_bits\n\n        #   Config  Req.    Resp.\n        #   ------  ------  --------------------------------------------------\n        #   None    None    None\n        #   None    8\u2264M\u226415  M\n        #   8\u2264N\u226415  None    N - must change value\n        #   8\u2264N\u226415  8\u2264M\u2264N   M\n        #   8\u2264N\u226415  N<M\u226415  N - must change value\n\n        if self.server_max_window_bits is None:\n            pass\n\n        else:\n            if server_max_window_bits is None:\n                server_max_window_bits = self.server_max_window_bits\n            elif server_max_window_bits > self.server_max_window_bits:\n                server_max_window_bits = self.server_max_window_bits\n\n        # client_max_window_bits\n\n        #   Config  Req.    Resp.\n        #   ------  ------  --------------------------------------------------\n        #   None    None    None\n        #   None    True    None - must change value\n        #   None    8\u2264M\u226415  M (or None)\n        #   8\u2264N\u226415  None    Error!\n        #   8\u2264N\u226415  True    N - must change value\n        #   8\u2264N\u226415  8\u2264M\u2264N   M (or None)\n        #   8\u2264N\u226415  N<M\u226415  N\n\n        if self.client_max_window_bits is None:\n            if client_max_window_bits is True:\n                client_max_window_bits = self.client_max_window_bits\n\n        else:\n            if client_max_window_bits is None:\n                raise NegotiationError(\"Required client_max_window_bits\")\n            elif client_max_window_bits is True:\n                client_max_window_bits = self.client_max_window_bits\n            elif self.client_max_window_bits < client_max_window_bits:\n                client_max_window_bits = self.client_max_window_bits\n\n        return (\n            _build_parameters(\n                server_no_context_takeover,\n                client_no_context_takeover,\n                server_max_window_bits,\n                client_max_window_bits,\n            ),\n            PerMessageDeflate(\n                client_no_context_takeover,  # remote_no_context_takeover\n                server_no_context_takeover,  # local_no_context_takeover\n                client_max_window_bits or 15,  # remote_max_window_bits\n                server_max_window_bits or 15,  # local_max_window_bits\n                self.compress_settings,\n            ),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_mask(data: bytes, mask: bytes) -> bytes:\n    if len(mask) != 4:\n        raise ValueError(\"mask must contain 4 bytes\")\n\n    return bytes(b ^ m for b, m in zip(data, itertools.cycle(mask)))", "response": "Apply masking to the data of a WebSocket message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat a close code and reason.", "response": "def format_close(code: int, reason: str) -> str:\n    \"\"\"\n    Display a human-readable version of the close code and reason.\n\n\n    \"\"\"\n    if 3000 <= code < 4000:\n        explanation = \"registered\"\n    elif 4000 <= code < 5000:\n        explanation = \"private use\"\n    else:\n        explanation = CLOSE_CODES.get(code, \"unknown\")\n    result = f\"code = {code} ({explanation}), \"\n\n    if reason:\n        result += f\"reason = {reason}\"\n    else:\n        result += \"no reason\"\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing request parameters received from the client and return a 2 - tuple containing the response parameters and extensions.", "response": "def process_request_params(\n        self,\n        params: Sequence[ExtensionParameter],\n        accepted_extensions: Sequence[Extension],\n    ) -> Tuple[List[ExtensionParameter], Extension]:\n        \"\"\"\n        Process request parameters received from the client.\n\n        ``params`` is a list of (name, value) pairs.\n\n        ``accepted_extensions`` is a list of previously accepted extensions.\n\n        To accept the offer, return a 2-uple containing:\n\n        - response parameters: a list of (name, value) pairs\n        - an extension: an instance of a subclass of :class:`Extension`\n\n        To reject the offer, raise\n        :exc:`~websockets.exceptions.NegotiationError`.\n\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserve a number of services for a contextual block.", "response": "def run_services(config, *services, **kwargs):\n    \"\"\" Serves a number of services for a contextual block.\n    The caller can specify a number of service classes then serve them either\n    stopping (default) or killing them on exiting the contextual block.\n\n\n    Example::\n\n        with run_services(config, Foobar, Spam) as runner:\n            # interact with services and stop them on exiting the block\n\n        # services stopped\n\n\n    Additional configuration available to :class:``ServiceRunner`` instances\n    can be specified through keyword arguments::\n\n        with run_services(config, Foobar, Spam, kill_on_exit=True):\n            # interact with services\n\n        # services killed\n\n    :Parameters:\n        config : dict\n            Configuration to instantiate the service containers with\n        services : service definitions\n            Services to be served for the contextual block\n        kill_on_exit : bool (default=False)\n            If ``True``, run ``kill()`` on the service containers when exiting\n            the contextual block. Otherwise ``stop()`` will be called on the\n            service containers on exiting the block.\n\n    :Returns: The configured :class:`ServiceRunner` instance\n\n    \"\"\"\n    kill_on_exit = kwargs.pop('kill_on_exit', False)\n\n    runner = ServiceRunner(config)\n    for service in services:\n        runner.add_service(service)\n\n    runner.start()\n\n    yield runner\n\n    if kill_on_exit:\n        runner.kill()\n    else:\n        runner.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_service(self, cls):\n        service_name = get_service_name(cls)\n        container = self.container_cls(cls, self.config)\n        self.service_map[service_name] = container", "response": "Add a service class to the runner."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self):\n        service_names = ', '.join(self.service_names)\n        _log.info('starting services: %s', service_names)\n\n        SpawningProxy(self.containers).start()\n\n        _log.debug('services started: %s', service_names)", "response": "Start all the registered services."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait(self):\n        try:\n            SpawningProxy(self.containers, abort_on_error=True).wait()\n        except Exception:\n            # If a single container failed, stop its peers and re-raise the\n            # exception\n            self.stop()\n            raise", "response": "Wait for all running containers to stop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self):\n        if not self._providers_registered:\n            self.queue_consumer.unregister_provider(self)\n            self._unregistered_from_queue_consumer.send(True)", "response": "Stop the RpcConsumer.\n\n        The RpcConsumer ordinary unregisters from the QueueConsumer when the\n        last Rpc subclass unregisters from it. If no providers were registered,\n        we should unregister from the QueueConsumer as soon as we're asked\n        to stop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninjecting a dispatch method onto the service instance", "response": "def get_dependency(self, worker_ctx):\n        \"\"\" Inject a dispatch method onto the service instance\n        \"\"\"\n        extra_headers = self.get_message_headers(worker_ctx)\n\n        def dispatch(event_type, event_data):\n            self.publisher.publish(\n                event_data,\n                exchange=self.exchange,\n                routing_key=event_type,\n                extra_headers=extra_headers\n            )\n\n        return dispatch"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_module_path(exc_type):\n    module = inspect.getmodule(exc_type)\n    return \"{}.{}\".format(module.__name__, exc_type.__name__)", "response": "Return the dotted module path of exc_type including the class name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_for_serialization(value):\n\n    if isinstance(value, six.string_types):\n        return value\n    if isinstance(value, dict):\n        return {\n            safe_for_serialization(key): safe_for_serialization(val)\n            for key, val in six.iteritems(value)\n        }\n    if isinstance(value, collections.Iterable):\n        return list(map(safe_for_serialization, value))\n\n    try:\n        return six.text_type(value)\n    except Exception:\n        return '[__unicode__ failed]'", "response": "Transform a value in preparation for serializing as json\n    no - op for strings mappings and iterables have their entries made safe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing self. exc into a data dictionary representing it.", "response": "def serialize(exc):\n    \"\"\" Serialize `self.exc` into a data dictionary representing it.\n    \"\"\"\n\n    return {\n        'exc_type': type(exc).__name__,\n        'exc_path': get_module_path(type(exc)),\n        'exc_args': list(map(safe_for_serialization, exc.args)),\n        'value': safe_for_serialization(exc),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deserialize(data):\n    key = data.get('exc_path')\n    if key in registry:\n        exc_args = data.get('exc_args', ())\n        return registry[key](*exc_args)\n\n    exc_type = data.get('exc_type')\n    value = data.get('value')\n    return RemoteError(exc_type=exc_type, value=value)", "response": "Deserialize data to an exception instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_from_path(path):\n    if path is None:\n        return\n\n    obj = locate(path)\n    if obj is None:\n        raise ImportError(\n            \"`{}` could not be imported\".format(path)\n        )\n\n    return obj", "response": "Import and return the object at path if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all the subscriptions of a socket.", "response": "def get_subscriptions(self, socket_id):\n        \"\"\"Returns a list of all the subscriptions of a socket.\"\"\"\n        con = self._get_connection(socket_id, create=False)\n        if con is None:\n            return []\n        return sorted(con.subscriptions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subscribe(self, socket_id, channel):\n        con = self._get_connection(socket_id)\n        self.subscriptions.setdefault(channel, set()).add(socket_id)\n        con.subscriptions.add(channel)", "response": "Subscribes a socket to a channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef broadcast(self, channel, event, data):\n        payload = self._server.serialize_event(event, data)\n        for socket_id in self.subscriptions.get(channel, ()):\n            rv = self._server.sockets.get(socket_id)\n            if rv is not None:\n                rv.socket.send(payload)", "response": "Broadcasts an event to all sockets listening on a channel."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unicast(self, socket_id, event, data):\n        payload = self._server.serialize_event(event, data)\n        rv = self._server.sockets.get(socket_id)\n        if rv is not None:\n            rv.socket.send(payload)\n            return True\n        return False", "response": "Sends an event to a single socket. Returns True if that worked False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a timing logger.", "response": "def make_timing_logger(logger, precision=3, level=logging.DEBUG):\n    \"\"\" Return a timing logger.\n\n    Usage::\n\n        >>> logger = logging.getLogger('foobar')\n        >>> log_time = make_timing_logger(\n        ...     logger, level=logging.INFO, precision=2)\n        >>>\n        >>> with log_time(\"hello %s\", \"world\"):\n        ...     time.sleep(1)\n        INFO:foobar:hello world in 1.00s\n    \"\"\"\n    @contextmanager\n    def log_time(msg, *args):\n        \"\"\" Log `msg` and `*args` with (naive wallclock) timing information\n        when the context block exits.\n        \"\"\"\n        start_time = time.time()\n\n        try:\n            yield\n        finally:\n            message = \"{} in %0.{}fs\".format(msg, precision)\n            duration = time.time() - start_time\n            args = args + (duration,)\n            logger.log(level, message, *args)\n\n    return log_time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the WSGI server used to process requests.", "response": "def get_wsgi_server(\n        self, sock, wsgi_app, protocol=HttpOnlyProtocol, debug=False\n    ):\n        \"\"\"Get the WSGI server used to process requests.\"\"\"\n        return wsgi.Server(\n            sock,\n            sock.getsockname(),\n            wsgi_app,\n            protocol=protocol,\n            debug=debug,\n            log=getLogger(__name__)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an exchange for service_name events.", "response": "def get_event_exchange(service_name):\n    \"\"\" Get an exchange for ``service_name`` events.\n    \"\"\"\n    exchange_name = \"{}.events\".format(service_name)\n    exchange = Exchange(\n        exchange_name, type='topic', durable=True, delivery_mode=PERSISTENT\n    )\n\n    return exchange"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef event_dispatcher(nameko_config, **kwargs):\n    amqp_uri = nameko_config[AMQP_URI_CONFIG_KEY]\n\n    serializer, _ = serialization.setup(nameko_config)\n    serializer = kwargs.pop('serializer', serializer)\n\n    ssl = nameko_config.get(AMQP_SSL_CONFIG_KEY)\n\n    # TODO: standalone event dispatcher should accept context event_data\n    # and insert a call id\n\n    publisher = Publisher(amqp_uri, serializer=serializer, ssl=ssl, **kwargs)\n\n    def dispatch(service_name, event_type, event_data):\n        \"\"\" Dispatch an event claiming to originate from `service_name` with\n        the given `event_type` and `event_data`.\n        \"\"\"\n        exchange = get_event_exchange(service_name)\n\n        publisher.publish(\n            event_data,\n            exchange=exchange,\n            routing_key=event_type\n        )\n\n    return dispatch", "response": "Returns a function that dispatches nameko events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a function against each item in a given list yielding the result of the function call.", "response": "def fail_fast_imap(pool, call, items):\n    \"\"\" Run a function against each item in a given list, yielding each\n    function result in turn, where the function call is handled in a\n    :class:`~eventlet.greenthread.GreenThread` spawned by the provided pool.\n\n    If any function raises an exception, all other ongoing threads are killed,\n    and the exception is raised to the caller.\n\n    This function is similar to :meth:`~eventlet.greenpool.GreenPool.imap`.\n\n    :param pool: Pool to spawn function threads from\n    :type pool: eventlet.greenpool.GreenPool\n    :param call: Function call to make, expecting to receive an item from the\n        given list\n    \"\"\"\n    result_queue = LightQueue(maxsize=len(items))\n    spawned_threads = set()\n\n    def handle_result(finished_thread):\n        try:\n            thread_result = finished_thread.wait()\n            spawned_threads.remove(finished_thread)\n            result_queue.put((thread_result, None))\n        except Exception:\n            spawned_threads.remove(finished_thread)\n            result_queue.put((None, sys.exc_info()))\n\n    for item in items:\n        gt = pool.spawn(call, item)\n        spawned_threads.add(gt)\n        gt.link(handle_result)\n\n    while spawned_threads:\n        result, exc_info = result_queue.get()\n        if exc_info is not None:\n            # Kill all other ongoing threads\n            for ongoing_thread in spawned_threads:\n                ongoing_thread.kill()\n            # simply raising here (even raising a full exc_info) isn't\n            # sufficient to preserve the original stack trace.\n            # greenlet.throw() achieves this.\n            eventlet.getcurrent().throw(*exc_info)\n        yield result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the interval loop.", "response": "def _run(self):\n        \"\"\" Runs the interval loop. \"\"\"\n\n        def get_next_interval():\n            start_time = time.time()\n            start = 0 if self.eager else 1\n            for count in itertools.count(start=start):\n                yield max(start_time + count * self.interval - time.time(), 0)\n        interval = get_next_interval()\n        sleep_time = next(interval)\n        while True:\n            # sleep for `sleep_time`, unless `should_stop` fires, in which\n            # case we leave the while loop and stop entirely\n            with Timeout(sleep_time, exception=False):\n                self.should_stop.wait()\n                break\n\n            self.handle_timer_tick()\n\n            self.worker_complete.wait()\n            self.worker_complete.reset()\n\n            sleep_time = next(interval)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the queue - consumer gracefully.", "response": "def stop(self):\n        \"\"\" Stop the queue-consumer gracefully.\n\n        Wait until the last provider has been unregistered and for\n        the ConsumerMixin's greenthread to exit (i.e. until all pending\n        messages have been acked or requeued and all consumers stopped).\n        \"\"\"\n        if not self._consumers_ready.ready():\n            _log.debug('stopping while consumer is starting %s', self)\n\n            stop_exc = QueueConsumerStopped()\n\n            # stopping before we have started successfully by brutally\n            # killing the consumer thread as we don't have a way to hook\n            # into the pre-consumption startup process\n            self._gt.kill(stop_exc)\n\n        self.wait_for_providers()\n\n        try:\n            _log.debug('waiting for consumer death %s', self)\n            self._gt.wait()\n        except QueueConsumerStopped:\n            pass\n\n        super(QueueConsumer, self).stop()\n        _log.debug('stopped %s', self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kill(self):\n        # greenlet has a magic attribute ``dead`` - pylint: disable=E1101\n        if self._gt is not None and not self._gt.dead:\n            # we can't just kill the thread because we have to give\n            # ConsumerMixin a chance to close the sockets properly.\n            self._providers = set()\n            self._pending_remove_providers = {}\n            self.should_stop = True\n            try:\n                self._gt.wait()\n            except Exception as exc:\n                # discard the exception since we're already being killed\n                _log.warn(\n                    'QueueConsumer %s raised `%s` during kill', self, exc)\n\n            super(QueueConsumer, self).kill()\n            _log.debug('killed %s', self)", "response": "Kill the queue - consumer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprovide the connection parameters for kombu s ConsumerMixin.", "response": "def connection(self):\n        \"\"\" Provide the connection parameters for kombu's ConsumerMixin.\n\n        The `Connection` object is a declaration of connection parameters\n        that is lazily evaluated. It doesn't represent an established\n        connection to the broker at this point.\n        \"\"\"\n        heartbeat = self.container.config.get(\n            HEARTBEAT_CONFIG_KEY, DEFAULT_HEARTBEAT\n        )\n        transport_options = self.container.config.get(\n            TRANSPORT_OPTIONS_CONFIG_KEY, DEFAULT_TRANSPORT_OPTIONS\n        )\n        ssl = self.container.config.get(AMQP_SSL_CONFIG_KEY)\n        conn = Connection(self.amqp_uri,\n                          transport_options=transport_options,\n                          heartbeat=heartbeat,\n                          ssl=ssl\n                          )\n\n        return conn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_consumers(self, consumer_cls, channel):\n        _log.debug('setting up consumers %s', self)\n\n        for provider in self._providers:\n            callbacks = [partial(self.handle_message, provider)]\n\n            consumer = consumer_cls(\n                queues=[provider.queue],\n                callbacks=callbacks,\n                accept=self.accept\n            )\n            consumer.qos(prefetch_count=self.prefetch_count)\n\n            self._consumers[provider] = consumer\n\n        return self._consumers.values()", "response": "Get consumers for this channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_iteration(self):\n        self._cancel_consumers_if_requested()\n\n        if len(self._consumers) == 0:\n            _log.debug('requesting stop after iteration')\n            self.should_stop = True", "response": "Kombu callback for each drain_events loop iteration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_consume_ready(self, connection, channel, consumers, **kwargs):\n        if not self._consumers_ready.ready():\n            _log.debug('consumer started %s', self)\n            self._consumers_ready.send(None)", "response": "Kombu callback when consumers are ready to accept messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_nameko_helper(config):\n    module = ModuleType('nameko')\n    module.__doc__ = \"\"\"Nameko shell helper for making rpc calls and dispatching\nevents.\n\nUsage:\n    >>> n.rpc.service.method()\n    \"reply\"\n\n    >>> n.dispatch_event('service', 'event_type', 'event_data')\n\"\"\"\n    proxy = ClusterRpcProxy(config)\n    module.rpc = proxy.start()\n    module.dispatch_event = event_dispatcher(config)\n    module.config = config\n    module.disconnect = proxy.stop\n    return module", "response": "Create a fake module that provides some convenient access to nameko."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_extensions(extension):\n    for _, ext in inspect.getmembers(extension, is_extension):\n        for item in iter_extensions(ext):\n            yield item\n        yield ext", "response": "Depth - first iterator over sub - extensions on extension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an instance of this Extension to bind to container.", "response": "def bind(self, container):\n        \"\"\" Get an instance of this Extension to bind to `container`.\n        \"\"\"\n\n        def clone(prototype):\n            if prototype.is_bound():\n                raise RuntimeError('Cannot `bind` a bound extension.')\n\n            cls = type(prototype)\n            args, kwargs = prototype.__params\n            instance = cls(*args, **kwargs)\n            # instance.container must be a weakref to avoid a strong reference\n            # from value to key in the `shared_extensions` weakkey dict\n            # see test_extension_sharing.py: test_weakref\n            instance.container = weakref.proxy(container)\n            return instance\n\n        instance = clone(self)\n\n        # recurse over sub-extensions\n        for name, ext in inspect.getmembers(self, is_extension):\n            setattr(instance, name, ext.bind(container))\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind(self, container):\n        # if there's already a matching bound instance, return that\n        shared = container.shared_extensions.get(self.sharing_key)\n        if shared:\n            return shared\n\n        instance = super(SharedExtension, self).bind(container)\n\n        # save the new instance\n        container.shared_extensions[self.sharing_key] = instance\n\n        return instance", "response": "Bind implementation that supports sharing.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind(self, container, attr_name):\n        instance = super(DependencyProvider, self).bind(container)\n        instance.attr_name = attr_name\n        self.attr_name = attr_name\n        return instance", "response": "Bind to container with attr_name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_for_providers(self):\n        if self._providers_registered:\n            _log.debug('waiting for providers to unregister %s', self)\n            self._last_provider_unregistered.wait()\n            _log.debug('all providers unregistered %s', self)", "response": "Wait for any providers to be unregistered."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bind(self, container, method_name):\n        instance = super(Entrypoint, self).bind(container)\n        instance.method_name = method_name\n        return instance", "response": "Bind to a container with the given method_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a container by starting all of its extensions.", "response": "def start(self):\n        \"\"\" Start a container by starting all of its extensions.\n        \"\"\"\n        _log.debug('starting %s', self)\n        self.started = True\n\n        with _log_time('started %s', self):\n            self.extensions.all.setup()\n            self.extensions.all.start()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the container gracefully.", "response": "def stop(self):\n        \"\"\" Stop the container gracefully.\n\n        First all entrypoints are asked to ``stop()``.\n        This ensures that no new worker threads are started.\n\n        It is the extensions' responsibility to gracefully shut down when\n        ``stop()`` is called on them and only return when they have stopped.\n\n        After all entrypoints have stopped the container waits for any\n        active workers to complete.\n\n        After all active workers have stopped the container stops all\n        dependency providers.\n\n        At this point there should be no more managed threads. In case there\n        are any managed threads, they are killed by the container.\n        \"\"\"\n        if self._died.ready():\n            _log.debug('already stopped %s', self)\n            return\n\n        if self._being_killed:\n            # this race condition can happen when a container is hosted by a\n            # runner and yields during its kill method; if it's unlucky in\n            # scheduling the runner will try to stop() it before self._died\n            # has a result\n            _log.debug('already being killed %s', self)\n            try:\n                self._died.wait()\n            except:\n                pass  # don't re-raise if we died with an exception\n            return\n\n        _log.debug('stopping %s', self)\n\n        with _log_time('stopped %s', self):\n\n            # entrypoint have to be stopped before dependencies to ensure\n            # that running workers can successfully complete\n            self.entrypoints.all.stop()\n\n            # there might still be some running workers, which we have to\n            # wait for to complete before we can stop dependencies\n            self._worker_pool.waitall()\n\n            # it should be safe now to stop any dependency as there is no\n            # active worker which could be using it\n            self.dependencies.all.stop()\n\n            # finally, stop remaining extensions\n            self.subextensions.all.stop()\n\n            # any any managed threads they spawned\n            self._kill_managed_threads()\n\n            self.started = False\n\n            # if `kill` is called after `stop`, they race to send this\n            if not self._died.ready():\n                self._died.send(None)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kill(self, exc_info=None):\n        if self._being_killed:\n            # this happens if a managed thread exits with an exception\n            # while the container is being killed or if multiple errors\n            # happen simultaneously\n            _log.debug('already killing %s ... waiting for death', self)\n            try:\n                self._died.wait()\n            except:\n                pass  # don't re-raise if we died with an exception\n            return\n\n        self._being_killed = True\n\n        if self._died.ready():\n            _log.debug('already stopped %s', self)\n            return\n\n        if exc_info is not None:\n            _log.info('killing %s due to %s', self, exc_info[1])\n        else:\n            _log.info('killing %s', self)\n\n        # protect against extensions that throw during kill; the container\n        # is already dying with an exception, so ignore anything else\n        def safely_kill_extensions(ext_set):\n            try:\n                ext_set.kill()\n            except Exception as exc:\n                _log.warning('Extension raised `%s` during kill', exc)\n\n        safely_kill_extensions(self.entrypoints.all)\n        self._kill_worker_threads()\n        safely_kill_extensions(self.extensions.all)\n        self._kill_managed_threads()\n\n        self.started = False\n\n        # if `kill` is called after `stop`, they race to send this\n        if not self._died.ready():\n            self._died.send(None, exc_info)", "response": "Kill the container in a semi - grace way."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nspawn a worker thread for running the service method decorated by entrypoint.", "response": "def spawn_worker(self, entrypoint, args, kwargs,\n                     context_data=None, handle_result=None):\n        \"\"\" Spawn a worker thread for running the service method decorated\n        by `entrypoint`.\n\n        ``args`` and ``kwargs`` are used as parameters for the service method.\n\n        ``context_data`` is used to initialize a ``WorkerContext``.\n\n        ``handle_result`` is an optional function which may be passed\n        in by the entrypoint. It is called with the result returned\n        or error raised by the service method. If provided it must return a\n        value for ``result`` and ``exc_info`` to propagate to dependencies;\n        these may be different to those returned by the service method.\n        \"\"\"\n\n        if self._being_killed:\n            _log.info(\"Worker spawn prevented due to being killed\")\n            raise ContainerBeingKilled()\n\n        service = self.service_cls()\n        worker_ctx = WorkerContext(\n            self, service, entrypoint, args, kwargs, data=context_data\n        )\n\n        _log.debug('spawning %s', worker_ctx)\n        gt = self._worker_pool.spawn(\n            self._run_worker, worker_ctx, handle_result\n        )\n        gt.link(self._handle_worker_thread_exited, worker_ctx)\n\n        self._worker_threads[worker_ctx] = gt\n        return worker_ctx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spawn_managed_thread(self, fn, identifier=None):\n        if identifier is None:\n            identifier = getattr(fn, '__name__', \"<unknown>\")\n\n        gt = eventlet.spawn(fn)\n        self._managed_threads[gt] = identifier\n        gt.link(self._handle_managed_thread_exited, identifier)\n        return gt", "response": "Spawns a managed thread to run fn on behalf of an extension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nkilling any currently executing worker threads.", "response": "def _kill_worker_threads(self):\n        \"\"\" Kill any currently executing worker threads.\n\n        See :meth:`ServiceContainer.spawn_worker`\n        \"\"\"\n        num_workers = len(self._worker_threads)\n\n        if num_workers:\n            _log.warning('killing %s active workers(s)', num_workers)\n            for worker_ctx, gt in list(self._worker_threads.items()):\n                _log.warning('killing active worker for %s', worker_ctx)\n                gt.kill()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _kill_managed_threads(self):\n        num_threads = len(self._managed_threads)\n\n        if num_threads:\n            _log.warning('killing %s managed thread(s)', num_threads)\n            for gt, identifier in list(self._managed_threads.items()):\n                _log.warning('killing managed thread `%s`', identifier)\n                gt.kill()", "response": "Kill any currently executing managed threads."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits for a message to arrive from the queue_consumer until the message has been processed.", "response": "def wait(self):\n        \"\"\" Makes a blocking call to its queue_consumer until the message\n        with the given correlation_id has been processed.\n\n        By the time the blocking call exits, self.send() will have been called\n        with the body of the received message\n        (see :meth:`~nameko.rpc.ReplyListener.handle_message`).\n\n        Exceptions are raised directly.\n        \"\"\"\n        # disconnected before starting to wait\n        if self.exception:\n            raise self.exception\n\n        if self.queue_consumer.stopped:\n            raise RuntimeError(\n                \"This consumer has been stopped, and can no longer be used\"\n            )\n        if self.queue_consumer.connection.connected is False:\n            # we can't just reconnect here. the consumer (and its exclusive,\n            # auto-delete reply queue) must be re-established _before_ sending\n            # any request, otherwise the reply queue may not exist when the\n            # response is published.\n            raise RuntimeError(\n                \"This consumer has been disconnected, and can no longer \"\n                \"be used\"\n            )\n\n        try:\n            self.queue_consumer.get_message(self.correlation_id)\n        except socket.error as exc:\n            self.exception = exc\n\n        # disconnected while waiting\n        if self.exception:\n            raise self.exception\n        return self.body"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls : func : Form. new_control on the currently selected form.", "response": "def new_control(self, type, name, value, **kwargs):\n        \"\"\"Call :func:`Form.new_control` on the currently selected form.\"\"\"\n        return self.get_current_form().new_control(type, name, value, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the URL and store the Browser s state in this object.", "response": "def open(self, url, *args, **kwargs):\n        \"\"\"Open the URL and store the Browser's state in this object.\n        All arguments are forwarded to :func:`Browser.get`.\n\n        :return: Forwarded from :func:`Browser.get`.\n        \"\"\"\n        if self.__verbose == 1:\n            sys.stdout.write('.')\n            sys.stdout.flush()\n        elif self.__verbose >= 2:\n            print(url)\n\n        resp = self.get(url, *args, **kwargs)\n        self.__state = _BrowserState(page=resp.soup, url=resp.url,\n                                     request=resp.request)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmock version of open.", "response": "def open_fake_page(self, page_text, url=None, soup_config=None):\n        \"\"\"Mock version of :func:`open`.\n\n        Behave as if opening a page whose text is ``page_text``, but do not\n        perform any network access. If ``url`` is set, pretend it is the page's\n        URL. Useful mainly for testing.\n        \"\"\"\n        soup_config = soup_config or self.soup_config\n        self.__state = _BrowserState(\n            page=bs4.BeautifulSoup(page_text, **soup_config),\n            url=url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlike open but can be relative to the currently visited page.", "response": "def open_relative(self, url, *args, **kwargs):\n        \"\"\"Like :func:`open`, but ``url`` can be relative to the currently\n        visited page.\n        \"\"\"\n        return self.open(self.absolute_url(url), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreloads the current page with the same request as originally done.", "response": "def refresh(self):\n        \"\"\"Reload the current page with the same request as originally done.\n        Any change (`select_form`, or any value filled-in in the form) made to\n        the current page before refresh is discarded.\n\n        :raise ValueError: Raised if no refreshable page is loaded, e.g., when\n            using the shallow ``Browser`` wrapper functions.\n\n        :return: Response of the request.\"\"\"\n        old_request = self.__state.request\n        if old_request is None:\n            raise ValueError('The current page is not refreshable. Either no '\n                             'page is opened or low-level browser methods '\n                             'were used to do so')\n\n        resp = self.session.send(old_request)\n        Browser.add_soup(resp, self.soup_config)\n        self.__state = _BrowserState(page=resp.soup, url=resp.url,\n                                     request=resp.request)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_form(self, selector=\"form\", nr=0):\n        if isinstance(selector, bs4.element.Tag):\n            if selector.name != \"form\":\n                raise LinkNotFoundError\n            self.__state.form = Form(selector)\n        else:\n            # nr is a 0-based index for consistency with mechanize\n            found_forms = self.get_current_page().select(selector,\n                                                         limit=nr + 1)\n            if len(found_forms) != nr + 1:\n                if self.__debug:\n                    print('select_form failed for', selector)\n                    self.launch_browser()\n                raise LinkNotFoundError()\n            self.__state.form = Form(found_forms[-1])\n\n        return self.get_current_form()", "response": "Select a form in the current page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubmit the form that was selected with select_form.", "response": "def submit_selected(self, btnName=None, update_state=True,\n                        *args, **kwargs):\n        \"\"\"Submit the form that was selected with :func:`select_form`.\n\n        :return: Forwarded from :func:`Browser.submit`.\n\n        If there are multiple submit input/button elements, passes ``btnName``\n        to :func:`Form.choose_submit` on the current form to choose between\n        them. If `update_state` is False, form will be submited but the browser\n        state will remain unchanged. This is useful for forms that result in\n        a download of a file. All other arguments are forwarded to\n        :func:`Browser.submit`.\n        \"\"\"\n        self.get_current_form().choose_submit(btnName)\n\n        referer = self.get_url()\n        if referer is not None:\n            if 'headers' in kwargs:\n                kwargs['headers']['Referer'] = referer\n            else:\n                kwargs['headers'] = {'Referer': referer}\n\n        resp = self.submit(self.__state.form, url=self.__state.url,\n                           *args, **kwargs)\n        if update_state:\n            self.__state = _BrowserState(page=resp.soup, url=resp.url,\n                                         request=resp.request)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays the list of links in the current page. Arguments are passed to links.", "response": "def list_links(self, *args, **kwargs):\n        \"\"\"Display the list of links in the current page. Arguments are\n        forwarded to :func:`links`.\n        \"\"\"\n        print(\"Links in the current page:\")\n        for l in self.links(*args, **kwargs):\n            print(\"    \", l)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef links(self, url_regex=None, link_text=None, *args, **kwargs):\n        all_links = self.get_current_page().find_all(\n            'a', href=True, *args, **kwargs)\n        if url_regex is not None:\n            all_links = [a for a in all_links\n                         if re.search(url_regex, a['href'])]\n        if link_text is not None:\n            all_links = [a for a in all_links\n                         if a.text == link_text]\n        return all_links", "response": "Return a list of bs4. element. Tag objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_link(self, *args, **kwargs):\n        links = self.links(*args, **kwargs)\n        if len(links) == 0:\n            raise LinkNotFoundError()\n        else:\n            return links[0]", "response": "Find and return a link as a bs4. element. Tag object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap around find_link that handles special - cases.", "response": "def _find_link_internal(self, link, args, kwargs):\n        \"\"\"Wrapper around find_link that deals with convenience special-cases:\n\n        * If ``link`` has an *href*-attribute, then return it. If not,\n          consider it as a ``url_regex`` argument.\n\n        * If searching for the link fails and debug is active, launch\n          a browser.\n        \"\"\"\n        if hasattr(link, 'attrs') and 'href' in link.attrs:\n            return link\n\n        # Check if \"link\" parameter should be treated as \"url_regex\"\n        # but reject obtaining it from both places.\n        if link and 'url_regex' in kwargs:\n            raise ValueError('link parameter cannot be treated as '\n                             'url_regex because url_regex is already '\n                             'present in keyword arguments')\n        elif link:\n            kwargs['url_regex'] = link\n\n        try:\n            return self.find_link(*args, **kwargs)\n        except LinkNotFoundError:\n            if self.get_debug():\n                print('find_link failed for', kwargs)\n                self.list_links()\n                self.launch_browser()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef follow_link(self, link=None, *args, **kwargs):\n        link = self._find_link_internal(link, args, kwargs)\n\n        referer = self.get_url()\n        headers = {'Referer': referer} if referer else None\n\n        return self.open_relative(link['href'], headers=headers)", "response": "Follow a link.\n\n        If ``link`` is a bs4.element.Tag (i.e. from a previous call to\n        :func:`links` or :func:`find_link`), then follow the link.\n\n        If ``link`` doesn't have a *href*-attribute or is None, treat\n        ``link`` as a url_regex and look it up with :func:`find_link`.\n        Any additional arguments specified are forwarded to this function.\n\n        If the link is not found, raise :class:`LinkNotFoundError`.\n        Before raising, if debug is activated, list available links in the\n        page and launch a browser.\n\n        :return: Forwarded from :func:`open_relative`."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload the contents of a link to a file.", "response": "def download_link(self, link=None, file=None, *args, **kwargs):\n        \"\"\"Downloads the contents of a link to a file. This function behaves\n        similarly to :func:`follow_link`, but the browser state will\n        not change when calling this function.\n\n        :param file: Filesystem path where the page contents will be\n            downloaded. If the file already exists, it will be overwritten.\n\n        Other arguments are the same as :func:`follow_link` (``link``\n        can either be a bs4.element.Tag or a URL regex, other\n        arguments are forwarded to :func:`find_link`).\n\n        :return: `requests.Response\n            <http://docs.python-requests.org/en/master/api/#requests.Response>`__\n            object.\n        \"\"\"\n        link = self._find_link_internal(link, args, kwargs)\n        url = self.absolute_url(link['href'])\n\n        referer = self.get_url()\n        headers = {'Referer': referer} if referer else None\n\n        response = self.session.get(url, headers=headers)\n        if self.raise_on_404 and response.status_code == 404:\n            raise LinkNotFoundError()\n\n        # Save the response content to file\n        if file is not None:\n            with open(file, 'wb') as f:\n                f.write(response.content)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_browser(self, soup=None):\n        if soup is None:\n            soup = self.get_current_page()\n        super(StatefulBrowser, self).launch_browser(soup)", "response": "Launch a browser to display a page for debugging purposes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfilling - in a set of fields in a form.", "response": "def set_input(self, data):\n        \"\"\"Fill-in a set of fields in a form.\n\n        Example: filling-in a login/password form\n\n        .. code-block:: python\n\n           form.set_input({\"login\": username, \"password\": password})\n\n        This will find the input element named \"login\" and give it the\n        value ``username``, and the input element named \"password\" and\n        give it the value ``password``.\n        \"\"\"\n\n        for (name, value) in data.items():\n            i = self.form.find(\"input\", {\"name\": name})\n            if not i:\n                raise InvalidFormMethod(\"No input field named \" + name)\n            i[\"value\"] = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uncheck_all(self, name):\n        for option in self.form.find_all(\"input\", {\"name\": name}):\n            if \"checked\" in option.attrs:\n                del option.attrs[\"checked\"]", "response": "Remove the checked attribute of all input elements with a given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the checked attribute of input elements of type checkbox.", "response": "def set_checkbox(self, data, uncheck_other_boxes=True):\n        \"\"\"Set the *checked*-attribute of input elements of type \"checkbox\"\n        specified by ``data`` (i.e. check boxes).\n\n        :param data: Dict of ``{name: value, ...}``.\n            In the family of checkboxes whose *name*-attribute is ``name``,\n            check the box whose *value*-attribute is ``value``. All boxes in\n            the family can be checked (unchecked) if ``value`` is True (False).\n            To check multiple specific boxes, let ``value`` be a tuple or list.\n        :param uncheck_other_boxes: If True (default), before checking any\n            boxes specified by ``data``, uncheck the entire checkbox family.\n            Consider setting to False if some boxes are checked by default when\n            the HTML is served.\n        \"\"\"\n        for (name, value) in data.items():\n            # Case-insensitive search for type=checkbox\n            checkboxes = self.find_by_type(\"input\", \"checkbox\", {'name': name})\n            if not checkboxes:\n                raise InvalidFormMethod(\"No input checkbox named \" + name)\n\n            # uncheck if requested\n            if uncheck_other_boxes:\n                self.uncheck_all(name)\n\n            # Wrap individual values (e.g. int, str) in a 1-element tuple.\n            if not isinstance(value, list) and not isinstance(value, tuple):\n                value = (value,)\n\n            # Check or uncheck one or more boxes\n            for choice in value:\n                choice_str = str(choice)  # Allow for example literal numbers\n                for checkbox in checkboxes:\n                    if checkbox.attrs.get(\"value\", \"on\") == choice_str:\n                        checkbox[\"checked\"] = \"\"\n                        break\n                    # Allow specifying True or False to check/uncheck\n                    elif choice is True:\n                        checkbox[\"checked\"] = \"\"\n                        break\n                    elif choice is False:\n                        if \"checked\" in checkbox.attrs:\n                            del checkbox.attrs[\"checked\"]\n                        break\n                else:\n                    raise LinkNotFoundError(\n                        \"No input checkbox named %s with choice %s\" %\n                        (name, choice)\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the checked attribute of input elements of type radio.", "response": "def set_radio(self, data):\n        \"\"\"Set the *checked*-attribute of input elements of type \"radio\"\n        specified by ``data`` (i.e. select radio buttons).\n\n        :param data: Dict of ``{name: value, ...}``.\n            In the family of radio buttons whose *name*-attribute is ``name``,\n            check the radio button whose *value*-attribute is ``value``.\n            Only one radio button in the family can be checked.\n        \"\"\"\n        for (name, value) in data.items():\n            # Case-insensitive search for type=radio\n            radios = self.find_by_type(\"input\", \"radio\", {'name': name})\n            if not radios:\n                raise InvalidFormMethod(\"No input radio named \" + name)\n\n            # only one radio button can be checked\n            self.uncheck_all(name)\n\n            # Check the appropriate radio button (value cannot be a list/tuple)\n            for radio in radios:\n                if radio.attrs.get(\"value\", \"on\") == str(value):\n                    radio[\"checked\"] = \"\"\n                    break\n            else:\n                raise LinkNotFoundError(\n                    \"No input radio named %s with choice %s\" % (name, value)\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the string * - attribute of the first textarea element whose name is name and value is value.", "response": "def set_textarea(self, data):\n        \"\"\"Set the *string*-attribute of the first textarea element\n        specified by ``data`` (i.e. set the text of a textarea).\n\n        :param data: Dict of ``{name: value, ...}``.\n            The textarea whose *name*-attribute is ``name`` will have\n            its *string*-attribute set to ``value``.\n        \"\"\"\n        for (name, value) in data.items():\n            t = self.form.find(\"textarea\", {\"name\": name})\n            if not t:\n                raise InvalidFormMethod(\"No textarea named \" + name)\n            t.string = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_select(self, data):\n        for (name, value) in data.items():\n            select = self.form.find(\"select\", {\"name\": name})\n            if not select:\n                raise InvalidFormMethod(\"No select named \" + name)\n\n            # Deselect all options first\n            for option in select.find_all(\"option\"):\n                if \"selected\" in option.attrs:\n                    del option.attrs[\"selected\"]\n\n            # Wrap individual values in a 1-element tuple.\n            # If value is a list/tuple, select must be a <select multiple>.\n            if not isinstance(value, list) and not isinstance(value, tuple):\n                value = (value,)\n            elif \"multiple\" not in select.attrs:\n                raise LinkNotFoundError(\"Cannot select multiple options!\")\n\n            for choice in value:\n                option = select.find(\"option\", {\"value\": choice})\n\n                # try to find with text instead of value\n                if not option:\n                    option = select.find(\"option\", string=choice)\n\n                if not option:\n                    raise LinkNotFoundError(\n                        'Option %s not found for select %s' % (choice, name)\n                    )\n\n                option.attrs[\"selected\"] = \"selected\"", "response": "Set the selected attribute of the first option element whose name * value* - attribute is value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, name, value, force=False):\n        for func in (\"checkbox\", \"radio\", \"input\", \"textarea\", \"select\"):\n            try:\n                getattr(self, \"set_\" + func)({name: value})\n                return\n            except InvalidFormMethod:\n                pass\n        if force:\n            self.new_control('text', name, value=value)\n            return\n        raise LinkNotFoundError(\"No valid element named \" + name)", "response": "Set a form element identified by name to a specified value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new input element to the form.", "response": "def new_control(self, type, name, value, **kwargs):\n        \"\"\"Add a new input element to the form.\n\n        The arguments set the attributes of the new element.\n        \"\"\"\n        old_input = self.form.find_all('input', {'name': name})\n        for old in old_input:\n            old.decompose()\n        old_textarea = self.form.find_all('textarea', {'name': name})\n        for old in old_textarea:\n            old.decompose()\n        # We don't have access to the original soup object (just the\n        # Tag), so we instantiate a new BeautifulSoup() to call\n        # new_tag(). We're only building the soup object, not parsing\n        # anything, so the parser doesn't matter. Specify the one\n        # included in Python to avoid having dependency issue.\n        control = BeautifulSoup(\"\", \"html.parser\").new_tag('input')\n        control['type'] = type\n        control['name'] = name\n        control['value'] = value\n        for k, v in kwargs.items():\n            control[k] = v\n        self.form.append(control)\n        return control"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect the input element or button element to use for form submission.", "response": "def choose_submit(self, submit):\n        \"\"\"Selects the input (or button) element to use for form submission.\n\n        :param submit: The bs4.element.Tag (or just its *name*-attribute) that\n            identifies the submit element to use. If ``None``, will choose the\n            first valid submit element in the form, if one exists.\n\n        To simulate a normal web browser, only one submit element must be\n        sent. Therefore, this does not need to be called if there is only\n        one submit element in the form.\n\n        If the element is not found or if multiple elements match, raise a\n        :class:`LinkNotFoundError` exception.\n\n        Example: ::\n\n            browser = mechanicalsoup.StatefulBrowser()\n            browser.open(url)\n            form = browser.select_form()\n            form.choose_submit('form_name_attr')\n            browser.submit_selected()\n        \"\"\"\n        # Since choose_submit is destructive, it doesn't make sense to call\n        # this method twice unless no submit is specified.\n        if self._submit_chosen:\n            if submit is None:\n                return\n            else:\n                raise Exception('Submit already chosen. Cannot change submit!')\n\n        # All buttons NOT of type (button,reset) are valid submits\n        inps = (self.find_by_type(\"input\", \"submit\", dict()) +\n                self.form.find_all(\"button\"))\n        inps = [i for i in inps\n                if i.get('type', '').lower() not in ('button', 'reset')]\n\n        # If no submit specified, choose the first one\n        if submit is None and inps:\n            submit = inps[0]\n\n        found = False\n        for inp in inps:\n            if (inp.has_attr('name') and inp['name'] == submit):\n                if found:\n                    raise LinkNotFoundError(\n                        \"Multiple submit elements match: {0}\".format(submit)\n                    )\n                found = True\n            elif inp == submit:\n                if found:\n                    # Ignore submit element since it is an exact\n                    # duplicate of the one we're looking at.\n                    del inp['name']\n                found = True\n            else:\n                # Delete any non-matching element's name so that it will be\n                # omitted from the submitted form data.\n                del inp['name']\n\n        if not found and submit is not None:\n            raise LinkNotFoundError(\n                \"Specified submit element not found: {0}\".format(submit)\n            )\n        self._submit_chosen = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_summary(self):\n        for input in self.form.find_all(\n                (\"input\", \"textarea\", \"select\", \"button\")):\n            input_copy = copy.copy(input)\n            # Text between the opening tag and the closing tag often\n            # contains a lot of spaces that we don't want here.\n            for subtag in input_copy.find_all() + [input_copy]:\n                if subtag.string:\n                    subtag.string = subtag.string.strip()\n            print(input_copy)", "response": "Print a summary of the form."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nguess entity type when Content - Type header is missing.", "response": "def __looks_like_html(response):\n        \"\"\"Guesses entity type when Content-Type header is missing.\n        Since Content-Type is not strictly required, some servers leave it out.\n        \"\"\"\n        text = response.text.lstrip().lower()\n        return text.startswith('<html') or text.startswith('<!doctype')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_soup(response, soup_config):\n        if (\"text/html\" in response.headers.get(\"Content-Type\", \"\") or\n                Browser.__looks_like_html(response)):\n            response.soup = bs4.BeautifulSoup(response.content, **soup_config)\n        else:\n            response.soup = None", "response": "Attaches a soup object to a requests response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_user_agent(self, user_agent):\n        # set a default user_agent if not specified\n        if user_agent is None:\n            requests_ua = requests.utils.default_user_agent()\n            user_agent = '%s (%s/%s)' % (requests_ua, __title__, __version__)\n\n        # the requests module uses a case-insensitive dict for session headers\n        self.session.headers['User-agent'] = user_agent", "response": "Replaces the current user agent in the requests session headers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(self, *args, **kwargs):\n        response = self.session.request(*args, **kwargs)\n        Browser.add_soup(response, self.soup_config)\n        return response", "response": "Straightforward wrapper around requests. Session. request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _request(self, form, url=None, **kwargs):\n        method = str(form.get(\"method\", \"get\"))\n        action = form.get(\"action\")\n        url = urllib.parse.urljoin(url, action)\n        if url is None:  # This happens when both `action` and `url` are None.\n            raise ValueError('no URL to submit to')\n\n        # read https://www.w3.org/TR/html52/sec-forms.html\n        data = kwargs.pop(\"data\", dict())\n        files = kwargs.pop(\"files\", dict())\n\n        # Use a list of 2-tuples to better reflect the behavior of browser QSL.\n        # Requests also retains order when encoding form data in 2-tuple lists.\n        data = [(k, v) for k, v in data.items()]\n\n        # Process form tags in the order that they appear on the page,\n        # skipping those tags that do not have a name-attribute.\n        selector = \",\".join(\"{}[name]\".format(i) for i in\n                            (\"input\", \"button\", \"textarea\", \"select\"))\n        for tag in form.select(selector):\n            name = tag.get(\"name\")  # name-attribute of tag\n\n            # Skip disabled elements, since they should not be submitted.\n            if tag.has_attr('disabled'):\n                continue\n\n            if tag.name == \"input\":\n                if tag.get(\"type\", \"\").lower() in (\"radio\", \"checkbox\"):\n                    if \"checked\" not in tag.attrs:\n                        continue\n                    value = tag.get(\"value\", \"on\")\n                else:\n                    # browsers use empty string for inputs with missing values\n                    value = tag.get(\"value\", \"\")\n\n                if tag.get(\"type\", \"\").lower() == \"file\":\n                    # read http://www.cs.tut.fi/~jkorpela/forms/file.html\n                    # in browsers, file upload only happens if the form\n                    # (or submit button) enctype attribute is set to\n                    # \"multipart/form-data\". We don't care, simplify.\n                    filename = value\n                    if filename != \"\" and isinstance(filename, string_types):\n                        content = open(filename, \"rb\")\n                    else:\n                        content = \"\"\n                    # If value is the empty string, we still pass it for\n                    # consistency with browsers (see #250).\n                    files[name] = (filename, content)\n                else:\n                    data.append((name, value))\n\n            elif tag.name == \"button\":\n                if tag.get(\"type\", \"\").lower() in (\"button\", \"reset\"):\n                    continue\n                else:\n                    data.append((name, tag.get(\"value\", \"\")))\n\n            elif tag.name == \"textarea\":\n                data.append((name, tag.text))\n\n            elif tag.name == \"select\":\n                # If the value attribute is not specified, the content will\n                # be passed as a value instead.\n                options = tag.select(\"option\")\n                selected_values = [i.get(\"value\", i.text) for i in options\n                                   if \"selected\" in i.attrs]\n                if \"multiple\" in tag.attrs:\n                    for value in selected_values:\n                        data.append((name, value))\n                elif selected_values:\n                    # A standard select element only allows one option to be\n                    # selected, but browsers pick last if somehow multiple.\n                    data.append((name, selected_values[-1]))\n                elif options:\n                    # Selects the first option if none are selected\n                    first_value = options[0].get(\"value\", options[0].text)\n                    data.append((name, first_value))\n\n        if method.lower() == \"get\":\n            kwargs[\"params\"] = data\n        else:\n            kwargs[\"data\"] = data\n\n        return self.session.request(method, url, files=files, **kwargs)", "response": "This method is used to send data from the form to a Requests session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef submit(self, form, url=None, **kwargs):\n        if isinstance(form, Form):\n            form = form.form\n        response = self._request(form, url, **kwargs)\n        Browser.add_soup(response, self.soup_config)\n        return response", "response": "Prepares and sends a form request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlaunching a browser to display a page for debugging purposes.", "response": "def launch_browser(self, soup):\n        \"\"\"Launch a browser to display a page, for debugging purposes.\n\n        :param: soup: Page contents to display, supplied as a bs4 soup object.\n        \"\"\"\n        with tempfile.NamedTemporaryFile(delete=False, suffix='.html') as file:\n            file.write(soup.encode())\n        webbrowser.open('file://' + file.name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if self.session is not None:\n            self.session.cookies.clear()\n            self.session.close()\n            self.session = None", "response": "Close the current session if still open."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a pip requirements file into a list of strings.", "response": "def requirements_from_file(filename):\n    \"\"\"Parses a pip requirements file into a list.\"\"\"\n    return [line.strip() for line in open(filename, 'r')\n            if line.strip() and not line.strip().startswith('--')]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(fname, URL, URLImage):\n    readme = open(path.join(path.dirname(__file__), fname)).read()\n    if hasattr(readme, 'decode'):\n        # In Python 3, turn bytes into str.\n        readme = readme.decode('utf8')\n    # turn relative links into absolute ones\n    readme = re.sub(r'`<([^>]*)>`__',\n                    r'`\\1 <' + URL + r\"/blob/master/\\1>`__\",\n                    readme)\n    readme = re.sub(r\"\\.\\. image:: /\", \".. image:: \" + URLImage + \"/\", readme)\n\n    return readme", "response": "Read the content of a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a scatter plot of the images at the given positions.", "response": "def imscatter(images, positions):\n    '''\n        Creates a scatter plot, where each plot is shown by corresponding image\n    '''\n    positions = np.array(positions)\n\n    bottoms = positions[:, 1] - np.array([im.shape[1] / 2.0 for im in images])\n    tops = bottoms + np.array([im.shape[1] for im in images])\n\n    lefts = positions[:, 0] - np.array([im.shape[0] / 2.0 for im in images])\n    rigths = lefts + np.array([im.shape[0] for im in images])\n\n    most_bottom = int(np.floor(bottoms.min()))\n    most_top = int(np.ceil(tops.max()))\n\n    most_left = int(np.floor(lefts.min()))\n    most_right = int(np.ceil(rigths.max()))\n\n    scatter_image = np.zeros(\n        [most_right - most_left, most_top - most_bottom, 3], dtype=imgs[0].dtype)\n\n    # shift, now all from zero\n    positions -= [most_left, most_bottom]\n\n    for im, pos in zip(images, positions):\n\n        xl = int(pos[0] - im.shape[0] / 2)\n        xr = xl + im.shape[0]\n\n        yb = int(pos[1] - im.shape[1] / 2)\n        yt = yb + im.shape[1]\n\n        scatter_image[xl:xr, yb:yt, :] = im\n    return scatter_image"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a sequence of pauli operators to a sequence of pauli operators.", "response": "def pauli(qubo):\n\t\"\"\"\n\tConvert to pauli operators of universal gate model.\n\tRequires blueqat.\n\t\"\"\"\n\tfrom blueqat.pauli import qubo_bit\n\th = 0.0\n\tassert all(len(q) == len(qubo) for q in qubo)\n\tfor i in range(len(qubo)):\n\t\th += qubo_bit(i) * qubo[i][i]\n\t\tfor j in range(i + 1, len(qubo)):\n\t\t\th += qubo_bit(i)*qubo_bit(j) * (qubo[i][j] + qubo[j][i])\n\treturn h"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_qs(n, m=None):\n    try:\n        import sympy\n    except ImportError:\n        raise ImportError(\"This function requires sympy. Please install it.\")\n    if m is None:\n        syms = sympy.symbols(\" \".join(f\"q{i}\" for i in range(n)))\n        if isinstance(syms, tuple):\n            return syms\n        else:\n            return (syms,)\n    syms = sympy.symbols(\" \".join(f\"q{i}\" for i in range(n, m)))\n    if isinstance(syms, tuple):\n        return syms\n    else:\n        return (syms,)", "response": "Make sympy symbols q0 q1..."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting n - body problem to 2 - body problem.", "response": "def nbody_separation(expr, qs):\n    \"\"\"Convert n-body problem to 2-body problem.\n    \n    Args:\n        expr: sympy expressions to be separated.\n        qs: sympy's symbols to be used as supplementary variable.\n\n    Return:\n        new_expr(sympy expr), constraints(sympy expr), mapping(dict(str, str -> Symbol)):\n            `new_expr` is converted problem, `constraints` is constraints for supplementary variable.\n            You may use `expr = new_expr + delta * constraints`, delta is floating point variable.\n            mapping is supplementary variable's mapping.\n    \"\"\"\n    try:\n        import sympy\n    except ImportError:\n        raise ImportError(\"This function requires sympy. Please install it.\")\n    logging.debug(expr)\n    free_symbols = expr.free_symbols\n    logging.debug(free_symbols)\n    assert type(expr) == sympy.Add\n    logging.debug(expr.args)\n    mapping = {}\n    new_expr = sympy.expand(0)\n    constraints = sympy.expand(0)\n    i_var = 0\n    for arg in expr.args:\n        if isinstance(arg, sympy.Symbol):\n            new_expr += arg\n            continue\n        if not arg.free_symbols:\n            new_expr += arg\n            continue\n        assert type(arg) == sympy.Mul\n        syms = arg.free_symbols.copy()\n        while len(syms) > 2:\n            it = iter(syms)\n            for v1, v2 in zip(it, it):\n                if (str(v1), str(v2)) in mapping:\n                    v = mapping[str(v1), str(v2)]\n                    logging.debug(f\"{v1}*{v2} -> {v} (Existed variable)\")\n                else:\n                    v = qs[i_var]\n                    i_var += 1\n                    mapping[(str(v1), str(v2))] = v\n                    logging.debug(f\"{v1}*{v2} -> {v} (New variable)\")\n                    constraints += 3*v + v1*v2 - 2*v1*v - 2*v2*v\n                    logging.debug(f\"constraints: {constraints}\")\n                arg = arg.subs(v1*v2, v)\n            syms = arg.free_symbols.copy()\n        new_expr += arg\n        logging.debug(f\"new_expr: {new_expr}\")\n    return new_expr, constraints, mapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a Sympy s quadratic expression with variable q0 q1... to a QUBO matrix.", "response": "def qn_to_qubo(expr):\n    \"\"\"Convert Sympy's expr to QUBO.\n    \n    Args:\n        expr: Sympy's quadratic expression with variable `q0`, `q1`, ...\n    Returns:\n        [[float]]: Returns QUBO matrix.\n    \"\"\"\n    try:\n        import sympy\n    except ImportError:\n        raise ImportError(\"This function requires sympy. Please install it.\")\n    assert type(expr) == sympy.Add\n    to_i = lambda s: int(str(s)[1:])\n    max_i = max(map(to_i, expr.free_symbols)) + 1\n    qubo = [[0.] * max_i for _ in range(max_i)]\n    for arg in expr.args:\n        syms = arg.free_symbols\n        assert len(syms) <= 2\n        if len(syms) == 2:\n            assert type(arg) == sympy.Mul\n            i, j = list(map(to_i, syms))\n            if i > j:\n                i, j = j, i\n            if i == j:\n                if len(arg.args) == 2:\n                    qubo[i][i] = float(arg.args[0])\n                elif len(arg.args) == 1:\n                    qubo[i][i] = 1.0\n                else:\n                    raise ValueError(f\"Too many args! arg.args = {arg.args}\")\n                continue\n            if len(arg.args) == 3:\n                qubo[i][j] = float(arg.args[0])\n            elif len(arg.args) == 2:\n                qubo[i][j]\n        if len(syms) == 1:\n            if len(arg.args) == 2:\n                assert type(arg) == sympy.Mul\n                i = to_i(next(iter(syms)))\n                qubo[i][i] = float(arg.args[0])\n            elif len(arg.args) == 1:\n                qubo[i][i] = 1.0\n            else:\n                raise ValueError(f\"Too many args! arg.args = {arg.args}\")\n    return qubo"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sel(selN,selK,selarr=[]):\n\tselres = np.diag([1-2*selK]*selN)+np.triu([[2] * selN for i in range(selN)],k=1)\n\tselmat = np.zeros(selN)\n\tfor i in range(len(selarr)):\n\t\tselmat[selarr[i]] += 1\n\tselres = np.asarray(selres) - 0.5*np.diag(selmat)\n\treturn selres", "response": "create QUBO which select K qubits from N qubits"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a matrix of connectivity between 0 and 1 for all edges and graph size N", "response": "def net(narr,nnet):\n\t\"\"\"\n\tAutomatically create QUBO which has value 1 for all connectivity defined by array of edges and graph size N\n\t.. code-block:: python\n\t\tprint(wq.net([[0,1],[1,2]],4))\n\t\t#=>\n\t\t[[0. 1. 0. 0.]\n\t\t[0. 0. 1. 0.]\n\t\t[0. 0. 0. 0.]\n\t\t[0. 0. 0. 0.]]\n\tthis create 4*4 QUBO and put value 1 on connection between 0th and 1st qubit, 1st and 2nd qubit\n\t\"\"\"\n\tmat = np.zeros((nnet,nnet))\n\tfor i in range(len(narr)):\n\t\tnarr[i] = np.sort(narr[i])\n\t\tmat[narr[i][0]][narr[i][1]] = 1\n\treturn mat"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndrawing the energy chart using matplotlib.", "response": "def plot(self):\n\t\t\"\"\"\n\t\tDraws energy chart using matplotlib.\n\t\t\"\"\"\n\t\timport matplotlib.pyplot as plt\n\t\tplt.plot(self.E)\n\t\tplt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self,shots=1,targetT=0.02,verbose=False):\n\t\tif self.qubo != []:\n\t\t\tself.qi()\n\t\tJ = self.reJ()\n\t\tN = len(J)\n\n\t\titetemp = 100\n\t\tRtemp = 0.75\n\n\t\tself.E = []\n\t\tqq = []\n\t\tfor i in range(shots):\n\t\t\tT = self.Ts\n\t\t\tq = np.random.choice([-1,1],N)\n\t\t\tEE = []\n\t\t\tEE.append(Ei(q,self.J)+self.ep)\n\t\t\twhile T>targetT:\n\t\t\t\tx_list = np.random.randint(0, N, itetemp)\n\t\t\t\tfor x in x_list:\n\t\t\t\t\tq2 = np.ones(N)*q[x]\n\t\t\t\t\tq2[x] = 1\n\t\t\t\t\tdE = -2*sum(q*q2*J[:,x])\n\n\t\t\t\t\tif dE < 0 or np.exp(-dE/T) > np.random.random_sample():\n\t\t\t\t\t\tq[x] *= -1\n\t\t\t\tEE.append(Ei(q,self.J)+self.ep)\n\t\t\t\tT *= Rtemp\n\t\t\tself.E.append(EE)\n\t\t\tqtemp = (np.asarray(q,int)+1)/2\n\t\t\tqq.append([int(s) for s in qtemp])\n\t\t\tif verbose == True:\n\t\t\t\tprint(i,':',[int(s) for s in qtemp])\n\t\t\tif shots == 1:\n\t\t\t\tqq = qq[0]\n\t\tif shots == 1:\n\t\t\tself.E = self.E[0]\n\t\treturn qq", "response": "Run SA with provided QUBO. \n\tSet qubo attribute in advance of calling this method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo the Number partition QAOA.", "response": "def numpartition_qaoa(n_step, nums, minimizer=None, sampler=None):\n    \"\"\"Do the Number partition QAOA.\n\n    :param n_step: The number of step of QAOA\n    :param nums: The edges list of the graph.\n    :returns Vqe object\n    \"\"\"\n    hamiltonian = pauli.Expr.zero()\n    for i, x in enumerate(nums):\n        hamiltonian += pauli.Z[i] * x\n    hamiltonian = (hamiltonian ** 2).simplify()\n\n    return vqe.Vqe(vqe.QaoaAnsatz(hamiltonian, n_step), minimizer, sampler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_maximum_index(indices):\n    def _maximum_idx_single(idx):\n        if isinstance(idx, slice):\n            start = -1\n            stop = 0\n            if idx.start is not None:\n                start = idx.start.__index__()\n            if idx.stop is not None:\n                stop = idx.stop.__index__()\n            return max(start, stop - 1)\n        else:\n            return idx.__index__()\n    if isinstance(indices, tuple):\n        return max((_maximum_idx_single(i) for i in indices), default=-1)\n    else:\n        return _maximum_idx_single(indices)", "response": "Internally used. Returns the index of the maximum entry in the sequence of entries in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _str_targets(self):\n        def _slice_to_str(obj):\n            if isinstance(obj, slice):\n                start = \"\" if obj.start is None else str(obj.start.__index__())\n                stop = \"\" if obj.stop is None else str(obj.stop.__index__())\n                if obj.step is None:\n                    return f\"{start}:{stop}\"\n                else:\n                    step = str(obj.step.__index__())\n                    return f\"{start}:{stop}:{step}\"\n            else:\n                return obj.__index__()\n\n        if isinstance(self.targets, tuple):\n            return f\"[{', '.join(_slice_to_str(idx for idx in self.targets))}]\"\n        else:\n            return f\"[{_slice_to_str(self.targets)}]\"", "response": "Returns printable string of targets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_inttuple(bitstr):\n    if isinstance(bitstr, str):\n        return tuple(int(b) for b in bitstr)\n    if isinstance(bitstr, Counter):\n        return Counter({tuple(int(b) for b in k): v for k, v in bitstr.items()})\n    if isinstance(bitstr, dict):\n        return {tuple(int(b) for b in k): v for k, v in bitstr.items()}\n    raise ValueError(\"bitstr type shall be `str`, `Counter` or `dict`\")", "response": "Convert from bitstring likes 01011 to int tuple likes 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_scipy_minimizer(**kwargs):\n    def minimizer(objective, n_params):\n        params = [random.random() for _ in range(n_params)]\n        result = scipy_minimizer(objective, params, **kwargs)\n        return result.x\n    return minimizer", "response": "Get minimizer which uses scipy. optimize. minimize"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef expect(qubits, meas):\n    \"For the VQE simulation without sampling.\"\n    result = {}\n    i = np.arange(len(qubits))\n    meas = tuple(meas)\n\n    def to_mask(n):\n        return reduce(lambda acc, im: acc | (n & (1 << im[0])) << (im[1] - im[0]), enumerate(meas), 0)\n\n    def to_key(k):\n        return tuple(1 if k & (1 << i) else 0 for i in meas)\n\n    mask = reduce(lambda acc, v: acc | (1 << v), meas, 0)\n\n    cnt = defaultdict(float)\n    for i, v in enumerate(qubits):\n        p = v.real ** 2 + v.imag ** 2\n        if p != 0.0:\n            cnt[i & mask] += p\n    return {to_key(k): v for k, v in cnt.items()}", "response": "For the VQE simulation without sampling."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef non_sampling_sampler(circuit, meas):\n    meas = tuple(meas)\n    n_qubits = circuit.n_qubits\n    return expect(circuit.run(returns=\"statevector\"), meas)", "response": "Calculate the expectations without sampling."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_measurement_sampler(n_sample, run_options=None):\n    if run_options is None:\n        run_options = {}\n\n    def sampling_by_measurement(circuit, meas):\n        def reduce_bits(bits, meas):\n            bits = [int(x) for x in bits[::-1]]\n            return tuple(bits[m] for m in meas)\n\n        meas = tuple(meas)\n        circuit.measure[meas]\n        counter = circuit.run(shots=n_sample, returns=\"shots\", **run_options)\n        counts = Counter({reduce_bits(bits, meas): val for bits, val in counter.items()})\n        return {k: v / n_sample for k, v in counts.items()}\n\n    return sampling_by_measurement", "response": "Returns a function which returns the expectations by sampling the measured circuit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a function which gets the expectations by sampling the state vector", "response": "def get_state_vector_sampler(n_sample):\n    \"\"\"Returns a function which get the expectations by sampling the state vector\"\"\"\n    def sampling_by_measurement(circuit, meas):\n        val = 0.0\n        e = expect(circuit.run(returns=\"statevector\"), meas)\n        bits, probs = zip(*e.items())\n        dists = np.random.multinomial(n_sample, probs) / n_sample\n        return dict(zip(tuple(bits), dists))\n    return sampling_by_measurement"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_qiskit_sampler(backend, **execute_kwargs):\n    try:\n        import qiskit\n    except ImportError:\n        raise ImportError(\"blueqat.vqe.get_qiskit_sampler() requires qiskit. Please install before call this function.\")\n    try:\n        shots = execute_kwargs['shots']\n    except KeyError:\n        execute_kwargs['shots'] = shots = 1024\n\n    def reduce_bits(bits, meas):\n        # In Qiskit 0.6.1, For example\n        # Aer backend returns bit string and IBMQ backend returns hex string.\n        # Sample code:\n        \"\"\"\nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer, IBMQ\nIBMQ.load_accounts()\nq, c = QuantumRegister(4, 'q'), ClassicalRegister(4, 'c')\ncirc = QuantumCircuit(q, c)\ncirc.x(q[1])\nfor i in range(4):\n    circ.measure(q[i], c[i])\nprint(\"Aer qasm_simulator_py\")\nprint(execute(circ, Aer.get_backend('qasm_simulator_py')).result().get_counts())\nprint(\"IBMQ ibmq_qasm_simulator\")\nprint(execute(circ, IBMQ.get_backend('ibmq_qasm_simulator')).result().get_counts())\n        \"\"\"\n        # The result is,\n        # Aer: {'0010': 1024}\n        # IBMQ: {'0x2': 1024}\n        # This is workaround for this IBM's specifications.\n        if bits.startswith(\"0x\"):\n            bits = int(bits, base=16)\n            bits = \"0\"*100 + format(bits, \"b\")\n        bits = [int(x) for x in bits[::-1]]\n        return tuple(bits[m] for m in meas)\n\n    def sampling(circuit, meas):\n        meas = tuple(meas)\n        if not meas:\n            return {}\n        circuit.measure[meas]\n        qasm = circuit.to_qasm()\n        qk_circuit = qiskit.load_qasm_string(qasm)\n        result = qiskit.execute(qk_circuit, backend, **execute_kwargs).result()\n        counts = Counter({reduce_bits(bits, meas): val for bits, val in result.get_counts().items()})\n        return {k: v / shots for k, v in counts.items()}\n\n    return sampling", "response": "Returns a function which get the expectation by sampling via Qiskit module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_energy(self, circuit, sampler):\n        val = 0.0\n        for meas in self.hamiltonian:\n            c = circuit.copy()\n            for op in meas.ops:\n                if op.op == \"X\":\n                    c.h[op.n]\n                elif op.op == \"Y\":\n                    c.rx(-np.pi / 2)[op.n]\n            measured = sampler(c, meas.n_iter())\n            for bits, prob in measured.items():\n                if sum(bits) % 2:\n                    val -= prob * meas.coeff\n                else:\n                    val += prob * meas.coeff\n        return val.real", "response": "Calculate energy from circuit and sampler."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_objective(self, sampler):\n        def objective(params):\n            circuit = self.get_circuit(params)\n            circuit.make_cache()\n            return self.get_energy(circuit, sampler)\n        return objective", "response": "Get an objective function to be optimized."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef factoring_qaoa(n_step, num, minimizer=None, sampler=None, verbose=True):\n    def get_nbit(n):\n        m = 1\n        while 2**m < n:\n            m += 1\n        return m\n\n    n1_bits = get_nbit(int(num**0.5)) - 1\n    n2_bits = get_nbit(int(num**0.5))\n\n    def mk_expr(offset, n):\n        expr = pauli.Expr.from_number(1)\n        for i in range(n):\n            expr = expr + 2**(i + 1) * q(i + offset)\n        return expr\n\n    def bitseparator(bits):\n        assert len(bits) == n1_bits + n2_bits\n        p = 1\n        m = 1\n        for b in bits[:n1_bits]:\n            if b:\n                p += 2**m\n            m += 1\n        q = 1\n        m = 1\n        for b in bits[n1_bits:]:\n            if b:\n                q += 2**m\n            m += 1\n        return p, q\n\n    hamiltonian = (num - mk_expr(0, n1_bits) * mk_expr(n1_bits, n2_bits))**2\n    return vqe.Vqe(vqe.QaoaAnsatz(hamiltonian, n_step), minimizer, sampler), bitseparator", "response": "Factor the number of nodes in the QAOA graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run_gates(self, gates, n_qubits, ctx):\n        for gate in gates:\n            action = self._get_action(gate)\n            if action is not None:\n                ctx = action(gate, ctx)\n            else:\n                ctx = self._run_gates(gate.fallback(n_qubits), n_qubits, ctx)\n        return ctx", "response": "Iterate gates and call backend s action for each gate"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run(self, gates, n_qubits, args, kwargs):\n        gates, ctx = self._preprocess_run(gates, n_qubits, args, kwargs)\n        self._run_gates(gates, n_qubits, ctx)\n        return self._postprocess_run(ctx)", "response": "Default implementation of Backend. run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve fallbacks and flatten gates.", "response": "def _resolve_fallback(self, gates, n_qubits):\n        \"\"\"Resolve fallbacks and flatten gates.\"\"\"\n        flattened = []\n        for g in gates:\n            if self._has_action(g):\n                flattened.append(g)\n            else:\n                flattened += self._resolve_fallback(g.fallback(n_qubits), n_qubits)\n        return flattened"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(self, cache):\n        if cache is not None:\n            np.copyto(self.qubits, cache)\n        else:\n            self.qubits.fill(0.0)\n            self.qubits[0] = 1.0\n        self.cregs = [0] * self.n_qubits", "response": "Prepare to run next shot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store_shot(self):\n        def to_str(cregs):\n            return ''.join(str(b) for b in cregs)\n        key = to_str(self.cregs)\n        self.shots_result[key] = self.shots_result.get(key, 0) + 1", "response": "Store current cregs to shots_result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying the current state of the current state of the current state.", "response": "def copy(self, copy_backends=True, copy_default_backend=True,\n             copy_cache=None, copy_history=None):\n        \"\"\"Copy the circuit.\n\n        :params\n        copy_backends :bool copy backends if True.\n        copy_default_backend :bool copy default_backend if True.\n        \"\"\"\n        copied = Circuit(self.n_qubits, self.ops.copy())\n        if copy_backends:\n            copied._backends = {k: v.copy() for k, v in self._backends.items()}\n        if copy_default_backend:\n            copied._default_backend = self._default_backend\n\n        # Warn for deprecated options\n        if copy_cache is not None:\n            warnings.warn(\"copy_cache is deprecated. Use copy_backends instead.\",\n                          DeprecationWarning)\n        if copy_history is not None:\n            warnings.warn(\"copy_history is deprecated.\", DeprecationWarning)\n\n        return copied"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the circuit. `Circuit` have several backends. When `backend` parameter is specified, use specified backend, and otherwise, default backend is used. Other parameters are passed to the backend. The meaning of parameters are depends on the backend specifications. However, following parameters are commonly used. Commonly used args (Depends on backend): shots (int, optional): The number of sampling the circuit. returns (str, optional): The category of returns value. e.g. \"statevector\" returns the state vector after run the circuit. \"shots\" returns the counter of measured value. token, url (str, optional): The token and URL for cloud resource. Returns: Depends on backend. Raises: Depends on backend.", "response": "def run(self, *args, backend=None, **kwargs):\n        \"\"\"Run the circuit.\n\n        `Circuit` have several backends. When `backend` parameter is specified,\n        use specified backend, and otherwise, default backend is used.\n        Other parameters are passed to the backend.\n\n        The meaning of parameters are depends on the backend specifications.\n        However, following parameters are commonly used.\n\n        Commonly used args (Depends on backend):\n            shots (int, optional): The number of sampling the circuit.\n            returns (str, optional):  The category of returns value.\n                e.g. \"statevector\" returns the state vector after run the circuit.\n                     \"shots\" returns the counter of measured value.\n            token, url (str, optional): The token and URL for cloud resource.\n\n        Returns:\n            Depends on backend.\n\n        Raises:\n            Depends on backend.\n        \"\"\"\n        if backend is None:\n            if self._default_backend is None:\n                backend = self.__get_backend(DEFAULT_BACKEND_NAME)\n            else:\n                backend = self.__get_backend(self._default_backend)\n        elif isinstance(backend, str):\n            backend = self.__get_backend(backend)\n        return backend.run(self.ops, self.n_qubits, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a cache to reduce the time of run.", "response": "def make_cache(self, backend=None):\n        \"\"\"Make a cache to reduce the time of run. Some backends may implemented it.\n\n        This is temporary API. It may changed or deprecated.\"\"\"\n        if backend is None:\n            if self._default_backend is None:\n                backend = DEFAULT_BACKEND_NAME\n            else:\n                backend = self._default_backend\n        return self.__get_backend(backend).make_cache(self.ops, self.n_qubits)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the default backend of this circuit.", "response": "def set_default_backend(self, backend_name):\n        \"\"\"Set the default backend of this circuit.\n\n        This setting is only applied for this circuit.\n        If you want to change the default backend of all gates,\n        use `BlueqatGlobalSetting.set_default_backend()`.\n\n        After set the default backend by this method,\n        global setting is ignored even if `BlueqatGlobalSetting.set_default_backend()` is called.\n        If you want to use global default setting, call this method with backend_name=None.\n\n        Args:\n            backend_name (str or None): new default backend name.\n                If None is given, global setting is applied.\n\n        Raises:\n            ValueError: If `backend_name` is not registered backend.\n        \"\"\"\n        if backend_name not in BACKENDS:\n            raise ValueError(f\"Unknown backend '{backend_name}'.\")\n        self._default_backend = backend_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_macro(name: str, func: Callable, allow_overwrite: bool = False) -> None:\n        if hasattr(Circuit, name):\n            if allow_overwrite:\n                warnings.warn(f\"Circuit has attribute `{name}`.\")\n            else:\n                raise ValueError(f\"Circuit has attribute `{name}`.\")\n        if name.startswith(\"run_with_\"):\n            if allow_overwrite:\n                warnings.warn(f\"Gate name `{name}` may conflict with run of backend.\")\n            else:\n                raise ValueError(f\"Gate name `{name}` shall not start with 'run_with_'.\")\n        if not allow_overwrite:\n            if name in GATE_SET:\n                raise ValueError(f\"Gate '{name}' is already exists in gate set.\")\n            if name in GLOBAL_MACROS:\n                raise ValueError(f\"Macro '{name}' is already exists.\")\n        GLOBAL_MACROS[name] = func", "response": "Register a new macro to Circuit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_gate(name, gateclass, allow_overwrite=False):\n        if hasattr(Circuit, name):\n            if allow_overwrite:\n                warnings.warn(f\"Circuit has attribute `{name}`.\")\n            else:\n                raise ValueError(f\"Circuit has attribute `{name}`.\")\n        if name.startswith(\"run_with_\"):\n            if allow_overwrite:\n                warnings.warn(f\"Gate name `{name}` may conflict with run of backend.\")\n            else:\n                raise ValueError(f\"Gate name `{name}` shall not start with 'run_with_'.\")\n        if not allow_overwrite:\n            if name in GATE_SET:\n                raise ValueError(f\"Gate '{name}' is already exists in gate set.\")\n            if name in GLOBAL_MACROS:\n                raise ValueError(f\"Macro '{name}' is already exists.\")\n        GATE_SET[name] = gateclass", "response": "Register a new gate to the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_backend(name, backend, allow_overwrite=False):\n        if hasattr(Circuit, \"run_with_\" + name):\n            if allow_overwrite:\n                warnings.warn(f\"Circuit has attribute `run_with_{name}`.\")\n            else:\n                raise ValueError(f\"Circuit has attribute `run_with_{name}`.\")\n        if not allow_overwrite:\n            if name in BACKENDS:\n                raise ValueError(f\"Backend '{name}' is already registered as backend.\")\n        BACKENDS[name] = backend", "response": "Register a new backend."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pauli_from_char(ch, n=0):\n    ch = ch.upper()\n    if ch == \"I\":\n        return I\n    if ch == \"X\":\n        return X(n)\n    if ch == \"Y\":\n        return Y(n)\n    if ch == \"Z\":\n        return Z(n)\n    raise ValueError(\"ch shall be X, Y, Z or I\")", "response": "Make a Pauli matrix from a character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the commutator of expr1 and expr2.", "response": "def commutator(expr1, expr2):\n    \"\"\"Returns [expr1, expr2] = expr1 * expr2 - expr2 * expr1.\n\n    Args:\n        expr1 (Expr, Term or Pauli operator): Pauli's expression.\n        expr2 (Expr, Term or Pauli operator): Pauli's expression.\n\n    Returns:\n        Expr: expr1 * expr2 - expr2 * expr1.\n    \"\"\"\n    expr1 = expr1.to_expr().simplify()\n    expr2 = expr2.to_expr().simplify()\n    return (expr1 * expr2 - expr2 * expr1).simplify()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_commutable(expr1, expr2, eps=0.00000001):\n    return sum((x * x.conjugate()).real for x in commutator(expr1, expr2).coeffs()) < eps", "response": "Test whether expr1 and expr2 are commutable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting to the matrix.", "response": "def to_matrix(self, n_qubits=-1):\n        \"\"\"Convert to the matrix.\"\"\"\n        if self.is_identity:\n            if n_qubits == -1:\n                return self.matrix\n            else:\n                return reduce(np.kron, [I.matrix for _ in range(n_qubits)])\n        if n_qubits == -1:\n            n_qubits = _n(self) + 1\n        if _n(self) == 0:\n            mat = self.matrix\n        else:\n            mat = reduce(np.kron, [I.matrix for _ in range(_n(self))])\n            mat = np.kron(mat, self.matrix)\n        if n_qubits > _n(self) + 1:\n            mat = reduce(np.kron, [I.matrix for _ in range(n_qubits - _n(self) - 1)], mat)\n        return mat"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a Term from a Pauli operator", "response": "def from_pauli(pauli, coeff=1.0):\n        \"\"\"Make new Term from an Pauli operator\"\"\"\n        if pauli.is_identity or coeff == 0:\n            return Term((), coeff)\n        return Term((pauli,), coeff)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_chars(chars):\n        paulis = [pauli_from_char(c, n) for n, c in enumerate(chars) if c != \"I\"]\n        if not paulis:\n            return 1.0 * I\n        if len(paulis) == 1:\n            return 1.0 * paulis[0]\n        return reduce(lambda a, b: a * b, paulis)", "response": "Make Pauli s Term from a sequence of characters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_to_circuit(self, circuit, simplify=True):\n        if simplify:\n            term = self.simplify()\n        else:\n            term = self\n        for op in term.ops[::-1]:\n            gate = op.op.lower()\n            if gate != \"i\":\n                getattr(circuit, gate)[op.n]", "response": "Append Pauli gates to circuit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_time_evolution(self):\n        term = self.simplify()\n        coeff = term.coeff\n        if coeff.imag:\n            raise ValueError(\"Not a real coefficient.\")\n        ops = term.ops\n        def append_to_circuit(circuit, t):\n            if not ops:\n                return\n            for op in ops:\n                n = op.n\n                if op.op == \"X\":\n                    circuit.h[n]\n                elif op.op == \"Y\":\n                    circuit.rx(-half_pi)[n]\n            for i in range(1, len(ops)):\n                circuit.cx[ops[i-1].n, ops[i].n]\n            circuit.rz(-2 * coeff * t)[ops[-1].n]\n            for i in range(len(ops)-1, 0, -1):\n                circuit.cx[ops[i-1].n, ops[i].n]\n            for op in ops:\n                n = op.n\n                if op.op == \"X\":\n                    circuit.h[n]\n                elif op.op == \"Y\":\n                    circuit.rx(half_pi)[n]\n        return append_to_circuit", "response": "Get the function to append the time evolution of this term."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting to the matrix.", "response": "def to_matrix(self, n_qubits=-1):\n        \"\"\"Convert to the matrix.\"\"\"\n        if n_qubits == -1:\n            n_qubits = self.max_n() + 1\n        mat = I.to_matrix(n_qubits)\n        for op in self.ops:\n            if op.is_identity:\n                continue\n            mat = mat @ op.to_matrix(n_qubits)\n        return mat * self.coeff"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if self is I otherwise False.", "response": "def is_identity(self):\n        \"\"\"If `self` is I, returns True, otherwise False.\"\"\"\n        if not self.terms:\n            return True\n        return len(self.terms) == 1 and not self.terms[0].ops and self.terms[0].coeff == 1.0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the maximum index of Pauli matrices in the Term.", "response": "def max_n(self):\n        \"\"\"Returns the maximum index of Pauli matrices in the Term.\"\"\"\n        return max(term.max_n() for term in self.terms if term.ops)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_all_terms_commutable(self):\n        return all(is_commutable(a, b) for a, b in combinations(self.terms, 2))", "response": "Test whether all terms are commutable. This function may very slow."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert to the matrix.", "response": "def to_matrix(self, n_qubits=-1):\n        \"\"\"Convert to the matrix.\"\"\"\n        if n_qubits == -1:\n            n_qubits = self.max_n() + 1\n        return sum(term.to_matrix(n_qubits) for term in self.terms)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_coord(self, x, y):\n        x = x*self.x_factor\n        y = y*self.y_factor\n        self.plotData.add_coord(x, y)\n        self.circles_list.append(gui.SvgCircle(x, y, self.circle_radius))\n        self.append(self.circles_list[-1])\n        if len(self.circles_list) > self.maxlen:\n            self.remove_child(self.circles_list[0])\n            del self.circles_list[0]", "response": "Adds a coord to the polyline and creates another circle"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the stroke properties.", "response": "def set_stroke(self, width=1, color='black'):\r\n        \"\"\"Sets the stroke properties.\r\n\r\n        Args:\r\n            width (int): stroke width\r\n            color (str): stroke color\r\n        \"\"\"\r\n        self.attributes['stroke'] = color\r\n        self.attributes['stroke-width'] = str(width)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_arrow_coord(self, line, arrow_height, arrow_width, recess):\r\n        # arrow = SvgPolygon(_maxlen=4)\r\n        if line.type == 'polyline':\r\n            xe = line.coordsX[-1]\r\n            ye = line.coordsY[-1]\r\n            xp = line.coordsX[-2]\r\n            yp = line.coordsY[-2]\r\n        else:\r\n            xe = line.attributes['x2']\r\n            ye = line.attributes['y2']\r\n            xp = line.attributes['x1']\r\n            yp = line.attributes['y1']\r\n        h = arrow_height\r\n        if arrow_width == 0:\r\n            w = arrow_height / 3\r\n        else:\r\n            w = arrow_width\r\n        r = recess\r\n        self.add_coord(xe, ye)\r\n        dx = xe - xp\r\n        dy = ye - yp\r\n        de = math.sqrt(dx**2 + dy**2)\r\n        xh = xe - h * dx / de\r\n        yh = ye - h * dy / de\r\n        x1 = xh + w * dy / de\r\n        y1 = yh - w * dx / de\r\n        self.add_coord(x1, y1)\r\n        x2 = xe - (h - r) * dx / de\r\n        y2 = ye - (h - r) * dy / de\r\n        self.add_coord(x2, y2)\r\n        x3 = xh - w * dy / de\r\n        y3 = yh + w * dx / de\r\n        self.add_coord(x3, y3)", "response": "Add the coordinates of an arrow head polygon to the current SvgLine object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndraws a drawing of one sheet of a set of boxes.", "response": "def Draw_a_drawing_of_one_sheet(self, nr_of_boxes, box_names):\r\n        \"\"\" Draw a drawing with two boxes, each with a name inside\r\n            and a polyline between the midpoints of the sides of the boxes,\r\n            with half-way the polyline a rhombus with an id included.\r\n        \"\"\"\r\n        thickness = 2  # Line thickness\r\n        center_x = []    # x of the center of box[i] on canvas\r\n        center_y = []    # y of the center of box[i] on canvas\r\n        mid_points = []\r\n        box_width = 100  # pixels\r\n        box_height = 100  # pixels\r\n        delta_x = self.screen_width / (nr_of_boxes + 1)\r\n        delta_y = self.screen_height / (nr_of_boxes + 1)\r\n        # Draw the boxes\r\n        for box_nr in range(0, nr_of_boxes):\r\n            center_x.append(delta_x + box_nr * delta_x)\r\n            center_y.append(delta_y + box_nr * delta_y)\r\n            name = box_names[box_nr]\r\n            ident = str(box_nr + 1)\r\n            # Draw one box at the specified location\r\n            mid_points.append(self.box_type_1(\r\n                center_x[box_nr], center_y[box_nr],\r\n                name, ident, box_width,box_height))\r\n\r\n        # Draw a line with arrow head to the first box\r\n        x2 = mid_points[0][3][0]\r\n        y2 = mid_points[0][3][1]\r\n        x1 = x2 - 150\r\n        y1 = y2\r\n        line_0 = gui.SvgLine(x1, y1, x2, y2)\r\n        line_0.set_stroke(width=thickness, color='black')\r\n        self.sheet.append(line_0)\r\n        # Add an arrow head to line_0\r\n        head_0 = SvgPolygon(4)\r\n        arrow_height = 20\r\n        arrow_width = arrow_height / 3\r\n        recess = arrow_height / 5\r\n        head_0.add_arrow_coord(line_0, arrow_height, arrow_width, recess)\r\n        head_0.set_stroke(width=thickness, color='black')\r\n        head_0.set_fill(color='blue')\r\n        self.sheet.append(head_0)\r\n\r\n        # Draw a rhombus polygon\r\n        x = (center_x[0] + center_x[1]) / 2\r\n        y = (center_y[0] + center_y[1]) / 2\r\n        self.int_id += 1\r\n        str_id = str(self.int_id)\r\n        hor_size = 15  # pixels\r\n        vert_size = 25  # pixels\r\n        rhombus = self.rhombus_polygon(x, y, str_id, hor_size, vert_size)\r\n\r\n        # Determine points of the first polyline\r\n        line_1_points = []\r\n        line_1_points.append(mid_points[0][2])\r\n        corner = [rhombus[0][0], mid_points[0][2][1]]\r\n        line_1_points.append(corner)\r\n        line_1_points.append(rhombus[0])\r\n        # Draw a polyline from box_1 to rhombus\r\n        line1 = gui.SvgPolyline(_maxlen=4)\r\n        for pt in line_1_points:\r\n            line1.add_coord(*pt)\r\n        line1.set_stroke(width=thickness, color='black')\r\n        self.sheet.append(line1)\r\n\r\n        # Determine points of the second polyline\r\n        line_2_points = []\r\n        line_2_points.append(rhombus[1])\r\n        corner = [rhombus[1][0], mid_points[1][3][1]]\r\n        line_2_points.append(corner)\r\n        line_2_points.append(mid_points[1][3])\r\n        # Drawa polyline from rhombus to box_2\r\n        line2 = gui.SvgPolyline(_maxlen=4)\r\n        for pt in line_2_points:\r\n            line2.add_coord(pt[0], pt[1])\r\n        line2.set_stroke(width=thickness, color='black')\r\n        self.sheet.append(line2)\r\n        \r\n        # Add an arrow head to line2\r\n        head = SvgPolygon(4)\r\n        head.add_arrow_coord(line2, arrow_height, arrow_width, recess)\r\n        head.set_stroke(width=thickness, color='black')\r\n        head.set_fill(color='blue')\r\n        self.sheet.append(head)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw a rectangular box of box_width and box_height with name and ident on the canvas and return the midpoint of the box.", "response": "def box_type_1(self, X, Y, name, ident, box_width, box_height):\r\n        \"\"\" Draw a rectangular box of box_width and box_height\r\n            with name and ident,\r\n            on sheet with (X,Y) as its center on the canvas\r\n            Return midpts = N(x,y), S(x,y), E(x,y), W(x,y).\r\n        \"\"\"\r\n        boxW2 = box_width / 2\r\n        boxH2 = box_height / 2\r\n        x0, y0 = X - boxW2, Y - boxH2   # Top_left of box\r\n        x1, y1 = X + boxW2, Y + boxH2   # Bottom_right of box\r\n        width = x1 - x0\r\n        height = y1 - y0\r\n        \r\n        box = gui.SvgRectangle(x0, y0, width, height)\r\n        box.set_stroke(width=2, color='black')\r\n        box.set_fill(color='yellow')\r\n        box_name = gui.SvgText(X, Y, name)\r\n        box_name.attributes['text-anchor'] = 'middle'\r\n        box_id = gui.SvgText(X, Y + 15, str(ident))\r\n        box_id.attributes['text-anchor'] = 'middle'\r\n        self.sheet.append([box, box_name, box_id])\r\n\r\n        mid_north = [X, Y - boxH2]\r\n        mid_south = [X, Y + boxH2]\r\n        mid_east = [X + boxW2, Y]\r\n        mid_west = [X - boxW2, Y]\r\n\r\n        return mid_north, mid_south, mid_east, mid_west"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing a rhombus polygon.", "response": "def rhombus_polygon(self, X, Y, str_id, hor_size, vert_size):\r\n        \"\"\" Draw a rhombus polygon.\r\n            Horizontal size (-hor_size, +hor_size) and\r\n            vertical size (-vert_size, +vert_size).\r\n            with its center on position X,Y\r\n            and with its str_id as text in the middle.\r\n        \"\"\"\r\n        x0, y0 = X - hor_size, Y   # mid_west\r\n        x1, y1 = X, Y - vert_size  # mid_north\r\n        x2, y2 = X + hor_size, Y   # mid_east\r\n        x3, y3 = X, Y + vert_size  # mid_south\r\n\r\n        polygon = SvgPolygon(4)\r\n        polygon.set_stroke(width=2, color='black')\r\n        poly_name = gui.SvgText(X, Y + 5, str_id)\r\n        poly_name.attributes['text-anchor'] = 'middle'\r\n        self.sheet.append([polygon, poly_name])\r\n\r\n        mid_north = [x1, y1]\r\n        mid_south = [x3, y3]\r\n        mid_east = [x2, y2]\r\n        mid_west = [x0, y0]\r\n        \r\n        polygon.add_coord(*mid_north)\r\n        polygon.add_coord(*mid_east)\r\n        polygon.add_coord(*mid_south)\r\n        polygon.add_coord(*mid_west)\r\n\r\n        return mid_north, mid_south, mid_east, mid_west"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef onerror(self, emitter, message, source, lineno, colno):\n        super(MyApp, self).onerror(emitter, message, source, lineno, colno)", "response": "Event that occurs on webpage errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef onresize(self, emitter, width, height):\n        super(MyApp, self).onresize(emitter, width, height)", "response": "Event that occurs on webpage gets resized"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef My_TreeTable(self, table, heads, heads2=None):\n        ''' Define and display a table\n            in which the values in first column form one or more trees.\n        '''\n        self.Define_TreeTable(heads, heads2)\n        self.Display_TreeTable(table)", "response": "Define and display a table\n            in which the values in first column form one or more trees."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Define_TreeTable(self, heads, heads2=None):\n        ''' Define a TreeTable with a heading row\n            and optionally a second heading row.\n        '''\n        display_heads = []\n        display_heads.append(tuple(heads[2:]))\n        self.tree_table = TreeTable()\n        self.tree_table.append_from_list(display_heads, fill_title=True)\n        if heads2 is not None:\n            heads2_color = heads2[1]\n            row_widget = gui.TableRow()\n            for index, field in enumerate(heads2[2:]):\n                row_item = gui.TableItem(text=field,\n                                         style={'background-color': heads2_color})\n                row_widget.append(row_item, field)\n            self.tree_table.append(row_widget, heads2[0])\n        self.wid.append(self.tree_table)", "response": "Define a TreeTable with a heading row\n            and optionally a second heading row."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Display_TreeTable(self, table):\n        ''' Display a table in which the values in first column form one or more trees.\n            The table has row with fields that are strings of identifiers/names.\n            First convert each row into a row_widget and item_widgets\n            that are displayed in a TableTree.\n            Each input row shall start with a parent field (field[0])\n            that determines the tree hierarchy but that is not displayed on that row.\n            The parent widget becomes an attribute of the first child widget.\n            Field[1] is the row color, field[2:] contains the row values.\n            Top child(s) shall have a parent field value that is blank ('').\n            The input table rows shall be in the correct sequence.\n        '''\n        parent_names = []\n        hierarchy = {}\n        indent_level = 0\n        widget_dict = {}  # key, value = name, widget\n        for row in table:\n            parent_name = row[0]\n            row_color = row[1]\n            child_name = row[2]\n            row_widget = gui.TableRow(style={'background-color': row_color})\n            # Determine whether hierarchy of sub_sub concepts shall be open or not\n            openness = 'true'\n            row_widget.attributes['treeopen'] = openness\n            # widget_dict[child_name] = row_widget\n            for index, field in enumerate(row[2:]):\n                # Determine field color\n                field_color = '#ffff99'\n                row_item = gui.TableItem(text=field,\n                                         style={'text-align': 'left',\n                                                'background-color': field_color})\n                row_widget.append(row_item, field)\n                if index == 0:\n                    row_item.parent = parent_name\n                    child_id = row_item\n\n            # The root of each tree has a parent that is blank ('').\n            # Each row with childs has as attribute openness, which by default is 'true'.\n            # The fields can be given other attributes, such as color.\n\n            # Verify whether the parent_name (child.parent)\n            # is present or is in the list of parent_names.\n            print('parent-child:', parent_name, child_name)\n            if parent_name == '':\n                hierarchy[child_name] = 0\n                parent_names.append(child_name)\n                target_level = 0\n            elif parent_name in parent_names:\n                hierarchy[child_name] = hierarchy[parent_name] + 1\n                target_level = hierarchy[child_name]\n            else:\n                # Parent not in parent_names\n                print('Error: Parent name \"{}\" does not appear in network'\n                      .format(parent_name))\n                return\n            print('indent, target-pre:', indent_level, target_level,\n                  parent_name, child_name)\n            # Indentation\n            if target_level > indent_level:\n                self.tree_table.begin_fold()\n                indent_level += 1\n            if target_level < indent_level:\n                while target_level < indent_level:\n                    indent_level += -1\n                    self.tree_table.end_fold()\n            print('indent, target-post:', indent_level, target_level,\n                  parent_name, child_name)\n            if child_name not in parent_names:\n                parent_names.append(child_name)\n            self.tree_table.append(row_widget, child_name)", "response": "Display a table in which the values in first column form one or more trees."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef confirm_value(self, widget, x, y):\n        self.gauge.onmousedown(self.gauge, x, y)\n        params = (self.gauge.value)\n        return params", "response": "event called when the user clicks on the gauge and changes its value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure_widget_for_editing(self, widget):\n        \n        if not 'editor_varname' in widget.attributes:\n            return\n        widget.onclick.do(self.on_widget_selection)\n        \n        #setup of the on_dropped function of the widget in order to manage the dragNdrop \n        widget.__class__.on_dropped = on_dropped\n\n        #drag properties\n        #widget.style['resize'] = 'both'\n        widget.style['overflow'] = 'auto'\n        widget.attributes['draggable'] = 'true'\n                \n        widget.attributes['tabindex']=str(self.tabindex)\n        #if not 'position' in widget.style.keys():\n        #    widget.style['position'] = 'absolute'\n        #if not 'left' in widget.style.keys():\n        #    widget.style['left'] = '1px'\n        #if not 'top' in widget.style.keys():\n        #    widget.style['top'] = '1px'\n        self.tabindex += 1", "response": "Configure the widget for editing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_mine_matrix(self, w, h, minenum):\n        self.minecount = 0\n        matrix = [[Cell(30, 30, x, y, self) for x in range(w)] for y in range(h)]\n        for i in range(0, minenum):\n            x = random.randint(0, w - 1)\n            y = random.randint(0, h - 1)\n            if matrix[y][x].has_mine:\n                continue\n\n            self.minecount += 1\n            matrix[y][x].has_mine = True\n            for coord in [[-1, -1], [-1, 0], [-1, 1], [0, -1], [0, 1], [1, -1], [1, 0], [1, 1]]:\n                _x, _y = coord\n                if not self.coord_in_map(x + _x, y + _y, w, h):\n                    continue\n                matrix[y + _y][x + _x].add_nearest_mine()\n        return matrix", "response": "build a matrix of cells with mines and increments nearest mines num in adiacent cells"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_if_win(self):\n        self.flagcount = 0\n        win = True\n        for x in range(0, len(self.mine_matrix[0])):\n            for y in range(0, len(self.mine_matrix)):\n                if self.mine_matrix[y][x].state == 1:\n                    self.flagcount += 1\n                    if not self.mine_matrix[y][x].has_mine:\n                        win = False\n                elif self.mine_matrix[y][x].has_mine:\n                    win = False\n        self.lblMineCount.set_text(\"%s\" % self.minecount)\n        self.lblFlagCount.set_text(\"%s\" % self.flagcount)\n        if win:\n            self.dialog = gui.GenericDialog(title='You Win!', message='Game done in %s seconds' % self.time_count)\n            self.dialog.confirm_dialog.do(self.new_game)\n            self.dialog.cancel_dialog.do(self.new_game)\n            self.dialog.show(self)", "response": "Here are counted the flags. Is checked if the user win."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a cookie on the page.", "response": "def set_cookie(self, key, value, expiration='Infinity', path='/', domain='', secure=False):\n        \"\"\"\n        expiration (int): seconds after with the cookie automatically gets deleted\n        \"\"\"\n\n        secure = 'true' if secure else 'false'\n        self.app_instance.execute_javascript(\"\"\"\n            var sKey = \"%(sKey)s\";\n            var sValue = \"%(sValue)s\";\n            var vEnd = eval(\"%(vEnd)s\");\n            var sPath = \"%(sPath)s\"; \n            var sDomain = \"%(sDomain)s\"; \n            var bSecure = %(bSecure)s;\n            if( (!sKey || /^(?:expires|max\\-age|path|domain|secure)$/i.test(sKey)) == false ){\n                var sExpires = \"\";\n                if (vEnd) {\n                    switch (vEnd.constructor) {\n                        case Number:\n                            sExpires = vEnd === Infinity ? \"; expires=Fri, 31 Dec 9999 23:59:59 GMT\" : \"; max-age=\" + vEnd;\n                        break;\n                        case String:\n                            sExpires = \"; expires=\" + vEnd;\n                        break;\n                        case Date:\n                            sExpires = \"; expires=\" + vEnd.toUTCString();\n                        break;\n                    }\n                }\n                document.cookie = encodeURIComponent(sKey) + \"=\" + encodeURIComponent(sValue) + sExpires + (sDomain ? \"; domain=\" + sDomain : \"\") + (sPath ? \"; path=\" + sPath : \"\") + (bSecure ? \"; secure\" : \"\");\n            }\n            \"\"\"%{'sKey': key, 'sValue': value, 'vEnd': expiration, 'sPath': path, 'sDomain': domain, 'bSecure': secure})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef renew_session(self):\n        if ((not 'user_uid' in self.cookieInterface.cookies) or self.cookieInterface.cookies['user_uid']!=self.session_uid) and (not self.expired):\n            self.on_session_expired()\n\n        if self.expired:\n            self.session_uid = str(random.randint(1,999999999))\n        \n        self.cookieInterface.set_cookie('user_uid', self.session_uid, str(self.session_timeout_seconds))\n\n        #here we renew the internal timeout timer\n        if self.timeout_timer:\n            self.timeout_timer.cancel()\n        self.timeout_timer = threading.Timer(self.session_timeout_seconds, self.on_session_expired)\n        self.expired = False\n        self.timeout_timer.start()", "response": "This function is called when a user has to renew a session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decorate_event_js(js_code):\n    def add_annotation(method):\n        setattr(method, \"__is_event\", True )\n        setattr(method, \"_js_code\", js_code )\n        return method\n    return add_annotation", "response": "setup a method as an event adds also javascript code to generate\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef repr(self, changed_widgets=None):\n        if changed_widgets is None:\n            changed_widgets = {}\n        local_changed_widgets = {}\n        _innerHTML = self.innerHTML(local_changed_widgets)\n\n        if self._ischanged() or ( len(local_changed_widgets) > 0 ):\n            self._backup_repr = ''.join(('<', self.type, ' ', self._repr_attributes, '>', \n                                        _innerHTML, '</', self.type, '>'))\n            #faster but unsupported before python3.6\n            #self._backup_repr = f'<{self.type} {self._repr_attributes}>{_innerHTML}</{self.type}>'\n        if self._ischanged():\n            # if self changed, no matter about the children because will be updated the entire parent\n            # and so local_changed_widgets is not merged\n            changed_widgets[self] = self._backup_repr\n            self._set_updated()\n        else:\n            changed_widgets.update(local_changed_widgets)\n        return self._backup_repr", "response": "This function returns the textual representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_child(self, key, value):\n        if type(value) in (list, tuple, dict):\n            if type(value)==dict:\n                for k in value.keys():\n                    self.add_child(k, value[k])\n                return\n            i = 0\n            for child in value:\n                self.add_child(key[i], child)\n                i = i + 1\n            return\n\n        if hasattr(value, 'attributes'):\n            value.attributes['data-parent-widget'] = self.identifier\n            value._parent = self\n\n        if key in self.children:\n            self._render_children_list.remove(key)\n        self._render_children_list.append(key)\n\n        self.children[key] = value", "response": "Adds a child to the Tag. children dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all children from the widget", "response": "def empty(self):\n        \"\"\"remove all children from the widget\"\"\"\n        for k in list(self.children.keys()):\n            self.remove_child(self.children[k])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_child(self, child):\n        if child in self.children.values() and hasattr(child, 'identifier'):\n            for k in self.children.keys():\n                if hasattr(self.children[k], 'identifier'):\n                    if self.children[k].identifier == child.identifier:\n                        if k in self._render_children_list:\n                            self._render_children_list.remove(k)\n                        self.children.pop(k)\n                        # when the child is removed we stop the iteration\n                        # this implies that a child replication should not be allowed\n                        break", "response": "Removes a child instance from the Tag s children."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nallow to set style properties for the widget.", "response": "def set_style(self, style):\n        \"\"\" Allows to set style properties for the widget.\n            Args:\n                style (str or dict): The style property dictionary or json string.\n        \"\"\"\n        if style is not None:\n            try:\n                self.style.update(style)\n            except ValueError:\n                for s in style.split(';'):\n                    k, v = s.split(':', 1)\n                    self.style[k.strip()] = v.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_size(self, width, height):\n        if width is not None:\n            try:\n                width = to_pix(int(width))\n            except ValueError:\n                # now we know w has 'px or % in it'\n                pass\n            self.style['width'] = width\n\n        if height is not None:\n            try:\n                height = to_pix(int(height))\n            except ValueError:\n                # now we know w has 'px or % in it'\n                pass\n            self.style['height'] = height", "response": "Set the widget size."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef repr(self, changed_widgets=None):\n        if changed_widgets is None:\n            changed_widgets={}\n        return super(Widget, self).repr(changed_widgets)", "response": "Represents the widget as HTML format packs all the attributes children and so on."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when user types and releases a key.", "response": "def onkeyup(self, key, keycode, ctrl, shift, alt):\n        \"\"\"Called when user types and releases a key. \n        The widget should be able to receive the focus in order to emit the event.\n        Assign a 'tabindex' attribute to make it focusable.\n        \n        Args:\n            key (str): the character value\n            keycode (str): the numeric char code\n        \"\"\"\n        return (key, keycode, ctrl, shift, alt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when user types and releases a key.", "response": "def onkeydown(self, key, keycode, ctrl, shift, alt):\n        \"\"\"Called when user types and releases a key.\n        The widget should be able to receive the focus in order to emit the event.\n        Assign a 'tabindex' attribute to make it focusable.\n        \n        Args:\n            key (str): the character value\n            keycode (str): the numeric char code\n        \"\"\"\n        return (key, keycode, ctrl, shift, alt)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_icon_file(self, filename, rel=\"icon\"):\n        mimetype, encoding = mimetypes.guess_type(filename)\n        self.add_child(\"favicon\", '<link rel=\"%s\" href=\"%s\" type=\"%s\" />'%(rel, filename, mimetype))", "response": "Allows to define an icon for the App\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow to define an icon for the App", "response": "def set_icon_data(self, base64_data, mimetype=\"image/png\", rel=\"icon\"):\n        \"\"\" Allows to define an icon for the App\n        \n            Args:\n                base64_data (str): base64 encoded image data  (ie. \"data:image/x-icon;base64,AAABAAEAEBA....\")\n                mimetype (str): mimetype of the image (\"image/png\" or \"image/x-icon\"...)\n                rel (str): leave it unchanged (standard \"icon\")\n        \"\"\"\n        self.add_child(\"favicon\", '<link rel=\"%s\" href=\"%s\" type=\"%s\" />'%(rel, base64_data, mimetype))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef onerror(self, message, source, lineno, colno):\n        return (message, source, lineno, colno)", "response": "Called when an error occurs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npopulate the Table with a list of tuples of strings.", "response": "def define_grid(self, matrix):\n        \"\"\"Populates the Table with a list of tuples of strings.\n\n        Args:\n            matrix (list): list of iterables of strings (lists or something else). \n                Items in the matrix have to correspond to a key for the children.\n        \"\"\"\n        self.style['grid-template-areas'] = ''.join(\"'%s'\"%(' '.join(x)) for x in matrix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the size value for each column in the log.", "response": "def set_column_sizes(self, values):\n        \"\"\"Sets the size value for each column\n\n        Args:\n            values (iterable of int or str): values are treated as percentage.\n        \"\"\"\n        self.style['grid-template-columns'] = ' '.join(map(lambda value: (str(value) if str(value).endswith('%') else str(value) + '%') , values))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_column_gap(self, value):\n        value = str(value) + 'px'\n        value = value.replace('pxpx', 'px')\n        self.style['grid-column-gap'] = value", "response": "Sets the gap value between columns\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_row_gap(self, value):\n        value = str(value) + 'px'\n        value = value.replace('pxpx', 'px')\n        self.style['grid-row-gap'] = value", "response": "Sets the gap value between rows\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append(self, value, key=''):\n        if type(value) in (list, tuple, dict):\n            if type(value)==dict:\n                for k in value.keys():\n                    self.append(value[k], k)\n                return value.keys()\n            keys = []\n            for child in value:\n                keys.append( self.append(child) )\n            return keys\n        \n        key = str(key)\n        if not isinstance(value, Widget):\n            raise ValueError('value should be a Widget (otherwise use add_child(key,other)')\n\n        if 'left' in value.style.keys():\n            del value.style['left']\n        if 'right' in value.style.keys():\n            del value.style['right']\n\n        if not 'order' in value.style.keys():\n            value.style.update({'position':'static', 'order':'-1'})\n\n        if key.isdigit():\n            value.style['order'] = key\n\n        key = value.identifier if key == '' else key\n        self.add_child(key, value)\n\n        return key", "response": "This method allows to add child widgets to this."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects a tab identified by the contained widget", "response": "def select_by_widget(self, widget):\n        \"\"\" shows a tab identified by the contained widget \"\"\"\n        for a, li, holder in self._tabs.values():\n            if holder.children['content'] == widget:\n                self._on_tab_pressed(a, li, holder)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow a tab identified by the name", "response": "def select_by_name(self, name):\n        \"\"\" shows a tab identified by the name \"\"\"\n        for a, li, holder in self._tabs.values():\n            if a.children['text'] == name:\n                self._on_tab_pressed(a, li, holder)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the text content.", "response": "def set_value(self, text):\n        \"\"\"Sets the text content.\n\n        Args:\n            text (str): The string content that have to be appended as standard child identified by the key 'text'\n        \"\"\"\n        if self.single_line:\n            text = text.replace('\\n', '')\n        self.set_text(text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onchange(self, new_value):\n        self.disable_refresh()\n        self.set_value(new_value)\n        self.enable_refresh()\n        return (new_value, )", "response": "Called when the user changes the content of the TextInput."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a field to the dialog together with a descriptive label and a unique identifier.", "response": "def add_field_with_label(self, key, label_description, field):\n        \"\"\"\n        Adds a field to the dialog together with a descriptive label and a unique identifier.\n\n        Note: You can access to the fields content calling the function GenericDialog.get_field(key).\n\n        Args:\n            key (str): The unique identifier for the field.\n            label_description (str): The string content of the description label.\n            field (Widget): The instance of the field Widget. It can be for example a TextInput or maybe\n            a custom widget.\n        \"\"\"\n        self.inputs[key] = field\n        label = Label(label_description)\n        label.style['margin'] = '0px 5px'\n        label.style['min-width'] = '30%'\n        container = HBox()\n        container.style.update({'justify-content':'space-between', 'overflow':'auto', 'padding':'3px'})\n        container.append(label, key='lbl' + key)\n        container.append(self.inputs[key], key=key)\n        self.container.append(container, key=key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_field(self, key, field):\n        self.inputs[key] = field\n        container = HBox()\n        container.style.update({'justify-content':'space-between', 'overflow':'auto', 'padding':'3px'})\n        container.append(self.inputs[key], key=key)\n        self.container.append(container, key=key)", "response": "Adds a field to the dialog with a unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_from_list(cls, items, **kwargs):\n        obj = cls(**kwargs)\n        for item in items:\n            obj.append(ListItem(item))\n        return obj", "response": "Populates the ListView with a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append(self, value, key=''):\n        if isinstance(value, type('')) or isinstance(value, type(u'')):\n            value = ListItem(value)\n\n        keys = super(ListView, self).append(value, key=key)\n        if type(value) in (list, tuple, dict):\n            for k in keys:\n                if not self.EVENT_ONCLICK in self.children[k].attributes:\n                    self.children[k].onclick.connect(self.onselection)\n                self.children[k].attributes['selected'] = False\n        else:\n            # if an event listener is already set for the added item, it will not generate a selection event\n            if not self.EVENT_ONCLICK in value.attributes:\n                value.onclick.connect(self.onselection)\n            value.attributes['selected'] = False\n        return keys", "response": "Appends child items to the ListView."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef empty(self):\n        self._selected_item = None\n        self._selected_key = None\n        super(ListView, self).empty()", "response": "Removes all children from the list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef onselection(self, widget):\n        self._selected_key = None\n        for k in self.children:\n            if self.children[k] == widget:  # widget is the selected ListItem\n                self._selected_key = k\n                if (self._selected_item is not None) and self._selectable:\n                    self._selected_item.attributes['selected'] = False\n                self._selected_item = self.children[self._selected_key]\n                if self._selectable:\n                    self._selected_item.attributes['selected'] = True\n                break\n        return (self._selected_key,)", "response": "Called when a new item gets selected in the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nselect an item by its unique string identifier.", "response": "def select_by_key(self, key):\n        \"\"\"Selects an item by its key.\n\n        Args:\n            key (str): The unique string identifier of the item that have to be selected.\n        \"\"\"\n        self._selected_key = None\n        self._selected_item = None\n        for item in self.children.values():\n            item.attributes['selected'] = False\n\n        if key in self.children:\n            self.children[key].attributes['selected'] = True\n            self._selected_key = key\n            self._selected_item = self.children[key]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_by_value(self, value):\n        self._selected_key = None\n        self._selected_item = None\n        for k in self.children:\n            item = self.children[k]\n            item.attributes['selected'] = False\n            if value == item.get_value():\n                self._selected_key = k\n                self._selected_item = item\n                self._selected_item.attributes['selected'] = True", "response": "Selects an item by the text content of the child."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect an item by its unique string identifier.", "response": "def select_by_key(self, key):\n        \"\"\"Selects an item by its unique string identifier.\n\n        Args:\n            key (str): Unique string identifier of the DropDownItem that have to be selected.\n        \"\"\"\n        for item in self.children.values():\n            if 'selected' in item.attributes:\n                del item.attributes['selected']\n        self.children[key].attributes['selected'] = 'selected'\n        self._selected_key = key\n        self._selected_item = self.children[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_by_value(self, value):\n        self._selected_key = None\n        self._selected_item = None\n        for k in self.children:\n            item = self.children[k]\n            if item.get_text() == value:\n                item.attributes['selected'] = 'selected'\n                self._selected_key = k\n                self._selected_item = item\n            else:\n                if 'selected' in item.attributes:\n                    del item.attributes['selected']", "response": "Selects a DropDownItem by means of the contained text - availabe - item - that has to be selected."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when a new DropDownItem gets selected.", "response": "def onchange(self, value):\n        \"\"\"Called when a new DropDownItem gets selected.\n        \"\"\"\n        log.debug('combo box. selected %s' % value)\n        self.select_by_value(value)\n        return (value, )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_from_list(cls, content, fill_title=True, **kwargs):\n        obj = cls(**kwargs)\n        obj.append_from_list(content, fill_title)\n        return obj", "response": "Populates the Table with a list of tuples of strings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend rows created from the provided list of tuples of strings.", "response": "def append_from_list(self, content, fill_title=False):\n        \"\"\"\n        Appends rows created from the data contained in the provided\n        list of tuples of strings. The first tuple of the list can be\n        set as table title.\n\n        Args:\n            content (list): list of tuples of strings. Each tuple is a row.\n            fill_title (bool): if true, the first tuple in the list will\n                be set as title.\n        \"\"\"\n        row_index = 0\n        for row in content:\n            tr = TableRow()\n            column_index = 0\n            for item in row:\n                if row_index == 0 and fill_title:\n                    ti = TableTitle(item)\n                else:\n                    ti = TableItem(item)\n                tr.append(ti, str(column_index))\n                column_index = column_index + 1\n            self.append(tr, str(row_index))\n            row_index = row_index + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the TableItem instance at row column cordinates", "response": "def item_at(self, row, column):\n        \"\"\"Returns the TableItem instance at row, column cordinates\n\n        Args:\n            row (int): zero based index\n            column (int): zero based index\n        \"\"\"\n        return self.children[str(row)].children[str(column)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef item_coords(self, table_item):\n        for row_key in self.children.keys():\n            for item_key in self.children[row_key].children.keys():\n                if self.children[row_key].children[item_key] == table_item:\n                    return (int(row_key), int(item_key))\n        return None", "response": "Returns the row column coordinates of an item in the table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_row_count(self, count):\n        current_row_count = self.row_count()\n        current_column_count = self.column_count()\n        if count > current_row_count:\n            cl = TableEditableItem if self._editable else TableItem\n            for i in range(current_row_count, count):\n                tr = TableRow()\n                for c in range(0, current_column_count):\n                    tr.append(cl(), str(c))\n                    if self._editable:\n                        tr.children[str(c)].onchange.connect(\n                            self.on_item_changed, int(i), int(c))\n                self.append(tr, str(i))\n            self._update_first_row()\n        elif count < current_row_count:\n            for i in range(count, current_row_count):\n                self.remove_child(self.children[str(i)])", "response": "Sets the table row count."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_column_count(self, count):\n        current_row_count = self.row_count()\n        current_column_count = self.column_count()\n        if count > current_column_count:\n            cl = TableEditableItem if self._editable else TableItem\n            for r_key in self.children.keys():\n                row = self.children[r_key]\n                for i in range(current_column_count, count):\n                    row.append(cl(), str(i))\n                    if self._editable:\n                        row.children[str(i)].onchange.connect(\n                            self.on_item_changed, int(r_key), int(i))\n            self._update_first_row()\n        elif count < current_column_count:\n            for row in self.children.values():\n                for i in range(count, current_column_count):\n                    row.remove_child(row.children[str(i)])\n        self._column_count = count", "response": "Sets the table column count."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when the item value has changed.", "response": "def on_item_changed(self, item, new_value, row, column):\n        \"\"\"Event for the item change.\n\n        Args:\n            emitter (TableWidget): The emitter of the event.\n            item (TableItem): The TableItem instance.\n            new_value (str): New text content.\n            row (int): row index.\n            column (int): column index.\n        \"\"\"\n        return (item, new_value, row, column)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the origin and size of the viewbox describing a virtual view area.", "response": "def set_viewbox(self, x, y, w, h):\n        \"\"\"Sets the origin and size of the viewbox, describing a virtual view area.\n\n        Args:\n            x (int): x coordinate of the viewbox origin\n            y (int): y coordinate of the viewbox origin\n            w (int): width of the viewbox\n            h (int): height of the viewbox\n        \"\"\"\n        self.attributes['viewBox'] = \"%s %s %s %s\" % (x, y, w, h)\n        self.attributes['preserveAspectRatio'] = 'none'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the shape position.", "response": "def set_position(self, x, y):\n        \"\"\"Sets the shape position.\n\n        Args:\n            x (int): the x coordinate\n            y (int): the y coordinate\n        \"\"\"\n        self.attributes['x'] = str(x)\n        self.attributes['y'] = str(y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the rectangle size.", "response": "def set_size(self, w, h):\n        \"\"\" Sets the rectangle size.\n\n        Args:\n            w (int): width of the rectangle\n            h (int): height of the rectangle\n        \"\"\"\n        self.attributes['width'] = str(w)\n        self.attributes['height'] = str(h)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a cookie to get the session value.", "response": "def parse_session_cookie(cookie_to_cook):\n    \"\"\" cookie_to_cook = http_header['cookie']\n    \"\"\"\n    #print(\"cookie_to_cook: %s\"%str(cookie_to_cook))\n    session_value = None\n    tokens = cookie_to_cook.split(\";\")\n    for tok in tokens:\n        if 'remi_session=' in tok:\n            #print(\"found session id: %s\"%str(tok))\n            try:\n                session_value = int(tok.replace('remi_session=', ''))\n            except:\n                pass\n    return session_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the parameters given from POST or websocket reqs expecting the parameters as: 11|par1 = asd|6|par2 = 1", "response": "def parse_parametrs(p):\n    \"\"\"\n    Parses the parameters given from POST or websocket reqs\n    expecting the parameters as:  \"11|par1='asd'|6|par2=1\"\n    returns a dict like {par1:'asd',par2:1}\n    \"\"\"\n    ret = {}\n    while len(p) > 1 and p.count('|') > 0:\n        s = p.split('|')\n        l = int(s[0])  # length of param field\n        if l > 0:\n            p = p[len(s[0]) + 1:]\n            field_name = p.split('|')[0].split('=')[0]\n            field_value = p[len(field_name) + 1:l]\n            p = p[l + 1:]\n            ret[field_name] = field_value\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _instance(self):\n        global clients\n        global runtimeInstances\n        \"\"\"\n        This method is used to get the Application instance previously created\n        managing on this, it is possible to switch to \"single instance for\n        multiple clients\" or \"multiple instance for multiple clients\" execution way\n        \"\"\"\n\n        self.session = 0\n        #checking previously defined session\n        if 'cookie' in self.headers:\n            self.session = parse_session_cookie(self.headers['cookie'])\n            #if not a valid session id\n            if self.session == None:\n                self.session = 0\n            if not self.session in clients.keys():\n                self.session = 0\n\n        #if no session id\n        if self.session == 0:\n            if self.server.multiple_instance:\n                self.session = int(time.time()*1000)\n            #send session to browser\n            del self.headers['cookie']\n\n        #if the client instance doesn't exist\n        if not(self.session in clients):\n            self.update_interval = self.server.update_interval\n\n            from remi import gui\n            \n            head = gui.HEAD(self.server.title)\n            # use the default css, but append a version based on its hash, to stop browser caching\n            head.add_child('internal_css', \"<link href='/res:style.css' rel='stylesheet' />\\n\")\n            \n            body = gui.BODY()\n            body.onload.connect(self.onload)\n            body.onerror.connect(self.onerror)\n            body.ononline.connect(self.ononline)\n            body.onpagehide.connect(self.onpagehide)\n            body.onpageshow.connect(self.onpageshow)\n            body.onresize.connect(self.onresize)\n            self.page = gui.HTML()\n            self.page.add_child('head', head)\n            self.page.add_child('body', body)\n\n            if not hasattr(self, 'websockets'):\n                self.websockets = []\n\n            self.update_lock = threading.RLock()\n\n            if not hasattr(self, '_need_update_flag'):\n                self._need_update_flag = False\n                self._stop_update_flag = False\n                if self.update_interval > 0:\n                    self._update_thread = threading.Thread(target=self._idle_loop)\n                    self._update_thread.setDaemon(True)\n                    self._update_thread.start()\n\n            runtimeInstances[str(id(self))] = self\n            clients[self.session] = self\n        else:\n            #restore instance attributes\n            client = clients[self.session]\n\n            self.websockets = client.websockets\n            self.page = client.page\n\n            self.update_lock = client.update_lock\n\n            self.update_interval = client.update_interval\n            self._need_update_flag = client._need_update_flag\n            if hasattr(client, '_update_thread'):\n                self._update_thread = client._update_thread\n                \n        net_interface_ip = self.headers.get('Host', \"%s:%s\"%(self.connection.getsockname()[0],self.server.server_address[1]))\n        websocket_timeout_timer_ms = str(self.server.websocket_timeout_timer_ms)\n        pending_messages_queue_length = str(self.server.pending_messages_queue_length)\n        self.page.children['head'].set_internal_js(net_interface_ip, pending_messages_queue_length, websocket_timeout_timer_ms)", "response": "This method is used to get the Application instance for the current application instance. It is used to get the Application instance for the current application instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _idle_loop(self):\n        while not self._stop_update_flag:\n            time.sleep(self.update_interval)\n            with self.update_lock:\n                try:\n                    self.idle()\n                except:\n                    self._log.error(\"exception in App.idle method\", exc_info=True)\n                if self._need_update_flag:\n                    try:\n                        self.do_gui_update()\n                    except:\n                        self._log.error('''exception during gui update. It is advisable to \n                            use App.update_lock using external threads.''', exc_info=True)", "response": "This is the main idle loop for the thread."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_GET(self):\n        # check here request header to identify the type of req, if http or ws\n        # if this is a ws req, instance a ws handler, add it to App's ws list, return\n        if \"Upgrade\" in self.headers:\n            if self.headers['Upgrade'] == 'websocket':\n                #passing arguments to websocket handler, otherwise it will lost the last message, \n                # and will be unable to handshake\n                ws = WebSocketsHandler(self.headers, self.request, self.client_address, self.server)\n                return\n\n        \"\"\"Handler for the GET requests.\"\"\"\n        do_process = False\n        if self.server.auth is None:\n            do_process = True\n        else:\n            if not ('Authorization' in self.headers) or self.headers['Authorization'] is None:\n                self._log.info(\"Authenticating\")\n                self.do_AUTHHEAD()\n                self.wfile.write(encode_text('no auth header received'))\n            elif self.headers['Authorization'] == 'Basic ' + self.server.auth.decode():\n                do_process = True\n            else:\n                self.do_AUTHHEAD()\n                self.wfile.write(encode_text(self.headers['Authorization']))\n                self.wfile.write(encode_text('not authenticated'))\n\n        if do_process:\n            path = str(unquote(self.path))\n            # noinspection PyBroadException\n            try:\n                self._instance()\n                # build the page (call main()) in user code, if not built yet\n                with self.update_lock:\n                    # build the root page once if necessary\n                    if not 'root' in self.page.children['body'].children.keys():\n                        self._log.info('built UI (path=%s)' % path)\n                        self.set_root_widget(self.main(*self.server.userdata))\n                self._process_all(path)\n            except:\n                self._log.error('error processing GET request', exc_info=True)", "response": "Handler for the GET requests."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall by the server when the App has to be terminated", "response": "def on_close(self):\n        \"\"\" Called by the server when the App have to be terminated\n        \"\"\"\n        self._stop_update_flag = True\n        for ws in self.websockets:\n            ws.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef onerror(self, emitter, message, source, lineno, colno):\n        self._log.debug(\"\"\"App.onerror event occurred in webpage: \n            \\nMESSAGE:%s\\nSOURCE:%s\\nLINENO:%s\\nCOLNO:%s\\n\"\"\"%(message, source, lineno, colno))", "response": "Called when an error occurs in the webpage."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, widget, widget_tree):\n        self.listeners_list = []\n        self.build_widget_list_from_tree(widget_tree)\n\n        self.label.set_text('Signal connections: ' + widget.attributes['editor_varname'])\n        #del self.container\n        self.container = gui.VBox(width='100%', height='90%')\n        self.container.style['justify-content'] = 'flex-start'\n        self.container.style['overflow-y'] = 'scroll'\n        self.append(self.container, 'container')\n        ##for all the events of this widget\n        #isclass instead of ismethod because event methods are replaced with ClassEventConnector\n        for (setOnEventListenerFuncname,setOnEventListenerFunc) in inspect.getmembers(widget):\n            #if the member is decorated by decorate_set_on_listener and the function is referred to this event\n            if hasattr(setOnEventListenerFunc, '_event_info'):\n                self.container.append( SignalConnection(widget, \n                    self.listeners_list, \n                    setOnEventListenerFuncname, \n                    setOnEventListenerFunc, \n                    width='100%') )", "response": "update the list of signal connections for the selected widget"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when user presses OK button.", "response": "def confirm_dialog(self, emitter):\n        \"\"\"event called pressing on OK button.\n        \"\"\"\n        #here the user input is transferred to the dict, ready to use\n        self.from_fields_to_dict()\n        return super(ProjectConfigurationDialog,self).confirm_dialog(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nallow to show the widget as root window", "response": "def show(self, baseAppInstance):\n        \"\"\"Allows to show the widget as root window\"\"\"\n        self.from_dict_to_fields(self.configDict)\n        super(ProjectConfigurationDialog, self).show(baseAppInstance)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_value(self, value):\n        v = 0\n        measure_unit = 'px'\n        try:\n            v = int(float(value.replace('px', '')))\n        except ValueError:\n            try:\n                v = int(float(value.replace('%', '')))\n                measure_unit = '%'\n            except ValueError:\n                pass\n        self.numInput.set_value(v)\n        self.dropMeasureUnit.set_value(measure_unit)", "response": "Set the value of the numInput and dropMeasureUnit attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhighlight selected row and put the result of a muti_row selection in the list \"self. selected_row_list.", "response": "def on_table_row_click(self, row, item):\n        ''' Highlight selected row(s)\n            and put the result of a muti_row selection\n            in the list \"self.selected_row_list\".\n        '''\n        if not self.multi_selection_enabled:\n            self.remove_selection()\n        if row not in self.selected_row_list:\n            self.selected_row_list.append(row)\n            row.style['outline'] = \"2px dotted blue\"\n        return (row, item)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_kwargs(docstring):\n    lines = inspect.cleandoc(docstring).split('\\n')\n    retval = []\n\n    #\n    # 1. Find the underlined 'Parameters' section\n    # 2. Once there, continue parsing parameters until we hit an empty line\n    #\n    while lines[0] != 'Parameters':\n        lines.pop(0)\n    lines.pop(0)\n    lines.pop(0)\n\n    while lines and lines[0]:\n        name, type_ = lines.pop(0).split(':', 1)\n        description = []\n        while lines and lines[0].startswith('    '):\n            description.append(lines.pop(0).strip())\n        if 'optional' in type_:\n            retval.append((name.strip(), type_.strip(), description))\n\n    return retval", "response": "Extract keyword argument documentation from a function s docstring."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreconstructs a docstring from keyword argument info.", "response": "def to_docstring(kwargs, lpad=''):\n    \"\"\"Reconstruct a docstring from keyword argument info.\n\n    Basically reverses :func:`extract_kwargs`.\n\n    Parameters\n    ----------\n    kwargs: list\n        Output from the extract_kwargs function\n    lpad: str, optional\n        Padding string (from the left).\n\n    Returns\n    -------\n    str\n        The docstring snippet documenting the keyword arguments.\n\n    Examples\n    --------\n\n    >>> kwargs = [\n    ...     ('bar', 'str, optional', ['This parameter is the bar.']),\n    ...     ('baz', 'int, optional', ['This parameter is the baz.']),\n    ... ]\n    >>> print(to_docstring(kwargs), end='')\n    bar: str, optional\n        This parameter is the bar.\n    baz: int, optional\n        This parameter is the baz.\n\n    \"\"\"\n    buf = io.StringIO()\n    for name, type_, description in kwargs:\n        buf.write('%s%s: %s\\n' % (lpad, name, type_))\n        for line in description:\n            buf.write('%s    %s\\n' % (lpad, line))\n    return buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_examples_from_readme_rst(indent='    '):\n    curr_dir = os.path.dirname(os.path.abspath(__file__))\n    readme_path = os.path.join(curr_dir, '..', 'README.rst')\n    try:\n        with open(readme_path) as fin:\n            lines = list(fin)\n        start = lines.index('.. _doctools_before_examples:\\n')\n        end = lines.index(\".. _doctools_after_examples:\\n\")\n        lines = lines[start+4:end-2]\n        return ''.join([indent + re.sub('^  ', '', l) for l in lines])\n    except Exception:\n        return indent + 'See README.rst'", "response": "Extract examples from this project s README. rst file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open(\n        bucket_id,\n        key_id,\n        mode,\n        buffer_size=DEFAULT_BUFFER_SIZE,\n        min_part_size=DEFAULT_MIN_PART_SIZE,\n        session=None,\n        resource_kwargs=None,\n        multipart_upload_kwargs=None,\n        ):\n    \"\"\"Open an S3 object for reading or writing.\n\n    Parameters\n    ----------\n    bucket_id: str\n        The name of the bucket this object resides in.\n    key_id: str\n        The name of the key within the bucket.\n    mode: str\n        The mode for opening the object.  Must be either \"rb\" or \"wb\".\n    buffer_size: int, optional\n        The buffer size to use when performing I/O.\n    min_part_size: int, optional\n        The minimum part size for multipart uploads.  For writing only.\n    session: object, optional\n        The S3 session to use when working with boto3.\n    resource_kwargs: dict, optional\n        Keyword arguments to use when accessing the S3 resource for reading or writing.\n    multipart_upload_kwargs: dict, optional\n        Additional parameters to pass to boto3's initiate_multipart_upload function.\n        For writing only.\n\n    \"\"\"\n    logger.debug('%r', locals())\n    if mode not in MODES:\n        raise NotImplementedError('bad mode: %r expected one of %r' % (mode, MODES))\n\n    if resource_kwargs is None:\n        resource_kwargs = {}\n    if multipart_upload_kwargs is None:\n        multipart_upload_kwargs = {}\n\n    if mode == READ_BINARY:\n        fileobj = SeekableBufferedInputBase(\n            bucket_id,\n            key_id,\n            buffer_size=buffer_size,\n            session=session,\n            resource_kwargs=resource_kwargs,\n        )\n    elif mode == WRITE_BINARY:\n        fileobj = BufferedOutputBase(\n            bucket_id,\n            key_id,\n            min_part_size=min_part_size,\n            session=session,\n            multipart_upload_kwargs=multipart_upload_kwargs,\n            resource_kwargs=resource_kwargs,\n        )\n    else:\n        assert False, 'unexpected mode: %r' % mode\n\n    return fileobj", "response": "Open an object in a bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_bucket(bucket_name, prefix='', accept_key=None,\n                key_limit=None, workers=16, retries=3):\n    \"\"\"\n    Iterate and download all S3 objects under `s3://bucket_name/prefix`.\n\n    Parameters\n    ----------\n    bucket_name: str\n        The name of the bucket.\n    prefix: str, optional\n        Limits the iteration to keys starting wit the prefix.\n    accept_key: callable, optional\n        This is a function that accepts a key name (unicode string) and\n        returns True/False, signalling whether the given key should be downloaded.\n        The default behavior is to accept all keys.\n    key_limit: int, optional\n        If specified, the iterator will stop after yielding this many results.\n    workers: int, optional\n        The number of subprocesses to use.\n    retries: int, optional\n        The number of time to retry a failed download.\n\n    Yields\n    ------\n    str\n        The full key name (does not include the bucket name).\n    bytes\n        The full contents of the key.\n\n    Notes\n    -----\n    The keys are processed in parallel, using `workers` processes (default: 16),\n    to speed up downloads greatly. If multiprocessing is not available, thus\n    _MULTIPROCESSING is False, this parameter will be ignored.\n\n    Examples\n    --------\n\n      >>> # get all JSON files under \"mybucket/foo/\"\n      >>> for key, content in iter_bucket(bucket_name, prefix='foo/', accept_key=lambda key: key.endswith('.json')):\n      ...     print key, len(content)\n\n      >>> # limit to 10k files, using 32 parallel workers (default is 16)\n      >>> for key, content in iter_bucket(bucket_name, key_limit=10000, workers=32):\n      ...     print key, len(content)\n    \"\"\"\n    if accept_key is None:\n        accept_key = lambda key: True\n\n    #\n    # If people insist on giving us bucket instances, silently extract the name\n    # before moving on.  Works for boto3 as well as boto.\n    #\n    try:\n        bucket_name = bucket_name.name\n    except AttributeError:\n        pass\n\n    total_size, key_no = 0, -1\n    key_iterator = _list_bucket(bucket_name, prefix=prefix, accept_key=accept_key)\n    download_key = functools.partial(_download_key, bucket_name=bucket_name, retries=retries)\n\n    with _create_process_pool(processes=workers) as pool:\n        result_iterator = pool.imap_unordered(download_key, key_iterator)\n        for key_no, (key, content) in enumerate(result_iterator):\n            if True or key_no % 1000 == 0:\n                logger.info(\n                    \"yielding key #%i: %s, size %i (total %.1fMB)\",\n                    key_no, key, len(content), total_size / 1024.0 ** 2\n                )\n            yield key, content\n            total_size += len(content)\n\n            if key_limit is not None and key_no + 1 >= key_limit:\n                # we were asked to output only a limited number of keys => we're done\n                break\n    logger.info(\"processed %i keys, total size %i\" % (key_no + 1, total_size))", "response": "Iterate and download all S3 objects under a given bucket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nseek to the specified position in the S3 key.", "response": "def seek(self, position):\n        \"\"\"Seek to the specified position (byte offset) in the S3 key.\n\n        :param int position: The byte offset from the beginning of the key.\n        \"\"\"\n        self._position = position\n        range_string = make_range_string(self._position)\n        logger.debug('content_length: %r range_string: %r', self._content_length, range_string)\n\n        #\n        # Close old body explicitly.\n        # When first seek(), self._body is not exist. Catch the exception and do nothing.\n        #\n        try:\n            self._body.close()\n        except AttributeError:\n            pass\n\n        if position == self._content_length == 0 or position == self._content_length:\n            #\n            # When reading, we can't seek to the first byte of an empty file.\n            # Similarly, we can't seek past the last byte.  Do nothing here.\n            #\n            self._body = io.BytesIO()\n        else:\n            self._body = self._object.get(Range=range_string)['Body']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, size=-1):\n        if size == 0:\n            return b''\n        elif size < 0:\n            from_buf = self._read_from_buffer()\n            self._current_pos = self._content_length\n            return from_buf + self._raw_reader.read()\n\n        #\n        # Return unused data first\n        #\n        if len(self._buffer) >= size:\n            return self._read_from_buffer(size)\n\n        #\n        # If the stream is finished, return what we have.\n        #\n        if self._eof:\n            return self._read_from_buffer()\n\n        #\n        # Fill our buffer to the required size.\n        #\n        # logger.debug('filling %r byte-long buffer up to %r bytes', len(self._buffer), size)\n        self._fill_buffer(size)\n        return self._read_from_buffer(size)", "response": "Read up to size bytes from the object and return them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readinto(self, b):\n        data = self.read(len(b))\n        if not data:\n            return 0\n        b[:len(data)] = data\n        return len(data)", "response": "Read up to len ( b ) bytes into b and return the number of bytes read."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readline(self, limit=-1):\n        if limit != -1:\n            raise NotImplementedError('limits other than -1 not implemented yet')\n        the_line = io.BytesIO()\n        while not (self._eof and len(self._buffer) == 0):\n            #\n            # In the worst case, we're reading the unread part of self._buffer\n            # twice here, once in the if condition and once when calling index.\n            #\n            # This is sub-optimal, but better than the alternative: wrapping\n            # .index in a try..except, because that is slower.\n            #\n            remaining_buffer = self._buffer.peek()\n            if self._line_terminator in remaining_buffer:\n                next_newline = remaining_buffer.index(self._line_terminator)\n                the_line.write(self._read_from_buffer(next_newline + 1))\n                break\n            else:\n                the_line.write(self._read_from_buffer())\n                self._fill_buffer()\n        return the_line.getvalue()", "response": "Reads up to and including the next newline. Returns the bytes read."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_from_buffer(self, size=-1):\n        # logger.debug('reading %r bytes from %r byte-long buffer', size, len(self._buffer))\n        size = size if size >= 0 else len(self._buffer)\n        part = self._buffer.read(size)\n        self._current_pos += len(part)\n        # logger.debug('part: %r', part)\n        return part", "response": "Read at most size bytes from our buffer and return them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nseeking to the specified offset.", "response": "def seek(self, offset, whence=START):\n        \"\"\"Seek to the specified position.\n\n        :param int offset: The offset in bytes.\n        :param int whence: Where the offset is from.\n\n        Returns the position after seeking.\"\"\"\n        logger.debug('seeking to offset: %r whence: %r', offset, whence)\n        if whence not in WHENCE_CHOICES:\n            raise ValueError('invalid whence, expected one of %r' % WHENCE_CHOICES)\n\n        if whence == START:\n            new_position = offset\n        elif whence == CURRENT:\n            new_position = self._current_pos + offset\n        else:\n            new_position = self._content_length + offset\n        new_position = clamp(new_position, 0, self._content_length)\n        self._current_pos = new_position\n        self._raw_reader.seek(new_position)\n        logger.debug('new_position: %r', self._current_pos)\n\n        self._buffer.empty()\n        self._eof = self._current_pos == self._content_length\n        return self._current_pos"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, b):\n\n        if not isinstance(b, _BINARY_TYPES):\n            raise TypeError(\n                \"input must be one of %r, got: %r\" % (_BINARY_TYPES, type(b)))\n\n        self._buf.write(b)\n        self._total_bytes += len(b)\n\n        if self._buf.tell() >= self._min_part_size:\n            self._upload_next_part()\n\n        return len(b)", "response": "Writes the given bytes to the S3 file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening a new resource in a given mode.", "response": "def open(uri, mode, min_part_size=WEBHDFS_MIN_PART_SIZE):\n    \"\"\"\n    Parameters\n    ----------\n    min_part_size: int, optional\n        For writing only.\n\n    \"\"\"\n    if mode == 'rb':\n        return BufferedInputBase(uri)\n    elif mode == 'wb':\n        return BufferedOutputBase(uri, min_part_size=min_part_size)\n    else:\n        raise NotImplementedError('webhdfs support for mode %r not implemented' % mode)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, b):\n        if self._closed:\n            raise ValueError(\"I/O operation on closed file\")\n\n        if not isinstance(b, six.binary_type):\n            raise TypeError(\"input must be a binary string\")\n\n        self.lines.append(b)\n        self.chunk_bytes += len(b)\n        self.total_size += len(b)\n\n        if self.chunk_bytes >= self.min_part_size:\n            buff = b\"\".join(self.lines)\n            logger.info(\n                \"uploading part #%i, %i bytes (total %.3fGB)\",\n                self.parts, len(buff), self.total_size / 1024.0 ** 3\n            )\n            self._upload(buff)\n            logger.debug(\"upload of part #%i finished\", self.parts)\n            self.parts += 1\n            self.lines, self.chunk_bytes = [], 0", "response": "Write the given bytes into the WebHDFS file from constructor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open(path, mode='r', host=None, user=None, port=DEFAULT_PORT):\n    if not host:\n        raise ValueError('you must specify the host to connect to')\n    if not user:\n        user = getpass.getuser()\n    conn = _connect(host, user, port)\n    sftp_client = conn.get_transport().open_sftp_client()\n    return sftp_client.open(path, mode)", "response": "Open a file on a remote machine over SSH."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(uri, mode, kerberos=False, user=None, password=None):\n    if mode == 'rb':\n        return BufferedInputBase(uri, mode, kerberos=kerberos, user=user, password=password)\n    else:\n        raise NotImplementedError('http support for mode %r not implemented' % mode)", "response": "Implement streamed reader from a web site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading size bytes from the response buffer and returns them as a byte string.", "response": "def read(self, size=-1):\n        \"\"\"\n        Mimics the read call to a filehandle object.\n        \"\"\"\n        logger.debug(\"reading with size: %d\", size)\n        if self.response is None:\n            return b''\n\n        if size == 0:\n            return b''\n        elif size < 0 and len(self._read_buffer) == 0:\n            retval = self.response.raw.read()\n        elif size < 0:\n            retval = self._read_buffer.read() + self.response.raw.read()\n        else:\n            while len(self._read_buffer) < size:\n                logger.debug(\"http reading more content at current_pos: %d with size: %d\", self._current_pos, size)\n                bytes_read = self._read_buffer.fill(self._read_iter)\n                if bytes_read == 0:\n                    # Oops, ran out of data early.\n                    retval = self._read_buffer.read()\n                    self._current_pos += len(retval)\n\n                    return retval\n\n            # If we got here, it means we have enough data in the buffer\n            # to return to the caller.\n            retval = self._read_buffer.read(size)\n\n        self._current_pos += len(retval)\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nseek to the specified offset.", "response": "def seek(self, offset, whence=0):\n        \"\"\"Seek to the specified position.\n\n        :param int offset: The offset in bytes.\n        :param int whence: Where the offset is from.\n\n        Returns the position after seeking.\"\"\"\n        logger.debug('seeking to offset: %r whence: %r', offset, whence)\n        if whence not in s3.WHENCE_CHOICES:\n            raise ValueError('invalid whence, expected one of %r' % s3.WHENCE_CHOICES)\n\n        if not self.seekable():\n            raise OSError\n\n        if whence == s3.START:\n            new_pos = offset\n        elif whence == s3.CURRENT:\n            new_pos = self._current_pos + offset\n        elif whence == s3.END:\n            new_pos = self.content_length + offset\n\n        new_pos = s3.clamp(new_pos, 0, self.content_length)\n\n        if self._current_pos == new_pos:\n            return self._current_pos\n\n        logger.debug(\"http seeking from current_pos: %d to new_pos: %d\", self._current_pos, new_pos)\n\n        self._current_pos = new_pos\n\n        if new_pos == self.content_length:\n            self.response = None\n            self._read_iter = None\n            self._read_buffer.empty()\n        else:\n            response = self._partial_request(new_pos)\n            if response.ok:\n                self.response = response\n                self._read_iter = self.response.iter_content(self.buffer_size)\n                self._read_buffer.empty()\n            else:\n                self.response = None\n\n        return self._current_pos"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the next size bytes from the buffer and advance the read position.", "response": "def read(self, size=-1):\n        \"\"\"Read bytes from the buffer and advance the read position. Returns\n        the bytes in a bytestring.\n\n        Parameters\n        ----------\n        size: int, optional\n            Maximum number of bytes to read. If negative or not supplied, read\n            all unread bytes in the buffer.\n\n        Returns\n        -------\n        bytes\n        \"\"\"\n        part = self.peek(size)\n        self._pos += len(part)\n        return part"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the next size bytes from the buffer without advancing the read position.", "response": "def peek(self, size=-1):\n        \"\"\"Get bytes from the buffer without advancing the read position.\n        Returns the bytes in a bytestring.\n\n        Parameters\n        ----------\n        size: int, optional\n            Maximum number of bytes to return. If negative or not supplied,\n            return all unread bytes in the buffer.\n\n        Returns\n        -------\n        bytes\n        \"\"\"\n        if size < 0 or size > len(self):\n            size = len(self)\n\n        part = self._bytes[self._pos:self._pos+size]\n        return part"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfills the buffer with bytes from source until one of these conditions are met.", "response": "def fill(self, source, size=-1):\n        \"\"\"Fill the buffer with bytes from source until one of these\n        conditions is met:\n            * size bytes have been read from source (if size >= 0);\n            * chunk_size bytes have been read from source;\n            * no more bytes can be read from source;\n        Returns the number of new bytes added to the buffer.\n        Note: all previously-read bytes in the buffer are removed.\n\n        Parameters\n        ----------\n        source: a file-like object, or iterable/list that contains bytes\n            The source of bytes to fill the buffer with. If this argument has\n            the `read` attribute, it's assumed to be a file-like object and\n            `read` is called to get the bytes; otherwise it's assumed to be an\n            iterable or list that contains bytes, and a for loop is used to get\n            the bytes.\n        size: int, optional\n            The number of bytes to try to read from source. If not supplied,\n            negative, or larger than the buffer's chunk_size, then chunk_size\n            bytes are read. Note that if source is an iterable or list, then\n            it's possible that more than size bytes will be read if iterating\n            over source produces more than one byte at a time.\n\n        Returns\n        -------\n        int, the number of new bytes added to the buffer.\n        \"\"\"\n        size = size if size >= 0 else self._chunk_size\n        size = min(size, self._chunk_size)\n\n        if self._pos != 0:\n            self._bytes = self._bytes[self._pos:]\n            self._pos = 0\n\n        if hasattr(source, 'read'):\n            new_bytes = source.read(size)\n        else:\n            new_bytes = b''\n            for more_bytes in source:\n                new_bytes += more_bytes\n                if len(new_bytes) >= size:\n                    break\n\n        self._bytes += new_bytes\n        return len(new_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_compressor(ext, callback):\n    if not (ext and ext[0] == '.'):\n        raise ValueError('ext must be a string starting with ., not %r' % ext)\n    if ext in _COMPRESSOR_REGISTRY:\n        logger.warning('overriding existing compression handler for %r', ext)\n    _COMPRESSOR_REGISTRY[ext] = callback", "response": "Register a callback for transparently decompressing files with a specific extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks which keyword arguments the callable supports.", "response": "def _check_kwargs(kallable, kwargs):\n    \"\"\"Check which keyword arguments the callable supports.\n\n    Parameters\n    ----------\n    kallable: callable\n        A function or method to test\n    kwargs: dict\n        The keyword arguments to check.  If the callable doesn't support any\n        of these, a warning message will get printed.\n\n    Returns\n    -------\n    dict\n        A dictionary of argument names and values supported by the callable.\n    \"\"\"\n    supported_keywords = sorted(_inspect_kwargs(kallable))\n    unsupported_keywords = [k for k in sorted(kwargs) if k not in supported_keywords]\n    supported_kwargs = {k: v for (k, v) in kwargs.items() if k in supported_keywords}\n\n    if unsupported_keywords:\n        logger.warning('ignoring unsupported keyword arguments: %r', unsupported_keywords)\n\n    return supported_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smart_open(uri, mode=\"rb\", **kw):\n    logger.warning('this function is deprecated, use smart_open.open instead')\n\n    #\n    # The new function uses a shorter name for this parameter, handle it separately.\n    #\n    ignore_extension = kw.pop('ignore_extension', False)\n\n    expected_kwargs = _inspect_kwargs(open)\n    scrubbed_kwargs = {}\n    transport_params = {}\n\n    #\n    # Handle renamed keyword arguments.  This is required to maintain backward\n    # compatibility.  See test_smart_open_old.py for tests.\n    #\n    if 'host' in kw or 's3_upload' in kw:\n        transport_params['multipart_upload_kwargs'] = {}\n        transport_params['resource_kwargs'] = {}\n\n    if 'host' in kw:\n        url = kw.pop('host')\n        if not url.startswith('http'):\n            url = 'http://' + url\n        transport_params['resource_kwargs'].update(endpoint_url=url)\n\n    if 's3_upload' in kw and kw['s3_upload']:\n        transport_params['multipart_upload_kwargs'].update(**kw.pop('s3_upload'))\n\n    #\n    # Providing the entire Session object as opposed to just the profile name\n    # is more flexible and powerful, and thus preferable in the case of\n    # conflict.\n    #\n    if 'profile_name' in kw and 's3_session' in kw:\n        logger.error('profile_name and s3_session are mutually exclusive, ignoring the former')\n\n    if 'profile_name' in kw:\n        transport_params['session'] = boto3.Session(profile_name=kw.pop('profile_name'))\n\n    if 's3_session' in kw:\n        transport_params['session'] = kw.pop('s3_session')\n\n    for key, value in kw.items():\n        if key in expected_kwargs:\n            scrubbed_kwargs[key] = value\n        else:\n            #\n            # Assume that anything not explicitly supported by the new function\n            # is a transport layer keyword argument.  This is safe, because if\n            # the argument ends up being unsupported in the transport layer,\n            # it will only cause a logging warning, not a crash.\n            #\n            transport_params[key] = value\n\n    return open(uri, mode, ignore_ext=ignore_extension, transport_params=transport_params, **scrubbed_kwargs)", "response": "Smart open a resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _shortcut_open(\n        uri,\n        mode,\n        ignore_ext=False,\n        buffering=-1,\n        encoding=None,\n        errors=None,\n        ):\n    \"\"\"Try to open the URI using the standard library io.open function.\n\n    This can be much faster than the alternative of opening in binary mode and\n    then decoding.\n\n    This is only possible under the following conditions:\n\n        1. Opening a local file\n        2. Ignore extension is set to True\n\n    If it is not possible to use the built-in open for the specified URI, returns None.\n\n    :param str uri: A string indicating what to open.\n    :param str mode: The mode to pass to the open function.\n    :param dict kw:\n    :returns: The opened file\n    :rtype: file\n    \"\"\"\n    if not isinstance(uri, six.string_types):\n        return None\n\n    parsed_uri = _parse_uri(uri)\n    if parsed_uri.scheme != 'file':\n        return None\n\n    _, extension = P.splitext(parsed_uri.uri_path)\n    if extension in _COMPRESSOR_REGISTRY and not ignore_ext:\n        return None\n\n    open_kwargs = {}\n\n    if encoding is not None:\n        open_kwargs['encoding'] = encoding\n        mode = mode.replace('b', '')\n\n    #\n    # binary mode of the builtin/stdlib open function doesn't take an errors argument\n    #\n    if errors and 'b' not in mode:\n        open_kwargs['errors'] = errors\n\n    #\n    # Under Py3, the built-in open accepts kwargs, and it's OK to use that.\n    # Under Py2, the built-in open _doesn't_ accept kwargs, but we still use it\n    # whenever possible (see issue #207).  If we're under Py2 and have to use\n    # kwargs, then we have no option other to use io.open.\n    #\n    if six.PY3:\n        return _builtin_open(parsed_uri.uri_path, mode, buffering=buffering, **open_kwargs)\n    elif not open_kwargs:\n        return _builtin_open(parsed_uri.uri_path, mode, buffering=buffering)\n    return io.open(parsed_uri.uri_path, mode, buffering=buffering, **open_kwargs)", "response": "Try to open the specified URI using the standard library io. open function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening an arbitrary URI in the specified binary mode.", "response": "def _open_binary_stream(uri, mode, transport_params):\n    \"\"\"Open an arbitrary URI in the specified binary mode.\n\n    Not all modes are supported for all protocols.\n\n    :arg uri: The URI to open.  May be a string, or something else.\n    :arg str mode: The mode to open with.  Must be rb, wb or ab.\n    :arg transport_params: Keyword argumens for the transport layer.\n    :returns: A file object and the filename\n    :rtype: tuple\n    \"\"\"\n    if mode not in ('rb', 'rb+', 'wb', 'wb+', 'ab', 'ab+'):\n        #\n        # This should really be a ValueError, but for the sake of compatibility\n        # with older versions, which raise NotImplementedError, we do the same.\n        #\n        raise NotImplementedError('unsupported mode: %r' % mode)\n\n    if isinstance(uri, six.string_types):\n        # this method just routes the request to classes handling the specific storage\n        # schemes, depending on the URI protocol in `uri`\n        filename = uri.split('/')[-1]\n        parsed_uri = _parse_uri(uri)\n        unsupported = \"%r mode not supported for %r scheme\" % (mode, parsed_uri.scheme)\n\n        if parsed_uri.scheme == \"file\":\n            fobj = io.open(parsed_uri.uri_path, mode)\n            return fobj, filename\n        elif parsed_uri.scheme in smart_open_ssh.SCHEMES:\n            fobj = smart_open_ssh.open(\n                parsed_uri.uri_path,\n                mode,\n                host=parsed_uri.host,\n                user=parsed_uri.user,\n                port=parsed_uri.port,\n            )\n            return fobj, filename\n        elif parsed_uri.scheme in smart_open_s3.SUPPORTED_SCHEMES:\n            return _s3_open_uri(parsed_uri, mode, transport_params), filename\n        elif parsed_uri.scheme == \"hdfs\":\n            _check_kwargs(smart_open_hdfs.open, transport_params)\n            return smart_open_hdfs.open(parsed_uri.uri_path, mode), filename\n        elif parsed_uri.scheme == \"webhdfs\":\n            kw = _check_kwargs(smart_open_webhdfs.open, transport_params)\n            return smart_open_webhdfs.open(parsed_uri.uri_path, mode, **kw), filename\n        elif parsed_uri.scheme.startswith('http'):\n            #\n            # The URI may contain a query string and fragments, which interfere\n            # with our compressed/uncompressed estimation, so we strip them.\n            #\n            filename = P.basename(urlparse.urlparse(uri).path)\n            kw = _check_kwargs(smart_open_http.open, transport_params)\n            return smart_open_http.open(uri, mode, **kw), filename\n        else:\n            raise NotImplementedError(\"scheme %r is not supported\", parsed_uri.scheme)\n    elif hasattr(uri, 'read'):\n        # simply pass-through if already a file-like\n        # we need to return something as the file name, but we don't know what\n        # so we probe for uri.name (e.g., this works with open() or tempfile.NamedTemporaryFile)\n        # if the value ends with COMPRESSED_EXT, we will note it in _compression_wrapper()\n        # if there is no such an attribute, we return \"unknown\" - this effectively disables any compression\n        filename = getattr(uri, 'name', 'unknown')\n        return uri, filename\n    else:\n        raise TypeError(\"don't know how to handle uri %r\" % uri)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _my_urlsplit(url):\n    if '?' not in url:\n        return urlsplit(url, allow_fragments=False)\n\n    sr = urlsplit(url.replace('?', '\\n'), allow_fragments=False)\n    SplitResult = collections.namedtuple('SplitResult', 'scheme netloc path query fragment')\n    return SplitResult(sr.scheme, sr.netloc, sr.path.replace('\\n', '?'), '', '')", "response": "This function is a hack to prevent urlsplit from splitting around question marks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_uri(uri_as_string):\n    if os.name == 'nt':\n        # urlsplit doesn't work on Windows -- it parses the drive as the scheme...\n        if '://' not in uri_as_string:\n            # no protocol given => assume a local file\n            uri_as_string = 'file://' + uri_as_string\n\n    parsed_uri = _my_urlsplit(uri_as_string)\n\n    if parsed_uri.scheme == \"hdfs\":\n        return _parse_uri_hdfs(parsed_uri)\n    elif parsed_uri.scheme == \"webhdfs\":\n        return _parse_uri_webhdfs(parsed_uri)\n    elif parsed_uri.scheme in smart_open_s3.SUPPORTED_SCHEMES:\n        return _parse_uri_s3x(parsed_uri)\n    elif parsed_uri.scheme == 'file':\n        return _parse_uri_file(parsed_uri.netloc + parsed_uri.path)\n    elif parsed_uri.scheme in ('', None):\n        return _parse_uri_file(uri_as_string)\n    elif parsed_uri.scheme.startswith('http'):\n        return Uri(scheme=parsed_uri.scheme, uri_path=uri_as_string)\n    elif parsed_uri.scheme in smart_open_ssh.SCHEMES:\n        return _parse_uri_ssh(parsed_uri)\n    else:\n        raise NotImplementedError(\n            \"unknown URI scheme %r in %r\" % (parsed_uri.scheme, uri_as_string)\n        )", "response": "Parse the given URI from a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a Uri from a urllib namedtuple.", "response": "def _parse_uri_ssh(unt):\n    \"\"\"Parse a Uri from a urllib namedtuple.\"\"\"\n    if '@' in unt.netloc:\n        user, host_port = unt.netloc.split('@', 1)\n    else:\n        user, host_port = None, unt.netloc\n\n    if ':' in host_port:\n        host, port = host_port.split(':', 1)\n    else:\n        host, port = host_port, None\n\n    if not user:\n        user = None\n    if not port:\n        port = smart_open_ssh.DEFAULT_PORT\n    else:\n        port = int(port)\n\n    return Uri(scheme=unt.scheme, uri_path=unt.path, user=user, host=host, port=port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if we need to buffer the whole file in memory in order to proceed.", "response": "def _need_to_buffer(file_obj, mode, ext):\n    \"\"\"Returns True if we need to buffer the whole file in memory in order to proceed.\"\"\"\n    try:\n        is_seekable = file_obj.seekable()\n    except AttributeError:\n        #\n        # Under Py2, built-in file objects returned by open do not have\n        # .seekable, but have a .seek method instead.\n        #\n        is_seekable = hasattr(file_obj, 'seek')\n    return six.PY2 and mode.startswith('r') and ext in _COMPRESSOR_REGISTRY and not is_seekable"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _compression_wrapper(file_obj, filename, mode):\n    _, ext = os.path.splitext(filename)\n\n    if _need_to_buffer(file_obj, mode, ext):\n        warnings.warn('streaming gzip support unavailable, see %s' % _ISSUE_189_URL)\n        file_obj = io.BytesIO(file_obj.read())\n    if ext in _COMPRESSOR_REGISTRY and mode.endswith('+'):\n        raise ValueError('transparent (de)compression unsupported for mode %r' % mode)\n\n    try:\n        callback = _COMPRESSOR_REGISTRY[ext]\n    except KeyError:\n        return file_obj\n    else:\n        return callback(file_obj, mode)", "response": "Wrapper for the file_obj with a appropriate compressor mechanism based on the extension of the filename."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding bytes into text, if necessary. If mode specifies binary access, does nothing, unless the encoding is specified. A non-null encoding implies text mode. :arg fileobj: must quack like a filehandle object. :arg str mode: is the mode which was originally requested by the user. :arg str encoding: The text encoding to use. If mode is binary, overrides mode. :arg str errors: The method to use when handling encoding/decoding errors. :returns: a file object", "response": "def _encoding_wrapper(fileobj, mode, encoding=None, errors=None):\n    \"\"\"Decode bytes into text, if necessary.\n\n    If mode specifies binary access, does nothing, unless the encoding is\n    specified.  A non-null encoding implies text mode.\n\n    :arg fileobj: must quack like a filehandle object.\n    :arg str mode: is the mode which was originally requested by the user.\n    :arg str encoding: The text encoding to use.  If mode is binary, overrides mode.\n    :arg str errors: The method to use when handling encoding/decoding errors.\n    :returns: a file object\n    \"\"\"\n    logger.debug('encoding_wrapper: %r', locals())\n\n    #\n    # If the mode is binary, but the user specified an encoding, assume they\n    # want text.  If we don't make this assumption, ignore the encoding and\n    # return bytes, smart_open behavior will diverge from the built-in open:\n    #\n    #   open(filename, encoding='utf-8') returns a text stream in Py3\n    #   smart_open(filename, encoding='utf-8') would return a byte stream\n    #       without our assumption, because the default mode is rb.\n    #\n    if 'b' in mode and encoding is None:\n        return fileobj\n\n    if encoding is None:\n        encoding = SYSTEM_ENCODING\n\n    kw = {'errors': errors} if errors else {}\n    if mode[0] == 'r' or mode.endswith('+'):\n        fileobj = codecs.getreader(encoding)(fileobj, **kw)\n    if mode[0] in ('w', 'a') or mode.endswith('+'):\n        fileobj = codecs.getwriter(encoding)(fileobj, **kw)\n    return fileobj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default(name, value):\n    return os.environ.get('EXAMPLE_{}'.format(name.upper()), value)", "response": "get default value from environment variables with name EXAMPLE_<name > or value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_zone():\n    response = urlopen('{}/getNewZone'.format(ACRA_CONNECTOR_API_ADDRESS))\n    json_data = response.read().decode('utf-8')\n    zone_data = json.loads(json_data)\n    return zone_data['id'], b64decode(zone_data['public_key'])", "response": "make http response to AcraServer api to generate new zone and return tuple of zone id and public key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch data from database and print to console", "response": "def print_data(zone_id, connection):\n    \"\"\"fetch data from database (use zone_id if not empty/None) and print to\n    console\"\"\"\n    result = connection.execute(\n        # explicitly pass zone id before related data\n        select([cast(zone_id.encode('utf-8'), BYTEA), test_table]))\n    result = result.fetchall()\n    ZONE_ID_INDEX = 0\n    print(\"use zone_id: \", zone_id)\n    print(\"{:<3} - {} - {} - {}\".format(\"id\", 'zone', \"data\", \"raw_data\"))\n    for row in result:\n        print(\n            \"{:<3} - {} - {} - {}\\n\".format(\n            row['id'], row[ZONE_ID_INDEX].decode('utf-8'),\n            row['data'].decode('utf-8', errors='ignore'), row['raw_data']))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iqr(a):\n    a = np.asarray(a)\n    q1 = stats.scoreatpercentile(a, 25)\n    q3 = stats.scoreatpercentile(a, 75)\n    return q3 - q1", "response": "Calculate the IQR for an array of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef freedman_diaconis_bins(a):\n    # From http://stats.stackexchange.com/questions/798/\n    a = np.asarray(a)\n    h = 2 * iqr(a) / (len(a) ** (1 / 3))\n\n    # fall back to sqrt(a) bins if iqr is 0\n    if h == 0:\n        bins = np.ceil(np.sqrt(a.size))\n    else:\n        bins = np.ceil((np.nanmax(a) - np.nanmin(a)) / h)\n\n    return np.int(bins)", "response": "Calculate number of bins using Freedman - Diaconis rule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the breaks given a range of data.", "response": "def breaks_from_binwidth(x_range, binwidth=None, center=None,\n                         boundary=None):\n    \"\"\"\n    Calculate breaks given binwidth\n\n    Parameters\n    ----------\n    x_range : array_like\n        Range over with to calculate the breaks. Must be\n        of size 2.\n    binwidth : float\n        Separation between the breaks\n    center : float\n        The center of one of the bins\n    boundary : float\n        A boundary between two bins\n\n    Returns\n    -------\n    out : array_like\n        Sequence of break points.\n    \"\"\"\n    if binwidth <= 0:\n        raise PlotnineError(\"The 'binwidth' must be positive.\")\n\n    if boundary is not None and center is not None:\n        raise PlotnineError(\"Only one of 'boundary' and 'center' \"\n                            \"may be specified.\")\n    elif boundary is None:\n        if center is None:\n            # This puts min and max of data in outer half\n            # of their bins\n            boundary = binwidth/2\n        else:\n            boundary = center - binwidth/2\n\n    epsilon = np.finfo(float).eps\n    shift = np.floor((x_range[0]-boundary)/binwidth)\n    origin = boundary + shift * binwidth\n    # The (1-epsilon) factor prevents numerical roundoff in the\n    # binwidth from creating an extra break beyond the one that\n    # includes x_range[1].\n    max_x = x_range[1]+binwidth*(1-epsilon)\n    breaks = np.arange(origin, max_x, binwidth)\n    return breaks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef breaks_from_bins(x_range, bins=30, center=None, boundary=None):\n    if bins < 1:\n        raise PlotnineError(\"Need at least one bin.\")\n    elif bins == 1:\n        binwidth = x_range[1] - x_range[0]\n        boundary = x_range[1]\n    else:\n        binwidth = (x_range[1]-x_range[0])/(bins-1)\n\n    return breaks_from_binwidth(x_range, binwidth, center, boundary)", "response": "Calculate the breaks given a range of bins."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_bins(x, breaks, weight=None, pad=False, closed='right'):\n    right = closed == 'right'\n    # If weight not supplied to, use one (no weight)\n    if weight is None:\n        weight = np.ones(len(x))\n    else:\n        weight = np.asarray(weight)\n        weight[np.isnan(weight)] = 0\n\n    bin_idx = pd.cut(x, bins=breaks, labels=False,\n                     right=right, include_lowest=True)\n    bin_widths = np.diff(breaks)\n    bin_x = (breaks[:-1] + breaks[1:]) * 0.5\n\n    # Create a dataframe with two columns:\n    #   - the bins to which each x is assigned\n    #   - the weight of each x value\n    # Then create a weighted frequency table\n    df = pd.DataFrame({'bin_idx': bin_idx, 'weight': weight})\n    wftable = df.pivot_table(\n        'weight', index=['bin_idx'], aggfunc=np.sum)['weight']\n\n    # Empty bins get no value in the computed frequency table.\n    # We need to add the zeros and since frequency table is a\n    # Series object, we need to keep it ordered\n    if len(wftable) < len(bin_x):\n        empty_bins = set(range(len(bin_x))) - set(bin_idx)\n        for b in empty_bins:\n            wftable.loc[b] = 0\n        wftable = wftable.sort_index()\n    bin_count = wftable.tolist()\n\n    if pad:\n        bw0 = bin_widths[0]\n        bwn = bin_widths[-1]\n        bin_count = np.hstack([0, bin_count, 0])\n        bin_widths = np.hstack([bw0, bin_widths, bwn])\n        bin_x = np.hstack([bin_x[0]-bw0, bin_x, bin_x[-1]+bwn])\n\n    return result_dataframe(bin_count, bin_x, bin_widths)", "response": "Assign value in x to bins demacated by the break points breaks and weight."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef result_dataframe(count, x, width, xmin=None, xmax=None):\n    if xmin is None:\n        xmin = x-width/2\n\n    if xmax is None:\n        xmax = x+width/2\n\n    # Eliminate any numerical roundoff discrepancies\n    # between the edges\n    xmin[1:] = xmax[:-1]\n    density = (count/width) / np.sum(np.abs(count))\n\n    out = pd.DataFrame({\n        'count': count,\n        'x': x,\n        'xmin': xmin,\n        'xmax': xmax,\n        'width': width,\n        'density': density,\n        'ncount': count/np.max(np.abs(count)),\n        'ndensity': count/np.max(np.abs(density))})\n    return out", "response": "Create a dataframe to hold bin information for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fuzzybreaks(scale, breaks=None, boundary=None,\n                binwidth=None, bins=30, right=True):\n    \"\"\"\n    Compute fuzzy breaks\n\n    For a continuous scale, fuzzybreaks \"preserve\" the range of\n    the scale. The fuzzing is close to numerical roundoff and\n    is visually imperceptible.\n\n    Parameters\n    ----------\n    scale : scale\n        Scale\n    breaks : array_like\n        Sequence of break points. If provided and the scale is not\n        discrete, they are returned.\n    boundary : float\n        First break. If `None` a suitable on is computed using\n        the range of the scale and the binwidth.\n    binwidth : float\n        Separation between the breaks\n    bins : int\n        Number of bins\n    right : bool\n        If `True` the right edges of the bins are part of the\n        bin. If `False` then the left edges of the bins are part\n        of the bin.\n\n    Returns\n    -------\n    out : array_like\n    \"\"\"\n    # Bins for categorical data should take the width\n    # of one level, and should show up centered over\n    # their tick marks. All other parameters are ignored.\n    if isinstance(scale, scale_discrete):\n        breaks = scale.get_breaks()\n        return -0.5 + np.arange(1, len(breaks)+2)\n    else:\n        if breaks is not None:\n            breaks = scale.transform(breaks)\n\n    if breaks is not None:\n        return breaks\n\n    recompute_bins = binwidth is not None\n    srange = scale.limits\n\n    if binwidth is None or np.isnan(binwidth):\n        binwidth = (srange[1]-srange[0]) / bins\n\n    if boundary is None or np.isnan(boundary):\n        boundary = round_any(srange[0], binwidth, np.floor)\n\n    if recompute_bins:\n        bins = np.int(np.ceil((srange[1]-boundary)/binwidth))\n\n    # To minimise precision errors, we do not pass the boundary and\n    # binwidth into np.arange as params. The resulting breaks\n    # can then be adjusted with finer(epsilon based rather than\n    # some arbitrary small number) precision.\n    breaks = np.arange(boundary, srange[1]+binwidth, binwidth)\n    return _adjust_breaks(breaks, right)", "response": "Compute fuzzy breaks for a continuous scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the guides for a specific color.", "response": "def build(self, plot):\n        \"\"\"\n        Build the guides\n\n        Parameters\n        ----------\n        plot : ggplot\n            ggplot object being drawn\n\n        Returns\n        -------\n        box : matplotlib.offsetbox.Offsetbox | None\n            A box that contains all the guides for the plot.\n            If there are no guides, **None** is returned.\n        \"\"\"\n        get_property = plot.theme.themeables.property\n\n        # by default, guide boxes are vertically aligned\n        with suppress(KeyError):\n            self.box_direction = get_property('legend_box')\n        if self.box_direction is None:\n            self.box_direction = 'vertical'\n\n        with suppress(KeyError):\n            self.position = get_property('legend_position')\n\n        if self.position == 'none':\n            return\n\n        # justification of legend boxes\n        with suppress(KeyError):\n            self.box_align = get_property('legend_box_just')\n        if self.box_align is None:\n            if self.position in {'left', 'right'}:\n                tmp = 'left'\n            else:\n                tmp = 'center'\n            self.box_align = tmp\n\n        with suppress(KeyError):\n            self.box_margin = get_property('legend_box_margin')\n        if self.box_margin is None:\n            self.box_margin = 10\n\n        with suppress(KeyError):\n            self.spacing = get_property('legend_spacing')\n        if self.spacing is None:\n            self.spacing = 10\n\n        gdefs = self.train(plot)\n        if not gdefs:\n            return\n\n        gdefs = self.merge(gdefs)\n        gdefs = self.create_geoms(gdefs, plot)\n\n        if not gdefs:\n            return\n\n        gboxes = self.draw(gdefs, plot.theme)\n        bigbox = self.assemble(gboxes, gdefs, plot.theme)\n        return bigbox"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntrains the object with the required guides.", "response": "def train(self, plot):\n        \"\"\"\n        Compute all the required guides\n\n        Parameters\n        ----------\n        plot : ggplot\n            ggplot object\n\n        Returns\n        -------\n        gdefs : list\n            Guides for the plots\n        \"\"\"\n        gdefs = []\n\n        for scale in plot.scales:\n            for output in scale.aesthetics:\n                # The guide for aesthetic 'xxx' is stored\n                # in plot.guides['xxx']. The priority for\n                # the guides depends on how they are created\n                # 1. ... + guides(xxx=guide_blah())\n                # 2. ... + scale_xxx(guide=guide_blah())\n                # 3. default(either guide_legend or guide_colorbar\n                #            depending on the scale type)\n                # output = scale.aesthetics[0]\n                guide = self.get(output, scale.guide)\n\n                if guide is None or guide is False:\n                    continue\n\n                # check the validity of guide.\n                # if guide is character, then find the guide object\n                guide = self.validate(guide)\n                # check the consistency of the guide and scale.\n                if (guide.available_aes != 'any' and\n                        scale.aesthetics[0] not in guide.available_aes):\n                    raise PlotnineError(\n                        \"{} cannot be used for {}\".format(\n                            guide.__class__.__name__, scale.aesthetics))\n\n                # title\n                if is_waive(guide.title):\n                    if scale.name:\n                        guide.title = scale.name\n                    else:\n                        try:\n                            guide.title = str(plot.labels[output])\n                        except KeyError:\n                            warn(\"Cannot generate legend for the {!r} \"\n                                 \"aesthetic. Make sure you have mapped a \"\n                                 \"variable to it\".format(output),\n                                 PlotnineWarning)\n                            continue\n\n                # each guide object trains scale within the object,\n                # so Guides (i.e., the container of guides)\n                # need not to know about them\n                guide = guide.train(scale, output)\n\n                if guide is not None:\n                    gdefs.append(guide)\n\n        return gdefs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge overlapped guides into one guides.", "response": "def merge(self, gdefs):\n        \"\"\"\n        Merge overlapped guides\n\n        For example::\n\n            from plotnine import *\n            gg = ggplot(mtcars, aes(y='wt', x='mpg', colour='factor(cyl)'))\n            gg = gg + stat_smooth(aes(fill='factor(cyl)'), method='lm')\n            gg = gg + geom_point()\n            gg\n\n        This would create two guides with the same hash\n        \"\"\"\n        # group guide definitions by hash, and\n        # reduce each group to a single guide\n        # using the guide.merge method\n        df = pd.DataFrame({\n            'gdef': gdefs,\n            'hash': [g.hash for g in gdefs]})\n        grouped = df.groupby('hash', sort=False)\n        gdefs = []\n        for name, group in grouped:\n            # merge\n            gdef = group['gdef'].iloc[0]\n            for g in group['gdef'].iloc[1:]:\n                gdef = gdef.merge(g)\n            gdefs.append(gdef)\n        return gdefs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_geoms(self, gdefs, plot):\n        new_gdefs = []\n        for gdef in gdefs:\n            gdef = gdef.create_geoms(plot)\n            if gdef:\n                new_gdefs.append(gdef)\n\n        return new_gdefs", "response": "Create the geoms for the guide definitions in gdefs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw(self, gdefs, theme):\n        for g in gdefs:\n            g.theme = theme\n            g._set_defaults()\n        return [g.draw() for g in gdefs]", "response": "Draw out each guide definition"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassemble the guide boxes into a single OffsetBox object.", "response": "def assemble(self, gboxes, gdefs, theme):\n        \"\"\"\n        Put together all the guide boxes\n\n        Parameters\n        ----------\n        gboxes : list\n            List of :class:`~matplotlib.offsetbox.Offsetbox`,\n            where each item is a legend for a single aesthetic.\n        gdefs : list of guide_legend|guide_colorbar\n            guide definitions\n        theme : theme\n            Plot theme\n\n        Returns\n        -------\n        box : OffsetBox\n            A box than can be placed onto a plot\n        \"\"\"\n        # place the guides according to the guide.order\n        # 0 do not sort\n        # 1-99 sort\n        for gdef in gdefs:\n            if gdef.order == 0:\n                gdef.order = 100\n            elif not 0 <= gdef.order <= 99:\n                raise PlotnineError(\n                    \"'order' for a guide should be \"\n                    \"between 0 and 99\")\n        orders = [gdef.order for gdef in gdefs]\n        idx = np.argsort(orders)\n        gboxes = [gboxes[i] for i in idx]\n\n        # direction when more than legend\n        if self.box_direction == 'vertical':\n            packer = VPacker\n        elif self.box_direction == 'horizontal':\n            packer = HPacker\n        else:\n            raise PlotnineError(\n                \"'legend_box' should be either \"\n                \"'vertical' or 'horizontal'\")\n\n        box = packer(children=gboxes, align=self.box_align,\n                     pad=self.box_margin, sep=self.spacing)\n        return box"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_entries_to_gallery(app, doctree, docname):\n    if docname != 'gallery':\n        return\n\n    if not has_gallery(app.builder.name):\n        return\n\n    # Find gallery node\n    try:\n        node = doctree.traverse(gallery)[0]\n    except TypeError:\n        return\n\n    content = []\n    for entry in app.env.gallery_entries:\n        raw_html_node = nodes.raw('', text=entry.html, format='html')\n        content.append(raw_html_node)\n\n    # Even when content is empty, we want the gallery node replaced\n    node.replace_self(content)", "response": "Add entries to the gallery node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn html for a the entry.", "response": "def html(self):\n        \"\"\"\n        Return html for a the entry\n        \"\"\"\n        # No empty tooltips\n        if self.description:\n            tooltip = 'tooltip=\"{}\"'.format(self.description)\n        else:\n            tooltip = ''\n\n        return entry_html(\n            title=self.title,\n            thumbnail=self.thumbnail,\n            link=self.html_link,\n            tooltip=tooltip)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking thumbnail and return html path to image", "response": "def make_thumbnail(self, imgfilename_inrst):\n        \"\"\"\n        Make thumbnail and return (html) path to image\n\n        Parameters\n        ----------\n        imgfilename_rst : rst\n            Image filename (relative path), as it appears in the\n            ReST file (coverted).\n        \"\"\"\n        builddir = self.env.app.outdir\n\n        imgfilename_src = os.path.join(DOC_PATH, imgfilename_inrst)\n\n        thumbfilename = self.thumbfilename(imgfilename_inrst)\n        thumbfilename_inhtml = os.path.join('_images', thumbfilename)\n        thumbfilename_dest = os.path.join(builddir, '_images', thumbfilename)\n\n        im = Image.open(imgfilename_src)\n        im.thumbnail(thumbnail_size)\n        im.save(thumbfilename_dest)\n        return thumbfilename_inhtml"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the range and break information for the panel", "response": "def setup_panel_params(self, scale_x, scale_y):\n        \"\"\"\n        Compute the range and break information for the panel\n\n        \"\"\"\n        def train(scale, limits, trans, name):\n            \"\"\"\n            Train a single coordinate axis\n            \"\"\"\n            if limits is None:\n                rangee = scale.dimension()\n            else:\n                rangee = scale.transform(limits)\n\n            # data space\n            out = scale.break_info(rangee)\n\n            # trans'd range\n            out['range'] = np.sort(trans.transform(out['range']))\n\n            if limits is None:\n                expand = self.expand_default(scale)\n                out['range'] = expand_range_distinct(out['range'], expand)\n\n            # major and minor breaks in plot space\n            out['major'] = transform_value(trans, out['major'], out['range'])\n            out['minor'] = transform_value(trans, out['minor'], out['range'])\n\n            for key in list(out.keys()):\n                new_key = '{}_{}'.format(name, key)\n                out[new_key] = out.pop(key)\n\n            return out\n\n        out = dict(\n            scales=types.SimpleNamespace(x=scale_x, y=scale_y),\n            **train(scale_x, self.limits.xlim, self.trans.x, 'x'),\n            **train(scale_y, self.limits.xlim, self.trans.y, 'y')\n        )\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_log_scale(base, sides, scales, coord):\n        def is_log(trans):\n            return (trans.__class__.__name__.startswith('log') and\n                    hasattr(trans, 'base'))\n\n        base_x, base_y = base, base\n        x_is_log = is_log(scales.x.trans)\n        y_is_log = is_log(scales.y.trans)\n        if isinstance(coord, coord_flip):\n            x_is_log, y_is_log = y_is_log, x_is_log\n\n        if 't' in sides or 'b' in sides:\n            if base_x is None:\n                base_x = scales.x.trans.base\n\n            if not x_is_log:\n                warnings.warn(\n                    \"annotation_logticks for x-axis which does not have \"\n                    \"a log scale. The logticks may not make sense.\",\n                    PlotnineWarning)\n            elif x_is_log and base_x != scales.x.trans.base:\n                warnings.warn(\n                    \"The x-axis is log transformed in base {} ,\"\n                    \"but the annotation_logticks are computed in base {}\"\n                    \"\".format(base_x, scales.x.trans.base),\n                    PlotnineWarning)\n\n        if 'l' in sides or 'r' in sides:\n            if base_y is None:\n                base_y = scales.y.trans.base\n\n            if not y_is_log:\n                warnings.warn(\n                    \"annotation_logticks for y-axis which does not have \"\n                    \"a log scale. The logticks may not make sense.\",\n                    PlotnineWarning)\n            elif y_is_log and base_y != scales.x.trans.base:\n                warnings.warn(\n                    \"The y-axis is log transformed in base {} ,\"\n                    \"but the annotation_logticks are computed in base {}\"\n                    \"\".format(base_y, scales.x.trans.base),\n                    PlotnineWarning)\n        return base_x, base_y", "response": "Checks the log transform for the log - scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the ticks for a set of values within a range.", "response": "def _calc_ticks(value_range, base):\n        \"\"\"\n        Calculate tick marks within a range\n\n        Parameters\n        ----------\n        value_range: tuple\n            Range for which to calculate ticks.\n\n        Returns\n        -------\n        out: tuple\n            (major, middle, minor) tick locations\n        \"\"\"\n        def _minor(x, mid_idx):\n            return np.hstack([x[1:mid_idx], x[mid_idx+1:-1]])\n\n        # * Calculate the low and high powers,\n        # * Generate for all intervals in along the low-high power range\n        #   The intervals are in normal space\n        # * Calculate evenly spaced breaks in normal space, then convert\n        #   them to log space.\n        low = np.floor(value_range[0])\n        high = np.ceil(value_range[1])\n        arr = base ** np.arange(low, float(high+1))\n        n_ticks = base - 1\n        breaks = [log(np.linspace(b1, b2, n_ticks+1), base)\n                  for (b1, b2) in list(zip(arr, arr[1:]))]\n\n        # Partition the breaks in the 3 groups\n        major = np.array([x[0] for x in breaks] + [breaks[-1][-1]])\n        if n_ticks % 2:\n            mid_idx = n_ticks // 2\n            middle = [x[mid_idx] for x in breaks]\n            minor = np.hstack([_minor(x, mid_idx) for x in breaks])\n        else:\n            middle = []\n            minor = np.hstack([x[1:-1] for x in breaks])\n\n        return major, middle, minor"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the range and break information for the panel", "response": "def setup_panel_params(self, scale_x, scale_y):\n        \"\"\"\n        Compute the range and break information for the panel\n        \"\"\"\n\n        def train(scale, limits, name):\n            \"\"\"\n            Train a single coordinate axis\n            \"\"\"\n            # Which axis are we dealing with\n            name = scale.aesthetics[0]\n\n            if self.expand:\n                expand = self.expand_default(scale)\n            else:\n                expand = (0, 0, 0, 0)\n\n            if limits is None:\n                rangee = scale.dimension(expand)\n            else:\n                rangee = scale.transform(limits)\n                rangee = expand_range_distinct(rangee, expand)\n\n            out = scale.break_info(rangee)\n            # This is where\n            # x_major, x_labels, x_minor, ...\n            # range keys are created\n            for key in list(out.keys()):\n                new_key = '{}_{}'.format(name, key)\n                out[new_key] = out.pop(key)\n            return out\n\n        out = dict(\n            scales=types.SimpleNamespace(x=scale_x, y=scale_y),\n            **train(scale_x, self.limits.xlim, 'x'),\n            **train(scale_y, self.limits.ylim, 'y')\n        )\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_option(name):\n    d = globals()\n\n    if name in {'get_option', 'set_option'} or name not in d:\n        from ..exceptions import PlotnineError\n        raise PlotnineError(\"Unknown option {}\".format(name))\n\n    return d[name]", "response": "Get option from the\n    package"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_option(name, value):\n    d = globals()\n\n    if name in {'get_option', 'set_option'} or name not in d:\n        from ..exceptions import PlotnineError\n        raise PlotnineError(\"Unknown option {}\".format(name))\n\n    old = d[name]\n    d[name] = value\n    return old", "response": "Set the value of an option in the\n    package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding the limits any aesthetic using data MimeType", "response": "def expand_limits(**kwargs):\n    \"\"\"\n    Expand the limits any aesthetic using data\n\n    Parameters\n    ----------\n    kwargs : dict or dataframe\n        Data to use in expanding the limits.\n        The keys should be aesthetic names\n        e.g. *x*, *y*, *colour*, ...\n    \"\"\"\n    def as_list(key):\n        with suppress(KeyError):\n            if isinstance(kwargs[key], (int, float, str)):\n                kwargs[key] = [kwargs[key]]\n\n    if isinstance(kwargs, dict):\n        as_list('x')\n        as_list('y')\n        data = pd.DataFrame(kwargs)\n    else:\n        data = kwargs\n\n    mapping = {}\n    for ae in set(kwargs) & all_aesthetics:\n        mapping[ae] = ae\n\n    return geom_blank(mapping=mapping, data=data, inherit_aes=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_scale(self, gg):\n        # This method does some introspection to save users from\n        # scale mismatch error. This could happen when the\n        # aesthetic is mapped to a categorical but the limits\n        # are not provided in categorical form. We only handle\n        # the case where the mapping uses an expression to\n        # conver to categorical e.g `aes(color='factor(cyl)')`.\n        # However if `'cyl'` column is a categorical and the\n        # mapping is `aes(color='cyl')`, that will result in\n        # an error. If later case proves common enough then we\n        # could inspect the data and be clever based on that too!!\n        ae = self.aesthetic\n        series = self.limits_series\n        ae_values = []\n\n        # Look through all the mappings for this aesthetic,\n        # if we detect any factor stuff then we convert the\n        # limits data to categorical so that the right scale\n        # can be choosen. This should take care of the most\n        # common use cases.\n        for layer in gg.layers:\n            with suppress(KeyError):\n                value = layer.mapping[ae]\n                if isinstance(value, str):\n                    ae_values.append(value)\n\n        for value in ae_values:\n            if ('factor(' in value or\n                    'Categorical(' in value):\n                series = pd.Categorical(self.limits_series)\n                break\n        return make_scale(self.aesthetic,\n                          series,\n                          limits=self.limits,\n                          trans=self.trans)", "response": "Create a scale for the most recent aesthetic and limits."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an instantiated geom object from a stat object.", "response": "def from_stat(stat):\n        \"\"\"\n        Return an instantiated geom object\n\n        geoms should not override this method.\n\n        Parameters\n        ----------\n        stat : stat\n            `stat`\n\n        Returns\n        -------\n        out : geom\n            A geom object\n\n        Raises\n        ------\n        :class:`PlotnineError` if unable to create a `geom`.\n        \"\"\"\n        name = stat.params['geom']\n        if issubclass(type(name), geom):\n            return name\n\n        if isinstance(name, type) and issubclass(name, geom):\n            klass = name\n        elif is_string(name):\n            if not name.startswith('geom_'):\n                name = 'geom_{}'.format(name)\n            klass = Registry[name]\n        else:\n            raise PlotnineError(\n                'Unknown geom of type {}'.format(type(name)))\n\n        return klass(stat=stat, **stat._kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all the aesthetics for this geom.", "response": "def aesthetics(cls):\n        \"\"\"\n        Return all the aesthetics for this geom\n\n        geoms should not override this method.\n        \"\"\"\n        main = cls.DEFAULT_AES.keys() | cls.REQUIRED_AES\n        other = {'group'}\n        # Need to recognize both spellings\n        if 'color' in main:\n            other.add('colour')\n        if 'outlier_color' in main:\n            other.add('outlier_colour')\n        return main | other"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncombine data with defaults and set aesthetics from parameters AttributeNames geoms should not override this method.", "response": "def use_defaults(self, data):\n        \"\"\"\n        Combine data with defaults and set aesthetics from parameters\n\n        geoms should not override this method.\n\n        Parameters\n        ----------\n        data : dataframe\n            Data used for drawing the geom.\n\n        Returns\n        -------\n        out : dataframe\n            Data used for drawing the geom.\n        \"\"\"\n        missing_aes = (self.DEFAULT_AES.keys() -\n                       self.aes_params.keys() -\n                       set(data.columns))\n\n        # Not in data and not set, use default\n        for ae in missing_aes:\n            data[ae] = self.DEFAULT_AES[ae]\n\n        # If set, use it\n        for ae, value in self.aes_params.items():\n            try:\n                data[ae] = value\n            except ValueError:\n                # sniff out the special cases, like custom\n                # tupled linetypes, shapes and colors\n                if is_valid_aesthetic(value, ae):\n                    data[ae] = [value]*len(data)\n                else:\n                    msg = (\"'{}' does not look like a \"\n                           \"valid value for `{}`\")\n                    raise PlotnineError(msg.format(value, ae))\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_layer(self, data, layout, coord, **params):\n        for pid, pdata in data.groupby('PANEL'):\n            if len(pdata) == 0:\n                continue\n            ploc = pid - 1\n            panel_params = layout.panel_params[ploc]\n            ax = layout.axs[ploc]\n            self.draw_panel(pdata, panel_params, coord, ax, **params)", "response": "Draw a single layer across all panels and axes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot all the groups and labels of the cluster entries in the specified axes.", "response": "def draw_panel(self, data, panel_params, coord, ax, **params):\n        \"\"\"\n        Plot all groups\n\n        For effeciency, geoms that do not need to partition\n        different groups before plotting should override this\n        method and avoid the groupby.\n\n        Parameters\n        ----------\n        data : dataframe\n            Data to be plotted by this geom. This is the\n            dataframe created in the plot_build pipeline.\n        panel_params : dict\n            The scale information as may be required by the\n            axes. At this point, that information is about\n            ranges, ticks and labels. Keys of interest to\n            the geom are::\n\n                'x_range'  # tuple\n                'y_range'  # tuple\n\n        coord : coord\n            Coordinate (e.g. coord_cartesian) system of the\n            geom.\n        ax : axes\n            Axes on which to plot.\n        params : dict\n            Combined parameters for the geom and stat. Also\n            includes the 'zorder'.\n        \"\"\"\n        for _, gdata in data.groupby('group'):\n            gdata.reset_index(inplace=True, drop=True)\n            self.draw_group(gdata, panel_params, coord, ax, **params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the arguments passed to the geom are valid.", "response": "def _verify_arguments(self, kwargs):\n        \"\"\"\n        Verify arguments passed to the geom\n        \"\"\"\n        geom_stat_args = kwargs.keys() | self._stat._kwargs.keys()\n        unknown = (geom_stat_args -\n                   self.aesthetics() -                # geom aesthetics\n                   self.DEFAULT_PARAMS.keys() -        # geom parameters\n                   self._stat.aesthetics() -          # stat aesthetics\n                   self._stat.DEFAULT_PARAMS.keys() -  # stat parameters\n                   {'data', 'mapping',                # layer parameters\n                    'show_legend', 'inherit_aes'})    # layer parameters\n        if unknown:\n            msg = (\"Parameters {}, are not understood by \"\n                   \"either the geom, stat or layer.\")\n            raise PlotnineError(msg.format(unknown))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove rows with NaN values geoms that infer extra information from missing values should override this method. For example :class:`~plotnine.geoms.geom_path`. Parameters ---------- data : dataframe Data Returns ------- out : dataframe Data without the NaNs. Notes ----- Shows a warning if the any rows are removed and the `na_rm` parameter is False. It only takes into account the columns of the required aesthetics.", "response": "def handle_na(self, data):\n        \"\"\"\n        Remove rows with NaN values\n\n        geoms that infer extra information from missing values\n        should override this method. For example\n        :class:`~plotnine.geoms.geom_path`.\n\n        Parameters\n        ----------\n        data : dataframe\n            Data\n\n        Returns\n        -------\n        out : dataframe\n            Data without the NaNs.\n\n        Notes\n        -----\n        Shows a warning if the any rows are removed and the\n        `na_rm` parameter is False. It only takes into account\n        the columns of the required aesthetics.\n        \"\"\"\n        return remove_missing(data,\n                              self.params['na_rm'],\n                              list(self.REQUIRED_AES | self.NON_MISSING_AES),\n                              self.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets up the parameters for the stacking.", "response": "def setup_params(self, data):\n        \"\"\"\n        Verify, modify & return a copy of the params.\n        \"\"\"\n        # Variable for which to do the stacking\n        if 'ymax' in data:\n            if any((data['ymin'] != 0) & (data['ymax'] != 0)):\n                warn(\"Stacking not well defined when not \"\n                     \"anchored on the axis.\", PlotnineWarning)\n            var = 'ymax'\n        elif 'y' in data:\n            var = 'y'\n        else:\n            warn(\"Stacking requires either ymin & ymax or y \"\n                 \"aesthetics. Maybe you want position = 'identity'?\",\n                 PlotnineWarning)\n            var = None\n\n        params = self.params.copy()\n        params['var'] = var\n        params['fill'] = self.fill\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strategy(data, params):\n        vjust = params['vjust']\n\n        y = data['y'].copy()\n        y[np.isnan(y)] = 0\n        heights = np.append(0, y.cumsum())\n\n        if params['fill']:\n            heights = heights / np.abs(heights[-1])\n\n        data['ymin'] = np.min([heights[:-1], heights[1:]], axis=0)\n        data['ymax'] = np.max([heights[:-1], heights[1:]], axis=0)\n        # less intuitive than (ymin + vjust(ymax-ymin)), but\n        # this way avoids subtracting numbers of potentially\n        # similar precision\n        data['y'] = ((1-vjust)*data['ymin'] + vjust*data['ymax'])\n        return data", "response": "Stack overlapping intervals.\n\n        Assumes that each set has the same horizontal position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef densitybin(x, weight=None, binwidth=None, bins=None, rangee=None):\n    if all(pd.isnull(x)):\n        return pd.DataFrame()\n\n    if weight is None:\n        weight = np.ones(len(x))\n    weight = np.asarray(weight)\n    weight[np.isnan(weight)] = 0\n\n    if rangee is None:\n        rangee = np.min(x), np.max(x)\n    if bins is None:\n        bins = 30\n    if binwidth is None:\n        binwidth = np.ptp(rangee) / bins\n\n    # Sort weight and x, by x\n    order = np.argsort(x)\n    weight = weight[order]\n    x = x[order]\n\n    cbin = 0                # Current bin ID\n    binn = [None] * len(x)  # The bin ID for each observation\n    # End position of current bin (scan left to right)\n    binend = -np.inf\n\n    # Scan list and put dots in bins\n    for i, value in enumerate(x):\n        # If past end of bin, start a new bin at this point\n        if value >= binend:\n            binend = value + binwidth\n            cbin = cbin + 1\n        binn[i] = cbin\n\n    def func(series):\n        return (series.min()+series.max())/2\n\n    results = pd.DataFrame({'x': x,\n                            'bin': binn,\n                            'binwidth': binwidth,\n                            'weight': weight})\n    # This is a plyr::ddply\n    results['bincenter'] = results.groupby('bin')['x'].transform(func)\n    return results", "response": "Do density binning of a set of events."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the default theme", "response": "def theme_get():\n    \"\"\"\n    Return the default theme\n\n    The default theme is the one set (using :func:`theme_set`) by\n    the user. If none has been set, then :class:`theme_gray` is\n    the default.\n    \"\"\"\n    from .theme_gray import theme_gray\n    _theme = get_option('current_theme')\n    if isinstance(_theme, type):\n        _theme = _theme()\n    return _theme or theme_gray()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchanges the current theme", "response": "def theme_set(new):\n    \"\"\"\n    Change the current(default) theme\n\n    Parameters\n    ----------\n    new : theme\n        New default theme\n\n    Returns\n    -------\n    out : theme\n        Previous theme\n    \"\"\"\n    if (not isinstance(new, theme) and\n            not issubclass(new, theme)):\n        raise PlotnineError(\"Expecting object to be a theme\")\n\n    out = get_option('current_theme')\n    set_option('current_theme', new)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply this theme then apply additional modifications in order.", "response": "def apply(self, ax):\n        \"\"\"\n        Apply this theme, then apply additional modifications in order.\n\n        Subclasses that override this method should make sure that\n        the base class method is called.\n        \"\"\"\n        for th in self.themeables.values():\n            th.apply(ax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes any desired changes to the figure object", "response": "def setup_figure(self, figure):\n        \"\"\"\n        Makes any desired changes to the figure object\n\n        This method will be called once with a figure object\n        before any plotting has completed. Subclasses that\n        override this method should make sure that the base\n        class method is called.\n        \"\"\"\n        for th in self.themeables.values():\n            th.setup_figure(figure)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply any desired changes to the figure object.", "response": "def apply_figure(self, figure):\n        \"\"\"\n        Makes any desired changes to the figure object\n\n        This method will be called once with a figure object\n        after plot has completed. Subclasses that override this\n        method should make sure that the base class method is\n        called.\n        \"\"\"\n        for th in self.themeables.values():\n            th.apply_figure(figure)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_rcparams(self):\n        from matplotlib import rcParams\n        for key, val in self.rcParams.items():\n            try:\n                rcParams[key] = val\n            except Exception as e:\n                msg = (\"\"\"Setting \"mpl.rcParams['{}']={}\" \"\"\"\n                       \"raised an Exception: {}\")\n                raise PlotnineError(msg.format(key, val, e))", "response": "Set the rcParams to the values of the rcParams object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn rcParams dict for this theme.", "response": "def rcParams(self):\n        \"\"\"\n        Return rcParams dict for this theme.\n\n        Notes\n        -----\n        Subclasses should not need to override this method method as long as\n        self._rcParams is constructed properly.\n\n        rcParams are used during plotting. Sometimes the same theme can be\n        achieved by setting rcParams before plotting or a apply\n        after plotting. The choice of how to implement it is is a matter of\n        convenience in that case.\n\n        There are certain things can only be themed after plotting. There\n        may not be an rcParam to control the theme or the act of plotting\n        may cause an entity to come into existence before it can be themed.\n\n        \"\"\"\n\n        try:\n            rcParams = deepcopy(self._rcParams)\n        except NotImplementedError:\n            # deepcopy raises an error for objects that are drived from or\n            # composed of matplotlib.transform.TransformNode.\n            # Not desirable, but probably requires upstream fix.\n            # In particular, XKCD uses matplotlib.patheffects.withStrok\n            rcParams = copy(self._rcParams)\n\n        for th in self.themeables.values():\n            rcParams.update(th.rcParams)\n        return rcParams"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds themes together. Subclasses should not override this method. This will be called when adding two instances of class 'theme' together. A complete theme will annihilate any previous themes. Partial themes can be added together and can be added to a complete theme.", "response": "def add_theme(self, other, inplace=False):\n        \"\"\"Add themes together.\n\n        Subclasses should not override this method.\n\n        This will be called when adding two instances of class 'theme'\n        together.\n        A complete theme will annihilate any previous themes. Partial themes\n        can be added together and can be added to a complete theme.\n        \"\"\"\n        if other.complete:\n            return other\n\n        theme_copy = self if inplace else deepcopy(self)\n        theme_copy.themeables.update(deepcopy(other.themeables))\n        return theme_copy"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw the plots for the specified set of plots.", "response": "def _draw_plots(self, plots):\n        \"\"\"\n        Plot and return the figure and artists\n\n        Parameters\n        ----------\n        plots : iterable\n            ggplot objects that make up the the frames of the animation\n\n        Returns\n        -------\n        figure : matplotlib.figure.Figure\n            Matplotlib figure\n        artists : list\n            List of :class:`Matplotlib.artist.artist`\n        \"\"\"\n        # For keeping track of artists for each frame\n        artist_offsets = {\n            'collections': [],\n            'patches': [],\n            'lines': [],\n            'texts': [],\n            'artists': []\n        }\n\n        scale_limits = dict()\n\n        def initialise_artist_offsets(n):\n            \"\"\"\n            Initilise artists_offsets arrays to zero\n\n            Parameters\n            ----------\n            n : int\n                Number of axes to initialise artists for.\n                The artists for each axes are tracked separately.\n            \"\"\"\n            for artist_type in artist_offsets:\n                artist_offsets[artist_type] = [0] * n\n\n        def get_frame_artists(plot):\n            \"\"\"\n            Parameters\n            ----------\n            plot : ggplot\n                Drawn ggplot object from which to extract\n                artists.\n            \"\"\"\n            # The axes accumulate artists for all frames\n            # For each frame we pickup the newly added artists\n            # We use offsets to mark the end of the previous frame\n            # e.g ax.collections[start:]\n            frame_artists = []\n            for i, ax in enumerate(plot.axs):\n                for name in artist_offsets:\n                    start = artist_offsets[name][i]\n                    new_artists = getattr(ax, name)[start:]\n                    frame_artists.extend(new_artists)\n                    artist_offsets[name][i] += len(new_artists)\n            return frame_artists\n\n        def set_scale_limits(plot):\n            \"\"\"\n            Set limits of all the scales in the animation\n\n            Should be called before :func:`check_scale_limits`.\n\n            Parameters\n            ----------\n            plot : ggplot\n                First ggplot object that has been drawn\n            \"\"\"\n            for sc in plot.scales:\n                ae = sc.aesthetics[0]\n                scale_limits[ae] = sc.limits\n\n        def check_scale_limits(plot, frame_no):\n            \"\"\"\n            Check limits of the scales of a plot in the animation\n\n            Raises a PlotnineError if any of the scales has limits\n            that do not match those of the first plot/frame.\n\n            Should be called after :func:`set_scale_limits`.\n\n            Parameters\n            ----------\n            plot : ggplot\n                ggplot object that has been drawn\n\n            frame_no : int\n                Frame number\n            \"\"\"\n            if len(scale_limits) != len(plot.scales):\n                raise PlotnineError(\n                    \"All plots must have the same number of scales \"\n                    \"as the first plot of the animation.\"\n                )\n\n            for sc in plot.scales:\n                ae = sc.aesthetics[0]\n                if ae not in scale_limits:\n                    raise PlotnineError(\n                        \"The plot for frame {} does not have a scale \"\n                        \"for the {} aesthetic.\".format(frame_no, ae)\n                    )\n                if sc.limits != scale_limits[ae]:\n                    raise PlotnineError(\n                        \"The {} scale of plot for frame {} has different \"\n                        \"limits from those of the first frame.\"\n                        \"\".format(ae, frame_no)\n                    )\n\n        figure = None\n        axs = None\n        artists = []\n\n        # The first ggplot creates the figure, axes and the initial\n        # frame of the animation. The rest of the ggplots draw\n        # onto the figure and axes created by the first ggplot and\n        # they create the subsequent frames.\n        for frame_no, p in enumerate(plots):\n            if figure is None:\n                figure, plot = p.draw(return_ggplot=True)\n                axs = plot.axs\n                initialise_artist_offsets(len(axs))\n                set_scale_limits(plot)\n            else:\n                p = copy(p)\n                plot = p._draw_using_figure(figure, axs)\n                try:\n                    check_scale_limits(plot, frame_no)\n                except PlotnineError as err:\n                    plt.close(figure)\n                    raise err\n            artists.append(get_frame_artists(plot))\n\n        if figure is None:\n            figure = plt.figure()\n\n        return figure, artists"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flip_labels(obj):\n    def sub(a, b):\n        \"\"\"\n        Substitute all keys that start with a to b\n        \"\"\"\n        for label in list(obj.keys()):\n            if label.startswith(a):\n                new_label = b+label[1:]\n                obj[new_label] = obj.pop(label)\n\n    sub('x', 'z')\n    sub('y', 'x')\n    sub('z', 'y')\n    return obj", "response": "Flips the labels of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bootstrap_statistics(series, statistic, n_samples=1000,\n                         confidence_interval=0.95, random_state=None):\n    \"\"\"\n    Default parameters taken from\n    R's Hmisc smean.cl.boot\n    \"\"\"\n    if random_state is None:\n        random_state = np.random\n\n    alpha = 1 - confidence_interval\n    size = (n_samples, len(series))\n    inds = random_state.randint(0, len(series), size=size)\n    samples = series.values[inds]\n    means = np.sort(statistic(samples, axis=1))\n    return pd.DataFrame({'ymin': means[int((alpha/2)*n_samples)],\n                         'ymax': means[int((1-alpha/2)*n_samples)],\n                         'y': [statistic(series)]})", "response": "Bootstrap statistics for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mean_cl_boot(series, n_samples=1000, confidence_interval=0.95,\n                 random_state=None):\n    \"\"\"\n    Bootstrapped mean with confidence limits\n    \"\"\"\n    return bootstrap_statistics(series, np.mean,\n                                n_samples=n_samples,\n                                confidence_interval=confidence_interval,\n                                random_state=random_state)", "response": "Bootstrapped mean with confidence limits\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mean_cl_normal(series, confidence_interval=0.95):\n    a = np.asarray(series)\n    m = np.mean(a)\n    se = scipy.stats.sem(a)\n    h = se * scipy.stats.t._ppf((1+confidence_interval)/2, len(a)-1)\n    return pd.DataFrame({'y': [m],\n                         'ymin': m-h,\n                         'ymax': m+h})", "response": "Mean normal distribution of a series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmean plus or minus a constant times the standard deviation", "response": "def mean_sdl(series, mult=2):\n    \"\"\"\n    mean plus or minus a constant times the standard deviation\n    \"\"\"\n    m = series.mean()\n    s = series.std()\n    return pd.DataFrame({'y': [m],\n                         'ymin': m-mult*s,\n                         'ymax': m+mult*s})"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mean_se(series, mult=1):\n    m = np.mean(series)\n    se = mult * np.sqrt(np.var(series) / len(series))\n    return pd.DataFrame({'y': [m],\n                         'ymin': m-se,\n                         'ymax': m+se})", "response": "Calculate mean and standard errors on either side of a sequence"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_breaks_and_labels(self, ranges, layout_info, pidx):\n        ax = self.axs[pidx]\n        facet.set_breaks_and_labels(self, ranges, layout_info, pidx)\n        ax.xaxis.set_ticks_position('bottom')\n        ax.yaxis.set_ticks_position('left')", "response": "Add breaks and labels to the axes containing the species."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spaceout_and_resize_panels(self):\n        # Only deal with the aspect ratio\n        figure = self.figure\n        theme = self.theme\n\n        try:\n            aspect_ratio = theme.themeables.property('aspect_ratio')\n        except KeyError:\n            aspect_ratio = self.coordinates.aspect(\n                    self.layout.panel_params[0])\n\n        if aspect_ratio is None:\n            return\n\n        left = figure.subplotpars.left\n        right = figure.subplotpars.right\n        top = figure.subplotpars.top\n        bottom = figure.subplotpars.bottom\n        W, H = figure.get_size_inches()\n\n        w = (right-left)*W\n        h = w*aspect_ratio\n        H = h / (top-bottom)\n\n        figure.set_figheight(H)", "response": "Adjust the space between the panels and the resize panels."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw independent line segments between all the segment objects in a group .", "response": "def _draw_segments(data, ax, **params):\n    \"\"\"\n    Draw independent line segments between all the\n    points\n    \"\"\"\n    color = to_rgba(data['color'], data['alpha'])\n    # All we do is line-up all the points in a group\n    # into segments, all in a single list.\n    # Along the way the other parameters are put in\n    # sequences accordingly\n    indices = []  # for attributes of starting point of each segment\n    segments = []\n    for _, df in data.groupby('group'):\n        idx = df.index\n        indices.extend(idx[:-1])  # One line from two points\n        x = data['x'].iloc[idx]\n        y = data['y'].iloc[idx]\n        segments.append(make_line_segments(x, y, ispath=True))\n\n    segments = np.vstack(segments)\n\n    if color is None:\n        edgecolor = color\n    else:\n        edgecolor = [color[i] for i in indices]\n\n    linewidth = data.loc[indices, 'size']\n    linestyle = data.loc[indices, 'linetype']\n\n    coll = mcoll.LineCollection(segments,\n                                edgecolor=edgecolor,\n                                linewidth=linewidth,\n                                linestyle=linestyle,\n                                zorder=params['zorder'])\n    ax.add_collection(coll)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndraws a path with the same characteristics from the first point to the last point", "response": "def _draw_lines(data, ax, **params):\n    \"\"\"\n    Draw a path with the same characteristics from the\n    first point to the last point\n    \"\"\"\n    color = to_rgba(data['color'].iloc[0], data['alpha'].iloc[0])\n    join_style = _get_joinstyle(data, params)\n    lines = mlines.Line2D(data['x'],\n                          data['y'],\n                          color=color,\n                          linewidth=data['size'].iloc[0],\n                          linestyle=data['linetype'].iloc[0],\n                          zorder=params['zorder'],\n                          **join_style)\n    ax.add_artist(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw(self, data, panel_params, coord, ax, zorder, constant=True):\n        first = self.ends in ('first', 'both')\n        last = self.ends in ('last', 'both')\n\n        data = data.sort_values('group', kind='mergesort')\n        data['color'] = to_rgba(data['color'], data['alpha'])\n\n        if self.type == 'open':\n            data['facecolor'] = 'none'\n        else:\n            data['facecolor'] = data['color']\n\n        if not constant:\n            # Get segments/points (x1, y1) -> (x2, y2)\n            # for which to calculate the arrow heads\n            idx1, idx2 = [], []\n            for _, df in data.groupby('group'):\n                idx1.extend(df.index[:-1])\n                idx2.extend(df.index[1:])\n\n            d = dict(\n                zorder=zorder,\n                edgecolor=data.loc[idx1, 'color'],\n                facecolor=data.loc[idx1, 'facecolor'],\n                linewidth=data.loc[idx1, 'size'],\n                linestyle=data.loc[idx1, 'linetype'])\n\n            x1 = data.loc[idx1, 'x'].values\n            y1 = data.loc[idx1, 'y'].values\n            x2 = data.loc[idx2, 'x'].values\n            y2 = data.loc[idx2, 'y'].values\n\n            if first:\n                paths = self.get_paths(x1, y1, x2, y2,\n                                       panel_params, coord, ax)\n                coll = mcoll.PathCollection(paths, **d)\n                ax.add_collection(coll)\n            if last:\n                x1, y1, x2, y2 = x2, y2, x1, y1\n                paths = self.get_paths(x1, y1, x2, y2,\n                                       panel_params, coord, ax)\n                coll = mcoll.PathCollection(paths, **d)\n                ax.add_collection(coll)\n        else:\n            d = dict(\n                zorder=zorder,\n                edgecolor=data['color'].iloc[0],\n                facecolor=data['facecolor'].iloc[0],\n                linewidth=data['size'].iloc[0],\n                linestyle=data['linetype'].iloc[0],\n                joinstyle='round',\n                capstyle='butt')\n\n            if first:\n                x1, x2 = data['x'].iloc[0:2]\n                y1, y2 = data['y'].iloc[0:2]\n                x1, y1, x2, y2 = [np.array([i])\n                                  for i in (x1, y1, x2, y2)]\n                paths = self.get_paths(x1, y1, x2, y2,\n                                       panel_params, coord, ax)\n                patch = mpatches.PathPatch(paths[0], **d)\n                ax.add_artist(patch)\n\n            if last:\n                x1, x2 = data['x'].iloc[-2:]\n                y1, y2 = data['y'].iloc[-2:]\n                x1, y1, x2, y2 = x2, y2, x1, y1\n                x1, y1, x2, y2 = [np.array([i])\n                                  for i in (x1, y1, x2, y2)]\n                paths = self.get_paths(x1, y1, x2, y2,\n                                       panel_params, coord, ax)\n                patch = mpatches.PathPatch(paths[0], **d)\n                ax.add_artist(patch)", "response": "Draw the arrows at the end of the path of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the paths that create the arrow heads at x1 y1 x2 y2.", "response": "def get_paths(self, x1, y1, x2, y2, panel_params, coord, ax):\n        \"\"\"\n        Compute paths that create the arrow heads\n\n        Parameters\n        ----------\n        x1, y1, x2, y2 : array_like\n            List of points that define the tails of the arrows.\n            The arrow heads will be at x1, y1. If you need them\n            at x2, y2 reverse the input.\n\n        Returns\n        -------\n        out : list of Path\n            Paths that create arrow heads\n        \"\"\"\n        Path = mpath.Path\n\n        # Create reusable lists of vertices and codes\n        # arrowhead path has 3 vertices (Nones),\n        # plus dummy vertex for the STOP code\n        verts = [None, None, None,\n                 (0, 0)]\n\n        # codes list remains the same after initialization\n        codes = [Path.MOVETO, Path.LINETO, Path.LINETO,\n                 Path.STOP]\n\n        # Slices into the vertices list\n        slc = slice(0, 3)\n\n        # We need the plot dimensions so that we can\n        # compute scaling factors\n        fig = ax.get_figure()\n        width, height = fig.get_size_inches()\n        ranges = coord.range(panel_params)\n        width_ = np.ptp(ranges.x)\n        height_ = np.ptp(ranges.y)\n\n        # scaling factors to prevent skewed arrowheads\n        lx = self.length * width_/width\n        ly = self.length * height_/height\n\n        # angle in radians\n        a = self.angle * np.pi / 180\n\n        # direction of arrow head\n        xdiff, ydiff = x2 - x1, y2 - y1\n        rotations = np.arctan2(ydiff/ly, xdiff/lx)\n\n        # Arrow head vertices\n        v1x = x1 + lx * np.cos(rotations + a)\n        v1y = y1 + ly * np.sin(rotations + a)\n        v2x = x1 + lx * np.cos(rotations - a)\n        v2y = y1 + ly * np.sin(rotations - a)\n\n        # create a path for each arrow head\n        paths = []\n        for t in zip(v1x, v1y, x1, y1, v2x, v2y):\n            verts[slc] = [t[:2], t[2:4], t[4:]]\n            paths.append(Path(verts, codes))\n\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncombine faceting variables into a single data frame.", "response": "def combine_vars(data, environment=None, vars=None, drop=True):\n    \"\"\"\n    Base layout function that generates all combinations of data\n    needed for facetting\n    The first data frame in the list should be the default data\n    for the plot. Other data frames in the list are ones that are\n    added to the layers.\n    \"\"\"\n    if not vars:\n        return pd.DataFrame()\n\n    # For each layer, compute the facet values\n    values = [eval_facet_vars(df, vars, environment)\n              for df in data if df is not None]\n\n    # Form the base data frame which contains all combinations\n    # of facetting variables that appear in the data\n    has_all = [x.shape[1] == len(vars) for x in values]\n    if not any(has_all):\n        raise PlotnineError(\n            \"At least one layer must contain all variables \" +\n            \"used for facetting\")\n    base = pd.concat([x for i, x in enumerate(values) if has_all[i]],\n                     axis=0)\n    base = base.drop_duplicates()\n\n    if not drop:\n        base = unique_combs(base)\n\n    # sorts according to order of factor levels\n    base = base.sort_values(list(base.columns))\n\n    # Systematically add on missing combinations\n    for i, value in enumerate(values):\n        if has_all[i] or len(value.columns) == 0:\n            continue\n        old = base.loc[:, base.columns - value.columns]\n        new = value.loc[:, base.columns & value.columns].drop_duplicates()\n        if not drop:\n            new = unique_combs(new)\n        base = base.append(cross_join(old, new), ignore_index=True)\n\n    if len(base) == 0:\n        raise PlotnineError(\n            \"Faceting variables must have at least one value\")\n\n    base = base.reset_index(drop=True)\n    return base"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns data frame with all possible combinations of the values in the columns", "response": "def unique_combs(df):\n    \"\"\"\n    Return data frame with all possible combinations\n    of the values in the columns\n    \"\"\"\n    # List of unique values from every column\n    lst = (x.unique() for x in (df[c] for c in df))\n    rows = list(itertools.product(*lst))\n    _df = pd.DataFrame(rows, columns=df.columns)\n\n    # preserve the column dtypes\n    for col in df:\n        _df[col] = _df[col].astype(df[col].dtype, copy=False)\n    return _df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eval_facet_vars(data, vars, env):\n    # To allow expressions in facet formula\n    def I(value):\n        return value\n\n    env = env.with_outer_namespace({'I': I})\n    facet_vals = pd.DataFrame(index=data.index)\n\n    for name in vars:\n        if name in data:\n            # This is a limited solution. If a keyword is\n            # part of an expression it will fail in the\n            # else statement below\n            res = data[name]\n        elif str.isidentifier(name):\n            # All other non-statements\n            continue\n        else:\n            # Statements\n            try:\n                res = env.eval(name, inner_namespace=data)\n            except NameError:\n                continue\n        facet_vals[name] = res\n\n    return facet_vals", "response": "Evaluate facet variables in the specified list of available variables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset properties of the object.", "response": "def set(self, **kwargs):\n        \"\"\"\n        Set properties\n        \"\"\"\n        for name, value in kwargs.items():\n            if hasattr(self, name):\n                setattr(self, name, value)\n            else:\n                raise AttributeError(\n                    \"{!r} object has no attribute {}\".format(\n                        self.__class__.__name__,\n                        name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map(self, data, layout):\n        msg = \"{} should implement this method.\"\n        raise NotImplementedError(\n            msg.format(self.__class.__name__))", "response": "Assign a data point to panels and layout."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_layout(self, data):\n        msg = \"{} should implement this method.\"\n        raise NotImplementedError(\n            msg.format(self.__class.__name__))", "response": "Compute layout of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntrain the x and y scales for each panel in turn.", "response": "def train_position_scales(self, layout, layers):\n        \"\"\"\n        Compute ranges for the x and y scales\n        \"\"\"\n        _layout = layout.layout\n        panel_scales_x = layout.panel_scales_x\n        panel_scales_y = layout.panel_scales_y\n\n        # loop over each layer, training x and y scales in turn\n        for layer in layers:\n            data = layer.data\n            match_id = match(data['PANEL'], _layout['PANEL'])\n            if panel_scales_x:\n                x_vars = list(set(panel_scales_x[0].aesthetics) &\n                              set(data.columns))\n                # the scale index for each data point\n                SCALE_X = _layout['SCALE_X'].iloc[match_id].tolist()\n                panel_scales_x.train(data, x_vars, SCALE_X)\n\n            if panel_scales_y:\n                y_vars = list(set(panel_scales_y[0].aesthetics) &\n                              set(data.columns))\n                # the scale index for each data point\n                SCALE_Y = _layout['SCALE_Y'].iloc[match_id].tolist()\n                panel_scales_y.train(data, y_vars, SCALE_Y)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates suplots and return axs for the unique key.", "response": "def _create_subplots(self, fig, layout):\n        \"\"\"\n        Create suplots and return axs\n        \"\"\"\n        num_panels = len(layout)\n        axsarr = np.empty((self.nrow, self.ncol), dtype=object)\n\n        # Create axes\n        i = 1\n        for row in range(self.nrow):\n            for col in range(self.ncol):\n                axsarr[row, col] = fig.add_subplot(self.nrow, self.ncol, i)\n                i += 1\n\n        # Rearrange axes\n        # They are ordered to match the positions in the layout table\n        if self.dir == 'h':\n            order = 'C'\n            if not self.as_table:\n                axsarr = axsarr[::-1]\n        elif self.dir == 'v':\n            order = 'F'\n            if not self.as_table:\n                axsarr = np.array([row[::-1] for row in axsarr])\n\n        axs = axsarr.ravel(order)\n\n        # Delete unused axes\n        for ax in axs[num_panels:]:\n            fig.delaxes(ax)\n        axs = axs[:num_panels]\n        return axs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and return Matplotlib axes for the current MPL.", "response": "def make_axes(self, figure, layout, coordinates):\n        \"\"\"\n        Create and return Matplotlib axes\n        \"\"\"\n        axs = self._create_subplots(figure, layout)\n\n        # Used for labelling the x and y axes, the first and\n        # last axes according to how MPL creates them.\n        self.first_ax = figure.axes[0]\n        self.last_ax = figure.axes[-1]\n        self.figure = figure\n        self.axs = axs\n        return axs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_size(self, location='top', num_lines=None):\n        dpi = 72\n        theme = self.theme\n        get_property = theme.themeables.property\n\n        if location == 'right':\n            strip_name = 'strip_text_y'\n            num_lines = num_lines or self.num_vars_y\n        else:\n            strip_name = 'strip_text_x'\n            num_lines = num_lines or self.num_vars_x\n\n        if not num_lines:\n            return 0\n\n        # The facet labels are placed onto the figure using\n        # transAxes dimensions. The line height and line\n        # width are mapped to the same [0, 1] range\n        # i.e (pts) * (inches / pts) * (1 / inches)\n        try:\n            fontsize = get_property(strip_name, 'size')\n        except KeyError:\n            fontsize = float(theme.rcParams.get('font.size', 10))\n\n        try:\n            linespacing = get_property(strip_name, 'linespacing')\n        except KeyError:\n            linespacing = 1\n\n        # margins on either side of the strip text\n        m1, m2 = self.inner_strip_margins(location)\n        # Using figure.dpi value here does not workout well!\n        breadth = (linespacing*fontsize) * num_lines / dpi\n        breadth = breadth + (m1 + m2) / dpi\n        return breadth", "response": "Returns the size of the strip in inches."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_dimensions(self, text_lines, location, pid):\n        dpi = 72\n        num_lines = len(text_lines)\n        get_property = self.theme.themeables.property\n        ax = self.axs[pid]\n        bbox = ax.get_window_extent().transformed(\n            self.figure.dpi_scale_trans.inverted())\n        ax_width, ax_height = bbox.width, bbox.height  # in inches\n        strip_size = self.strip_size(location, num_lines)\n        m1, m2 = self.inner_strip_margins(location)\n        m1, m2 = m1/dpi, m2/dpi\n        margin = 0  # default\n\n        if location == 'right':\n            box_x = 1\n            box_y = 0\n            box_width = strip_size/ax_width\n            box_height = 1\n            # y & height properties of the background slide and\n            # shrink the strip vertically. The y margin slides\n            # it horizontally.\n            with suppress(KeyError):\n                box_y = get_property('strip_background_y', 'y')\n            with suppress(KeyError):\n                box_height = get_property('strip_background_y', 'height')\n            with suppress(KeyError):\n                margin = get_property('strip_margin_y')\n            x = 1 + (strip_size-m2+m1) / (2*ax_width)\n            y = (2*box_y+box_height)/2\n            # margin adjustment\n            hslide = 1 + margin*strip_size/ax_width\n            x *= hslide\n            box_x *= hslide\n        else:\n            box_x = 0\n            box_y = 1\n            box_width = 1\n            box_height = strip_size/ax_height\n            # x & width properties of the background slide and\n            # shrink the strip horizontally. The y margin slides\n            # it vertically.\n            with suppress(KeyError):\n                box_x = get_property('strip_background_x', 'x')\n            with suppress(KeyError):\n                box_width = get_property('strip_background_x', 'width')\n            with suppress(KeyError):\n                margin = get_property('strip_margin_x')\n            x = (2*box_x+box_width)/2\n            y = 1 + (strip_size-m1+m2)/(2*ax_height)\n            # margin adjustment\n            vslide = 1 + margin*strip_size/ax_height\n            y *= vslide\n            box_y *= vslide\n\n        dimensions = types.SimpleNamespace(\n            x=x, y=y, box_x=box_x, box_y=box_y,\n            box_width=box_width,\n            box_height=box_height)\n        return dimensions", "response": "Calculate the dimension of the strip text and the background boxes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw a strip text on the current figure.", "response": "def draw_strip_text(self, text_lines, location, pid):\n        \"\"\"\n        Create a background patch and put a label on it\n        \"\"\"\n        ax = self.axs[pid]\n        themeable = self.figure._themeable\n        dim = self.strip_dimensions(text_lines, location, pid)\n\n        if location == 'right':\n            rotation = -90\n            label = '\\n'.join(reversed(text_lines))\n        else:\n            rotation = 0\n            label = '\\n'.join(text_lines)\n\n        rect = mpatch.FancyBboxPatch((dim.box_x, dim.box_y),\n                                     width=dim.box_width,\n                                     height=dim.box_height,\n                                     facecolor='lightgrey',\n                                     edgecolor='None',\n                                     transform=ax.transAxes,\n                                     zorder=2.2,  # > ax line & boundary\n                                     boxstyle='square, pad=0',\n                                     clip_on=False)\n\n        text = mtext.Text(dim.x, dim.y, label,\n                          rotation=rotation,\n                          verticalalignment='center',\n                          horizontalalignment='center',\n                          transform=ax.transAxes,\n                          zorder=3.3,  # > rect\n                          clip_on=False)\n\n        ax.add_artist(rect)\n        ax.add_artist(text)\n\n        for key in ('strip_text_x', 'strip_text_y',\n                    'strip_background_x', 'strip_background_y'):\n            if key not in themeable:\n                themeable[key] = []\n\n        if location == 'right':\n            themeable['strip_background_y'].append(rect)\n            themeable['strip_text_y'].append(text)\n        else:\n            themeable['strip_background_x'].append(rect)\n            themeable['strip_text_x'].append(text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_data(self, value):\n        s = locale.format_string('%1.10e', (value,))\n        return self.fix_minus(s)", "response": "Return a formatted string representation of a number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_interpolated_colorbar(da, colors, direction):\n    # Special case that arises due to not so useful\n    # aesthetic mapping.\n    if len(colors) == 1:\n        colors = [colors[0], colors[0]]\n\n    # Number of horizontal egdes(breaks) in the grid\n    # No need to create more nbreak than colors, provided\n    # no. of colors = no. of breaks = no. of cmap colors\n    # the shading does a perfect interpolation\n    nbreak = len(colors)\n\n    if direction == 'vertical':\n        mesh_width = 1\n        mesh_height = nbreak-1\n        linewidth = da.height/mesh_height\n        # Construct rectangular meshgrid\n        # The values(Z) at each vertex are just the\n        # normalized (onto [0, 1]) vertical distance\n        x = np.array([0, da.width])\n        y = np.arange(0, nbreak) * linewidth\n        X, Y = np.meshgrid(x, y)\n        Z = Y/y.max()\n    else:\n        mesh_width = nbreak-1\n        mesh_height = 1\n        linewidth = da.width/mesh_width\n        x = np.arange(0, nbreak) * linewidth\n        y = np.array([0, da.height])\n        X, Y = np.meshgrid(x, y)\n        Z = X/x.max()\n\n    # As a 2D coordinates array\n    coordinates = np.zeros(\n        ((mesh_width+1)*(mesh_height+1), 2),\n        dtype=float)\n    coordinates[:, 0] = X.ravel()\n    coordinates[:, 1] = Y.ravel()\n\n    cmap = ListedColormap(colors)\n    coll = mcoll.QuadMesh(mesh_width, mesh_height,\n                          coordinates,\n                          antialiased=False,\n                          shading='gouraud',\n                          linewidth=0,\n                          cmap=cmap,\n                          array=Z.ravel())\n    da.add_artist(coll)", "response": "Add rastered colorbar to DrawingArea\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a colorbar to the drawing area.", "response": "def add_segmented_colorbar(da, colors, direction):\n    \"\"\"\n    Add 'non-rastered' colorbar to DrawingArea\n    \"\"\"\n    nbreak = len(colors)\n    if direction == 'vertical':\n        linewidth = da.height/nbreak\n        verts = [None] * nbreak\n        x1, x2 = 0, da.width\n        for i, color in enumerate(colors):\n            y1 = i * linewidth\n            y2 = y1 + linewidth\n            verts[i] = ((x1, y1), (x1, y2), (x2, y2), (x2, y1))\n    else:\n        linewidth = da.width/nbreak\n        verts = [None] * nbreak\n        y1, y2 = 0, da.height\n        for i, color in enumerate(colors):\n            x1 = i * linewidth\n            x2 = x1 + linewidth\n            verts[i] = ((x1, y1), (x1, y2), (x2, y2), (x2, y1))\n\n    coll = mcoll.PolyCollection(verts,\n                                facecolors=colors,\n                                linewidth=0,\n                                antialiased=False)\n    da.add_artist(coll)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a labels box and a legend text for the given dataset.", "response": "def create_labels(da, labels, locations, direction):\n    \"\"\"\n    Return an OffsetBox with label texts\n    \"\"\"\n    # The box dimensions are determined by the size of\n    # the text objects. We put two dummy children at\n    # either end to gaurantee that when center packed\n    # the labels in the labels_box matchup with the ticks.\n    fontsize = 9\n    aux_transform = mtransforms.IdentityTransform()\n    labels_box = MyAuxTransformBox(aux_transform)\n    xs, ys = [0]*len(labels), locations\n    ha, va = 'left', 'center'\n\n    x1, y1 = 0, 0\n    x2, y2 = 0, da.height\n    if direction == 'horizontal':\n        xs, ys = ys, xs\n        ha, va = 'center', 'top'\n        x2, y2 = da.width, 0\n    txt1 = mtext.Text(x1, y1, '',\n                      horizontalalignment=ha,\n                      verticalalignment=va)\n    txt2 = mtext.Text(x2, y2, '',\n                      horizontalalignment=ha,\n                      verticalalignment=va)\n    labels_box.add_artist(txt1)\n    labels_box.add_artist(txt2)\n\n    legend_text = []\n    for i, (x, y, text) in enumerate(zip(xs, ys, labels)):\n        txt = mtext.Text(x, y, text,\n                         size=fontsize,\n                         horizontalalignment=ha,\n                         verticalalignment=va)\n        labels_box.add_artist(txt)\n        legend_text.append(txt)\n    return labels_box, legend_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_geoms(self, plot):\n        for l in plot.layers:\n            exclude = set()\n            if isinstance(l.show_legend, dict):\n                l.show_legend = rename_aesthetics(l.show_legend)\n                exclude = {ae for ae, val in l.show_legend.items()\n                           if not val}\n            elif l.show_legend not in (None, True):\n                continue\n\n            matched = self.legend_aesthetics(l, plot)\n\n            # layer uses guide\n            if set(matched) - exclude:\n                break\n        # no break, no layer uses this guide\n        else:\n            return None\n\n        return self", "response": "Create a colorbar if it is not geom based"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw(self):\n        obverse = slice(0, None)\n        reverse = slice(None, None, -1)\n        width = self.barwidth\n        height = self.barheight\n        nbars = len(self.bar)\n        length = height\n        direction = self.direction\n        colors = self.bar['color'].tolist()\n        labels = self.key['label'].tolist()\n        themeable = self.theme.figure._themeable\n\n        # When there is more than one guide, we keep\n        # record of all of them using lists\n        if 'legend_title' not in themeable:\n            themeable['legend_title'] = []\n        if 'legend_text_colorbar' not in themeable:\n            themeable['legend_text_colorbar'] = []\n\n        # .5 puts the ticks in the middle of the bars when\n        # raster=False. So when raster=True the ticks are\n        # in between interpolation points and the matching is\n        # close though not exactly right.\n        _from = self.bar['value'].min(), self.bar['value'].max()\n        tick_locations = rescale(self.key['value'],\n                                 (.5, nbars-.5),\n                                 _from) * length/nbars\n\n        if direction == 'horizontal':\n            width, height = height, width\n            length = width\n\n        if self.reverse:\n            colors = colors[::-1]\n            labels = labels[::-1]\n            tick_locations = length - tick_locations[::-1]\n\n        # title #\n        title_box = TextArea(self.title,\n                             textprops=dict(color='black'))\n        themeable['legend_title'].append(title_box)\n\n        # colorbar and ticks #\n        da = ColoredDrawingArea(width, height, 0, 0)\n        if self.raster:\n            add_interpolated_colorbar(da, colors, direction)\n        else:\n            add_segmented_colorbar(da, colors, direction)\n\n        if self.ticks:\n            _locations = tick_locations\n            if not self.draw_ulim:\n                _locations = _locations[:-1]\n\n            if not self.draw_llim:\n                _locations = _locations[1:]\n\n            add_ticks(da, _locations, direction)\n\n        # labels #\n        if self.label:\n            labels_da, legend_text = create_labels(da, labels,\n                                                   tick_locations,\n                                                   direction)\n            themeable['legend_text_colorbar'].extend(legend_text)\n        else:\n            labels_da = ColoredDrawingArea(0, 0)\n\n        # colorbar + labels #\n        if direction == 'vertical':\n            packer, align = HPacker, 'bottom'\n            align = 'center'\n        else:\n            packer, align = VPacker, 'right'\n            align = 'center'\n        slc = obverse if self.label_position == 'right' else reverse\n        if self.label_position in ('right', 'bottom'):\n            slc = obverse\n        else:\n            slc = reverse\n        main_box = packer(children=[da, labels_da][slc],\n                          sep=self._label_margin,\n                          align=align,\n                          pad=0)\n\n        # title + colorbar(with labels) #\n        lookup = {\n            'right': (HPacker, reverse),\n            'left': (HPacker, obverse),\n            'bottom': (VPacker, reverse),\n            'top': (VPacker, obverse)}\n        packer, slc = lookup[self.title_position]\n        children = [title_box, main_box][slc]\n        box = packer(children=children,\n                     sep=self._title_margin,\n                     align=self._title_align,\n                     pad=0)\n        return box", "response": "Draw guide and return a matplotlib. offsetbox. Offsetbox object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_transform(self):\n        return self.aux_transform + \\\n            self.ref_offset_transform + \\\n            self.dpi_transform + \\\n            self.offset_transform", "response": "Return the |matplotlib. transforms. Transform| applied to the children of this entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw(self, renderer):\n        dpi_cor = renderer.points_to_pixels(1.)\n        self.dpi_transform.clear()\n        self.dpi_transform.scale(dpi_cor, dpi_cor)\n\n        for c in self._children:\n            c.draw(renderer)\n\n        self.stale = False", "response": "Draw the children of this object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an instance of themeable by name.", "response": "def from_class_name(name, theme_element):\n        \"\"\"\n        Create an themeable by name\n\n        Parameters\n        ----------\n        name : str\n            Class name\n        theme_element : element object\n            One of :class:`element_line`, :class:`element_rect`,\n            :class:`element_text` or :class:`element_blank`\n\n        Returns\n        -------\n        out : Themeable\n        \"\"\"\n        msg = \"No such themeable element {}\".format(name)\n        try:\n            klass = themeable._registry[name]\n        except KeyError:\n            raise PlotnineError(msg)\n\n        if not issubclass(klass, themeable):\n            raise PlotnineError(msg)\n\n        return klass(theme_element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge properties of other into self.", "response": "def merge(self, other):\n        \"\"\"\n        Merge properties of other into self\n\n        Raises ValueError if any them are a blank\n        \"\"\"\n        if self.is_blank() or other.is_blank():\n            raise ValueError('Cannot merge if there is a blank.')\n        else:\n            self.properties.update(other.properties)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating themeables with those from other.", "response": "def update(self, other):\n        \"\"\"\n        Update themeables with those from `other`\n\n        This method takes care of inserting the `themeable`\n        into the underlying dictionary. Before doing the\n        insertion, any existing themeables that will be\n        affected by a new from `other` will either be merged\n        or removed. This makes sure that a general themeable\n        of type :class:`text` can be added to override an\n        existing specific one of type :class:`axis_text_x`.\n        \"\"\"\n        for new in other.values():\n            new_key = new.__class__.__name__\n\n            # 1st in the mro is self, the\n            # last 2 are (themeable, object)\n            for child in new.__class__.mro()[1:-2]:\n                child_key = child.__name__\n                try:\n                    self[child_key].merge(new)\n                except KeyError:\n                    pass\n                except ValueError:\n                    # Blank child is will be overridden\n                    del self[child_key]\n            try:\n                self[new_key].merge(new)\n            except (KeyError, ValueError):\n                # Themeable type is new or\n                # could not merge blank element.\n                self[new_key] = new"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef values(self):\n        def key(th):\n            return len(th.__class__.__mro__)\n\n        return sorted(dict.values(self), key=key, reverse=True)", "response": "Return a list of themeables sorted in reverse based on their depth in the inheritance hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of a specific themeable property.", "response": "def property(self, name, key='value'):\n        \"\"\"\n        Get the value a specific themeable(s) property\n\n        Themeables store theming attribute values in the\n        :attr:`Themeable.properties` :class:`dict`. The goal\n        of this method is to look a value from that dictionary,\n        and fallback along the inheritance heirarchy of themeables.\n\n        Parameters\n        ----------\n        name : str\n            Themeable name\n        key : str\n            Property name to lookup\n\n        Returns\n        -------\n        out : object\n            Value\n\n        Raises\n        ------\n        KeyError\n            If key is in not in any of themeables\n        \"\"\"\n        hlist = themeable._hierarchy[name]\n        scalar = key == 'value'\n        for th in hlist:\n            try:\n                value = self[th].properties[key]\n            except KeyError:\n                continue\n            else:\n                if not scalar or value is not None:\n                    return value\n\n        msg = \"'{}' is not in the properties of {} \"\n        raise KeyError(msg.format(key, hlist))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the themeable with the given name is blank otherwise False.", "response": "def is_blank(self, name):\n        \"\"\"\n        Return True if the themeable *name* is blank\n\n        This if the *name* is not in the list of themeables\n        then the lookup falls back to inheritance hierarchy\n        is considered. If the none of the themeables in the\n        hierary are present, ``False`` will be returned.\n\n        Parameters\n        ----------\n        names : str\n            Themeable, in order of most specific to most\n            general.\n        \"\"\"\n        for th in themeable._hierarchy[name]:\n            with suppress(KeyError):\n                return self[th].is_blank()\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_data(self, data, params):\n        check_required_aesthetics(\n            self.REQUIRED_AES,\n            data.columns,\n            self.__class__.__name__)\n        return data", "response": "Verify & return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the position of the layer in all panels and the panels that are in the specified layout.", "response": "def compute_layer(cls, data, params, layout):\n        \"\"\"\n        Compute position for the layer in all panels\n\n        Positions can override this function instead of\n        `compute_panel` if the position computations are\n        independent of the panel. i.e when not colliding\n        \"\"\"\n        def fn(pdata):\n            \"\"\"\n            Helper compute function\n            \"\"\"\n            # Given data belonging to a specific panel, grab\n            # the corresponding scales and call the method\n            # that does the real computation\n            if len(pdata) == 0:\n                return pdata\n            scales = layout.get_scales(pdata['PANEL'].iat[0])\n            return cls.compute_panel(pdata, scales, params)\n\n        return groupby_apply(data, 'PANEL', fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the panel for the current locale.", "response": "def compute_panel(cls, data, scales, params):\n        \"\"\"\n        Positions must override this function\n\n        Notes\n        -----\n        Make necessary adjustments to the columns in the dataframe.\n\n        Create the position transformation functions and\n        use self.transform_position() do the rest.\n\n        See Also\n        --------\n        position_jitter.compute_panel\n        \"\"\"\n        msg = '{} needs to implement this method'\n        raise NotImplementedError(msg.format(cls.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming all the variables that map onto the x and y scales.", "response": "def transform_position(data, trans_x=None, trans_y=None):\n        \"\"\"\n        Transform all the variables that map onto the x and y scales.\n\n        Parameters\n        ----------\n        data    : dataframe\n        trans_x : function\n            Transforms x scale mappings\n            Takes one argument, either a scalar or an array-type\n        trans_y : function\n            Transforms y scale mappings\n            Takes one argument, either a scalar or an array-type\n        \"\"\"\n        # Aesthetics that map onto the x and y scales\n        X = {'x', 'xmin', 'xmax', 'xend', 'xintercept'}\n        Y = {'y', 'ymin', 'ymax', 'yend', 'yintercept'}\n\n        if trans_x:\n            xs = [name for name in data.columns if name in X]\n            data[xs] = data[xs].apply(trans_x)\n\n        if trans_y:\n            ys = [name for name in data.columns if name in Y]\n            data[ys] = data[ys].apply(trans_y)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate and return a position object for the geom.", "response": "def from_geom(geom):\n        \"\"\"\n        Create and return a position object for the geom\n\n        Parameters\n        ----------\n        geom : geom\n            An instantiated geom object.\n\n        Returns\n        -------\n        out : position\n            A position object\n\n        Raises :class:`PlotnineError` if unable to create a `position`.\n        \"\"\"\n        name = geom.params['position']\n        if issubclass(type(name), position):\n            return name\n\n        if isinstance(name, type) and issubclass(name, position):\n            klass = name\n        elif is_string(name):\n            if not name.startswith('position_'):\n                name = 'position_{}'.format(name)\n            klass = Registry[name]\n        else:\n            raise PlotnineError(\n                'Unknown position of type {}'.format(type(name)))\n\n        return klass()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collide(cls, data, params):\n        xminmax = ['xmin', 'xmax']\n        data, width = cls._collide_setup(data, params)\n        if params.get('width', None) is None:\n            params['width'] = width\n\n        # Reorder by x position then on group, relying on stable sort to\n        # preserve existing ordering. The default stacking order reverses\n        # the group in order to match the legend order.\n        if params and 'reverse' in params and params['reverse']:\n            idx = data.sort_values(\n                ['xmin', 'group'], kind='mergesort').index\n        else:\n            data['-group'] = -data['group']\n            idx = data.sort_values(\n                ['xmin', '-group'], kind='mergesort').index\n            del data['-group']\n\n        data = data.loc[idx, :]\n\n        # Check for overlap\n        intervals = data[xminmax].drop_duplicates().values.flatten()\n        intervals = intervals[~np.isnan(intervals)]\n\n        if (len(np.unique(intervals)) > 1 and\n                any(np.diff(intervals - intervals.mean()) < -1e-6)):\n            msg = \"{} requires non-overlapping x intervals\"\n            warn(msg.format(cls.__name__), PlotnineWarning)\n\n        if 'ymax' in data:\n            data = groupby_apply(data, 'xmin', cls.strategy, params)\n        elif 'y' in data:\n            data['ymax'] = data['y']\n            data = groupby_apply(data, 'xmin', cls.strategy, params)\n            data['y'] = data['ymax']\n        else:\n            raise PlotnineError('Neither y nor ymax defined')\n\n        return data", "response": "Collide the data array by finding the minimum and maximum values of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncolliding object with other object.", "response": "def collide2(cls, data, params):\n        \"\"\"\n        Calculate boundaries of geometry object\n\n        Uses Strategy\n        \"\"\"\n        data, width = cls._collide_setup(data, params)\n        if params.get('width', None) is None:\n            params['width'] = width\n\n        # Reorder by x position then on group, relying on stable sort to\n        # preserve existing ordering. The default stacking order reverses\n        # the group in order to match the legend order.\n        if params and 'reverse' in params and params['reverse']:\n            data['-group'] = -data['group']\n            idx = data.sort_values(\n                ['x', '-group'], kind='mergesort').index\n            del data['-group']\n        else:\n            idx = data.sort_values(\n                ['x', 'group'], kind='mergesort').index\n\n        data = data.loc[idx, :]\n        data.reset_index(inplace=True, drop=True)\n        return cls.strategy(data, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a proper scale object for the series", "response": "def make_scale(ae, series, *args, **kwargs):\n    \"\"\"\n    Return a proper scale object for the series\n\n    The scale is for the aesthetic ae, and args & kwargs\n    are passed on to the scale creating class\n    \"\"\"\n    stype = scale_type(series)\n\n    # filter parameters by scale type\n    if stype == 'discrete':\n        with suppress(KeyError):\n            del kwargs['trans']\n\n    scale_name = 'scale_{}_{}'.format(ae, stype)\n    scale_klass = Registry[scale_name]\n    return scale_klass(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd scale sc and remove any previous scales that cover the same aesthetics", "response": "def append(self, sc):\n        \"\"\"\n        Add scale 'sc' and remove any previous\n        scales that cover the same aesthetics\n        \"\"\"\n        ae = sc.aesthetics[0]\n        cover_ae = self.find(ae)\n        if any(cover_ae):\n            warn(_TPL_DUPLICATE_SCALE.format(ae), PlotnineWarning)\n            idx = cover_ae.index(True)\n            self.pop(idx)\n        # super() does not work well with reloads\n        list.append(self, sc)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the aesthetics covered by the scales.", "response": "def input(self):\n        \"\"\"\n        Return a list of all the aesthetics covered by\n        the scales.\n        \"\"\"\n        lst = [s.aesthetics for s in self]\n        return list(itertools.chain(*lst))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_scales(self, aesthetic):\n        bool_lst = self.find(aesthetic)\n        try:\n            idx = bool_lst.index(True)\n            return self[idx]\n        except ValueError:\n            return None", "response": "Return the scale for the aesthetic or None if there isn t one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef non_position_scales(self):\n        l = [s for s in self\n             if not ('x' in s.aesthetics) and not ('y' in s.aesthetics)]\n        return Scales(l)", "response": "Return a list of the non - position scales that are present in the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef position_scales(self):\n        l = [s for s in self\n             if ('x' in s.aesthetics) or ('y' in s.aesthetics)]\n        return Scales(l)", "response": "Return a list of the position scales that are present in the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef train(self, data, vars, idx):\n        idx = np.asarray(idx)\n        for col in vars:\n            for i, sc in enumerate(self, start=1):\n                bool_idx = (i == idx)\n                sc.train(data.loc[bool_idx, col])", "response": "Train the scales on the data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map(self, data, vars, idx):\n        idx = np.asarray(idx)\n        # discrete scales change the dtype\n        # from category to int. Use a new dataframe\n        # to collect these results.\n        # Using `type` preserves the subclass of pd.DataFrame\n        df = type(data)(index=data.index)\n        discrete_cols = []\n\n        # Loop through each variable, mapping across each scale,\n        # then joining back into the copy of the data\n        for col in vars:\n            use_df = array_kind.discrete(data[col])\n            if use_df:\n                discrete_cols.append(col)\n            for i, sc in enumerate(self, start=1):\n                bool_idx = (i == idx)\n                results = sc.map(data.loc[bool_idx, col])\n                if use_df:\n                    df.loc[bool_idx, col] = results\n                else:\n                    data.loc[bool_idx, col] = results\n\n        for col in discrete_cols:\n            data[col] = df[col]", "response": "Map the data on the scales"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train_df(self, df, drop=False):\n        if (len(df) == 0) or (len(self) == 0):\n            return df\n\n        # Each scale trains the columns it understands\n        for sc in self:\n            sc.train_df(df)\n        return df", "response": "Train scales from a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_df(self, df):\n        if (len(df) == 0) or (len(self) == 0):\n            return df\n\n        # Each scale maps the columns it understands\n        for sc in self:\n            df = sc.map_df(df)\n        return df", "response": "Maps values from a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming values in a dataframe.", "response": "def transform_df(self, df):\n        \"\"\"\n        Transform values in a dataframe.\n\n        Returns dataframe\n        \"\"\"\n        if (len(df) == 0) or (len(self) == 0):\n            return df\n\n        # Each scale transforms the columns it understands\n        for sc in self:\n            df = sc.transform_df(df)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_defaults(self, data, aesthetics):\n        if not aesthetics:\n            return\n\n        # aesthetics with scales\n        aws = set()\n        if self:\n            for s in (set(sc.aesthetics) for sc in self):\n                aws.update(s)\n\n        # aesthetics that do not have scales present\n        # We preserve the order of the aesthetics\n        new_aesthetics = [x for x in aesthetics.keys() if x not in aws]\n        if not new_aesthetics:\n            return\n\n        # If a new aesthetic corresponds to a column in the data\n        # frame, find a default scale for the type of data in that\n        # column\n        seen = set()\n        for ae in new_aesthetics:\n            col = aesthetics[ae]\n            if col not in data:\n                col = ae\n            scale_var = aes_to_scale(ae)\n\n            if self.get_scales(scale_var):\n                continue\n\n            seen.add(scale_var)\n            try:\n                sc = make_scale(scale_var, data[col])\n            except PlotnineError:\n                # Skip aesthetics with no scales (e.g. group, order, etc)\n                continue\n            self.append(sc)", "response": "Add default scales for the aesthetics that are not present in the data frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_missing(self, aesthetics):\n        # Keep only aesthetics that don't have scales\n        aesthetics = set(aesthetics) - set(self.input())\n\n        for ae in aesthetics:\n            scale_name = 'scale_{}_continuous'.format(ae)\n            scale_f = Registry[scale_name]\n            self.append(scale_f())", "response": "Add missing scales but required scales."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef label_value(label_info, multi_line=True):\n    label_info = label_info.astype(str)\n    if not multi_line:\n        label_info = collapse_label_lines(label_info)\n\n    return label_info", "response": "Converts series values to str and maybe concatenate them"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef label_both(label_info, multi_line=True, sep=': '):\n    label_info = label_info.astype(str)\n    for var in label_info.index:\n        label_info[var] = '{0}{1}{2}'.format(var, sep, label_info[var])\n\n    if not multi_line:\n        label_info = collapse_label_lines(label_info)\n\n    return label_info", "response": "Returns a series with the same values and the index of the series."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a unabiguous label string for a set of variables.", "response": "def label_context(label_info, multi_line=True, sep=': '):\n    \"\"\"\n    Create an unabiguous label string\n\n    If facetting over a single variable, `label_value` is\n    used, if two or more variables then `label_both` is used.\n\n    Parameters\n    ----------\n    label_info : series\n        Series whose values will be returned. It must have\n        an index made of variable names\n    multi_line : bool\n        Whether to place each variable on a separate line\n    sep :  str\n        Separation between variable name and value\n\n    Returns\n    -------\n    out : str\n        Contatenated label values (or pairs of variable names\n        & values)\n    \"\"\"\n    if len(label_info) == 1:\n        return label_value(label_info, multi_line)\n    else:\n        return label_both(label_info, multi_line, sep)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_labeller(x, default=label_value, multi_line=True):\n    if x is None:\n        x = default\n\n    # One of the labelling functions as string\n    with suppress(KeyError, TypeError):\n        x = LABELLERS[x]\n\n    # x is a labeller\n    with suppress(AttributeError):\n        if x.__name__ == '_labeller':\n            return x\n\n    def _labeller(label_info):\n        label_info = pd.Series(label_info).astype(str)\n\n        if callable(x) and x.__name__ in LABELLERS:\n            # labellers in this module\n            return x(label_info)\n        elif hasattr(x, '__contains__'):\n            # dictionary lookup\n            for var in label_info.index:\n                if label_info[var] in x:\n                    label_info[var] = x[label_info[var]]\n            return label_info\n        elif callable(x):\n            # generic function\n            for var in label_info.index:\n                label_info[var] = x(label_info[var])\n            return label_info\n        else:\n            msg = \"Could not use '{0}' for labelling.\"\n            raise PlotnineError(msg.format(x))\n\n    return _labeller", "response": "Coerse to labeller function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef labeller(rows=None, cols=None, multi_line=True,\n             default=label_value, **kwargs):\n    \"\"\"\n    Return a labeller function\n\n    Parameters\n    ----------\n    rows : str | function | None\n        How to label the rows\n    cols : str | function | None\n        How to label the columns\n    multi_line : bool\n        Whether to place each variable on a separate line\n    default : function | str\n        Fallback labelling function. If it is a string,\n        it should be the name of one the labelling\n        functions provided by plotnine.\n    kwargs : dict\n        {variable name : function | string} pairs for\n        renaming variables. A function to rename the variable\n        or a string name.\n\n    Returns\n    -------\n    out : function\n        Function to do the labelling\n    \"\"\"\n    # Sort out the labellers along each dimension\n    rows_labeller = as_labeller(rows, default, multi_line)\n    cols_labeller = as_labeller(cols, default, multi_line)\n\n    def _labeller(label_info):\n        # When there is no variable specific labeller,\n        # use that of the dimension\n        if label_info._meta['dimension'] == 'rows':\n            margin_labeller = rows_labeller\n        else:\n            margin_labeller = cols_labeller\n\n        # Labelling functions expect string values\n        label_info = label_info.astype(str)\n\n        # Each facetting variable is labelled independently\n        for name, value in label_info.iteritems():\n            func = as_labeller(kwargs.get(name), margin_labeller)\n            new_info = func(label_info[[name]])\n            label_info[name] = new_info[name]\n\n        if not multi_line:\n            label_info = collapse_label_lines(label_info)\n\n        return label_info\n\n    return _labeller", "response": "Returns a function that labelles the elements of the n - grams in the n - grams of the n - grams in the n - grams of the n - grams in the n - grams."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a dataframe with info needed to draw quantile segments", "response": "def make_quantile_df(data, draw_quantiles):\n    \"\"\"\n    Return a dataframe with info needed to draw quantile segments\n    \"\"\"\n    dens = data['density'].cumsum() / data['density'].sum()\n    ecdf = interp1d(dens, data['y'], assume_sorted=True)\n    ys = ecdf(draw_quantiles)\n\n    # Get the violin bounds for the requested quantiles\n    violin_xminvs = interp1d(data['y'], data['xminv'])(ys)\n    violin_xmaxvs = interp1d(data['y'], data['xmaxv'])(ys)\n\n    data = pd.DataFrame({\n        'x': interleave(violin_xminvs, violin_xmaxvs),\n        'y': np.repeat(ys, 2),\n        'group': np.repeat(np.arange(1, len(ys)+1), 2)})\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an instantiated stat object from a geom object.", "response": "def from_geom(geom):\n        \"\"\"\n        Return an instantiated stat object\n\n        stats should not override this method.\n\n        Parameters\n        ----------\n        geom : geom\n            `geom`\n\n        Returns\n        -------\n        out : stat\n            A stat object\n\n        Raises\n        ------\n        :class:`PlotnineError` if unable to create a `stat`.\n        \"\"\"\n        name = geom.params['stat']\n        kwargs = geom._kwargs\n        # More stable when reloading modules than\n        # using issubclass\n        if (not isinstance(name, type) and\n                hasattr(name, 'compute_layer')):\n            return name\n\n        if isinstance(name, stat):\n            return name\n        elif isinstance(name, type) and issubclass(name, stat):\n            klass = name\n        elif is_string(name):\n            if not name.startswith('stat_'):\n                name = 'stat_{}'.format(name)\n            klass = Registry[name]\n        else:\n            raise PlotnineError(\n                'Unknown stat of type {}'.format(type(name)))\n\n        valid_kwargs = (\n             (klass.aesthetics() |\n              klass.DEFAULT_PARAMS.keys()) &\n             kwargs.keys())\n\n        params = {k: kwargs[k] for k in valid_kwargs}\n        return klass(geom=geom, **params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a set of all non - computed aesthetics for this stat.", "response": "def aesthetics(cls):\n        \"\"\"\n        Return a set of all non-computed aesthetics for this stat.\n\n        stats should not override this method.\n        \"\"\"\n        aesthetics = cls.REQUIRED_AES.copy()\n        calculated = get_calculated_aes(cls.DEFAULT_AES)\n        for ae in set(cls.DEFAULT_AES) - set(calculated):\n            aesthetics.add(ae)\n        return aesthetics"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining data with defaults and set aesthetics from parameters", "response": "def use_defaults(self, data):\n        \"\"\"\n        Combine data with defaults and set aesthetics from parameters\n\n        stats should not override this method.\n\n        Parameters\n        ----------\n        data : dataframe\n            Data used for drawing the geom.\n\n        Returns\n        -------\n        out : dataframe\n            Data used for drawing the geom.\n        \"\"\"\n        missing = (self.aesthetics() -\n                   self.aes_params.keys() -\n                   set(data.columns))\n\n        for ae in missing-self.REQUIRED_AES:\n            if self.DEFAULT_AES[ae] is not None:\n                data[ae] = self.DEFAULT_AES[ae]\n\n        missing = (self.aes_params.keys() -\n                   set(data.columns))\n\n        for ae in self.aes_params:\n            data[ae] = self.aes_params[ae]\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_layer(cls, data, params, layout):\n        check_required_aesthetics(\n            cls.REQUIRED_AES,\n            list(data.columns) + list(params.keys()),\n            cls.__name__)\n\n        data = remove_missing(\n            data,\n            na_rm=params.get('na_rm', False),\n            vars=list(cls.REQUIRED_AES | cls.NON_MISSING_AES),\n            name=cls.__name__,\n            finite=True)\n\n        def fn(pdata):\n            \"\"\"\n            Helper compute function\n            \"\"\"\n            # Given data belonging to a specific panel, grab\n            # the corresponding scales and call the method\n            # that does the real computation\n            if len(pdata) == 0:\n                return pdata\n            pscales = layout.get_scales(pdata['PANEL'].iat[0])\n            return cls.compute_panel(pdata, pscales, **params)\n\n        return groupby_apply(data, 'PANEL', fn)", "response": "Compute statistics for the specified object in a specific layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_panel(cls, data, scales, **params):\n        if not len(data):\n            return type(data)()\n\n        stats = []\n        for _, old in data.groupby('group'):\n            new = cls.compute_group(old, scales, **params)\n            unique = uniquecols(old)\n            missing = unique.columns.difference(new.columns)\n            u = unique.loc[[0]*len(new), missing].reset_index(drop=True)\n            # concat can have problems with empty dataframes that\n            # have an index\n            if u.empty and len(u):\n                u = type(data)()\n\n            df = pd.concat([new, u], axis=1)\n            stats.append(df)\n\n        stats = pd.concat(stats, axis=0, ignore_index=True)\n\n        # Note: If the data coming in has columns with non-unique\n        # values with-in group(s), this implementation loses the\n        # columns. Individual stats may want to do some preparation\n        # before then fall back on this implementation or override\n        # it completely.\n        return stats", "response": "Compute the stats of all the groups and the related ones."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kde_scipy(data, grid, **kwargs):\n    kde = gaussian_kde(data.T, **kwargs)\n    return kde.evaluate(grid.T)", "response": "Kernel Density Estimation with Scipy s kde function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kde_statsmodels_u(data, grid, **kwargs):\n    kde = KDEUnivariate(data)\n    kde.fit(**kwargs)\n    return kde.evaluate(grid)", "response": "Univariate Kernel Density Estimation with Statsmodels\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction to compute a multivariate Kernel Density Estimation with Statsmodels", "response": "def kde_statsmodels_m(data, grid, **kwargs):\n    \"\"\"\n    Multivariate Kernel Density Estimation with Statsmodels\n\n    Parameters\n    ----------\n    data : numpy.array\n        Data points used to compute a density estimator. It\n        has `n x p` dimensions, representing n points and p\n        variables.\n    grid : numpy.array\n        Data points at which the desity will be estimated. It\n        has `m x p` dimensions, representing m points and p\n        variables.\n\n    Returns\n    -------\n    out : numpy.array\n        Density estimate. Has `m x 1` dimensions\n    \"\"\"\n    kde = KDEMultivariate(data, **kwargs)\n    return kde.pdf(grid)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kde_sklearn(data, grid, **kwargs):\n    kde_skl = KernelDensity(**kwargs)\n    kde_skl.fit(data)\n    # score_samples() returns the log-likelihood of the samples\n    log_pdf = kde_skl.score_samples(grid)\n    return np.exp(log_pdf)", "response": "Kernel Density Estimation with Scikit - learn"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kde(data, grid, package, **kwargs):\n    if package == 'statsmodels':\n        package = 'statsmodels-m'\n    func = KDE_FUNCS[package]\n    return func(data, grid, **kwargs)", "response": "Compute the kernel density estimate of a set of data points at which the desity will be estimated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_var_type(col):\n    if pdtypes.is_numeric_dtype(col):\n        # continuous\n        return 'c'\n    elif pdtypes.is_categorical_dtype(col):\n        # ordered or unordered\n        return 'o' if col.cat.ordered else 'u'\n    else:\n        # unordered if unsure, e.g string columns that\n        # are not categorical\n        return 'u'", "response": "Returns the type of the column as a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndodging overlapping interval Assumes that each set has the same horizontal position.", "response": "def strategy(data, params):\n        \"\"\"\n        Dodge overlapping interval\n\n        Assumes that each set has the same horizontal position.\n        \"\"\"\n        width = params['width']\n        with suppress(TypeError):\n            iter(width)\n            width = np.asarray(width)\n            width = width[data.index]\n\n        udata_group = data['group'].drop_duplicates()\n\n        n = params.get('n', None)\n        if n is None:\n            n = len(udata_group)\n        if n == 1:\n            return data\n\n        if not all([col in data.columns for col in ['xmin', 'xmax']]):\n            data['xmin'] = data['x']\n            data['xmax'] = data['x']\n\n        d_width = np.max(data['xmax'] - data['xmin'])\n\n        # Have a new group index from 1 to number of groups.\n        # This might be needed if the group numbers in this set don't\n        # include all of 1:n\n        udata_group = udata_group.sort_values()\n        groupidx = match(data['group'], udata_group)\n        groupidx = np.asarray(groupidx) + 1\n\n        # Find the center for each group, then use that to\n        # calculate xmin and xmax\n        data['x'] = data['x'] + width * ((groupidx - 0.5) / n - 0.5)\n        data['xmin'] = data['x'] - (d_width / n) / 2\n        data['xmax'] = data['x'] + (d_width / n) / 2\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_grid_facets(facets):\n    valid_seqs = [\"('var1', '.')\", \"('var1', 'var2')\",\n                  \"('.', 'var1')\", \"((var1, var2), (var3, var4))\"]\n    error_msg_s = (\"Valid sequences for specifying 'facets' look like\"\n                   \" {}\".format(valid_seqs))\n\n    valid_forms = ['var1 ~ .', 'var1 ~ var2', '. ~ var1',\n                   'var1 + var2 ~ var3 + var4',\n                   '. ~ func(var1) + func(var2)',\n                   '. ~ func(var1+var3) + func(var2)'\n                   ] + valid_seqs\n    error_msg_f = (\"Valid formula for 'facet_grid' look like\"\n                   \" {}\".format(valid_forms))\n\n    if isinstance(facets, (tuple, list)):\n        if len(facets) != 2:\n            raise PlotnineError(error_msg_s)\n\n        rows, cols = facets\n\n        if isinstance(rows, str):\n            rows = [] if rows == '.' else [rows]\n        if isinstance(cols, str):\n            cols = [] if cols == '.' else [cols]\n\n        return rows, cols\n\n    if not isinstance(facets, str):\n        raise PlotnineError(error_msg_f)\n\n    # Example of allowed formulae\n    # 'c ~ a + b'\n    # '. ~ func(a) + func(b)'\n    # 'func(c) ~ func(a+1) + func(b+2)'\n    try:\n        lhs, rhs = facets.split('~')\n    except ValueError:\n        raise PlotnineError(error_msg_s)\n    else:\n        lhs = lhs.strip()\n        rhs = rhs.strip()\n\n    lhs = ensure_var_or_dot(lhs)\n    rhs = ensure_var_or_dot(rhs)\n\n    lsplitter = ' + ' if ' + ' in lhs else '+'\n    rsplitter = ' + ' if ' + ' in rhs else '+'\n\n    if lhs == '.':\n        rows = []\n    else:\n        rows = [var.strip() for var in lhs.split(lsplitter)]\n\n    if rhs == '.':\n        cols = []\n    else:\n        cols = [var.strip() for var in rhs.split(rsplitter)]\n\n    return rows, cols", "response": "Parse facetting variables in a grid of facetting variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_label(self, layout_info, ax):\n        toprow = layout_info['ROW'] == 1\n        rightcol = layout_info['COL'] == self.ncol\n\n        if toprow and len(self.cols):\n            label_info = layout_info[list(self.cols)]\n            label_info._meta = {'dimension': 'cols'}\n            label_info = self.labeller(label_info)\n            self.draw_strip_text(label_info, 'top', ax)\n\n        if rightcol and len(self.rows):\n            label_info = layout_info[list(self.rows)]\n            label_info._meta = {'dimension': 'rows'}\n            label_info = self.labeller(label_info)\n            self.draw_strip_text(label_info, 'right', ax)", "response": "Draw facet label onto the axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexpands a single scale.", "response": "def expand_default(self, scale, discrete=(0, 0.6, 0, 0.6),\n                       continuous=(0.05, 0, 0.05, 0)):\n        \"\"\"\n        Expand a single scale\n        \"\"\"\n        if is_waive(scale.expand):\n            if isinstance(scale, scale_discrete):\n                return discrete\n            elif isinstance(scale, scale_continuous):\n                return continuous\n            else:\n                name = scale.__class__.__name__\n                msg = \"Failed to expand scale '{}'\".format(name)\n                raise PlotnineError(msg)\n        else:\n            return scale.expand"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict_to_table(header, contents):\n    def to_text(row):\n        name, value = row\n        m = max_col1_size + 1 - len(name)\n        spacing = ' ' * m\n\n        return ''.join([name, spacing, value])\n\n    thead = tuple(str(col) for col in header)\n    rows = []\n    for name, value in contents.items():\n        # code highlighting\n        if value != '':\n            if isinstance(value, str):\n                value = \"'{}'\".format(value)\n            value = ':py:`{}`'.format(value)\n        rows.append((name, value))\n\n    n = np.max([len(header[0])] +\n               [len(col1) for col1, _ in rows])\n    hborder = tuple('='*n for col in header)\n    rows = [hborder, thead, hborder] + rows + [hborder]\n    max_col1_size = np.max([len(col1) for col1, _ in rows])\n    table = '\\n'.join([to_text(row) for row in rows])\n    return table", "response": "Convert dict to table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a signature for a geom or stat", "response": "def make_signature(name, params, common_params, common_param_values):\n    \"\"\"\n    Create a signature for a geom or stat\n\n    Gets the DEFAULT_PARAMS (params) and creates are comma\n    separated list of the `name=value` pairs. The common_params\n    come first in the list, and they get take their values from\n    either the params-dict or the common_geom_param_values-dict.\n    \"\"\"\n    tokens = []\n    seen = set()\n\n    def tokens_append(key, value):\n        if isinstance(value, str):\n            value = \"'{}'\".format(value)\n        tokens.append('{}={}'.format(key, value))\n\n    # preferred params come first\n    for key in common_params:\n        seen.add(key)\n        try:\n            value = params[key]\n        except KeyError:\n            value = common_param_values[key]\n        tokens_append(key, value)\n\n    # other params (these are the geom/stat specific parameters\n    for key in (set(params) - seen):\n        tokens_append(key, params[key])\n\n    # name, 1 opening bracket, 4 spaces in SIGNATURE_TPL\n    s1 = name + '('\n    s2 = ', '.join(tokens) + ', **kwargs)'\n    line_width = 78 - len(s1)\n    indent_spaces = ' ' * (len(s1) + 4)\n    newline_and_space = '\\n' + indent_spaces\n    s2_lines = wrap(s2, width=line_width)\n    return s1 + newline_and_space.join(s2_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef docstring_section_lines(docstring, section_name):\n    lines = []\n    inside_section = False\n    underline = '-' * len(section_name)\n    expect_underline = False\n    for line in docstring.splitlines():\n        _line = line.strip().lower()\n\n        if expect_underline:\n            expect_underline = False\n            if _line == underline:\n                inside_section = True\n                continue\n\n        if _line == section_name:\n            expect_underline = True\n        elif _line in DOCSTRING_SECTIONS:\n            # next section\n            break\n        elif inside_section:\n            lines.append(line)\n    return '\\n'.join(lines)", "response": "Returns a section of a numpydoc string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a param section to a dict.", "response": "def parameters_str_to_dict(param_section):\n    \"\"\"\n    Convert a param section to a dict\n\n    Parameters\n    ----------\n    param_section : str\n        Text in the parameter section\n\n    Returns\n    -------\n    d : OrderedDict\n        Dictionary of the parameters in the order that they\n        are described in the parameters section. The dict\n        is of the form ``{param: all_parameter_text}``.\n        You can reconstruct the ``param_section`` from the\n        keys of the dictionary.\n\n    See Also\n    --------\n    :func:`parameters_dict_to_str`\n    \"\"\"\n    d = OrderedDict()\n    previous_param = None\n    param_desc = None\n    for line in param_section.split('\\n'):\n        param = param_spec(line)\n        if param:\n            if previous_param:\n                d[previous_param] = '\\n'.join(param_desc)\n            param_desc = [line]\n            previous_param = param\n        elif param_desc:\n            param_desc.append(line)\n\n    if previous_param:\n        d[previous_param] = '\\n'.join(param_desc)\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a structured documentation for the geometry.", "response": "def document_geom(geom):\n    \"\"\"\n    Create a structured documentation for the geom\n\n    It replaces `{usage}`, `{common_parameters}` and\n    `{aesthetics}` with generated documentation.\n    \"\"\"\n    # Dedented so that it lineups (in sphinx) with the part\n    # generated parts when put together\n    docstring = dedent(geom.__doc__)\n\n    # usage\n    signature = make_signature(geom.__name__,\n                               geom.DEFAULT_PARAMS,\n                               common_geom_params,\n                               common_geom_param_values)\n    usage = GEOM_SIGNATURE_TPL.format(signature=signature)\n\n    # aesthetics\n    contents = OrderedDict(('**{}**'.format(ae), '')\n                           for ae in sorted(geom.REQUIRED_AES))\n    if geom.DEFAULT_AES:\n        d = geom.DEFAULT_AES.copy()\n        d['group'] = ''  # All geoms understand the group aesthetic\n        contents.update(sorted(d.items()))\n\n    table = dict_to_table(('Aesthetic', 'Default value'), contents)\n    aesthetics_table = AESTHETICS_TABLE_TPL.format(table=table)\n    tpl = dedent(geom._aesthetics_doc.lstrip('\\n'))\n    aesthetics_doc = tpl.format(aesthetics_table=aesthetics_table)\n    aesthetics_doc = indent(aesthetics_doc, ' '*4)\n\n    # common_parameters\n    d = geom.DEFAULT_PARAMS\n    common_parameters = GEOM_PARAMS_TPL.format(\n        default_stat=d['stat'],\n        default_position=d['position'],\n        default_na_rm=d['na_rm'],\n        default_inherit_aes=d.get('inherit_aes', True),\n        _aesthetics_doc=aesthetics_doc,\n        **common_params_doc)\n\n    docstring = docstring.replace('{usage}', usage)\n    docstring = docstring.replace('{common_parameters}',\n                                  common_parameters)\n    geom.__doc__ = docstring\n    return geom"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a structured documentation for the stat object", "response": "def document_stat(stat):\n    \"\"\"\n    Create a structured documentation for the stat\n\n    It replaces `{usage}`, `{common_parameters}` and\n    `{aesthetics}` with generated documentation.\n    \"\"\"\n    # Dedented so that it lineups (in sphinx) with the part\n    # generated parts when put together\n    docstring = dedent(stat.__doc__)\n\n    # usage:\n    signature = make_signature(stat.__name__,\n                               stat.DEFAULT_PARAMS,\n                               common_stat_params,\n                               common_stat_param_values)\n    usage = STAT_SIGNATURE_TPL.format(signature=signature)\n\n    # aesthetics\n    contents = OrderedDict(('**{}**'.format(ae), '')\n                           for ae in sorted(stat.REQUIRED_AES))\n    contents.update(sorted(stat.DEFAULT_AES.items()))\n    table = dict_to_table(('Aesthetic', 'Default value'), contents)\n    aesthetics_table = AESTHETICS_TABLE_TPL.format(table=table)\n    tpl = dedent(stat._aesthetics_doc.lstrip('\\n'))\n    aesthetics_doc = tpl.format(aesthetics_table=aesthetics_table)\n    aesthetics_doc = indent(aesthetics_doc, ' '*4)\n\n    # common_parameters\n    d = stat.DEFAULT_PARAMS\n    common_parameters = STAT_PARAMS_TPL.format(\n            default_geom=d['geom'],\n            default_position=d['position'],\n            default_na_rm=d['na_rm'],\n            _aesthetics_doc=aesthetics_doc,\n            **common_params_doc)\n\n    docstring = docstring.replace('{usage}', usage)\n    docstring = docstring.replace('{common_parameters}',\n                                  common_parameters)\n    stat.__doc__ = docstring\n    return stat"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a documentation for a scale class.", "response": "def document_scale(cls):\n    \"\"\"\n    Create a documentation for a scale\n\n    Import the superclass parameters\n\n    It replaces `{superclass_parameters}` with the documentation\n    of the parameters from the superclass.\n\n    Parameters\n    ----------\n    cls : type\n        A scale class\n\n    Returns\n    -------\n    cls : type\n        The scale class with a modified docstring.\n    \"\"\"\n    params_list = []\n    # Get set of cls params\n    cls_param_string = docstring_parameters_section(cls)\n    cls_param_dict = parameters_str_to_dict(cls_param_string)\n    cls_params = set(cls_param_dict.keys())\n\n    for i, base in enumerate(cls.__bases__):\n        # Get set of base class params\n        base_param_string = param_string = docstring_parameters_section(base)\n        base_param_dict = parameters_str_to_dict(base_param_string)\n        base_params = set(base_param_dict.keys())\n\n        # Remove duplicate params from the base class\n        duplicate_params = base_params & cls_params\n        for param in duplicate_params:\n            del base_param_dict[param]\n\n        if duplicate_params:\n            param_string = parameters_dict_to_str(base_param_dict)\n\n        # Accumulate params of base case\n        if i == 0:\n            # Compensate for the indentation of the\n            # {superclass_parameters} string\n            param_string = param_string.strip()\n        params_list.append(param_string)\n\n        # Prevent the next base classes from bringing in the\n        # same parameters.\n        cls_params |= base_params\n\n    # Fill in the processed superclass parameters\n    superclass_parameters = '\\n'.join(params_list)\n    cls.__doc__ = cls.__doc__.format(\n        superclass_parameters=superclass_parameters)\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef document(cls):\n    if cls.__doc__ is None:\n        return cls\n\n    baseclass_name = cls.mro()[-2].__name__\n\n    try:\n        return DOC_FUNCTIONS[baseclass_name](cls)\n    except KeyError:\n        return cls", "response": "Decorator to document a class"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave multiple plots to a PDF file.", "response": "def save_as_pdf_pages(plots, filename=None, path=None, verbose=True, **kwargs):\n    \"\"\"\n    Save multiple :class:`ggplot` objects to a PDF file, one per page.\n\n    Parameters\n    ----------\n    plots : collection or generator of :class:`ggplot`\n        Plot objects to write to file. `plots` may be either a\n        collection such as a :py:class:`list` or :py:class:`set`:\n\n        >>> base_plot = ggplot(\u2026)\n        >>> plots = [base_plot + ggtitle('%d of 3' % i) for i in range(1, 3)]\n        >>> save_as_pdf_pages(plots)\n\n        or, a generator that yields :class:`ggplot` objects:\n\n        >>> def myplots():\n        >>>     for i in range(1, 3):\n        >>>         yield ggplot(\u2026) + ggtitle('%d of 3' % i)\n        >>> save_as_pdf_pages(myplots())\n\n    filename : :py:class:`str`, optional\n        File name to write the plot to. If not specified, a name\n        like \u201cplotnine-save-<hash>.pdf\u201d is used.\n    path : :py:class:`str`, optional\n        Path to save plot to (if you just want to set path and\n        not filename).\n    verbose : :py:class:`bool`\n        If ``True``, print the saving information.\n    kwargs : :py:class:`dict`\n        Additional arguments to pass to\n        :py:meth:`matplotlib.figure.Figure.savefig`.\n\n    Notes\n    -----\n    Using pandas' :meth:`~pandas.DataFrame.groupby` methods, tidy data\n    can be \u201cfaceted\u201d across pages:\n\n    >>> from plotnine.data import mtcars\n    >>> def facet_pages(column)\n    >>>     base_plot = [\n    >>>         aes(x='wt', y='mpg', label='name'),\n    >>>         geom_text(),\n    >>>         ]\n    >>>     for label, group_data in mtcars.groupby(column):\n    >>>         yield ggplot(group_data) + base_plot + ggtitle(label)\n    >>> save_as_pdf_pages(facet_pages('cyl'))\n\n    Unlike :meth:`ggplot.save`, :meth:`save_as_pdf_pages` does not\n    process arguments for `height` or `width`. To set the figure size,\n    add :class:`~plotnine.themes.themeable.figure_size` to the theme\n    for some or all of the objects in `plots`:\n\n    >>> plot = ggplot(\u2026)\n    >>> # The following are equivalent\n    >>> plot.save('filename.pdf', height=6, width=8)\n    >>> save_as_pdf_pages([plot + theme(figure_size=(8, 6))])\n    \"\"\"\n    from itertools import chain\n\n    from matplotlib.backends.backend_pdf import PdfPages\n\n    # as in ggplot.save()\n    fig_kwargs = {'bbox_inches': 'tight'}\n    fig_kwargs.update(kwargs)\n\n    figure = [None]\n\n    # If plots is already an iterator, this is a no-op; otherwise convert a\n    # list, etc. to an iterator\n    plots = iter(plots)\n    peek = []\n\n    # filename, depends on the object\n    if filename is None:\n        # Take the first element from the iterator, store it, and use it to\n        # generate a file name\n        peek = [next(plots)]\n        filename = peek[0]._save_filename('pdf')\n\n    if path:\n        filename = os.path.join(path, filename)\n\n    if verbose:\n        warn('Filename: {}'.format(filename), PlotnineWarning)\n\n    with PdfPages(filename) as pdf:\n        # Re-add the first element to the iterator, if it was removed\n        for plot in chain(peek, plots):\n            try:\n                fig = figure[0] = plot.draw()\n\n                # as in ggplot.save()\n                facecolor = fig.get_facecolor()\n                edgecolor = fig.get_edgecolor()\n                if edgecolor:\n                    fig_kwargs['facecolor'] = facecolor\n                if edgecolor:\n                    fig_kwargs['edgecolor'] = edgecolor\n                    fig_kwargs['frameon'] = True\n\n                # Save as a page in the PDF file\n                pdf.savefig(figure[0], **fig_kwargs)\n            except AttributeError as err:\n                msg = 'non-ggplot object of %s: %s' % (type(plot), plot)\n                raise TypeError(msg) from err\n            except Exception:\n                raise\n            finally:\n                # Close the figure whether or not there was an exception, to\n                # conserve memory when plotting a large number of pages\n                figure[0] and plt.close(figure[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _draw_using_figure(self, figure, axs):\n        self = deepcopy(self)\n        self._build()\n\n        self.theme = self.theme or theme_get()\n        self.figure = figure\n        self.axs = axs\n\n        try:\n            with mpl.rc_context():\n                self.theme.apply_rcparams()\n                self._setup_parameters()\n                self._draw_layers()\n                self._draw_facet_labels()\n                self._draw_legend()\n                self._apply_theme()\n        except Exception as err:\n            if self.figure is not None:\n                plt.close(self.figure)\n            raise err\n\n        return self", "response": "Draw onto a figure and axes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the ggplot object for rendering.", "response": "def _build(self):\n        \"\"\"\n        Build ggplot for rendering.\n\n        Notes\n        -----\n        This method modifies the ggplot object. The caller is\n        responsible for making a copy and using that to make\n        the method call.\n        \"\"\"\n        if not self.layers:\n            self += geom_blank()\n\n        self.layout = Layout()\n        layers = self.layers\n        scales = self.scales\n        layout = self.layout\n\n        # Give each layer a copy of the data that it will need\n        layers.generate_data(self.data)\n\n        # Initialise panels, add extra data for margins & missing\n        # facetting variables, and add on a PANEL variable to data\n        layout.setup(layers, self)\n\n        # Compute aesthetics to produce data with generalised\n        # variable names\n        layers.compute_aesthetics(self)\n\n        # Transform data using all scales\n        layers.transform(scales)\n\n        # Map and train positions so that statistics have access\n        # to ranges and all positions are numeric\n        layout.train_position(layers, scales.x, scales.y)\n        layout.map_position(layers)\n\n        # Apply and map statistics\n        layers.compute_statistic(layout)\n        layers.map_statistic(self)\n\n        # Make sure missing (but required) aesthetics are added\n        scales.add_missing(('x', 'y'))\n\n        # Prepare data in geoms\n        # e.g. from y and width to ymin and ymax\n        layers.setup_data()\n\n        # Apply position adjustments\n        layers.compute_position(layout)\n\n        # Reset position scales, then re-train and map.  This\n        # ensures that facets have control over the range of\n        # a plot.\n        layout.reset_position_scales()\n        layout.train_position(layers, scales.x, scales.y)\n        layout.map_position(layers)\n\n        # Train and map non-position scales\n        npscales = scales.non_position_scales()\n        if len(npscales):\n            layers.train(npscales)\n            layers.map(npscales)\n\n        # Train coordinate system\n        layout.setup_panel_params(self.coordinates)\n\n        # fill in the defaults\n        layers.use_defaults()\n\n        # Allow stats to modify the layer data\n        layers.finish_statistics()\n\n        # Allow layout to modify data before rendering\n        layout.finish_data(layers)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_figure(self):\n        # Good for development\n        if get_option('close_all_figures'):\n            plt.close('all')\n\n        figure = plt.figure()\n        axs = self.facet.make_axes(\n            figure,\n            self.layout.layout,\n            self.coordinates)\n\n        # Dictionary to collect matplotlib objects that will\n        # be targeted for theming by the themeables\n        figure._themeable = {}\n\n        self.figure = figure\n        self.axs = axs\n        return figure, axs", "response": "Create Matplotlib figure and axes for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _draw_legend(self):\n        legend_box = self.guides.build(self)\n        if not legend_box:\n            return\n\n        figure = self.figure\n        left = figure.subplotpars.left\n        right = figure.subplotpars.right\n        top = figure.subplotpars.top\n        bottom = figure.subplotpars.bottom\n        W, H = figure.get_size_inches()\n        position = self.guides.position\n        get_property = self.theme.themeables.property\n        # defaults\n        spacing = 0.1\n        strip_margin_x = 0\n        strip_margin_y = 0\n\n        with suppress(KeyError):\n            spacing = get_property('legend_box_spacing')\n        with suppress(KeyError):\n            strip_margin_x = get_property('strip_margin_x')\n        with suppress(KeyError):\n            strip_margin_y = get_property('strip_margin_y')\n\n        right_strip_width = self.facet.strip_size('right')\n        top_strip_height = self.facet.strip_size('top')\n\n        # Other than when the legend is on the right the rest of\n        # the computed x, y locations are not gauranteed not to\n        # overlap with the axes or the labels. The user must then\n        # use the legend_margin theme parameter to adjust the\n        # location. This should get fixed when MPL has a better\n        # layout manager.\n        if position == 'right':\n            loc = 6\n            pad = right_strip_width*(1+strip_margin_x) + spacing\n            x = right + pad/W\n            y = 0.5\n        elif position == 'left':\n            loc = 7\n            x = left - spacing/W\n            y = 0.5\n        elif position == 'top':\n            loc = 8\n            x = 0.5\n            pad = top_strip_height*(1+strip_margin_y) + spacing\n            y = top + pad/H\n        elif position == 'bottom':\n            loc = 9\n            x = 0.5\n            y = bottom - spacing/H\n        else:\n            loc = 10\n            x, y = position\n\n        anchored_box = AnchoredOffsetbox(\n            loc=loc,\n            child=legend_box,\n            pad=0.,\n            frameon=False,\n            bbox_to_anchor=(x, y),\n            bbox_transform=figure.transFigure,\n            borderpad=0.)\n\n        anchored_box.set_zorder(90.1)\n        self.figure._themeable['legend_background'] = anchored_box\n        ax = self.axs[0]\n        ax.add_artist(anchored_box)", "response": "Draw the legend onto the figure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _draw_labels(self):\n        # This is very laboured. Should be changed when MPL\n        # finally has a constraint based layout manager.\n        figure = self.figure\n        get_property = self.theme.themeables.property\n\n        try:\n            margin = get_property('axis_title_x', 'margin')\n        except KeyError:\n            pad_x = 5\n        else:\n            pad_x = margin.get_as('t', 'pt')\n\n        try:\n            margin = get_property('axis_title_y', 'margin')\n        except KeyError:\n            pad_y = 5\n        else:\n            pad_y = margin.get_as('r', 'pt')\n\n        # Get the axis labels (default or specified by user)\n        # and let the coordinate modify them e.g. flip\n        labels = self.coordinates.labels({\n            'x': self.layout.xlabel(self.labels),\n            'y': self.layout.ylabel(self.labels)\n        })\n\n        # The first axes object is on left, and the last axes object\n        # is at the bottom. We change the transform so that the relevant\n        # coordinate is in figure coordinates. This way we take\n        # advantage of how MPL adjusts the label position so that they\n        # do not overlap with the tick text. This works well for\n        # facetting with scales='fixed' and also when not facetting.\n        # first_ax = self.axs[0]\n        # last_ax = self.axs[-1]\n\n        xlabel = self.facet.last_ax.set_xlabel(\n            labels['x'], labelpad=pad_x)\n        ylabel = self.facet.first_ax.set_ylabel(\n            labels['y'], labelpad=pad_y)\n\n        xlabel.set_transform(mtransforms.blended_transform_factory(\n            figure.transFigure, mtransforms.IdentityTransform()))\n        ylabel.set_transform(mtransforms.blended_transform_factory(\n            mtransforms.IdentityTransform(), figure.transFigure))\n\n        figure._themeable['axis_title_x'] = xlabel\n        figure._themeable['axis_title_y'] = ylabel", "response": "Draw x and y labels onto the figure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _draw_title(self):\n        # This is very laboured. Should be changed when MPL\n        # finally has a constraint based layout manager.\n        figure = self.figure\n        title = self.labels.get('title', '')\n        rcParams = self.theme.rcParams\n        get_property = self.theme.themeables.property\n\n        # Pick suitable values in inches and convert them to\n        # transFigure dimension. This gives fixed spacing\n        # margins which work for oblong plots.\n        top = figure.subplotpars.top\n        W, H = figure.get_size_inches()\n\n        # Adjust the title to avoid overlap with the facet\n        # labels on the top row\n        # pad/H is inches in transFigure coordinates. A fixed\n        # margin value in inches prevents oblong plots from\n        # getting unpredictably large spaces.\n        try:\n            fontsize = get_property('plot_title', 'size')\n        except KeyError:\n            fontsize = float(rcParams.get('font.size', 12))\n\n        try:\n            linespacing = get_property('plot_title', 'linespacing')\n        except KeyError:\n            linespacing = 1.2\n\n        try:\n            margin = get_property('plot_title', 'margin')\n        except KeyError:\n            pad = 0.09\n        else:\n            pad = margin.get_as('b', 'in')\n\n        try:\n            strip_margin_x = get_property('strip_margin_x')\n        except KeyError:\n            strip_margin_x = 0\n\n        line_size = fontsize / 72.27\n        num_lines = len(title.split('\\n'))\n        title_size = line_size * linespacing * num_lines\n        strip_height = self.facet.strip_size('top')\n        # vertical adjustment\n        strip_height *= (1 + strip_margin_x)\n\n        x = 0.5\n        y = top + (strip_height+title_size/2+pad)/H\n\n        text = figure.text(x, y, title, ha='center', va='center')\n        figure._themeable['plot_title'] = text", "response": "Draw the title onto the figure."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies theme attributes to Matplotlib objects", "response": "def _apply_theme(self):\n        \"\"\"\n        Apply theme attributes to Matplotlib objects\n        \"\"\"\n        self.theme.apply_axs(self.axs)\n        self.theme.apply_figure(self.figure)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _save_filename(self, ext):\n        hash_token = abs(self.__hash__())\n        return 'plotnine-save-{}.{}'.format(hash_token, ext)", "response": "Returns the filename used by the save method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, filename=None, format=None, path=None,\n             width=None, height=None, units='in',\n             dpi=None, limitsize=True, verbose=True, **kwargs):\n        \"\"\"\n        Save a ggplot object as an image file\n\n        Parameters\n        ----------\n        filename : str, optional\n            File name to write the plot to. If not specified, a name\n            like \u201cplotnine-save-<hash>.<format>\u201d is used.\n        format : str\n            Image format to use, automatically extract from\n            file name extension.\n        path : str\n            Path to save plot to (if you just want to set path and\n            not filename).\n        width : number, optional\n            Width (defaults to value set by the theme). If specified\n            the `height` must also be given.\n        height : number, optional\n            Height (defaults to value set by the theme). If specified\n            the `width` must also be given.\n        units : str\n            Units for width and height when either one is explicitly\n            specified (in, cm, or mm).\n        dpi : float\n            DPI to use for raster graphics. If None, defaults to using\n            the `dpi` of theme, if none is set then a `dpi` of 100.\n        limitsize : bool\n            If ``True`` (the default), ggsave will not save images\n            larger than 50x50 inches, to prevent the common error\n            of specifying dimensions in pixels.\n        verbose : bool\n            If ``True``, print the saving information.\n        kwargs : dict\n            Additional arguments to pass to matplotlib `savefig()`.\n        \"\"\"\n        fig_kwargs = {'bbox_inches': 'tight',  # 'tight' is a good default\n                      'format': format}\n        fig_kwargs.update(kwargs)\n\n        figure = [None]  # nonlocal\n\n        # filename, depends on the object\n        if filename is None:\n            ext = format if format else 'pdf'\n            filename = self._save_filename(ext)\n\n        if path:\n            filename = os.path.join(path, filename)\n\n        # Preserve the users object\n        self = deepcopy(self)\n\n        # theme\n        self.theme = self.theme or theme_get()\n\n        # The figure size should be known by the theme\n        if width is not None and height is not None:\n            width = to_inches(width, units)\n            height = to_inches(height, units)\n            self += theme(figure_size=(width, height))\n        elif (width is None and height is not None or\n              width is not None and height is None):\n            raise PlotnineError(\n                \"You must specify both width and height\")\n\n        width, height = self.theme.themeables.property('figure_size')\n\n        if limitsize and (width > 25 or height > 25):\n            raise PlotnineError(\n                \"Dimensions (width={}, height={}) exceed 25 inches \"\n                \"(height and width are specified in inches/cm/mm, \"\n                \"not pixels). If you are sure you want these \"\n                \"dimensions, use 'limitsize=False'.\".format(width, height))\n\n        if dpi is None:\n            try:\n                self.theme.themeables.property('dpi')\n            except KeyError:\n                self.theme = self.theme + theme(dpi=100)\n        else:\n            self.theme = self.theme + theme(dpi=dpi)\n\n        if verbose:\n            warn(\"Saving {0} x {1} {2} image.\".format(\n                 from_inches(width, units),\n                 from_inches(height, units), units), PlotnineWarning)\n            warn('Filename: {}'.format(filename), PlotnineWarning)\n\n        # Helper function so that we can clean up when it fails\n        def _save():\n            fig = figure[0] = self.draw()\n\n            # savefig ignores the figure face & edge colors\n            facecolor = fig.get_facecolor()\n            edgecolor = fig.get_edgecolor()\n            if edgecolor:\n                fig_kwargs['facecolor'] = facecolor\n            if edgecolor:\n                fig_kwargs['edgecolor'] = edgecolor\n                fig_kwargs['frameon'] = True\n\n            fig.savefig(filename, **fig_kwargs)\n\n        try:\n            _save()\n        except Exception as err:\n            figure[0] and plt.close(figure[0])\n            raise err\n        else:\n            figure[0] and plt.close(figure[0])", "response": "Save a ggplot object as an image file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfitting OLS and WLS to data and predict the level of the log likelihood of the OLS or WLS.", "response": "def lm(data, xseq, **params):\n    \"\"\"\n    Fit OLS / WLS if data has weight\n    \"\"\"\n    X = sm.add_constant(data['x'])\n    Xseq = sm.add_constant(xseq)\n\n    if 'weight' in data:\n        init_kwargs, fit_kwargs = separate_method_kwargs(\n            params['method_args'], sm.WLS, sm.WLS.fit)\n        model = sm.WLS(data['y'], X, weights=data['weight'], **init_kwargs)\n    else:\n        init_kwargs, fit_kwargs = separate_method_kwargs(\n            params['method_args'], sm.OLS, sm.OLS.fit)\n        model = sm.OLS(data['y'], X, **init_kwargs)\n\n    results = model.fit(**fit_kwargs)\n    data = pd.DataFrame({'x': xseq})\n    data['y'] = results.predict(Xseq)\n\n    if params['se']:\n        alpha = 1 - params['level']\n        prstd, iv_l, iv_u = wls_prediction_std(\n            results, Xseq, alpha=alpha)\n        data['se'] = prstd\n        data['ymin'] = iv_l\n        data['ymax'] = iv_u\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits RLM to data and predict the data.", "response": "def rlm(data, xseq, **params):\n    \"\"\"\n    Fit RLM\n    \"\"\"\n    X = sm.add_constant(data['x'])\n    Xseq = sm.add_constant(xseq)\n\n    init_kwargs, fit_kwargs = separate_method_kwargs(\n        params['method_args'], sm.RLM, sm.RLM.fit)\n    model = sm.RLM(data['y'], X, **init_kwargs)\n    results = model.fit(**fit_kwargs)\n\n    data = pd.DataFrame({'x': xseq})\n    data['y'] = results.predict(Xseq)\n\n    if params['se']:\n        warnings.warn(\"Confidence intervals are not yet implemented\"\n                      \"for RLM smoothing.\", PlotnineWarning)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfitting GLM to data and return the result", "response": "def glm(data, xseq, **params):\n    \"\"\"\n    Fit GLM\n    \"\"\"\n    X = sm.add_constant(data['x'])\n    Xseq = sm.add_constant(xseq)\n\n    init_kwargs, fit_kwargs = separate_method_kwargs(\n        params['method_args'], sm.GLM, sm.GLM.fit)\n    model = sm.GLM(data['y'], X, **init_kwargs)\n    results = model.fit(**fit_kwargs)\n\n    data = pd.DataFrame({'x': xseq})\n    data['y'] = results.predict(Xseq)\n\n    if params['se']:\n        prediction = results.get_prediction(Xseq)\n        ci = prediction.conf_int(1 - params['level'])\n        data['ymin'] = ci[:, 0]\n        data['ymax'] = ci[:, 1]\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gpr(data, xseq, **params):\n    try:\n        from sklearn import gaussian_process\n    except ImportError:\n        raise PlotnineError(\n            \"To use gaussian process smoothing, \"\n            \"You need to install scikit-learn.\")\n\n    kwargs = params['method_args']\n    if not kwargs:\n        warnings.warn(\n            \"See sklearn.gaussian_process.GaussianProcessRegressor \"\n            \"for parameters to pass in as 'method_args'\", PlotnineWarning)\n\n    regressor = gaussian_process.GaussianProcessRegressor(**kwargs)\n    X = np.atleast_2d(data['x']).T\n    n = len(data)\n    Xseq = np.atleast_2d(xseq).T\n    regressor.fit(X, data['y'])\n\n    data = pd.DataFrame({'x': xseq})\n    if params['se']:\n        y, stderr = regressor.predict(Xseq, return_std=True)\n        data['y'] = y\n        data['se'] = stderr\n        data['ymin'], data['ymax'] = tdist_ci(\n            y, n-1, stderr, params['level'])\n    else:\n        data['y'] = regressor.predict(Xseq, return_std=True)\n\n    return data", "response": "Fit gaussian process to data and predict the next term"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tdist_ci(x, df, stderr, level):\n    q = (1 + level)/2\n    delta = stats.t.ppf(q, df) * stderr\n    return x - delta, x + delta", "response": "tdist_ci - Compute Confidence Intervals using the t - distribution\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating standard deviation and confidence interval Applies to WLS and OLS, not to general GLS, that is independently but not identically distributed observations Parameters ---------- res : regression result instance results of WLS or OLS regression required attributes see notes exog : array_like (optional) exogenous variables for points to predict weights : scalar or array_like (optional) weights as defined for WLS (inverse of variance of observation) alpha : float (default: alpha = 0.05) confidence level for two-sided hypothesis Returns ------- predstd : array_like, 1d standard error of prediction same length as rows of exog interval_l, interval_u : array_like lower und upper confidence bounds Notes ----- The result instance needs to have at least the following res.model.predict() : predicted values or res.fittedvalues : values used in estimation res.cov_params() : covariance matrix of parameter estimates If exog is 1d, then it is interpreted as one observation, i.e. a row vector. testing status: not compared with other packages References ---------- Greene p.111 for OLS, extended to WLS by analogy", "response": "def wls_prediction_std(res, exog=None, weights=None, alpha=0.05,\n                       interval='confidence'):\n    \"\"\"\n    calculate standard deviation and confidence interval\n\n    Applies to WLS and OLS, not to general GLS,\n    that is independently but not identically distributed observations\n\n    Parameters\n    ----------\n    res : regression result instance\n        results of WLS or OLS regression required attributes see notes\n    exog : array_like (optional)\n        exogenous variables for points to predict\n    weights : scalar or array_like (optional)\n        weights as defined for WLS (inverse of variance of observation)\n    alpha : float (default: alpha = 0.05)\n        confidence level for two-sided hypothesis\n\n    Returns\n    -------\n    predstd : array_like, 1d\n        standard error of prediction\n        same length as rows of exog\n    interval_l, interval_u : array_like\n        lower und upper confidence bounds\n\n    Notes\n    -----\n    The result instance needs to have at least the following\n    res.model.predict() : predicted values or\n    res.fittedvalues : values used in estimation\n    res.cov_params() : covariance matrix of parameter estimates\n\n    If exog is 1d, then it is interpreted as one observation,\n    i.e. a row vector.\n\n    testing status: not compared with other packages\n\n    References\n    ----------\n    Greene p.111 for OLS, extended to WLS by analogy\n    \"\"\"\n    # work around current bug:\n    #    fit doesn't attach results to model, predict broken\n    # res.model.results\n\n    covb = res.cov_params()\n    if exog is None:\n        exog = res.model.exog\n        predicted = res.fittedvalues\n        if weights is None:\n            weights = res.model.weights\n    else:\n        exog = np.atleast_2d(exog)\n        if covb.shape[1] != exog.shape[1]:\n            raise ValueError('wrong shape of exog')\n        predicted = res.model.predict(res.params, exog)\n        if weights is None:\n            weights = 1.\n        else:\n            weights = np.asarray(weights)\n            if weights.size > 1 and len(weights) != exog.shape[0]:\n                raise ValueError('weights and exog do not have matching shape')\n\n    # full covariance:\n    # predvar = res3.mse_resid + np.diag(np.dot(X2,np.dot(covb,X2.T)))\n    # predication variance only\n    predvar = res.mse_resid/weights\n    ip = (exog * np.dot(covb, exog.T).T).sum(1)\n    if interval == 'confidence':\n        predstd = np.sqrt(ip)\n    elif interval == 'prediction':\n        predstd = np.sqrt(ip + predvar)\n\n    tppf = stats.t.isf(alpha/2., res.df_resid)\n    interval_u = predicted + tppf * predstd\n    interval_l = predicted - tppf * predstd\n    return predstd, interval_l, interval_u"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a layout for the panels that will have the data for each item in the plot.", "response": "def setup(self, layers, plot):\n        \"\"\"\n        Create a layout for the panels\n\n        The layout is a dataframe that stores all the\n        structual information about the panels that will\n        make up the plot. The actual layout depends on\n        the type of facet.\n\n        This method ensures that each layer has a copy of the\n        data it needs in `layer.data`. That data is also has\n        column `PANEL` that indicates the panel onto which each\n        data row/item will be plotted.\n        \"\"\"\n        data = [l.data for l in layers]\n\n        # setup facets\n        self.facet = plot.facet\n        self.facet.setup_params(data)\n        data = self.facet.setup_data(data)\n\n        # setup coords\n        self.coord = plot.coordinates\n        self.coord.setup_params(data)\n        data = self.coord.setup_data(data)\n\n        # Generate panel layout\n        data = self.facet.setup_data(data)\n        self.layout = self.facet.compute_layout(data)\n        self.layout = self.coord.setup_layout(self.layout)\n        self.check_layout()\n\n        # Map the data to the panels\n        for layer, ldata in zip(layers, data):\n            layer.data = self.facet.map(ldata, self.layout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntraining the position of the panels.", "response": "def train_position(self, layers, x_scale, y_scale):\n        \"\"\"\n        Create all the required x & y panel_scales y_scales\n        and set the ranges for each scale according to the data.\n\n        Notes\n        -----\n        The number of x or y scales depends on the facetting,\n        particularly the scales parameter. e.g if `scales='free'`\n        then each panel will have separate x and y scales, and\n        if `scales='fixed'` then all panels will share an x\n        scale and a y scale.\n        \"\"\"\n        layout = self.layout\n        if self.panel_scales_x is None and x_scale:\n            result = self.facet.init_scales(layout, x_scale, None)\n            self.panel_scales_x = result.x\n\n        if self.panel_scales_y is None and y_scale:\n            result = self.facet.init_scales(layout, None, y_scale)\n            self.panel_scales_y = result.y\n\n        self.facet.train_position_scales(self, layers)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_scales(self, i):\n        # wrapping with np.asarray prevents an exception\n        # on some datasets\n        bool_idx = (np.asarray(self.layout['PANEL']) == i)\n        xsc = None\n        ysc = None\n\n        if self.panel_scales_x:\n            idx = self.layout.loc[bool_idx, 'SCALE_X'].values[0]\n            xsc = self.panel_scales_x[idx-1]\n\n        if self.panel_scales_y:\n            idx = self.layout.loc[bool_idx, 'SCALE_Y'].values[0]\n            ysc = self.panel_scales_y[idx-1]\n\n        return types.SimpleNamespace(x=xsc, y=ysc)", "response": "Return x & y scales for panel i."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset x and y scales", "response": "def reset_position_scales(self):\n        \"\"\"\n        Reset x and y scales\n        \"\"\"\n        if not self.facet.shrink:\n            return\n\n        with suppress(AttributeError):\n            self.panel_scales_x.reset()\n\n        with suppress(AttributeError):\n            self.panel_scales_y.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the x & y range & breaks information for each panel Parameters ---------- coord : coord Coordinate", "response": "def setup_panel_params(self, coord):\n        \"\"\"\n        Calculate the x & y range & breaks information for each panel\n\n        Parameters\n        ----------\n        coord : coord\n            Coordinate\n        \"\"\"\n        if not self.panel_scales_x:\n            raise PlotnineError('Missing an x scale')\n\n        if not self.panel_scales_y:\n            raise PlotnineError('Missing a y scale')\n\n        self.panel_params = []\n        cols = ['SCALE_X', 'SCALE_Y']\n        for i, j in self.layout[cols].itertuples(index=False):\n            i, j = i-1, j-1\n            params = coord.setup_panel_params(\n                self.panel_scales_x[i],\n                self.panel_scales_y[j])\n            self.panel_params.append(params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef finish_data(self, layers):\n        for layer in layers:\n            layer.data = self.facet.finish_data(layer.data, self)", "response": "Modify data before it is drawn out by the geom\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xlabel(self, labels):\n        if self.panel_scales_x[0].name is not None:\n            return self.panel_scales_x[0].name\n        else:\n            return labels.get('x', '')", "response": "Determine x - axis label for a specific set of labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines the y - axis label for a set of labels.", "response": "def ylabel(self, labels):\n        \"\"\"\n        Determine x-axis label\n\n        Parameters\n        ----------\n        labels : dict\n            Labels as specified by the user through the ``labs`` or\n            ``ylab`` calls.\n\n        Returns\n        -------\n        out : str\n            y-axis label\n        \"\"\"\n        if self.panel_scales_y[0].name is not None:\n            return self.panel_scales_y[0].name\n        else:\n            return labels.get('y', '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws watermark Matplolib figure on which to draw", "response": "def draw(self, figure):\n        \"\"\"\n        Draw watermark\n\n        Parameters\n        ----------\n        figure : Matplotlib.figure.Figure\n            Matplolib figure on which to draw\n        \"\"\"\n        X = mimage.imread(self.filename)\n        figure.figimage(X, **self.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the default value for a key.", "response": "def _default(self, key, default=None):\n        \"\"\"\n        Lookup value of *key* themeable\n\n        If *key* not in themeable or value is None,\n        return the *default* value.\n        \"\"\"\n        try:\n            value = self.theme.themeables.property(key)\n        except KeyError:\n            value = None\n\n        return value if value is not None else default"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the default values for drawing guide and other properties.", "response": "def _set_defaults(self):\n        \"\"\"\n        Set configuration parameters for drawing guide\n        \"\"\"\n        valid_locations = {'top', 'bottom', 'left', 'right'}\n        horizontal_locations = {'left', 'right'}\n        get_property = self.theme.themeables.property\n        margin_location_lookup = {'t': 'b', 'b': 't',\n                                  'l': 'r', 'r': 'l'}\n\n        # label position\n        self.label_position = self.label_position or 'right'\n        if self.label_position not in valid_locations:\n            msg = \"label position '{}' is invalid\"\n            raise PlotnineError(msg.format(self.label_position))\n\n        # label margin\n        # legend_text_legend or legend_text_colorbar\n        name = 'legend_text_{}'.format(\n            self.__class__.__name__.split('_')[-1])\n        loc = margin_location_lookup[self.label_position[0]]\n        try:\n            margin = get_property(name, 'margin')\n        except KeyError:\n            self._label_margin = 3\n        else:\n            self._label_margin = margin.get_as(loc, 'pt')\n\n        # direction of guide\n        if self.direction is None:\n            if self.label_position in horizontal_locations:\n                self.direction = 'vertical'\n            else:\n                self.direction = 'horizontal'\n\n        # title position\n        if self.title_position is None:\n            if self.direction == 'vertical':\n                self.title_position = 'top'\n            elif self.direction == 'horizontal':\n                self.title_position = 'left'\n        if self.title_position not in valid_locations:\n            msg = \"title position '{}' is invalid\"\n            raise PlotnineError(msg.format(self.title_position))\n\n        # title alignment\n        tmp = 'left' if self.direction == 'vertical' else 'center'\n        self._title_align = self._default('legend_title_align', tmp)\n\n        # by default, direction of each guide depends on\n        # the position all the guides\n        try:\n            position = get_property('legend_position')\n        except KeyError:\n            position = 'right'\n\n        if position in {'top', 'bottom'}:\n            tmp = 'horizontal'\n        else:  # left, right, (default)\n            tmp = 'vertical'\n        self.direction = self._default('legend_direction', tmp)\n\n        # title margin\n        loc = margin_location_lookup[self.title_position[0]]\n        try:\n            margin = get_property('legend_title', 'margin')\n        except KeyError:\n            self._title_margin = 8\n        else:\n            self._title_margin = margin.get_as(loc, 'pt')\n\n        # legend_margin\n        try:\n            self._legend_margin = get_property('legend_margin')\n        except KeyError:\n            self._legend_margin = 10\n\n        # legend_entry_spacing\n        try:\n            self._legend_entry_spacing_x = get_property(\n                'legend_entry_spacing_x')\n        except KeyError:\n            self._legend_entry_spacing_x = 5\n\n        try:\n            self._legend_entry_spacing_y = get_property(\n                'legend_entry_spacing_y')\n        except KeyError:\n            self._legend_entry_spacing_y = 2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef legend_aesthetics(self, layer, plot):\n        l = layer\n        legend_ae = set(self.key.columns) - {'label'}\n        all_ae = (l.mapping.keys() |\n                  (plot.mapping if l.inherit_aes else set()) |\n                  l.stat.DEFAULT_AES.keys())\n        geom_ae = l.geom.REQUIRED_AES | l.geom.DEFAULT_AES.keys()\n        matched = all_ae & geom_ae & legend_ae\n        matched = list(matched - set(l.geom.aes_params))\n        return matched", "response": "Returns the aesthetics that contribute to the legend."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef train_df(self, df):\n        aesthetics = sorted(set(self.aesthetics) & set(df.columns))\n        for ae in aesthetics:\n            self.train(df[ae])", "response": "Train scale from a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps a dataframe of aesthetics to a new aesthetics", "response": "def map_df(self, df):\n        \"\"\"\n        Map df\n        \"\"\"\n        if len(df) == 0:\n            return\n\n        aesthetics = set(self.aesthetics) & set(df.columns)\n        for ae in aesthetics:\n            df[ae] = self.map(df[ae])\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(context=\"notebook\", style=\"darkgrid\", palette=\"deep\",\n        font=\"sans-serif\", font_scale=1, color_codes=False, rc=None):\n    \"\"\"Set aesthetic parameters in one step.\n    Each set of parameters can be set directly or temporarily, see the\n    referenced functions below for more information.\n    Parameters\n    ----------\n    context : string or dict\n        Plotting context parameters, see :func:`plotting_context`\n    style : string or dict\n        Axes style parameters, see :func:`axes_style`\n    palette : string or sequence\n        Color palette, see :func:`color_palette`\n    font : string\n        Font family, see matplotlib font manager.\n    font_scale : float, optional\n        Separate scaling factor to independently scale the size of the\n        font elements.\n    color_codes : bool\n        If ``True`` and ``palette`` is a seaborn palette, remap the shorthand\n        color codes (e.g. \"b\", \"g\", \"r\", etc.) to the colors from this palette.\n    rc : dict or None\n        Dictionary of rc parameter mappings to override the above.\n    \"\"\"\n    mpl.rcParams = {}\n    set_context(context, font_scale)\n    set_style(style, rc={\"font.family\": font})\n    if rc is not None:\n        mpl.rcParams.update(rc)\n    return mpl.rcParams", "response": "Set the parameters of the aesthetic parameters in one step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef axes_style(style=None, rc=None):\n    if style is None:\n        style_dict = {k: mpl.rcParams[k] for k in _style_keys}\n\n    elif isinstance(style, dict):\n        style_dict = style\n\n    else:\n        styles = [\"white\", \"dark\", \"whitegrid\", \"darkgrid\", \"ticks\"]\n        if style not in styles:\n            raise ValueError(\"style must be one of %s\" % \", \".join(styles))\n\n        # Define colors here\n        dark_gray = \".15\"\n        light_gray = \".8\"\n\n        # Common parameters\n        style_dict = {\n            \"figure.facecolor\": \"white\",\n            \"text.color\": dark_gray,\n            \"axes.labelcolor\": dark_gray,\n            \"legend.frameon\": False,\n            \"legend.numpoints\": 1,\n            \"legend.scatterpoints\": 1,\n            \"xtick.direction\": \"out\",\n            \"ytick.direction\": \"out\",\n            \"xtick.color\": dark_gray,\n            \"ytick.color\": dark_gray,\n            \"axes.axisbelow\": True,\n            \"image.cmap\": \"Greys\",\n            \"font.family\": [\"sans-serif\"],\n            \"font.sans-serif\": [\"Arial\", \"Liberation Sans\",\n                                \"Bitstream Vera Sans\", \"sans-serif\"],\n            \"grid.linestyle\": \"-\",\n            \"lines.solid_capstyle\": \"round\",\n            }\n\n        # Set grid on or off\n        if \"grid\" in style:\n            style_dict.update({\n                \"axes.grid\": True,\n                })\n        else:\n            style_dict.update({\n                \"axes.grid\": False,\n                })\n\n        # Set the color of the background, spines, and grids\n        if style.startswith(\"dark\"):\n            style_dict.update({\n                \"axes.facecolor\": \"#EAEAF2\",\n                \"axes.edgecolor\": \"white\",\n                \"axes.linewidth\": 0,\n                \"grid.color\": \"white\",\n                })\n\n        elif style == \"whitegrid\":\n            style_dict.update({\n                \"axes.facecolor\": \"white\",\n                \"axes.edgecolor\": light_gray,\n                \"axes.linewidth\": 1,\n                \"grid.color\": light_gray,\n                })\n\n        elif style in [\"white\", \"ticks\"]:\n            style_dict.update({\n                \"axes.facecolor\": \"white\",\n                \"axes.edgecolor\": dark_gray,\n                \"axes.linewidth\": 1.25,\n                \"grid.color\": light_gray,\n                })\n\n        # Show or hide the axes ticks\n        if style == \"ticks\":\n            style_dict.update({\n                \"xtick.major.size\": 6,\n                \"ytick.major.size\": 6,\n                \"xtick.minor.size\": 3,\n                \"ytick.minor.size\": 3,\n                })\n        else:\n            style_dict.update({\n                \"xtick.major.size\": 0,\n                \"ytick.major.size\": 0,\n                \"xtick.minor.size\": 0,\n                \"ytick.minor.size\": 0,\n                })\n\n    # Override these settings with the provided rc dictionary\n    if rc is not None:\n        rc = {k: v for k, v in rc.items() if k in _style_keys}\n        style_dict.update(rc)\n\n    # Wrap in an _AxesStyle object so this can be used in a with statement\n    style_object = _AxesStyle(style_dict)\n\n    return style_object", "response": "Return a parameter dict for the aesthetic style of the plots."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the aesthetic style of the plots.", "response": "def set_style(style=None, rc=None):\n    \"\"\"Set the aesthetic style of the plots.\n    This affects things like the color of the axes, whether a grid is\n    enabled by default, and other aesthetic elements.\n    Parameters\n    ----------\n    style : dict, None, or one of {darkgrid, whitegrid, dark, white, ticks}\n        A dictionary of parameters or the name of a preconfigured set.\n    rc : dict, optional\n        Parameter mappings to override the values in the preset seaborn\n        style dictionaries. This only updates parameters that are\n        considered part of the style definition.\n    Examples\n    --------\n    >>> set_style(\"whitegrid\")\n    >>> set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n    See Also\n    --------\n    axes_style : return a dict of parameters or use in a ``with`` statement\n                 to temporarily set the style.\n    set_context : set parameters to scale plot elements\n    set_palette : set the default color palette for figures\n    \"\"\"\n    style_object = axes_style(style, rc)\n    mpl.rcParams.update(style_object)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plotting_context(context=None, font_scale=1, rc=None):\n    if context is None:\n        context_dict = {k: mpl.rcParams[k] for k in _context_keys}\n\n    elif isinstance(context, dict):\n        context_dict = context\n\n    else:\n\n        contexts = [\"paper\", \"notebook\", \"talk\", \"poster\"]\n        if context not in contexts:\n            raise ValueError(\"context must be in %s\" % \", \".join(contexts))\n\n        # Set up dictionary of default parameters\n        base_context = {\n\n            \"figure.figsize\": np.array([8, 5.5]),\n            \"font.size\": 12,\n            \"axes.labelsize\": 11,\n            \"axes.titlesize\": 12,\n            \"xtick.labelsize\": 10,\n            \"ytick.labelsize\": 10,\n            \"legend.fontsize\": 10,\n\n            \"grid.linewidth\": 1,\n            \"lines.linewidth\": 1.75,\n            \"patch.linewidth\": .3,\n            \"lines.markersize\": 7,\n            \"lines.markeredgewidth\": 0,\n\n            \"xtick.major.width\": 1,\n            \"ytick.major.width\": 1,\n            \"xtick.minor.width\": .5,\n            \"ytick.minor.width\": .5,\n\n            \"xtick.major.pad\": 7,\n            \"ytick.major.pad\": 7,\n            }\n\n        # Scale all the parameters by the same factor depending on the context\n        scaling = dict(paper=.8, notebook=1, talk=1.3, poster=1.6)[context]\n        context_dict = {k: v * scaling for k, v in base_context.items()}\n\n        # Now independently scale the fonts\n        font_keys = [\"axes.labelsize\", \"axes.titlesize\", \"legend.fontsize\",\n                     \"xtick.labelsize\", \"ytick.labelsize\", \"font.size\"]\n        font_dict = {k: context_dict[k] * font_scale for k in font_keys}\n        context_dict.update(font_dict)\n\n    # Implement hack workaround for matplotlib bug\n    # See https://github.com/mwaskom/seaborn/issues/344\n    # There is a bug in matplotlib 1.4.2 that makes points invisible when\n    # they don't have an edgewidth. It will supposedly be fixed in 1.4.3.\n    if mpl.__version__ == \"1.4.2\":\n        context_dict[\"lines.markeredgewidth\"] = 0.01\n\n    # Override these settings with the provided rc dictionary\n    if rc is not None:\n        rc = {k: v for k, v in rc.items() if k in _context_keys}\n        context_dict.update(rc)\n\n    # Wrap in a _PlottingContext object so this can be used in a with statement\n    context_object = _PlottingContext(context_dict)\n\n    return context_object", "response": "Returns a parameter dictionary to scale the elements of the figure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_context(context=None, font_scale=1, rc=None):\n    context_object = plotting_context(context, font_scale, rc)\n    mpl.rcParams.update(context_object)", "response": "Set the plotting context parameters for a base context."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrains the guide for the aesthetic and a value.", "response": "def train(self, scale, aesthetic=None):\n        \"\"\"\n        Create the key for the guide\n\n        The key is a dataframe with two columns:\n            - scale name : values\n            - label : labels for each value\n\n        scale name is one of the aesthetics\n        ['x', 'y', 'color', 'fill', 'size', 'shape', 'alpha',\n         'stroke']\n\n        Returns this guide if training is successful and None\n        if it fails\n        \"\"\"\n        if aesthetic is None:\n            aesthetic = scale.aesthetics[0]\n\n        breaks = scale.get_breaks()\n        if isinstance(breaks, OrderedDict):\n            if all([np.isnan(x) for x in breaks.values()]):\n                return None\n        elif not len(breaks) or all(np.isnan(breaks)):\n            return None\n\n        with suppress(AttributeError):\n            breaks = list(breaks.keys())\n\n        key = pd.DataFrame({\n            aesthetic: scale.map(breaks),\n            'label': scale.get_labels(breaks)})\n        # Drop out-of-range values for continuous scale\n        # (should use scale$oob?)\n\n        # Currently, numpy does not deal with NA (Not available)\n        # When they are introduced, the block below should be\n        # adjusted likewise, see ggplot2, guide-lengend.r\n        if isinstance(scale, scale_continuous):\n            limits = scale.limits\n            b = np.asarray(breaks)\n            noob = np.logical_and(limits[0] <= b,\n                                  b <= limits[1])\n            key = key[noob]\n\n        if len(key) == 0:\n            return None\n\n        self.key = key\n\n        # create a hash of the important information in the guide\n        labels = ' '.join(str(x) for x in self.key['label'])\n        info = '\\n'.join([self.title, labels, str(self.direction),\n                          self.__class__.__name__])\n        self.hash = hashlib.md5(info.encode('utf-8')).hexdigest()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(self, other):\n        self.key = pd.merge(self.key, other.key)\n        duplicated = set(self.override_aes) & set(other.override_aes)\n        if duplicated:\n            warn(\"Duplicated override_aes is ignored.\", PlotnineWarning)\n        self.override_aes.update(other.override_aes)\n        for ae in duplicated:\n            del self.override_aes[ae]\n        return self", "response": "Merge two guides into this one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_geoms(self, plot):\n        def get_legend_geom(layer):\n            if hasattr(layer.geom, 'draw_legend'):\n                geom = layer.geom.__class__\n            else:\n                name = 'geom_{}'.format(layer.geom.legend_geom)\n                geom = Registry[name]\n            return geom\n\n        # A layer either contributes to the guide, or it does not. The\n        # guide entries may be ploted in the layers\n        self.glayers = []\n        for l in plot.layers:\n            exclude = set()\n            if isinstance(l.show_legend, dict):\n                l.show_legend = rename_aesthetics(l.show_legend)\n                exclude = {ae for ae, val in l.show_legend.items()\n                           if not val}\n            elif l.show_legend not in (None, True):\n                continue\n\n            matched = self.legend_aesthetics(l, plot)\n\n            # This layer does not contribute to the legend\n            if not set(matched) - exclude:\n                continue\n\n            data = self.key[matched].copy()\n            data = l.use_defaults(data)\n\n            # override.aes in guide_legend manually changes the geom\n            for ae in set(self.override_aes) & set(data.columns):\n                data[ae] = self.override_aes[ae]\n\n            geom = get_legend_geom(l)\n            data = remove_missing(\n                data, l.geom.params['na_rm'],\n                list(l.geom.REQUIRED_AES | l.geom.NON_MISSING_AES),\n                '{} legend'.format(l.geom.__class__.__name__))\n            self.glayers.append(\n                types.SimpleNamespace(geom=geom, data=data, layer=l))\n        if not self.glayers:\n            return None\n        return self", "response": "Create the geometry information for each of the layers and add them to the self. glayers attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_defaults(self):\n        guide._set_defaults(self)\n\n        nbreak = len(self.key)\n\n        # rows and columns\n        if self.nrow is not None and self.ncol is not None:\n            if guide.nrow * guide.ncol < nbreak:\n                raise PlotnineError(\n                    \"nrow x ncol need to be larger\",\n                    \"than the number of breaks\")\n\n        if self.nrow is None and self.ncol is None:\n            if self.direction == 'horizontal':\n                self.nrow = int(np.ceil(nbreak/5))\n            else:\n                self.ncol = int(np.ceil(nbreak/20))\n\n        self.nrow = self.nrow or int(np.ceil(nbreak/self.ncol))\n        self.ncol = self.ncol or int(np.ceil(nbreak/self.nrow))\n\n        # key width and key height for each legend entry\n        #\n        # Take a peak into data['size'] to make sure the\n        # legend dimensions are big enough\n        \"\"\"\n        >>> gg = ggplot(diamonds, aes(x='cut', y='clarity'))\n        >>> gg = gg + stat_sum(aes(group='cut'))\n        >>> gg + scale_size(range=(3, 25))\n\n        Note the different height sizes for the entries\n        \"\"\"\n\n        # FIXME: This should be in the geom instead of having\n        # special case conditional branches\n        def determine_side_length(initial_size):\n            default_pad = initial_size * 0.5\n            # default_pad = 0\n            size = np.ones(nbreak) * initial_size\n            for i in range(nbreak):\n                for gl in self.glayers:\n                    _size = 0\n                    pad = default_pad\n                    # Full size of object to appear in the\n                    # legend key\n                    with suppress(IndexError):\n                        if 'size' in gl.data:\n                            _size = gl.data['size'].iloc[i] * SIZE_FACTOR\n                            if 'stroke' in gl.data:\n                                _size += (2 * gl.data['stroke'].iloc[i] *\n                                          SIZE_FACTOR)\n\n                        # special case, color does not apply to\n                        # border/linewidth\n                        if issubclass(gl.geom, geom_text):\n                            pad = 0\n                            if _size < initial_size:\n                                continue\n\n                        try:\n                            # color(edgecolor) affects size(linewidth)\n                            # When the edge is not visible, we should\n                            # not expand the size of the keys\n                            if gl.data['color'].iloc[i] is not None:\n                                size[i] = np.max([_size+pad, size[i]])\n                        except KeyError:\n                            break\n\n            return size\n\n        # keysize\n        if self.keywidth is None:\n            width = determine_side_length(\n                self._default('legend_key_width', 18))\n            if self.direction == 'vertical':\n                width[:] = width.max()\n            self._keywidth = width\n        else:\n            self._keywidth = [self.keywidth]*nbreak\n\n        if self.keyheight is None:\n            height = determine_side_length(\n                self._default('legend_key_height', 18))\n            if self.direction == 'horizontal':\n                height[:] = height.max()\n            self._keyheight = height\n        else:\n            self._keyheight = [self.keyheight]*nbreak", "response": "Set the default values for the entry and legend."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw(self):\n        obverse = slice(0, None)\n        reverse = slice(None, None, -1)\n        nbreak = len(self.key)\n        themeable = self.theme.figure._themeable\n\n        # When there is more than one guide, we keep\n        # record of all of them using lists\n        if 'legend_title' not in themeable:\n            themeable['legend_title'] = []\n        if 'legend_text_legend' not in themeable:\n            themeable['legend_key'] = []\n            themeable['legend_text_legend'] = []\n\n        # title\n        title_box = TextArea(self.title, textprops=dict(color='black'))\n        themeable['legend_title'].append(title_box)\n\n        # labels\n        labels = []\n        for item in self.key['label']:\n            if isinstance(item, np.float) and np.float.is_integer(item):\n                item = np.int(item)  # 1.0 to 1\n            va = 'center' if self.label_position == 'top' else 'baseline'\n            ta = TextArea(item, textprops=dict(color='black', va=va))\n            labels.append(ta)\n            themeable['legend_text_legend'].extend(labels)\n\n        # Drawings\n        drawings = []\n        for i in range(nbreak):\n            da = ColoredDrawingArea(self._keywidth[i],\n                                    self._keyheight[i],\n                                    0, 0, color='white')\n            # overlay geoms\n            for gl in self.glayers:\n                with suppress(IndexError):\n                    data = gl.data.iloc[i]\n                    da = gl.geom.draw_legend(data, da, gl.layer)\n            drawings.append(da)\n        themeable['legend_key'].append(drawings)\n\n        # Match Drawings with labels to create the entries\n        lookup = {\n            'right': (HPacker, reverse),\n            'left': (HPacker, obverse),\n            'bottom': (VPacker, reverse),\n            'top': (VPacker, obverse)}\n        packer, slc = lookup[self.label_position]\n        entries = []\n        for d, l in zip(drawings, labels):\n            e = packer(children=[l, d][slc],\n                       sep=self._label_margin,\n                       align='center',\n                       pad=0)\n            entries.append(e)\n\n        # Put the entries together in rows or columns\n        # A chunk is either a row or a column of entries\n        # for a single legend\n        if self.byrow:\n            chunk_size, packers = self.ncol, [HPacker, VPacker]\n            sep1 = self._legend_entry_spacing_x\n            sep2 = self._legend_entry_spacing_y\n        else:\n            chunk_size, packers = self.nrow, [VPacker, HPacker]\n            sep1 = self._legend_entry_spacing_y\n            sep2 = self._legend_entry_spacing_x\n\n        if self.reverse:\n            entries = entries[::-1]\n        chunks = []\n        for i in range(len(entries)):\n            start = i*chunk_size\n            stop = start + chunk_size\n            s = islice(entries, start, stop)\n            chunks.append(list(s))\n            if stop >= len(entries):\n                break\n\n        chunk_boxes = []\n        for chunk in chunks:\n            d1 = packers[0](children=chunk,\n                            align='left',\n                            sep=sep1, pad=0,)\n            chunk_boxes.append(d1)\n\n        # Put all the entries (row & columns) together\n        entries_box = packers[1](children=chunk_boxes,\n                                 align='baseline',\n                                 sep=sep2, pad=0)\n\n        # Put the title and entries together\n        packer, slc = lookup[self.title_position]\n        children = [title_box, entries_box][slc]\n        box = packer(children=children,\n                     sep=self._title_margin,\n                     align=self._title_align,\n                     pad=self._legend_margin)\n\n        return box", "response": "Draw guide and return a matplotlib. offsetbox. Offsetbox object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn package data for the current version of the base package", "response": "def get_package_data():\n    \"\"\"\n    Return package data\n\n    For example:\n\n        {'': ['*.txt', '*.rst'],\n         'hello': ['*.msg']}\n\n    means:\n        - If any package contains *.txt or *.rst files,\n          include them\n        - And include any *.msg files found in\n          the 'hello' package, too:\n    \"\"\"\n    baseline_images = [\n        'tests/baseline_images/%s/*' % x\n        for x in os.listdir('plotnine/tests/baseline_images')]\n    csv_data = ['data/*.csv']\n    package_data = {'plotnine': baseline_images + csv_data}\n    return package_data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_all_imports():\n    import types\n    lst = [name for name, obj in globals().items()\n           if not (name.startswith('_') or\n                   name == 'absolute_import' or\n                   isinstance(obj, types.ModuleType))]\n    return lst", "response": "Returns a list of all the imports that are not in the user namespace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to create a quick plot of the aesthetic mappings.", "response": "def qplot(x=None, y=None, data=None, facets=None, margins=False,\n          geom='auto', xlim=None, ylim=None, log='', main=None,\n          xlab=None, ylab=None, asp=None, **kwargs):\n    \"\"\"\n    Quick plot\n\n    Parameters\n    ----------\n    x : str | array_like\n        x aesthetic\n    y : str | array_like\n        y aesthetic\n    data : dataframe\n        Data frame to use (optional). If not specified,\n        will create one, extracting arrays from the\n        current environment.\n    geom : str | list\n        *geom(s)* to do the drawing. If ``auto``, defaults\n        to 'point' if ``x`` and ``y`` are specified or\n        'histogram' if only ``x`` is specified.\n    xlim : tuple\n        x-axis limits\n    ylim : tuple\n        y-axis limits\n    log : str in ``{'x', 'y', 'xy'}``\n        Which variables to log transform.\n    main : str\n        Plot title\n    xlab : str\n        x-axis label\n    ylab : str\n        y-axis label\n    asp : str | float\n        The y/x aspect ratio.\n    **kwargs : dict\n        Arguments passed on to the geom.\n\n    Returns\n    -------\n    p: ggplot\n        ggplot object\n    \"\"\"\n    # Extract all recognizable aesthetic mappings from the parameters\n    # String values e.g  \"I('red')\", \"I(4)\" are not treated as mappings\n\n    environment = EvalEnvironment.capture(1)\n    aesthetics = {} if x is None else {'x': x}\n    if y is not None:\n        aesthetics['y'] = y\n\n    def is_mapping(value):\n        \"\"\"\n        Return True if value is not enclosed in I() function\n        \"\"\"\n        with suppress(AttributeError):\n            return not (value.startswith('I(') and value.endswith(')'))\n        return True\n\n    def I(value):\n        return value\n\n    I_env = EvalEnvironment([{'I': I}])\n\n    for ae in kwargs.keys() & all_aesthetics:\n        value = kwargs[ae]\n        if is_mapping(value):\n            aesthetics[ae] = value\n        else:\n            kwargs[ae] = I_env.eval(value)\n\n    # List of geoms\n    if is_string(geom):\n        geom = [geom]\n    elif isinstance(geom, tuple):\n        geom = list(geom)\n\n    if data is None:\n        data = pd.DataFrame()\n\n    # Work out plot data, and modify aesthetics, if necessary\n    def replace_auto(lst, str2):\n        \"\"\"\n        Replace all occurences of 'auto' in with str2\n        \"\"\"\n        for i, value in enumerate(lst):\n            if value == 'auto':\n                lst[i] = str2\n        return lst\n\n    if 'auto' in geom:\n        if 'sample' in aesthetics:\n            replace_auto(geom, 'qq')\n        elif y is None:\n            # If x is discrete we choose geom_bar &\n            # geom_histogram otherwise. But we need to\n            # evaluate the mapping to find out the dtype\n            env = environment.with_outer_namespace(\n                {'factor': pd.Categorical})\n\n            if isinstance(aesthetics['x'], str):\n                try:\n                    x = env.eval(aesthetics['x'], inner_namespace=data)\n                except Exception:\n                    msg = \"Could not evaluate aesthetic 'x={}'\"\n                    raise PlotnineError(msg.format(aesthetics['x']))\n            elif not hasattr(aesthetics['x'], 'dtype'):\n                x = np.asarray(aesthetics['x'])\n\n            if array_kind.discrete(x):\n                replace_auto(geom, 'bar')\n            else:\n                replace_auto(geom, 'histogram')\n\n        else:\n            if x is None:\n                if pdtypes.is_list_like(aesthetics['y']):\n                    aesthetics['x'] = range(len(aesthetics['y']))\n                    xlab = 'range(len(y))'\n                    ylab = 'y'\n                else:\n                    # We could solve the issue in layer.compute_asthetics\n                    # but it is not worth the extra complexity\n                    raise PlotnineError(\n                        \"Cannot infer how long x should be.\")\n            replace_auto(geom, 'point')\n\n    p = ggplot(aes(**aesthetics), data=data, environment=environment)\n\n    def get_facet_type(facets):\n        with suppress(PlotnineError):\n            parse_grid_facets(facets)\n            return 'grid'\n\n        with suppress(PlotnineError):\n            parse_wrap_facets(facets)\n            return 'wrap'\n\n        warn(\"Could not determine the type of faceting, \"\n             \"therefore no faceting.\", PlotnineWarning)\n        return 'null'\n\n    if facets:\n        facet_type = get_facet_type(facets)\n        if facet_type == 'grid':\n            p += facet_grid(facets, margins=margins)\n        elif facet_type == 'wrap':\n            p += facet_wrap(facets)\n        else:\n            p += facet_null()\n\n    # Add geoms\n    for g in geom:\n        geom_name = 'geom_{}'.format(g)\n        geom_klass = Registry[geom_name]\n        stat_name = 'stat_{}'.format(geom_klass.DEFAULT_PARAMS['stat'])\n        stat_klass = Registry[stat_name]\n        # find params\n        recognized = (kwargs.keys() &\n                      (geom_klass.DEFAULT_PARAMS.keys() |\n                       geom_klass.aesthetics() |\n                       stat_klass.DEFAULT_PARAMS.keys() |\n                       stat_klass.aesthetics()))\n        recognized = recognized - aesthetics.keys()\n        params = {ae: kwargs[ae] for ae in recognized}\n        p += geom_klass(**params)\n\n    # pd.Series objects have name attributes. In a dataframe, the\n    # series have the name of the column.\n    labels = {}\n    for ae in scaled_aesthetics & kwargs.keys():\n        with suppress(AttributeError):\n            labels[ae] = kwargs[ae].name\n\n    with suppress(AttributeError):\n        labels['x'] = xlab if xlab is not None else x.name\n\n    with suppress(AttributeError):\n        labels['y'] = ylab if ylab is not None else y.name\n\n    if main is not None:\n        labels['title'] = main\n\n    if 'x' in log:\n        p += scale_x_log10()\n\n    if 'y' in log:\n        p += scale_y_log10()\n\n    if labels:\n        p += labs(**labels)\n\n    if asp:\n        p += theme(aspect_ratio=asp)\n\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking the columns in df categorical", "response": "def _ordered_categories(df, categories):\n    \"\"\"\n    Make the columns in df categorical\n\n    Parameters:\n    -----------\n    categories: dict\n        Of the form {str: list},\n        where the key the column name and the value is\n        the ordered category list\n    \"\"\"\n    for col, cats in categories.items():\n        df[col] = df[col].astype(CategoricalDtype(cats, ordered=True))\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _unordered_categories(df, columns):\n    for col in columns:\n        df[col] = df[col].astype(CategoricalDtype(ordered=False))\n    return df", "response": "Make the columns in df categorical"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _rectangles_to_polygons(df):\n    n = len(df)\n\n    # Helper indexing arrays\n    xmin_idx = np.tile([True, True, False, False], n)\n    xmax_idx = ~xmin_idx\n    ymin_idx = np.tile([True, False, False, True], n)\n    ymax_idx = ~ymin_idx\n\n    # There are 2 x and 2 y values for each of xmin, xmax, ymin & ymax\n    # The positions are as layed out in the indexing arrays\n    # x and y values\n    x = np.empty(n*4)\n    y = np.empty(n*4)\n    x[xmin_idx] = df['xmin'].repeat(2)\n    x[xmax_idx] = df['xmax'].repeat(2)\n    y[ymin_idx] = df['ymin'].repeat(2)\n    y[ymax_idx] = df['ymax'].repeat(2)\n\n    # Aesthetic columns and others\n    other_cols = df.columns.difference(\n        ['x', 'y', 'xmin', 'xmax', 'ymin', 'ymax'])\n    d = {col: np.repeat(df[col].values, 4) for col in other_cols}\n    data = pd.DataFrame({\n        'x': x,\n        'y': y,\n        **d\n    })\n    return data", "response": "Convert rect data to polygons"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rename_aesthetics(obj):\n    if isinstance(obj, dict):\n        for name in obj:\n            new_name = name.replace('colour', 'color')\n            if name != new_name:\n                obj[new_name] = obj.pop(name)\n    else:\n        obj = [name.replace('colour', 'color') for name in obj]\n\n    return obj", "response": "Rename aesthetics in obj\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of the aesthetics that are calculated", "response": "def get_calculated_aes(aesthetics):\n    \"\"\"\n    Return a list of the aesthetics that are calculated\n    \"\"\"\n    calculated_aesthetics = []\n    for name, value in aesthetics.items():\n        if is_calculated_aes(value):\n            calculated_aesthetics.append(name)\n    return calculated_aesthetics"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a True if the object is calculated by the Aesthetic", "response": "def is_calculated_aes(ae):\n    \"\"\"\n    Return a True if of the aesthetics that are calculated\n\n    Parameters\n    ----------\n    ae : object\n        Aesthetic mapping\n\n    >>> is_calculated_aes('density')\n    False\n\n    >>> is_calculated_aes(4)\n    False\n\n    >>> is_calculated_aes('..density..')\n    True\n\n    >>> is_calculated_aes('stat(density)')\n    True\n\n    >>> is_calculated_aes('stat(100*density)')\n    True\n\n    >>> is_calculated_aes('100*stat(density)')\n    True\n    \"\"\"\n    if not isinstance(ae, str):\n        return False\n\n    for pattern in (STAT_RE, DOTS_RE):\n        if pattern.search(ae):\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove calc function that mark calculated aesthetics and count functions from the value.", "response": "def strip_stat(value):\n    \"\"\"\n    Remove calc function that mark calculated aesthetics\n\n    Parameters\n    ----------\n    value : object\n        Aesthetic value. In most cases this will be a string\n        but other types will pass through unmodified.\n\n    Return\n    ------\n    out : object\n        Aesthetic value with the dots removed.\n\n    >>> strip_stat('stat(density + stat(count))')\n    density + count\n\n    >>> strip_stat('stat(density) + 5')\n    density + 5\n\n    >>> strip_stat('5 + stat(func(density))')\n    5 + func(density)\n\n    >>> strip_stat('stat(func(density) + var1)')\n    func(density) + var1\n\n    >>> strip_stat('calc + var1')\n    calc + var1\n\n    >>> strip_stat(4)\n    4\n    \"\"\"\n    def strip_hanging_closing_parens(s):\n        \"\"\"\n        Remove leftover  parens\n        \"\"\"\n        # Use and integer stack to track parens\n        # and ignore leftover closing parens\n        stack = 0\n        idx = []\n        for i, c in enumerate(s):\n            if c == '(':\n                stack += 1\n            elif c == ')':\n                stack -= 1\n                if stack < 0:\n                    idx.append(i)\n                    stack = 0\n                    continue\n            yield c\n\n    with suppress(TypeError):\n        if STAT_RE.search(value):\n            value = re.sub(r'\\bstat\\(', '', value)\n            value = ''.join(strip_hanging_closing_parens(value))\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves dots from the string value.", "response": "def strip_dots(value):\n    \"\"\"\n    Remove dots(if any) that mark calculated aesthetics\n\n    Parameters\n    ----------\n    value : object\n        Aesthetic value. In most cases this will be a string\n        but other types will pass through unmodified.\n\n    Return\n    ------\n    out : object\n        Aesthetic value with the dots removed.\n    \"\"\"\n    with suppress(TypeError):\n        value = DOTS_RE.sub(r'\\1', value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_position_aes(vars_):\n    try:\n        return all([aes_to_scale(v) in {'x', 'y'} for v in vars_])\n    except TypeError:\n        return aes_to_scale(vars_) in {'x', 'y'}", "response": "Figure out if an aesthetic is a position aesthetic or not"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_labels(mapping):\n    labels = mapping.copy()\n    for ae in labels:\n        labels[ae] = strip_calculated_markers(labels[ae])\n    return labels", "response": "Convert aesthetic mapping into text labels"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_valid_aesthetic(value, ae):\n\n    if ae == 'linetype':\n        named = {'solid', 'dashed', 'dashdot', 'dotted',\n                 '_', '--', '-.', ':', 'None', ' ', ''}\n        if value in named:\n            return True\n\n        # tuple of the form (offset, (on, off, on, off, ...))\n        # e.g (0, (1, 2))\n        conditions = [isinstance(value, tuple),\n                      isinstance(value[0], int),\n                      isinstance(value[1], tuple),\n                      len(value[1]) % 2 == 0,\n                      all(isinstance(x, int) for x in value[1])]\n        if all(conditions):\n            return True\n        return False\n\n    elif ae == 'shape':\n        if isinstance(value, str):\n            return True\n\n        # tuple of the form (numsides, style, angle)\n        # where style is in the range [0, 3]\n        # e.g (4, 1, 45)\n        conditions = [isinstance(value, tuple),\n                      all(isinstance(x, int) for x in value),\n                      0 <= value[1] < 3]\n        if all(conditions):\n            return True\n        return False\n\n    elif ae in {'color', 'fill'}:\n        if isinstance(value, str):\n            return True\n        with suppress(TypeError):\n            if (isinstance(value, (tuple, list)) and\n                    all(0 <= x <= 1 for x in value)):\n                return True\n        return False\n\n    # For any other aesthetics we return False to allow\n    # for special cases to be discovered and then coded\n    # for appropriately.\n    return False", "response": "Checks if the value is a valid aesthetic."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the facetting variables in a list of facetting variables", "response": "def parse_wrap_facets(facets):\n    \"\"\"\n    Return list of facetting variables\n    \"\"\"\n    valid_forms = ['~ var1', '~ var1 + var2']\n    error_msg = (\"Valid formula for 'facet_wrap' look like\"\n                 \" {}\".format(valid_forms))\n\n    if isinstance(facets, (list, tuple)):\n        return facets\n\n    if not isinstance(facets, str):\n        raise PlotnineError(error_msg)\n\n    if '~' in facets:\n        variables_pattern = r'(\\w+(?:\\s*\\+\\s*\\w+)*|\\.)'\n        pattern = r'\\s*~\\s*{0}\\s*'.format(variables_pattern)\n        match = re.match(pattern, facets)\n        if not match:\n            raise PlotnineError(error_msg)\n\n        facets = [var.strip() for var in match.group(1).split('+')]\n    elif re.match(r'\\w+', facets):\n        # allow plain string as the variable name\n        facets = [facets]\n    else:\n        raise PlotnineError(error_msg)\n\n    return facets"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef n2mfrow(nr_plots):\n    if nr_plots <= 3:\n        nrow, ncol = nr_plots, 1\n    elif nr_plots <= 6:\n        nrow, ncol = (nr_plots + 1) // 2, 2\n    elif nr_plots <= 12:\n        nrow, ncol = (nr_plots + 2) // 3, 3\n    else:\n        nrow = int(np.ceil(np.sqrt(nr_plots)))\n        ncol = int(np.ceil(nr_plots/nrow))\n    return (nrow, ncol)", "response": "Compute the rows and columns given the number\n    of plots."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spaceout_and_resize_panels(self):\n        ncol = self.ncol\n        nrow = self.nrow\n        figure = self.figure\n        theme = self.theme\n        get_property = theme.themeables.property\n\n        left = figure.subplotpars.left\n        right = figure.subplotpars.right\n        top = figure.subplotpars.top\n        bottom = figure.subplotpars.bottom\n        top_strip_height = self.strip_size('top')\n        W, H = figure.get_size_inches()\n\n        try:\n            spacing_x = get_property('panel_spacing_x')\n        except KeyError:\n            spacing_x = 0.1\n\n        try:\n            spacing_y = get_property('panel_spacing_y')\n        except KeyError:\n            spacing_y = 0.1\n\n        try:\n            aspect_ratio = get_property('aspect_ratio')\n        except KeyError:\n            # If the panels have different limits the coordinates\n            # cannot compute a common aspect ratio\n            if not self.free['x'] and not self.free['y']:\n                aspect_ratio = self.coordinates.aspect(\n                    self.layout.panel_params[0])\n            else:\n                aspect_ratio = None\n\n        if theme.themeables.is_blank('strip_text_x'):\n            top_strip_height = 0\n\n        # Account for the vertical sliding of the strip if any\n        with suppress(KeyError):\n            strip_margin_x = get_property('strip_margin_x')\n            top_strip_height *= (1 + strip_margin_x)\n\n        # The goal is to have equal spacing along the vertical\n        # and the horizontal. We use the wspace and compute\n        # the appropriate hspace. It would be a lot easier if\n        # MPL had a better layout manager.\n\n        # width of axes and height of axes\n        w = ((right-left)*W - spacing_x*(ncol-1)) / ncol\n        h = ((top-bottom)*H - (spacing_y+top_strip_height)*(nrow-1)) / nrow\n\n        # aspect ratio changes the size of the figure\n        if aspect_ratio is not None:\n            h = w*aspect_ratio\n            H = (h*nrow + (spacing_y+top_strip_height)*(nrow-1)) / \\\n                (top-bottom)\n            figure.set_figheight(H)\n\n        # spacing\n        wspace = spacing_x/w\n        hspace = (spacing_y + top_strip_height) / h\n        figure.subplots_adjust(wspace=wspace, hspace=hspace)", "response": "Adjust the spacing between the panels and resize them if they are not spaceged."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_label(self, layout_info, ax):\n        label_info = layout_info[list(self.vars)]\n        label_info._meta = {'dimension': 'cols'}\n        label_info = self.labeller(label_info)\n        self.draw_strip_text(label_info, 'top', ax)", "response": "Draw facet label onto the axes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of the key in given units", "response": "def get_as(self, key, units='pt'):\n        \"\"\"\n        Return key in given units\n        \"\"\"\n        dpi = 72\n        size = self.element.properties.get('size', 0)\n        value = self[key]\n\n        functions = {\n            'pt-lines': lambda x: x/size,\n            'pt-in': lambda x: x/dpi,\n            'lines-pt': lambda x: x*size,\n            'lines-in': lambda x: x*size/dpi,\n            'in-pt': lambda x: x*dpi,\n            'in-lines': lambda x: x*dpi/size\n        }\n\n        if self['units'] != units:\n            conversion = '{}-{}'.format(self['units'], units)\n            try:\n                value = functions[conversion](value)\n            except ZeroDivisionError:\n                value = 0\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of the discrete columns in the DataFrame df. ignore is a list|set|tuple with the names of the columns to skip.", "response": "def discrete_columns(df, ignore):\n    \"\"\"\n    Return a list of the discrete columns in the\n    dataframe `df`. `ignore` is a list|set|tuple with the\n    names of the columns to skip.\n    \"\"\"\n    lst = []\n    for col in df:\n        if array_kind.discrete(df[col]) and (col not in ignore):\n            # Some columns are represented as object dtype\n            # but may have compound structures as values.\n            try:\n                hash(df[col].iloc[0])\n            except TypeError:\n                continue\n            lst.append(col)\n    return lst"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if value is a type we expect in a dataframe", "response": "def is_known_scalar(value):\n    \"\"\"\n    Return True if value is a type we expect in a dataframe\n    \"\"\"\n    def _is_datetime_or_timedelta(value):\n        # Using pandas.Series helps catch python, numpy and pandas\n        # versions of these types\n        return pd.Series(value).dtype.kind in ('M', 'm')\n\n    return not np.iterable(value) and (isinstance(value, numbers.Number) or\n                                       _is_datetime_or_timedelta(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a layer from a geom object.", "response": "def from_geom(geom):\n        \"\"\"\n        Create a layer given a :class:`geom`\n\n        Parameters\n        ----------\n        geom : geom\n            `geom` from which a layer will be created\n\n        Returns\n        -------\n        out : layer\n            Layer that represents the specific `geom`.\n        \"\"\"\n        kwargs = geom._kwargs\n        lkwargs = {'geom': geom,\n                   'mapping': geom.mapping,\n                   'data': geom.data,\n                   'stat': geom._stat,\n                   'position': geom._position}\n\n        for param in ('show_legend', 'inherit_aes'):\n            if param in kwargs:\n                lkwargs[param] = kwargs[param]\n            elif param in geom.DEFAULT_PARAMS:\n                lkwargs[param] = geom.DEFAULT_PARAMS[param]\n\n        return layer(**lkwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_data(self, plot_data):\n        # Each layer that does not have data gets a copy of\n        # of the ggplot.data. If the has data it is replaced\n        # by copy so that we do not alter the users data\n        if self.data is None:\n            self.data = plot_data.copy()\n        elif hasattr(self.data, '__call__'):\n            self.data = self.data(plot_data)\n            if not isinstance(self.data, pd.DataFrame):\n                raise PlotnineError(\n                    \"Data function must return a dataframe\")\n        else:\n            self.data = self.data.copy()", "response": "Generate data for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef layer_mapping(self, mapping):\n        # For certain geoms, it is useful to be able to\n        # ignore the default aesthetics and only use those\n        # set in the layer\n        if self.inherit_aes:\n            aesthetics = defaults(self.mapping, mapping)\n        else:\n            aesthetics = self.mapping\n\n        # drop aesthetic parameters or the calculated aesthetics\n        calculated = set(get_calculated_aes(aesthetics))\n        d = dict((ae, v) for ae, v in aesthetics.items()\n                 if (ae not in self.geom.aes_params) and\n                 (ae not in calculated))\n        self._active_mapping = aes(**d)\n        return self._active_mapping", "response": "Returns the aesthetic parameters that are used to generate the layer mappings for this ggplot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_aesthetics(self, plot):\n        data = self.data\n        aesthetics = self.layer_mapping(plot.mapping)\n\n        # Override grouping if set in layer.\n        with suppress(KeyError):\n            aesthetics['group'] = self.geom.aes_params['group']\n\n        env = EvalEnvironment.capture(eval_env=plot.environment)\n        env = env.with_outer_namespace({'factor': pd.Categorical})\n\n        # Using `type` preserves the subclass of pd.DataFrame\n        evaled = type(data)(index=data.index)\n\n        # If a column name is not in the data, it is evaluated/transformed\n        # in the environment of the call to ggplot\n        for ae, col in aesthetics.items():\n            if isinstance(col, str):\n                if col in data:\n                    evaled[ae] = data[col]\n                else:\n                    try:\n                        new_val = env.eval(col, inner_namespace=data)\n                    except Exception as e:\n                        raise PlotnineError(\n                            _TPL_EVAL_FAIL.format(ae, col, str(e)))\n\n                    try:\n                        evaled[ae] = new_val\n                    except Exception as e:\n                        raise PlotnineError(\n                            _TPL_BAD_EVAL_TYPE.format(\n                                ae, col, str(type(new_val)), str(e)))\n            elif pdtypes.is_list_like(col):\n                n = len(col)\n                if len(data) and n != len(data) and n != 1:\n                    raise PlotnineError(\n                        \"Aesthetics must either be length one, \" +\n                        \"or the same length as the data\")\n                # An empty dataframe does not admit a scalar value\n                elif len(evaled) and n == 1:\n                    col = col[0]\n                evaled[ae] = col\n            elif is_known_scalar(col):\n                if not len(evaled):\n                    col = [col]\n                evaled[ae] = col\n            else:\n                msg = \"Do not know how to deal with aesthetic '{}'\"\n                raise PlotnineError(msg.format(ae))\n\n        evaled_aes = aes(**dict((col, col) for col in evaled))\n        plot.scales.add_defaults(evaled, evaled_aes)\n\n        if len(data) == 0 and len(evaled) > 0:\n            # No data, and vectors suppled to aesthetics\n            evaled['PANEL'] = 1\n        else:\n            evaled['PANEL'] = data['PANEL']\n\n        self.data = add_group(evaled)", "response": "Compute the aesthetics for the current layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute & return statistics for this layer", "response": "def compute_statistic(self, layout):\n        \"\"\"\n        Compute & return statistics for this layer\n        \"\"\"\n        data = self.data\n        if not len(data):\n            return type(data)()\n\n        params = self.stat.setup_params(data)\n        data = self.stat.use_defaults(data)\n        data = self.stat.setup_data(data)\n        data = self.stat.compute_layer(data, params, layout)\n        self.data = data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps aesthetics to computed statistics", "response": "def map_statistic(self, plot):\n        \"\"\"\n        Mapping aesthetics to computed statistics\n        \"\"\"\n        data = self.data\n        if not len(data):\n            return type(data)()\n\n        # Assemble aesthetics from layer, plot and stat mappings\n        aesthetics = deepcopy(self.mapping)\n        if self.inherit_aes:\n            aesthetics = defaults(aesthetics, plot.mapping)\n\n        aesthetics = defaults(aesthetics, self.stat.DEFAULT_AES)\n\n        # The new aesthetics are those that the stat calculates\n        # and have been mapped to with dot dot notation\n        # e.g aes(y='..count..'), y is the new aesthetic and\n        # 'count' is the computed column in data\n        new = {}  # {'aesthetic_name': 'calculated_stat'}\n        stat_data = type(data)()\n        stat_namespace = dict(stat=stat)\n        env = plot.environment.with_outer_namespace(stat_namespace)\n        for ae in get_calculated_aes(aesthetics):\n            new[ae] = strip_calculated_markers(aesthetics[ae])\n            # In conjuction with the pd.concat at the end,\n            # be careful not to create duplicate columns\n            # for cases like y='..y..'\n            if new[ae] != ae:\n                stat_data[ae] = env.eval(\n                    new[ae], inner_namespace=data)\n\n        if not new:\n            return\n\n        # (see stat_spoke for one exception)\n        if self.stat.retransform:\n            stat_data = plot.scales.transform_df(stat_data)\n\n        # When there are duplicate columns, we use the computed\n        # ones in stat_data\n        columns = data.columns.difference(stat_data.columns)\n        self.data = pd.concat([data[columns], stat_data], axis=1)\n\n        # Add any new scales, if needed\n        plot.scales.add_defaults(self.data, new)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_data(self):\n        data = self.data\n        if len(data) == 0:\n            return type(data)()\n\n        data = self.geom.setup_data(data)\n\n        check_required_aesthetics(\n            self.geom.REQUIRED_AES,\n            set(data.columns) | set(self.geom.aes_params),\n            self.geom.__class__.__name__)\n\n        self.data = data", "response": "Prepare and modify data for plotting\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the position of each geometric object in concert with the other objects in the panel.", "response": "def compute_position(self, layout):\n        \"\"\"\n        Compute the position of each geometric object\n        in concert with the other objects in the panel\n        \"\"\"\n        params = self.position.setup_params(self.data)\n        data = self.position.setup_data(self.data, params)\n        data = self.position.compute_layer(data, params, layout)\n        self.data = data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw(self, layout, coord):\n        params = copy(self.geom.params)\n        params.update(self.stat.params)\n        params['zorder'] = self.zorder\n        self.data = self.geom.handle_na(self.data)\n        # At this point each layer must have the data\n        # that is created by the plot build process\n        self.geom.draw_layer(self.data, layout, coord, **params)", "response": "Draw geom\n            and draw the data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse defaults for the current object.", "response": "def use_defaults(self, data=None):\n        \"\"\"\n        Prepare/modify data for plotting\n        \"\"\"\n        if data is None:\n            data = self.data\n        return self.geom.use_defaults(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef finish_statistics(self):\n        # params = self.stat.setup_params(self.data)\n        self.stat.finish_layer(self.data, self.stat.params)", "response": "Finish statistics for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking an iterable of n times.", "response": "def make_iterable_ntimes(val, n):\n    \"\"\"\n    Return [*val*, *val*, ...] if *val* is not iterable.\n\n    If *val* is an iterable of length n, it is returned as is.\n    Strings are not recognized as iterables\n\n    Raises an exception if *val* is an iterable but has length\n    not equal to n\n    \"\"\"\n    if cbook.iterable(val) and not is_string(val):\n        if len(val) != n:\n            raise PlotnineError(\n                '`val` is an iterable of length not equal to n.')\n        return val\n    return [val] * n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match(v1, v2, nomatch=-1, incomparables=None, start=0):\n    # NOTE: This function gets called a lot. If it can\n    # be optimised, it should.\n    lookup = {}\n    for i, x in enumerate(v2):\n        if x not in lookup:\n            lookup[x] = i\n\n    if incomparables:\n        skip = set(incomparables) if incomparables else set()\n        lst = [lookup[x]+start\n               if x not in skip and x in lookup else nomatch\n               for x in v1]\n    else:\n        lst = [lookup[x]+start\n               if x in lookup else nomatch\n               for x in v1]\n    return lst", "response": "Returns a vector of the positions of the first element in v1 that matches the second element in v2."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of lists that are possible margins over the given variables.", "response": "def _margins(vars, margins=True):\n    \"\"\"\n    Figure out margining variables.\n\n    Given the variables that form the rows and\n    columns, and a set of desired margins, works\n    out which ones are possible. Variables that\n    can't be margined over are dropped silently.\n\n    Parameters\n    ----------\n    vars : list\n        variable names for rows and columns\n    margins : bool | list\n        If true, margins over all vars, otherwise\n        only those listed\n\n    Return\n    ------\n    out : list\n        All the margins to create.\n    \"\"\"\n    if margins is False:\n        return []\n\n    def fn(_vars):\n        \"The margin variables for a given row or column\"\n        # The first item is and empty list for no margins\n        dim_margins = [[]]\n        # for each wanted variable, couple it with\n        # all variables to the right\n        for i, u in enumerate(_vars):\n            if margins is True or u in margins:\n                lst = [u] + [v for v in _vars[i+1:]]\n                dim_margins.append(lst)\n        return dim_margins\n\n    # Margin variables for rows and columns\n    row_margins = fn(vars[0])\n    col_margins = fn(vars[1])\n\n    # Cross the two\n    lst = list(itertools.product(col_margins, row_margins))\n\n    # Clean up -- merge the row and column variables\n    pretty = []\n    for c, r in lst:\n        pretty.append(r + c)\n    return pretty"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_margins(df, vars, margins=True):\n    margin_vars = _margins(vars, margins)\n    if not margin_vars:\n        return df\n\n    # create margin dataframes\n    margin_dfs = [df]\n    for vlst in margin_vars[1:]:\n        dfx = df.copy()\n        for v in vlst:\n            dfx.loc[0:, v] = '(all)'\n        margin_dfs.append(dfx)\n\n    merged = pd.concat(margin_dfs, axis=0)\n    merged.reset_index(drop=True, inplace=True)\n\n    # All margin columns become categoricals. The margin indicator\n    # (all) needs to be added as the last level of the categories.\n    categories = {}\n    for v in itertools.chain(*vars):\n        col = df[v]\n        if not pdtypes.is_categorical_dtype(df[v].dtype):\n            col = pd.Categorical(df[v])\n        categories[v] = col.categories\n        if '(all)' not in categories[v]:\n            categories[v] = categories[v].insert(\n                len(categories[v]), '(all)')\n\n    for v in merged.columns.intersection(set(categories)):\n        merged[v] = merged[v].astype(\n           pdtypes.CategoricalDtype(categories[v]))\n\n    return merged", "response": "Add margins to a data frame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ninteraction(df, drop=False):\n    if len(df) == 0:\n        return []\n\n    # Special case for single variable\n    if len(df.columns) == 1:\n        return _id_var(df[df.columns[0]], drop)\n\n    # Calculate individual ids\n    ids = df.apply(_id_var, axis=0)\n    ids = ids.reindex(columns=reversed(ids.columns))\n\n    # Calculate dimensions\n    def len_unique(x):\n        return len(np.unique(x))\n    ndistinct = ids.apply(len_unique, axis=0).values\n\n    combs = np.array(\n        np.hstack([1, np.cumprod(ndistinct[:-1])]))\n    mat = np.array(ids)\n    res = (mat - 1) @ combs.T + 1\n    res = np.array(res).flatten().tolist()\n\n    if drop:\n        return _id_var(res, drop)\n    else:\n        return res", "response": "Compute a unique numeric id for each unique row in the data frame."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassigns ids to items in x.", "response": "def _id_var(x, drop=False):\n    \"\"\"\n    Assign ids to items in x. If two items\n    are the same, they get the same id.\n\n    Parameters\n    ----------\n    x : array-like\n        items to associate ids with\n    drop : bool\n        Whether to drop unused factor levels\n    \"\"\"\n    if len(x) == 0:\n        return []\n\n    categorical = pdtypes.is_categorical_dtype(x)\n\n    if categorical:\n        if drop:\n            x = x.cat.remove_unused_categories()\n            lst = list(x.cat.codes + 1)\n        else:\n            has_nan = any(np.isnan(i) for i in x if isinstance(i, float))\n            if has_nan:\n                # NaNs are -1, we give them the highest code\n                nan_code = -1\n                new_nan_code = np.max(x.cat.codes) + 1\n                lst = [val if val != nan_code else new_nan_code for val in x]\n            else:\n                lst = list(x.cat.codes + 1)\n    else:\n        try:\n            levels = np.sort(np.unique(x))\n        except TypeError:\n            # x probably has NANs\n            levels = multitype_sort(set(x))\n\n        lst = match(x, levels)\n        lst = [item + 1 for item in lst]\n\n    return lst"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\njoins keys. Given two dataframes create a unique key for each row.", "response": "def join_keys(x, y, by=None):\n    \"\"\"\n    Join keys.\n\n    Given two data frames, create a unique key for each row.\n\n    Parameters\n    -----------\n    x : dataframe\n    y : dataframe\n    by : list-like\n        Column names to join by\n\n    Returns\n    -------\n    out : dict\n        Dictionary with keys x and y. The values of both keys\n        are arrays with integer elements. Identical rows in\n        x and y dataframes would have the same key in the\n        output. The key elements start at 1.\n    \"\"\"\n    if by is None:\n        by = slice(None, None, None)\n\n    if isinstance(by, tuple):\n        by = list(by)\n\n    joint = x[by].append(y[by], ignore_index=True)\n    keys = ninteraction(joint, drop=True)\n    keys = np.asarray(keys)\n    nx, ny = len(x), len(y)\n    return {'x': keys[np.arange(nx)],\n            'y': keys[nx + np.arange(ny)]}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn unique columns in a DataFrame", "response": "def uniquecols(df):\n    \"\"\"\n    Return unique columns\n\n    This is used for figuring out which columns are\n    constant within a group\n    \"\"\"\n    bool_idx = df.apply(lambda col: len(np.unique(col)) == 1, axis=0)\n    df = df.loc[:, bool_idx].iloc[0:1, :].reset_index(drop=True)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a copy of d1 with the contents of d2 that are not in d1. d1 and d2 are dictionary like objects.", "response": "def defaults(d1, d2):\n    \"\"\"\n    Update a copy of d1 with the contents of d2 that are\n    not in d1. d1 and d2 are dictionary like objects.\n\n    Parameters\n    ----------\n    d1 : dict | dataframe\n        dict with the preferred values\n    d2 : dict | dataframe\n        dict with the default values\n\n    Returns\n    -------\n    out : dict | dataframe\n        Result of adding default values type of d1\n    \"\"\"\n    d1 = d1.copy()\n    tolist = isinstance(d2, pd.DataFrame)\n    keys = (k for k in d2 if k not in d1)\n    for k in keys:\n        if tolist:\n            d1[k] = d2[k].tolist()\n        else:\n            d1[k] = d2[k]\n\n    return d1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jitter(x, factor=1, amount=None, random_state=None):\n    if len(x) == 0:\n        return x\n\n    if random_state is None:\n        random_state = np.random\n    elif isinstance(random_state, int):\n        random_state = np.random.RandomState(random_state)\n\n    x = np.asarray(x)\n\n    try:\n        z = np.ptp(x[np.isfinite(x)])\n    except IndexError:\n        z = 0\n\n    if z == 0:\n        z = np.abs(np.min(x))\n    if z == 0:\n        z = 1\n\n    if amount is None:\n        _x = np.round(x, 3-np.int(np.floor(np.log10(z)))).astype(np.int)\n        xx = np.unique(np.sort(_x))\n        d = np.diff(xx)\n        if len(d):\n            d = d.min()\n        elif xx != 0:\n            d = xx/10.\n        else:\n            d = z/10\n        amount = factor/5. * abs(d)\n    elif amount == 0:\n        amount = factor * (z / 50.)\n\n    return x + random_state.uniform(-amount, amount, len(x))", "response": "Add a small amount of noise to the array_like object x."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pivot_apply(df, column, index, func, *args, **kwargs):\n    def _func(x):\n        return func(x, *args, **kwargs)\n\n    return df.pivot_table(column, index, aggfunc=_func)[column]", "response": "Apply a function to each group of a column and return a new dataframe with the values grouped on that column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngrouping by on columns with NaN or None values Pandas currently does not have proper support for this function.", "response": "def groupby_with_null(data, *args, **kwargs):\n    \"\"\"\n    Groupby on columns with NaN/None/Null values\n\n    Pandas currently does have proper support for\n    groupby on columns with null values. The nulls\n    are discarded and so not grouped on.\n    \"\"\"\n    by = kwargs.get('by', args[0])\n    altered_columns = {}\n\n    if not isinstance(by, (list, tuple)):\n        by = [by]\n\n    # Convert NaNs & Nones in the grouping columns\n    # to sum unique string value. And, for those\n    # columns record which rows have been converted\n    # Note: this may affect the dtype of the column,\n    # so we record the dtype too. Both these changes\n    # are undone.\n    for col in by:\n        bool_idx = pd.isnull(data[col])\n        idx = bool_idx.index[bool_idx]\n        if idx.size:\n            altered_columns[col] = (idx, data[col].dtype)\n            data.loc[idx, col] = '-*-null-*-'\n\n    # Groupby on the columns, making sure to revert back\n    # to NaN/None and the correct dtype.\n    for group, df in data.groupby(*args, **kwargs):\n        for col, (orig_idx, orig_dtype) in altered_columns.items():\n            # Indices in the grouped df that need correction\n            sub_idx = orig_idx.intersection(df[col].index)\n            # NaN/None\n            if sub_idx.size:\n                df.loc[sub_idx, col] = None\n            # dtype\n            if df[col].dtype != orig_dtype:\n                df[col] = df[col].astype(orig_dtype)\n\n        yield group, df\n\n    # Undo the NaN / None conversion and any dtype\n    # changes on the original dataframe\n    for col, (orig_idx, orig_dtype) in altered_columns.items():\n        data.loc[orig_idx, col] = None\n        if data[col].dtype != orig_dtype:\n            data[col] = data[col].astype(orig_dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an array of n line segments from two arrays x and y.", "response": "def make_line_segments(x, y, ispath=True):\n    \"\"\"\n    Return an (n x 2 x 2) array of n line segments\n\n    Parameters\n    ----------\n    x : array-like\n        x points\n    y : array-like\n        y points\n    ispath : bool\n        If True, the points represent a path from one point\n        to the next until the last. If False, then each pair\n        of successive(even-odd pair) points yields a line.\n    \"\"\"\n    if ispath:\n        x = interleave(x[:-1], x[1:])\n        y = interleave(y[:-1], y[1:])\n    elif len(x) % 2:\n        raise PlotnineError(\"Expects an even number of points\")\n\n    n = len(x) // 2\n    segments = np.reshape(list(zip(x, y)), [n, 2, 2])\n    return segments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_keys(source, destination, keys=None):\n    if keys is None:\n        keys = destination.keys()\n    for k in set(source) & set(keys):\n        destination[k] = source[k]\n    return destination", "response": "Copy keys in source to destination."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an alias of a class object.", "response": "def alias(name, class_object):\n    \"\"\"\n    Create an alias of a class object\n\n    The objective of this method is to have\n    an alias that is Registered. i.e If we have\n\n        class_b = class_a\n\n    Makes `class_b` an alias of `class_a`, but if\n    `class_a` is registered by its metaclass,\n    `class_b` is not. The solution\n\n        alias('class_b', class_a)\n\n    is equivalent to:\n\n        class_b = class_a\n        Register['class_b'] = class_a\n    \"\"\"\n    module = inspect.getmodule(class_object)\n    module.__dict__[name] = class_object\n    if isinstance(class_object, Registry):\n        Registry[name] = class_object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of valid kwargs to function func", "response": "def get_kwarg_names(func):\n    \"\"\"\n    Return a list of valid kwargs to function func\n    \"\"\"\n    sig = inspect.signature(func)\n    kwonlyargs = [p.name for p in sig.parameters.values()\n                  if p.default is not p.empty]\n    return kwonlyargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns valid kwargs to function func", "response": "def get_valid_kwargs(func, potential_kwargs):\n    \"\"\"\n    Return valid kwargs to function func\n    \"\"\"\n    kwargs = {}\n    for name in get_kwarg_names(func):\n        with suppress(KeyError):\n            kwargs[name] = potential_kwargs[name]\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy_missing_columns(df, ref_df):\n    cols = ref_df.columns.difference(df.columns)\n    _loc = ref_df.columns.get_loc\n\n    l1, l2 = len(df), len(ref_df)\n    if l1 >= l2 and l1 % l2 == 0:\n        idx = np.tile(range(l2), l1 // l2)\n    else:\n        idx = np.repeat(0, l1)\n\n    for col in cols:\n        df[col] = ref_df.iloc[idx, _loc(col)].values", "response": "Copy missing columns from df to ref_df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data_mapping_as_kwargs(args, kwargs):\n    # No need to be strict about the aesthetic superclass\n    aes = dict\n    mapping, data = aes(), None\n    aes_err = (\"Found more than one aes argument. \"\n               \"Expecting zero or one\")\n    data_err = \"More than one dataframe argument.\"\n\n    # check args #\n    for arg in args:\n        if isinstance(arg, aes) and mapping:\n            raise PlotnineError(aes_err)\n        if isinstance(arg, pd.DataFrame) and data:\n            raise PlotnineError(data_err)\n\n        if isinstance(arg, aes):\n            mapping = arg\n        elif isinstance(arg, pd.DataFrame):\n            data = arg\n        else:\n            msg = \"Unknown argument of type '{0}'.\"\n            raise PlotnineError(msg.format(type(arg)))\n\n    # check kwargs #\n    # kwargs mapping has precedence over that in args\n    if 'mapping' not in kwargs:\n        kwargs['mapping'] = mapping\n\n    if data is not None and 'data' in kwargs:\n        raise PlotnineError(data_err)\n    elif 'data' not in kwargs:\n        kwargs['data'] = data\n\n    duplicates = set(kwargs['mapping']) & set(kwargs)\n    if duplicates:\n        msg = \"Aesthetics {} specified two times.\"\n        raise PlotnineError(msg.format(duplicates))\n    return kwargs", "response": "Returns kwargs with mapping and data values as kwargs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the resolution of a 1D array - like object x", "response": "def resolution(x, zero=True):\n    \"\"\"\n    Compute the resolution of a data vector\n\n    Resolution is smallest non-zero distance between adjacent values\n\n    Parameters\n    ----------\n    x    : 1D array-like\n    zero : Boolean\n        Whether to include zero values in the computation\n\n    Result\n    ------\n    res : resolution of x\n        If x is an integer array, then the resolution is 1\n    \"\"\"\n    x = np.asarray(x)\n\n    # (unsigned) integers or an effective range of zero\n    _x = x[~np.isnan(x)]\n    _x = (x.min(), x.max())\n    if x.dtype.kind in ('i', 'u') or zero_range(_x):\n        return 1\n\n    x = np.unique(x)\n    if zero:\n        x = np.unique(np.hstack([0, x]))\n\n    return np.min(np.diff(np.sort(x)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cross_join(df1, df2):\n    if len(df1) == 0:\n        return df2\n\n    if len(df2) == 0:\n        return df1\n\n    # Add as lists so that the new index keeps the items in\n    # the order that they are added together\n    all_columns = pd.Index(list(df1.columns) + list(df2.columns))\n    df1['key'] = 1\n    df2['key'] = 1\n    return pd.merge(df1, df2, on='key').loc[:, all_columns]", "response": "Return a dataframe that is a cross between dataframes df1 and df2"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert value to inches", "response": "def to_inches(value, units):\n    \"\"\"\n    Convert value to inches\n\n    Parameters\n    ----------\n    value : float\n        Value to be converted\n    units : str\n        Units of value. Must be one of\n        `['in', 'cm', 'mm']`.\n    \"\"\"\n    lookup = {'in': lambda x: x,\n              'cm': lambda x: x/2.54,\n              'mm': lambda x: x/(2.54*10)}\n    try:\n        return lookup[units](value)\n    except KeyError:\n        raise PlotnineError(\"Unknown units '{}'\".format(units))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert value in inches to given units", "response": "def from_inches(value, units):\n    \"\"\"\n    Convert value in inches to given units\n\n    Parameters\n    ----------\n    value : float\n        Value to be converted\n    units : str\n        Units to convert value to. Must be one of\n        `['in', 'cm', 'mm']`.\n    \"\"\"\n    lookup = {'in': lambda x: x,\n              'cm': lambda x: x*2.54,\n              'mm': lambda x: x*2.54*10}\n    try:\n        return lookup[units](value)\n    except KeyError:\n        raise PlotnineError(\"Unknown units '{}'\".format(units))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log(x, base=None):\n    if base == 10:\n        return np.log10(x)\n    elif base == 2:\n        return np.log2(x)\n    elif base is None or base == np.e:\n        return np.log(x)\n    else:\n        return np.log(x)/np.log(base)", "response": "Calculates the log of the base of the logarithm of the input array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the value of a key for a given hook in hook_data.", "response": "def handle(cls, value, context, **kwargs):\n        \"\"\"Returns the value of a key for a given hook in hook_data.\n\n        Format of value:\n\n            <hook_name>::<key>\n        \"\"\"\n        try:\n            hook_name, key = value.split(\"::\")\n        except ValueError:\n            raise ValueError(\"Invalid value for hook_data: %s. Must be in \"\n                             \"<hook_name>::<key> format.\" % value)\n\n        return context.hook_data[hook_name][key]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a list of variables resolve all of them.", "response": "def resolve_variables(variables, context, provider):\n    \"\"\"Given a list of variables, resolve all of them.\n\n    Args:\n        variables (list of :class:`stacker.variables.Variable`): list of\n            variables\n        context (:class:`stacker.context.Context`): stacker context\n        provider (:class:`stacker.provider.base.BaseProvider`): subclass of the\n            base provider\n\n    \"\"\"\n    for variable in variables:\n        variable.resolve(context, provider)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the current value of the Variable.", "response": "def value(self):\n        \"\"\"Return the current value of the Variable.\n        \"\"\"\n        try:\n            return self._value.value()\n        except UnresolvedVariableValue:\n            raise UnresolvedVariable(\"<unknown>\", self)\n        except InvalidLookupConcatenation as e:\n            raise InvalidLookupCombination(e.lookup, e.lookups, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_plan(description, graph,\n               targets=None, reverse=False):\n    \"\"\"Builds a plan from a list of steps.\n    Args:\n        description (str): an arbitrary string to\n            describe the plan.\n        graph (:class:`Graph`): a list of :class:`Graph` to execute.\n        targets (list): an optional list of step names to filter the graph to.\n            If provided, only these steps, and their transitive dependencies\n            will be executed. If no targets are specified, every node in the\n            graph will be executed.\n        reverse (bool): If provided, the graph will be walked in reverse order\n            (dependencies last).\n    \"\"\"\n\n    # If we want to execute the plan in reverse (e.g. Destroy), transpose the\n    # graph.\n    if reverse:\n        graph = graph.transposed()\n\n    # If we only want to build a specific target, filter the graph.\n    if targets:\n        nodes = []\n        for target in targets:\n            for k, step in graph.steps.items():\n                if step.name == target:\n                    nodes.append(step.name)\n        graph = graph.filtered(nodes)\n\n    return Plan(description=description, graph=graph)", "response": "Builds a Plan from a list of steps."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a graph of the given list of steps.", "response": "def build_graph(steps):\n    \"\"\"Builds a graph of steps.\n    Args:\n        steps (list): a list of :class:`Step` objects to execute.\n    \"\"\"\n\n    graph = Graph()\n\n    for step in steps:\n        graph.add_step(step)\n\n    for step in steps:\n        for dep in step.requires:\n            graph.connect(step.name, dep)\n\n        for parent in step.required_by:\n            graph.connect(parent, step.name)\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n\n        stop_watcher = threading.Event()\n        watcher = None\n        if self.watch_func:\n            watcher = threading.Thread(\n                target=self.watch_func,\n                args=(self.stack, stop_watcher)\n            )\n            watcher.start()\n\n        try:\n            while not self.done:\n                self._run_once()\n        finally:\n            if watcher:\n                stop_watcher.set()\n                watcher.join()\n        return self.ok", "response": "Runs this step until it has completed successfully or been passed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the current step s status.", "response": "def set_status(self, status):\n        \"\"\"Sets the current step's status.\n        Args:\n            status (:class:`Status <Status>` object): The status to set the\n                step to.\n        \"\"\"\n        if status is not self.status:\n            logger.debug(\"Setting %s state to %s.\", self.stack.name,\n                         status.name)\n            self.status = status\n            self.last_updated = time.time()\n            if self.stack.logging:\n                log_step(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the direct dependencies of the given step", "response": "def downstream(self, step_name):\n        \"\"\"Returns the direct dependencies of the given step\"\"\"\n        return list(self.steps[dep] for dep in self.dag.downstream(step_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new version of this graph. Useful for walking in reverse.", "response": "def transposed(self):\n        \"\"\"Returns a \"transposed\" version of this graph. Useful for walking in\n        reverse.\n        \"\"\"\n        return Graph(steps=self.steps, dag=self.dag.transpose())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filtered(self, step_names):\n        return Graph(steps=self.steps, dag=self.dag.filter(step_names))", "response": "Returns a filtered version of this graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef outline(self, level=logging.INFO, message=\"\"):\n        steps = 1\n        logger.log(level, \"Plan \\\"%s\\\":\", self.description)\n        for step in self.steps:\n            logger.log(\n                level,\n                \"  - step: %s: target: \\\"%s\\\", action: \\\"%s\\\"\",\n                steps,\n                step.name,\n                step.fn.__name__,\n            )\n            steps += 1\n\n        if message:\n            logger.log(level, message)", "response": "Print an outline of the actions in the current order of the steps in the current order of the actions in the current order of the steps in the current order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, *args, **kwargs):\n        self.walk(*args, **kwargs)\n\n        failed_steps = [step for step in self.steps if step.status == FAILED]\n        if failed_steps:\n            raise PlanFailed(failed_steps)", "response": "Executes the underlying graph and raises an exception if any of the steps fail."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwalking the underlying graph in topological order.", "response": "def walk(self, walker):\n        \"\"\"Walks each step in the underlying graph, in topological order.\n\n        Args:\n            walker (func): a walker function to be passed to\n                :class:`stacker.dag.DAG` to walk the graph.\n        \"\"\"\n\n        def walk_func(step):\n            # Before we execute the step, we need to ensure that it's\n            # transitive dependencies are all in an \"ok\" state. If not, we\n            # won't execute this step.\n            for dep in self.graph.downstream(step.name):\n                if not dep.ok:\n                    step.set_status(FailedStatus(\"dependency has failed\"))\n                    return step.ok\n\n            return step.run()\n\n        return self.graph.walk(walker, walk_func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the troposphere type from the value.", "response": "def create(self, value):\n        \"\"\"Create the troposphere type from the value.\n\n        Args:\n            value (Union[dict, list]): A dictionary or list of dictionaries\n                (see class documentation for details) to use as parameters to\n                create the Troposphere type instance.\n                Each dictionary will be passed to the `from_dict` method of the\n                type.\n\n        Returns:\n            Union[list, type]: Returns the value converted to the troposphere\n                type\n\n        \"\"\"\n\n        # Explicitly check with len such that non-sequence types throw.\n        if self._optional and (value is None or len(value) == 0):\n            return None\n\n        if hasattr(self._type, 'resource_type'):\n            # Our type is a resource, so ensure we have a dict of title to\n            # parameters\n            if not isinstance(value, dict):\n                raise ValueError(\"Resources must be specified as a dict of \"\n                                 \"title to parameters\")\n            if not self._many and len(value) > 1:\n                raise ValueError(\"Only one resource can be provided for this \"\n                                 \"TroposphereType variable\")\n\n            result = [\n                self._type.from_dict(title, v) for title, v in value.items()\n            ]\n        else:\n            # Our type is for properties, not a resource, so don't use\n            # titles\n            if self._many:\n                result = [self._type.from_dict(None, v) for v in value]\n            elif not isinstance(value, dict):\n                raise ValueError(\"TroposphereType for a single non-resource\"\n                                 \"type must be specified as a dict of \"\n                                 \"parameters\")\n            else:\n                result = [self._type.from_dict(None, value)]\n\n        if self._validate:\n            for v in result:\n                v._validate_props()\n\n        return result[0] if not self._many else result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the table keys and return the order in which the stacks should be executed.", "response": "def _lookup_key_parse(table_keys):\n    \"\"\"Return the order in which the stacks should be executed.\n\n    Args:\n        dependencies (dict): a dictionary where each key should be the\n            fully qualified name of a stack whose value is an array of\n            fully qualified stack names that the stack depends on. This is\n            used to generate the order in which the stacks should be\n            executed.\n\n    Returns:\n        dict: includes a dict of lookup types with data types ('new_keys')\n              and a list of the lookups with without ('clean_table_keys')\n\n    \"\"\"\n    # we need to parse the key lookup passed in\n    regex_matcher = '\\[([^\\]]+)]'\n    valid_dynamodb_datatypes = ['M', 'S', 'N', 'L']\n    clean_table_keys = []\n    new_keys = []\n\n    for key in table_keys:\n        match = re.search(regex_matcher, key)\n        if match:\n            # the datatypes are pulled from the dynamodb docs\n            if match.group(1) in valid_dynamodb_datatypes:\n                match_val = str(match.group(1))\n                key = key.replace(match.group(0), '')\n                new_keys.append({match_val: key})\n                clean_table_keys.append(key)\n            else:\n                raise ValueError(\n                    ('Stacker does not support looking up the datatype: {}')\n                    .format(str(match.group(1))))\n        else:\n            new_keys.append({'S': key})\n            clean_table_keys.append(key)\n    key_dict = {}\n    key_dict['new_keys'] = new_keys\n    key_dict['clean_table_keys'] = clean_table_keys\n\n    return key_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a projection expression for the dynamodb lookup.", "response": "def _build_projection_expression(clean_table_keys):\n    \"\"\"Given cleaned up keys, this will return a projection expression for\n    the dynamodb lookup.\n\n    Args:\n        clean_table_keys (dict): keys without the data types attached\n\n    Returns:\n        str: A projection expression for the dynamodb lookup.\n    \"\"\"\n    projection_expression = ''\n    for key in clean_table_keys[:-1]:\n        projection_expression += ('{},').format(key)\n    projection_expression += clean_table_keys[-1]\n    return projection_expression"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a dictionary of dynamodb data (including the datatypes) and a properly structured keylist, it will return the value of the lookup Args: data (dict): the raw dynamodb data keylist(list): a list of keys to lookup. This must include the datatype Returns: various: It returns the value from the dynamodb record, and casts it to a matching python datatype", "response": "def _get_val_from_ddb_data(data, keylist):\n    \"\"\"Given a dictionary of dynamodb data (including the datatypes) and a\n    properly structured keylist, it will return the value of the lookup\n\n    Args:\n        data (dict): the raw dynamodb data\n            keylist(list): a list of keys to lookup. This must include the\n                datatype\n\n    Returns:\n        various: It returns the value from the dynamodb record, and casts it\n            to a matching python datatype\n    \"\"\"\n    next_type = None\n    # iterate through the keylist to find the matching key/datatype\n    for k in keylist:\n        for k1 in k:\n            if next_type is None:\n                data = data[k[k1]]\n            else:\n                temp_dict = data[next_type]\n                data = temp_dict[k[k1]]\n            next_type = k1\n    if next_type == 'L':\n        # if type is list, convert it to a list and return\n        return _convert_ddb_list_to_list(data[next_type])\n    if next_type == 'N':\n        # TODO: handle various types of 'number' datatypes, (e.g. int, double)\n        # if a number, convert to an int and return\n        return int(data[next_type])\n    # else, just assume its a string and return\n    return str(data[next_type])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a dynamodb list it will return a python list with the dynamodb datatypes", "response": "def _convert_ddb_list_to_list(conversion_list):\n    \"\"\"Given a dynamodb list, it will return a python list without the dynamodb\n        datatypes\n\n    Args:\n        conversion_list (dict): a dynamodb list which includes the\n            datatypes\n\n    Returns:\n        list: Returns a sanitized list without the dynamodb datatypes\n    \"\"\"\n    ret_list = []\n    for v in conversion_list:\n        for v1 in v:\n            ret_list.append(v[v1])\n    return ret_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle(cls, value, **kwargs):\n        value = read_value_from_path(value)\n        table_info = None\n        table_keys = None\n        region = None\n        table_name = None\n        if '@' in value:\n            table_info, table_keys = value.split('@', 1)\n            if ':' in table_info:\n                region, table_name = table_info.split(':', 1)\n            else:\n                table_name = table_info\n        else:\n            raise ValueError('Please make sure to include a tablename')\n\n        if not table_name:\n            raise ValueError('Please make sure to include a dynamodb table '\n                             'name')\n\n        table_lookup, table_keys = table_keys.split(':', 1)\n\n        table_keys = table_keys.split('.')\n\n        key_dict = _lookup_key_parse(table_keys)\n        new_keys = key_dict['new_keys']\n        clean_table_keys = key_dict['clean_table_keys']\n\n        projection_expression = _build_projection_expression(clean_table_keys)\n\n        # lookup the data from dynamodb\n        dynamodb = get_session(region).client('dynamodb')\n        try:\n            response = dynamodb.get_item(\n                TableName=table_name,\n                Key={\n                    table_lookup: new_keys[0]\n                },\n                ProjectionExpression=projection_expression\n            )\n        except ClientError as e:\n            if e.response['Error']['Code'] == 'ResourceNotFoundException':\n                raise ValueError(\n                    'Cannot find the dynamodb table: {}'.format(table_name))\n            elif e.response['Error']['Code'] == 'ValidationException':\n                raise ValueError(\n                    'No dynamodb record matched the partition key: '\n                    '{}'.format(table_lookup))\n            else:\n                raise ValueError('The dynamodb lookup {} had an error: '\n                                 '{}'.format(value, e))\n        # find and return the key from the dynamo data returned\n        if 'Item' in response:\n            return (_get_val_from_ddb_data(response['Item'], new_keys[1:]))\n        else:\n            raise ValueError(\n                'The dynamodb record could not be found using the following '\n                'key: {}'.format(new_keys[0]))", "response": "Get a value from a dynamodb table and return the related object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_walker(concurrency):\n    if concurrency == 1:\n        return walk\n\n    semaphore = UnlimitedSemaphore()\n    if concurrency > 1:\n        semaphore = threading.Semaphore(concurrency)\n\n    return ThreadedWalker(semaphore).walk", "response": "This function will return a function suitable for passing to\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plan(description, stack_action, context,\n         tail=None, reverse=False):\n    \"\"\"A simple helper that builds a graph based plan from a set of stacks.\n\n    Args:\n        description (str): a description of the plan.\n        action (func): a function to call for each stack.\n        context (:class:`stacker.context.Context`): a\n            :class:`stacker.context.Context` to build the plan from.\n        tail (func): an optional function to call to tail the stack progress.\n        reverse (bool): if True, execute the graph in reverse (useful for\n            destroy actions).\n\n    Returns:\n        :class:`plan.Plan`: The resulting plan object\n    \"\"\"\n\n    def target_fn(*args, **kwargs):\n        return COMPLETE\n\n    steps = [\n        Step(stack, fn=stack_action, watch_func=tail)\n        for stack in context.get_stacks()]\n\n    steps += [\n        Step(target, fn=target_fn) for target in context.get_targets()]\n\n    graph = build_graph(steps)\n\n    return build_plan(\n        description=description,\n        graph=graph,\n        targets=context.stack_names,\n        reverse=reverse)", "response": "A simple helper that builds a graph based plan from a set of stacks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stack_template_key_name(blueprint):\n    name = blueprint.name\n    return \"stack_templates/%s/%s-%s.json\" % (blueprint.context.get_fqn(name),\n                                              name,\n                                              blueprint.version)", "response": "Produce an appropriate key name for a given blueprint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an s3 url for a given blueprint.", "response": "def stack_template_url(bucket_name, blueprint, endpoint):\n    \"\"\"Produces an s3 url for a given blueprint.\n\n    Args:\n        bucket_name (string): The name of the S3 bucket where the resulting\n            templates are stored.\n        blueprint (:class:`stacker.blueprints.base.Blueprint`): The blueprint\n            object to create the URL to.\n        endpoint (string): The s3 endpoint used for the bucket.\n\n    Returns:\n        string: S3 URL.\n    \"\"\"\n    key_name = stack_template_key_name(blueprint)\n    return \"%s/%s/%s\" % (endpoint, bucket_name, key_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that the CloudFormation bucket exists.", "response": "def ensure_cfn_bucket(self):\n        \"\"\"The CloudFormation bucket where templates will be stored.\"\"\"\n        if self.bucket_name:\n            ensure_s3_bucket(self.s3_conn,\n                             self.bucket_name,\n                             self.bucket_region)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef s3_stack_push(self, blueprint, force=False):\n        key_name = stack_template_key_name(blueprint)\n        template_url = self.stack_template_url(blueprint)\n        try:\n            template_exists = self.s3_conn.head_object(\n                Bucket=self.bucket_name, Key=key_name) is not None\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == '404':\n                template_exists = False\n            else:\n                raise\n\n        if template_exists and not force:\n            logger.debug(\"Cloudformation template %s already exists.\",\n                         template_url)\n            return template_url\n        self.s3_conn.put_object(Bucket=self.bucket_name,\n                                Key=key_name,\n                                Body=blueprint.rendered,\n                                ServerSideEncryption='AES256',\n                                ACL='bucket-owner-full-control')\n        logger.debug(\"Blueprint %s pushed to %s.\", blueprint.name,\n                     template_url)\n        return template_url", "response": "Pushes the rendered blueprint s template to S3."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_provider(self, stack):\n        return self.provider_builder.build(region=stack.region,\n                                           profile=stack.profile)", "response": "Builds a provider suitable for the given stack."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a ZIP file in - memory from a list of files.", "response": "def _zip_files(files, root):\n    \"\"\"Generates a ZIP file in-memory from a list of files.\n\n    Files will be stored in the archive with relative names, and have their\n    UNIX permissions forced to 755 or 644 (depending on whether they are\n    user-executable in the source filesystem).\n\n    Args:\n        files (list[str]): file names to add to the archive, relative to\n            ``root``.\n        root (str): base directory to retrieve files from.\n\n    Returns:\n        str: content of the ZIP file as a byte string.\n        str: A calculated hash of all the files.\n\n    \"\"\"\n    zip_data = StringIO()\n    with ZipFile(zip_data, 'w', ZIP_DEFLATED) as zip_file:\n        for fname in files:\n            zip_file.write(os.path.join(root, fname), fname)\n\n        # Fix file permissions to avoid any issues - only care whether a file\n        # is executable or not, choosing between modes 755 and 644 accordingly.\n        for zip_entry in zip_file.filelist:\n            perms = (zip_entry.external_attr & ZIP_PERMS_MASK) >> 16\n            if perms & stat.S_IXUSR != 0:\n                new_perms = 0o755\n            else:\n                new_perms = 0o644\n\n            if new_perms != perms:\n                logger.debug(\"lambda: fixing perms: %s: %o => %o\",\n                             zip_entry.filename, perms, new_perms)\n                new_attr = ((zip_entry.external_attr & ~ZIP_PERMS_MASK) |\n                            (new_perms << 16))\n                zip_entry.external_attr = new_attr\n\n    contents = zip_data.getvalue()\n    zip_data.close()\n    content_hash = _calculate_hash(files, root)\n\n    return contents, content_hash"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the hash of the given files at the given root.", "response": "def _calculate_hash(files, root):\n    \"\"\" Returns a hash of all of the given files at the given root.\n\n    Args:\n        files (list[str]): file names to include in the hash calculation,\n            relative to ``root``.\n        root (str): base directory to analyze files in.\n\n    Returns:\n        str: A hash of the hashes of the given files.\n    \"\"\"\n    file_hash = hashlib.md5()\n    for fname in sorted(files):\n        f = os.path.join(root, fname)\n        file_hash.update((fname + \"\\0\").encode())\n        with open(f, \"rb\") as fd:\n            for chunk in iter(lambda: fd.read(4096), \"\"):\n                if not chunk:\n                    break\n                file_hash.update(chunk)\n            file_hash.update(\"\\0\".encode())\n\n    return file_hash.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind files inside a directory based on include and exclude rules.", "response": "def _find_files(root, includes, excludes, follow_symlinks):\n    \"\"\"List files inside a directory based on include and exclude rules.\n\n    This is a more advanced version of `glob.glob`, that accepts multiple\n    complex patterns.\n\n    Args:\n        root (str): base directory to list files from.\n        includes (list[str]): inclusion patterns. Only files matching those\n            patterns will be included in the result.\n        excludes (list[str]): exclusion patterns. Files matching those\n            patterns will be excluded from the result. Exclusions take\n            precedence over inclusions.\n        follow_symlinks (bool): If true, symlinks will be included in the\n            resulting zip file\n\n    Yields:\n        str: a file name relative to the root.\n\n    Note:\n        Documentation for the patterns can be found at\n        http://www.aviser.asia/formic/doc/index.html\n    \"\"\"\n\n    root = os.path.abspath(root)\n    file_set = formic.FileSet(\n        directory=root, include=includes,\n        exclude=excludes, symlinks=follow_symlinks,\n    )\n\n    for filename in file_set.qualified_files(absolute=False):\n        yield filename"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _zip_from_file_patterns(root, includes, excludes, follow_symlinks):\n    logger.info('lambda: base directory: %s', root)\n\n    files = list(_find_files(root, includes, excludes, follow_symlinks))\n    if not files:\n        raise RuntimeError('Empty list of files for Lambda payload. Check '\n                           'your include/exclude options for errors.')\n\n    logger.info('lambda: adding %d files:', len(files))\n\n    for fname in files:\n        logger.debug('lambda: + %s', fname)\n\n    return _zip_files(files, root)", "response": "Generates a ZIP file in - memory from file search patterns."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves information about an object in S3 if it exists.", "response": "def _head_object(s3_conn, bucket, key):\n    \"\"\"Retrieve information about an object in S3 if it exists.\n\n    Args:\n        s3_conn (botocore.client.S3): S3 connection to use for operations.\n        bucket (str): name of the bucket containing the key.\n        key (str): name of the key to lookup.\n\n    Returns:\n        dict: S3 object information, or None if the object does not exist.\n            See the AWS documentation for explanation of the contents.\n\n    Raises:\n        botocore.exceptions.ClientError: any error from boto3 other than key\n            not found is passed through.\n    \"\"\"\n    try:\n        return s3_conn.head_object(Bucket=bucket, Key=key)\n    except botocore.exceptions.ClientError as e:\n        if e.response['Error']['Code'] == '404':\n            return None\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupload a ZIP file to Lambda and return a Code object pointing to it.", "response": "def _upload_code(s3_conn, bucket, prefix, name, contents, content_hash,\n                 payload_acl):\n    \"\"\"Upload a ZIP file to S3 for use by Lambda.\n\n    The key used for the upload will be unique based on the checksum of the\n    contents. No changes will be made if the contents in S3 already match the\n    expected contents.\n\n    Args:\n        s3_conn (botocore.client.S3): S3 connection to use for operations.\n        bucket (str): name of the bucket to create.\n        prefix (str): S3 prefix to prepend to the constructed key name for\n            the uploaded file\n        name (str): desired name of the Lambda function. Will be used to\n            construct a key name for the uploaded file.\n        contents (str): byte string with the content of the file upload.\n        content_hash (str): md5 hash of the contents to be uploaded.\n        payload_acl (str): The canned S3 object ACL to be applied to the\n            uploaded payload\n\n    Returns:\n        troposphere.awslambda.Code: CloudFormation Lambda Code object,\n        pointing to the uploaded payload in S3.\n\n    Raises:\n        botocore.exceptions.ClientError: any error from boto3 is passed\n            through.\n    \"\"\"\n\n    logger.debug('lambda: ZIP hash: %s', content_hash)\n    key = '{}lambda-{}-{}.zip'.format(prefix, name, content_hash)\n\n    if _head_object(s3_conn, bucket, key):\n        logger.info('lambda: object %s already exists, not uploading', key)\n    else:\n        logger.info('lambda: uploading object %s', key)\n        s3_conn.put_object(Bucket=bucket, Key=key, Body=contents,\n                           ContentType='application/zip',\n                           ACL=payload_acl)\n\n    return Code(S3Bucket=bucket, S3Key=key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates file search patterns from user configuration.", "response": "def _check_pattern_list(patterns, key, default=None):\n    \"\"\"Validates file search patterns from user configuration.\n\n    Acceptable input is a string (which will be converted to a singleton list),\n    a list of strings, or anything falsy (such as None or an empty dictionary).\n    Empty or unset input will be converted to a default.\n\n    Args:\n        patterns: input from user configuration (YAML).\n        key (str): name of the configuration key the input came from,\n            used for error display purposes.\n\n    Keyword Args:\n        default: value to return in case the input is empty or unset.\n\n    Returns:\n        list[str]: validated list of patterns\n\n    Raises:\n        ValueError: if the input is unacceptable.\n    \"\"\"\n    if not patterns:\n        return default\n\n    if isinstance(patterns, basestring):\n        return [patterns]\n\n    if isinstance(patterns, list):\n        if all(isinstance(p, basestring) for p in patterns):\n            return patterns\n\n    raise ValueError(\"Invalid file patterns in key '{}': must be a string or \"\n                     'list of strings'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a Lambda payload from user configuration and uploads it to S3.", "response": "def _upload_function(s3_conn, bucket, prefix, name, options, follow_symlinks,\n                     payload_acl):\n    \"\"\"Builds a Lambda payload from user configuration and uploads it to S3.\n\n    Args:\n        s3_conn (botocore.client.S3): S3 connection to use for operations.\n        bucket (str): name of the bucket to upload to.\n        prefix (str): S3 prefix to prepend to the constructed key name for\n            the uploaded file\n        name (str): desired name of the Lambda function. Will be used to\n            construct a key name for the uploaded file.\n        options (dict): configuration for how to build the payload.\n            Consists of the following keys:\n                * path:\n                    base path to retrieve files from (mandatory). If not\n                    absolute, it will be interpreted as relative to the stacker\n                    configuration file directory, then converted to an absolute\n                    path. See :func:`stacker.util.get_config_directory`.\n                * include:\n                    file patterns to include in the payload (optional).\n                * exclude:\n                    file patterns to exclude from the payload (optional).\n        follow_symlinks  (bool): If true, symlinks will be included in the\n            resulting zip file\n        payload_acl (str): The canned S3 object ACL to be applied to the\n            uploaded payload\n\n    Returns:\n        troposphere.awslambda.Code: CloudFormation AWS Lambda Code object,\n        pointing to the uploaded object in S3.\n\n    Raises:\n        ValueError: if any configuration is invalid.\n        botocore.exceptions.ClientError: any error from boto3 is passed\n            through.\n    \"\"\"\n    try:\n        root = os.path.expanduser(options['path'])\n    except KeyError as e:\n        raise ValueError(\n            \"missing required property '{}' in function '{}'\".format(\n                e.args[0], name))\n\n    includes = _check_pattern_list(options.get('include'), 'include',\n                                   default=['**'])\n    excludes = _check_pattern_list(options.get('exclude'), 'exclude',\n                                   default=[])\n\n    logger.debug('lambda: processing function %s', name)\n\n    # os.path.join will ignore other parameters if the right-most one is an\n    # absolute path, which is exactly what we want.\n    if not os.path.isabs(root):\n        root = os.path.abspath(os.path.join(get_config_directory(), root))\n    zip_contents, content_hash = _zip_from_file_patterns(root,\n                                                         includes,\n                                                         excludes,\n                                                         follow_symlinks)\n\n    return _upload_code(s3_conn, bucket, prefix, name, zip_contents,\n                        content_hash, payload_acl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef select_bucket_region(custom_bucket, hook_region, stacker_bucket_region,\n                         provider_region):\n    \"\"\"Returns the appropriate region to use when uploading functions.\n\n    Select the appropriate region for the bucket where lambdas are uploaded in.\n\n    Args:\n        custom_bucket (str, None): The custom bucket name provided by the\n            `bucket` kwarg of the aws_lambda hook, if provided.\n        hook_region (str): The contents of the `bucket_region` argument to\n            the hook.\n        stacker_bucket_region (str): The contents of the\n            `stacker_bucket_region` global setting.\n        provider_region (str): The region being used by the provider.\n\n    Returns:\n        str: The appropriate region string.\n    \"\"\"\n    region = None\n    if custom_bucket:\n        region = hook_region\n    else:\n        region = stacker_bucket_region\n    return region or provider_region", "response": "Returns the appropriate region to use when uploading lambdas in the bucket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding Lambda payloads from user configuration and uploads them to Amazon S3.", "response": "def upload_lambda_functions(context, provider, **kwargs):\n    \"\"\"Builds Lambda payloads from user configuration and uploads them to S3.\n\n    Constructs ZIP archives containing files matching specified patterns for\n    each function, uploads the result to Amazon S3, then stores objects (of\n    type :class:`troposphere.awslambda.Code`) in the context's hook data,\n    ready to be referenced in blueprints.\n\n    Configuration consists of some global options, and a dictionary of function\n    specifications. In the specifications, each key indicating the name of the\n    function (used for generating names for artifacts), and the value\n    determines what files to include in the ZIP (see more details below).\n\n    Payloads are uploaded to either a custom bucket or stackers default bucket,\n    with the key containing it's checksum, to allow repeated uploads to be\n    skipped in subsequent runs.\n\n    The configuration settings are documented as keyword arguments below.\n\n    Keyword Arguments:\n        bucket (str, optional): Custom bucket to upload functions to.\n            Omitting it will cause the default stacker bucket to be used.\n        bucket_region (str, optional): The region in which the bucket should\n            exist. If not given, the region will be either be that of the\n            global `stacker_bucket_region` setting, or else the region in\n            use by the provider.\n        prefix (str, optional): S3 key prefix to prepend to the uploaded\n            zip name.\n        follow_symlinks (bool, optional): Will determine if symlinks should\n            be followed and included with the zip artifact. Default: False\n        payload_acl (str, optional): The canned S3 object ACL to be applied to\n            the uploaded payload. Default: private\n        functions (dict):\n            Configurations of desired payloads to build. Keys correspond to\n            function names, used to derive key names for the payload. Each\n            value should itself be a dictionary, with the following data:\n\n                * path (str):\n\n                    Base directory of the Lambda function payload content.\n                    If it not an absolute path, it will be considered relative\n                    to the directory containing the stacker configuration file\n                    in use.\n\n                    Files in this directory will be added to the payload ZIP,\n                    according to the include and exclude patterns. If not\n                    patterns are provided, all files in this directory\n                    (respecting default exclusions) will be used.\n\n                    Files are stored in the archive with path names relative to\n                    this directory. So, for example, all the files contained\n                    directly under this directory will be added to the root of\n                    the ZIP file.\n\n                * include(str or list[str], optional):\n\n                    Pattern or list of patterns of files to include in the\n                    payload. If provided, only files that match these\n                    patterns will be included in the payload.\n\n                    Omitting it is equivalent to accepting all files that are\n                    not otherwise excluded.\n\n                * exclude(str or list[str], optional):\n                    Pattern or list of patterns of files to exclude from the\n                    payload. If provided, any files that match will be ignored,\n                    regardless of whether they match an inclusion pattern.\n\n                    Commonly ignored files are already excluded by default,\n                    such as ``.git``, ``.svn``, ``__pycache__``, ``*.pyc``,\n                    ``.gitignore``, etc.\n\n    Examples:\n        .. Hook configuration.\n        .. code-block:: yaml\n\n            pre_build:\n              - path: stacker.hooks.aws_lambda.upload_lambda_functions\n                required: true\n                enabled: true\n                data_key: lambda\n                args:\n                  bucket: custom-bucket\n                  follow_symlinks: true\n                  prefix: cloudformation-custom-resources/\n                  payload_acl: authenticated-read\n                  functions:\n                    MyFunction:\n                      path: ./lambda_functions\n                      include:\n                        - '*.py'\n                        - '*.txt'\n                      exclude:\n                        - '*.pyc'\n                        - test/\n\n        .. Blueprint usage\n        .. code-block:: python\n\n            from troposphere.awslambda import Function\n            from stacker.blueprints.base import Blueprint\n\n            class LambdaBlueprint(Blueprint):\n                def create_template(self):\n                    code = self.context.hook_data['lambda']['MyFunction']\n\n                    self.template.add_resource(\n                        Function(\n                            'MyFunction',\n                            Code=code,\n                            Handler='my_function.handler',\n                            Role='...',\n                            Runtime='python2.7'\n                        )\n                    )\n    \"\"\"\n    custom_bucket = kwargs.get('bucket')\n    if not custom_bucket:\n        bucket_name = context.bucket_name\n        logger.info(\"lambda: using default bucket from stacker: %s\",\n                    bucket_name)\n    else:\n        bucket_name = custom_bucket\n        logger.info(\"lambda: using custom bucket: %s\", bucket_name)\n\n    custom_bucket_region = kwargs.get(\"bucket_region\")\n    if not custom_bucket and custom_bucket_region:\n        raise ValueError(\"Cannot specify `bucket_region` without specifying \"\n                         \"`bucket`.\")\n\n    bucket_region = select_bucket_region(\n        custom_bucket,\n        custom_bucket_region,\n        context.config.stacker_bucket_region,\n        provider.region\n    )\n\n    # Check if we should walk / follow symlinks\n    follow_symlinks = kwargs.get('follow_symlinks', False)\n    if not isinstance(follow_symlinks, bool):\n        raise ValueError('follow_symlinks option must be a boolean')\n\n    # Check for S3 object acl. Valid values from:\n    # https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\n    payload_acl = kwargs.get('payload_acl', 'private')\n\n    # Always use the global client for s3\n    session = get_session(bucket_region)\n    s3_client = session.client('s3')\n\n    ensure_s3_bucket(s3_client, bucket_name, bucket_region)\n\n    prefix = kwargs.get('prefix', '')\n\n    results = {}\n    for name, options in kwargs['functions'].items():\n        results[name] = _upload_function(s3_client, bucket_name, prefix, name,\n                                         options, follow_symlinks, payload_acl)\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches the most recent AMI Id using a filter For example: ${ami [<region>@]owners:self,account,amazon name_regex:serverX-[0-9]+ architecture:x64,i386} The above fetches the most recent AMI where owner is self account or amazon and the ami name matches the regex described, the architecture will be either x64 or i386 You can also optionally specify the region in which to perform the AMI lookup. Valid arguments: owners (comma delimited) REQUIRED ONCE: aws_account_id | amazon | self name_regex (a regex) REQUIRED ONCE: e.g. my-ubuntu-server-[0-9]+ executable_users (comma delimited) OPTIONAL ONCE: aws_account_id | amazon | self Any other arguments specified are sent as filters to the aws api For example, \"architecture:x86_64\" will add a filter", "response": "def handle(cls, value, provider, **kwargs):\n        \"\"\"Fetch the most recent AMI Id using a filter\n    \n        For example:\n    \n            ${ami [<region>@]owners:self,account,amazon name_regex:serverX-[0-9]+ architecture:x64,i386}\n    \n            The above fetches the most recent AMI where owner is self\n            account or amazon and the ami name matches the regex described,\n            the architecture will be either x64 or i386\n    \n            You can also optionally specify the region in which to perform the\n            AMI lookup.\n    \n            Valid arguments:\n    \n            owners (comma delimited) REQUIRED ONCE:\n                aws_account_id | amazon | self\n    \n            name_regex (a regex) REQUIRED ONCE:\n                e.g. my-ubuntu-server-[0-9]+\n    \n            executable_users (comma delimited) OPTIONAL ONCE:\n                aws_account_id | amazon | self\n    \n            Any other arguments specified are sent as filters to the aws api\n            For example, \"architecture:x86_64\" will add a filter\n        \"\"\"  # noqa\n        value = read_value_from_path(value)\n\n        if \"@\" in value:\n            region, value = value.split(\"@\", 1)\n        else:\n            region = provider.region\n\n        ec2 = get_session(region).client('ec2')\n\n        values = {}\n        describe_args = {}\n\n        # now find any other arguments that can be filters\n        matches = re.findall('([0-9a-zA-z_-]+:[^\\s$]+)', value)\n        for match in matches:\n            k, v = match.split(':', 1)\n            values[k] = v\n\n        if not values.get('owners'):\n            raise Exception(\"'owners' value required when using ami\")\n        owners = values.pop('owners').split(',')\n        describe_args[\"Owners\"] = owners\n\n        if not values.get('name_regex'):\n            raise Exception(\"'name_regex' value required when using ami\")\n        name_regex = values.pop('name_regex')\n\n        executable_users = None\n        if values.get('executable_users'):\n            executable_users = values.pop('executable_users').split(',')\n            describe_args[\"ExecutableUsers\"] = executable_users\n\n        filters = []\n        for k, v in values.items():\n            filters.append({\"Name\": k, \"Values\": v.split(',')})\n        describe_args[\"Filters\"] = filters\n\n        result = ec2.describe_images(**describe_args)\n\n        images = sorted(result['Images'],\n                        key=operator.itemgetter('CreationDate'),\n                        reverse=True)\n        for image in images:\n            if re.match(\"^%s$\" % name_regex, image['Name']):\n                return image['ImageId']\n\n        raise ImageNotFound(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the formatting of differences between two dicts returned by the action.", "response": "def format_params_diff(parameter_diff):\n    \"\"\"Handles the formatting of differences in parameters.\n\n    Args:\n        parameter_diff (list): A list of DictValues detailing the\n            differences between two dicts returned by\n            :func:`stacker.actions.diff.diff_dictionaries`\n    Returns:\n        string: A formatted string that represents a parameter diff\n    \"\"\"\n\n    params_output = '\\n'.join([line for v in parameter_diff\n                               for line in v.changes()])\n    return \"\"\"--- Old Parameters\n+++ New Parameters\n******************\n%s\\n\"\"\" % params_output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomparing the old vs. new parameters and returns a list of differences", "response": "def diff_parameters(old_params, new_params):\n    \"\"\"Compares the old vs. new parameters and returns a \"diff\"\n\n    If there are no changes, we return an empty list.\n\n    Args:\n        old_params(dict): old paramters\n        new_params(dict): new parameters\n\n    Returns:\n        list: A list of differences\n    \"\"\"\n    [changes, diff] = diff_dictionaries(old_params, new_params)\n    if changes == 0:\n        return []\n    return diff"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_json(template):\n    obj = parse_cloudformation_template(template)\n    json_str = json.dumps(\n        obj, sort_keys=True, indent=4, default=str, separators=(',', ': '),\n    )\n    result = []\n    lines = json_str.split(\"\\n\")\n    for line in lines:\n        result.append(line + \"\\n\")\n    return result", "response": "Normalize our template for diffing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a list of strings to represent the parameters and stack diff", "response": "def build_stack_changes(stack_name, new_stack, old_stack, new_params,\n                        old_params):\n    \"\"\"Builds a list of strings to represent the the parameters (if changed)\n     and stack diff\"\"\"\n    from_file = \"old_%s\" % (stack_name,)\n    to_file = \"new_%s\" % (stack_name,)\n    lines = difflib.context_diff(\n        old_stack, new_stack,\n        fromfile=from_file, tofile=to_file,\n        n=7)  # ensure at least a few lines of context are displayed afterward\n\n    template_changes = list(lines)\n    log_lines = []\n    if not template_changes:\n        log_lines.append(\"*** No changes to template ***\")\n    param_diffs = diff_parameters(old_params, new_params)\n    if param_diffs:\n        log_lines.append(format_params_diff(param_diffs))\n    if template_changes:\n        log_lines.append(\"\".join(template_changes))\n    return log_lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef changes(self):\n        output = []\n        if self.status() is self.UNMODIFIED:\n            output = [self.formatter % (' ', self.key, self.old_value)]\n        elif self.status() is self.ADDED:\n            output.append(self.formatter % ('+', self.key, self.new_value))\n        elif self.status() is self.REMOVED:\n            output.append(self.formatter % ('-', self.key, self.old_value))\n        elif self.status() is self.MODIFIED:\n            output.append(self.formatter % ('-', self.key, self.old_value))\n            output.append(self.formatter % ('+', self.key, self.new_value))\n        return output", "response": "Returns a list of changes to represent the diff between old and new value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct the parameters & contents of a new stack and returns a list of str representation to be output to the user list", "response": "def _build_new_template(self, stack, parameters):\n        \"\"\"Constructs the parameters & contents of a new stack and returns a\n        list(str) representation to be output to the user\n        \"\"\"\n        log_lines = [\"New template parameters:\"]\n        for param in sorted(parameters,\n                            key=lambda param: param['ParameterKey']):\n            log_lines.append(\"%s = %s\" % (param['ParameterKey'],\n                                          param['ParameterValue']))\n\n        log_lines.append(\"\\nNew template contents:\")\n        log_lines.append(\"\".join(stack))\n        return log_lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the diffing a stack in CloudFormation vs our config", "response": "def _diff_stack(self, stack, **kwargs):\n        \"\"\"Handles the diffing a stack in CloudFormation vs our config\"\"\"\n        if self.cancel.wait(0):\n            return INTERRUPTED\n\n        if not build.should_submit(stack):\n            return NotSubmittedStatus()\n\n        if not build.should_update(stack):\n            return NotUpdatedStatus()\n\n        provider = self.build_provider(stack)\n\n        provider_stack = provider.get_stack(stack.fqn)\n\n        # get the current stack template & params from AWS\n        try:\n            [old_template, old_params] = provider.get_stack_info(\n                provider_stack)\n        except exceptions.StackDoesNotExist:\n            old_template = None\n            old_params = {}\n\n        stack.resolve(self.context, provider)\n        # generate our own template & params\n        parameters = self.build_parameters(stack)\n        new_params = dict()\n        for p in parameters:\n            new_params[p['ParameterKey']] = p['ParameterValue']\n        new_template = stack.blueprint.rendered\n        new_stack = normalize_json(new_template)\n\n        output = [\"============== Stack: %s ==============\" % (stack.name,)]\n        # If this is a completely new template dump our params & stack\n        if not old_template:\n            output.extend(self._build_new_template(new_stack, parameters))\n        else:\n            # Diff our old & new stack/parameters\n            old_template = parse_cloudformation_template(old_template)\n            if isinstance(old_template, str):\n                # YAML templates returned from CFN need parsing again\n                # \"AWSTemplateFormatVersion: \\\"2010-09-09\\\"\\nParam...\"\n                # ->\n                # AWSTemplateFormatVersion: \"2010-09-09\"\n                old_template = parse_cloudformation_template(old_template)\n            old_stack = normalize_json(\n                json.dumps(old_template,\n                           sort_keys=True,\n                           indent=4,\n                           default=str)\n            )\n            output.extend(build_stack_changes(stack.name, new_stack, old_stack,\n                                              new_params, old_params))\n        ui.info('\\n' + '\\n'.join(output))\n\n        stack.set_outputs(\n            provider.get_output_dict(provider_stack))\n\n        return COMPLETE"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef each_step(graph):\n\n    steps = graph.topological_sort()\n    steps.reverse()\n\n    for step in steps:\n        deps = graph.downstream(step.name)\n        yield (step, deps)", "response": "Returns an iterator that yields each step and its direct\n    dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dot_format(out, graph, name=\"digraph\"):\n\n    out.write(\"digraph %s {\\n\" % name)\n    for step, deps in each_step(graph):\n        for dep in deps:\n            out.write(\"  \\\"%s\\\" -> \\\"%s\\\";\\n\" % (step, dep))\n\n    out.write(\"}\\n\")", "response": "Outputs the graph using the graphviz dot format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noutput the graph in a machine readable JSON format.", "response": "def json_format(out, graph):\n    \"\"\"Outputs the graph in a machine readable JSON format.\"\"\"\n    steps = {}\n    for step, deps in each_step(graph):\n        steps[step.name] = {}\n        steps[step.name][\"deps\"] = [dep.name for dep in deps]\n\n    json.dump({\"steps\": steps}, out, indent=4)\n    out.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, format=None, reduce=False, *args, **kwargs):\n        plan = self._generate_plan()\n        if reduce:\n            # This will performa a transitive reduction on the underlying\n            # graph, producing less edges. Mostly useful for the \"dot\" format,\n            # when converting to PNG, so it creates a prettier/cleaner\n            # dependency graph.\n            plan.graph.transitive_reduction()\n\n        fn = FORMATTERS[format]\n        fn(sys.stdout, plan.graph)\n        sys.stdout.flush()", "response": "Generates the underlying graph and prints it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the ecsServieRole which has to be named exactly that getTerminalized by the user.", "response": "def create_ecs_service_role(provider, context, **kwargs):\n    \"\"\"Used to create the ecsServieRole, which has to be named exactly that\n    currently, so cannot be created via CloudFormation. See:\n\n    http://docs.aws.amazon.com/AmazonECS/latest/developerguide/IAM_policies.html#service_IAM_role\n\n    Args:\n        provider (:class:`stacker.providers.base.BaseProvider`): provider\n            instance\n        context (:class:`stacker.context.Context`): context instance\n\n    Returns: boolean for whether or not the hook succeeded.\n\n    \"\"\"\n    role_name = kwargs.get(\"role_name\", \"ecsServiceRole\")\n    client = get_session(provider.region).client('iam')\n\n    try:\n        client.create_role(\n            RoleName=role_name,\n            AssumeRolePolicyDocument=get_ecs_assumerole_policy().to_json()\n        )\n    except ClientError as e:\n        if \"already exists\" in str(e):\n            pass\n        else:\n            raise\n\n    policy = Policy(\n        Statement=[\n            Statement(\n                Effect=Allow,\n                Resource=[\"*\"],\n                Action=[ecs.CreateCluster, ecs.DeregisterContainerInstance,\n                        ecs.DiscoverPollEndpoint, ecs.Poll,\n                        ecs.Action(\"Submit*\")]\n            )\n        ])\n    client.put_role_policy(\n        RoleName=role_name,\n        PolicyName=\"AmazonEC2ContainerServiceRolePolicy\",\n        PolicyDocument=policy.to_json()\n    )\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a dictionary containing the appropriate parameters to supply to upload_server_certificate.", "response": "def get_cert_contents(kwargs):\n    \"\"\"Builds parameters with server cert file contents.\n\n    Args:\n        kwargs(dict): The keyword args passed to ensure_server_cert_exists,\n            optionally containing the paths to the cert, key and chain files.\n\n    Returns:\n        dict: A dictionary containing the appropriate parameters to supply to\n            upload_server_certificate. An empty dictionary if there is a\n            problem.\n    \"\"\"\n    paths = {\n        \"certificate\": kwargs.get(\"path_to_certificate\"),\n        \"private_key\": kwargs.get(\"path_to_private_key\"),\n        \"chain\": kwargs.get(\"path_to_chain\"),\n    }\n\n    for key, value in paths.items():\n        if value is not None:\n            continue\n\n        path = input(\"Path to %s (skip): \" % (key,))\n        if path == \"skip\" or not path.strip():\n            continue\n\n        paths[key] = path\n\n    parameters = {\n        \"ServerCertificateName\": kwargs.get(\"cert_name\"),\n    }\n\n    for key, path in paths.items():\n        if not path:\n            continue\n\n        # Allow passing of file like object for tests\n        try:\n            contents = path.read()\n        except AttributeError:\n            with open(utils.full_path(path)) as read_file:\n                contents = read_file.read()\n\n        if key == \"certificate\":\n            parameters[\"CertificateBody\"] = contents\n        elif key == \"private_key\":\n            parameters[\"PrivateKey\"] = contents\n        elif key == \"chain\":\n            parameters[\"CertificateChain\"] = contents\n\n    return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the path to a template file in the working directory or in sys. path.", "response": "def get_template_path(filename):\n    \"\"\"Find raw template in working directory or in sys.path.\n\n    template_path from config may refer to templates colocated with the Stacker\n    config, or files in remote package_sources. Here, we emulate python module\n    loading to find the path to the template.\n\n    Args:\n        filename (str): Template filename.\n\n    Returns:\n        Optional[str]: Path to file, or None if no file found\n\n    \"\"\"\n    if os.path.isfile(filename):\n        return os.path.abspath(filename)\n    for i in sys.path:\n        if os.path.isfile(os.path.join(i, filename)):\n            return os.path.abspath(os.path.join(i, filename))\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve_variable(provided_variable, blueprint_name):\n    value = None\n    if provided_variable:\n        if not provided_variable.resolved:\n            raise UnresolvedVariable(blueprint_name, provided_variable)\n\n        value = provided_variable.value\n\n    return value", "response": "Resolves a provided variable against the variable definition."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve the values of the blueprint variables.", "response": "def resolve_variables(self, provided_variables):\n        \"\"\"Resolve the values of the blueprint variables.\n\n        This will resolve the values of the template parameters with values\n        from the env file, the config, and any lookups resolved. The\n        resolution is run twice, in case the blueprint is jinja2 templated\n        and requires provided variables to render.\n\n        Args:\n            provided_variables (list of :class:`stacker.variables.Variable`):\n                list of provided variables\n\n        \"\"\"\n        # Pass 1 to set resolved_variables to provided variables\n        self.resolved_variables = {}\n        variable_dict = dict((var.name, var) for var in provided_variables)\n        for var_name, _var_def in variable_dict.items():\n            value = resolve_variable(\n                variable_dict.get(var_name),\n                self.name\n            )\n            if value is not None:\n                self.resolved_variables[var_name] = value\n\n        # Pass 2 to render the blueprint and set resolved_variables according\n        # to defined variables\n        defined_variables = self.get_parameter_definitions()\n        self.resolved_variables = {}\n        variable_dict = dict((var.name, var) for var in provided_variables)\n        for var_name, _var_def in defined_variables.items():\n            value = resolve_variable(\n                variable_dict.get(var_name),\n                self.name\n            )\n            if value is not None:\n                self.resolved_variables[var_name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning ( generating first if needed ) rendered template.", "response": "def rendered(self):\n        \"\"\"Return (generating first if needed) rendered template.\"\"\"\n        if not self._rendered:\n            template_path = get_template_path(self.raw_template_path)\n            if template_path:\n                with open(template_path, 'r') as template:\n                    if len(os.path.splitext(template_path)) == 2 and (\n                            os.path.splitext(template_path)[1] == '.j2'):\n                        self._rendered = Template(template.read()).render(\n                            context=self.context,\n                            mappings=self.mappings,\n                            name=self.name,\n                            variables=self.resolved_variables\n                        )\n                    else:\n                        self._rendered = template.read()\n            else:\n                raise InvalidConfig(\n                    'Could not find template %s' % self.raw_template_path\n                )\n\n        return self._rendered"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the version of the current object.", "response": "def version(self):\n        \"\"\"Return (generating first if needed) version hash.\"\"\"\n        if not self._version:\n            self._version = hashlib.md5(self.rendered.encode()).hexdigest()[:8]\n        return self._version"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate ECS clusters. Expects a \"clusters\" argument, which should contain a list of cluster names to create. Args: provider (:class:`stacker.providers.base.BaseProvider`): provider instance context (:class:`stacker.context.Context`): context instance Returns: boolean for whether or not the hook succeeded.", "response": "def create_clusters(provider, context, **kwargs):\n    \"\"\"Creates ECS clusters.\n\n    Expects a \"clusters\" argument, which should contain a list of cluster\n    names to create.\n\n    Args:\n        provider (:class:`stacker.providers.base.BaseProvider`): provider\n            instance\n        context (:class:`stacker.context.Context`): context instance\n\n    Returns: boolean for whether or not the hook succeeded.\n\n    \"\"\"\n    conn = get_session(provider.region).client('ecs')\n\n    try:\n        clusters = kwargs[\"clusters\"]\n    except KeyError:\n        logger.error(\"setup_clusters hook missing \\\"clusters\\\" argument\")\n        return False\n\n    if isinstance(clusters, basestring):\n        clusters = [clusters]\n\n    cluster_info = {}\n    for cluster in clusters:\n        logger.debug(\"Creating ECS cluster: %s\", cluster)\n        r = conn.create_cluster(clusterName=cluster)\n        cluster_info[r[\"cluster\"][\"clusterName\"]] = r\n    return {\"clusters\": cluster_info}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(cls, value, context=None, **kwargs):\n\n        if context is None:\n            raise ValueError('Context is required')\n\n        d = deconstruct(value)\n        stack = context.get_stack(d.stack_name)\n        return stack.outputs[d.output_name]", "response": "Return an output from the designated stack."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a troposphere Parameter with the given properties.", "response": "def build_parameter(name, properties):\n    \"\"\"Builds a troposphere Parameter with the given properties.\n\n    Args:\n        name (string): The name of the parameter.\n        properties (dict): Contains the properties that will be applied to the\n            parameter. See:\n            http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html\n\n    Returns:\n        :class:`troposphere.Parameter`: The created parameter object.\n    \"\"\"\n    p = Parameter(name, Type=properties.get(\"type\"))\n    for name, attr in PARAMETER_PROPERTIES.items():\n        if name in properties:\n            setattr(p, attr, properties[name])\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_variable_type(var_name, var_type, value):\n\n    if isinstance(var_type, CFNType):\n        value = CFNParameter(name=var_name, value=value)\n    elif isinstance(var_type, TroposphereType):\n        try:\n            value = var_type.create(value)\n        except Exception as exc:\n            name = \"{}.create\".format(var_type.resource_name)\n            raise ValidatorError(var_name, name, value, exc)\n    else:\n        if not isinstance(value, var_type):\n            raise ValueError(\n                \"Value for variable %s must be of type %s. Actual \"\n                \"type: %s.\" % (var_name, var_type, type(value))\n            )\n\n    return value", "response": "Ensures the value is of the correct type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsupport a variable defining which values it allows.", "response": "def validate_allowed_values(allowed_values, value):\n    \"\"\"Support a variable defining which values it allows.\n\n    Args:\n        allowed_values (Optional[list]): A list of allowed values from the\n            variable definition\n        value (obj): The object representing the value provided for the\n            variable\n\n    Returns:\n        bool: Boolean for whether or not the value is valid.\n\n    \"\"\"\n    # ignore CFNParameter, troposphere handles these for us\n    if not allowed_values or isinstance(value, CFNParameter):\n        return True\n\n    return value in allowed_values"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving a provided variable value against the variable definition.", "response": "def resolve_variable(var_name, var_def, provided_variable, blueprint_name):\n    \"\"\"Resolve a provided variable value against the variable definition.\n\n    Args:\n        var_name (str): The name of the defined variable on a blueprint.\n        var_def (dict): A dictionary representing the defined variables\n            attributes.\n        provided_variable (:class:`stacker.variables.Variable`): The variable\n            value provided to the blueprint.\n        blueprint_name (str): The name of the blueprint that the variable is\n            being applied to.\n\n    Returns:\n        object: The resolved variable value, could be any python object.\n\n    Raises:\n        MissingVariable: Raised when a variable with no default is not\n            provided a value.\n        UnresolvedVariable: Raised when the provided variable is not already\n            resolved.\n        ValueError: Raised when the value is not the right type and cannot be\n            cast as the correct type. Raised by\n            :func:`stacker.blueprints.base.validate_variable_type`\n        ValidatorError: Raised when a validator raises an exception. Wraps the\n            original exception.\n    \"\"\"\n\n    try:\n        var_type = var_def[\"type\"]\n    except KeyError:\n        raise VariableTypeRequired(blueprint_name, var_name)\n\n    if provided_variable:\n        if not provided_variable.resolved:\n            raise UnresolvedVariable(blueprint_name, provided_variable)\n\n        value = provided_variable.value\n    else:\n        # Variable value not provided, try using the default, if it exists\n        # in the definition\n        try:\n            value = var_def[\"default\"]\n        except KeyError:\n            raise MissingVariable(blueprint_name, var_name)\n\n    # If no validator, return the value as is, otherwise apply validator\n    validator = var_def.get(\"validator\", lambda v: v)\n    try:\n        value = validator(value)\n    except Exception as exc:\n        raise ValidatorError(var_name, validator.__name__, value, exc)\n\n    # Ensure that the resulting value is the correct type\n    value = validate_variable_type(var_name, var_type, value)\n\n    allowed_values = var_def.get(\"allowed_values\")\n    if not validate_allowed_values(allowed_values, value):\n        message = (\n            \"Invalid value passed to '%s' in blueprint: %s. Got: '%s', \"\n            \"expected one of %s\"\n        ) % (var_name, blueprint_name, value, allowed_values)\n        raise ValueError(message)\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_user_data(variables, raw_user_data, blueprint_name):\n    variable_values = {}\n\n    for key, value in variables.items():\n        if type(value) is CFNParameter:\n            variable_values[key] = value.to_parameter_value()\n        else:\n            variable_values[key] = value\n\n    template = string.Template(raw_user_data)\n\n    res = \"\"\n\n    try:\n        res = template.substitute(variable_values)\n    except ValueError as exp:\n        raise InvalidUserdataPlaceholder(blueprint_name, exp.args[0])\n    except KeyError as key:\n        raise MissingVariable(blueprint_name, key)\n\n    return res", "response": "Parse the given user data and renders it as a template and returns the result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the parameter definitions to submit to CloudFormation.", "response": "def get_parameter_definitions(self):\n        \"\"\"Get the parameter definitions to submit to CloudFormation.\n\n        Any variable definition whose `type` is an instance of `CFNType` will\n        be returned as a CloudFormation Parameter.\n\n        Returns:\n            dict: parameter definitions. Keys are parameter names, the values\n                are dicts containing key/values for various parameter\n                properties.\n\n        \"\"\"\n        output = {}\n        for var_name, attrs in self.defined_variables().items():\n            var_type = attrs.get(\"type\")\n            if isinstance(var_type, CFNType):\n                cfn_attrs = copy.deepcopy(attrs)\n                cfn_attrs[\"type\"] = var_type.parameter_type\n                output[var_name] = cfn_attrs\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_required_parameter_definitions(self):\n        required = {}\n        for name, attrs in self.get_parameter_definitions().items():\n            if \"Default\" not in attrs:\n                required[name] = attrs\n        return required", "response": "Returns all template parameters that do not have a default value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_parameter_values(self):\n        variables = self.get_variables()\n        output = {}\n        for key, value in variables.items():\n            try:\n                output[key] = value.to_parameter_value()\n            except AttributeError:\n                continue\n\n        return output", "response": "Return a dictionary of variables with type CFNType."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_parameters(self):\n        t = self.template\n        parameters = self.get_parameter_definitions()\n\n        if not parameters:\n            logger.debug(\"No parameters defined.\")\n            return\n\n        for name, attrs in parameters.items():\n            p = build_parameter(name, attrs)\n            t.add_parameter(p)", "response": "Add any CloudFormation parameters to the template"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of variables with type : class : CFNType.", "response": "def get_cfn_parameters(self):\n        \"\"\"Return a dictionary of variables with `type` :class:`CFNType`.\n\n        Returns:\n            dict: variables that need to be submitted as CloudFormation\n                Parameters.\n\n        \"\"\"\n        variables = self.get_variables()\n        output = {}\n        for key, value in variables.items():\n            if hasattr(value, \"to_parameter_value\"):\n                output[key] = value.to_parameter_value()\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves the values of the VARIABLES environment file and config files.", "response": "def resolve_variables(self, provided_variables):\n        \"\"\"Resolve the values of the blueprint variables.\n\n        This will resolve the values of the `VARIABLES` with values from the\n        env file, the config, and any lookups resolved.\n\n        Args:\n            provided_variables (list of :class:`stacker.variables.Variable`):\n                list of provided variables\n\n        \"\"\"\n        self.resolved_variables = {}\n        defined_variables = self.defined_variables()\n        variable_dict = dict((var.name, var) for var in provided_variables)\n        for var_name, var_def in defined_variables.items():\n            value = resolve_variable(\n                var_name,\n                var_def,\n                variable_dict.get(var_name),\n                self.name\n            )\n            self.resolved_variables[var_name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_template(self):\n        self.import_mappings()\n        self.create_template()\n        if self.description:\n            self.set_template_description(self.description)\n        self.setup_parameters()\n        rendered = self.template.to_json(indent=self.context.template_indent)\n        version = hashlib.md5(rendered.encode()).hexdigest()[:8]\n        return (version, rendered)", "response": "Render the Blueprint to a CloudFormation template"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_json(self, variables=None):\n\n        variables_to_resolve = []\n        if variables:\n            for key, value in variables.items():\n                variables_to_resolve.append(Variable(key, value))\n        for k in self.get_parameter_definitions():\n            if not variables or k not in variables:\n                # The provided value for a CFN parameter has no effect in this\n                # context (generating the CFN template), so any string can be\n                # provided for its value - just needs to be something\n                variables_to_resolve.append(Variable(k, 'unused_value'))\n        self.resolve_variables(variables_to_resolve)\n\n        return self.render_template()[1]", "response": "Render the blueprint and return the json form."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads and parses a user_data file.", "response": "def read_user_data(self, user_data_path):\n        \"\"\"Reads and parses a user_data file.\n\n        Args:\n            user_data_path (str):\n                path to the userdata file\n\n        Returns:\n            str: the parsed user data file\n\n        \"\"\"\n        raw_user_data = read_value_from_path(user_data_path)\n\n        variables = self.get_variables()\n\n        return parse_user_data(variables, raw_user_data, self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_logging(verbosity, formats=None):\n    if formats is None:\n        formats = {}\n\n    log_level = logging.INFO\n\n    log_format = formats.get(\"info\", INFO_FORMAT)\n\n    if sys.stdout.isatty():\n        log_format = formats.get(\"color\", COLOR_FORMAT)\n\n    if verbosity > 0:\n        log_level = logging.DEBUG\n        log_format = formats.get(\"debug\", DEBUG_FORMAT)\n\n    if verbosity < 2:\n        logging.getLogger(\"botocore\").setLevel(logging.CRITICAL)\n\n    hdlr = logging.StreamHandler()\n    hdlr.setFormatter(ColorFormatter(log_format, ISO_8601))\n    logging.root.addHandler(hdlr)\n    logging.root.setLevel(log_level)", "response": "Configure a proper logger based on verbosity and optional log formats."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_hooks(stage, hooks, provider, context):\n    if not hooks:\n        logger.debug(\"No %s hooks defined.\", stage)\n        return\n\n    hook_paths = []\n    for i, h in enumerate(hooks):\n        try:\n            hook_paths.append(h.path)\n        except KeyError:\n            raise ValueError(\"%s hook #%d missing path.\" % (stage, i))\n\n    logger.info(\"Executing %s hooks: %s\", stage, \", \".join(hook_paths))\n    for hook in hooks:\n        data_key = hook.data_key\n        required = hook.required\n        kwargs = hook.args or {}\n        enabled = hook.enabled\n        if not enabled:\n            logger.debug(\"hook with method %s is disabled, skipping\",\n                         hook.path)\n            continue\n        try:\n            method = load_object_from_string(hook.path)\n        except (AttributeError, ImportError):\n            logger.exception(\"Unable to load method at %s:\", hook.path)\n            if required:\n                raise\n            continue\n        try:\n            result = method(context=context, provider=provider, **kwargs)\n        except Exception:\n            logger.exception(\"Method %s threw an exception:\", hook.path)\n            if required:\n                raise\n            continue\n        if not result:\n            if required:\n                logger.error(\"Required hook %s failed. Return value: %s\",\n                             hook.path, result)\n                sys.exit(1)\n            logger.warning(\"Non-required hook %s failed. Return value: %s\",\n                           hook.path, result)\n        else:\n            if isinstance(result, collections.Mapping):\n                if data_key:\n                    logger.debug(\"Adding result for hook %s to context in \"\n                                 \"data_key %s.\", hook.path, data_key)\n                    context.set_hook_data(data_key, result)\n                else:\n                    logger.debug(\"Hook %s returned result data, but no data \"\n                                 \"key set, so ignoring.\", hook.path)", "response": "This function handles the pre and post build hooks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _gather_variables(stack_def):\n    variable_values = copy.deepcopy(stack_def.variables or {})\n    return [Variable(k, v) for k, v in variable_values.items()]", "response": "Gather variables from a context provided & stack defined variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the tags that should be set on this stack.", "response": "def tags(self):\n        \"\"\"Returns the tags that should be set on this stack. Includes both the\n        global tags, as well as any stack specific tags or overrides.\n\n        Returns:\n\n            dict: dictionary of tags\n\n        \"\"\"\n        tags = self.definition.tags or {}\n        return dict(self.context.tags, **tags)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve(self, context, provider):\n        resolve_variables(self.variables, context, provider)\n        self.blueprint.resolve_variables(self.variables)", "response": "Resolve the Stack variables and prepares the Blueprint for the available resources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubstitute placeholders in a string using CloudFormation references", "response": "def _parameterize_string(raw):\n    \"\"\"Substitute placeholders in a string using CloudFormation references\n\n    Args:\n        raw (`str`): String to be processed. Byte strings are not\n        supported; decode them before passing them to this function.\n\n    Returns:\n        `str` | :class:`troposphere.GenericHelperFn`: An expression with\n            placeholders from the input replaced, suitable to be passed to\n            Troposphere to be included in CloudFormation template. This will\n            be the input string without modification if no substitutions are\n            found, and a composition of CloudFormation calls otherwise.\n    \"\"\"\n\n    parts = []\n    s_index = 0\n\n    for match in _PARAMETER_PATTERN.finditer(raw):\n        parts.append(raw[s_index:match.start()])\n        parts.append({u\"Ref\": match.group(1)})\n        s_index = match.end()\n\n    if not parts:\n        return GenericHelperFn(raw)\n\n    parts.append(raw[s_index:])\n    return GenericHelperFn({u\"Fn::Join\": [u\"\", parts]})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parameterize_obj(obj):\n\n    if isinstance(obj, Mapping):\n        return dict((key, _parameterize_obj(value))\n                    for key, value in obj.items())\n    elif isinstance(obj, bytes):\n        return _parameterize_string(obj.decode('utf8'))\n    elif isinstance(obj, str):\n        return _parameterize_string(obj)\n    elif isinstance(obj, Sequence):\n        return list(_parameterize_obj(item) for item in obj)\n    else:\n        return obj", "response": "Recursively parameterizes all strings contained in an object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntranslating a filename into the file contents.", "response": "def handle(cls, value, **kwargs):\n        \"\"\"Translate a filename into the file contents.\n\n        Fields should use the following format::\n\n            <codec>:<path>\n\n        For example::\n\n            # We've written a file to /some/path:\n            $ echo \"hello there\" > /some/path\n\n            # In stacker we would reference the contents of this file with the\n            # following\n            conf_key: ${file plain:file://some/path}\n\n            # The above would resolve to\n            conf_key: hello there\n\n            # Or, if we used wanted a base64 encoded copy of the file data\n            conf_key: ${file base64:file://some/path}\n\n            # The above would resolve to\n            conf_key: aGVsbG8gdGhlcmUK\n\n        Supported codecs:\n\n            - plain\n\n            - base64 - encode the plain text file at the given path with base64\n              prior to returning it\n\n            - parameterized - the same as plain, but additionally supports\n              referencing template parameters to create userdata that's\n              supplemented with information from the template, as is commonly\n              needed in EC2 UserData. For example, given a template parameter\n              of BucketName, the file could contain the following text::\n\n                #!/bin/sh\n                aws s3 sync s3://{{BucketName}}/somepath /somepath\n\n              and then you could use something like this in the YAML config\n              file::\n\n                UserData: ${file parameterized:/path/to/file}\n\n              resulting in the UserData parameter being defined as::\n\n                  { \"Fn::Join\" : [\"\", [\n                      \"#!/bin/sh\\\\naws s3 sync s3://\",\n                      {\"Ref\" : \"BucketName\"},\n                      \"/somepath /somepath\"\n                  ]] }\n\n            - parameterized-b64 - the same as parameterized, with the results\n              additionally wrapped in *{ \"Fn::Base64\": ... }* , which is what\n              you actually need for EC2 UserData\n\n        When using parameterized-b64 for UserData, you should use a variable\n        defined as such:\n\n        .. code-block:: python\n\n            from troposphere import AWSHelperFn\n\n              \"UserData\": {\n                  \"type\": AWSHelperFn,\n                  \"description\": \"Instance user data\",\n                  \"default\": Ref(\"AWS::NoValue\")\n              }\n\n        and then assign UserData in a LaunchConfiguration or Instance to\n        *self.get_variables()[\"UserData\"]*. Note that we use AWSHelperFn as the\n        type because the parameterized-b64 codec returns either a Base64 or a\n        GenericHelperFn troposphere object\n        \"\"\"\n\n        try:\n            codec, path = value.split(\":\", 1)\n        except ValueError:\n            raise TypeError(\n                \"File value must be of the format\"\n                \" \\\"<codec>:<path>\\\" (got %s)\" % (value)\n            )\n\n        value = read_value_from_path(path)\n\n        return CODECS[codec](value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle(cls, value, **kwargs):\n        value = read_value_from_path(value)\n\n        try:\n            return os.environ[value]\n        except KeyError:\n            raise ValueError('EnvVar \"{}\" does not exist'.format(value))", "response": "Retrieve an environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_output_dict(stack):\n    outputs = {}\n    if 'Outputs' not in stack:\n        return outputs\n\n    for output in stack['Outputs']:\n        logger.debug(\"    %s %s: %s\", stack['StackName'], output['OutputKey'],\n                     output['OutputValue'])\n        outputs[output['OutputKey']] = output['OutputValue']\n    return outputs", "response": "Returns a dictionary of key - value pairs for each output on the CF stack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ask_for_approval(full_changeset=None, params_diff=None,\n                     include_verbose=False):\n    \"\"\"Prompt the user for approval to execute a change set.\n\n    Args:\n        full_changeset (list, optional): A list of the full changeset that will\n            be output if the user specifies verbose.\n        params_diff (list, optional): A list of DictValue detailing the\n            differences between two parameters returned by\n            :func:`stacker.actions.diff.diff_dictionaries`\n        include_verbose (bool, optional): Boolean for whether or not to include\n            the verbose option\n\n    \"\"\"\n    approval_options = ['y', 'n']\n    if include_verbose:\n        approval_options.append('v')\n\n    approve = ui.ask(\"Execute the above changes? [{}] \".format(\n        '/'.join(approval_options))).lower()\n\n    if include_verbose and approve == \"v\":\n        if params_diff:\n            logger.info(\n                \"Full changeset:\\n\\n%s\\n%s\",\n                format_params_diff(params_diff),\n                yaml.safe_dump(full_changeset),\n            )\n        else:\n            logger.info(\n                \"Full changeset:\\n%s\",\n                yaml.safe_dump(full_changeset),\n            )\n        return ask_for_approval()\n    elif approve != \"y\":\n        raise exceptions.CancelExecution", "response": "Prompts the user for approval to execute a change set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output_summary(fqn, action, changeset, params_diff,\n                   replacements_only=False):\n    \"\"\"Log a summary of the changeset.\n\n    Args:\n        fqn (string): fully qualified name of the stack\n        action (string): action to include in the log message\n        changeset (list): AWS changeset\n        params_diff (list): A list of dictionaries detailing the differences\n            between two parameters returned by\n            :func:`stacker.actions.diff.diff_dictionaries`\n        replacements_only (bool, optional): boolean for whether or not we only\n            want to list replacements\n\n    \"\"\"\n    replacements = []\n    changes = []\n    for change in changeset:\n        resource = change['ResourceChange']\n        replacement = resource.get('Replacement') == 'True'\n        summary = '- %s %s (%s)' % (\n            resource['Action'],\n            resource['LogicalResourceId'],\n            resource['ResourceType'],\n        )\n        if replacement:\n            replacements.append(summary)\n        else:\n            changes.append(summary)\n\n    summary = ''\n    if params_diff:\n        summary += summarize_params_diff(params_diff)\n    if replacements:\n        if not replacements_only:\n            summary += 'Replacements:\\n'\n        summary += '\\n'.join(replacements)\n    if changes:\n        if summary:\n            summary += '\\n'\n        summary += 'Changes:\\n%s' % ('\\n'.join(changes))\n    logger.info('%s %s:\\n%s', fqn, action, summary)", "response": "Log a summary of the changeset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_till_change_set_complete(cfn_client, change_set_id, try_count=25,\n                                  sleep_time=.5, max_sleep=3):\n    \"\"\" Checks state of a changeset, returning when it is in a complete state.\n\n    Since changesets can take a little bit of time to get into a complete\n    state, we need to poll it until it does so. This will try to get the\n    state `try_count` times, waiting `sleep_time` * 2 seconds between each try\n    up to the `max_sleep` number of seconds. If, after that time, the changeset\n    is not in a complete state it fails. These default settings will wait a\n    little over one minute.\n\n    Args:\n        cfn_client (:class:`botocore.client.CloudFormation`): Used to query\n            cloudformation.\n        change_set_id (str): The unique changeset id to wait for.\n        try_count (int): Number of times to try the call.\n        sleep_time (int): Time to sleep between attempts.\n        max_sleep (int): Max time to sleep during backoff\n\n    Return:\n        dict: The response from cloudformation for the describe_change_set\n            call.\n    \"\"\"\n    complete = False\n    response = None\n    for i in range(try_count):\n        response = cfn_client.describe_change_set(\n            ChangeSetName=change_set_id,\n        )\n        complete = response[\"Status\"] in (\"FAILED\", \"CREATE_COMPLETE\")\n        if complete:\n            break\n        if sleep_time == max_sleep:\n            logger.debug(\n                \"Still waiting on changeset for another %s seconds\",\n                sleep_time\n            )\n        time.sleep(sleep_time)\n\n        # exponential backoff with max\n        sleep_time = min(sleep_time * 2, max_sleep)\n    if not complete:\n        raise exceptions.ChangesetDidNotStabilize(change_set_id)\n    return response", "response": "Waits until the changeset is in a complete state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_tags_contain(actual, expected):\n\n    actual_set = set((item[\"Key\"], item[\"Value\"]) for item in actual)\n    expected_set = set((item[\"Key\"], item[\"Value\"]) for item in expected)\n\n    return actual_set >= expected_set", "response": "Checks if a set of AWS resource tags is contained in another resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse to generate the args for common cloudformation API interactions. This is used for create_stack/update_stack/create_change_set calls in cloudformation. Args: stack_name (str): The fully qualified stack name in Cloudformation. parameters (list): A list of dictionaries that defines the parameter list to be applied to the Cloudformation stack. tags (list): A list of dictionaries that defines the tags that should be applied to the Cloudformation stack. template (:class:`stacker.provider.base.Template`): The template object. capabilities (list, optional): A list of capabilities to use when updating Cloudformation. change_set_type (str, optional): An optional change set type to use with create_change_set. service_role (str, optional): An optional service role to use when interacting with Cloudformation. stack_policy (:class:`stacker.providers.base.Template`): A template object representing a stack policy. change_set_name (str, optional): An optional change set name to use with create_change_set. Returns: dict: A dictionary of arguments to be used in the Cloudformation API call.", "response": "def generate_cloudformation_args(stack_name, parameters, tags, template,\n                                 capabilities=DEFAULT_CAPABILITIES,\n                                 change_set_type=None,\n                                 service_role=None,\n                                 stack_policy=None,\n                                 change_set_name=None):\n    \"\"\"Used to generate the args for common cloudformation API interactions.\n\n    This is used for create_stack/update_stack/create_change_set calls in\n    cloudformation.\n\n    Args:\n        stack_name (str): The fully qualified stack name in Cloudformation.\n        parameters (list): A list of dictionaries that defines the\n            parameter list to be applied to the Cloudformation stack.\n        tags (list): A list of dictionaries that defines the tags\n            that should be applied to the Cloudformation stack.\n        template (:class:`stacker.provider.base.Template`): The template\n            object.\n        capabilities (list, optional): A list of capabilities to use when\n            updating Cloudformation.\n        change_set_type (str, optional): An optional change set type to use\n            with create_change_set.\n        service_role (str, optional): An optional service role to use when\n            interacting with Cloudformation.\n        stack_policy (:class:`stacker.providers.base.Template`): A template\n            object representing a stack policy.\n        change_set_name (str, optional): An optional change set name to use\n            with create_change_set.\n\n    Returns:\n        dict: A dictionary of arguments to be used in the Cloudformation API\n            call.\n    \"\"\"\n    args = {\n        \"StackName\": stack_name,\n        \"Parameters\": parameters,\n        \"Tags\": tags,\n        \"Capabilities\": capabilities,\n    }\n\n    if service_role:\n        args[\"RoleARN\"] = service_role\n\n    if change_set_name:\n        args[\"ChangeSetName\"] = change_set_name\n\n    if change_set_type:\n        args[\"ChangeSetType\"] = change_set_type\n\n    if template.url:\n        args[\"TemplateURL\"] = template.url\n    else:\n        args[\"TemplateBody\"] = template.body\n\n    # When creating args for CreateChangeSet, don't include the stack policy,\n    # since ChangeSets don't support it.\n    if not change_set_name:\n        args.update(generate_stack_policy_args(stack_policy))\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a stack policy object into keyword arguments.", "response": "def generate_stack_policy_args(stack_policy=None):\n    \"\"\" Converts a stack policy object into keyword args.\n\n    Args:\n        stack_policy (:class:`stacker.providers.base.Template`): A template\n            object representing a stack policy.\n\n    Returns:\n        dict: A dictionary of keyword arguments to be used elsewhere.\n    \"\"\"\n\n    args = {}\n    if stack_policy:\n        logger.debug(\"Stack has a stack policy\")\n        if stack_policy.url:\n            # stacker currently does not support uploading stack policies to\n            # S3, so this will never get hit (unless your implementing S3\n            # uploads, and then you're probably reading this comment about why\n            # the exception below was raised :))\n            #\n            # args[\"StackPolicyURL\"] = stack_policy.url\n            raise NotImplementedError\n        else:\n            args[\"StackPolicyBody\"] = stack_policy.body\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget or create the provider for the given region and profile.", "response": "def build(self, region=None, profile=None):\n        \"\"\"Get or create the provider for the given region and profile.\"\"\"\n\n        with self.lock:\n            # memoization lookup key derived from region + profile.\n            key = \"{}-{}\".format(profile, region)\n            try:\n                # assume provider is in provider dictionary.\n                provider = self.providers[key]\n            except KeyError:\n                msg = \"Missed memoized lookup ({}), creating new AWS Provider.\"\n                logger.debug(msg.format(key))\n                if not region:\n                    region = self.region\n                # memoize the result for later.\n                self.providers[key] = Provider(\n                    get_session(region=region, profile=profile),\n                    region=region,\n                    **self.kwargs\n                )\n                provider = self.providers[key]\n\n        return provider"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_events(self, stack_name, chronological=True):\n        next_token = None\n        event_list = []\n        while True:\n            if next_token is not None:\n                events = self.cloudformation.describe_stack_events(\n                    StackName=stack_name, NextToken=next_token\n                )\n            else:\n                events = self.cloudformation.describe_stack_events(\n                    StackName=stack_name\n                )\n            event_list.append(events['StackEvents'])\n            next_token = events.get('NextToken', None)\n            if next_token is None:\n                break\n            time.sleep(GET_EVENTS_SLEEP)\n        if chronological:\n            return reversed(sum(event_list, []))\n        else:\n            return sum(event_list, [])", "response": "Get the events in batches and return in chronological order"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses events and returns latest roll back reason", "response": "def get_rollback_status_reason(self, stack_name):\n        \"\"\"Process events and returns latest roll back reason\"\"\"\n        event = next((item for item in self.get_events(stack_name,\n                      False) if item[\"ResourceStatus\"] ==\n                      \"UPDATE_ROLLBACK_IN_PROGRESS\"), None)\n        if event:\n            reason = event[\"ResourceStatusReason\"]\n            return reason\n        else:\n            event = next((item for item in self.get_events(stack_name)\n                          if item[\"ResourceStatus\"] ==\n                          \"ROLLBACK_IN_PROGRESS\"), None)\n            reason = event[\"ResourceStatusReason\"]\n            return reason"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow and then tail the event log", "response": "def tail(self, stack_name, cancel, log_func=_tail_print, sleep_time=5,\n             include_initial=True):\n        \"\"\"Show and then tail the event log\"\"\"\n        # First dump the full list of events in chronological order and keep\n        # track of the events we've seen already\n        seen = set()\n        initial_events = self.get_events(stack_name)\n        for e in initial_events:\n            if include_initial:\n                log_func(e)\n            seen.add(e['EventId'])\n\n        # Now keep looping through and dump the new events\n        while True:\n            events = self.get_events(stack_name)\n            for e in events:\n                if e['EventId'] not in seen:\n                    log_func(e)\n                    seen.add(e['EventId'])\n            if cancel.wait(sleep_time):\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_stack(self, fqn, template, parameters, tags,\n                     force_change_set=False, stack_policy=None,\n                     **kwargs):\n        \"\"\"Create a new Cloudformation stack.\n\n        Args:\n            fqn (str): The fully qualified name of the Cloudformation stack.\n            template (:class:`stacker.providers.base.Template`): A Template\n                object to use when creating the stack.\n            parameters (list): A list of dictionaries that defines the\n                parameter list to be applied to the Cloudformation stack.\n            tags (list): A list of dictionaries that defines the tags\n                that should be applied to the Cloudformation stack.\n            force_change_set (bool): Whether or not to force change set use.\n            stack_policy (:class:`stacker.providers.base.Template`): A template\n                object representing a stack policy.\n        \"\"\"\n\n        logger.debug(\"Attempting to create stack %s:.\", fqn)\n        logger.debug(\"    parameters: %s\", parameters)\n        logger.debug(\"    tags: %s\", tags)\n        if template.url:\n            logger.debug(\"    template_url: %s\", template.url)\n        else:\n            logger.debug(\"    no template url, uploading template \"\n                         \"directly.\")\n        if force_change_set:\n            logger.debug(\"force_change_set set to True, creating stack with \"\n                         \"changeset.\")\n            _changes, change_set_id = create_change_set(\n                self.cloudformation, fqn, template, parameters, tags,\n                'CREATE', service_role=self.service_role, **kwargs\n            )\n\n            self.cloudformation.execute_change_set(\n                ChangeSetName=change_set_id,\n            )\n        else:\n            args = generate_cloudformation_args(\n                fqn, parameters, tags, template,\n                service_role=self.service_role,\n                stack_policy=stack_policy,\n            )\n\n            try:\n                self.cloudformation.create_stack(**args)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Message'] == ('TemplateURL must '\n                                                      'reference a valid S3 '\n                                                      'object to which you '\n                                                      'have access.'):\n                    s3_fallback(fqn, template, parameters, tags,\n                                self.cloudformation.create_stack,\n                                self.service_role)\n                else:\n                    raise", "response": "Creates a new Cloudformation stack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_update_method(self, force_interactive, force_change_set):\n        if self.interactive or force_interactive:\n            return self.interactive_update_stack\n        elif force_change_set:\n            return self.noninteractive_changeset_update\n        else:\n            return self.default_update_stack", "response": "Select the correct update method when updating a stack."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_stack_for_update(self, stack, tags):\n\n        if self.is_stack_destroyed(stack):\n            return False\n        elif self.is_stack_completed(stack):\n            return True\n\n        stack_name = self.get_stack_name(stack)\n        stack_status = self.get_stack_status(stack)\n\n        if self.is_stack_in_progress(stack):\n            raise exceptions.StackUpdateBadStatus(\n                stack_name, stack_status,\n                'Update already in-progress')\n\n        if not self.is_stack_recreatable(stack):\n            raise exceptions.StackUpdateBadStatus(\n                stack_name, stack_status,\n                'Unsupported state for re-creation')\n\n        if not self.recreate_failed:\n            raise exceptions.StackUpdateBadStatus(\n                stack_name, stack_status,\n                'Stack re-creation is disabled. Run stacker again with the '\n                '--recreate-failed option to force it to be deleted and '\n                'created from scratch.')\n\n        stack_tags = self.get_stack_tags(stack)\n        if not check_tags_contain(stack_tags, tags):\n            raise exceptions.StackUpdateBadStatus(\n                stack_name, stack_status,\n                'Tags differ from current configuration, possibly not created '\n                'with stacker')\n\n        if self.interactive:\n            sys.stdout.write(\n                'The \\\"%s\\\" stack is in a failed state (%s).\\n'\n                'It cannot be updated, but it can be deleted and re-created.\\n'\n                'All its current resources will IRREVERSIBLY DESTROYED.\\n'\n                'Proceed carefully!\\n\\n' % (stack_name, stack_status))\n            sys.stdout.flush()\n\n            ask_for_approval(include_verbose=False)\n\n        logger.warn('Destroying stack \\\"%s\\\" for re-creation', stack_name)\n        self.destroy_stack(stack)\n\n        return False", "response": "Prepares a stack for updating."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating a Cloudformation stack with the specified parameters and tags.", "response": "def update_stack(self, fqn, template, old_parameters, parameters, tags,\n                     force_interactive=False, force_change_set=False,\n                     stack_policy=None, **kwargs):\n        \"\"\"Update a Cloudformation stack.\n\n        Args:\n            fqn (str): The fully qualified name of the Cloudformation stack.\n            template (:class:`stacker.providers.base.Template`): A Template\n                object to use when updating the stack.\n            old_parameters (list): A list of dictionaries that defines the\n                parameter list on the existing Cloudformation stack.\n            parameters (list): A list of dictionaries that defines the\n                parameter list to be applied to the Cloudformation stack.\n            tags (list): A list of dictionaries that defines the tags\n                that should be applied to the Cloudformation stack.\n            force_interactive (bool): A flag that indicates whether the update\n                should be interactive. If set to True, interactive mode will\n                be used no matter if the provider is in interactive mode or\n                not. False will follow the behavior of the provider.\n            force_change_set (bool): A flag that indicates whether the update\n                must be executed with a change set.\n            stack_policy (:class:`stacker.providers.base.Template`): A template\n                object representing a stack policy.\n        \"\"\"\n        logger.debug(\"Attempting to update stack %s:\", fqn)\n        logger.debug(\"    parameters: %s\", parameters)\n        logger.debug(\"    tags: %s\", tags)\n        if template.url:\n            logger.debug(\"    template_url: %s\", template.url)\n        else:\n            logger.debug(\"    no template url, uploading template directly.\")\n        update_method = self.select_update_method(force_interactive,\n                                                  force_change_set)\n\n        return update_method(fqn, template, old_parameters, parameters,\n                             stack_policy=stack_policy, tags=tags, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a stack policy when using changesets.", "response": "def deal_with_changeset_stack_policy(self, fqn, stack_policy):\n        \"\"\" Set a stack policy when using changesets.\n\n        ChangeSets don't allow you to set stack policies in the same call to\n        update them. This sets it before executing the changeset if the\n        stack policy is passed in.\n\n        Args:\n            stack_policy (:class:`stacker.providers.base.Template`): A template\n                object representing a stack policy.\n        \"\"\"\n        if stack_policy:\n            kwargs = generate_stack_policy_args(stack_policy)\n            kwargs[\"StackName\"] = fqn\n            logger.debug(\"Setting stack policy on %s.\", fqn)\n            self.cloudformation.set_stack_policy(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a Cloudformation stack in interactive mode.", "response": "def interactive_update_stack(self, fqn, template, old_parameters,\n                                 parameters, stack_policy, tags,\n                                 **kwargs):\n        \"\"\"Update a Cloudformation stack in interactive mode.\n\n        Args:\n            fqn (str): The fully qualified name of the Cloudformation stack.\n            template (:class:`stacker.providers.base.Template`): A Template\n                object to use when updating the stack.\n            old_parameters (list): A list of dictionaries that defines the\n                parameter list on the existing Cloudformation stack.\n            parameters (list): A list of dictionaries that defines the\n                parameter list to be applied to the Cloudformation stack.\n            stack_policy (:class:`stacker.providers.base.Template`): A template\n                object representing a stack policy.\n            tags (list): A list of dictionaries that defines the tags\n                that should be applied to the Cloudformation stack.\n        \"\"\"\n        logger.debug(\"Using interactive provider mode for %s.\", fqn)\n        changes, change_set_id = create_change_set(\n            self.cloudformation, fqn, template, parameters, tags,\n            'UPDATE', service_role=self.service_role, **kwargs\n        )\n        old_parameters_as_dict = self.params_as_dict(old_parameters)\n        new_parameters_as_dict = self.params_as_dict(\n            [x\n             if 'ParameterValue' in x\n             else {'ParameterKey': x['ParameterKey'],\n                   'ParameterValue': old_parameters_as_dict[x['ParameterKey']]}\n             for x in parameters]\n        )\n        params_diff = diff_parameters(\n            old_parameters_as_dict,\n            new_parameters_as_dict)\n\n        action = \"replacements\" if self.replacements_only else \"changes\"\n        full_changeset = changes\n        if self.replacements_only:\n            changes = requires_replacement(changes)\n\n        if changes or params_diff:\n            ui.lock()\n            try:\n                output_summary(fqn, action, changes, params_diff,\n                               replacements_only=self.replacements_only)\n                ask_for_approval(\n                    full_changeset=full_changeset,\n                    params_diff=params_diff,\n                    include_verbose=True,\n                )\n            finally:\n                ui.unlock()\n\n        self.deal_with_changeset_stack_policy(fqn, stack_policy)\n\n        self.cloudformation.execute_change_set(\n            ChangeSetName=change_set_id,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate a Cloudformation stack using a change set.", "response": "def noninteractive_changeset_update(self, fqn, template, old_parameters,\n                                        parameters, stack_policy, tags,\n                                        **kwargs):\n        \"\"\"Update a Cloudformation stack using a change set.\n\n        This is required for stacks with a defined Transform (i.e. SAM), as the\n        default update_stack API cannot be used with them.\n\n        Args:\n            fqn (str): The fully qualified name of the Cloudformation stack.\n            template (:class:`stacker.providers.base.Template`): A Template\n                object to use when updating the stack.\n            old_parameters (list): A list of dictionaries that defines the\n                parameter list on the existing Cloudformation stack.\n            parameters (list): A list of dictionaries that defines the\n                parameter list to be applied to the Cloudformation stack.\n            stack_policy (:class:`stacker.providers.base.Template`): A template\n                object representing a stack policy.\n            tags (list): A list of dictionaries that defines the tags\n                that should be applied to the Cloudformation stack.\n        \"\"\"\n        logger.debug(\"Using noninterative changeset provider mode \"\n                     \"for %s.\", fqn)\n        _changes, change_set_id = create_change_set(\n            self.cloudformation, fqn, template, parameters, tags,\n            'UPDATE', service_role=self.service_role, **kwargs\n        )\n\n        self.deal_with_changeset_stack_policy(fqn, stack_policy)\n\n        self.cloudformation.execute_change_set(\n            ChangeSetName=change_set_id,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating a Cloudformation stack in default mode. Args: fqn (str): The fully qualified name of the Cloudformation stack. template (:class:`stacker.providers.base.Template`): A Template object to use when updating the stack. old_parameters (list): A list of dictionaries that defines the parameter list on the existing Cloudformation stack. parameters (list): A list of dictionaries that defines the parameter list to be applied to the Cloudformation stack. tags (list): A list of dictionaries that defines the tags that should be applied to the Cloudformation stack. stack_policy (:class:`stacker.providers.base.Template`): A template object representing a stack policy.", "response": "def default_update_stack(self, fqn, template, old_parameters, parameters,\n                             tags, stack_policy=None, **kwargs):\n        \"\"\"Update a Cloudformation stack in default mode.\n\n        Args:\n            fqn (str): The fully qualified name of the Cloudformation stack.\n            template (:class:`stacker.providers.base.Template`): A Template\n                object to use when updating the stack.\n            old_parameters (list): A list of dictionaries that defines the\n                parameter list on the existing Cloudformation stack.\n            parameters (list): A list of dictionaries that defines the\n                parameter list to be applied to the Cloudformation stack.\n            tags (list): A list of dictionaries that defines the tags\n                that should be applied to the Cloudformation stack.\n            stack_policy (:class:`stacker.providers.base.Template`): A template\n                object representing a stack policy.\n        \"\"\"\n\n        logger.debug(\"Using default provider mode for %s.\", fqn)\n        args = generate_cloudformation_args(\n            fqn, parameters, tags, template,\n            service_role=self.service_role,\n            stack_policy=stack_policy,\n        )\n\n        try:\n            self.cloudformation.update_stack(**args)\n        except botocore.exceptions.ClientError as e:\n            if \"No updates are to be performed.\" in str(e):\n                logger.debug(\n                    \"Stack %s did not change, not updating.\",\n                    fqn,\n                )\n                raise exceptions.StackDidNotChange\n            elif e.response['Error']['Message'] == ('TemplateURL must '\n                                                    'reference a valid '\n                                                    'S3 object to which '\n                                                    'you have access.'):\n                s3_fallback(fqn, template, parameters, tags,\n                            self.cloudformation.update_stack,\n                            self.service_role)\n            else:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_stack_info(self, stack):\n        stack_name = stack['StackId']\n\n        try:\n            template = self.cloudformation.get_template(\n                StackName=stack_name)['TemplateBody']\n        except botocore.exceptions.ClientError as e:\n            if \"does not exist\" not in str(e):\n                raise\n            raise exceptions.StackDoesNotExist(stack_name)\n\n        parameters = self.params_as_dict(stack.get('Parameters', []))\n\n        return [json.dumps(template), parameters]", "response": "Get the template and parameters of the stack currently in AWS\n 69"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_session(region, profile=None):\n    if profile is None:\n        logger.debug(\"No AWS profile explicitly provided. \"\n                     \"Falling back to default.\")\n        profile = default_profile\n\n    logger.debug(\"Building session using profile \\\"%s\\\" in region \\\"%s\\\"\"\n                 % (profile, region))\n\n    session = boto3.Session(region_name=region, profile_name=profile)\n    c = session._session.get_component('credential_provider')\n    provider = c.get_provider('assume-role')\n    provider.cache = credential_cache\n    provider._prompter = ui.getpass\n    return session", "response": "Creates a boto3 session with a cache\n            credential caching\n countryCode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancel():\n    cancel = threading.Event()\n\n    def cancel_execution(signum, frame):\n        signame = SIGNAL_NAMES.get(signum, signum)\n        logger.info(\"Signal %s received, quitting \"\n                    \"(this can take some time)...\", signame)\n        cancel.set()\n\n    signal.signal(signal.SIGINT, cancel_execution)\n    signal.signal(signal.SIGTERM, cancel_execution)\n    return cancel", "response": "Returns a threading. Event that will get set when SIGTERM or\n    SIGINT are triggered."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_lookup_handler(lookup_type, handler_or_path):\n    handler = handler_or_path\n    if isinstance(handler_or_path, basestring):\n        handler = load_object_from_string(handler_or_path)\n    LOOKUP_HANDLERS[lookup_type] = handler\n    if type(handler) != type:\n        # Hander is a not a new-style handler\n        logger = logging.getLogger(__name__)\n        logger.warning(\"Registering lookup `%s`: Please upgrade to use the \"\n                       \"new style of Lookups.\" % lookup_type)\n        warnings.warn(\n            # For some reason, this does not show up...\n            # Leaving it in anyway\n            \"Lookup `%s`: Please upgrade to use the new style of Lookups\"\n            \".\" % lookup_type,\n            DeprecationWarning,\n            stacklevel=2,\n        )", "response": "Register a new lookup handler under the given lookup type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_lookups(variable, context, provider):\n    resolved_lookups = {}\n    for lookup in variable.lookups:\n        try:\n            handler = LOOKUP_HANDLERS[lookup.type]\n        except KeyError:\n            raise UnknownLookupType(lookup)\n        try:\n            resolved_lookups[lookup] = handler(\n                value=lookup.input,\n                context=context,\n                provider=provider,\n            )\n        except Exception as e:\n            raise FailedVariableLookup(variable.name, lookup, e)\n    return resolved_lookups", "response": "Resolve a set of lookups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(cls, value, **kwargs):\n\n        try:\n            env_var_name, default_val = value.split(\"::\", 1)\n        except ValueError:\n            raise ValueError(\"Invalid value for default: %s. Must be in \"\n                             \"<env_var>::<default value> format.\" % value)\n\n        if env_var_name in kwargs['context'].environment:\n            return kwargs['context'].environment[env_var_name]\n        else:\n            return default_val", "response": "Return a value from the environment or fall back to a default."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract any lookups within a string.", "response": "def extract_lookups_from_string(value):\n    \"\"\"Extract any lookups within a string.\n\n    Args:\n        value (str): string value we're extracting lookups from\n\n    Returns:\n        list: list of :class:`stacker.lookups.Lookup` if any\n\n    \"\"\"\n    lookups = set()\n    for match in LOOKUP_REGEX.finditer(value):\n        groupdict = match.groupdict()\n        raw = match.groups()[0]\n        lookup_type = groupdict[\"type\"]\n        lookup_input = groupdict[\"input\"]\n        lookups.add(Lookup(lookup_type, lookup_input, raw))\n    return lookups"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a node to the internal cache if it does not exist yet.", "response": "def add_node(self, node_name):\n        \"\"\" Add a node if it does not exist yet, or error out.\n\n        Args:\n            node_name (str): The unique name of the node to add.\n\n        Raises:\n            KeyError: Raised if a node with the same name already exist in the\n                      graph\n        \"\"\"\n        graph = self.graph\n        if node_name in graph:\n            raise KeyError('node %s already exists' % node_name)\n        graph[node_name] = set()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_node(self, node_name):\n        graph = self.graph\n        if node_name not in graph:\n            raise KeyError('node %s does not exist' % node_name)\n        graph.pop(node_name)\n\n        for node, edges in graph.items():\n            if node_name in edges:\n                edges.remove(node_name)", "response": "Deletes this node and all edges referencing it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an edge between the specified nodes.", "response": "def add_edge(self, ind_node, dep_node):\n        \"\"\" Add an edge (dependency) between the specified nodes.\n\n        Args:\n            ind_node (str): The independent node to add an edge to.\n            dep_node (str): The dependent node that has a dependency on the\n                            ind_node.\n\n        Raises:\n            KeyError: Either the ind_node, or dep_node do not exist.\n            DAGValidationError: Raised if the resulting graph is invalid.\n        \"\"\"\n        graph = self.graph\n        if ind_node not in graph:\n            raise KeyError('independent node %s does not exist' % ind_node)\n        if dep_node not in graph:\n            raise KeyError('dependent node %s does not exist' % dep_node)\n        test_graph = deepcopy(graph)\n        test_graph[ind_node].add(dep_node)\n        test_dag = DAG()\n        test_dag.graph = test_graph\n        is_valid, message = test_dag.validate()\n        if is_valid:\n            graph[ind_node].add(dep_node)\n        else:\n            raise DAGValidationError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an edge between the node and the dependent node.", "response": "def delete_edge(self, ind_node, dep_node):\n        \"\"\" Delete an edge from the graph.\n\n        Args:\n            ind_node (str): The independent node to delete an edge from.\n            dep_node (str): The dependent node that has a dependency on the\n                            ind_node.\n\n        Raises:\n            KeyError: Raised when the edge doesn't already exist.\n        \"\"\"\n        graph = self.graph\n        if dep_node not in graph.get(ind_node, []):\n            raise KeyError(\n                \"No edge exists between %s and %s.\" % (ind_node, dep_node)\n            )\n        graph[ind_node].remove(dep_node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a new DAG with the edges reversed.", "response": "def transpose(self):\n        \"\"\" Builds a new graph with the edges reversed.\n\n        Returns:\n            :class:`stacker.dag.DAG`: The transposed graph.\n        \"\"\"\n        graph = self.graph\n        transposed = DAG()\n        for node, edges in graph.items():\n            transposed.add_node(node)\n        for node, edges in graph.items():\n            # for each edge A -> B, transpose it so that B -> A\n            for edge in edges:\n                transposed.add_edge(edge, node)\n        return transposed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwalk the tree in reverse topological order.", "response": "def walk(self, walk_func):\n        \"\"\" Walks each node of the graph in reverse topological order.\n        This can be used to perform a set of operations, where the next\n        operation depends on the previous operation. It's important to note\n        that walking happens serially, and is not paralellized.\n\n        Args:\n            walk_func (:class:`types.FunctionType`): The function to be called\n                on each node of the graph.\n        \"\"\"\n        nodes = self.topological_sort()\n        # Reverse so we start with nodes that have no dependencies.\n        nodes.reverse()\n\n        for n in nodes:\n            walk_func(n)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a transitive reduction on the DAG.", "response": "def transitive_reduction(self):\n        \"\"\" Performs a transitive reduction on the DAG. The transitive\n        reduction of a graph is a graph with as few edges as possible with the\n        same reachability as the original graph.\n\n        See https://en.wikipedia.org/wiki/Transitive_reduction\n        \"\"\"\n        combinations = []\n        for node, edges in self.graph.items():\n            combinations += [[node, edge] for edge in edges]\n\n        while True:\n            new_combinations = []\n            for comb1 in combinations:\n                for comb2 in combinations:\n                    if not comb1[-1] == comb2[0]:\n                        continue\n                    new_entry = comb1 + comb2[1:]\n                    if new_entry not in combinations:\n                        new_combinations.append(new_entry)\n            if not new_combinations:\n                break\n            combinations += new_combinations\n\n        constructed = {(c[0], c[-1]) for c in combinations if len(c) != 2}\n        for node, edges in self.graph.items():\n            bad_nodes = {e for n, e in constructed if node == n}\n            self.graph[node] = edges - bad_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenames a node in the edges list.", "response": "def rename_edges(self, old_node_name, new_node_name):\n        \"\"\" Change references to a node in existing edges.\n\n        Args:\n            old_node_name (str): The old name for the node.\n            new_node_name (str): The new name for the node.\n        \"\"\"\n        graph = self.graph\n        for node, edges in graph.items():\n            if node == old_node_name:\n                graph[new_node_name] = copy(edges)\n                del graph[old_node_name]\n\n            else:\n                if old_node_name in edges:\n                    edges.remove(old_node_name)\n                    edges.add(new_node_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef downstream(self, node):\n        graph = self.graph\n        if node not in graph:\n            raise KeyError('node %s is not in graph' % node)\n        return list(graph[node])", "response": "Returns a list of all nodes that are immediately downstream from the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all_downstreams(self, node):\n        nodes = [node]\n        nodes_seen = set()\n        i = 0\n        while i < len(nodes):\n            downstreams = self.downstream(nodes[i])\n            for downstream_node in downstreams:\n                if downstream_node not in nodes_seen:\n                    nodes_seen.add(downstream_node)\n                    nodes.append(downstream_node)\n            i += 1\n        return [\n            node_ for node_ in self.topological_sort() if node_ in nodes_seen\n        ]", "response": "Returns a list of all nodes that are downstream from the given node in the dependency graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new DAG with only the given nodes and their dependencies.", "response": "def filter(self, nodes):\n        \"\"\" Returns a new DAG with only the given nodes and their\n        dependencies.\n\n        Args:\n            nodes (list): The nodes you are interested in.\n\n        Returns:\n            :class:`stacker.dag.DAG`: The filtered graph.\n        \"\"\"\n\n        filtered_dag = DAG()\n\n        # Add only the nodes we need.\n        for node in nodes:\n            filtered_dag.add_node_if_not_exists(node)\n            for edge in self.all_downstreams(node):\n                filtered_dag.add_node_if_not_exists(edge)\n\n        # Now, rebuild the graph for each node that's present.\n        for node, edges in self.graph.items():\n            if node in filtered_dag.graph:\n                filtered_dag.graph[node] = edges\n\n        return filtered_dag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_dict(self, graph_dict):\n\n        self.reset_graph()\n        for new_node in graph_dict:\n            self.add_node(new_node)\n        for ind_node, dep_nodes in graph_dict.items():\n            if not isinstance(dep_nodes, collections.Iterable):\n                raise TypeError('%s: dict values must be lists' % ind_node)\n            for dep_node in dep_nodes:\n                self.add_edge(ind_node, dep_node)", "response": "Reset the graph and build it from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all nodes in the graph with no dependencies.", "response": "def ind_nodes(self):\n        \"\"\" Returns a list of all nodes in the graph with no dependencies.\n\n        Returns:\n            list: A list of all independent nodes.\n        \"\"\"\n        graph = self.graph\n\n        dependent_nodes = set(\n            node for dependents\n            in graph.values() for node in dependents)\n        return [node_ for node_ in graph if node_ not in dependent_nodes]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns (Boolean, message) of whether DAG is valid.", "response": "def validate(self):\n        \"\"\" Returns (Boolean, message) of whether DAG is valid. \"\"\"\n        if len(self.ind_nodes()) == 0:\n            return (False, 'no independent nodes detected')\n        try:\n            self.topological_sort()\n        except ValueError as e:\n            return (False, str(e))\n        return (True, 'valid')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef topological_sort(self):\n        graph = self.graph\n\n        in_degree = {}\n        for u in graph:\n            in_degree[u] = 0\n\n        for u in graph:\n            for v in graph[u]:\n                in_degree[v] += 1\n\n        queue = deque()\n        for u in in_degree:\n            if in_degree[u] == 0:\n                queue.appendleft(u)\n\n        sorted_graph = []\n        while queue:\n            u = queue.pop()\n            sorted_graph.append(u)\n            for v in sorted(graph[u]):\n                in_degree[v] -= 1\n                if in_degree[v] == 0:\n                    queue.appendleft(v)\n\n        if len(sorted_graph) == len(graph):\n            return sorted_graph\n        else:\n            raise ValueError('graph is not acyclic')", "response": "Returns a topologically sorted list of nodes in the DAG."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwalk the graph in parallel if it can.", "response": "def walk(self, dag, walk_func):\n        \"\"\" Walks each node of the graph, in parallel if it can.\n        The walk_func is only called when the nodes dependencies have been\n        satisfied\n        \"\"\"\n\n        # First, we'll topologically sort all of the nodes, with nodes that\n        # have no dependencies first. We do this to ensure that we don't call\n        # .join on a thread that hasn't yet been started.\n        #\n        # TODO(ejholmes): An alternative would be to ensure that Thread.join\n        # blocks if the thread has not yet been started.\n        nodes = dag.topological_sort()\n        nodes.reverse()\n\n        # This maps a node name to a thread of execution.\n        threads = {}\n\n        # Blocks until all of the given nodes have completed execution (whether\n        # successfully, or errored). Returns True if all nodes returned True.\n        def wait_for(nodes):\n            for node in nodes:\n                thread = threads[node]\n                while thread.is_alive():\n                    threads[node].join(0.5)\n\n        # For each node in the graph, we're going to allocate a thread to\n        # execute. The thread will block executing walk_func, until all of the\n        # nodes dependencies have executed.\n        for node in nodes:\n            def fn(n, deps):\n                if deps:\n                    logger.debug(\n                        \"%s waiting for %s to complete\",\n                        n,\n                        \", \".join(deps))\n\n                # Wait for all dependencies to complete.\n                wait_for(deps)\n\n                logger.debug(\"%s starting\", n)\n\n                self.semaphore.acquire()\n                try:\n                    return walk_func(n)\n                finally:\n                    self.semaphore.release()\n\n            deps = dag.all_downstreams(node)\n            threads[node] = Thread(target=fn, args=(node, deps), name=node)\n\n        # Start up all of the threads.\n        for node in nodes:\n            threads[node].start()\n\n        # Wait for all threads to complete executing.\n        wait_for(nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the get_output method of the object that is passed to the provider.", "response": "def handle(cls, value, provider=None, **kwargs):\n        \"\"\"Fetch an output from the designated stack.\n\n        Args:\n            value (str): string with the following format:\n                <stack_name>::<output_name>, ie. some-stack::SomeOutput\n            provider (:class:`stacker.provider.base.BaseProvider`): subclass of\n                the base provider\n\n        Returns:\n            str: output from the specified stack\n        \"\"\"\n\n        if provider is None:\n            raise ValueError('Provider is required')\n\n        d = deconstruct(value)\n        stack_fqn = d.stack_name\n        output = provider.get_output(stack_fqn, d.output_name)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cf_tokenize(s):\n    t = []\n    parts = split_re.split(s)\n    for part in parts:\n        cf_func = replace_re.search(part)\n        if cf_func:\n            args = [a.strip(\"'\\\" \") for a in cf_func.group(\"args\").split(\",\")]\n            t.append(HELPERS[cf_func.group(\"helper\")](*args).data)\n        else:\n            t.append(part)\n    return t", "response": "Parses a string that contains a Cloudformation helper function and returns a list of Cloudformation objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the supplied string on the given delimiter and provide a list of Subnets.", "response": "def handle(cls, value, **kwargs):\n        \"\"\"Split the supplied string on the given delimiter, providing a list.\n\n        Format of value:\n\n            <delimiter>::<value>\n\n        For example:\n\n            Subnets: ${split ,::subnet-1,subnet-2,subnet-3}\n\n        Would result in the variable `Subnets` getting a list consisting of:\n\n            [\"subnet-1\", \"subnet-2\", \"subnet-3\"]\n\n        This is particularly useful when getting an output from another stack\n        that contains a list. For example, the standard vpc blueprint outputs\n        the list of Subnets it creates as a pair of Outputs (PublicSubnets,\n        PrivateSubnets) that are comma separated, so you could use this in your\n        config:\n\n            Subnets: ${split ,::${output vpc::PrivateSubnets}}\n        \"\"\"\n\n        try:\n            delimiter, text = value.split(\"::\", 1)\n        except ValueError:\n            raise ValueError(\"Invalid value for split: %s. Must be in \"\n                             \"<delimiter>::<text> format.\" % value)\n\n        return text.split(delimiter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef should_update(stack):\n    if stack.locked:\n        if not stack.force:\n            logger.debug(\"Stack %s locked and not in --force list. \"\n                         \"Refusing to update.\", stack.name)\n            return False\n        else:\n            logger.debug(\"Stack %s locked, but is in --force \"\n                         \"list.\", stack.name)\n    return True", "response": "Tests whether a stack should be updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef should_submit(stack):\n    if stack.enabled:\n        return True\n\n    logger.debug(\"Stack %s is not enabled.  Skipping.\", stack.name)\n    return False", "response": "Tests whether a stack should be submitted to CF for update or create."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _resolve_parameters(parameters, blueprint):\n    params = {}\n    param_defs = blueprint.get_parameter_definitions()\n\n    for key, value in parameters.items():\n        if key not in param_defs:\n            logger.debug(\"Blueprint %s does not use parameter %s.\",\n                         blueprint.name, key)\n            continue\n        if value is None:\n            logger.debug(\"Got None value for parameter %s, not submitting it \"\n                         \"to cloudformation, default value should be used.\",\n                         key)\n            continue\n        if isinstance(value, bool):\n            logger.debug(\"Converting parameter %s boolean \\\"%s\\\" to string.\",\n                         key, value)\n            value = str(value).lower()\n        params[key] = value\n    return params", "response": "Resolves CloudFormation Parameters for a given list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_missing_parameters(parameter_values, all_params, required_params,\n                               existing_stack=None):\n    \"\"\"Handles any missing parameters.\n\n    If an existing_stack is provided, look up missing parameters there.\n\n    Args:\n        parameter_values (dict): key/value dictionary of stack definition\n            parameters\n        all_params (list): A list of all the parameters used by the\n            template/blueprint.\n        required_params (list): A list of all the parameters required by the\n            template/blueprint.\n        existing_stack (dict): A dict representation of the stack. If\n            provided, will be searched for any missing parameters.\n\n    Returns:\n        list of tuples: The final list of key/value pairs returned as a\n            list of tuples.\n\n    Raises:\n        MissingParameterException: Raised if a required parameter is\n            still missing.\n\n    \"\"\"\n    missing_params = list(set(all_params) - set(parameter_values.keys()))\n    if existing_stack and 'Parameters' in existing_stack:\n        stack_parameters = [\n            p[\"ParameterKey\"] for p in existing_stack[\"Parameters\"]\n        ]\n        for p in missing_params:\n            if p in stack_parameters:\n                logger.debug(\n                    \"Using previous value for parameter %s from existing \"\n                    \"stack\",\n                    p\n                )\n                parameter_values[p] = UsePreviousParameterValue\n    final_missing = list(set(required_params) - set(parameter_values.keys()))\n    if final_missing:\n        raise MissingParameterException(final_missing)\n\n    return list(parameter_values.items())", "response": "Handles any missing parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_hooks(stage, hooks, provider, context, dump, outline):\n    if not outline and not dump and hooks:\n        utils.handle_hooks(\n            stage=stage,\n            hooks=hooks,\n            provider=provider,\n            context=context\n        )", "response": "Handle pre and post hooks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_parameters(self, stack, provider_stack=None):\n        resolved = _resolve_parameters(stack.parameter_values, stack.blueprint)\n        required_parameters = list(stack.required_parameter_definitions)\n        all_parameters = list(stack.all_parameter_definitions)\n        parameters = _handle_missing_parameters(resolved, all_parameters,\n                                                required_parameters,\n                                                provider_stack)\n\n        param_list = []\n\n        for key, value in parameters:\n            param_dict = {\"ParameterKey\": key}\n            if value is UsePreviousParameterValue:\n                param_dict[\"UsePreviousValue\"] = True\n            else:\n                param_dict[\"ParameterValue\"] = str(value)\n\n            param_list.append(param_dict)\n\n        return param_list", "response": "Builds the CloudFormation Parameters for our stack."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _launch_stack(self, stack, **kwargs):\n        old_status = kwargs.get(\"status\")\n        wait_time = 0 if old_status is PENDING else STACK_POLL_TIME\n        if self.cancel.wait(wait_time):\n            return INTERRUPTED\n\n        if not should_submit(stack):\n            return NotSubmittedStatus()\n\n        provider = self.build_provider(stack)\n\n        try:\n            provider_stack = provider.get_stack(stack.fqn)\n        except StackDoesNotExist:\n            provider_stack = None\n\n        if provider_stack and not should_update(stack):\n            stack.set_outputs(\n                self.provider.get_output_dict(provider_stack))\n            return NotUpdatedStatus()\n\n        recreate = False\n        if provider_stack and old_status == SUBMITTED:\n            logger.debug(\n                \"Stack %s provider status: %s\",\n                stack.fqn,\n                provider.get_stack_status(provider_stack),\n            )\n\n            if provider.is_stack_rolling_back(provider_stack):\n                if 'rolling back' in old_status.reason:\n                    return old_status\n\n                logger.debug(\"Stack %s entered a roll back\", stack.fqn)\n                if 'updating' in old_status.reason:\n                    reason = 'rolling back update'\n                else:\n                    reason = 'rolling back new stack'\n\n                return SubmittedStatus(reason)\n            elif provider.is_stack_in_progress(provider_stack):\n                logger.debug(\"Stack %s in progress.\", stack.fqn)\n                return old_status\n            elif provider.is_stack_destroyed(provider_stack):\n                logger.debug(\"Stack %s finished deleting\", stack.fqn)\n                recreate = True\n                # Continue with creation afterwards\n            # Failure must be checked *before* completion, as both will be true\n            # when completing a rollback, and we don't want to consider it as\n            # a successful update.\n            elif provider.is_stack_failed(provider_stack):\n                reason = old_status.reason\n                if 'rolling' in reason:\n                    reason = reason.replace('rolling', 'rolled')\n                status_reason = provider.get_rollback_status_reason(stack.fqn)\n                logger.info(\n                    \"%s Stack Roll Back Reason: \" + status_reason, stack.fqn)\n                return FailedStatus(reason)\n\n            elif provider.is_stack_completed(provider_stack):\n                stack.set_outputs(\n                    provider.get_output_dict(provider_stack))\n                return CompleteStatus(old_status.reason)\n            else:\n                return old_status\n\n        logger.debug(\"Resolving stack %s\", stack.fqn)\n        stack.resolve(self.context, self.provider)\n\n        logger.debug(\"Launching stack %s now.\", stack.fqn)\n        template = self._template(stack.blueprint)\n        stack_policy = self._stack_policy(stack)\n        tags = build_stack_tags(stack)\n        parameters = self.build_parameters(stack, provider_stack)\n        force_change_set = stack.blueprint.requires_change_set\n\n        if recreate:\n            logger.debug(\"Re-creating stack: %s\", stack.fqn)\n            provider.create_stack(stack.fqn, template, parameters,\n                                  tags, stack_policy=stack_policy)\n            return SubmittedStatus(\"re-creating stack\")\n        elif not provider_stack:\n            logger.debug(\"Creating new stack: %s\", stack.fqn)\n            provider.create_stack(stack.fqn, template, parameters, tags,\n                                  force_change_set,\n                                  stack_policy=stack_policy)\n            return SubmittedStatus(\"creating new stack\")\n\n        try:\n            wait = stack.in_progress_behavior == \"wait\"\n            if wait and provider.is_stack_in_progress(provider_stack):\n                return WAITING\n            if provider.prepare_stack_for_update(provider_stack, tags):\n                existing_params = provider_stack.get('Parameters', [])\n                provider.update_stack(\n                    stack.fqn,\n                    template,\n                    existing_params,\n                    parameters,\n                    tags,\n                    force_interactive=stack.protected,\n                    force_change_set=force_change_set,\n                    stack_policy=stack_policy,\n                )\n\n                logger.debug(\"Updating existing stack: %s\", stack.fqn)\n                return SubmittedStatus(\"updating existing stack\")\n            else:\n                return SubmittedStatus(\"destroying stack for re-creation\")\n        except CancelExecution:\n            stack.set_outputs(provider.get_output_dict(provider_stack))\n            return SkippedStatus(reason=\"canceled execution\")\n        except StackDidNotChange:\n            stack.set_outputs(provider.get_output_dict(provider_stack))\n            return DidNotChangeStatus()", "response": "Launches a stack in CloudFormation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a suitable template based on whether or not the bucket is set.", "response": "def _template(self, blueprint):\n        \"\"\"Generates a suitable template based on whether or not an S3 bucket\n        is set.\n\n        If an S3 bucket is set, then the template will be uploaded to S3 first,\n        and CreateStack/UpdateStack operations will use the uploaded template.\n        If not bucket is set, then the template will be inlined.\n        \"\"\"\n        if self.bucket_name:\n            return Template(url=self.s3_stack_push(blueprint))\n        else:\n            return Template(body=blueprint.rendered)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, concurrency=0, outline=False,\n            tail=False, dump=False, *args, **kwargs):\n        \"\"\"Kicks off the build/update of the stacks in the stack_definitions.\n\n        This is the main entry point for the Builder.\n\n        \"\"\"\n        plan = self._generate_plan(tail=tail)\n        if not plan.keys():\n            logger.warn('WARNING: No stacks detected (error in config?)')\n        if not outline and not dump:\n            plan.outline(logging.DEBUG)\n            logger.debug(\"Launching stacks: %s\", \", \".join(plan.keys()))\n            walker = build_walker(concurrency)\n            plan.execute(walker)\n        else:\n            if outline:\n                plan.outline()\n            if dump:\n                plan.dump(directory=dump, context=self.context,\n                          provider=self.provider)", "response": "Runs the build_walker method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_domain(provider, context, **kwargs):\n    session = get_session(provider.region)\n    client = session.client(\"route53\")\n    domain = kwargs.get(\"domain\")\n    if not domain:\n        logger.error(\"domain argument or BaseDomain variable not provided.\")\n        return False\n    zone_id = create_route53_zone(client, domain)\n    return {\"domain\": domain, \"zone_id\": zone_id}", "response": "Create a domain within route53."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef info(self, *args, **kwargs):\n        self.lock()\n        try:\n            return logger.info(*args, **kwargs)\n        finally:\n            self.unlock()", "response": "Logs the line of the current thread owns the underlying lock and or\n        blocks."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert CamelCase to snake_case.", "response": "def camel_to_snake(name):\n    \"\"\"Converts CamelCase to snake_case.\n\n    Args:\n        name (string): The name to convert from CamelCase to snake_case.\n\n    Returns:\n        string: Converted string.\n    \"\"\"\n    s1 = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", name)\n    return re.sub(\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s1).lower()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the id of an existing zone by name.", "response": "def get_hosted_zone_by_name(client, zone_name):\n    \"\"\"Get the zone id of an existing zone by name.\n\n    Args:\n        client (:class:`botocore.client.Route53`): The connection used to\n            interact with Route53's API.\n        zone_name (string): The name of the DNS hosted zone to create.\n\n    Returns:\n        string: The Id of the Hosted Zone.\n    \"\"\"\n    p = client.get_paginator(\"list_hosted_zones\")\n\n    for i in p.paginate():\n        for zone in i[\"HostedZones\"]:\n            if zone[\"Name\"] == zone_name:\n                return parse_zone_id(zone[\"Id\"])\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the Id of an existing zone or create it.", "response": "def get_or_create_hosted_zone(client, zone_name):\n    \"\"\"Get the Id of an existing zone, or create it.\n\n    Args:\n        client (:class:`botocore.client.Route53`): The connection used to\n            interact with Route53's API.\n        zone_name (string): The name of the DNS hosted zone to create.\n\n    Returns:\n        string: The Id of the Hosted Zone.\n    \"\"\"\n    zone_id = get_hosted_zone_by_name(client, zone_name)\n    if zone_id:\n        return zone_id\n\n    logger.debug(\"Zone %s does not exist, creating.\", zone_name)\n\n    reference = uuid.uuid4().hex\n\n    response = client.create_hosted_zone(Name=zone_name,\n                                         CallerReference=reference)\n\n    return parse_zone_id(response[\"HostedZone\"][\"Id\"])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the SOA record for zone_name from zone_id.", "response": "def get_soa_record(client, zone_id, zone_name):\n    \"\"\"Gets the SOA record for zone_name from zone_id.\n\n    Args:\n        client (:class:`botocore.client.Route53`): The connection used to\n            interact with Route53's API.\n        zone_id (string): The AWS Route53 zone id of the hosted zone to query.\n        zone_name (string): The name of the DNS hosted zone to create.\n\n    Returns:\n        :class:`stacker.util.SOARecord`: An object representing the parsed SOA\n            record returned from AWS Route53.\n    \"\"\"\n\n    response = client.list_resource_record_sets(HostedZoneId=zone_id,\n                                                StartRecordName=zone_name,\n                                                StartRecordType=\"SOA\",\n                                                MaxItems=\"1\")\n    return SOARecord(response[\"ResourceRecordSets\"][0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_route53_zone(client, zone_name):\n    if not zone_name.endswith(\".\"):\n        zone_name += \".\"\n    zone_id = get_or_create_hosted_zone(client, zone_name)\n    old_soa = get_soa_record(client, zone_id, zone_name)\n\n    # If the negative cache value is already 300, don't update it.\n    if old_soa.text.min_ttl == \"300\":\n        return zone_id\n\n    new_soa = copy.deepcopy(old_soa)\n    logger.debug(\"Updating negative caching value on zone %s to 300.\",\n                 zone_name)\n    new_soa.text.min_ttl = \"300\"\n    client.change_resource_record_sets(\n        HostedZoneId=zone_id,\n        ChangeBatch={\n            \"Comment\": \"Update SOA min_ttl to 300.\",\n            \"Changes\": [\n                {\n                    \"Action\": \"UPSERT\",\n                    \"ResourceRecordSet\": {\n                        \"Name\": zone_name,\n                        \"Type\": \"SOA\",\n                        \"TTL\": old_soa.ttl,\n                        \"ResourceRecords\": [\n                            {\n                                \"Value\": str(new_soa.text)\n                            }\n                        ]\n                    }\n                },\n            ]\n        }\n    )\n    return zone_id", "response": "Creates a new zone_name if it doesn t already exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a. delimited string representing the full path to an object and returns that object.", "response": "def load_object_from_string(fqcn):\n    \"\"\"Converts \".\" delimited strings to a python object.\n\n    Given a \".\" delimited string representing the full path to an object\n    (function, class, variable) inside a module, return that object.  Example:\n\n    load_object_from_string(\"os.path.basename\")\n    load_object_from_string(\"logging.Logger\")\n    load_object_from_string(\"LocalClassName\")\n    \"\"\"\n    module_path = \"__main__\"\n    object_name = fqcn\n    if \".\" in fqcn:\n        module_path, object_name = fqcn.rsplit(\".\", 1)\n        importlib.import_module(module_path)\n    return getattr(sys.modules[module_path], object_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a YAML string and returns an OrderedDict.", "response": "def yaml_to_ordered_dict(stream, loader=yaml.SafeLoader):\n    \"\"\"Provides yaml.load alternative with preserved dictionary order.\n\n    Args:\n        stream (string): YAML string to load.\n        loader (:class:`yaml.loader`): PyYAML loader class. Defaults to safe\n            load.\n\n    Returns:\n        OrderedDict: Parsed YAML.\n    \"\"\"\n    class OrderedUniqueLoader(loader):\n        \"\"\"\n        Subclasses the given pyYAML `loader` class.\n\n        Validates all sibling keys to insure no duplicates.\n\n        Returns an OrderedDict instead of a Dict.\n        \"\"\"\n\n        # keys which require no duplicate siblings.\n        NO_DUPE_SIBLINGS = [\"stacks\", \"class_path\"]\n        # keys which require no duplicate children keys.\n        NO_DUPE_CHILDREN = [\"stacks\"]\n\n        def _error_mapping_on_dupe(self, node, node_name):\n            \"\"\"check mapping node for dupe children keys.\"\"\"\n            if isinstance(node, MappingNode):\n                mapping = {}\n                for n in node.value:\n                    a = n[0]\n                    b = mapping.get(a.value, None)\n                    if b:\n                        msg = \"{} mapping cannot have duplicate keys {} {}\"\n                        raise ConstructorError(\n                            msg.format(node_name, b.start_mark, a.start_mark)\n                        )\n                    mapping[a.value] = a\n\n        def _validate_mapping(self, node, deep=False):\n            if not isinstance(node, MappingNode):\n                raise ConstructorError(\n                    None, None,\n                    \"expected a mapping node, but found %s\" % node.id,\n                    node.start_mark)\n            mapping = OrderedDict()\n            for key_node, value_node in node.value:\n                key = self.construct_object(key_node, deep=deep)\n                try:\n                    hash(key)\n                except TypeError as exc:\n                    raise ConstructorError(\n                        \"while constructing a mapping\", node.start_mark,\n                        \"found unhashable key (%s)\" % exc, key_node.start_mark\n                    )\n                # prevent duplicate sibling keys for certain \"keywords\".\n                if key in mapping and key in self.NO_DUPE_SIBLINGS:\n                    msg = \"{} key cannot have duplicate siblings {} {}\"\n                    raise ConstructorError(\n                        msg.format(key, node.start_mark, key_node.start_mark)\n                    )\n                if key in self.NO_DUPE_CHILDREN:\n                    # prevent duplicate children keys for this mapping.\n                    self._error_mapping_on_dupe(value_node, key_node.value)\n                value = self.construct_object(value_node, deep=deep)\n                mapping[key] = value\n            return mapping\n\n        def construct_mapping(self, node, deep=False):\n            \"\"\"Override parent method to use OrderedDict.\"\"\"\n            if isinstance(node, MappingNode):\n                self.flatten_mapping(node)\n            return self._validate_mapping(node, deep=deep)\n\n        def construct_yaml_map(self, node):\n            data = OrderedDict()\n            yield data\n            value = self.construct_mapping(node)\n            data.update(value)\n\n    OrderedUniqueLoader.add_constructor(\n        u'tag:yaml.org,2002:map', OrderedUniqueLoader.construct_yaml_map,\n    )\n    return yaml.load(stream, OrderedUniqueLoader)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cf_safe_name(name):\n    alphanumeric = r\"[a-zA-Z0-9]+\"\n    parts = re.findall(alphanumeric, name)\n    return \"\".join([uppercase_first_letter(part) for part in parts])", "response": "Converts a string to a safe string for a Cloudformation\n    Resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_config_directory():\n    # avoid circular import\n    from .commands.stacker import Stacker\n    command = Stacker()\n    namespace = command.parse_args()\n    return os.path.dirname(namespace.config.name)", "response": "Return the directory the config file is located in."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenabling translators to read values from files.", "response": "def read_value_from_path(value):\n    \"\"\"Enables translators to read values from files.\n\n    The value can be referred to with the `file://` prefix. ie:\n\n        conf_key: ${kms file://kms_value.txt}\n\n    \"\"\"\n    if value.startswith('file://'):\n        path = value.split('file://', 1)[1]\n        config_directory = get_config_directory()\n        relative_path = os.path.join(config_directory, path)\n        with open(relative_path) as read_file:\n            value = read_file.read()\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_s3_bucket(s3_client, bucket_name, bucket_region):\n    try:\n        s3_client.head_bucket(Bucket=bucket_name)\n    except botocore.exceptions.ClientError as e:\n        if e.response['Error']['Message'] == \"Not Found\":\n            logger.debug(\"Creating bucket %s.\", bucket_name)\n            create_args = {\"Bucket\": bucket_name}\n            location_constraint = s3_bucket_location_constraint(\n                bucket_region\n            )\n            if location_constraint:\n                create_args[\"CreateBucketConfiguration\"] = {\n                    \"LocationConstraint\": location_constraint\n                }\n            s3_client.create_bucket(**create_args)\n        elif e.response['Error']['Message'] == \"Forbidden\":\n            logger.exception(\"Access denied for bucket %s.  Did \" +\n                             \"you remember to use a globally unique name?\",\n                             bucket_name)\n            raise\n        else:\n            logger.exception(\"Error creating bucket %s. Error %s\",\n                             bucket_name, e.response)\n            raise", "response": "Ensures an s3 bucket exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the archive to destination.", "response": "def extract(self, destination):\n        \"\"\"Extract the archive.\"\"\"\n        with zipfile.ZipFile(self.archive, 'r') as zip_ref:\n            zip_ref.extractall(destination)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that source processor cache directories exist.", "response": "def create_cache_directories(self):\n        \"\"\"Ensure that SourceProcessor cache directories exist.\"\"\"\n        if not os.path.isdir(self.package_cache_dir):\n            if not os.path.isdir(self.stacker_cache_dir):\n                os.mkdir(self.stacker_cache_dir)\n            os.mkdir(self.package_cache_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_package_sources(self):\n        # Checkout local modules\n        for config in self.sources.get('local', []):\n            self.fetch_local_package(config=config)\n        # Checkout S3 repositories specified in config\n        for config in self.sources.get('s3', []):\n            self.fetch_s3_package(config=config)\n        # Checkout git repositories specified in config\n        for config in self.sources.get('git', []):\n            self.fetch_git_package(config=config)", "response": "Make remote python packages available for local use."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch a local package from the local path.", "response": "def fetch_local_package(self, config):\n        \"\"\"Make a local path available to current stacker config.\n\n        Args:\n            config (dict): 'local' path config dictionary\n\n        \"\"\"\n        # Update sys.path & merge in remote configs (if necessary)\n        self.update_paths_and_config(config=config,\n                                     pkg_dir_name=config['source'],\n                                     pkg_cache_dir=os.getcwd())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching a remote S3 archive for the current branch.", "response": "def fetch_s3_package(self, config):\n        \"\"\"Make a remote S3 archive available for local use.\n\n        Args:\n            config (dict): git config dictionary\n\n        \"\"\"\n        extractor_map = {'.tar.gz': TarGzipExtractor,\n                         '.tar': TarExtractor,\n                         '.zip': ZipExtractor}\n        extractor = None\n        for suffix, klass in extractor_map.items():\n            if config['key'].endswith(suffix):\n                extractor = klass()\n                logger.debug(\"Using extractor %s for S3 object \\\"%s\\\" in \"\n                             \"bucket %s.\",\n                             klass.__name__,\n                             config['key'],\n                             config['bucket'])\n                dir_name = self.sanitize_uri_path(\n                    \"s3-%s-%s\" % (config['bucket'],\n                                  config['key'][:-len(suffix)])\n                )\n                break\n\n        if extractor is None:\n            raise ValueError(\n                \"Archive type could not be determined for S3 object \\\"%s\\\" \"\n                \"in bucket %s.\" % (config['key'], config['bucket'])\n            )\n\n        session = get_session(region=None)\n        extra_s3_args = {}\n        if config.get('requester_pays', False):\n            extra_s3_args['RequestPayer'] = 'requester'\n\n        # We can skip downloading the archive if it's already been cached\n        if config.get('use_latest', True):\n            try:\n                # LastModified should always be returned in UTC, but it doesn't\n                # hurt to explicitly convert it to UTC again just in case\n                modified_date = session.client('s3').head_object(\n                    Bucket=config['bucket'],\n                    Key=config['key'],\n                    **extra_s3_args\n                )['LastModified'].astimezone(dateutil.tz.tzutc())\n            except botocore.exceptions.ClientError as client_error:\n                logger.error(\"Error checking modified date of \"\n                             \"s3://%s/%s : %s\",\n                             config['bucket'],\n                             config['key'],\n                             client_error)\n                sys.exit(1)\n            dir_name += \"-%s\" % modified_date.strftime(self.ISO8601_FORMAT)\n        cached_dir_path = os.path.join(self.package_cache_dir, dir_name)\n        if not os.path.isdir(cached_dir_path):\n            logger.debug(\"Remote package s3://%s/%s does not appear to have \"\n                         \"been previously downloaded - starting download and \"\n                         \"extraction to %s\",\n                         config['bucket'],\n                         config['key'],\n                         cached_dir_path)\n            tmp_dir = tempfile.mkdtemp(prefix='stacker')\n            tmp_package_path = os.path.join(tmp_dir, dir_name)\n            try:\n                extractor.set_archive(os.path.join(tmp_dir, dir_name))\n                logger.debug(\"Starting remote package download from S3 to %s \"\n                             \"with extra S3 options \\\"%s\\\"\",\n                             extractor.archive,\n                             str(extra_s3_args))\n                session.resource('s3').Bucket(config['bucket']).download_file(\n                    config['key'],\n                    extractor.archive,\n                    ExtraArgs=extra_s3_args\n                )\n                logger.debug(\"Download complete; extracting downloaded \"\n                             \"package to %s\",\n                             tmp_package_path)\n                extractor.extract(tmp_package_path)\n                logger.debug(\"Moving extracted package directory %s to the \"\n                             \"Stacker cache at %s\",\n                             dir_name,\n                             self.package_cache_dir)\n                shutil.move(tmp_package_path, self.package_cache_dir)\n            finally:\n                shutil.rmtree(tmp_dir)\n        else:\n            logger.debug(\"Remote package s3://%s/%s appears to have \"\n                         \"been previously downloaded to %s -- bypassing \"\n                         \"download\",\n                         config['bucket'],\n                         config['key'],\n                         cached_dir_path)\n\n        # Update sys.path & merge in remote configs (if necessary)\n        self.update_paths_and_config(config=config,\n                                     pkg_dir_name=dir_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch a git repository and update sys. path and config.", "response": "def fetch_git_package(self, config):\n        \"\"\"Make a remote git repository available for local use.\n\n        Args:\n            config (dict): git config dictionary\n\n        \"\"\"\n        # only loading git here when needed to avoid load errors on systems\n        # without git installed\n        from git import Repo\n\n        ref = self.determine_git_ref(config)\n        dir_name = self.sanitize_git_path(uri=config['uri'], ref=ref)\n        cached_dir_path = os.path.join(self.package_cache_dir, dir_name)\n\n        # We can skip cloning the repo if it's already been cached\n        if not os.path.isdir(cached_dir_path):\n            logger.debug(\"Remote repo %s does not appear to have been \"\n                         \"previously downloaded - starting clone to %s\",\n                         config['uri'],\n                         cached_dir_path)\n            tmp_dir = tempfile.mkdtemp(prefix='stacker')\n            try:\n                tmp_repo_path = os.path.join(tmp_dir, dir_name)\n                with Repo.clone_from(config['uri'], tmp_repo_path) as repo:\n                    repo.head.reference = ref\n                    repo.head.reset(index=True, working_tree=True)\n                shutil.move(tmp_repo_path, self.package_cache_dir)\n            finally:\n                shutil.rmtree(tmp_dir)\n        else:\n            logger.debug(\"Remote repo %s appears to have been previously \"\n                         \"cloned to %s -- bypassing download\",\n                         config['uri'],\n                         cached_dir_path)\n\n        # Update sys.path & merge in remote configs (if necessary)\n        self.update_paths_and_config(config=config,\n                                     pkg_dir_name=dir_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate sys. path and self. configs_to_merge with the remote config yamls to merge.", "response": "def update_paths_and_config(self, config, pkg_dir_name,\n                                pkg_cache_dir=None):\n        \"\"\"Handle remote source defined sys.paths & configs.\n\n        Args:\n            config (dict): git config dictionary\n            pkg_dir_name (string): directory name of the stacker archive\n            pkg_cache_dir (string): fully qualified path to stacker cache\n                                    cache directory\n\n        \"\"\"\n        if pkg_cache_dir is None:\n            pkg_cache_dir = self.package_cache_dir\n        cached_dir_path = os.path.join(pkg_cache_dir, pkg_dir_name)\n\n        # Add the appropriate directory (or directories) to sys.path\n        if config.get('paths'):\n            for path in config['paths']:\n                path_to_append = os.path.join(cached_dir_path,\n                                              path)\n                logger.debug(\"Appending \\\"%s\\\" to python sys.path\",\n                             path_to_append)\n                sys.path.append(path_to_append)\n        else:\n            sys.path.append(cached_dir_path)\n\n        # If the configuration defines a set of remote config yamls to\n        # include, add them to the list for merging\n        if config.get('configs'):\n            for config_filename in config['configs']:\n                self.configs_to_merge.append(os.path.join(cached_dir_path,\n                                                          config_filename))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef git_ls_remote(self, uri, ref):\n        logger.debug(\"Invoking git to retrieve commit id for repo %s...\", uri)\n        lsremote_output = subprocess.check_output(['git',\n                                                   'ls-remote',\n                                                   uri,\n                                                   ref])\n        if b\"\\t\" in lsremote_output:\n            commit_id = lsremote_output.split(b\"\\t\")[0]\n            logger.debug(\"Matching commit id found: %s\", commit_id)\n            return commit_id\n        else:\n            raise ValueError(\"Ref \\\"%s\\\" not found for repo %s.\" % (ref, uri))", "response": "Determine the latest commit id for a given ref."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine the ref to be used for git checkout.", "response": "def determine_git_ref(self, config):\n        \"\"\"Determine the ref to be used for 'git checkout'.\n\n        Args:\n            config (dict): git config dictionary\n\n        Returns:\n            str: A commit id or tag name\n\n        \"\"\"\n        # First ensure redundant config keys aren't specified (which could\n        # cause confusion as to which take precedence)\n        ref_config_keys = 0\n        for i in ['commit', 'tag', 'branch']:\n            if config.get(i):\n                ref_config_keys += 1\n        if ref_config_keys > 1:\n            raise ImportError(\"Fetching remote git sources failed: \"\n                              \"conflicting revisions (e.g. 'commit', 'tag', \"\n                              \"'branch') specified for a package source\")\n\n        # Now check for a specific point in time referenced and return it if\n        # present\n        if config.get('commit'):\n            ref = config['commit']\n        elif config.get('tag'):\n            ref = config['tag']\n        else:\n            # Since a specific commit/tag point in time has not been specified,\n            # check the remote repo for the commit id to use\n            ref = self.git_ls_remote(\n                config['uri'],\n                self.determine_git_ls_remote_ref(config)\n            )\n        if sys.version_info[0] > 2 and isinstance(ref, bytes):\n            return ref.decode()\n        return ref"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sanitize_git_path(self, uri, ref=None):\n        if uri.endswith('.git'):\n            dir_name = uri[:-4]  # drop .git\n        else:\n            dir_name = uri\n        dir_name = self.sanitize_uri_path(dir_name)\n        if ref is not None:\n            dir_name += \"-%s\" % ref\n        return dir_name", "response": "Take a git URI and ref and converts it to a directory safe path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_command(provider, context, command, capture=False, interactive=False,\n                ignore_status=False, quiet=False, stdin=None, env=None,\n                **kwargs):\n    \"\"\"Run a custom command as a hook\n\n    Keyword Arguments:\n        command (list or str):\n            Command to run\n        capture (bool, optional):\n            If enabled, capture the command's stdout and stderr, and return\n            them in the hook result. Default: false\n        interactive (bool, optional):\n            If enabled, allow the command to interact with stdin. Otherwise,\n            stdin will be set to the null device. Default: false\n        ignore_status (bool, optional):\n            Don't fail the hook if the command returns a non-zero status.\n            Default: false\n        quiet (bool, optional):\n            Redirect the command's stdout and stderr to the null device,\n            silencing all output. Should not be enaled if `capture` is also\n            enabled. Default: false\n        stdin (str, optional):\n            String to send to the stdin of the command. Implicitly disables\n            `interactive`.\n        env (dict, optional):\n            Dictionary of environment variable overrides for the command\n            context. Will be merged with the current environment.\n        **kwargs:\n            Any other arguments will be forwarded to the `subprocess.Popen`\n            function. Interesting ones include: `cwd` and `shell`.\n\n    Examples:\n        .. code-block:: yaml\n\n            pre_build:\n              - path: stacker.hooks.command.run_command\n                required: true\n                enabled: true\n                data_key: copy_env\n                args:\n                  command: ['cp', 'environment.template', 'environment']\n              - path: stacker.hooks.command.run_command\n                required: true\n                enabled: true\n                data_key: get_git_commit\n                args:\n                  command: ['git', 'rev-parse', 'HEAD']\n                  cwd: ./my-git-repo\n                  capture: true\n              - path: stacker.hooks.command.run_command\n                args:\n                  command: `cd $PROJECT_DIR/project; npm install'\n                  env:\n                    PROJECT_DIR: ./my-project\n                  shell: true\n    \"\"\"\n\n    if quiet and capture:\n        raise ImproperlyConfigured(\n            __name__ + '.run_command',\n            'Cannot enable `quiet` and `capture` options simultaneously')\n\n    if quiet:\n        out_err_type = _devnull()\n    elif capture:\n        out_err_type = PIPE\n    else:\n        out_err_type = None\n\n    if interactive:\n        in_type = None\n    elif stdin:\n        in_type = PIPE\n    else:\n        in_type = _devnull()\n\n    if env:\n        full_env = os.environ.copy()\n        full_env.update(env)\n        env = full_env\n\n    logger.info('Running command: %s', command)\n\n    proc = Popen(command, stdin=in_type, stdout=out_err_type,\n                 stderr=out_err_type, env=env, **kwargs)\n    try:\n        out, err = proc.communicate(stdin)\n        status = proc.wait()\n\n        if status == 0 or ignore_status:\n            return {\n                'returncode': proc.returncode,\n                'stdout': out,\n                'stderr': err\n            }\n\n        # Don't print the command line again if we already did earlier\n        if logger.isEnabledFor(logging.INFO):\n            logger.warn('Command failed with returncode %d', status)\n        else:\n            logger.warn('Command failed with returncode %d: %s', status,\n                        command)\n\n        return None\n    finally:\n        if proc.returncode is None:\n            proc.kill()", "response": "Run a custom command as a hook."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_keypair_exists(provider, context, **kwargs):\n\n    keypair_name = kwargs[\"keypair\"]\n    ssm_parameter_name = kwargs.get(\"ssm_parameter_name\")\n    ssm_key_id = kwargs.get(\"ssm_key_id\")\n    public_key_path = kwargs.get(\"public_key_path\")\n\n    if public_key_path and ssm_parameter_name:\n        logger.error(\"public_key_path and ssm_parameter_name cannot be \"\n                     \"specified at the same time\")\n        return False\n\n    session = get_session(region=provider.region,\n                          profile=kwargs.get(\"profile\"))\n    ec2 = session.client(\"ec2\")\n\n    keypair = get_existing_key_pair(ec2, keypair_name)\n    if keypair:\n        return keypair\n\n    if public_key_path:\n        keypair = create_key_pair_from_public_key_file(\n            ec2, keypair_name, public_key_path)\n\n    elif ssm_parameter_name:\n        ssm = session.client('ssm')\n        keypair = create_key_pair_in_ssm(\n            ec2, ssm, keypair_name, ssm_parameter_name, ssm_key_id)\n    else:\n        action, path = interactive_prompt(keypair_name)\n        if action == \"import\":\n            keypair = create_key_pair_from_public_key_file(\n                ec2, keypair_name, path)\n        elif action == \"create\":\n            keypair = create_key_pair_local(ec2, keypair_name, path)\n        else:\n            logger.warning(\"no action to find keypair, failing\")\n\n    if not keypair:\n        return False\n\n    return keypair", "response": "Ensures a specific keypair exists within AWS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the fully qualified name of an object within this context.", "response": "def get_fqn(base_fqn, delimiter, name=None):\n    \"\"\"Return the fully qualified name of an object within this context.\n\n    If the name passed already appears to be a fully qualified name, it\n    will be returned with no further processing.\n\n    \"\"\"\n    if name and name.startswith(\"%s%s\" % (base_fqn, delimiter)):\n        return name\n\n    return delimiter.join([_f for _f in [base_fqn, name] if _f])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the named targets that are specified in the config.", "response": "def get_targets(self):\n        \"\"\"Returns the named targets that are specified in the config.\n\n        Returns:\n            list: a list of :class:`stacker.target.Target` objects\n\n        \"\"\"\n        if not hasattr(self, \"_targets\"):\n            targets = []\n            for target_def in self.config.targets or []:\n                target = Target(target_def)\n                targets.append(target)\n            self._targets = targets\n        return self._targets"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_stacks(self):\n        if not hasattr(self, \"_stacks\"):\n            stacks = []\n            definitions = self._get_stack_definitions()\n            for stack_def in definitions:\n                stack = Stack(\n                    definition=stack_def,\n                    context=self,\n                    mappings=self.mappings,\n                    force=stack_def.name in self.force_stacks,\n                    locked=stack_def.locked,\n                    enabled=stack_def.enabled,\n                    protected=stack_def.protected,\n                )\n                stacks.append(stack)\n            self._stacks = stacks\n        return self._stacks", "response": "Get the stacks for the current action."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_hook_data(self, key, data):\n\n        if not isinstance(data, collections.Mapping):\n            raise ValueError(\"Hook (key: %s) data must be an instance of \"\n                             \"collections.Mapping (a dictionary for \"\n                             \"example).\" % key)\n\n        if key in self.hook_data:\n            raise KeyError(\"Hook data for key %s already exists, each hook \"\n                           \"must have a unique data_key.\", key)\n\n        self.hook_data[key] = data", "response": "Set the hook data for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(cls, value, **kwargs):\n        value = read_value_from_path(value)\n\n        region = \"us-east-1\"\n        if \"@\" in value:\n            region, value = value.split(\"@\", 1)\n\n        client = get_session(region).client(\"ssm\")\n        response = client.get_parameters(\n            Names=[\n                value,\n            ],\n            WithDecryption=True\n        )\n        if 'Parameters' in response:\n            return str(response['Parameters'][0]['Value'])\n\n        raise ValueError('SSMKey \"{}\" does not exist in region {}'.format(\n            value, region))", "response": "Retrieve and decrypt a parameter from SSM Parameter Store."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_parse_load(raw_config, environment=None, validate=True):\n\n    pre_rendered = render(raw_config, environment)\n\n    rendered = process_remote_sources(pre_rendered, environment)\n\n    config = parse(rendered)\n\n    # For backwards compatibility, if the config doesn't specify a namespace,\n    # we fall back to fetching it from the environment, if provided.\n    if config.namespace is None:\n        namespace = environment.get(\"namespace\")\n        if namespace:\n            logger.warn(\"DEPRECATION WARNING: specifying namespace in the \"\n                        \"environment is deprecated. See \"\n                        \"https://stacker.readthedocs.io/en/latest/config.html\"\n                        \"#namespace \"\n                        \"for more info.\")\n            config.namespace = namespace\n\n    if validate:\n        config.validate()\n\n    return load(config)", "response": "Encapsulates the render parse and load functions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a stacker configuration string using the environment.", "response": "def render(raw_config, environment=None):\n    \"\"\"Renders a config, using it as a template with the environment.\n\n    Args:\n        raw_config (str): the raw stacker configuration string.\n        environment (dict, optional): any environment values that should be\n            passed to the config\n\n    Returns:\n        str: the stacker configuration populated with any values passed from\n            the environment\n\n    \"\"\"\n\n    t = Template(raw_config)\n    buff = StringIO()\n    if not environment:\n        environment = {}\n    try:\n        substituted = t.substitute(environment)\n    except KeyError as e:\n        raise exceptions.MissingEnvironment(e.args[0])\n    except ValueError:\n        # Support \"invalid\" placeholders for lookup placeholders.\n        substituted = t.safe_substitute(environment)\n\n    if not isinstance(substituted, str):\n        substituted = substituted.decode('utf-8')\n\n    buff.write(substituted)\n    buff.seek(0)\n    return buff.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(raw_config):\n\n    # Convert any applicable dictionaries back into lists\n    # This is necessary due to the move from lists for these top level config\n    # values to either lists or OrderedDicts.\n    # Eventually we should probably just make them OrderedDicts only.\n    config_dict = yaml_to_ordered_dict(raw_config)\n    if config_dict:\n        for top_level_key in ['stacks', 'pre_build', 'post_build',\n                              'pre_destroy', 'post_destroy']:\n            top_level_value = config_dict.get(top_level_key)\n            if isinstance(top_level_value, dict):\n                tmp_list = []\n                for key, value in top_level_value.items():\n                    tmp_dict = copy.deepcopy(value)\n                    if top_level_key == 'stacks':\n                        tmp_dict['name'] = key\n                    tmp_list.append(tmp_dict)\n                config_dict[top_level_key] = tmp_list\n\n    # Top-level excess keys are removed by Config._convert, so enabling strict\n    # mode is fine here.\n    try:\n        return Config(config_dict, strict=True)\n    except SchematicsError as e:\n        raise exceptions.InvalidConfig(e.errors)", "response": "Parse a raw yaml formatted stacker config string into a new stacker config object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(config):\n\n    if config.sys_path:\n        logger.debug(\"Appending %s to sys.path.\", config.sys_path)\n        sys.path.append(config.sys_path)\n        logger.debug(\"sys.path is now %s\", sys.path)\n    if config.lookups:\n        for key, handler in config.lookups.items():\n            register_lookup_handler(key, handler)\n\n    return config", "response": "Loads a stacker configuration by modifying sys. path loading lookups and etc."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump a stacker Config object as yaml.", "response": "def dump(config):\n    \"\"\"Dumps a stacker Config object as yaml.\n\n    Args:\n        config (:class:`Config`): the stacker Config object.\n        stream (stream): an optional stream object to write to.\n\n    Returns:\n        str: the yaml formatted stacker Config.\n\n    \"\"\"\n\n    return yaml.safe_dump(\n        config.to_primitive(),\n        default_flow_style=False,\n        encoding='utf-8',\n        allow_unicode=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_remote_sources(raw_config, environment=None):\n\n    config = yaml.safe_load(raw_config)\n    if config and config.get('package_sources'):\n        processor = SourceProcessor(\n            sources=config['package_sources'],\n            stacker_cache_dir=config.get('stacker_cache_dir')\n        )\n        processor.get_package_sources()\n        if processor.configs_to_merge:\n            for i in processor.configs_to_merge:\n                logger.debug(\"Merging in remote config \\\"%s\\\"\", i)\n                remote_config = yaml.safe_load(open(i))\n                config = merge_map(remote_config, config)\n            # Call the render again as the package_sources may have merged in\n            # additional environment lookups\n            if not environment:\n                environment = {}\n            return render(str(config), environment)\n\n    return raw_config", "response": "Stage remote package sources and merge in remote configs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_header(soap_action):\n    # This way of setting accepted language is obviously flawed, in that it\n    # depends on the locale settings of the system. However, I'm unsure if\n    # they are actually used. The character coding is set elsewhere and I think\n    # the available music in each country is bound to the account.\n    language, _ = locale.getdefaultlocale()\n    if language is None:\n        language = ''\n    else:\n        language = language.replace('_', '-') + ', '\n\n    header = {\n        'CONNECTION': 'close',\n        'ACCEPT-ENCODING': 'gzip',\n        'ACCEPT-LANGUAGE': '{}en-US;q=0.9'.format(language),\n        'Content-Type': 'text/xml; charset=\"utf-8\"',\n        'SOAPACTION': SOAP_ACTION[soap_action]\n    }\n    return header", "response": "Return the HTTP header for the given SOAP Action."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_playlists(self, search, start=0, max_items=100):\n        return self.get_music_service_information('playlists', search, start,\n                                                  max_items)", "response": "Search for playlists.\n\n        See get_music_service_information for details on the arguments.\n\n        Note:\n\n            Un-intuitively this method returns MSAlbumList items. See\n            note in class doc string for details."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for music service information items.", "response": "def get_music_service_information(self, search_type, search, start=0,\n                                      max_items=100):\n        \"\"\"Search for music service information items.\n\n        :param search_type: The type of search to perform, possible values are:\n            'artists', 'albums', 'tracks' and 'playlists'\n        :type search_type: str\n        :param search: The search string to use\n        :type search: str\n        :param start: The starting index of the returned items\n        :type start: int\n        :param max_items: The maximum number of returned items\n        :type max_items: int\n\n        Note:\n            Un-intuitively the playlist search returns MSAlbumList\n            items. See note in class doc string for details.\n        \"\"\"\n        # Check input\n        if search_type not in ['artists', 'albums', 'tracks', 'playlists']:\n            message = 'The requested search {} is not valid'\\\n                .format(search_type)\n            raise ValueError(message)\n        # Transform search: tracks -> tracksearch\n        search_type = '{}earch'.format(search_type)\n        parent_id = SEARCH_PREFIX.format(search_type=search_type,\n                                         search=search)\n\n        # Perform search\n        body = self._search_body(search_type, search, start, max_items)\n        headers = _get_header('search')\n        response = _post(self._url, headers, body, **self._http_vars)\n        self._check_for_errors(response)\n        result_dom = XML.fromstring(response.text.encode('utf-8'))\n\n        # Parse results\n        search_result = result_dom.find('.//' + _ns_tag('', 'searchResult'))\n        out = {'item_list': []}\n        for element in ['index', 'count', 'total']:\n            out[element] = search_result.findtext(_ns_tag('', element))\n\n        if search_type == 'tracksearch':\n            item_name = 'mediaMetadata'\n        else:\n            item_name = 'mediaCollection'\n        for element in search_result.findall(_ns_tag('', item_name)):\n            out['item_list'].append(get_ms_item(element, self, parent_id))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef browse(self, ms_item=None):\n        # Check for correct service\n        if ms_item is not None and ms_item.service_id != self._service_id:\n            message = 'This music service item is not for this service'\n            raise ValueError(message)\n\n        # Form HTTP body and set parent_id\n        if ms_item:\n            body = self._browse_body(ms_item.item_id)\n            parent_id = ms_item.extended_id\n            if parent_id is None:\n                parent_id = ''\n        else:\n            body = self._browse_body('root')\n            parent_id = '0'\n\n        # Get HTTP header and post\n        headers = _get_header('get_metadata')\n        response = _post(self._url, headers, body, **self._http_vars)\n\n        # Check for errors and get XML\n        self._check_for_errors(response)\n        result_dom = XML.fromstring(really_utf8(response.text))\n        # Find the getMetadataResult item ...\n        xpath_search = './/' + _ns_tag('', 'getMetadataResult')\n        metadata_result = list(result_dom.findall(xpath_search))\n        # ... and make sure there is exactly 1\n        if len(metadata_result) != 1:\n            raise UnknownXMLStructure(\n                'The results XML has more than 1 \\'getMetadataResult\\'. This '\n                'is unexpected and parsing will dis-continue.'\n            )\n        metadata_result = metadata_result[0]\n\n        # Browse the children of metadata result\n        out = {'item_list': []}\n        for element in ['index', 'count', 'total']:\n            out[element] = metadata_result.findtext(_ns_tag('', element))\n        for result in metadata_result:\n            if result.tag in [_ns_tag('', 'mediaCollection'),\n                              _ns_tag('', 'mediaMetadata')]:\n                out['item_list'].append(get_ms_item(result, self, parent_id))\n        return out", "response": "Browsing a MSTrack item returns the sub - elements of the item or of the root element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef id_to_extended_id(item_id, item_class):\n        out = ID_PREFIX[item_class]\n        if out:\n            out += item_id\n        return out", "response": "Return the extended ID from an ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef form_uri(item_content, item_class):\n        extension = None\n        if 'mime_type' in item_content:\n            extension = MIME_TYPE_TO_EXTENSION[item_content['mime_type']]\n        out = URIS.get(item_class)\n        if out:\n            out = out.format(extension=extension, **item_content)\n        return out", "response": "Form the URI for a music service element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _search_body(self, search_type, search_term, start, max_items):\n        xml = self._base_body()\n\n        # Add the Body part\n        XML.SubElement(xml, 's:Body')\n        item_attrib = {\n            'xmlns': 'http://www.sonos.com/Services/1.1'\n        }\n        search = XML.SubElement(xml[1], 'search', item_attrib)\n        XML.SubElement(search, 'id').text = search_type\n        XML.SubElement(search, 'term').text = search_term\n        XML.SubElement(search, 'index').text = str(start)\n        XML.SubElement(search, 'count').text = str(max_items)\n\n        return XML.tostring(xml)", "response": "Return the search XML body."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _browse_body(self, search_id):\n        xml = self._base_body()\n\n        # Add the Body part\n        XML.SubElement(xml, 's:Body')\n        item_attrib = {\n            'xmlns': 'http://www.sonos.com/Services/1.1'\n        }\n        search = XML.SubElement(xml[1], 'getMetadata', item_attrib)\n        XML.SubElement(search, 'id').text = search_id\n        # Investigate this index, count stuff more\n        XML.SubElement(search, 'index').text = '0'\n        XML.SubElement(search, 'count').text = '100'\n\n        return XML.tostring(xml)", "response": "Return the browse XML body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the base XML body of the log entry.", "response": "def _base_body(self):\n        \"\"\"Return the base XML body, which has the following form:\n\n        .. code :: xml\n\n         <s:Envelope xmlns:s=\"http://schemas.xmlsoap.org/soap/envelope/\">\n           <s:Header>\n             <credentials xmlns=\"http://www.sonos.com/Services/1.1\">\n               <sessionId>self._session_id</sessionId>\n               <deviceId>self._serial_number</deviceId>\n               <deviceProvider>Sonos</deviceProvider>\n             </credentials>\n           </s:Header>\n         </s:Envelope>\n        \"\"\"\n        item_attrib = {\n            'xmlns:s': 'http://schemas.xmlsoap.org/soap/envelope/',\n        }\n        xml = XML.Element('s:Envelope', item_attrib)\n\n        # Add the Header part\n        XML.SubElement(xml, 's:Header')\n        item_attrib = {\n            'xmlns': 'http://www.sonos.com/Services/1.1'\n        }\n        credentials = XML.SubElement(xml[0], 'credentials', item_attrib)\n        XML.SubElement(credentials, 'sessionId').text = self._session_id\n        XML.SubElement(credentials, 'deviceId').text = self._serial_number\n        XML.SubElement(credentials, 'deviceProvider').text = 'Sonos'\n\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck a response for errors.", "response": "def _check_for_errors(self, response):\n        \"\"\"Check a response for errors.\n\n        :param response: the response from requests.post()\n        \"\"\"\n        if response.status_code != 200:\n            xml_error = really_utf8(response.text)\n            error_dom = XML.fromstring(xml_error)\n            fault = error_dom.find('.//' + _ns_tag('s', 'Fault'))\n            error_description = fault.find('faultstring').text\n            error_code = EXCEPTION_STR_TO_CODE[error_description]\n            message = 'UPnP Error {} received: {} from {}'.format(\n                error_code, error_description, self._url)\n            raise SoCoUPnPException(\n                message=message,\n                error_code=error_code,\n                error_description=error_description,\n                error_xml=really_utf8(response.text)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef desc_from_uri(uri):\n    #\n    # If there is an sn parameter (which is the serial number of an account),\n    # we can obtain all the information we need from that, because we can find\n    # the relevant service_id in the account database (it is the same as the\n    # service_type). Consequently, the sid parameter is unneeded. But if sn is\n    # missing, we need the sid (service_type) parameter to find a relevant\n    # account\n\n    # urlparse does not work consistently with custom URI schemes such as\n    # those used by Sonos. This is especially broken in Python 2.6 and\n    # early versions of 2.7: http://bugs.python.org/issue9374\n    # As a workaround, we split off the scheme manually, and then parse\n    # the uri as if it were http\n    if \":\" in uri:\n        _, uri = uri.split(\":\", 1)\n    query_string = parse_qs(urlparse(uri, 'http').query)\n    # Is there an account serial number?\n    if query_string.get('sn'):\n        account_serial_number = query_string['sn'][0]\n        try:\n            account = Account.get_accounts()[account_serial_number]\n            desc = \"SA_RINCON{}_{}\".format(\n                account.service_type, account.username)\n            return desc\n        except KeyError:\n            # There is no account matching this serial number. Fall back to\n            # using the service id to find an account\n            pass\n    if query_string.get('sid'):\n        service_id = query_string['sid'][0]\n        for service in MusicService._get_music_services_data().values():\n            if service_id == service[\"ServiceID\"]:\n                service_type = service[\"ServiceType\"]\n                account = Account.get_accounts_for_service(service_type)\n                if not account:\n                    break\n                # Use the first account we find\n                account = account[0]\n                desc = \"SA_RINCON{}_{}\".format(\n                    account.service_type, account.username)\n                return desc\n    # Nothing found. Default to the standard desc value. Is this the right\n    # thing to do?\n    desc = 'RINCON_AssociatedZPUDN'\n    return desc", "response": "Create the content of a DIDL desc element from a URI."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_soap_header(self):\n\n        # According to the SONOS SMAPI, this header must be sent with all\n        # SOAP requests. Building this is an expensive operation (though\n        # occasionally necessary), so f we have a cached value, return it\n        if self._cached_soap_header is not None:\n            return self._cached_soap_header\n        music_service = self.music_service\n        credentials_header = XML.Element(\n            \"credentials\", {'xmlns': \"http://www.sonos.com/Services/1.1\"})\n        device_id = XML.SubElement(credentials_header, 'deviceId')\n        device_id.text = self._device_id\n        device_provider = XML.SubElement(credentials_header, 'deviceProvider')\n        device_provider.text = 'Sonos'\n        if music_service.account.oa_device_id:\n            # OAuth account credentials are present. We must use them to\n            # authenticate.\n            login_token = XML.Element('loginToken')\n            token = XML.SubElement(login_token, 'token')\n            token.text = music_service.account.oa_device_id\n            key = XML.SubElement(login_token, 'key')\n            key.text = music_service.account.key\n            household_id = XML.SubElement(login_token, 'householdId')\n            household_id.text = self._device.household_id\n            credentials_header.append(login_token)\n\n        # otherwise, perhaps use DeviceLink or UserId auth\n        elif music_service.auth_type in ['DeviceLink', 'UserId']:\n            # We need a session ID from Sonos\n            session_id = self._device.musicServices.GetSessionId([\n                ('ServiceId', music_service.service_id),\n                ('Username', music_service.account.username)\n            ])['SessionId']\n            session_elt = XML.Element('sessionId')\n            session_elt.text = session_id\n            credentials_header.append(session_elt)\n\n        # Anonymous auth. No need for anything further.\n        self._cached_soap_header = XML.tostring(\n            credentials_header,\n            encoding='utf-8').decode(encoding='utf-8')\n        return self._cached_soap_header", "response": "Generate the SOAP authentication header for the related service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call(self, method, args=None):\n        message = SoapMessage(\n            endpoint=self.endpoint,\n            method=method,\n            parameters=[] if args is None else args,\n            http_headers=self.http_headers,\n            soap_action=\"http://www.sonos.com/Services/1\"\n                        \".1#{0}\".format(method),\n            soap_header=self.get_soap_header(),\n            namespace=self.namespace,\n            timeout=self.timeout)\n\n        try:\n            result_elt = message.call()\n        except SoapFault as exc:\n            if 'Client.TokenRefreshRequired' in exc.faultcode:\n                log.debug('Token refresh required. Trying again')\n                # Remove any cached value for the SOAP header\n                self._cached_soap_header = None\n\n                # <detail>\n                #   <refreshAuthTokenResult>\n                #       <authToken>xxxxxxx</authToken>\n                #       <privateKey>zzzzzz</privateKey>\n                #   </refreshAuthTokenResult>\n                # </detail>\n                auth_token = exc.detail.findtext('.//authToken')\n                private_key = exc.detail.findtext('.//privateKey')\n                # We have new details - update the account\n                self.music_service.account.oa_device_id = auth_token\n                self.music_service.account.key = private_key\n                message = SoapMessage(\n                    endpoint=self.endpoint,\n                    method=method,\n                    parameters=args,\n                    http_headers=self.http_headers,\n                    soap_action=\"http://www.sonos.com/Services/1\"\n                                \".1#{0}\".format(method),\n                    soap_header=self.get_soap_header(),\n                    namespace=self.namespace,\n                    timeout=self.timeout)\n                result_elt = message.call()\n\n            else:\n                raise MusicServiceException(exc.faultstring, exc.faultcode)\n\n        # The top key in the OrderedDict will be the methodResult. Its\n        # value may be None if no results were returned.\n        result = list(parse(\n            XML.tostring(result_elt), process_namespaces=True,\n            namespaces={'http://www.sonos.com/Services/1.1': None}\n        ).values())[0]\n\n        return result if result is not None else {}", "response": "Call a method on the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_music_services_data_xml(soco=None):\n        device = soco or discovery.any_soco()\n        log.debug(\"Fetching music services data from %s\", device)\n        available_services = device.musicServices.ListAvailableServices()\n        descriptor_list_xml = available_services[\n            'AvailableServiceDescriptorList']\n        log.debug(\"Services descriptor list: %s\", descriptor_list_xml)\n        return descriptor_list_xml", "response": "Fetch the music services data xml from a Sonos device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_music_services_data(cls):\n        # Return from cache if we have it.\n        if cls._music_services_data is not None:\n            return cls._music_services_data\n\n        result = {}\n        root = XML.fromstring(\n            cls._get_music_services_data_xml().encode('utf-8')\n        )\n        # <Services SchemaVersion=\"1\">\n        #     <Service Id=\"163\" Name=\"Spreaker\" Version=\"1.1\"\n        #         Uri=\"http://sonos.spreaker.com/sonos/service/v1\"\n        #         SecureUri=\"https://sonos.spreaker.com/sonos/service/v1\"\n        #         ContainerType=\"MService\"\n        #         Capabilities=\"513\"\n        #         MaxMessagingChars=\"0\">\n        #         <Policy Auth=\"Anonymous\" PollInterval=\"30\" />\n        #         <Presentation>\n        #             <Strings\n        #                 Version=\"1\"\n        #                 Uri=\"https:...string_table.xml\" />\n        #             <PresentationMap Version=\"2\"\n        #                 Uri=\"https://...presentation_map.xml\" />\n        #         </Presentation>\n        #     </Service>\n        # ...\n        # </ Services>\n\n        # Ideally, the search path should be './/Service' to find Service\n        # elements at any level, but Python 2.6 breaks with this if Service\n        # is a child of the current element. Since 'Service' works here, we use\n        # that instead\n        services = root.findall('Service')\n        for service in services:\n            result_value = service.attrib.copy()\n            name = service.get('Name')\n            result_value['Name'] = name\n            auth_element = (service.find('Policy'))\n            auth = auth_element.attrib\n            result_value.update(auth)\n            presentation_element = (service.find('.//PresentationMap'))\n            if presentation_element is not None:\n                result_value['PresentationMapUri'] = \\\n                    presentation_element.get('Uri')\n            result_value['ServiceID'] = service.get('Id')\n            # ServiceType is used elsewhere in Sonos, eg to form tokens,\n            # and get_subscribed_music_services() below. It is also the\n            # 'Type' used in account_xml (see above). Its value always\n            # seems to be (ID*256) + 7. Some serviceTypes are also\n            # listed in available_services['AvailableServiceTypeList']\n            # but this does not seem to be comprehensive\n            service_type = str(int(service.get('Id')) * 256 + 7)\n            result_value['ServiceType'] = service_type\n            result[service_type] = result_value\n        # Cache this so we don't need to do it again.\n        cls._music_services_data = result\n        return result", "response": "Parse the music services xml into a useful python datastructure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_subscribed_services_names(cls):\n        # This is very inefficient - loops within loops within loops, and\n        # many network requests\n        # Optimise it?\n        accounts_for_service = Account.get_accounts_for_service\n        service_data = cls._get_music_services_data().values()\n        return [\n            service['Name'] for service in service_data\n            if len(\n                accounts_for_service(service['ServiceType'])\n            ) > 0\n        ]", "response": "Get a list of the names of all subscribed music services."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the data relating to a named music service.", "response": "def get_data_for_name(cls, service_name):\n        \"\"\"Get the data relating to a named music service.\n\n        Args:\n            service_name (str): The name of the music service for which data\n                is required.\n\n        Returns:\n            dict: Data relating to the music service.\n\n        Raises:\n            `MusicServiceException`: if the music service cannot be found.\n        \"\"\"\n        for service in cls._get_music_services_data().values():\n            if service_name == service[\"Name\"]:\n                return service\n        raise MusicServiceException(\n            \"Unknown music service: '%s'\" % service_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch and parse the service search category mapping.", "response": "def _get_search_prefix_map(self):\n        \"\"\"Fetch and parse the service search category mapping.\n\n        Standard Sonos search categories are 'all', 'artists', 'albums',\n        'tracks', 'playlists', 'genres', 'stations', 'tags'. Not all are\n        available for each music service\n        \"\"\"\n        # TuneIn does not have a pmap. Its search keys are is search:station,\n        # search:show, search:host\n\n        # Presentation maps can also define custom categories. See eg\n        # http://sonos-pmap.ws.sonos.com/hypemachine_pmap.6.xml\n        # <SearchCategories>\n        # ...\n        #     <CustomCategory mappedId=\"SBLG\" stringId=\"Blogs\"/>\n        # </SearchCategories>\n        # Is it already cached? If so, return it\n        if self._search_prefix_map is not None:\n            return self._search_prefix_map\n        # Not cached. Fetch and parse presentation map\n        self._search_prefix_map = {}\n        # Tunein is a special case. It has no pmap, but supports searching\n        if self.service_name == \"TuneIn\":\n            self._search_prefix_map = {\n                'stations': 'search:station',\n                'shows': 'search:show',\n                'hosts': 'search:host',\n            }\n            return self._search_prefix_map\n        if self.presentation_map_uri is None:\n            # Assume not searchable?\n            return self._search_prefix_map\n        log.info('Fetching presentation map from %s',\n                 self.presentation_map_uri)\n        pmap = requests.get(self.presentation_map_uri, timeout=9)\n        pmap_root = XML.fromstring(pmap.content)\n        # Search translations can appear in Category or CustomCategory elements\n        categories = pmap_root.findall(\".//SearchCategories/Category\")\n        if categories is None:\n            return self._search_prefix_map\n        for cat in categories:\n            self._search_prefix_map[cat.get('id')] = cat.get('mappedId')\n        custom_categories = pmap_root.findall(\n            \".//SearchCategories/CustomCategory\")\n        for cat in custom_categories:\n            self._search_prefix_map[cat.get('stringId')] = cat.get('mappedId')\n        return self._search_prefix_map"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sonos_uri_from_id(self, item_id):\n        # Real Sonos URIs look like this:\n        # x-sonos-http:tr%3a92352286.mp3?sid=2&flags=8224&sn=4 The\n        # extension (.mp3) presumably comes from the mime-type returned in a\n        # MusicService.get_metadata() result (though for Spotify the mime-type\n        # is audio/x-spotify, and there is no extension. See\n        # http://musicpartners.sonos.com/node/464 for supported mime-types and\n        # related extensions). The scheme (x-sonos-http) presumably\n        # indicates how the player is to obtain the stream for playing. It\n        # is not clear what the flags param is used for (perhaps bitrate,\n        # or certain metadata such as canSkip?). Fortunately, none of these\n        # seems to be necessary. We can leave them out, (or in the case of\n        # the scheme, use 'soco' as dummy text, and the players still seem\n        # to do the right thing.\n\n        # quote_url will break if given unicode on Py2.6, and early 2.7. So\n        # we need to encode.\n        item_id = quote_url(item_id.encode('utf-8'))\n        # Add the account info to the end as query params\n        account = self.account\n        result = \"soco://{}?sid={}&sn={}\".format(\n            item_id, self.service_id,\n            account.serial_number\n        )\n        return result", "response": "Return a Sonos URI from a music item id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef desc(self):\n        desc = \"SA_RINCON{}_{}\".format(\n            self.account.service_type, self.account.username\n        )\n        return desc", "response": "str - The Sonos descriptor for this service."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the metadata for a container or item.", "response": "def get_metadata(\n            self, item='root', index=0, count=100, recursive=False):\n        \"\"\"Get metadata for a container or item.\n\n        Args:\n            item (str or MusicServiceItem): The container or item to browse\n                given either as a MusicServiceItem instance or as a str.\n                Defaults to the root item.\n            index (int): The starting index. Default 0.\n            count (int): The maximum number of items to return. Default 100.\n            recursive (bool): Whether the browse should recurse into sub-items\n                (Does not always work). Defaults to `False`.\n\n        Returns:\n            ~collections.OrderedDict: The item or container's metadata,\n            or `None`.\n\n        See also:\n            The Sonos `getMetadata API\n            <http://musicpartners.sonos.com/node/83>`_.\n\n        \"\"\"\n        if isinstance(item, MusicServiceItem):\n            item_id = item.id  # pylint: disable=no-member\n        else:\n            item_id = item\n        response = self.soap_client.call(\n            'getMetadata', [\n                ('id', item_id),\n                ('index', index), ('count', count),\n                ('recursive', 1 if recursive else 0)]\n        )\n        return parse_response(self, response, 'browse')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for an item in a category.", "response": "def search(self, category, term='', index=0, count=100):\n        \"\"\"Search for an item in a category.\n\n        Args:\n            category (str): The search category to use. Standard Sonos search\n                categories are 'artists', 'albums', 'tracks', 'playlists',\n                'genres', 'stations', 'tags'. Not all are available for each\n                music service. Call available_search_categories for a list for\n                this service.\n            term (str): The term to search for.\n            index (int): The starting index. Default 0.\n            count (int): The maximum number of items to return. Default 100.\n\n        Returns:\n            ~collections.OrderedDict: The search results, or `None`.\n\n        See also:\n            The Sonos `search API <http://musicpartners.sonos.com/node/86>`_\n        \"\"\"\n        search_category = self._get_search_prefix_map().get(category, None)\n        if search_category is None:\n            raise MusicServiceException(\n                \"%s does not support the '%s' search category\" % (\n                    self.service_name, category))\n\n        response = self.soap_client.call(\n            'search',\n            [\n                ('id', search_category), ('term', term), ('index', index),\n                ('count', count)])\n\n        return parse_response(self, response, category)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets metadata for a media item.", "response": "def get_media_metadata(self, item_id):\n        \"\"\"Get metadata for a media item.\n\n        Args:\n            item_id (str): The item for which metadata is required.\n\n        Returns:\n            ~collections.OrderedDict: The item's metadata, or `None`\n\n        See also:\n            The Sonos `getMediaMetadata API\n            <http://musicpartners.sonos.com/node/83>`_\n        \"\"\"\n        response = self.soap_client.call(\n            'getMediaMetadata',\n            [('id', item_id)])\n        return response.get('getMediaMetadataResult', None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a streaming URI for an item. Note: You should not need to use this directly. It is used by the Sonos players (not the controllers) to obtain the uri of the media stream. If you want to have a player play a media item, you should add add it to the queue using its id and let the player work out where to get the stream from (see `On Demand Playback <http://musicpartners.sonos.com/node/421>`_ and `Programmed Radio <http://musicpartners.sonos.com/node/422>`_) Args: item_id (str): The item for which the URI is required Returns: str: The item's streaming URI.", "response": "def get_media_uri(self, item_id):\n        \"\"\"Get a streaming URI for an item.\n\n        Note:\n           You should not need to use this directly. It is used by the Sonos\n           players (not the controllers) to obtain the uri of the media\n           stream. If you want to have a player play a media item,\n           you should add add it to the queue using its id and let the\n           player work out where to get the stream from (see `On Demand\n           Playback <http://musicpartners.sonos.com/node/421>`_ and\n           `Programmed Radio <http://musicpartners.sonos.com/node/422>`_)\n\n        Args:\n            item_id (str): The item for which the URI is required\n\n        Returns:\n            str: The item's streaming URI.\n        \"\"\"\n        response = self.soap_client.call(\n            'getMediaURI',\n            [('id', item_id)])\n        return response.get('getMediaURIResult', None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_extended_metadata(self, item_id):\n        response = self.soap_client.call(\n            'getExtendedMetadata',\n            [('id', item_id)])\n        return response.get('getExtendedMetadataResult', None)", "response": "Get extended metadata for a media item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets extended metadata text for a media item.", "response": "def get_extended_metadata_text(self, item_id, metadata_type):\n        \"\"\"Get extended metadata text for a media item.\n\n        Args:\n            item_id (str): The item for which metadata is required\n            metadata_type (str): The type of text to return, eg\n            ``'ARTIST_BIO'``, or ``'ALBUM_NOTES'``. Calling\n            `get_extended_metadata` for the item will show which extended\n            metadata_types are available (under relatedBrowse and relatedText).\n\n        Returns:\n            str: The item's extended metadata text or None\n\n        See also:\n            The Sonos `getExtendedMetadataText API\n            <http://musicpartners.sonos.com/node/127>`_\n        \"\"\"\n        response = self.soap_client.call(\n            'getExtendedMetadataText',\n            [('id', item_id), ('type', metadata_type)])\n        return response.get('getExtendedMetadataTextResult', None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_class(class_key):\n    if class_key not in CLASSES:\n        for basecls in (MediaMetadata, MediaCollection):\n            if class_key.startswith(basecls.__name__):\n                # So MediaMetadataTrack turns into MSTrack\n                class_name = 'MS' + class_key.replace(basecls.__name__, '')\n                if sys.version_info[0] == 2:\n                    class_name = class_name.encode('ascii')\n                CLASSES[class_key] = type(class_name, (basecls,), {})\n                _LOG.info('Class %s created', CLASSES[class_key])\n    return CLASSES[class_key]", "response": "Form a music service data structure class from the class key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the response to a music service query and return a SearchResult object.", "response": "def parse_response(service, response, search_type):\n    \"\"\"Parse the response to a music service query and return a SearchResult\n\n    Args:\n        service (MusicService): The music service that produced the response\n        response (OrderedDict): The response from the soap client call\n        search_type (str): A string that indicates the search type that the\n            response is from\n\n    Returns:\n        SearchResult: A SearchResult object\n    \"\"\"\n    _LOG.debug('Parse response \"%s\" from service \"%s\" of type \"%s\"', response,\n               service, search_type)\n    items = []\n    # The result to be parsed is in either searchResult or getMetadataResult\n    if 'searchResult' in response:\n        response = response['searchResult']\n    elif 'getMetadataResult' in response:\n        response = response['getMetadataResult']\n    else:\n        raise ValueError('\"response\" should contain either the key '\n                         '\"searchResult\" or \"getMetadataResult\"')\n\n    # Form the search metadata\n    search_metadata = {\n        'number_returned': response['count'],\n        'total_matches': None,\n        'search_type': search_type,\n        'update_id': None,\n    }\n\n    for result_type in ('mediaCollection', 'mediaMetadata'):\n        # Upper case the first letter (used for the class_key)\n        result_type_proper = result_type[0].upper() + result_type[1:]\n        raw_items = response.get(result_type, [])\n        # If there is only 1 result, it is not put in an array\n        if isinstance(raw_items, OrderedDict):\n            raw_items = [raw_items]\n\n        for raw_item in raw_items:\n            # Form the class_key, which is a unique string for this type,\n            # formed by concatenating the result type with the item type. Turns\n            # into e.g: MediaMetadataTrack\n            class_key = result_type_proper + raw_item['itemType'].title()\n            cls = get_class(class_key)\n            items.append(cls.from_music_service(service, raw_item))\n    return SearchResult(items, **search_metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nform and return a music service item uri based on the item id and the music service", "response": "def form_uri(item_id, service, is_track):\n    \"\"\"Form and return a music service item uri\n\n    Args:\n        item_id (str): The item id\n        service (MusicService): The music service that the item originates from\n        is_track (bool): Whether the item_id is from a track or not\n\n    Returns:\n        str: The music service item uri\n    \"\"\"\n    if is_track:\n        uri = service.sonos_uri_from_id(item_id)\n    else:\n        uri = 'x-rincon-cpcontainer:' + item_id\n    return uri"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a boolean from a string imput of true or false", "response": "def bool_str(string):\n    \"\"\"Returns a boolean from a string imput of 'true' or 'false'\"\"\"\n    if string not in BOOL_STRS:\n        raise ValueError('Invalid boolean string: \"{}\"'.format(string))\n    return True if string == 'true' else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an element instantiated from the information that a music service originated from .", "response": "def from_music_service(cls, music_service, content_dict):\n        \"\"\"Return an element instantiated from the information that a music\n        service has (alternative constructor)\n\n        Args:\n            music_service (MusicService): The music service that content_dict\n                originated from\n            content_dict (OrderedDict): The data to instantiate the music\n                service item from\n\n        Returns:\n            MusicServiceItem: A MusicServiceItem instance\n        \"\"\"\n        # Form the item_id\n        quoted_id = quote_url(content_dict['id'].encode('utf-8'))\n        # The hex prefix remains a mistery for now\n        item_id = '0fffffff{}'.format(quoted_id)\n        # Form the uri\n        is_track = cls == get_class('MediaMetadataTrack')\n        uri = form_uri(item_id, music_service, is_track)\n        # Form resources and get desc\n        resources = [DidlResource(uri=uri, protocol_info=\"DUMMY\")]\n        desc = music_service.desc\n        return cls(item_id, desc, resources, uri, content_dict,\n                   music_service=music_service)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an ElementTree Element representing this object.", "response": "def to_element(self, include_namespaces=False):\n        \"\"\"Return an ElementTree Element representing this instance.\n\n        Args:\n            include_namespaces (bool, optional): If True, include xml\n                namespace attributes on the root element\n\n        Return:\n            ~xml.etree.ElementTree.Element: The (XML) Element representation of\n                this object\n        \"\"\"\n        # We piggy back on the implementation in DidlItem\n        didl_item = DidlItem(\n            title=\"DUMMY\",\n            # This is ignored. Sonos gets the title from the item_id\n            parent_id=\"DUMMY\",  # Ditto\n            item_id=self.item_id,\n            desc=self.desc,\n            resources=self.resources\n        )\n        return didl_item.to_element(include_namespaces=include_namespaces)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching the account data from a Sonos instance.", "response": "def _get_account_xml(soco):\n        \"\"\"Fetch the account data from a Sonos device.\n\n        Args:\n            soco (SoCo): a SoCo instance to query. If soco is `None`, a\n                random device will be used.\n\n        Returns:\n            str: a byte string containing the account data xml\n        \"\"\"\n        # It is likely that the same information is available over UPnP as well\n        # via a call to\n        # systemProperties.GetStringX([('VariableName','R_SvcAccounts')]))\n        # This returns an encrypted string, and, so far, we cannot decrypt it\n        device = soco or discovery.any_soco()\n        log.debug(\"Fetching account data from %s\", device)\n        settings_url = \"http://{}:1400/status/accounts\".format(\n            device.ip_address)\n        result = requests.get(settings_url).content\n        log.debug(\"Account data: %s\", result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_accounts(cls, soco=None):\n\n        root = XML.fromstring(cls._get_account_xml(soco))\n        # _get_account_xml returns an ElementTree element like this:\n\n        # <ZPSupportInfo type=\"User\">\n        #   <Accounts\n        #   LastUpdateDevice=\"RINCON_000XXXXXXXX400\"\n        #   Version=\"8\" NextSerialNum=\"5\">\n        #     <Account Type=\"2311\" SerialNum=\"1\">\n        #         <UN>12345678</UN>\n        #         <MD>1</MD>\n        #         <NN></NN>\n        #         <OADevID></OADevID>\n        #         <Key></Key>\n        #     </Account>\n        #     <Account Type=\"41735\" SerialNum=\"3\" Deleted=\"1\">\n        #         <UN></UN>\n        #         <MD>1</MD>\n        #         <NN>Nickname</NN>\n        #         <OADevID></OADevID>\n        #         <Key></Key>\n        #     </Account>\n        # ...\n        #   <Accounts />\n\n        xml_accounts = root.findall('.//Account')\n        result = {}\n        for xml_account in xml_accounts:\n            serial_number = xml_account.get('SerialNum')\n            is_deleted = True if xml_account.get('Deleted') == '1' else False\n            # cls._all_accounts is a weakvaluedict keyed by serial number.\n            # We use it as a database to store details of the accounts we\n            # know about. We need to update it with info obtained from the\n            # XML just obtained, so (1) check to see if we already have an\n            # entry in cls._all_accounts for the account we have found in\n            # XML; (2) if so, delete it if the XML says it has been deleted;\n            # and (3) if not, create an entry for it\n            if cls._all_accounts.get(serial_number):\n                # We have an existing entry in our database. Do we need to\n                # delete it?\n                if is_deleted:\n                    # Yes, so delete it and move to the next XML account\n                    del cls._all_accounts[serial_number]\n                    continue\n                else:\n                    # No, so load up its details, ready to update them\n                    account = cls._all_accounts.get(serial_number)\n            else:\n                # We have no existing entry for this account\n                if is_deleted:\n                    # but it is marked as deleted, so we don't need one\n                    continue\n                # If it is not marked as deleted, we need to create an entry\n                account = Account()\n                account.serial_number = serial_number\n                cls._all_accounts[serial_number] = account\n\n            # Now, update the entry in our database with the details from XML\n            account.service_type = xml_account.get('Type')\n            account.deleted = is_deleted\n            account.username = xml_account.findtext('UN')\n            # Not sure what 'MD' stands for.  Metadata? May Delete?\n            account.metadata = xml_account.findtext('MD')\n            account.nickname = xml_account.findtext('NN')\n            account.oa_device_id = xml_account.findtext('OADevID')\n            account.key = xml_account.findtext('Key')\n            result[serial_number] = account\n            # There is always a TuneIn account, but it is handled separately\n            #  by Sonos, and does not appear in the xml account data. We\n            # need to add it ourselves.\n            tunein = Account()\n            tunein.service_type = '65031'  # Is this always the case?\n            tunein.deleted = False\n            tunein.username = ''\n            tunein.metadata = ''\n            tunein.nickname = ''\n            tunein.oa_device_id = ''\n            tunein.key = ''\n            tunein.serial_number = '0'\n            result['0'] = tunein\n\n        return result", "response": "Get all accounts known to the Sonos system."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of accounts for a given service type.", "response": "def get_accounts_for_service(cls, service_type):\n        \"\"\"Get a list of accounts for a given music service.\n\n        Args:\n            service_type (str): The service_type to use.\n\n        Returns:\n            list: A list of `Account` instances.\n        \"\"\"\n        return [\n            a for a in cls.get_accounts().values()\n            if a.service_type == service_type\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef play_alert(zones, alert_uri, alert_volume=20, alert_duration=0, fade_back=False):\n\n    # Use soco.snapshot to capture current state of each zone to allow restore\n    for zone in zones:\n        zone.snap = Snapshot(zone)\n        zone.snap.snapshot()\n        print('snapshot of zone: {}'.format(zone.player_name))\n\n    # prepare all zones for playing the alert\n    for zone in zones:\n        # Each Sonos group has one coordinator only these can play, pause, etc.\n        if zone.is_coordinator:\n            if not zone.is_playing_tv:  # can't pause TV - so don't try!\n                # pause music for each coordinators if playing\n                trans_state = zone.get_current_transport_info()\n                if trans_state['current_transport_state'] == 'PLAYING':\n                    zone.pause()\n\n        # For every Sonos player set volume and mute for every zone\n        zone.volume = alert_volume\n        zone.mute = False\n\n    # play the sound (uri) on each sonos coordinator\n    print('will play: {} on all coordinators'.format(alert_uri))\n    for zone in zones:\n        if zone.is_coordinator:\n            zone.play_uri(uri=alert_uri, title='Sonos Alert')\n\n    # wait for alert_duration\n    time.sleep(alert_duration)\n\n    # restore each zone to previous state\n    for zone in zones:\n        print('restoring {}'.format(zone.player_name))\n        zone.snap.restore(fade=fade_back)", "response": "This function is a convenience function that can be used to play an alert on several SoCo objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an item from the cache for this combination of args and kwargs.", "response": "def get(self, *args, **kwargs):\n        \"\"\"Get an item from the cache for this combination of args and kwargs.\n\n        Args:\n            *args: any arguments.\n            **kwargs: any keyword arguments.\n\n        Returns:\n            object: The object which has been found in the cache, or `None` if\n            no unexpired item is found. This means that there is no point\n            storing an item in the cache if it is `None`.\n\n        \"\"\"\n        if not self.enabled:\n            return None\n        # Look in the cache to see if there is an unexpired item. If there is\n        # we can just return the cached result.\n        cache_key = self.make_key(args, kwargs)\n        # Lock and load\n        with self._cache_lock:\n            if cache_key in self._cache:\n                expirytime, item = self._cache[cache_key]\n\n                if expirytime >= time():\n                    return item\n                else:\n                    # An expired item is present - delete it\n                    del self._cache[cache_key]\n        # Nothing found\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nputting an item into the cache for this combination of args and kwargs.", "response": "def put(self, item, *args, **kwargs):\n        \"\"\"Put an item into the cache, for this combination of args and kwargs.\n\n        Args:\n            *args: any arguments.\n            **kwargs: any keyword arguments. If ``timeout`` is specified as one\n                 of the keyword arguments, the item will remain available\n                 for retrieval for ``timeout`` seconds. If ``timeout`` is\n                 `None` or not specified, the ``default_timeout`` for this\n                 cache will be used. Specify a ``timeout`` of 0 (or ensure that\n                 the ``default_timeout`` for this cache is 0) if this item is\n                 not to be cached.\n        \"\"\"\n        if not self.enabled:\n            return\n        # Check for a timeout keyword, store and remove it.\n        timeout = kwargs.pop('timeout', None)\n        if timeout is None:\n            timeout = self.default_timeout\n        cache_key = self.make_key(args, kwargs)\n        # Store the item, along with the time at which it will expire\n        with self._cache_lock:\n            self._cache[cache_key] = (time() + timeout, item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete an item from the cache for this combination of args and kwargs.", "response": "def delete(self, *args, **kwargs):\n        \"\"\"Delete an item from the cache for this combination of args and\n        kwargs.\"\"\"\n        cache_key = self.make_key(args, kwargs)\n        with self._cache_lock:\n            try:\n                del self._cache[cache_key]\n            except KeyError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure an Album Art URI is an absolute URI.", "response": "def build_album_art_full_uri(self, url):\n        \"\"\"Ensure an Album Art URI is an absolute URI.\n\n        Args:\n             url (str): the album art URI.\n\n        Returns:\n            str: An absolute URI.\n        \"\"\"\n        # Add on the full album art link, as the URI version\n        # does not include the ipaddress\n        if not url.startswith(('http:', 'https:')):\n            url = 'http://' + self.soco.ip_address + ':1400' + url\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_album_art_to_full_uri(self, item):\n        if getattr(item, 'album_art_uri', False):\n            item.album_art_uri = self.build_album_art_full_uri(\n                item.album_art_uri)", "response": "Update an item s Album Art URI to be an absolute URI."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_artists(self, *args, **kwargs):\n        args = tuple(['artists'] + list(args))\n        return self.get_music_library_information(*args, **kwargs)", "response": "Convenience method for get_music_library_information with search_type = artists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_album_artists(self, *args, **kwargs):\n        args = tuple(['album_artists'] + list(args))\n        return self.get_music_library_information(*args, **kwargs)", "response": "Convenience method for getting album artists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_favorite_radio_stations(self, *args, **kwargs):\n        args = tuple(['radio_stations'] + list(args))\n        return self.get_music_library_information(*args, **kwargs)", "response": "Convenience method for get_music_library_information with search_type = radio_stations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_music_library_information(self, search_type, start=0,\n                                      max_items=100, full_album_art_uri=False,\n                                      search_term=None, subcategories=None,\n                                      complete_result=False):\n        \"\"\"Retrieve music information objects from the music library.\n\n        This method is the main method to get music information items, like\n        e.g. tracks, albums etc., from the music library with. It can be used\n        in a few different ways:\n\n        The ``search_term`` argument performs a fuzzy search on that string in\n        the results, so e.g calling::\n\n            get_music_library_information('artists', search_term='Metallica')\n\n        will perform a fuzzy search for the term 'Metallica' among all the\n        artists.\n\n        Using the ``subcategories`` argument, will jump directly into that\n        subcategory of the search and return results from there. So. e.g\n        knowing that among the artist is one called 'Metallica', calling::\n\n            get_music_library_information('artists',\n                                          subcategories=['Metallica'])\n\n        will jump directly into the 'Metallica' sub category and return the\n        albums associated with Metallica and::\n\n            get_music_library_information('artists',\n                                          subcategories=['Metallica', 'Black'])\n\n        will return the tracks of the album 'Black' by the artist 'Metallica'.\n        The order of sub category types is: Genres->Artists->Albums->Tracks.\n        It is also possible to combine the two, to perform a fuzzy search in a\n        sub category.\n\n        The ``start``, ``max_items`` and ``complete_result`` arguments all\n        have to do with paging of the results. By default the searches are\n        always paged, because there is a limit to how many items we can get at\n        a time. This paging is exposed to the user with the ``start`` and\n        ``max_items`` arguments. So calling::\n\n            get_music_library_information('artists', start=0, max_items=100)\n            get_music_library_information('artists', start=100, max_items=100)\n\n        will get the first and next 100 items, respectively. It is also\n        possible to ask for all the elements at once::\n\n            get_music_library_information('artists', complete_result=True)\n\n        This will perform the paging internally and simply return all the\n        items.\n\n        Args:\n\n            search_type (str):\n                The kind of information to retrieve. Can be one of:\n                ``'artists'``, ``'album_artists'``, ``'albums'``,\n                ``'genres'``, ``'composers'``, ``'tracks'``, ``'share'``,\n                ``'sonos_playlists'``, or ``'playlists'``, where playlists\n                are the imported playlists from the music library.\n            start (int, optional): starting number of returned matches\n                (zero based). Default 0.\n            max_items (int, optional): Maximum number of returned matches.\n                Default 100.\n            full_album_art_uri (bool):\n                whether the album art URI should be absolute (i.e. including\n                the IP address). Default `False`.\n            search_term (str, optional):\n                a string that will be used to perform a fuzzy search among the\n                search results. If used in combination with subcategories,\n                the fuzzy search will be performed in the subcategory.\n            subcategories (str, optional):\n                A list of strings that indicate one or more subcategories to\n                dive into.\n            complete_result (bool): if `True`, will disable\n                paging (ignore ``start`` and ``max_items``) and return all\n                results for the search.\n\n        Warning:\n            Getting e.g. all the tracks in a large collection might\n            take some time.\n\n\n        Returns:\n             `SearchResult`: an instance of `SearchResult`.\n\n        Note:\n            * The maximum numer of results may be restricted by the unit,\n              presumably due to transfer size consideration, so check the\n              returned number against that requested.\n\n            * The playlists that are returned with the ``'playlists'`` search,\n              are the playlists imported from the music library, they\n              are not the Sonos playlists.\n\n        Raises:\n             `SoCoException` upon errors.\n        \"\"\"\n        search = self.SEARCH_TRANSLATION[search_type]\n\n        # Add sub categories\n        if subcategories is not None:\n            for category in subcategories:\n                search += '/' + url_escape_path(really_unicode(category))\n        # Add fuzzy search\n        if search_term is not None:\n            search += ':' + url_escape_path(really_unicode(search_term))\n\n        item_list = []\n        metadata = {'total_matches': 100000}\n        while len(item_list) < metadata['total_matches']:\n            # Change start and max for complete searches\n            if complete_result:\n                start, max_items = len(item_list), 100000\n\n            # Try and get this batch of results\n            try:\n                response, metadata = \\\n                    self._music_lib_search(search, start, max_items)\n            except SoCoUPnPException as exception:\n                # 'No such object' UPnP errors\n                if exception.error_code == '701':\n                    return SearchResult([], search_type, 0, 0, None)\n                else:\n                    raise exception\n\n            # Parse the results\n            items = from_didl_string(response['Result'])\n            for item in items:\n                # Check if the album art URI should be fully qualified\n                if full_album_art_uri:\n                    self._update_album_art_to_full_uri(item)\n                # Append the item to the list\n                item_list.append(item)\n\n            # If we are not after the complete results, the stop after 1\n            # iteration\n            if not complete_result:\n                break\n\n        metadata['search_type'] = search_type\n        if complete_result:\n            metadata['number_returned'] = len(item_list)\n\n        # pylint: disable=star-args\n        return SearchResult(item_list, **metadata)", "response": "This method returns music information objects from the music library."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef browse(self, ml_item=None, start=0, max_items=100,\n               full_album_art_uri=False, search_term=None, subcategories=None):\n        \"\"\"Browse (get sub-elements from) a music library item.\n\n        Args:\n            ml_item (`DidlItem`): the item to browse, if left out or\n                `None`, items at the root level will be searched.\n            start (int): the starting index of the results.\n            max_items (int): the maximum number of items to return.\n            full_album_art_uri (bool): whether the album art URI should be\n                fully qualified with the relevant IP address.\n            search_term (str): A string that will be used to perform a fuzzy\n                search among the search results. If used in combination with\n                subcategories, the fuzzy search will be performed on the\n                subcategory. Note: Searching will not work if ``ml_item`` is\n                `None`.\n            subcategories (list): A list of strings that indicate one or more\n                subcategories to descend into. Note: Providing sub categories\n                will not work if ``ml_item`` is `None`.\n\n        Returns:\n            A `SearchResult` instance.\n\n        Raises:\n            AttributeError: if ``ml_item`` has no ``item_id`` attribute.\n            SoCoUPnPException: with ``error_code='701'`` if the item cannot be\n                browsed.\n        \"\"\"\n        if ml_item is None:\n            search = 'A:'\n        else:\n            search = ml_item.item_id\n\n        # Add sub categories\n        if subcategories is not None:\n            for category in subcategories:\n                search += '/' + url_escape_path(really_unicode(category))\n        # Add fuzzy search\n        if search_term is not None:\n            search += ':' + url_escape_path(really_unicode(search_term))\n\n        try:\n            response, metadata = \\\n                self._music_lib_search(search, start, max_items)\n        except SoCoUPnPException as exception:\n            # 'No such object' UPnP errors\n            if exception.error_code == '701':\n                return SearchResult([], 'browse', 0, 0, None)\n            else:\n                raise exception\n        metadata['search_type'] = 'browse'\n\n        # Parse the results\n        containers = from_didl_string(response['Result'])\n        item_list = []\n        for container in containers:\n            # Check if the album art URI should be fully qualified\n            if full_album_art_uri:\n                self._update_album_art_to_full_uri(container)\n            item_list.append(container)\n\n        # pylint: disable=star-args\n        return SearchResult(item_list, **metadata)", "response": "Browse ( get sub - elements from a music library item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef browse_by_idstring(self, search_type, idstring, start=0,\n                           max_items=100, full_album_art_uri=False):\n        \"\"\"Browse (get sub-elements from) a given music library item,\n        specified by a string.\n\n        Args:\n            search_type (str): The kind of information to retrieve. Can be\n                one of: ``'artists'``, ``'album_artists'``, ``'albums'``,\n                ``'genres'``, ``'composers'``, ``'tracks'``, ``'share'``,\n                ``'sonos_playlists'``, and ``'playlists'``, where\n                playlists are the imported file based playlists from the\n                music library.\n            idstring (str): a term to search for.\n            start (int): starting number of returned matches. Default 0.\n            max_items (int): Maximum number of returned matches. Default 100.\n            full_album_art_uri (bool): whether the album art URI should be\n                absolute (i.e. including the IP address). Default `False`.\n\n        Returns:\n            `SearchResult`: a `SearchResult` instance.\n\n        Note:\n            The maximum numer of results may be restricted by the unit,\n            presumably due to transfer size consideration, so check the\n            returned number against that requested.\n        \"\"\"\n        search = self.SEARCH_TRANSLATION[search_type]\n\n        # Check if the string ID already has the type, if so we do not want to\n        # add one also Imported playlist have a full path to them, so they do\n        # not require the A:PLAYLISTS part first\n        if idstring.startswith(search) or (search_type == 'playlists'):\n            search = \"\"\n\n        search_item_id = search + idstring\n        search_uri = \"#\" + search_item_id\n        # Not sure about the res protocol. But this seems to work\n        res = [DidlResource(\n            uri=search_uri, protocol_info=\"x-rincon-playlist:*:*:*\")]\n        search_item = DidlObject(\n            resources=res, title='', parent_id='',\n            item_id=search_item_id)\n\n        # Call the base version\n        return self.browse(search_item, start, max_items, full_album_art_uri)", "response": "Browse ( get sub - elements from a given music library item specified by a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _music_lib_search(self, search, start, max_items):\n        response = self.contentDirectory.Browse([\n            ('ObjectID', search),\n            ('BrowseFlag', 'BrowseDirectChildren'),\n            ('Filter', '*'),\n            ('StartingIndex', start),\n            ('RequestedCount', max_items),\n            ('SortCriteria', '')\n        ])\n\n        # Get result information\n        metadata = {}\n        for tag in ['NumberReturned', 'TotalMatches', 'UpdateID']:\n            metadata[camel_to_underscore(tag)] = int(response[tag])\n        return response, metadata", "response": "Perform a music library search and extract search numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_track(self, artist, album=None, track=None,\n                     full_album_art_uri=False):\n        \"\"\"Search for an artist, an artist's albums, or specific track.\n\n        Args:\n            artist (str): an artist's name.\n            album (str, optional): an album name. Default `None`.\n            track (str, optional): a track name. Default `None`.\n            full_album_art_uri (bool): whether the album art URI should be\n                absolute (i.e. including the IP address). Default `False`.\n\n        Returns:\n            A `SearchResult` instance.\n        \"\"\"\n        subcategories = [artist]\n        subcategories.append(album or '')\n\n        # Perform the search\n        result = self.get_album_artists(\n            full_album_art_uri=full_album_art_uri,\n            subcategories=subcategories, search_term=track,\n            complete_result=True)\n        result._metadata['search_type'] = 'search_track'\n        return result", "response": "Search for an artist album or specific track."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an artist s albums.", "response": "def get_albums_for_artist(self, artist, full_album_art_uri=False):\n        \"\"\"Get an artist's albums.\n\n        Args:\n            artist (str): an artist's name.\n            full_album_art_uri: whether the album art URI should be\n                absolute (i.e. including the IP address). Default `False`.\n\n        Returns:\n            A `SearchResult` instance.\n        \"\"\"\n        subcategories = [artist]\n        result = self.get_album_artists(\n            full_album_art_uri=full_album_art_uri,\n            subcategories=subcategories,\n            complete_result=True)\n\n        reduced = [item for item in result if item.__class__ == DidlMusicAlbum]\n        # It is necessary to update the list of items in two places, due to\n        # a bug in SearchResult\n        result[:] = reduced\n        result._metadata.update({\n            'item_list': reduced,\n            'search_type': 'albums_for_artist',\n            'number_returned': len(reduced),\n            'total_matches': len(reduced)\n        })\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the tracks of an artist s album.", "response": "def get_tracks_for_album(self, artist, album, full_album_art_uri=False):\n        \"\"\"Get the tracks of an artist's album.\n\n        Args:\n            artist (str): an artist's name.\n            album (str): an album name.\n            full_album_art_uri: whether the album art URI should be\n                absolute (i.e. including the IP address). Default `False`.\n\n        Returns:\n            A `SearchResult` instance.\n        \"\"\"\n        subcategories = [artist, album]\n        result = self.get_album_artists(\n            full_album_art_uri=full_album_art_uri,\n            subcategories=subcategories,\n            complete_result=True)\n        result._metadata['search_type'] = 'tracks_for_album'\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discover(timeout=5, include_invisible=False, interface_addr=None):\n\n    def create_socket(interface_addr=None):\n        \"\"\" A helper function for creating a socket for discover purposes.\n\n        Create and return a socket with appropriate options set for multicast.\n        \"\"\"\n\n        _sock = socket.socket(\n            socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n        # UPnP v1.0 requires a TTL of 4\n        _sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL,\n                         struct.pack(\"B\", 4))\n        if interface_addr is not None:\n            _sock.setsockopt(\n                socket.IPPROTO_IP, socket.IP_MULTICAST_IF,\n                socket.inet_aton(interface_addr))\n        return _sock\n\n    # pylint: disable=invalid-name\n    PLAYER_SEARCH = dedent(\"\"\"\\\n        M-SEARCH * HTTP/1.1\n        HOST: 239.255.255.250:1900\n        MAN: \"ssdp:discover\"\n        MX: 1\n        ST: urn:schemas-upnp-org:device:ZonePlayer:1\n        \"\"\").encode('utf-8')\n    MCAST_GRP = \"239.255.255.250\"\n    MCAST_PORT = 1900\n\n    _sockets = []\n    # Use the specified interface, if any\n    if interface_addr is not None:\n        try:\n            address = socket.inet_aton(interface_addr)\n        except socket.error:\n            raise ValueError(\"{0} is not a valid IP address string\".format(\n                interface_addr))\n        _sockets.append(create_socket(interface_addr))\n        _LOG.info(\"Sending discovery packets on default interface\")\n    else:\n        # Find the local network address using a couple of different methods.\n        # Create a socket for each unique address found, and one for the\n        # default multicast address\n        addresses = set()\n        try:\n            addresses.add(socket.gethostbyname(socket.gethostname()))\n        except socket.error:\n            pass\n        try:\n            addresses.add(socket.gethostbyname(socket.getfqdn()))\n        except socket.error:\n            pass\n        for address in addresses:\n            try:\n                _sockets.append(create_socket(address))\n            except socket.error as e:\n                _LOG.warning(\"Can't make a discovery socket for %s: %s: %s\",\n                             address, e.__class__.__name__, e)\n        # Add a socket using the system default address\n        _sockets.append(create_socket())\n        # Used to be logged as:\n        # list(s.getsockname()[0] for s in _sockets)\n        # but getsockname fails on Windows with unconnected unbound sockets\n        # https://bugs.python.org/issue1049\n        _LOG.info(\"Sending discovery packets on %s\", _sockets)\n\n    for _ in range(0, 3):\n        # Send a few times to each socket. UDP is unreliable\n        for _sock in _sockets:\n            _sock.sendto(really_utf8(PLAYER_SEARCH), (MCAST_GRP, MCAST_PORT))\n\n    t0 = time.time()\n    while True:\n        # Check if the timeout is exceeded. We could do this check just\n        # before the currently only continue statement of this loop,\n        # but I feel it is safer to do it here, so that we do not forget\n        # to do it if/when another continue statement is added later.\n        # Note: this is sensitive to clock adjustments. AFAIK there\n        # is no monotonic timer available before Python 3.3.\n        t1 = time.time()\n        if t1 - t0 > timeout:\n            return None\n\n        # The timeout of the select call is set to be no greater than\n        # 100ms, so as not to exceed (too much) the required timeout\n        # in case the loop is executed more than once.\n        response, _, _ = select.select(_sockets, [], [], min(timeout, 0.1))\n\n        # Only Zone Players should respond, given the value of ST in the\n        # PLAYER_SEARCH message. However, to prevent misbehaved devices\n        # on the network disrupting the discovery process, we check that\n        # the response contains the \"Sonos\" string; otherwise we keep\n        # waiting for a correct response.\n        #\n        # Here is a sample response from a real Sonos device (actual numbers\n        # have been redacted):\n        # HTTP/1.1 200 OK\n        # CACHE-CONTROL: max-age = 1800\n        # EXT:\n        # LOCATION: http://***.***.***.***:1400/xml/device_description.xml\n        # SERVER: Linux UPnP/1.0 Sonos/26.1-76230 (ZPS3)\n        # ST: urn:schemas-upnp-org:device:ZonePlayer:1\n        # USN: uuid:RINCON_B8*************00::urn:schemas-upnp-org:device:\n        #                                                     ZonePlayer:1\n        # X-RINCON-BOOTSEQ: 3\n        # X-RINCON-HOUSEHOLD: Sonos_7O********************R7eU\n\n        if response:\n            for _sock in response:\n                data, addr = _sock.recvfrom(1024)\n                _LOG.debug(\n                    'Received discovery response from %s: \"%s\"', addr, data\n                )\n                if b\"Sonos\" in data:\n                    # Now we have an IP, we can build a SoCo instance and query\n                    # that player for the topology to find the other players.\n                    # It is much more efficient to rely upon the Zone\n                    # Player's ability to find the others, than to wait for\n                    # query responses from them ourselves.\n                    zone = config.SOCO_CLASS(addr[0])\n                    if include_invisible:\n                        return zone.all_zones\n                    else:\n                        return zone.visible_zones", "response": "Discover Sonos zones on the local network."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn any visible soco device for when it doesn t matter which.", "response": "def any_soco():\n    \"\"\"Return any visible soco device, for when it doesn't matter which.\n\n    Try to obtain an existing instance, or use `discover` if necessary.\n    Note that this assumes that the existing instance has not left\n    the network.\n\n    Returns:\n        SoCo: A `SoCo` instance (or subclass if `config.SOCO_CLASS` is set,\n            or `None` if no instances are found\n    \"\"\"\n\n    cls = config.SOCO_CLASS\n    # pylint: disable=no-member, protected-access\n    try:\n        # Try to get the first pre-existing soco instance we know about,\n        # as long as it is visible (i.e. not a bridge etc). Otherwise,\n        # perform discovery (again, excluding invisibles) and return one of\n        # those\n        device = next(d for d in cls._instances[cls._class_group].values()\n                      if d.is_visible)\n    except (KeyError, StopIteration):\n        devices = discover()\n        return None if devices is None else devices.pop()\n\n    return device"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap_arguments(args=None):\n        if args is None:\n            args = []\n\n        tags = []\n        for name, value in args:\n            tag = \"<{name}>{value}</{name}>\".format(\n                name=name, value=escape(\"%s\" % value, {'\"': \"&quot;\"}))\n            # % converts to unicode because we are using unicode literals.\n            # Avoids use of 'unicode' function which does not exist in python 3\n            tags.append(tag)\n\n        xml = \"\".join(tags)\n        return xml", "response": "Wrap a list of tuples in xml ready to pass into a SOAP request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unwrap_arguments(xml_response):\n\n        # A UPnP SOAP response (including headers) looks like this:\n\n        # HTTP/1.1 200 OK\n        # CONTENT-LENGTH: bytes in body\n        # CONTENT-TYPE: text/xml; charset=\"utf-8\" DATE: when response was\n        # generated\n        # EXT:\n        # SERVER: OS/version UPnP/1.0 product/version\n        #\n        # <?xml version=\"1.0\"?>\n        # <s:Envelope\n        #   xmlns:s=\"http://schemas.xmlsoap.org/soap/envelope/\"\n        #   s:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\">\n        #   <s:Body>\n        #       <u:actionNameResponse\n        #           xmlns:u=\"urn:schemas-upnp-org:service:serviceType:v\">\n        #           <argumentName>out arg value</argumentName>\n        #               ... other out args and their values go here, if any\n        #       </u:actionNameResponse>\n        #   </s:Body>\n        # </s:Envelope>\n\n        # Get all tags in order. Elementree (in python 2.x) seems to prefer to\n        # be fed bytes, rather than unicode\n        xml_response = xml_response.encode('utf-8')\n        try:\n            tree = XML.fromstring(xml_response)\n        except XML.ParseError:\n            # Try to filter illegal xml chars (as unicode), in case that is\n            # the reason for the parse error\n            filtered = illegal_xml_re.sub('', xml_response.decode('utf-8'))\\\n                                     .encode('utf-8')\n            tree = XML.fromstring(filtered)\n\n        # Get the first child of the <Body> tag which will be\n        # <{actionNameResponse}> (depends on what actionName is). Turn the\n        # children of this into a {tagname, content} dict. XML unescaping\n        # is carried out for us by elementree.\n        action_response = tree.find(\n            \"{http://schemas.xmlsoap.org/soap/envelope/}Body\")[0]\n        return dict((i.tag, i.text or \"\") for i in action_response)", "response": "Extract arguments and their values from a SOAP response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compose_args(self, action_name, in_argdict):\n\n        for action in self.actions:\n            if action.name == action_name:\n                # The found 'action' will be visible from outside the loop\n                break\n        else:\n            raise AttributeError('Unknown Action: {0}'.format(action_name))\n\n        # Check for given argument names which do not occur in the expected\n        # argument list\n        # pylint: disable=undefined-loop-variable\n        unexpected = set(in_argdict) - \\\n            set(argument.name for argument in action.in_args)\n        if unexpected:\n            raise ValueError(\n                \"Unexpected argument '{0}'. Method signature: {1}\"\n                .format(next(iter(unexpected)), str(action))\n            )\n\n        # List the (name, value) tuples for each argument in the argument list\n        composed = []\n        for argument in action.in_args:\n            name = argument.name\n            if name in in_argdict:\n                composed.append((name, in_argdict[name]))\n                continue\n            if name in self.DEFAULT_ARGS:\n                composed.append((name, self.DEFAULT_ARGS[name]))\n                continue\n            if argument.vartype.default is not None:\n                composed.append((name, argument.vartype.default))\n            raise ValueError(\n                \"Missing argument '{0}'. Method signature: {1}\"\n                .format(argument.name, str(action))\n            )\n        return composed", "response": "Compose the argument list from an argument dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_command(self, action, args=None, cache=None, cache_timeout=None,\n                     **kwargs):\n        \"\"\"Send a command to a Sonos device.\n\n        Args:\n            action (str): the name of an action (a string as specified in the\n                service description XML file) to be sent.\n            args (list, optional): Relevant arguments as a list of (name,\n                value) tuples, as an alternative to ``kwargs``.\n            cache (Cache): A cache is operated so that the result will be\n                stored for up to ``cache_timeout`` seconds, and a subsequent\n                call with the same arguments within that period will be\n                returned from the cache, saving a further network call. The\n                cache may be invalidated or even primed from another thread\n                (for example if a UPnP event is received to indicate that\n                the state of the Sonos device has changed). If\n                ``cache_timeout`` is missing or `None`, the cache will use a\n                default value (which may be 0 - see `cache`). By default,\n                the cache identified by the service's `cache` attribute will\n                be used, but a different cache object may be specified in\n                the `cache` parameter.\n            kwargs: Relevant arguments for the command.\n\n        Returns:\n             dict: a dict of ``{argument_name, value}`` items.\n\n        Raises:\n            `AttributeError`: If this service does not support the action.\n            `ValueError`: If the argument lists do not match the action\n                signature.\n            `SoCoUPnPException`: if a SOAP error occurs.\n            `UnknownSoCoException`: if an unknonwn UPnP error occurs.\n            `requests.exceptions.HTTPError`: if an http error occurs.\n\n        \"\"\"\n        if args is None:\n            args = self.compose_args(action, kwargs)\n        if cache is None:\n            cache = self.cache\n        result = cache.get(action, args)\n        if result is not None:\n            log.debug(\"Cache hit\")\n            return result\n        # Cache miss, so go ahead and make a network call\n        headers, body = self.build_command(action, args)\n        log.info(\"Sending %s %s to %s\", action, args, self.soco.ip_address)\n        log.debug(\"Sending %s, %s\", headers, prettify(body))\n        # Convert the body to bytes, and send it.\n        response = requests.post(\n            self.base_url + self.control_url,\n            headers=headers,\n            data=body.encode('utf-8')\n        )\n        log.debug(\"Received %s, %s\", response.headers, response.text)\n        status = response.status_code\n        log.info(\n            \"Received status %s from %s\", status, self.soco.ip_address)\n        if status == 200:\n            # The response is good. Get the output params, and return them.\n            # NB an empty dict is a valid result. It just means that no\n            # params are returned. By using response.text, we rely upon\n            # the requests library to convert to unicode for us.\n            result = self.unwrap_arguments(response.text) or True\n            # Store in the cache. There is no need to do this if there was an\n            # error, since we would want to try a network call again.\n            cache.put(result, action, args, timeout=cache_timeout)\n            return result\n        elif status == 500:\n            # Internal server error. UPnP requires this to be returned if the\n            # device does not like the action for some reason. The returned\n            # content will be a SOAP Fault. Parse it and raise an error.\n            try:\n                self.handle_upnp_error(response.text)\n            except Exception as exc:\n                log.exception(str(exc))\n                raise\n        else:\n            # Something else has gone wrong. Probably a network error. Let\n            # Requests handle it\n            response.raise_for_status()\n        return None", "response": "Send a command to a Sonos device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubscribe to the service s events.", "response": "def subscribe(\n            self, requested_timeout=None, auto_renew=False, event_queue=None):\n        \"\"\"Subscribe to the service's events.\n\n        Args:\n            requested_timeout (int, optional): If requested_timeout is\n                provided, a subscription valid for that\n                number of seconds will be requested, but not guaranteed. Check\n                `Subscription.timeout` on return to find out what period of\n                validity is actually allocated.\n            auto_renew (bool): If auto_renew is `True`, the subscription will\n                automatically be renewed just before it expires, if possible.\n                Default is `False`.\n\n            event_queue (:class:`~queue.Queue`): a thread-safe queue object on\n                which received events will be put. If not specified,\n                a (:class:`~queue.Queue`) will be created and used.\n\n        Returns:\n            `Subscription`: an insance of `Subscription`, representing\n                the new subscription.\n\n        To unsubscribe, call the `unsubscribe` method on the returned object.\n        \"\"\"\n        subscription = Subscription(\n            self, event_queue)\n        subscription.subscribe(\n            requested_timeout=requested_timeout, auto_renew=auto_renew)\n        return subscription"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield the services eventable variables.", "response": "def iter_event_vars(self):\n        \"\"\"Yield the services eventable variables.\n\n        Yields:\n            `tuple`: a tuple of (variable name, data type).\n        \"\"\"\n\n        # pylint: disable=invalid-name\n        ns = '{urn:schemas-upnp-org:service-1-0}'\n        scpd_body = requests.get(self.base_url + self.scpd_url).text\n        tree = XML.fromstring(scpd_body.encode('utf-8'))\n        # parse the state variables to get the relevant variable types\n        statevars = tree.findall('{}stateVariable'.format(ns))\n        for state in statevars:\n            # We are only interested if 'sendEvents' is 'yes', i.e this\n            # is an eventable variable\n            if state.attrib['sendEvents'] == \"yes\":\n                name = state.findtext('{}name'.format(ns))\n                vartype = state.findtext('{}dataType'.format(ns))\n                yield (name, vartype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetZoneGroupState(self, *args, **kwargs):\n        kwargs['cache'] = kwargs.get('cache', zone_group_state_shared_cache)\n        return self.send_command('GetZoneGroupState', *args, **kwargs)", "response": "Overrides default handling to use the global shared zone group state\n        cache unless another cache is specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a random non - py file from this folder and subfolders to soco", "response": "def add_random_file_from_present_folder(machine_ip, port, zone):\n    \"\"\"Add a random non-py file from this folder and subfolders to soco\"\"\"\n    # Make a list of music files, right now it is done by collection all files\n    # below the current folder whose extension does not start with .py\n    # This will probably need to be modded for other pusposes.\n    music_files = []\n    print('Looking for music files')\n    for path, dirs, files in os.walk('.'):\n        for file_ in files:\n            if not os.path.splitext(file_)[1].startswith('.py'):\n                music_files.append(os.path.relpath(os.path.join(path, file_)))\n                print('Found:', music_files[-1])\n\n    random_file = choice(music_files)\n    # urlencode all the path parts (but not the /'s)\n    random_file = os.path.join(\n        *[quote(part) for part in os.path.split(random_file)]\n    )\n    print('\\nPlaying random file:', random_file)\n    netpath = 'http://{}:{}/{}'.format(machine_ip, port, random_file)\n\n    number_in_queue = zone.add_uri_to_queue(netpath)\n    # play_from_queue indexes are 0-based\n    zone.play_from_queue(number_in_queue - 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts any number of DidlObjects <DidlObject > to a unicode xml string.", "response": "def to_didl_string(*args):\n    \"\"\"Convert any number of `DidlObjects <DidlObject>` to a unicode xml\n    string.\n\n    Args:\n        *args (DidlObject): One or more `DidlObject` (or subclass) instances.\n\n    Returns:\n        str: A unicode string representation of DIDL-Lite XML in the form\n        ``'<DIDL-Lite ...>...</DIDL-Lite>'``.\n    \"\"\"\n    didl = XML.Element(\n        'DIDL-Lite',\n        {\n            'xmlns': \"urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/\",\n            'xmlns:dc': \"http://purl.org/dc/elements/1.1/\",\n            'xmlns:upnp': \"urn:schemas-upnp-org:metadata-1-0/upnp/\",\n            'xmlns:r': \"urn:schemas-rinconnetworks-com:metadata-1-0/\"\n        })\n    for arg in args:\n        didl.append(arg.to_element())\n    if sys.version_info[0] == 2:\n        return XML.tostring(didl)\n    else:\n        return XML.tostring(didl, encoding='unicode')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_element(cls, element):\n        def _int_helper(name):\n            \"\"\"Try to convert the name attribute to an int, or None.\"\"\"\n            result = element.get(name)\n            if result is not None:\n                try:\n                    return int(result)\n                except ValueError:\n                    raise DIDLMetadataError(\n                        'Could not convert {0} to an integer'.format(name))\n            else:\n                return None\n\n        content = {}\n        # required\n        content['protocol_info'] = element.get('protocolInfo')\n        if content['protocol_info'] is None:\n            raise DIDLMetadataError('Could not create Resource from Element: '\n                                    'protocolInfo not found (required).')\n        # Optional\n        content['import_uri'] = element.get('importUri')\n        content['size'] = _int_helper('size')\n        content['duration'] = element.get('duration')\n        content['bitrate'] = _int_helper('bitrate')\n        content['sample_frequency'] = _int_helper('sampleFrequency')\n        content['bits_per_sample'] = _int_helper('bitsPerSample')\n        content['nr_audio_channels'] = _int_helper('nrAudioChannels')\n        content['resolution'] = element.get('resolution')\n        content['color_depth'] = _int_helper('colorDepth')\n        content['protection'] = element.get('protection')\n        content['uri'] = element.text\n        return cls(**content)", "response": "Create a new resource from an XML element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_element(self):\n        if not self.protocol_info:\n            raise DIDLMetadataError('Could not create Element for this'\n                                    'resource:'\n                                    'protocolInfo not set (required).')\n        root = XML.Element('res')\n\n        # Required\n        root.attrib['protocolInfo'] = self.protocol_info\n        # Optional\n        if self.import_uri is not None:\n            root.attrib['importUri'] = self.import_uri\n        if self.size is not None:\n            root.attrib['size'] = str(self.size)\n        if self.duration is not None:\n            root.attrib['duration'] = self.duration\n        if self.bitrate is not None:\n            root.attrib['bitrate'] = str(self.bitrate)\n        if self.sample_frequency is not None:\n            root.attrib['sampleFrequency'] = str(self.sample_frequency)\n        if self.bits_per_sample is not None:\n            root.attrib['bitsPerSample'] = str(self.bits_per_sample)\n        if self.nr_audio_channels is not None:\n            root.attrib['nrAudioChannels'] = str(self.nr_audio_channels)\n        if self.resolution is not None:\n            root.attrib['resolution'] = self.resolution\n        if self.color_depth is not None:\n            root.attrib['colorDepth'] = str(self.color_depth)\n        if self.protection is not None:\n            root.attrib['protection'] = self.protection\n\n        root.text = self.uri\n        return root", "response": "Returns an ElementTree Element based on this resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self, remove_nones=False):\n        content = {\n            'uri': self.uri,\n            'protocol_info': self.protocol_info,\n            'import_uri': self.import_uri,\n            'size': self.size,\n            'duration': self.duration,\n            'bitrate': self.bitrate,\n            'sample_frequency': self.sample_frequency,\n            'bits_per_sample': self.bits_per_sample,\n            'nr_audio_channels': self.nr_audio_channels,\n            'resolution': self.resolution,\n            'color_depth': self.color_depth,\n            'protection': self.protection,\n        }\n        if remove_nones:\n            # delete any elements that have a value of None to optimize size\n            # of the returned structure\n            nones = [k for k in content if content[k] is None]\n            for k in nones:\n                del content[k]\n        return content", "response": "Return a dict representation of the DidlResource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_element(cls, element):     # pylint: disable=R0914\n        # We used to check here that we have the right sort of element,\n        # ie a container or an item. But Sonos seems to use both\n        # indiscriminately, eg a playlistContainer can be an item or a\n        # container. So we now just check that it is one or the other.\n        tag = element.tag\n        if not (tag.endswith('item') or tag.endswith('container')):\n            raise DIDLMetadataError(\n                \"Wrong element. Expected <item> or <container>,\"\n                \" got <{0}> for class {1}'\".format(\n                    tag, cls.item_class))\n        # and that the upnp matches what we are expecting\n        item_class = element.find(ns_tag('upnp', 'class')).text\n\n        # In case this class has an # specified unofficial\n        # subclass, ignore it by stripping it from item_class\n        if '.#' in item_class:\n            item_class = item_class[:item_class.find('.#')]\n\n        if item_class != cls.item_class:\n            raise DIDLMetadataError(\n                \"UPnP class is incorrect. Expected '{0}',\"\n                \" got '{1}'\".format(cls.item_class, item_class))\n\n        # parent_id, item_id  and restricted are stored as attributes on the\n        # element\n        item_id = element.get('id', None)\n        if item_id is None:\n            raise DIDLMetadataError(\"Missing id attribute\")\n        item_id = really_unicode(item_id)\n        parent_id = element.get('parentID', None)\n        if parent_id is None:\n            raise DIDLMetadataError(\"Missing parentID attribute\")\n        parent_id = really_unicode(parent_id)\n\n        # CAUTION: This implementation deviates from the spec.\n        # Elements are normally required to have a `restricted` tag, but\n        # Spotify Direct violates this. To make it work, a missing restricted\n        # tag is interpreted as `restricted = True`.\n        restricted = element.get('restricted', None)\n        restricted = False if restricted in [0, 'false', 'False'] else True\n\n        # Similarily, all elements should have a title tag, but Spotify Direct\n        # does not comply\n        title_elt = element.find(ns_tag('dc', 'title'))\n        if title_elt is None or not title_elt.text:\n            title = ''\n        else:\n            title = really_unicode(title_elt.text)\n\n        # Deal with any resource elements\n        resources = []\n        for res_elt in element.findall(ns_tag('', 'res')):\n            resources.append(\n                DidlResource.from_element(res_elt))\n\n        # and the desc element (There is only one in Sonos)\n        desc = element.findtext(ns_tag('', 'desc'))\n\n        # Get values of the elements listed in _translation and add them to\n        # the content dict\n        content = {}\n        for key, value in cls._translation.items():\n            result = element.findtext(ns_tag(*value))\n            if result is not None:\n                # We store info as unicode internally.\n                content[key] = really_unicode(result)\n\n        # Convert type for original track number\n        if content.get('original_track_number') is not None:\n            content['original_track_number'] = \\\n                int(content['original_track_number'])\n\n        # Now pass the content dict we have just built to the main\n        # constructor, as kwargs, to create the object\n        return cls(title=title, parent_id=parent_id, item_id=item_id,\n                   restricted=restricted, resources=resources, desc=desc,\n                   **content)", "response": "Create an instance of this class from an ElementTree xml element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(cls, content):\n        # Do we really need this constructor? Could use DidlObject(**content)\n        # instead.  -- We do now\n        if 'resources' in content:\n            content['resources'] = [DidlResource.from_dict(x)\n                                    for x in content['resources']]\n        return cls(**content)", "response": "Create an instance from a dict containing metadata information."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the dict representation of the instance.", "response": "def to_dict(self, remove_nones=False):\n        \"\"\"Return the dict representation of the instance.\n\n       Args:\n            remove_nones (bool, optional): Optionally remove dictionary\n                elements when their value is `None`.\n\n        Returns:\n            dict: a dict representation of the `DidlObject`.\n        \"\"\"\n        content = {}\n        # Get the value of each attribute listed in _translation, and add it\n        # to the content dict\n        for key in self._translation:\n            if hasattr(self, key):\n                content[key] = getattr(self, key)\n        # also add parent_id, item_id, restricted, title and resources because\n        # they are not listed in _translation\n        content['parent_id'] = self.parent_id\n        content['item_id'] = self.item_id\n        content['restricted'] = self.restricted\n        content['title'] = self.title\n        if self.resources != []:\n            content['resources'] = [resource.to_dict(remove_nones=remove_nones)\n                                    for resource in self.resources]\n        content['desc'] = self.desc\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an ElementTree Element representing this instance.", "response": "def to_element(self, include_namespaces=False):\n        \"\"\"Return an ElementTree Element representing this instance.\n\n        Args:\n            include_namespaces (bool, optional): If True, include xml\n                namespace attributes on the root element\n\n        Return:\n            ~xml.etree.ElementTree.Element: an Element.\n        \"\"\"\n        elt_attrib = {}\n        if include_namespaces:\n            elt_attrib.update({\n                'xmlns': \"urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/\",\n                'xmlns:dc': \"http://purl.org/dc/elements/1.1/\",\n                'xmlns:upnp': \"urn:schemas-upnp-org:metadata-1-0/upnp/\",\n            })\n        elt_attrib.update({\n            'parentID': self.parent_id,\n            'restricted': 'true' if self.restricted else 'false',\n            'id': self.item_id\n        })\n        elt = XML.Element(self.tag, elt_attrib)\n\n        # Add the title, which should always come first, according to the spec\n        XML.SubElement(elt, 'dc:title').text = self.title\n\n        # Add in any resources\n        for resource in self.resources:\n            elt.append(resource.to_element())\n\n        # Add the rest of the metadata attributes (i.e all those listed in\n        # _translation) as sub-elements of the item element.\n        for key, value in self._translation.items():\n            if hasattr(self, key):\n                # Some attributes have a namespace of '', which means they\n                # are in the default namespace. We need to handle those\n                # carefully\n                tag = \"%s:%s\" % value if value[0] else \"%s\" % value[1]\n                XML.SubElement(elt, tag).text = (\"%s\" % getattr(self, key))\n        # Now add in the item class\n        XML.SubElement(elt, 'upnp:class').text = self.item_class\n\n        # And the desc element\n        desc_attrib = {'id': 'cdudn', 'nameSpace':\n                       'urn:schemas-rinconnetworks-com:metadata-1-0/'}\n        desc_elt = XML.SubElement(elt, 'desc', desc_attrib)\n        desc_elt.text = self.desc\n\n        return elt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a resource uri for this instance.", "response": "def set_uri(self, uri, resource_nr=0, protocol_info=None):\n        \"\"\"Set a resource uri for this instance. If no resource exists, create\n        a new one with the given protocol info.\n\n        Args:\n            uri (str): The resource uri.\n            resource_nr (int): The index of the resource on which to set the\n                uri. If it does not exist, a new resource is added to the list.\n                Note that by default, only the uri of the first resource is\n                used for playing the item.\n            protocol_info (str): Protocol info for the resource. If none is\n                given and the resource does not exist yet, a default protocol\n                info is constructed as '[uri prefix]:*:*:*'.\n        \"\"\"\n        try:\n            self.resources[resource_nr].uri = uri\n            if protocol_info is not None:\n                self.resources[resource_nr].protocol_info = protocol_info\n        except IndexError:\n            if protocol_info is None:\n                # create default protcol info\n                protocol_info = uri[:uri.index(':')] + ':*:*:*'\n            self.resources.append(DidlResource(uri, protocol_info))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_NOTIFY(self):  # pylint: disable=invalid-name\n        timestamp = time.time()\n        headers = requests.structures.CaseInsensitiveDict(self.headers)\n        seq = headers['seq']  # Event sequence number\n        sid = headers['sid']  # Event Subscription Identifier\n        content_length = int(headers['content-length'])\n        content = self.rfile.read(content_length)\n        # Find the relevant service and queue from the sid\n        with _subscriptions_lock:\n            subscription = _subscriptions.get(sid)\n        # It might have been removed by another thread\n        if subscription:\n            service = subscription.service\n            log.info(\n                \"Event %s received for %s service on thread %s at %s\", seq,\n                service.service_id, threading.current_thread(), timestamp)\n            log.debug(\"Event content: %s\", content)\n            variables = parse_event_xml(content)\n            # Build the Event object\n            event = Event(sid, seq, service, timestamp, variables)\n            # pass the event details on to the service so it can update its\n            # cache.\n            # pylint: disable=protected-access\n            service._update_cache_on_event(event)\n            # Put the event on the queue\n            subscription.events.put(event)\n        else:\n            log.info(\"No service registered for %s\", sid)\n        self.send_response(200)\n        self.end_headers()", "response": "Handle a NOTIFY request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n        listener = EventServer(self.address, EventNotifyHandler)\n        log.info(\"Event listener running on %s\", listener.server_address)\n        # Listen for events until told to stop\n        while not self.stop_flag.is_set():\n            listener.handle_request()", "response": "Start the event server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the event listener server thread.", "response": "def start(self, any_zone):\n        \"\"\"Start the event listener listening on the local machine at port 1400\n        (default)\n\n        Make sure that your firewall allows connections to this port\n\n        Args:\n            any_zone (SoCo): Any Sonos device on the network. It does not\n                matter which device. It is used only to find a local IP address\n                reachable by the Sonos net.\n\n        Note:\n            The port on which the event listener listens is configurable.\n            See `config.EVENT_LISTENER_PORT`\n        \"\"\"\n\n        # Find our local network IP address which is accessible to the\n        # Sonos net, see http://stackoverflow.com/q/166506\n        with self._start_lock:\n            if not self.is_running:\n                # Use configured IP address if there is one, else detect\n                # automatically.\n                if config.EVENT_LISTENER_IP:\n                    ip_address = config.EVENT_LISTENER_IP\n                else:\n                    temp_sock = socket.socket(socket.AF_INET,\n                                              socket.SOCK_DGRAM)\n                    temp_sock.connect((any_zone.ip_address,\n                                       config.EVENT_LISTENER_PORT))\n                    ip_address = temp_sock.getsockname()[0]\n                    temp_sock.close()\n\n                # Start the event listener server in a separate thread.\n                self.address = (ip_address, config.EVENT_LISTENER_PORT)\n                self._listener_thread = EventServerThread(self.address)\n                self._listener_thread.daemon = True\n                self._listener_thread.start()\n                self.is_running = True\n                log.info(\"Event listener started\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the event listener.", "response": "def stop(self):\n        \"\"\"Stop the event listener.\"\"\"\n        # Signal the thread to stop before handling the next request\n        self._listener_thread.stop_flag.set()\n        # Send a dummy request in case the http server is currently listening\n        try:\n            urlopen(\n                'http://%s:%s/' % (self.address[0], self.address[1]))\n        except URLError:\n            # If the server is already shut down, we receive a socket error,\n            # which we ignore.\n            pass\n        # wait for the thread to finish\n        self._listener_thread.join()\n        self.is_running = False\n        log.info(\"Event listener stopped\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubscribes to the service.", "response": "def subscribe(self, requested_timeout=None, auto_renew=False):\n        \"\"\"Subscribe to the service.\n\n        If requested_timeout is provided, a subscription valid for that number\n        of seconds will be requested, but not guaranteed. Check\n        `timeout` on return to find out what period of validity is\n        actually allocated.\n\n        Note:\n            SoCo will try to unsubscribe any subscriptions which are still\n            subscribed on program termination, but it is good practice for\n            you to clean up by making sure that you call :meth:`unsubscribe`\n            yourself.\n\n        Args:\n            requested_timeout(int, optional): The timeout to be requested.\n            auto_renew (bool, optional): If `True`, renew the subscription\n                automatically shortly before timeout. Default `False`.\n        \"\"\"\n\n        class AutoRenewThread(threading.Thread):\n            \"\"\"Used by the auto_renew code to renew a subscription from within\n            a thread.\n\n            \"\"\"\n\n            def __init__(self, interval, stop_flag, sub, *args, **kwargs):\n                super(AutoRenewThread, self).__init__(*args, **kwargs)\n                self.interval = interval\n                self.sub = sub\n                self.stop_flag = stop_flag\n                self.daemon = True\n\n            def run(self):\n                sub = self.sub\n                stop_flag = self.stop_flag\n                interval = self.interval\n                while not stop_flag.wait(interval):\n                    log.info(\"Autorenewing subscription %s\", sub.sid)\n                    sub.renew()\n\n        # TIMEOUT is provided for in the UPnP spec, but it is not clear if\n        # Sonos pays any attention to it. A timeout of 86400 secs always seems\n        # to be allocated\n        self.requested_timeout = requested_timeout\n        if self._has_been_unsubscribed:\n            raise SoCoException(\n                'Cannot resubscribe instance once unsubscribed')\n        service = self.service\n        # The event listener must be running, so start it if not\n        if not event_listener.is_running:\n            event_listener.start(service.soco)\n        # an event subscription looks like this:\n        # SUBSCRIBE publisher path HTTP/1.1\n        # HOST: publisher host:publisher port\n        # CALLBACK: <delivery URL>\n        # NT: upnp:event\n        # TIMEOUT: Second-requested subscription duration (optional)\n\n        # pylint: disable=unbalanced-tuple-unpacking\n        ip_address, port = event_listener.address\n\n        if config.EVENT_ADVERTISE_IP:\n            ip_address = config.EVENT_ADVERTISE_IP\n\n        headers = {\n            'Callback': '<http://{}:{}>'.format(ip_address, port),\n            'NT': 'upnp:event'\n        }\n        if requested_timeout is not None:\n            headers[\"TIMEOUT\"] = \"Second-{}\".format(requested_timeout)\n\n        # Lock out EventNotifyHandler during registration\n        with _subscriptions_lock:\n            response = requests.request(\n                'SUBSCRIBE', service.base_url + service.event_subscription_url,\n                headers=headers)\n            response.raise_for_status()\n            self.sid = response.headers['sid']\n            timeout = response.headers['timeout']\n            # According to the spec, timeout can be \"infinite\" or \"second-123\"\n            # where 123 is a number of seconds.  Sonos uses \"Second-123\" (with\n            # a capital letter)\n            if timeout.lower() == 'infinite':\n                self.timeout = None\n            else:\n                self.timeout = int(timeout.lstrip('Second-'))\n            self._timestamp = time.time()\n            self.is_subscribed = True\n            log.info(\n                \"Subscribed to %s, sid: %s\",\n                service.base_url + service.event_subscription_url, self.sid)\n            # Add the subscription to the master dict so it can be looked up\n            # by sid\n            _subscriptions[self.sid] = self\n\n        # Register this subscription to be unsubscribed at exit if still alive\n        # This will not happen if exit is abnormal (eg in response to a\n        # signal or fatal interpreter error - see the docs for `atexit`).\n        atexit.register(self.unsubscribe)\n\n        # Set up auto_renew\n        if not auto_renew:\n            return\n        # Autorenew just before expiry, say at 85% of self.timeout seconds\n        interval = self.timeout * 85 / 100\n        auto_renew_thread = AutoRenewThread(\n            interval, self._auto_renew_thread_flag, self)\n        auto_renew_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenews the event subscription.", "response": "def renew(self, requested_timeout=None):\n        \"\"\"Renew the event subscription.\n\n        You should not try to renew a subscription which has been\n        unsubscribed, or once it has expired.\n\n        Args:\n            requested_timeout (int, optional): The period for which a renewal\n                request should be made. If None (the default), use the timeout\n                requested on subscription.\n        \"\"\"\n        # NB This code is sometimes called from a separate thread (when\n        # subscriptions are auto-renewed. Be careful to ensure thread-safety\n\n        if self._has_been_unsubscribed:\n            raise SoCoException(\n                'Cannot renew subscription once unsubscribed')\n        if not self.is_subscribed:\n            raise SoCoException(\n                'Cannot renew subscription before subscribing')\n        if self.time_left == 0:\n            raise SoCoException(\n                'Cannot renew subscription after expiry')\n\n        # SUBSCRIBE publisher path HTTP/1.1\n        # HOST: publisher host:publisher port\n        # SID: uuid:subscription UUID\n        # TIMEOUT: Second-requested subscription duration (optional)\n        headers = {\n            'SID': self.sid\n        }\n        if requested_timeout is None:\n            requested_timeout = self.requested_timeout\n        if requested_timeout is not None:\n            headers[\"TIMEOUT\"] = \"Second-{}\".format(requested_timeout)\n        response = requests.request(\n            'SUBSCRIBE',\n            self.service.base_url + self.service.event_subscription_url,\n            headers=headers)\n        response.raise_for_status()\n        timeout = response.headers['timeout']\n        # According to the spec, timeout can be \"infinite\" or \"second-123\"\n        # where 123 is a number of seconds.  Sonos uses \"Second-123\" (with a\n        # a capital letter)\n        if timeout.lower() == 'infinite':\n            self.timeout = None\n        else:\n            self.timeout = int(timeout.lstrip('Second-'))\n        self._timestamp = time.time()\n        self.is_subscribed = True\n        log.info(\n            \"Renewed subscription to %s, sid: %s\",\n            self.service.base_url + self.service.event_subscription_url,\n            self.sid)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the amount of time left until the subscription expires ( seconds", "response": "def time_left(self):\n        \"\"\"\n        `int`: The amount of time left until the subscription expires (seconds)\n\n        If the subscription is unsubscribed (or not yet subscribed),\n        `time_left` is 0.\n        \"\"\"\n        if self._timestamp is None:\n            return 0\n        else:\n            time_left = self.timeout - (time.time() - self._timestamp)\n            return time_left if time_left > 0 else 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uid(self):\n        # Since this does not change over time (?) check whether we already\n        # know the answer. If so, there is no need to go further\n        if self._uid is not None:\n            return self._uid\n        # if not, we have to get it from the zone topology, which\n        # is probably quicker than any alternative, since the zgt is probably\n        # cached. This will set self._uid for us for next time, so we won't\n        # have to do this again\n        self._parse_zone_group_state()\n        return self._uid", "response": "str - A unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef household_id(self):\n        # Since this does not change over time (?) check whether we already\n        # know the answer. If so, return the cached version\n        if self._household_id is None:\n            self._household_id = self.deviceProperties.GetHouseholdID()[\n                'CurrentHouseholdID']\n        return self._household_id", "response": "str - A unique identifier for all players in a household."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nam this zone a bridge?", "response": "def is_bridge(self):\n        \"\"\"bool: Is this zone a bridge?\"\"\"\n        # Since this does not change over time (?) check whether we already\n        # know the answer. If so, there is no need to go further\n        if self._is_bridge is not None:\n            return self._is_bridge\n        # if not, we have to get it from the zone topology. This will set\n        # self._is_bridge for us for next time, so we won't have to do this\n        # again\n        self._parse_zone_group_state()\n        return self._is_bridge"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_soundbar(self):\n        if self._is_soundbar is None:\n            if not self.speaker_info:\n                self.get_speaker_info()\n\n            model_name = self.speaker_info['model_name'].lower()\n            self._is_soundbar = any(model_name.endswith(s) for s in SOUNDBARS)\n\n        return self._is_soundbar", "response": "bool - True if this zone is a soundbar."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the speaker s cross fade state. False otherwise.", "response": "def cross_fade(self):\n        \"\"\"bool: The speaker's cross fade state.\n\n        True if enabled, False otherwise\n        \"\"\"\n\n        response = self.avTransport.GetCrossfadeMode([\n            ('InstanceID', 0),\n        ])\n        cross_fade_state = response['CrossfadeMode']\n        return True if int(cross_fade_state) else False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ramp_to_volume(self, volume, ramp_type='SLEEP_TIMER_RAMP_TYPE'):\n        response = self.renderingControl.RampToVolume([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n            ('RampType', ramp_type),\n            ('DesiredVolume', volume),\n            ('ResetVolumeAfter', False),\n            ('ProgramURI', '')\n        ])\n        return int(response['RampTime'])", "response": "Smoothly change the current volume."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef play_from_queue(self, index, start=True):\n        # Grab the speaker's information if we haven't already since we'll need\n        # it in the next step.\n        if not self.speaker_info:\n            self.get_speaker_info()\n\n        # first, set the queue itself as the source URI\n        uri = 'x-rincon-queue:{0}#0'.format(self.uid)\n        self.avTransport.SetAVTransportURI([\n            ('InstanceID', 0),\n            ('CurrentURI', uri),\n            ('CurrentURIMetaData', '')\n        ])\n\n        # second, set the track number with a seek command\n        self.avTransport.Seek([\n            ('InstanceID', 0),\n            ('Unit', 'TRACK_NR'),\n            ('Target', index + 1)\n        ])\n\n        # finally, just play what's set if needed\n        if start:\n            self.play()", "response": "Play a track from the queue by index."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplay a URI. Playing a URI will replace what was playing with the stream given by the URI. For some streams at least a title is required as metadata. This can be provided using the `meta` argument or the `title` argument. If the `title` argument is provided minimal metadata will be generated. If `meta` argument is provided the `title` argument is ignored. Args: uri (str): URI of the stream to be played. meta (str): The metadata to show in the player, DIDL format. title (str): The title to show in the player (if no meta). start (bool): If the URI that has been set should start playing. force_radio (bool): forces a uri to play as a radio stream. On a Sonos controller music is shown with one of the following display formats and controls: * Radio format: Shows the name of the radio station and other available data. No seek, next, previous, or voting capability. Examples: TuneIn, radioPup * Smart Radio: Shows track name, artist, and album. Limited seek, next and sometimes voting capability depending on the Music Service. Examples: Amazon Prime Stations, Pandora Radio Stations. * Track format: Shows track name, artist, and album the same as when playing from a queue. Full seek, next and previous capabilities. Examples: Spotify, Napster, Rhapsody. How it is displayed is determined by the URI prefix: `x-sonosapi-stream:`, `x-sonosapi-radio:`, `x-rincon-mp3radio:`, `hls-radio:` default to radio or smart radio format depending on the stream. Others default to track format: `x-file-cifs:`, `aac:`, `http:`, `https:`, `x-sonos-spotify:` (used by Spotify), `x-sonosapi-hls-static:` (Amazon Prime), `x-sonos-http:` (Google Play & Napster). Some URIs that default to track format could be radio streams, typically `http:`, `https:` or `aac:`. To force display and controls to Radio format set `force_radio=True` .. note:: Other URI prefixes exist but are less common. If you have information on these please add to this doc string. .. note:: A change in Sonos\u00ae (as of at least version 6.4.2) means that the devices no longer accepts ordinary `http:` and `https:` URIs for radio stations. This method has the option to replaces these prefixes with the one that Sonos\u00ae expects: `x-rincon-mp3radio:` by using the \"force_radio=True\" parameter. A few streams may fail if not forced to to Radio format.", "response": "def play_uri(self, uri='', meta='', title='', start=True,\n                 force_radio=False):\n        \"\"\"Play a URI.\n\n        Playing a URI will replace what was playing with the stream given by\n        the URI. For some streams at least a title is required as metadata.\n        This can be provided using the `meta` argument or the `title` argument.\n        If the `title` argument is provided minimal metadata will be generated.\n        If `meta` argument is provided the `title` argument is ignored.\n\n        Args:\n            uri (str): URI of the stream to be played.\n            meta (str): The metadata to show in the player, DIDL format.\n            title (str): The title to show in the player (if no meta).\n            start (bool): If the URI that has been set should start playing.\n            force_radio (bool): forces a uri to play as a radio stream.\n\n        On a Sonos controller music is shown with one of the following display\n        formats and controls:\n\n        * Radio format: Shows the name of the radio station and other available\n          data. No seek, next, previous, or voting capability.\n          Examples: TuneIn, radioPup\n        * Smart Radio:  Shows track name, artist, and album. Limited seek, next\n          and sometimes voting capability depending on the Music Service.\n          Examples: Amazon Prime Stations, Pandora Radio Stations.\n        * Track format: Shows track name, artist, and album the same as when\n          playing from a queue. Full seek, next and previous capabilities.\n          Examples: Spotify, Napster, Rhapsody.\n\n        How it is displayed is determined by the URI prefix:\n        `x-sonosapi-stream:`, `x-sonosapi-radio:`, `x-rincon-mp3radio:`,\n        `hls-radio:` default to radio or smart radio format depending on the\n        stream. Others default to track format: `x-file-cifs:`, `aac:`,\n        `http:`, `https:`, `x-sonos-spotify:` (used by Spotify),\n        `x-sonosapi-hls-static:` (Amazon Prime),\n        `x-sonos-http:` (Google Play & Napster).\n\n        Some URIs that default to track format could be radio streams,\n        typically `http:`, `https:` or `aac:`.\n        To force display and controls to Radio format set `force_radio=True`\n\n        .. note:: Other URI prefixes exist but are less common.\n           If you have information on these please add to this doc string.\n\n        .. note:: A change in Sonos\u00ae (as of at least version 6.4.2) means that\n           the devices no longer accepts ordinary `http:` and `https:` URIs for\n           radio stations. This method has the option to replaces these\n           prefixes with the one that Sonos\u00ae expects: `x-rincon-mp3radio:` by\n           using the \"force_radio=True\" parameter.\n           A few streams may fail if not forced to to Radio format.\n        \"\"\"\n        if meta == '' and title != '':\n            meta_template = '<DIDL-Lite xmlns:dc=\"http://purl.org/dc/elements'\\\n                '/1.1/\" xmlns:upnp=\"urn:schemas-upnp-org:metadata-1-0/upnp/\" '\\\n                'xmlns:r=\"urn:schemas-rinconnetworks-com:metadata-1-0/\" '\\\n                'xmlns=\"urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/\">'\\\n                '<item id=\"R:0/0/0\" parentID=\"R:0/0\" restricted=\"true\">'\\\n                '<dc:title>{title}</dc:title><upnp:class>'\\\n                'object.item.audioItem.audioBroadcast</upnp:class><desc '\\\n                'id=\"cdudn\" nameSpace=\"urn:schemas-rinconnetworks-com:'\\\n                'metadata-1-0/\">{service}</desc></item></DIDL-Lite>'\n            tunein_service = 'SA_RINCON65031_'\n            # Radio stations need to have at least a title to play\n            meta = meta_template.format(\n                title=escape(title),\n                service=tunein_service)\n\n        # change uri prefix to force radio style display and commands\n        if force_radio:\n            colon = uri.find(':')\n            if colon > 0:\n                uri = 'x-rincon-mp3radio{0}'.format(uri[colon:])\n\n        self.avTransport.SetAVTransportURI([\n            ('InstanceID', 0),\n            ('CurrentURI', uri),\n            ('CurrentURIMetaData', meta)\n        ])\n        # The track is enqueued, now play it if needed\n        if start:\n            return self.play()\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nseeks to a given timestamp in the current track specified in the the format of HH : MM : SS or H : MM : SS format.", "response": "def seek(self, timestamp):\n        \"\"\"Seek to a given timestamp in the current track, specified in the\n        format of HH:MM:SS or H:MM:SS.\n\n        Raises:\n            ValueError: if the given timestamp is invalid.\n        \"\"\"\n        if not re.match(r'^[0-9][0-9]?:[0-9][0-9]:[0-9][0-9]$', timestamp):\n            raise ValueError('invalid timestamp, use HH:MM:SS format')\n\n        self.avTransport.Seek([\n            ('InstanceID', 0),\n            ('Unit', 'REL_TIME'),\n            ('Target', timestamp)\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mute(self):\n\n        response = self.renderingControl.GetMute([\n            ('InstanceID', 0),\n            ('Channel', 'Master')\n        ])\n        mute_state = response['CurrentMute']\n        return True if int(mute_state) else False", "response": "bool - Returns True if the speaker s mute state False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the current volume of the speaker.", "response": "def volume(self):\n        \"\"\"int: The speaker's volume.\n\n        An integer between 0 and 100.\n        \"\"\"\n\n        response = self.renderingControl.GetVolume([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n        ])\n        volume = response['CurrentVolume']\n        return int(volume)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef volume(self, volume):\n        volume = int(volume)\n        volume = max(0, min(volume, 100))  # Coerce in range\n        self.renderingControl.SetVolume([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n            ('DesiredVolume', volume)\n        ])", "response": "Set the speaker s volume."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bass(self):\n\n        response = self.renderingControl.GetBass([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n        ])\n        bass = response['CurrentBass']\n        return int(bass)", "response": "Return the speaker s bass EQ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bass(self, bass):\n        bass = int(bass)\n        bass = max(-10, min(bass, 10))  # Coerce in range\n        self.renderingControl.SetBass([\n            ('InstanceID', 0),\n            ('DesiredBass', bass)\n        ])", "response": "Set the speaker s bass."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef treble(self):\n\n        response = self.renderingControl.GetTreble([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n        ])\n        treble = response['CurrentTreble']\n        return int(treble)", "response": "Returns the speaker s treble EQ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the speaker s treble.", "response": "def treble(self, treble):\n        \"\"\"Set the speaker's treble.\"\"\"\n        treble = int(treble)\n        treble = max(-10, min(treble, 10))  # Coerce in range\n        self.renderingControl.SetTreble([\n            ('InstanceID', 0),\n            ('DesiredTreble', treble)\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loudness(self):\n        response = self.renderingControl.GetLoudness([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n        ])\n        loudness = response[\"CurrentLoudness\"]\n        return True if int(loudness) else False", "response": "True if on False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef night_mode(self, night_mode):\n        if not self.is_soundbar:\n            message = 'This device does not support night mode'\n            raise NotSupportedException(message)\n\n        self.renderingControl.SetEQ([\n            ('InstanceID', 0),\n            ('EQType', 'NightMode'),\n            ('DesiredValue', int(night_mode))\n        ])", "response": "Switch on or off the speaker s night mode."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the Sonos speaker s dialog mode.", "response": "def dialog_mode(self):\n        \"\"\"bool: Get the Sonos speaker's dialog mode.\n\n        True if on, False if off, None if not supported.\n        \"\"\"\n        if not self.is_soundbar:\n            return None\n\n        response = self.renderingControl.GetEQ([\n            ('InstanceID', 0),\n            ('EQType', 'DialogLevel')\n        ])\n        return bool(int(response['CurrentValue']))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nswitching on or off the speaker s dialog mode.", "response": "def dialog_mode(self, dialog_mode):\n        \"\"\"Switch on/off the speaker's dialog mode.\n\n        :param dialog_mode: Enable or disable dialog mode\n        :type dialog_mode: bool\n        :raises NotSupportedException: If the device does not support\n        dialog mode.\n        \"\"\"\n        if not self.is_soundbar:\n            message = 'This device does not support dialog mode'\n            raise NotSupportedException(message)\n\n        self.renderingControl.SetEQ([\n            ('InstanceID', 0),\n            ('EQType', 'DialogLevel'),\n            ('DesiredValue', int(dialog_mode))\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the Zone Group State XML file.", "response": "def _parse_zone_group_state(self):\n        \"\"\"The Zone Group State contains a lot of useful information.\n\n        Retrieve and parse it, and populate the relevant properties.\n        \"\"\"\n\n# zoneGroupTopology.GetZoneGroupState()['ZoneGroupState'] returns XML like\n# this:\n#\n# <ZoneGroups>\n#   <ZoneGroup Coordinator=\"RINCON_000XXX1400\" ID=\"RINCON_000XXXX1400:0\">\n#     <ZoneGroupMember\n#         BootSeq=\"33\"\n#         Configuration=\"1\"\n#         Icon=\"x-rincon-roomicon:zoneextender\"\n#         Invisible=\"1\"\n#         IsZoneBridge=\"1\"\n#         Location=\"http://192.168.1.100:1400/xml/device_description.xml\"\n#         MinCompatibleVersion=\"22.0-00000\"\n#         SoftwareVersion=\"24.1-74200\"\n#         UUID=\"RINCON_000ZZZ1400\"\n#         ZoneName=\"BRIDGE\"/>\n#   </ZoneGroup>\n#   <ZoneGroup Coordinator=\"RINCON_000XXX1400\" ID=\"RINCON_000XXX1400:46\">\n#     <ZoneGroupMember\n#         BootSeq=\"44\"\n#         Configuration=\"1\"\n#         Icon=\"x-rincon-roomicon:living\"\n#         Location=\"http://192.168.1.101:1400/xml/device_description.xml\"\n#         MinCompatibleVersion=\"22.0-00000\"\n#         SoftwareVersion=\"24.1-74200\"\n#         UUID=\"RINCON_000XXX1400\"\n#         ZoneName=\"Living Room\"/>\n#     <ZoneGroupMember\n#         BootSeq=\"52\"\n#         Configuration=\"1\"\n#         Icon=\"x-rincon-roomicon:kitchen\"\n#         Location=\"http://192.168.1.102:1400/xml/device_description.xml\"\n#         MinCompatibleVersion=\"22.0-00000\"\n#         SoftwareVersion=\"24.1-74200\"\n#         UUID=\"RINCON_000YYY1400\"\n#         ZoneName=\"Kitchen\"/>\n#   </ZoneGroup>\n# </ZoneGroups>\n#\n\n        def parse_zone_group_member(member_element):\n            \"\"\"Parse a ZoneGroupMember or Satellite element from Zone Group\n            State, create a SoCo instance for the member, set basic attributes\n            and return it.\"\"\"\n            # Create a SoCo instance for each member. Because SoCo\n            # instances are singletons, this is cheap if they have already\n            # been created, and useful if they haven't. We can then\n            # update various properties for that instance.\n            member_attribs = member_element.attrib\n            ip_addr = member_attribs['Location'].\\\n                split('//')[1].split(':')[0]\n            zone = config.SOCO_CLASS(ip_addr)\n            # uid doesn't change, but it's not harmful to (re)set it, in case\n            # the zone is as yet unseen.\n            zone._uid = member_attribs['UUID']\n            zone._player_name = member_attribs['ZoneName']\n            # add the zone to the set of all members, and to the set\n            # of visible members if appropriate\n            is_visible = False if member_attribs.get(\n                'Invisible') == '1' else True\n            if is_visible:\n                self._visible_zones.add(zone)\n            self._all_zones.add(zone)\n            return zone\n\n        # This is called quite frequently, so it is worth optimising it.\n        # Maintain a private cache. If the zgt has not changed, there is no\n        # need to repeat all the XML parsing. In addition, switch on network\n        # caching for a short interval (5 secs).\n        zgs = self.zoneGroupTopology.GetZoneGroupState(\n            cache_timeout=5)['ZoneGroupState']\n        if zgs == self._zgs_cache:\n            return\n        self._zgs_cache = zgs\n        tree = XML.fromstring(zgs.encode('utf-8'))\n        # Empty the set of all zone_groups\n        self._groups.clear()\n        # and the set of all members\n        self._all_zones.clear()\n        self._visible_zones.clear()\n        # Loop over each ZoneGroup Element\n        for group_element in tree.findall('ZoneGroup'):\n            coordinator_uid = group_element.attrib['Coordinator']\n            group_uid = group_element.attrib['ID']\n            group_coordinator = None\n            members = set()\n            for member_element in group_element.findall('ZoneGroupMember'):\n                zone = parse_zone_group_member(member_element)\n                # Perform extra processing relevant to direct zone group\n                # members\n                #\n                # If this element has the same UUID as the coordinator, it is\n                # the coordinator\n                if zone._uid == coordinator_uid:\n                    group_coordinator = zone\n                    zone._is_coordinator = True\n                else:\n                    zone._is_coordinator = False\n                # is_bridge doesn't change, but it does no real harm to\n                # set/reset it here, just in case the zone has not been seen\n                # before\n                zone._is_bridge = True if member_element.attrib.get(\n                    'IsZoneBridge') == '1' else False\n                # add the zone to the members for this group\n                members.add(zone)\n                # Loop over Satellite elements if present, and process as for\n                # ZoneGroup elements\n                for satellite_element in member_element.findall('Satellite'):\n                    zone = parse_zone_group_member(satellite_element)\n                    # Assume a satellite can't be a bridge or coordinator, so\n                    # no need to check.\n                    #\n                    # Add the zone to the members for this group.\n                    members.add(zone)\n                # Now create a ZoneGroup with this info and add it to the list\n                # of groups\n            self._groups.add(ZoneGroup(group_uid, group_coordinator, members))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef partymode(self):\n        # Tell every other visible zone to join this one\n        # pylint: disable = expression-not-assigned\n        [zone.join(self) for zone in self.visible_zones if zone is not self]", "response": "A. k. a Party\n        Mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef switch_to_line_in(self, source=None):\n        if source:\n            uid = source.uid\n        else:\n            uid = self.uid\n\n        self.avTransport.SetAVTransportURI([\n            ('InstanceID', 0),\n            ('CurrentURI', 'x-rincon-stream:{0}'.format(uid)),\n            ('CurrentURIMetaData', '')\n        ])", "response": "Switch the speaker s input to line - in."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nam the speaker playing radio?", "response": "def is_playing_radio(self):\n        \"\"\"bool: Is the speaker playing radio?\"\"\"\n        response = self.avTransport.GetPositionInfo([\n            ('InstanceID', 0),\n            ('Channel', 'Master')\n        ])\n        track_uri = response['TrackURI']\n        return re.match(r'^x-rincon-mp3radio:', track_uri) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the speaker is playing line - in.", "response": "def is_playing_line_in(self):\n        \"\"\"bool: Is the speaker playing line-in?\"\"\"\n        response = self.avTransport.GetPositionInfo([\n            ('InstanceID', 0),\n            ('Channel', 'Master')\n        ])\n        track_uri = response['TrackURI']\n        return re.match(r'^x-rincon-stream:', track_uri) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbeing the playbar speaker input from TV?", "response": "def is_playing_tv(self):\n        \"\"\"bool: Is the playbar speaker input from TV?\"\"\"\n        response = self.avTransport.GetPositionInfo([\n            ('InstanceID', 0),\n            ('Channel', 'Master')\n        ])\n        track_uri = response['TrackURI']\n        return re.match(r'^x-sonos-htastream:', track_uri) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status_light(self):\n        result = self.deviceProperties.GetLEDState()\n        LEDState = result[\"CurrentLEDState\"]  # pylint: disable=invalid-name\n        return True if LEDState == \"On\" else False", "response": "bool - True if the white Sonos status light between the mute button and the volume up button on the speaker False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets information about the currently playing track.", "response": "def get_current_track_info(self):\n        \"\"\"Get information about the currently playing track.\n\n        Returns:\n            dict: A dictionary containing information about the currently\n            playing track: playlist_position, duration, title, artist, album,\n            position and an album_art link.\n\n        If we're unable to return data for a field, we'll return an empty\n        string. This can happen for all kinds of reasons so be sure to check\n        values. For example, a track may not have complete metadata and be\n        missing an album name. In this case track['album'] will be an empty\n        string.\n\n        .. note:: Calling this method on a slave in a group will not\n            return the track the group is playing, but the last track\n            this speaker was playing.\n\n        \"\"\"\n        response = self.avTransport.GetPositionInfo([\n            ('InstanceID', 0),\n            ('Channel', 'Master')\n        ])\n\n        track = {'title': '', 'artist': '', 'album': '', 'album_art': '',\n                 'position': ''}\n        track['playlist_position'] = response['Track']\n        track['duration'] = response['TrackDuration']\n        track['uri'] = response['TrackURI']\n        track['position'] = response['RelTime']\n\n        metadata = response['TrackMetaData']\n        # Store the entire Metadata entry in the track, this can then be\n        # used if needed by the client to restart a given URI\n        track['metadata'] = metadata\n        # Duration seems to be '0:00:00' when listening to radio\n        if metadata != '' and track['duration'] == '0:00:00':\n            metadata = XML.fromstring(really_utf8(metadata))\n            # Try parse trackinfo\n            trackinfo = metadata.findtext('.//{urn:schemas-rinconnetworks-com:'\n                                          'metadata-1-0/}streamContent') or ''\n            index = trackinfo.find(' - ')\n\n            if index > -1:\n                track['artist'] = trackinfo[:index]\n                track['title'] = trackinfo[index + 3:]\n            else:\n                # Might find some kind of title anyway in metadata\n                track['title'] = metadata.findtext('.//{http://purl.org/dc/'\n                                                   'elements/1.1/}title')\n                if not track['title']:\n                    track['title'] = trackinfo\n\n        # If the speaker is playing from the line-in source, querying for track\n        # metadata will return \"NOT_IMPLEMENTED\".\n        elif metadata not in ('', 'NOT_IMPLEMENTED', None):\n            # Track metadata is returned in DIDL-Lite format\n            metadata = XML.fromstring(really_utf8(metadata))\n            md_title = metadata.findtext(\n                './/{http://purl.org/dc/elements/1.1/}title')\n            md_artist = metadata.findtext(\n                './/{http://purl.org/dc/elements/1.1/}creator')\n            md_album = metadata.findtext(\n                './/{urn:schemas-upnp-org:metadata-1-0/upnp/}album')\n\n            track['title'] = \"\"\n            if md_title:\n                track['title'] = md_title\n            track['artist'] = \"\"\n            if md_artist:\n                track['artist'] = md_artist\n            track['album'] = \"\"\n            if md_album:\n                track['album'] = md_album\n\n            album_art_url = metadata.findtext(\n                './/{urn:schemas-upnp-org:metadata-1-0/upnp/}albumArtURI')\n            if album_art_url is not None:\n                track['album_art'] = \\\n                    self.music_library.build_album_art_full_uri(album_art_url)\n\n        return track"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_speaker_info(self, refresh=False, timeout=None):\n        if self.speaker_info and refresh is False:\n            return self.speaker_info\n        else:\n            response = requests.get('http://' + self.ip_address +\n                                    ':1400/xml/device_description.xml',\n                                    timeout=timeout)\n            dom = XML.fromstring(response.content)\n\n        device = dom.find('{urn:schemas-upnp-org:device-1-0}device')\n        if device is not None:\n            self.speaker_info['zone_name'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}roomName')\n\n            # no zone icon in device_description.xml -> player icon\n            self.speaker_info['player_icon'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}iconList/'\n                '{urn:schemas-upnp-org:device-1-0}icon/'\n                '{urn:schemas-upnp-org:device-1-0}url'\n            )\n\n            self.speaker_info['uid'] = self.uid\n            self.speaker_info['serial_number'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}serialNum')\n            self.speaker_info['software_version'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}softwareVersion')\n            self.speaker_info['hardware_version'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}hardwareVersion')\n            self.speaker_info['model_number'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}modelNumber')\n            self.speaker_info['model_name'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}modelName')\n            self.speaker_info['display_version'] = device.findtext(\n                '{urn:schemas-upnp-org:device-1-0}displayVersion')\n\n            # no mac address - extract from serial number\n            mac = self.speaker_info['serial_number'].split(':')[0]\n            self.speaker_info['mac_address'] = mac\n\n            return self.speaker_info\n        return None", "response": "Get information about the Sonos speaker."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current playback state.", "response": "def get_current_transport_info(self):\n        \"\"\"Get the current playback state.\n\n        Returns:\n            dict: The following information about the\n            speaker's playing state:\n\n            *   current_transport_state (``PLAYING``, ``TRANSITIONING``,\n                ``PAUSED_PLAYBACK``, ``STOPPED``)\n            *   current_transport_status (OK, ?)\n            *   current_speed(1, ?)\n\n        This allows us to know if speaker is playing or not. Don't know other\n        states of CurrentTransportStatus and CurrentSpeed.\n        \"\"\"\n        response = self.avTransport.GetTransportInfo([\n            ('InstanceID', 0),\n        ])\n\n        playstate = {\n            'current_transport_status': '',\n            'current_transport_state': '',\n            'current_transport_speed': ''\n        }\n\n        playstate['current_transport_state'] = \\\n            response['CurrentTransportState']\n        playstate['current_transport_status'] = \\\n            response['CurrentTransportStatus']\n        playstate['current_transport_speed'] = response['CurrentSpeed']\n\n        return playstate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget information about the queue.", "response": "def get_queue(self, start=0, max_items=100, full_album_art_uri=False):\n        \"\"\"Get information about the queue.\n\n        :param start: Starting number of returned matches\n        :param max_items: Maximum number of returned matches\n        :param full_album_art_uri: If the album art URI should include the\n            IP address\n        :returns: A :py:class:`~.soco.data_structures.Queue` object\n\n        This method is heavly based on Sam Soffes (aka soffes) ruby\n        implementation\n        \"\"\"\n        queue = []\n        response = self.contentDirectory.Browse([\n            ('ObjectID', 'Q:0'),\n            ('BrowseFlag', 'BrowseDirectChildren'),\n            ('Filter', '*'),\n            ('StartingIndex', start),\n            ('RequestedCount', max_items),\n            ('SortCriteria', '')\n        ])\n        result = response['Result']\n\n        metadata = {}\n        for tag in ['NumberReturned', 'TotalMatches', 'UpdateID']:\n            metadata[camel_to_underscore(tag)] = int(response[tag])\n\n        # I'm not sure this necessary (any more). Even with an empty queue,\n        # there is still a result object. This shoud be investigated.\n        if not result:\n            # pylint: disable=star-args\n            return Queue(queue, **metadata)\n\n        items = from_didl_string(result)\n        for item in items:\n            # Check if the album art URI should be fully qualified\n            if full_album_art_uri:\n                self.music_library._update_album_art_to_full_uri(item)\n            queue.append(item)\n\n        # pylint: disable=star-args\n        return Queue(queue, **metadata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the size of the queue.", "response": "def queue_size(self):\n        \"\"\"int: Size of the queue.\"\"\"\n        response = self.contentDirectory.Browse([\n            ('ObjectID', 'Q:0'),\n            ('BrowseFlag', 'BrowseMetadata'),\n            ('Filter', '*'),\n            ('StartingIndex', 0),\n            ('RequestedCount', 1),\n            ('SortCriteria', '')\n        ])\n        dom = XML.fromstring(really_utf8(response['Result']))\n\n        queue_size = None\n        container = dom.find(\n            '{urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/}container')\n        if container is not None:\n            child_count = container.get('childCount')\n            if child_count is not None:\n                queue_size = int(child_count)\n\n        return queue_size"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_uri_to_queue(self, uri, position=0, as_next=False):\n        # FIXME: The res.protocol_info should probably represent the mime type\n        # etc of the uri. But this seems OK.\n        res = [DidlResource(uri=uri, protocol_info=\"x-rincon-playlist:*:*:*\")]\n        item = DidlObject(resources=res, title='', parent_id='', item_id='')\n        return self.add_to_queue(item, position, as_next)", "response": "Add the URI to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new item to the queue.", "response": "def add_to_queue(self, queueable_item, position=0, as_next=False):\n        \"\"\"Add a queueable item to the queue.\n\n        Args:\n            queueable_item (DidlObject or MusicServiceItem): The item to be\n                added to the queue\n            position (int): The index (1-based) at which the URI should be\n                added. Default is 0 (add URI at the end of the queue).\n            as_next (bool): Whether this URI should be played as the next\n                track in shuffle mode. This only works if `play_mode=SHUFFLE`.\n\n        Returns:\n            int: The index of the new item in the queue.\n        \"\"\"\n        metadata = to_didl_string(queueable_item)\n        response = self.avTransport.AddURIToQueue([\n            ('InstanceID', 0),\n            ('EnqueuedURI', queueable_item.resources[0].uri),\n            ('EnqueuedURIMetaData', metadata),\n            ('DesiredFirstTrackNumberEnqueued', position),\n            ('EnqueueAsNext', int(as_next))\n        ])\n        qnumber = response['FirstTrackNumberEnqueued']\n        return int(qnumber)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_multiple_to_queue(self, items, container=None):\n        if container is not None:\n            container_uri = container.resources[0].uri\n            container_metadata = to_didl_string(container)\n        else:\n            container_uri = ''  # Sonos seems to accept this as well\n            container_metadata = ''  # pylint: disable=redefined-variable-type\n\n        chunk_size = 16  # With each request, we can only add 16 items\n        item_list = list(items)  # List for slicing\n        for index in range(0, len(item_list), chunk_size):\n            chunk = item_list[index:index + chunk_size]\n            uris = ' '.join([item.resources[0].uri for item in chunk])\n            uri_metadata = ' '.join([to_didl_string(item) for item in chunk])\n            self.avTransport.AddMultipleURIsToQueue([\n                ('InstanceID', 0),\n                ('UpdateID', 0),\n                ('NumberOfURIs', len(chunk)),\n                ('EnqueuedURIs', uris),\n                ('EnqueuedURIsMetaData', uri_metadata),\n                ('ContainerURI', container_uri),\n                ('ContainerMetaData', container_metadata),\n                ('DesiredFirstTrackNumberEnqueued', 0),\n                ('EnqueueAsNext', 0)\n            ])", "response": "Adds a sequence of items to the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a track from the queue by index.", "response": "def remove_from_queue(self, index):\n        \"\"\"Remove a track from the queue by index. The index number is\n        required as an argument, where the first index is 0.\n\n        Args:\n            index (int): The (0-based) index of the track to remove\n        \"\"\"\n        # TODO: what do these parameters actually do?\n        updid = '0'\n        objid = 'Q:0/' + str(index + 1)\n        self.avTransport.RemoveTrackFromQueue([\n            ('InstanceID', 0),\n            ('ObjectID', objid),\n            ('UpdateID', updid),\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the list of favorite radio shows from Sonos Radio app.", "response": "def get_favorite_radio_shows(self, start=0, max_items=100):\n        \"\"\"Get favorite radio shows from Sonos' Radio app.\n\n        Returns:\n            dict: A dictionary containing the total number of favorites, the\n            number of favorites returned, and the actual list of favorite radio\n            shows, represented as a dictionary with `title` and `uri` keys.\n\n        Depending on what you're building, you'll want to check to see if the\n        total number of favorites is greater than the amount you\n        requested (`max_items`), if it is, use `start` to page through and\n        get the entire list of favorites.\n        \"\"\"\n        message = 'The output type of this method will probably change in '\\\n                  'the future to use SoCo data structures'\n        warnings.warn(message, stacklevel=2)\n        return self.__get_favorites(RADIO_SHOWS, start, max_items)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets favorite radio stations from Sonos Radio app.", "response": "def get_favorite_radio_stations(self, start=0, max_items=100):\n        \"\"\"Get favorite radio stations from Sonos' Radio app.\n\n        See :meth:`get_favorite_radio_shows` for return type and remarks.\n        \"\"\"\n        message = 'The output type of this method will probably change in '\\\n                  'the future to use SoCo data structures'\n        warnings.warn(message, stacklevel=2)\n        return self.__get_favorites(RADIO_STATIONS, start, max_items)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_sonos_favorites(self, start=0, max_items=100):\n        message = 'The output type of this method will probably change in '\\\n                  'the future to use SoCo data structures'\n        warnings.warn(message, stacklevel=2)\n        return self.__get_favorites(SONOS_FAVORITES, start, max_items)", "response": "Get a list of Sonos favorites."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of dictionaries containing the radio favorites of the specified type.", "response": "def __get_favorites(self, favorite_type, start=0, max_items=100):\n        \"\"\" Helper method for `get_favorite_radio_*` methods.\n\n        Args:\n            favorite_type (str): Specify either `RADIO_STATIONS` or\n                `RADIO_SHOWS`.\n            start (int): Which number to start the retrieval from. Used for\n                paging.\n            max_items (int): The total number of results to return.\n\n        \"\"\"\n        if favorite_type not in (RADIO_SHOWS, RADIO_STATIONS):\n            favorite_type = SONOS_FAVORITES\n\n        response = self.contentDirectory.Browse([\n            ('ObjectID',\n             'FV:2' if favorite_type is SONOS_FAVORITES\n             else 'R:0/{0}'.format(favorite_type)),\n            ('BrowseFlag', 'BrowseDirectChildren'),\n            ('Filter', '*'),\n            ('StartingIndex', start),\n            ('RequestedCount', max_items),\n            ('SortCriteria', '')\n        ])\n        result = {}\n        favorites = []\n        results_xml = response['Result']\n\n        if results_xml != '':\n            # Favorites are returned in DIDL-Lite format\n            metadata = XML.fromstring(really_utf8(results_xml))\n\n            for item in metadata.findall(\n                    '{urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/}container'\n                    if favorite_type == RADIO_SHOWS else\n                    '{urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/}item'):\n                favorite = {}\n                favorite['title'] = item.findtext(\n                    '{http://purl.org/dc/elements/1.1/}title')\n                favorite['uri'] = item.findtext(\n                    '{urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/}res')\n                if favorite_type == SONOS_FAVORITES:\n                    favorite['meta'] = item.findtext(\n                        '{urn:schemas-rinconnetworks-com:metadata-1-0/}resMD')\n                favorites.append(favorite)\n\n        result['total'] = response['TotalMatches']\n        result['returned'] = len(favorites)\n        result['favorites'] = favorites\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_sonos_playlist(self, title):\n        response = self.avTransport.CreateSavedQueue([\n            ('InstanceID', 0),\n            ('Title', title),\n            ('EnqueuedURI', ''),\n            ('EnqueuedURIMetaData', ''),\n        ])\n\n        item_id = response['AssignedObjectID']\n        obj_id = item_id.split(':', 2)[1]\n        uri = \"file:///jffs/settings/savedqueues.rsq#{0}\".format(obj_id)\n\n        res = [DidlResource(uri=uri, protocol_info=\"x-rincon-playlist:*:*:*\")]\n        return DidlPlaylistContainer(\n            resources=res, title=title, parent_id='SQ:', item_id=item_id)", "response": "Create a new empty Sonos playlist."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Sonos playlist from the current queue.", "response": "def create_sonos_playlist_from_queue(self, title):\n        \"\"\"Create a new Sonos playlist from the current queue.\n\n        Args:\n            title: Name of the playlist\n\n        :rtype: :py:class:`~.soco.data_structures.DidlPlaylistContainer`\n        \"\"\"\n        # Note: probably same as Queue service method SaveAsSonosPlaylist\n        # but this has not been tested.  This method is what the\n        # controller uses.\n        response = self.avTransport.SaveQueue([\n            ('InstanceID', 0),\n            ('Title', title),\n            ('ObjectID', '')\n        ])\n        item_id = response['AssignedObjectID']\n        obj_id = item_id.split(':', 2)[1]\n        uri = \"file:///jffs/settings/savedqueues.rsq#{0}\".format(obj_id)\n        res = [DidlResource(uri=uri, protocol_info=\"x-rincon-playlist:*:*:*\")]\n        return DidlPlaylistContainer(\n            resources=res, title=title, parent_id='SQ:', item_id=item_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a Sonos playlist.", "response": "def remove_sonos_playlist(self, sonos_playlist):\n        \"\"\"Remove a Sonos playlist.\n\n        Args:\n            sonos_playlist (DidlPlaylistContainer): Sonos playlist to remove\n                or the item_id (str).\n\n        Returns:\n            bool: True if succesful, False otherwise\n\n        Raises:\n            SoCoUPnPException: If sonos_playlist does not point to a valid\n                object.\n\n        \"\"\"\n        object_id = getattr(sonos_playlist, 'item_id', sonos_playlist)\n        return self.contentDirectory.DestroyObject([('ObjectID', object_id)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_item_to_sonos_playlist(self, queueable_item, sonos_playlist):\n        # Get the update_id for the playlist\n        response, _ = self.music_library._music_lib_search(\n            sonos_playlist.item_id, 0, 1)\n        update_id = response['UpdateID']\n\n        # Form the metadata for queueable_item\n        metadata = to_didl_string(queueable_item)\n\n        # Make the request\n        self.avTransport.AddURIToSavedQueue([\n            ('InstanceID', 0),\n            ('UpdateID', update_id),\n            ('ObjectID', sonos_playlist.item_id),\n            ('EnqueuedURI', queueable_item.resources[0].uri),\n            ('EnqueuedURIMetaData', metadata),\n            # 2 ** 32 - 1 = 4294967295, this field has always this value. Most\n            # likely, playlist positions are represented as a 32 bit uint and\n            # this is therefore the largest index possible. Asking to add at\n            # this index therefore probably amounts to adding it \"at the end\"\n            ('AddAtIndex', 4294967295)\n        ])", "response": "Adds a queueable item to a Sonos playlist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve remaining sleep time if any sleep timer currently set returns None", "response": "def get_sleep_timer(self):\n        \"\"\"Retrieves remaining sleep time, if any\n\n        Returns:\n            int or NoneType: Number of seconds left in timer. If there is no\n                sleep timer currently set it will return None.\n        \"\"\"\n        resp = self.avTransport.GetRemainingSleepTimerDuration([\n            ('InstanceID', 0),\n        ])\n        if resp['RemainingSleepTimerDuration']:\n            times = resp['RemainingSleepTimerDuration'].split(':')\n            return (int(times[0]) * 3600 +\n                    int(times[1]) * 60 +\n                    int(times[2]))\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reorder_sonos_playlist(self, sonos_playlist, tracks, new_pos,\n                               update_id=0):\n        \"\"\"Reorder and/or Remove tracks in a Sonos playlist.\n\n        The underlying call is quite complex as it can both move a track\n        within the list or delete a track from the playlist.  All of this\n        depends on what tracks and new_pos specify.\n\n        If a list is specified for tracks, then a list must be used for\n        new_pos. Each list element is a discrete modification and the next\n        list operation must anticipate the new state of the playlist.\n\n        If a comma formatted string to tracks is specified, then use\n        a similiar string to specify new_pos. Those operations should be\n        ordered from the end of the list to the beginning\n\n        See the helper methods\n        :py:meth:`clear_sonos_playlist`, :py:meth:`move_in_sonos_playlist`,\n        :py:meth:`remove_from_sonos_playlist` for simplified usage.\n\n        update_id - If you have a series of operations, tracking the update_id\n        and setting it, will save a lookup operation.\n\n        Examples:\n          To reorder the first two tracks::\n\n            # sonos_playlist specified by the DidlPlaylistContainer object\n            sonos_playlist = device.get_sonos_playlists()[0]\n            device.reorder_sonos_playlist(sonos_playlist,\n                                          tracks=[0, ], new_pos=[1, ])\n            # OR specified by the item_id\n            device.reorder_sonos_playlist('SQ:0', tracks=[0, ], new_pos=[1, ])\n\n          To delete the second track::\n\n            # tracks/new_pos are a list of int\n            device.reorder_sonos_playlist(sonos_playlist,\n                                          tracks=[1, ], new_pos=[None, ])\n            # OR tracks/new_pos are a list of int-like\n            device.reorder_sonos_playlist(sonos_playlist,\n                                          tracks=['1', ], new_pos=['', ])\n            # OR tracks/new_pos are strings - no transform is done\n            device.reorder_sonos_playlist(sonos_playlist, tracks='1',\n                                          new_pos='')\n\n          To reverse the order of a playlist with 4 items::\n\n            device.reorder_sonos_playlist(sonos_playlist, tracks='3,2,1,0',\n                                          new_pos='0,1,2,3')\n\n        Args:\n            sonos_playlist\n                (:py:class:`~.soco.data_structures.DidlPlaylistContainer`): The\n                Sonos playlist object or the item_id (str) of the Sonos\n                playlist.\n            tracks: (list): list of track indices(int) to reorder. May also be\n                a list of int like things. i.e. ``['0', '1',]`` OR it may be a\n                str of comma separated int like things. ``\"0,1\"``.  Tracks are\n                **0**-based. Meaning the first track is track 0, just like\n                indexing into a Python list.\n            new_pos (list): list of new positions (int|None)\n                corresponding to track_list. MUST be the same type as\n                ``tracks``. **0**-based, see tracks above. ``None`` is the\n                indicator to remove the track. If using a list of strings,\n                then a remove is indicated by an empty string.\n            update_id (int): operation id (default: 0) If set to 0, a lookup\n                is done to find the correct value.\n\n        Returns:\n            dict: Which contains 3 elements: change, length and update_id.\n                Change in size between original playlist and the resulting\n                playlist, the length of resulting playlist, and the new\n                update_id.\n\n        Raises:\n            SoCoUPnPException: If playlist does not exist or if your tracks\n                and/or new_pos arguments are invalid.\n        \"\"\"\n        # allow either a string 'SQ:10' or an object with item_id attribute.\n        object_id = getattr(sonos_playlist, 'item_id', sonos_playlist)\n\n        if isinstance(tracks, UnicodeType):\n            track_list = [tracks, ]\n            position_list = [new_pos, ]\n        elif isinstance(tracks, int):\n            track_list = [tracks, ]\n            if new_pos is None:\n                new_pos = ''\n            position_list = [new_pos, ]\n        else:\n            track_list = [str(x) for x in tracks]\n            position_list = [str(x) if x is not None else '' for x in new_pos]\n        # track_list = ','.join(track_list)\n        # position_list = ','.join(position_list)\n        if update_id == 0:  # retrieve the update id for the object\n            response, _ = self.music_library._music_lib_search(object_id, 0, 1)\n            update_id = response['UpdateID']\n        change = 0\n\n        for track, position in zip(track_list, position_list):\n            if track == position:   # there is no move, a no-op\n                continue\n            response = self.avTransport.ReorderTracksInSavedQueue([\n                (\"InstanceID\", 0),\n                (\"ObjectID\", object_id),\n                (\"UpdateID\", update_id),\n                (\"TrackList\", track),\n                (\"NewPositionList\", position),\n            ])\n            change += int(response['QueueLengthChange'])\n            update_id = int(response['NewUpdateID'])\n        length = int(response['NewQueueLength'])\n        response = {'change': change,\n                    'update_id': update_id,\n                    'length': length}\n        return response", "response": "Reorder and or remove tracks in a Sonos playlist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclearing all tracks from a Sonos playlist.", "response": "def clear_sonos_playlist(self, sonos_playlist, update_id=0):\n        \"\"\"Clear all tracks from a Sonos playlist.\n        This is a convenience method for :py:meth:`reorder_sonos_playlist`.\n\n        Example::\n\n            device.clear_sonos_playlist(sonos_playlist)\n\n        Args:\n            sonos_playlist\n                (:py:class:`~.soco.data_structures.DidlPlaylistContainer`):\n                Sonos playlist object or the item_id (str) of the Sonos\n                playlist.\n            update_id (int): Optional update counter for the object. If left\n                at the default of 0, it will be looked up.\n\n        Returns:\n            dict: See :py:meth:`reorder_sonos_playlist`\n\n        Raises:\n            ValueError: If sonos_playlist specified by string and is not found.\n            SoCoUPnPException: See :py:meth:`reorder_sonos_playlist`\n        \"\"\"\n        if not isinstance(sonos_playlist, DidlPlaylistContainer):\n            sonos_playlist = self.get_sonos_playlist_by_attr('item_id',\n                                                             sonos_playlist)\n        count = self.music_library.browse(ml_item=sonos_playlist).total_matches\n        tracks = ','.join([str(x) for x in range(count)])\n        if tracks:\n            return self.reorder_sonos_playlist(sonos_playlist, tracks=tracks,\n                                               new_pos='', update_id=update_id)\n        else:\n            return {'change': 0, 'update_id': update_id, 'length': count}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_in_sonos_playlist(self, sonos_playlist, track, new_pos,\n                               update_id=0):\n        \"\"\"Move a track to a new position within a Sonos Playlist.\n        This is a convenience method for :py:meth:`reorder_sonos_playlist`.\n\n        Example::\n\n            device.move_in_sonos_playlist(sonos_playlist, track=0, new_pos=1)\n\n        Args:\n            sonos_playlist\n                (:py:class:`~.soco.data_structures.DidlPlaylistContainer`):\n                Sonos playlist object or the item_id (str) of the Sonos\n                playlist.\n            track (int): **0**-based position of the track to move. The first\n                track is track 0, just like indexing into a Python list.\n            new_pos (int): **0**-based location to move the track.\n            update_id (int): Optional update counter for the object. If left\n                at the default of 0, it will be looked up.\n\n        Returns:\n            dict: See :py:meth:`reorder_sonos_playlist`\n\n        Raises:\n            SoCoUPnPException: See :py:meth:`reorder_sonos_playlist`\n        \"\"\"\n        return self.reorder_sonos_playlist(sonos_playlist, int(track),\n                                           int(new_pos), update_id)", "response": "Move a track in a Sonos playlist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a track from a Sonos playlist.", "response": "def remove_from_sonos_playlist(self, sonos_playlist, track, update_id=0):\n        \"\"\"Remove a track from a Sonos Playlist.\n        This is a convenience method for :py:meth:`reorder_sonos_playlist`.\n\n        Example::\n\n            device.remove_from_sonos_playlist(sonos_playlist, track=0)\n\n        Args:\n            sonos_playlist\n                (:py:class:`~.soco.data_structures.DidlPlaylistContainer`):\n                Sonos playlist object or the item_id (str) of the Sonos\n                playlist.\n            track (int): *0**-based position of the track to move. The first\n                track is track 0, just like indexing into a Python list.\n            update_id (int): Optional update counter for the object. If left\n                at the default of 0, it will be looked up.\n\n        Returns:\n            dict: See :py:meth:`reorder_sonos_playlist`\n\n        Raises:\n            SoCoUPnPException: See :py:meth:`reorder_sonos_playlist`\n        \"\"\"\n        return self.reorder_sonos_playlist(sonos_playlist, int(track), None,\n                                           update_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first Sonos Playlist object that matches the attribute specified.", "response": "def get_sonos_playlist_by_attr(self, attr_name, match):\n        \"\"\"Return the first Sonos Playlist DidlPlaylistContainer that\n        matches the attribute specified.\n\n        Args:\n            attr_name (str): DidlPlaylistContainer attribute to compare. The\n                most useful being: 'title' and 'item_id'.\n            match (str): Value to match.\n\n        Returns:\n            (:class:`~.soco.data_structures.DidlPlaylistContainer`): The\n                first matching playlist object.\n\n        Raises:\n            (AttributeError): If indicated attribute name does not exist.\n            (ValueError): If a match can not be found.\n\n        Example::\n\n            device.get_sonos_playlist_by_attr('title', 'Foo')\n            device.get_sonos_playlist_by_attr('item_id', 'SQ:3')\n\n        \"\"\"\n        for sonos_playlist in self.get_sonos_playlists():\n            if getattr(sonos_playlist, attr_name) == match:\n                return sonos_playlist\n        raise ValueError('No match on \"{0}\" for value \"{1}\"'.format(attr_name,\n                                                                    match))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef really_unicode(in_string):\n    if isinstance(in_string, StringType):\n        for args in (('utf-8',), ('latin-1',), ('ascii', 'replace')):\n            try:\n                # pylint: disable=star-args\n                in_string = in_string.decode(*args)\n                break\n            except UnicodeDecodeError:\n                continue\n    if not isinstance(in_string, UnicodeType):\n        raise ValueError('%s is not a string at all.' % in_string)\n    return in_string", "response": "Make a string unicode. Really."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef camel_to_underscore(string):\n    string = FIRST_CAP_RE.sub(r'\\1_\\2', string)\n    return ALL_CAP_RE.sub(r'\\1_\\2', string).lower()", "response": "Convert camelcase to lowercase and underscore."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prettify(unicode_text):\n    import xml.dom.minidom\n    reparsed = xml.dom.minidom.parseString(unicode_text.encode('utf-8'))\n    return reparsed.toprettyxml(indent=\"  \", newl=\"\\n\")", "response": "Return a pretty - printed version of a unicode XML string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_headers(self, http_headers, soap_action):\n\n        headers = {'Content-Type': 'text/xml; charset=\"utf-8\"'}\n        if soap_action is not None:\n            headers.update({'SOAPACTION': '\"{}\"'.format(soap_action)})\n        if http_headers is not None:\n            headers.update(http_headers)\n        return headers", "response": "Prepare the http headers for sending."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare the SOAP message body for sending.", "response": "def prepare_soap_body(self, method, parameters, namespace):\n        \"\"\"Prepare the SOAP message body for sending.\n\n        Args:\n            method (str): The name of the method to call.\n            parameters (list): A list of (name, value) tuples containing\n                the parameters to pass to the method.\n            namespace (str): tThe XML namespace to use for the method.\n\n        Returns:\n            str: A properly formatted SOAP Body.\n        \"\"\"\n\n        tags = []\n        for name, value in parameters:\n            tag = \"<{name}>{value}</{name}>\".format(\n                name=name, value=escape(\"%s\" % value, {'\"': \"&quot;\"}))\n            # % converts to unicode because we are using unicode literals.\n            # Avoids use of 'unicode' function which does not exist in python 3\n            tags.append(tag)\n\n        wrapped_params = \"\".join(tags)\n        # Prepare the SOAP Body\n        if namespace is not None:\n            soap_body = (\n                '<{method} xmlns=\"{namespace}\">'\n                '{params}'\n                '</{method}>'.format(\n                    method=method, params=wrapped_params,\n                    namespace=namespace\n                ))\n        else:\n            soap_body = (\n                '<{method}>'\n                '{params}'\n                '</{method}>'.format(\n                    method=method, params=wrapped_params\n                ))\n\n        return soap_body"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare the SOAP Envelope for sending.", "response": "def prepare_soap_envelope(self, prepared_soap_header, prepared_soap_body):\n        \"\"\"Prepare the SOAP Envelope for sending.\n\n        Args:\n            prepared_soap_header (str): A SOAP Header prepared by\n                `prepare_soap_header`\n            prepared_soap_body (str): A SOAP Body prepared by\n                `prepare_soap_body`\n\n        Returns:\n            str: A prepared SOAP Envelope\n        \"\"\"\n\n        # pylint: disable=bad-continuation\n        soap_env_template = (\n            '<?xml version=\"1.0\"?>'\n            '<s:Envelope xmlns:s=\"http://schemas.xmlsoap.org/soap/envelope/\"'\n            ' s:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\">'\n                '{soap_header}'\n                    '<s:Body>'\n                        '{soap_body}'\n                    '</s:Body>'\n            '</s:Envelope>')  # noqa PEP8\n        return soap_env_template.format(\n            soap_header=prepared_soap_header,\n            soap_body=prepared_soap_body)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the SOAP message for sending to the server.", "response": "def prepare(self):\n        \"\"\"Prepare the SOAP message for sending to the server.\"\"\"\n        headers = self.prepare_headers(self.http_headers, self.soap_action)\n\n        soap_header = self.prepare_soap_header(self.soap_header)\n        soap_body = self.prepare_soap_body(\n            self.method, self.parameters, self.namespace\n        )\n        data = self.prepare_soap_envelope(soap_header, soap_body)\n        return (headers, data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(self):\n\n        headers, data = self.prepare()\n\n        # Check log level before logging XML, since prettifying it is\n        # expensive\n        if _LOG.isEnabledFor(logging.DEBUG):\n            _LOG.debug(\"Sending %s, %s\", headers, prettify(data))\n\n        response = requests.post(\n            self.endpoint,\n            headers=headers,\n            data=data.encode('utf-8'),\n            **self.request_args\n        )\n        _LOG.debug(\"Received %s, %s\", response.headers, response.text)\n        status = response.status_code\n        if status == 200:\n            # The response is good. Extract the Body\n            tree = XML.fromstring(response.content)\n            # Get the first child of the <Body> tag. NB There should only be\n            # one if the RPC standard is followed.\n            body = tree.find(\n                \"{http://schemas.xmlsoap.org/soap/envelope/}Body\")[0]\n            return body\n        elif status == 500:\n            # We probably have a SOAP Fault\n            tree = XML.fromstring(response.content)\n            fault = tree.find(\n                './/{http://schemas.xmlsoap.org/soap/envelope/}Fault'\n            )\n            if fault is None:\n                # Not a SOAP fault. Must be something else.\n                response.raise_for_status()\n            faultcode = fault.findtext(\"faultcode\")\n            faultstring = fault.findtext(\"faultstring\")\n            faultdetail = fault.find(\"detail\")\n            raise SoapFault(faultcode, faultstring, faultdetail)\n        else:\n            # Something else has gone wrong. Probably a network error. Let\n            # Requests handle it\n            response.raise_for_status()\n\n        return None", "response": "Call the SOAP method on the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __build_option_parser():\n    description = \"\"\"\n    Tool to analyze Wireshark dumps of Sonos traffic.\n\n    The files that are input to this script must be in the\n    \"Wireshark/tcpdump/...-libpcap\" format, which can be exported from\n    Wireshark.\n\n    To use the open in browser function, a configuration file must be\n    written. It should be in the same directory as this script and have the\n    name \"analyse_ws.ini\". An example of such a file is given below ({0}\n    indicates the file):\n    [General]\n    browser_command: epiphany {0}\n\n    The browser command should be any command that opens a new tab in\n    the program you wish to read the Wireshark dumps in.\n\n    Separating Sonos traffic out from the rest of the network traffic is\n    tricky. Therefore, it will in all likelyhood increase the succes of\n    this tool, if the traffic is filtered in Wireshark to only show\n    traffic to and from the Sonos unit. Still, if the analysis fails,\n    then use the debug mode. This will show you the analysis of the\n    traffic packet by packet and give you packet numbers so you can find\n    and analyze problematic packets in Wireshark.\n    \"\"\"\n    description = textwrap.dedent(description).strip()\n\n    parser = \\\n        argparse.ArgumentParser(description=description,\n                                formatter_class=argparse.RawTextHelpFormatter)\n    parser.add_argument('file_', metavar='FILE', type=str, nargs=1,\n                        help='the file to analyze')\n    parser.add_argument('-o', '--output-prefix', type=str,\n                        help='the output filename prefix to use')\n    parser.add_argument('-f', '--to-file', action='store_const', const=True,\n                        help='output xml to files', default=False)\n    parser.add_argument('-d', '--debug-analysis', action='store_const',\n                        const=True,\n                        help='writes debug information to file.debug',\n                        default=False)\n    parser.add_argument('-m', '--disable-color', action='store_const',\n                        const=False, help='disable color in interactive mode',\n                        default=COLOR, dest='color')\n    parser.add_argument('-c', '--enable-color', action='store_const',\n                        const=True, help='disable color in interactive mode',\n                        default=COLOR, dest='color')\n    parser.add_argument('-b', '--to-browser', action='store_const', const=True,\n                        help='output xml to browser, implies --to-file',\n                        default=False)\n    parser.add_argument('-e', '--external-inner-xml', action='store_const',\n                        const=True, help='show the internal separately '\n                        'encoded xml externally instead of re-integrating it',\n                        default=False)\n    return parser", "response": "Build the option parser for this script"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a single character non - echoed and return it.", "response": "def getch():\n    \"\"\" Read a single character non-echoed and return it. Recipe from:\n    http://code.activestate.com/recipes/\n    134892-getch-like-unbuffered-character-reading-from-stdin/\n    \"\"\"\n    filedescriptor = sys.stdin.fileno()\n    old_settings = termios.tcgetattr(filedescriptor)\n    if PLATFORM == 'win32':\n        character = msvcrt.getch()\n    else:\n        try:\n            tty.setraw(sys.stdin.fileno())\n            character = sys.stdin.read(1)\n        finally:\n            termios.tcsetattr(filedescriptor, termios.TCSADRAIN, old_settings)\n    return character"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_file(self, filename):\n        # Use the file name as prefix if none is given\n        if self.output_prefix is None:\n            _, self.output_prefix = os.path.split(filename)\n        # Check if the file is present, since rdpcap will not do that\n        if not (os.path.isfile(filename) and os.access(filename, os.R_OK)):\n            print 'The file \\'{0}\\' is either not present or not readable. '\\\n                  'Exiting!'.format(filename)\n            sys.exit(1)\n        try:\n            packets = rdpcap(filename)\n        except NameError:\n            # Due probably to a bug in rdpcap, this kind of error raises a\n            # NameError, because the exception that is tried to raise, is not\n            # defined\n            print 'The file \\'{}\\' is not a pcap capture file. Exiting!'\\\n                .format(filename)\n            sys.exit(2)\n\n        for number, packet in enumerate(packets):\n            # See if there is a field called load\n            self._debug('\\nNUMBER {0}'.format(number), no_prefix=True)\n            try:\n                # Will cause AttributeError if there is no load\n                packet.getfieldval('load')\n                # Get the full load\n                load = packet.sprintf('%TCP.payload%')\n                self._debug('PAYLOAD LENGTH {0}'.format(len(load)),\n                            no_prefix=True)\n                self._debug(load, load=True)\n                self._parse_load(load)\n            except AttributeError:\n                self._debug('LOAD EXCEPTION', no_prefix=True)\n        if len(self.messages) > 0 and not self.messages[-1].write_closed:\n            self._debug('DELETE LAST OPEN FILE')\n            del self.messages[-1]\n\n        if self.args.debug_analysis:\n            sys.exit(0)", "response": "Analyse the file with the captured content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_load(self, load):\n        # If the load is ??\n        if load in ['??']:\n            self._debug('IGNORING')\n        # If there is a start in load\n        elif any([start in load for start in STARTS]):\n            self._debug('START')\n            self.messages.append(WSPart(load, self.args))\n            # and there is also an end\n            if any([end in load for end in ENDS]):\n                self.messages[-1].finalize_content()\n                self._debug('AND END')\n        # If there is an end in load\n        elif any([end in load for end in ENDS]):\n            # If there is an open WSPart\n            if len(self.messages) > 0 and not\\\n                    self.messages[-1].write_closed:\n                self._debug('END ON OPEN FILE')\n                self.messages[-1].add_content(load)\n                self.messages[-1].finalize_content()\n            # Ignore ends before start\n            else:\n                self._debug('END BUT NO OPEN FILE')\n        else:\n            # If there is an open WSPart\n            if len(self.messages) > 0 and not\\\n                    self.messages[-1].write_closed:\n                self._debug('ADD TO OPEN FILE')\n                self.messages[-1].add_content(load)\n            # else ignore\n            else:\n                self._debug('NOTHING TO DO')", "response": "Parse the load from a single packet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_file_mode(self):\n        for message_no in range(len(self.messages)):\n            self.__to_file(message_no)", "response": "Write all the messages to files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a single message to a file", "response": "def __to_file(self, message_no):\n        \"\"\" Write a single message to file \"\"\"\n        filename = self.__create_file_name(message_no)\n        try:\n            with codecs.open(filename, mode='w',\n                             encoding=self.messages[message_no].encoding)\\\n                    as file__:\n                file__.write(self.messages[message_no].output)\n        except IOError as excep:\n            print 'Unable for open the file \\'{0}\\' for writing. The '\\\n                  'following exception was raised:'.format(filename)\n            print excep\n            print 'Exiting!'\n            sys.exit(2)\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the filename to save to", "response": "def __create_file_name(self, message_no):\n        \"\"\" Create the filename to save to \"\"\"\n        cwd = os.getcwd()\n        filename = '{0}_{1}.xml'.format(self.output_prefix, message_no)\n        return os.path.join(cwd, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting all the messages to files and open them in the browser", "response": "def to_browser_mode(self):\n        \"\"\" Write all the messages to files and open them in the browser \"\"\"\n        for message_no in range(len(self.messages)):\n            self.__to_browser(message_no)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __to_browser(self, message_no):\n        filename = self.__to_file(message_no)\n        try:\n            command = self.config.get('General', 'browser_command')\n        except (ConfigParser.NoOptionError, AttributeError):\n            print 'Incorrect or missing .ini file. See --help.'\n            sys.exit(5)\n        command = str(command).format(filename)\n        command_list = command.split(' ')\n        try:\n            subprocess.Popen(command_list, stdout=subprocess.PIPE,\n                             stderr=subprocess.PIPE)\n        except OSError:\n            print 'Unable to execute the browsercommand:'\n            print command\n            print 'Exiting!'\n            sys.exit(21)", "response": "Write a single message to file and open the file in browser"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the window with the menu and the new text", "response": "def __update_window(self, width, height, message_no, page_no):\n        \"\"\" Update the window with the menu and the new text \"\"\"\n        file_exists_label = '-F-ILE'\n        if not os.path.exists(self.__create_file_name(message_no)):\n            file_exists_label = '(f)ile'\n\n        # Clear the screen\n        if PLATFORM == 'win32':\n            # Ugly hack until someone figures out a better way for Windows\n            # probably something with a cls command, but I cannot test it\n            for _ in range(50):\n                print\n        else:\n            sys.stdout.write('\\x1b[2J\\x1b[H')  # Clear screen\n\n        # Content\n        content = self.messages[message_no].output.rstrip('\\n')\n        out = content\n        if self.args.color:\n            out = pygments.highlight(content, XmlLexer(), TerminalFormatter())\n\n        # Paging functionality\n        if message_no not in self.pages:\n            self._form_pages(message_no, content, out, height, width)\n        # Coerce in range\n        page_no = max(min(len(self.pages[message_no]) - 1, page_no), 0)\n        page_content = self.pages[message_no][page_no]\n\n        # Menu\n        max_message = str(len(self.messages) - 1)\n        position_string = u'{{0: >{0}}}/{{1: <{0}}}'.format(len(max_message))\n        position_string = position_string.format(message_no, max_message)\n        # Assume less than 100 pages\n        current_max_page = len(self.pages[message_no]) - 1\n        pages_string = u'{0: >2}/{1: <2}'.format(page_no, current_max_page)\n        menu = (u'(b)rowser | {0} | Message {1} \\u2193 (s)\\u2191 (w) | '\n                u'Page {2} \\u2190 (a)\\u2192 (d) | (q)uit\\n{3}').\\\n            format(file_exists_label, position_string, pages_string,\n                   '-' * width)\n\n        print menu\n        print page_content\n        return page_no"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _form_pages(self, message_no, content, out, height, width):\n        self.pages[message_no] = []\n        page_height = height - 4  # 2-3 for menu, 1 for cursor\n        outline = u''\n        no_lines_page = 0\n        for original, formatted in zip(content.split('\\n'), out.split('\\n')):\n            no_lines_original = int(math.ceil(len(original) / float(width)))\n\n            # Blank line\n            if len(original) == 0:\n                if no_lines_page + 1 <= page_height:\n                    outline += u'\\n'\n                    no_lines_page += 1\n                else:\n                    self.pages[message_no].append(outline)\n                    outline = u'\\n'\n                    no_lines_page = 1\n                original = formatted = u'\\n'\n            # Too large line\n            elif no_lines_original > page_height:\n                if len(outline) > 0:\n                    self.pages[message_no].append(outline)\n                    outline = u''\n                    no_lines_page = 0\n                self.pages[message_no].append(formatted)\n            # The line(s) can be added to the current page\n            elif no_lines_page + no_lines_original <= page_height:\n                if len(outline) > 0:\n                    outline += u'\\n'\n                outline += formatted\n                no_lines_page += no_lines_original\n            # End the page and start a new\n            else:\n                self.pages[message_no].append(outline)\n                outline = formatted\n                no_lines_page = no_lines_original\n        # Add the remainder\n        if len(outline) > 0:\n            self.pages[message_no].append(outline)\n        if len(self.pages[message_no]) == 0:\n            self.pages[message_no].append(u'')", "response": "Form the pages for the given message number."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef finalize_content(self):\n        self.write_closed = True\n        body = self.raw_body.decode(self.encoding)\n        self._init_xml(body)\n        self._form_output()", "response": "Finalize the content of the log file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the present body as xml and set the internal attributes to self. inner_xml.", "response": "def _init_xml(self, body):\n        \"\"\" Parse the present body as xml \"\"\"\n        tree = etree.fromstring(body.encode(self.encoding), PARSER)\n        # Extract and replace inner DIDL xml in tags\n        for text in tree.xpath('.//text()[contains(., \"DIDL\")]'):\n            item = text.getparent()\n            didl_tree = etree.fromstring(item.text)\n            if self.external_inner_xml:\n                item.text = 'DIDL_REPLACEMENT_{0}'.format(len(self.inner_xml))\n                self.inner_xml.append(didl_tree)\n            else:\n                item.text = None\n                item.append(didl_tree)\n\n        # Extract and replace inner DIDL xml in properties in inner xml\n        for inner_tree in self.inner_xml:\n            for item in inner_tree.xpath('//*[contains(@val, \"DIDL\")]'):\n                if self.external_inner_xml:\n                    didl_tree = etree.fromstring(item.attrib['val'])\n                    item.attrib['val'] = 'DIDL_REPLACEMENT_{0}'.\\\n                        format(len(self.inner_xml))\n                    self.inner_xml.append(didl_tree)\n\n        self.body_formatted = etree.tostring(tree, pretty_print=True).decode(\n            self.encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_didl_string(string):\n    items = []\n    root = XML.fromstring(string.encode('utf-8'))\n    for elt in root:\n        if elt.tag.endswith('item') or elt.tag.endswith('container'):\n            item_class = elt.findtext(ns_tag('upnp', 'class'))\n\n            # In case this class has an # specified unofficial\n            # subclass, ignore it by stripping it from item_class\n            if '.#' in item_class:\n                item_class = item_class[:item_class.find('.#')]\n\n            try:\n                cls = _DIDL_CLASS_TO_CLASS[item_class]\n            except KeyError:\n                raise DIDLMetadataError(\"Unknown UPnP class: %s\" % item_class)\n            item = cls.from_element(elt)\n            item = attempt_datastructure_upgrade(item)\n            items.append(item)\n        else:\n            # <desc> elements are allowed as an immediate child of <DIDL-Lite>\n            # according to the spec, but I have not seen one there in Sonos, so\n            # we treat them as illegal. May need to fix this if this\n            # causes problems.\n            raise DIDLMetadataError(\"Illegal child of DIDL element: <%s>\"\n                                    % elt.tag)\n    _LOG.debug(\n        'Created data structures: %.20s (CUT) from Didl string \"%.20s\" (CUT)',\n        items, string,\n    )\n    return items", "response": "Convert a unicode xml string to a list of DIDLObjects <DidlObject > or a subclass of DIDLObject."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attempt_datastructure_upgrade(didl_item):\n    try:\n        resource = didl_item.resources[0]\n    except IndexError:\n        _LOG.debug('Upgrade not possible, no resources')\n        return didl_item\n\n    if resource.uri.startswith('x-sonos-http'):\n        # Get data\n        uri = resource.uri\n        # Now we need to create a DIDL item id. It seems to be based on the uri\n        path = urlparse(uri).path\n        # Strip any extensions, eg .mp3, from the end of the path\n        path = path.rsplit('.', 1)[0]\n        # The ID has an 8 (hex) digit prefix. But it doesn't seem to\n        # matter what it is!\n        item_id = '11111111{0}'.format(path)\n\n        # Ignore other metadata for now, in future ask ms data\n        # structure to upgrade metadata from the service\n        metadata = {}\n        try:\n            metadata['title'] = didl_item.title\n        except AttributeError:\n            pass\n\n        # Get class\n        try:\n            cls = get_class(DIDL_NAME_TO_QUALIFIED_MS_NAME[\n                didl_item.__class__.__name__\n            ])\n        except KeyError:\n            # The data structure should be upgraded, but there is an entry\n            # missing from DIDL_NAME_TO_QUALIFIED_MS_NAME. Log this as a\n            # warning.\n            _LOG.warning(\n                'DATA STRUCTURE UPGRADE FAIL. Unable to upgrade music library '\n                'data structure to music service data structure because an '\n                'entry is missing for %s in DIDL_NAME_TO_QUALIFIED_MS_NAME. '\n                'This should be reported as a bug.',\n                didl_item.__class__.__name__,\n            )\n            return didl_item\n\n        upgraded_item = cls(\n            item_id=item_id,\n            desc=desc_from_uri(resource.uri),\n            resources=didl_item.resources,\n            uri=uri,\n            metadata_dict=metadata,\n        )\n        _LOG.debug(\"Item %s upgraded to %s\", didl_item, upgraded_item)\n        return upgraded_item\n\n    _LOG.debug('Upgrade not necessary')\n    return didl_item", "response": "Attempt to upgrade a didl item to a music services data structure if it originates from a music services data structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the music service item that corresponds to xml.", "response": "def get_ms_item(xml, service, parent_id):\n    \"\"\"Return the music service item that corresponds to xml.\n\n    The class is identified by getting the type from the 'itemType' tag\n    \"\"\"\n    cls = MS_TYPE_TO_CLASS.get(xml.findtext(ns_tag('ms', 'itemType')))\n    out = cls.from_xml(xml, service, parent_id)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of tags that contain text retrieved recursively from an an XML tree.", "response": "def tags_with_text(xml, tags=None):\n    \"\"\"Return a list of tags that contain text retrieved recursively from an\n    XML tree.\"\"\"\n    if tags is None:\n        tags = []\n    for element in xml:\n        if element.text is not None:\n            tags.append(element)\n        elif len(element) > 0:  # pylint: disable=len-as-condition\n            tags_with_text(element, tags)\n        else:\n            message = 'Unknown XML structure: {}'.format(element)\n            raise ValueError(message)\n    return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_xml(cls, xml, service, parent_id):\n        # Add a few extra pieces of information\n        content = {'description': service.description,\n                   'service_id': service.service_id,\n                   'parent_id': parent_id}\n        # Extract values from the XML\n        all_text_elements = tags_with_text(xml)\n        for item in all_text_elements:\n            tag = item.tag[len(NAMESPACES['ms']) + 2:]  # Strip namespace\n            tag = camel_to_underscore(tag)  # Convert to nice names\n            if tag not in cls.valid_fields:\n                message = 'The info tag \\'{}\\' is not allowed for this item'.\\\n                    format(tag)\n                raise ValueError(message)\n            content[tag] = item.text\n\n        # Convert values for known types\n        for key, value in content.items():\n            if key == 'duration':\n                content[key] = int(value)\n            if key in ['can_play', 'can_skip', 'can_add_to_favorites',\n                       'can_enumerate']:\n                content[key] = True if value == 'true' else False\n        # Rename a single item\n        content['item_id'] = content.pop('id')\n        # And get the extended id\n        content['extended_id'] = service.id_to_extended_id(content['item_id'],\n                                                           cls)\n        # Add URI if there is one for the relevant class\n        uri = service.form_uri(content, cls)\n        if uri:\n            content['uri'] = uri\n\n        # Check for all required values\n        for key in cls.required_fields:\n            if key not in content:\n                message = 'An XML field that correspond to the key \\'{}\\' '\\\n                    'is required. See the docstring for help.'.format(key)\n\n        return cls.from_dict(content)", "response": "Create a Music Service item from an XML object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the class from a dictionary.", "response": "def from_dict(cls, dict_in):\n        \"\"\"Initialize the class from a dict.\n\n        :param dict_in: The dictionary that contains the item content. Required\n            fields are listed class variable by that name\n        :type dict_in: dict\n        \"\"\"\n        kwargs = dict_in.copy()\n        args = [kwargs.pop(key) for key in cls.required_fields]\n        return cls(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef didl_metadata(self):\n        # Check if this item is meant to be played\n        if not self.can_play:\n            message = 'This item is not meant to be played and therefore '\\\n                'also not to create its own didl_metadata'\n            raise DIDLMetadataError(message)\n        # Check if we have the attributes to create the didl metadata:\n        for key in ['extended_id', 'title', 'item_class']:\n            if not hasattr(self, key):\n                message = 'The property \\'{}\\' is not present on this item. '\\\n                    'This indicates that this item was not meant to create '\\\n                    'didl_metadata'.format(key)\n                raise DIDLMetadataError(message)\n        if 'description' not in self.content:\n            message = 'The item for \\'description\\' is not present in '\\\n                'self.content. This indicates that this item was not meant '\\\n                'to create didl_metadata'\n            raise DIDLMetadataError(message)\n\n        # Main element, ugly? yes! but I have given up on using namespaces\n        # with xml.etree.ElementTree\n        item_attrib = {\n            'xmlns:dc': 'http://purl.org/dc/elements/1.1/',\n            'xmlns:upnp': 'urn:schemas-upnp-org:metadata-1-0/upnp/',\n            'xmlns:r': 'urn:schemas-rinconnetworks-com:metadata-1-0/',\n            'xmlns': 'urn:schemas-upnp-org:metadata-1-0/DIDL-Lite/'\n        }\n        xml = XML.Element('DIDL-Lite', item_attrib)\n        # Item sub element\n        item_attrib = {\n            'parentID': '',\n            'restricted': 'true',\n            'id': self.extended_id\n        }\n        # Only add the parent_id if we have it\n        if self.parent_id:\n            item_attrib['parentID'] = self.parent_id\n        item = XML.SubElement(xml, 'item', item_attrib)\n\n        # Add title and class\n        XML.SubElement(item, 'dc:title').text = self.title\n        XML.SubElement(item, 'upnp:class').text = self.item_class\n        # Add the desc element\n        desc_attrib = {\n            'id': 'cdudn',\n            'nameSpace': 'urn:schemas-rinconnetworks-com:metadata-1-0/'\n        }\n        desc = XML.SubElement(item, 'desc', desc_attrib)\n        desc.text = self.content['description']\n\n        return xml", "response": "Return the DIDL metadata for a Music Service Track."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef label(self):\n        group_names = sorted([m.player_name for m in self.members])\n        return \", \".join(group_names)", "response": "str - A description of the group.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef short_label(self):\n        group_names = sorted([m.player_name for m in self.members])\n        group_label = group_names[0]\n        if len(group_names) > 1:\n            group_label += \" + {}\".format(len(group_names) - 1)\n        return group_label", "response": "str - A short description of the group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a set of all alarms known to the Sonos system.", "response": "def get_alarms(zone=None):\n    \"\"\"Get a set of all alarms known to the Sonos system.\n\n    Args:\n        zone (`SoCo`, optional): a SoCo instance to query. If None, a random\n            instance is used. Defaults to `None`.\n\n    Returns:\n        set: A set of `Alarm` instances\n\n    Note:\n        Any existing `Alarm` instance will have its attributes updated to those\n        currently stored on the Sonos system.\n    \"\"\"\n    # Get a soco instance to query. It doesn't matter which.\n    if zone is None:\n        zone = discovery.any_soco()\n    response = zone.alarmClock.ListAlarms()\n    alarm_list = response['CurrentAlarmList']\n    tree = XML.fromstring(alarm_list.encode('utf-8'))\n\n    # An alarm list looks like this:\n    # <Alarms>\n    #     <Alarm ID=\"14\" StartTime=\"07:00:00\"\n    #         Duration=\"02:00:00\" Recurrence=\"DAILY\" Enabled=\"1\"\n    #         RoomUUID=\"RINCON_000ZZZZZZ1400\"\n    #         ProgramURI=\"x-rincon-buzzer:0\" ProgramMetaData=\"\"\n    #         PlayMode=\"SHUFFLE_NOREPEAT\" Volume=\"25\"\n    #         IncludeLinkedZones=\"0\"/>\n    #     <Alarm ID=\"15\" StartTime=\"07:00:00\"\n    #         Duration=\"02:00:00\" Recurrence=\"DAILY\" Enabled=\"1\"\n    #         RoomUUID=\"RINCON_000ZZZZZZ01400\"\n    #         ProgramURI=\"x-rincon-buzzer:0\" ProgramMetaData=\"\"\n    #         PlayMode=\"SHUFFLE_NOREPEAT\" Volume=\"25\"\n    #          IncludeLinkedZones=\"0\"/>\n    # </Alarms>\n\n    # pylint: disable=protected-access\n    alarms = tree.findall('Alarm')\n    result = set()\n    for alarm in alarms:\n        values = alarm.attrib\n        alarm_id = values['ID']\n        # If an instance already exists for this ID, update and return it.\n        # Otherwise, create a new one and populate its values\n        if Alarm._all_alarms.get(alarm_id):\n            instance = Alarm._all_alarms.get(alarm_id)\n        else:\n            instance = Alarm(None)\n            instance._alarm_id = alarm_id\n            Alarm._all_alarms[instance._alarm_id] = instance\n\n        instance.start_time = datetime.strptime(\n            values['StartTime'], \"%H:%M:%S\").time()  # NB StartTime, not\n        # StartLocalTime, which is used by CreateAlarm\n        instance.duration = None if values['Duration'] == '' else\\\n            datetime.strptime(values['Duration'], \"%H:%M:%S\").time()\n        instance.recurrence = values['Recurrence']\n        instance.enabled = values['Enabled'] == '1'\n        instance.zone = next((z for z in zone.all_zones\n                              if z.uid == values['RoomUUID']), None)\n        # some alarms are not associated to zones -> filter these out\n        if instance.zone is None:\n            continue\n        instance.program_uri = None if values['ProgramURI'] ==\\\n            \"x-rincon-buzzer:0\" else values['ProgramURI']\n        instance.program_metadata = values['ProgramMetaData']\n        instance.play_mode = values['PlayMode']\n        instance.volume = values['Volume']\n        instance.include_linked_zones = values['IncludeLinkedZones'] == '1'\n\n        result.add(instance)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the alarm to the Sonos system.", "response": "def save(self):\n        \"\"\"Save the alarm to the Sonos system.\n\n        Raises:\n            ~soco.exceptions.SoCoUPnPException: if the alarm cannot be created\n                because there\n                is already an alarm for this room at the specified time.\n        \"\"\"\n        # pylint: disable=bad-continuation\n        args = [\n            ('StartLocalTime', self.start_time.strftime(TIME_FORMAT)),\n            ('Duration', '' if self.duration is None else\n                self.duration.strftime(TIME_FORMAT)),\n            ('Recurrence', self.recurrence),\n            ('Enabled', '1' if self.enabled else '0'),\n            ('RoomUUID', self.zone.uid),\n            ('ProgramURI', \"x-rincon-buzzer:0\" if self.program_uri is None\n                else self.program_uri),\n            ('ProgramMetaData', self.program_metadata),\n            ('PlayMode', self.play_mode),\n            ('Volume', self.volume),\n            ('IncludeLinkedZones', '1' if self.include_linked_zones else '0')\n        ]\n        if self._alarm_id is None:\n            response = self.zone.alarmClock.CreateAlarm(args)\n            self._alarm_id = response['AssignedID']\n            Alarm._all_alarms[self._alarm_id] = self\n        else:\n            # The alarm has been saved before. Update it instead.\n            args.insert(0, ('ID', self._alarm_id))\n            self.zone.alarmClock.UpdateAlarm(args)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self):\n        self.zone.alarmClock.DestroyAlarm([\n            ('ID', self._alarm_id)\n        ])\n        alarm_id = self._alarm_id\n        try:\n            del Alarm._all_alarms[alarm_id]\n        except KeyError:\n            pass\n        self._alarm_id = None", "response": "Remove the alarm from the Sonos system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    parser = argparse.ArgumentParser(\n        prog='',\n        description='Dump data about Sonos services'\n    )\n    parser.add_argument(\n        '-d', '--device',\n        default=None,\n        help=\"The ip address of the device to query. \"\n             \"If none is supplied, a random device will be used\"\n    )\n    parser.add_argument(\n        '-s', '--service',\n        default=None,\n        help=\"Dump data relating to services matching this regexp \"\n             \"only, e.g. %(prog)s -s GroupRenderingControl\"\n    )\n\n    args = parser.parse_args()\n\n    # get a zone player - any one will do\n    if args.device:\n        device = soco.SoCo(args.device)\n    else:\n        device = soco.discovery.any_soco()\n    print(\"Querying %s\" % device.player_name)\n    # loop over each of the available services\n    # pylint: disable=no-member\n    services = (srv(device) for srv in soco.services.Service.__subclasses__())\n\n    for srv in services:\n        if args.service is None or re.search(\n                args.service, srv.service_type):\n            print_details(srv)", "response": "This is the main function of the main script."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_details(srv):\n    name = srv.service_type\n    box = \"=\" * 79\n    print(\"{0}\\n|{1:^77}|\\n{0}\\n\".format(box, name))\n    for action in srv.iter_actions():\n        print(action.name)\n        print(\"~\" * len(action.name))\n        print(\"\\n  Input\")\n        for arg in action.in_args:\n            print(\"    \", arg)\n        print(\"\\n  Output\")\n        for arg in action.out_args:\n            print(\"    \", arg)\n\n        print(\"\\n\\n\")", "response": "Prints the details of a service"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef snapshot(self):\n        # get if device coordinator (or slave) True (or False)\n        self.is_coordinator = self.device.is_coordinator\n\n        # Get information about the currently playing media\n        media_info = self.device.avTransport.GetMediaInfo([('InstanceID', 0)])\n        self.media_uri = media_info['CurrentURI']\n        # Extract source from media uri - below some media URI value examples:\n        #  'x-rincon-queue:RINCON_000E5859E49601400#0'\n        #       - playing a local queue always #0 for local queue)\n        #\n        #  'x-rincon-queue:RINCON_000E5859E49601400#6'\n        #       - playing a cloud queue where #x changes with each queue)\n        #\n        #  -'x-rincon:RINCON_000E5859E49601400'\n        #       - a slave player pointing to coordinator player\n\n        if self.media_uri.split(':')[0] == 'x-rincon-queue':\n            # The pylint error below is a false positive, see about removing it\n            # in the future\n            # pylint: disable=simplifiable-if-statement\n            if self.media_uri.split('#')[1] == '0':\n                # playing local queue\n                self.is_playing_queue = True\n            else:\n                # playing cloud queue - started from Alexa\n                self.is_playing_cloud_queue = True\n\n        # Save the volume, mute and other sound settings\n        self.volume = self.device.volume\n        self.mute = self.device.mute\n        self.bass = self.device.bass\n        self.treble = self.device.treble\n        self.loudness = self.device.loudness\n\n        # get details required for what's playing:\n        if self.is_playing_queue:\n            # playing from queue - save repeat, random, cross fade, track, etc.\n            self.play_mode = self.device.play_mode\n            self.cross_fade = self.device.cross_fade\n\n            # Get information about the currently playing track\n            track_info = self.device.get_current_track_info()\n            if track_info is not None:\n                position = track_info['playlist_position']\n                if position != \"\":\n                    # save as integer\n                    self.playlist_position = int(position)\n                self.track_position = track_info['position']\n        else:\n            # playing from a stream - save media metadata\n            self.media_metadata = media_info['CurrentURIMetaData']\n\n        # Work out what the playing state is - if a coordinator\n        if self.is_coordinator:\n            transport_info = self.device.get_current_transport_info()\n            if transport_info is not None:\n                self.transport_state = transport_info[\n                    'current_transport_state']\n\n        # Save of the current queue if we need to\n        self._save_queue()\n\n        # return if device is a coordinator (helps usage)\n        return self.is_coordinator", "response": "Record and store the current state of a device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrestoring the state of a device to that which was previously saved.", "response": "def restore(self, fade=False):\n        \"\"\"Restore the state of a device to that which was previously saved.\n\n        For coordinator devices restore everything. For slave devices\n        only restore volume etc., not transport info (transport info\n        comes from the slave's coordinator).\n\n        Args:\n            fade (bool): Whether volume should be faded up on restore.\n        \"\"\"\n\n        if self.is_coordinator:\n            # Start by ensuring that the speaker is paused as we don't want\n            # things all rolling back when we are changing them, as this could\n            # include things like audio\n            transport_info = self.device.get_current_transport_info()\n            if transport_info is not None:\n                if transport_info['current_transport_state'] == 'PLAYING':\n                    self.device.pause()\n\n            # Check if the queue should be restored\n            self._restore_queue()\n\n            # Reinstate what was playing\n\n            if self.is_playing_queue and self.playlist_position > 0:\n                # was playing from playlist\n\n                if self.playlist_position is not None:\n                    # The position in the playlist returned by\n                    # get_current_track_info starts at 1, but when\n                    # playing from playlist, the index starts at 0\n                    # if position > 0:\n                    self.playlist_position -= 1\n                    self.device.play_from_queue(self.playlist_position, False)\n\n                if self.track_position is not None:\n                    if self.track_position != \"\":\n                        self.device.seek(self.track_position)\n\n                # reinstate track, position, play mode, cross fade\n                # Need to make sure there is a proper track selected first\n                self.device.play_mode = self.play_mode\n                self.device.cross_fade = self.cross_fade\n\n            elif self.is_playing_cloud_queue:\n                # was playing a cloud queue started by Alexa\n                # No way yet to re-start this so prevent it throwing an error!\n                pass\n\n            else:\n                # was playing a stream (radio station, file, or nothing)\n                # reinstate uri and meta data\n                if self.media_uri != \"\":\n                    self.device.play_uri(\n                        self.media_uri, self.media_metadata, start=False)\n\n        # For all devices:\n        # Reinstate all the properties that are pretty easy to do\n        self.device.mute = self.mute\n        self.device.bass = self.bass\n        self.device.treble = self.treble\n        self.device.loudness = self.loudness\n\n        # Reinstate volume\n        # Can only change volume on device with fixed volume set to False\n        # otherwise get uPnP error, so check first. Before issuing a network\n        # command to check, fixed volume always has volume set to 100.\n        # So only checked fixed volume if volume is 100.\n        if self.volume == 100:\n            fixed_vol = self.device.renderingControl.GetOutputFixed(\n                [('InstanceID', 0)])['CurrentFixed']\n        else:\n            fixed_vol = False\n\n        # now set volume if not fixed\n        if not fixed_vol:\n            if fade:\n                # if fade requested in restore\n                # set volume to 0 then fade up to saved volume (non blocking)\n                self.device.volume = 0\n                self.device.ramp_to_volume(self.volume)\n            else:\n                # set volume\n                self.device.volume = self.volume\n\n        # Now everything is set, see if we need to be playing, stopped\n        # or paused ( only for coordinators)\n        if self.is_coordinator:\n            if self.transport_state == 'PLAYING':\n                self.device.play()\n            elif self.transport_state == 'STOPPED':\n                self.device.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _save_queue(self):\n        if self.queue is not None:\n            # Maximum batch is 486, anything larger will still only\n            # return 486\n            batch_size = 400\n            total = 0\n            num_return = batch_size\n\n            # Need to get all the tracks in batches, but Only get the next\n            # batch if all the items requested were in the last batch\n            while num_return == batch_size:\n                queue_items = self.device.get_queue(total, batch_size)\n                # Check how many entries were returned\n                num_return = len(queue_items)\n                # Make sure the queue is not empty\n                if num_return > 0:\n                    self.queue.append(queue_items)\n                # Update the total that have been processed\n                total = total + num_return", "response": "Save the current state of the queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestoring the previous state of the queue.", "response": "def _restore_queue(self):\n        \"\"\"Restore the previous state of the queue.\n\n        Note:\n            The restore currently adds the items back into the queue\n            using the URI, for items the Sonos system already knows about\n            this is OK, but for other items, they may be missing some of\n            their metadata as it will not be automatically picked up.\n        \"\"\"\n        if self.queue is not None:\n            # Clear the queue so that it can be reset\n            self.device.clear_queue()\n            # Now loop around all the queue entries adding them\n            for queue_group in self.queue:\n                for queue_item in queue_group:\n                    self.device.add_uri_to_queue(queue_item.uri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading and updates default parameters for a single language model", "response": "def default_params(model, update_dict=None):\n    \"\"\"\n    Loads and updates default model parameters\n\n    Parameters\n    ----------\n\n    model : str\n        The name of a model\n\n    update_dict : dict\n        A dict to update default parameters\n\n    Returns\n    ----------\n\n    params : dict\n        A dictionary of parameters\n    \"\"\"\n\n    if model in parameters:\n        params = parameters[model].copy()\n    else:\n        params = None\n\n    if update_dict:\n        if params is None:\n            params = {}\n        params.update(update_dict)\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate plot describing covariance with as a function of number of dimensions", "response": "def describe(x, reduce='IncrementalPCA', max_dims=None, show=True,\n             format_data=True):\n    \"\"\"\n    Create plot describing covariance with as a function of number of dimensions\n\n    This function correlates the raw data with reduced data to get a sense\n    for how well the data can be summarized with n dimensions.  Useful for\n    evaluating quality of dimensionality reduced plots.\n\n    Parameters\n    ----------\n\n    x : Numpy array, DataFrame or list of arrays/dfs\n        A list of Numpy arrays or Pandas Dataframes\n\n    reduce : str or dict\n        Decomposition/manifold learning model to use.  Models supported: PCA,\n        IncrementalPCA, SparsePCA, MiniBatchSparsePCA, KernelPCA, FastICA,\n        FactorAnalysis, TruncatedSVD, DictionaryLearning, MiniBatchDictionaryLearning,\n        TSNE, Isomap, SpectralEmbedding, LocallyLinearEmbedding, and MDS. Can be\n        passed as a string, but for finer control of the model parameters, pass\n        as a dictionary, e.g. reduce={'model' : 'PCA', 'params' : {'whiten' : True}}.\n        See scikit-learn specific model docs for details on parameters supported\n        for each model.\n\n    max_dims : int\n        Maximum number of dimensions to consider\n\n    show : bool\n        Plot the result (default : true)\n\n    format_data : bool\n        Whether or not to first call the format_data function (default: True).\n\n    Returns\n    ----------\n\n    result : dict\n        A dictionary with the analysis results. 'average' is the correlation\n        by number of components for all data. 'individual' is a list of lists,\n        where each list is a correlation by number of components vector (for each\n        input list).\n\n    \"\"\"\n\n    warnings.warn('When input data is large, this computation can take a long time.')\n\n    def summary(x, max_dims=None):\n\n        # if data is a list, stack it\n        if type(x) is list:\n            x = np.vstack(x)\n\n        # if max dims is not set, make it the length of the minimum number of columns\n        if max_dims is None:\n            if x.shape[1]>x.shape[0]:\n                max_dims = x.shape[0]\n            else:\n                max_dims = x.shape[1]\n\n        # correlation matrix for all dimensions\n        alldims = get_cdist(x)\n\n        corrs=[]\n        for dims in range(2, max_dims):\n            reduced = get_cdist(reducer(x, ndims=dims, reduce=reduce))\n            corrs.append(get_corr(alldims, reduced))\n            del reduced\n        return corrs\n\n    # common format\n    if format_data:\n        x = formatter(x, ppca=True)\n\n    # a dictionary to store results\n    result = {}\n    result['average'] = summary(x, max_dims)\n    result['individual'] = [summary(x_i, max_dims) for x_i in x]\n\n    if max_dims is None:\n        max_dims = len(result['average'])\n\n    # if show, plot it\n    if show:\n        fig, ax = plt.subplots()\n        ax = sns.tsplot(data=result['individual'], time=[i for i in range(2, max_dims+2)], err_style=\"unit_traces\")\n        ax.set_title('Correlation with raw data by number of components')\n        ax.set_ylabel('Correlation')\n        ax.set_xlabel('Number of components')\n        plt.show()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_data(x, vectorizer='CountVectorizer',\n                semantic='LatentDirichletAllocation', corpus='wiki', ppca=True, text_align='hyper'):\n    \"\"\"\n    Formats data into a list of numpy arrays\n\n    This function is useful to identify rows of your array that contain missing\n    data or nans.  The returned indices can be used to remove the rows with\n    missing data, or label the missing data points that are interpolated\n    using PPCA.\n\n    Parameters\n    ----------\n\n    x : numpy array, dataframe, string or (mixed) list\n        The data to convert\n\n    vectorizer : str, dict, class or class instance\n        The vectorizer to use. Built-in options are 'CountVectorizer' or\n        'TfidfVectorizer'. To change default parameters, set to a dictionary\n        e.g. {'model' : 'CountVectorizer', 'params' : {'max_features' : 10}}. See\n        http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n        for details. You can also specify your own vectorizer model as a class,\n        or class instance.  With either option, the class must have a\n        fit_transform method (see here: http://scikit-learn.org/stable/data_transforms.html).\n        If a class, pass any parameters as a dictionary to vectorizer_params. If\n        a class instance, no parameters can be passed.\n\n    semantic : str, dict, class or class instance\n        Text model to use to transform text data. Built-in options are\n        'LatentDirichletAllocation' or 'NMF' (default: LDA). To change default\n        parameters, set to a dictionary e.g. {'model' : 'NMF', 'params' :\n        {'n_components' : 10}}. See\n        http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n        for details on the two model options. You can also specify your own\n        text model as a class, or class instance.  With either option, the class\n        must have a fit_transform method (see here:\n        http://scikit-learn.org/stable/data_transforms.html).\n        If a class, pass any parameters as a dictionary to text_params. If\n        a class instance, no parameters can be passed.\n\n    corpus : list (or list of lists) of text samples or 'wiki', 'nips', 'sotus'.\n         Text to use to fit the semantic model (optional). If set to 'wiki', 'nips'\n         or 'sotus' and the default semantic and vectorizer models are used, a\n         pretrained model will be loaded which can save a lot of time.\n\n    ppca : bool\n        Performs PPCA to fill in missing values (default: True)\n\n    text_align : str\n        Alignment algorithm to use when both text and numerical data are passed.\n        If numerical arrays have the same shape, and the text data contains the\n        same number of samples, the text and numerical data are automatically\n        aligned to a common space. Example use case: an array of movie frames\n        (frames by pixels) and text descriptions of the frame.  In this case,\n        the movie and text will be automatically aligned to the same space\n        (default: hyperalignment).\n\n    Returns\n    ----------\n    data : list of numpy arrays\n        A list of formatted arrays\n    \"\"\"\n\n    # not sure why i needed to import here, but its the only way I could get it to work\n    from .df2mat import df2mat\n    from .text2mat import text2mat\n    from ..datageometry import DataGeometry\n\n    # if x is not a list, make it one\n    if type(x) is not list:\n        x = [x]\n\n    if all([isinstance(xi, six.string_types) for xi in x]):\n        x = [x]\n\n    # check data type for each element in list\n    dtypes = list(map(get_type, x))\n\n    # handle text data:\n    if any(map(lambda x: x in ['list_str', 'str', 'arr_str'], dtypes)):\n\n        # default text args\n        text_args = {\n            'vectorizer' : vectorizer,\n            'semantic' : semantic,\n            'corpus' : corpus\n        }\n\n        # filter text data\n        text_data = []\n        for i,j in zip(x, dtypes):\n            if j in ['list_str', 'str', 'arr_str']:\n                text_data.append(np.array(i).reshape(-1, 1))\n        # convert text to numerical matrices\n        text_data = text2mat(text_data, **text_args)\n\n    # replace the text data with transformed data\n    processed_x = []\n    textidx=0\n    for i, dtype in enumerate(dtypes):\n        if dtype in ['list_str', 'str', 'arr_str']:\n            processed_x.append(text_data[textidx])\n            textidx+=1\n        elif dtype == 'df':\n            processed_x.append(df2mat(x[i]))\n        elif dtype == 'geo':\n            text_args = {\n                'vectorizer' : vectorizer,\n                'semantic' : semantic,\n                'corpus' : corpus\n            }\n            for j in format_data(x[i].get_data(), **text_args):\n                processed_x.append(j)\n        else:\n            processed_x.append(x[i])\n\n    # reshape anything that is 1d\n    if any([i.ndim<=1 for i in processed_x]):\n        processed_x = [np.reshape(i,(i.shape[0],1)) if i.ndim==1 else i for i in processed_x]\n\n    contains_text = any([dtype in ['list_str', 'str', 'arr_str'] for dtype in dtypes])\n    contains_num = any([dtype in ['list_num', 'array', 'df', 'arr_num'] for dtype in dtypes])\n\n    # if there are any nans in any of the lists, use ppca\n    if ppca is True:\n        if contains_num:\n            num_data = []\n            for i,j in zip(processed_x, dtypes):\n                if j in ['list_num', 'array', 'df', 'arr_num']:\n                    num_data.append(i)\n            if np.isnan(np.vstack(num_data)).any():\n                warnings.warn('Missing data: Inexact solution computed with PPCA (see https://github.com/allentran/pca-magic for details)')\n                num_data = fill_missing(num_data)\n                x_temp = []\n                for dtype in dtypes:\n                    if dtype in ['list_str', 'str', 'arr_str']:\n                        x_temp.append(text_data.pop(0))\n                    elif dtype in ['list_num', 'array', 'df', 'arr_num']:\n                        x_temp.append(num_data.pop(0))\n                processed_x = x_temp\n\n    # if input data contains both text and numerical data\n    if contains_num and contains_text:\n\n        # and if they have the same number of samples\n        if np.unique(np.array([i.shape[0] for i, j in zip(processed_x, dtypes)])).shape[0] == 1:\n\n            from .align import align as aligner\n\n            # align the data\n            warnings.warn('Numerical and text data with same number of '\n                          'samples detected.  Aligning data to a common space.')\n            processed_x = aligner(processed_x, align=text_align, format_data=False)\n\n    return processed_x", "response": "Formats data into a list of numpy arrays with the specified vectorizer and semantic."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef missing_inds(x, format_data=True):\n\n    if format_data:\n        x = formatter(x, ppca=False)\n\n    inds = []\n    for arr in x:\n        if np.argwhere(np.isnan(arr)).size is 0:\n            inds.append(None)\n        else:\n            inds.append(np.argwhere(np.isnan(arr))[:,0])\n    if len(inds) > 1:\n        return inds\n    else:\n        return inds[0]", "response": "Returns indices of missing data points in a sequence of nans."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(x, normalize='across', internal=False, format_data=True):\n\n    assert normalize in ['across','within','row', False, None], \"scale_type must be across, within, row or none.\"\n\n    if normalize in [False, None]:\n        return x\n    else:\n\n        if format_data:\n            x = formatter(x, ppca=True)\n\n        zscore = lambda X, y: (y - np.mean(X)) / np.std(X) if len(set(y)) > 1 else np.zeros(y.shape)\n\n        if normalize == 'across':\n            x_stacked=np.vstack(x)\n            normalized_x = [np.array([zscore(x_stacked[:,j], i[:,j]) for j in range(i.shape[1])]).T for i in x]\n\n        elif normalize == 'within':\n            normalized_x = [np.array([zscore(i[:,j], i[:,j]) for j in range(i.shape[1])]).T for i in x]\n\n        elif normalize == 'row':\n            normalized_x = [np.array([zscore(i[j,:], i[j,:]) for j in range(i.shape[0])]) for i in x]\n\n        if internal or len(normalized_x)>1:\n            return normalized_x\n        else:\n            return normalized_x[0]", "response": "This function normalizes the columns or rows of an array or list of arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the mappings Wi for the SRM with random orthogonal matrices.", "response": "def _init_w_transforms(data, features):\n    \"\"\"Initialize the mappings (Wi) for the SRM with random orthogonal matrices.\n\n    Parameters\n    ----------\n\n    data : list of 2D arrays, element i has shape=[voxels_i, samples]\n        Each element in the list contains the fMRI data of one subject.\n\n    features : int\n        The number of features in the model.\n\n\n    Returns\n    -------\n\n    w : list of array, element i has shape=[voxels_i, features]\n        The initialized orthogonal transforms (mappings) :math:`W_i` for each\n        subject.\n\n    voxels : list of int\n        A list with the number of voxels per subject.\n\n\n    Note\n    ----\n\n        This function assumes that the numpy random number generator was\n        initialized.\n\n        Not thread safe.\n    \"\"\"\n    w = []\n    subjects = len(data)\n    voxels = np.empty(subjects, dtype=int)\n\n    # Set Wi to a random orthogonal voxels by features matrix\n    for subject in range(subjects):\n        voxels[subject] = data[subject].shape[0]\n        rnd_matrix = np.random.random((voxels[subject], features))\n        q, r = np.linalg.qr(rnd_matrix)\n        w.append(q)\n\n    return w, voxels"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_structures(self, data, subjects):\n        x = []\n        mu = []\n        rho2 = np.zeros(subjects)\n\n        trace_xtx = np.zeros(subjects)\n        for subject in range(subjects):\n            mu.append(np.mean(data[subject], 1))\n            rho2[subject] = 1\n            trace_xtx[subject] = np.sum(data[subject] ** 2)\n            x.append(data[subject] - mu[subject][:, np.newaxis])\n\n        return x, mu, rho2, trace_xtx", "response": "Initializes data structures for SRM and preprocess the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the log - likelihood function for the current state of the object.", "response": "def _likelihood(self, chol_sigma_s_rhos, log_det_psi, chol_sigma_s,\n                    trace_xt_invsigma2_x, inv_sigma_s_rhos, wt_invpsi_x,\n                    samples):\n        \"\"\"Calculate the log-likelihood function\n\n\n        Parameters\n        ----------\n\n        chol_sigma_s_rhos : array, shape=[features, features]\n            Cholesky factorization of the matrix (Sigma_S + sum_i(1/rho_i^2)\n            * I)\n\n        log_det_psi : float\n            Determinant of diagonal matrix Psi (containing the rho_i^2 value\n            voxels_i times).\n\n        chol_sigma_s : array, shape=[features, features]\n            Cholesky factorization of the matrix Sigma_S\n\n        trace_xt_invsigma2_x : float\n            Trace of :math:`\\\\sum_i (||X_i||_F^2/\\\\rho_i^2)`\n\n        inv_sigma_s_rhos : array, shape=[features, features]\n            Inverse of :math:`(\\\\Sigma_S + \\\\sum_i(1/\\\\rho_i^2) * I)`\n\n        wt_invpsi_x : array, shape=[features, samples]\n\n        samples : int\n            The total number of samples in the data.\n\n\n        Returns\n        -------\n\n        loglikehood : float\n            The log-likelihood value.\n        \"\"\"\n        log_det = (np.log(np.diag(chol_sigma_s_rhos) ** 2).sum() + log_det_psi\n                   + np.log(np.diag(chol_sigma_s) ** 2).sum())\n        loglikehood = -0.5 * samples * log_det - 0.5 * trace_xt_invsigma2_x\n        loglikehood += 0.5 * np.trace(\n            wt_invpsi_x.T.dot(inv_sigma_s_rhos).dot(wt_invpsi_x))\n        # + const --> -0.5*nTR*nvoxel*subjects*math.log(2*math.pi)\n\n        return loglikehood"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _srm(self, data):\n\n        samples = data[0].shape[1]\n        subjects = len(data)\n\n        np.random.seed(self.rand_seed)\n\n        # Initialization step: initialize the outputs with initial values,\n        # voxels with the number of voxels in each subject, and trace_xtx with\n        # the ||X_i||_F^2 of each subject.\n        w, voxels = _init_w_transforms(data, self.features)\n        x, mu, rho2, trace_xtx = self._init_structures(data, subjects)\n        shared_response = np.zeros((self.features, samples))\n        sigma_s = np.identity(self.features)\n\n        # Main loop of the algorithm (run\n        for iteration in range(self.n_iter):\n            logger.info('Iteration %d' % (iteration + 1))\n\n            # E-step:\n\n            # Sum the inverted the rho2 elements for computing W^T * Psi^-1 * W\n            rho0 = (1 / rho2).sum()\n\n            # Invert Sigma_s using Cholesky factorization\n            (chol_sigma_s, lower_sigma_s) = scipy.linalg.cho_factor(\n                sigma_s, check_finite=False)\n            inv_sigma_s = scipy.linalg.cho_solve(\n                (chol_sigma_s, lower_sigma_s), np.identity(self.features),\n                check_finite=False)\n\n            # Invert (Sigma_s + rho_0 * I) using Cholesky factorization\n            sigma_s_rhos = inv_sigma_s + np.identity(self.features) * rho0\n            (chol_sigma_s_rhos, lower_sigma_s_rhos) = scipy.linalg.cho_factor(\n                sigma_s_rhos, check_finite=False)\n            inv_sigma_s_rhos = scipy.linalg.cho_solve(\n                (chol_sigma_s_rhos, lower_sigma_s_rhos),\n                np.identity(self.features), check_finite=False)\n\n            # Compute the sum of W_i^T * rho_i^-2 * X_i, and the sum of traces\n            # of X_i^T * rho_i^-2 * X_i\n            wt_invpsi_x = np.zeros((self.features, samples))\n            trace_xt_invsigma2_x = 0.0\n            for subject in range(subjects):\n                wt_invpsi_x += (w[subject].T.dot(x[subject])) / rho2[subject]\n                trace_xt_invsigma2_x += trace_xtx[subject] / rho2[subject]\n\n            log_det_psi = np.sum(np.log(rho2) * voxels)\n\n            # Update the shared response\n            shared_response = sigma_s.dot(\n                np.identity(self.features) - rho0 * inv_sigma_s_rhos).dot(\n                    wt_invpsi_x)\n\n            # M-step\n\n            # Update Sigma_s and compute its trace\n            sigma_s = (inv_sigma_s_rhos\n                       + shared_response.dot(shared_response.T) / samples)\n            trace_sigma_s = samples * np.trace(sigma_s)\n\n            # Update each subject's mapping transform W_i and error variance\n            # rho_i^2\n            for subject in range(subjects):\n                a_subject = x[subject].dot(shared_response.T)\n                perturbation = np.zeros(a_subject.shape)\n                np.fill_diagonal(perturbation, 0.001)\n                u_subject, s_subject, v_subject = np.linalg.svd(\n                    a_subject + perturbation, full_matrices=False)\n                w[subject] = u_subject.dot(v_subject)\n                rho2[subject] = trace_xtx[subject]\n                rho2[subject] += -2 * np.sum(w[subject] * a_subject).sum()\n                rho2[subject] += trace_sigma_s\n                rho2[subject] /= samples * voxels[subject]\n\n            if logger.isEnabledFor(logging.INFO):\n                # Calculate and log the current log-likelihood for checking\n                # convergence\n                loglike = self._likelihood(\n                    chol_sigma_s_rhos, log_det_psi, chol_sigma_s,\n                    trace_xt_invsigma2_x, inv_sigma_s_rhos, wt_invpsi_x,\n                    samples)\n                logger.info('Objective function %f' % loglike)\n\n        return sigma_s, w, mu, rho2, shared_response", "response": "Expectation - Maximization algorithm for fitting the probabilistic SRM."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the Deterministic Shared Response Model for a set of subject - level data sets.", "response": "def fit(self, X, y=None):\n        \"\"\"Compute the Deterministic Shared Response Model\n\n        Parameters\n        ----------\n        X : list of 2D arrays, element i has shape=[voxels_i, samples]\n            Each element in the list contains the fMRI data of one subject.\n\n        y : not used\n        \"\"\"\n        logger.info('Starting Deterministic SRM')\n\n        # Check the number of subjects\n        if len(X) <= 1:\n            raise ValueError(\"There are not enough subjects \"\n                             \"({0:d}) to train the model.\".format(len(X)))\n\n        # Check for input data sizes\n        if X[0].shape[1] < self.features:\n            raise ValueError(\n                \"There are not enough samples to train the model with \"\n                \"{0:d} features.\".format(self.features))\n\n        # Check if all subjects have same number of TRs\n        number_trs = X[0].shape[1]\n        number_subjects = len(X)\n        for subject in range(number_subjects):\n            assert_all_finite(X[subject])\n            if X[subject].shape[1] != number_trs:\n                raise ValueError(\"Different number of samples between subjects\"\n                                 \".\")\n\n        # Run SRM\n        self.w_, self.s_ = self._srm(X)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the objective function for the record set.", "response": "def _objective_function(self, data, w, s):\n        \"\"\"Calculate the objective function\n\n        Parameters\n        ----------\n\n        data : list of 2D arrays, element i has shape=[voxels_i, samples]\n            Each element in the list contains the fMRI data of one subject.\n\n        w : list of 2D arrays, element i has shape=[voxels_i, features]\n            The orthogonal transforms (mappings) :math:`W_i` for each subject.\n\n        s : array, shape=[features, samples]\n            The shared response\n\n        Returns\n        -------\n\n        objective : float\n            The objective function value.\n        \"\"\"\n        subjects = len(data)\n        objective = 0.0\n        for m in range(subjects):\n            objective += \\\n                np.linalg.norm(data[m] - w[m].dot(s), 'fro')**2\n\n        return objective * 0.5 / data[0].shape[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a list of text samples into a matrix using a vectorizer and a text model.", "response": "def text2mat(data, vectorizer='CountVectorizer',\n             semantic='LatentDirichletAllocation', corpus='wiki'):\n    \"\"\"\n    Turns a list of text samples into a matrix using a vectorizer and a text model\n\n    Parameters\n    ----------\n\n    data : list (or list of lists) of text samples\n        The text data to transform\n\n    vectorizer : str, dict, class or class instance\n        The vectorizer to use. Built-in options are 'CountVectorizer' or\n        'TfidfVectorizer'. To change default parameters, set to a dictionary\n        e.g. {'model' : 'CountVectorizer', 'params' : {'max_features' : 10}}. See\n        http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n        for details. You can also specify your own vectorizer model as a class,\n        or class instance.  With either option, the class must have a\n        fit_transform method (see here: http://scikit-learn.org/stable/data_transforms.html).\n        If a class, pass any parameters as a dictionary to vectorizer_params. If\n        a class instance, no parameters can be passed.\n\n    semantic : str, dict, class or class instance\n        Text model to use to transform text data. Built-in options are\n        'LatentDirichletAllocation' or 'NMF' (default: LDA). To change default\n        parameters, set to a dictionary e.g. {'model' : 'NMF', 'params' :\n        {'n_components' : 10}}. See\n        http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n        for details on the two model options. You can also specify your own\n        text model as a class, or class instance.  With either option, the class\n        must have a fit_transform method (see here:\n        http://scikit-learn.org/stable/data_transforms.html).\n        If a class, pass any parameters as a dictionary to text_params. If\n        a class instance, no parameters can be passed.\n\n    corpus : list (or list of lists) of text samples or 'wiki', 'nips', 'sotus'.\n         Text to use to fit the semantic model (optional). If set to 'wiki', 'nips'\n         or 'sotus' and the default semantic and vectorizer models are used, a\n         pretrained model will be loaded which can save a lot of time.\n\n    Returns\n    ----------\n\n    transformed data : list of numpy arrays\n        The transformed text data\n    \"\"\"\n    if semantic is None:\n        semantic = 'LatentDirichletAllocation'\n    if vectorizer is None:\n        vectorizer = 'CountVectorizer'\n    model_is_fit=False\n    if corpus is not None:\n        if corpus in ('wiki', 'nips', 'sotus',):\n            if semantic == 'LatentDirichletAllocation' and vectorizer == 'CountVectorizer':\n                semantic = load(corpus + '_model')\n                vectorizer = None\n                model_is_fit = True\n            else:\n                corpus = np.array(load(corpus).get_data())\n        else:\n            corpus = np.array([corpus])\n\n    vtype = _check_mtype(vectorizer)\n    if vtype == 'str':\n        vectorizer_params = default_params(vectorizer)\n    elif vtype == 'dict':\n        vectorizer_params = default_params(vectorizer['model'], vectorizer['params'])\n        vectorizer = vectorizer['model']\n    elif vtype in ('class', 'class_instance'):\n        if hasattr(vectorizer, 'fit_transform'):\n            vectorizer_models.update({'user_model' : vectorizer})\n            vectorizer = 'user_model'\n        else:\n            raise RuntimeError('Error: Vectorizer model must have fit_transform '\n                               'method following the scikit-learn API. See here '\n                               'for more details: '\n                               'http://scikit-learn.org/stable/data_transforms.html')\n    ttype = _check_mtype(semantic)\n    if ttype == 'str':\n        text_params = default_params(semantic)\n    elif ttype == 'dict':\n        text_params = default_params(semantic['model'], semantic['params'])\n        semantic = semantic['model']\n    elif ttype in ('class', 'class_instance'):\n        if hasattr(semantic, 'fit_transform'):\n            texts.update({'user_model' : semantic})\n            semantic = 'user_model'\n        else:\n            raise RuntimeError('Text model must have fit_transform '\n                               'method following the scikit-learn API. See here '\n                               'for more details: '\n                               'http://scikit-learn.org/stable/data_transforms.html')\n    if vectorizer:\n        if vtype in ('str', 'dict'):\n            vmodel = vectorizer_models[vectorizer](**vectorizer_params)\n        elif vtype == 'class':\n            vmodel = vectorizer_models[vectorizer]()\n        elif vtype == 'class_instance':\n            vmodel = vectorizer_models[vectorizer]\n    else:\n        vmodel = None\n\n    if semantic:\n        if ttype in ('str', 'dict'):\n            tmodel = texts[semantic](**text_params)\n        elif ttype == 'class':\n            tmodel = texts[semantic]()\n        elif ttype == 'class_instance':\n            tmodel = texts[semantic]\n    else:\n        tmodel = None\n\n    if not isinstance(data, list):\n        data = [data]\n\n    if corpus is None:\n        _fit_models(vmodel, tmodel, data, model_is_fit)\n    else:\n        _fit_models(vmodel, tmodel, corpus, model_is_fit)\n\n    return _transform(vmodel, tmodel, data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping values to colors in the Seaborn", "response": "def vals2colors(vals,cmap='GnBu_d',res=100):\n    \"\"\"Maps values to colors\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    cmap (str) - color map (default is 'husl')\n    res (int) - resolution of the color map (default: 100)\n    Returns:\n    list of rgb tuples\n    \"\"\"\n    # flatten if list of lists\n    if any(isinstance(el, list) for el in vals):\n        vals = list(itertools.chain(*vals))\n\n    # get palette from seaborn\n    palette = np.array(sns.color_palette(cmap, res))\n    ranks = np.digitize(vals, np.linspace(np.min(vals), np.max(vals)+1, res+1)) - 1\n    return [tuple(i) for i in palette[ranks, :]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping values to bins in a", "response": "def vals2bins(vals,res=100):\n    \"\"\"Maps values to bins\n    Args:\n    values (list or list of lists) - list of values to map to colors\n    res (int) - resolution of the color map (default: 100)\n    Returns:\n    list of numbers representing bins\n    \"\"\"\n    # flatten if list of lists\n    if any(isinstance(el, list) for el in vals):\n        vals = list(itertools.chain(*vals))\n    return list(np.digitize(vals, np.linspace(np.min(vals), np.max(vals)+1, res+1)) - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npatch lines between groups", "response": "def patch_lines(x):\n    \"\"\"\n    Draw lines between groups\n    \"\"\"\n    for idx in range(len(x)-1):\n        x[idx] = np.vstack([x[idx], x[idx+1][0,:]])\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_type(data):\n    import six\n    from ..datageometry import DataGeometry\n\n    if isinstance(data, list):\n        if isinstance(data[0], (six.string_types, six.text_type, six.binary_type)):\n            return 'list_str'\n        elif isinstance(data[0], (int, float)):\n            return 'list_num'\n        elif isinstance(data[0], np.ndarray):\n            return 'list_arr'\n        else:\n            raise TypeError('Unsupported data type passed. Supported types: '\n                            'Numpy Array, Pandas DataFrame, String, List of strings'\n                            ', List of numbers')\n    elif isinstance(data, np.ndarray):\n        if isinstance(data[0][0], (six.string_types, six.text_type, six.binary_type)):\n            return 'arr_str'\n        else:\n            return 'arr_num'\n    elif isinstance(data, pd.DataFrame):\n        return 'df'\n    elif isinstance(data, (six.string_types, six.text_type, six.binary_type)):\n        return 'str'\n    elif isinstance(data, DataGeometry):\n        return 'geo'\n    else:\n        raise TypeError('Unsupported data type passed. Supported types: '\n                        'Numpy Array, Pandas DataFrame, String, List of strings'\n                        ', List of numbers')", "response": "Checks what the data type is and returns it as a string label\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks a geo and makes sure the text fields are not binary", "response": "def check_geo(geo):\n    \"\"\" Checks a geo and makes sure the text fields are not binary \"\"\"\n    geo = copy.copy(geo)\n\n    def fix_item(item):\n        if isinstance(item, six.binary_type):\n            return item.decode()\n        return item\n\n    def fix_list(lst):\n        return [fix_item(i) for i in lst]\n    if isinstance(geo.reduce, six.binary_type):\n        geo.reduce = geo.reduce.decode()\n    for key in geo.kwargs.keys():\n        if geo.kwargs[key] is not None:\n            if isinstance(geo.kwargs[key], (list, np.ndarray)):\n                geo.kwargs[key] = fix_list(geo.kwargs[key])\n            elif isinstance(geo.kwargs[key], six.binary_type):\n                geo.kwargs[key] = fix_item(geo.kwargs[key])\n    return geo"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dtype(data):\n    import six\n    from ..datageometry import DataGeometry\n\n    if isinstance(data, list):\n        return 'list'\n    elif isinstance(data, np.ndarray):\n        return 'arr'\n    elif isinstance(data, pd.DataFrame):\n        return 'df'\n    elif isinstance(data, (six.string_types, six.text_type, six.binary_type)):\n        return 'str'\n    elif isinstance(data, DataGeometry):\n        return 'geo'\n    else:\n        raise TypeError('Unsupported data type passed. Supported types: '\n                        'Numpy Array, Pandas DataFrame, String, List of strings'\n                        ', List of numbers')", "response": "Checks what the data type is and returns it as a string label\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef df2mat(data, return_labels=False):\n\n    df_str = data.select_dtypes(include=['object'])\n    df_num = data.select_dtypes(exclude=['object'])\n\n    for colname in df_str.columns:\n        df_num = df_num.join(pd.get_dummies(data[colname], prefix=colname))\n\n    plot_data = df_num.as_matrix()\n\n    labels=list(df_num.columns.values)\n\n    if return_labels:\n        return plot_data,labels\n    else:\n        return plot_data", "response": "Transforms a Pandas DataFrame into a Numpy array with binarized text columns."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction to plot a reduced data set into a single node.", "response": "def plot(x, fmt='-', marker=None, markers=None, linestyle=None, linestyles=None,\n         color=None, colors=None, palette='hls', group=None, hue=None,\n         labels=None, legend=None, title=None, size=None, elev=10, azim=-60,\n         ndims=3, model=None, model_params=None, reduce='IncrementalPCA',\n         cluster=None, align=None, normalize=None, n_clusters=None,\n         save_path=None, animate=False, duration=30, tail_duration=2,\n         rotations=2, zoom=1, chemtrails=False, precog=False, bullettime=False,\n         frame_rate=50, explore=False, show=True, transform=None,\n         vectorizer='CountVectorizer', semantic='LatentDirichletAllocation',\n         corpus='wiki', ax=None):\n    \"\"\"\n    Plots dimensionality reduced data and parses plot arguments\n\n    Parameters\n    ----------\n    x : Numpy array, DataFrame, String, Geo or mixed list\n        Data for the plot. The form should be samples (rows) by features (cols).\n\n    fmt : str or list of strings\n        A list of format strings.  All matplotlib format strings are supported.\n\n    linestyle(s) : str or list of str\n        A list of line styles\n\n    marker(s) : str or list of str\n        A list of marker types\n\n    color(s) : str or list of str\n        A list of marker types\n\n    palette : str\n        A matplotlib or seaborn color palette\n\n    group : str/int/float or list\n        A list of group labels. Length must match the number of rows in your\n        dataset. If the data type is numerical, the values will be mapped to\n        rgb values in the specified palette. If the data type is strings,\n        the points will be labeled categorically. To label a subset of points,\n        use None (i.e. ['a', None, 'b','a']).\n\n    labels : list\n        A list of labels for each point. Must be dimensionality of data (x).\n        If no label is wanted for a particular point, input None.\n\n    legend : list or bool\n        If set to True, legend is implicitly computed from data. Passing a\n        list will add string labels to the legend (one for each list item).\n\n    title : str\n        A title for the plot\n\n    size : list\n        A list of [width, height] in inches to resize the figure\n\n    normalize : str or False\n        If set to 'across', the columns of the input data will be z-scored\n        across lists (default). If set to 'within', the columns will be\n        z-scored within each list that is passed. If set to 'row', each row of\n        the input data will be z-scored. If set to False, the input data will\n        be returned (default is False).\n\n    reduce : str or dict\n        Decomposition/manifold learning model to use.  Models supported: PCA,\n        IncrementalPCA, SparsePCA, MiniBatchSparsePCA, KernelPCA, FastICA,\n        FactorAnalysis, TruncatedSVD, DictionaryLearning, MiniBatchDictionaryLearning,\n        TSNE, Isomap, SpectralEmbedding, LocallyLinearEmbedding, and MDS. Can be\n        passed as a string, but for finer control of the model parameters, pass\n        as a dictionary, e.g. reduce={'model' : 'PCA', 'params' : {'whiten' : True}}.\n        See scikit-learn specific model docs for details on parameters supported\n        for each model.\n\n    ndims : int\n        An `int` representing the number of dims to reduce the data x\n        to. If ndims > 3, will plot in 3 dimensions but return the higher\n        dimensional data. Default is None, which will plot data in 3\n        dimensions and return the data with the same number of dimensions\n        possibly normalized and/or aligned according to normalize/align\n        kwargs.\n\n    align : str or dict or False/None\n        If str, either 'hyper' or 'SRM'.  If 'hyper', alignment algorithm will be\n        hyperalignment. If 'SRM', alignment algorithm will be shared response\n        model.  You can also pass a dictionary for finer control, where the 'model'\n        key is a string that specifies the model and the params key is a dictionary\n        of parameter values (default : 'hyper').\n\n    cluster : str or dict or False/None\n        If cluster is passed, HyperTools will perform clustering using the\n        specified clustering clustering model. Supportted algorithms are:\n        KMeans, MiniBatchKMeans, AgglomerativeClustering, Birch,\n        FeatureAgglomeration, SpectralClustering and HDBSCAN (default: None).\n        Can be passed as a string, but for finer control of the model\n        parameters, pass as a dictionary, e.g.\n        reduce={'model' : 'KMeans', 'params' : {'max_iter' : 100}}. See\n        scikit-learn specific model docs for details on parameters supported for\n        each model. If no parameters are specified in the string a default set\n        of parameters will be used.\n\n    n_clusters : int\n        If n_clusters is passed, HyperTools will perform k-means clustering\n        with the k parameter set to n_clusters. The resulting clusters will\n        be plotted in different colors according to the color palette.\n\n    save_path : str\n        Path to save the image/movie. Must include the file extension in the\n        save path (i.e. save_path='/path/to/file/image.png'). NOTE: If saving\n        an animation, FFMPEG must be installed (this is a matplotlib req).\n        FFMPEG can be easily installed on a mac via homebrew brew install\n        ffmpeg or linux via apt-get apt-get install ffmpeg. If you don't\n        have homebrew (mac only), you can install it like this:\n        /usr/bin/ruby -e \"$(curl -fsSL\n        https://raw.githubusercontent.com/Homebrew/install/master/install)\".\n\n    animate : bool, 'parallel' or 'spin'\n        If True or 'parallel', plots the data as an animated trajectory, with\n        each dataset plotted simultaneously. If 'spin', all the data is plotted\n        at once but the camera spins around the plot (default: False).\n\n    duration (animation only) : float\n        Length of the animation in seconds (default: 30 seconds)\n\n    tail_duration (animation only) : float\n        Sets the length of the tail of the data (default: 2 seconds)\n\n    rotations (animation only) : float\n        Number of rotations around the box (default: 2)\n\n    zoom (animation only) : float\n        How far to zoom into the plot, positive numbers will zoom in (default: 0)\n\n    chemtrails (animation only) : bool\n        A low-opacity trail is left behind the trajectory (default: False).\n\n    precog (animation only) : bool\n        A low-opacity trail is plotted ahead of the trajectory (default: False).\n\n    bullettime (animation only) : bool\n        A low-opacity trail is plotted ahead and behind the trajectory\n        (default: False).\n\n    frame_rate (animation only) : int or float\n        Frame rate for animation (default: 50)\n\n    explore : bool\n        Displays user defined labels will appear on hover. If no labels are\n        passed, the point index and coordinate will be plotted. To use,\n        set explore=True. Note: Explore mode is currently only supported\n        for 3D static plots, and is an experimental feature (i.e it may not yet\n        work properly).\n\n    show : bool\n        If set to False, the figure will not be displayed, but the figure,\n        axis and data objects will still be returned (default: True).\n\n    transform : list of numpy arrays or None\n        The transformed data, bypasses transformations if this is set\n        (default : None).\n\n    vectorizer : str, dict, class or class instance\n        The vectorizer to use. Built-in options are 'CountVectorizer' or\n        'TfidfVectorizer'. To change default parameters, set to a dictionary\n        e.g. {'model' : 'CountVectorizer', 'params' : {'max_features' : 10}}. See\n        http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n        for details. You can also specify your own vectorizer model as a class,\n        or class instance.  With either option, the class must have a\n        fit_transform method (see here: http://scikit-learn.org/stable/data_transforms.html).\n        If a class, pass any parameters as a dictionary to vectorizer_params. If\n        a class instance, no parameters can be passed.\n\n    semantic : str, dict, class or class instance\n        Text model to use to transform text data. Built-in options are\n        'LatentDirichletAllocation' or 'NMF' (default: LDA). To change default\n        parameters, set to a dictionary e.g. {'model' : 'NMF', 'params' :\n        {'n_components' : 10}}. See\n        http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n        for details on the two model options. You can also specify your own\n        text model as a class, or class instance.  With either option, the class\n        must have a fit_transform method (see here:\n        http://scikit-learn.org/stable/data_transforms.html).\n        If a class, pass any parameters as a dictionary to text_params. If\n        a class instance, no parameters can be passed.\n\n    corpus : list (or list of lists) of text samples or 'wiki', 'nips', 'sotus'.\n         Text to use to fit the semantic model (optional). If set to 'wiki', 'nips'\n         or 'sotus' and the default semantic and vectorizer models are used, a\n         pretrained model will be loaded which can save a lot of time.\n\n    ax : matplotlib.Axes\n        Axis handle to plot the figure\n\n    Returns\n    ----------\n    geo : hypertools.DataGeometry\n        A new data geometry object\n\n    \"\"\"\n\n    # warnings for deprecated API args\n    if (model is not None) or (model_params is not None):\n        warnings.warn('Model and model_params arguments will be deprecated. Please use \\\n                      reduce keyword argument. See docs for details: http://hypertools.readthedocs.io/en/latest/hypertools.plot.html#hypertools.plot')\n        reduce = {}\n        reduce['model'] = model\n        reduce['params'] = model_params\n\n    if group is not None:\n        warnings.warn('Group will be deprecated. Please use '\n                      'hue keyword argument. See docs for details: ' 'http://hypertools.readthedocs.io/en/latest/hypertools.plot.html#hypertools.plot')\n        hue = group\n\n    if ax is not None:\n        if ndims>2:\n            if ax.name!='3d':\n                raise ValueError('If passing ax and the plot is 3D, ax must '\n                                 'also be 3d')\n\n    text_args = {\n        'vectorizer' : vectorizer,\n        'semantic' : semantic,\n        'corpus' : corpus\n    }\n\n    # analyze the data\n    if transform is None:\n        raw = format_data(x, **text_args)\n        xform = analyze(raw, ndims=ndims, normalize=normalize, reduce=reduce,\n                    align=align, internal=True)\n    else:\n        xform = transform\n\n    # Return data that has been normalized and possibly reduced and/or aligned\n    xform_data = copy.copy(xform)\n\n    # catch all matplotlib kwargs here to pass on\n    mpl_kwargs = {}\n\n    # handle color (to be passed onto matplotlib)\n    if color is not None:\n        mpl_kwargs['color'] = color\n        if colors is not None:\n            mpl_kwargs['color'] = colors\n            warnings.warn('Both color and colors defined: color will be ignored \\\n                          in favor of colors.')\n\n    # handle linestyle (to be passed onto matplotlib)\n    if linestyle is not None:\n        mpl_kwargs['linestyle'] = linestyle\n        if linestyles is not None:\n            mpl_kwargs['linestyle'] = linestyles\n            warnings.warn('Both linestyle and linestyles defined: linestyle  \\\n                          will be ignored in favor of linestyles.')\n\n    # handle marker (to be passed onto matplotlib)\n    if marker is not None:\n        mpl_kwargs['marker'] = marker\n        if markers is not None:\n            mpl_kwargs['marker'] = markers\n            warnings.warn('Both marker and markers defined: marker will be \\\n                          ignored in favor of markers.')\n\n    # reduce data to 3 dims for plotting, if ndims is None, return this\n    if (ndims and ndims < 3):\n        xform = reducer(xform, ndims=ndims, reduce=reduce, internal=True)\n    else:\n        xform = reducer(xform, ndims=3, reduce=reduce, internal=True)\n\n    # find cluster and reshape if n_clusters\n    if cluster is not None:\n        if hue is not None:\n            warnings.warn('cluster overrides hue, ignoring hue.')\n        if isinstance(cluster, (six.string_types, six.binary_type)):\n            model = cluster\n            params = default_params(model)\n        elif isinstance(cluster, dict):\n            model = cluster['model']\n            params = default_params(model, cluster['params'])\n        else:\n            raise ValueError('Invalid cluster model specified; should be'\n                             ' string or dictionary!')\n\n        if n_clusters is not None:\n            if cluster in ('HDBSCAN',):\n                warnings.warn('n_clusters is not a valid parameter for '\n                              'HDBSCAN clustering and will be ignored.')\n            else:\n                params['n_clusters'] = n_clusters\n\n        cluster_labels = clusterer(xform, cluster={'model': model,\n                                               'params': params})\n        xform, labels = reshape_data(xform, cluster_labels, labels)\n        hue = cluster_labels\n\n    elif n_clusters is not None:\n        # If cluster was None default to KMeans\n        cluster_labels = clusterer(xform, cluster='KMeans', n_clusters=n_clusters)\n        xform, labels = reshape_data(xform, cluster_labels, labels)\n        if hue is not None:\n            warnings.warn('n_clusters overrides hue, ignoring hue.')\n\n    # group data if there is a grouping var\n    elif hue is not None:\n        if color is not None:\n            warnings.warn(\"Using group, color keyword will be ignored.\")\n\n        # if list of lists, unpack\n        if any(isinstance(el, list) for el in hue):\n            hue = list(itertools.chain(*hue))\n\n        # if all of the elements are numbers, map them to colors\n        if all(isinstance(el, int) or isinstance(el, float) for el in hue):\n            hue = vals2bins(hue)\n        elif all(isinstance(el, str) for el in hue):\n            hue = group_by_category(hue)\n\n        # reshape the data according to group\n        if n_clusters is None:\n            xform, labels = reshape_data(xform, hue, labels)\n        # interpolate lines if they are grouped\n        if is_line(fmt):\n            xform = patch_lines(xform)\n\n    # handle legend\n    if legend is not None:\n        if legend is False:\n            legend = None\n        elif legend is True and hue is not None:\n            legend = [item for item in sorted(set(hue), key=list(hue).index)]\n        elif legend is True and hue is None:\n            legend = [i + 1 for i in range(len(xform))]\n\n        mpl_kwargs['label'] = legend\n\n    # interpolate if its a line plot\n    if fmt is None or isinstance(fmt, six.string_types):\n        if is_line(fmt):\n            if xform[0].shape[0] > 1:\n                xform = interp_array_list(xform, interp_val=frame_rate*duration/(xform[0].shape[0] - 1))\n    elif type(fmt) is list:\n        for idx, xi in enumerate(xform):\n            if is_line(fmt[idx]):\n                if xi.shape[0] > 1:\n                    xform[idx] = interp_array_list(xi, interp_val=frame_rate*duration/(xi.shape[0] - 1))\n\n    # handle explore flag\n    if explore:\n        assert xform[0].shape[1] is 3, \"Explore mode is currently only supported for 3D plots.\"\n        mpl_kwargs['picker']=True\n\n    # center\n    xform = center(xform)\n\n    # scale\n    xform = scale(xform)\n\n    # handle palette with seaborn\n    if isinstance(palette, np.bytes_):\n        palette = palette.decode(\"utf-8\")\n    sns.set_palette(palette=palette, n_colors=len(xform))\n    sns.set_style(style='whitegrid')\n\n    # turn kwargs into a list\n    kwargs_list = parse_kwargs(xform, mpl_kwargs)\n\n    # handle format strings\n    if fmt is not None:\n        if type(fmt) is not list:\n            draw_fmt = [fmt for i in xform]\n        else:\n            draw_fmt = fmt\n    else:\n        draw_fmt = ['-']*len(x)\n\n    # convert all nans to zeros\n    for i, xi in enumerate(xform):\n        xform[i] = np.nan_to_num(xi)\n\n    # draw the plot\n    fig, ax, data, line_ani = _draw(xform, fmt=draw_fmt,\n                            kwargs_list=kwargs_list,\n                            labels=labels,\n                            legend=legend,\n                            title=title,\n                            animate=animate,\n                            duration=duration,\n                            tail_duration=tail_duration,\n                            rotations=rotations,\n                            zoom=zoom,\n                            chemtrails=chemtrails,\n                            precog=precog,\n                            bullettime=bullettime,\n                            frame_rate=frame_rate,\n                            elev=elev,\n                            azim=azim,\n                            explore=explore,\n                            show=show,\n                            size=size,\n                            ax=ax)\n\n    # tighten layout\n    plt.tight_layout()\n\n    # save\n    if save_path is not None:\n        if animate:\n            Writer = animation.writers['ffmpeg']\n            writer = Writer(fps=frame_rate, bitrate=1800)\n            line_ani.save(save_path, writer=writer)\n\n        else:\n            plt.savefig(save_path)\n\n    # show the plot\n    if show:\n        plt.show()\n    else:\n        # safely closes the plot so it doesn't pop up in another call to this function\n        plt.close('all')\n\n    # gather reduce params\n    if isinstance(reduce, dict):\n        reduce_dict = reduce\n    else:\n        reduce_dict = {\n            'model' : reduce,\n            'params' : {\n                'n_components' : ndims\n            },\n        }\n\n    # gather align params\n    if isinstance(align, dict):\n        align_dict = align\n    else:\n        align_dict = {\n            'model' : align,\n            'params' : {}\n        }\n\n    # gather all other kwargs\n    kwargs = {\n        'fmt' : fmt,\n        'marker': marker,\n        'markers' : markers,\n        'linestyle' : linestyle,\n        'linestyles' : linestyles,\n        'color' : color,\n        'colors' : colors,\n        'palette' : palette,\n        'hue' : hue,\n        'ndims' : ndims,\n        'labels' : labels,\n        'legend' : legend,\n        'title' : title,\n        'animate' : animate,\n        'duration' : duration,\n        'tail_duration' : tail_duration,\n        'rotations' : rotations,\n        'zoom' : zoom,\n        'chemtrails' : chemtrails,\n        'precog' : precog,\n        'bullettime' : bullettime,\n        'frame_rate' : frame_rate,\n        'elev' : elev,\n        'azim' : azim,\n        'explore' : explore,\n        'n_clusters' : n_clusters,\n        'size' : size\n    }\n    # turn lists into np arrays so that they don't turn into pickles when saved\n    for kwarg in kwargs:\n        if isinstance(kwargs[kwarg], list):\n            try:\n                kwargs[kwarg]=np.array(kwargs[kwarg])\n            except:\n                warnings.warn('Could not convert all list arguments to numpy '\n                              'arrays.  If list is longer than 256 items, it '\n                              'will automatically be pickled, which could '\n                              'cause Python 2/3 compatibility issues for the '\n                              'DataGeometry object.')\n\n    return DataGeometry(fig=fig, ax=ax, data=x, xform_data=xform_data,\n                        line_ani=line_ani, reduce=reduce_dict, align=align_dict,\n                        normalize=normalize, semantic=semantic,\n                        vectorizer=vectorizer, corpus=corpus, kwargs=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef align(data, align='hyper', normalize=None, ndims=None, method=None,\n          format_data=True):\n    \"\"\"\n    Aligns a list of arrays\n\n    This function takes a list of high dimensional arrays and 'hyperaligns' them\n    to a 'common' space, or coordinate system following the approach outlined by\n    Haxby et al, 2011. Hyperalignment uses linear transformations (rotation,\n    reflection, translation, scaling) to register a group of arrays to a common\n    space. This can be useful when two or more datasets describe an identical\n    or similar system, but may not be in same coordinate system. For example,\n    consider the example of fMRI recordings (voxels by time) from the visual\n    cortex of a group of subjects watching the same movie: The brain responses\n    should be highly similar, but the coordinates may not be aligned.\n\n    Haxby JV, Guntupalli JS, Connolly AC, Halchenko YO, Conroy BR, Gobbini\n    MI, Hanke M, and Ramadge PJ (2011)  A common, high-dimensional model of\n    the representational space in human ventral temporal cortex.  Neuron 72,\n    404 -- 416. (used to implement hyperalignment, see https://github.com/PyMVPA/PyMVPA)\n\n    Brain Imaging Analysis Kit, http://brainiak.org. (used to implement Shared Response Model [SRM], see https://github.com/IntelPNI/brainiak)\n\n    Parameters\n    ----------\n    data : numpy array, pandas df, or list of arrays/dfs\n        A list of Numpy arrays or Pandas Dataframes\n\n    align : str or dict\n        If str, either 'hyper' or 'SRM'.  If 'hyper', alignment algorithm will be\n        hyperalignment. If 'SRM', alignment algorithm will be shared response\n        model.  You can also pass a dictionary for finer control, where the 'model'\n        key is a string that specifies the model and the params key is a dictionary\n        of parameter values (default : 'hyper').\n\n    format_data : bool\n        Whether or not to first call the format_data function (default: True).\n\n    normalize : None\n        Deprecated argument.  Please use new analyze function to perform\n        combinations of transformations\n\n    ndims : None\n        Deprecated argument.  Please use new analyze function to perform\n        combinations of transformations\n\n    Returns\n    ----------\n    aligned : list\n        An aligned list of numpy arrays\n\n    \"\"\"\n\n    # if model is None, just return data\n    if align is None:\n        return data\n    elif isinstance(align, dict):\n        if align['model'] is None:\n            return data\n    else:\n        if method is not None:\n            warnings.warn('The method argument will be deprecated.  Please use align. See the API docs for more info: http://hypertools.readthedocs.io/en/latest/hypertools.tools.align.html#hypertools.tools.align')\n            align = method\n\n        if align is True:\n            warnings.warn(\"Setting align=True will be deprecated.  Please specify the \\\n                          type of alignment, i.e. align='hyper'. See API docs for more info: http://hypertools.readthedocs.io/en/latest/hypertools.tools.align.html#hypertools.tools.align\")\n            align = 'hyper'\n\n        # common format\n        if format_data:\n            data = formatter(data, ppca=True)\n\n        if len(data) is 1:\n            warnings.warn('Data in list of length 1 can not be aligned. '\n                 'Skipping the alignment.')\n\n        if data[0].shape[1] >= data[0].shape[0]:\n            warnings.warn('The number of features exceeds number of samples. This can lead \\\n                 to overfitting.  We recommend reducing the dimensionality to be \\\n                 less than the number of samples prior to hyperalignment.')\n\n        if (align == 'hyper') or (method == 'hyper'):\n\n            ##STEP 0: STANDARDIZE SIZE AND SHAPE##\n            sizes_0 = [x.shape[0] for x in data]\n            sizes_1 = [x.shape[1] for x in data]\n\n            #find the smallest number of rows\n            R = min(sizes_0)\n            C = max(sizes_1)\n\n            m = [np.empty((R,C), dtype=np.ndarray)] * len(data)\n\n            for idx,x in enumerate(data):\n                y = x[0:R,:]\n                missing = C - y.shape[1]\n                add = np.zeros((y.shape[0], missing))\n                y = np.append(y, add, axis=1)\n                m[idx]=y\n\n            ##STEP 1: TEMPLATE##\n            for x in range(0, len(m)):\n                if x==0:\n                    template = np.copy(m[x])\n                else:\n                    next = procrustes(m[x], template / (x + 1))\n                    template += next\n            template /= len(m)\n\n            ##STEP 2: NEW COMMON TEMPLATE##\n            #align each subj to the template from STEP 1\n            template2 = np.zeros(template.shape)\n            for x in range(0, len(m)):\n                next = procrustes(m[x], template)\n                template2 += next\n            template2 /= len(m)\n\n            #STEP 3 (below): ALIGN TO NEW TEMPLATE\n            aligned = [np.zeros(template2.shape)] * len(m)\n            for x in range(0, len(m)):\n                next = procrustes(m[x], template2)\n                aligned[x] = next\n            return aligned\n\n        elif (align == 'SRM') or (method == 'SRM'):\n            data = [i.T for i in data]\n            srm = SRM(features=np.min([i.shape[0] for i in data]))\n            fit = srm.fit(data)\n            return [i.T for i in srm.transform(data)]", "response": "Aligns a list of arrays to a common space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing the internal plot of the internal data structure.", "response": "def _draw(x, legend=None, title=None, labels=False,\n         show=True, kwargs_list=None, fmt=None, animate=False,\n         tail_duration=2, rotations=2, zoom=1, chemtrails=False, precog=False,\n         bullettime=False, frame_rate=50, elev=10, azim=-60, duration=30,\n         explore=False, size=None, ax=None):\n    \"\"\"\n    Draws the plot\n    \"\"\"\n    # handle static plots\n    def dispatch_static(x, ax=None):\n        shape = x[0].shape[1]\n        if shape==3:\n            opts = dict(projection='3d')\n        else:\n            opts = dict()\n        if not ax:\n            fig = plt.figure()\n            ax = fig.add_subplot(111, **opts)\n        else:\n            fig = ax.figure\n        if x[0].ndim==1 or x[0].shape[-1]==1:\n            return plot1D(x, fig, ax)\n        elif x[0].shape[-1]==2:\n            return plot2D(x, fig, ax)\n        elif x[0].shape[-1]==3:\n            return plot3D(x, fig, ax)\n\n    # plot data in 1D\n    def plot1D(data, fig, ax):\n        n=len(data)\n        for i in range(n):\n            ikwargs = kwargs_list[i]\n            if fmt is None:\n                ax.plot(data[i][:,0], **ikwargs)\n            else:\n                ax.plot(data[i][:,0], fmt[i], **ikwargs)\n        return fig, ax, data\n\n    # plot data in 2D\n    def plot2D(data, fig, ax):\n        n=len(data)\n        for i in range(n):\n            ikwargs = kwargs_list[i]\n            if fmt is None:\n                ax.plot(data[i][:,0], data[i][:,1], **ikwargs)\n            else:\n                ax.plot(data[i][:,0], data[i][:,1], fmt[i], **ikwargs)\n        return fig, ax, data\n\n    # plot data in 3D\n    def plot3D(data, fig, ax):\n        n=len(data)\n        for i in range(n):\n            ikwargs = kwargs_list[i]\n            if fmt is None:\n                ax.plot(data[i][:,0], data[i][:,1], data[i][:,2], **ikwargs)\n            else:\n                ax.plot(data[i][:,0], data[i][:,1], data[i][:,2], fmt[i], **ikwargs)\n        return fig, ax, data\n\n    def annotate_plot(data, labels):\n        \"\"\"Create labels in 3d chart\n        Args:\n            X (np.array) - array of points, of shape (numPoints, 3)\n            labels (list) - list of labels of shape (numPoints,1)\n        Returns:\n            None\n        \"\"\"\n\n        global labels_and_points\n        labels_and_points = []\n\n        if data[0].shape[-1]>2:\n            proj = ax.get_proj()\n\n        for idx,x in enumerate(data):\n            if labels[idx] is not None:\n                if data[0].shape[-1]>2:\n                    x2, y2, _ = proj3d.proj_transform(x[0], x[1], x[2], proj)\n                    label = plt.annotate(\n                    labels[idx],\n                    xy = (x2, y2), xytext = (-20, 20), textcoords = 'offset points', ha = 'right', va = 'bottom',\n                    bbox = dict(boxstyle = 'round,pad=0.5', fc = 'white', alpha = 0.5),\n                    arrowprops = dict(arrowstyle = '-', connectionstyle = 'arc3,rad=0'),family='serif')\n                    labels_and_points.append((label,x[0],x[1],x[2]))\n                elif data[0].shape[-1]==2:\n                    x2, y2 = x[0], x[1]\n                    label = plt.annotate(\n                    labels[idx],\n                    xy = (x2, y2), xytext = (-20, 20), textcoords = 'offset points', ha = 'right', va = 'bottom',\n                    bbox = dict(boxstyle = 'round,pad=0.5', fc = 'white', alpha = 0.5),\n                    arrowprops = dict(arrowstyle = '-', connectionstyle = 'arc3,rad=0'),family='serif')\n                    label.draggable()\n                    labels_and_points.append((label,x[0],x[1]))\n        fig.canvas.draw()\n\n    def update_position(e):\n        \"\"\"Update label positions in 3d chart\n        Args:\n            e (mouse event) - event handle to update on\n        Returns:\n            None\n        \"\"\"\n\n        proj = ax.get_proj()\n        for label, x, y, z in labels_and_points:\n            x2, y2, _ = proj3d.proj_transform(x, y, z, proj)\n            label.xy = x2,y2\n            label.update_positions(fig.canvas.renderer)\n            label._visible=True\n        fig.canvas.draw()\n\n    def hide_labels(e):\n        \"\"\"Hides labels on button press\n        Args:\n            e (mouse event) - event handle to update on\n        Returns:\n            None\n        \"\"\"\n\n        for label in labels_and_points:\n            label[0]._visible=False\n\n    def add_labels(x, labels, explore=False):\n        \"\"\"Add labels to graph if available\n        Args:\n            data (np.ndarray) - Array containing the data points\n            labels (list) - List containing labels\n        Returns:\n            None\n        \"\"\"\n        # if explore mode is activated, implement the on hover behavior\n        if explore:\n            X = np.vstack(x)\n            if labels is not None:\n                if any(isinstance(el, list) for el in labels):\n                    labels = list(itertools.chain(*labels))\n                fig.canvas.mpl_connect('motion_notify_event', lambda event: onMouseMotion(event, X, labels)) # on mouse motion\n                # fig.canvas.mpl_connect('button_press_event', lambda event: onMouseClick(event, X, labels))  # on mouse click\n            else:\n                fig.canvas.mpl_connect('motion_notify_event', lambda event: onMouseMotion(event, X)) # on mouse motion\n                # fig.canvas.mpl_connect('button_press_event', lambda event: onMouseClick(event, X, labels))  # on mouse click\n\n        elif labels is not None:\n            X = np.vstack(x)\n            if any(isinstance(el, list) for el in labels):\n                labels = list(itertools.chain(*labels))\n            annotate_plot(X, labels)\n            fig.canvas.mpl_connect('button_press_event', hide_labels)\n            fig.canvas.mpl_connect('button_release_event', update_position)\n\n    ##EXPLORE MODE##\n    def distance(point, event):\n        \"\"\"Return distance between mouse position and given data point\n\n        Args:\n            point (np.array) -  np.array of shape (3,), with x,y,z in data coords\n            event (MouseEvent) - mouse event (which contains mouse position in .x and .xdata)\n        Returns:\n            distance (np.float64) - distance (in screen coords) between mouse pos and data point\n        \"\"\"\n        assert point.shape == (3,), \"distance: point.shape is wrong: %s, must be (3,)\" % point.shape\n\n        # Project 3d data space to 2d data space\n        x2, y2, _ = proj3d.proj_transform(point[0], point[1], point[2], plt.gca().get_proj())\n        # Convert 2d data space to 2d screen space\n        x3, y3 = ax.transData.transform((x2, y2))\n\n        return np.sqrt ((x3 - event.x)**2 + (y3 - event.y)**2)\n\n    def calcClosestDatapoint(X, event):\n        \"\"\"\"Calculate which data point is closest to the mouse position.\n\n        Args:\n            X (np.array) - array of points, of shape (numPoints, 3)\n            event (MouseEvent) - mouse event (containing mouse position)\n        Returns:\n            smallestIndex (int) - the index (into the array of points X) of the element closest to the mouse position\n        \"\"\"\n\n        distances = [distance (X[i, 0:3], event) for i in range(X.shape[0])]\n        return np.argmin(distances)\n\n    def annotate_plot_explore(X, index, labels=False):\n        \"\"\"Create popover label in 3d chart\n\n        Args:\n            X (np.array) - array of points, of shape (numPoints, 3)\n            index (int) - index (into points array X) of item which should be printed\n            labels (list or False) - list of data point labels (default is False)\n        Returns:\n            None\n        \"\"\"\n\n        # save clicked points\n        if not hasattr(annotate_plot_explore, 'clicked'):\n            annotate_plot_explore.clicked = []\n\n        # If we have previously displayed another label, remove it first\n        if hasattr(annotate_plot_explore, 'label'):\n            if index not in annotate_plot_explore.clicked:\n                annotate_plot_explore.label.remove()\n\n        # Get data point from array of points X, at position index\n        x2, y2, _ = proj3d.proj_transform(X[index, 0], X[index, 1], X[index, 2], ax.get_proj())\n\n        if type(labels) is list:\n            label = labels[index]\n        else:\n            label = \"Index \" + str(index) + \": (\" + \"{0:.2f}, \".format(X[index, 0]) + \"{0:.2f}, \".format(X[index, 1]) + \"{0:.2f}\".format(X[index, 2]) + \")\"\n\n        annotate_plot_explore.label = plt.annotate(\n        label,\n        xy = (x2, y2), xytext = (-20, 20), textcoords = 'offset points', ha = 'right', va = 'bottom',\n        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n        fig.canvas.draw()\n\n    def onMouseMotion(event,X,labels=False):\n        \"\"\"Event that is triggered when mouse is moved. Shows text annotation over data point closest to mouse\n        Args:\n            event (event) - event triggered when the mous is moved\n            X (np.ndarray) - coordinates by datapoints matrix\n            labels (list or False) - list of data labels (default is False)\n        Returns:\n            None\n        \"\"\"\n\n        closestIndex = calcClosestDatapoint(X, event)\n\n        if hasattr(onMouseMotion, 'first'):\n            pass\n        else:\n            onMouseMotion.first = False\n            onMouseMotion.closestIndex_prev = calcClosestDatapoint(X, event)\n\n        if closestIndex!=onMouseMotion.closestIndex_prev:\n            if type(labels) is list:\n                annotate_plot_explore (X, closestIndex, labels)\n                closestIndex_prev = closestIndex\n            else:\n                annotate_plot_explore (X, closestIndex)\n                closestIndex_prev = closestIndex\n\n    def plot_cube(scale):\n        cube = {\n            \"top\"    : ( [[-1,1],[-1,1]], [[-1,-1],[1,1]], [[1,1],[1,1]] ),\n            \"bottom\" : ( [[-1,1],[-1,1]], [[-1,-1],[1,1]], [[-1,-1],[-1,-1]] ),\n            \"left\"   : ( [[-1,-1],[-1,-1]], [[-1,1],[-1,1]], [[-1,-1],[1,1]] ),\n            \"right\"  : ( [[1,1],[1,1]], [[-1,1],[-1,1]], [[-1,-1],[1,1]] ),\n            \"front\"  : ( [[-1,1],[-1,1]], [[-1,-1],[-1,-1]], [[-1,-1],[1,1]] ),\n            \"back\"   : ( [[-1,1],[-1,1]], [[1,1],[1,1]], [[-1,-1],[1,1]] )\n            }\n\n        plane_list = []\n        for side in cube:\n            (Xs, Ys, Zs) = (\n                np.asarray(cube[side][0])*scale,\n                np.asarray(cube[side][1])*scale,\n                np.asarray(cube[side][2])*scale\n                )\n            plane_list.append(ax.plot_wireframe(Xs, Ys, Zs, rstride=1, cstride=1, color='black', linewidth=1))\n        return plane_list\n\n    def plot_square(ax, scale=1):\n        ax.add_patch(patches.Rectangle(scale*[-1, -1], scale*2, scale*2, fill=False, edgecolor='black', linewidth=1))\n\n    def update_lines_parallel(num, data_lines, lines, trail_lines, cube_scale, tail_duration=2,\n                     rotations=2, zoom=1, chemtrails=False, elev=10):\n\n        if hasattr(update_lines_parallel, 'planes'):\n            for plane in update_lines_parallel.planes:\n                plane.remove()\n\n        update_lines_parallel.planes = plot_cube(cube_scale)\n        ax.view_init(elev=10, azim=rotations*(360*(num/data_lines[0].shape[0])))\n        ax.dist=9-zoom\n\n        for line, data, trail in zip(lines, data_lines, trail_lines):\n\n            if (precog and chemtrails) or bullettime:\n                trail.set_data(data[:, 0:2].T)\n                trail.set_3d_properties(data[:, 2])\n            elif chemtrails:\n                trail.set_data(data[0:num-tail_duration + 1, 0:2].T)\n                trail.set_3d_properties(data[0:num-tail_duration + 1, 2])\n            elif precog:\n                trail.set_data(data[num+1:, 0:2].T)\n                trail.set_3d_properties(data[num+1:, 2])\n\n            if num<=tail_duration:\n                    line.set_data(data[0:num+1, 0:2].T)\n                    line.set_3d_properties(data[0:num+1, 2])\n            else:\n                line.set_data(data[num-tail_duration:num+1, 0:2].T)\n                line.set_3d_properties(data[num-tail_duration:num+1, 2])\n\n        return lines, trail_lines\n\n    # NOTE: We will include a serial animation version in a future release.  This\n    # commented code currently does not work\n\n    # def update_lines_serial(num, data_lines, lines, trail_lines, cube_scale, dataset_idx, plot_idx, tail_duration=2,\n    #                  rotations=2, zoom=1, chemtrails=False, elev=10):\n    #\n    #     if hasattr(update_lines_serial, 'planes'):\n    #         for plane in update_lines_serial.planes:\n    #             plane.remove()\n    #\n    #     update_lines_serial.planes = plot_cube(cube_scale)\n    #     ax.view_init(elev=10, azim=rotations*(360*(num/data_lines[0].shape[0])))\n    #     ax.dist=9-zoom\n    #\n    #     for idx, (line, data, trail) in enumerate(zip(lines, data_lines, trail_lines)):\n    #         if num<=tail_duration and idx is 0:\n    #                 line.set_data(data[0:int(plot_idx[num, idx])+1, 0:2].T)\n    #                 line.set_3d_properties(data[0:int(plot_idx[num, idx])+1, 2])\n    #         elif dataset_idx[num-tail_duration] >= idx:\n    #             line.set_data(data[int(plot_idx[num, idx])-tail_duration:int(plot_idx[num, idx])+1, 0:2].T)\n    #             line.set_3d_properties(data[int(plot_idx[num, idx])-tail_duration:int(plot_idx[num, idx])+1, 2])\n    #             if chemtrails:\n    #                 trail.set_data(data[0:int(plot_idx[num, idx]) + 1, 0:2].T)\n    #                 trail.set_3d_properties(data[0:int(plot_idx[num, idx]) + 1, 2])\n    #         if dataset_idx[num] > idx:\n    #             line.set_data(data[num-tail_duration:num+1, 0:2].T)\n    #             line.set_3d_properties(data[num-tail_duration:num+1, 2])\n    #             if chemtrails:\n    #                 trail.set_data(data[0:int(plot_idx[num, idx]) + 1, 0:2].T)\n    #                 trail.set_3d_properties(data[0:int(plot_idx[num, idx]) + 1, 2])\n    #\n    #     return lines, trail_lines\n\n    def update_lines_spin(num, data_lines, lines, cube_scale, rotations=2,\n                          zoom=1, elev=10):\n\n        if hasattr(update_lines_spin, 'planes'):\n            for plane in update_lines_spin.planes:\n                plane.remove()\n\n        update_lines_spin.planes = plot_cube(cube_scale)\n        ax.view_init(elev=elev, azim=rotations*(360*(num/(frame_rate*duration))))\n        ax.dist=9-zoom\n\n        for line, data in zip(lines, data_lines):\n            line.set_data(data[:, 0:2].T)\n            line.set_3d_properties(data[:, 2])\n\n        return lines\n\n    def dispatch_animate(x, ani_params):\n        if x[0].shape[1] is 3:\n            return animate_plot3D(x, **ani_params)\n\n    def animate_plot3D(x, tail_duration=2, rotations=2, zoom=1, chemtrails=False,\n                       frame_rate=50, elev=10, style='parallel'):\n\n        # inialize plot\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection='3d')\n\n        # create lines\n        if fmt is not None:\n            lines = [ax.plot(dat[0:1, 0], dat[0:1, 1], dat[0:1, 2], fmt[idx],\n                             linewidth=1, **kwargs_list[idx])[0] for idx,dat in enumerate(x)]\n            if is_line(fmt):\n                trail = [ax.plot(dat[0:1, 0], dat[0:1, 1], dat[0:1, 2], fmt[idx],\n                                 alpha=.3, linewidth=1, **kwargs_list[idx])[0] for idx, dat in enumerate(x)]\n        else:\n            lines = [ax.plot(dat[0:1, 0], dat[0:1, 1], dat[0:1, 2],\n                             linewidth=1, **kwargs_list[idx])[0] for idx,dat in enumerate(x)]\n            if is_line(fmt):\n                trail = [ax.plot(dat[0:1, 0], dat[0:1, 1], dat[0:1, 2],\n                                 alpha=.3, linewidth=1, **kwargs_list[idx])[0] for idx, dat in enumerate(x)]\n        if tail_duration==0:\n            tail_duration=1\n        else:\n            tail_duration = int(frame_rate*tail_duration)\n\n        # get line animation\n        if style in ['parallel', True]:\n            line_ani = animation.FuncAnimation(fig, update_lines_parallel, x[0].shape[0],\n                            fargs=(x, lines, trail, 1, tail_duration, rotations, zoom, chemtrails, elev),\n                            interval=1000/frame_rate, blit=False, repeat=False)\n        # elif style == 'serial':\n        #     dataset_idx = []\n        #     for idx, data in enumerate(x):\n        #         for i in range(data.shape[0]):\n        #             dataset_idx.append(idx)\n        #     plot_idx = np.empty((np.sum([data.shape[0] for data in x]), len(x))) * 0\n        #     start=int(0)\n        #     end=int(x[0].shape[0])\n        #     for idx, d in enumerate(x):\n        #         plot_idx[start:end,idx] = [int(i) for i in range(d.shape[0])]\n        #         plot_idx[end:,idx]=int(d.shape[0])\n        #         if idx+1 < len(x):\n        #             start+=int(d.shape[0])-tail_duration\n        #             end+=int(x[idx+1].shape[0])-tail_duration\n        #     line_ani = animation.FuncAnimation(fig, update_lines_serial, np.sum([i.shape[0] for i in x]),\n        #                     fargs=(x, lines, trail, 1, dataset_idx, plot_idx,\n        #                     tail_duration, rotations, zoom, chemtrails, elev),\n        #                     interval=1000/frame_rate, blit=False, repeat=False)\n        elif style == 'spin':\n            line_ani = animation.FuncAnimation(fig, update_lines_spin, frame_rate*duration,\n                            fargs=(x, lines, 1, rotations, zoom, elev),\n                            interval=1000/frame_rate, blit=False, repeat=False)\n\n        return fig, ax, x, line_ani\n\n    # if a single point, but formatted as a line, replace with a point\n    for i, (xi, fi) in enumerate(zip(x, fmt)):\n        if xi.shape[0]==1 and fi in ('-', ':', '--'):\n            fmt[i]='.'\n\n    if not show:\n        # prevents the backend from rendering this plot\n        plt.ioff()\n\n    if animate in [True, 'parallel', 'spin']:\n        assert x[0].shape[1] is 3, \"Animations are currently only supported for 3d plots.\"\n\n        # animation params\n        ani_params = dict(tail_duration=tail_duration,\n                          rotations=rotations,\n                          zoom=zoom,\n                          chemtrails=chemtrails,\n                          frame_rate=frame_rate,\n                          elev=elev,\n                          style=animate)\n\n        # dispatch animation\n        fig, ax, data, line_ani = dispatch_animate(x, ani_params)\n\n    else:\n\n        # dispatch static\n        fig, ax, data = dispatch_static(x, ax)\n\n        # if 3d, plot the cube\n        if x[0].shape[1] is 3:\n\n            # set cube scale\n            cube_scale = 1\n\n            # plot cube\n            plot_cube(cube_scale)\n\n            # set the axes properties\n            ax.set_xlim3d([-cube_scale, cube_scale])\n            ax.set_ylim3d([-cube_scale, cube_scale])\n            ax.set_zlim3d([-cube_scale, cube_scale])\n\n            # initialize the view\n            ax.view_init(elev=elev, azim=azim)\n\n        elif x[0].shape[1] is 2:\n\n            # plot square\n            plot_square(ax)\n\n            # set axes\n            ax.set_xlim(-1.1, 1.1)\n            ax.set_ylim(-1.1, 1.1)\n\n        # set line_ani to empty\n        line_ani = None\n\n    # remove axes\n    ax.set_axis_off()\n\n    # add labels\n    add_labels(x, labels, explore=explore)\n\n    # add title\n    if title is not None:\n        ax.set_title(title)\n\n    # add legend\n    if legend is not None:\n        ax.legend()\n\n    if size is not None:\n        fig.set_size_inches(size)\n\n    return fig, ax, data, line_ani"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(dataset, reduce=None, ndims=None, align=None, normalize=None):\n\n    if dataset[-4:] == '.geo':\n        geo = dd.io.load(dataset)\n        if 'dtype' in geo:\n            if 'list' in geo['dtype']:\n                geo['data'] = list(geo['data'])\n            elif 'df' in geo['dtype']:\n                geo['data'] = pd.DataFrame(geo['data'])\n        geo['xform_data'] = list(geo['xform_data'])\n        data = DataGeometry(**geo)\n    elif dataset in datadict.keys():\n        data = _load_data(dataset, datadict[dataset])\n    else:\n        raise RuntimeError('No data loaded. Please specify a .geo file or '\n                       'one of the following sample files: weights, '\n                       'weights_avg, weights_sample, spiral, mushrooms, '\n                       'wiki, nips or sotus.')\n\n    if data is not None:\n        if dataset in ('wiki_model', 'nips_model', 'sotus_model'):\n            return data\n    if isinstance(data, DataGeometry):\n        if any([reduce, ndims, align, normalize]):\n            from ..plot.plot import plot\n            if ndims:\n                if reduce is None:\n                    reduce='IncrementalPCA'\n            d = analyze(data.get_data(), reduce=reduce, ndims=ndims, align=align, normalize=normalize)\n            return plot(d, show=False)\n        else:\n            return data\n    else:\n        return analyze(data, reduce=reduce, ndims=ndims, align=align, normalize=normalize)", "response": "Load a. geo file or example data into a base - level dict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef procrustes(source, target, scaling=True, reflection=True, reduction=False,\n               oblique=False, oblique_rcond=-1, format_data=True):\n    \"\"\"\n    Function to project from one space to another using Procrustean\n    transformation (shift + scaling + rotation + reflection).\n\n    The implementation of this function was based on the ProcrusteanMapper in\n    pyMVPA: https://github.com/PyMVPA/PyMVPA\n\n    See also: http://en.wikipedia.org/wiki/Procrustes_transformation\n\n    Parameters\n    ----------\n    source : Numpy array\n        Array to be aligned to target's coordinate system.\n\n    target: Numpy array\n        Source is aligned to this target space\n\n    scaling : bool\n        Estimate a global scaling factor for the transformation\n        (no longer rigid body)\n\n    reflection : bool\n        Allow for the data to be reflected (so it might not be\n        a rotation. Effective only for non-oblique transformations.\n\n    reduction : bool\n        If true, it is allowed to map into lower-dimensional\n        space. Forward transformation might be suboptimal then and\n        reverse transformation might not recover all original\n        variance.\n\n    oblique : bool\n        Either to allow non-orthogonal transformation -- might\n        heavily overfit the data if there is less samples than\n        dimensions. Use `oblique_rcond`.\n\n    oblique_rcond : float\n        Cutoff for 'small' singular values to regularize the\n        inverse. See :class:`~numpy.linalg.lstsq` for more\n        information.\n\n    Returns\n    ----------\n    aligned_source : Numpy array\n        The array source is aligned to target and returned\n\n    \"\"\"\n\n    def fit(source, target):\n\n        datas = (source, target)\n        sn, sm = source.shape\n        tn, tm = target.shape\n\n        # Check the sizes\n        if sn != tn:\n            raise ValueError(\"Data for both spaces should have the same \" \\\n                  \"number of samples. Got %d in template and %d in target space\" \\\n                  % (sn, tn))\n\n        # Sums of squares\n        ssqs = [np.sum(d**2, axis=0) for d in datas]\n\n        # XXX check for being invariant?\n        #     needs to be tuned up properly and not raise but handle\n        for i in range(2):\n            if np.all(ssqs[i] <= np.abs((np.finfo(datas[i].dtype).eps\n                                       * sn )**2)):\n                raise ValueError(\"For now do not handle invariant in time datasets\")\n\n        norms = [ np.sqrt(np.sum(ssq)) for ssq in ssqs ]\n        normed = [ data/norm for (data, norm) in zip(datas, norms) ]\n\n        # add new blank dimensions to template space if needed\n        if sm < tm:\n            normed[0] = np.hstack( (normed[0], np.zeros((sn, tm-sm))) )\n\n        if sm > tm:\n            if reduction:\n                normed[1] = np.hstack( (normed[1], np.zeros((sn, sm-tm))) )\n            else:\n                raise ValueError(\"reduction=False, so mapping from \" \\\n                      \"higher dimensionality \" \\\n                      \"template space is not supported. template space had %d \" \\\n                      \"while target %d dimensions (features)\" % (sm, tm))\n\n        source, target = normed\n        if oblique:\n            # Just do silly linear system of equations ;) or naive\n            # inverse problem\n            if sn == sm and tm == 1:\n                T = np.linalg.solve(source, target)\n            else:\n                T = np.linalg.lstsq(source, target, rcond=oblique_rcond)[0]\n            ss = 1.0\n        else:\n            # Orthogonal transformation\n            # figure out optimal rotation\n            U, s, Vh = np.linalg.svd(np.dot(target.T, source),\n                                     full_matrices=False)\n            T = np.dot(Vh.T, U.T)\n\n            if not reflection:\n                # then we need to assure that it is only rotation\n                # \"recipe\" from\n                # http://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n                # for more and info and original references, see\n                # http://dx.doi.org/10.1007%2FBF02289451\n                nsv = len(s)\n                s[:-1] = 1\n                s[-1] = np.linalg.det(T)\n                T = np.dot(U[:, :nsv] * s, Vh)\n\n            # figure out scale and final translation\n            # XXX with reflection False -- not sure if here or there or anywhere...\n            ss = sum(s)\n\n        # if we were to collect standardized distance\n        # std_d = 1 - sD**2\n\n        # select out only relevant dimensions\n        if sm != tm:\n            T = T[:sm, :tm]\n\n        # Assign projection\n        if scaling:\n            scale = ss * norms[1] / norms[0]\n            proj = scale * T\n        else:\n            proj = T\n        return proj\n\n    def transform(data, proj):\n        if proj is None:\n            raise RuntimeError(\"Mapper needs to be trained before use.\")\n\n        d = np.asmatrix(data)\n\n        # Do projection\n        res = (d * proj).A\n\n        return res\n\n    if format_data:\n        source, target = formatter([source, target])\n\n    # fit and transform\n    proj = fit(source, target)\n    return transform(source, proj)", "response": "Returns a new array that is aligned to source using the ProcrusteanMapper function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, data=None):\n        # if no new data passed,\n        if data is None:\n            return self.xform_data\n        else:\n            formatted = format_data(\n                data,\n                semantic=self.semantic,\n                vectorizer=self.vectorizer,\n                corpus=self.corpus,\n                ppca=True)\n            norm = normalizer(formatted, normalize=self.normalize)\n            reduction = reducer(\n                norm,\n                reduce=self.reduce,\n                ndims=self.reduce['params']['n_components'])\n            return aligner(reduction, align=self.align)", "response": "Transform the data using the same model as the original data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot(self, data=None, **kwargs):\n\n        # import plot here to avoid circular imports\n        from .plot.plot import plot as plotter\n\n        if data is None:\n            d = copy.copy(self.data)\n            transform = copy.copy(self.xform_data)\n            if any([k in kwargs for k in ['reduce', 'align', 'normalize',\n                                          'semantic', 'vectorizer', 'corpus']]):\n                d = copy.copy(self.data)\n                transform = None\n        else:\n            d = data\n            transform = None\n\n        # get kwargs and update with new kwargs\n        new_kwargs = copy.copy(self.kwargs)\n        update_kwargs = dict(transform=transform, reduce=self.reduce,\n                       align=self.align, normalize=self.normalize,\n                       semantic=self.semantic, vectorizer=self.vectorizer,\n                       corpus=self.corpus)\n        new_kwargs.update(update_kwargs)\n        for key in kwargs:\n            new_kwargs.update({key : kwargs[key]})\n        return plotter(d, **new_kwargs)", "response": "Plot the data of the object with the specified data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the object to a. geo file.", "response": "def save(self, fname, compression='blosc'):\n        \"\"\"\n        Save method for the data geometry object\n\n        The data will be saved as a 'geo' file, which is a dictionary containing\n        the elements of a data geometry object saved in the hd5 format using\n        `deepdish`.\n\n        Parameters\n        ----------\n\n        fname : str\n            A name for the file.  If the file extension (.geo) is not specified,\n            it will be appended.\n\n        compression : str\n            The kind of compression to use.  See the deepdish documentation for\n            options: http://deepdish.readthedocs.io/en/latest/api_io.html#deepdish.io.save\n\n        \"\"\"\n        if hasattr(self, 'dtype'):\n            if 'list' in self.dtype:\n                data = np.array(self.data)\n            elif 'df' in self.dtype:\n                data = {k: np.array(v).astype('str') for k, v in self.data.to_dict('list').items()}\n            else:\n                data = self.data\n\n        # put geo vars into a dict\n        geo = {\n            'data' : data,\n            'xform_data' : np.array(self.xform_data),\n            'reduce' : self.reduce,\n            'align' : self.align,\n            'normalize' : self.normalize,\n            'semantic' : self.semantic,\n            'corpus' : np.array(self.corpus) if isinstance(self.corpus, list) else self.corpus,\n            'kwargs' : self.kwargs,\n            'version' : self.version,\n            'dtype' : self.dtype\n        }\n\n        # if extension wasn't included, add it\n        if fname[-4:]!='.geo':\n            fname+='.geo'\n\n        # save\n        dd.io.save(fname, geo, compression=compression)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef analyze(data, normalize=None, reduce=None, ndims=None, align=None, internal=False):\n\n    # return processed data\n    return aligner(reducer(normalizer(data, normalize=normalize, internal=internal),\n                   reduce=reduce, ndims=ndims, internal=internal), align=align)", "response": "Analyzes the data and returns the data that is valid for the base language of the base language."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreduces dimensionality of an array or list of arrays with dimensionality reduced using PCA.", "response": "def reduce(x, reduce='IncrementalPCA', ndims=None, normalize=None, align=None,\n           model=None, model_params=None, internal=False, format_data=True):\n    \"\"\"\n    Reduces dimensionality of an array, or list of arrays\n\n    Parameters\n    ----------\n    x : Numpy array or list of arrays\n        Dimensionality reduction using PCA is performed on this array.\n\n    reduce : str or dict\n        Decomposition/manifold learning model to use.  Models supported: PCA,\n        IncrementalPCA, SparsePCA, MiniBatchSparsePCA, KernelPCA, FastICA,\n        FactorAnalysis, TruncatedSVD, DictionaryLearning, MiniBatchDictionaryLearning,\n        TSNE, Isomap, SpectralEmbedding, LocallyLinearEmbedding, MDS and UMAP.\n        Can be passed as a string, but for finer control of the model\n        parameters, pass as a dictionary, e.g. reduce={'model' : 'PCA',\n        'params' : {'whiten' : True}}. See scikit-learn specific model docs\n        for details on parameters supported for each model.\n\n    ndims : int\n        Number of dimensions to reduce\n\n    format_data : bool\n        Whether or not to first call the format_data function (default: True).\n\n    model : None\n        Deprecated argument.  Please use reduce.\n\n    model_params : None\n        Deprecated argument.  Please use reduce.\n\n    align : None\n        Deprecated argument.  Please use new analyze function to perform\n        combinations of transformations\n\n    normalize : None\n        Deprecated argument.  Please use new analyze function to perform\n        combinations of transformations\n\n    Returns\n    ----------\n    x_reduced : Numpy array or list of arrays\n        The reduced data with ndims dimensionality is returned.  If the input\n        is a list, a list is returned.\n\n    \"\"\"\n\n    # deprecated warning\n    if (model is not None) or (model_params is not None):\n        warnings.warn('Model and model params will be deprecated.  Please use the \\\n                      reduce keyword.  See API docs for more info: http://hypertools.readthedocs.io/en/latest/hypertools.tools.reduce.html#hypertools.tools.reduce')\n        reduce = {}\n        reduce['model'] = model\n        reduce['params'] = model_params\n\n    # if model is None, just return data\n    if reduce is None:\n        return x\n    else:\n\n        # common format\n        if format_data:\n            x = formatter(x, ppca=True)\n\n        if np.vstack([i for i in x]).shape[0]==1:\n            warnings.warn('Cannot reduce the dimensionality of a single row of'\n                          ' data. Return zeros length of ndims')\n            return [np.zeros((1, ndims))]\n        if ndims:\n            if np.vstack([i for i in x]).shape[0]<ndims:\n                warnings.warn('The number of rows in your data is less than ndims.'\n                              ' The data will be reduced to the number of rows.')\n\n        # deprecation warnings\n        if normalize is not None:\n            warnings.warn('The normalize argument will be deprecated for this function.  Please use the \\\n                          analyze function to perform combinations of these transformations.  See API docs for more info: http://hypertools.readthedocs.io/en/latest/hypertools.analyze.html#hypertools.analyze')\n            x = normalizer(x, normalize=normalize)\n\n        if align is not None:\n            warnings.warn('The align argument will be deprecated for this function.  Please use the \\\n                          analyze function to perform combinations of these transformations.  See API docs for more info: http://hypertools.readthedocs.io/en/latest/hypertools.analyze.html#hypertools.analyze')\n            x = aligner(x, align=align)\n\n        # if the shape of the data is already less than ndims, just return it\n        if ndims is None:\n            return x\n        elif all([i.shape[1]<=ndims for i in x]):\n            return x\n\n        # if reduce is a string, find the corresponding model\n        if type(reduce) in [str, np.string_]:\n            model = models[reduce]\n            model_params = {\n                'n_components' : ndims\n            }\n        # if its a dict, use custom params\n        elif type(reduce) is dict:\n            if isinstance((reduce['model']), six.string_types):\n                model = models[reduce['model']]\n                if reduce['params'] is None:\n                    model_params = {\n                        'n_components' : ndims\n                    }\n                else:\n                    model_params = reduce['params']\n        if ndims:\n            model_params = {\n                'n_components' : ndims\n            }\n\n        # initialize model\n        model = model(**model_params)\n\n        # reduce data\n        x_reduced = reduce_list(x, model)\n\n        # return data\n        if internal or len(x_reduced)>1:\n            return x_reduced\n        else:\n            return x_reduced[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming clustering analysis and returns a list of cluster labels.", "response": "def cluster(x, cluster='KMeans', n_clusters=3, ndims=None, format_data=True):\n    \"\"\"\n    Performs clustering analysis and returns a list of cluster labels\n\n    Parameters\n    ----------\n    x : A Numpy array, Pandas Dataframe or list of arrays/dfs\n        The data to be clustered.  You can pass a single array/df or a list.\n        If a list is passed, the arrays will be stacked and the clustering\n        will be performed across all lists (i.e. not within each list).\n\n    cluster : str or dict\n        Model to use to discover clusters.  Support algorithms are: KMeans,\n        MiniBatchKMeans, AgglomerativeClustering, Birch, FeatureAgglomeration,\n        SpectralClustering and HDBSCAN (default: KMeans). Can be passed as a\n        string, but for finer control of the model parameters, pass as a\n        dictionary, e.g. reduce={'model' : 'KMeans', 'params' : {'max_iter' : 100}}.\n        See scikit-learn specific model docs for details on parameters supported for\n        each model.\n\n    n_clusters : int\n        Number of clusters to discover. Not required for HDBSCAN.\n\n    format_data : bool\n        Whether or not to first call the format_data function (default: True).\n\n    ndims : None\n        Deprecated argument.  Please use new analyze function to perform\n        combinations of transformations\n\n    Returns\n    ----------\n    cluster_labels : list\n        An list of cluster labels\n\n    \"\"\"\n\n    if cluster == None:\n        return x\n    elif (isinstance(cluster, six.string_types) and cluster=='HDBSCAN') or \\\n    (isinstance(cluster, dict) and cluster['model']=='HDBSCAN'):\n        if not _has_hdbscan:\n            raise ImportError('HDBSCAN is not installed. Please install hdbscan>=0.8.11')\n\n    if ndims != None:\n        warnings.warn('The ndims argument is now deprecated. Ignoring dimensionality reduction step.')\n\n    if format_data:\n        x = formatter(x, ppca=True)\n\n    # if reduce is a string, find the corresponding model\n    if isinstance(cluster, six.string_types):\n        model = models[cluster]\n        if cluster != 'HDBSCAN':\n            model_params = {\n                'n_clusters' : n_clusters\n            }\n        else:\n            model_params = {}\n    # if its a dict, use custom params\n    elif type(cluster) is dict:\n        if isinstance(cluster['model'], six.string_types):\n            model = models[cluster['model']]\n            model_params = cluster['params']\n\n    # initialize model\n    model = model(**model_params)\n\n    # fit the model\n    model.fit(np.vstack(x))\n\n    # return the labels\n    return list(model.labels_)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_item(self, url):\n\n        _hash = self.build_hash(url)\n        query = {'_id': _hash}\n        return self.dbase.cache.find_one(query)", "response": "Get a specific item from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if required item exists in the cache.", "response": "def has_item(self, url):\n        \"\"\"\n        Test if required item exists in the cache.\n        \"\"\"\n\n        _hash = self.build_hash(url)\n        query = {'_id': _hash}\n        doc = self.dbase.cache.find_one(query, {'id': 1})\n        return doc is not None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds Grab exception from the exception.", "response": "def build_grab_exception(ex, curl):\n    \"\"\"\n    Build Grab exception from the pycurl exception\n\n    Args:\n        ex - the original pycurl exception\n        curl - the Curl instance raised the exception\n    \"\"\"\n    # CURLE_WRITE_ERROR (23)\n    # An error occurred when writing received data to a local file, or\n    # an error was returned to libcurl from a write callback.\n    # This exception should be ignored if grab_callback_interrupted\n    # flag # is enabled (this happens when nohead or nobody options\n    # enabled)\n    #\n    # Also this error is raised when curl receives KeyboardInterrupt\n    # while it is processing some callback function\n    # (WRITEFUNCTION, HEADERFUNCTIO, etc)\n    # If you think WTF then see details here:\n    # https://github.com/pycurl/pycurl/issues/413\n    if ex.args[0] == 23:\n        if getattr(curl, 'grab_callback_interrupted', None) is True:\n            # If the execution of body_process callback is\n            # interrupted (body_maxsize, nobody and other options)\n            # then the pycurl raised exception with code 23\n            # We should ignore it\n            return None\n        else:\n            return error.GrabNetworkError(ex.args[1], ex)\n    else:\n        if ex.args[0] == 28:\n            return error.GrabTimeoutError(ex.args[1], ex)\n        elif ex.args[0] == 7:\n            return error.GrabConnectionError(ex.args[1], ex)\n        elif ex.args[0] == 67:\n            return error.GrabAuthError(ex.args[1], ex)\n        elif ex.args[0] == 47:\n            return error.GrabTooManyRedirectsError(ex.args[1], ex)\n        elif ex.args[0] == 6:\n            return error.GrabCouldNotResolveHostError(ex.args[1], ex)\n        elif ex.args[0] == 3:\n            return error.GrabInvalidUrl(ex.args[1], ex)\n        else:\n            return error.GrabNetworkError(ex.args[1], ex)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef body_processor(self, chunk):\n\n        if self.config_nobody:\n            self.curl.grab_callback_interrupted = True\n            return 0\n\n        bytes_read = len(chunk)\n\n        self.response_body_bytes_read += bytes_read\n        if self.body_file:\n            self.body_file.write(chunk)\n        else:\n            self.response_body_chunks.append(chunk)\n        if self.config_body_maxsize is not None:\n            if self.response_body_bytes_read > self.config_body_maxsize:\n                logger.debug('Response body max size limit reached: %s',\n                             self.config_body_maxsize)\n                self.curl.grab_callback_interrupted = True\n                return 0\n\n        # Returning None implies that all bytes were written\n        return None", "response": "Process the response body of the HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing request details. 0: CURLINFO_TEXT 1: CURLINFO_HEADER_IN 2: CURLINFO_HEADER_OUT 3: CURLINFO_DATA_IN 4: CURLINFO_DATA_OUT 5: CURLINFO_unrecognized_type", "response": "def debug_processor(self, _type, text):\n        \"\"\"\n        Process request details.\n\n        0: CURLINFO_TEXT\n        1: CURLINFO_HEADER_IN\n        2: CURLINFO_HEADER_OUT\n        3: CURLINFO_DATA_IN\n        4: CURLINFO_DATA_OUT\n        5: CURLINFO_unrecognized_type\n        \"\"\"\n        if _type == pycurl.INFOTYPE_HEADER_OUT:\n            if isinstance(text, six.text_type):\n                text = text.encode('utf-8')\n            self.request_head += text\n\n        if _type == pycurl.INFOTYPE_DATA_OUT:\n            # Untill 7.19.5.2 version\n            # pycurl gives unicode in `text` variable\n            # WTF??? Probably that codes would fails\n            # or does unexpected things if you use\n            # pycurl<7.19.5.2\n            if isinstance(text, six.text_type):\n                text = text.encode('utf-8')\n            self.request_body += text\n\n        #if _type == pycurl.INFOTYPE_TEXT:\n        #    if self.request_log is None:\n        #        self.request_log = ''\n        #    self.request_log += text\n\n        if self.verbose_logging:\n            if _type in (pycurl.INFOTYPE_TEXT, pycurl.INFOTYPE_HEADER_IN,\n                         pycurl.INFOTYPE_HEADER_OUT):\n                marker_types = {\n                    pycurl.INFOTYPE_TEXT: 'i',\n                    pycurl.INFOTYPE_HEADER_IN: '<',\n                    pycurl.INFOTYPE_HEADER_OUT: '>',\n                }\n                marker = marker_types[_type]\n                logger.debug('%s: %s', marker, text.rstrip())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_config(self, grab):\n\n        # Copy some config for future usage\n        self.config_nobody = grab.config['nobody']\n        self.config_body_maxsize = grab.config['body_maxsize']\n\n        try:\n            request_url = normalize_url(grab.config['url'])\n        except Exception as ex:\n            raise error.GrabInvalidUrl(\n                u'%s: %s' % (six.text_type(ex), grab.config['url']))\n\n        # py3 hack\n        if not six.PY3:\n            request_url = make_str(request_url)\n\n        self.curl.setopt(pycurl.URL, request_url)\n\n        # 30* redirects are handled by Grab\n        self.curl.setopt(pycurl.FOLLOWLOCATION, 0)\n        self.curl.setopt(pycurl.MAXREDIRS, grab.config['redirect_limit'])\n        self.curl.setopt(pycurl.CONNECTTIMEOUT, grab.config['connect_timeout'])\n        self.curl.setopt(pycurl.TIMEOUT, grab.config['timeout'])\n        #self.curl.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_V4)\n        # self.curl.setopt(pycurl.DNS_CACHE_TIMEOUT, 0)\n        if not grab.config['connection_reuse']:\n            self.curl.setopt(pycurl.FRESH_CONNECT, 1)\n            self.curl.setopt(pycurl.FORBID_REUSE, 1)\n\n        self.curl.setopt(pycurl.NOSIGNAL, 1)\n        self.curl.setopt(pycurl.HEADERFUNCTION, self.header_processor)\n\n        if grab.config['body_inmemory']:\n            self.curl.setopt(pycurl.WRITEFUNCTION, self.body_processor)\n        else:\n            if not grab.config['body_storage_dir']:\n                raise error.GrabMisuseError(\n                    'Option body_storage_dir is not defined')\n            self.setup_body_file(\n                grab.config['body_storage_dir'],\n                grab.config['body_storage_filename'],\n                create_dir=grab.config['body_storage_create_dir'])\n            self.curl.setopt(pycurl.WRITEFUNCTION, self.body_processor)\n\n        if grab.config['verbose_logging']:\n            self.verbose_logging = True\n\n        # User-Agent\n        if grab.config['user_agent'] is None:\n            if grab.config['user_agent_file'] is not None:\n                with open(grab.config['user_agent_file']) as inf:\n                    lines = inf.read().splitlines()\n                grab.config['user_agent'] = random.choice(lines)\n            else:\n                grab.config['user_agent'] = generate_user_agent()\n\n        # If value is None then set empty string\n        # None is not acceptable because in such case\n        # pycurl will set its default user agent \"PycURL/x.xx.x\"\n        if not grab.config['user_agent']:\n            grab.config['user_agent'] = ''\n\n        self.curl.setopt(pycurl.USERAGENT, grab.config['user_agent'])\n\n        if grab.config['debug']:\n            self.curl.setopt(pycurl.VERBOSE, 1)\n            self.curl.setopt(pycurl.DEBUGFUNCTION, self.debug_processor)\n\n        # Ignore SSL errors\n        self.curl.setopt(pycurl.SSL_VERIFYPEER, 0)\n        self.curl.setopt(pycurl.SSL_VERIFYHOST, 0)\n\n        # Disabled to avoid SSL3_READ_BYTES:sslv3 alert handshake failure error\n        # self.curl.setopt(pycurl.SSLVERSION, pycurl.SSLVERSION_SSLv3)\n\n        if grab.request_method in ('POST', 'PUT'):\n            if (grab.config['post'] is None\n                    and grab.config['multipart_post'] is None):\n                raise GrabMisuseError('Neither `post` or `multipart_post`'\n                                      ' options was specified for the %s'\n                                      ' request' % grab.request_method)\n\n        if grab.request_method == 'POST':\n            self.curl.setopt(pycurl.POST, 1)\n            if grab.config['multipart_post']:\n                if isinstance(grab.config['multipart_post'], six.string_types):\n                    raise error.GrabMisuseError(\n                        'multipart_post option could not be a string')\n                post_items = normalize_http_values(\n                    grab.config['multipart_post'],\n                    charset=grab.config['charset'],\n                    ignore_classes=(UploadFile, UploadContent),\n                )\n                # py3 hack\n                #if six.PY3:\n                #    post_items = decode_pairs(post_items,\n                #                              grab.config['charset'])\n                self.curl.setopt(pycurl.HTTPPOST,\n                                 process_upload_items(post_items))\n            elif grab.config['post']:\n                post_data = normalize_post_data(grab.config['post'],\n                                                grab.config['charset'])\n                # py3 hack\n                # if six.PY3:\n                #    post_data = smart_unicode(post_data,\n                #                              grab.config['charset'])\n                self.curl.setopt(pycurl.POSTFIELDS, post_data)\n            else:\n                self.curl.setopt(pycurl.POSTFIELDS, '')\n        elif grab.request_method == 'PUT':\n            data = grab.config['post']\n            if isinstance(data, six.text_type):\n                # py3 hack\n                # if six.PY3:\n                #    data = data.encode('utf-8')\n                # else:\n                raise error.GrabMisuseError(\n                    'Value of post option could be only '\n                    'byte string if PUT method is used')\n            self.curl.setopt(pycurl.UPLOAD, 1)\n            self.curl.setopt(pycurl.CUSTOMREQUEST, 'PUT')\n            self.curl.setopt(pycurl.READFUNCTION, StringIO(data).read)\n            self.curl.setopt(pycurl.INFILESIZE, len(data))\n        elif grab.request_method == 'PATCH':\n            data = grab.config['post']\n            if isinstance(data, six.text_type):\n                raise error.GrabMisuseError(\n                    'Value of post option could be only byte '\n                    'string if PATCH method is used')\n            self.curl.setopt(pycurl.UPLOAD, 1)\n            self.curl.setopt(pycurl.CUSTOMREQUEST, 'PATCH')\n            self.curl.setopt(pycurl.READFUNCTION, StringIO(data).read)\n            self.curl.setopt(pycurl.INFILESIZE, len(data))\n        elif grab.request_method == 'DELETE':\n            self.curl.setopt(pycurl.CUSTOMREQUEST, 'DELETE')\n        elif grab.request_method == 'HEAD':\n            self.curl.setopt(pycurl.NOBODY, 1)\n        elif grab.request_method == 'UPLOAD':\n            self.curl.setopt(pycurl.UPLOAD, 1)\n        elif grab.request_method == 'GET':\n            self.curl.setopt(pycurl.HTTPGET, 1)\n        elif grab.request_method == 'OPTIONS':\n            data = grab.config['post']\n            if data is not None:\n                if isinstance(data, six.text_type):\n                    raise error.GrabMisuseError(\n                        'Value of post option could be only byte '\n                        'string if PATCH method is used')\n                self.curl.setopt(pycurl.UPLOAD, 1)\n                self.curl.setopt(pycurl.READFUNCTION, StringIO(data).read)\n                self.curl.setopt(pycurl.INFILESIZE, len(data))\n            self.curl.setopt(pycurl.CUSTOMREQUEST, 'OPTIONS')\n        else:\n            raise error.GrabMisuseError('Invalid method: %s' %\n                                        grab.request_method)\n\n        headers = grab.config['common_headers'].copy()\n        if grab.config['headers']:\n            headers.update(grab.config['headers'])\n        # This is required to avoid some problems\n        headers.update({'Expect': ''})\n        header_tuples = [str('%s: %s' % x) for x\n                         in headers.items()]\n        self.curl.setopt(pycurl.HTTPHEADER, header_tuples)\n\n        self.process_cookie_options(grab, request_url)\n\n        if grab.config['referer']:\n            self.curl.setopt(pycurl.REFERER, str(grab.config['referer']))\n\n        if grab.config['proxy']:\n            self.curl.setopt(pycurl.PROXY, str(grab.config['proxy']))\n        else:\n            self.curl.setopt(pycurl.PROXY, '')\n\n        if grab.config['proxy_userpwd']:\n            self.curl.setopt(pycurl.PROXYUSERPWD,\n                             str(grab.config['proxy_userpwd']))\n\n        if grab.config['proxy_type']:\n            key = 'PROXYTYPE_%s' % grab.config['proxy_type'].upper()\n            self.curl.setopt(pycurl.PROXYTYPE, getattr(pycurl, key))\n\n        if grab.config['encoding']:\n            if ('gzip' in grab.config['encoding'] and\n                    'zlib' not in pycurl.version):\n                raise error.GrabMisuseError(\n                    'You can not use gzip encoding because '\n                    'pycurl was built without zlib support')\n            self.curl.setopt(pycurl.ENCODING, grab.config['encoding'])\n\n        if grab.config['userpwd']:\n            self.curl.setopt(pycurl.USERPWD, str(grab.config['userpwd']))\n\n        if grab.config.get('interface') is not None:\n            self.curl.setopt(pycurl.INTERFACE, grab.config['interface'])\n\n        if grab.config.get('reject_file_size') is not None:\n            self.curl.setopt(pycurl.MAXFILESIZE,\n                             grab.config['reject_file_size'])", "response": "Setup curl instance with values from self. config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_cookiejar(self):\n\n        # Example of line:\n        # www.google.com\\tFALSE\\t/accounts/\\tFALSE\\t0'\n        # \\tGoogleAccountsLocale_session\\ten\n        # Fields:\n        # * domain\n        # * whether or not all machines under that domain can\n        # read the cookie's information.\n        # * path\n        # * Secure Flag: whether or not a secure connection (HTTPS)\n        # is required to read the cookie.\n        # * exp. timestamp\n        # * name\n        # * value\n        cookiejar = CookieJar()\n        for line in self.curl.getinfo(pycurl.INFO_COOKIELIST):\n            values = line.split('\\t')\n            domain = values[0].lower()\n            if domain.startswith('#httponly_'):\n                domain = domain.replace('#httponly_', '')\n                httponly = True\n            else:\n                httponly = False\n            # old\n            # cookies[values[-2]] = values[-1]\n            # new\n            cookie = create_cookie(\n                name=values[5],\n                value=values[6],\n                domain=domain,\n                path=values[2],\n                secure=values[3] == \"TRUE\",\n                expires=int(values[4]) if values[4] else None,\n                httponly=httponly,\n            )\n            cookiejar.set_cookie(cookie)\n        return cookiejar", "response": "Extract cookies that pycurl instance knows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndefault logging for all log messages.", "response": "def default_logging(grab_log=None, # '/tmp/grab.log',\n                    network_log=None, # '/tmp/grab.network.log',\n                    level=logging.DEBUG, mode='a',\n                    propagate_network_logger=False):\n    \"\"\"\n    Customize logging output to display all log messages\n    except grab network logs.\n\n    Redirect grab network logs into file.\n    \"\"\"\n\n    logging.basicConfig(level=level)\n\n    network_logger = logging.getLogger('grab.network')\n    network_logger.propagate = propagate_network_logger\n    if network_log:\n        hdl = logging.FileHandler(network_log, mode)\n        network_logger.addHandler(hdl)\n        network_logger.setLevel(level)\n\n    grab_logger = logging.getLogger('grab')\n    if grab_log:\n        hdl = logging.FileHandler(grab_log, mode)\n        grab_logger.addHandler(hdl)\n        grab_logger.setLevel(level)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_list(lst, path):\n\n    with open(path, 'wb') as out:\n        lines = []\n        for item in lst:\n            if isinstance(item, (six.text_type, six.binary_type)):\n                lines.append(make_str(item))\n            else:\n                lines.append(make_str(json.dumps(item)))\n        out.write(b'\\n'.join(lines) + b'\\n')", "response": "Save items from list to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses proxy details from the raw text line.", "response": "def parse_proxy_line(line):\n    \"\"\"\n    Parse proxy details from the raw text line.\n\n    The text line could be in one of the following formats:\n    * host:port\n    * host:port:username:password\n    \"\"\"\n\n    line = line.strip()\n    match = RE_SIMPLE_PROXY.search(line)\n    if match:\n        return match.group(1), match.group(2), None, None\n\n    match = RE_AUTH_PROXY.search(line)\n    if match:\n        host, port, user, pwd = match.groups()\n        return host, port, user, pwd\n\n    raise InvalidProxyLine('Invalid proxy line: %s' % line)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over proxy servers found in the raw data", "response": "def parse_raw_list_data(data, proxy_type='http', proxy_userpwd=None):\n    \"\"\"Iterate over proxy servers found in the raw data\"\"\"\n    if not isinstance(data, six.text_type):\n        data = data.decode('utf-8')\n    for orig_line in data.splitlines():\n        line = orig_line.strip().replace(' ', '')\n        if line and not line.startswith('#'):\n            try:\n                host, port, username, password = parse_proxy_line(line)\n            except InvalidProxyLine as ex:\n                logger.error(ex)\n            else:\n                if username is None and proxy_userpwd is not None:\n                    username, password = proxy_userpwd.split(':')\n                yield Proxy(host, port, username, password, proxy_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self):\n        self._list = self._source.load()\n        self._list_iter = itertools.cycle(self._list)", "response": "Load proxy list from configured proxy source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clone(self, **kwargs):\n\n        # First, create exact copy of the current Task object\n        attr_copy = self.__dict__.copy()\n        if attr_copy.get('grab_config') is not None:\n            del attr_copy['url']\n        if not attr_copy['priority_set_explicitly']:\n            attr_copy['priority'] = None\n        task = Task(**attr_copy)\n\n        # Reset some task properties if they have not\n        # been set explicitly in kwargs\n        if 'network_try_count' not in kwargs:\n            task.network_try_count = 0\n        if 'task_try_count' not in kwargs:\n            task.task_try_count = self.task_try_count + 1\n        if 'refresh_cache' not in kwargs:\n            task.refresh_cache = False\n        if 'disable_cache' not in kwargs:\n            task.disable_cache = False\n\n        if kwargs.get('url') is not None and kwargs.get('grab') is not None:\n            raise SpiderMisuseError('Options url and grab could not be '\n                                    'used together')\n\n        if (kwargs.get('url') is not None and\n                kwargs.get('grab_config') is not None):\n            raise SpiderMisuseError('Options url and grab_config could not '\n                                    'be used together')\n\n        if (kwargs.get('grab') is not None and\n                kwargs.get('grab_config') is not None):\n            raise SpiderMisuseError('Options grab and grab_config could not '\n                                    'be used together')\n\n        if kwargs.get('grab'):\n            task.setup_grab_config(kwargs['grab'].dump_config())\n            del kwargs['grab']\n        elif kwargs.get('grab_config'):\n            task.setup_grab_config(kwargs['grab_config'])\n            del kwargs['grab_config']\n        elif kwargs.get('url'):\n            task.url = kwargs['url']\n            if task.grab_config:\n                task.grab_config['url'] = kwargs['url']\n            del kwargs['url']\n\n        for key, value in kwargs.items():\n            setattr(task, key, value)\n\n        task.process_delay_option(None)\n\n        return task", "response": "Clone the current Task instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy config with correct handling of mutable config values.", "response": "def copy_config(config, mutable_config_keys=MUTABLE_CONFIG_KEYS):\n    \"\"\"\n    Copy grab config with correct handling of mutable config values.\n    \"\"\"\n\n    cloned_config = copy(config)\n    # Apply ``copy`` function to mutable config values\n    for key in mutable_config_keys:\n        cloned_config[key] = copy(config[key])\n    return cloned_config"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset(self):\n\n        self.request_head = None\n        #self.request_log = None\n        self.request_body = None\n        self.request_method = None\n        self.request_counter = None\n        self.exception = None\n        if self.transport:\n            self.transport.reset()", "response": "Reset all attributes which could be modified during previous request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clone(self, **kwargs):\n\n        grab = Grab(transport=self.transport_param)\n        grab.config = self.dump_config()\n\n        grab.doc = self.doc.copy()\n        #grab.doc.grab = weakref.proxy(grab)\n\n        for key in self.clonable_attributes:\n            setattr(grab, key, getattr(self, key))\n        grab.cookies = deepcopy(self.cookies)\n\n        if kwargs:\n            grab.setup(**kwargs)\n\n        return grab", "response": "Create a copy of this Grab instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy the state of another Grab instance.", "response": "def adopt(self, grab):\n        \"\"\"\n        Copy the state of another `Grab` instance.\n\n        Use case: create backup of current state to the cloned instance and\n        then restore the state from it.\n        \"\"\"\n\n        self.load_config(grab.config)\n\n        self.doc = grab.doc.copy(new_grab=self)\n\n        for key in self.clonable_attributes:\n            setattr(self, key, getattr(grab, key))\n        self.cookies = deepcopy(grab.cookies)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_config(self):\n\n        conf = copy_config(self.config, self.mutable_config_keys)\n        conf['state'] = {\n            'cookiejar_cookies': list(self.cookies.cookiejar),\n        }\n        return conf", "response": "Make clone of current config."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_config(self, config):\n\n        self.config = copy_config(config, self.mutable_config_keys)\n        if 'cookiejar_cookies' in config['state']:\n            self.cookies = CookieManager.from_cookie_list(\n                config['state']['cookiejar_cookies'])", "response": "Configure grab instance with external config object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up Grab instance configuration.", "response": "def setup(self, **kwargs):\n        \"\"\"\n        Setting up Grab instance configuration.\n        \"\"\"\n\n        for key in kwargs:\n            if key not in self.config.keys():\n                raise error.GrabMisuseError('Unknown option: %s' % key)\n\n        if 'url' in kwargs:\n            if self.config.get('url'):\n                kwargs['url'] = self.make_url_absolute(kwargs['url'])\n        self.config.update(kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a document from url and save it to location.", "response": "def download(self, url, location, **kwargs):\n        \"\"\"\n        Fetch document located at ``url`` and save to to ``location``.\n        \"\"\"\n\n        doc = self.go(url, **kwargs)\n        with open(location, 'wb') as out:\n            out.write(doc.body)\n        return len(doc.body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares all things to make real network request.", "response": "def prepare_request(self, **kwargs):\n        \"\"\"\n        Configure all things to make real network request.\n        This method is called before doing real request via\n        transport extension.\n        \"\"\"\n\n        if self.transport is None:\n            self.setup_transport(self.transport_param)\n        self.reset()\n        self.request_counter = next(REQUEST_COUNTER)\n        if kwargs:\n            self.setup(**kwargs)\n        if self.proxylist.size() and self.config['proxy_auto_change']:\n            self.change_proxy()\n        self.request_method = self.detect_request_method()\n        self.transport.process_config(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend request details to logging system.", "response": "def log_request(self, extra=''):\n        \"\"\"\n        Send request details to logging system.\n        \"\"\"\n\n        # pylint: disable=no-member\n        thread_name = threading.currentThread().getName().lower()\n        # pylint: enable=no-member\n        if thread_name == 'mainthread':\n            thread_name = ''\n        else:\n            thread_name = '-%s' % thread_name\n\n        if self.config['proxy']:\n            if self.config['proxy_userpwd']:\n                auth = ' with authorization'\n            else:\n                auth = ''\n            proxy_info = ' via %s proxy of type %s%s' % (\n                self.config['proxy'], self.config['proxy_type'], auth)\n        else:\n            proxy_info = ''\n        if extra:\n            extra = '[%s] ' % extra\n        logger_network.debug(\n            '[%s%s] %s%s %s%s',\n            ('%02d' % self.request_counter\n             if self.request_counter is not None else 'NA'),\n            thread_name,\n            extra, self.request_method or 'GET',\n            self.config['url'], proxy_info)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(self, **kwargs):\n\n        self.prepare_request(**kwargs)\n        refresh_count = 0\n\n        while True:\n            self.log_request()\n\n            try:\n                self.transport.request()\n            except error.GrabError as ex:\n                self.exception = ex\n                self.reset_temporary_options()\n                if self.config['log_dir']:\n                    self.save_failed_dump()\n                raise\n            else:\n                doc = self.process_request_result()\n\n                if self.config['follow_location']:\n                    if doc.code in (301, 302, 303, 307, 308):\n                        if doc.headers.get('Location'):\n                            refresh_count += 1\n                            if refresh_count > self.config['redirect_limit']:\n                                raise error.GrabTooManyRedirectsError()\n                            else:\n                                url = doc.headers.get('Location')\n                                self.prepare_request(\n                                    url=self.make_url_absolute(url),\n                                    referer=None)\n                                continue\n\n                if self.config['follow_refresh']:\n                    refresh_url = self.doc.get_meta_refresh_url()\n                    if refresh_url is not None:\n                        refresh_count += 1\n                        if refresh_count > self.config['redirect_limit']:\n                            raise error.GrabTooManyRedirectsError()\n                        else:\n                            self.prepare_request(\n                                url=self.make_url_absolute(refresh_url),\n                                referer=None)\n                            continue\n                return doc", "response": "Perform network request.\n\n        You can specify grab settings in ``**kwargs``.\n        Any keyword argument will be passed to ``self.config``.\n\n        Returns: ``Document`` objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef submit(self, make_request=True, **kwargs):\n        result = self.doc.get_form_request(**kwargs)\n        if result['multipart_post']:\n            self.setup(multipart_post=result['multipart_post'])\n        if result['post']:\n            self.setup(post=result['post'])\n        if result['url']:\n            self.setup(url=result['url'])\n        if make_request:\n            return self.request()\n        else:\n            return None", "response": "Submit current form.\n\n        :param make_request: if `False` then grab instance will be\n            configured with form post data but request will not be\n            performed\n\n        For details see `Document.submit()` method\n\n        Example::\n\n            # Assume that we going to some page with some form\n            g.go('some url')\n            # Fill some fields\n            g.doc.set_input('username', 'bob')\n            g.doc.set_input('pwd', '123')\n            # Submit the form\n            g.submit()\n\n            # or we can just fill the form\n            # and do manual submission\n            g.doc.set_input('foo', 'bar')\n            g.submit(make_request=False)\n            g.request()\n\n            # for multipart forms we can specify files\n            from grab import UploadFile\n            g.doc.set_input('img', UploadFile('/path/to/image.png'))\n            g.submit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses the result of a real request.", "response": "def process_request_result(self, prepare_response_func=None):\n        \"\"\"\n        Process result of real request performed via transport extension.\n        \"\"\"\n\n        now = datetime.utcnow()\n        # TODO: move into separate method\n        if self.config['debug_post']:\n            post = self.config['post'] or self.config['multipart_post']\n            if isinstance(post, dict):\n                post = list(post.items())\n            if post:\n                if isinstance(post, six.string_types):\n                    post = make_str(post[:self.config['debug_post_limit']],\n                                    errors='ignore') + b'...'\n                else:\n                    items = normalize_http_values(\n                        post, charset=self.config['charset'])\n                    new_items = []\n                    for key, value in items:\n                        if len(value) > self.config['debug_post_limit']:\n                            value = value[\n                                :self.config['debug_post_limit']] + b'...'\n                        else:\n                            value = value\n                        new_items.append((key, value))\n                    post = '\\n'.join('%-25s: %s' % x for x in new_items)\n            if post:\n                logger_network.debug('[%02d] POST request:\\n%s\\n',\n                                     self.request_counter, post)\n\n        # It's important to delete old POST data after request is performed.\n        # If POST data is not cleared then next request will try to use them\n        # again!\n        self.reset_temporary_options()\n\n        if prepare_response_func:\n            self.doc = prepare_response_func(self.transport, self)\n        else:\n            self.doc = self.transport.prepare_response(self)\n\n        self.doc.process_grab(self)\n\n        if self.config['reuse_cookies']:\n            self.cookies.update(self.doc.cookies)\n\n        self.doc.timestamp = now\n\n        self.config['charset'] = self.doc.charset\n\n        if self.config['log_file']:\n            with open(self.config['log_file'], 'wb') as out:\n                out.write(self.doc.body)\n\n        if self.config['cookiefile']:\n            self.cookies.save_to_file(self.config['cookiefile'])\n\n        if self.config['reuse_referer']:\n            self.config['referer'] = self.doc.url\n\n        self.copy_request_data()\n\n        # Should be called after `copy_request_data`\n        if self.config['log_dir']:\n            self.save_dumps()\n\n        return self.doc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving dump of failed request for debugging.", "response": "def save_failed_dump(self):\n        \"\"\"\n        Save dump of failed request for debugging.\n\n        This method is called then fatal network exception is raised.\n        The saved dump could be used for debugging the reason of the failure.\n        \"\"\"\n\n        # try/except for safety, to not break live spiders\n        try:\n            # FIXME\n            if (self.transport.__class__.__name__ == 'Urllib3Transport'\n                    and not getattr(self.transport, '_response', None)):\n                self.doc = None\n            else:\n                self.doc = self.transport.prepare_response(self)\n            self.copy_request_data()\n            self.save_dumps()\n        except Exception as ex: # pylint: disable=broad-except\n            logger.error('', exc_info=ex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_document(self, content, **kwargs):\n\n        self.reset()\n        if isinstance(content, six.text_type):\n            raise error.GrabMisuseError('Method `setup_document` accepts only '\n                                        'byte string in `content` argument.')\n\n        # Configure Document instance\n        doc = Document(grab=self)\n        doc.body = content\n        doc.status = ''\n        doc.head = b'HTTP/1.1 200 OK\\r\\n\\r\\n'\n        doc.parse(charset=kwargs.get('document_charset'))\n        doc.code = 200\n        doc.total_time = 0\n        doc.connect_time = 0\n        doc.name_lookup_time = 0\n        doc.url = ''\n\n        for key, value in kwargs.items():\n            setattr(doc, key, value)\n\n        self.doc = doc", "response": "Setup response object without real network requests."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging proxy from proxylist.", "response": "def change_proxy(self, random=True):\n        \"\"\"\n        Set random proxy from proxylist.\n        \"\"\"\n\n        if self.proxylist.size():\n            if random:\n                proxy = self.proxylist.get_random_proxy()\n            else:\n                proxy = self.proxylist.get_next_proxy()\n            self.setup(proxy=proxy.get_address(),\n                       proxy_userpwd=proxy.get_userpwd(),\n                       proxy_type=proxy.proxy_type)\n        else:\n            logger.debug('Proxy list is empty')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking url absolute using previous request url as base url.", "response": "def make_url_absolute(self, url, resolve_base=False):\n        \"\"\"\n        Make url absolute using previous request url as base url.\n        \"\"\"\n\n        if self.config['url']:\n            if resolve_base:\n                ubody = self.doc.unicode_body()\n                base_url = find_base_url(ubody)\n                if base_url:\n                    return urljoin(base_url, url)\n            return urljoin(self.config['url'], url)\n        else:\n            return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetect the request method for the current locale.", "response": "def detect_request_method(self):\n        \"\"\"\n        Analyze request config and find which\n        request method will be used.\n\n        Returns request method in upper case\n\n        This method needs simetime when `process_config` method\n        was not called yet.\n        \"\"\"\n\n        method = self.config['method']\n        if method:\n            method = method.upper()\n        else:\n            if self.config['post'] or self.config['multipart_post']:\n                method = 'POST'\n            else:\n                method = 'GET'\n        return method"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_cookie(name, value, domain, httponly=None, **kwargs):\n\n    if domain == 'localhost':\n        domain = ''\n    config = dict(\n        name=name,\n        value=value,\n        version=0,\n        port=None,\n        domain=domain,\n        path='/',\n        secure=False,\n        expires=None,\n        discard=True,\n        comment=None,\n        comment_url=None,\n        rfc2109=False,\n        rest={'HttpOnly': httponly},\n    )\n\n    for key in kwargs:\n        if key not in config:\n            raise GrabMisuseError('Function `create_cookie` does not accept '\n                                  '`%s` argument' % key)\n\n    config.update(**kwargs)\n    config['rest']['HttpOnly'] = httponly\n\n    config['port_specified'] = bool(config['port'])\n    config['domain_specified'] = bool(config['domain'])\n    config['domain_initial_dot'] = (config['domain'] or '').startswith('.')\n    config['path_specified'] = bool(config['path'])\n\n    return Cookie(**config)", "response": "Creates a new Cookie instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, name, value, domain, **kwargs):\n\n        if domain == 'localhost':\n            domain = ''\n\n        self.cookiejar.set_cookie(create_cookie(name, value, domain, **kwargs))", "response": "Add new cookie or replace existing cookie with same parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading cookies from the file.", "response": "def load_from_file(self, path):\n        \"\"\"\n        Load cookies from the file.\n\n        Content of file should be a JSON-serialized list of dicts.\n        \"\"\"\n\n        with open(path) as inf:\n            data = inf.read()\n            if data:\n                items = json.loads(data)\n            else:\n                items = {}\n        for item in items:\n            extra = dict((x, y) for x, y in item.items()\n                         if x not in ['name', 'value', 'domain'])\n            self.set(item['name'], item['value'], item['domain'], **extra)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump all cookies to file.", "response": "def save_to_file(self, path):\n        \"\"\"\n        Dump all cookies to file.\n\n        Cookies are dumped as JSON-serialized dict of keys and values.\n        \"\"\"\n\n        with open(path, 'w') as out:\n            out.write(json.dumps(self.get_dict()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Cookie header of the given httplib. Request object.", "response": "def get_cookie_header(self, req):\n        \"\"\"\n        :param req: object with httplib.Request interface\n            Actually, it have to have `url` and `headers` attributes\n        \"\"\"\n        mocked_req = MockRequest(req)\n        self.cookiejar.add_cookie_header(mocked_req)\n        return mocked_req.get_new_headers().get('Cookie')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget item from database.", "response": "def get_item(self, url):\n        \"\"\"\n        Returned item should have specific interface. See module docstring.\n        \"\"\"\n\n        _hash = self.build_hash(url)\n        self.cursor.execute('BEGIN')\n        sql = '''\n              SELECT data\n              FROM cache\n              WHERE id = %s\n          '''\n        self.cursor.execute(sql, (_hash,))\n        row = self.cursor.fetchone()\n        self.cursor.execute('COMMIT')\n        if row:\n            data = row[0]\n            return self.unpack_database_value(data)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_service_result(self, result, task, meta=None):\n\n        if meta is None:\n            meta = {}\n        if isinstance(result, Task):\n            if meta.get('source') == 'cache_reader':\n                self.spider.add_task(result, queue=self.spider.task_queue)\n            else:\n                self.spider.add_task(result)\n        elif result is None:\n            pass\n        elif isinstance(result, ResponseNotValid):\n            self.spider.add_task(task.clone(refresh_cache=True))\n            error_code = result.__class__.__name__.replace('_', '-')\n            self.spider.stat.inc('integrity:%s' % error_code)\n        elif isinstance(result, Exception):\n            if task:\n                handler = self.spider.find_task_handler(task)\n                handler_name = getattr(handler, '__name__', 'NONE')\n            else:\n                handler_name = 'NA'\n            self.spider.process_parser_error(\n                handler_name, task, meta['exc_info'],\n            )\n            if isinstance(result, FatalError):\n                self.spider.fatal_error_queue.put(meta['exc_info'])\n        elif isinstance(result, dict) and 'grab' in result:\n            if (self.spider.cache_writer_service\n                    and not result.get('from_cache')\n                    and result['ok']):\n                self.spider.cache_writer_service.input_queue.put(\n                    (task, result['grab'])\n                )\n            # TODO: Move to network service\n            # starts\n            self.spider.log_network_result_stats(result, task)\n            # ends\n            is_valid = False\n            if task.get('raw'):\n                is_valid = True\n            elif result['ok']:\n                res_code = result['grab'].doc.code\n                is_valid = self.spider.is_valid_network_response_code(\n                    res_code, task\n                )\n            if is_valid:\n                self.spider.parser_service.input_queue.put((result, task))\n            else:\n                self.spider.log_failed_network_result(result)\n                # Try to do network request one more time\n                # TODO:\n                # Implement valid_try_limit\n                # Use it if request failed not because of network error\n                # But because of content integrity check\n                if self.spider.network_try_limit > 0:\n                    task.refresh_cache = True\n                    task.setup_grab_config(\n                        result['grab_config_backup'])\n                    self.spider.add_task(task)\n            if result.get('from_cache'):\n                self.spider.stat.inc('spider:task-%s-cache'\n                                     % task.name)\n            self.spider.stat.inc('spider:request')\n        else:\n            raise SpiderError('Unknown result received from a service: %s'\n                              % result)", "response": "Process the result from a service to the task dispatcher service."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntesting if required item exists in the cache.", "response": "def has_item(self, url):\n        \"\"\"\n        Test if required item exists in the cache.\n        \"\"\"\n\n        _hash = self.build_hash(url)\n        self.execute('BEGIN')\n        self.execute('''\n            SELECT id\n            FROM cache\n            WHERE id = x%s\n            LIMIT 1\n        ''', (_hash,))\n        row = self.cursor.fetchone()\n        self.execute('COMMIT')\n        return True if row else False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind link in response body which href value matches href_pattern. Returns None if no match is found.", "response": "def find_link(self, href_pattern, make_absolute=True):\n        \"\"\"\n        Find link in response body which href value matches ``href_pattern``.\n\n        Returns found url or None.\n        \"\"\"\n\n        if make_absolute:\n            self.tree.make_links_absolute(self.doc.url)\n\n        if isinstance(href_pattern, six.text_type):\n            raise GrabMisuseError('Method `find_link` accepts only '\n                                  'byte-string argument')\n        href_pattern = make_unicode(href_pattern)\n        for elem, _, link, _ in self.tree.iterlinks():\n            if elem.tag == 'a' and href_pattern in link:\n                return link\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind link matched the given regular expression in response body. Returns None if no match is found.", "response": "def find_link_rex(self, rex, make_absolute=True):\n        \"\"\"\n        Find link matched the given regular expression in response body.\n\n        Returns found url or None.\n        \"\"\"\n\n        if make_absolute:\n            self.tree.make_links_absolute(self.doc.url)\n\n        for elem, _, link, _ in self.tree.iterlinks():\n            if elem.tag == 'a':\n                match = rex.search(link)\n                if match:\n                    # That does not work for string object\n                    # link.match = match\n                    return link\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first element which matches the given css path. If default is not given then return the first element.", "response": "def css_one(self, path, default=NULL):\n        \"\"\"\n        Get first element which matches the given css path\n            or raise DataNotFound.\n        \"\"\"\n\n        try:\n            return self.css_list(path)[0]\n        except IndexError:\n            if default is NULL:\n                raise DataNotFound('CSS path not found: %s' % path)\n            else:\n                return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget normalized text of node which matches the css path.", "response": "def css_text(self, path, default=NULL, smart=False, normalize_space=True):\n        \"\"\"\n        Get normalized text of node which matches the css path.\n        \"\"\"\n\n        try:\n            return get_node_text(self.css_one(path), smart=smart,\n                                 normalize_space=normalize_space)\n        except IndexError:\n            if default is NULL:\n                raise\n            else:\n                return default"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef css_number(self, path, default=NULL, ignore_spaces=False, smart=False,\n                   make_int=True):\n        \"\"\"\n        Find number in normalized text of node which\n            matches the given css path.\n        \"\"\"\n\n        try:\n            text = self.css_text(path, smart=smart)\n            return find_number(text, ignore_spaces=ignore_spaces,\n                               make_int=make_int)\n        except IndexError:\n            if default is NULL:\n                raise\n            else:\n                return default", "response": "Find number in normalized text of node which matches the given css path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstrip tags from the HTML content.", "response": "def strip_tags(self, content, smart=False):\n        \"\"\"\n        Strip tags from the HTML content.\n        \"\"\"\n        from lxml.html import fromstring\n\n        return get_node_text(fromstring(content), smart=smart)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef camel_case_to_underscore(name):\n    res = RE_TOKEN1.sub(r'\\1_\\2', name)\n    res = RE_TOKEN2.sub(r'\\1_\\2', res)\n    return res.lower()", "response": "Converts camel_case into CamelCase"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deprecated(use_instead=None):\n\n    def wrapped(func):\n        @wraps(func)\n        def new_func(*args, **kwargs):\n            message = \"Call to deprecated function %s.\" % func.__name__\n            if use_instead:\n                message += \" Use %s instead.\" % use_instead\n            if not DISABLE_WARNINGS:\n                warn(message, stacklevel=3)\n            return func(*args, **kwargs)\n        return new_func\n    return wrapped", "response": "This is a decorator which can be used to mark functions\n    as deprecated. It will result in a warning being emitted when the function is used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_time(self, key):\n        start = time.time()\n        try:\n            yield\n        finally:\n            self.timers[key] += (time.time() - start)", "response": "A context manager that logs the time taken for a specific key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_bom(data):\n    # common case is no BOM, so this is fast\n    if data and data[0] in _FIRST_CHARS:\n        for bom, encoding in _BOM_TABLE:\n            if data.startswith(bom):\n                return encoding, bom\n    return None, None", "response": "Read the byte order mark in the text and return the encoding represented by the BOM and the BOM."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, charset=None, headers=None):\n\n        if headers:\n            self.headers = headers\n        else:\n            # Parse headers only from last response\n            # There could be multiple responses in `self.head`\n            # in case of 301/302 redirect\n            # Separate responses\n            if self.head:\n                responses = self.head.rsplit(b'\\nHTTP/', 1)\n                # Cut off the 'HTTP/*' line from the last response\n                _, response = responses[-1].split(b'\\n', 1)\n                response = response.decode('utf-8', 'ignore')\n            else:\n                response = u''\n            if six.PY2:\n                # email_from_string does not work with unicode input\n                response = response.encode('utf-8')\n            self.headers = email.message_from_string(response)\n\n        if charset is None:\n            if isinstance(self.body, six.text_type):\n                self.charset = 'utf-8'\n            else:\n                self.detect_charset()\n        else:\n            self.charset = charset.lower()\n\n        self._unicode_body = None", "response": "Parse the HTTP response from Grab instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detect_charset(self):\n\n        charset = None\n\n        body_chunk = self.get_body_chunk()\n\n        if body_chunk:\n            # Try to extract charset from http-equiv meta tag\n            match_charset = RE_META_CHARSET.search(body_chunk)\n            if match_charset:\n                charset = match_charset.group(1)\n            else:\n                match_charset_html5 = RE_META_CHARSET_HTML5.search(body_chunk)\n                if match_charset_html5:\n                    charset = match_charset_html5.group(1)\n\n            # TODO: <meta charset=\"utf-8\" />\n            bom_enc, bom = read_bom(body_chunk)\n            if bom_enc:\n                charset = bom_enc\n                self.bom = bom\n\n            # Try to process XML declaration\n            if not charset:\n                if body_chunk.startswith(b'<?xml'):\n                    match = RE_XML_DECLARATION.search(body_chunk)\n                    if match:\n                        enc_match = RE_DECLARATION_ENCODING.search(\n                            match.group(0))\n                        if enc_match:\n                            charset = enc_match.group(1)\n\n        if not charset:\n            if 'Content-Type' in self.headers:\n                pos = self.headers['Content-Type'].find('charset=')\n                if pos > -1:\n                    charset = self.headers['Content-Type'][(pos + 8):]\n\n        if charset:\n            charset = charset.lower()\n            if not isinstance(charset, str):\n                # Convert to unicode (py2.x) or string (py3.x)\n                charset = charset.decode('utf-8')\n            # Check that python knows such charset\n            try:\n                codecs.lookup(charset)\n            except LookupError:\n                logger.debug('Unknown charset found: %s.'\n                             ' Using utf-8 istead.', charset)\n                self.charset = 'utf-8'\n            else:\n                self.charset = charset", "response": "Detect charset of the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a copy of the Response object.", "response": "def copy(self, new_grab=None):\n        \"\"\"\n        Clone the Response object.\n        \"\"\"\n\n        obj = self.__class__()\n        obj.process_grab(new_grab if new_grab else self.grab)\n\n        copy_keys = ('status', 'code', 'head', 'body', 'total_time',\n                     'connect_time', 'name_lookup_time',\n                     'url', 'charset', '_unicode_body',\n                     '_grab_config')\n        for key in copy_keys:\n            setattr(obj, key, getattr(self, key))\n\n        obj.headers = copy(self.headers)\n        # TODO: Maybe, deepcopy?\n        obj.cookies = copy(self.cookies)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves response body to file.", "response": "def save(self, path):\n        \"\"\"\n        Save response body to file.\n        \"\"\"\n\n        path_dir = os.path.split(path)[0]\n        if not os.path.exists(path_dir):\n            try:\n                os.makedirs(path_dir)\n            except OSError:\n                pass\n\n        with open(path, 'wb') as out:\n            out.write(self._bytes_body if self._bytes_body is not None\n                      else b'')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_hash(self, location, basedir, ext=None):\n\n        if isinstance(location, six.text_type):\n            location = location.encode('utf-8')\n        rel_path = hashed_path(location, ext=ext)\n        path = os.path.join(basedir, rel_path)\n        if not os.path.exists(path):\n            path_dir, _ = os.path.split(path)\n            try:\n                os.makedirs(path_dir)\n            except OSError:\n                pass\n            with open(path, 'wb') as out:\n                out.write(self._bytes_body)\n        return rel_path", "response": "Save response body into file with special path\n            builded from hash. That allows to lower number of files per directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn response body deserialized into JSON object.", "response": "def json(self):\n        \"\"\"\n        Return response body deserialized into JSON object.\n        \"\"\"\n\n        if six.PY3:\n            return json.loads(self.body.decode(self.charset))\n        else:\n            return json.loads(self.body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave response in temporary file and open it in GUI browser.", "response": "def browse(self):\n        \"\"\"\n        Save response in temporary file and open it in GUI browser.\n        \"\"\"\n\n        _, path = tempfile.mkstemp()\n        self.save(path)\n        webbrowser.open('file://' + path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef text_search(self, anchor, byte=False):\n\n        if isinstance(anchor, six.text_type):\n            if byte:\n                raise GrabMisuseError('The anchor should be bytes string in '\n                                      'byte mode')\n            else:\n                return anchor in self.unicode_body()\n\n        if not isinstance(anchor, six.text_type):\n            if byte:\n                # if six.PY3:\n                    # return anchor in self.body_as_bytes()\n                return anchor in self.body\n            else:\n                raise GrabMisuseError('The anchor should be byte string in '\n                                      'non-byte mode')", "response": "Search the substring in response body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef text_assert(self, anchor, byte=False):\n\n        if not self.text_search(anchor, byte=byte):\n            raise DataNotFound(u'Substring not found: %s' % anchor)", "response": "Assert that anchor is found in the text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nasserting that there are no anchors in the text.", "response": "def text_assert_any(self, anchors, byte=False):\n        \"\"\"\n        If no `anchors` were found then raise `DataNotFound` exception.\n        \"\"\"\n\n        found = False\n        for anchor in anchors:\n            if self.text_search(anchor, byte=byte):\n                found = True\n                break\n        if not found:\n            raise DataNotFound(u'Substrings not found: %s'\n                               % ', '.join(anchors))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rex_text(self, regexp, flags=0, byte=False, default=NULL):\n\n        # pylint: disable=no-member\n        try:\n            match = self.rex_search(regexp, flags=flags, byte=byte)\n        except DataNotFound:\n            if default is NULL:\n                raise DataNotFound('Regexp not found')\n            else:\n                return default\n        else:\n            return normalize_space(decode_entities(match.group(1)))", "response": "Search regular expression in response body and return content of first matching group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rex_search(self, regexp, flags=0, byte=False, default=NULL):\n\n        regexp = normalize_regexp(regexp, flags)\n        match = None\n        if byte:\n            if not isinstance(regexp.pattern, six.text_type) or not six.PY3:\n                # if six.PY3:\n                    # body = self.body_as_bytes()\n                # else:\n                    # body = self.body\n                match = regexp.search(self.body)\n        else:\n            if isinstance(regexp.pattern, six.text_type) or not six.PY3:\n                ubody = self.unicode_body()\n                match = regexp.search(ubody)\n        if match:\n            return match\n        else:\n            if default is NULL:\n                raise DataNotFound('Could not find regexp: %s' % regexp)\n            else:\n                return default", "response": "Search the regular expression in response. body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rex_assert(self, rex, byte=False):\n\n        self.rex_search(rex, byte=byte)", "response": "Assert that rex is a valid regexp expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unicode_body(self, ignore_errors=True, fix_special_entities=True):\n\n        if not self._unicode_body:\n            self._unicode_body = self.convert_body_to_unicode(\n                body=self.body,\n                bom=self.bom,\n                charset=self.charset,\n                ignore_errors=ignore_errors,\n                fix_special_entities=fix_special_entities,\n            )\n        return self._unicode_body", "response": "Return response body as unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef choose_form(self, number=None, xpath=None, name=None, **kwargs):\n\n        id_ = kwargs.pop('id', None)\n        if id_ is not None:\n            try:\n                self._lxml_form = self.select('//form[@id=\"%s\"]' % id_).node()\n            except IndexError:\n                raise DataNotFound(\"There is no form with id: %s\" % id_)\n        elif name is not None:\n            try:\n                self._lxml_form = self.select(\n                    '//form[@name=\"%s\"]' % name).node()\n            except IndexError:\n                raise DataNotFound('There is no form with name: %s' % name)\n        elif number is not None:\n            try:\n                self._lxml_form = self.tree.forms[number]\n            except IndexError:\n                raise DataNotFound('There is no form with number: %s' % number)\n        elif xpath is not None:\n            try:\n                self._lxml_form = self.select(xpath).node()\n            except IndexError:\n                raise DataNotFound(\n                    'Could not find form with xpath: %s' % xpath)\n        else:\n            raise GrabMisuseError('choose_form methods requires one of '\n                                  '[number, id, name, xpath] arguments')", "response": "Select the form for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form(self):\n\n        if self._lxml_form is None:\n            forms = [(idx, len(list(x.fields)))\n                     for idx, x in enumerate(self.tree.forms)]\n            if forms:\n                idx = sorted(forms, key=lambda x: x[1], reverse=True)[0][0]\n                self.choose_form(idx)\n            else:\n                raise DataNotFound('Response does not contains any form')\n        return self._lxml_form", "response": "This attribute points to default form."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of form element by its name attribute.", "response": "def set_input(self, name, value):\n        \"\"\"\n        Set the value of form element by its `name` attribute.\n\n        :param name: name of element\n        :param value: value which should be set to element\n\n        To check/uncheck the checkbox pass boolean value.\n\n        Example::\n\n            g.set_input('sex', 'male')\n\n            # Check the checkbox\n            g.set_input('accept', True)\n        \"\"\"\n\n        if self._lxml_form is None:\n            self.choose_form_by_element('.//*[@name=\"%s\"]' % name)\n        elem = self.form.inputs[name] # pylint: disable=no-member\n\n        processed = False\n        if getattr(elem, 'type', None) == 'checkbox':\n            if isinstance(value, bool):\n                elem.checked = value\n                processed = True\n\n        if not processed:\n            # We need to remember original values of file fields\n            # Because lxml will convert UploadContent/UploadFile object to\n            # string\n            if getattr(elem, 'type', '').lower() == 'file':\n                self._file_fields[name] = value\n                elem.value = ''\n            else:\n                elem.value = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the value of form element by its id attribute.", "response": "def set_input_by_id(self, _id, value):\n        \"\"\"\n        Set the value of form element by its `id` attribute.\n\n        :param _id: id of element\n        :param value: value which should be set to element\n        \"\"\"\n\n        xpath = './/*[@id=\"%s\"]' % _id\n        if self._lxml_form is None:\n            self.choose_form_by_element(xpath)\n        sel = XpathSelector(self.form)\n        elem = sel.select(xpath).node()\n        # pylint: disable=no-member\n        return self.set_input(elem.get('name'), value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_input_by_number(self, number, value):\n\n        sel = XpathSelector(self.form)\n        elem = sel.select('.//input[@type=\"text\"]')[number].node()\n        return self.set_input(elem.get('name'), value)", "response": "Set the value of form element by its number in the form\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the value of form element by xpath", "response": "def set_input_by_xpath(self, xpath, value):\n        \"\"\"\n        Set the value of form element by xpath\n\n        :param xpath: xpath path\n        :param value: value which should be set to element\n        \"\"\"\n\n        elem = self.select(xpath).node()\n\n        if self._lxml_form is None:\n            # Explicitly set the default form\n            # which contains found element\n            parent = elem\n            while True:\n                parent = parent.getparent() # pylint: disable=no-member\n                if parent.tag == 'form':\n                    self._lxml_form = parent\n                    break\n\n        # pylint: disable=no-member\n        return self.set_input(elem.get('name'), value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_form_request(\n            self, submit_name=None,\n            url=None, extra_post=None, remove_from_post=None):\n        \"\"\"\n        Submit default form.\n\n        :param submit_name: name of button which should be \"clicked\" to\n            submit form\n        :param url: explicitly specify form action url\n        :param extra_post: (dict or list of pairs) additional form data which\n            will override data automatically extracted from the form.\n        :param remove_from_post: list of keys to remove from the submitted data\n\n        Following input elements are automatically processed:\n\n        * input[type=\"hidden\"] - default value\n        * select: value of last option\n        * radio - ???\n        * checkbox - ???\n\n        Multipart forms are correctly recognized by grab library.\n        \"\"\"\n\n        # pylint: disable=no-member\n\n        post = self.form_fields()\n\n        # Build list of submit buttons which have a name\n        submit_controls = {}\n        for elem in self.form.inputs:\n            if (elem.tag == 'input' and elem.type == 'submit' and\n                    elem.get('name') is not None):\n                submit_controls[elem.name] = elem\n\n        # All this code need only for one reason:\n        # to not send multiple submit keys in form data\n        # in real life only this key is submitted whose button\n        # was pressed\n        if submit_controls:\n            # If name of submit control is not given then\n            # use the name of first submit control\n            if submit_name is None or submit_name not in submit_controls:\n                controls = sorted(submit_controls.values(),\n                                  key=lambda x: x.name)\n                submit_name = controls[0].name\n\n            # Form data should contain only one submit control\n            for name in submit_controls:\n                if name != submit_name:\n                    if name in post:\n                        del post[name]\n\n        if url:\n            action_url = urljoin(self.url, url)\n        else:\n            action_url = urljoin(self.url,\n                                 self.form.action)\n\n        # Values from `extra_post` should override values in form\n        # `extra_post` allows multiple value of one key\n\n        # Process saved values of file fields\n        if self.form.method == 'POST':\n            if 'multipart' in self.form.get('enctype', ''):\n                for key, obj in self._file_fields.items():\n                    post[key] = obj\n\n        post_items = list(post.items())\n        del post\n\n        if extra_post:\n            if isinstance(extra_post, dict):\n                extra_post_items = extra_post.items()\n            else:\n                extra_post_items = extra_post\n\n            # Drop existing post items with such key\n            keys_to_drop = set([x for x, y in extra_post_items])\n            for key in keys_to_drop:\n                post_items = [(x, y) for x, y in post_items if x != key]\n\n            for key, value in extra_post_items:\n                post_items.append((key, value))\n\n        if remove_from_post:\n            post_items = [(x, y) for x, y in post_items\n                          if x not in remove_from_post]\n\n        result = {\n            'multipart_post': None,\n            'post': None,\n            'url': None,\n        }\n\n        if self.form.method == 'POST':\n            if 'multipart' in self.form.get('enctype', ''):\n                result['multipart_post'] = post_items\n                #self.grab.setup(multipart_post=post_items)\n            else:\n                result['post'] = post_items\n                #self.grab.setup(post=post_items)\n            result['url'] = action_url\n            #self.grab.setup(url=action_url)\n\n        else:\n            url = action_url.split('?')[0] + '?' + smart_urlencode(post_items)\n            result['url'] = url\n            #self.grab.setup(url=url)\n\n        return result", "response": "Get the form request for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef form_fields(self):\n\n        fields = dict(self.form.fields) # pylint: disable=no-member\n\n        fields_to_remove = set()\n\n        for key, val in list(fields.items()):\n            if isinstance(val, CheckboxValues):\n                if not len(val): # pylint: disable=len-as-condition\n                    del fields[key]\n                elif len(val) == 1:\n                    fields[key] = val.pop()\n                else:\n                    fields[key] = list(val)\n            if isinstance(val, MultipleSelectOptions):\n                if not len(val): # pylint: disable=len-as-condition\n                    del fields[key]\n                elif len(val) == 1:\n                    fields[key] = val.pop()\n                else:\n                    fields[key] = list(val)\n\n        for elem in self.form.inputs: # pylint: disable=no-member\n            # Ignore elements without name\n            if not elem.get('name'):\n                continue\n\n            # Do not submit disabled fields\n            # http://www.w3.org/TR/html4/interact/forms.html#h-17.12\n            if elem.get('disabled'):\n                if elem.name in fields:\n                    fields_to_remove.add(elem.name)\n            elif getattr(elem, 'type', None) == 'checkbox':\n                if not elem.checked:\n                    if elem.name is not None:\n                        if elem.name in fields and fields[elem.name] is None:\n                            fields_to_remove.add(elem.name)\n            else:\n                if elem.name in fields_to_remove:\n                    fields_to_remove.remove(elem.name)\n                if elem.tag == 'select':\n                    if elem.name in fields and fields[elem.name] is None:\n                        if elem.value_options:\n                            fields[elem.name] = elem.value_options[0]\n\n                elif getattr(elem, 'type', None) == 'radio':\n                    if fields[elem.name] is None:\n                        fields[elem.name] = elem.get('value')\n        for fname in fields_to_remove:\n            del fields[fname]\n        return fields", "response": "Return the fields of the default form."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd two lists of parameters one by one", "response": "def add_params(param_list_left, param_list_right):\n    \"\"\"Add two lists of parameters one by one\n\n    :param param_list_left: list of numpy arrays\n    :param param_list_right: list of numpy arrays\n    :return: list of numpy arrays\n    \"\"\"\n    res = []\n    for x, y in zip(param_list_left, param_list_right):\n        res.append(x + y)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subtract_params(param_list_left, param_list_right):\n    res = []\n    for x, y in zip(param_list_left, param_list_right):\n        res.append(x - y)\n    return res", "response": "Subtract two lists of parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting list of zero - valued numpy arrays for specified list of numpy arrays", "response": "def get_neutral(array_list):\n    \"\"\"Get list of zero-valued numpy arrays for\n    specified list of numpy arrays\n\n    :param array_list: list of numpy arrays\n    :return: list of zeros of same shape as input\n    \"\"\"\n    res = []\n    for x in array_list:\n        res.append(np.zeros_like(x))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef divide_by(array_list, num_workers):\n    for i, x in enumerate(array_list):\n        array_list[i] /= num_workers\n    return array_list", "response": "Divides a list of parameters by an integer num_workers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefines the parameter server service.", "response": "def start_flask_service(self):\n        \"\"\"Define Flask parameter server service.\n\n        This HTTP server can do two things: get the current model\n        parameters and update model parameters. After registering\n        the `parameters` and `update` routes, the service will\n        get started.\n\n        \"\"\"\n        app = Flask(__name__)\n        self.app = app\n\n        @app.route('/')\n        def home():\n            return 'Elephas'\n\n        @app.route('/parameters', methods=['GET'])\n        def handle_get_parameters():\n            if self.mode == 'asynchronous':\n                self.lock.acquire_read()\n            self.pickled_weights = pickle.dumps(self.weights, -1)\n            pickled_weights = self.pickled_weights\n            if self.mode == 'asynchronous':\n                self.lock.release()\n            return pickled_weights\n\n        @app.route('/update', methods=['POST'])\n        def handle_update_parameters():\n            delta = pickle.loads(request.data)\n            if self.mode == 'asynchronous':\n                self.lock.acquire_write()\n\n            if not self.master_network.built:\n                self.master_network.build()\n\n            # Just apply the gradient\n            weights_before = self.weights\n            self.weights = subtract_params(weights_before, delta)\n\n            if self.mode == 'asynchronous':\n                self.lock.release()\n            return 'Update done'\n\n        master_url = determine_master(self.port)\n        host = master_url.split(':')[0]\n        self.app.run(host=host, debug=self.debug, port=self.port,\n                     threaded=self.threaded, use_reloader=self.use_reloader)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_matrix(np_array):\n    if len(np_array.shape) == 2:\n        return Matrices.dense(np_array.shape[0],\n                              np_array.shape[1],\n                              np_array.ravel())\n    else:\n        raise Exception(\"An MLLib Matrix can only be created from a two-dimensional \" +\n                        \"numpy array, got {}\".format(len(np_array.shape)))", "response": "Convert numpy array to MLlib Matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_vector(np_array):\n    if len(np_array.shape) == 1:\n        return Vectors.dense(np_array)\n    else:\n        raise Exception(\"An MLLib Vector can only be created from a one-dimensional \" +\n                        \"numpy array, got {}\".format(len(np_array.shape)))", "response": "Convert numpy array to MLlib Vector"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an ND4J array to a numpy array", "response": "def to_numpy(nd4j_array):\n    \"\"\" Convert an ND4J array to a numpy array\n    :param nd4j_array:\n    :return:\n    \"\"\"\n    buff = nd4j_array.data()\n    address = buff.pointer().address()\n    type_name = java_classes.DataTypeUtil.getDtypeFromContext()\n    data_type = java_classes.DataTypeUtil.getDTypeForName(type_name)\n    mapping = {\n        'double': ctypes.c_double,\n        'float': ctypes.c_float\n    }\n    Pointer = ctypes.POINTER(mapping[data_type])\n    pointer = ctypes.cast(address, Pointer)\n    np_array = np.ctypeslib.as_array(pointer, tuple(nd4j_array.shape()))\n    return np_array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retrieve_keras_weights(java_model):\n    weights = []\n    layers = java_model.getLayers()\n    for layer in layers:\n        params = layer.paramTable()\n        keys = params.keySet()\n        key_list = java_classes.ArrayList(keys)\n        for key in key_list:\n            weight = params.get(key)\n            np_weight = np.squeeze(to_numpy(weight))\n            weights.append(np_weight)\n    return weights", "response": "This function returns a list of numpy arrays that can be used to set the resulting weights to the original Keras model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fit(self, df):\n        simple_rdd = df_to_simple_rdd(df, categorical=self.get_categorical_labels(), nb_classes=self.get_nb_classes(),\n                                      features_col=self.getFeaturesCol(), label_col=self.getLabelCol())\n        simple_rdd = simple_rdd.repartition(self.get_num_workers())\n        keras_model = model_from_yaml(self.get_keras_model_config())\n        metrics = self.get_metrics()\n        loss = self.get_loss()\n        optimizer = get_optimizer(self.get_optimizer_config())\n        keras_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\n        spark_model = SparkModel(model=keras_model,\n                                 mode=self.get_mode(),\n                                 frequency=self.get_frequency(),\n                                 num_workers=self.get_num_workers())\n        spark_model.fit(simple_rdd,\n                        epochs=self.get_epochs(),\n                        batch_size=self.get_batch_size(),\n                        verbose=self.get_verbosity(),\n                        validation_split=self.get_validation_split())\n\n        model_weights = spark_model.master_network.get_weights()\n        weights = simple_rdd.ctx.broadcast(model_weights)\n        return ElephasTransformer(labelCol=self.getLabelCol(),\n                                  outputCol='prediction',\n                                  keras_model_config=spark_model.master_network.to_yaml(),\n                                  weights=weights)", "response": "Private fit method of the Estimator which trains the model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data():\n    from keras.datasets import mnist\n    from keras.utils import np_utils\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(60000, 784)\n    x_test = x_test.reshape(10000, 784)\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    x_train /= 255\n    x_test /= 255\n    nb_classes = 10\n    y_train = np_utils.to_categorical(y_train, nb_classes)\n    y_test = np_utils.to_categorical(y_test, nb_classes)\n    return x_train, y_train, x_test, y_test", "response": "Data providing function for the as\n    model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate Keras model with double curly brackets dropped - in as needed.", "response": "def model(x_train, y_train, x_test, y_test):\n    \"\"\"Model providing function:\n\n    Create Keras model with double curly brackets dropped-in as needed.\n    Return value has to be a valid python dictionary with two customary keys:\n        - loss: Specify a numeric evaluation metric to be minimized\n        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n    The last one is optional, though recommended, namely:\n        - model: specify the model just created so that we can later use it again.\n    \"\"\"\n    from keras.models import Sequential\n    from keras.layers.core import Dense, Dropout, Activation\n    from keras.optimizers import RMSprop\n\n    keras_model = Sequential()\n    keras_model.add(Dense(512, input_shape=(784,)))\n    keras_model.add(Activation('relu'))\n    keras_model.add(Dropout({{uniform(0, 1)}}))\n    keras_model.add(Dense({{choice([256, 512, 1024])}}))\n    keras_model.add(Activation('relu'))\n    keras_model.add(Dropout({{uniform(0, 1)}}))\n    keras_model.add(Dense(10))\n    keras_model.add(Activation('softmax'))\n\n    rms = RMSprop()\n    keras_model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['acc'])\n\n    keras_model.fit(x_train, y_train,\n                    batch_size={{choice([64, 128])}},\n                    epochs=1,\n                    verbose=2,\n                    validation_data=(x_test, y_test))\n    score, acc = keras_model.evaluate(x_test, y_test, verbose=0)\n    print('Test accuracy:', acc)\n    return {'loss': -acc, 'status': STATUS_OK, 'model': keras_model.to_yaml(),\n            'weights': pickle.dumps(keras_model.get_weights())}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_nd4j_dtype(np_dtype):\n    if type(np_dtype) == type:\n        np_dtype = np_dtype.__name__\n    elif type(np_dtype) == np.dtype:\n        np_dtype = np_dtype.name\n    mapping = {\n        'float64': 'double',\n        'float32': 'float',\n        'float16': 'half'\n    }\n    nd4j_dtype = mapping.get(np_dtype)\n    if not nd4j_dtype:\n        raise Exception('Invalid numpy data type : ' + np_dtype)\n    return nd4j_dtype", "response": "Gets the equivalent nd4j data type for a given numpy data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_np_dtype(nd4j_dtype):\n    mapping = {\n        'double': np.float64,\n        'float': np.float32,\n        'half': np.float16\n    }\n    np_dtype = mapping.get(nd4j_dtype)\n    if not np_dtype:\n        raise Exception('Invalid nd4j data type : ' + nd4j_dtype)\n    return np_dtype", "response": "Gets the equivalent numpy data type for a given nd4j data type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert numpy array to nd4j array", "response": "def _from_numpy(np_array):\n    \"\"\"\n    Convert numpy array to nd4j array\n    \"\"\"\n\n    # Convert the numpy array to nd4j context dtype\n    required_dtype = get_np_dtype(get_context_dtype())\n    if np_array.dtype != required_dtype:\n        raise Exception(\"{} is required, got {}\".format(\n            repr(required_dtype), repr(np_array.dtype)))\n\n    # Nd4j does not have 1-d vectors.\n    # So we add a dummy dimension.\n    if np_array.ndim == 1:\n        np_array = np.expand_dims(np_array, 0)\n\n    # We have to maintain references to all incoming\n    # numpy arrays. Else they will get GCed\n\n    # creates a Nd4j array from a numpy array\n    # To create an Nd4j array, we need 3 things:\n    # buffer, strides, and shape\n\n    # Get the buffer\n    # A buffer is basically an array. To get the buffer object\n    # we need a pointer to the first element and the size.\n    pointer_address, _ = np_array.__array_interface__['data']\n    _refs.append(np_array)\n    pointer = native_ops.pointerForAddress(pointer_address)\n    size = np_array.size\n    mapping = {\n        np.float64: DoublePointer,\n        np.float32: FloatPointer,\n    }\n    pointer = mapping[required_dtype](pointer)\n    buff = Nd4j.createBuffer(pointer, size)\n    assert buff.address() == pointer_address\n    _refs.append(buff)\n    # Get the strides\n    # strides = tuple of bytes to step in each\n    # dimension when traversing an array.\n    elem_size = buff.getElementSize()\n    # Make sure word size is same in both python\n    # and java worlds\n    assert elem_size == np_array.dtype.itemsize\n    strides = np_array.strides\n    # numpy uses byte wise strides. We have to\n    # convert it to word wise strides.\n    strides = [dim / elem_size for dim in strides]\n\n    # Finally, shape:\n    shape = np_array.shape\n\n    nd4j_array = Nd4j.create(buff, shape, strides, 0)\n    assert buff.address() == nd4j_array.data().address()\n    return nd4j_array"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _to_numpy(nd4j_array):\n    buff = nd4j_array.data()\n    address = buff.pointer().address()\n    dtype = get_context_dtype()\n    mapping = {\n        'double': ctypes.c_double,\n        'float': ctypes.c_float\n    }\n    Pointer = ctypes.POINTER(mapping[dtype])\n    pointer = ctypes.cast(address, Pointer)\n    np_array = np.ctypeslib.as_array(pointer, tuple(nd4j_array.shape()))\n    return np_array", "response": "Convert nd4j array to numpy array"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nacquires a write lock.", "response": "def acquire_write(self):\n        \"\"\"\n        Acquire a write lock. Only one thread can hold this lock, and\n        only when no read locks are also held.\n        \"\"\"\n        self.monitor.acquire()\n        while self.rwlock != 0:\n            self.writers_waiting += 1\n            self.writers_ok.wait()\n            self.writers_waiting -= 1\n        self.rwlock = -1\n        self.monitor.release()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef release(self):\n        self.monitor.acquire()\n        if self.rwlock < 0:\n            self.rwlock = 0\n        else:\n            self.rwlock -= 1\n        wake_writers = self.writers_waiting and self.rwlock == 0\n        wake_readers = self.writers_waiting == 0\n        self.monitor.release()\n        if wake_writers:\n            self.writers_ok.acquire()\n            self.writers_ok.notify()\n            self.writers_ok.release()\n        elif wake_readers:\n            self.readers_ok.acquire()\n            self.readers_ok.notifyAll()\n            self.readers_ok.release()", "response": "Release a lock whether read or write."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_data_frame(sc, features, labels, categorical=False):\n    lp_rdd = to_labeled_point(sc, features, labels, categorical)\n    sql_context = SQLContext(sc)\n    df = sql_context.createDataFrame(lp_rdd)\n    return df", "response": "Convert numpy arrays of features and labels into Spark DataFrame\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_data_frame(df, categorical=False, nb_classes=None):\n    lp_rdd = df.rdd.map(lambda row: LabeledPoint(row.label, row.features))\n    features, labels = from_labeled_point(lp_rdd, categorical, nb_classes)\n    return features, labels", "response": "Convert DataFrame back to pair of numpy arrays\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef df_to_simple_rdd(df, categorical=False, nb_classes=None, features_col='features', label_col='label'):\n    sql_context = df.sql_ctx\n    sql_context.registerDataFrameAsTable(df, \"temp_table\")\n    selected_df = sql_context.sql(\n        \"SELECT {0} AS features, {1} as label from temp_table\".format(features_col, label_col))\n    if isinstance(selected_df.first().features, MLLibVector):\n        lp_rdd = selected_df.rdd.map(\n            lambda row: LabeledPoint(row.label, row.features))\n    else:\n        lp_rdd = selected_df.rdd.map(lambda row: LabeledPoint(\n            row.label, MLLibVectors.fromML(row.features)))\n    rdd = lp_to_simple_rdd(lp_rdd, categorical, nb_classes)\n    return rdd", "response": "Convert DataFrame into RDD of pairs of base classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrain an elephas model on an RDD.", "response": "def fit(self, rdd, epochs=10, batch_size=32,\n            verbose=0, validation_split=0.1):\n        \"\"\"\n        Train an elephas model on an RDD. The Keras model configuration as specified\n        in the elephas model is sent to Spark workers, abd each worker will be trained\n        on their data partition.\n\n        :param rdd: RDD with features and labels\n        :param epochs: number of epochs used for training\n        :param batch_size: batch size used for training\n        :param verbose: logging verbosity level (0, 1 or 2)\n        :param validation_split: percentage of data set aside for validation\n        \"\"\"\n        print('>>> Fit model')\n        if self.num_workers:\n            rdd = rdd.repartition(self.num_workers)\n\n        if self.mode in ['asynchronous', 'synchronous', 'hogwild']:\n            self._fit(rdd, epochs, batch_size, verbose, validation_split)\n        else:\n            raise ValueError(\n                \"Choose from one of the modes: asynchronous, synchronous or hogwild\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprotects train method to make wrapping of modes easier", "response": "def _fit(self, rdd, epochs, batch_size, verbose, validation_split):\n        \"\"\"Protected train method to make wrapping of modes easier\n        \"\"\"\n        self._master_network.compile(optimizer=self.master_optimizer,\n                                     loss=self.master_loss,\n                                     metrics=self.master_metrics)\n        if self.mode in ['asynchronous', 'hogwild']:\n            self.start_server()\n        train_config = self.get_train_config(\n            epochs, batch_size, verbose, validation_split)\n        mode = self.parameter_server_mode\n        freq = self.frequency\n        optimizer = self.master_optimizer\n        loss = self.master_loss\n        metrics = self.master_metrics\n        custom = self.custom_objects\n\n        yaml = self._master_network.to_yaml()\n        init = self._master_network.get_weights()\n        parameters = rdd.context.broadcast(init)\n\n        if self.mode in ['asynchronous', 'hogwild']:\n            print('>>> Initialize workers')\n            worker = AsynchronousSparkWorker(\n                yaml, parameters, mode, train_config, freq, optimizer, loss, metrics, custom)\n            print('>>> Distribute load')\n            rdd.mapPartitions(worker.train).collect()\n            print('>>> Async training complete.')\n            new_parameters = self.client.get_parameters()\n        elif self.mode == 'synchronous':\n            worker = SparkWorker(yaml, parameters, train_config,\n                                 optimizer, loss, metrics, custom)\n            gradients = rdd.mapPartitions(worker.train).collect()\n            new_parameters = self._master_network.get_weights()\n            for grad in gradients:  # simply accumulate gradients one by one\n                new_parameters = subtract_params(new_parameters, grad)\n            print('>>> Synchronous training complete.')\n        else:\n            raise ValueError(\"Unsupported mode {}\".format(self.mode))\n        self._master_network.set_weights(new_parameters)\n        if self.mode in ['asynchronous', 'hogwild']:\n            self.stop_server()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(self, labeled_points, epochs=10, batch_size=32, verbose=0, validation_split=0.1,\n            categorical=False, nb_classes=None):\n        \"\"\"Train an elephas model on an RDD of LabeledPoints\n        \"\"\"\n        rdd = lp_to_simple_rdd(labeled_points, categorical, nb_classes)\n        rdd = rdd.repartition(self.num_workers)\n        self._fit(rdd=rdd, epochs=epochs, batch_size=batch_size,\n                  verbose=verbose, validation_split=validation_split)", "response": "Train an elephas model on an RDD of LabeledPoints"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict(self, mllib_data):\n        if isinstance(mllib_data, pyspark.mllib.linalg.Matrix):\n            return to_matrix(self._master_network.predict(from_matrix(mllib_data)))\n        elif isinstance(mllib_data, pyspark.mllib.linalg.Vector):\n            return to_vector(self._master_network.predict(from_vector(mllib_data)))\n        else:\n            raise ValueError(\n                'Provide either an MLLib matrix or vector, got {}'.format(mllib_data.__name__))", "response": "Predict probabilities for an RDD of features"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntraining a keras model on a worker", "response": "def train(self, data_iterator):\n        \"\"\"Train a keras model on a worker\n        \"\"\"\n        optimizer = get_optimizer(self.master_optimizer)\n        self.model = model_from_yaml(self.yaml, self.custom_objects)\n        self.model.compile(optimizer=optimizer,\n                           loss=self.master_loss, metrics=self.master_metrics)\n        self.model.set_weights(self.parameters.value)\n\n        feature_iterator, label_iterator = tee(data_iterator, 2)\n        x_train = np.asarray([x for x, y in feature_iterator])\n        y_train = np.asarray([y for x, y in label_iterator])\n\n        self.model.compile(optimizer=self.master_optimizer,\n                           loss=self.master_loss,\n                           metrics=self.master_metrics)\n\n        weights_before_training = self.model.get_weights()\n        if x_train.shape[0] > self.train_config.get('batch_size'):\n            self.model.fit(x_train, y_train, **self.train_config)\n        weights_after_training = self.model.get_weights()\n        deltas = subtract_params(\n            weights_before_training, weights_after_training)\n        yield deltas"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef train(self, data_iterator):\n        feature_iterator, label_iterator = tee(data_iterator, 2)\n        x_train = np.asarray([x for x, y in feature_iterator])\n        y_train = np.asarray([y for x, y in label_iterator])\n\n        if x_train.size == 0:\n            return\n\n        optimizer = get_optimizer(self.master_optimizer)\n        self.model = model_from_yaml(self.yaml, self.custom_objects)\n        self.model.compile(optimizer=optimizer,\n                           loss=self.master_loss, metrics=self.master_metrics)\n        self.model.set_weights(self.parameters.value)\n\n        epochs = self.train_config['epochs']\n        batch_size = self.train_config.get('batch_size')\n        nb_train_sample = x_train.shape[0]\n        nb_batch = int(np.ceil(nb_train_sample / float(batch_size)))\n        index_array = np.arange(nb_train_sample)\n        batches = [\n            (i * batch_size, min(nb_train_sample, (i + 1) * batch_size))\n            for i in range(0, nb_batch)\n        ]\n\n        if self.frequency == 'epoch':\n            for epoch in range(epochs):\n                weights_before_training = self.client.get_parameters()\n                self.model.set_weights(weights_before_training)\n                self.train_config['epochs'] = 1\n                if x_train.shape[0] > batch_size:\n                    self.model.fit(x_train, y_train, **self.train_config)\n                self.train_config['epochs'] = epochs\n                weights_after_training = self.model.get_weights()\n                deltas = subtract_params(\n                    weights_before_training, weights_after_training)\n                self.client.update_parameters(deltas)\n        elif self.frequency == 'batch':\n            for epoch in range(epochs):\n                if x_train.shape[0] > batch_size:\n                    for (batch_start, batch_end) in batches:\n                        weights_before_training = self.client.get_parameters()\n                        self.model.set_weights(weights_before_training)\n                        batch_ids = index_array[batch_start:batch_end]\n                        x = slice_arrays(x_train, batch_ids)\n                        y = slice_arrays(y_train, batch_ids)\n                        self.model.train_on_batch(x, y)\n                        weights_after_training = self.model.get_weights()\n                        deltas = subtract_params(\n                            weights_before_training, weights_after_training)\n                        self.client.update_parameters(deltas)\n        else:\n            raise ValueError(\n                'frequency parameter can be `epoch` or `batch, got {}'.format(self.frequency))\n        yield []", "response": "Train a keras model on a worker and send asynchronous updates to parameter server"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the master address of the cluster.", "response": "def determine_master(port=4000):\n    \"\"\"Determine address of master so that workers\n    can connect to it. If the environment variable\n    SPARK_LOCAL_IP is set, that address will be used.\n\n    :param port: port on which the application runs\n    :return: Master address\n\n    Example usage:\n        SPARK_LOCAL_IP=127.0.0.1 spark-submit --master \\\n            local[8] examples/mllib_mlp.py\n    \"\"\"\n    if os.environ.get('SPARK_LOCAL_IP'):\n        return os.environ['SPARK_LOCAL_IP'] + \":\" + str(port)\n    else:\n        return gethostbyname(gethostname()) + \":\" + str(port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads num_bytes bytes from the specified socket.", "response": "def _receive_all(socket, num_bytes):\n    \"\"\"Reads `num_bytes` bytes from the specified socket.\n\n    :param socket: open socket instance\n    :param num_bytes: number of bytes to read\n\n    :return: received data\n    \"\"\"\n\n    buffer = ''\n    buffer_size = 0\n    bytes_left = num_bytes\n    while buffer_size < num_bytes:\n        data = socket.recv(bytes_left)\n        delta = len(data)\n        buffer_size += delta\n        bytes_left -= delta\n        buffer += data\n    return buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receive(socket, num_bytes=20):\n    length = int(_receive_all(socket, num_bytes).decode())\n    serialized_data = _receive_all(socket, length)\n    return pickle.loads(serialized_data)", "response": "Receive data from open socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(socket, data, num_bytes=20):\n    pickled_data = pickle.dumps(data, -1)\n    length = str(len(pickled_data)).zfill(num_bytes)\n    socket.sendall(length.encode())\n    socket.sendall(pickled_data)", "response": "Send data to specified socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert numpy features and labels into a JavaRDD of DL4J DataSet type.", "response": "def to_java_rdd(jsc, features, labels, batch_size):\n    \"\"\"Convert numpy features and labels into a JavaRDD of\n    DL4J DataSet type.\n\n    :param jsc: JavaSparkContext from pyjnius\n    :param features: numpy array with features\n    :param labels: numpy array with labels:\n    :return: JavaRDD<DataSet>\n    \"\"\"\n    data_sets = java_classes.ArrayList()\n    num_batches = int(len(features) / batch_size)\n    for i in range(num_batches):\n        xi = ndarray(features[:batch_size].copy())\n        yi = ndarray(labels[:batch_size].copy())\n        data_set = java_classes.DataSet(xi.array, yi.array)\n        data_sets.add(data_set)\n        features = features[batch_size:]\n        labels = labels[batch_size:]\n\n    return jsc.parallelize(data_sets)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_simple_rdd(sc, features, labels):\n    pairs = [(x, y) for x, y in zip(features, labels)]\n    return sc.parallelize(pairs)", "response": "Convert numpy arrays of features and labels into an RDD of pairs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_labeled_point(sc, features, labels, categorical=False):\n    labeled_points = []\n    for x, y in zip(features, labels):\n        if categorical:\n            lp = LabeledPoint(np.argmax(y), to_vector(x))\n        else:\n            lp = LabeledPoint(y, to_vector(x))\n        labeled_points.append(lp)\n    return sc.parallelize(labeled_points)", "response": "Convert numpy arrays of features and labels into a LabeledPoint RDD for MLlib and ML integration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a LabeledPoint RDD back to a pair of numpy arrays features and labels.", "response": "def from_labeled_point(rdd, categorical=False, nb_classes=None):\n    \"\"\"Convert a LabeledPoint RDD back to a pair of numpy arrays\n\n    :param rdd: LabeledPoint RDD\n    :param categorical: boolean, if labels should be one-hot encode when returned\n    :param nb_classes: optional int, indicating the number of class labels\n    :return: pair of numpy arrays, features and labels\n    \"\"\"\n    features = np.asarray(\n        rdd.map(lambda lp: from_vector(lp.features)).collect())\n    labels = np.asarray(rdd.map(lambda lp: lp.label).collect(), dtype='int32')\n    if categorical:\n        if not nb_classes:\n            nb_classes = np.max(labels) + 1\n        temp = np.zeros((len(labels), nb_classes))\n        for i, label in enumerate(labels):\n            temp[i, label] = 1.\n        labels = temp\n    return features, labels"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_label(label, nb_classes):\n    encoded = np.zeros(nb_classes)\n    encoded[int(label)] = 1.\n    return encoded", "response": "One - hot encoding of a single label in a sequence of nb_classes classes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lp_to_simple_rdd(lp_rdd, categorical=False, nb_classes=None):\n    if categorical:\n        if not nb_classes:\n            labels = np.asarray(lp_rdd.map(\n                lambda lp: lp.label).collect(), dtype='int32')\n            nb_classes = np.max(labels) + 1\n        rdd = lp_rdd.map(lambda lp: (from_vector(lp.features),\n                                     encode_label(lp.label, nb_classes)))\n    else:\n        rdd = lp_rdd.map(lambda lp: (from_vector(lp.features), lp.label))\n    return rdd", "response": "Convert a LabeledPoint RDD into a Spark RDD of feature - label pairs with categorical = True."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetect the nginx configuration file path based on nginx - V output", "response": "def detect_config_path():\n    \"\"\"\n    Get nginx configuration file path based on `nginx -V` output\n    :return: detected nginx configuration file path\n    \"\"\"\n    try:\n        proc = subprocess.Popen(['nginx', '-V'], stderr=subprocess.PIPE)\n    except OSError:\n        error_exit('Access log file or format was not set and nginx config file cannot be detected. ' +\n                   'Perhaps nginx is not in your PATH?')\n\n    stdout, stderr = proc.communicate()\n    version_output = stderr.decode('utf-8')\n    conf_path_match = re.search(r'--conf-path=(\\S*)', version_output)\n    if conf_path_match is not None:\n        return conf_path_match.group(1)\n\n    prefix_match = re.search(r'--prefix=(\\S*)', version_output)\n    if prefix_match is not None:\n        return prefix_match.group(1) + '/conf/nginx.conf'\n    return '/etc/nginx/nginx.conf'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_access_logs(config):\n    access_log = Literal(\"access_log\") + ZeroOrMore(parameter) + semicolon\n    access_log.ignore(pythonStyleComment)\n\n    for directive in access_log.searchString(config).asList():\n        path = directive[1]\n        if path == 'off' or path.startswith('syslog:'):\n            # nothing to process here\n            continue\n\n        format_name = 'combined'\n        if len(directive) > 2 and '=' not in directive[2]:\n            format_name = directive[2]\n\n        yield path, format_name", "response": "Parse config for access_log directives\n    Parse config for access_log directives\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing config for log_format directives Parse config for log_format name and format string", "response": "def get_log_formats(config):\n    \"\"\"\n    Parse config for log_format directives\n    :return: iterator over ('format name', 'format string') tuple of found directives\n    \"\"\"\n    # log_format name [params]\n    log_format = Literal('log_format') + parameter + Group(OneOrMore(parameter)) + semicolon\n    log_format.ignore(pythonStyleComment)\n\n    for directive in log_format.searchString(config).asList():\n        name = directive[1]\n        format_string = ''.join(directive[2])\n        yield name, format_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_log_config(arguments):\n    config = arguments['--config']\n    if config is None:\n        config = detect_config_path()\n    if not os.path.exists(config):\n        error_exit('Nginx config file not found: %s' % config)\n\n    with open(config) as f:\n        config_str = f.read()\n    access_logs = dict(get_access_logs(config_str))\n    if not access_logs:\n        error_exit('Access log file is not provided and ngxtop cannot detect it from your config file (%s).' % config)\n\n    log_formats = dict(get_log_formats(config_str))\n    if len(access_logs) == 1:\n        log_path, format_name = list(access_logs.items())[0]\n        if format_name == 'combined':\n            return log_path, LOG_FORMAT_COMBINED\n        if format_name not in log_formats:\n            error_exit('Incorrect format name set in config for access log file \"%s\"' % log_path)\n        return log_path, log_formats[format_name]\n\n    # multiple access logs configured, offer to select one\n    print('Multiple access logs detected in configuration:')\n    log_path = choose_one(list(access_logs.keys()), 'Select access log file to process: ')\n    format_name = access_logs[log_path]\n    if format_name not in log_formats:\n        error_exit('Incorrect format name set in config for access log file \"%s\"' % log_path)\n    return log_path, log_formats[format_name]", "response": "Detects the access log config of nginx and returns the path and format of the detected access log file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds regular expression to parse given log_format.", "response": "def build_pattern(log_format):\n    \"\"\"\n    Build regular expression to parse given format.\n    :param log_format: format string to parse\n    :return: regular expression to parse given format\n    \"\"\"\n    if log_format == 'combined':\n        log_format = LOG_FORMAT_COMBINED\n    elif log_format == 'common':\n        log_format = LOG_FORMAT_COMMON\n    pattern = re.sub(REGEX_SPECIAL_CHARS, r'\\\\\\1', log_format)\n    pattern = re.sub(REGEX_LOG_FORMAT_VARIABLE, '(?P<\\\\1>.*)', pattern)\n    return re.compile(pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_variables(log_format):\n    if log_format == 'combined':\n        log_format = LOG_FORMAT_COMBINED\n    for match in re.findall(REGEX_LOG_FORMAT_VARIABLE, log_format):\n        yield match", "response": "Extract all variables from a log format string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef follow(the_file):\n    with open(the_file) as f:\n        f.seek(0, 2)  # seek to eof\n        while True:\n            line = f.readline()\n            if not line:\n                time.sleep(0.1)  # sleep briefly before trying again\n                continue\n            yield line", "response": "Follow a given file and yield new lines when they are available."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_field(field, func, dict_sequence):\n    for item in dict_sequence:\n        try:\n            item[field] = func(item.get(field, None))\n            yield item\n        except ValueError:\n            pass", "response": "Apply given function to value of given key in every dictionary in sequence and yield all items that have the given field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_field(field, func, dict_sequence):\n    for item in dict_sequence:\n        if field not in item:\n            item[field] = func(item)\n        yield item", "response": "Add given field to given record and store result in given field of current record."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getCentroid(attribute_variants, comparator):\n\n    n = len(attribute_variants)\n\n    distance_matrix = numpy.zeros([n, n])\n\n    # populate distance matrix by looping through elements of matrix triangle\n    for i in range(0, n):\n        for j in range(0, i):\n            distance = comparator(attribute_variants[i], attribute_variants[j])\n            distance_matrix[i, j] = distance_matrix[j, i] = distance\n\n    average_distance = distance_matrix.mean(0)\n\n    # there can be ties for minimum, average distance string\n    min_dist_indices = numpy.where(\n        average_distance == average_distance.min())[0]\n\n    if len(min_dist_indices) > 1:\n        centroid = breakCentroidTie(attribute_variants, min_dist_indices)\n    else:\n        centroid_index = min_dist_indices[0]\n        centroid = attribute_variants[centroid_index]\n\n    return centroid", "response": "Takes in a list of attribute values for a field evaluates the centroid using the comparator and returns the centroid"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of records within a duplicate cluster constructs a canonical representation of the duplicate cluster.", "response": "def getCanonicalRep(record_cluster):\n    \"\"\"\n    Given a list of records within a duplicate cluster, constructs a\n    canonical representation of the cluster by finding canonical\n    values for each field\n\n    \"\"\"\n    canonical_rep = {}\n\n    keys = record_cluster[0].keys()\n\n    for key in keys:\n        key_values = []\n        for record in record_cluster:\n            # assume non-empty values always better than empty value\n            # for canonical record\n            if record[key]:\n                key_values.append(record[key])\n        if key_values:\n            canonical_rep[key] = getCentroid(key_values, comparator)\n        else:\n            canonical_rep[key] = ''\n\n    return canonical_rep"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nearIntegersPredicate(field):\n    ints = integers(field)\n    near_ints = set()\n    for char in ints:\n        num = int(char)\n        near_ints.add(str(num - 1))\n        near_ints.add(str(num))\n        near_ints.add(str(num + 1))\n\n    return near_ints", "response": "return any integers N + 1 and N - 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of grid coordinates at the nearest base value of a latitude and long pair.", "response": "def latLongGridPredicate(field, digits=1):\n    \"\"\"\n    Given a lat / long pair, return the grid coordinates at the\n    nearest base value.  e.g., (42.3, -5.4) returns a grid at 0.1\n    degree resolution of 0.1 degrees of latitude ~ 7km, so this is\n    effectively a 14km lat grid.  This is imprecise for longitude,\n    since 1 degree of longitude is 0km at the poles, and up to 111km\n    at the equator. But it should be reasonably precise given some\n    prior logical block (e.g., country).\n    \"\"\"\n    if any(field):\n        return (str([round(dim, digits) for dim in field]),)\n    else:\n        return ()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn random combinations of indices for a square matrix of size n_records", "response": "def randomPairs(n_records, sample_size):\n    \"\"\"\n    Return random combinations of indices for a square matrix of size n\n    records. For a discussion of how this works see\n    http://stackoverflow.com/a/14839010/98080\n\n    \"\"\"\n    n = int(n_records * (n_records - 1) / 2)\n\n    if sample_size >= n:\n        random_pairs = numpy.arange(n, dtype='uint')\n    else:\n        try:\n            random_pairs = numpy.array(random.sample(range(n), sample_size),\n                                       dtype='uint')\n        except OverflowError:\n            return randomPairsWithReplacement(n_records, sample_size)\n\n    b = 1 - 2 * n_records\n\n    root = (-b - 2 * numpy.sqrt(2 * (n - random_pairs) + 0.25)) / 2\n\n    i = numpy.floor(root).astype('uint')\n    j = numpy.rint(random_pairs + i * (b + i + 2) / 2 + 1).astype('uint')\n\n    return zip(i, j)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns random combinations of indices for record list A and B.", "response": "def randomPairsMatch(n_records_A, n_records_B, sample_size):\n    \"\"\"\n    Return random combinations of indices for record list A and B\n    \"\"\"\n    n = int(n_records_A * n_records_B)\n\n    if sample_size >= n:\n        random_pairs = numpy.arange(n)\n    else:\n        random_pairs = numpy.array(random.sample(range(n), sample_size),\n                                   dtype=int)\n\n    i, j = numpy.unravel_index(random_pairs, (n_records_A, n_records_B))\n\n    return zip(i, j)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef thresholdBlocks(self, blocks, recall_weight=1.5):  # pragma: nocover\n        candidate_records = itertools.chain.from_iterable(self._blockedPairs(blocks))\n\n        probability = core.scoreDuplicates(candidate_records,\n                                           self.data_model,\n                                           self.classifier,\n                                           self.num_cores)['score']\n\n        probability = probability.copy()\n        probability.sort()\n        probability = probability[::-1]\n\n        expected_dupes = numpy.cumsum(probability)\n\n        recall = expected_dupes / expected_dupes[-1]\n        precision = expected_dupes / numpy.arange(1, len(expected_dupes) + 1)\n\n        score = recall * precision / (recall + recall_weight ** 2 * precision)\n\n        i = numpy.argmax(score)\n\n        logger.info('Maximum expected recall and precision')\n        logger.info('recall: %2.3f', recall[i])\n        logger.info('precision: %2.3f', precision[i])\n        logger.info('With threshold: %2.3f', probability[i])\n\n        return probability[i]", "response": "Returns the threshold that maximizes the expected F score and weighted average of precision and recall for a sample of a blocked data set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a set of blocks generate a sequence of clusters that match them.", "response": "def matchBlocks(self, blocks, threshold=.5, *args, **kwargs):\n        \"\"\"\n        Partitions blocked data and generates a sequence of clusters,\n        where each cluster is a tuple of record ids\n\n        Keyword arguments:\n\n        blocks -- Sequence of tuples of records, where each tuple is a\n                  set of records covered by a blocking predicate\n\n        threshold -- Number between 0 and 1 (default is .5). We will\n                      only consider as duplicates record pairs as\n                      duplicates if their estimated duplicate\n                      likelihood is greater than the threshold.\n\n                      Lowering the number will increase recall,\n                      raising it will increase precision\n\n        \"\"\"\n        candidate_records = itertools.chain.from_iterable(self._blockedPairs(blocks))\n\n        matches = core.scoreDuplicates(candidate_records,\n                                       self.data_model,\n                                       self.classifier,\n                                       self.num_cores,\n                                       threshold=0)\n\n        logger.debug(\"matching done, begin clustering\")\n\n        for cluster in self._cluster(matches, threshold, *args, **kwargs):\n            yield cluster\n\n        try:\n            match_file = matches.filename\n            del matches\n            os.remove(match_file)\n        except AttributeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the current settings into a file object.", "response": "def writeSettings(self, file_obj, index=False):  # pragma: no cover\n        \"\"\"\n        Write a settings file containing the\n        data model and predicates to a file object\n\n        Keyword arguments:\n        file_obj -- file object to write settings data into\n        \"\"\"\n\n        pickle.dump(self.data_model, file_obj)\n        pickle.dump(self.classifier, file_obj)\n        pickle.dump(self.predicates, file_obj)\n\n        if index:\n            self._writeIndices(file_obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of tuples containing the record ids that are all refer to the same entity and the confidence score of the record that are not the same entity.", "response": "def match(self, data, threshold=0.5, generator=False):  # pragma: no cover\n        \"\"\"Identifies records that all refer to the same entity, returns\n        tuples\n\n        containing a set of record ids and a confidence score as a\n        float between 0 and 1. The record_ids within each set should\n        refer to the same entity and the confidence score is a measure\n        of our confidence that all the records in a cluster refer to\n        the same entity.\n\n        This method should only used for small to moderately sized\n        datasets for larger data, use matchBlocks\n\n        Arguments:\n\n        data -- Dictionary of records, where the keys are record_ids\n                and the values are dictionaries with the keys being\n                field names\n\n        threshold -- Number between 0 and 1 (default is .5). We will\n                      consider records as potential duplicates if the\n                      predicted probability of being a duplicate is\n                      above the threshold.\n\n                      Lowering the number will increase recall,\n                      raising it will increase precision\n\n        \"\"\"\n        blocked_pairs = self._blockData(data)\n        clusters = self.matchBlocks(blocked_pairs, threshold)\n        if generator:\n            return clusters\n        else:\n            return list(clusters)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the threshold that maximizes the expected F score for a sample of a record.", "response": "def threshold(self, data, recall_weight=1.5):  # pragma: no cover\n        \"\"\"\n        Returns the threshold that maximizes the expected F score,\n        a weighted average of precision and recall for a sample of\n        data.\n\n        Arguments:\n        data          -- Dictionary of records, where the keys are record_ids\n                         and the values are dictionaries with the keys being\n                         field names\n\n        recall_weight -- Sets the tradeoff between precision and\n                         recall. I.e. if you care twice as much about\n                         recall as you do precision, set recall_weight\n                         to 2.\n        \"\"\"\n\n        blocked_pairs = self._blockData(data)\n        return self.thresholdBlocks(blocked_pairs, recall_weight)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates tuples of pairs of records from a block of records", "response": "def _blockedPairs(self, blocks):\n        \"\"\"\n        Generate tuples of pairs of records from a block of records\n\n        Arguments:\n\n        blocks -- an iterable sequence of blocked records\n        \"\"\"\n\n        block, blocks = core.peek(blocks)\n        self._checkBlock(block)\n\n        combinations = itertools.combinations\n\n        pairs = (combinations(sorted(block), 2) for block in blocks)\n\n        return pairs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match(self, data_1, data_2, threshold=0.5, generator=False):  # pragma: no cover\n\n        blocked_pairs = self._blockData(data_1, data_2)\n        clusters = self.matchBlocks(blocked_pairs, threshold)\n\n        if generator:\n            return clusters\n        else:\n            return list(clusters)", "response": "Match two data sets and return a list of tuples containing the set of record ids that refer to the same entity and the confidence score of that record."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef threshold(self, data_1, data_2, recall_weight=1.5):  # pragma: no cover\n\n        blocked_pairs = self._blockData(data_1, data_2)\n        return self.thresholdBlocks(blocked_pairs, recall_weight)", "response": "Returns the threshold that maximizes the expected F score for a sample of records data_1 and data_2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _blockedPairs(self, blocks):\n\n        block, blocks = core.peek(blocks)\n        self._checkBlock(block)\n\n        product = itertools.product\n\n        pairs = (product(base, target) for base, target in blocks)\n\n        return pairs", "response": "Generate tuples of pairs of records from a block of records\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading training data from a previously built training data file and populates the current instance with the training data.", "response": "def readTraining(self, training_file):\n        '''\n        Read training from previously built training data file object\n\n        Arguments:\n\n        training_file -- file object containing the training data\n        '''\n\n        logger.info('reading training from file')\n        training_pairs = json.load(training_file,\n                                   cls=serializer.dedupe_decoder)\n        self.markPairs(training_pairs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrain the classifier on the training pairs.", "response": "def train(self, recall=0.95, index_predicates=True):  # pragma: no cover\n        \"\"\"\n        Keyword arguments:\n\n        maximum_comparisons -- The maximum number of comparisons a\n                               blocking rule is allowed to make.\n\n                               Defaults to 1000000\n\n        recall -- The proportion of true dupe pairs in our training\n                  data that that we the learned blocks must cover. If\n                  we lower the recall, there will be pairs of true\n                  dupes that we will never directly compare.\n\n                  recall should be a float between 0.0 and 1.0, the default\n                  is 0.95\n\n        index_predicates -- Should dedupe consider predicates that\n                            rely upon indexing the data. Index predicates can\n                            be slower and take susbstantial memory.\n\n                            Defaults to True.\n        \"\"\"\n        examples, y = flatten_training(self.training_pairs)\n        self.classifier.fit(self.data_model.distances(examples), y)\n\n        self.predicates = self.active_learner.learn_predicates(\n            recall, index_predicates)\n        self.blocker = blocking.Blocker(self.predicates)\n        self.blocker.resetIndices()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef writeTraining(self, file_obj):  # pragma: no cover\n\n        json.dump(self.training_pairs,\n                  file_obj,\n                  default=serializer._to_json,\n                  tuple_as_array=False,\n                  ensure_ascii=True)", "response": "Writes to a json file that contains labeled examples\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmark the labeled_pairs as training pairs.", "response": "def markPairs(self, labeled_pairs):\n        '''\n        Argument :\n\n        labeled_pairs -- A dictionary with two keys, `match` and `distinct`\n                         the values are lists that can contain pairs of records\n        '''\n        self._checkTrainingPairs(labeled_pairs)\n\n        for label, examples in labeled_pairs.items():\n            self.training_pairs[label].extend(examples)\n\n        if self.active_learner:\n            examples, y = flatten_training(labeled_pairs)\n            self.active_learner.mark(examples, y)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sample(self, data, sample_size=15000,\n               blocked_proportion=0.5, original_length=None):\n        '''Draw a sample of record pairs from the dataset\n        (a mix of random pairs & pairs of similar records)\n        and initialize active learning with this sample\n\n        Arguments: data -- Dictionary of records, where the keys are\n        record_ids and the values are dictionaries with the keys being\n        field names\n\n        sample_size         -- Size of the sample to draw\n        blocked_proportion  -- Proportion of the sample that will be blocked\n        original_length     -- Length of original data, should be set if `data` is\n                               a sample of full data\n        '''\n        self._checkData(data)\n\n        self.active_learner = self.ActiveLearner(self.data_model)\n        self.active_learner.sample_combo(data, blocked_proportion,\n                                         sample_size, original_length)", "response": "Draw a sample of record pairs from the dataset and initialize active learning with this sample."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a random sample of combinations of records from the first and second datasets and initializes the active learner with this sample.", "response": "def sample(self, data_1, data_2, sample_size=15000,\n               blocked_proportion=.5, original_length_1=None,\n               original_length_2=None):\n        '''\n        Draws a random sample of combinations of records from\n        the first and second datasets, and initializes active\n        learning with this sample\n\n        Arguments:\n\n        data_1      -- Dictionary of records from first dataset, where the\n                       keys are record_ids and the values are dictionaries\n                       with the keys being field names\n        data_2      -- Dictionary of records from second dataset, same\n                       form as data_1\n\n        sample_size -- Size of the sample to draw\n        '''\n        self._checkData(data_1, data_2)\n\n        self.active_learner = self.ActiveLearner(self.data_model)\n        self.active_learner.sample_product(data_1, data_2,\n                                           blocked_proportion,\n                                           sample_size,\n                                           original_length_1,\n                                           original_length_2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef matchBlocks(self, blocks, threshold=.5, *args, **kwargs):\n        candidate_records = self._blockedPairs(blocks)\n\n        matches = core.scoreGazette(candidate_records,\n                                    self.data_model,\n                                    self.classifier,\n                                    self.num_cores,\n                                    threshold=threshold)\n\n        logger.debug(\"matching done, begin clustering\")\n\n        return self._cluster(matches, *args, **kwargs)", "response": "Given a set of blocks generate a cluster of records that match them."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match(self, messy_data, threshold=0.5, n_matches=1, generator=False):  # pragma: no cover\n        blocked_pairs = self._blockData(messy_data)\n\n        clusters = self.matchBlocks(blocked_pairs, threshold, n_matches)\n\n        clusters = (cluster for cluster in clusters if len(cluster))\n\n        if generator:\n            return clusters\n        else:\n            return list(clusters)", "response": "Returns a list of tuples containing a set of record ids and a confidence score of the record that refer to the same entity."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef threshold(self, messy_data, recall_weight=1.5):  # pragma: no cover\n\n        blocked_pairs = self._blockData(messy_data)\n        return self.thresholdBlocks(blocked_pairs, recall_weight)", "response": "Returns the threshold that maximizes the expected F score for a sample of messy_data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef writeSettings(self, file_obj, index=False):  # pragma: no cover\n        super().writeSettings(file_obj, index)\n\n        if index:\n            pickle.dump(self.blocked_records, file_obj)", "response": "Writes the settings file containing the data model and predicates to a file object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef condensedDistance(dupes):\n    '''\n    Convert the pairwise list of distances in dupes to \"condensed\n    distance matrix\" required by the hierarchical clustering\n    algorithms. Also return a dictionary that maps the distance matrix\n    to the record_ids.\n\n    The formula for an index of the condensed matrix is\n\n    index = {N choose 2}-{N-row choose 2} + (col-row-1)\n          = N*(N-1)/2 - (N-row)*(N-row-1)/2 + col - row - 1\n            ^^^^^^^^^   ^^^^^^^^^^^^^^^^^^^\n          matrix_length       row_step\n\n    where (row,col) is index of an uncondensed square N X N distance matrix.\n\n    See http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.squareform.html\n    '''\n\n    candidate_set = numpy.unique(dupes['pairs'])\n\n    i_to_id = dict(enumerate(candidate_set))\n\n    ids = candidate_set.searchsorted(dupes['pairs'])\n    row = ids[:, 0]\n    col = ids[:, 1]\n\n    N = len(candidate_set)\n    matrix_length = N * (N - 1) / 2\n\n    row_step = (N - row) * (N - row - 1) / 2\n    index = matrix_length - row_step + col - row - 1\n\n    condensed_distances = numpy.ones(int(matrix_length), 'f4')\n    condensed_distances[index.astype(int)] = 1 - dupes['score']\n\n    return i_to_id, condensed_distances, N", "response": "Convert the pairwise list of distances in dupes to condensed\n    distance matrix required by the hierarchical clustering\n    algorithms. Also return a dictionary that maps the distance matrix to record_ids."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of duplicate pairs and clusters them in a single list of duplicate pairs.", "response": "def cluster(dupes, threshold=.5, max_components=30000):\n    '''\n    Takes in a list of duplicate pairs and clusters them in to a\n    list records that all refer to the same entity based on a given\n    threshold\n\n    Keyword arguments:\n    threshold -- number betweent 0 and 1 (default is .5). lowering the\n                 number will increase precision, raising it will increase\n                 recall\n    '''\n    distance_threshold = 1 - threshold\n    dupe_sub_graphs = connected_components(dupes, max_components)\n\n    for sub_graph in dupe_sub_graphs:\n        if len(sub_graph) > 1:\n\n            i_to_id, condensed_distances, N = condensedDistance(sub_graph)\n\n            linkage = fastcluster.linkage(condensed_distances,\n                                          method='centroid',\n                                          preserve_input=True)\n\n            partition = hcluster.fcluster(linkage,\n                                          distance_threshold,\n                                          criterion='distance')\n\n            clusters = defaultdict(list)\n\n            for i, cluster_id in enumerate(partition):\n                clusters[cluster_id].append(i)\n\n            for cluster in viewvalues(clusters):\n                if len(cluster) > 1:\n                    scores = confidences(cluster, condensed_distances, N)\n                    yield tuple(i_to_id[i] for i in cluster), scores\n\n        else:\n            (ids, score), = sub_graph\n            if score > threshold:\n                yield tuple(ids), (score,) * 2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the confidences of a cluster.", "response": "def confidences(cluster, condensed_distances, d):\n    '''\n    We calculate a per record score that is similar to a standard\n    deviation.  The main reason is that these record scores can be\n    used to calculate the standard deviation of an entire cluster,\n    which is a reasonable metric for clusters.\n    '''\n\n    scores = dict.fromkeys(cluster, 0.0)\n    squared_distances = condensed_distances ** 2\n    for i, j in itertools.combinations(cluster, 2):\n        index = d * (d - 1) / 2 - (d - i) * (d - i - 1) / 2 + j - i - 1\n        squared_dist = squared_distances[int(index)]\n        scores[i] += squared_dist\n        scores[j] += squared_dist\n    scores = numpy.array([score for _, score in sorted(scores.items())])\n    scores /= len(cluster) - 1\n    scores = numpy.sqrt(scores)\n    scores = 1 - scores\n    return scores"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncommanding line interface for presenting and labeling training pairs by the user Argument : A deduper object", "response": "def consoleLabel(deduper):  # pragma: no cover\n    '''\n    Command line interface for presenting and labeling training pairs\n    by the user\n\n    Argument :\n    A deduper object\n    '''\n\n    finished = False\n    use_previous = False\n    fields = unique(field.field\n                    for field\n                    in deduper.data_model.primary_fields)\n\n    buffer_len = 1  # Max number of previous operations\n    examples_buffer = []\n    uncertain_pairs = []\n\n    while not finished:\n        if use_previous:\n            record_pair, _ = examples_buffer.pop(0)\n            use_previous = False\n        else:\n            if not uncertain_pairs:\n                uncertain_pairs = deduper.uncertainPairs()\n\n            try:\n                record_pair = uncertain_pairs.pop()\n            except IndexError:\n                break\n\n        n_match = (len(deduper.training_pairs['match']) +\n                   sum(label == 'match' for _, label in examples_buffer))\n        n_distinct = (len(deduper.training_pairs['distinct']) +\n                      sum(label == 'distinct' for _, label in examples_buffer))\n\n        for pair in record_pair:\n            for field in fields:\n                line = \"%s : %s\" % (field, pair[field])\n                print(line, file=sys.stderr)\n            print(file=sys.stderr)\n\n        print(\"{0}/10 positive, {1}/10 negative\".format(n_match, n_distinct),\n              file=sys.stderr)\n        print('Do these records refer to the same thing?', file=sys.stderr)\n\n        valid_response = False\n        user_input = ''\n        while not valid_response:\n            if examples_buffer:\n                prompt = '(y)es / (n)o / (u)nsure / (f)inished / (p)revious'\n                valid_responses = {'y', 'n', 'u', 'f', 'p'}\n            else:\n                prompt = '(y)es / (n)o / (u)nsure / (f)inished'\n                valid_responses = {'y', 'n', 'u', 'f'}\n\n            print(prompt, file=sys.stderr)\n            user_input = input()\n            if user_input in valid_responses:\n                valid_response = True\n\n        if user_input == 'y':\n            examples_buffer.insert(0, (record_pair, 'match'))\n        elif user_input == 'n':\n            examples_buffer.insert(0, (record_pair, 'distinct'))\n        elif user_input == 'u':\n            examples_buffer.insert(0, (record_pair, 'uncertain'))\n        elif user_input == 'f':\n            print('Finished labeling', file=sys.stderr)\n            finished = True\n        elif user_input == 'p':\n            use_previous = True\n            uncertain_pairs.append(record_pair)\n\n        if len(examples_buffer) > buffer_len:\n            record_pair, label = examples_buffer.pop()\n            if label in ['distinct', 'match']:\n                examples = {'distinct': [], 'match': []}\n                examples[label].append(record_pair)\n                deduper.markPairs(examples)\n\n    for record_pair, label in examples_buffer:\n        if label in ['distinct', 'match']:\n            examples = {'distinct': [], 'match': []}\n            examples[label].append(record_pair)\n            deduper.markPairs(examples)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trainingDataLink(data_1, data_2, common_key, training_size=50000):  # pragma: nocover\n    '''\n    Construct training data for consumption by the ActiveLearning\n    markPairs method from already linked datasets.\n\n    Arguments :\n    data_1        -- Dictionary of records from first dataset, where the keys\n                     are record_ids and the values are dictionaries with the\n                     keys being field names\n\n    data_2        -- Dictionary of records from second dataset, same form as\n                     data_1\n\n    common_key    -- The name of the record field that uniquely identifies\n                     a match\n\n    training_size -- the rough limit of the number of training examples,\n                     defaults to 50000\n\n    Warning:\n\n    Every match must be identified by the sharing of a common key.\n    This function assumes that if two records do not share a common key\n    then they are distinct records.\n    '''\n\n    identified_records = collections.defaultdict(lambda: [[], []])\n    matched_pairs = set()\n    distinct_pairs = set()\n\n    for record_id, record in data_1.items():\n        identified_records[record[common_key]][0].append(record_id)\n\n    for record_id, record in data_2.items():\n        identified_records[record[common_key]][1].append(record_id)\n\n    for keys_1, keys_2 in identified_records.values():\n        if keys_1 and keys_2:\n            matched_pairs.update(itertools.product(keys_1, keys_2))\n\n    keys_1 = list(data_1.keys())\n    keys_2 = list(data_2.keys())\n\n    random_pairs = [(keys_1[i], keys_2[j])\n                    for i, j\n                    in randomPairsMatch(len(data_1), len(data_2),\n                                        training_size)]\n\n    distinct_pairs = (\n        pair for pair in random_pairs if pair not in matched_pairs)\n\n    matched_records = [(data_1[key_1], data_2[key_2])\n                       for key_1, key_2 in matched_pairs]\n    distinct_records = [(data_1[key_1], data_2[key_2])\n                        for key_1, key_2 in distinct_pairs]\n\n    training_pairs = {'match': matched_records,\n                      'distinct': distinct_records}\n\n    return training_pairs", "response": "Construct training data for consumption by the ActiveLearning markPairs method from already linked datasets."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs training data for consumption by the ActiveLearning markPairs method from an already deduplicated dataset.", "response": "def trainingDataDedupe(data, common_key, training_size=50000):  # pragma: nocover\n    '''\n    Construct training data for consumption by the ActiveLearning\n    markPairs method from an already deduplicated dataset.\n\n    Arguments :\n    data          -- Dictionary of records, where the keys are record_ids and\n                     the values are dictionaries with the keys being\n                     field names\n\n    common_key    -- The name of the record field that uniquely identifies\n                     a match\n\n    training_size -- the rough limit of the number of training examples,\n                     defaults to 50000\n\n    Warning:\n\n    Every match must be identified by the sharing of a common key.\n    This function assumes that if two records do not share a common key\n    then they are distinct records.\n    '''\n\n    identified_records = collections.defaultdict(list)\n    matched_pairs = set()\n    distinct_pairs = set()\n    unique_record_ids = set()\n\n    # a list of record_ids associated with each common_key\n    for record_id, record in data.items():\n        unique_record_ids.add(record_id)\n        identified_records[record[common_key]].append(record_id)\n\n    # all combinations of matched_pairs from each common_key group\n    for record_ids in identified_records.values():\n        if len(record_ids) > 1:\n            matched_pairs.update(itertools.combinations(sorted(record_ids), 2))\n\n    # calculate indices using dedupe.core.randomPairs to avoid\n    # the memory cost of enumerating all possible pairs\n    unique_record_ids = list(unique_record_ids)\n    pair_indices = randomPairs(len(unique_record_ids), training_size)\n    distinct_pairs = set()\n    for i, j in pair_indices:\n        distinct_pairs.add((unique_record_ids[i],\n                            unique_record_ids[j]))\n\n    distinct_pairs -= matched_pairs\n\n    matched_records = [(data[key_1], data[key_2])\n                       for key_1, key_2 in matched_pairs]\n\n    distinct_records = [(data[key_1], data[key_2])\n                        for key_1, key_2 in distinct_pairs]\n\n    training_pairs = {'match': matched_records,\n                      'distinct': distinct_records}\n\n    return training_pairs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the unique elements of a collection even if those elements are unhashable and unsortable", "response": "def unique(seq):\n    \"\"\"Return the unique elements of a collection even if those elements are\n       unhashable and unsortable, like dicts and sets\"\"\"\n    cleaned = []\n    for each in seq:\n        if each not in cleaned:\n            cleaned.append(each)\n    return cleaned"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef learn(self, matches, recall):\n        '''\n        Takes in a set of training pairs and predicates and tries to find\n        a good set of blocking rules.\n        '''\n        compound_length = 2\n\n        dupe_cover = Cover(self.blocker.predicates, matches)\n        dupe_cover.dominators(cost=self.total_cover)\n        dupe_cover.compound(compound_length)\n\n        comparison_count = self.comparisons(dupe_cover, compound_length)\n\n        dupe_cover.dominators(cost=comparison_count, comparison=True)\n\n        coverable_dupes = set.union(*viewvalues(dupe_cover))\n        uncoverable_dupes = [pair for i, pair in enumerate(matches)\n                             if i not in coverable_dupes]\n\n        epsilon = int((1.0 - recall) * len(matches))\n\n        if len(uncoverable_dupes) > epsilon:\n            logger.warning(OUT_OF_PREDICATES_WARNING)\n            logger.debug(uncoverable_dupes)\n            epsilon = 0\n        else:\n            epsilon -= len(uncoverable_dupes)\n\n        for pred in dupe_cover:\n            pred.count = comparison_count[pred]\n\n        searcher = BranchBound(len(coverable_dupes) - epsilon, 2500)\n        final_predicates = searcher.search(dupe_cover)\n\n        logger.info('Final predicate set:')\n        for predicate in final_predicates:\n            logger.info(predicate)\n\n        return final_predicates", "response": "Given a set of training pairs and predicates and a good set of blocking rules find the training pairs and predicates and return the set of training pairs and predicates that are found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unindex(self, data, field):\n        '''Remove index of a given set of data'''\n        indices = extractIndices(self.index_fields[field])\n\n        for doc in data:\n            if doc:\n                for _, index, preprocess in indices:\n                    index.unindex(preprocess(doc))\n\n        for index_type, index, _ in indices:\n\n            index._index.initSearch()\n\n            for predicate in self.index_fields[field][index_type]:\n                logger.debug(\"Canopy: %s\", str(predicate))\n                predicate.index = index", "response": "Remove index of a given set of data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the snippet to the database.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Use the `pygments` library to create a highlighted HTML\n        representation of the code snippet.\n        \"\"\"\n        lexer = get_lexer_by_name(self.language)\n        linenos = self.linenos and 'table' or False\n        options = self.title and {'title': self.title} or {}\n        formatter = HtmlFormatter(style=self.style, linenos=linenos,\n                                  full=True, **options)\n        self.highlighted = highlight(self.code, lexer, formatter)\n        super(Snippet, self).save(*args, **kwargs)\n\n        # limit the number of instances retained\n        snippets = Snippet.objects.all()\n        if len(snippets) > 100:\n            snippets[0].delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a Swagger view which renders Swagger and OpenAPI.", "response": "def get_swagger_view(title=None, url=None, patterns=None, urlconf=None):\n    \"\"\"\n    Returns schema view which renders Swagger/OpenAPI.\n    \"\"\"\n    class SwaggerSchemaView(APIView):\n        _ignore_model_permissions = True\n        exclude_from_schema = True\n        permission_classes = [AllowAny]\n        renderer_classes = [\n            CoreJSONRenderer,\n            renderers.OpenAPIRenderer,\n            renderers.SwaggerUIRenderer\n        ]\n\n        def get(self, request):\n            generator = SchemaGenerator(\n                title=title,\n                url=url,\n                patterns=patterns,\n                urlconf=urlconf\n            )\n            schema = generator.get_schema(request=request)\n\n            if not schema:\n                raise exceptions.ValidationError(\n                    'The schema generator did not return a schema Document'\n                )\n\n            return Response(schema)\n\n    return SwaggerSchemaView.as_view()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reload_settings(*args, **kwargs):  # pragma: no cover\n    # pylint: disable=W0603\n    global swagger_settings\n\n    if kwargs['setting'] == 'LOGIN_URL':\n        swagger_settings.LOGIN_URL = kwargs['value']\n    if kwargs['setting'] == 'LOGOUT_URL':\n        swagger_settings.LOGOUT_URL = kwargs['value']\n    if kwargs['setting'] != 'SWAGGER_SETTINGS':\n        return\n\n    swagger_settings = APISettings(\n        kwargs['value'],\n        DEFAULTS,\n        IMPORT_STRINGS\n    )", "response": "Reloads the current settings during unit tests if override_settings is used."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan(self):\n        found = []\n        for addr in range(0,0x80):\n            try:\n                self._i2c_bus.read_byte(addr)\n            except OSError:\n                continue\n            found.append(addr)\n        return found", "response": "Scan the i2c bus for the available I2C class entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef final():\n    if DEBUG:\n        print(\"Cleaning up message queues\", queues)\n        print(\"Cleaning up processes\", procs)\n    for q in queues:\n        q.remove()\n    for proc in procs:\n        proc.terminate()", "response": "This function is called when the program is cancelled or quit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deinit(self):\n        # Clean up after ourselves\n        self._process.terminate()\n        procs.remove(self._process)\n        self._mq.remove()\n        queues.remove(self._mq)", "response": "Deinitialises the PulseIn and releases any hardware and software\n        resources for reuse."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resume(self, trigger_duration=0):\n        if trigger_duration != 0:\n            self._mq.send(\"t%d\" % trigger_duration, True, type=1)\n        else:\n            self._mq.send(\"r\", True, type=1)\n        self._paused = False", "response": "Resumes pulse capture after an optional trigger pulse."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npause capture of the current thread.", "response": "def pause(self):\n        \"\"\"Pause pulse capture\"\"\"\n        self._mq.send(\"p\", True, type=1)\n        self._paused = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef popleft(self):\n        self._mq.send(\"^\", True, type=1)\n        message = self._wait_receive_msg()\n        reply = int(message[0].decode('utf-8'))\n        #print(reply)\n        if reply == -1:\n            raise IndexError(\"pop from empty list\")\n        return reply", "response": "Removes and returns the oldest read pulse."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iteritems(cls):\n        for key in dir(cls):\n            val = getattr(cls, key)\n            if isinstance(cls, val):\n                yield (key, val)", "response": "Iterates over the class attributes and returns as key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_layers(self, proposal):\n        '''Validate layers list.\n\n        Makes sure only one instance of any given layer can exist in the\n        layers list.\n        '''\n        self._layer_ids = [l.model_id for l in proposal.value]\n        if len(set(self._layer_ids)) != len(self._layer_ids):\n            raise LayerException('duplicate layer detected, only use each layer once')\n        return proposal.value", "response": "Validate layers list.\n\n        Makes sure only one instance of any given layer can exist in the\n        layers list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a callback to be invoked when the log entry is hovered.", "response": "def on_hover(self, callback, remove=False):\n        '''\n        The hover callback takes an unpacked set of keyword arguments.\n        '''\n        self._hover_callbacks.register_callback(callback, remove=remove)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_controls(self, proposal):\n        '''Validate controls list.\n\n        Makes sure only one instance of any given layer can exist in the\n        controls list.\n        '''\n        self._control_ids = [c.model_id for c in proposal.value]\n        if len(set(self._control_ids)) != len(self._control_ids):\n            raise ControlException('duplicate control detected, only use each control once')\n        return proposal.value", "response": "Validate the controls list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ds2json(ds, u_var, v_var, lat_dim='latitude', lon_dim='longitude', units=None):\n    import numpy as np\n    ds = ds.copy()\n    for var_name in (u_var, v_var):\n        var_dims = ds[var_name].dims\n\n        if set(var_dims) != set([lat_dim, lon_dim]):\n            raise ValueError(\n                \"Invalid dimensions for variable '{}' in Dataset: \"\n                \"should include only {}, found {}.\"\n                .format(var_name, (lat_dim, lon_dim), var_dims)\n            )\n\n        # If dataset contains nans replace with 0\n        ds[var_name] = ds[var_name].fillna(0)\n\n    if units is None:\n        u_var_units = ds[u_var].attrs.get('units')\n        v_var_units = ds[v_var].attrs.get('units')\n\n        if u_var_units != v_var_units:\n            raise ValueError(\n                \"Different units found for U-component '{}' and \"\n                \"V-component '{}' variables: '{}' and '{}'\"\n                .format(u_var, v_var, u_var_units, v_var_units))\n\n        units = u_var_units\n\n    if units is None:\n        units = ''\n\n    # Data should be in gaussian grid format (latitudes descending)\n    if np.any(np.diff(ds[lat_dim].values) >= 0):\n        ds = ds.sel(**{lat_dim: slice(None, None, -1)})\n\n    # infer grid specifications (assume a rectangular grid)\n    lat = ds[lat_dim].values\n    lon = ds[lon_dim].values\n\n    lon_left = float(lon.min())\n    lon_right = float(lon.max())\n    lat_lower = float(lat.min())\n    lat_upper = float(lat.max())\n\n    dx = float((lon_right - lon_left) / (lon.size - 1))\n    dy = float((lat_upper - lat_lower) / (lat.size - 1))\n\n    nx = lon.size\n    ny = lat.size\n\n    u_v_spec = ([2, 3],\n                [\"Eastward current\", \"Northward current\"],\n                [u_var, v_var])\n\n    velocity_data = []\n\n    for p_number, p_name, var_name in zip(*u_v_spec):\n        velocity_data.append({\n            \"header\": {\n                \"parameterUnit\": units,\n                \"parameterNumber\": p_number,\n                \"dx\": dx, \"dy\": dy,\n                \"parameterNumberName\": p_name,\n                \"la1\": lat_upper,\n                \"la2\": lat_lower,\n                \"parameterCategory\": 2,\n                \"lo2\": lon_right,\n                \"nx\": nx,\n                \"ny\": ny,\n                \"refTime\": \"2017-02-01 23:00:00\",\n                \"lo1\": lon_left\n                },\n            \"data\": ds[var_name].values.flatten().tolist()\n        })\n\n    return velocity_data", "response": "Convert a Dataset into a JSON representation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef byte_list_to_u32le_list(data, pad=0x00):\n    res = []\n    for i in range(len(data) // 4):\n        res.append(data[i * 4 + 0] |\n                   data[i * 4 + 1] << 8 |\n                   data[i * 4 + 2] << 16 |\n                   data[i * 4 + 3] << 24)\n    remainder = (len(data) % 4)\n    if remainder != 0:\n        padCount = 4 - remainder\n        res += byte_list_to_u32le_list(list(data[-remainder:]) + [pad] * padCount)\n    return res", "response": "Convert a list of bytes to a list of 32 - bit integers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef u32le_list_to_byte_list(data):\n    res = []\n    for x in data:\n        res.append((x >> 0) & 0xff)\n        res.append((x >> 8) & 0xff)\n        res.append((x >> 16) & 0xff)\n        res.append((x >> 24) & 0xff)\n    return res", "response": "Convert a word array into a byte array"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a halfword array into a byte array", "response": "def u16le_list_to_byte_list(data):\n    \"\"\"! @brief Convert a halfword array into a byte array\"\"\"\n    byteData = []\n    for h in data:\n        byteData.extend([h & 0xff, (h >> 8) & 0xff])\n    return byteData"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef byte_list_to_u16le_list(byteData):\n    data = []\n    for i in range(0, len(byteData), 2):\n        data.append(byteData[i] | (byteData[i + 1] << 8))\n    return data", "response": "Convert a byte array into a halfword array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef u64_to_hex16le(val):\n    return ''.join(\"%02x\" % (x & 0xFF) for x in (\n        val,\n        val >> 8,\n        val >> 16,\n        val >> 24,\n        val >> 32,\n        val >> 40,\n        val >> 48,\n        val >> 56,\n    ))", "response": "! @brief Convert a 64 - bit register value to a 16 - digit hexadecimal string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a 16 - digit hexadecimal string to a 64 - bit register value.", "response": "def hex16_to_u64be(data):\n    \"\"\"! @brief Build 64-bit register value from big-endian 16-digit hexadecimal string\"\"\"\n    return int(data[14:16] + data[12:14] + data[10:12] + data[8:10] + data[6:8] + data[4:6] + data[2:4] + data[0:2], 16)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_program_weight(self):\n        return self.program_weight + \\\n            float(len(self.data)) / float(DATA_TRANSFER_B_PER_S)", "response": "Get the total number of programmed pages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_data(self, addr, data):\n        # Ignore empty data.\n        if len(data) == 0:\n            return\n        \n        # Sanity check\n        if not self.flash.region.contains_range(start=addr, length=len(data)):\n            raise FlashFailure(\"Flash address range 0x%x-0x%x is not contained within region '%s'\" %\n                (addr, addr + len(data) - 1, self.flash.region.name))\n\n        # Add operation to list\n        self.flash_operation_list.append(_FlashOperation(addr, data))\n        self.buffered_data_size += len(data)\n\n        # Keep list sorted\n        self.flash_operation_list = sorted(self.flash_operation_list, key=lambda operation: operation.addr)\n        \n        # Verify this does not overlap\n        prev_flash_operation = None\n        for operation in self.flash_operation_list:\n            if prev_flash_operation is not None:\n                if prev_flash_operation.addr + len(prev_flash_operation.data) > operation.addr:\n                    raise ValueError(\"Error adding data - Data at 0x%x..0x%x overlaps with 0x%x..0x%x\"\n                            % (prev_flash_operation.addr, prev_flash_operation.addr + len(prev_flash_operation.data),\n                               operation.addr, operation.addr + len(operation.data)))\n            prev_flash_operation = operation", "response": "Add data to the block of data that is programmed by this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _enable_read_access(self):\n        if not self.algo_inited_for_read:\n            self.flash.init(self.flash.Operation.VERIFY)\n            self.algo_inited_for_read = True", "response": "Enable read access for the specified object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_sectors_and_pages(self, keep_unwritten):\n        assert len(self.flash_operation_list) > 0\n        \n        self.program_byte_count = 0\n        \n        flash_addr = self.flash_operation_list[0].addr\n        sector_info = self.flash.get_sector_info(flash_addr)\n        if sector_info is None:\n            raise FlashFailure(\"Attempt to program flash at invalid address 0x%08x\" % flash_addr)\n        \n        page_info = self.flash.get_page_info(flash_addr)\n        if page_info is None:\n            raise FlashFailure(\"Attempt to program flash at invalid address 0x%08x\" % flash_addr)\n\n        current_sector = _FlashSector(sector_info)\n        self.sector_list.append(current_sector)\n        current_page = _FlashPage(page_info)\n        current_sector.add_page(current_page)\n        self.page_list.append(current_page)\n        \n        for flash_operation in self.flash_operation_list:\n            pos = 0\n            while pos < len(flash_operation.data):\n                flash_addr = flash_operation.addr + pos\n                \n                # Check if operation is in a different sector.\n                if flash_addr >= current_sector.addr + current_sector.size:\n                    sector_info = self.flash.get_sector_info(flash_addr)\n                    if sector_info is None:\n                        raise FlashFailure(\"Attempt to program flash at invalid address 0x%08x\" % flash_addr)\n                    current_sector = _FlashSector(sector_info)\n                    self.sector_list.append(current_sector)\n\n                # Check if operation is in a different page\n                if flash_addr >= current_page.addr + current_page.size:\n                    page_info = self.flash.get_page_info(flash_addr)\n                    if page_info is None:\n                        raise FlashFailure(\"Attempt to program flash at invalid address 0x%08x\" % flash_addr)\n                    current_page = _FlashPage(page_info)\n                    current_sector.add_page(current_page)\n                    self.page_list.append(current_page)\n\n                # Fill the page gap if there is one\n                page_data_end = current_page.addr + len(current_page.data)\n                if flash_addr != page_data_end:\n                    old_data_len = flash_addr - page_data_end\n                    if keep_unwritten:\n                        self._enable_read_access()\n                        old_data = self.flash.target.read_memory_block8(page_data_end, old_data_len)\n                    else:\n                        old_data = [self.flash.region.erased_byte_value] * old_data_len\n                    current_page.data.extend(old_data)\n                    self.program_byte_count += old_data_len\n\n                # Copy data to page and increment pos\n                space_left_in_page = page_info.size - len(current_page.data)\n                space_left_in_data = len(flash_operation.data) - pos\n                amount = min(space_left_in_page, space_left_in_data)\n                current_page.data.extend(flash_operation.data[pos:pos + amount])\n                self.program_byte_count += amount\n\n                #increment position\n                pos += amount\n\n        # Fill the page gap at the end if there is one\n        if len(current_page.data) != current_page.size:\n            page_data_end = current_page.addr + len(current_page.data)\n            old_data_len = current_page.size - len(current_page.data)\n            if keep_unwritten and self.flash.region.is_readable:\n                self._enable_read_access()\n                old_data = self.flash.target.read_memory_block8(page_data_end, old_data_len)\n            else:\n                old_data = [self.flash.region.erased_byte_value] * old_data_len\n            current_page.data.extend(old_data)\n            self.program_byte_count += old_data_len\n        \n        # Go back through sectors and fill any missing pages with existing data.\n        if keep_unwritten and self.flash.region.is_readable:\n            self._fill_unwritten_sector_pages()", "response": "Convert the list of flash operations to flash sectors and pages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfill in missing pages from sectors that are not written to target memory.", "response": "def _fill_unwritten_sector_pages(self):\n        \"\"\"! @brief Fill in missing pages from sectors we are going to modify.\"\"\"\n        for sector in self.sector_list:\n            sector_page_number = 0\n            sector_page_addr = sector.addr\n\n            def add_page_with_existing_data():\n                page_info = self.flash.get_page_info(sector_page_addr)\n                if page_info is None:\n                    raise FlashFailure(\"Attempt to program flash at invalid address 0x%08x\" % sector_page_addr)\n                new_page = _FlashPage(page_info)\n                self._enable_read_access()\n                new_page.data = self.flash.target.read_memory_block8(new_page.addr, new_page.size)\n                new_page.same = True\n                sector.add_page(new_page)\n                self.page_list.append(new_page)\n                self.program_byte_count += len(new_page.data)\n                return new_page\n        \n            # Iterate over pages defined for the sector. If a gap is found, a new page is inserted\n            # with the current contents of target memory.\n            while sector_page_number < len(sector.page_list):\n                page = sector.page_list[sector_page_number]\n            \n                if page.addr != sector_page_addr:\n                    page = add_page_with_existing_data()\n            \n                sector_page_number += 1\n                sector_page_addr += page.size\n        \n            # Add missing pages at the end of the sector.\n            while sector_page_addr < sector.addr + sector.size:\n                page = add_page_with_existing_data()\n                sector_page_addr += page.size"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprograms the contents of the current object into memory.", "response": "def program(self, chip_erase=None, progress_cb=None, smart_flash=True, fast_verify=False, keep_unwritten=True):\n        \"\"\"! @brief Determine fastest method of flashing and then run flash programming.\n\n        Data must have already been added with add_data().\n        \n        @param self\n        @param chip_erase A value of True forces chip erase, False forces sector erase, and a\n            value of None means that the estimated fastest method should be used.\n        @param progress_cb A callable that accepts a single parameter of the percentage complete.\n        @param smart_flash If True, FlashBuilder will scan target memory to attempt to avoid\n            programming contents that are not changing with this program request. False forces\n            all requested data to be programmed.\n        @param fast_verify If smart_flash is enabled and the target supports the CRC32 analyzer,\n            this parameter controls whether positive results from the analyzer will be accepted.\n            In other words, pages with matching CRCs will be marked as the same. There is a small,\n            but non-zero, chance that the CRCs match even though the data is different, but the\n            odds of this happing are low: ~1/(2^32) = ~2.33*10^-8%.\n        @param keep_unwritten Depending on the sector versus page size and the amount of data\n            written, there may be ranges of flash that would be erased but not written with new\n            data. This parameter sets whether the existing contents of those unwritten ranges will\n            be read from memory and restored while programming.\n        \"\"\"\n\n        # Send notification that we're about to program flash.\n        self.flash.target.notify(Notification(event=Target.EVENT_PRE_FLASH_PROGRAM, source=self))\n\n        # Examples\n        # - lpc4330     -Non 0 base address\n        # - nRF51       -UICR location far from flash (address 0x10001000)\n        # - LPC1768     -Different sized pages\n        program_start = time()\n\n        if progress_cb is None:\n            progress_cb = _stub_progress\n\n        # There must be at least 1 flash operation\n        if len(self.flash_operation_list) == 0:\n            LOG.warning(\"No pages were programmed\")\n            return\n\n        # Convert the list of flash operations into flash sectors and pages\n        self._build_sectors_and_pages(keep_unwritten)\n        assert len(self.sector_list) != 0 and len(self.sector_list[0].page_list) != 0\n        self.flash_operation_list = None # Don't need this data in memory anymore.\n        \n        # If smart flash was set to false then mark all pages\n        # as requiring programming\n        if not smart_flash:\n            self._mark_all_pages_for_programming()\n        \n        # If the flash algo doesn't support erase all, disable chip erase.\n        if not self.flash.is_erase_all_supported:\n            chip_erase = False\n\n        # If the first page being programmed is not the first page\n        # in flash then don't use a chip erase unless explicitly directed to.\n        if self.page_list[0].addr > self.flash_start:\n            if chip_erase is None:\n                chip_erase = False\n            elif chip_erase is True:\n                LOG.warning('Chip erase used when flash address 0x%x is not the same as flash start 0x%x',\n                    self.page_list[0].addr, self.flash_start)\n\n        chip_erase_count, chip_erase_program_time = self._compute_chip_erase_pages_and_weight()\n        sector_erase_min_program_time = self._compute_sector_erase_pages_weight_min()\n\n        # If chip_erase hasn't been specified determine if chip erase is faster\n        # than page erase regardless of contents\n        if (chip_erase is None) and (chip_erase_program_time < sector_erase_min_program_time):\n            chip_erase = True\n\n        # If chip erase isn't True then analyze the flash\n        if chip_erase is not True:\n            sector_erase_count, page_program_time = self._compute_sector_erase_pages_and_weight(fast_verify)\n\n        # If chip erase hasn't been set then determine fastest method to program\n        if chip_erase is None:\n            LOG.debug(\"Chip erase count %i, sector erase est count %i\" % (chip_erase_count, sector_erase_count))\n            LOG.debug(\"Chip erase weight %f, sector erase weight %f\" % (chip_erase_program_time, page_program_time))\n            chip_erase = chip_erase_program_time < page_program_time\n\n        if chip_erase:\n            if self.flash.is_double_buffering_supported and self.enable_double_buffering:\n                LOG.debug(\"Using double buffer chip erase program\")\n                flash_operation = self._chip_erase_program_double_buffer(progress_cb)\n            else:\n                flash_operation = self._chip_erase_program(progress_cb)\n        else:\n            if self.flash.is_double_buffering_supported and self.enable_double_buffering:\n                LOG.debug(\"Using double buffer sector erase program\")\n                flash_operation = self._sector_erase_program_double_buffer(progress_cb)\n            else:\n                flash_operation = self._sector_erase_program(progress_cb)\n\n        # Cleanup flash algo and reset target after programming.\n        self.flash.cleanup()\n        self.flash.target.reset_and_halt()\n\n        program_finish = time()\n        self.perf.program_time = program_finish - program_start\n        self.perf.program_type = flash_operation\n\n        erase_byte_count = 0\n        erase_sector_count = 0\n        actual_program_byte_count = 0\n        actual_program_page_count = 0\n        skipped_byte_count = 0\n        skipped_page_count = 0\n        for page in self.page_list:\n            if (page.same is True) or (page.erased and chip_erase):\n                skipped_byte_count += page.size\n                skipped_page_count += 1\n            else:\n                actual_program_byte_count += page.size\n                actual_program_page_count += 1\n        for sector in self.sector_list:\n            if sector.are_any_pages_not_same():\n                erase_byte_count += sector.size\n                erase_sector_count += 1\n        \n        self.perf.total_byte_count = self.program_byte_count\n        self.perf.program_byte_count = actual_program_byte_count\n        self.perf.program_page_count = actual_program_page_count\n        self.perf.erase_byte_count = erase_byte_count\n        self.perf.erase_sector_count = erase_sector_count\n        self.perf.skipped_byte_count = skipped_byte_count\n        self.perf.skipped_page_count = skipped_page_count\n        \n        if self.log_performance:\n            if chip_erase:\n                LOG.info(\"Erased chip, programmed %d bytes (%s), skipped %d bytes (%s) at %.02f kB/s\",\n                    actual_program_byte_count, get_page_count(actual_program_page_count),\n                    skipped_byte_count, get_page_count(skipped_page_count),\n                    ((self.program_byte_count/1024) / self.perf.program_time))\n            else:\n                LOG.info(\"Erased %d bytes (%s), programmed %d bytes (%s), skipped %d bytes (%s) at %.02f kB/s\", \n                    erase_byte_count, get_sector_count(erase_sector_count),\n                    actual_program_byte_count, get_page_count(actual_program_page_count),\n                    skipped_byte_count, get_page_count(skipped_page_count),\n                    ((self.program_byte_count/1024) / self.perf.program_time))\n\n        # Send notification that we're done programming flash.\n        self.flash.target.notify(Notification(event=Target.EVENT_POST_FLASH_PROGRAM, source=self))\n\n        return self.perf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the number of pages in the new data that have already been erased and the number of pages in the new data that have not been erased.", "response": "def _compute_chip_erase_pages_and_weight(self):\n        \"\"\"! @brief Compute the number of erased pages.\n\n        Determine how many pages in the new data are already erased.\n        \"\"\"\n        chip_erase_count = 0\n        chip_erase_weight = 0\n        chip_erase_weight += self.flash.get_flash_info().erase_weight\n        for page in self.page_list:\n            if page.erased is None:\n                page.erased = self.flash.region.is_erased(page.data)\n            if not page.erased:\n                chip_erase_count += 1\n                chip_erase_weight += page.get_program_weight()\n        self.chip_erase_count = chip_erase_count\n        self.chip_erase_weight = chip_erase_weight\n        return chip_erase_count, chip_erase_weight"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nanalyzes the pages that have been analyzed with a partial read.", "response": "def _analyze_pages_with_partial_read(self):\n        \"\"\"! @brief Estimate how many pages are the same by reading data.\n\n        Pages are analyzed by reading the first 32 bytes and comparing with data to be\n        programmed.\n        \"\"\"\n        # Quickly estimate how many pages are the same as current flash contents.\n        # Init the flash algo in case it is required in order to access the flash memory.\n        self._enable_read_access()\n        for page in self.page_list:\n            # Analyze pages that haven't been analyzed yet\n            if page.same is None:\n                size = min(PAGE_ESTIMATE_SIZE, len(page.data))\n                data = self.flash.target.read_memory_block8(page.addr, size)\n                page_same = same(data, page.data[0:size])\n                if page_same is False:\n                    page.same = False\n                else:\n                    # Save the data read for estimation so we don't need to read it again.\n                    page.cached_estimate_data = data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _analyze_pages_with_crc32(self, assume_estimate_correct=False):\n        # Build list of all the pages that need to be analyzed\n        sector_list = []\n        page_list = []\n        for page in self.page_list:\n            if page.same is None:\n                # Add page to compute_crcs\n                sector_list.append((page.addr, page.size))\n                page_list.append(page)\n                # Compute CRC of data (Padded with 0xFF)\n                data = list(page.data)\n                pad_size = page.size - len(page.data)\n                if pad_size > 0:\n                    data.extend([0xFF] * pad_size)\n                page.crc = crc32(bytearray(data)) & 0xFFFFFFFF\n\n        # Analyze pages\n        if len(page_list) > 0:\n            self._enable_read_access()\n            crc_list = self.flash.compute_crcs(sector_list)\n            for page, crc in zip(page_list, crc_list):\n                page_same = page.crc == crc\n                if assume_estimate_correct:\n                    page.same = page_same\n                elif page_same is False:\n                    page.same = False", "response": "Analyze the pages that need to be analyzed with a CRC32 analyzer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the number of pages and weights for a sector erase.", "response": "def _compute_sector_erase_pages_and_weight(self, fast_verify):\n        \"\"\"! @brief Quickly analyze flash contents and compute weights for sector erase.\n\n        Quickly estimate how many pages are the same.  These estimates are used\n        by _sector_erase_program so it is recommended to call this before beginning programming\n        This is done automatically by smart_program.\n        \"\"\"\n        analyze_start = time()\n        \n        # Analyze pages using either CRC32 analyzer or partial reads.\n        if self.flash.get_flash_info().crc_supported:\n            self._analyze_pages_with_crc32(fast_verify)\n            self.perf.analyze_type = FlashBuilder.FLASH_ANALYSIS_CRC32\n        elif self.flash.region.is_readable:\n            self._analyze_pages_with_partial_read()\n            self.perf.analyze_type = FlashBuilder.FLASH_ANALYSIS_PARTIAL_PAGE_READ\n        else:\n            # The CRC analyzer isn't supported and flash isn't directly readable, so\n            # just mark all pages as needing programming. This will also prevent\n            # _scan_pages_for_same() from trying to read flash.\n            self._mark_all_pages_for_programming()\n\n        # Put together page and time estimate.\n        sector_erase_count = 0\n        sector_erase_weight = 0\n        for sector in self.sector_list:\n            for page in sector.page_list:\n                if page.same is False:\n                    sector_erase_count += 1\n                    sector_erase_weight += page.get_program_weight()\n                elif page.same is None:\n                    # Page may be the same but must be read to confirm\n                    sector_erase_weight += page.get_verify_weight()\n                elif page.same is True:\n                    # Page is confirmed to be the same so no programming weight\n                    pass\n            \n            if sector.are_any_pages_not_same():\n                sector_erase_weight += sector.erase_weight\n\n        self.sector_erase_count = sector_erase_count\n        self.sector_erase_weight = sector_erase_weight\n\n        analyze_finish = time()\n        self.perf.analyze_time = analyze_finish - analyze_start\n        LOG.debug(\"Analyze time: %f\" % (analyze_finish - analyze_start))\n        \n        return sector_erase_count, sector_erase_weight"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _chip_erase_program(self, progress_cb=_stub_progress):\n        LOG.debug(\"%i of %i pages have erased data\", len(self.page_list) - self.chip_erase_count, len(self.page_list))\n        progress_cb(0.0)\n        progress = 0\n\n        self.flash.init(self.flash.Operation.ERASE)\n        self.flash.erase_all()\n        self.flash.uninit()\n        \n        progress += self.flash.get_flash_info().erase_weight\n        progress_cb(float(progress) / float(self.chip_erase_weight))\n        \n        self.flash.init(self.flash.Operation.PROGRAM)\n        for page in self.page_list:\n            if not page.erased:\n                self.flash.program_page(page.addr, page.data)\n                progress += page.get_program_weight()\n                progress_cb(float(progress) / float(self.chip_erase_weight))\n        self.flash.uninit()\n        progress_cb(1.0)\n        return FlashBuilder.FLASH_CHIP_ERASE", "response": "! @brief Program by first performing an erase all."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _chip_erase_program_double_buffer(self, progress_cb=_stub_progress):\n        LOG.debug(\"%i of %i pages have erased data\", len(self.page_list) - self.chip_erase_count, len(self.page_list))\n        progress_cb(0.0)\n        progress = 0\n\n        self.flash.init(self.flash.Operation.ERASE)\n        self.flash.erase_all()\n        self.flash.uninit()\n        \n        progress += self.flash.get_flash_info().erase_weight\n        progress_cb(float(progress) / float(self.chip_erase_weight))\n\n        # Set up page and buffer info.\n        current_buf = 0\n        next_buf = 1\n        page, i = self._next_unerased_page(0)\n        assert page is not None\n\n        # Load first page buffer\n        self.flash.load_page_buffer(current_buf, page.addr, page.data)\n\n        self.flash.init(self.flash.Operation.PROGRAM)\n        while page is not None:\n            # Kick off this page program.\n            current_addr = page.addr\n            current_weight = page.get_program_weight()\n            self.flash.start_program_page_with_buffer(current_buf, current_addr)\n\n            # Get next page and load it.\n            page, i = self._next_unerased_page(i)\n            if page is not None:\n                self.flash.load_page_buffer(next_buf, page.addr, page.data)\n\n            # Wait for the program to complete.\n            result = self.flash.wait_for_completion()\n            if result != 0:\n                raise FlashProgramFailure('program_page(0x%x) error: %i'\n                        % (current_addr, result), current_addr, result)\n\n            # Swap buffers.\n            current_buf, next_buf = next_buf, current_buf\n\n            # Update progress.\n            progress += current_weight\n            progress_cb(float(progress) / float(self.chip_erase_weight))\n        \n        self.flash.uninit()\n        progress_cb(1.0)\n        return FlashBuilder.FLASH_CHIP_ERASE", "response": "Erases all data from the chip and then erases the entire chip."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nerasing all pages in the sector list and program all pages in the flash.", "response": "def _sector_erase_program(self, progress_cb=_stub_progress):\n        \"\"\"! @brief Program by performing sector erases.\"\"\"\n        actual_sector_erase_count = 0\n        actual_sector_erase_weight = 0\n        progress = 0\n\n        progress_cb(0.0)\n\n        # Fill in same flag for all pages. This is done up front so we're not trying\n        # to read from flash while simultaneously programming it.\n        progress = self._scan_pages_for_same(progress_cb)\n        \n        for sector in self.sector_list:\n            if sector.are_any_pages_not_same():\n                # Erase the sector\n                self.flash.init(self.flash.Operation.ERASE)\n                self.flash.erase_sector(sector.addr)\n                self.flash.uninit()\n\n                actual_sector_erase_weight += sector.erase_weight\n\n                # Update progress\n                if self.sector_erase_weight > 0:\n                    progress_cb(float(progress) / float(self.sector_erase_weight))\n                \n                # The sector was erased, so we must program all pages in the sector\n                # regardless of whether they were the same or not.\n                for page in sector.page_list:\n\n                    progress += page.get_program_weight()\n\n                    self.flash.init(self.flash.Operation.PROGRAM)\n                    self.flash.program_page(page.addr, page.data)\n                    self.flash.uninit()\n            \n                    actual_sector_erase_count += 1\n                    actual_sector_erase_weight += page.get_program_weight()\n\n                    # Update progress\n                    if self.sector_erase_weight > 0:\n                        progress_cb(float(progress) / float(self.sector_erase_weight))\n\n        progress_cb(1.0)\n\n        LOG.debug(\"Estimated sector erase programmed page count: %i\", self.sector_erase_count)\n        LOG.debug(\"Actual sector erase programmed page count: %i\", actual_sector_erase_count)\n\n        return FlashBuilder.FLASH_SECTOR_ERASE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _scan_pages_for_same(self, progress_cb=_stub_progress):\n        progress = 0\n        \n        # Read page data if unknown - after this page.same will be True or False\n        unknown_pages = [page for page in self.page_list if page.same is None]\n        if unknown_pages:\n            self._enable_read_access()\n\n            for page in unknown_pages:\n                if page.cached_estimate_data is not None:\n                    data = page.cached_estimate_data\n                    offset = len(data)\n                else:\n                    data = []\n                    offset = 0\n                assert len(page.data) == page.size\n                data.extend(self.flash.target.read_memory_block8(page.addr + offset,\n                                                                    page.size - offset))\n                page.same = same(page.data, data)\n                page.cached_estimate_data = None # This data isn't needed anymore.\n                progress += page.get_verify_weight()\n            \n                # Update progress\n                if self.sector_erase_weight > 0:\n                    progress_cb(float(progress) / float(self.sector_erase_weight))\n        \n        # If we have to program any pages of a sector, then mark all pages of that sector\n        # as needing to be programmed, since the sector will be erased.\n        for sector in self.sector_list:\n            if sector.are_any_pages_not_same():\n                sector.mark_all_pages_not_same()\n        \n        return progress", "response": "Read the full page data to determine if it is unchanged."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sector_erase_program_double_buffer(self, progress_cb=_stub_progress):\n        actual_sector_erase_count = 0\n        actual_sector_erase_weight = 0\n        progress = 0\n\n        progress_cb(0.0)\n\n        # Fill in same flag for all pages. This is done up front so we're not trying\n        # to read from flash while simultaneously programming it.\n        progress = self._scan_pages_for_same(progress_cb)\n\n        # Erase all sectors up front.\n        self.flash.init(self.flash.Operation.ERASE)\n        for sector in self.sector_list:\n            if sector.are_any_pages_not_same():\n                # Erase the sector\n                self.flash.erase_sector(sector.addr)\n                \n                # Update progress\n                progress += sector.erase_weight\n                if self.sector_erase_weight > 0:\n                    progress_cb(float(progress) / float(self.sector_erase_weight))\n        self.flash.uninit()\n\n        # Set up page and buffer info.\n        current_buf = 0\n        next_buf = 1\n        page, i = self._next_nonsame_page(0)\n\n        # Make sure there are actually pages to program differently from current flash contents.\n        if page is not None:\n            self.flash.init(self.flash.Operation.PROGRAM)\n\n            # Load first page buffer\n            self.flash.load_page_buffer(current_buf, page.addr, page.data)\n\n            while page is not None:\n                assert page.same is not None\n\n                # Kick off this page program.\n                current_addr = page.addr\n                current_weight = page.get_program_weight()\n\n                self.flash.start_program_page_with_buffer(current_buf, current_addr)\n                \n                actual_sector_erase_count += 1\n                actual_sector_erase_weight += page.get_program_weight()\n\n                # Get next page and load it.\n                page, i = self._next_nonsame_page(i)\n                if page is not None:\n                    self.flash.load_page_buffer(next_buf, page.addr, page.data)\n\n                # Wait for the program to complete.\n                result = self.flash.wait_for_completion()\n                if result != 0:\n                    raise FlashProgramFailure('program_page(0x%x) error: %i'\n                            % (current_addr, result), current_addr, result)\n                \n                # Swap buffers.\n                current_buf, next_buf = next_buf, current_buf\n\n                # Update progress\n                progress += current_weight\n                if self.sector_erase_weight > 0:\n                    progress_cb(float(progress) / float(self.sector_erase_weight))\n\n            self.flash.uninit()\n\n        progress_cb(1.0)\n\n        LOG.debug(\"Estimated sector erase programmed page count: %i\", self.sector_erase_count)\n        LOG.debug(\"Actual sector erase programmed page count: %i\", actual_sector_erase_count)\n\n        return FlashBuilder.FLASH_SECTOR_ERASE", "response": "Programs the sectors in flash using double - buffered erases."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the value of a CPU register.", "response": "def read_core_register(self, reg):\n        \"\"\"\n        read CPU register\n        Unpack floating point register values\n        \"\"\"\n        regIndex = register_name_to_index(reg)\n        regValue = self.read_core_register_raw(regIndex)\n        # Convert int to float.\n        if is_single_float_register(regIndex):\n            regValue = conversion.u32_to_float32(regValue)\n        elif is_double_float_register(regIndex):\n            regValue = conversion.u64_to_float64(regValue)\n        return regValue"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_core_register(self, reg, data):\n        regIndex = register_name_to_index(reg)\n        # Convert float to int.\n        if is_single_float_register(regIndex) and type(data) is float:\n            data = conversion.float32_to_u32(data)\n        elif is_double_float_register(regIndex) and type(data) is float:\n            data = conversion.float64_to_u64(data)\n        self.write_core_register_raw(regIndex, data)", "response": "Write a CPU register."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the DAP IO pins for JTAG or SWD.", "response": "def connect(self, protocol=None):\n        \"\"\"Initialize DAP IO pins for JTAG or SWD\"\"\"\n        # Convert protocol to port enum.\n        if protocol is not None:\n            port = self.PORT_MAP[protocol]\n        else:\n            port = DAPAccess.PORT.DEFAULT\n        \n        try:\n            self._link.connect(port)\n        except DAPAccess.Error as exc:\n            six.raise_from(self._convert_exception(exc), exc)\n        \n        # Read the current mode and save it.\n        actualMode = self._link.get_swj_mode()\n        self._protocol = self.PORT_MAP[actualMode]\n        \n        self._invalidate_cached_registers()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disconnect(self):\n        try:\n            self._link.disconnect()\n            self._protocol = None\n            self._invalidate_cached_registers()\n        except DAPAccess.Error as exc:\n            six.raise_from(self._convert_exception(exc), exc)", "response": "Deinitialises the DAP I / O pins"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the frequency for JTAG and SWD in Hz", "response": "def set_clock(self, frequency):\n        \"\"\"Set the frequency for JTAG and SWD in Hz\n\n        This function is safe to call before connect is called.\n        \"\"\"\n        try:\n            self._link.set_clock(frequency)\n        except DAPAccess.Error as exc:\n            six.raise_from(self._convert_exception(exc), exc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assert_reset(self, asserted):\n        try:\n            self._invalidate_cached_registers()\n            self._link.assert_reset(asserted)\n        except DAPAccess.Error as exc:\n            six.raise_from(self._convert_exception(exc), exc)", "response": "Assert or de - assert target reset line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart receiving SWO data at the given baudrate.", "response": "def swo_start(self, baudrate):\n        \"\"\"! @brief Start receiving SWO data at the given baudrate.\"\"\"\n        try:\n            self._link.swo_configure(True, baudrate)\n            self._link.swo_control(True)\n        except DAPAccess.Error as exc:\n            six.raise_from(self._convert_exception(exc), exc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef swo_stop(self):\n        try:\n            self._link.swo_configure(False, 0)\n        except DAPAccess.Error as exc:\n            six.raise_from(self._convert_exception(exc), exc)", "response": "! Stop receiving SWO data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of CmsisPackDevice objects for installed pack targets.", "response": "def get_installed_targets():\n        \"\"\"! @brief Return a list of CmsisPackDevice objects for installed pack targets.\"\"\"\n        try:\n            cache = cmsis_pack_manager.Cache(True, True)\n            results = []\n            for pack in ManagedPacks.get_installed_packs(cache=cache):\n                pack_path = os.path.join(cache.data_path, pack.get_pack_name())\n                pack = CmsisPack(pack_path)\n                results += list(pack.devices)\n            return sorted(results, key=lambda dev:dev.part_number)\n        except FileNotFoundError:\n            # cmsis-pack-manager can raise this exception if the cache is empty.\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef populate_target(device_name):\n        device_name = device_name.lower()\n        targets = ManagedPacks.get_installed_targets()\n        for dev in targets:\n            if device_name == dev.part_number.lower():\n                PackTargets.populate_device(dev)", "response": "Adds target information from cmsis - pack - manager matching the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pack_target_create_init_sequence(self):\n        seq = super(self.__class__, self).create_init_sequence()\n        seq.insert_after('create_cores',\n            ('set_default_reset_type', self.set_default_reset_type))\n        return seq", "response": "! Creates an init task to set the default reset type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the first core s default reset type to the one specified in the pack.", "response": "def _pack_target_set_default_reset_type(self):\n        \"\"\"! @brief Set's the first core's default reset type to the one specified in the pack.\"\"\"\n        if 0 in self.cores:\n            self.cores[0].default_reset_type = self._pack_device.default_reset_type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_family_class(dev):\n        for familyInfo in FAMILIES:\n            # Skip if wrong vendor.\n            if dev.vendor != familyInfo.vendor:\n                continue\n\n            # Scan each level of families\n            for familyName in dev.families:\n                for regex in familyInfo.matches:\n                    # Require the regex to match the entire family name.\n                    match = regex.match(familyName)\n                    if match and match.span() == (0, len(familyName)):\n                        return familyInfo.klass\n        else:\n            # Default target superclass.\n            return CoreSightTarget", "response": "Searches the families list for matching entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _generate_pack_target_class(dev):\n        try:\n            # Look up the target family superclass.\n            superklass = PackTargets._find_family_class(dev)\n\n            # Replace spaces and dashes with underscores on the new target subclass name.\n            subclassName = dev.part_number.replace(' ', '_').replace('-', '_')\n\n            # Create a new subclass for this target.\n            targetClass = type(subclassName, (superklass,), {\n                        \"_pack_device\": dev,\n                        \"__init__\": _PackTargetMethods._pack_target__init__,\n                        \"create_init_sequence\": _PackTargetMethods._pack_target_create_init_sequence,\n                        \"set_default_reset_type\": _PackTargetMethods._pack_target_set_default_reset_type,\n                    })\n            return targetClass\n        except (MalformedCmsisPackError, FileNotFoundError_) as err:\n            LOG.warning(err)\n            return None", "response": "Generates a new class from a CmsisPackDevice object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef populate_device(dev):\n        try:\n            tgt = PackTargets._generate_pack_target_class(dev)\n            if tgt is None:\n                return\n            part = dev.part_number.lower()\n            LOG.debug(\"Loading target '%s' from CMSIS-Pack\", part)\n\n            # Make sure there isn't a duplicate target name.\n            if part not in TARGET:\n                TARGET[part] = tgt\n        except (MalformedCmsisPackError, FileNotFoundError_) as err:\n            LOG.warning(err)", "response": "Generates and populates the target class of a given device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds targets defined in the CMSIS - Pack.", "response": "def populate_targets_from_pack(pack_list):\n        \"\"\"! @brief Adds targets defined in the provided CMSIS-Pack.\n\n        Targets are added to the `#TARGET` list.\n\n        @param pack_list Sequence of strings that are paths to .pack files, file objects,\n            ZipFile instances, or CmsisPack instance. May also be a single object of one of\n            the accepted types.\n        \"\"\"\n        if not isinstance(pack_list, (list, tuple)):\n            pack_list = [pack_list]\n        for pack_or_path in pack_list:\n            if not isinstance(pack_or_path, CmsisPack):\n                pack = CmsisPack(pack_or_path)\n            for dev in pack.devices:\n                PackTargets.populate_device(dev)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting whether the device should be ignored by comparing bDeviceClass.", "response": "def filter_device_by_class(vid, pid, device_class):\n    \"\"\"! @brief Test whether the device should be ignored by comparing bDeviceClass.\n    \n    This function checks the device's bDeviceClass to determine whether the it is likely to be\n    a CMSIS-DAP device. It uses the vid and pid for device-specific quirks.\n    \n    @retval True Skip the device.\n    @retval False The device is valid.\n    \"\"\"\n    # Check valid classes for CMSIS-DAP firmware.\n    if device_class in CMSIS_DAP_USB_CLASSES:\n        return False\n    # Old \"Mbed CMSIS-DAP\" firmware has an incorrect bDeviceClass.\n    if ((vid, pid) == ARM_DAPLINK_ID) and (device_class == USB_CLASS_COMMUNICATIONS):\n        return False\n    # Any other class indicates the device is not CMSIS-DAP.\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all the connected CMSIS - DAP devices and the corresponding boards.", "response": "def get_all_connected_interfaces():\n        \"\"\"\n        returns all the connected CMSIS-DAP devices\n        \"\"\"\n        all_devices = hid.find_all_hid_devices()\n\n        # find devices with good vid/pid\n        all_mbed_devices = []\n        for d in all_devices:\n            if (d.product_name.find(\"CMSIS-DAP\") >= 0):\n                all_mbed_devices.append(d)\n\n        boards = []\n        for dev in all_mbed_devices:\n            try:\n                dev.open(shared=True)\n\n                # Perform device-specific filtering.\n                if filter_device_by_usage_page(dev.vendor_id, dev.product_id, dev.hid_caps.usage_page):\n                    dev.close()\n                    continue\n\n                report = dev.find_output_reports()\n                if len(report) != 1:\n                    dev.close()\n                    continue\n                new_board = PyWinUSB()\n                new_board.report = report[0]\n                new_board.vendor_name = dev.vendor_name\n                new_board.product_name = dev.product_name\n                new_board.serial_number = dev.serial_number\n                new_board.vid = dev.vendor_id\n                new_board.pid = dev.product_id\n                new_board.device = dev\n                dev.close()\n                boards.append(new_board)\n            except Exception as e:\n                if (str(e) != \"Failure to get HID pre parsed data\"):\n                    log.error(\"Receiving Exception: %s\", e)\n                dev.close()\n\n        return boards"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, timeout=20.0):\n        start = time()\n        while len(self.rcv_data) == 0:\n            sleep(0)\n            if time() - start > timeout:\n                # Read operations should typically take ~1-2ms.\n                # If this exception occurs, then it could indicate\n                # a problem in one of the following areas:\n                # 1. Bad usb driver causing either a dropped read or write\n                # 2. CMSIS-DAP firmware problem cause a dropped read or write\n                # 3. CMSIS-DAP is performing a long operation or is being\n                #    halted in a debugger\n                raise DAPAccessIntf.DeviceError(\"Read timed out\")\n        return self.rcv_data.popleft()", "response": "read data from the IN endpoint associated to the HID interface"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_graph(node):\n    \n    def _dump(node, level):\n        print(\"  \" * level + \"- \" + str(node))\n        for child in node.children:\n            _dump(child, level + 1)\n    \n    _dump(node, 0)", "response": "! Draw the object graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlink a child node onto this object.", "response": "def add_child(self, node):\n        \"\"\"! @brief Link a child node onto this object.\"\"\"\n        node._parent = self\n        self._children.append(node)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_first_child_of_type(self, klass):\n        matches = self.find_children(lambda c: isinstance(c, klass))\n        if len(matches):\n            return matches[0]\n        else:\n            return None", "response": "Breadth - first search for a child of the given class type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self, protocol=None):\n        self._link.enter_debug(STLink.Protocol.SWD)\n        self._is_connected = True", "response": "Initialize DAP IO pins for JTAG or SWD"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disconnect(self):\n        # TODO Close the APs. When this is attempted, we get an undocumented 0x1d error. Doesn't\n        #      seem to be necessary, anyway.\n        self._memory_interfaces = {}\n        \n        self._link.enter_idle()\n        self._is_connected = False", "response": "Disconnects from the DAP I/O pins"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a single memory location.", "response": "def write_memory(self, addr, data, transfer_size=32):\n        \"\"\"! @brief Write a single memory location.\n        \n        By default the transfer size is a word.\n        \"\"\"\n        assert transfer_size in (8, 16, 32)\n        if transfer_size == 32:\n            self._link.write_mem32(addr, conversion.u32le_list_to_byte_list([data]), self._apsel)\n        elif transfer_size == 16:\n            self._link.write_mem16(addr, conversion.u16le_list_to_byte_list([data]), self._apsel)\n        elif transfer_size == 8:\n            self._link.write_mem8(addr, [data], self._apsel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a memory location.", "response": "def read_memory(self, addr, transfer_size=32, now=True):\n        \"\"\"! @brief Read a memory location.\n        \n        By default, a word will be read.\n        \"\"\"\n        assert transfer_size in (8, 16, 32)\n        if transfer_size == 32:\n            result = conversion.byte_list_to_u32le_list(self._link.read_mem32(addr, 4, self._apsel))[0]\n        elif transfer_size == 16:\n            result = conversion.byte_list_to_u16le_list(self._link.read_mem16(addr, 2, self._apsel))[0]\n        elif transfer_size == 8:\n            result = self._link.read_mem8(addr, 1, self._apsel)[0]\n        \n        def read_callback():\n            return result\n        return result if now else read_callback"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef for_each(self, action, filter=None):\n        for component in self.components:\n            # Recurse into child ROM tables.\n            if isinstance(component, ROMTable):\n                component.for_each(action, filter)\n                continue\n            \n            # Skip component if the filter returns False.\n            if filter is not None and not filter(component):\n                continue\n            \n            # Perform the action.\n            action(component)", "response": "This method iterates over all the components in the ROM table and calls the action function on each entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receive(self, event):\n        if not isinstance(event, TraceITMEvent):\n            return\n        \n        if not event.port == 0:\n            return\n        \n        # Extract bytes.\n        if event.width == 8:\n            data = chr(event.data)\n        elif event.width == 16:\n            data = chr(event.data & 0xff) + chr((event.data >> 8) & 0xff)\n        elif event.width == 32:\n            data = (chr(event.data & 0xff)\n                    + chr((event.data >> 8) & 0xff)\n                    + chr((event.data >> 16) & 0xff)\n                    + chr((event.data >> 24) & 0xff))\n\n        self._console.write(data)", "response": "Handle an event from the SWV trace."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes trace graph and starts thread.", "response": "def init(self, sys_clock, swo_clock, console):\n        \"\"\"! @brief Configures trace graph and starts thread.\n        \n        This method performs all steps required to start up SWV. It first calls the target's\n        trace_start() method, which allows for target-specific trace initialization. Then it\n        configures the TPIU and ITM modules. A simple trace data processing graph is created that\n        connects an SWVEventSink with a SWOParser. Finally, the reader thread is started.\n        \n        If the debug probe does not support SWO, a warning is printed but nothing else is done.\n        \n        @param self\n        @param sys_clock\n        @param swo_clock\n        @param console\n        \"\"\"\n        self._swo_clock = swo_clock\n        \n        if not self._session.probe.has_swo():\n            LOG.warning(\"Probe %s does not support SWO\", self._session.probe.unique_id)\n            return\n        \n        self._session.target.trace_start()\n        \n        itm = self._session.target.get_first_child_of_type(ITM)\n        tpiu = self._session.target.get_first_child_of_type(TPIU)\n\n        itm.init()\n        itm.enable()\n        tpiu.init()\n\n        if tpiu.set_swo_clock(swo_clock, sys_clock):\n            LOG.info(\"Set SWO clock to %d\", swo_clock)\n        else:\n            LOG.warning(\"Failed to set SWO clock rate\")\n            return\n\n        self._parser = SWOParser(self._session.target.cores[self._core_number])\n        self._sink = SWVEventSink(console)\n        self._parser.connect(self._sink)\n        \n        self.start()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        if not self.is_alive():\n            return\n\n        self._shutdown_event.set()\n        self.join()\n\n        itm = self._session.target.get_first_child_of_type(ITM)\n        itm.disable()\n        \n        self._session.target.trace_stop()", "response": "Stops processing SWV data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_connected_interfaces():\n\n        devices = hid.enumerate()\n\n        if not devices:\n            log.debug(\"No Mbed device connected\")\n            return []\n\n        boards = []\n\n        for deviceInfo in devices:\n            product_name = to_str_safe(deviceInfo['product_string'])\n            if (product_name.find(\"CMSIS-DAP\") < 0):\n                # Skip non cmsis-dap devices\n                continue\n            \n            vid = deviceInfo['vendor_id']\n            pid = deviceInfo['product_id']\n            \n            # Perform device-specific filtering.\n            if filter_device_by_usage_page(vid, pid, deviceInfo['usage_page']):\n                continue\n\n            try:\n                dev = hid.device(vendor_id=vid, product_id=pid, path=deviceInfo['path'])\n            except IOError as exc:\n                log.debug(\"Failed to open USB device: %s\", exc)\n                continue\n\n            # Create the USB interface object for this device.\n            new_board = HidApiUSB()\n            new_board.vendor_name = deviceInfo['manufacturer_string']\n            new_board.product_name = deviceInfo['product_string']\n            new_board.serial_number = deviceInfo['serial_number']\n            new_board.vid = vid\n            new_board.pid = pid\n            new_board.device_info = deviceInfo\n            new_board.device = dev\n            boards.append(new_board)\n\n        return boards", "response": "Returns all the connected USB interfaces which match the given USB device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if all the data in d are erased.", "response": "def is_erased(self, d):\n        \"\"\"! @brief Helper method to check if a block of data is erased.\n        @param self\n        @param d List of data or bytearray.\n        @retval True The contents of d all match the erased byte value for this flash region.\n        @retval False At least one byte in d did not match the erased byte value.\n        \"\"\"\n        erasedByte = self.erased_byte_value\n        for b in d:\n            if b != erasedByte:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a memory region from the map.", "response": "def remove_region(self, region):\n        \"\"\"! @brief Removes a memory region from the map.\n        @param self\n        @param region The region to remove. The region to remove is matched by identity, not value,\n            so this parameter must be the exact object that you wish to remove from the map.\n        \"\"\"\n        for i, r in enumerate(self._regions):\n            if r is region:\n                del self._regions[i]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_text(node, tag, default=None):\n    try:\n        return node.find(tag).text\n    except AttributeError:\n        return default", "response": "Get the text for the provided tag from the provided node"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites bytes into the connection.", "response": "def write(self, data):\n        \"\"\"! @brief Write bytes into the connection.\"\"\"\n        # If nobody is connected, act like all data was written anyway.\n        if self.connected is None:\n            return 0\n        data = to_bytes_safe(data)\n        size = len(data)\n        remaining = size\n        while remaining:\n            count = self._abstract_socket.write(data)\n            remaining -= count\n            if remaining:\n                data = data[count:]\n        return size"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_input(self, length):\n        self._buffer_lock.acquire()\n        try:\n            if length == -1:\n                actualLength = len(self._buffer)\n            else:\n                actualLength = min(length, len(self._buffer))\n            if actualLength:\n                data = self._buffer[:actualLength]\n                self._buffer = self._buffer[actualLength:]\n            else:\n                data = bytearray()\n            return data\n        finally:\n            self._buffer_lock.release()", "response": "! @brief Extract requested amount of data from the read buffer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self, size=-1):\n        if self.connected is None:\n            return None\n\n        # Extract requested amount of data from the read buffer.\n        data = self._get_input(size)\n\n        return data", "response": "! \\ ~english Read from the connection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread bytes into a mutable buffer.", "response": "def readinto(self, b):\n        \"\"\"! @brief Read bytes into a mutable buffer.\"\"\"\n        if self.connected is None:\n            return None\n\n        # Extract requested amount of data from the read buffer.\n        b[:] = self._get_input(size)\n\n        if len(b):\n            return len(b)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmodifies the default software reset method.", "response": "def default_software_reset_type(self, reset_type):\n        \"\"\"! @brief Modify the default software reset method.\n        @param self\n        @param reset_type Must be one of the software reset types: Target.ResetType.SW_SYSRESETREQ,\n            Target.ResetType.SW_VECTRESET, or Target.ResetType.SW_EMULATED.\n        \"\"\"\n        assert isinstance(reset_type, Target.ResetType)\n        assert reset_type in (Target.ResetType.SW_SYSRESETREQ, Target.ResetType.SW_VECTRESET,\n                                Target.ResetType.SW_EMULATED)\n        self._default_software_reset_type = reset_type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the Cortex M.", "response": "def init(self):\n        \"\"\"\n        Cortex M initialization. The bus must be accessible when this method is called.\n        \"\"\"\n        if not self.call_delegate('will_start_debug_core', core=self):\n            if self.halt_on_connect:\n                self.halt()\n            self._read_core_type()\n            self._check_for_fpu()\n            self.build_target_xml()\n            self.sw_bp.init()\n\n        self.call_delegate('did_start_debug_core', core=self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_memory(self, addr, value, transfer_size=32):\n        self.ap.write_memory(addr, value, transfer_size)", "response": "Writes a value to the local memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a block of unaligned bytes in memory. Returns an array of byte values.", "response": "def read_memory_block8(self, addr, size):\n        \"\"\"\n        read a block of unaligned bytes in memory. Returns\n        an array of byte values\n        \"\"\"\n        data = self.ap.read_memory_block8(addr, size)\n        return self.bp_manager.filter_memory_unaligned_8(addr, size, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_memory_block32(self, addr, size):\n        data = self.ap.read_memory_block32(addr, size)\n        return self.bp_manager.filter_memory_aligned_32(addr, size, data)", "response": "Reads a block of aligned words in memory. Returns an array of word values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef step(self, disable_interrupts=True, start=0, end=0):\n        # Was 'if self.get_state() != TARGET_HALTED:'\n        # but now value of dhcsr is saved\n        dhcsr = self.read_memory(CortexM.DHCSR)\n        if not (dhcsr & (CortexM.C_STEP | CortexM.C_HALT)):\n            logging.error('cannot step: target not halted')\n            return\n\n        self.notify(Notification(event=Target.EVENT_PRE_RUN, source=self, data=Target.RUN_TYPE_STEP))\n\n        self.clear_debug_cause_bits()\n\n        # Save previous interrupt mask state\n        interrupts_masked = (CortexM.C_MASKINTS & dhcsr) != 0\n\n        # Mask interrupts - C_HALT must be set when changing to C_MASKINTS\n        if not interrupts_masked and disable_interrupts:\n            self.write_memory(CortexM.DHCSR, CortexM.DBGKEY | CortexM.C_DEBUGEN | CortexM.C_HALT | CortexM.C_MASKINTS)\n\n        # Single step using current C_MASKINTS setting\n        while True:\n            if disable_interrupts or interrupts_masked:\n                self.write_memory(CortexM.DHCSR, CortexM.DBGKEY | CortexM.C_DEBUGEN | CortexM.C_MASKINTS | CortexM.C_STEP)\n            else:\n                self.write_memory(CortexM.DHCSR, CortexM.DBGKEY | CortexM.C_DEBUGEN | CortexM.C_STEP)\n\n            # Wait for halt to auto set (This should be done before the first read)\n            while not self.read_memory(CortexM.DHCSR) & CortexM.C_HALT:\n                pass\n\n            # Range is empty, 'range step' will degenerate to 'step'\n            if start == end:\n                break\n\n            # Read program counter and compare to [start, end)\n            program_counter = self.read_core_register(CORE_REGISTER['pc'])\n            if program_counter < start or end <= program_counter:\n                break\n\n            # Check other stop reasons\n            if self.read_memory(CortexM.DFSR) & (CortexM.DFSR_DWTTRAP | CortexM.DFSR_BKPT):\n                break\n\t\n        # Restore interrupt mask state\n        if not interrupts_masked and disable_interrupts:\n            # Unmask interrupts - C_HALT must be set when changing to C_MASKINTS\n            self.write_memory(CortexM.DHCSR, CortexM.DBGKEY | CortexM.C_DEBUGEN | CortexM.C_HALT)\n\n        self.flush()\n\n        self._run_token += 1\n\n        self.notify(Notification(event=Target.EVENT_POST_RUN, source=self, data=Target.RUN_TYPE_STEP))", "response": "Perform an instruction level step."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nemulate a software reset by writing the core registers and then writing the values to the vector table.", "response": "def _perform_emulated_reset(self):\n        \"\"\"! @brief Emulate a software reset by writing registers.\n        \n        All core registers are written to reset values. This includes setting the initial PC and SP\n        to values read from the vector table, which is assumed to be located at the based of the\n        boot memory region.\n        \n        If the memory map does not provide a boot region, then the current value of the VTOR register\n        is reused, as it should at least point to a valid vector table.\n        \n        The current value of DEMCR.VC_CORERESET determines whether the core will be resumed or\n        left halted.\n        \n        Note that this reset method will not set DHCSR.S_RESET_ST or DFSR.VCATCH.\n        \"\"\"\n        # Halt the core before making changes.\n        self.halt()\n        \n        bootMemory = self.memory_map.get_boot_memory()\n        if bootMemory is None:\n            # Reuse current VTOR value if we don't know the boot memory region.\n            vectorBase = self.read32(self.VTOR)\n        else:\n            vectorBase = bootMemory.start\n        \n        # Read initial SP and PC.\n        initialSp = self.read32(vectorBase)\n        initialPc = self.read32(vectorBase + 4)\n        \n        # Init core registers.\n        regList = ['r0', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7', 'r8', 'r9', 'r10', 'r11', 'r12',\n                    'psp', 'msp', 'lr', 'pc', 'xpsr', 'cfbp']\n        valueList = [0] * 13 + \\\n                    [\n                        0,          # PSP\n                        initialSp,  # MSP\n                        0xffffffff, # LR\n                        initialPc,  # PC\n                        0x01000000, # XPSR\n                        0,          # CFBP\n                    ]\n        \n        if self.has_fpu:\n            regList += [('s%d' % n) for n in range(32)] + ['fpscr']\n            valueList += [0] * 33\n        \n        self.write_core_registers_raw(regList, valueList)\n        \n        # \"Reset\" SCS registers.\n        data = [\n                (self.ICSR_PENDSVCLR | self.ICSR_PENDSTCLR),  # ICSR\n                vectorBase,                   # VTOR\n                (self.NVIC_AIRCR_VECTKEY | self.NVIC_AIRCR_VECTCLRACTIVE),    # AIRCR\n                0,  # SCR\n                0,  # CCR\n                0,  # SHPR1\n                0,  # SHPR2\n                0,  # SHPR3\n                0,  # SHCSR\n                0,  # CFSR\n                ]\n        self.write_memory_block32(self.ICSR, data)\n        self.write32(self.CPACR, 0)\n        \n        if self.has_fpu:\n            data = [\n                    0,  # FPCCR\n                    0,  # FPCAR\n                    0,  # FPDSCR\n                    ]\n            self.write_memory_block32(self.FPCCR, data)\n        \n        # \"Reset\" SysTick.\n        self.write_memory_block32(self.SYSTICK_CSR, [0] * 3)\n        \n        # \"Reset\" NVIC registers.\n        numregs = (self.read32(self.ICTR) & 0xf) + 1\n        self.write_memory_block32(self.NVIC_ICER0, [0xffffffff] * numregs)\n        self.write_memory_block32(self.NVIC_ICPR0, [0xffffffff] * numregs)\n        self.write_memory_block32(self.NVIC_IPR0, [0xffffffff] * (numregs * 8))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_actual_reset_type(self, reset_type):\n        \n        # Default to reset_type session option if reset_type parameter is None. If the session\n        # option isn't set, then use the core's default reset type.\n        if reset_type is None:\n            if 'reset_type' not in self.session.options:\n                reset_type = self.default_reset_type\n            else:\n                try:\n                    # Convert session option value to enum.\n                    resetOption = self.session.options['reset_type']\n                    reset_type = cmdline.convert_reset_type(resetOption)\n                    \n                    # The converted option will be None if the option value is 'default'.\n                    if reset_type is None:\n                        reset_type = self.default_reset_type\n                except ValueError:\n                    reset_type = self.default_reset_type\n        else:\n            assert isinstance(reset_type, Target.ResetType)\n        \n        # If the reset type is just SW, then use our default software reset type.\n        if reset_type is Target.ResetType.SW:\n            reset_type = self.default_software_reset_type\n        \n        # Fall back to emulated sw reset if the vectreset is specified and the core doesn't support it.\n        if (reset_type is Target.ResetType.SW_VECTRESET) and (not self._supports_vectreset):\n            reset_type = Target.ResetType.SW_EMULATED\n        \n        return reset_type", "response": "Determine the actual reset type based on the reset type specified in the command line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _perform_reset(self, reset_type):\n        if reset_type is Target.ResetType.HW:\n            self.session.probe.reset()\n        elif reset_type is Target.ResetType.SW_EMULATED:\n            self._perform_emulated_reset()\n        else:\n            if reset_type is Target.ResetType.SW_SYSRESETREQ:\n                mask = CortexM.NVIC_AIRCR_SYSRESETREQ\n            elif reset_type is Target.ResetType.SW_VECTRESET:\n                mask = CortexM.NVIC_AIRCR_VECTRESET\n            else:\n                raise RuntimeError(\"internal error, unhandled reset type\")\n        \n            try:\n                self.write_memory(CortexM.NVIC_AIRCR, CortexM.NVIC_AIRCR_VECTKEY | mask)\n                # Without a flush a transfer error can occur\n                self.flush()\n            except exceptions.TransferError:\n                self.flush()", "response": "Perform a reset of the specified type of an element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a reset and halt the core on the reset handler.", "response": "def reset_and_halt(self, reset_type=None):\n        \"\"\"\n        perform a reset and stop the core on the reset handler\n        \"\"\"\n        \n        delegateResult = self.call_delegate('set_reset_catch', core=self, reset_type=reset_type)\n        \n        # halt the target\n        if not delegateResult:\n            self.halt()\n\n        # Save CortexM.DEMCR\n        demcr = self.read_memory(CortexM.DEMCR)\n\n        # enable the vector catch\n        if not delegateResult:\n            self.write_memory(CortexM.DEMCR, demcr | CortexM.DEMCR_VC_CORERESET)\n\n        self.reset(reset_type)\n\n        # wait until the unit resets\n        with timeout.Timeout(2.0) as t_o:\n            while t_o.check():\n                if self.get_state() not in (Target.TARGET_RESET, Target.TARGET_RUNNING):\n                    break\n                sleep(0.01)\n\n        # Make sure the thumb bit is set in XPSR in case the reset handler\n        # points to an invalid address.\n        xpsr = self.read_core_register('xpsr')\n        if xpsr & self.XPSR_THUMB == 0:\n            self.write_core_register('xpsr', xpsr | self.XPSR_THUMB)\n\n        self.call_delegate('clear_reset_catch', core=self, reset_type=reset_type)\n\n        # restore vector catch setting\n        self.write_memory(CortexM.DEMCR, demcr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resume(self):\n        if self.get_state() != Target.TARGET_HALTED:\n            logging.debug('cannot resume: target not halted')\n            return\n        self.notify(Notification(event=Target.EVENT_PRE_RUN, source=self, data=Target.RUN_TYPE_RESUME))\n        self._run_token += 1\n        self.clear_debug_cause_bits()\n        self.write_memory(CortexM.DHCSR, CortexM.DBGKEY | CortexM.C_DEBUGEN)\n        self.flush()\n        self.notify(Notification(event=Target.EVENT_POST_RUN, source=self, data=Target.RUN_TYPE_RESUME))", "response": "resume the execution of the execution of the target"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_core_registers_raw(self, reg_list):\n        # convert to index only\n        reg_list = [register_name_to_index(reg) for reg in reg_list]\n\n        # Sanity check register values\n        for reg in reg_list:\n            if reg not in CORE_REGISTER.values():\n                raise ValueError(\"unknown reg: %d\" % reg)\n            elif is_fpu_register(reg) and (not self.has_fpu):\n                raise ValueError(\"attempt to read FPU register without FPU\")\n\n        # Handle doubles.\n        doubles = [reg for reg in reg_list if is_double_float_register(reg)]\n        hasDoubles = len(doubles) > 0\n        if hasDoubles:\n            originalRegList = reg_list\n            \n            # Strip doubles from reg_list.\n            reg_list = [reg for reg in reg_list if not is_double_float_register(reg)]\n            \n            # Read float regs required to build doubles.\n            singleRegList = []\n            for reg in doubles:\n                singleRegList += (-reg, -reg + 1)\n            singleValues = self.read_core_registers_raw(singleRegList)\n\n        # Begin all reads and writes\n        dhcsr_cb_list = []\n        reg_cb_list = []\n        for reg in reg_list:\n            if is_cfbp_subregister(reg):\n                reg = CORE_REGISTER['cfbp']\n            elif is_psr_subregister(reg):\n                reg = CORE_REGISTER['xpsr']\n\n            # write id in DCRSR\n            self.write_memory(CortexM.DCRSR, reg)\n\n            # Technically, we need to poll S_REGRDY in DHCSR here before reading DCRDR. But\n            # we're running so slow compared to the target that it's not necessary.\n            # Read it and assert that S_REGRDY is set\n\n            dhcsr_cb = self.read_memory(CortexM.DHCSR, now=False)\n            reg_cb = self.read_memory(CortexM.DCRDR, now=False)\n            dhcsr_cb_list.append(dhcsr_cb)\n            reg_cb_list.append(reg_cb)\n\n        # Read all results\n        reg_vals = []\n        for reg, reg_cb, dhcsr_cb in zip(reg_list, reg_cb_list, dhcsr_cb_list):\n            dhcsr_val = dhcsr_cb()\n            assert dhcsr_val & CortexM.S_REGRDY\n            val = reg_cb()\n\n            # Special handling for registers that are combined into a single DCRSR number.\n            if is_cfbp_subregister(reg):\n                val = (val >> ((-reg - 1) * 8)) & 0xff\n            elif is_psr_subregister(reg):\n                val &= sysm_to_psr_mask(reg)\n\n            reg_vals.append(val)\n        \n        # Merge double regs back into result list.\n        if hasDoubles:\n            results = []\n            for reg in originalRegList:\n                # Double\n                if is_double_float_register(reg):\n                    doubleIndex = doubles.index(reg)\n                    singleLow = singleValues[doubleIndex * 2]\n                    singleHigh = singleValues[doubleIndex * 2 + 1]\n                    double = (singleHigh << 32) | singleLow\n                    results.append(double)\n                # Other register\n                else:\n                    results.append(reg_vals[reg_list.index(reg)])\n            reg_vals = results\n\n        return reg_vals", "response": "Read one or more core registers in reg_list and return a list of values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite one or more core registers in reg_list with the associated value in data_list.", "response": "def write_core_registers_raw(self, reg_list, data_list):\n        \"\"\"\n        Write one or more core registers\n\n        Write core registers in reg_list with the associated value in\n        data_list.  If any register in reg_list is a string, find the number\n        associated to this register in the lookup table CORE_REGISTER.\n        \"\"\"\n        assert len(reg_list) == len(data_list)\n        # convert to index only\n        reg_list = [register_name_to_index(reg) for reg in reg_list]\n\n        # Sanity check register values\n        for reg in reg_list:\n            if reg not in CORE_REGISTER.values():\n                raise ValueError(\"unknown reg: %d\" % reg)\n            elif is_fpu_register(reg) and (not self.has_fpu):\n                raise ValueError(\"attempt to write FPU register without FPU\")\n\n        # Read special register if it is present in the list and\n        # convert doubles to single float register writes.\n        cfbpValue = None\n        xpsrValue = None\n        reg_data_list = []\n        for reg, data in zip(reg_list, data_list):\n            if is_double_float_register(reg):\n                # Replace double with two single float register writes. For instance,\n                # a write of D2 gets converted to writes to S4 and S5.\n                singleLow = data & 0xffffffff\n                singleHigh = (data >> 32) & 0xffffffff\n                reg_data_list += [(-reg, singleLow), (-reg + 1, singleHigh)]\n            elif is_cfbp_subregister(reg) and cfbpValue is None:\n                cfbpValue = self.read_core_register_raw(CORE_REGISTER['cfbp'])\n            elif is_psr_subregister(reg) and xpsrValue is None:\n                xpsrValue = self.read_core_register_raw(CORE_REGISTER['xpsr'])\n            else:\n                # Other register, just copy directly.\n                reg_data_list.append((reg, data))\n        \n        # Write out registers\n        dhcsr_cb_list = []\n        for reg, data in reg_data_list:\n            if is_cfbp_subregister(reg):\n                # Mask in the new special register value so we don't modify the other register\n                # values that share the same DCRSR number.\n                shift = (-reg - 1) * 8\n                mask = 0xffffffff ^ (0xff << shift)\n                data = (cfbpValue & mask) | ((data & 0xff) << shift)\n                cfbpValue = data # update special register for other writes that might be in the list\n                reg = CORE_REGISTER['cfbp']\n            elif is_psr_subregister(reg):\n                mask = sysm_to_psr_mask(reg)\n                data = (xpsrValue & (0xffffffff ^ mask)) | (data & mask)\n                xpsrValue = data\n                reg = CORE_REGISTER['xpsr']\n\n            # write DCRDR\n            self.write_memory(CortexM.DCRDR, data)\n\n            # write id in DCRSR and flag to start write transfer\n            self.write_memory(CortexM.DCRSR, reg | CortexM.DCRSR_REGWnR)\n\n            # Technically, we need to poll S_REGRDY in DHCSR here to ensure the\n            # register write has completed.\n            # Read it and assert that S_REGRDY is set\n            dhcsr_cb = self.read_memory(CortexM.DHCSR, now=False)\n            dhcsr_cb_list.append(dhcsr_cb)\n\n        # Make sure S_REGRDY was set for all register\n        # writes\n        for dhcsr_cb in dhcsr_cb_list:\n            dhcsr_val = dhcsr_cb()\n            assert dhcsr_val & CortexM.S_REGRDY"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_watchpoint(self, addr, size, type):\n        return self.dwt.set_watchpoint(addr, size, type)", "response": "set a hardware watchpoint"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a hardware watchpoint", "response": "def remove_watchpoint(self, addr, size, type):\n        \"\"\"\n        remove a hardware watchpoint\n        \"\"\"\n        return self.dwt.remove_watchpoint(addr, size, type)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_user_file(self, option_name, filename_list):\n        if option_name is not None:\n            filePath = self._options.get(option_name, None)\n        else:\n            filePath = None\n        \n        # Look for default filenames if a path wasn't provided.\n        if filePath is None:\n            for filename in filename_list:\n                thisPath = os.path.join(self.project_dir, filename)\n                if os.path.isfile(thisPath):\n                    filePath = thisPath\n                    break\n        # Use the path passed in options, which may be absolute, relative to the\n        # home directory, or relative to the project directory.\n        else:\n            filePath = os.path.expanduser(filePath)\n            if not os.path.isabs(filePath):\n                filePath = os.path.join(self.project_dir, filePath)\n        \n        return filePath", "response": "Searches the project directory for a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self):\n        if self._closed:\n            return\n        self._closed = True\n\n        LOG.debug(\"uninit session %s\", self)\n        if self._inited:\n            try:\n                self.board.uninit()\n                self._inited = False\n            except:\n                LOG.error(\"exception during board uninit:\", exc_info=self.log_tracebacks)\n        \n        if self._probe.is_open:\n            try:\n                self._probe.disconnect()\n            except:\n                LOG.error(\"probe exception during disconnect:\", exc_info=self.log_tracebacks)\n            try:\n                self._probe.close()\n            except:\n                LOG.error(\"probe exception during close:\", exc_info=self.log_tracebacks)", "response": "! @brief Close the session.\n        \n        Uninits the board and disconnects then closes the probe."}
