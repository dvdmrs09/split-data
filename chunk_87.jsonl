{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchanging the current working directory to a different directory for a code . Useful for running commands from a specific directory.", "response": "def chdir(directory):\n    \"\"\"Change the current working directory to a different directory for a code\n    block and return the previous directory after the block exits. Useful to\n    run commands from a specificed directory.\n\n    :param str directory: The directory path to change to for this context.\n    \"\"\"\n    cur = os.getcwd()\n    try:\n        yield os.chdir(directory)\n    finally:\n        os.chdir(cur)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef owner(path):\n    stat = os.stat(path)\n    username = pwd.getpwuid(stat.st_uid)[0]\n    groupname = grp.getgrgid(stat.st_gid)[0]\n    return username, groupname", "response": "Returns a tuple containing the username groupname of the user and group owning the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_total_ram():\n    with open('/proc/meminfo', 'r') as f:\n        for line in f.readlines():\n            if line:\n                key, value, unit = line.split()\n                if key == 'MemTotal:':\n                    assert unit == 'kB', 'Unknown unit'\n                    return int(value) * 1024  # Classic, not KiB.\n        raise NotImplementedError()", "response": "Returns the total amount of system RAM in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_to_updatedb_prunepath(path, updatedb_path=UPDATEDB_PATH):\n    if not os.path.exists(updatedb_path) or os.path.isdir(updatedb_path):\n        # If the updatedb.conf file doesn't exist then don't attempt to update\n        # the file as the package providing mlocate may not be installed on\n        # the local system\n        return\n\n    with open(updatedb_path, 'r+') as f_id:\n        updatedb_text = f_id.read()\n        output = updatedb(updatedb_text, path)\n        f_id.seek(0)\n        f_id.write(output)\n        f_id.truncate()", "response": "Adds the specified path to the mlocate s udpatedb. conf PRUNEPATHS list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modulo_distribution(modulo=3, wait=30, non_zero_wait=False):\n    unit_number = int(local_unit().split('/')[1])\n    calculated_wait_time = (unit_number % modulo) * wait\n    if non_zero_wait and calculated_wait_time == 0:\n        return modulo * wait\n    else:\n        return calculated_wait_time", "response": "This helper returns the time to wait for a given modulo value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_ca_cert(ca_cert, name=None):\n    if not ca_cert:\n        return\n    if not isinstance(ca_cert, bytes):\n        ca_cert = ca_cert.encode('utf8')\n    if not name:\n        name = 'juju-{}'.format(charm_name())\n    cert_file = '/usr/local/share/ca-certificates/{}.crt'.format(name)\n    new_hash = hashlib.md5(ca_cert).hexdigest()\n    if file_hash(cert_file) == new_hash:\n        return\n    log(\"Installing new CA cert at: {}\".format(cert_file), level=INFO)\n    write_file(cert_file, ca_cert)\n    subprocess.check_call(['update-ca-certificates', '--fresh'])", "response": "Installs a given CA cert as a trusted CA."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_audits():\n    audits = []\n    audits.append(TemplatedFile('/etc/securetty', SecureTTYContext(),\n                                template_dir=TEMPLATES_DIR,\n                                mode=0o0400, user='root', group='root'))\n    return audits", "response": "Get OS hardening Secure TTY audits."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_keys_without_hyphens(a_dict):\n    return dict(\n        (key.replace('-', '_'), val) for key, val in a_dict.items())", "response": "Return a new dict with underscores instead of hyphens in keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_relations(context, namespace_separator=':'):\n    # Add any relation data prefixed with the relation type.\n    relation_type = charmhelpers.core.hookenv.relation_type()\n    relations = []\n    context['current_relation'] = {}\n    if relation_type is not None:\n        relation_data = charmhelpers.core.hookenv.relation_get()\n        context['current_relation'] = relation_data\n        # Deprecated: the following use of relation data as keys\n        # directly in the context will be removed.\n        relation_data = dict(\n            (\"{relation_type}{namespace_separator}{key}\".format(\n                relation_type=relation_type,\n                key=key,\n                namespace_separator=namespace_separator), val)\n            for key, val in relation_data.items())\n        relation_data = dict_keys_without_hyphens(relation_data)\n        context.update(relation_data)\n        relations = charmhelpers.core.hookenv.relations_of_type(relation_type)\n        relations = [dict_keys_without_hyphens(rel) for rel in relations]\n\n    context['relations_full'] = charmhelpers.core.hookenv.relations()\n\n    # the hookenv.relations() data structure is effectively unusable in\n    # templates and other contexts when trying to access relation data other\n    # than the current relation. So provide a more useful structure that works\n    # with any hook.\n    local_unit = charmhelpers.core.hookenv.local_unit()\n    relations = {}\n    for rname, rids in context['relations_full'].items():\n        relations[rname] = []\n        for rid, rdata in rids.items():\n            data = rdata.copy()\n            if local_unit in rdata:\n                data.pop(local_unit)\n            for unit_name, rel_data in data.items():\n                new_data = {'__relid__': rid, '__unit__': unit_name}\n                new_data.update(rel_data)\n                relations[rname].append(new_data)\n    context['relations'] = relations", "response": "Update the context with the relation data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the juju config and state in a yaml file.", "response": "def juju_state_to_yaml(yaml_path, namespace_separator=':',\n                       allow_hyphens_in_keys=True, mode=None):\n    \"\"\"Update the juju config and state in a yaml file.\n\n    This includes any current relation-get data, and the charm\n    directory.\n\n    This function was created for the ansible and saltstack\n    support, as those libraries can use a yaml file to supply\n    context to templates, but it may be useful generally to\n    create and update an on-disk cache of all the config, including\n    previous relation data.\n\n    By default, hyphens are allowed in keys as this is supported\n    by yaml, but for tools like ansible, hyphens are not valid [1].\n\n    [1] http://www.ansibleworks.com/docs/playbooks_variables.html#what-makes-a-valid-variable-name\n    \"\"\"\n    config = charmhelpers.core.hookenv.config()\n\n    # Add the charm_dir which we will need to refer to charm\n    # file resources etc.\n    config['charm_dir'] = charm_dir\n    config['local_unit'] = charmhelpers.core.hookenv.local_unit()\n    config['unit_private_address'] = charmhelpers.core.hookenv.unit_private_ip()\n    config['unit_public_address'] = charmhelpers.core.hookenv.unit_get(\n        'public-address'\n    )\n\n    # Don't use non-standard tags for unicode which will not\n    # work when salt uses yaml.load_safe.\n    yaml.add_representer(six.text_type,\n                         lambda dumper, value: dumper.represent_scalar(\n                             six.u('tag:yaml.org,2002:str'), value))\n\n    yaml_dir = os.path.dirname(yaml_path)\n    if not os.path.exists(yaml_dir):\n        os.makedirs(yaml_dir)\n\n    if os.path.exists(yaml_path):\n        with open(yaml_path, \"r\") as existing_vars_file:\n            existing_vars = yaml.load(existing_vars_file.read())\n    else:\n        with open(yaml_path, \"w+\"):\n            pass\n        existing_vars = {}\n\n    if mode is not None:\n        os.chmod(yaml_path, mode)\n\n    if not allow_hyphens_in_keys:\n        config = dict_keys_without_hyphens(config)\n    existing_vars.update(config)\n\n    update_relations(existing_vars, namespace_separator)\n\n    with open(yaml_path, \"w+\") as fp:\n        fp.write(yaml.dump(existing_vars, default_flow_style=False))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets Apache hardening config audits.", "response": "def get_audits():\n    \"\"\"Get Apache hardening config audits.\n\n    :returns:  dictionary of audits\n    \"\"\"\n    if subprocess.call(['which', 'apache2'], stdout=subprocess.PIPE) != 0:\n        log(\"Apache server does not appear to be installed on this node - \"\n            \"skipping apache hardening\", level=INFO)\n        return []\n\n    context = ApacheConfContext()\n    settings = utils.get_settings('apache')\n    audits = [\n        FilePermissionAudit(paths=os.path.join(\n                            settings['common']['apache_dir'], 'apache2.conf'),\n                            user='root', group='root', mode=0o0640),\n\n        TemplatedFile(os.path.join(settings['common']['apache_dir'],\n                                   'mods-available/alias.conf'),\n                      context,\n                      TEMPLATES_DIR,\n                      mode=0o0640,\n                      user='root',\n                      service_actions=[{'service': 'apache2',\n                                        'actions': ['restart']}]),\n\n        TemplatedFile(os.path.join(settings['common']['apache_dir'],\n                                   'conf-enabled/99-hardening.conf'),\n                      context,\n                      TEMPLATES_DIR,\n                      mode=0o0640,\n                      user='root',\n                      service_actions=[{'service': 'apache2',\n                                        'actions': ['restart']}]),\n\n        DirectoryPermissionAudit(settings['common']['apache_dir'],\n                                 user='root',\n                                 group='root',\n                                 mode=0o0750),\n\n        DisabledModuleAudit(settings['hardening']['modules_to_disable']),\n\n        NoReadWriteForOther(settings['common']['apache_dir']),\n\n        DeletedFile(['/var/www/html/index.html'])\n    ]\n\n    return audits"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget OS hardening access audits.", "response": "def get_audits():\n    \"\"\"Get OS hardening access audits.\n\n    :returns:  dictionary of audits\n    \"\"\"\n    audits = []\n    settings = utils.get_settings('os')\n\n    # Remove write permissions from $PATH folders for all regular users.\n    # This prevents changing system-wide commands from normal users.\n    path_folders = {'/usr/local/sbin',\n                    '/usr/local/bin',\n                    '/usr/sbin',\n                    '/usr/bin',\n                    '/bin'}\n    extra_user_paths = settings['environment']['extra_user_paths']\n    path_folders.update(extra_user_paths)\n    audits.append(ReadOnly(path_folders))\n\n    # Only allow the root user to have access to the shadow file.\n    audits.append(FilePermissionAudit('/etc/shadow', 'root', 'root', 0o0600))\n\n    if 'change_user' not in settings['security']['users_allow']:\n        # su should only be accessible to user and group root, unless it is\n        # expressly defined to allow users to change to root via the\n        # security_users_allow config option.\n        audits.append(FilePermissionAudit('/bin/su', 'root', 'root', 0o750))\n\n    return audits"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef harden(overrides=None):\n    if overrides is None:\n        overrides = []\n\n    def _harden_inner1(f):\n        # As this has to be py2.7 compat, we can't use nonlocal.  Use a trick\n        # to capture the dictionary that can then be updated.\n        _logged = {'done': False}\n\n        def _harden_inner2(*args, **kwargs):\n            # knock out hardening via a config var; normally it won't get\n            # disabled.\n            if _DISABLE_HARDENING_FOR_UNIT_TEST:\n                return f(*args, **kwargs)\n            if not _logged['done']:\n                log(\"Hardening function '%s'\" % (f.__name__), level=DEBUG)\n                _logged['done'] = True\n            RUN_CATALOG = OrderedDict([('os', run_os_checks),\n                                       ('ssh', run_ssh_checks),\n                                       ('mysql', run_mysql_checks),\n                                       ('apache', run_apache_checks)])\n\n            enabled = overrides[:] or (config(\"harden\") or \"\").split()\n            if enabled:\n                modules_to_run = []\n                # modules will always be performed in the following order\n                for module, func in six.iteritems(RUN_CATALOG):\n                    if module in enabled:\n                        enabled.remove(module)\n                        modules_to_run.append(func)\n\n                if enabled:\n                    log(\"Unknown hardening modules '%s' - ignoring\" %\n                        (', '.join(enabled)), level=WARNING)\n\n                for hardener in modules_to_run:\n                    log(\"Executing hardening module '%s'\" %\n                        (hardener.__name__), level=DEBUG)\n                    hardener()\n            else:\n                log(\"No hardening applied to '%s'\" % (f.__name__), level=DEBUG)\n\n            return f(*args, **kwargs)\n        return _harden_inner2\n\n    return _harden_inner1", "response": "A function that hardenes the resources of a single charm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kernel_version():\n    kver = check_output(['uname', '-r']).decode('UTF-8').strip()\n    kver = kver.split('.')\n    return (int(kver[0]), int(kver[1]))", "response": "Retrieve the current kernel version as a tuple e. g. 3. 13"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of the network - manager for the current node.", "response": "def network_manager():\n    '''\n    Deals with the renaming of Quantum to Neutron in H and any situations\n    that require compatability (eg, deploying H with network-manager=quantum,\n    upgrading from G).\n    '''\n    release = os_release('nova-common')\n    manager = config('network-manager').lower()\n\n    if manager not in ['quantum', 'neutron']:\n        return manager\n\n    if release in ['essex']:\n        # E does not support neutron\n        log('Neutron networking not supported in Essex.', level=ERROR)\n        raise Exception\n    elif release in ['folsom', 'grizzly']:\n        # neutron is named quantum in F and G\n        return 'quantum'\n    else:\n        # ensure accurate naming for all releases post-H\n        return 'neutron'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the mappings string into a dictionary.", "response": "def parse_mappings(mappings, key_rvalue=False):\n    \"\"\"By default mappings are lvalue keyed.\n\n    If key_rvalue is True, the mapping will be reversed to allow multiple\n    configs for the same lvalue.\n    \"\"\"\n    parsed = {}\n    if mappings:\n        mappings = mappings.split()\n        for m in mappings:\n            p = m.partition(':')\n\n            if key_rvalue:\n                key_index = 2\n                val_index = 0\n                # if there is no rvalue skip to next\n                if not p[1]:\n                    continue\n            else:\n                key_index = 0\n                val_index = 2\n\n            key = p[key_index].strip()\n            parsed[key] = p[val_index].strip()\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_data_port_mappings(mappings, default_bridge='br-data'):\n\n    # NOTE(dosaboy): we use rvalue for key to allow multiple values to be\n    # proposed for <port> since it may be a mac address which will differ\n    # across units this allowing first-known-good to be chosen.\n    _mappings = parse_mappings(mappings, key_rvalue=True)\n    if not _mappings or list(_mappings.values()) == ['']:\n        if not mappings:\n            return {}\n\n        # For backwards-compatibility we need to support port-only provided in\n        # config.\n        _mappings = {mappings.split()[0]: default_bridge}\n\n    ports = _mappings.keys()\n    if len(set(ports)) != len(ports):\n        raise Exception(\"It is not allowed to have the same port configured \"\n                        \"on more than one bridge\")\n\n    return _mappings", "response": "Parse data port mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses vlan range mappings.", "response": "def parse_vlan_range_mappings(mappings):\n    \"\"\"Parse vlan range mappings.\n\n    Mappings must be a space-delimited list of provider:start:end mappings.\n\n    The start:end range is optional and may be omitted.\n\n    Returns dict of the form {provider: (start, end)}.\n    \"\"\"\n    _mappings = parse_mappings(mappings)\n    if not _mappings:\n        return {}\n\n    mappings = {}\n    for p, r in six.iteritems(_mappings):\n        mappings[p] = tuple(r.split(':'))\n\n    return mappings"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_tarfile(archive_name, destpath):\n    \"Unpack a tar archive, optionally compressed\"\n    archive = tarfile.open(archive_name)\n    archive.extractall(destpath)", "response": "Unpack a tar archive optionally compressed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunpacking a zip file", "response": "def extract_zipfile(archive_name, destpath):\n    \"Unpack a zip file\"\n    archive = zipfile.ZipFile(archive_name)\n    archive.extractall(destpath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an netaddr. IPNetwork object for the given IPv6 address", "response": "def _get_ipv6_network_from_address(address):\n    \"\"\"Get an netaddr.IPNetwork for the given IPv6 address\n    :param address: a dict as returned by netifaces.ifaddresses\n    :returns netaddr.IPNetwork: None if the address is a link local or loopback\n    address\n    \"\"\"\n    if address['addr'].startswith('fe80') or address['addr'] == \"::1\":\n        return None\n\n    prefix = address['netmask'].split(\"/\")\n    if len(prefix) > 1:\n        netmask = prefix[1]\n    else:\n        netmask = address['netmask']\n    return netaddr.IPNetwork(\"%s/%s\" % (address['addr'],\n                                        netmask))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_address_in_network(network, fallback=None, fatal=False):\n    if network is None:\n        if fallback is not None:\n            return fallback\n\n        if fatal:\n            no_ip_found_error_out(network)\n        else:\n            return None\n\n    networks = network.split() or [network]\n    for network in networks:\n        _validate_cidr(network)\n        network = netaddr.IPNetwork(network)\n        for iface in netifaces.interfaces():\n            try:\n                addresses = netifaces.ifaddresses(iface)\n            except ValueError:\n                # If an instance was deleted between\n                # netifaces.interfaces() run and now, its interfaces are gone\n                continue\n            if network.version == 4 and netifaces.AF_INET in addresses:\n                for addr in addresses[netifaces.AF_INET]:\n                    cidr = netaddr.IPNetwork(\"%s/%s\" % (addr['addr'],\n                                                        addr['netmask']))\n                    if cidr in network:\n                        return str(cidr.ip)\n\n            if network.version == 6 and netifaces.AF_INET6 in addresses:\n                for addr in addresses[netifaces.AF_INET6]:\n                    cidr = _get_ipv6_network_from_address(addr)\n                    if cidr and cidr in network:\n                        return str(cidr.ip)\n\n    if fallback is not None:\n        return fallback\n\n    if fatal:\n        no_ip_found_error_out(network)\n\n    return None", "response": "Get an IPv4 or IPv6 address within the network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine whether provided address is IPv6.", "response": "def is_ipv6(address):\n    \"\"\"Determine whether provided address is IPv6 or not.\"\"\"\n    try:\n        address = netaddr.IPAddress(address)\n    except netaddr.AddrFormatError:\n        # probably a hostname - so not an address at all!\n        return False\n\n    return address.version == 6"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_address_in_network(network, address):\n    try:\n        network = netaddr.IPNetwork(network)\n    except (netaddr.core.AddrFormatError, ValueError):\n        raise ValueError(\"Network (%s) is not in CIDR presentation format\" %\n                         network)\n\n    try:\n        address = netaddr.IPAddress(address)\n    except (netaddr.core.AddrFormatError, ValueError):\n        raise ValueError(\"Address (%s) is not in correct presentation format\" %\n                         address)\n\n    if address in network:\n        return True\n    else:\n        return False", "response": "Determines whether the provided address is within a network range."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_for_address(address, key):\n    address = netaddr.IPAddress(address)\n    for iface in netifaces.interfaces():\n        addresses = netifaces.ifaddresses(iface)\n        if address.version == 4 and netifaces.AF_INET in addresses:\n            addr = addresses[netifaces.AF_INET][0]['addr']\n            netmask = addresses[netifaces.AF_INET][0]['netmask']\n            network = netaddr.IPNetwork(\"%s/%s\" % (addr, netmask))\n            cidr = network.cidr\n            if address in cidr:\n                if key == 'iface':\n                    return iface\n                else:\n                    return addresses[netifaces.AF_INET][0][key]\n\n        if address.version == 6 and netifaces.AF_INET6 in addresses:\n            for addr in addresses[netifaces.AF_INET6]:\n                network = _get_ipv6_network_from_address(addr)\n                if not network:\n                    continue\n\n                cidr = network.cidr\n                if address in cidr:\n                    if key == 'iface':\n                        return iface\n                    elif key == 'netmask' and cidr:\n                        return str(cidr).split('/')[1]\n                    else:\n                        return addr[key]\n    return None", "response": "Returns an attribute of or None if the given address is not bindable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the assigned IP address for a given interface.", "response": "def get_iface_addr(iface='eth0', inet_type='AF_INET', inc_aliases=False,\n                   fatal=True, exc_list=None):\n    \"\"\"Return the assigned IP address for a given interface, if any.\n\n    :param iface: network interface on which address(es) are expected to\n                  be found.\n    :param inet_type: inet address family\n    :param inc_aliases: include alias interfaces in search\n    :param fatal: if True, raise exception if address not found\n    :param exc_list: list of addresses to ignore\n    :return: list of ip addresses\n    \"\"\"\n    # Extract nic if passed /dev/ethX\n    if '/' in iface:\n        iface = iface.split('/')[-1]\n\n    if not exc_list:\n        exc_list = []\n\n    try:\n        inet_num = getattr(netifaces, inet_type)\n    except AttributeError:\n        raise Exception(\"Unknown inet type '%s'\" % str(inet_type))\n\n    interfaces = netifaces.interfaces()\n    if inc_aliases:\n        ifaces = []\n        for _iface in interfaces:\n            if iface == _iface or _iface.split(':')[0] == iface:\n                ifaces.append(_iface)\n\n        if fatal and not ifaces:\n            raise Exception(\"Invalid interface '%s'\" % iface)\n\n        ifaces.sort()\n    else:\n        if iface not in interfaces:\n            if fatal:\n                raise Exception(\"Interface '%s' not found \" % (iface))\n            else:\n                return []\n\n        else:\n            ifaces = [iface]\n\n    addresses = []\n    for netiface in ifaces:\n        net_info = netifaces.ifaddresses(netiface)\n        if inet_num in net_info:\n            for entry in net_info[inet_num]:\n                if 'addr' in entry and entry['addr'] not in exc_list:\n                    addresses.append(entry['addr'])\n\n    if fatal and not addresses:\n        raise Exception(\"Interface '%s' doesn't have any %s addresses.\" %\n                        (iface, inet_type))\n\n    return sorted(addresses)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nworks out on which interface the provided address is configured.", "response": "def get_iface_from_addr(addr):\n    \"\"\"Work out on which interface the provided address is configured.\"\"\"\n    for iface in netifaces.interfaces():\n        addresses = netifaces.ifaddresses(iface)\n        for inet_type in addresses:\n            for _addr in addresses[inet_type]:\n                _addr = _addr['addr']\n                # link local\n                ll_key = re.compile(\"(.+)%.*\")\n                raw = re.match(ll_key, _addr)\n                if raw:\n                    _addr = raw.group(1)\n\n                if _addr == addr:\n                    log(\"Address '%s' is configured on iface '%s'\" %\n                        (addr, iface))\n                    return iface\n\n    msg = \"Unable to infer net iface on which '%s' is configured\" % (addr)\n    raise Exception(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures decorated function is called with a value for iface. If no iface provided, inject net iface inferred from unit private address.", "response": "def sniff_iface(f):\n    \"\"\"Ensure decorated function is called with a value for iface.\n\n    If no iface provided, inject net iface inferred from unit private address.\n    \"\"\"\n    def iface_sniffer(*args, **kwargs):\n        if not kwargs.get('iface', None):\n            kwargs['iface'] = get_iface_from_addr(unit_get('private-address'))\n\n        return f(*args, **kwargs)\n\n    return iface_sniffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets assigned IPv6 address for a given interface.", "response": "def get_ipv6_addr(iface=None, inc_aliases=False, fatal=True, exc_list=None,\n                  dynamic_only=True):\n    \"\"\"Get assigned IPv6 address for a given interface.\n\n    Returns list of addresses found. If no address found, returns empty list.\n\n    If iface is None, we infer the current primary interface by doing a reverse\n    lookup on the unit private-address.\n\n    We currently only support scope global IPv6 addresses i.e. non-temporary\n    addresses. If no global IPv6 address is found, return the first one found\n    in the ipv6 address list.\n\n    :param iface: network interface on which ipv6 address(es) are expected to\n                  be found.\n    :param inc_aliases: include alias interfaces in search\n    :param fatal: if True, raise exception if address not found\n    :param exc_list: list of addresses to ignore\n    :param dynamic_only: only recognise dynamic addresses\n    :return: list of ipv6 addresses\n    \"\"\"\n    addresses = get_iface_addr(iface=iface, inet_type='AF_INET6',\n                               inc_aliases=inc_aliases, fatal=fatal,\n                               exc_list=exc_list)\n\n    if addresses:\n        global_addrs = []\n        for addr in addresses:\n            key_scope_link_local = re.compile(\"^fe80::..(.+)%(.+)\")\n            m = re.match(key_scope_link_local, addr)\n            if m:\n                eui_64_mac = m.group(1)\n                iface = m.group(2)\n            else:\n                global_addrs.append(addr)\n\n        if global_addrs:\n            # Make sure any found global addresses are not temporary\n            cmd = ['ip', 'addr', 'show', iface]\n            out = subprocess.check_output(cmd).decode('UTF-8')\n            if dynamic_only:\n                key = re.compile(\"inet6 (.+)/[0-9]+ scope global.* dynamic.*\")\n            else:\n                key = re.compile(\"inet6 (.+)/[0-9]+ scope global.*\")\n\n            addrs = []\n            for line in out.split('\\n'):\n                line = line.strip()\n                m = re.match(key, line)\n                if m and 'temporary' not in line:\n                    # Return the first valid address we find\n                    for addr in global_addrs:\n                        if m.group(1) == addr:\n                            if not dynamic_only or \\\n                                    m.group(1).endswith(eui_64_mac):\n                                addrs.append(addr)\n\n            if addrs:\n                return addrs\n\n    if fatal:\n        raise Exception(\"Interface '%s' does not have a scope global \"\n                        \"non-temporary ipv6 address.\" % iface)\n\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_bridges(vnic_dir='/sys/devices/virtual/net'):\n    b_regex = \"%s/*/bridge\" % vnic_dir\n    return [x.replace(vnic_dir, '').split('/')[1] for x in glob.glob(b_regex)]", "response": "Return a list of bridges on the system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bridge_nics(bridge, vnic_dir='/sys/devices/virtual/net'):\n    brif_regex = \"%s/%s/brif/*\" % (vnic_dir, bridge)\n    return [x.split('/')[-1] for x in glob.glob(brif_regex)]", "response": "Return a list of nics comprising a given bridge on the system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_ip(address):\n    try:\n        # Test to see if already an IPv4/IPv6 address\n        address = netaddr.IPAddress(address)\n        return True\n    except (netaddr.AddrFormatError, ValueError):\n        return False", "response": "Returns True if the given address is a valid IP address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_host_ip(hostname, fallback=None):\n    if is_ip(hostname):\n        return hostname\n\n    ip_addr = ns_query(hostname)\n    if not ip_addr:\n        try:\n            ip_addr = socket.gethostbyname(hostname)\n        except Exception:\n            log(\"Failed to resolve hostname '%s'\" % (hostname),\n                level=WARNING)\n            return fallback\n    return ip_addr", "response": "Resolves the IP for a given hostname."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves hostname for given IP or returns the input if it is already a hostname.", "response": "def get_hostname(address, fqdn=True):\n    \"\"\"\n    Resolves hostname for given IP, or returns the input\n    if it is already a hostname.\n    \"\"\"\n    if is_ip(address):\n        try:\n            import dns.reversename\n        except ImportError:\n            if six.PY2:\n                apt_install(\"python-dnspython\", fatal=True)\n            else:\n                apt_install(\"python3-dnspython\", fatal=True)\n            import dns.reversename\n\n        rev = dns.reversename.from_address(address)\n        result = ns_query(rev)\n\n        if not result:\n            try:\n                result = socket.gethostbyaddr(address)[0]\n            except Exception:\n                return None\n    else:\n        result = address\n\n    if fqdn:\n        # strip trailing .\n        if result.endswith('.'):\n            return result[:-1]\n        else:\n            return result\n    else:\n        return result.split('.')[0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the port is open and being listened to otherwise False.", "response": "def port_has_listener(address, port):\n    \"\"\"\n    Returns True if the address:port is open and being listened to,\n    else False.\n\n    @param address: an IP address or hostname\n    @param port: integer port\n\n    Note calls 'zc' via a subprocess shell\n    \"\"\"\n    cmd = ['nc', '-z', address, str(port)]\n    result = subprocess.call(cmd)\n    return not(bool(result))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_relation_ip(interface, cidr_network=None):\n    # Select the interface address first\n    # For possible use as a fallback bellow with get_address_in_network\n    try:\n        # Get the interface specific IP\n        address = network_get_primary_address(interface)\n    except NotImplementedError:\n        # If network-get is not available\n        address = get_host_ip(unit_get('private-address'))\n    except NoNetworkBinding:\n        log(\"No network binding for {}\".format(interface), WARNING)\n        address = get_host_ip(unit_get('private-address'))\n\n    if config('prefer-ipv6'):\n        # Currently IPv6 has priority, eventually we want IPv6 to just be\n        # another network space.\n        assert_charm_supports_ipv6()\n        return get_ipv6_addr()[0]\n    elif cidr_network:\n        # If a specific CIDR network is passed get the address from that\n        # network.\n        return get_address_in_network(cidr_network, address)\n\n    # Return the interface address\n    return address", "response": "Return this unit s IP for the given interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring that all registered files comply to registered criteria.", "response": "def ensure_compliance(self):\n        \"\"\"Ensure that the all registered files comply to registered criteria.\n        \"\"\"\n        for p in self.paths:\n            if os.path.exists(p):\n                if self.is_compliant(p):\n                    continue\n\n                log('File %s is not in compliance.' % p, level=INFO)\n            else:\n                if not self.always_comply:\n                    log(\"Non-existent path '%s' - skipping compliance check\"\n                        % (p), level=INFO)\n                    continue\n\n            if self._take_action():\n                log(\"Applying compliance criteria to '%s'\" % (p), level=INFO)\n                self.comply(p)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_compliant(self, path):\n        stat = self._get_stat(path)\n        user = self.user\n        group = self.group\n\n        compliant = True\n        if stat.st_uid != user.pw_uid or stat.st_gid != group.gr_gid:\n            log('File %s is not owned by %s:%s.' % (path, user.pw_name,\n                                                    group.gr_name),\n                level=INFO)\n            compliant = False\n\n        # POSIX refers to the st_mode bits as corresponding to both the\n        # file type and file permission bits, where the least significant 12\n        # bits (o7777) are the suid (11), sgid (10), sticky bits (9), and the\n        # file permission bits (8-0)\n        perms = stat.st_mode & 0o7777\n        if perms != self.mode:\n            log('File %s has incorrect permissions, currently set to %s' %\n                (path, oct(stat.st_mode & 0o7777)), level=INFO)\n            compliant = False\n\n        return compliant", "response": "Checks if the path specified meets the necessary neccesary neccesary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef comply(self, path):\n        utils.ensure_permissions(path, self.user.pw_name, self.group.gr_name,\n                                 self.mode)", "response": "Issues a chown and chmod to the file paths specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the directory tree is compliant.", "response": "def is_compliant(self, path):\n        \"\"\"Checks if the directory is compliant.\n\n        Used to determine if the path specified and all of its children\n        directories are in compliance with the check itself.\n\n        :param path: the directory path to check\n        :returns: True if the directory tree is compliant, otherwise False.\n        \"\"\"\n        if not os.path.isdir(path):\n            log('Path specified %s is not a directory.' % path, level=ERROR)\n            raise ValueError(\"%s is not a directory.\" % path)\n\n        if not self.recursive:\n            return super(DirectoryPermissionAudit, self).is_compliant(path)\n\n        compliant = True\n        for root, dirs, _ in os.walk(path):\n            if len(dirs) > 0:\n                continue\n\n            if not super(DirectoryPermissionAudit, self).is_compliant(root):\n                compliant = False\n                continue\n\n        return compliant"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_compliant(self, path):\n        same_templates = self.templates_match(path)\n        same_content = self.contents_match(path)\n        same_permissions = self.permissions_match(path)\n\n        if same_content and same_permissions and same_templates:\n            return True\n\n        return False", "response": "Determines if the templated file is compliant."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns any actions on services requested.", "response": "def run_service_actions(self):\n        \"\"\"Run any actions on services requested.\"\"\"\n        if not self.service_actions:\n            return\n\n        for svc_action in self.service_actions:\n            name = svc_action['service']\n            actions = svc_action['actions']\n            log(\"Running service '%s' actions '%s'\" % (name, actions),\n                level=DEBUG)\n            for action in actions:\n                cmd = ['service', name, action]\n                try:\n                    check_call(cmd)\n                except CalledProcessError as exc:\n                    log(\"Service name='%s' action='%s' failed - %s\" %\n                        (name, action, exc), level=WARNING)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring the contents and the permissions of the file.", "response": "def comply(self, path):\n        \"\"\"Ensures the contents and the permissions of the file.\n\n        :param path: the path to correct\n        \"\"\"\n        dirname = os.path.dirname(path)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        self.pre_write()\n        render_and_write(self.template_dir, path, self.context())\n        utils.ensure_permissions(path, self.user, self.group, self.mode)\n        self.run_service_actions()\n        self.save_checksum(path)\n        self.post_write()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef templates_match(self, path):\n        template_path = get_template_path(self.template_dir, path)\n        key = 'hardening:template:%s' % template_path\n        template_checksum = file_hash(template_path)\n        kv = unitdata.kv()\n        stored_tmplt_checksum = kv.get(key)\n        if not stored_tmplt_checksum:\n            kv.set(key, template_checksum)\n            kv.flush()\n            log('Saved template checksum for %s.' % template_path,\n                level=DEBUG)\n            # Since we don't have a template checksum, then assume it doesn't\n            # match and return that the template is different.\n            return False\n        elif stored_tmplt_checksum != template_checksum:\n            kv.set(key, template_checksum)\n            kv.flush()\n            log('Updated template checksum for %s.' % template_path,\n                level=DEBUG)\n            return False\n\n        # Here the template hasn't changed based upon the calculated\n        # checksum of the template and what was previously stored.\n        return True", "response": "Determines if the template files are the same."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the contents of the file is the same as the file stored in the file store.", "response": "def contents_match(self, path):\n        \"\"\"Determines if the file content is the same.\n\n        This is determined by comparing hashsum of the file contents and\n        the saved hashsum. If there is no hashsum, then the content cannot\n        be sure to be the same so treat them as if they are not the same.\n        Otherwise, return True if the hashsums are the same, False if they\n        are not the same.\n\n        :param path: the file to check.\n        \"\"\"\n        checksum = file_hash(path)\n\n        kv = unitdata.kv()\n        stored_checksum = kv.get('hardening:%s' % path)\n        if not stored_checksum:\n            # If the checksum hasn't been generated, return False to ensure\n            # the file is written and the checksum stored.\n            log('Checksum for %s has not been calculated.' % path, level=DEBUG)\n            return False\n        elif stored_checksum != checksum:\n            log('Checksum mismatch for %s.' % path, level=DEBUG)\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef permissions_match(self, path):\n        audit = FilePermissionAudit(path, self.user, self.group, self.mode)\n        return audit.is_compliant(path)", "response": "Determines if the file owner and permissions match."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating and saves the checksum for the path specified.", "response": "def save_checksum(self, path):\n        \"\"\"Calculates and saves the checksum for the path specified.\n\n        :param path: the path of the file to save the checksum.\n        \"\"\"\n        checksum = file_hash(path)\n        kv = unitdata.kv()\n        kv.set('hardening:%s' % path, checksum)\n        kv.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_compliant(self, path):\n        log(\"Auditing contents of file '%s'\" % (path), level=DEBUG)\n        with open(path, 'r') as fd:\n            contents = fd.read()\n\n        matches = 0\n        for pattern in self.pass_cases:\n            key = re.compile(pattern, flags=re.MULTILINE)\n            results = re.search(key, contents)\n            if results:\n                matches += 1\n            else:\n                log(\"Pattern '%s' was expected to pass but instead it failed\"\n                    % (pattern), level=WARNING)\n\n        for pattern in self.fail_cases:\n            key = re.compile(pattern, flags=re.MULTILINE)\n            results = re.search(key, contents)\n            if not results:\n                matches += 1\n            else:\n                log(\"Pattern '%s' was expected to fail but instead it passed\"\n                    % (pattern), level=WARNING)\n\n        total = len(self.pass_cases) + len(self.fail_cases)\n        log(\"Checked %s cases and %s passed\" % (total, matches), level=DEBUG)\n        return matches == total", "response": "Checks that the contents of the file matches the set of content matching cases i. e. whether or not regex is expected to match with the contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bool_from_string(value):\n    if isinstance(value, six.string_types):\n        value = six.text_type(value)\n    else:\n        msg = \"Unable to interpret non-string value '%s' as boolean\" % (value)\n        raise ValueError(msg)\n\n    value = value.strip().lower()\n\n    if value in ['y', 'yes', 'true', 't', 'on']:\n        return True\n    elif value in ['n', 'no', 'false', 'f', 'off']:\n        return False\n\n    msg = \"Unable to interpret string value '%s' as boolean\" % (value)\n    raise ValueError(msg)", "response": "Interpret string value as boolean."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninterprets human readable string value as bytes. Returns int Raises ValueError if value is not a string", "response": "def bytes_from_string(value):\n    \"\"\"Interpret human readable string value as bytes.\n\n    Returns int\n    \"\"\"\n    BYTE_POWER = {\n        'K': 1,\n        'KB': 1,\n        'M': 2,\n        'MB': 2,\n        'G': 3,\n        'GB': 3,\n        'T': 4,\n        'TB': 4,\n        'P': 5,\n        'PB': 5,\n    }\n    if isinstance(value, six.string_types):\n        value = six.text_type(value)\n    else:\n        msg = \"Unable to interpret non-string value '%s' as bytes\" % (value)\n        raise ValueError(msg)\n    matches = re.match(\"([0-9]+)([a-zA-Z]+)\", value)\n    if matches:\n        size = int(matches.group(1)) * (1024 ** BYTE_POWER[matches.group(2)])\n    else:\n        # Assume that value passed in is bytes\n        try:\n            size = int(value)\n        except ValueError:\n            msg = \"Unable to interpret string value '%s' as bytes\" % (value)\n            raise ValueError(msg)\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef audit(*args):\n    def wrapper(f):\n        test_name = f.__name__\n        if _audits.get(test_name):\n            raise RuntimeError(\n                \"Test name '{}' used more than once\"\n                .format(test_name))\n        non_callables = [fn for fn in args if not callable(fn)]\n        if non_callables:\n            raise RuntimeError(\n                \"Configuration includes non-callable filters: {}\"\n                .format(non_callables))\n        _audits[test_name] = Audit(func=f, filters=args)\n        return f\n    return wrapper", "response": "Decorator to register an audit. a\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function that returns True if the audit_type is included in the specified kinds of audits.", "response": "def is_audit_type(*args):\n    \"\"\"This audit is included in the specified kinds of audits.\n\n    :param *args: List of AuditTypes to include this audit in\n    :type args: List[AuditType]\n    :rtype: Callable[Dict]\n    \"\"\"\n    def _is_audit_type(audit_options):\n        if audit_options.get('audit_type') in args:\n            return True\n        else:\n            return False\n    return _is_audit_type"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(audit_options):\n    errors = {}\n    results = {}\n    for name, audit in sorted(_audits.items()):\n        result_name = name.replace('_', '-')\n        if result_name in audit_options.get('excludes', []):\n            print(\n                \"Skipping {} because it is\"\n                \"excluded in audit config\"\n                .format(result_name))\n            continue\n        if all(p(audit_options) for p in audit.filters):\n            try:\n                audit.func(audit_options)\n                print(\"{}: PASS\".format(name))\n                results[result_name] = {\n                    'success': True,\n                }\n            except AssertionError as e:\n                print(\"{}: FAIL ({})\".format(name, e))\n                results[result_name] = {\n                    'success': False,\n                    'message': e,\n                }\n            except Exception as e:\n                print(\"{}: ERROR ({})\".format(name, e))\n                errors[name] = e\n                results[result_name] = {\n                    'success': False,\n                    'message': e,\n                }\n    for name, error in errors.items():\n        print(\"=\" * 20)\n        print(\"Error in {}: \".format(name))\n        traceback.print_tb(error.__traceback__)\n        print()\n    return results", "response": "Run the configured audits with the specified audit_options."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef action_parse_results(result):\n    passed = True\n    for test, result in result.items():\n        if result['success']:\n            hookenv.action_set({test: 'PASS'})\n        else:\n            hookenv.action_set({test: 'FAIL - {}'.format(result['message'])})\n            passed = False\n    if not passed:\n        hookenv.action_fail(\"One or more tests failed\")\n    return 0 if passed else 1", "response": "Parse the result of run in the context of an action on a unit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_selfsigned(keyfile, certfile, keysize=\"1024\", config=None, subject=None, cn=None):\n\n    cmd = []\n    if config:\n        cmd = [\"/usr/bin/openssl\", \"req\", \"-new\", \"-newkey\",\n               \"rsa:{}\".format(keysize), \"-days\", \"365\", \"-nodes\", \"-x509\",\n               \"-keyout\", keyfile,\n               \"-out\", certfile, \"-config\", config]\n    elif subject:\n        ssl_subject = \"\"\n        if \"country\" in subject:\n            ssl_subject = ssl_subject + \"/C={}\".format(subject[\"country\"])\n        if \"state\" in subject:\n            ssl_subject = ssl_subject + \"/ST={}\".format(subject[\"state\"])\n        if \"locality\" in subject:\n            ssl_subject = ssl_subject + \"/L={}\".format(subject[\"locality\"])\n        if \"organization\" in subject:\n            ssl_subject = ssl_subject + \"/O={}\".format(subject[\"organization\"])\n        if \"organizational_unit\" in subject:\n            ssl_subject = ssl_subject + \"/OU={}\".format(subject[\"organizational_unit\"])\n        if \"cn\" in subject:\n            ssl_subject = ssl_subject + \"/CN={}\".format(subject[\"cn\"])\n        else:\n            hookenv.log(\"When using \\\"subject\\\" argument you must \"\n                        \"provide \\\"cn\\\" field at very least\")\n            return False\n        if \"email\" in subject:\n            ssl_subject = ssl_subject + \"/emailAddress={}\".format(subject[\"email\"])\n\n        cmd = [\"/usr/bin/openssl\", \"req\", \"-new\", \"-newkey\",\n               \"rsa:{}\".format(keysize), \"-days\", \"365\", \"-nodes\", \"-x509\",\n               \"-keyout\", keyfile,\n               \"-out\", certfile, \"-subj\", ssl_subject]\n    elif cn:\n        cmd = [\"/usr/bin/openssl\", \"req\", \"-new\", \"-newkey\",\n               \"rsa:{}\".format(keysize), \"-days\", \"365\", \"-nodes\", \"-x509\",\n               \"-keyout\", keyfile,\n               \"-out\", certfile, \"-subj\", \"/CN={}\".format(cn)]\n\n    if not cmd:\n        hookenv.log(\"No config, subject or cn provided,\"\n                    \"unable to generate self signed SSL certificates\")\n        return False\n    try:\n        subprocess.check_call(cmd)\n        return True\n    except Exception as e:\n        print(\"Execution of openssl command failed:\\n{}\".format(e))\n        return False", "response": "Generate selfsigned SSL keypair"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ssh_directory_for_unit(application_name, user=None):\n    if user:\n        application_name = \"{}_{}\".format(application_name, user)\n    _dir = os.path.join(NOVA_SSH_DIR, application_name)\n    for d in [NOVA_SSH_DIR, _dir]:\n        if not os.path.isdir(d):\n            os.mkdir(d)\n    for f in ['authorized_keys', 'known_hosts']:\n        f = os.path.join(_dir, f)\n        if not os.path.isfile(f):\n            open(f, 'w').close()\n    return _dir", "response": "Return the full path to the ssh assets for the given application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first entry in known_hosts for host.", "response": "def ssh_known_host_key(host, application_name, user=None):\n    \"\"\"Return the first entry in known_hosts for host.\n\n    :param host: hostname to lookup in file.\n    :type host: str\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    :returns: Host key\n    :rtype: str or None\n    \"\"\"\n    cmd = [\n        'ssh-keygen',\n        '-f', known_hosts(application_name, user),\n        '-H',\n        '-F',\n        host]\n    try:\n        # The first line of output is like '# Host xx found: line 1 type RSA',\n        # which should be excluded.\n        output = subprocess.check_output(cmd)\n    except subprocess.CalledProcessError as e:\n        # RC of 1 seems to be legitimate for most ssh-keygen -F calls.\n        if e.returncode == 1:\n            output = e.output\n        else:\n            raise\n    output = output.strip()\n\n    if output:\n        # Bug #1500589 cmd has 0 rc on precise if entry not present\n        lines = output.split('\\n')\n        if len(lines) >= 1:\n            return lines[0]\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the entry in known_hosts for host.", "response": "def remove_known_host(host, application_name, user=None):\n    \"\"\"Remove the entry in known_hosts for host.\n\n    :param host: hostname to lookup in file.\n    :type host: str\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    \"\"\"\n    log('Removing SSH known host entry for compute host at %s' % host)\n    cmd = ['ssh-keygen', '-f', known_hosts(application_name, user), '-R', host]\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_same_key(key_1, key_2):\n    # The key format get will be like '|1|2rUumCavEXWVaVyB5uMl6m85pZo=|Cp'\n    # 'EL6l7VTY37T/fg/ihhNb/GPgs= ssh-rsa AAAAB', we only need to compare\n    # the part start with 'ssh-rsa' followed with '= ', because the hash\n    # value in the beginning will change each time.\n    k_1 = key_1.split('= ')[1]\n    k_2 = key_2.split('= ')[1]\n    return k_1 == k_2", "response": "Extract the key from two host entries and compare them."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_known_host(host, application_name, user=None):\n    cmd = ['ssh-keyscan', '-H', '-t', 'rsa', host]\n    try:\n        remote_key = subprocess.check_output(cmd).strip()\n    except Exception as e:\n        log('Could not obtain SSH host key from %s' % host, level=ERROR)\n        raise e\n\n    current_key = ssh_known_host_key(host, application_name, user)\n    if current_key and remote_key:\n        if is_same_key(remote_key, current_key):\n            log('Known host key for compute host %s up to date.' % host)\n            return\n        else:\n            remove_known_host(host, application_name, user)\n\n    log('Adding SSH host key to known hosts for compute node at %s.' % host)\n    with open(known_hosts(application_name, user), 'a') as out:\n        out.write(\"{}\\n\".format(remote_key))", "response": "Add the given host key to the known hosts file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if given key is in the authorized_key file.", "response": "def ssh_authorized_key_exists(public_key, application_name, user=None):\n    \"\"\"Check if given key is in the authorized_key file.\n\n    :param public_key: Public key.\n    :type public_key: str\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    :returns: Whether given key is in the authorized_key file.\n    :rtype: boolean\n    \"\"\"\n    with open(authorized_keys(application_name, user)) as keys:\n        return ('%s' % public_key) in keys.read()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_authorized_key(public_key, application_name, user=None):\n    with open(authorized_keys(application_name, user), 'a') as keys:\n        keys.write(\"{}\\n\".format(public_key))", "response": "Add given public key to the authorized_key file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ssh_compute_add_host_and_key(public_key, hostname, private_address,\n                                 application_name, user=None):\n    \"\"\"Add a compute nodes ssh details to local cache.\n\n    Collect various hostname variations and add the corresponding host keys to\n    the local known hosts file. Finally, add the supplied public key to the\n    authorized_key file.\n\n    :param public_key: Public key.\n    :type public_key: str\n    :param hostname: Hostname to collect host keys from.\n    :type hostname: str\n    :param private_address:aCorresponding private address for hostname\n    :type private_address: str\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    \"\"\"\n    # If remote compute node hands us a hostname, ensure we have a\n    # known hosts entry for its IP, hostname and FQDN.\n    hosts = [private_address]\n\n    if not is_ipv6(private_address):\n        if hostname:\n            hosts.append(hostname)\n\n        if is_ip(private_address):\n            hn = get_hostname(private_address)\n            if hn:\n                hosts.append(hn)\n                short = hn.split('.')[0]\n                if ns_query(short):\n                    hosts.append(short)\n        else:\n            hosts.append(get_host_ip(private_address))\n            short = private_address.split('.')[0]\n            if ns_query(short):\n                hosts.append(short)\n\n    for host in list(set(hosts)):\n        add_known_host(host, application_name, user)\n\n    if not ssh_authorized_key_exists(public_key, application_name, user):\n        log('Saving SSH authorized key for compute host at %s.' %\n            private_address)\n        add_authorized_key(public_key, application_name, user)", "response": "Add a compute node and SSH authorized key to the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a compute node ssh details to the local cache.", "response": "def ssh_compute_add(public_key, application_name, rid=None, unit=None,\n                    user=None):\n    \"\"\"Add a compute nodes ssh details to local cache.\n\n    Collect various hostname variations and add the corresponding host keys to\n    the local known hosts file. Finally, add the supplied public key to the\n    authorized_key file.\n\n    :param public_key: Public key.\n    :type public_key: str\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param rid: Relation id of the relation between this charm and the app. If\n                none is supplied it is assumed its the relation relating to\n                the current hook context.\n    :type rid: str\n    :param unit: Unit to add ssh asserts for if none is supplied it is assumed\n                 its the unit relating to the current hook context.\n    :type unit: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    \"\"\"\n    relation_data = relation_get(rid=rid, unit=unit)\n    ssh_compute_add_host_and_key(\n        public_key,\n        relation_data.get('hostname'),\n        relation_data.get('private-address'),\n        application_name,\n        user=user)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning contents of known_hosts file for given application.", "response": "def ssh_known_hosts_lines(application_name, user=None):\n    \"\"\"Return contents of known_hosts file for given application.\n\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    \"\"\"\n    known_hosts_list = []\n    with open(known_hosts(application_name, user)) as hosts:\n        for hosts_line in hosts:\n            if hosts_line.rstrip():\n                known_hosts_list.append(hosts_line.rstrip())\n    return(known_hosts_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ssh_authorized_keys_lines(application_name, user=None):\n    authorized_keys_list = []\n\n    with open(authorized_keys(application_name, user)) as keys:\n        for authkey_line in keys:\n            if authkey_line.rstrip():\n                authorized_keys_list.append(authkey_line.rstrip())\n    return(authorized_keys_list)", "response": "Return contents of authorized_keys file for given application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove given public key from authorized_keys file.", "response": "def ssh_compute_remove(public_key, application_name, user=None):\n    \"\"\"Remove given public key from authorized_keys file.\n\n    :param public_key: Public key.\n    :type public_key: str\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :param user: The user that the ssh asserts are for.\n    :type user: str\n    \"\"\"\n    if not (os.path.isfile(authorized_keys(application_name, user)) or\n            os.path.isfile(known_hosts(application_name, user))):\n        return\n\n    keys = ssh_authorized_keys_lines(application_name, user=None)\n    keys = [k.strip() for k in keys]\n\n    if public_key not in keys:\n        return\n\n    [keys.remove(key) for key in keys if key == public_key]\n\n    with open(authorized_keys(application_name, user), 'w') as _keys:\n        keys = '\\n'.join(keys)\n        if not keys.endswith('\\n'):\n            keys += '\\n'\n        _keys.write(keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_ssh_settings(application_name, user=None):\n    settings = {}\n    keys = {}\n    prefix = ''\n    if user:\n        prefix = '{}_'.format(user)\n\n    for i, line in enumerate(ssh_known_hosts_lines(\n            application_name=application_name, user=user)):\n        settings['{}known_hosts_{}'.format(prefix, i)] = line\n    if settings:\n        settings['{}known_hosts_max_index'.format(prefix)] = len(\n            settings.keys())\n\n    for i, line in enumerate(ssh_authorized_keys_lines(\n            application_name=application_name, user=user)):\n        keys['{}authorized_keys_{}'.format(prefix, i)] = line\n    if keys:\n        keys['{}authorized_keys_max_index'.format(prefix)] = len(keys.keys())\n    settings.update(keys)\n    return settings", "response": "Retrieve the known host entries and public keys for the given application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the known host entries and public keys for all units related to a given application.", "response": "def get_all_user_ssh_settings(application_name):\n    \"\"\"Retrieve the known host entries and public keys for application\n\n    Retrieve the known host entries and public keys for application for all\n    units of the given application related to this application for root user\n    and nova user.\n\n    :param application_name: Name of application eg nova-compute-something\n    :type application_name: str\n    :returns: Public keys + host keys for all units for app + user combination.\n    :rtype: dict\n    \"\"\"\n    settings = get_ssh_settings(application_name)\n    settings.update(get_ssh_settings(application_name, user='nova'))\n    return settings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of packages that require installation.", "response": "def filter_installed_packages(packages):\n    \"\"\"Return a list of packages that require installation.\"\"\"\n    cache = apt_cache()\n    _pkgs = []\n    for package in packages:\n        try:\n            p = cache[package]\n            p.current_ver or _pkgs.append(package)\n        except KeyError:\n            log('Package {} has no installation candidate.'.format(package),\n                level='WARNING')\n            _pkgs.append(package)\n    return _pkgs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apt_cache(in_memory=True, progress=None):\n    from apt import apt_pkg\n    apt_pkg.init()\n    if in_memory:\n        apt_pkg.config.set(\"Dir::Cache::pkgcache\", \"\")\n        apt_pkg.config.set(\"Dir::Cache::srcpkgcache\", \"\")\n    return apt_pkg.Cache(progress)", "response": "Build and return an apt cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall one or more packages.", "response": "def apt_install(packages, options=None, fatal=False):\n    \"\"\"Install one or more packages.\"\"\"\n    if options is None:\n        options = ['--option=Dpkg::Options::=--force-confold']\n\n    cmd = ['apt-get', '--assume-yes']\n    cmd.extend(options)\n    cmd.append('install')\n    if isinstance(packages, six.string_types):\n        cmd.append(packages)\n    else:\n        cmd.extend(packages)\n    log(\"Installing {} with options: {}\".format(packages,\n                                                options))\n    _run_apt_command(cmd, fatal)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npurging one or more packages.", "response": "def apt_purge(packages, fatal=False):\n    \"\"\"Purge one or more packages.\"\"\"\n    cmd = ['apt-get', '--assume-yes', 'purge']\n    if isinstance(packages, six.string_types):\n        cmd.append(packages)\n    else:\n        cmd.extend(packages)\n    log(\"Purging {}\".format(packages))\n    _run_apt_command(cmd, fatal)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npurging one or more packages.", "response": "def apt_autoremove(purge=True, fatal=False):\n    \"\"\"Purge one or more packages.\"\"\"\n    cmd = ['apt-get', '--assume-yes', 'autoremove']\n    if purge:\n        cmd.append('--purge')\n    _run_apt_command(cmd, fatal)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apt_mark(packages, mark, fatal=False):\n    log(\"Marking {} as {}\".format(packages, mark))\n    cmd = ['apt-mark', mark]\n    if isinstance(packages, six.string_types):\n        cmd.append(packages)\n    else:\n        cmd.extend(packages)\n\n    if fatal:\n        subprocess.check_call(cmd, universal_newlines=True)\n    else:\n        subprocess.call(cmd, universal_newlines=True)", "response": "Flag one or more packages using apt - mark."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef import_key(key):\n    key = key.strip()\n    if '-' in key or '\\n' in key:\n        # Send everything not obviously a keyid to GPG to import, as\n        # we trust its validation better than our own. eg. handling\n        # comments before the key.\n        log(\"PGP key found (looks like ASCII Armor format)\", level=DEBUG)\n        if ('-----BEGIN PGP PUBLIC KEY BLOCK-----' in key and\n                '-----END PGP PUBLIC KEY BLOCK-----' in key):\n            log(\"Writing provided PGP key in the binary format\", level=DEBUG)\n            if six.PY3:\n                key_bytes = key.encode('utf-8')\n            else:\n                key_bytes = key\n            key_name = _get_keyid_by_gpg_key(key_bytes)\n            key_gpg = _dearmor_gpg_key(key_bytes)\n            _write_apt_gpg_keyfile(key_name=key_name, key_material=key_gpg)\n        else:\n            raise GPGKeyError(\"ASCII armor markers missing from GPG key\")\n    else:\n        log(\"PGP key found (looks like Radix64 format)\", level=WARNING)\n        log(\"SECURELY importing PGP key from keyserver; \"\n            \"full key not provided.\", level=WARNING)\n        # as of bionic add-apt-repository uses curl with an HTTPS keyserver URL\n        # to retrieve GPG keys. `apt-key adv` command is deprecated as is\n        # apt-key in general as noted in its manpage. See lp:1433761 for more\n        # history. Instead, /etc/apt/trusted.gpg.d is used directly to drop\n        # gpg\n        key_asc = _get_key_by_keyid(key)\n        # write the key in GPG format so that apt-key list shows it\n        key_gpg = _dearmor_gpg_key(key_asc)\n        _write_apt_gpg_keyfile(key_name=key, key_material=key_gpg)", "response": "Imports a key from a keyserver."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a GPG key fingerprint by GPG key material.", "response": "def _get_keyid_by_gpg_key(key_material):\n    \"\"\"Get a GPG key fingerprint by GPG key material.\n    Gets a GPG key fingerprint (40-digit, 160-bit) by the ASCII armor-encoded\n    or binary GPG key material. Can be used, for example, to generate file\n    names for keys passed via charm options.\n\n    :param key_material: ASCII armor-encoded or binary GPG key material\n    :type key_material: bytes\n    :raises: GPGKeyError if invalid key material has been provided\n    :returns: A GPG key fingerprint\n    :rtype: str\n    \"\"\"\n    # Use the same gpg command for both Xenial and Bionic\n    cmd = 'gpg --with-colons --with-fingerprint'\n    ps = subprocess.Popen(cmd.split(),\n                          stdout=subprocess.PIPE,\n                          stderr=subprocess.PIPE,\n                          stdin=subprocess.PIPE)\n    out, err = ps.communicate(input=key_material)\n    if six.PY3:\n        out = out.decode('utf-8')\n        err = err.decode('utf-8')\n    if 'gpg: no valid OpenPGP data found.' in err:\n        raise GPGKeyError('Invalid GPG key material provided')\n    # from gnupg2 docs: fpr :: Fingerprint (fingerprint is in field 10)\n    return re.search(r\"^fpr:{9}([0-9A-F]{40}):$\", out, re.MULTILINE).group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_key_by_keyid(keyid):\n    # options=mr - machine-readable output (disables html wrappers)\n    keyserver_url = ('https://keyserver.ubuntu.com'\n                     '/pks/lookup?op=get&options=mr&exact=on&search=0x{}')\n    curl_cmd = ['curl', keyserver_url.format(keyid)]\n    # use proxy server settings in order to retrieve the key\n    return subprocess.check_output(curl_cmd,\n                                   env=env_proxy_settings(['https']))", "response": "Get a key from the key server using HTTPS."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dearmor_gpg_key(key_asc):\n    ps = subprocess.Popen(['gpg', '--dearmor'],\n                          stdout=subprocess.PIPE,\n                          stderr=subprocess.PIPE,\n                          stdin=subprocess.PIPE)\n    out, err = ps.communicate(input=key_asc)\n    # no need to decode output as it is binary (invalid utf-8), only error\n    if six.PY3:\n        err = err.decode('utf-8')\n    if 'gpg: no valid OpenPGP data found.' in err:\n        raise GPGKeyError('Invalid GPG key material. Check your network setup'\n                          ' (MTU, routing, DNS) and/or proxy server settings'\n                          ' as well as destination keyserver status.')\n    else:\n        return out", "response": "Converts a GPG key in the ASCII armor format to the binary format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _write_apt_gpg_keyfile(key_name, key_material):\n    with open('/etc/apt/trusted.gpg.d/{}.gpg'.format(key_name),\n              'wb') as keyf:\n        keyf.write(key_material)", "response": "Writes a GPG key material into a file at a provided path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a source to the system.", "response": "def add_source(source, key=None, fail_invalid=False):\n    \"\"\"Add a package source to this system.\n\n    @param source: a URL or sources.list entry, as supported by\n    add-apt-repository(1). Examples::\n\n        ppa:charmers/example\n        deb https://stub:key@private.example.com/ubuntu trusty main\n\n    In addition:\n        'proposed:' may be used to enable the standard 'proposed'\n        pocket for the release.\n        'cloud:' may be used to activate official cloud archive pockets,\n        such as 'cloud:icehouse'\n        'distro' may be used as a noop\n\n    Full list of source specifications supported by the function are:\n\n    'distro': A NOP; i.e. it has no effect.\n    'proposed': the proposed deb spec [2] is wrtten to\n      /etc/apt/sources.list/proposed\n    'distro-proposed': adds <version>-proposed to the debs [2]\n    'ppa:<ppa-name>': add-apt-repository --yes <ppa_name>\n    'deb <deb-spec>': add-apt-repository --yes deb <deb-spec>\n    'http://....': add-apt-repository --yes http://...\n    'cloud-archive:<spec>': add-apt-repository -yes cloud-archive:<spec>\n    'cloud:<release>[-staging]': specify a Cloud Archive pocket <release> with\n      optional staging version.  If staging is used then the staging PPA [2]\n      with be used.  If staging is NOT used then the cloud archive [3] will be\n      added, and the 'ubuntu-cloud-keyring' package will be added for the\n      current distro.\n\n    Otherwise the source is not recognised and this is logged to the juju log.\n    However, no error is raised, unless sys_error_on_exit is True.\n\n    [1] deb http://ubuntu-cloud.archive.canonical.com/ubuntu {} main\n        where {} is replaced with the derived pocket name.\n    [2] deb http://archive.ubuntu.com/ubuntu {}-proposed \\\n        main universe multiverse restricted\n        where {} is replaced with the lsb_release codename (e.g. xenial)\n    [3] deb http://ubuntu-cloud.archive.canonical.com/ubuntu <pocket>\n        to /etc/apt/sources.list.d/cloud-archive-list\n\n    @param key: A key to be added to the system's APT keyring and used\n    to verify the signatures on packages. Ideally, this should be an\n    ASCII format GPG public key including the block headers. A GPG key\n    id may also be used, but be aware that only insecure protocols are\n    available to retrieve the actual public key from a public keyserver\n    placing your Juju environment at risk. ppa and cloud archive keys\n    are securely added automtically, so sould not be provided.\n\n    @param fail_invalid: (boolean) if True, then the function raises a\n    SourceConfigError is there is no matching installation source.\n\n    @raises SourceConfigError() if for cloud:<pocket>, the <pocket> is not a\n    valid pocket in CLOUD_ARCHIVE_POCKETS\n    \"\"\"\n    _mapping = OrderedDict([\n        (r\"^distro$\", lambda: None),  # This is a NOP\n        (r\"^(?:proposed|distro-proposed)$\", _add_proposed),\n        (r\"^cloud-archive:(.*)$\", _add_apt_repository),\n        (r\"^((?:deb |http:|https:|ppa:).*)$\", _add_apt_repository),\n        (r\"^cloud:(.*)-(.*)\\/staging$\", _add_cloud_staging),\n        (r\"^cloud:(.*)-(.*)$\", _add_cloud_distro_check),\n        (r\"^cloud:(.*)$\", _add_cloud_pocket),\n        (r\"^snap:.*-(.*)-(.*)$\", _add_cloud_distro_check),\n    ])\n    if source is None:\n        source = ''\n    for r, fn in six.iteritems(_mapping):\n        m = re.match(r, source)\n        if m:\n            # call the assoicated function with the captured groups\n            # raises SourceConfigError on error.\n            fn(*m.groups())\n            if key:\n                try:\n                    import_key(key)\n                except GPGKeyError as e:\n                    raise SourceConfigError(str(e))\n            break\n    else:\n        # nothing matched.  log an error and maybe sys.exit\n        err = \"Unknown source: {!r}\".format(source)\n        log(err)\n        if fail_invalid:\n            raise SourceConfigError(err)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_proposed():\n    release = get_distrib_codename()\n    arch = platform.machine()\n    if arch not in six.iterkeys(ARCH_TO_PROPOSED_POCKET):\n        raise SourceConfigError(\"Arch {} not supported for (distro-)proposed\"\n                                .format(arch))\n    with open('/etc/apt/sources.list.d/proposed.list', 'w') as apt:\n        apt.write(ARCH_TO_PROPOSED_POCKET[arch].format(release))", "response": "Add the PROPOSED_POCKET as the source. list. d file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_apt_repository(spec):\n    if '{series}' in spec:\n        series = get_distrib_codename()\n        spec = spec.replace('{series}', series)\n    # software-properties package for bionic properly reacts to proxy settings\n    # passed as environment variables (See lp:1433761). This is not the case\n    # LTS and non-LTS releases below bionic.\n    _run_with_retries(['add-apt-repository', '--yes', spec],\n                      cmd_env=env_proxy_settings(['https']))", "response": "Add the given spec using add_apt_repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a cloud pocket to the list file.", "response": "def _add_cloud_pocket(pocket):\n    \"\"\"Add a cloud pocket as /etc/apt/sources.d/cloud-archive.list\n\n    Note that this overwrites the existing file if there is one.\n\n    This function also converts the simple pocket in to the actual pocket using\n    the CLOUD_ARCHIVE_POCKETS mapping.\n\n    :param pocket: string representing the pocket to add a deb spec for.\n    :raises: SourceConfigError if the cloud pocket doesn't exist or the\n        requested release doesn't match the current distro version.\n    \"\"\"\n    apt_install(filter_installed_packages(['ubuntu-cloud-keyring']),\n                fatal=True)\n    if pocket not in CLOUD_ARCHIVE_POCKETS:\n        raise SourceConfigError(\n            'Unsupported cloud: source option %s' %\n            pocket)\n    actual_pocket = CLOUD_ARCHIVE_POCKETS[pocket]\n    with open('/etc/apt/sources.list.d/cloud-archive.list', 'w') as apt:\n        apt.write(CLOUD_ARCHIVE.format(actual_pocket))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the cloud staging repository which is in ppa : ubuntu - cloud - archive/<openstack_release > - staging", "response": "def _add_cloud_staging(cloud_archive_release, openstack_release):\n    \"\"\"Add the cloud staging repository which is in\n    ppa:ubuntu-cloud-archive/<openstack_release>-staging\n\n    This function checks that the cloud_archive_release matches the current\n    codename for the distro that charm is being installed on.\n\n    :param cloud_archive_release: string, codename for the release.\n    :param openstack_release: String, codename for the openstack release.\n    :raises: SourceConfigError if the cloud_archive_release doesn't match the\n        current version of the os.\n    \"\"\"\n    _verify_is_ubuntu_rel(cloud_archive_release, openstack_release)\n    ppa = 'ppa:ubuntu-cloud-archive/{}-staging'.format(openstack_release)\n    cmd = 'add-apt-repository -y {}'.format(ppa)\n    _run_with_retries(cmd.split(' '))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_cloud_distro_check(cloud_archive_release, openstack_release):\n    _verify_is_ubuntu_rel(cloud_archive_release, openstack_release)\n    _add_cloud_pocket(\"{}-{}\".format(cloud_archive_release, openstack_release))", "response": "Add the cloud pocket but also check the cloud_archive_release against the current distro and use the openstack_release as the full lookup."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that the release is in the same as the current ubuntu release.", "response": "def _verify_is_ubuntu_rel(release, os_release):\n    \"\"\"Verify that the release is in the same as the current ubuntu release.\n\n    :param release: String, lowercase for the release.\n    :param os_release: String, the os_release being asked for\n    :raises: SourceConfigError if the release is not the same as the ubuntu\n        release.\n    \"\"\"\n    ubuntu_rel = get_distrib_codename()\n    if release != ubuntu_rel:\n        raise SourceConfigError(\n            'Invalid Cloud Archive release specified: {}-{} on this Ubuntu'\n            'version ({})'.format(release, os_release, ubuntu_rel))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a command and retry until success or max_retries is reached.", "response": "def _run_with_retries(cmd, max_retries=CMD_RETRY_COUNT, retry_exitcodes=(1,),\n                      retry_message=\"\", cmd_env=None):\n    \"\"\"Run a command and retry until success or max_retries is reached.\n\n    :param: cmd: str: The apt command to run.\n    :param: max_retries: int: The number of retries to attempt on a fatal\n        command. Defaults to CMD_RETRY_COUNT.\n    :param: retry_exitcodes: tuple: Optional additional exit codes to retry.\n        Defaults to retry on exit code 1.\n    :param: retry_message: str: Optional log prefix emitted during retries.\n    :param: cmd_env: dict: Environment variables to add to the command run.\n    \"\"\"\n\n    env = None\n    kwargs = {}\n    if cmd_env:\n        env = os.environ.copy()\n        env.update(cmd_env)\n        kwargs['env'] = env\n\n    if not retry_message:\n        retry_message = \"Failed executing '{}'\".format(\" \".join(cmd))\n    retry_message += \". Will retry in {} seconds\".format(CMD_RETRY_DELAY)\n\n    retry_count = 0\n    result = None\n\n    retry_results = (None,) + retry_exitcodes\n    while result in retry_results:\n        try:\n            # result = subprocess.check_call(cmd, env=env)\n            result = subprocess.check_call(cmd, **kwargs)\n        except subprocess.CalledProcessError as e:\n            retry_count = retry_count + 1\n            if retry_count > max_retries:\n                raise\n            result = e.returncode\n            log(retry_message)\n            time.sleep(CMD_RETRY_DELAY)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run_apt_command(cmd, fatal=False):\n    # Provide DEBIAN_FRONTEND=noninteractive if not present in the environment.\n    cmd_env = {\n        'DEBIAN_FRONTEND': os.environ.get('DEBIAN_FRONTEND', 'noninteractive')}\n\n    if fatal:\n        _run_with_retries(\n            cmd, cmd_env=cmd_env, retry_exitcodes=(1, APT_NO_LOCK,),\n            retry_message=\"Couldn't acquire DPKG lock\")\n    else:\n        env = os.environ.copy()\n        env.update(cmd_env)\n        subprocess.call(cmd, env=env)", "response": "Run an apt command with optional retries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_upstream_version(package):\n    import apt_pkg\n    cache = apt_cache()\n    try:\n        pkg = cache[package]\n    except Exception:\n        # the package is unknown to the current apt cache.\n        return None\n\n    if not pkg.current_ver:\n        # package is known, but no version is currently installed.\n        return None\n\n    return apt_pkg.upstream_version(pkg.current_ver.ver_str)", "response": "Determine upstream version based on installed package\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all cache sets", "response": "def get_bcache_fs():\n    \"\"\"Return all cache sets\n    \"\"\"\n    cachesetroot = \"{}/fs/bcache\".format(SYSFS)\n    try:\n        dirs = os.listdir(cachesetroot)\n    except OSError:\n        log(\"No bcache fs found\")\n        return []\n    cacheset = set([Bcache('{}/{}'.format(cachesetroot, d)) for d in dirs if not d.startswith('register')])\n    return cacheset"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets stats for a given cachespec and interval", "response": "def get_stats_action(cachespec, interval):\n    \"\"\"Action for getting bcache statistics for a given cachespec.\n    Cachespec can either be a device name, eg. 'sdb', which will retrieve\n    cache stats for the given device, or 'global', which will retrieve stats\n    for all cachesets\n    \"\"\"\n    if cachespec == 'global':\n        caches = get_bcache_fs()\n    else:\n        caches = [Bcache.fromdevice(cachespec)]\n    res = dict((c.cachepath, c.get_stats(interval)) for c in caches)\n    return json.dumps(res, indent=4, separators=(',', ': '))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_dns_ha_resource_params(resources, resource_params,\n                                  relation_id=None,\n                                  crm_ocf='ocf:maas:dns'):\n    \"\"\" Configure DNS-HA resources based on provided configuration and\n    update resource dictionaries for the HA relation.\n\n    @param resources: Pointer to dictionary of resources.\n                      Usually instantiated in ha_joined().\n    @param resource_params: Pointer to dictionary of resource parameters.\n                            Usually instantiated in ha_joined()\n    @param relation_id: Relation ID of the ha relation\n    @param crm_ocf: Corosync Open Cluster Framework resource agent to use for\n                    DNS HA\n    \"\"\"\n    _relation_data = {'resources': {}, 'resource_params': {}}\n    update_hacluster_dns_ha(charm_name(),\n                            _relation_data,\n                            crm_ocf)\n    resources.update(_relation_data['resources'])\n    resource_params.update(_relation_data['resource_params'])\n    relation_set(relation_id=relation_id, groups=_relation_data['groups'])", "response": "Configure DNS - HA resources based on provided configuration and update resource parameters for the HA relation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking juju goal - state if the unit expects to be in HA", "response": "def expect_ha():\n    \"\"\" Determine if the unit expects to be in HA\n\n    Check juju goal-state if ha relation is expected, check for VIP or dns-ha\n    settings which indicate the unit should expect to be related to hacluster.\n\n    @returns boolean\n    \"\"\"\n    ha_related_units = []\n    try:\n        ha_related_units = list(expected_related_units(reltype='ha'))\n    except (NotImplementedError, KeyError):\n        pass\n    return len(ha_related_units) > 0 or config('vip') or config('dns-ha')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_ha_relation_data(service, extra_settings=None):\n    _haproxy_res = 'res_{}_haproxy'.format(service)\n    _relation_data = {\n        'resources': {\n            _haproxy_res: 'lsb:haproxy',\n        },\n        'resource_params': {\n            _haproxy_res: 'op monitor interval=\"5s\"'\n        },\n        'init_services': {\n            _haproxy_res: 'haproxy'\n        },\n        'clones': {\n            'cl_{}_haproxy'.format(service): _haproxy_res\n        },\n    }\n\n    if extra_settings:\n        for k, v in extra_settings.items():\n            if _relation_data.get(k):\n                _relation_data[k].update(v)\n            else:\n                _relation_data[k] = v\n\n    if config('dns-ha'):\n        update_hacluster_dns_ha(service, _relation_data)\n    else:\n        update_hacluster_vip(service, _relation_data)\n\n    return {\n        'json_{}'.format(k): json.dumps(v, **JSON_ENCODE_OPTIONS)\n        for k, v in _relation_data.items() if v\n    }", "response": "Generates a json encoded dict of relation data for the given service."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_hacluster_dns_ha(service, relation_data,\n                            crm_ocf='ocf:maas:dns'):\n    \"\"\" Configure DNS-HA resources based on provided configuration\n\n    @param service: Name of the service being configured\n    @param relation_data: Pointer to dictionary of relation data.\n    @param crm_ocf: Corosync Open Cluster Framework resource agent to use for\n                    DNS HA\n    \"\"\"\n    # Validate the charm environment for DNS HA\n    assert_charm_supports_dns_ha()\n\n    settings = ['os-admin-hostname', 'os-internal-hostname',\n                'os-public-hostname', 'os-access-hostname']\n\n    # Check which DNS settings are set and update dictionaries\n    hostname_group = []\n    for setting in settings:\n        hostname = config(setting)\n        if hostname is None:\n            log('DNS HA: Hostname setting {} is None. Ignoring.'\n                ''.format(setting),\n                DEBUG)\n            continue\n        m = re.search('os-(.+?)-hostname', setting)\n        if m:\n            endpoint_type = m.group(1)\n            # resolve_address's ADDRESS_MAP uses 'int' not 'internal'\n            if endpoint_type == 'internal':\n                endpoint_type = 'int'\n        else:\n            msg = ('Unexpected DNS hostname setting: {}. '\n                   'Cannot determine endpoint_type name'\n                   ''.format(setting))\n            status_set('blocked', msg)\n            raise DNSHAException(msg)\n\n        hostname_key = 'res_{}_{}_hostname'.format(service, endpoint_type)\n        if hostname_key in hostname_group:\n            log('DNS HA: Resource {}: {} already exists in '\n                'hostname group - skipping'.format(hostname_key, hostname),\n                DEBUG)\n            continue\n\n        hostname_group.append(hostname_key)\n        relation_data['resources'][hostname_key] = crm_ocf\n        relation_data['resource_params'][hostname_key] = (\n            'params fqdn=\"{}\" ip_address=\"{}\"'\n            .format(hostname, resolve_address(endpoint_type=endpoint_type,\n                                              override=False)))\n\n    if len(hostname_group) >= 1:\n        log('DNS HA: Hostname group is set with {} as members. '\n            'Informing the ha relation'.format(' '.join(hostname_group)),\n            DEBUG)\n        relation_data['groups'] = {\n            DNSHA_GROUP_NAME.format(service=service): ' '.join(hostname_group)\n        }\n    else:\n        msg = 'DNS HA: Hostname group has no members.'\n        status_set('blocked', msg)\n        raise DNSHAException(msg)", "response": "Update the DNS - HA resources based on the configuration of the service and the relation data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_vip_settings(vip):\n    iface = get_iface_for_address(vip)\n    netmask = get_netmask_for_address(vip)\n    fallback = False\n    if iface is None:\n        iface = config('vip_iface')\n        fallback = True\n    if netmask is None:\n        netmask = config('vip_cidr')\n        fallback = True\n    return iface, netmask, fallback", "response": "Calculate which nic is on the correct network for the given vip."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_hacluster_vip(service, relation_data):\n    cluster_config = get_hacluster_config()\n    vip_group = []\n    vips_to_delete = []\n    for vip in cluster_config['vip'].split():\n        if is_ipv6(vip):\n            res_vip = 'ocf:heartbeat:IPv6addr'\n            vip_params = 'ipv6addr'\n        else:\n            res_vip = 'ocf:heartbeat:IPaddr2'\n            vip_params = 'ip'\n\n        iface, netmask, fallback = get_vip_settings(vip)\n\n        vip_monitoring = 'op monitor depth=\"0\" timeout=\"20s\" interval=\"10s\"'\n        if iface is not None:\n            # NOTE(jamespage): Delete old VIP resources\n            # Old style naming encoding iface in name\n            # does not work well in environments where\n            # interface/subnet wiring is not consistent\n            vip_key = 'res_{}_{}_vip'.format(service, iface)\n            if vip_key in vips_to_delete:\n                vip_key = '{}_{}'.format(vip_key, vip_params)\n            vips_to_delete.append(vip_key)\n\n            vip_key = 'res_{}_{}_vip'.format(\n                service,\n                hashlib.sha1(vip.encode('UTF-8')).hexdigest()[:7])\n\n            relation_data['resources'][vip_key] = res_vip\n            # NOTE(jamespage):\n            # Use option provided vip params if these where used\n            # instead of auto-detected values\n            if fallback:\n                relation_data['resource_params'][vip_key] = (\n                    'params {ip}=\"{vip}\" cidr_netmask=\"{netmask}\" '\n                    'nic=\"{iface}\" {vip_monitoring}'.format(\n                        ip=vip_params,\n                        vip=vip,\n                        iface=iface,\n                        netmask=netmask,\n                        vip_monitoring=vip_monitoring))\n            else:\n                # NOTE(jamespage):\n                # let heartbeat figure out which interface and\n                # netmask to configure, which works nicely\n                # when network interface naming is not\n                # consistent across units.\n                relation_data['resource_params'][vip_key] = (\n                    'params {ip}=\"{vip}\" {vip_monitoring}'.format(\n                        ip=vip_params,\n                        vip=vip,\n                        vip_monitoring=vip_monitoring))\n\n            vip_group.append(vip_key)\n\n    if vips_to_delete:\n        try:\n            relation_data['delete_resources'].extend(vips_to_delete)\n        except KeyError:\n            relation_data['delete_resources'] = vips_to_delete\n\n    if len(vip_group) >= 1:\n        key = VIP_GROUP_NAME.format(service=service)\n        try:\n            relation_data['groups'][key] = ' '.join(vip_group)\n        except KeyError:\n            relation_data['groups'] = {\n                key: ' '.join(vip_group)\n            }", "response": "Update the VIP resources based on the configuration of the service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_services(self, this_service, other_services):\n        if this_service['name'] != os.path.basename(os.getcwd()):\n            s = this_service['name']\n            msg = \"The charm's root directory name needs to be {}\".format(s)\n            amulet.raise_status(amulet.FAIL, msg=msg)\n\n        if 'units' not in this_service:\n            this_service['units'] = 1\n\n        self.d.add(this_service['name'], units=this_service['units'],\n                   constraints=this_service.get('constraints'),\n                   storage=this_service.get('storage'))\n\n        for svc in other_services:\n            if 'location' in svc:\n                branch_location = svc['location']\n            elif self.series:\n                branch_location = 'cs:{}/{}'.format(self.series, svc['name']),\n            else:\n                branch_location = None\n\n            if 'units' not in svc:\n                svc['units'] = 1\n\n            self.d.add(svc['name'], charm=branch_location, units=svc['units'],\n                       constraints=svc.get('constraints'),\n                       storage=svc.get('storage'))", "response": "Add services to the deployment where this_service is the local charm that we re testing and other_services are the local amulet tests."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd all of the relations for the services.", "response": "def _add_relations(self, relations):\n        \"\"\"Add all of the relations for the services.\"\"\"\n        for k, v in six.iteritems(relations):\n            self.d.relate(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _configure_services(self, configs):\n        for service, config in six.iteritems(configs):\n            self.d.configure(service, config)", "response": "Configure all of the services."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeploys environment and wait for all hooks to finish executing.", "response": "def _deploy(self):\n        \"\"\"Deploy environment and wait for all hooks to finish executing.\"\"\"\n        timeout = int(os.environ.get('AMULET_SETUP_TIMEOUT', 900))\n        try:\n            self.d.setup(timeout=timeout)\n            self.d.sentry.wait(timeout=timeout)\n        except amulet.helpers.TimeoutError:\n            amulet.raise_status(\n                amulet.FAIL,\n                msg=\"Deployment timed out ({}s)\".format(timeout)\n            )\n        except Exception:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_ca(self):\n        if not exists(path_join(self.ca_dir, 'ca.cnf')):\n            with open(path_join(self.ca_dir, 'ca.cnf'), 'w') as fh:\n                fh.write(\n                    CA_CONF_TEMPLATE % (self.get_conf_variables()))\n\n        if not exists(path_join(self.ca_dir, 'signing.cnf')):\n            with open(path_join(self.ca_dir, 'signing.cnf'), 'w') as fh:\n                fh.write(\n                    SIGNING_CONF_TEMPLATE % (self.get_conf_variables()))\n\n        if exists(self.ca_cert) or exists(self.ca_key):\n            raise RuntimeError(\"Initialized called when CA already exists\")\n        cmd = ['openssl', 'req', '-config', self.ca_conf,\n               '-x509', '-nodes', '-newkey', 'rsa',\n               '-days', self.default_ca_expiry,\n               '-keyout', self.ca_key, '-out', self.ca_cert,\n               '-outform', 'PEM']\n        output = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n        log(\"CA Init:\\n %s\" % output, level=DEBUG)", "response": "Generate the root CA cert and key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_endpoint(schema, addr, port, api_version):\n    return '{}://{}:{}/{}/'.format(schema, addr, port,\n                                   get_api_suffix(api_version))", "response": "Return a fully formatted keystone endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_keystone_manager(endpoint, api_version, **kwargs):\n    if api_version == 2:\n        return KeystoneManager2(endpoint, **kwargs)\n    if api_version == 3:\n        return KeystoneManager3(endpoint, **kwargs)\n    raise ValueError('No manager found for api version {}'.format(api_version))", "response": "Return a keystonemanager for the correct API version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_keystone_manager_from_identity_service_context():\n    context = IdentityServiceContext()()\n    if not context:\n        msg = \"Identity service context cannot be generated\"\n        log(msg, level=ERROR)\n        raise ValueError(msg)\n\n    endpoint = format_endpoint(context['service_protocol'],\n                               context['service_host'],\n                               context['service_port'],\n                               context['api_version'])\n\n    if context['api_version'] in (2, \"2.0\"):\n        api_version = 2\n    else:\n        api_version = 3\n\n    return get_keystone_manager(endpoint, api_version,\n                                username=context['admin_user'],\n                                password=context['admin_password'],\n                                tenant_name=context['admin_tenant_name'])", "response": "Return a keystonamenager instance generated from a\n    instance of charmhelpers. contrib. openstack. context. IdentityServiceContext\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve_service_id(self, service_name=None, service_type=None):\n        services = [s._info for s in self.api.services.list()]\n\n        service_name = service_name.lower()\n        for s in services:\n            name = s['name'].lower()\n            if service_type and service_name:\n                if (service_name == name and service_type == s['type']):\n                    return s['id']\n            elif service_name and service_name == name:\n                return s['id']\n            elif service_type and service_type == s['type']:\n                return s['id']\n        return None", "response": "Find the service_id of a given service"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deactivate_lvm_volume_group(block_device):\n    '''\n    Deactivate any volume gruop associated with an LVM physical volume.\n\n    :param block_device: str: Full path to LVM physical volume\n    '''\n    vg = list_lvm_volume_group(block_device)\n    if vg:\n        cmd = ['vgchange', '-an', vg]\n        check_call(cmd)", "response": "Deactivate any volume gruop associated with an LVM physical volume."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_lvm_physical_volume(block_device):\n    '''\n    Remove LVM PV signatures from a given block device.\n\n    :param block_device: str: Full path of block device to scrub.\n    '''\n    p = Popen(['pvremove', '-ff', block_device],\n              stdin=PIPE)\n    p.communicate(input='y\\n')", "response": "Remove LVM PV signatures from a given block device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_lvm_volume_group(block_device):\n    '''\n    List LVM volume group associated with a given block device.\n\n    Assumes block device is a valid LVM PV.\n\n    :param block_device: str: Full path of block device to inspect.\n\n    :returns: str: Name of volume group associated with block device or None\n    '''\n    vg = None\n    pvd = check_output(['pvdisplay', block_device]).splitlines()\n    for lvm in pvd:\n        lvm = lvm.decode('UTF-8')\n        if lvm.strip().startswith('VG Name'):\n            vg = ' '.join(lvm.strip().split()[2:])\n    return vg", "response": "List LVM volume group associated with a given block device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_logical_volumes(select_criteria=None, path_mode=False):\n    '''\n    List logical volumes\n\n    :param select_criteria: str: Limit list to those volumes matching this\n                                 criteria (see 'lvs -S help' for more details)\n    :param path_mode: bool: return logical volume name in 'vg/lv' format, this\n                            format is required for some commands like lvextend\n    :returns: [str]: List of logical volumes\n    '''\n    lv_diplay_attr = 'lv_name'\n    if path_mode:\n        # Parsing output logic relies on the column order\n        lv_diplay_attr = 'vg_name,' + lv_diplay_attr\n    cmd = ['lvs', '--options', lv_diplay_attr, '--noheadings']\n    if select_criteria:\n        cmd.extend(['--select', select_criteria])\n    lvs = []\n    for lv in check_output(cmd).decode('UTF-8').splitlines():\n        if not lv:\n            continue\n        if path_mode:\n            lvs.append('/'.join(lv.strip().split()))\n        else:\n            lvs.append(lv.strip())\n    return lvs", "response": "List all logical volumes in this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new logical volume in an existing volume group.", "response": "def create_logical_volume(lv_name, volume_group, size=None):\n    '''\n    Create a new logical volume in an existing volume group\n\n    :param lv_name: str: name of logical volume to be created.\n    :param volume_group: str: Name of volume group to use for the new volume.\n    :param size: str: Size of logical volume to create (100% if not supplied)\n    :raises subprocess.CalledProcessError: in the event that the lvcreate fails.\n    '''\n    if size:\n        check_call([\n            'lvcreate',\n            '--yes',\n            '-L',\n            '{}'.format(size),\n            '-n', lv_name, volume_group\n        ])\n    # create the lv with all the space available, this is needed because the\n    # system call is different for LVM\n    else:\n        check_call([\n            'lvcreate',\n            '--yes',\n            '-l',\n            '100%FREE',\n            '-n', lv_name, volume_group\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(source, target, context, owner='root', group='root',\n           perms=0o444, templates_dir=None, encoding='UTF-8',\n           template_loader=None, config_template=None):\n    \"\"\"\n    Render a template.\n\n    The `source` path, if not absolute, is relative to the `templates_dir`.\n\n    The `target` path should be absolute.  It can also be `None`, in which\n    case no file will be written.\n\n    The context should be a dict containing the values to be replaced in the\n    template.\n\n    config_template may be provided to render from a provided template instead\n    of loading from a file.\n\n    The `owner`, `group`, and `perms` options will be passed to `write_file`.\n\n    If omitted, `templates_dir` defaults to the `templates` folder in the charm.\n\n    The rendered template will be written to the file as well as being returned\n    as a string.\n\n    Note: Using this requires python-jinja2 or python3-jinja2; if it is not\n    installed, calling this will attempt to use charmhelpers.fetch.apt_install\n    to install it.\n    \"\"\"\n    try:\n        from jinja2 import FileSystemLoader, Environment, exceptions\n    except ImportError:\n        try:\n            from charmhelpers.fetch import apt_install\n        except ImportError:\n            hookenv.log('Could not import jinja2, and could not import '\n                        'charmhelpers.fetch to install it',\n                        level=hookenv.ERROR)\n            raise\n        if sys.version_info.major == 2:\n            apt_install('python-jinja2', fatal=True)\n        else:\n            apt_install('python3-jinja2', fatal=True)\n        from jinja2 import FileSystemLoader, Environment, exceptions\n\n    if template_loader:\n        template_env = Environment(loader=template_loader)\n    else:\n        if templates_dir is None:\n            templates_dir = os.path.join(hookenv.charm_dir(), 'templates')\n        template_env = Environment(loader=FileSystemLoader(templates_dir))\n\n    # load from a string if provided explicitly\n    if config_template is not None:\n        template = template_env.from_string(config_template)\n    else:\n        try:\n            source = source\n            template = template_env.get_template(source)\n        except exceptions.TemplateNotFound as e:\n            hookenv.log('Could not load template %s from %s.' %\n                        (source, templates_dir),\n                        level=hookenv.ERROR)\n            raise e\n    content = template.render(context)\n    if target is not None:\n        target_dir = os.path.dirname(target)\n        if not os.path.exists(target_dir):\n            # This is a terrible default directory permission, as the file\n            # or its siblings will often contain secrets.\n            host.mkdir(os.path.dirname(target), owner, group, perms=0o755)\n        host.write_file(target, content.encode(encoding), owner, group, perms)\n    return content", "response": "Render a template from source to target."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cached(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        global cache\n        key = json.dumps((func, args, kwargs), sort_keys=True, default=str)\n        try:\n            return cache[key]\n        except KeyError:\n            pass  # Drop out of the exception handler scope.\n        res = func(*args, **kwargs)\n        cache[key] = res\n        return res\n    wrapper._wrapped = func\n    return wrapper", "response": "A decorator that caches the result of a function + args\n\nAttributeNames."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flush(key):\n    flush_list = []\n    for item in cache:\n        if key in item:\n            flush_list.append(item)\n    for item in flush_list:\n        del cache[item]", "response": "Flushes any entries from function cache where the key is found in the function + args"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log(message, level=None):\n    command = ['juju-log']\n    if level:\n        command += ['-l', level]\n    if not isinstance(message, six.string_types):\n        message = repr(message)\n    command += [message[:SH_MAX_ARG]]\n    # Missing juju-log should not cause failures in unit tests\n    # Send log output to stderr\n    try:\n        subprocess.call(command)\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            if level:\n                message = \"{}: {}\".format(level, message)\n            message = \"juju-log: {}\".format(message)\n            print(message, file=sys.stderr)\n        else:\n            raise", "response": "Write a message to the juju log"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execution_environment():\n    context = {}\n    context['conf'] = config()\n    if relation_id():\n        context['reltype'] = relation_type()\n        context['relid'] = relation_id()\n        context['rel'] = relation_get()\n    context['unit'] = local_unit()\n    context['rels'] = relations()\n    context['env'] = os.environ\n    return context", "response": "A convenient bundling of the current execution environment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the relation ID for the current or a specified relation", "response": "def relation_id(relation_name=None, service_or_unit=None):\n    \"\"\"The relation ID for the current or a specified relation\"\"\"\n    if not relation_name and not service_or_unit:\n        return os.environ.get('JUJU_RELATION_ID', None)\n    elif relation_name and service_or_unit:\n        service_name = service_or_unit.split('/')[0]\n        for relid in relation_ids(relation_name):\n            remote_service = remote_service_name(relid)\n            if remote_service == service_name:\n                return relid\n    else:\n        raise ValueError('Must specify neither or both of relation_name and service_or_unit')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef principal_unit():\n    # Juju 2.2 and above provides JUJU_PRINCIPAL_UNIT\n    principal_unit = os.environ.get('JUJU_PRINCIPAL_UNIT', None)\n    # If it's empty, then this unit is the principal\n    if principal_unit == '':\n        return os.environ['JUJU_UNIT_NAME']\n    elif principal_unit is not None:\n        return principal_unit\n    # For Juju 2.1 and below, let's try work out the principle unit by\n    # the various charms' metadata.yaml.\n    for reltype in relation_types():\n        for rid in relation_ids(reltype):\n            for unit in related_units(rid):\n                md = _metadata_unit(unit)\n                if not md:\n                    continue\n                subordinate = md.pop('subordinate', None)\n                if not subordinate:\n                    return unit\n    return None", "response": "Returns the principal unit of this unit if it exists otherwise None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the remote service name for a given relation - id or the current relation.", "response": "def remote_service_name(relid=None):\n    \"\"\"The remote service name for a given relation-id (or the current relation)\"\"\"\n    if relid is None:\n        unit = remote_unit()\n    else:\n        units = related_units(relid)\n        unit = units[0] if units else None\n    return unit.split('/')[0] if unit else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the juju charm configuration or individual key from the juju charm configuration.", "response": "def config(scope=None):\n    \"\"\"\n    Get the juju charm configuration (scope==None) or individual key,\n    (scope=str).  The returned value is a Python data structure loaded as\n    JSON from the Juju config command.\n\n    :param scope: If set, return the value for the specified key.\n    :type scope: Optional[str]\n    :returns: Either the whole config as a Config, or a key from it.\n    :rtype: Any\n    \"\"\"\n    global _cache_config\n    config_cmd_line = ['config-get', '--all', '--format=json']\n    try:\n        # JSON Decode Exception for Python3.5+\n        exc_json = json.decoder.JSONDecodeError\n    except AttributeError:\n        # JSON Decode Exception for Python2.7 through Python3.4\n        exc_json = ValueError\n    try:\n        if _cache_config is None:\n            config_data = json.loads(\n                subprocess.check_output(config_cmd_line).decode('UTF-8'))\n            _cache_config = Config(config_data)\n        if scope is not None:\n            return _cache_config.get(scope)\n        return _cache_config\n    except (exc_json, UnicodeDecodeError) as e:\n        log('Unable to parse output from config-get: config_cmd_line=\"{}\" '\n            'message=\"{}\"'\n            .format(config_cmd_line, str(e)), level=ERROR)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relation_set(relation_id=None, relation_settings=None, **kwargs):\n    relation_settings = relation_settings if relation_settings else {}\n    relation_cmd_line = ['relation-set']\n    accepts_file = \"--file\" in subprocess.check_output(\n        relation_cmd_line + [\"--help\"], universal_newlines=True)\n    if relation_id is not None:\n        relation_cmd_line.extend(('-r', relation_id))\n    settings = relation_settings.copy()\n    settings.update(kwargs)\n    for key, value in settings.items():\n        # Force value to be a string: it always should, but some call\n        # sites pass in things like dicts or numbers.\n        if value is not None:\n            settings[key] = \"{}\".format(value)\n    if accepts_file:\n        # --file was introduced in Juju 1.23.2. Use it by default if\n        # available, since otherwise we'll break if the relation data is\n        # too big. Ideally we should tell relation-set to read the data from\n        # stdin, but that feature is broken in 1.23.2: Bug #1454678.\n        with tempfile.NamedTemporaryFile(delete=False) as settings_file:\n            settings_file.write(yaml.safe_dump(settings).encode(\"utf-8\"))\n        subprocess.check_call(\n            relation_cmd_line + [\"--file\", settings_file.name])\n        os.remove(settings_file.name)\n    else:\n        for key, value in settings.items():\n            if value is None:\n                relation_cmd_line.append('{}='.format(key))\n            else:\n                relation_cmd_line.append('{}={}'.format(key, value))\n        subprocess.check_call(relation_cmd_line)\n    # Flush cache of any relation-gets for local unit\n    flush(local_unit())", "response": "Set relation information for the current unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef relation_clear(r_id=None):\n    ''' Clears any relation data already set on relation r_id '''\n    settings = relation_get(rid=r_id,\n                            unit=local_unit())\n    for setting in settings:\n        if setting not in ['public-address', 'private-address']:\n            settings[setting] = None\n    relation_set(relation_id=r_id,\n                 **settings)", "response": "Clears any relation data already set on relation r_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef related_units(relid=None):\n    relid = relid or relation_id()\n    units_cmd_line = ['relation-list', '--format=json']\n    if relid is not None:\n        units_cmd_line.extend(('-r', relid))\n    return json.loads(\n        subprocess.check_output(units_cmd_line).decode('UTF-8')) or []", "response": "A list of related units"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator that returns the expected peer units for the current state of the current state.", "response": "def expected_peer_units():\n    \"\"\"Get a generator for units we expect to join peer relation based on\n    goal-state.\n\n    The local unit is excluded from the result to make it easy to gauge\n    completion of all peers joining the relation with existing hook tools.\n\n    Example usage:\n    log('peer {} of {} joined peer relation'\n        .format(len(related_units()),\n                len(list(expected_peer_units()))))\n\n    This function will raise NotImplementedError if used with juju versions\n    without goal-state support.\n\n    :returns: iterator\n    :rtype: types.GeneratorType\n    :raises: NotImplementedError\n    \"\"\"\n    if not has_juju_version(\"2.4.0\"):\n        # goal-state first appeared in 2.4.0.\n        raise NotImplementedError(\"goal-state\")\n    _goal_state = goal_state()\n    return (key for key in _goal_state['units']\n            if '/' in key and key != local_unit())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an iterator for units that are expected to join the given relation type.", "response": "def expected_related_units(reltype=None):\n    \"\"\"Get a generator for units we expect to join relation based on\n    goal-state.\n\n    Note that you can not use this function for the peer relation, take a look\n    at expected_peer_units() for that.\n\n    This function will raise KeyError if you request information for a\n    relation type for which juju goal-state does not have information.  It will\n    raise NotImplementedError if used with juju versions without goal-state\n    support.\n\n    Example usage:\n    log('participant {} of {} joined relation {}'\n        .format(len(related_units()),\n                len(list(expected_related_units())),\n                relation_type()))\n\n    :param reltype: Relation type to list data for, default is to list data for\n                    the realtion type we are currently executing a hook for.\n    :type reltype: str\n    :returns: iterator\n    :rtype: types.GeneratorType\n    :raises: KeyError, NotImplementedError\n    \"\"\"\n    if not has_juju_version(\"2.4.4\"):\n        # goal-state existed in 2.4.0, but did not list individual units to\n        # join a relation in 2.4.1 through 2.4.3. (LP: #1794739)\n        raise NotImplementedError(\"goal-state relation unit count\")\n    reltype = reltype or relation_type()\n    _goal_state = goal_state()\n    return (key for key in _goal_state['relations'][reltype] if '/' in key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the json represenation of a unit s relation", "response": "def relation_for_unit(unit=None, rid=None):\n    \"\"\"Get the json represenation of a unit's relation\"\"\"\n    unit = unit or remote_unit()\n    relation = relation_get(unit=unit, rid=rid)\n    for key in relation:\n        if key.endswith('-list'):\n            relation[key] = relation[key].split()\n    relation['__unit__'] = unit\n    return relation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting relations of a specific relation ID", "response": "def relations_for_id(relid=None):\n    \"\"\"Get relations of a specific relation ID\"\"\"\n    relation_data = []\n    relid = relid or relation_ids()\n    for unit in related_units(relid):\n        unit_data = relation_for_unit(unit, relid)\n        unit_data['__relid__'] = relid\n        relation_data.append(unit_data)\n    return relation_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef relations_of_type(reltype=None):\n    relation_data = []\n    reltype = reltype or relation_type()\n    for relid in relation_ids(reltype):\n        for relation in relations_for_id(relid):\n            relation['__relid__'] = relid\n            relation_data.append(relation)\n    return relation_data", "response": "Get relations of a specific type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the current charm metadata. yaml contents as a python object", "response": "def metadata():\n    \"\"\"Get the current charm metadata.yaml contents as a python object\"\"\"\n    with open(os.path.join(charm_dir(), 'metadata.yaml')) as md:\n        return yaml.safe_load(md)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _metadata_unit(unit):\n    basedir = os.sep.join(charm_dir().split(os.sep)[:-2])\n    unitdir = 'unit-{}'.format(unit.replace(os.sep, '-'))\n    joineddir = os.path.join(basedir, unitdir, 'charm', 'metadata.yaml')\n    if not os.path.exists(joineddir):\n        return None\n    with open(joineddir) as md:\n        return yaml.safe_load(md)", "response": "Get the charm s\n    metadata. yaml as a python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of relation types supported by this charm", "response": "def relation_types():\n    \"\"\"Get a list of relation types supported by this charm\"\"\"\n    rel_types = []\n    md = metadata()\n    for key in ('provides', 'requires', 'peers'):\n        section = md.get(key)\n        if section:\n            rel_types.extend(section.keys())\n    return rel_types"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef peer_relation_id():\n    '''Get the peers relation id if a peers relation has been joined, else None.'''\n    md = metadata()\n    section = md.get('peers')\n    if section:\n        for key in section:\n            relids = relation_ids(key)\n            if relids:\n                return relids[0]\n    return None", "response": "Get the peers relation id if a peers relation has been joined else None."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relation_to_role_and_interface(relation_name):\n    _metadata = metadata()\n    for role in ('provides', 'requires', 'peers'):\n        interface = _metadata.get(role, {}).get(relation_name, {}).get('interface')\n        if interface:\n            return role, interface\n    return None, None", "response": "Given a relation name return the role and interface that relation uses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef role_and_interface_to_relations(role, interface_name):\n    _metadata = metadata()\n    results = []\n    for relation_name, relation in _metadata.get(role, {}).items():\n        if relation['interface'] == interface_name:\n            results.append(relation_name)\n    return results", "response": "Given a role and interface name return a list of relation names for the current charm that use that role."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interface_to_relations(interface_name):\n    results = []\n    for role in ('provides', 'requires', 'peers'):\n        results.extend(role_and_interface_to_relations(role, interface_name))\n    return results", "response": "Given an interface return a list of relation names for the current\n    charm that use that interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relations():\n    rels = {}\n    for reltype in relation_types():\n        relids = {}\n        for relid in relation_ids(reltype):\n            units = {local_unit(): relation_get(unit=local_unit(), rid=relid)}\n            for unit in related_units(relid):\n                reldata = relation_get(unit=unit, rid=relid)\n                units[unit] = reldata\n            relids[relid] = units\n        rels[reltype] = relids\n    return rels", "response": "Get a nested dictionary of relation data for all related units"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine whether a relation is established by checking for the presence of the given keys.", "response": "def is_relation_made(relation, keys='private-address'):\n    '''\n    Determine whether a relation is established by checking for\n    presence of key(s).  If a list of keys is provided, they\n    must all be present for the relation to be identified as made\n    '''\n    if isinstance(keys, str):\n        keys = [keys]\n    for r_id in relation_ids(relation):\n        for unit in related_units(r_id):\n            context = {}\n            for k in keys:\n                context[k] = relation_get(k, rid=r_id,\n                                          unit=unit)\n            if None not in context.values():\n                return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _port_op(op_name, port, protocol=\"TCP\"):\n    _args = [op_name]\n    icmp = protocol.upper() == \"ICMP\"\n    if icmp:\n        _args.append(protocol)\n    else:\n        _args.append('{}/{}'.format(port, protocol))\n    try:\n        subprocess.check_call(_args)\n    except subprocess.CalledProcessError:\n        # Older Juju pre 2.3 doesn't support ICMP\n        # so treat it as a no-op if it fails.\n        if not icmp:\n            raise", "response": "Open or close a service network port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_ports(start, end, protocol=\"TCP\"):\n    _args = ['open-port']\n    _args.append('{}-{}/{}'.format(start, end, protocol))\n    subprocess.check_call(_args)", "response": "Opens a range of service network ports."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unit_get(attribute):\n    _args = ['unit-get', '--format=json', attribute]\n    try:\n        return json.loads(subprocess.check_output(_args).decode('UTF-8'))\n    except ValueError:\n        return None", "response": "Get the unit ID for the remote unit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist the storage IDs for the unit", "response": "def storage_list(storage_name=None):\n    \"\"\"List the storage IDs for the unit\"\"\"\n    _args = ['storage-list', '--format=json']\n    if storage_name:\n        _args.append(storage_name)\n    try:\n        return json.loads(subprocess.check_output(_args).decode('UTF-8'))\n    except ValueError:\n        return None\n    except OSError as e:\n        import errno\n        if e.errno == errno.ENOENT:\n            # storage-list does not exist\n            return []\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef charm_dir():\n    d = os.environ.get('JUJU_CHARM_DIR')\n    if d is not None:\n        return d\n    return os.environ.get('CHARM_DIR')", "response": "Return the root directory of the current charm"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value of an action parameter or all key value param pairs", "response": "def action_get(key=None):\n    \"\"\"Gets the value of an action parameter, or all key/value param pairs\"\"\"\n    cmd = ['action-get']\n    if key is not None:\n        cmd.append(key)\n    cmd.append('--format=json')\n    action_data = json.loads(subprocess.check_output(cmd).decode('UTF-8'))\n    return action_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the values to be returned after the action finishes", "response": "def action_set(values):\n    \"\"\"Sets the values to be returned after the action finishes\"\"\"\n    cmd = ['action-set']\n    for k, v in list(values.items()):\n        cmd.append('{}={}'.format(k, v))\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the state of a message which is visible by the user via status - set.", "response": "def status_set(workload_state, message):\n    \"\"\"Set the workload state with a message\n\n    Use status-set to set the workload state with a message which is visible\n    to the user via juju status. If the status-set command is not found then\n    assume this is juju < 1.23 and juju-log the message unstead.\n\n    workload_state -- valid juju workload state.\n    message        -- status update message\n    \"\"\"\n    valid_states = ['maintenance', 'blocked', 'waiting', 'active']\n    if workload_state not in valid_states:\n        raise ValueError(\n            '{!r} is not a valid workload state'.format(workload_state)\n        )\n    cmd = ['status-set', workload_state, message]\n    try:\n        ret = subprocess.call(cmd)\n        if ret == 0:\n            return\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise\n    log_message = 'status-set failed: {} {}'.format(workload_state,\n                                                    message)\n    log(log_message, level='INFO')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the previously set juju workload state and message of a dedicated resource.", "response": "def status_get():\n    \"\"\"Retrieve the previously set juju workload state and message\n\n    If the status-get command is not found then assume this is juju < 1.23 and\n    return 'unknown', \"\"\n\n    \"\"\"\n    cmd = ['status-get', \"--format=json\", \"--include-data\"]\n    try:\n        raw_status = subprocess.check_output(cmd)\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            return ('unknown', \"\")\n        else:\n            raise\n    else:\n        status = json.loads(raw_status.decode(\"UTF-8\"))\n        return (status[\"status\"], status[\"message\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef application_version_set(version):\n\n    cmd = ['application-version-set']\n    cmd.append(version)\n    try:\n        subprocess.check_call(cmd)\n    except OSError:\n        log(\"Application Version: {}\".format(version))", "response": "Set the version of the application."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef leader_get(attribute=None):\n    cmd = ['leader-get', '--format=json'] + [attribute or '-']\n    return json.loads(subprocess.check_output(cmd).decode('UTF-8'))", "response": "Juju leader get value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef leader_set(settings=None, **kwargs):\n    # Don't log secrets.\n    # log(\"Juju leader-set '%s'\" % (settings), level=DEBUG)\n    cmd = ['leader-set']\n    settings = settings or {}\n    settings.update(kwargs)\n    for k, v in settings.items():\n        if v is None:\n            cmd.append('{}='.format(k))\n        else:\n            cmd.append('{}={}'.format(k, v))\n    subprocess.check_call(cmd)", "response": "Get the value of the NX - OS leader - set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a new resource in the base base.", "response": "def payload_register(ptype, klass, pid):\n    \"\"\" is used while a hook is running to let Juju know that a\n        payload has been started.\"\"\"\n    cmd = ['payload-register']\n    for x in [ptype, klass, pid]:\n        cmd.append(x)\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef payload_unregister(klass, pid):\n    cmd = ['payload-unregister']\n    for x in [klass, pid]:\n        cmd.append(x)\n    subprocess.check_call(cmd)", "response": "Unregisters a payload from the base base."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef payload_status_set(klass, pid, status):\n    cmd = ['payload-status-set']\n    for x in [klass, pid, status]:\n        cmd.append(x)\n    subprocess.check_call(cmd)", "response": "is used to update the current status of a registered payload."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resource_get(name):\n    if not name:\n        return False\n\n    cmd = ['resource-get', name]\n    try:\n        return subprocess.check_output(cmd).decode('UTF-8')\n    except subprocess.CalledProcessError:\n        return False", "response": "used to fetch the path of the given name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef juju_version():\n    # Per https://bugs.launchpad.net/juju-core/+bug/1455368/comments/1\n    jujud = glob.glob('/var/lib/juju/tools/machine-*/jujud')[0]\n    return subprocess.check_output([jujud, 'version'],\n                                   universal_newlines=True).strip()", "response": "Return the full version string of the juju."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nschedules a callback to run before the main hook.", "response": "def atstart(callback, *args, **kwargs):\n    '''Schedule a callback to run before the main hook.\n\n    Callbacks are run in the order they were added.\n\n    This is useful for modules and classes to perform initialization\n    and inject behavior. In particular:\n\n        - Run common code before all of your hooks, such as logging\n          the hook name or interesting relation data.\n        - Defer object or module initialization that requires a hook\n          context until we know there actually is a hook context,\n          making testing easier.\n        - Rather than requiring charm authors to include boilerplate to\n          invoke your helper's behavior, have it run automatically if\n          your object is instantiated or module imported.\n\n    This is not at all useful after your hook framework as been launched.\n    '''\n    global _atstart\n    _atstart.append((callback, args, kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the hook frameworks at start.", "response": "def _run_atstart():\n    '''Hook frameworks must invoke this before running the main hook body.'''\n    global _atstart\n    for callback, args, kwargs in _atstart:\n        callback(*args, **kwargs)\n    del _atstart[:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_atexit():\n    '''Hook frameworks must invoke this after the main hook body has\n    successfully completed. Do not invoke it if the hook fails.'''\n    global _atexit\n    for callback, args, kwargs in reversed(_atexit):\n        callback(*args, **kwargs)\n    del _atexit[:]", "response": "Invoke the callbacks after the main hook body has been completed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef network_get_primary_address(binding):\n    '''\n    Deprecated since Juju 2.3; use network_get()\n\n    Retrieve the primary network address for a named binding\n\n    :param binding: string. The name of a relation of extra-binding\n    :return: string. The primary IP address for the named binding\n    :raise: NotImplementedError if run on Juju < 2.0\n    '''\n    cmd = ['network-get', '--primary-address', binding]\n    try:\n        response = subprocess.check_output(\n            cmd,\n            stderr=subprocess.STDOUT).decode('UTF-8').strip()\n    except CalledProcessError as e:\n        if 'no network config found for binding' in e.output.decode('UTF-8'):\n            raise NoNetworkBinding(\"No network binding for {}\"\n                                   .format(binding))\n        else:\n            raise\n    return response", "response": "Deprecated since Juju 2. 3 use network_get"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the network details for a relation endpoint.", "response": "def network_get(endpoint, relation_id=None):\n    \"\"\"\n    Retrieve the network details for a relation endpoint\n\n    :param endpoint: string. The name of a relation endpoint\n    :param relation_id: int. The ID of the relation for the current context.\n    :return: dict. The loaded YAML output of the network-get query.\n    :raise: NotImplementedError if request not supported by the Juju version.\n    \"\"\"\n    if not has_juju_version('2.2'):\n        raise NotImplementedError(juju_version())  # earlier versions require --primary-address\n    if relation_id and not has_juju_version('2.3'):\n        raise NotImplementedError  # 2.3 added the -r option\n\n    cmd = ['network-get', endpoint, '--format', 'yaml']\n    if relation_id:\n        cmd.append('-r')\n        cmd.append(relation_id)\n    response = subprocess.check_output(\n        cmd,\n        stderr=subprocess.STDOUT).decode('UTF-8').strip()\n    return yaml.safe_load(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding metric values. Values may be expressed with keyword arguments. For metric names containing dashes these may be expressed as one or more key = value positional arguments.", "response": "def add_metric(*args, **kwargs):\n    \"\"\"Add metric values. Values may be expressed with keyword arguments. For\n    metric names containing dashes, these may be expressed as one or more\n    'key=value' positional arguments. May only be called from the collect-metrics\n    hook.\"\"\"\n    _args = ['add-metric']\n    _kvpairs = []\n    _kvpairs.extend(args)\n    _kvpairs.extend(['{}={}'.format(k, v) for k, v in kwargs.items()])\n    _args.extend(sorted(_kvpairs))\n    try:\n        subprocess.check_call(_args)\n        return\n    except EnvironmentError as e:\n        if e.errno != errno.ENOENT:\n            raise\n    log_message = 'add-metric failed: {}'.format(' '.join(_kvpairs))\n    log(log_message, level='INFO')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter_units_for_relation_name(relation_name):\n    RelatedUnit = namedtuple('RelatedUnit', 'rid, unit')\n    for rid in relation_ids(relation_name):\n        for unit in related_units(rid):\n            yield RelatedUnit(rid, unit)", "response": "Iterate through all the units in a relation and yields a named tuple with rid and unit field names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ingress_address(rid=None, unit=None):\n    settings = relation_get(rid=rid, unit=unit)\n    return (settings.get('ingress-address') or\n            settings.get('private-address'))", "response": "Returns the ingress - address of a unit on a relation when available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the egress - subnets from a relation.", "response": "def egress_subnets(rid=None, unit=None):\n    \"\"\"\n    Retrieve the egress-subnets from a relation.\n\n    This function is to be used on the providing side of the\n    relation, and provides the ranges of addresses that client\n    connections may come from. The result is uninteresting on\n    the consuming side of a relation (unit == local_unit()).\n\n    Returns a stable list of subnets in CIDR format.\n    eg. ['192.168.1.0/24', '2001::F00F/128']\n\n    If egress-subnets is not available, falls back to using the published\n    ingress-address, or finally private-address.\n\n    :param rid: string relation id\n    :param unit: string unit name\n    :side effect: calls relation_get\n    :return: list of subnets in CIDR format. eg. ['192.168.1.0/24', '2001::F00F/128']\n    \"\"\"\n    def _to_range(addr):\n        if re.search(r'^(?:\\d{1,3}\\.){3}\\d{1,3}$', addr) is not None:\n            addr += '/32'\n        elif ':' in addr and '/' not in addr:  # IPv6\n            addr += '/128'\n        return addr\n\n    settings = relation_get(rid=rid, unit=unit)\n    if 'egress-subnets' in settings:\n        return [n.strip() for n in settings['egress-subnets'].split(',') if n.strip()]\n    if 'ingress-address' in settings:\n        return [_to_range(settings['ingress-address'])]\n    if 'private-address' in settings:\n        return [_to_range(settings['private-address'])]\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unit_doomed(unit=None):\n    if not has_juju_version(\"2.4.1\"):\n        # We cannot risk blindly returning False for 'we don't know',\n        # because that could cause data loss; if call sites don't\n        # need an accurate answer, they likely don't need this helper\n        # at all.\n        # goal-state existed in 2.4.0, but did not handle removals\n        # correctly until 2.4.1.\n        raise NotImplementedError(\"is_doomed\")\n    if unit is None:\n        unit = local_unit()\n    gs = goal_state()\n    units = gs.get('units', {})\n    if unit not in units:\n        return True\n    # I don't think 'dead' units ever show up in the goal-state, but\n    # check anyway in addition to 'dying'.\n    return units[unit]['status'] in ('dying', 'dead')", "response": "Returns True if the unit is being removed from the model False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets proxy settings from process environment variables that correspond to juju - http - proxy and juju - https - proxy and juju - no - proxy.", "response": "def env_proxy_settings(selected_settings=None):\n    \"\"\"Get proxy settings from process environment variables.\n\n    Get charm proxy settings from environment variables that correspond to\n    juju-http-proxy, juju-https-proxy and juju-no-proxy (available as of 2.4.2,\n    see lp:1782236) in a format suitable for passing to an application that\n    reacts to proxy settings passed as environment variables. Some applications\n    support lowercase or uppercase notation (e.g. curl), some support only\n    lowercase (e.g. wget), there are also subjectively rare cases of only\n    uppercase notation support. no_proxy CIDR and wildcard support also varies\n    between runtimes and applications as there is no enforced standard.\n\n    Some applications may connect to multiple destinations and expose config\n    options that would affect only proxy settings for a specific destination\n    these should be handled in charms in an application-specific manner.\n\n    :param selected_settings: format only a subset of possible settings\n    :type selected_settings: list\n    :rtype: Option(None, dict[str, str])\n    \"\"\"\n    SUPPORTED_SETTINGS = {\n        'http': 'HTTP_PROXY',\n        'https': 'HTTPS_PROXY',\n        'no_proxy': 'NO_PROXY',\n        'ftp': 'FTP_PROXY'\n    }\n    if selected_settings is None:\n        selected_settings = SUPPORTED_SETTINGS\n\n    selected_vars = [v for k, v in SUPPORTED_SETTINGS.items()\n                     if k in selected_settings]\n    proxy_settings = {}\n    for var in selected_vars:\n        var_val = os.getenv(var)\n        if var_val:\n            proxy_settings[var] = var_val\n            proxy_settings[var.lower()] = var_val\n        # Now handle juju-prefixed environment variables. The legacy vs new\n        # environment variable usage is mutually exclusive\n        charm_var_val = os.getenv('JUJU_CHARM_{}'.format(var))\n        if charm_var_val:\n            proxy_settings[var] = charm_var_val\n            proxy_settings[var.lower()] = charm_var_val\n    if 'no_proxy' in proxy_settings:\n        if _contains_range(proxy_settings['no_proxy']):\n            log(RANGE_WARNING, level=WARNING)\n    return proxy_settings if proxy_settings else None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload previous copy of config from disk.", "response": "def load_previous(self, path=None):\n        \"\"\"Load previous copy of config from disk.\n\n        In normal usage you don't need to call this method directly - it\n        is called automatically at object initialization.\n\n        :param path:\n\n            File path from which to load the previous config. If `None`,\n            config is loaded from the default location. If `path` is\n            specified, subsequent `save()` calls will write to the same\n            path.\n\n        \"\"\"\n        self.path = path or self.path\n        with open(self.path) as f:\n            try:\n                self._prev_dict = json.load(f)\n            except ValueError as e:\n                log('Unable to parse previous config data - {}'.format(str(e)),\n                    level=ERROR)\n        for k, v in copy.deepcopy(self._prev_dict).items():\n            if k not in self:\n                self[k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the current value for this key is different from the previous value for this key.", "response": "def changed(self, key):\n        \"\"\"Return True if the current value for this key is different from\n        the previous value.\n\n        \"\"\"\n        if self._prev_dict is None:\n            return True\n        return self.previous(key) != self.get(key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave this config to disk.", "response": "def save(self):\n        \"\"\"Save this config to disk.\n\n        If the charm is using the :mod:`Services Framework <services.base>`\n        or :meth:'@hook <Hooks.hook>' decorator, this\n        is called automatically at the end of successful hook execution.\n        Otherwise, it should be called directly by user code.\n\n        To disable automatic saves, set ``implicit_save=False`` on this\n        instance.\n\n        \"\"\"\n        with open(self.path, 'w') as f:\n            os.fchmod(f.fileno(), 0o600)\n            json.dump(self, f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, args):\n        _run_atstart()\n        hook_name = os.path.basename(args[0])\n        if hook_name in self._hooks:\n            try:\n                self._hooks[hook_name]()\n            except SystemExit as x:\n                if x.code is None or x.code == 0:\n                    _run_atexit()\n                raise\n            _run_atexit()\n        else:\n            raise UnregisteredHookError(hook_name)", "response": "Execute a registered hook based on args [ 0 ]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shutdown(self):\n        sys.stdout = self.old_stdout\n        sys.stdin = self.old_stdin\n        self.skt.close()\n        self.set_continue()", "response": "Revert stdout and stdin close the socket."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start():\n        action_set('meta.start', time.strftime('%Y-%m-%dT%H:%M:%SZ'))\n\n        \"\"\"\n        If the collectd charm is also installed, tell it to send a snapshot\n        of the current profile data.\n        \"\"\"\n        COLLECT_PROFILE_DATA = '/usr/local/bin/collect-profile-data'\n        if os.path.exists(COLLECT_PROFILE_DATA):\n            subprocess.check_output([COLLECT_PROFILE_DATA])", "response": "Start the collectd profile data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_os_codename_install_source(src):\n    '''Derive OpenStack release codename from a given installation source.'''\n    ubuntu_rel = lsb_release()['DISTRIB_CODENAME']\n    rel = ''\n    if src is None:\n        return rel\n    if src in ['distro', 'distro-proposed', 'proposed']:\n        try:\n            rel = UBUNTU_OPENSTACK_RELEASE[ubuntu_rel]\n        except KeyError:\n            e = 'Could not derive openstack release for '\\\n                'this Ubuntu release: %s' % ubuntu_rel\n            error_out(e)\n        return rel\n\n    if src.startswith('cloud:'):\n        ca_rel = src.split(':')[1]\n        ca_rel = ca_rel.split('-')[1].split('/')[0]\n        return ca_rel\n\n    # Best guess match based on deb string provided\n    if (src.startswith('deb') or\n            src.startswith('ppa') or\n            src.startswith('snap')):\n        for v in OPENSTACK_CODENAMES.values():\n            if v in src:\n                return v", "response": "Derive OpenStack release codename from a given installation source."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine OpenStack version number from codename.", "response": "def get_os_version_codename(codename, version_map=OPENSTACK_CODENAMES):\n    '''Determine OpenStack version number from codename.'''\n    for k, v in six.iteritems(version_map):\n        if v == codename:\n            return k\n    e = 'Could not derive OpenStack version for '\\\n        'codename: %s' % codename\n    error_out(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_os_version_codename_swift(codename):\n    '''Determine OpenStack version number of swift from codename.'''\n    for k, v in six.iteritems(SWIFT_CODENAMES):\n        if k == codename:\n            return v[-1]\n    e = 'Could not derive swift version for '\\\n        'codename: %s' % codename\n    error_out(e)", "response": "Determine OpenStack version number of swift from codename."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine OpenStack codename that corresponds to swift version.", "response": "def get_swift_codename(version):\n    '''Determine OpenStack codename that corresponds to swift version.'''\n    codenames = [k for k, v in six.iteritems(SWIFT_CODENAMES) if version in v]\n\n    if len(codenames) > 1:\n        # If more than one release codename contains this version we determine\n        # the actual codename based on the highest available install source.\n        for codename in reversed(codenames):\n            releases = UBUNTU_OPENSTACK_RELEASE\n            release = [k for k, v in six.iteritems(releases) if codename in v]\n            ret = subprocess.check_output(['apt-cache', 'policy', 'swift'])\n            if six.PY3:\n                ret = ret.decode('UTF-8')\n            if codename in ret or release[0] in ret:\n                return codename\n    elif len(codenames) == 1:\n        return codenames[0]\n\n    # NOTE: fallback - attempt to match with just major.minor version\n    match = re.match(r'^(\\d+)\\.(\\d+)', version)\n    if match:\n        major_minor_version = match.group(0)\n        for codename, versions in six.iteritems(SWIFT_CODENAMES):\n            for release_version in versions:\n                if release_version.startswith(major_minor_version):\n                    return codename\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nderive OpenStack release codename from an installed package.", "response": "def get_os_codename_package(package, fatal=True):\n    '''Derive OpenStack release codename from an installed package.'''\n\n    if snap_install_requested():\n        cmd = ['snap', 'list', package]\n        try:\n            out = subprocess.check_output(cmd)\n            if six.PY3:\n                out = out.decode('UTF-8')\n        except subprocess.CalledProcessError:\n            return None\n        lines = out.split('\\n')\n        for line in lines:\n            if package in line:\n                # Second item in list is Version\n                return line.split()[1]\n\n    import apt_pkg as apt\n\n    cache = apt_cache()\n\n    try:\n        pkg = cache[package]\n    except Exception:\n        if not fatal:\n            return None\n        # the package is unknown to the current apt cache.\n        e = 'Could not determine version of package with no installation '\\\n            'candidate: %s' % package\n        error_out(e)\n\n    if not pkg.current_ver:\n        if not fatal:\n            return None\n        # package is known, but no version is currently installed.\n        e = 'Could not determine version of uninstalled package: %s' % package\n        error_out(e)\n\n    vers = apt.upstream_version(pkg.current_ver.ver_str)\n    if 'swift' in pkg.name:\n        # Fully x.y.z match for swift versions\n        match = re.match(r'^(\\d+)\\.(\\d+)\\.(\\d+)', vers)\n    else:\n        # x.y match only for 20XX.X\n        # and ignore patch level for other packages\n        match = re.match(r'^(\\d+)\\.(\\d+)', vers)\n\n    if match:\n        vers = match.group(0)\n\n    # Generate a major version number for newer semantic\n    # versions of openstack projects\n    major_vers = vers.split('.')[0]\n    # >= Liberty independent project versions\n    if (package in PACKAGE_CODENAMES and\n            major_vers in PACKAGE_CODENAMES[package]):\n        return PACKAGE_CODENAMES[package][major_vers]\n    else:\n        # < Liberty co-ordinated project versions\n        try:\n            if 'swift' in pkg.name:\n                return get_swift_codename(vers)\n            else:\n                return OPENSTACK_CODENAMES[vers]\n        except KeyError:\n            if not fatal:\n                return None\n            e = 'Could not determine OpenStack codename for version %s' % vers\n            error_out(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_os_version_package(pkg, fatal=True):\n    '''Derive OpenStack version number from an installed package.'''\n    codename = get_os_codename_package(pkg, fatal=fatal)\n\n    if not codename:\n        return None\n\n    if 'swift' in pkg:\n        vers_map = SWIFT_CODENAMES\n        for cname, version in six.iteritems(vers_map):\n            if cname == codename:\n                return version[-1]\n    else:\n        vers_map = OPENSTACK_CODENAMES\n        for version, cname in six.iteritems(vers_map):\n            if cname == codename:\n                return version", "response": "Derive OpenStack version number from an installed package."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef os_release(package, base='essex', reset_cache=False):\n    '''\n    Returns OpenStack release codename from a cached global.\n\n    If reset_cache then unset the cached os_release version and return the\n    freshly determined version.\n\n    If the codename can not be determined from either an installed package or\n    the installation source, the earliest release supported by the charm should\n    be returned.\n    '''\n    global _os_rel\n    if reset_cache:\n        reset_os_release()\n    if _os_rel:\n        return _os_rel\n    _os_rel = (\n        get_os_codename_package(package, fatal=False) or\n        get_os_codename_install_source(config('openstack-origin')) or\n        base)\n    return _os_rel", "response": "Returns OpenStack release codename for the given package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_key(keyid):\n    try:\n        return fetch_import_key(keyid)\n    except GPGKeyError as e:\n        error_out(\"Could not import key: {}\".format(str(e)))", "response": "Import a key from ASCII armored format or a GPG key id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_source_and_pgp_key(source_and_key):\n    try:\n        source, key = source_and_key.split('|', 2)\n        return source, key or None\n    except ValueError:\n        return source_and_key, None", "response": "Look for a pgp key ID or ascii - armor key in the given input."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configure_installation_source(source_plus_key):\n    if source_plus_key.startswith('snap'):\n        # Do nothing for snap installs\n        return\n    # extract the key if there is one, denoted by a '|' in the rel\n    source, key = get_source_and_pgp_key(source_plus_key)\n\n    # handle the ordinary sources via add_source\n    try:\n        fetch_add_source(source, key, fail_invalid=True)\n    except SourceConfigError as se:\n        error_out(str(se))", "response": "Configure an installation source."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config_value_changed(option):\n    hook_data = unitdata.HookData()\n    with hook_data():\n        db = unitdata.kv()\n        current = config(option)\n        saved = db.get(option)\n        db.set(option, current)\n        if saved is None:\n            return False\n        return current != saved", "response": "Determines if config value has changed since last call to this function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the rc file in the charm - delivered directory containing the charm scripts exported by env_vars.", "response": "def save_script_rc(script_path=\"scripts/scriptrc\", **env_vars):\n    \"\"\"\n    Write an rc file in the charm-delivered directory containing\n    exported environment variables provided by env_vars. Any charm scripts run\n    outside the juju hook environment can source this scriptrc to obtain\n    updated config information necessary to perform health checks or\n    service changes.\n    \"\"\"\n    juju_rc_path = \"%s/%s\" % (charm_dir(), script_path)\n    if not os.path.exists(os.path.dirname(juju_rc_path)):\n        os.mkdir(os.path.dirname(juju_rc_path))\n    with open(juju_rc_path, 'wt') as rc_script:\n        rc_script.write(\n            \"#!/bin/bash\\n\")\n        [rc_script.write('export %s=%s\\n' % (u, p))\n         for u, p in six.iteritems(env_vars) if u != \"script_path\"]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef openstack_upgrade_available(package):\n\n    import apt_pkg as apt\n    src = config('openstack-origin')\n    cur_vers = get_os_version_package(package)\n    if not cur_vers:\n        # The package has not been installed yet do not attempt upgrade\n        return False\n    if \"swift\" in package:\n        codename = get_os_codename_install_source(src)\n        avail_vers = get_os_version_codename_swift(codename)\n    else:\n        avail_vers = get_os_version_install_source(src)\n    apt.init()\n    return apt.version_compare(avail_vers, cur_vers) >= 1", "response": "Determines if an OpenStack upgrade is available from installation\n    source based on version of installed package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_block_device(block_device):\n    '''\n    Confirm block_device, create as loopback if necessary.\n\n    :param block_device: str: Full path of block device to ensure.\n\n    :returns: str: Full path of ensured block device.\n    '''\n    _none = ['None', 'none', None]\n    if (block_device in _none):\n        error_out('prepare_storage(): Missing required input: block_device=%s.'\n                  % block_device)\n\n    if block_device.startswith('/dev/'):\n        bdev = block_device\n    elif block_device.startswith('/'):\n        _bd = block_device.split('|')\n        if len(_bd) == 2:\n            bdev, size = _bd\n        else:\n            bdev = block_device\n            size = DEFAULT_LOOPBACK_SIZE\n        bdev = ensure_loopback_device(bdev, size)\n    else:\n        bdev = '/dev/%s' % block_device\n\n    if not is_block_device(bdev):\n        error_out('Failed to locate valid block device at %s' % bdev)\n\n    return bdev", "response": "Confirm block_device create as loopback if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_storage(block_device):\n    '''\n    Ensures a block device is clean.  That is:\n        - unmounted\n        - any lvm volume groups are deactivated\n        - any lvm physical device signatures removed\n        - partition table wiped\n\n    :param block_device: str: Full path to block device to clean.\n    '''\n    for mp, d in mounts():\n        if d == block_device:\n            juju_log('clean_storage(): %s is mounted @ %s, unmounting.' %\n                     (d, mp), level=INFO)\n            umount(mp, persist=True)\n\n    if is_lvm_physical_volume(block_device):\n        deactivate_lvm_volume_group(block_device)\n        remove_lvm_physical_volume(block_device)\n    else:\n        zap_disk(block_device)", "response": "Clean the storage for a given block device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef os_requires_version(ostack_release, pkg):\n    def wrap(f):\n        @wraps(f)\n        def wrapped_f(*args):\n            if os_release(pkg) < ostack_release:\n                raise Exception(\"This hook is not supported on releases\"\n                                \" before %s\" % ostack_release)\n            f(*args)\n        return wrapped_f\n    return wrap", "response": "Decorator for hook to specify minimum supported release"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_os_workload_status(configs, required_interfaces, charm_func=None,\n                           services=None, ports=None):\n    \"\"\"Set the state of the workload status for the charm.\n\n    This calls _determine_os_workload_status() to get the new state, message\n    and sets the status using status_set()\n\n    @param configs: a templating.OSConfigRenderer() object\n    @param required_interfaces: {generic: [specific, specific2, ...]}\n    @param charm_func: a callable function that returns state, message. The\n                       signature is charm_func(configs) -> (state, message)\n    @param services: list of strings OR dictionary specifying services/ports\n    @param ports: OPTIONAL list of port numbers.\n    @returns state, message: the new workload status, user message\n    \"\"\"\n    state, message = _determine_os_workload_status(\n        configs, required_interfaces, charm_func, services, ports)\n    status_set(state, message)", "response": "Set the state of the workload status for the charm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _determine_os_workload_status(\n        configs, required_interfaces, charm_func=None,\n        services=None, ports=None):\n    \"\"\"Determine the state of the workload status for the charm.\n\n    This function returns the new workload status for the charm based\n    on the state of the interfaces, the paused state and whether the\n    services are actually running and any specified ports are open.\n\n    This checks:\n\n     1. if the unit should be paused, that it is actually paused.  If so the\n        state is 'maintenance' + message, else 'broken'.\n     2. that the interfaces/relations are complete.  If they are not then\n        it sets the state to either 'broken' or 'waiting' and an appropriate\n        message.\n     3. If all the relation data is set, then it checks that the actual\n        services really are running.  If not it sets the state to 'broken'.\n\n    If everything is okay then the state returns 'active'.\n\n    @param configs: a templating.OSConfigRenderer() object\n    @param required_interfaces: {generic: [specific, specific2, ...]}\n    @param charm_func: a callable function that returns state, message. The\n                       signature is charm_func(configs) -> (state, message)\n    @param services: list of strings OR dictionary specifying services/ports\n    @param ports: OPTIONAL list of port numbers.\n    @returns state, message: the new workload status, user message\n    \"\"\"\n    state, message = _ows_check_if_paused(services, ports)\n\n    if state is None:\n        state, message = _ows_check_generic_interfaces(\n            configs, required_interfaces)\n\n    if state != 'maintenance' and charm_func:\n        # _ows_check_charm_func() may modify the state, message\n        state, message = _ows_check_charm_func(\n            state, message, lambda: charm_func(configs))\n\n    if state is None:\n        state, message = _ows_check_services_running(services, ports)\n\n    if state is None:\n        state = 'active'\n        message = \"Unit is ready\"\n        juju_log(message, 'INFO')\n\n    return state, message", "response": "Determine the state of the workload for the charm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ows_check_if_paused(services=None, ports=None):\n    if is_unit_upgrading_set():\n        state, message = check_actually_paused(services=services,\n                                               ports=ports)\n        if state is None:\n            # we're paused okay, so set maintenance and return\n            state = \"blocked\"\n            message = (\"Ready for do-release-upgrade and reboot. \"\n                       \"Set complete when finished.\")\n        return state, message\n\n    if is_unit_paused_set():\n        state, message = check_actually_paused(services=services,\n                                               ports=ports)\n        if state is None:\n            # we're paused okay, so set maintenance and return\n            state = \"maintenance\"\n            message = \"Paused. Use 'resume' action to resume normal service.\"\n        return state, message\n    return None, None", "response": "Checks if the unit is paused and if so checks if it is waiting to be resumed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the complete contexts to determine the workload status.", "response": "def _ows_check_generic_interfaces(configs, required_interfaces):\n    \"\"\"Check the complete contexts to determine the workload status.\n\n     - Checks for missing or incomplete contexts\n     - juju log details of missing required data.\n     - determines the correct workload status\n     - creates an appropriate message for status_set(...)\n\n    if there are no problems then the function returns None, None\n\n    @param configs: a templating.OSConfigRenderer() object\n    @params required_interfaces: {generic_interface: [specific_interface], }\n    @returns state, message or None, None\n    \"\"\"\n    incomplete_rel_data = incomplete_relation_data(configs,\n                                                   required_interfaces)\n    state = None\n    message = None\n    missing_relations = set()\n    incomplete_relations = set()\n\n    for generic_interface, relations_states in incomplete_rel_data.items():\n        related_interface = None\n        missing_data = {}\n        # Related or not?\n        for interface, relation_state in relations_states.items():\n            if relation_state.get('related'):\n                related_interface = interface\n                missing_data = relation_state.get('missing_data')\n                break\n        # No relation ID for the generic_interface?\n        if not related_interface:\n            juju_log(\"{} relation is missing and must be related for \"\n                     \"functionality. \".format(generic_interface), 'WARN')\n            state = 'blocked'\n            missing_relations.add(generic_interface)\n        else:\n            # Relation ID eists but no related unit\n            if not missing_data:\n                # Edge case - relation ID exists but departings\n                _hook_name = hook_name()\n                if (('departed' in _hook_name or 'broken' in _hook_name) and\n                        related_interface in _hook_name):\n                    state = 'blocked'\n                    missing_relations.add(generic_interface)\n                    juju_log(\"{} relation's interface, {}, \"\n                             \"relationship is departed or broken \"\n                             \"and is required for functionality.\"\n                             \"\".format(generic_interface, related_interface),\n                             \"WARN\")\n                # Normal case relation ID exists but no related unit\n                # (joining)\n                else:\n                    juju_log(\"{} relations's interface, {}, is related but has\"\n                             \" no units in the relation.\"\n                             \"\".format(generic_interface, related_interface),\n                             \"INFO\")\n            # Related unit exists and data missing on the relation\n            else:\n                juju_log(\"{} relation's interface, {}, is related awaiting \"\n                         \"the following data from the relationship: {}. \"\n                         \"\".format(generic_interface, related_interface,\n                                   \", \".join(missing_data)), \"INFO\")\n            if state != 'blocked':\n                state = 'waiting'\n            if generic_interface not in missing_relations:\n                incomplete_relations.add(generic_interface)\n\n    if missing_relations:\n        message = \"Missing relations: {}\".format(\", \".join(missing_relations))\n        if incomplete_relations:\n            message += \"; incomplete relations: {}\" \\\n                       \"\".format(\", \".join(incomplete_relations))\n        state = 'blocked'\n    elif incomplete_relations:\n        message = \"Incomplete relations: {}\" \\\n                  \"\".format(\", \".join(incomplete_relations))\n        state = 'waiting'\n\n    return state, message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a custom check function for the charm to see if it wants to change the state.", "response": "def _ows_check_charm_func(state, message, charm_func_with_configs):\n    \"\"\"Run a custom check function for the charm to see if it wants to\n    change the state.  This is only run if not in 'maintenance' and\n    tests to see if the new state is more important that the previous\n    one determined by the interfaces/relations check.\n\n    @param state: the previously determined state so far.\n    @param message: the user orientated message so far.\n    @param charm_func: a callable function that returns state, message\n    @returns state, message strings.\n    \"\"\"\n    if charm_func_with_configs:\n        charm_state, charm_message = charm_func_with_configs()\n        if (charm_state != 'active' and\n                charm_state != 'unknown' and\n                charm_state is not None):\n            state = workload_state_compare(state, charm_state)\n            if message:\n                charm_message = charm_message.replace(\"Incomplete relations: \",\n                                                      \"\")\n                message = \"{}, {}\".format(message, charm_message)\n            else:\n                message = charm_message\n    return state, message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ows_check_services_running(services, ports):\n    messages = []\n    state = None\n    if services is not None:\n        services = _extract_services_list_helper(services)\n        services_running, running = _check_running_services(services)\n        if not all(running):\n            messages.append(\n                \"Services not running that should be: {}\"\n                .format(\", \".join(_filter_tuples(services_running, False))))\n            state = 'blocked'\n        # also verify that the ports that should be open are open\n        # NB, that ServiceManager objects only OPTIONALLY have ports\n        map_not_open, ports_open = (\n            _check_listening_on_services_ports(services))\n        if not all(ports_open):\n            # find which service has missing ports. They are in service\n            # order which makes it a bit easier.\n            message_parts = {service: \", \".join([str(v) for v in open_ports])\n                             for service, open_ports in map_not_open.items()}\n            message = \", \".join(\n                [\"{}: [{}]\".format(s, sp) for s, sp in message_parts.items()])\n            messages.append(\n                \"Services with ports not open that should be: {}\"\n                .format(message))\n            state = 'blocked'\n\n    if ports is not None:\n        # and we can also check ports which we don't know the service for\n        ports_open, ports_open_bools = _check_listening_on_ports_list(ports)\n        if not all(ports_open_bools):\n            messages.append(\n                \"Ports which should be open, but are not: {}\"\n                .format(\", \".join([str(p) for p, v in ports_open\n                                   if not v])))\n            state = 'blocked'\n\n    if state is not None:\n        message = \"; \".join(messages)\n        return state, message\n\n    return None, None", "response": "Checks that the services that should be running are actually running and that any ports that are being listened to are actually open."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts a OrderedDict of {service: [ports]} of the supplied services for use by the other functions. The services object can either be: - None : no services were passed (an empty dict is returned) - a list of strings - A dictionary (optionally OrderedDict) {service_name: {'service': ..}} - An array of [{'service': service_name, ...}, ...] @param services: see above @returns OrderedDict(service: [ports], ...)", "response": "def _extract_services_list_helper(services):\n    \"\"\"Extract a OrderedDict of {service: [ports]} of the supplied services\n    for use by the other functions.\n\n    The services object can either be:\n      - None : no services were passed (an empty dict is returned)\n      - a list of strings\n      - A dictionary (optionally OrderedDict) {service_name: {'service': ..}}\n      - An array of [{'service': service_name, ...}, ...]\n\n    @param services: see above\n    @returns OrderedDict(service: [ports], ...)\n    \"\"\"\n    if services is None:\n        return {}\n    if isinstance(services, dict):\n        services = services.values()\n    # either extract the list of services from the dictionary, or if\n    # it is a simple string, use that. i.e. works with mixed lists.\n    _s = OrderedDict()\n    for s in services:\n        if isinstance(s, dict) and 'service' in s:\n            _s[s['service']] = s.get('ports', [])\n        if isinstance(s, str):\n            _s[s] = []\n    return _s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the services dict provided is actually running and provide a list of booleans for each service.", "response": "def _check_running_services(services):\n    \"\"\"Check that the services dict provided is actually running and provide\n    a list of (service, boolean) tuples for each service.\n\n    Returns both a zipped list of (service, boolean) and a list of booleans\n    in the same order as the services.\n\n    @param services: OrderedDict of strings: [ports], one for each service to\n                     check.\n    @returns [(service, boolean), ...], : results for checks\n             [boolean]                  : just the result of the service checks\n    \"\"\"\n    services_running = [service_running(s) for s in services]\n    return list(zip(services, services_running)), services_running"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_listening_on_services_ports(services, test=False):\n    test = not(not(test))  # ensure test is True or False\n    all_ports = list(itertools.chain(*services.values()))\n    ports_states = [port_has_listener('0.0.0.0', p) for p in all_ports]\n    map_ports = OrderedDict()\n    matched_ports = [p for p, opened in zip(all_ports, ports_states)\n                     if opened == test]  # essentially opened xor test\n    for service, ports in services.items():\n        set_ports = set(ports).intersection(matched_ports)\n        if set_ports:\n            map_ports[service] = set_ports\n    return map_ports, ports_states", "response": "Check that the unit is actually listening on the ports that the service specifies are open."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that the ports list given are being listened to Returns a list of ports being listened to and a list of the booleans.", "response": "def _check_listening_on_ports_list(ports):\n    \"\"\"Check that the ports list given are being listened to\n\n    Returns a list of ports being listened to and a list of the\n    booleans.\n\n    @param ports: LIST or port numbers.\n    @returns [(port_num, boolean), ...], [boolean]\n    \"\"\"\n    ports_open = [port_has_listener('0.0.0.0', p) for p in ports]\n    return zip(ports, ports_open), ports_open"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning highest priority of two states", "response": "def workload_state_compare(current_workload_state, workload_state):\n    \"\"\" Return highest priority of two states\"\"\"\n    hierarchy = {'unknown': -1,\n                 'active': 0,\n                 'maintenance': 1,\n                 'waiting': 2,\n                 'blocked': 3,\n                 }\n\n    if hierarchy.get(workload_state) is None:\n        workload_state = 'unknown'\n    if hierarchy.get(current_workload_state) is None:\n        current_workload_state = 'unknown'\n\n    # Set workload_state based on hierarchy of statuses\n    if hierarchy.get(current_workload_state) > hierarchy.get(workload_state):\n        return current_workload_state\n    else:\n        return workload_state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef incomplete_relation_data(configs, required_interfaces):\n    complete_ctxts = configs.complete_contexts()\n    incomplete_relations = [\n        svc_type\n        for svc_type, interfaces in required_interfaces.items()\n        if not set(interfaces).intersection(complete_ctxts)]\n    return {\n        i: configs.get_incomplete_context_data(required_interfaces[i])\n        for i in incomplete_relations}", "response": "Check complete contexts against required_interfaces returning a dictionary of incomplete relation data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms action - managed OpenStack upgrade.", "response": "def do_action_openstack_upgrade(package, upgrade_callback, configs):\n    \"\"\"Perform action-managed OpenStack upgrade.\n\n    Upgrades packages to the configured openstack-origin version and sets\n    the corresponding action status as a result.\n\n    If the charm was installed from source we cannot upgrade it.\n    For backwards compatibility a config flag (action-managed-upgrade) must\n    be set for this code to run, otherwise a full service level upgrade will\n    fire on config-changed.\n\n    @param package: package name for determining if upgrade available\n    @param upgrade_callback: function callback to charm's upgrade function\n    @param configs: templating object derived from OSConfigRenderer class\n\n    @return: True if upgrade successful; False if upgrade failed or skipped\n    \"\"\"\n    ret = False\n\n    if openstack_upgrade_available(package):\n        if config('action-managed-upgrade'):\n            juju_log('Upgrading OpenStack release')\n\n            try:\n                upgrade_callback(configs=configs)\n                action_set({'outcome': 'success, upgrade completed.'})\n                ret = True\n            except Exception:\n                action_set({'outcome': 'upgrade failed, see traceback.'})\n                action_set({'traceback': traceback.format_exc()})\n                action_fail('do_openstack_upgrade resulted in an '\n                            'unexpected error')\n        else:\n            action_set({'outcome': 'action-managed-upgrade config is '\n                                   'False, skipped upgrade.'})\n    else:\n        action_set({'outcome': 'no upgrade available.'})\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_actually_paused(services=None, ports=None):\n    state = None\n    message = None\n    messages = []\n    if services is not None:\n        services = _extract_services_list_helper(services)\n        services_running, services_states = _check_running_services(services)\n        if any(services_states):\n            # there shouldn't be any running so this is a problem\n            messages.append(\"these services running: {}\"\n                            .format(\", \".join(\n                                _filter_tuples(services_running, True))))\n            state = \"blocked\"\n        ports_open, ports_open_bools = (\n            _check_listening_on_services_ports(services, True))\n        if any(ports_open_bools):\n            message_parts = {service: \", \".join([str(v) for v in open_ports])\n                             for service, open_ports in ports_open.items()}\n            message = \", \".join(\n                [\"{}: [{}]\".format(s, sp) for s, sp in message_parts.items()])\n            messages.append(\n                \"these service:ports are open: {}\".format(message))\n            state = 'blocked'\n    if ports is not None:\n        ports_open, bools = _check_listening_on_ports_list(ports)\n        if any(bools):\n            messages.append(\n                \"these ports which should be closed, but are open: {}\"\n                .format(\", \".join([str(p) for p, v in ports_open if v])))\n            state = 'blocked'\n    if messages:\n        message = (\"Services should be paused but {}\"\n                   .format(\", \".join(messages)))\n    return state, message", "response": "Check that the services and ports are actually closed and that they are not listening to."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the state of the unit paused.", "response": "def is_unit_paused_set():\n    \"\"\"Return the state of the kv().get('unit-paused').\n    This does NOT verify that the unit really is paused.\n\n    To help with units that don't have HookData() (testing)\n    if it excepts, return False\n    \"\"\"\n    try:\n        with unitdata.HookData()() as t:\n            kv = t[0]\n            # transform something truth-y into a Boolean.\n            return not(not(kv.get('unit-paused')))\n    except Exception:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmanage the payload of a single service.", "response": "def manage_payload_services(action, services=None, charm_func=None):\n    \"\"\"Run an action against all services.\n\n    An optional charm_func() can be called. It should raise an Exception to\n    indicate that the function failed. If it was succesfull it should return\n    None or an optional message.\n\n    The signature for charm_func is:\n    charm_func() -> message: str\n\n    charm_func() is executed after any services are stopped, if supplied.\n\n    The services object can either be:\n      - None : no services were passed (an empty dict is returned)\n      - a list of strings\n      - A dictionary (optionally OrderedDict) {service_name: {'service': ..}}\n      - An array of [{'service': service_name, ...}, ...]\n\n    :param action: Action to run: pause, resume, start or stop.\n    :type action: str\n    :param services: See above\n    :type services: See above\n    :param charm_func: function to run for custom charm pausing.\n    :type charm_func: f()\n    :returns: Status boolean and list of messages\n    :rtype: (bool, [])\n    :raises: RuntimeError\n    \"\"\"\n    actions = {\n        'pause': service_pause,\n        'resume': service_resume,\n        'start': service_start,\n        'stop': service_stop}\n    action = action.lower()\n    if action not in actions.keys():\n        raise RuntimeError(\n            \"action: {} must be one of: {}\".format(action,\n                                                   ', '.join(actions.keys())))\n    services = _extract_services_list_helper(services)\n    messages = []\n    success = True\n    if services:\n        for service in services.keys():\n            rc = actions[action](service)\n            if not rc:\n                success = False\n                messages.append(\"{} didn't {} cleanly.\".format(service,\n                                                               action))\n    if charm_func:\n        try:\n            message = charm_func()\n            if message:\n                messages.append(message)\n        except Exception as e:\n            success = False\n            messages.append(str(e))\n    return success, messages"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npausing a unit by stopping the services and setting unit - paused in the local kv store.", "response": "def pause_unit(assess_status_func, services=None, ports=None,\n               charm_func=None):\n    \"\"\"Pause a unit by stopping the services and setting 'unit-paused'\n    in the local kv() store.\n\n    Also checks that the services have stopped and ports are no longer\n    being listened to.\n\n    An optional charm_func() can be called that can either raise an\n    Exception or return non None, None to indicate that the unit\n    didn't pause cleanly.\n\n    The signature for charm_func is:\n    charm_func() -> message: string\n\n    charm_func() is executed after any services are stopped, if supplied.\n\n    The services object can either be:\n      - None : no services were passed (an empty dict is returned)\n      - a list of strings\n      - A dictionary (optionally OrderedDict) {service_name: {'service': ..}}\n      - An array of [{'service': service_name, ...}, ...]\n\n    @param assess_status_func: (f() -> message: string | None) or None\n    @param services: OPTIONAL see above\n    @param ports: OPTIONAL list of port\n    @param charm_func: function to run for custom charm pausing.\n    @returns None\n    @raises Exception(message) on an error for action_fail().\n    \"\"\"\n    _, messages = manage_payload_services(\n        'pause',\n        services=services,\n        charm_func=charm_func)\n    set_unit_paused()\n    if assess_status_func:\n        message = assess_status_func()\n        if message:\n            messages.append(message)\n    if messages and not is_unit_upgrading_set():\n        raise Exception(\"Couldn't pause: {}\".format(\"; \".join(messages)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresuming a unit by starting the services and clearing the unit - paused flag in the local kv store.", "response": "def resume_unit(assess_status_func, services=None, ports=None,\n                charm_func=None):\n    \"\"\"Resume a unit by starting the services and clearning 'unit-paused'\n    in the local kv() store.\n\n    Also checks that the services have started and ports are being listened to.\n\n    An optional charm_func() can be called that can either raise an\n    Exception or return non None to indicate that the unit\n    didn't resume cleanly.\n\n    The signature for charm_func is:\n    charm_func() -> message: string\n\n    charm_func() is executed after any services are started, if supplied.\n\n    The services object can either be:\n      - None : no services were passed (an empty dict is returned)\n      - a list of strings\n      - A dictionary (optionally OrderedDict) {service_name: {'service': ..}}\n      - An array of [{'service': service_name, ...}, ...]\n\n    @param assess_status_func: (f() -> message: string | None) or None\n    @param services: OPTIONAL see above\n    @param ports: OPTIONAL list of port\n    @param charm_func: function to run for custom charm resuming.\n    @returns None\n    @raises Exception(message) on an error for action_fail().\n    \"\"\"\n    _, messages = manage_payload_services(\n        'resume',\n        services=services,\n        charm_func=charm_func)\n    clear_unit_paused()\n    if assess_status_func:\n        message = assess_status_func()\n        if message:\n            messages.append(message)\n    if messages:\n        raise Exception(\"Couldn't resume: {}\".format(\"; \".join(messages)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a function that returns None if the unit is not in maintenance or active states.", "response": "def make_assess_status_func(*args, **kwargs):\n    \"\"\"Creates an assess_status_func() suitable for handing to pause_unit()\n    and resume_unit().\n\n    This uses the _determine_os_workload_status(...) function to determine\n    what the workload_status should be for the unit.  If the unit is\n    not in maintenance or active states, then the message is returned to\n    the caller.  This is so an action that doesn't result in either a\n    complete pause or complete resume can signal failure with an action_fail()\n    \"\"\"\n    def _assess_status_func():\n        state, message = _determine_os_workload_status(*args, **kwargs)\n        status_set(state, message)\n        if state not in ['maintenance', 'active']:\n            return message\n        return None\n\n    return _assess_status_func"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pausable_restart_on_change(restart_map, stopstart=False,\n                               restart_functions=None):\n    \"\"\"A restart_on_change decorator that checks to see if the unit is\n    paused. If it is paused then the decorated function doesn't fire.\n\n    This is provided as a helper, as the @restart_on_change(...) decorator\n    is in core.host, yet the openstack specific helpers are in this file\n    (contrib.openstack.utils).  Thus, this needs to be an optional feature\n    for openstack charms (or charms that wish to use the openstack\n    pause/resume type features).\n\n    It is used as follows:\n\n        from contrib.openstack.utils import (\n            pausable_restart_on_change as restart_on_change)\n\n        @restart_on_change(restart_map, stopstart=<boolean>)\n        def some_hook(...):\n            pass\n\n    see core.utils.restart_on_change() for more details.\n\n    Note restart_map can be a callable, in which case, restart_map is only\n    evaluated at runtime.  This means that it is lazy and the underlying\n    function won't be called if the decorated function is never called.  Note,\n    retains backwards compatibility for passing a non-callable dictionary.\n\n    @param f: the function to decorate\n    @param restart_map: (optionally callable, which then returns the\n        restart_map) the restart map {conf_file: [services]}\n    @param stopstart: DEFAULT false; whether to stop, start or just restart\n    @returns decorator to use a restart_on_change with pausability\n    \"\"\"\n    def wrap(f):\n        # py27 compatible nonlocal variable.  When py3 only, replace with\n        # nonlocal keyword\n        __restart_map_cache = {'cache': None}\n\n        @functools.wraps(f)\n        def wrapped_f(*args, **kwargs):\n            if is_unit_paused_set():\n                return f(*args, **kwargs)\n            if __restart_map_cache['cache'] is None:\n                __restart_map_cache['cache'] = restart_map() \\\n                    if callable(restart_map) else restart_map\n            # otherwise, normal restart_on_change functionality\n            return restart_on_change_helper(\n                (lambda: f(*args, **kwargs)), __restart_map_cache['cache'],\n                stopstart, restart_functions)\n        return wrapped_f\n    return wrap", "response": "A pausable_restart_on_change decorator that checks to see if the unit is paused and restarts it if it is paused."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the provided dictionary into an OrderedDict.", "response": "def ordered(orderme):\n    \"\"\"Converts the provided dictionary into a collections.OrderedDict.\n\n    The items in the returned OrderedDict will be inserted based on the\n    natural sort order of the keys. Nested dictionaries will also be sorted\n    in order to ensure fully predictable ordering.\n\n    :param orderme: the dict to order\n    :return: collections.OrderedDict\n    :raises: ValueError: if `orderme` isn't a dict instance.\n    \"\"\"\n    if not isinstance(orderme, dict):\n        raise ValueError('argument must be a dict type')\n\n    result = OrderedDict()\n    for k, v in sorted(six.iteritems(orderme), key=lambda x: x[0]):\n        if isinstance(v, dict):\n            result[k] = ordered(v)\n        else:\n            result[k] = v\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_flags_parser(config_flags):\n    # If we find a colon before an equals sign then treat it as yaml.\n    # Note: limit it to finding the colon first since this indicates assignment\n    # for inline yaml.\n    colon = config_flags.find(':')\n    equals = config_flags.find('=')\n    if colon > 0:\n        if colon < equals or equals < 0:\n            return ordered(yaml.safe_load(config_flags))\n\n    if config_flags.find('==') >= 0:\n        juju_log(\"config_flags is not in expected format (key=value)\",\n                 level=ERROR)\n        raise OSContextError\n\n    # strip the following from each value.\n    post_strippers = ' ,'\n    # we strip any leading/trailing '=' or ' ' from the string then\n    # split on '='.\n    split = config_flags.strip(' =').split('=')\n    limit = len(split)\n    flags = OrderedDict()\n    for i in range(0, limit - 1):\n        current = split[i]\n        next = split[i + 1]\n        vindex = next.rfind(',')\n        if (i == limit - 2) or (vindex < 0):\n            value = next\n        else:\n            value = next[:vindex]\n\n        if i == 0:\n            key = current\n        else:\n            # if this not the first entry, expect an embedded key.\n            index = current.rfind(',')\n            if index < 0:\n                juju_log(\"Invalid config value(s) at index %s\" % (i),\n                         level=ERROR)\n                raise OSContextError\n            key = current[index + 1:]\n\n        # Add to collection.\n        flags[key.strip(post_strippers)] = value.rstrip(post_strippers)\n\n    return flags", "response": "Parses config flags string into a dict of config flags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef os_application_version_set(package):\n    '''Set version of application for Juju 2.0 and later'''\n    application_version = get_upstream_version(package)\n    # NOTE(jamespage) if not able to figure out package version, fallback to\n    #                 openstack codename version detection.\n    if not application_version:\n        application_version_set(os_release(package))\n    else:\n        application_version_set(application_version)", "response": "Set version of application for Juju 2. 0 and later."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_memcache(source=None, release=None, package=None):\n    _release = None\n    if release:\n        _release = release\n    else:\n        _release = os_release(package, base='icehouse')\n    if not _release:\n        _release = get_os_codename_install_source(source)\n\n    return CompareOpenStackReleases(_release) >= 'mitaka'", "response": "Determines if memcache should be enabled on the local unit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining additional packages needed for token caching", "response": "def token_cache_pkgs(source=None, release=None):\n    \"\"\"Determine additional packages needed for token caching\n\n    @param source: source string for charm\n    @param release: release of OpenStack currently deployed\n    @returns List of package to enable token caching\n    \"\"\"\n    packages = []\n    if enable_memcache(source=source, release=release):\n        packages.extend(['memcached', 'python-memcache'])\n    return packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the json file with a given dict.", "response": "def update_json_file(filename, items):\n    \"\"\"Updates the json `filename` with a given dict.\n    :param filename: path to json file (e.g. /etc/glance/policy.json)\n    :param items: dict of items to update\n    \"\"\"\n    if not items:\n        return\n\n    with open(filename) as fd:\n        policy = json.load(fd)\n\n    # Compare before and after and if nothing has changed don't write the file\n    # since that could cause unnecessary service restarts.\n    before = json.dumps(policy, indent=4, sort_keys=True)\n    policy.update(items)\n    after = json.dumps(policy, indent=4, sort_keys=True)\n    if before == after:\n        return\n\n    with open(filename, \"w\") as fd:\n        fd.write(after)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef snap_install_requested():\n    origin = config('openstack-origin') or \"\"\n    if not origin.startswith('snap:'):\n        return False\n\n    _src = origin[5:]\n    if '/' in _src:\n        channel = _src.split('/')[1]\n    else:\n        # Handle snap:track with no channel\n        channel = 'stable'\n    return valid_snap_channel(channel)", "response": "Determine if installing from snaps\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a dictionary of snap install information from origin snaps.", "response": "def get_snaps_install_info_from_origin(snaps, src, mode='classic'):\n    \"\"\"Generate a dictionary of snap install information from origin\n\n    @param snaps: List of snaps\n    @param src: String of openstack-origin or source of the form\n        snap:track/channel\n    @param mode: String classic, devmode or jailmode\n    @returns: Dictionary of snaps with channels and modes\n    \"\"\"\n\n    if not src.startswith('snap:'):\n        juju_log(\"Snap source is not a snap origin\", 'WARN')\n        return {}\n\n    _src = src[5:]\n    channel = '--channel={}'.format(_src)\n\n    return {snap: {'channel': channel, 'mode': mode}\n            for snap in snaps}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls OpenStack snaps from channel and mode.", "response": "def install_os_snaps(snaps, refresh=False):\n    \"\"\"Install OpenStack snaps from channel and with mode\n\n    @param snaps: Dictionary of snaps with channels and modes of the form:\n        {'snap_name': {'channel': 'snap_channel',\n                       'mode': 'snap_mode'}}\n        Where channel is a snapstore channel and mode is --classic, --devmode\n        or --jailmode.\n    @param post_snap_install: Callback function to run after snaps have been\n    installed\n    \"\"\"\n\n    def _ensure_flag(flag):\n        if flag.startswith('--'):\n            return flag\n        return '--{}'.format(flag)\n\n    if refresh:\n        for snap in snaps.keys():\n            snap_refresh(snap,\n                         _ensure_flag(snaps[snap]['channel']),\n                         _ensure_flag(snaps[snap]['mode']))\n    else:\n        for snap in snaps.keys():\n            snap_install(snap,\n                         _ensure_flag(snaps[snap]['channel']),\n                         _ensure_flag(snaps[snap]['mode']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_unit_upgrading_set():\n    try:\n        with unitdata.HookData()() as t:\n            kv = t[0]\n            # transform something truth-y into a Boolean.\n            return not(not(kv.get('unit-upgrading')))\n    except Exception:\n        return False", "response": "Return the state of the kv. get ( unit - upgrades )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef series_upgrade_complete(resume_unit_helper=None, configs=None):\n    clear_unit_paused()\n    clear_unit_upgrading()\n    if configs:\n        configs.write_all()\n        if resume_unit_helper:\n            resume_unit_helper(configs)", "response": "Run common series upgrade complete tasks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a certificate request based on the network confioguration", "response": "def get_certificate_request(json_encode=True):\n    \"\"\"Generate a certificatee requests based on the network confioguration\n\n    \"\"\"\n    req = CertRequest(json_encode=json_encode)\n    req.add_hostname_cn()\n    # Add os-hostname entries\n    for net_type in [INTERNAL, ADMIN, PUBLIC]:\n        net_config = config(ADDRESS_MAP[net_type]['override'])\n        try:\n            net_addr = resolve_address(endpoint_type=net_type)\n            ip = network_get_primary_address(\n                ADDRESS_MAP[net_type]['binding'])\n            addresses = [net_addr, ip]\n            vip = get_vip_in_network(resolve_network_cidr(ip))\n            if vip:\n                addresses.append(vip)\n            if net_config:\n                req.add_entry(\n                    net_type,\n                    net_config,\n                    addresses)\n            else:\n                # There is network address with no corresponding hostname.\n                # Add the ip to the hostname cert to allow for this.\n                req.add_hostname_cn_ip(addresses)\n        except NoNetworkBinding:\n            log(\"Skipping request for certificate for ip in {} space, no \"\n                \"local address found\".format(net_type), WARNING)\n    return req.get_request()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates symlinks for the local address and the local certificate.", "response": "def create_ip_cert_links(ssl_dir, custom_hostname_link=None):\n    \"\"\"Create symlinks for SAN records\n\n    :param ssl_dir: str Directory to create symlinks in\n    :param custom_hostname_link: str Additional link to be created\n    \"\"\"\n    hostname = get_hostname(unit_get('private-address'))\n    hostname_cert = os.path.join(\n        ssl_dir,\n        'cert_{}'.format(hostname))\n    hostname_key = os.path.join(\n        ssl_dir,\n        'key_{}'.format(hostname))\n    # Add links to hostname cert, used if os-hostname vars not set\n    for net_type in [INTERNAL, ADMIN, PUBLIC]:\n        try:\n            addr = resolve_address(endpoint_type=net_type)\n            cert = os.path.join(ssl_dir, 'cert_{}'.format(addr))\n            key = os.path.join(ssl_dir, 'key_{}'.format(addr))\n            if os.path.isfile(hostname_cert) and not os.path.isfile(cert):\n                os.symlink(hostname_cert, cert)\n                os.symlink(hostname_key, key)\n        except NoNetworkBinding:\n            log(\"Skipping creating cert symlink for ip in {} space, no \"\n                \"local address found\".format(net_type), WARNING)\n    if custom_hostname_link:\n        custom_cert = os.path.join(\n            ssl_dir,\n            'cert_{}'.format(custom_hostname_link))\n        custom_key = os.path.join(\n            ssl_dir,\n            'key_{}'.format(custom_hostname_link))\n        if os.path.isfile(hostname_cert) and not os.path.isfile(custom_cert):\n            os.symlink(hostname_cert, custom_cert)\n            os.symlink(hostname_key, custom_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls the certs passed into the ssl dir and append the chain if provided.", "response": "def install_certs(ssl_dir, certs, chain=None, user='root', group='root'):\n    \"\"\"Install the certs passed into the ssl dir and append the chain if\n       provided.\n\n    :param ssl_dir: str Directory to create symlinks in\n    :param certs: {} {'cn': {'cert': 'CERT', 'key': 'KEY'}}\n    :param chain: str Chain to be appended to certs\n    :param user: (Optional) Owner of certificate files. Defaults to 'root'\n    :type user: str\n    :param group: (Optional) Group of certificate files. Defaults to 'root'\n    :type group: str\n    \"\"\"\n    for cn, bundle in certs.items():\n        cert_filename = 'cert_{}'.format(cn)\n        key_filename = 'key_{}'.format(cn)\n        cert_data = bundle['cert']\n        if chain:\n            # Append chain file so that clients that trust the root CA will\n            # trust certs signed by an intermediate in the chain\n            cert_data = cert_data + os.linesep + chain\n        write_file(\n            path=os.path.join(ssl_dir, cert_filename), owner=user, group=group,\n            content=cert_data, perms=0o640)\n        write_file(\n            path=os.path.join(ssl_dir, key_filename), owner=user, group=group,\n            content=bundle['key'], perms=0o640)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_certificates(service_name, relation_id, unit,\n                         custom_hostname_link=None, user='root', group='root'):\n    \"\"\"Process the certificates supplied down the relation\n\n    :param service_name: str Name of service the certifcates are for.\n    :param relation_id: str Relation id providing the certs\n    :param unit: str Unit providing the certs\n    :param custom_hostname_link: str Name of custom link to create\n    :param user: (Optional) Owner of certificate files. Defaults to 'root'\n    :type user: str\n    :param group: (Optional) Group of certificate files. Defaults to 'root'\n    :type group: str\n    :returns: True if certificates processed for local unit or False\n    :rtype: bool\n    \"\"\"\n    data = relation_get(rid=relation_id, unit=unit)\n    ssl_dir = os.path.join('/etc/apache2/ssl/', service_name)\n    mkdir(path=ssl_dir)\n    name = local_unit().replace('/', '_')\n    certs = data.get('{}.processed_requests'.format(name))\n    chain = data.get('chain')\n    ca = data.get('ca')\n    if certs:\n        certs = json.loads(certs)\n        install_ca_cert(ca.encode())\n        install_certs(ssl_dir, certs, chain, user=user, group=group)\n        create_ip_cert_links(\n            ssl_dir,\n            custom_hostname_link=custom_hostname_link)\n        return True\n    return False", "response": "Process the certificates supplied down the relation and create the SSL certificates."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts any certificates data targeted at this unit down relation_name.", "response": "def get_requests_for_local_unit(relation_name=None):\n    \"\"\"Extract any certificates data targeted at this unit down relation_name.\n\n    :param relation_name: str Name of relation to check for data.\n    :returns: List of bundles of certificates.\n    :rtype: List of dicts\n    \"\"\"\n    local_name = local_unit().replace('/', '_')\n    raw_certs_key = '{}.processed_requests'.format(local_name)\n    relation_name = relation_name or 'certificates'\n    bundles = []\n    for rid in relation_ids(relation_name):\n        for unit in related_units(rid):\n            data = relation_get(rid=rid, unit=unit)\n            if data.get(raw_certs_key):\n                bundles.append({\n                    'ca': data['ca'],\n                    'chain': data.get('chain'),\n                    'certs': json.loads(data[raw_certs_key])})\n    return bundles"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_bundle_for_cn(cn, relation_name=None):\n    entries = get_requests_for_local_unit(relation_name)\n    cert_bundle = {}\n    for entry in entries:\n        for _cn, bundle in entry['certs'].items():\n            if _cn == cn:\n                cert_bundle = {\n                    'cert': bundle['cert'],\n                    'key': bundle['key'],\n                    'chain': entry['chain'],\n                    'ca': entry['ca']}\n                break\n        if cert_bundle:\n            break\n    return cert_bundle", "response": "Extract certificates for the given CN and return a dictionary of certificate data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a request to the batch", "response": "def add_entry(self, net_type, cn, addresses):\n        \"\"\"Add a request to the batch\n\n        :param net_type: str netwrok space name request is for\n        :param cn: str Canonical Name for certificate\n        :param addresses: [] List of addresses to be used as SANs\n        \"\"\"\n        self.entries.append({\n            'cn': cn,\n            'addresses': addresses})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_hostname_cn(self):\n        ip = unit_get('private-address')\n        addresses = [ip]\n        # If a vip is being used without os-hostname config or\n        # network spaces then we need to ensure the local units\n        # cert has the approriate vip in the SAN list\n        vip = get_vip_in_network(resolve_network_cidr(ip))\n        if vip:\n            addresses.append(vip)\n        self.hostname_entry = {\n            'cn': get_hostname(ip),\n            'addresses': addresses}", "response": "Add a request for the hostname of the machine"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_hostname_cn_ip(self, addresses):\n        for addr in addresses:\n            if addr not in self.hostname_entry['addresses']:\n                self.hostname_entry['addresses'].append(addr)", "response": "Add an address to the SAN list for the hostname request\nMimeType"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate request from the batched up entries", "response": "def get_request(self):\n        \"\"\"Generate request from the batched up entries\n\n        \"\"\"\n        if self.hostname_entry:\n            self.entries.append(self.hostname_entry)\n        request = {}\n        for entry in self.entries:\n            sans = sorted(list(set(entry['addresses'])))\n            request[entry['cn']] = {'sans': sans}\n        if self.json_encode:\n            return {'cert_requests': json.dumps(request, sort_keys=True)}\n        else:\n            return {'cert_requests': request}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the rendered template using Python s str. format method.", "response": "def render(template, extra={}, **kwargs):\n    \"\"\"Return the template rendered using Python's str.format().\"\"\"\n    context = hookenv.execution_environment()\n    context.update(extra)\n    context.update(kwargs)\n    return template.format(**context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_audits():\n    audits = []\n    settings = utils.get_settings('os')\n\n    # Apply the sysctl settings which are configured to be applied.\n    audits.append(SysctlConf())\n    # Make sure that only root has access to the sysctl.conf file, and\n    # that it is read-only.\n    audits.append(FilePermissionAudit('/etc/sysctl.conf',\n                                      user='root',\n                                      group='root', mode=0o0440))\n    # If module loading is not enabled, then ensure that the modules\n    # file has the appropriate permissions and rebuild the initramfs\n    if not settings['security']['kernel_enable_module_loading']:\n        audits.append(ModulesTemplate())\n\n    return audits", "response": "Get OS hardening sysctl audits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the Ownership information from a file.", "response": "def _stat(file):\n    \"\"\"\n    Get the Ownership information from a file.\n\n    :param file: The path to a file to stat\n    :type file: str\n    :returns: owner, group, and mode of the specified file\n    :rtype: Ownership\n    :raises subprocess.CalledProcessError: If the underlying stat fails\n    \"\"\"\n    out = subprocess.check_output(\n        ['stat', '-c', '%U %G %a', file]).decode('utf-8')\n    return Ownership(*out.strip().split(' '))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an ini file containing a configuration.", "response": "def _config_ini(path):\n    \"\"\"\n    Parse an ini file\n\n    :param path: The path to a file to parse\n    :type file: str\n    :returns: Configuration contained in path\n    :rtype: Dict\n    \"\"\"\n    conf = configparser.ConfigParser()\n    conf.read(path)\n    return dict(conf)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_file_ownership(owner, group, file_name, optional=False):\n    try:\n        ownership = _stat(file_name)\n    except subprocess.CalledProcessError as e:\n        print(\"Error reading file: {}\".format(e))\n        if not optional:\n            assert False, \"Specified file does not exist: {}\".format(file_name)\n    assert owner == ownership.owner, \\\n        \"{} has an incorrect owner: {} should be {}\".format(\n            file_name, ownership.owner, owner)\n    assert group == ownership.group, \\\n        \"{} has an incorrect group: {} should be {}\".format(\n            file_name, ownership.group, group)\n    print(\"Validate ownership of {}: PASS\".format(file_name))", "response": "Validate that a specified file is owned by owner and group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate that a specified file has the specified permissions.", "response": "def _validate_file_mode(mode, file_name, optional=False):\n    \"\"\"\n    Validate that a specified file has the specified permissions.\n\n    :param mode: file mode that is desires\n    :type owner: str\n    :param file_name: Path to the file to verify\n    :type file_name: str\n    :param optional: Is this file optional,\n                     ie: Should this test fail when it's missing\n    :type optional: bool\n    \"\"\"\n    try:\n        ownership = _stat(file_name)\n    except subprocess.CalledProcessError as e:\n        print(\"Error reading file: {}\".format(e))\n        if not optional:\n            assert False, \"Specified file does not exist: {}\".format(file_name)\n    assert mode == ownership.mode, \\\n        \"{} has an incorrect mode: {} should be {}\".format(\n            file_name, ownership.mode, mode)\n    print(\"Validate mode of {}: PASS\".format(file_name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the configuration file and return a section.", "response": "def _config_section(config, section):\n    \"\"\"Read the configuration file and return a section.\"\"\"\n    path = os.path.join(config.get('config_path'), config.get('config_file'))\n    conf = _config_ini(path)\n    return conf.get(section)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that configuration files are owned by the correct user or group.", "response": "def validate_file_ownership(config):\n    \"\"\"Verify that configuration files are owned by the correct user/group.\"\"\"\n    files = config.get('files', {})\n    for file_name, options in files.items():\n        for key in options.keys():\n            if key not in [\"owner\", \"group\", \"mode\"]:\n                raise RuntimeError(\n                    \"Invalid ownership configuration: {}\".format(key))\n        owner = options.get('owner', config.get('owner', 'root'))\n        group = options.get('group', config.get('group', 'root'))\n        optional = options.get('optional', config.get('optional', 'False'))\n        if '*' in file_name:\n            for file in glob.glob(file_name):\n                if file not in files.keys():\n                    if os.path.isfile(file):\n                        _validate_file_ownership(owner, group, file, optional)\n        else:\n            if os.path.isfile(file_name):\n                _validate_file_ownership(owner, group, file_name, optional)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_file_permissions(config):\n    files = config.get('files', {})\n    for file_name, options in files.items():\n        for key in options.keys():\n            if key not in [\"owner\", \"group\", \"mode\"]:\n                raise RuntimeError(\n                    \"Invalid ownership configuration: {}\".format(key))\n        mode = options.get('mode', config.get('permissions', '600'))\n        optional = options.get('optional', config.get('optional', 'False'))\n        if '*' in file_name:\n            for file in glob.glob(file_name):\n                if file not in files.keys():\n                    if os.path.isfile(file):\n                        _validate_file_mode(mode, file, optional)\n        else:\n            if os.path.isfile(file_name):\n                _validate_file_mode(mode, file_name, optional)", "response": "Verify that permissions on configuration files are secure enough."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_uses_tls_for_keystone(audit_options):\n    section = _config_section(audit_options, 'keystone_authtoken')\n    assert section is not None, \"Missing section 'keystone_authtoken'\"\n    assert not section.get('insecure') and \\\n        \"https://\" in section.get(\"auth_uri\"), \\\n        \"TLS is not used for Keystone\"", "response": "Verify that TLS is used to communicate with Keystone."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_uses_tls_for_glance(audit_options):\n    section = _config_section(audit_options, 'glance')\n    assert section is not None, \"Missing section 'glance'\"\n    assert not section.get('insecure') and \\\n        \"https://\" in section.get(\"api_servers\"), \\\n        \"TLS is not used for Glance\"", "response": "Verify that TLS is used to communicate with Glance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_ready(self):\n        ready = len(self.get(self.name, [])) > 0\n        if not ready:\n            hookenv.log('Incomplete relation: {}'.format(self.__class__.__name__), hookenv.DEBUG)\n        return ready", "response": "Returns True if all of the required_keys are available from any units."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntests a set of relation data and returns True if all of the required_keys are present.", "response": "def _is_ready(self, unit_data):\n        \"\"\"\n        Helper method that tests a set of relation data and returns True if\n        all of the `required_keys` are present.\n        \"\"\"\n        return set(unit_data.keys()).issuperset(set(self.required_keys))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the relation data for each service or unit involved in a relation and store it in a list under self. name.", "response": "def get_data(self):\n        \"\"\"\n        Retrieve the relation data for each unit involved in a relation and,\n        if complete, store it in a list under `self[self.name]`.  This\n        is automatically called when the RelationContext is instantiated.\n\n        The units are sorted lexographically first by the service ID, then by\n        the unit ID.  Thus, if an interface has two other services, 'db:1'\n        and 'db:2', with 'db:1' having two units, 'wordpress/0' and 'wordpress/1',\n        and 'db:2' having one unit, 'mediawiki/0', all of which have a complete\n        set of data, the relation data for the units will be stored in the\n        order: 'wordpress/0', 'wordpress/1', 'mediawiki/0'.\n\n        If you only care about a single unit on the relation, you can just\n        access it as `{{ interface[0]['key'] }}`.  However, if you can at all\n        support multiple units on a relation, you should iterate over the list,\n        like::\n\n            {% for unit in interface -%}\n                {{ unit['key'] }}{% if not loop.last %},{% endif %}\n            {%- endfor %}\n\n        Note that since all sets of relation data from all related services and\n        units are in a single list, if you need to know which service or unit a\n        set of data came from, you'll need to extend this class to preserve\n        that information.\n        \"\"\"\n        if not hookenv.relation_ids(self.name):\n            return\n\n        ns = self.setdefault(self.name, [])\n        for rid in sorted(hookenv.relation_ids(self.name)):\n            for unit in sorted(hookenv.related_units(rid)):\n                reldata = hookenv.relation_get(rid=rid, unit=unit)\n                if self._is_ready(reldata):\n                    ns.append(reldata)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef service_restart(service_name):\n    if host.service_available(service_name):\n        if host.service_running(service_name):\n            host.service_restart(service_name)\n        else:\n            host.service_start(service_name)", "response": "Wrapper around host. service_restart to prevent spurious unknown service"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmanages the current hook by doing the Right Thing with the registered services.", "response": "def manage(self):\n        \"\"\"\n        Handle the current hook by doing The Right Thing with the registered services.\n        \"\"\"\n        hookenv._run_atstart()\n        try:\n            hook_name = hookenv.hook_name()\n            if hook_name == 'stop':\n                self.stop_services()\n            else:\n                self.reconfigure_services()\n                self.provide_data()\n        except SystemExit as x:\n            if x.code is None or x.code == 0:\n                hookenv._run_atexit()\n        hookenv._run_atexit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef provide_data(self):\n        for service_name, service in self.services.items():\n            service_ready = self.is_ready(service_name)\n            for provider in service.get('provided_data', []):\n                for relid in hookenv.relation_ids(provider.name):\n                    units = hookenv.related_units(relid)\n                    if not units:\n                        continue\n                    remote_service = units[0].split('/')[0]\n                    argspec = getargspec(provider.provide_data)\n                    if len(argspec.args) > 1:\n                        data = provider.provide_data(remote_service, service_ready)\n                    else:\n                        data = provider.provide_data()\n                    if data:\n                        hookenv.relation_set(relid, data)", "response": "Set the relation data for each provider in the provided_data list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconfigure_services(self, *service_names):\n        for service_name in service_names or self.services.keys():\n            if self.is_ready(service_name):\n                self.fire_event('data_ready', service_name)\n                self.fire_event('start', service_name, default=[\n                    service_restart,\n                    manage_ports])\n                self.save_ready(service_name)\n            else:\n                if self.was_ready(service_name):\n                    self.fire_event('data_lost', service_name)\n                self.fire_event('stop', service_name, default=[\n                    manage_ports,\n                    service_stop])\n                self.save_lost(service_name)", "response": "Updates all files for one or more services and optionally restart them if ready."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop one or more services by name.", "response": "def stop_services(self, *service_names):\n        \"\"\"\n        Stop one or more registered services, by name.\n\n        If no service names are given, stops all registered services.\n        \"\"\"\n        for service_name in service_names or self.services.keys():\n            self.fire_event('stop', service_name, default=[\n                manage_ports,\n                service_stop])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_service(self, service_name):\n        service = self.services.get(service_name)\n        if not service:\n            raise KeyError('Service not registered: %s' % service_name)\n        return service", "response": "Given the name of a registered service return its service definition."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfires an event on a given service.", "response": "def fire_event(self, event_name, service_name, default=None):\n        \"\"\"\n        Fire a data_ready, data_lost, start, or stop event on a given service.\n        \"\"\"\n        service = self.get_service(service_name)\n        callbacks = service.get(event_name, default)\n        if not callbacks:\n            return\n        if not isinstance(callbacks, Iterable):\n            callbacks = [callbacks]\n        for callback in callbacks:\n            if isinstance(callback, ManagerCallback):\n                callback(self, service_name, event_name)\n            else:\n                callback(service_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if a service is ready by checking its required_data.", "response": "def is_ready(self, service_name):\n        \"\"\"\n        Determine if a registered service is ready, by checking its 'required_data'.\n\n        A 'required_data' item can be any mapping type, and is considered ready\n        if `bool(item)` evaluates as True.\n        \"\"\"\n        service = self.get_service(service_name)\n        reqs = service.get('required_data', [])\n        return all(bool(req) for req in reqs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_ready(self, service_name):\n        self._load_ready_file()\n        self._ready.add(service_name)\n        self._save_ready_file()", "response": "Save an indicator that the given service is now data_ready."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave an indicator that the given service is no longer data_ready.", "response": "def save_lost(self, service_name):\n        \"\"\"\n        Save an indicator that the given service is no longer data_ready.\n        \"\"\"\n        self._load_ready_file()\n        self._ready.discard(service_name)\n        self._save_ready_file()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if ufw is enabled", "response": "def is_enabled():\n    \"\"\"\n    Check if `ufw` is enabled\n\n    :returns: True if ufw is enabled\n    \"\"\"\n    output = subprocess.check_output(['ufw', 'status'],\n                                     universal_newlines=True,\n                                     env={'LANG': 'en_US',\n                                          'PATH': os.environ['PATH']})\n\n    m = re.findall(r'^Status: active\\n', output, re.M)\n\n    return len(m) >= 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if IPv6 support is present and if it is loaded and if it is not raise an exception.", "response": "def is_ipv6_ok(soft_fail=False):\n    \"\"\"\n    Check if IPv6 support is present and ip6tables functional\n\n    :param soft_fail: If set to True and IPv6 support is broken, then reports\n                      that the host doesn't have IPv6 support, otherwise a\n                      UFWIPv6Error exception is raised.\n    :returns: True if IPv6 is working, False otherwise\n    \"\"\"\n\n    # do we have IPv6 in the machine?\n    if os.path.isdir('/proc/sys/net/ipv6'):\n        # is ip6tables kernel module loaded?\n        if not is_module_loaded('ip6_tables'):\n            # ip6tables support isn't complete, let's try to load it\n            try:\n                modprobe('ip6_tables')\n                # great, we can load the module\n                return True\n            except subprocess.CalledProcessError as ex:\n                hookenv.log(\"Couldn't load ip6_tables module: %s\" % ex.output,\n                            level=\"WARN\")\n                # we are in a world where ip6tables isn't working\n                if soft_fail:\n                    # so we inform that the machine doesn't have IPv6\n                    return False\n                else:\n                    raise UFWIPv6Error(\"IPv6 firewall support broken\")\n        else:\n            # the module is present :)\n            return True\n\n    else:\n        # the system doesn't have IPv6\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disable_ipv6():\n    exit_code = subprocess.call(['sed', '-i', 's/IPV6=.*/IPV6=no/g',\n                                 '/etc/default/ufw'])\n    if exit_code == 0:\n        hookenv.log('IPv6 support in ufw disabled', level='INFO')\n    else:\n        hookenv.log(\"Couldn't disable IPv6 support in ufw\", level=\"ERROR\")\n        raise UFWError(\"Couldn't disable IPv6 support in ufw\")", "response": "Disable IPv6 support in ufw"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables ufw on the current node.", "response": "def enable(soft_fail=False):\n    \"\"\"\n    Enable ufw\n\n    :param soft_fail: If set to True silently disables IPv6 support in ufw,\n                      otherwise a UFWIPv6Error exception is raised when IP6\n                      support is broken.\n    :returns: True if ufw is successfully enabled\n    \"\"\"\n    if is_enabled():\n        return True\n\n    if not is_ipv6_ok(soft_fail):\n        disable_ipv6()\n\n    output = subprocess.check_output(['ufw', 'enable'],\n                                     universal_newlines=True,\n                                     env={'LANG': 'en_US',\n                                          'PATH': os.environ['PATH']})\n\n    m = re.findall('^Firewall is active and enabled on system startup\\n',\n                   output, re.M)\n    hookenv.log(output, level='DEBUG')\n\n    if len(m) == 0:\n        hookenv.log(\"ufw couldn't be enabled\", level='WARN')\n        return False\n    else:\n        hookenv.log(\"ufw enabled\", level='INFO')\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreload ufw into a new ufw file", "response": "def reload():\n    \"\"\"\n    Reload ufw\n\n    :returns: True if ufw is successfully enabled\n    \"\"\"\n    output = subprocess.check_output(['ufw', 'reload'],\n                                     universal_newlines=True,\n                                     env={'LANG': 'en_US',\n                                          'PATH': os.environ['PATH']})\n\n    m = re.findall('^Firewall reloaded\\n',\n                   output, re.M)\n    hookenv.log(output, level='DEBUG')\n\n    if len(m) == 0:\n        hookenv.log(\"ufw couldn't be reloaded\", level='WARN')\n        return False\n    else:\n        hookenv.log(\"ufw reloaded\", level='INFO')\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchanging the default policy for the current traffic direction", "response": "def default_policy(policy='deny', direction='incoming'):\n    \"\"\"\n    Changes the default policy for traffic `direction`\n\n    :param policy: allow, deny or reject\n    :param direction: traffic direction, possible values: incoming, outgoing,\n                      routed\n    \"\"\"\n    if policy not in ['allow', 'deny', 'reject']:\n        raise UFWError(('Unknown policy %s, valid values: '\n                        'allow, deny, reject') % policy)\n\n    if direction not in ['incoming', 'outgoing', 'routed']:\n        raise UFWError(('Unknown direction %s, valid values: '\n                        'incoming, outgoing, routed') % direction)\n\n    output = subprocess.check_output(['ufw', 'default', policy, direction],\n                                     universal_newlines=True,\n                                     env={'LANG': 'en_US',\n                                          'PATH': os.environ['PATH']})\n    hookenv.log(output, level='DEBUG')\n\n    m = re.findall(\"^Default %s policy changed to '%s'\\n\" % (direction,\n                                                             policy),\n                   output, re.M)\n    if len(m) == 0:\n        hookenv.log(\"ufw couldn't change the default policy to %s for %s\"\n                    % (policy, direction), level='WARN')\n        return False\n    else:\n        hookenv.log(\"ufw default policy for %s changed to %s\"\n                    % (direction, policy), level='INFO')\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodify an access to a node or a node.", "response": "def modify_access(src, dst='any', port=None, proto=None, action='allow',\n                  index=None):\n    \"\"\"\n    Grant access to an address or subnet\n\n    :param src: address (e.g. 192.168.1.234) or subnet\n                (e.g. 192.168.1.0/24).\n    :param dst: destiny of the connection, if the machine has multiple IPs and\n                connections to only one of those have to accepted this is the\n                field has to be set.\n    :param port: destiny port\n    :param proto: protocol (tcp or udp)\n    :param action: `allow` or `delete`\n    :param index: if different from None the rule is inserted at the given\n                  `index`.\n    \"\"\"\n    if not is_enabled():\n        hookenv.log('ufw is disabled, skipping modify_access()', level='WARN')\n        return\n\n    if action == 'delete':\n        cmd = ['ufw', 'delete', 'allow']\n    elif index is not None:\n        cmd = ['ufw', 'insert', str(index), action]\n    else:\n        cmd = ['ufw', action]\n\n    if src is not None:\n        cmd += ['from', src]\n\n    if dst is not None:\n        cmd += ['to', dst]\n\n    if port is not None:\n        cmd += ['port', str(port)]\n\n    if proto is not None:\n        cmd += ['proto', proto]\n\n    hookenv.log('ufw {}: {}'.format(action, ' '.join(cmd)), level='DEBUG')\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n    (stdout, stderr) = p.communicate()\n\n    hookenv.log(stdout, level='INFO')\n\n    if p.returncode != 0:\n        hookenv.log(stderr, level='ERROR')\n        hookenv.log('Error running: {}, exit code: {}'.format(' '.join(cmd),\n                                                              p.returncode),\n                    level='ERROR')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngrant access to a source address or subnet.", "response": "def grant_access(src, dst='any', port=None, proto=None, index=None):\n    \"\"\"\n    Grant access to an address or subnet\n\n    :param src: address (e.g. 192.168.1.234) or subnet\n                (e.g. 192.168.1.0/24).\n    :param dst: destiny of the connection, if the machine has multiple IPs and\n                connections to only one of those have to accepted this is the\n                field has to be set.\n    :param port: destiny port\n    :param proto: protocol (tcp or udp)\n    :param index: if different from None the rule is inserted at the given\n                  `index`.\n    \"\"\"\n    return modify_access(src, dst=dst, port=port, proto=proto, action='allow',\n                         index=index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrevoke access to an address or subnet.", "response": "def revoke_access(src, dst='any', port=None, proto=None):\n    \"\"\"\n    Revoke access to an address or subnet\n\n    :param src: address (e.g. 192.168.1.234) or subnet\n                (e.g. 192.168.1.0/24).\n    :param dst: destiny of the connection, if the machine has multiple IPs and\n                connections to only one of those have to accepted this is the\n                field has to be set.\n    :param port: destiny port\n    :param proto: protocol (tcp or udp)\n    \"\"\"\n    return modify_access(src, dst=dst, port=port, proto=proto, action='delete')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen or close access to a service.", "response": "def service(name, action):\n    \"\"\"\n    Open/close access to a service\n\n    :param name: could be a service name defined in `/etc/services` or a port\n                 number.\n    :param action: `open` or `close`\n    \"\"\"\n    if action == 'open':\n        subprocess.check_output(['ufw', 'allow', str(name)],\n                                universal_newlines=True)\n    elif action == 'close':\n        subprocess.check_output(['ufw', 'delete', 'allow', str(name)],\n                                universal_newlines=True)\n    else:\n        raise UFWError((\"'{}' not supported, use 'allow' \"\n                        \"or 'delete'\").format(action))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a kernel module and configure for auto - load on reboot.", "response": "def modprobe(module, persist=True):\n    \"\"\"Load a kernel module and configure for auto-load on reboot.\"\"\"\n    cmd = ['modprobe', module]\n\n    log('Loading kernel module %s' % module, level=INFO)\n\n    subprocess.check_call(cmd)\n    if persist:\n        persistent_modprobe(module)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rmmod(module, force=False):\n    cmd = ['rmmod']\n    if force:\n        cmd.append('-f')\n    cmd.append(module)\n    log('Removing kernel module %s' % module, level=INFO)\n    return subprocess.check_call(cmd)", "response": "Remove a module from the linux kernel"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a kernel module is already loaded", "response": "def is_module_loaded(module):\n    \"\"\"Checks if a kernel module is already loaded\"\"\"\n    matches = re.findall('^%s[ ]+' % module, lsmod(), re.M)\n    return len(matches) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config():\n    '''Gather and sanity-check volume configuration data'''\n    volume_config = {}\n    config = hookenv.config()\n\n    errors = False\n\n    if config.get('volume-ephemeral') in (True, 'True', 'true', 'Yes', 'yes'):\n        volume_config['ephemeral'] = True\n    else:\n        volume_config['ephemeral'] = False\n\n    try:\n        volume_map = yaml.safe_load(config.get('volume-map', '{}'))\n    except yaml.YAMLError as e:\n        hookenv.log(\"Error parsing YAML volume-map: {}\".format(e),\n                    hookenv.ERROR)\n        errors = True\n    if volume_map is None:\n        # probably an empty string\n        volume_map = {}\n    elif not isinstance(volume_map, dict):\n        hookenv.log(\"Volume-map should be a dictionary, not {}\".format(\n            type(volume_map)))\n        errors = True\n\n    volume_config['device'] = volume_map.get(os.environ['JUJU_UNIT_NAME'])\n    if volume_config['device'] and volume_config['ephemeral']:\n        # asked for ephemeral storage but also defined a volume ID\n        hookenv.log('A volume is defined for this unit, but ephemeral '\n                    'storage was requested', hookenv.ERROR)\n        errors = True\n    elif not volume_config['device'] and not volume_config['ephemeral']:\n        # asked for permanent storage but did not define volume ID\n        hookenv.log('Ephemeral storage was requested, but there is no volume '\n                    'defined for this unit.', hookenv.ERROR)\n        errors = True\n\n    unit_mount_name = hookenv.local_unit().replace('/', '-')\n    volume_config['mountpoint'] = os.path.join(MOUNT_BASE, unit_mount_name)\n\n    if errors:\n        return None\n    return volume_config", "response": "Gather and sanity - check volume configuration data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring storage based on the charm s volume configuration.", "response": "def configure_volume(before_change=lambda: None, after_change=lambda: None):\n    '''Set up storage (or don't) according to the charm's volume configuration.\n       Returns the mount point or \"ephemeral\". before_change and after_change\n       are optional functions to be called if the volume configuration changes.\n    '''\n\n    config = get_config()\n    if not config:\n        hookenv.log('Failed to read volume configuration', hookenv.CRITICAL)\n        raise VolumeConfigurationError()\n\n    if config['ephemeral']:\n        if os.path.ismount(config['mountpoint']):\n            before_change()\n            unmount_volume(config)\n            after_change()\n        return 'ephemeral'\n    else:\n        # persistent storage\n        if os.path.ismount(config['mountpoint']):\n            mounts = dict(managed_mounts())\n            if mounts.get(config['mountpoint']) != config['device']:\n                before_change()\n                unmount_volume(config)\n                mount_volume(config)\n                after_change()\n        else:\n            before_change()\n            mount_volume(config)\n            after_change()\n        return config['mountpoint']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_audits():\n    audits = []\n    settings = utils.get_settings('os')\n\n    # Ensure that the /etc/security/limits.d directory is only writable\n    # by the root user, but others can execute and read.\n    audits.append(DirectoryPermissionAudit('/etc/security/limits.d',\n                                           user='root', group='root',\n                                           mode=0o755))\n\n    # If core dumps are not enabled, then don't allow core dumps to be\n    # created as they may contain sensitive information.\n    if not settings['security']['kernel_enable_core_dump']:\n        audits.append(TemplatedFile('/etc/security/limits.d/10.hardcore.conf',\n                                    SecurityLimitsContext(),\n                                    template_dir=TEMPLATES_DIR,\n                                    user='root', group='root', mode=0o0440))\n    return audits", "response": "Get OS hardening security limits audits."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _take_action(self):\n        # Do the action if there isn't an unless override.\n        if self.unless is None:\n            return True\n\n        # Invoke the callback if there is one.\n        if hasattr(self.unless, '__call__'):\n            return not self.unless()\n\n        return not self.unless", "response": "Determines whether to perform the action or not."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_packages(packages):\n    required = filter_installed_packages(packages)\n    if required:\n        apt_install(required, fatal=True)", "response": "Install but do not upgrade required plugin packages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _calculate_workers():\n    '''\n    Determine the number of worker processes based on the CPU\n    count of the unit containing the application.\n\n    Workers will be limited to MAX_DEFAULT_WORKERS in\n    container environments where no worker-multipler configuration\n    option been set.\n\n    @returns int: number of worker processes to use\n    '''\n    multiplier = config('worker-multiplier') or DEFAULT_MULTIPLIER\n    count = int(_num_cpus() * multiplier)\n    if multiplier > 0 and count == 0:\n        count = 1\n\n    if config('worker-multiplier') is None and is_container():\n        # NOTE(jamespage): Limit unconfigured worker-multiplier\n        #                  to MAX_DEFAULT_WORKERS to avoid insane\n        #                  worker configuration in LXD containers\n        #                  on large servers\n        # Reference: https://pad.lv/1665270\n        count = min(count, MAX_DEFAULT_WORKERS)\n\n    return count", "response": "Calculates the number of worker processes based on the CPU\n    count of the application containing the application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef context_complete(self, ctxt):\n        # Fresh start\n        self.complete = False\n        self.missing_data = []\n        for k, v in six.iteritems(ctxt):\n            if v is None or v == '':\n                if k not in self.missing_data:\n                    self.missing_data.append(k)\n\n        if self.missing_data:\n            self.complete = False\n            log('Missing required data: %s' % ' '.join(self.missing_data),\n                level=INFO)\n        else:\n            self.complete = True\n        return self.complete", "response": "Check for missing data for the required context data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if any of the context interfaces have relation ids. Set self. related and return True if any of the context interfaces have relation ids.", "response": "def get_related(self):\n        \"\"\"Check if any of the context interfaces have relation ids.\n        Set self.related and return True if one of the interfaces\n        has relation ids.\n        \"\"\"\n        # Fresh start\n        self.related = False\n        try:\n            for interface in self.interfaces:\n                if relation_ids(interface):\n                    self.related = True\n            return self.related\n        except AttributeError as e:\n            log(\"{} {}\"\n                \"\".format(self, e), 'INFO')\n            return self.related"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef canonical_names(self):\n        cns = []\n        for r_id in relation_ids('identity-service'):\n            for unit in related_units(r_id):\n                rdata = relation_get(rid=r_id, unit=unit)\n                for k in rdata:\n                    if k.startswith('ssl_key_'):\n                        cns.append(k.lstrip('ssl_key_'))\n\n        return sorted(list(set(cns)))", "response": "Figure out which canonical names clients will access this service."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of addresses that are configured for each network.", "response": "def get_network_addresses(self):\n        \"\"\"For each network configured, return corresponding address and\n           hostnamr or vip (if available).\n\n        Returns a list of tuples of the form:\n\n            [(address_in_net_a, hostname_in_net_a),\n             (address_in_net_b, hostname_in_net_b),\n             ...]\n\n            or, if no hostnames(s) available:\n\n            [(address_in_net_a, vip_in_net_a),\n             (address_in_net_b, vip_in_net_b),\n             ...]\n\n            or, if no vip(s) available:\n\n            [(address_in_net_a, address_in_net_a),\n             (address_in_net_b, address_in_net_b),\n             ...]\n        \"\"\"\n        addresses = []\n        for net_type in [INTERNAL, ADMIN, PUBLIC]:\n            net_config = config(ADDRESS_MAP[net_type]['config'])\n            # NOTE(jamespage): Fallback must always be private address\n            #                  as this is used to bind services on the\n            #                  local unit.\n            fallback = unit_get(\"private-address\")\n            if net_config:\n                addr = get_address_in_network(net_config,\n                                              fallback)\n            else:\n                try:\n                    addr = network_get_primary_address(\n                        ADDRESS_MAP[net_type]['binding']\n                    )\n                except (NotImplementedError, NoNetworkBinding):\n                    addr = fallback\n\n            endpoint = resolve_address(net_type)\n            addresses.append((addr, endpoint))\n\n        return sorted(set(addresses))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve_ports(self, ports):\n        if not ports:\n            return None\n\n        hwaddr_to_nic = {}\n        hwaddr_to_ip = {}\n        for nic in list_nics():\n            # Ignore virtual interfaces (bond masters will be identified from\n            # their slaves)\n            if not is_phy_iface(nic):\n                continue\n\n            _nic = get_bond_master(nic)\n            if _nic:\n                log(\"Replacing iface '%s' with bond master '%s'\" % (nic, _nic),\n                    level=DEBUG)\n                nic = _nic\n\n            hwaddr = get_nic_hwaddr(nic)\n            hwaddr_to_nic[hwaddr] = nic\n            addresses = get_ipv4_addr(nic, fatal=False)\n            addresses += get_ipv6_addr(iface=nic, fatal=False)\n            hwaddr_to_ip[hwaddr] = addresses\n\n        resolved = []\n        mac_regex = re.compile(r'([0-9A-F]{2}[:-]){5}([0-9A-F]{2})', re.I)\n        for entry in ports:\n            if re.match(mac_regex, entry):\n                # NIC is in known NICs and does NOT hace an IP address\n                if entry in hwaddr_to_nic and not hwaddr_to_ip[entry]:\n                    # If the nic is part of a bridge then don't use it\n                    if is_bridge_member(hwaddr_to_nic[entry]):\n                        continue\n\n                    # Entry is a MAC address for a valid interface that doesn't\n                    # have an IP address assigned yet.\n                    resolved.append(hwaddr_to_nic[entry])\n            else:\n                # If the passed entry is not a MAC address, assume it's a valid\n                # interface, and that the user put it there on purpose (we can\n                # trust it to be the real external network).\n                resolved.append(entry)\n\n        # Ensure no duplicates\n        return list(set(resolved))", "response": "Resolve NICs not yet bound to bridge."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _determine_ctxt(self):\n        rel = os_release(self.pkg, base='icehouse')\n        version = '2'\n        if CompareOpenStackReleases(rel) >= 'pike':\n            version = '3'\n\n        service_type = 'volumev{version}'.format(version=version)\n        service_name = 'cinderv{version}'.format(version=version)\n        endpoint_type = 'publicURL'\n        if config('use-internal-endpoints'):\n            endpoint_type = 'internalURL'\n        catalog_info = '{type}:{name}:{endpoint}'.format(\n            type=service_type, name=service_name, endpoint=endpoint_type)\n\n        return {\n            'volume_api_version': version,\n            'volume_catalog_info': catalog_info,\n        }", "response": "Determines the appropriate version of the API that should be used\n        and returns the appropriate version of the API that should be used\n        and the catalog_info string that would be supplied."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _determine_ctxt(self):\n        if config('aa-profile-mode') in ['disable', 'enforce', 'complain']:\n            ctxt = {'aa_profile_mode': config('aa-profile-mode'),\n                    'ubuntu_release': lsb_release()['DISTRIB_RELEASE']}\n            if self.aa_profile:\n                ctxt['aa_profile'] = self.aa_profile\n        else:\n            ctxt = None\n        return ctxt", "response": "Determine the aa - profile - mode settings and return a dictionary of the apparmor profile or None if not set."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a list of full paths to modules within execd_dir.", "response": "def execd_module_paths(execd_dir=None):\n    \"\"\"Generate a list of full paths to modules within execd_dir.\"\"\"\n    if not execd_dir:\n        execd_dir = default_execd_dir()\n\n    if not os.path.exists(execd_dir):\n        return\n\n    for subpath in os.listdir(execd_dir):\n        module = os.path.join(execd_dir, subpath)\n        if os.path.isdir(module):\n            yield module"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a list of full paths to the specified command within execd_dir.", "response": "def execd_submodule_paths(command, execd_dir=None):\n    \"\"\"Generate a list of full paths to the specified command within exec_dir.\n    \"\"\"\n    for module_path in execd_module_paths(execd_dir):\n        path = os.path.join(module_path, command)\n        if os.access(path, os.X_OK) and os.path.isfile(path):\n            yield path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun command for each module within execd_dir.", "response": "def execd_run(command, execd_dir=None, die_on_error=True, stderr=subprocess.STDOUT):\n    \"\"\"Run command for each module within execd_dir which defines it.\"\"\"\n    for submodule_path in execd_submodule_paths(command, execd_dir):\n        try:\n            subprocess.check_output(submodule_path, stderr=stderr,\n                                    universal_newlines=True)\n        except subprocess.CalledProcessError as e:\n            hookenv.log(\"Error ({}) running  {}. Output: {}\".format(\n                e.returncode, e.cmd, e.output))\n            if die_on_error:\n                sys.exit(e.returncode)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a range of keys starting with a common prefix as a mapping of key - value pairs.", "response": "def getrange(self, key_prefix, strip=False):\n        \"\"\"\n        Get a range of keys starting with a common prefix as a mapping of\n        keys to values.\n\n        :param str key_prefix: Common prefix among all keys\n        :param bool strip: Optionally strip the common prefix from the key\n            names in the returned dict\n        :return dict: A (possibly empty) dict of key-value mappings\n        \"\"\"\n        self.cursor.execute(\"select key, data from kv where key like ?\",\n                            ['%s%%' % key_prefix])\n        result = self.cursor.fetchall()\n\n        if not result:\n            return {}\n        if not strip:\n            key_prefix = ''\n        return dict([\n            (k[len(key_prefix):], json.loads(v)) for k, v in result])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the values of multiple keys at once.", "response": "def update(self, mapping, prefix=\"\"):\n        \"\"\"\n        Set the values of multiple keys at once.\n\n        :param dict mapping: Mapping of keys to values\n        :param str prefix: Optional prefix to apply to all keys in `mapping`\n            before setting\n        \"\"\"\n        for k, v in mapping.items():\n            self.set(\"%s%s\" % (prefix, k), v)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unset(self, key):\n        self.cursor.execute('delete from kv where key=?', [key])\n        if self.revision and self.cursor.rowcount:\n            self.cursor.execute(\n                'insert into kv_revisions values (?, ?, ?)',\n                [key, self.revision, json.dumps('DELETED')])", "response": "Remove a key from the database entirely."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a range of keys starting with a common prefix from the database entirely.", "response": "def unsetrange(self, keys=None, prefix=\"\"):\n        \"\"\"\n        Remove a range of keys starting with a common prefix, from the database\n        entirely.\n\n        :param list keys: List of keys to remove.\n        :param str prefix: Optional prefix to apply to all keys in ``keys``\n            before removing.\n        \"\"\"\n        if keys is not None:\n            keys = ['%s%s' % (prefix, key) for key in keys]\n            self.cursor.execute('delete from kv where key in (%s)' % ','.join(['?'] * len(keys)), keys)\n            if self.revision and self.cursor.rowcount:\n                self.cursor.execute(\n                    'insert into kv_revisions values %s' % ','.join(['(?, ?, ?)'] * len(keys)),\n                    list(itertools.chain.from_iterable((key, self.revision, json.dumps('DELETED')) for key in keys)))\n        else:\n            self.cursor.execute('delete from kv where key like ?',\n                                ['%s%%' % prefix])\n            if self.revision and self.cursor.rowcount:\n                self.cursor.execute(\n                    'insert into kv_revisions values (?, ?, ?)',\n                    ['%s%%' % prefix, self.revision, json.dumps('DELETED')])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, key, value):\n        serialized = json.dumps(value)\n\n        self.cursor.execute('select data from kv where key=?', [key])\n        exists = self.cursor.fetchone()\n\n        # Skip mutations to the same value\n        if exists:\n            if exists[0] == serialized:\n                return value\n\n        if not exists:\n            self.cursor.execute(\n                'insert into kv (key, data) values (?, ?)',\n                (key, serialized))\n        else:\n            self.cursor.execute('''\n            update kv\n            set data = ?\n            where key = ?''', [serialized, key])\n\n        # Save\n        if not self.revision:\n            return value\n\n        self.cursor.execute(\n            'select 1 from kv_revisions where key=? and revision=?',\n            [key, self.revision])\n        exists = self.cursor.fetchone()\n\n        if not exists:\n            self.cursor.execute(\n                '''insert into kv_revisions (\n                revision, key, data) values (?, ?, ?)''',\n                (self.revision, key, serialized))\n        else:\n            self.cursor.execute(\n                '''\n                update kv_revisions\n                set data = ?\n                where key = ?\n                and   revision = ?''',\n                [serialized, key, self.revision])\n\n        return value", "response": "Set a value for the key in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a delta containing values that have changed.", "response": "def delta(self, mapping, prefix):\n        \"\"\"\n        return a delta containing values that have changed.\n        \"\"\"\n        previous = self.getrange(prefix, strip=True)\n        if not previous:\n            pk = set()\n        else:\n            pk = set(previous.keys())\n        ck = set(mapping.keys())\n        delta = DeltaSet()\n\n        # added\n        for k in ck.difference(pk):\n            delta[k] = Delta(None, mapping[k])\n\n        # removed\n        for k in pk.difference(ck):\n            delta[k] = Delta(previous[k], None)\n\n        # changed\n        for k in pk.intersection(ck):\n            c = mapping[k]\n            p = previous[k]\n            if c != p:\n                delta[k] = Delta(p, c)\n\n        return delta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscope all future interactions to the current hook execution revision.", "response": "def hook_scope(self, name=\"\"):\n        \"\"\"Scope all future interactions to the current hook execution\n        revision.\"\"\"\n        assert not self.revision\n        self.cursor.execute(\n            'insert into hooks (hook, date) values (?, ?)',\n            (name or sys.argv[0],\n             datetime.datetime.utcnow().isoformat()))\n        self.revision = self.cursor.lastrowid\n        try:\n            yield self.revision\n            self.revision = None\n        except Exception:\n            self.flush(False)\n            self.revision = None\n            raise\n        else:\n            self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the named bridge to openvswitch", "response": "def add_bridge(name, datapath_type=None):\n    ''' Add the named bridge to openvswitch '''\n    log('Creating bridge {}'.format(name))\n    cmd = [\"ovs-vsctl\", \"--\", \"--may-exist\", \"add-br\", name]\n    if datapath_type is not None:\n        cmd += ['--', 'set', 'bridge', name,\n                'datapath_type={}'.format(datapath_type)]\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a port to the named openvswitch bridge", "response": "def add_bridge_port(name, port, promisc=False):\n    ''' Add a port to the named openvswitch bridge '''\n    log('Adding port {} to bridge {}'.format(port, name))\n    subprocess.check_call([\"ovs-vsctl\", \"--\", \"--may-exist\", \"add-port\",\n                           name, port])\n    subprocess.check_call([\"ip\", \"link\", \"set\", port, \"up\"])\n    if promisc:\n        subprocess.check_call([\"ip\", \"link\", \"set\", port, \"promisc\", \"on\"])\n    else:\n        subprocess.check_call([\"ip\", \"link\", \"set\", port, \"promisc\", \"off\"])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a port from an openvswitch bridge", "response": "def del_bridge_port(name, port):\n    ''' Delete a port from the named openvswitch bridge '''\n    log('Deleting port {} from bridge {}'.format(port, name))\n    subprocess.check_call([\"ovs-vsctl\", \"--\", \"--if-exists\", \"del-port\",\n                           name, port])\n    subprocess.check_call([\"ip\", \"link\", \"set\", port, \"down\"])\n    subprocess.check_call([\"ip\", \"link\", \"set\", port, \"promisc\", \"off\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a Linux bridge to the named openvswitch bridge .", "response": "def add_ovsbridge_linuxbridge(name, bridge):\n    ''' Add linux bridge to the named openvswitch bridge\n    :param name: Name of ovs bridge to be added to Linux bridge\n    :param bridge: Name of Linux bridge to be added to ovs bridge\n    :returns: True if veth is added between ovs bridge and linux bridge,\n    False otherwise'''\n    try:\n        import netifaces\n    except ImportError:\n        if six.PY2:\n            apt_install('python-netifaces', fatal=True)\n        else:\n            apt_install('python3-netifaces', fatal=True)\n        import netifaces\n\n    # NOTE(jamespage):\n    # Older code supported addition of a linuxbridge directly\n    # to an OVS bridge; ensure we don't break uses on upgrade\n    existing_ovs_bridge = port_to_br(bridge)\n    if existing_ovs_bridge is not None:\n        log('Linuxbridge {} is already directly in use'\n            ' by OVS bridge {}'.format(bridge, existing_ovs_bridge),\n            level=INFO)\n        return\n\n    # NOTE(jamespage):\n    # preserve existing naming because interfaces may already exist.\n    ovsbridge_port = \"veth-\" + name\n    linuxbridge_port = \"veth-\" + bridge\n    if (len(ovsbridge_port) > MAX_KERNEL_INTERFACE_NAME_LEN or\n            len(linuxbridge_port) > MAX_KERNEL_INTERFACE_NAME_LEN):\n        # NOTE(jamespage):\n        # use parts of hashed bridgename (openstack style) when\n        # a bridge name exceeds 15 chars\n        hashed_bridge = hashlib.sha256(bridge.encode('UTF-8')).hexdigest()\n        base = '{}-{}'.format(hashed_bridge[:8], hashed_bridge[-2:])\n        ovsbridge_port = \"cvo{}\".format(base)\n        linuxbridge_port = \"cvb{}\".format(base)\n\n    interfaces = netifaces.interfaces()\n    for interface in interfaces:\n        if interface == ovsbridge_port or interface == linuxbridge_port:\n            log('Interface {} already exists'.format(interface), level=INFO)\n            return\n\n    log('Adding linuxbridge {} to ovsbridge {}'.format(bridge, name),\n        level=INFO)\n\n    check_for_eni_source()\n\n    with open('/etc/network/interfaces.d/{}.cfg'.format(\n            linuxbridge_port), 'w') as config:\n        config.write(BRIDGE_TEMPLATE.format(linuxbridge_port=linuxbridge_port,\n                                            ovsbridge_port=ovsbridge_port,\n                                            bridge=bridge))\n\n    subprocess.check_call([\"ifup\", linuxbridge_port])\n    add_bridge_port(name, linuxbridge_port)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_linuxbridge_interface(port):\n    ''' Check if the interface is a linuxbridge bridge\n    :param port: Name of an interface to check whether it is a Linux bridge\n    :returns: True if port is a Linux bridge'''\n\n    if os.path.exists('/sys/class/net/' + port + '/bridge'):\n        log('Interface {} is a Linux bridge'.format(port), level=DEBUG)\n        return True\n    else:\n        log('Interface {} is not a Linux bridge'.format(port), level=DEBUG)\n        return False", "response": "Check if the interface is a Linux bridge"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_certificate():\n    ''' Read openvswitch certificate from disk '''\n    if os.path.exists(CERT_PATH):\n        log('Reading ovs certificate from {}'.format(CERT_PATH))\n        with open(CERT_PATH, 'r') as cert:\n            full_cert = cert.read()\n            begin_marker = \"-----BEGIN CERTIFICATE-----\"\n            end_marker = \"-----END CERTIFICATE-----\"\n            begin_index = full_cert.find(begin_marker)\n            end_index = full_cert.rfind(end_marker)\n            if end_index == -1 or begin_index == -1:\n                raise RuntimeError(\"Certificate does not contain valid begin\"\n                                   \" and end markers.\")\n            full_cert = full_cert[begin_index:(end_index + len(end_marker))]\n            return full_cert\n    else:\n        log('Certificate not found', level=WARNING)\n        return None", "response": "Read openvswitch certificate from disk"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the source line is set for the interfaces.", "response": "def check_for_eni_source():\n    ''' Juju removes the source line when setting up interfaces,\n    replace if missing '''\n\n    with open('/etc/network/interfaces', 'r') as eni:\n        for line in eni:\n            if line == 'source /etc/network/interfaces.d/*':\n                return\n    with open('/etc/network/interfaces', 'a') as eni:\n        eni.write('\\nsource /etc/network/interfaces.d/*')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables IPfix on bridge to target.", "response": "def enable_ipfix(bridge, target):\n    '''Enable IPfix on bridge to target.\n    :param bridge: Bridge to monitor\n    :param target: IPfix remote endpoint\n    '''\n    cmd = ['ovs-vsctl', 'set', 'Bridge', bridge, 'ipfix=@i', '--',\n           '--id=@i', 'create', 'IPFIX', 'targets=\"{}\"'.format(target)]\n    log('Enabling IPfix on {}.'.format(bridge))\n    subprocess.check_call(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_package(self, cache, pkg):\n        if self.is_virtual_package(pkg):\n            log(\"Package '%s' appears to be virtual - purging provides\" %\n                pkg.name, level=DEBUG)\n            for _p in pkg.provides_list:\n                self.delete_package(cache, _p[2].parent_pkg)\n        elif not pkg.current_ver:\n            log(\"Package '%s' not installed\" % pkg.name, level=DEBUG)\n            return\n        else:\n            log(\"Purging package '%s'\" % pkg.name, level=DEBUG)\n            apt_purge(pkg.name)", "response": "Deletes the package from the system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_ip_address(self, request):\n        ipaddr = request.META.get(\"HTTP_X_FORWARDED_FOR\", None)\n        if ipaddr:\n            # X_FORWARDED_FOR returns client1, proxy1, proxy2,...\n            return ipaddr.split(\",\")[0].strip()\n        return request.META.get(\"REMOTE_ADDR\", \"\")", "response": "Get the remote ip address of the request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the duration of the request response cycle is milliseconds.", "response": "def _get_response_ms(self):\n        \"\"\"\n        Get the duration of the request response cycle is milliseconds.\n        In case of negative duration 0 is returned.\n        \"\"\"\n        response_timedelta = now() - self.log['requested_at']\n        response_ms = int(response_timedelta.total_seconds() * 1000)\n        return max(response_ms, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef should_log(self, request, response):\n        return self.logging_methods == '__all__' or request.method in self.logging_methods", "response": "Returns True if the request should be logged False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning a dictionary of data of potentially sensitive info before sending to the database.", "response": "def _clean_data(self, data):\n        \"\"\"\n        Clean a dictionary of data of potentially sensitive info before\n        sending to the database.\n        Function based on the \"_clean_credentials\" function of django\n        (https://github.com/django/django/blob/stable/1.11.x/django/contrib/auth/__init__.py#L50)\n\n        Fields defined by django are by default cleaned with this function\n\n        You can define your own sensitive fields in your view by defining a set\n        eg: sensitive_fields = {'field1', 'field2'}\n        \"\"\"\n        if isinstance(data, bytes):\n            data = data.decode(errors='replace')\n\n        if isinstance(data, list):\n            return [self._clean_data(d) for d in data]\n        if isinstance(data, dict):\n            SENSITIVE_FIELDS = {'api', 'token', 'key', 'secret', 'password', 'signature'}\n\n            data = dict(data)\n            if self.sensitive_fields:\n                SENSITIVE_FIELDS = SENSITIVE_FIELDS | {field.lower() for field in self.sensitive_fields}\n\n            for key, value in data.items():\n                try:\n                    value = ast.literal_eval(value)\n                except (ValueError, SyntaxError):\n                    pass\n                if isinstance(value, list) or isinstance(value, dict):\n                    data[key] = self._clean_data(value)\n                if key.lower() in SENSITIVE_FIELDS:\n                    data[key] = self.CLEANED_SUBSTITUTE\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntraces the exception and returns it", "response": "def trace():\n    \"\"\"\n        trace finds the line, the filename\n        and error message and returns it\n        to the user\n    \"\"\"\n    import traceback\n    import sys\n    tb = sys.exc_info()[2]\n    tbinfo = traceback.format_tb(tb)[0]\n    # script name + line number\n    line = tbinfo.split(\", \")[1]\n    # Get Python syntax error\n    #\n    synerror = traceback.format_exc().splitlines()[-1]\n    return line, __file__, synerror"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(*argv):\n    try:\n        #   Inputs\n        #\n        adminUsername = argv[0]\n        adminPassword = argv[1]\n        siteURL = argv[2]\n        username = argv[3]\n        itemId = argv[4]\n        folderId = argv[5]\n        #   Logic\n        #\n        sh = arcrest.AGOLTokenSecurityHandler(adminUsername, adminPassword)\n        admin = arcrest.manageorg.Administration(url=siteURL,\n                                                 securityHandler=sh)\n        content = admin.content\n        #if isinstance(content, arcrest.manageorg._content.Content): pass\n        usercontent = content.usercontent(username=username)\n        if folderId is None or \\\n           folderId == \"\":\n            res = usercontent.deleteItem(item_id=itemId)\n        else:\n            res =  usercontent.deleteItem(item_id=itemId, folder=folderId)\n        arcpy.SetParameterAsText(6, str(res))\n    except arcpy.ExecuteError:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)\n        arcpy.AddError(\"ArcPy Error Message: %s\" % arcpy.GetMessages(2))\n    except FunctionError, f_e:\n        messages = f_e.args[0]\n        arcpy.AddError(\"error in function: %s\" % messages[\"function\"])\n        arcpy.AddError(\"error on line: %s\" % messages[\"line\"])\n        arcpy.AddError(\"error in file name: %s\" % messages[\"filename\"])\n        arcpy.AddError(\"with error message: %s\" % messages[\"synerror\"])\n        arcpy.AddError(\"ArcPy Error Message: %s\" % messages[\"arc\"])\n    except:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)", "response": "main driver of program"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_dicts(dicts, op=operator.add):\n    a = None\n    for b in dicts:\n\n        if a is None:\n            a = b.copy()\n        else:\n            a = dict(a.items() + b.items() + [(k, op(a[k], b[k])) for k in set(b) & set(a)])\n    return a", "response": "Merge a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getLayerIndex(url):\n    urlInfo = None\n    urlSplit = None\n    inx = None\n    try:\n        urlInfo = urlparse.urlparse(url)\n        urlSplit = str(urlInfo.path).split('/')\n        inx = urlSplit[len(urlSplit)-1]\n\n        if is_number(inx):\n            return int(inx)\n\n    except:\n        return 0\n    finally:\n        urlInfo = None\n        urlSplit = None\n\n        del urlInfo\n        del urlSplit\n\n        gc.collect()", "response": "Extract the layer index from a url."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the layer name from a url.", "response": "def getLayerName(url):\n    \"\"\"Extract the layer name from a url.\n\n    Args:\n        url (str): The url to parse.\n\n    Returns:\n        str: The layer name.\n\n    Examples:\n        >>> url = \"http://services.arcgis.com/<random>/arcgis/rest/services/test/FeatureServer/12\"\n        >>> arcresthelper.common.getLayerIndex(url)\n        'test'\n\n    \"\"\"\n    urlInfo = None\n    urlSplit = None\n    try:\n        urlInfo = urlparse.urlparse(url)\n        urlSplit = str(urlInfo.path).split('/')\n        name = urlSplit[len(urlSplit)-3]\n        return name\n    except:\n        return url\n\n    finally:\n        urlInfo = None\n        urlSplit = None\n\n        del urlInfo\n        del urlSplit\n\n        gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a random string from a set of characters.", "response": "def random_string_generator(size=6, chars=string.ascii_uppercase):\n    \"\"\"Generates a random string from a set of characters.\n\n    Args:\n        size (int): The length of the resultant string. Defaults to 6.\n        chars (str): The characters to be used by :py:func:`random.choice`. Defaults to :py:const:`string.ascii_uppercase`.\n\n    Returns:\n        str: The randomly generated string.\n\n    Examples:\n        >>> arcresthelper.common.random_string_generator()\n        'DCNYWU'\n        >>> arcresthelper.common.random_string_generator(12, \"arcREST\")\n        'cESaTTEacTES'\n\n    \"\"\"\n    try:\n        return ''.join(random.choice(chars) for _ in range(size))\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"random_string_generator\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_int_generator(maxrange):\n    try:\n        return random.randint(0,maxrange)\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"random_int_generator\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        pass", "response": "Returns a random integer from 0 to maxrange inclusive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a datetime object to a UTC timestamp for AGOL.", "response": "def local_time_to_online(dt=None):\n    \"\"\"Converts datetime object to a UTC timestamp for AGOL.\n\n    Args:\n        dt (datetime): The :py:class:`datetime.datetime` object to convert. Defaults to ``None``, i.e., :py:func:`datetime.datetime.now`.\n\n    Returns:\n        float: A UTC timestamp as understood by AGOL (time in ms since Unix epoch * 1000)\n\n    Examples:\n        >>> arcresthelper.common.local_time_to_online() # PST\n        1457167261000.0\n        >>> dt = datetime.datetime(1993, 3, 5, 12, 35, 15) # PST\n        >>> arcresthelper.common.local_time_to_online(dt)\n        731392515000.0\n    See Also:\n       :py:func:`online_time_to_string` for converting a UTC timestamp\n\n    \"\"\"\n    is_dst = None\n    utc_offset = None\n    try:\n        if dt is None:\n            dt = datetime.datetime.now()\n\n        is_dst = time.daylight > 0 and time.localtime().tm_isdst > 0\n        utc_offset =  (time.altzone if is_dst else time.timezone)\n\n        return (time.mktime(dt.timetuple()) * 1000) + (utc_offset * 1000)\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"local_time_to_online\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        is_dst = None\n        utc_offset = None\n\n        del is_dst\n        del utc_offset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an online timestamp to a string.", "response": "def online_time_to_string(value, timeFormat, utcOffset=0):\n    \"\"\"Converts AGOL timestamp to formatted string.\n\n    Args:\n        value (float): A UTC timestamp as reported by AGOL (time in ms since Unix epoch * 1000)\n        timeFormat (str): Date/Time format string as parsed by :py:func:`datetime.strftime`.\n        utcOffset (int): Hours difference from UTC and desired output. Default is 0 (remain in UTC).\n\n    Returns:\n        str: A string representation of the timestamp.\n\n    Examples:\n        >>> arcresthelper.common.online_time_to_string(1457167261000.0, \"%Y-%m-%d %H:%M:%S\")\n        '2016-03-05 00:41:01'\n        >>> arcresthelper.common.online_time_to_string(731392515000.0, '%m/%d/%Y %H:%M:%S', -8) # PST is UTC-8:00\n        '03/05/1993 12:35:15'\n\n    See Also:\n       :py:func:`local_time_to_online` for converting a :py:class:`datetime.datetime` object to AGOL timestamp\n\n    \"\"\"\n\n    try:\n        return datetime.datetime.fromtimestamp(value/1000 + utcOffset*3600).strftime(timeFormat)\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"online_time_to_string\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the input is numeric.", "response": "def is_number(s):\n    \"\"\"Determines if the input is numeric\n\n    Args:\n        s: The value to check.\n    Returns:\n        bool: ``True`` if the input is numeric, ``False`` otherwise.\n\n    \"\"\"\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_config_json(config_file, data):\n    outfile = None\n    try:\n        with open(config_file, 'w') as outfile:\n            json.dump(data, outfile)\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"init_config_json\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        outfile = None\n\n        del outfile\n\n        gc.collect()", "response": "Serializes an object to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unicode_convert(obj):\n    try:\n        if isinstance(obj, dict):\n            return {unicode_convert(key): unicode_convert(value) for key, value in obj.items()}\n        elif isinstance(obj, list):\n            return [unicode_convert(element) for element in obj]\n        elif isinstance(obj, str):\n            return obj \n        elif isinstance(obj, six.text_type):\n            return obj.encode('utf-8')\n        elif isinstance(obj, six.integer_types):\n            return obj\n        else:\n            return obj\n    except:\n        return obj", "response": "Converts unicode objects to anscii."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a string. replace() on the input object.", "response": "def find_replace_string(obj, find, replace):\n    \"\"\"Performs a string.replace() on the input object.\n\n    Args:\n        obj (object): The object to find/replace. It will be cast to ``str``.\n        find (str): The string to search for.\n        replace (str): The string to replace with.\n    Returns:\n        str: The replaced string.\n\n    \"\"\"\n    try:\n        strobj = str(obj)\n        newStr =  string.replace(strobj, find, replace)\n        if newStr == strobj:\n            return obj\n        else:\n            return newStr\n\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"find_replace_string\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_replace(obj, find, replace):\n    try:\n        if isinstance(obj, dict):\n            return {find_replace(key,find,replace): find_replace(value,find,replace) for key, value in obj.items()}\n        elif isinstance(obj, list):\n            return [find_replace(element,find,replace) for element in obj]\n        elif obj == find:\n            return unicode_convert(replace)\n        else:\n            try:\n                return unicode_convert(find_replace_string(obj, find, replace))\n                #obj = unicode_convert(json.loads(obj))\n                #return find_replace(obj,find,replace)\n            except:\n                return unicode_convert(obj)\n    except:\n        line, filename, synerror = trace()\n        raise ArcRestHelperError({\n                    \"function\": \"find_replace\",\n                    \"line\": line,\n                    \"filename\":  filename,\n                    \"synerror\": synerror,\n                                    }\n                                    )\n    finally:\n        pass", "response": "Searches an object and performs a find and replace."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef chunklist(l, n):\n    n = max(1, n)\n    for i in range(0, len(l), n):\n        yield l[i:i+n]", "response": "Yield successive n - sized chunks from l."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_log(log_file):\n    #Create the log file\n    log = None\n    try:\n        log = open(log_file, 'a')\n\n        #Change the output to both the windows and log file\n        #original = sys.stdout\n        sys.stdout = Tee(sys.stdout, log)\n    except:\n        pass\n    return log", "response": "Creates a log file on disk and Tees to console and disk\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_log(log_file):\n    sys.stdout = sys.__stdout__\n    if log_file is not None:\n        log_file.close()\n        del log_file", "response": "Closes the log file and returns sys. stdout to the default console output."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a object to string", "response": "def _tostr(self,obj):\n        \"\"\" converts a object to list, if object is a list, it creates a\n            comma seperated string.\n        \"\"\"\n        if not obj:\n            return ''\n        if isinstance(obj, list):\n            return ', '.join(map(self._tostr, obj))\n        return str(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _unzip_file(self, zip_file, out_folder):\n        try:\n            zf = zipfile.ZipFile(zip_file, 'r')\n            zf.extractall(path=out_folder)\n            zf.close()\n            del zf\n            return True\n        except:\n            return False", "response": "unzips a file to a given folder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist all files in a given directory", "response": "def _list_files(self, path):\n        \"\"\"lists files in a given directory\"\"\"\n        files = []\n        for f in glob.glob(pathname=path):\n            files.append(f)\n        files.sort()\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_content_type(self, filename):\n        mntype = mimetypes.guess_type(filename)[0]\n        filename, fileExtension = os.path.splitext(filename)\n        if mntype is None and\\\n            fileExtension.lower() == \".csv\":\n            mntype = \"text/csv\"\n        elif mntype is None and \\\n            fileExtension.lower() == \".sd\":\n            mntype = \"File/sd\"\n        elif mntype is None:\n            #mntype = 'application/octet-stream'\n            mntype= \"File/%s\" % fileExtension.replace('.', '')\n        return mntype", "response": "returns the content type of a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the line the filename and error message and returns it to the user", "response": "def trace():\n    \"\"\"\n        trace finds the line, the filename\n        and error message and returns it\n        to the user\n    \"\"\"\n    import traceback, inspect, sys\n    tb = sys.exc_info()[2]\n    tbinfo = traceback.format_tb(tb)[0]\n    filename = inspect.getfile(inspect.currentframe())\n    # script name + line number\n    line = tbinfo.split(\", \")[1]\n    # Get Python syntax error\n    #\n    synerror = traceback.format_exc().splitlines()[-1]\n    return line, filename, synerror"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the style of the object", "response": "def style(self, value):\n        \"\"\"gets/sets the style\"\"\"\n        if self._style != value and \\\n           value in self._styles:\n            self._style = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef angle(self, value):\n        if self._angle != value and \\\n           isinstance(value, (int, float, long)):\n            self._angle = value", "response": "gets or sets the angle"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef size(self, value):\n        if self._size != value and \\\n           isinstance(value, (int, float, long)):\n            self._size = value", "response": "sets the size of the resource"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the xoffset of the record", "response": "def xoffset(self, value):\n        \"\"\"gets/sets the xoffset\"\"\"\n        if self._xoffset != value and \\\n           isinstance(value, (int, float, long)):\n            self._xoffset = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef value(self):\n        if self._outline is None:\n            return {\n                \"type\" : \"esriSMS\",\n                \"style\" : self._style,\n                \"color\" : self._color.value,\n                \"size\" : self._size,\n                \"angle\" : self._angle,\n                \"xoffset\" : self._xoffset,\n                \"yoffset\" : self._yoffset\n            }\n        else:\n            return {\n                \"type\" : \"esriSMS\",\n                \"style\" : self._style,\n                \"color\" : self._color.value,\n                \"size\" : self._size,\n                \"angle\" : self._angle,\n                \"xoffset\" : self._xoffset,\n                \"yoffset\" : self._yoffset,\n                \"outline\" : {\n                    \"width\" : self._outline['width'],\n                    \"color\" : self._color.value\n                }\n            }", "response": "returns the object as dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting or sets the width", "response": "def width(self, value):\n        \"\"\"gets/sets the width\"\"\"\n        if self._width != value and \\\n           isinstance(value, (int, float, long)):\n            self._width = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the color value", "response": "def value(self):\n        \"\"\"gets the color value\"\"\"\n        return {\n            \"type\" : self._type,\n            \"style\" : self._style,\n            \"color\" : self._color.value,\n            \"width\" : self._width\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value(self):\n        if self._outline is None:\n            return {\n                \"type\" : self._type,\n                \"style\" : self._style,\n                \"color\" : self._color.value,\n            }\n        else:\n            return {\n                \"type\" : self._type,\n                \"style\" : self._style,\n                \"color\" : self._color.value,\n                \"outline\" : self._outline.value\n            }", "response": "gets the color value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef red(self, value):\n        if value != self._red and \\\n           isinstance(value, int):\n            self._red = value", "response": "sets the red value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef green(self, value):\n        if value != self._green and \\\n           isinstance(value, int):\n            self._green = value", "response": "sets the green value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the blue value", "response": "def blue(self, value):\n        \"\"\"gets/sets the blue value\"\"\"\n        if value != self._blue and \\\n           isinstance(value, int):\n            self._blue = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef alpha(self, value):\n        if value != self._alpha and \\\n           isinstance(value, int):\n            self._alpha = value", "response": "sets the alpha value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the color value", "response": "def value(self):\n        \"\"\"gets the color value\"\"\"\n        return [self._red,\n                self._green,\n                self._blue,\n                self._alpha]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef editLogSettings(self, logLocation, logLevel=\"WARNING\", maxLogFileAge=90):\n        url = self._url + \"/settings/edit\"\n        params = {\n            \"f\" : \"json\",\n            \"logDir\" : logLocation,\n            \"logLevel\" : logLevel,\n            \"maxLogFileAge\" : maxLogFileAge\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation allows you to edit the log settings for a portal site. The log settings are only updated if the log files are not already saved."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self, logLevel=\"WARNING\", source=\"ALL\",\n              startTime=None, endTime=None,\n              logCodes=None, users=None, messageCount=1000):\n        \"\"\"\n           allows users to look at the log files from a the REST endpoint\n\n           Inputs:\n              logLevel - this is the level of detail saved in the log files\n                Levels are: OFF, SEVERE, WARNING, INFO, FINE, VERBOSE, and\n                  DEBUG\n              source - the type of information to search.  Allowed values\n                are: ALL, PORTAL_ADMIN, SHARING, PORTAL\n              startTime - datetime object to start search at\n              endTime - datetime object to end search\n              logCodes - comma seperate list of codes to search\n              users - comma seperated list of users to query\n              messageCount - integer number of the max number of log\n                entries to return to the user.\n        \"\"\"\n        url = self._url + \"/query\"\n        filter_value = {\"codes\":[], \"users\":[], \"source\": \"*\"}\n        if source.lower() == \"all\":\n            filter_value['source'] = \"*\"\n        else:\n            filter_value['source'] = [source]\n        params = {\n            \"f\" : \"json\",\n            \"level\" : logLevel\n\n        }\n        if not startTime is None and \\\n           isinstance(startTime, datetime):\n            params['startTime'] = startTime.strftime(\"%Y-%m-%dT%H:%M:%S\")#2015-01-31T15:00:00\n        if not endTime is None and \\\n           isinstance(endTime, datetime):\n            params['endTime'] = startTime.strftime(\"%Y-%m-%dT%H:%M:%S\")\n        if not logCodes is None:\n            filter_value['codes'] = logCodes.split(',')\n        if not users is None:\n            filter_value['users'] = users.split(',')\n        if messageCount is None:\n            params['pageSize'] = 1000\n        elif isinstance(messageCount, (int, long, float)):\n            params['pageSize'] = int(messageCount)\n        else:\n            params['pageSize'] = 1000\n        params['filter'] = filter_value\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "This method queries the log files from a specific log file system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deleteCertificate(self, certName):\n\n        params = {\"f\" : \"json\"}\n        url = self._url + \"/sslCertificates/{cert}/delete\".format(\n            cert=certName)\n        return self._post(url=url, param_dict=params,\n                          proxy_port=self._proxy_port,\n                          proxy_url=self._proxy_url)", "response": "This operation deletes an SSL certificate from the key store. This operation is idempotent and will not delete the certificate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generateCertificate(self, alias,\n                            commonName, organizationalUnit,\n                            city, state, country,\n                            keyalg=\"RSA\", keysize=1024,\n                            sigalg=\"SHA256withRSA\",\n                            validity=90\n                            ):\n        \"\"\"\n        Use this operation to create a self-signed certificate or as a\n        starting point for getting a production-ready CA-signed\n        certificate. The portal will generate a certificate for you and\n        store it in its keystore.\n        \"\"\"\n        params = {\"f\" : \"json\",\n                  \"alias\" : alias,\n                  \"commonName\" : commonName,\n                  \"organizationalUnit\" : organizationalUnit,\n                  \"city\" : city,\n                  \"state\" : state,\n                  \"country\" : country,\n                  \"keyalg\" : keyalg,\n                  \"keysize\" : keysize,\n                  \"sigalg\" : sigalg,\n                  \"validity\" : validity\n                  }\n        url = self._url + \"/SSLCertificate/ generateCertificate\"\n        return self._post(url=url,\n                          param_dict=params,\n                          proxy_port=self._proxy_port,\n                          proxy_url=self._proxy_url)", "response": "This operation generates a self - signed certificate for the given alias. The certificate is stored in the keystore."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refreshUserMembership(self, users):\n        params = {\n            \"f\" : \"json\",\n            \"users\" : users\n        }\n        url = self._url + \"/users/refreshMembership\"\n        return self._post(url=url,\n                          param_dict=params,\n                          proxy_port=self._proxy_port,\n                          proxy_url=self._proxy_url)", "response": "This operation refreshes the user membership for the specified users. The user membership is only refreshed if the user is not in the enterprise group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateIdenityStore(self,\n                           userPassword,\n                           user,\n                           userFullnameAttribute,\n                           ldapURLForUsers,\n                           userEmailAttribute,\n                           usernameAttribute,\n                           isPasswordEncrypted=False,\n                           caseSensitive=True):\n        r\"\"\"\n        You can use this operation to change the identity provider\n        configuration in your portal. When Portal for ArcGIS is first\n        installed, it supports token-based authentication using the\n        built-in identity store for accounts. To configure your portal to\n        connect to your enterprise authentication mechanism, it must be\n        configured to use an enterprise identity store such as Windows\n        Active Directory or LDAP.\n\n        Inputs:\n           userPassword -The password for the domain account, for example,\n                         secret.\n           isPasswordEncrypted - Indicates if the userPassword property is\n                                 an encrypted password or plain text. If\n                                 the property is false, the API will\n                                 encrypt the password automatically.\n           user - A user account with at least read permissions to look up\n                  the email addresses and user names of users in your\n                  organization. If possible, use an account whose password\n                  does not expire.\n                  Windows Active Directory example: mydomain\\\\winaccount\n                  LDAP example: uid=admin\\,ou=system\n           userFullnameAttribute - The attribute in Windows Active\n                                   Directory or LDAP that contains the full\n                                   name of the users, for example, cn.\n           ldapURLForUsers - The URL to your LDAP that points to the user\n                             accounts, for example,\n                             ldap://bar2:10389/ou=users\\,ou=ags\\,dc=example\\,dc=com.\n                             The URL to your LDAP will need to be provided\n                             by your LDAP administrator.\n                             This property is not applicable when\n                             configuring Windows Active Directory.\n           userEmailAttribute - The attribute in Windows Active Directory\n                                or LDAP that contains the email addresses\n                                of the users, for example, email.\n           usernameAttribute - The LDAP attribute of the user entry that is\n                               to be treated as the user name, for example, cn.\n                               This property is not applicable when\n                               configuring Windows Active Directory.\n           caseSensitive - In the rare case where your Windows Active\n                           Directory is configured to be case sensitive,\n                           set this property to true.\n                           If your LDAP is configured to be case\n                           insensitive, set parameter to false.\n        \"\"\"\n        url = self._url + \"/config/updateIdentityStore\"\n        params = {\n            \"f\" : \"json\",\n            \"userPassword\" : userPassword,\n            \"isPasswordEncrypted\" : isPasswordEncrypted,\n            \"user\" : user,\n            \"userFullnameAttribute\": userFullnameAttribute,\n            \"ldapURLForUsers\" : ldapURLForUsers,\n            \"userEmailAttribute\" : userEmailAttribute,\n            \"usernameAttribute\" : usernameAttribute,\n            \"caseSensitive\" : caseSensitive\n        }\n        return self._post(url=url, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)", "response": "r Updates the identity provider s identity store with the given user password ldapURLForUsers userEmailAttribute usernameAttribute and caseSensitive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef removeAllEntitlements(self, appId):\n        params = {\n            \"f\" : \"json\",\n            \"appId\" : appId\n        }\n        url = self._url + \"/licenses/removeAllEntitlements\"\n        return self._post(url=url,\n                          param_dict=params,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port)", "response": "This operation removes all entitlements assigned to a specific application from the licensing portal for ArcGIS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef updateLanguages(self, languages):\n        url = self._url = \"/languages/update\"\n        params = {\n            \"f\" : \"json\",\n            \"languages\" : languages\n        }\n        return self._post(url=url,\n                          param_dict=params,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port)", "response": "This operation updates the languages of a possible has\n        content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateLicenseManager(self, licenseManagerInfo):\n        url = self._url + \"/licenses/updateLicenseManager\"\n        params = {\n            \"f\" : \"json\",\n            \"licenseManagerInfo\" : licenseManagerInfo\n        }\n        return self._post(url=url,\n                          param_dict=params,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port)", "response": "This operation updates the license manager connection information for ArcGIS Pro. The license server connection information for ArcGIS Pro is also updated with the license manager info for ArcGIS Pro. This operation allows you to change the license server connection information for your entitlements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef updateIndexConfiguration(self,\n                                 indexerHost=\"localhost\",\n                                 indexerPort=7199):\n        \"\"\"\n        You can use this operation to change the connection information for\n        the indexing service. By default, Portal for ArcGIS runs an\n        indexing service that runs on port 7199. If you want the sharing\n        API to refer to the indexing service on another instance, you need\n        to provide the host and port parameters.\n\n        Input:\n           indexerHost - The name of the server (hostname) on which the\n                         index service runs. The default value is localhost\n           indexerPort - The port number on which the index service is\n                         listening. The default value is 7199\n        \"\"\"\n        url = self._url + \"/indexer/update\"\n        params = {\n            \"f\" : \"json\",\n            \"indexerHost\": indexerHost,\n            \"indexerPort\": indexerPort\n        }\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)", "response": "This operation updates the connection information for a specific antenna index service. The index service is only available if the index service is running on an instance of ArcGIS."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exportSite(self, location):\n        params = {\n            \"location\" : location,\n            \"f\" : \"json\"\n        }\n        url = self._url + \"/exportSite\"\n        return self._post(url=url, param_dict=params)", "response": "This operation exports the portal site configuration to a location"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef federation(self):\n        url = self._url + \"/federation\"\n        return _Federation(url=url,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)", "response": "returns the class that controls federation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a reference to the System operations for Portal", "response": "def system(self):\n        \"\"\"\n        Creates a reference to the System operations for Portal\n        \"\"\"\n        url = self._url + \"/system\"\n        return _System(url=url,\n                       securityHandler=self._securityHandler,\n                       proxy_url=self._proxy_url,\n                       proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef security(self):\n        url = self._url + \"/security\"\n        return _Security(url=url,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)", "response": "returns a reference to the Security operations for Portal\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logs(self):\n        url = self._url + \"/logs\"\n        return _log(url=url,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port)", "response": "returns the portals log information"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self,\n               q=None,\n               per_page=None,\n               page=None,\n               bbox=None,\n               sort_by=\"relavance\",\n               sort_order=\"asc\"):\n        \"\"\"\n        searches the opendata site and returns the dataset results\n        \"\"\"\n        url = self._url + \"/datasets.json\"\n        param_dict = {\n            \"sort_by\" : sort_by,\n            \"f\" : \"json\"\n        }\n        if q is not None:\n            param_dict['q'] = q\n        if per_page is not None:\n            param_dict['per_page'] = per_page\n        if page is not None:\n            param_dict['page'] = page\n        if bbox is not None:\n            param_dict['bbox'] = bbox\n        if sort_by is not None:\n            param_dict['sort_by'] = sort_by\n        if sort_order is not None:\n            param_dict['sort_order'] = sort_order\n        ds_data =  self._get(url=url,\n                    param_dict=param_dict,\n                    securityHandler=self._securityHandler,\n                    additional_headers=[],\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port)\n        return ds_data", "response": "This method searches the opendata site and returns the dataset results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getDataset(self, itemId):\n        if self._url.lower().find('datasets') > -1:\n            url = self._url\n        else:\n            url = self._url + \"/datasets\"\n        return OpenDataItem(url=url,\n                            itemId=itemId,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "gets a dataset class"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __init(self):\n        url = \"%s/%s.json\" % (self._url, self._itemId)\n        params = {\"f\": \"json\"}\n        json_dict = self._get(url, params,\n                         securityHandler=self._securityHandler,\n                         proxy_port=self._proxy_port,\n                         proxy_url=self._proxy_url)\n        self._json_dict = json_dict\n        self._json = json.dumps(self._json_dict)\n        setattr(self, \"data\", json_dict['data'])\n        if 'data' in json_dict:\n            for k,v in json_dict['data'].items():\n                setattr(self, k, v)\n                del k,v", "response": "gets the properties for the site"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexports a dataset t", "response": "def export(self, outFormat=\"shp\", outFolder=None):\n        \"\"\"exports a dataset t\"\"\"\n        export_formats = {'shp':\".zip\", 'kml':'.kml', 'geojson':\".geojson\",'csv': '.csv'}\n        url = \"%s/%s%s\" % (self._url, self._itemId, export_formats[outFormat])\n        results =  self._get(url=url,\n                    securityHandler=self._securityHandler,\n                    out_folder=outFolder)\n        if 'status' in results:\n            self.time.sleep(7)\n            results = self.export(outFormat=outFormat, outFolder=outFolder)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_file(self, fieldname, filename, filePath, mimetype=None):\n        body = filePath\n        if mimetype is None:\n            mimetype = mimetypes.guess_type(filename)[0] or 'application/octet-stream'\n        self.files.append((fieldname, filename, mimetype, body))", "response": "Add a file to be uploaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets or sets the user agent value", "response": "def useragent(self, value):\n        \"\"\"gets/sets the user agent value\"\"\"\n        if value is None:\n            self._useragent = \"Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0\"\n        elif self._useragent != value:\n            self._useragent = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_file_name(self, contentDisposition,\n                       url, ext=\".unknown\"):\n        \"\"\" gets the file name from the header or url if possible \"\"\"\n        if self.PY2:\n            if contentDisposition is not None:\n                return re.findall(r'filename[^;=\\n]*=(([\\'\"]).*?\\2|[^;\\n]*)',\n                                  contentDisposition.strip().replace('\"', ''))[0][0]\n            elif os.path.basename(url).find('.') > -1:\n                return os.path.basename(url)\n        elif self.PY3:\n            if contentDisposition is not None:\n                p = re.compile(r'filename[^;=\\n]*=(([\\'\"]).*?\\2|[^;\\n]*)')\n                return p.findall(contentDisposition.strip().replace('\"', ''))[0][0]\n            elif os.path.basename(url).find('.') > -1:\n                return os.path.basename(url)\n        return \"%s.%s\" % (uuid.uuid4().get_hex(), ext)", "response": "gets the file name from the header or url if possible"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _mainType(self, resp):\n        if self.PY2:\n            return resp.headers.maintype\n        elif self.PY3:\n            return resp.headers.get_content_maintype()\n        else:\n            return None", "response": "returns the main type from the response object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _chunk(self, response, size=4096):\n        method = response.headers.get(\"content-encoding\")\n        if method == \"gzip\":\n            d = zlib.decompressobj(16+zlib.MAX_WBITS)\n            b = response.read(size)\n            while b:\n                data = d.decompress(b)\n                yield data\n                b = response.read(size)\n                del data\n        else:\n            while True:\n                chunk = response.read(size)\n                if not chunk: break\n                yield chunk", "response": "downloads a web response in pieces"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a POST operation on a URL. Inputs: param_dict - key/value pair of values ex: {\"foo\": \"bar\"} files - key/value pair of file objects where the key is the input name and the value is the file path ex: {\"file\": r\"c:\\temp\\myfile.zip\"} securityHandler - object that handles the token or other site security. It must inherit from the base security class. ex: arcrest.AGOLSecurityHandler(\"SomeUsername\", \"SOMEPASSWORD\") additional_headers - are additional key/value headers that a user wants to pass during the operation. ex: {\"accept-encoding\": \"gzip\"} custom_handlers - this is additional web operation handlers as a list of objects. Ex: [CustomAuthHandler] proxy_url - url of the proxy proxy_port - default 80, port number of the proxy compress - default true, determines if gzip should be used of not for the web operation. out_folder - if the URL requested returns a file, this will be the disk save location file_name - if the operation returns a file and the file name is not given in the header or a user wishes to override the return saved file name, provide value here. force_form_post - boolean - Output: returns dictionary or string depending on web operation.", "response": "def _post(self, url,\n              param_dict=None,\n              files=None,\n              securityHandler=None,\n              additional_headers=None,\n              custom_handlers=None,\n              proxy_url=None,\n              proxy_port=80,\n              compress=True,\n              out_folder=None,\n              file_name=None,\n              force_form_post=False):\n        \"\"\"\n        Performs a POST operation on a URL.\n\n        Inputs:\n           param_dict - key/value pair of values\n              ex: {\"foo\": \"bar\"}\n           files - key/value pair of file objects where the key is\n              the input name and the value is the file path\n              ex: {\"file\": r\"c:\\temp\\myfile.zip\"}\n           securityHandler - object that handles the token or other site\n              security.  It must inherit from the base security class.\n              ex: arcrest.AGOLSecurityHandler(\"SomeUsername\", \"SOMEPASSWORD\")\n           additional_headers - are additional key/value headers that a user\n              wants to pass during the operation.\n              ex: {\"accept-encoding\": \"gzip\"}\n           custom_handlers - this is additional web operation handlers as a\n              list of objects.\n              Ex: [CustomAuthHandler]\n           proxy_url - url of the proxy\n           proxy_port - default 80, port number of the proxy\n           compress - default true, determines if gzip should be used of not for\n              the web operation.\n           out_folder - if the URL requested returns a file, this will be the\n              disk save location\n           file_name - if the operation returns a file and the file name is not\n             given in the header or a user wishes to override the return saved\n             file name, provide value here.\n           force_form_post - boolean -\n        Output:\n           returns dictionary or string depending on web operation.\n        \"\"\"\n\n        # ensure that no spaces are in the url\n        url = url.replace(\" \", \"%20\")\n\n        if param_dict is None:\n            param_dict = {}\n        if files is None:\n            files = {}\n        if additional_headers is None:\n            additional_headers = {}\n        if custom_handlers is None:\n            custom_handlers = []\n        if self._verify == False and \\\n           sys.version_info[0:3] >= (2, 7, 9) and \\\n            hasattr(ssl,'create_default_context'):\n            ctx = ssl.create_default_context()\n            ctx.check_hostname = False\n            ctx.verify_mode = ssl.CERT_NONE\n            custom_handlers.append(request.HTTPSHandler(context=ctx))\n        if len(files) == 0 and force_form_post == False:\n            self._last_method = \"POST\"\n        elif len(files) == 0 and force_form_post == True:\n            self._last_method = \"FORM-MULTIPART\"\n        elif len(files) > 0:\n            self._last_method = \"FORM-MULTIPART\"\n            force_form_post = True\n\n        headers = {\n            \"User-Agent\": self.useragent,\n            'Accept': '*/*'\n        }\n        if securityHandler and securityHandler.referer_url:\n            headers['referer'] = securityHandler.referer_url\n        opener = None\n        return_value = None\n        handlers = [RedirectHandler()]\n        param_dict, handler, cj = self._processHandler(securityHandler, param_dict)\n        if handler is not None:\n            handlers.append(handler)\n        if cj is not None:\n            handlers.append(request.HTTPCookieProcessor(cj))\n        if isinstance(custom_handlers, list) and \\\n           len(custom_handlers) > 0:\n            for h in custom_handlers:\n                handlers.append(h)\n        if compress:\n            headers['Accept-Encoding'] = 'gzip'\n        else:\n            headers['Accept-Encoding'] = ''\n        for k,v in additional_headers.items():\n            headers[k] = v\n            del k,v\n        hasContext = 'context' in self._has_context(request.urlopen)\n        if self._verify == False and \\\n           sys.version_info[0:3] >= (2, 7, 9) and \\\n            hasattr(ssl,'create_default_context'):\n            ctx = ssl.create_default_context()\n            ctx.check_hostname = False\n            ctx.verify_mode = ssl.CERT_NONE\n\n        opener = request.build_opener(*handlers)\n        opener.addheaders = [(k,v) for k,v in headers.items()]\n        request.install_opener(opener)\n        if force_form_post == False:\n            data = urlencode(param_dict)\n            if self.PY3:\n                data = data.encode('ascii')\n            opener.data = data\n            req = request.Request(self._asString(url),\n                                  data = data,\n                                  headers=headers)\n            for k,v in headers.items():\n                req.add_header(k,v)\n            if hasContext and self._verify == False:\n                resp = request.urlopen(req, context=ctx)\n            else:\n                resp = request.urlopen(req)\n        else:\n            mpf = MultiPartForm(param_dict=param_dict,\n                                files=files)\n            req = request.Request(self._asString(url), headers=headers)\n            body = mpf.make_result\n            req.add_header('User-agent', self.useragent)\n            req.add_header('Content-type', mpf.get_content_type())\n            req.add_header('Content-length', len(body))\n            req.data = body\n            if 'context' in self._has_context(request.urlopen) and \\\n               self._verify == False:\n                resp = request.urlopen(req, context=ctx)\n            else:\n                resp = request.urlopen(req)\n            del body, mpf\n        self._last_code = resp.getcode()\n        self._last_url = resp.geturl()\n        return_value = self._process_response(resp=resp,\n                                              out_folder=out_folder)\n        if isinstance(return_value, dict):\n            if \"error\" in return_value and \\\n               'message' in return_value['error']:\n                if return_value['error']['message'].lower() == 'request not made over ssl':\n                    if url.startswith('http://'):\n                        url = url.replace('http://', 'https://')\n                        return self._post(url,\n                                          param_dict,\n                                          files,\n                                          securityHandler,\n                                          additional_headers,\n                                          custom_handlers,\n                                          proxy_url,\n                                          proxy_port,\n                                          compress,\n                                          out_folder,\n                                          file_name)\n            return return_value\n        else:\n            return return_value\n        return return_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _asString(self, value):\n        if sys.version_info[0] == 3:\n            if isinstance(value, str):\n                return value\n            elif isinstance(value, bytes):\n                return value.decode('utf-8')\n        elif sys.version_info[0] == 2:\n            return value.encode('ascii')", "response": "converts the value as a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a GET operation Inputs: Output: returns dictionary, string or None", "response": "def _get(self, url,\n             param_dict=None,\n             securityHandler=None,\n             additional_headers=None,\n             handlers=None,\n             proxy_url=None,\n             proxy_port=None,\n             compress=True,\n             custom_handlers=None,\n             out_folder=None,\n             file_name=None):\n        \"\"\"\n        Performs a GET operation\n        Inputs:\n\n        Output:\n           returns dictionary, string or None\n        \"\"\"\n        # ensure that no spaces are in the url\n        url = url.replace(\" \", \"%20\")\n\n        pass_headers = {}\n        if custom_handlers is None:\n            custom_handlers = []\n        if handlers is None:\n            handlers = []\n        if param_dict is None:\n            param_dict = {}\n        self._last_method = \"GET\"\n        CHUNK = 4056\n        param_dict, handler, cj = self._processHandler(securityHandler, param_dict)\n        if additional_headers is not None:\n            headers = [] + additional_headers\n        else:\n            headers = []\n        pass_headers = {}\n        if securityHandler and securityHandler.referer_url:\n            pass_headers['referer'] = securityHandler.referer_url\n        for h in headers:\n            pass_headers[h[0]] = h[1]\n\n        if compress:\n            pass_headers['Accept-encoding'] = 'gzip'\n        else:\n            pass_headers['Accept-encoding'] = \"\"\n        #headers.append(('User-Agent', USER_AGENT))\n        pass_headers['User-Agent'] = self.useragent\n        if len(param_dict.keys()) == 0:\n            param_dict = None\n        if handlers is None:\n            handlers = []\n        if handler is not None:\n            handlers.append(handler)\n        handlers.append(RedirectHandler())\n        if self._verify == False and \\\n           sys.version_info[0:3] >= (2, 7, 9) and \\\n            hasattr(ssl,'create_default_context'):\n            ctx = ssl.create_default_context()\n            ctx.check_hostname = False\n            ctx.verify_mode = ssl.CERT_NONE\n            handlers.append(request.HTTPSHandler(context=ctx))\n        if cj is not None:\n            handlers.append(request.HTTPCookieProcessor(cj))\n        if proxy_url is not None:\n            if proxy_port is None:\n                proxy_port = 80\n            proxies = {\"http\":\"http://%s:%s\" % (proxy_url, proxy_port),\n                       \"https\":\"https://%s:%s\" % (proxy_url, proxy_port)}\n            proxy_support = request.ProxyHandler(proxies)\n            handlers.append(proxy_support)\n        opener = request.build_opener(*handlers)\n\n        opener.addheaders = headers\n        request.install_opener(opener)\n        ctx = None\n        hasContext = False\n        if self._verify == False and \\\n           'context' in self._has_context(request.urlopen) and \\\n            sys.version_info[0:3] >= (2, 7, 9) and \\\n            hasattr(ssl,'create_default_context'):\n            ctx = ssl.create_default_context()\n            ctx.check_hostname = False\n            ctx.verify_mode = ssl.CERT_NONE\n            hasContext = True\n\n        if hasContext == False:\n\n            if param_dict is None:\n                req = request.Request(self._asString(url),\n                                      headers=pass_headers)\n                resp = request.urlopen(req)\n            elif len(str(urlencode(param_dict))) + len(url) >= 1999:\n                return self._post(\n                    url=url,\n                    param_dict=param_dict,\n                    files=None,\n                    securityHandler=securityHandler,\n                    additional_headers=additional_headers,\n                    custom_handlers=custom_handlers,\n                    proxy_url=proxy_url,\n                    proxy_port=proxy_port,\n                    compress=compress,\n                    out_folder=out_folder,\n                    file_name=file_name,\n                    force_form_post=False)\n            else:\n                format_url = self._asString(url) + \"?%s\" % urlencode(param_dict)\n                req = request.Request(format_url,\n                                      headers=pass_headers)\n                resp = request.urlopen(req)\n        else:\n            if param_dict is None:\n                req = request.Request(self._asString(url),\n                                      headers=pass_headers)\n                resp = request.urlopen(req,\n                                       context=ctx)\n            elif len(str(urlencode(param_dict))) + len(url) >= 1999:\n                return self._post(\n                    url=url,\n                    param_dict=param_dict,\n                    files=None,\n                    securityHandler=securityHandler,\n                    additional_headers=additional_headers,\n                    custom_handlers=custom_handlers,\n                    proxy_url=proxy_url,\n                    proxy_port=proxy_port,\n                    compress=compress,\n                    out_folder=out_folder,\n                    file_name=file_name,\n                    force_form_post=False)\n            else:\n                format_url = self._asString(url) + \"?%s\" % urlencode(param_dict)\n                req = request.Request(format_url,\n                                      headers=pass_headers)\n                resp = request.urlopen(req,\n                                       context=ctx)\n        self._last_code = resp.getcode()\n        self._last_url = resp.geturl()\n        #  Get some headers from the response\n        maintype = self._mainType(resp)\n        contentDisposition = resp.headers.get('content-disposition')\n        contentMD5 = resp.headers.get('Content-MD5')\n        #contentEncoding = resp.headers.get('content-encoding')\n        contentType = resp.headers.get('content-Type').split(';')[0].lower()\n        contentLength = resp.headers.get('content-length')\n        if maintype.lower() in ('image',\n                                'application/x-zip-compressed') or \\\n           contentType in ('application/x-zip-compressed', 'application/octet-stream') or \\\n           contentMD5 is not None or\\\n           (contentDisposition is not None and \\\n            contentDisposition.lower().find('attachment;') > -1):\n\n            fname = self._get_file_name(\n                contentDisposition=contentDisposition,\n                url=url)\n            if out_folder is None:\n                out_folder = tempfile.gettempdir()\n            if contentLength is not None:\n                max_length = int(contentLength)\n                if max_length < CHUNK:\n                    CHUNK = max_length\n            file_name = os.path.join(out_folder, fname)\n            with open(file_name, 'wb') as writer:\n                for data in self._chunk(response=resp,\n                                        size=CHUNK):\n                    writer.write(data)\n                    writer.flush()\n                writer.flush()\n                del writer\n            return file_name\n        else:\n            read = \"\"\n            for data in self._chunk(response=resp,\n                                    size=CHUNK):\n                if self.PY3 == True:\n                    read += data.decode('utf-8')\n                else:\n                    read += data\n\n                del data\n            try:\n                results = json.loads(read)\n                if 'error' in results:\n                    if 'message' in results['error']:\n                        if results['error']['message'] == 'Request not made over ssl':\n                            if url.startswith('http://'):\n                                url = url.replace('http://', 'https://')\n                                return self._get(url,\n                                                 param_dict,\n                                                 securityHandler,\n                                                 additional_headers,\n                                                 handlers,\n                                                 proxy_url,\n                                                 proxy_port,\n                                                 compress,\n                                                 custom_handlers,\n                                                 out_folder,\n                                                 file_name)\n                return results\n            except:\n                return read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createSite(self,\n                   username,\n                   password,\n                   configStoreConnection,\n                   directories,\n                   cluster=None,\n                   logsSettings=None,\n                   runAsync=False\n                   ):\n        \"\"\"\n        This is the first operation that you must invoke when you install\n        ArcGIS Server for the first time. Creating a new site involves:\n\n          -Allocating a store to save the site configuration\n          -Configuring the server machine and registering it with the site\n          -Creating a new cluster configuration that includes the server\n           machine\n          -Configuring server directories\n          -Deploying the services that are marked to auto-deploy\n\n        Because of the sheer number of tasks, it usually takes a little\n        while for this operation to complete. Once a site has been created,\n        you can publish GIS services and deploy them to your server\n        machines.\n\n        Inputs:\n           username - The name of the administrative account to be used by\n             the site. This can be changed at a later stage.\n           password - The credentials of the administrative account.\n           configStoreConnection - A JSON object representing the\n             connection to the configuration store. By default, the\n             configuration store will be maintained in the ArcGIS Server\n             installation directory.\n           directories - A JSON object representing a collection of server\n             directories to create. By default, the server directories will\n             be created locally.\n           cluster - An optional cluster configuration. By default, the\n             site will create a cluster called 'default' with the first\n             available port numbers starting from 4004.\n           logsSettings - Optional log settings.\n           runAsync - A flag to indicate if the operation needs to be run\n             asynchronously. Values: true | false\n        \"\"\"\n        url = self._url + \"/createNewSite\"\n        params = {\n            \"f\" : \"json\",\n            \"cluster\" : cluster,\n            \"directories\" : directories,\n            \"username\" : username,\n            \"password\" : password,\n            \"configStoreConnection\" : configStoreConnection,\n            \"logSettings\" : logsSettings,\n            \"runAsync\" : runAsync\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This method creates a new site in ArcGIS Server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a reference to the machines object", "response": "def machines(self):\n        \"\"\"gets a reference to the machines object\"\"\"\n        if self._resources is None:\n            self.__init()\n        if \"machines\" in self._resources:\n            url = self._url + \"/machines\"\n            return _machines.Machines(url,\n                                      securityHandler=self._securityHandler,\n                                      initialize=False,\n                                      proxy_url=self._proxy_url,\n                                      proxy_port=self._proxy_port)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data(self):\n        if self._resources is None:\n            self.__init()\n        if \"data\" in self._resources:\n            url = self._url + \"/data\"\n            return _data.Data(url=url,\n                              securityHandler=self._securityHandler,\n                              initialize=True,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port)\n        else:\n            return None", "response": "returns the reference to the data functions as a class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info(self):\n        if self._resources is None:\n            self.__init()\n        url = self._url + \"/info\"\n        return _info.Info(url=url,\n                          securityHandler=self._securityHandler,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port,\n                          initialize=True)", "response": "returns the info object that returns the server s meta information about the server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the clusters functions if supported in resources", "response": "def clusters(self):\n        \"\"\"returns the clusters functions if supported in resources\"\"\"\n        if self._resources is None:\n            self.__init()\n        if \"clusters\" in self._resources:\n            url = self._url + \"/clusters\"\n            return _clusters.Cluster(url=url,\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port,\n                                     initialize=True)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef services(self):\n        if self._resources is None:\n            self.__init()\n        if \"services\" in self._resources:\n            url = self._url + \"/services\"\n            return _services.Services(url=url,\n                                      securityHandler=self._securityHandler,\n                                      proxy_url=self._proxy_url,\n                                      proxy_port=self._proxy_port,\n                                      initialize=True)\n        else:\n            return None", "response": "Gets the services object which will provide the ArcGIS Server s\n        admin information about services and folders."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the services object which provides the ArcGIS Server s admin information about the usagereports.", "response": "def usagereports(self):\n        \"\"\"\n        Gets the services object which will provide the ArcGIS Server's\n        admin information about the usagereports.\n        \"\"\"\n        if self._resources is None:\n            self.__init()\n        if \"usagereports\" in self._resources:\n            url = self._url + \"/usagereports\"\n            return _usagereports.UsageReports(url=url,\n                                              securityHandler=self._securityHandler,\n                                              proxy_url=self._proxy_url,\n                                              proxy_port=self._proxy_port,\n                                              initialize=True)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the kml functions for server", "response": "def kml(self):\n        \"\"\"returns the kml functions for server\"\"\"\n        url = self._url + \"/kml\"\n        return _kml.KML(url=url,\n                        securityHandler=self._securityHandler,\n                        proxy_url=self._proxy_url,\n                        proxy_port=self._proxy_port,\n                        initialize=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an object to work with the site logs", "response": "def logs(self):\n        \"\"\"returns an object to work with the site logs\"\"\"\n        if self._resources is None:\n            self.__init()\n        if \"logs\" in self._resources:\n            url = self._url + \"/logs\"\n            return _logs.Log(url=url,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port,\n                             initialize=True)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mode(self):\n        if self._resources is None:\n            self.__init()\n        if \"mode\" in self._resources:\n            url = self._url + \"/mode\"\n            return _mode.Mode(url=url,\n                              securityHandler=self._securityHandler,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port,\n                              initialize=True)\n        else:\n            return None", "response": "returns an object to work with the site mode"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef security(self):\n        if self._resources is None:\n            self.__init()\n        if \"security\" in self._resources:\n            url = self._url + \"/security\"\n            return _security.Security(url=url,\n                                      securityHandler=self._securityHandler,\n                                      proxy_url=self._proxy_url,\n                                      proxy_port=self._proxy_port,\n                                      initialize=True)\n        else:\n            return None", "response": "returns an object to work with the site security"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef system(self):\n        if self._resources is None:\n            self.__init()\n        if \"system\" in self._resources:\n            url = self._url + \"/system\"\n            return _system.System(url=url,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port,\n                                  initialize=True)\n        else:\n            return None", "response": "returns an object to work with the site system"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an object to work with the site uploads", "response": "def uploads(self):\n        \"\"\"returns an object to work with the site uploads\"\"\"\n        if self._resources is None:\n            self.__init()\n        if \"uploads\" in self._resources:\n            url = self._url + \"/uploads\"\n            return _uploads.Uploads(url=url,\n                                    securityHandler=self._securityHandler,\n                                    proxy_url=self._proxy_url,\n                                    proxy_port=self._proxy_port,\n                                    initialize=True)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getItemID(self, userContent, title=None, name=None, itemType=None):\n        itemID = None\n        if name is None and title is None:\n            raise AttributeError('Name or Title needs to be specified')\n        for item in userContent:\n            if title is None and name is not None:\n                if item.name == name and (itemType is None or item.type == itemType):\n                    return item.id\n\n            elif title is not None and name is None:\n                if item.title == title and (itemType is None or item.type == itemType):\n                    return item.id\n\n            else:\n                if item.name == name and item.title == title and (itemType is None or item.type == itemType):\n                    return item.id\n        return None", "response": "Gets the ID of an item by a combination of title name and type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getItem(self, userContent, title=None, name=None, itemType=None):\n        itemID = None\n        if name is None and title is None:\n            raise AttributeError('Name or Title needs to be specified')\n        for item in userContent:\n            if title is None and name is not None:\n                if item.name == name and (itemType is None or item.type == itemType):\n                    return item\n\n            elif title is not None and name is None:\n                if item.title == title and (itemType is None or item.type == itemType):\n                    return item\n\n            else:\n                if item.name == name and item.title == title and (itemType is None or item.type == itemType):\n                    return item\n        return None", "response": "Gets an item by a combination of title name and type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef folderExist(self, name, folders):\n        if name is not None and name != '':\n\n            folderID = None\n\n            for folder in folders:\n                if folder['title'].lower() == name.lower():\n                    return True\n\n            del folders\n\n            return folderID\n\n        else:\n            return False", "response": "Determines if a folder exists in the list of folders."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npublishing a list of items to a new user.", "response": "def publishItems(self, items_info):\n        \"\"\"Publishes a list of items.\n        \n        Args:\n            items_info (list): A list of JSON configuration items to publish.\n        \n        Returns:\n            list: A list of results from :py:meth:`arcrest.manageorg._content.User.addItem`.\n            \n        \"\"\"\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        itemInfo = None\n        item_results = None\n        item_info = None\n        admin = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            item_results = []\n            for item_info in items_info:\n                if 'ReplaceTag' in item_info:\n\n                    itemInfo = {\"ReplaceTag\":item_info['ReplaceTag'] }\n                else:\n                    itemInfo = {\"ReplaceTag\":\"{FeatureService}\" }\n\n                itemInfo['ItemInfo']  = self._publishItems(config=item_info)\n\n                if itemInfo['ItemInfo'] is not None and 'name' in itemInfo['ItemInfo']:\n                    print (\"%s created\" % itemInfo['ItemInfo']['name'])\n                    item_results.append(itemInfo)\n                else:\n                    print (str(itemInfo['ItemInfo']))\n\n            return item_results\n\n        except common.ArcRestHelperError as e:\n            raise e\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"publishItems\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n            })\n        finally:\n            itemInfo = None\n            item_results = None\n            item_info = None\n            admin = None\n\n            del itemInfo\n            del item_results\n            del item_info\n            del admin\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef publishMap(self, maps_info, fsInfo=None, itInfo=None):\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        itemInfo = None\n        itemId = None\n        map_results = None\n        replaceInfo = None\n        replaceItem = None\n        map_info = None\n        admin = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            map_results = []\n            for map_info in maps_info:\n                itemInfo = {}\n\n                if 'ReplaceInfo' in map_info:\n                    replaceInfo = map_info['ReplaceInfo']\n                else:\n                    replaceInfo = None\n\n\n                if replaceInfo != None:\n\n                    for replaceItem in replaceInfo:\n                        if replaceItem['ReplaceType'] == 'Layer':\n\n                            if fsInfo is not None:\n\n                                for fs in fsInfo:\n                                    if fs is not None and replaceItem['ReplaceString'] == fs['ReplaceTag']:\n                                        replaceItem['ReplaceString'] = fs['FSInfo']['url']\n                                        replaceItem['ItemID'] = fs['FSInfo']['itemId']\n                                        replaceItem['ItemFolder'] = fs['FSInfo']['folderId']\n                                        if 'convertCase' in fs['FSInfo']:\n                                            replaceItem['convertCase'] = fs['FSInfo']['convertCase']\n                                    elif 'ItemID' in replaceItem:\n                                        if 'ItemFolder' in replaceItem == False:\n\n                                            itemId = replaceItem['ItemID']\n                                            itemInfo = admin.content.getItem(itemId=itemId)\n                                            if itemInfo.owner:\n                                                if itemInfo.owner == self._securityHandler.username and itemInfo.ownerFolder:\n                                                    replaceItem['ItemFolder'] = itemInfo.ownerFolder\n                                                else:\n                                                    replaceItem['ItemFolder'] = None\n                        elif replaceItem['ReplaceType'] == 'Global':\n\n                            if itInfo is not None:\n\n                                for itm in itInfo:\n                                    if itm is not None:\n\n                                        if replaceItem['ReplaceString'] == itm['ReplaceTag']:\n                                            if 'ItemInfo' in itm:\n                                                if 'url' in itm['ItemInfo']:\n                                                    replaceItem['ReplaceString'] = itm['ItemInfo']['url']\n\n\n                if 'ReplaceTag' in map_info:\n\n                    itemInfo = {\"ReplaceTag\":map_info['ReplaceTag'] }\n                else:\n                    itemInfo = {\"ReplaceTag\":\"{WebMap}\" }\n\n                itemInfo['MapInfo']  = self._publishMap(config=map_info,\n                                                   replaceInfo=replaceInfo)\n                map_results.append(itemInfo)\n                print (\"%s webmap created\" % itemInfo['MapInfo']['Name'])\n            return map_results\n\n        except common.ArcRestHelperError as e:\n            raise e\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                 \"function\": \"publishMap\",\n                 \"line\": line,\n                 \"filename\":  filename,\n                 \"synerror\": synerror,\n            })\n        finally:\n            itemInfo = None\n            itemId = None\n            replaceInfo = None\n            replaceItem = None\n            map_info = None\n            admin = None\n\n            del itemInfo\n            del itemId\n            del replaceInfo\n            del replaceItem\n            del map_info\n            del admin\n\n            gc.collect()", "response": "Publishes a list of maps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publishCombinedWebMap(self, maps_info, webmaps):\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        admin = None\n        map_results = None\n        map_info = None\n        operationalLayers = None\n        tableLayers = None\n        item = None\n        response = None\n        opLays = None\n        operationalLayers = None\n        tblLays = None\n        tblLayer = None\n        itemInfo = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n\n            map_results = []\n            for map_info in maps_info:\n\n                operationalLayers = []\n                tableLayers = []\n                for webmap in webmaps:\n                    item = admin.content.getItem(itemId=webmap)\n                    response = item.itemData()\n                    if 'operationalLayers' in response:\n\n                        opLays = []\n                        for opLayer in response['operationalLayers']:\n                            opLays.append(opLayer)\n                        opLays.extend(operationalLayers)\n                        operationalLayers = opLays\n                    if 'tables' in response:\n\n                        tblLays = []\n                        for tblLayer in response['tables']:\n                            tblLays.append(tblLayer)\n                        tblLays.extend(tableLayers)\n                        tableLayers = tblLays\n\n                if 'ReplaceTag' in map_info:\n\n                    itemInfo = {\"ReplaceTag\":map_info['ReplaceTag'] }\n                else:\n                    itemInfo = {\"ReplaceTag\":\"{WebMap}\" }\n\n                itemInfo['MapInfo'] = self._publishMap(config=map_info,\n                                                        replaceInfo=None,\n                                                        operationalLayers=operationalLayers,\n                                                        tableLayers=tableLayers)\n\n\n                map_results.append(itemInfo)\n                if not itemInfo is None:\n                    if not 'error' in itemInfo['MapInfo']['Results']:\n                        print (\"%s webmap created\" % itemInfo['MapInfo']['Name'])\n                    else:\n                        print (str(itemInfo['MapInfo']['Results']))\n                else:\n                    print (\"Map not created\")\n\n                return map_results\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"publishedCombinedWebMap\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n            })\n        finally:\n            admin = None\n\n            map_info = None\n\n            tableLayers = None\n            item = None\n            response = None\n            opLays = None\n            operationalLayers = None\n            tblLays = None\n            tblLayer = None\n            itemInfo = None\n\n            del admin\n            del map_info\n\n            del tableLayers\n            del item\n            del response\n            del opLays\n            del operationalLayers\n            del tblLays\n            del tblLayer\n            del itemInfo\n\n            gc.collect()", "response": "Publishes a combination of web maps."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publishFsFromMXD(self, fs_config):\n        fs = None\n        res = None\n        resItm = None\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        if self.securityhandler.is_portal:\n            url = self.securityhandler.org_url\n        else:\n            url = 'http://www.arcgis.com'\n        try:\n            res = []\n            if isinstance(fs_config, list):\n                for fs in fs_config:\n                    if 'ReplaceTag' in fs:\n\n                        resItm = {\"ReplaceTag\":fs['ReplaceTag'] }\n                    else:\n                        resItm = {\"ReplaceTag\":\"{FeatureService}\" }\n\n                    resItm['FSInfo'] = self._publishFSFromMXD(config=fs, url=url)\n\n                    if not resItm['FSInfo'] is None and 'url' in resItm['FSInfo']:\n                        print (\"%s created\" % resItm['FSInfo']['url'])\n                        res.append(resItm)\n                    else:\n                        print (str(resItm['FSInfo']))\n\n            else:\n                if 'ReplaceTag' in fs_config:\n\n                    resItm = {\"ReplaceTag\":fs_config['ReplaceTag'] }\n                else:\n                    resItm = {\"ReplaceTag\":\"{FeatureService}\" }\n\n                resItm['FSInfo'] = self._publishFSFromMXD(config=fs_config, url=url)\n\n                if 'url' in resItm['FSInfo']:\n                    print (\"%s created\" % resItm['FSInfo']['url'])\n                    res.append(resItm)\n                else:\n                    print (str(resItm['FSInfo']))\n\n            return res\n        except common.ArcRestHelperError as e:\n            raise e\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"publishFsFromMXD\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n\n        finally:\n            resItm = None\n            fs = None\n\n            del resItm\n            del fs\n\n            gc.collect()", "response": "Publishes the layers in a MXD to a feauture service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publishFeatureCollections(self, configs):\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        config = None\n        res = None\n        resItm = None\n        try:\n            res = []\n            if isinstance(configs, list):\n                for config in configs:\n                    if 'ReplaceTag' in config:\n\n                        resItm = {\"ReplaceTag\":config['ReplaceTag'] }\n                    else:\n                        resItm = {\"ReplaceTag\":\"{FeatureService}\" }\n\n                    if 'Zip' in config:\n                        resItm['FCInfo'] = self._publishFeatureCollection(config=config)\n\n\n                    if not resItm['FCInfo'] is None and 'id' in resItm['FCInfo']:\n                        print (\"%s feature collection created\" % resItm['FCInfo']['id'])\n                        res.append(resItm)\n                    else:\n                        print (str(resItm['FCInfo']))\n\n\n            return res\n\n        except common.ArcRestHelperError as e:\n            raise e\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"publishFeatureCollections\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n            })\n\n        finally:\n            resItm = None\n            config = None\n\n            del resItm\n            del config\n\n            gc.collect()", "response": "Publishes feature collections to a feature service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef publishApp(self, app_info, map_info=None, fsInfo=None):\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        appDet = None\n        try:\n            app_results = []\n            if isinstance(app_info, list):\n                for appDet in app_info:\n                    app_results.append(self._publishAppLogic(appDet=appDet,map_info=map_info,fsInfo=fsInfo))\n            else:\n                app_results.append(self._publishAppLogic(appDet=app_info,map_info=map_info,fsInfo=fsInfo))\n            return app_results\n\n        except (common.ArcRestHelperError) as e:\n            raise e\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"publishApp\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n            })\n\n        finally:\n            appDet = None\n\n            del appDet\n            gc.collect()", "response": "Publishes apps to AGOL"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a feature service.", "response": "def updateFeatureService(self, efs_config):\n        \"\"\"Updates a feature service.\n        \n        Args:\n            efs_config (list): A list of JSON configuration feature service details to update.\n        Returns:\n            dict: A dictionary of results objects.\n        \n        \"\"\"\n        if self.securityhandler is None:\n            print (\"Security handler required\")\n            return\n        fsRes = None\n        fst = None\n        fURL = None\n        resItm= None\n        try:\n\n            fsRes = []\n            fst = featureservicetools.featureservicetools(securityinfo=self)\n\n\n            if isinstance(efs_config, list):\n                for ext_service in efs_config:\n                    fURL = None\n                    cs = 0\n                    try:\n                        if 'ChunkSize' in ext_service:\n                            if common.is_number(ext_service['ChunkSize']):\n                                cs = ext_service['ChunkSize']\n                    except Exception as e:\n                        pass\n                    resItm={\"DeleteDetails\": None,\"AddDetails\":None}\n                    if 'ItemId' in ext_service and 'LayerName' in ext_service:\n                        fs = fst.GetFeatureService(itemId=ext_service['ItemId'],returnURLOnly=False)\n                        if not fs is None:\n                            fURL = fst.GetLayerFromFeatureService(fs=fs,layerName=ext_service['LayerName'],returnURLOnly=True)\n                    if fURL is None and 'URL' in ext_service:\n\n                        fURL = ext_service['URL']\n                    if fURL is None:\n                        print(\"Item and layer not found or URL not in config\")\n                        continue\n\n                    if 'DeleteInfo' in ext_service:\n                        if str(ext_service['DeleteInfo']['Delete']).upper() == \"TRUE\":\n                            resItm['DeleteDetails'] = fst.DeleteFeaturesFromFeatureLayer(url=fURL, sql=ext_service['DeleteInfo']['DeleteSQL'],chunksize=cs)\n                            if not 'error' in resItm['DeleteDetails'] :\n                                print (\"Delete Successful: %s\" % fURL)\n                            else:\n                                print (str(resItm['DeleteDetails']))\n\n                    resItm['AddDetails'] = fst.AddFeaturesToFeatureLayer(url=fURL, pathToFeatureClass = ext_service['FeatureClass'],chunksize=cs)\n\n                    fsRes.append(resItm)\n\n                    if not 'error' in resItm['AddDetails']:\n                        print (\"Add Successful: %s \" % fURL)\n                    else:\n                        print (str(resItm['AddDetails']))\n\n            else:\n                resItm={\"DeleteDetails\": None,\"AddDetails\":None}\n                fURL = efs_config['URL']\n                cs = 0\n                try:\n                    if 'ChunkSize' in efs_config:\n                        if common.is_number(efs_config['ChunkSize']):\n                            cs = efs_config['ChunkSize']\n                except Exception as e:\n                    pass\n                if 'ItemId' in efs_config and 'LayerName' in efs_config:\n                    fs = fst.GetFeatureService(itemId=efs_config['ItemId'],returnURLOnly=False)\n                    if not fs is None:\n                        fURL = fst.GetLayerFromFeatureService(fs=fs,layerName=efs_config['LayerName'],returnURLOnly=True)\n                if fURL is None and 'URL' in efs_config:\n\n                    fURL = efs_config['URL']\n                if fURL is None:\n                    print(\"Item and layer not found or URL not in config\")\n                    return None\n                if 'DeleteInfo' in efs_config:\n                    if str(efs_config['DeleteInfo']['Delete']).upper() == \"TRUE\":\n                        resItm['DeleteDetails'] = fst.DeleteFeaturesFromFeatureLayer(url=fURL, sql=efs_config['DeleteInfo']['DeleteSQL'],chunksize=cs)\n                        if not 'error' in resItm['DeleteDetails'] :\n                            print (\"            Delete Successful: %s\" % fURL)\n                        else:\n                            print (\"            \" + str(resItm['DeleteDetails']))\n\n                resItm['AddDetails'] = fst.AddFeaturesToFeatureLayer(url=fURL, pathToFeatureClass = efs_config['FeatureClass'],chunksize=cs)\n\n                fsRes.append(resItm)\n\n                if not 'error' in resItm['AddDetails']:\n                    print (\"            Add Successful: %s \" % fURL)\n                else:\n                    print (\"            \" + str(resItm['AddDetails']))\n\n            return fsRes\n\n        except common.ArcRestHelperError as e:\n            raise e\n        except Exception as e:\n\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"updateFeatureService\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n            })\n        finally:\n            fst = None\n            fURL = None\n            resItm= None\n\n            del fst\n            del fURL\n            del resItm\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createGroup(self,\n                    title,\n                    tags,\n                    description=\"\",\n                    snippet=\"\",\n                    phone=\"\",\n                    access=\"org\",\n                    sortField=\"title\",\n                    sortOrder=\"asc\",\n                    isViewOnly=False,\n                    isInvitationOnly=False,\n                    thumbnail=None):\n        \"\"\"\n        The Create Group operation (POST only) creates a new group in the\n        Portal community. Only authenticated users can create groups. The\n        user who creates the group automatically becomes the owner of the\n        group. The owner of the group is automatically an administrator of\n        the group. The calling user provides the title for the group, while\n        the group ID is generated by the system.\n\n        Inputs:\n           title - The group title must be unique for the username, and the\n                   character limit is 250.\n           tags - Tags are words or short phrases that describe the group.\n                  Separate terms with commas.\n           description -  A description of the group that can be any length\n           snippet - Snippet or summary of the group that has a character\n                     limit of 250 characters.\n           phone - group contact information\n           access - Sets the access level for the group. private is the\n                    default. Setting to org restricts group access to\n                    members of your organization. If public, all users can\n                    access the group.\n                    Values: private | org |public\n           sortField -  Sets sort field for group items.\n                        Values: title | owner | avgRating |numViews\n                                | created | modified\n           sortOrder - sets sort order for group items. Values: asc or desc\n           isViewOnly -  Allows the group owner or dmin to create view-only\n                         groups where members are not able to share items.\n                         If members try to share, view-only groups are\n                         returned in the notshared response property. false\n                         is the default.\n           isInvitationOnly - If true, this group will not accept join\n                              requests. If false, this group does not\n                              require an invitation to join. Only group\n                              owners and admins can invite users to the\n                              group. false is the default.\n           thumbnail - Enter the pathname to the thumbnail image to be used\n                       for the group. The recommended image size is 200\n                       pixels wide by 133 pixels high. Acceptable image\n                       formats are PNG, GIF, and JPEG. The maximum file size\n                       for an image is 1 MB. This is not a reference to\n                       the file but the file itself, which will be stored\n                       in the Portal.\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"title\" : title,\n            \"description\" : description,\n            \"snippet\" : snippet,\n            \"tags\" : tags,\n            \"phone\" : phone,\n            \"access\" : access,\n            \"sortField\" : sortField,\n            \"sortOrder\" : sortOrder,\n            \"isViewOnly\" : isViewOnly,\n            \"isInvitationOnly\" : isInvitationOnly\n        }\n        url = self._url + \"/createGroup\"\n\n        groups = self.groups\n        if thumbnail is not None and \\\n           os.path.isfile(thumbnail):\n            res = self._post(url=url,\n                             param_dict=params,\n                             files={'thumbnail': thumbnail},\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)\n        else:\n            res = self._post(url=url, param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n\n        if \"group\" not in res:\n            raise Exception(\"%s\" % res)\n        if \"id\" not in res['group']:\n            raise Exception(\"%s\" % res)\n        groupId = res['group']['id']\n        url = \"%s/groups/%s\" % (self.root, groupId)\n        return Group(url=url,\n                     securityHandler=self._securityHandler,\n                     proxy_url=self._proxy_url,\n                     proxy_port=self._proxy_port,\n                     initalize=False)", "response": "This method creates a new group in the Portal community. The group is created in the portal community."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the group object", "response": "def groups(self):\n        \"\"\" returns the group object \"\"\"\n        return Groups(url=\"%s/groups\" % self.root,\n                       securityHandler=self._securityHandler,\n                       proxy_url=self._proxy_url,\n                       proxy_port=self._proxy_port,\n                       initalize=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __init(self):\n\n        if self._portalId is None:\n\n            from .administration import Administration\n            portalSelf = Administration(url=self._securityHandler.org_url,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port).portals.portalSelf\n\n            self._portalId = portalSelf.id\n            self._currentUser = portalSelf.user['username']", "response": "loads the property data into the class"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a group based on it s ID", "response": "def group(self, groupId):\n        \"\"\"\n        gets a group based on it's ID\n        \"\"\"\n        url = \"%s/%s\" % (self.root, groupId)\n        return Group(url=url,\n                     securityHandler=self._securityHandler,\n                     proxy_url=self._proxy_url,\n                     proxy_port=self._proxy_port,\n                     initalize=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self,\n               clearEmptyFields=True,\n               title=None,\n               description=None,\n               snippet=None,\n               tags=None,\n               phone=None,\n               access=None,\n               sortField=None,\n               sortOrder=None,\n               isViewOnly=None,\n               isInvitationOnly=None,\n               thumbnail=None):\n        \"\"\"\n        The Update Group operation (POST only) modifies properties such as\n        the group title, tags, description, sort field and order, and\n        member sharing capabilities. Available only to the group\n        administrators or to the administrator of the organization if the\n        user is a member.\n\n        Only the properties that are to be updated need to be specified in\n        the request. Properties not specified will not be affected.\n\n        The group ID cannot be modified.\n\n        Inputs:\n           title - The group title must be unique for the username, and the\n                   character limit is 250.\n                   Example: title=Redlands Fire Department\n           description - A description of the group that can be any length.\n           snippet - Snippet or summary of the group that has a character\n                     limit of 250 characters.\n           tags\t- Tags are words or short phrases that describe the group.\n                  Separate terms with commas.\n           phone - Phone is the group contact information. It can be a\n                   combination of letters and numbers. The character limit\n                   is 250.\n           access - Sets the access level for the group. private is the\n                    default. Setting to org restricts group access to\n                    members of your organization. If public, all users can\n                    access the group.\n                    Values: private | org |public\n           sortField - Sets sort field for group items.\n                       Values: title | owner | avgRating |\n                               numViews| created | modified\n           sortOrder - Sets sort order for group items.\n                       Values: asc | desc\n           isViewOnly - Allows the group owner or admin to create view-only\n                        groups where members are not able to share items.\n                        If members try to share, view-only groups are\n                        returned in the notshared response property.\n                        Values: false | true\n\n        \"\"\"\n        params = {\n            \"f\" : \"json\"\n        }\n        if title is not None:\n            params['title'] = title\n        if description is not None:\n            params['description'] = description\n        if snippet is not None:\n            params['snippet'] = snippet\n        if tags is not None:\n            params['tags'] = tags\n        if phone is not None:\n            params['phone'] = phone\n        if access is not None:\n            params['access'] = access\n        if sortField is not None:\n            params['sortField'] = sortField\n        if isViewOnly is not None:\n            params['isViewOnly'] = isViewOnly\n        if isInvitationOnly is not None:\n            params['isInvitationOnly'] = isInvitationOnly\n        if clearEmptyFields is not None:\n            params['clearEmptyFields'] = clearEmptyFields\n        files = {}\n        url = self._url + \"/update\"\n\n        if thumbnail is not None and \\\n           os.path.isfile(thumbnail):\n            files['thumbnail'] =thumbnail\n        res = None\n        if thumbnail is not None and \\\n           os.path.isfile(thumbnail):\n            res = self._post(url=url,\n                             param_dict=params,\n                             files=files,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)\n            return res\n        else:\n            res = self._post(url=url, param_dict=params,\n                                securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        self.__init()\n        return res", "response": "This operation is used to update the properties of a group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninvite a user to a group. The group is not authenticated and the user is not allowed to join the group. The group is not allowed to join the group. The group is not allowed to join the user.", "response": "def invite(self, users, role, expiration=1440):\n        \"\"\"\n        A group administrator can invite users to join their group using\n        the Invite to Group operation. This creates a new user invitation,\n        which the users accept or decline. The role of the user and the\n        invitation expiration date can be set in the invitation.\n        A notification is created for the user indicating that they were\n        invited to join the group. Available only to authenticated users.\n\n        Inputs:\n           users - A comma separated list of usernames to be invited to the\n                   group. If a user is already a member of the group or an\n                   invitation has already been sent, the call still returns\n                   a success.\n                   Example: users=regularusername1,regularusername2\n           role\t- Allows administrators to set the user's role in the group\n                  Roles are:\n                     group_member: Ability to view and share items with\n                                   group.\n                     group_admin: In addition to viewing and sharing items,\n                                  the group_admin has the same capabilities\n                                  as the group owner-invite users to the\n                                  group, accept or decline group\n                                  applications, delete content, and remove\n                                  users.\n           expiration - Expiration date on the invitation can be set for\n                        one day, three days, one week, or two weeks, in\n                        minutes. Default is 1440\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"users\" : users,\n            \"role\" : role,\n            \"expiration\" : expiration\n        }\n        return self._post(url=self._url + \"/invite\",\n                             securityHandler=self._securityHandler,\n                             param_dict=params,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all the group applications to join", "response": "def applications(self):\n        \"\"\"returns all the group applications to join\"\"\"\n        url = self._url + \"/applications\"\n        params = {\"f\" : \"json\"}\n        res = self._get(url=url,\n                           param_dict=params,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        items = []\n        if \"applications\" in res.keys():\n            for apps in res['applications']:\n                items.append(\n                    self.Application(url=\"%s/%s\" % (self._url, apps['username']),\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port)\n                )\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to parse the user name from various objects", "response": "def __getUsername(self):\n        \"\"\"tries to parse the user name from various objects\"\"\"\n\n        if self._securityHandler is not None and \\\n           not self._securityHandler._username is None:\n            return self._securityHandler._username\n        elif self._securityHandler is not None and \\\n               hasattr(self._securityHandler, \"org_url\") and \\\n               self._securityHandler.org_url is not None:\n            from .administration import Administration\n            user = Administration(url=self._securityHandler.org_url,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port).portals.portalSelf.user\n            return user['username']\n        else:\n            from .administration import Administration\n            url = self._url.lower().split('/content/')[0]\n            user = Administration(url=url,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port).portals.portalSelf.user\n            return user['username']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef user(self, username=None):\n        if username is None:\n            username = self.__getUsername()\n        parsedUsername = urlparse.quote(username)\n        url = self.root + \"/%s\" % parsedUsername\n        return User(url=url,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port,\n                    initialize=False)", "response": "A user resource that represents a registered user in the portal."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef userContent(self):\n        replace_start = self._url.lower().find(\"/community/\")\n        len_replace = len(\"/community/\")\n        url = self._url.replace(self._url[replace_start:replace_start+len_replace],\n                                '/content/')\n        from ._content import User as UserContent\n        return UserContent(url=url,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)", "response": "allows access into the individual user s content to get at the\n        items owned by the current user"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef invitations(self):\n        url = \"%s/invitations\" % self.root\n        return Invitations(url=url,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)", "response": "returns a class to access the current user s invitations"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notifications(self):\n        params = {\"f\": \"json\"}\n        url = \"%s/notifications\" % self.root\n        return Notifications(url=url,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "The notifications that are available for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting a users password for an account. The password will be randomly generated and emailed by the system. Input: email - boolean that an email password will be sent to the user's profile email address. The default is True.", "response": "def resetPassword(self, email=True):\n        \"\"\"\n        resets a users password for an account.  The password will be randomly\n        generated and emailed by the system.\n\n        Input:\n           email - boolean that an email password will be sent to the\n                   user's profile email address.  The default is True.\n\n        \"\"\"\n        url = self.root + \"/reset\"\n        params = {\n            \"f\" : \"json\",\n            \"email\" : email\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a time when a user must reset their password", "response": "def expirePassword(self,\n                       hours=\"now\"):\n        \"\"\"sets a time when a user must reset their password\"\"\"\n\n        params = {\n            \"f\" : \"json\"\n        }\n        expiration = -1\n        if isinstance(hours, str):\n            if expiration == \"now\":\n                expiration = -1\n            elif expiration == \"never\":\n                expiration = 0\n            else:\n                expiration = -1\n        elif isinstance(expiration, (int, long)):\n            dt = datetime.now() + timedelta(hours=hours)\n            expiration = local_time_to_online(dt=dt)\n        else:\n            expiration = -1\n        params['expiration'] = expiration\n        url = \"%s/expirePassword\" % self.root\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget all user invitations", "response": "def userInvitations(self):\n        \"\"\"gets all user invitations\"\"\"\n        self.__init()\n        items = []\n        for n in self._userInvitations:\n            if \"id\" in n:\n                url = \"%s/%s\" % (self.root, n['id'])\n                items.append(self.Invitation(url=url,\n                                             securityHandler=self._securityHandler,\n                                             proxy_url=self._proxy_url,\n                                             proxy_port=self._proxy_port,\n                                             initialize=True))\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the user s notifications", "response": "def notifications(self):\n        \"\"\"gets the user's notifications\"\"\"\n        self.__init()\n        items = []\n        for n in self._notifications:\n            if \"id\" in n:\n                url = \"%s/%s\" % (self.root, n['id'])\n                items.append(self.Notification(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_url=self._proxy_url,\n                                               proxy_port=self._proxy_port))\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a JSON configuration file to stage content.", "response": "def stageContent(self, configFiles, dateTimeFormat=None):\n        \"\"\"Parses a JSON configuration file to stage content.\n\n        Args:\n            configFiles (list): A list of JSON files on disk containing\n                configuration data for staging content.\n            dateTimeFormat (str): A valid date formatting directive, as understood\n                by :py:meth:`datetime.datetime.strftime`. Defaults to ``None``, i.e.,\n                ``'%Y-%m-%d %H:%M'``.\n\n        \"\"\"\n        results = None\n        groups = None\n        items = None\n        group = None\n        content = None\n        contentInfo = None\n        startTime = None\n        orgTools = None\n\n\n        if dateTimeFormat is None:\n            dateTimeFormat = '%Y-%m-%d %H:%M'\n\n\n        scriptStartTime = datetime.datetime.now()\n        try:\n\n            print (\"********************Stage Content Started********************\")\n\n            print (\"Script started at %s\" % scriptStartTime.strftime(dateTimeFormat))\n\n            if self.securityhandler.valid == False:\n                print (\"Login required\")\n            else:\n                orgTools = orgtools.orgtools(securityinfo=self)\n\n                if orgTools is None:\n                    print (\"Error creating org tools\")\n                else:\n\n                    for configFile in configFiles:\n\n                        config = common.init_config_json(config_file=configFile)\n                        if config is not None:\n                            if 'ContentItems' in config:\n                                startTime = datetime.datetime.now()\n                                print (\"Processing config %s, starting at: %s\" % (configFile,startTime.strftime(dateTimeFormat)))\n                                contentInfo = config['ContentItems']\n                                for cont in contentInfo:\n                                    content = cont['Content']\n                                    group = cont['ShareToGroup']\n\n                                    print (\"Sharing content to: %s\" % group)\n                                    if os.path.isfile(content):\n                                        with open(content, 'rb') as csvfile:\n                                            items = []\n                                            groups = []\n                                            for row in csv.DictReader(csvfile,dialect='excel'):\n                                                if cont['Type'] == \"Group\":\n                                                    groups.append(row['id'])\n                                                elif cont['Type'] == \"Items\":\n                                                    items.append(row['id'])\n                                            results = orgTools.shareItemsToGroup(shareToGroupName=group,items=items,groups=groups)\n\n                                print (\"Config %s completed, time to complete: %s\" % (configFile, str(datetime.datetime.now() - startTime)))\n                            else:\n                                print (\"Config file missing ContentItems section\")\n                        else:\n                            print (\"Config %s not found\" % configFile)\n\n\n        except(TypeError,ValueError,AttributeError) as e:\n            print (e)\n        except (common.ArcRestHelperError) as e:\n            print (\"error in function: %s\" % e[0]['function'])\n            print (\"error on line: %s\" % e[0]['line'])\n            print (\"error in file name: %s\" % e[0]['filename'])\n            print (\"with error message: %s\" % e[0]['synerror'])\n            if 'arcpyError' in e[0]:\n                print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n\n        except Exception as e:\n            if (reportToolsInstalled):\n                if isinstance(e,(ReportTools.ReportToolsError,DataPrep.DataPrepError)):\n                    print (\"error in function: %s\" % e[0]['function'])\n                    print (\"error on line: %s\" % e[0]['line'])\n                    print (\"error in file name: %s\" % e[0]['filename'])\n                    print (\"with error message: %s\" % e[0]['synerror'])\n                    if 'arcpyError' in e[0]:\n                        print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n                else:\n                    line, filename, synerror = trace()\n                    print (\"error on line: %s\" % line)\n                    print (\"error in file name: %s\" % filename)\n                    print (\"with error message: %s\" % synerror)\n            else:\n                line, filename, synerror = trace()\n                print (\"error on line: %s\" % line)\n                print (\"error in file name: %s\" % filename)\n                print (\"with error message: %s\" % synerror)\n        finally:\n            print (\"Script complete, time to complete: %s\" % str(datetime.datetime.now() - scriptStartTime))\n            print (\"###############Stage Content Completed#################\")\n            print (\"\")\n            #if orgTools is not None:\n                #orgTools.dispose()\n\n            results = None\n            groups = None\n            items = None\n            group = None\n            content = None\n            contentInfo = None\n            startTime = None\n            orgTools = None\n\n            del results\n            del groups\n            del items\n            del group\n            del content\n            del contentInfo\n            del startTime\n            del orgTools\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a JSON configuration file and creates a list of roles.", "response": "def createRoles(self, configFiles, dateTimeFormat=None):\n        \"\"\"Parses a JSON configuration file to create roles.\n\n        Args:\n            configFiles (list): A list of JSON files on disk containing\n                configuration data for creating roles.\n            dateTimeFormat (str): A valid date formatting directive, as understood\n                by :py:meth:`datetime.datetime.strftime`. Defaults to ``None``, i.e.,\n                ``'%Y-%m-%d %H:%M'``.\n\n        \"\"\"\n        if dateTimeFormat is None:\n            dateTimeFormat = '%Y-%m-%d %H:%M'\n\n        scriptStartTime = datetime.datetime.now()\n        try:\n\n            print (\"********************Create Roles********************\")\n\n            print (\"Script started at %s\" % scriptStartTime.strftime(dateTimeFormat))\n\n            if self.securityhandler.valid == False:\n                print (\"Login required\")\n            else:\n                orgTools = orgtools.orgtools(securityinfo=self)\n\n                if orgTools is None:\n                    print (\"Error creating orgtools\")\n                else:\n\n                    for configFile in configFiles:\n\n                        config = common.init_config_json(config_file=configFile)\n                        if config is not None:\n\n                            startTime = datetime.datetime.now()\n                            print (\"Processing config %s, starting at: %s\" % (configFile,startTime.strftime(dateTimeFormat)))\n\n                            roleInfos = config['Roles']\n                            for roleInfo in roleInfos:\n                                createRoleResults = orgTools.createRole(roleInfo['Name'],roleInfo['Description'],roleInfo['Privileges'])\n\n                        else:\n                            print (\"Config %s not found\" % configFile)\n\n\n        except(TypeError,ValueError,AttributeError) as e:\n            print (e)\n        except (common.ArcRestHelperError) as e:\n            print (\"error in function: %s\" % e[0]['function'])\n            print (\"error on line: %s\" % e[0]['line'])\n            print (\"error in file name: %s\" % e[0]['filename'])\n            print (\"with error message: %s\" % e[0]['synerror'])\n            if 'arcpyError' in e[0]:\n                print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n\n        except Exception as e:\n            if (reportToolsInstalled):\n                if isinstance(e,(ReportTools.ReportToolsError,DataPrep.DataPrepError)):\n                    print (\"error in function: %s\" % e[0]['function'])\n                    print (\"error on line: %s\" % e[0]['line'])\n                    print (\"error in file name: %s\" % e[0]['filename'])\n                    print (\"with error message: %s\" % e[0]['synerror'])\n                    if 'arcpyError' in e[0]:\n                        print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n                else:\n                    line, filename, synerror = trace()\n                    print (\"error on line: %s\" % line)\n                    print (\"error in file name: %s\" % filename)\n                    print (\"with error message: %s\" % synerror)\n            else:\n                line, filename, synerror = trace()\n                print (\"error on line: %s\" % line)\n                print (\"error in file name: %s\" % filename)\n                print (\"with error message: %s\" % synerror)\n        finally:\n            print (\"Script complete, time to complete: %s\" % str(datetime.datetime.now() - scriptStartTime))\n            print (\"###############Create Groups Completed#################\")\n            print (\"\")\n\n            #if orgTools is not None:\n                #orgTools.dispose()\n            groupInfo = None\n            groupFile = None\n            iconPath = None\n            startTime = None\n            thumbnail = None\n            result = None\n            config = None\n            sciptPath = None\n            orgTools = None\n            del groupInfo\n            del groupFile\n            del iconPath\n            del startTime\n            del thumbnail\n            del result\n            del config\n            del sciptPath\n            del orgTools\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createGroups(self, configFiles, dateTimeFormat=None):\n        groupInfo = None\n        groupFile = None\n        iconPath = None\n        startTime = None\n        thumbnail = None\n        result = None\n        config = None\n        sciptPath = None\n        orgTools = None\n\n        if dateTimeFormat is None:\n            dateTimeFormat = '%Y-%m-%d %H:%M'\n\n        scriptStartTime = datetime.datetime.now()\n        try:\n\n            print (\"********************Create Groups********************\")\n\n            print (\"Script started at %s\" % scriptStartTime.strftime(dateTimeFormat))\n\n            if self.securityhandler is None or \\\n                self.securityhandler.valid == False:\n                print (\"Login required\")\n            else:\n                orgTools = orgtools.orgtools(securityinfo=self)\n\n                if orgTools is None:\n                    print (\"Error creating orgtools\")\n                else:\n\n                    for configFile in configFiles:\n\n                        config = common.init_config_json(config_file=configFile)\n                        if config is not None:\n\n                            startTime = datetime.datetime.now()\n                            print (\"Processing config %s, starting at: %s\" % (configFile,startTime.strftime(dateTimeFormat)))\n\n                            groupInfo = config['Groups']\n                            groupFile = groupInfo['GroupInfo']\n                            iconPath = groupInfo['IconPath']\n\n                            if os.path.isfile(groupFile):\n                                with open(groupFile, 'rb') as csvfile:\n\n                                    for row in csv.DictReader(csvfile,dialect='excel'):\n                                        if os.path.isfile(os.path.join(iconPath,row['thumbnail'])):\n                                            thumbnail = os.path.join(iconPath,row['thumbnail'])\n                                            if not os.path.isabs(thumbnail):\n\n                                                sciptPath = os.getcwd()\n                                                thumbnail = os.path.join(sciptPath,thumbnail)\n\n                                            result = orgTools.createGroup(title=row['title'],description=row['description'],tags=row['tags'],snippet=row['snippet'],phone=row['phone'],access=row['access'],sortField=row['sortField'],sortOrder=row['sortOrder'], \\\n                                                             isViewOnly=row['isViewOnly'],isInvitationOnly=row['isInvitationOnly'],thumbnail=thumbnail)\n\n                                        else:\n                                            result = orgTools.createGroup(title=row['title'],description=row['description'],tags=row['tags'],snippet=row['snippet'],phone=row['phone'],access=row['access'],sortField=row['sortField'],sortOrder=row['sortOrder'], \\\n                                                             isViewOnly=row['isViewOnly'],isInvitationOnly=row['isInvitationOnly'])\n\n                                        if result is None:\n                                            pass\n                                        else:\n                                            print (\"Group created: \" + result.title)\n\n\n\n                            print (\"Config %s completed, time to complete: %s\" % (configFile, str(datetime.datetime.now() - startTime)))\n\n                        else:\n                            print (\"Config %s not found\" % configFile)\n\n\n        except(TypeError,ValueError,AttributeError) as e:\n            print (e)\n        except (common.ArcRestHelperError) as e:\n            print (\"error in function: %s\" % e[0]['function'])\n            print (\"error on line: %s\" % e[0]['line'])\n            print (\"error in file name: %s\" % e[0]['filename'])\n            print (\"with error message: %s\" % e[0]['synerror'])\n            if 'arcpyError' in e[0]:\n                print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n\n        except Exception as e:\n            if (reportToolsInstalled):\n                if isinstance(e,(ReportTools.ReportToolsError,DataPrep.DataPrepError)):\n                    print (\"error in function: %s\" % e[0]['function'])\n                    print (\"error on line: %s\" % e[0]['line'])\n                    print (\"error in file name: %s\" % e[0]['filename'])\n                    print (\"with error message: %s\" % e[0]['synerror'])\n                    if 'arcpyError' in e[0]:\n                        print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n                else:\n                    line, filename, synerror = trace()\n                    print (\"error on line: %s\" % line)\n                    print (\"error in file name: %s\" % filename)\n                    print (\"with error message: %s\" % synerror)\n            else:\n                line, filename, synerror = trace()\n                print (\"error on line: %s\" % line)\n                print (\"error in file name: %s\" % filename)\n                print (\"with error message: %s\" % synerror)\n        finally:\n            print (\"Script complete, time to complete: %s\" % str(datetime.datetime.now() - scriptStartTime))\n            print (\"###############Create Groups Completed#################\")\n            print (\"\")\n\n            #if orgTools is not None:\n                #orgTools.dispose()\n            groupInfo = None\n            groupFile = None\n            iconPath = None\n            startTime = None\n            thumbnail = None\n            result = None\n            config = None\n            sciptPath = None\n            orgTools = None\n            del groupInfo\n            del groupFile\n            del iconPath\n            del startTime\n            del thumbnail\n            del result\n            del config\n            del sciptPath\n            del orgTools\n\n            gc.collect()", "response": "Parses a JSON configuration file and creates a set of groups."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef publishfromconfig(self, configFiles, combinedApp=None, dateTimeFormat=None):\n        publishTools = None\n        webmaps = None\n        config = None\n        resultsItems = None\n        resultFS = None\n        resultMaps = None\n        resultApps = None\n        combinedResults = None\n\n        if dateTimeFormat is None:\n            dateTimeFormat = '%Y-%m-%d %H:%M'\n\n        scriptStartTime = datetime.datetime.now()\n        try:\n\n            webmaps = []\n            print (\"********************Script Started********************\")\n\n            print (\"Script started at %s\" % scriptStartTime.strftime(dateTimeFormat))\n\n            # start report processing (moved out from under ArcREST logic. no AGO crednetials needed to run reports)\n            for configFile in configFiles:\n                config = common.init_config_json(config_file=configFile)\n                if config is not None:\n                    if 'ReportDetails' in config:\n                        if reportToolsInstalled == False:\n                            print (\"Report section is included in the config file but the solutionreporttools cannot be located\")\n                        else:\n                            reportConfig = config['ReportDetails']\n                            # This code checks to see if you want to export the data from SDE to a local GDB. The parameter is set in config file.\n                            # Could be performance gain to run locally. If you choose this option, both the report and the data prep in memory config\n                            # are modified so they can point to the local temp location.\n\n                            if 'RunReport' in reportConfig and (str(reportConfig['RunReport']).upper() ==\"TRUE\" or str(reportConfig['RunReport']).upper() ==\"YES\"):\n                                reportConfig = ReportTools.reportDataPrep(reportConfig)\n\n                                print (\"-----Report Section Starting-----\")\n                                startTime = datetime.datetime.now()\n                                print (\"Processing reports in config %s, starting at: %s\" % (configFile,startTime.strftime(dateTimeFormat)))\n                                ReportTools.create_report_layers_using_config(config=reportConfig)\n                                print (\"Reports in config %s completed, time to complete: %s\" % (configFile, str(datetime.datetime.now() - startTime)))\n\n                                print (\"-----Report Section Complete-----\")\n                    if 'PublishingDetails' in config:\n                        publishingConfig = config['PublishingDetails']\n\n                        if 'PublishData' in publishingConfig:\n                            publishData = publishingConfig['PublishData']\n                        else:\n                            print (\"PublishingDetails is missing the PublishData parameter:  type string, values, True or False\")\n                            publishData = 'TRUE'\n                        if (str(publishData).upper() ==\"TRUE\" or str(publishData).upper() ==\"YES\"):\n\n                            print (\" \")\n                            print (\"-----Publishing Section Starting-----\")\n                            startTime = datetime.datetime.now()\n                            print (\"Processing publishing in config %s, starting at: %s\" % (configFile,startTime.strftime(dateTimeFormat)))\n\n\n                            publishTools = publishingtools.publishingtools(securityinfo=self)\n                            if publishTools.valid == False :\n                                print (\"Error creating publishing tools: %s\" % publishTools.message)\n                            else:\n                                print (\"Publishing tools created: %s\" % publishTools.message)\n                                resultFS = []\n                                if 'Items' in publishingConfig:\n                                    startSectTime = datetime.datetime.now()\n                                    print (\" \")\n                                    print (\"Creating Items: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n                                    resultsItems = publishTools.publishItems(items_info=publishingConfig['Items'])\n                                    print (\"Items created, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n\n                                if 'FeatureCollections' in publishingConfig:\n                                    startSectTime = datetime.datetime.now()\n                                    print (\" \")\n                                    print (\"Creating Feature Collection: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n                                    resultFS = publishTools.publishFeatureCollections(configs=publishingConfig['FeatureCollections'])\n                                    print (\"Feature Collection published, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n                                if 'FeatureServices' in publishingConfig:\n                                    startSectTime = datetime.datetime.now()\n                                    print (\" \")\n                                    print (\"Creating Feature Services: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n                                    res = publishTools.publishFsFromMXD(fs_config=publishingConfig['FeatureServices'])\n                                    if res is None:\n                                        return\n                                    resultFS = resultFS + res\n                                    if len(resultFS) == 0:\n                                        print (\"Exiting, error creating feature services\")\n                                        return\n                                    print (\"Feature Services published, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n                                if 'ExistingServices' in publishingConfig:\n\n                                    startSectTime = datetime.datetime.now()\n                                    print (\" \")\n                                    print (\"Updating Existing Feature Services: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n                                    resultES = publishTools.updateFeatureService(efs_config=publishingConfig['ExistingServices'])\n                                    print (\"Updating Existing Feature Services completed, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n                                if 'MapDetails' in publishingConfig:\n                                    startSectTime = datetime.datetime.now()\n                                    print (\" \")\n                                    print (\"Creating maps: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n                                    resultMaps = publishTools.publishMap(maps_info=publishingConfig['MapDetails'],fsInfo=resultFS,itInfo=resultsItems)\n                                    for maps in resultMaps:\n                                        if 'MapInfo' in maps:\n                                            if 'Results' in maps['MapInfo']:\n                                                if 'itemId' in maps['MapInfo']['Results']:\n                                                    webmaps.append(maps['MapInfo']['Results']['itemId'])\n                                    print (\"Creating maps completed, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n                                if 'AppDetails' in publishingConfig:\n                                    startSectTime = datetime.datetime.now()\n                                    print (\" \")\n                                    print (\"Creating apps: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n                                    resultApps = publishTools.publishApp(app_info=publishingConfig['AppDetails'],map_info=resultMaps,fsInfo=resultFS)\n                                    print (\"Creating apps completed, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n\n\n                            print (\"Publishing complete in config %s completed, time to complete: %s\" % (configFile, str(datetime.datetime.now() - startTime)))\n\n                            print (\"-----Publishing Section Complete-----\")\n\n                else:\n                    print (\"Config %s not found\" % configFile)\n\n            if combinedApp:\n                if os.path.exists(combinedApp):\n                    print (\" \")\n                    startSectTime = datetime.datetime.now()\n                    print (\"Creating combined result: %s\" % str(startSectTime.strftime(dateTimeFormat)))\n\n                    config = common.init_config_json(config_file=combinedApp)\n                    combinedResults = publishTools.publishCombinedWebMap(maps_info=config['PublishingDetails']['MapDetails'],webmaps=webmaps)\n                    if 'PublishingDetails' in config:\n                        publishingConfig = config['PublishingDetails']\n\n                        if 'PublishData' in publishingConfig:\n                            publishData = publishingConfig['PublishData']\n                        else:\n                            print (\"PublishingDetails is missing the PublishData parameter:  type string, values, True or False\")\n                            publishData = 'TRUE'\n\n                        if (str(publishData).upper() ==\"TRUE\" or str(publishData).upper() ==\"YES\"):\n\n                            if 'AppDetails' in publishingConfig:\n                                resultApps = publishTools.publishApp(app_info=publishingConfig['AppDetails'],map_info=combinedResults)\n                            print (\"Creating combind result completed, time to complete: %s\" % str(datetime.datetime.now() - startSectTime))\n        except(TypeError,ValueError,AttributeError) as e:\n            print (e)\n        except (common.ArcRestHelperError) as e:\n            print (\"error in function: %s\" % e[0]['function'])\n            print (\"error on line: %s\" % e[0]['line'])\n            print (\"error in file name: %s\" % e[0]['filename'])\n            print (\"with error message: %s\" % e[0]['synerror'])\n            if 'arcpyError' in e[0]:\n                print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n\n        except Exception as e:\n            if (reportToolsInstalled):\n                if isinstance(e,(ReportTools.ReportToolsError,DataPrep.DataPrepError)):\n                    print (\"error in function: %s\" % e[0]['function'])\n                    print (\"error on line: %s\" % e[0]['line'])\n                    print (\"error in file name: %s\" % e[0]['filename'])\n                    print (\"with error message: %s\" % e[0]['synerror'])\n                    if 'arcpyError' in e[0]:\n                        print (\"with arcpy message: %s\" % e[0]['arcpyError'])\n                else:\n                    line, filename, synerror = trace()\n                    print (\"error on line: %s\" % line)\n                    print (\"error in file name: %s\" % filename)\n                    print (\"with error message: %s\" % synerror)\n            else:\n                line, filename, synerror = trace()\n                print (\"error on line: %s\" % line)\n                print (\"error in file name: %s\" % filename)\n                print (\"with error message: %s\" % synerror)\n\n        finally:\n            print (\"Script complete, time to complete: %s\" % str(datetime.datetime.now() - scriptStartTime))\n            print (\"###############Script Completed#################\")\n            print (\"\")\n            if publishTools is not None:\n                publishTools.dispose()\n\n            publishTools = None\n            webmaps = None\n            config = None\n            resultFS = None\n            resultsItems = None\n            resultMaps = None\n            resultApps = None\n            combinedResults = None\n\n            del publishTools\n            del webmaps\n            del config\n            del resultFS\n            del resultMaps\n            del resultApps\n            del combinedResults\n            del resultsItems\n            gc.collect()", "response": "Parses a JSON configuration file to publish data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the statistics group to the filter.", "response": "def add(self, statisticType, onStatisticField, outStatisticFieldName=None):\n        \"\"\"\n        Adds the statistics group to the filter.\n\n        outStatistics - is supported on only those layers/tables that\n          indicate supportsStatistics is true.\n        outStatisticFieldName is empty or missing, the map server assigns a\n          field name to the returned statistic field. A valid field name\n          can only contain alphanumeric characters and an underscore.\n        outStatisticFieldName is a reserved keyword of the underlying DBMS,\n          the operation can fail. Try specifying an alternative\n          outStatisticFieldName. When using outStatistics, the only other\n          parameters that can be used are groupByFieldsForStatistics,\n          orderByFields, time, and where.\n        \"\"\"\n        val = {\n            \"statisticType\" : statisticType,\n            \"onStatisticField\" : onStatisticField,\n            \"outStatisticFieldName\" : outStatisticFieldName\n        }\n        if outStatisticFieldName is None:\n            del val['outStatisticFieldName']\n        self._array.append(val)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a layer definition filter", "response": "def addFilter(self, layer_id, where=None, outFields=\"*\"):\n        \"\"\" adds a layer definition filter \"\"\"\n        import copy\n        f = copy.deepcopy(self._filterTemplate)\n        f['layerId'] = layer_id\n        f['outFields'] = outFields\n        if where is not None:\n            f['where'] = where\n        if f not in self._filter:\n            self._filter.append(f)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a layer filter based on the index in the filter list", "response": "def removeFilter(self, filter_index):\n        \"\"\" removes a layer filter based on position in filter list \"\"\"\n        f = self._filter[filter_index]\n        self._filter.remove(f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the geometry value", "response": "def geometry(self, geometry):\n        \"\"\" sets the geometry value \"\"\"\n     \n        if isinstance(geometry, AbstractGeometry):\n            self._geomObject = geometry\n            self._geomType = geometry.type\n        elif arcpyFound :\n            wkid = None\n            wkt = None\n            if (hasattr(geometry, 'spatialReference') and \\\n                       geometry.spatialReference is not None):\n                if (hasattr(geometry.spatialReference, 'factoryCode') and \\\n                            geometry.spatialReference.factoryCode is not None):\n                    wkid = geometry.spatialReference.factoryCode\n                else:\n                    wkt = geometry.spatialReference.exportToString()\n                    \n            if isinstance(geometry, arcpy.Polygon):\n                \n                self._geomObject = Polygon(geometry, wkid=wkid, wkt=wkt)\n                self._geomType = \"esriGeometryPolygon\"\n            elif isinstance(geometry, arcpy.Point):\n                self._geomObject = Point(geometry, wkid=wkid, wkt=wkt)\n                self._geomType = \"esriGeometryPoint\"\n            elif isinstance(geometry, arcpy.Polyline):\n                self._geomObject = Polyline(geometry, wkid=wkid, wkt=wkt)\n                self._geomType = \"esriGeometryPolyline\"\n            elif isinstance(geometry, arcpy.Multipoint):\n                self._geomObject = MultiPoint(geometry, wkid=wkid, wkt=wkt)\n                self._geomType = \"esriGeometryMultipoint\"\n            else:\n                raise AttributeError(\"geometry must be a common.Geometry or arcpy.Geometry type.\")\n        else:\n            raise AttributeError(\"geometry must be a common.Geometry or arcpy.Geometry type.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the key value pair of a geometry filter", "response": "def filter(self):\n        \"\"\" returns the key/value pair of a geometry filter \"\"\"\n\n        val = {\"geometryType\":self.geometryType,\n                \"geometry\": json.dumps(self._geomObject.asDictionary),\n                \"spatialRel\": self.spatialRelation,\n                \"inSR\" : self._geomObject.spatialReference['wkid']}\n        if self._buffer is not None and \\\n           self._units is not None:\n            val['buffer'] = self._buffer\n            val['units'] = self._units\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef layers(self):\n        if self._layers is None:\n            self.__init()\n        lyrs = []\n        for lyr in self._layers:\n            url = self._url + \"/%s\" % lyr['id']\n            lyr['object'] = MobileServiceLayer(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_url=self._proxy_url,\n                                               proxy_port=self._proxy_port,\n                                               initialize=False)\n        return self._layers", "response": "gets the service layers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the cluster object for each server", "response": "def clusters(self):\n        \"\"\"returns the cluster object for each server\"\"\"\n        if self._clusters is not None:\n            self.__init()\n            Cs = []\n            for c in self._clusters:\n                url = self._url + \"/%s\" % c['clusterName']\n                Cs.append(Cluster(url=url,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port,\n                                  initialize=True))\n            self._clusters = Cs\n        return self._clusters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the Cluster Protocol. This will cause the cluster to be restarted with updated protocol configuration.", "response": "def editProtocol(self, clusterProtocolObj):\n        \"\"\"\n        Updates the Cluster Protocol. This will cause the cluster to be\n        restarted with updated protocol configuration.\n        \"\"\"\n        if isinstance(clusterProtocolObj, ClusterProtocol): pass\n        else:\n            raise AttributeError(\"Invalid Input, must be a ClusterProtocal Object\")\n        url = self._url + \"/editProtocol\"\n        params = {\n            \"f\" : \"json\",\n            \"tcpClusterPort\" : str(clusterProtocolObj.value['tcpClusterPort'])\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the default parameters", "response": "def parameters(self):\n        \"\"\" returns the default parameters \"\"\"\n        if self._parameters is None:\n            self.__init()\n        for param in self._parameters:\n            if not isinstance(param['defaultValue'], BaseGPObject):\n                if param['dataType'] == \"GPFeatureRecordSetLayer\":\n                    param['defaultValue'] = GPFeatureRecordSetLayer.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPString\":\n                    param['defaultValue'] = GPString.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPLong\":\n                    param['defaultValue'] = GPLong.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPDouble\":\n                    param['defaultValue'] = GPDouble.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPDate\":\n                    param['defaultValue'] = GPDate.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPBoolean\":\n                    param['defaultValue'] = GPBoolean.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPDataFile\":\n                    param['defaultValue'] = GPDataFile.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPLinearUnit\":\n                    param['defaultValue'] = GPLinearUnit.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPMultiValue\":\n                    param['defaultValue'] = GPMultiValue.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPRasterData\":\n                    param['defaultValue'] = GPRasterData.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPRasterDataLayer\":\n                    param['defaultValue'] = GPRasterDataLayer.fromJSON(json.dumps(param))\n                elif param['dataType'] == \"GPRecordSet\":\n                    param['defaultValue'] = GPRecordSet.fromJSON(json.dumps(param))\n        return self._parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the results or status of a job", "response": "def getJob(self, jobID):\n        \"\"\" returns the results or status of a job \"\"\"\n        url = self._url + \"/jobs/%s\" % (jobID)\n        return GPJob(url=url,\n                     securityHandler=self._securityHandler,\n                     proxy_port=self._proxy_port,\n                     proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef submitJob(self, inputs, method=\"POST\",\n                  outSR=None, processSR=None,\n                  returnZ=False, returnM=False):\n        \"\"\"\n           submits a job to the current task, and returns a job ID\n           Inputs:\n              inputs - list of GP object values\n              method - string - either GET or POST.  The way the service is\n                       submitted.\n              outSR - spatial reference of output geometries\n              processSR - spatial reference that the model will use to\n               perform geometry operations\n              returnZ - Z values will be included in the result if true\n              returnM - M values will be included in the results if true\n           Ouput:\n              JOB ID as a string\n        \"\"\"\n        url = self._url + \"/submitJob\"\n        params = { \"f\" : \"json\" }\n        if not outSR is None:\n            params['env:outSR'] = outSR\n        if not processSR is None:\n            params['end:processSR'] = processSR\n        params['returnZ'] = returnZ\n        params['returnM'] = returnM\n        if not inputs is None:\n            for p in inputs:\n                if isinstance(p, BaseGPObject):\n                    params[p.paramName] = p.value\n        if method.lower() == \"get\":\n            res = self._get(url=url, param_dict=params,\n                               securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)\n            jobUrl = self._url + \"/jobs/%s\" % res['jobId']\n            return GPJob(url=jobUrl,\n                          securityHandler=self._securityHandler,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port,\n                          initialize=True)\n        elif method.lower() == \"post\":\n            res = self._post(url=url, param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)\n            jobUrl = self._url + \"/jobs/%s\" % res['jobId']\n            return GPJob(url=jobUrl,\n                          securityHandler=self._securityHandler,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port,\n                          initialize=True)\n        else:\n            raise AttributeError(\"Invalid input: %s. Must be GET or POST\" \\\n                                 % method)", "response": "This method submits a job to the current task and returns a job ID. The method is GET or POST."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms the execute task method", "response": "def executeTask(self,\n                    inputs,\n                    outSR=None,\n                    processSR=None,\n                    returnZ=False,\n                    returnM=False,\n                    f=\"json\",\n                    method=\"POST\"\n                    ):\n        \"\"\"\n        performs the execute task method\n        \"\"\"\n        params = {\n            \"f\" : f\n        }\n        url = self._url + \"/execute\"\n        params = { \"f\" : \"json\" }\n        if not outSR is None:\n            params['env:outSR'] = outSR\n        if not processSR is None:\n            params['end:processSR'] = processSR\n        params['returnZ'] = returnZ\n        params['returnM'] = returnM\n        for p in inputs:\n            if isinstance(p, BaseGPObject):\n                params[p.paramName] = p.value\n            del p\n        if method.lower() == \"post\":\n            return self._post(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        else:\n            return self._get(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the json dictionary of the object", "response": "def _get_json(self, urlpart):\n        \"\"\"\n        gets the result object dictionary\n        \"\"\"\n        url = self._url + \"/%s\" % urlpart\n        params = {\n            \"f\" : \"json\",\n\n        }\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self.proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getParameterValue(self, parameterName):\n        if  self._results is None:\n            self.__init()\n        parameter = self._results[parameterName]\n        return parameter", "response": "gets a parameter value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning information about the parent", "response": "def parentLayer(self):\n        \"\"\" returns information about the parent \"\"\"\n        if self._parentLayer is None:\n            from ..agol.services import FeatureService\n            self.__init()\n            url = os.path.dirname(self._url)\n            self._parentLayer = FeatureService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_url=self._proxy_url,\n                                               proxy_port=self._proxy_port)\n        return self._parentLayer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield n successive chunks from a list l.", "response": "def _chunks(self, l, n):\n        \"\"\" Yield n successive chunks from a list l.\n        \"\"\"\n        l.sort()\n        newn = int(1.0 * len(l) / n + 0.5)\n        for i in range(0, n-1):\n            yield l[i*newn:i*newn+newn]\n        yield l[n*newn-newn:]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addAttachments(self,\n                       featureId,\n                       attachment,\n                       gdbVersion=None,\n                       uploadId=None):\n        \"\"\"\n        This operation adds an attachment to the associated feature (POST\n        only). The addAttachment operation is performed on a feature\n        service feature resource.\n        Since this request uploads a file, it must be a multipart request\n        pursuant to IETF RFC1867.\n        This operation is available only if the layer has advertised that\n        it has attachments. A layer has attachments if its hasAttachments\n        property is true.\n        See the Limiting upload file size and file types section under\n        Uploads to learn more about default file size and file type\n        limitations imposed on attachments.\n        The result of this operation is an array of edit result objects.\n        Each edit result indicates whether or not the edit was successful.\n        If successful, the objectId of the result is the ID of the new\n        attachment. If unsuccessful, it also includes an error code and\n        error description.\n        You can provide arguments to the addAttachment operation as defined\n        in the following parameters table:\n\n        Inputs:\n           attachment - The file to be uploaded as a new feature\n             attachment. The content type, size, and name of the attachment\n             will be derived from the uploaded file.\n           gdbVersion - Geodatabase version to apply the edits. This\n             parameter applies only if the isDataVersioned property of the\n             layer is true. If the gdbVersion parameter is not specified,\n             edits are made to the published map's version.\n           uploadId - This option was added to the July 2014 of ArcGIS\n             Online. It is not available with ArcGIS Server. The ID of the\n             attachment that has already been uploaded to the server. This\n             parameter only applies if the supportsAttachmentsByUploadId\n             property of the layer is true.\n        \"\"\"\n        if self.hasAttachments == True:\n            url = self._url + \"/%s/addAttachment\" % featureId\n            params = {'f':'json'}\n            if not uploadId is None:\n                params['uploadId'] = uploadId\n            if not gdbVersion is None:\n                params['gdbVersion'] = gdbVersion\n            files = {}\n            files['attachment'] = attachment\n            return self._post(url=url,\n                              param_dict=params,\n                              files=files,\n                              securityHandler=self._securityHandler,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port)\n        else:\n            return \"Attachments are not supported for this feature service.\"", "response": "This operation adds an attachment to an existing feature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query(self,\n              where=\"1=1\",\n              out_fields=\"*\",\n              timeFilter=None,\n              geometryFilter=None,\n              returnGeometry=True,\n              returnIDsOnly=False,\n              returnCountOnly=False,\n              returnFeatureClass=False,\n              returnDistinctValues=False,\n              returnExtentOnly=False,\n              maxAllowableOffset=None,\n              geometryPrecision=None,\n              outSR=None,\n              groupByFieldsForStatistics=None,\n              statisticFilter=None,\n              out_fc=None,\n              **kwargs):\n        \"\"\" queries a feature service based on a sql statement\n            Inputs:\n               where - the selection sql statement\n               out_fields - the attribute fields to return\n               timeFilter - a TimeFilter object where either the start time\n                            or start and end time are defined to limit the\n                            search results for a given time.  The values in\n                            the timeFilter should be as UTC timestampes in\n                            milliseconds.  No checking occurs to see if they\n                            are in the right format.\n               geometryFilter - a GeometryFilter object to parse down a given\n                               query by another spatial dataset.\n               returnGeometry - true means a geometry will be returned,\n                                else just the attributes\n               returnIDsOnly - false is default.  True means only OBJECTIDs\n                               will be returned\n               returnCountOnly - if True, then an integer is returned only\n                                 based on the sql statement\n               returnFeatureClass - Default False. If true, query will be\n                                    returned as feature class\n               out_fc - only valid if returnFeatureClass is set to True.\n                        Output location of query.\n               groupByFieldsForStatistics - One or more field names on\n                                    which the values need to be grouped for\n                                    calculating the statistics.\n               statisticFilter - object that performs statistic queries\n               kwargs - optional parameters that can be passed to the Query\n                 function.  This will allow users to pass additional\n                 parameters not explicitly implemented on the function. A\n                 complete list of functions available is documented on the\n                 Query REST API.\n            Output:\n               A list of Feature Objects (default) or a path to the output featureclass if\n               returnFeatureClass is set to True.\n         \"\"\"\n        params = {\"f\": \"json\",\n                  \"where\": where,\n                  \"outFields\": out_fields,\n                  \"returnGeometry\" : returnGeometry,\n                  \"returnIdsOnly\" : returnIDsOnly,\n                  \"returnCountOnly\" : returnCountOnly,\n                  \"returnDistinctValues\" : returnDistinctValues,\n                  \"returnExtentOnly\" : returnExtentOnly\n                  }\n        if outSR is not None:\n            params['outSR'] = outSR\n        if not maxAllowableOffset is None:\n            params['maxAllowableOffset'] = maxAllowableOffset\n        if not geometryPrecision is None:\n            params['geometryPrecision'] = geometryPrecision\n        for k,v in kwargs.items():\n            params[k] = v\n        if returnDistinctValues:\n            params[\"returnGeometry\"] = False\n        if not timeFilter is None and \\\n           isinstance(timeFilter, filters.TimeFilter):\n            params['time'] = timeFilter.filter\n        if not geometryFilter is None and \\\n           isinstance(geometryFilter, filters.GeometryFilter):\n            gf = geometryFilter.filter\n            params['geometry'] = gf['geometry']\n            params['geometryType'] = gf['geometryType']\n            params['spatialRelationship'] = gf['spatialRel']\n            params['inSR'] = gf['inSR']\n            if \"buffer\" in gf:\n                params['buffer'] = gf['buffer']\n            if \"units\" in gf:\n                params['units'] = gf['units']\n        if not groupByFieldsForStatistics is None:\n            params['groupByFieldsForStatistics'] = groupByFieldsForStatistics\n        if not statisticFilter is None and \\\n           isinstance(statisticFilter, filters.StatisticFilter):\n            params['outStatistics'] = statisticFilter.filter\n        fURL = self._url + \"/query\"\n        results = self._post(fURL, params,\n                               securityHandler=self._securityHandler,\n                               proxy_port=self._proxy_port,\n                               proxy_url=self._proxy_url)\n        if 'error' in results:\n            raise ValueError (results)\n        if not returnCountOnly and not returnIDsOnly and \\\n           not returnDistinctValues and not returnExtentOnly:\n            if returnFeatureClass:\n                json_text = json.dumps(results)\n                temp = scratchFolder() + os.sep + uuid.uuid4().get_hex() + \".json\"\n                with open(temp, 'wb') as writer:\n                    writer.write(json_text)\n                    writer.flush()\n                del writer\n                fc = json_to_featureclass(json_file=temp,\n                                          out_fc=out_fc)\n                os.remove(temp)\n                return fc\n            else:\n                return FeatureSet.fromJSON(json.dumps(results))\n        else:\n            return results\n        return", "response": "This function queries a feature service based on a sql statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the object to a dictionary", "response": "def asDictionary(self):\n        \"\"\" converts the object to a dictionary \"\"\"\n        template = {\"type\" : self._type,\n                    \"mapLayerId\" : self._mapLayerId}\n        if not self._gdbVersion is None and\\\n           self._gdbVersion != \"\":\n            template['gdbVersion'] = self._gdbVersion\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value as a dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the value as a dictionary \"\"\"\n        template =  {\n            \"type\": \"dataLayer\",\n            \"dataSource\": self._dataSource\n        }\n        if not self._fields is None:\n            template['fields'] = self._fields\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the datasource object", "response": "def dataSource(self, value):\n        \"\"\" sets the datasource object \"\"\"\n        if isinstance(value, DataSource):\n            self._dataSource = value\n        else:\n            raise TypeError(\"value must be a DataSource object\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the fields variable", "response": "def fields(self, value):\n        \"\"\"sets the fields variable\"\"\"\n        if type(value) is list:\n            self._fields = value\n        else:\n            raise TypeError(\"Input must be a list\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the data source as JSON", "response": "def asJSON(self):\n        \"\"\" returns the data source as JSON \"\"\"\n        self._json = json.dumps(self.asDictionary)\n        return self._json"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asDictionary(self):\n        self._dict = {\n            \"type\" : self._type,\n            \"workspaceId\" : self._workspaceId,\n            \"dataSourceName\": self._dataSourceName,\n            \"gdbVersion\" : self._gdbVersion\n        }\n        return self._dict", "response": "returns the data source as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the data source as a dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the data source as a dictionary \"\"\"\n        self._dict = {\n            \"type\": \"queryTable\",\n            \"workspaceId\": self._workspaceId,\n            \"query\": self._query,\n            \"oidFields\": self._oidFields,\n            \"spatialReference\": {\"wkid\" : self._wkid}\n        }\n        if self._geometryType != \"\":\n            self._dict[\"geometryType\"] = self._geometryType\n        return self._dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asDictionary(self):\n        return {\n            \"type\": \"joinTable\",\n            \"leftTableSource\": self._leftTableSource,\n            \"rightTableSource\": self._rightTableSource,\n            \"leftTableKey\": self._leftTableKey,\n            \"rightTableKey\": self._rightTableKey,\n            \"joinType\": self._joinType\n        }", "response": "returns the data source as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addCodedValue(self, name, code):\n        i = {\"name\" : name, \"code\" : code}\n        if i not in self._codedValues:\n            self._codedValues.append(i)", "response": "Adds a coded value to the domain\n          "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef removeCodedValue(self, name):\n        for i in self._codedValues:\n            if i['name'] == name:\n                self._codedValues.remove(i)\n                return True\n        return False", "response": "removes a codedValue by name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value as a dictionary", "response": "def value(self):\n        \"\"\"gets the value as a dictionary\"\"\"\n        return {\n            \"type\" : self._type,\n            \"name\" : self._name,\n            \"range\" : [self._rangeMin, self._rangeMax]\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef minValue(self, value):\n        if isinstance(value, [int, float, long]):\n            self._rangeMin = value", "response": "gets or sets the min value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef maxValue(self, value):\n        if isinstance(value, [int, float, long]):\n            self._rangeMax = value", "response": "gets or sets the max value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef securityHandler(self, value):\n        if isinstance(value, BaseSecurityHandler):\n            if isinstance(value, (AGSTokenSecurityHandler,\n                                  PortalServerSecurityHandler)):\n                self._securityHandler = value\n            else:\n                pass\n        elif value is None:\n            self._securityHandler = None", "response": "sets the security handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exportImage(self,\n                    bbox,\n                    imageSR,\n                    bboxSR,\n                    size=[400,400],\n                    time=None,\n                    format=\"jpgpng\",\n                    pixelType=\"UNKNOWN\",\n                    noData=None,\n                    noDataInterpretation=\"esriNoDataMatchAny\",\n                    interpolation=None,\n                    compression=None,\n                    compressionQuality=75,\n                    bandIds=None,\n                    moasiacRule=None,\n                    renderingRule=\"\",\n                    f=\"json\",\n                    saveFolder=None,\n                    saveFile=None\n                    ):\n        \"\"\"\n        The exportImage operation is performed on an image service resource\n        The result of this operation is an image resource. This resource\n        provides information about the exported image, such as its URL,\n        extent, width, and height.\n        In addition to the usual response formats of HTML and JSON, you can\n        also request the image format while performing this operation. When\n        you perform an export with the image format , the server responds\n        by directly streaming the image bytes to the client. With this\n        approach, you don't get any information associated with the\n        exported image other than the image itself.\n\n        Inputs:\n           bbox - The extent (bounding box) of the exported image. Unless\n                  the bboxSR parameter has been specified, the bbox is\n                  assumed to be in the spatial reference of the image\n                  service.\n           imageSR - The spatial reference of the exported image.\n           bboxSR - The spatial reference of the bbox.\n           size - The size (width * height) of the exported image in\n                  pixels. If size is not specified, an image with a default\n                  size of 400 * 400 will be exported.\n           time - The time instant or the time extent of the exported image.\n           format - The format of the exported image. The default format is\n                    jpgpng.\n                    Values: jpgpng | png | png8 | png24 | jpg | bmp | gif |\n                            tiff | png32\n           pixelType - The pixel type, also known as data type, pertains to\n                       the type of values stored in the raster, such as\n                       signed integer, unsigned integer, or floating point.\n                       Integers are whole numbers, whereas floating points\n                       have decimals.\n           noDate - The pixel value representing no information.\n           noDataInterpretation - Interpretation of the noData setting. The\n                               default is esriNoDataMatchAny when noData is\n                               a number, and esriNoDataMatchAll when noData\n                               is a comma-delimited string:\n                               esriNoDataMatchAny | esriNoDataMatchAll.\n           interpolation - The resampling process of extrapolating the\n                           pixel values while transforming the raster\n                           dataset when it undergoes warping or when it\n                           changes coordinate space.\n           compression - Controls how to compress the image when exporting\n                         to TIFF format: None, JPEG, LZ77. It does not\n                         control compression on other formats.\n           compressionQuality - Controls how much loss the image will be\n                                subjected to by the compression algorithm.\n                                Valid value ranges of compression quality\n                                are from 0 to 100.\n           bandIds - If there are multiple bands, you can specify a single\n                     band to export, or you can change the band combination\n                     (red, green, blue) by specifying the band number. Band\n                     number is 0 based.\n           mosaicRule - Specifies the mosaic rule when defining how\n                        individual images should be mosaicked. When a mosaic\n                        rule is not specified, the default mosaic rule of\n                        the image service will be used (as advertised in\n                        the root resource: defaultMosaicMethod,\n                        mosaicOperator, sortField, sortValue).\n           renderingRule - Specifies the rendering rule for how the\n                           requested image should be rendered.\n           f - The response format.  default is json\n               Values: json | image | kmz\n        \"\"\"\n        params = {\n            \"bbox\" : bbox,\n            \"imageSR\": imageSR,\n            \"bboxSR\": bboxSR,\n            \"size\" : \"%s %s\" % (size[0], size[1]),\n            \"pixelType\" : pixelType,\n            \"compressionQuality\" : compressionQuality,\n\n        }\n        url = self._url + \"/exportImage\"\n        __allowedFormat = [\"jpgpng\", \"png\",\n                           \"png8\", \"png24\",\n                           \"jpg\", \"bmp\",\n                           \"gif\", \"tiff\",\n                           \"png32\"]\n        __allowedPixelTypes = [\n            \"C128\", \"C64\", \"F32\",\n            \"F64\", \"S16\", \"S32\",\n            \"S8\", \"U1\", \"U16\",\n            \"U2\", \"U32\", \"U4\",\n            \"U8\", \"UNKNOWN\"\n        ]\n        __allowednoDataInt = [\n            \"esriNoDataMatchAny\",\n            \"esriNoDataMatchAll\"\n        ]\n        __allowedInterpolation = [\n            \"RSP_BilinearInterpolation\",\n            \"RSP_CubicConvolution\",\n            \"RSP_Majority\",\n            \"RSP_NearestNeighbor\"\n        ]\n        __allowedCompression = [\n            \"JPEG\", \"LZ77\"\n        ]\n        if isinstance(moasiacRule,MosaicRuleObject):\n            params[\"moasiacRule\"] = moasiacRule.value\n        if format in __allowedFormat:\n            params['format'] = format\n        if isinstance(time, datetime.datetime):\n            params['time'] = local_time_to_online(time)\n        if interpolation is not None and \\\n           interpolation in __allowedInterpolation and \\\n           isinstance(interpolation, str):\n            params['interpolation'] = interpolation\n        if pixelType is not None and \\\n           pixelType in __allowedPixelTypes:\n            params['pixelType'] = pixelType\n        if noDataInterpretation in __allowedInterpolation:\n            params['noDataInterpretation']  = noDataInterpretation\n        if noData is not None:\n            params['noData'] = noData\n        if compression is not None and \\\n           compression in __allowedCompression:\n            params['compression'] = compression\n        if bandIds is not None and \\\n           isinstance(bandIds, list):\n            params['bandIds'] = \",\".join(bandIds)\n        if renderingRule is not None:\n            params['renderingRule'] = renderingRule\n        params[\"f\" ] = f\n        if f == \"json\":\n            return self._get(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_port=self._proxy_port,\n                                proxy_url=self._proxy_url)\n        elif f == \"image\":\n            result = self._get(url=url,\n                               param_dict=params,\n                               securityHandler=self._securityHandler,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port,\n                               out_folder=saveFolder,\n                               file_name=saveFile)\n            return result\n        elif f == \"kmz\":\n            return self._get(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port,\n                             out_folder=saveFolder,\n                             file_name=saveFile)", "response": "This method is used to export an image from the server to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query(self,\n              where=\"1=1\",\n              out_fields=\"*\",\n              timeFilter=None,\n              geometryFilter=None,\n              returnGeometry=True,\n              returnIDsOnly=False,\n              returnCountOnly=False,\n              pixelSize=None,\n              orderByFields=None,\n              returnDistinctValues=True,\n              outStatistics=None,\n              groupByFieldsForStatistics=None\n              ):\n        \"\"\" queries a feature service based on a sql statement\n            Inputs:\n               where - the selection sql statement\n               out_fields - the attribute fields to return\n               timeFilter - a TimeFilter object where either the start time\n                            or start and end time are defined to limit the\n                            search results for a given time.  The values in\n                            the timeFilter should be as UTC timestampes in\n                            milliseconds.  No checking occurs to see if they\n                            are in the right format.\n               geometryFilter - a GeometryFilter object to parse down a given\n                               query by another spatial dataset.\n               returnGeometry - true means a geometry will be returned,\n                                else just the attributes\n               returnIDsOnly - false is default.  True means only OBJECTIDs\n                               will be returned\n               returnCountOnly - if True, then an integer is returned only\n                                 based on the sql statement\n               pixelSize-Query visible rasters at a given pixel size. If\n                         pixelSize is not specified, rasters at all\n                         resolutions can be queried.\n               orderByFields-Order results by one or more field names. Use\n                             ASC or DESC for ascending or descending order,\n                             respectively\n               returnDistinctValues-  If true, returns distinct values\n                                    based on the fields specified in\n                                    outFields. This parameter applies only\n                                    if the supportsAdvancedQueries property\n                                    of the image service is true.\n               outStatistics- the definitions for one or more field-based\n                              statistics to be calculated.\n               groupByFieldsForStatistics-One or more field names using the\n                                         values that need to be grouped for\n                                         calculating the statistics.\n            Output:\n               A list of Feature Objects (default) or a path to the output featureclass if\n               returnFeatureClass is set to True.\n         \"\"\"\n        params = {\"f\": \"json\",\n                  \"where\": where,\n                  \"outFields\": out_fields,\n                  \"returnGeometry\" : returnGeometry,\n                  \"returnIdsOnly\" : returnIDsOnly,\n                  \"returnCountOnly\" : returnCountOnly,\n                  }\n        if not timeFilter is None and \\\n           isinstance(timeFilter, filters.TimeFilter):\n            params['time'] = timeFilter.filter\n        if not geometryFilter is None and \\\n           isinstance(geometryFilter, filters.GeometryFilter):\n            gf = geometryFilter.filter\n            params['geometry'] = gf['geometry']\n            params['geometryType'] = gf['geometryType']\n            params['spatialRelationship'] = gf['spatialRel']\n            params['inSR'] = gf['inSR']\n        if pixelSize is not None:\n            params['pixelSize'] = pixelSize\n        if orderByFields is not None:\n            params['orderByFields'] = orderByFields\n        if returnDistinctValues is not None:\n            params['returnDistinctValues'] = returnDistinctValues\n\n        url = self._url + \"/query\"\n        return self._get(url=url, param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "This function queries a feature service based on a sql statement."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addRasters(self,\n            rasterType,\n            itemIds=None,\n            serviceUrl=None,\n            computeStatistics=False,\n            buildPyramids=False,\n            buildThumbnail=False,\n            minimumCellSizeFactor=None,\n            maximumCellSizeFactor=None,\n            attributes=None,\n            geodataTransforms=None,\n            geodataTransformApplyMethod=\"esriGeodataTransformApplyAppend\"\n            ):\n        \"\"\"\n        This operation is supported at 10.1 and later.\n        The Add Rasters operation is performed on an image service resource.\n        The Add Rasters operation adds new rasters to an image service\n        (POST only).\n        The added rasters can either be uploaded items, using the itemIds\n        parameter, or published services, using the serviceUrl parameter.\n        If itemIds is specified, uploaded rasters are copied to the image\n        service's dynamic image workspace location; if the serviceUrl is\n        specified, the image service adds the URL to the mosaic dataset no\n        raster files are copied. The serviceUrl is required input for the\n        following raster types: Image Service, Map Service, WCS, and WMS.\n\n        Inputs:\n\n        itemIds - The upload items (raster files) to be added. Either\n         itemIds or serviceUrl is needed to perform this operation.\n            Syntax: itemIds=<itemId1>,<itemId2>\n            Example: itemIds=ib740c7bb-e5d0-4156-9cea-12fa7d3a472c,\n                             ib740c7bb-e2d0-4106-9fea-12fa7d3a482c\n        serviceUrl - The URL of the service to be added. The image service\n         will add this URL to the mosaic dataset. Either itemIds or\n         serviceUrl is needed to perform this operation. The service URL is\n         required for the following raster types: Image Service, Map\n         Service, WCS, and WMS.\n            Example: serviceUrl=http://myserver/arcgis/services/Portland/ImageServer\n        rasterType - The type of raster files being added. Raster types\n         define the metadata and processing template for raster files to be\n         added. Allowed values are listed in image service resource.\n            Example: Raster Dataset | CADRG/ECRG | CIB | DTED | Image Service | Map Service | NITF | WCS | WMS\n        computeStatistics - If true, statistics for the rasters will be\n         computed. The default is false.\n            Values: false | true\n        buildPyramids - If true, builds pyramids for the rasters. The\n         default is false.\n                Values: false | true\n        buildThumbnail\t - If true, generates a thumbnail for the rasters.\n         The default is false.\n                Values: false | true\n        minimumCellSizeFactor - The factor (times raster resolution) used\n         to populate the MinPS field (maximum cell size above which the\n         raster is visible).\n                Syntax: minimumCellSizeFactor=<minimumCellSizeFactor>\n                Example: minimumCellSizeFactor=0.1\n        maximumCellSizeFactor - The factor (times raster resolution) used\n         to populate MaxPS field (maximum cell size below which raster is\n         visible).\n                Syntax: maximumCellSizeFactor=<maximumCellSizeFactor>\n                Example: maximumCellSizeFactor=10\n        attributes - Any attribute for the added rasters.\n                Syntax:\n                {\n                  \"<name1>\" : <value1>,\n                  \"<name2>\" : <value2>\n                }\n                Example:\n                {\n                  \"MinPS\": 0,\n                  \"MaxPS\": 20;\n                  \"Year\" : 2002,\n                  \"State\" : \"Florida\"\n                }\n        geodataTransforms - The geodata transformations applied on the\n         added rasters. A geodata transformation is a mathematical model\n         that performs a geometric transformation on a raster; it defines\n         how the pixels will be transformed when displayed or accessed.\n         Polynomial, projective, identity, and other transformations are\n         available. The geodata transformations are applied to the dataset\n         that is added.\n                Syntax:\n                [\n                {\n                  \"geodataTransform\" : \"<geodataTransformName1>\",\n                  \"geodataTransformArguments\" : {<geodataTransformArguments1>}\n                  },\n                  {\n                  \"geodataTransform\" : \"<geodataTransformName2>\",\n                  \"geodataTransformArguments\" : {<geodataTransformArguments2>}\n                  }\n                ]\n         The syntax of the geodataTransformArguments property varies based\n         on the specified geodataTransform name. See Geodata Transformations\n         documentation for more details.\n        geodataTransformApplyMethod - This parameter defines how to apply\n         the provided geodataTransform. The default is\n         esriGeodataTransformApplyAppend.\n                Values: esriGeodataTransformApplyAppend |\n                esriGeodataTransformApplyReplace |\n                esriGeodataTransformApplyOverwrite\n        \"\"\"\n        url = self._url + \"/add\"\n        params = {\n            \"f\" : \"json\"\n        }\n        if itemIds is None and serviceUrl is None:\n            raise Exception(\"An itemId or serviceUrl must be provided\")\n        if isinstance(itemIds, str):\n            itemIds = [itemIds]\n        if isinstance(serviceUrl, str):\n            serviceUrl = [serviceUrl]\n        params['geodataTransformApplyMethod'] = geodataTransformApplyMethod\n        params['rasterType'] = rasterType\n        params['buildPyramids'] = buildPyramids\n        params['buildThumbnail'] = buildThumbnail\n        params['minimumCellSizeFactor'] = minimumCellSizeFactor\n        params['computeStatistics'] = computeStatistics\n        params['maximumCellSizeFactor'] = maximumCellSizeFactor\n        params['attributes'] = attributes\n        params['geodataTransforms'] = geodataTransforms\n        if not itemIds is None:\n            params['itemIds'] = itemIds\n        if not serviceUrl is None:\n            params['serviceUrl'] = serviceUrl\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation adds new rasters to an image service resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef measure(self,fromGeometry,toGeometry,measureOperation,\n                geometryType=\"esriGeometryPoint\",pixelSize=None,mosaicRule=None,\n                linearUnit=None,angularUnit=None,areaUnit=None):\n        \"\"\"\n        The measure operation is performed on an image service resource. It\n        lets a user measure distance, direction, area, perimeter, and height\n        from an image service. The result of this operation includes the name\n        of the raster dataset being used, sensor name, and measured values.\n\n        The measure operation can be supported by image services from raster\n        datasets and mosaic datasets. Spatial reference is required to perform\n        basic measurement (distance, area, and so on). Sensor metadata (geodata\n        transformation) needs to be present in the data source used by an image\n        service to enable height measurement (for example, imagery with RPCs).\n        The mosaic dataset or service needs to include DEM to perform 3D measure.\n\n        Users can provide arguments to the measure operation as query parameters.\n\n        Inputs:\n\n        fromGeometry - A geometry that defines the \"from\" location of the\n         measurement. The structure of the geometry is the same as the structure\n         of the JSON geometry objects returned by the ArcGIS REST API. In addition\n         to the JSON structures, for points, you can specify the geometry with a\n         simple comma-separated syntax.\n         By default, the geometry is assumed to be in the spatial reference of\n         the image service. You can specify a different spatial reference by\n         using the JSON structure syntax for geometries.\n\n         toGeometry - A geometry that defines the \"to\" location of the measurement.\n         The type of geometry must be the same as fromGeometry. The structure of\n         the geometry is the same as the structure of the JSON geometry objects\n         returned by the ArcGIS REST API. In addition to the JSON structures, for\n         points, you can specify the geometry with a simple comma-separated syntax.\n\n         By default, the geometry is assumed to be in the spatial reference of\n         the image service. You can specify a different spatial reference by\n         using the JSON structure syntax for geometries.\n\n        geometryType - The type of geometry specified by the fromGeometry and\n         toGeometry parameters. The geometry type can be a point, polygon, or\n         envelope. The default geometry type is point.\n         Values: esriGeometryPoint | esriGeometryPolygon | esriGeometryEnvelope\n\n        measureOperation - Specifies the type of measure being performed.\n         Values: esriMensurationPoint | esriMensurationDistanceAndAngle |\n         esriMensurationAreaAndPerimeter | esriMensurationHeightFromBaseAndTop |\n         esriMensurationHeightFromBaseAndTopShadow |\n         esriMensurationHeightFromTopAndTopShadow | esriMensurationCentroid |\n         esriMensurationPoint3D | esriMensurationDistanceAndAngle3D |\n         esriMensurationAreaAndPerimeter3D | esriMensurationCentroid3D\n\n        pixelSize - The pixel level (resolution) being measured. If pixel size\n         is not specified, pixelSize will default to the base resolution of the\n         image service. The raster at the specified pixel size in the mosaic\n         dataset will be used for measurement.\n         The structure of the pixelSize parameter is the same as the structure\n         of the point object returned by the ArcGIS REST API. In addition to the\n         JSON structure, you can specify the pixel size with a simple\n         comma-separated syntax.\n\n        mosaicRule - Specifies the mosaic rule when defining how individual\n         images should be mosaicked. When a mosaic rule is not specified, the\n         default mosaic rule of the image service will be used (as advertised\n         in the root resource: defaultMosaicMethod, mosaicOperator, sortField,\n         sortValue). The first visible image is used by measure.\n\n        linearUnit - The linear unit in which height, length, or perimeters\n         will be calculated. It can be any of the following esriUnits constant.\n         If the unit is not specified, the default is esriMeters. The list of\n         valid esriUnits constants include:\n         esriInches | esriFeet | esriYards | esriMiles | esriNauticalMiles |\n         esriMillimeters | esriCentimeters | esriDecimeters | esriMeters |\n         esriKilometers\n\n        angularUnit - The angular unit in which directions of line segments\n         will be calculated. It can be one of the following esriDirectionUnits\n         constants: esriDURadians | esriDUDecimalDegrees\n         If the unit is not specified, the default is esriDUDecimalDegrees.\n\n        areaUnit - The area unit in which areas of polygons will be calculated.\n         It can be any esriAreaUnits constant. If the unit is not specified, the\n         default is esriSquareMeters. The list of valid esriAreaUnits constants\n         include:\n         esriSquareInches | esriSquareFeet | esriSquareYards | esriAcres |\n         esriSquareMiles | esriSquareMillimeters | esriSquareCentimeters |\n         esriSquareDecimeters | esriSquareMeters | esriAres | esriHectares |\n         esriSquareKilometers\n        \"\"\"\n\n        url = self._url + \"/measure\"\n        params = {\n            \"f\" : \"json\",\n            \"fromGeometry\" : fromGeometry,\n            \"toGeometry\": toGeometry,\n            \"geometryType\": geometryType,\n            \"measureOperation\": measureOperation\n            }\n\n        if not pixelSize is None:\n            params[\"pixelSize\"] = pixelSize\n        if not mosaicRule is None:\n            params[\"mosaicRule\"] = mosaicRule\n        if not linearUnit is None:\n            params[\"linearUnit\"] = linearUnit\n        if not angularUnit is None:\n            params[\"angularUnit\"] = angularUnit\n        if not areaUnit is None:\n            params[\"areaUnit\"] = areaUnit\n\n        return self._get(url=url,\n                         param_dict=params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)", "response": "This method performs a measure operation on an image service resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getSamples(self,geometry,geometryType=\"esriGeometryPoint\",\n                   sampleDistance=None,sampleCount=None,mosaicRule=None,\n                   pixelSize=None,returnFirstValueOnly=None,interpolation=None,\n                   outFields=None):\n        \"\"\"\n        The getSamples operation is performed on an image service resource.\n        The getSamples operation is supported by both mosaic dataset and raster\n        dataset image services.\n        The result of this operation includes sample point locations, pixel\n        values, and corresponding spatial resolutions of the source data for a\n        given geometry. When the input geometry is a polyline, envelope, or\n        polygon, sampling is based on sampleCount or sampleDistance; when the\n        input geometry is a point or multipoint, the point or points are used\n        directly.\n        The number of sample locations in the response is based on the\n        sampleDistance or sampleCount parameter and cannot exceed the limit of\n        the image service (the default is 1000, which is an approximate limit).\n\n        Inputs:\n\n        geometry - A geometry that defines the location(s) to be sampled. The\n         structure of the geometry is the same as the structure of the JSON\n         geometry objects returned by the ArcGIS REST API. Applicable geometry\n         types are point, multipoint, polyline, polygon, and envelope. When\n         spatialReference is omitted in the input geometry, it will be assumed\n         to be the spatial reference of the image service.\n\n        geometryType - The type of geometry specified by the geometry parameter.\n         The geometry type can be point, multipoint, polyline, polygon, or envelope.\n         Values: esriGeometryPoint | esriGeometryMultipoint | esriGeometryPolyline |\n         esriGeometryPolygon | esriGeometryEnvelope\n\n        sampleDistance - The distance interval used to sample points from the\n         provided path. The unit is the same as the input geometry. If neither\n         sampleCount nor sampleDistance is provided, no densification can be done\n         for paths (polylines), and a default sampleCount (100) is used for areas\n         (polygons or envelopes).\n\n        sampleCount - The approximate number of sample locations from the provided\n         path. If neither sampleCount nor sampleDistance is provided, no\n         densification can be done for paths (polylines), and a default\n         sampleCount (100) is used for areas (polygons or envelopes).\n\n        mosaicRule - Specifies the mosaic rule defining the image sort order.\n         Additional filtering can be applied to the where clause and FIDs of a\n         mosaic rule.\n\n        pixelSize - The raster that is visible at the specified pixel size in the\n         mosaic dataset will be used for sampling. If pixelSize is not specified,\n         the service's pixel size is used.\n         The structure of the esri_codephpixelSize parameter is the same as the\n         structure of the point object returned by the ArcGIS REST API. In addition\n         to the JSON structure, you can specify the pixel size with a simple\n         comma-separated syntax.\n\n        returnFirstValueOnly - Indicates whether to return all values at a point,\n         or return the first non-NoData value based on the current mosaic rule.\n         The default is true.\n\n        interpolation - This parameter was added at 10.3. The resampling method.\n         Default is nearest neighbor.\n\n        outFields - This parameter was added at 10.3. The list of fields to be\n         included in the response. This list is a comma-delimited list of field\n         names. You can also specify the wildcard character (*) as the value of\n         this parameter to include all the field values in the results.\n        \"\"\"\n\n        url = self._url + \"/getSamples\"\n        params = {\n            \"f\" : \"json\",\n            \"geometry\" : geometry,\n            \"geometryType\": geometryType\n        }\n\n        if not sampleDistance is None:\n            params[\"sampleDistance\"] = sampleDistance\n        if not sampleCount is None:\n            params[\"sampleCount\"] = sampleCount\n        if not mosaicRule is None:\n            params[\"mosaicRule\"] = mosaicRule\n        if not pixelSize is None:\n            params[\"pixelSize\"] = pixelSize\n        if not returnFirstValueOnly is None:\n            params[\"returnFirstValueOnly\"] = returnFirstValueOnly\n        if not interpolation is None:\n            params[\"interpolation\"] = interpolation\n        if not outFields is None:\n            params[\"outFields\"] = outFields\n\n        return self._get(url=url,\n                         param_dict=params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)", "response": "This method is used to get a list of samples from the image service resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef registerItem(self, itemName, description=None):\n        url = self._url + \"/register\"\n        params = {\n            \"f\" : \"json\",\n            \"itemName\" : itemName,\n            \"description\" : \"\"\n        }\n        if description is not None:\n            params['description'] = description\n        return self._post(url=url,\n                             param_dict=params,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port,\n                             securityHandler=self._securityHandler)", "response": "This operation creates an entry for a given item. The item is uploaded by parts. The parts are merged together. The item is uploaded by parts. The parts are merged together. The item is uploaded by parts. The parts are merged together. The item is uploaded by parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the data by small parts. If commit is set to true, then parts will be merged together. If commit is false, the function will return the registerID so a manual commit can occur. If the user's file is over 10mbs, the uploadByParts should be used. Inputs: registerID - ID of the registered item filePath - path of the file to upload commit - default True, lets the function know if server will piece the file back together on the server side. Output: dictionary or string", "response": "def uploadByParts(self, registerID, filePath, commit=True):\n        \"\"\"\n        loads the data by small parts. If commit is set to true,\n        then parts will be merged together.  If commit is false, the\n        function will return the registerID so a manual commit can occur.\n\n        If the user's file is over 10mbs, the uploadByParts should be used.\n\n        Inputs:\n         registerID - ID of the registered item\n         filePath - path of the file to upload\n         commit - default True, lets the function know if server will piece\n          the file back together on the server side.\n        Output:\n          dictionary or string\n        \"\"\"\n        url = self._url + \"/%s/uploadPart\" % registerID\n        params = {\n            \"f\" : \"json\"\n        }\n        with open(filePath, 'rb') as f:\n            mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n            size = 1000000\n            steps =  int(os.fstat(f.fileno()).st_size / size)\n            if os.fstat(f.fileno()).st_size % size > 0:\n                steps += 1\n            for i in range(steps):\n                files = {}\n                tempFile = os.path.join(os.environ['TEMP'], \"split.part%s\" % i)\n                if os.path.isfile(tempFile):\n                    os.remove(tempFile)\n                with open(tempFile, 'wb') as writer:\n                    writer.write(mm.read(size))\n                    writer.flush()\n                    writer.close()\n                del writer\n                files['file'] = tempFile\n                params['partNum'] = i + 1\n                res = self._post(url=url,\n                                  param_dict=params,\n                                  files=files,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port)\n                os.remove(tempFile)\n                del files\n            del mm\n        return self.commit(registerID)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uploads(self):\n        if self.syncEnabled == True:\n            return Uploads(url=self._url + \"/uploads\",\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        return None", "response": "returns the class to perform the upload function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef administration(self):\n        url = self._url\n        res = search(\"/rest/\", url).span()\n        addText = \"admin/\"\n        part1 = url[:res[1]]\n        part2 = url[res[1]:]\n        adminURL = \"%s%s%s\" % (part1, addText, part2)\n\n        res = AdminFeatureService(url=url,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port,\n                            initialize=False)\n        return res", "response": "returns the hostservice object to manage the back - end functions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the replicas for a feature service", "response": "def replicas(self):\n        \"\"\" returns all the replicas for a feature service \"\"\"\n        params = {\n            \"f\" : \"json\",\n\n        }\n        url = self._url + \"/replicas\"\n        return self._get(url, params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef createReplica(self,\n                      replicaName,\n                      layers,\n                      layerQueries=None,\n                      geometryFilter=None,\n                      replicaSR=None,\n                      transportType=\"esriTransportTypeUrl\",\n                      returnAttachments=False,\n                      returnAttachmentsDatabyURL=False,\n                      async=False,\n                      attachmentsSyncDirection=\"none\",\n                      syncModel=\"none\",\n                      dataFormat=\"json\",\n                      replicaOptions=None,\n                      wait=False,\n                      out_path=None):\n        \"\"\"\n        The createReplica operation is performed on a feature service\n        resource. This operation creates the replica between the feature\n        service and a client based on a client-supplied replica definition.\n        It requires the Sync capability. See Sync overview for more\n        information on sync. The response for createReplica includes\n        replicaID, server generation number, and data similar to the\n        response from the feature service query operation.\n        The createReplica operation returns a response of type\n        esriReplicaResponseTypeData, as the response has data for the\n        layers in the replica. If the operation is called to register\n        existing data by using replicaOptions, the response type will be\n        esriReplicaResponseTypeInfo, and the response will not contain data\n        for the layers in the replica.\n\n        Inputs:\n           replicaName - name of the replica\n           layers - layers to export\n           layerQueries - In addition to the layers and geometry parameters, the layerQueries\n            parameter can be used to further define what is replicated. This\n            parameter allows you to set properties on a per layer or per table\n            basis. Only the properties for the layers and tables that you want\n            changed from the default are required.\n            Example:\n             layerQueries = {\"0\":{\"queryOption\": \"useFilter\", \"useGeometry\": true,\n             \"where\": \"requires_inspection = Yes\"}}\n           geometryFilter - Geospatial filter applied to the replica to\n            parse down data output.\n           returnAttachments - If true, attachments are added to the replica and returned in the\n            response. Otherwise, attachments are not included.\n           returnAttachmentDatabyURL -  If true, a reference to a URL will be provided for each\n            attachment returned from createReplica. Otherwise,\n            attachments are embedded in the response.\n           replicaSR - the spatial reference of the replica geometry.\n           transportType -  The transportType represents the response format. If the\n            transportType is esriTransportTypeUrl, the JSON response is contained in a file,\n            and the URL link to the file is returned. Otherwise, the JSON object is returned\n            directly. The default is esriTransportTypeUrl.\n            If async is true, the results will always be returned as if transportType is\n            esriTransportTypeUrl. If dataFormat is sqlite, the transportFormat will always be\n            esriTransportTypeUrl regardless of how the parameter is set.\n            Values: esriTransportTypeUrl | esriTransportTypeEmbedded\n           returnAttachments - If true, attachments are added to the replica and returned in\n            the response. Otherwise, attachments are not included. The default is false. This\n            parameter is only applicable if the feature service has attachments.\n           returnAttachmentsDatabyURL -  If true, a reference to a URL will be provided for\n            each attachment returned from createReplica. Otherwise, attachments are embedded\n            in the response. The default is true. This parameter is only applicable if the\n            feature service has attachments and if returnAttachments is true.\n           attachmentsSyncDirection - Client can specify the attachmentsSyncDirection when\n            creating a replica. AttachmentsSyncDirection is currently a createReplica property\n            and cannot be overridden during sync.\n            Values: none, upload, bidirectional\n           async - If true, the request is processed as an asynchronous job, and a URL is\n            returned that a client can visit to check the status of the job. See the topic on\n            asynchronous usage for more information. The default is false.\n           syncModel - Client can specify the attachmentsSyncDirection when creating a replica.\n            AttachmentsSyncDirection is currently a createReplica property and cannot be\n            overridden during sync.\n           dataFormat - The format of the replica geodatabase returned in the response. The\n            default is json.\n            Values: filegdb, json, sqlite, shapefile\n           replicaOptions - This parameter instructs the createReplica operation to create a\n            new replica based on an existing replica definition (refReplicaId). It can be used\n            to specify parameters for registration of existing data for sync. The operation\n            will create a replica but will not return data. The responseType returned in the\n            createReplica response will be esriReplicaResponseTypeInfo.\n           wait - if async, wait to pause the process until the async operation is completed.\n           out_path - folder path to save the file\n        \"\"\"\n        if self.syncEnabled == False and \"Extract\" not in self.capabilities:\n            return None\n        url = self._url + \"/createReplica\"\n        dataformat = [\"filegdb\", \"json\", \"sqlite\", \"shapefile\"]\n        params = {\"f\" : \"json\",\n                  \"replicaName\": replicaName,\n                  \"returnAttachments\": returnAttachments,\n                  \"returnAttachmentsDatabyURL\": returnAttachmentsDatabyURL,\n                  \"attachmentsSyncDirection\" : attachmentsSyncDirection,\n                  \"async\" : async,\n                  \"syncModel\" : syncModel,\n                  \"layers\" : layers\n                  }\n        if dataFormat.lower() in dataformat:\n            params['dataFormat'] = dataFormat.lower()\n        else:\n            raise Exception(\"Invalid dataFormat\")\n        if layerQueries is not None:\n            params['layerQueries'] = layerQueries\n        if geometryFilter is not None and \\\n           isinstance(geometryFilter, GeometryFilter):\n            params.update(geometryFilter.filter)\n        if replicaSR is not None:\n            params['replicaSR'] = replicaSR\n        if replicaOptions is not None:\n            params['replicaOptions'] = replicaOptions\n        if transportType is not None:\n            params['transportType'] = transportType\n\n        if async:\n            if wait:\n                exportJob = self._post(url=url,\n                                          param_dict=params,\n                                          securityHandler=self._securityHandler,\n                                          proxy_url=self._proxy_url,\n                                          proxy_port=self._proxy_port)\n                status = self.replicaStatus(url=exportJob['statusUrl'])\n                while status['status'].lower() != \"completed\":\n                    status = self.replicaStatus(url=exportJob['statusUrl'])\n                    if status['status'].lower() == \"failed\":\n                        return status\n\n                res = status\n\n            else:\n                res = self._post(url=url,\n                                     param_dict=params,\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port)\n        else:\n            res = self._post(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)\n\n\n        if out_path is not None and \\\n           os.path.isdir(out_path):\n            dlURL = None\n            if 'resultUrl' in res:\n                dlURL = res[\"resultUrl\"]\n            elif 'responseUrl' in res:\n                dlURL = res[\"responseUrl\"]\n            elif 'URL' in res:\n                dlURL = res[\"URL\"]\n            if dlURL is not None:\n                return self._get(url=dlURL,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port,\n                                 out_folder=out_path)\n            else:\n                return res\n        elif res is not None:\n            return res\n        return None", "response": "This method creates a replica between a feature service and a client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replicaStatus(self, url):\n        params = {\"f\" : \"json\"}\n        url = url + \"/status\"\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)", "response": "gets the replica status when exported async set to True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __init(self):\n        params = {\n            \"f\" : \"json\",\n        }\n        json_dict = self._get(self._url, params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        self._json_dict = json_dict\n        self._json = json.dumps(json_dict, default=self._date_handler)\n        attributes = [attr for attr in dir(self)\n                      if not attr.startswith('__') and \\\n                      not attr.startswith('_')]\n        for k,v in json_dict.items():\n            if k in attributes:\n                setattr(self, \"_\"+ k, json_dict[k])\n            else:\n                print(\"%s - attribute not implemented in Feature Layer.\" % k)\n        if self._parentLayer is None:\n            self._parentLayer = FeatureService(\n                url=os.path.dirname(self._url),\n                securityHandler=self._securityHandler,\n                proxy_port=self._proxy_port,\n                proxy_url=self._proxy_url, initialize=False)", "response": "initializes the object properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef securityHandler(self, value):\n        if isinstance(value, abstract.BaseSecurityHandler):\n            if isinstance(value, security.AGOLTokenSecurityHandler):\n                self._securityHandler = value\n                self._token = value.token\n                self._username = value.username\n                self._password = value._password\n                self._token_url = value.token_url\n            elif isinstance(value, security.OAuthSecurityHandler):\n                self._token = value.token\n                self._securityHandler = value\n            else:\n                pass", "response": "sets the security handler"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addAttachment(self, oid, file_path):\n        if self.hasAttachments == True:\n            attachURL = self._url + \"/%s/addAttachment\" % oid\n            params = {'f':'json'}\n            parsed = urlparse.urlparse(attachURL)\n\n            files = {'attachment': file_path}\n            res = self._post(url=attachURL,\n                             param_dict=params,\n                             files=files,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)\n            return self._unicode_convert(res)\n        else:\n            return \"Attachments are not supported for this feature service.\"", "response": "Adds an attachment to a feature service object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates an existing attachment with a new file Inputs: oid - string/integer - Unique record ID attachment_id - integer - Unique attachment identifier file_path - string - path to new attachment Output: JSON response", "response": "def updateAttachment(self, oid, attachment_id, file_path):\n        \"\"\" updates an existing attachment with a new file\n            Inputs:\n               oid - string/integer - Unique record ID\n               attachment_id - integer - Unique attachment identifier\n               file_path - string - path to new attachment\n            Output:\n               JSON response\n        \"\"\"\n        url = self._url + \"/%s/updateAttachment\" % oid\n        params = {\n            \"f\":\"json\",\n            \"attachmentId\" : \"%s\" % attachment_id\n        }\n        files = {'attachment': file_path }\n        res = self._post(url=url,\n                             param_dict=params,\n                             files=files,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)\n        return self._unicode_convert(res)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listAttachments(self, oid):\n        url = self._url + \"/%s/attachments\" % oid\n        params = {\n            \"f\":\"json\"\n        }\n        return self._get(url, params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)", "response": "returns a list of attachments for a given OBJECT ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a feature s attachment.", "response": "def getAttachment(self, oid, attachment_id, out_folder=None):\n        \"\"\"\n        downloads a feature's attachment.\n\n        Inputs:\n           oid - object id of the feature\n           attachment_id - ID of the attachment.  Should be an integer.\n           out_folder - save path of the file\n        Output:\n           string - full path of the file\n        \"\"\"\n        attachments = self.listAttachments(oid=oid)\n        if \"attachmentInfos\" in attachments:\n            for attachment in attachments['attachmentInfos']:\n                if \"id\" in attachment and \\\n                   attachment['id'] == attachment_id:\n                    url = self._url + \"/%s/attachments/%s\" % (oid, attachment_id)\n                    return self._get(url=url, param_dict={\"f\":'json'},\n                                     securityHandler=self._securityHandler,\n                                     out_folder=out_folder,\n                                     file_name=attachment['name'])\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a featureclass template on local disk", "response": "def create_fc_template(self, out_path, out_name):\n        \"\"\"creates a featureclass template on local disk\"\"\"\n        fields = self.fields\n        objectIdField = self.objectIdField\n        geomType = self.geometryType\n        wkid = self.parentLayer.spatialReference['wkid']\n        return create_feature_class(out_path,\n                                    out_name,\n                                    geomType,\n                                    wkid,\n                                    fields,\n                                    objectIdField)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a feature template", "response": "def create_feature_template(self):\n        \"\"\"creates a feature template\"\"\"\n        fields = self.fields\n        feat_schema = {}\n\n        att = {}\n        for fld in fields:\n            self._globalIdField\n            if not fld['name'] == self._objectIdField and not fld['name'] == self._globalIdField:\n                att[fld['name']] = ''\n\n        feat_schema['attributes'] = att\n        feat_schema['geometry'] = ''\n        return Feature(feat_schema)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying a feature service based on a sql statement Inputs: where - the selection sql statement out_fields - the attribute fields to return objectIds - The object IDs of this layer or table to be queried. distance - The buffer distance for the input geometries. The distance unit is specified by units. For example, if the distance is 100, the query geometry is a point, units is set to meters, and all points within 100 meters of the point are returned. units - The unit for calculating the buffer distance. If unit is not specified, the unit is derived from the geometry spatial reference. If the geometry spatial reference is not specified, the unit is derived from the feature service data spatial reference. This parameter only applies if supportsQueryWithDistance is true. Values: esriSRUnit_Meter | esriSRUnit_StatuteMile | esriSRUnit_Foot | esriSRUnit_Kilometer | esriSRUnit_NauticalMile | esriSRUnit_USNauticalMile timeFilter - a TimeFilter object where either the start time or start and end time are defined to limit the search results for a given time. The values in the timeFilter should be as UTC timestampes in milliseconds. No checking occurs to see if they are in the right format. geometryFilter - a GeometryFilter object to parse down a given query by another spatial dataset. maxAllowableOffset - This option can be used to specify the maxAllowableOffset to be used for generalizing geometries returned by the query operation. The maxAllowableOffset is in the units of outSR. If outSR is not specified, maxAllowableOffset is assumed to be in the unit of the spatial reference of the map. outSR - The spatial reference of the returned geometry. geometryPrecision - This option can be used to specify the number of decimal places in the response geometries returned by the Query operation. gdbVersion - Geodatabase version to query returnDistinctValues - If true, it returns distinct values based on the fields specified in outFields. This parameter applies only if the supportsAdvancedQueries property of the layer is true. returnIDsOnly - If true, the response only includes an array of object IDs. Otherwise, the response is a feature set. The default is false. returnCountOnly - If true, the response only includes the count (number of features/records) that would be returned by a query. Otherwise, the response is a feature set. The default is false. This option supersedes the returnIdsOnly parameter. If returnCountOnly = true, the response will return both the count and the extent. returnExtentOnly - If true, the response only includes the extent of the features that would be returned by the query. If returnCountOnly=true, the response will return both the count and the extent. The default is false. This parameter applies only if the supportsReturningQueryExtent property of the layer is true. orderByFields - One or more field names on which the features/records need to be ordered. Use ASC or DESC for ascending or descending, respectively, following every field to control the ordering. groupByFieldsForStatistics - One or more field names on which the values need to be grouped for calculating the statistics. outStatistics - The definitions for one or more field-based statistics to be calculated. returnZ - If true, Z values are included in the results if the features have Z values. Otherwise, Z values are not returned. The default is false. returnM - If true, M values are included in the results if the features have M values. Otherwise, M values are not returned. The default is false. multipatchOption - This option dictates how the geometry of a multipatch feature will be returned. resultOffset - This option can be used for fetching query results by skipping the specified number of records and starting from the next record (that is, resultOffset + 1th). resultRecordCount - This option can be used for fetching query results up to the resultRecordCount specified. When resultOffset is specified but this parameter is not, the map service defaults it to maxRecordCount. The maximum value for this parameter is the value of the layer's maxRecordCount property. quanitizationParameters - Used to project the geometry onto a virtual grid, likely representing pixels on the screen. returnCentroid - Used to return the geometry centroid associated with each feature returned. If true, the result includes the geometry centroid. The default is false. as_json - If true, the query will return as the raw JSON. The default is False. returnFeatureClass - If true and arcpy is installed, the script will attempt to save the result of the query to a feature class. out_fc - only valid if returnFeatureClass is set to True. Output location of query. If out_fc is set to None, then the feature class will be saved to the scratch File Geodatabase with a random name. kwargs - optional parameters that can be passed to the Query function. This will allow users to pass additional parameters not explicitly implemented on the function. A complete list of functions available is documented on the Query REST API. Output: A list of Feature Objects (default) or a path to the output featureclass if returnFeatureClass is set to True.", "response": "def query(self,\n              where=\"1=1\",\n              out_fields=\"*\",\n              timeFilter=None,\n              geometryFilter=None,\n              returnGeometry=True,\n              returnCountOnly=False,\n              returnIDsOnly=False,\n              returnFeatureClass=False,\n              returnDistinctValues=False,\n              returnExtentOnly=False,\n              groupByFieldsForStatistics=None,\n              statisticFilter=None,\n              resultOffset=None,\n              resultRecordCount=None,\n              out_fc=None,\n              objectIds=None,\n              distance=None,\n              units=None,\n              maxAllowableOffset=None,\n              outSR=None,\n              geometryPrecision=None,\n              gdbVersion=None,\n              orderByFields=None,\n              outStatistics=None,\n              returnZ=False,\n              returnM=False,\n              multipatchOption=None,\n              quanitizationParameters=None,\n              returnCentroid=False,\n              as_json=False,\n              **kwargs):\n        \"\"\" queries a feature service based on a sql statement\n            Inputs:\n                where - the selection sql statement\n                out_fields - the attribute fields to return\n                objectIds -  The object IDs of this layer or table to be\n                            queried.\n                distance - The buffer distance for the input geometries.\n                          The distance unit is specified by units. For\n                          example, if the distance is 100, the query\n                          geometry is a point, units is set to meters, and\n                          all points within 100 meters of the point are\n                          returned.\n                units - The unit for calculating the buffer distance. If\n                        unit is not specified, the unit is derived from the\n                        geometry spatial reference. If the geometry spatial\n                        reference is not specified, the unit is derived\n                        from the feature service data spatial reference.\n                        This parameter only applies if\n                        supportsQueryWithDistance is true.\n                        Values: esriSRUnit_Meter | esriSRUnit_StatuteMile |\n                        esriSRUnit_Foot | esriSRUnit_Kilometer |\n                        esriSRUnit_NauticalMile | esriSRUnit_USNauticalMile\n                timeFilter - a TimeFilter object where either the start time\n                            or start and end time are defined to limit the\n                            search results for a given time.  The values in\n                            the timeFilter should be as UTC timestampes in\n                            milliseconds.  No checking occurs to see if they\n                            are in the right format.\n                geometryFilter - a GeometryFilter object to parse down a given\n                               query by another spatial dataset.\n                maxAllowableOffset - This option can be used to specify the\n                                     maxAllowableOffset to be used for\n                                     generalizing geometries returned by\n                                     the query operation.\n                                     The maxAllowableOffset is in the units\n                                     of outSR. If outSR is not specified,\n                                     maxAllowableOffset is assumed to be in\n                                     the unit of the spatial reference of\n                                     the map.\n                outSR - The spatial reference of the returned geometry.\n                geometryPrecision -  This option can be used to specify the\n                                     number of decimal places in the\n                                     response geometries returned by the\n                                     Query operation.\n                gdbVersion - Geodatabase version to query\n                returnDistinctValues -  If true, it returns distinct values\n                                        based on the fields specified in\n                                        outFields. This parameter applies\n                                        only if the\n                                        supportsAdvancedQueries property of\n                                        the layer is true.\n                returnIDsOnly -  If true, the response only includes an\n                                 array of object IDs. Otherwise, the\n                                 response is a feature set. The default is\n                                 false.\n                returnCountOnly -  If true, the response only includes the\n                                   count (number of features/records) that\n                                   would be returned by a query. Otherwise,\n                                   the response is a feature set. The\n                                   default is false. This option supersedes\n                                   the returnIdsOnly parameter. If\n                                   returnCountOnly = true, the response will\n                                   return both the count and the extent.\n                returnExtentOnly -  If true, the response only includes the\n                                    extent of the features that would be\n                                    returned by the query. If\n                                    returnCountOnly=true, the response will\n                                    return both the count and the extent.\n                                    The default is false. This parameter\n                                    applies only if the\n                                    supportsReturningQueryExtent property\n                                    of the layer is true.\n                orderByFields - One or more field names on which the\n                                features/records need to be ordered. Use\n                                ASC or DESC for ascending or descending,\n                                respectively, following every field to\n                                control the ordering.\n                groupByFieldsForStatistics - One or more field names on\n                                             which the values need to be\n                                             grouped for calculating the\n                                             statistics.\n                outStatistics - The definitions for one or more field-based\n                                statistics to be calculated.\n                returnZ -  If true, Z values are included in the results if\n                           the features have Z values. Otherwise, Z values\n                           are not returned. The default is false.\n                returnM - If true, M values are included in the results if\n                          the features have M values. Otherwise, M values\n                          are not returned. The default is false.\n                multipatchOption - This option dictates how the geometry of\n                                   a multipatch feature will be returned.\n                resultOffset -  This option can be used for fetching query\n                                results by skipping the specified number of\n                                records and starting from the next record\n                                (that is, resultOffset + 1th).\n                resultRecordCount - This option can be used for fetching\n                                    query results up to the\n                                    resultRecordCount specified. When\n                                    resultOffset is specified but this\n                                    parameter is not, the map service\n                                    defaults it to maxRecordCount. The\n                                    maximum value for this parameter is the\n                                    value of the layer's maxRecordCount\n                                    property.\n                quanitizationParameters - Used to project the geometry onto\n                                          a virtual grid, likely\n                                          representing pixels on the screen.\n                returnCentroid - Used to return the geometry centroid\n                                 associated with each feature returned. If\n                                 true, the result includes the geometry\n                                 centroid. The default is false.\n                as_json - If true, the query will return as the raw JSON.\n                          The default is False.\n                returnFeatureClass - If true and arcpy is installed, the\n                                     script will attempt to save the result\n                                     of the query to a feature class.\n                out_fc - only valid if returnFeatureClass is set to True.\n                         Output location of query. If out_fc is set to None,\n                         then the feature class will be saved to the scratch\n                         File Geodatabase with a random name.\n               kwargs - optional parameters that can be passed to the Query\n                 function.  This will allow users to pass additional\n                 parameters not explicitly implemented on the function. A\n                 complete list of functions available is documented on the\n                 Query REST API.\n            Output:\n               A list of Feature Objects (default) or a path to the output featureclass if\n               returnFeatureClass is set to True.\n         \"\"\"\n        url = self._url + \"/query\"\n        params = {\"f\" : \"json\"}\n        params['where'] = where\n        params['outFields'] = out_fields\n        params['returnGeometry'] = returnGeometry\n        params['returnDistinctValues'] = returnDistinctValues\n        params['returnCentroid'] = returnCentroid\n        params['returnCountOnly'] = returnCountOnly\n        params['returnExtentOnly'] = returnExtentOnly\n        params['returnIdsOnly'] = returnIDsOnly\n        params['returnZ'] = returnZ\n        params['returnM'] = returnM\n        if resultRecordCount:\n            params['resultRecordCount'] = resultRecordCount\n        if resultOffset:\n            params['resultOffset'] = resultOffset\n        if quanitizationParameters:\n            params['quanitizationParameters'] = quanitizationParameters\n        if multipatchOption:\n            params['multipatchOption'] = multipatchOption\n        if orderByFields:\n            params['orderByFields'] = orderByFields\n        if groupByFieldsForStatistics:\n            params['groupByFieldsForStatistics'] = groupByFieldsForStatistics\n        if statisticFilter and \\\n           isinstance(statisticFilter, filters.StatisticFilter):\n            params['outStatistics'] = statisticFilter.filter\n        if outStatistics:\n            params['outStatistics'] = outStatistics\n        if outSR:\n            params['outSR'] = outSR\n        if maxAllowableOffset:\n            params['maxAllowableOffset'] = maxAllowableOffset\n        if gdbVersion:\n            params['gdbVersion'] = gdbVersion\n        if geometryPrecision:\n            params['geometryPrecision'] = geometryPrecision\n        if objectIds:\n            params['objectIds'] = objectIds\n        if distance:\n            params['distance'] = distance\n        if units:\n            params['units'] = units\n        if timeFilter and \\\n           isinstance(timeFilter, TimeFilter):\n            for k,v in timeFilter.filter.items():\n                params[k] = v\n        elif isinstance(timeFilter, dict):\n            for k,v in timeFilter.items():\n                params[k] = v\n        if geometryFilter and \\\n           isinstance(geometryFilter, GeometryFilter):\n            for k,v in geometryFilter.filter.items():\n                params[k] = v\n        elif geometryFilter and \\\n             isinstance(geometryFilter, dict):\n            for k,v in geometryFilter.items():\n                params[k] = v\n        if len(kwargs) > 0:\n            for k,v in kwargs.items():\n                params[k] = v\n                del k,v\n\n        result = self._post(url=url,\n                            securityHandler=self._securityHandler,\n                            param_dict=params,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)\n        if 'error' in result:\n            raise ValueError(result)\n        if as_json or \\\n           returnCountOnly == True or \\\n           returnIDsOnly == True:\n            return result\n        elif returnFeatureClass and\\\n             not returnCountOnly and \\\n             not returnIDsOnly:\n            uid = create_uid()\n            if out_fc is None:\n                out_fc = os.path.join(scratchGDB(),\n                                      \"a{fid}\".format(fid=uid))\n            text = json.dumps(result)\n            temp = scratchFolder() + os.sep + uid + \".json\"\n            with open(temp, 'wb') as writer:\n                if six.PY3:\n                    text = bytes(text, 'UTF-8')\n                writer.write(text)\n                writer.flush()\n                del writer\n            fc = json_to_featureclass(json_file=temp,\n                                      out_fc=out_fc)\n            os.remove(temp)\n            return fc\n        else:\n            return FeatureSet.fromJSON(jsonValue=json.dumps(result))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a local copy of the whole feature service to a feature class.", "response": "def get_local_copy(self, out_path, includeAttachments=False):\n        \"\"\" exports the whole feature service to a feature class\n            Input:\n               out_path - path to where the data will be placed\n               includeAttachments - default False. If sync is not supported\n                                    then the paramter is ignored.\n            Output:\n               path to exported feature class or fgdb (as list)\n        \"\"\"\n        if self.hasAttachments and \\\n           self.parentLayer != None and self.parentLayer.syncEnabled:\n            return self.parentLayer.createReplica(replicaName=\"fgdb_dump\",\n                                                  layers=\"%s\" % self.id,\n                                                  attachmentsSyncDirection=\"upload\",\n                                                  async=True,\n                                                  wait=True,\n                                                  returnAttachments=includeAttachments,\n                                                  out_path=out_path)[0]\n        elif self.hasAttachments == False and \\\n             self.parentLayer != None and self.parentLayer.syncEnabled:\n            return self.parentLayer.createReplica(replicaName=\"fgdb_dump\",\n                                                  layers=\"%s\" % self.id,\n                                                  attachmentsSyncDirection=\"upload\",\n                                                  async=True,\n                                                  wait=True,\n                                                  returnAttachments=includeAttachments,\n                                                  out_path=out_path)[0]\n        else:\n            result_features = []\n            res = self.query(returnIDsOnly=True)\n            OIDS = res['objectIds']\n            OIDS.sort()\n            OIDField = res['objectIdFieldName']\n            count = len(OIDS)\n            if count <= self.maxRecordCount:\n                bins = 1\n            else:\n                bins = count / self.maxRecordCount\n                v = count % self.maxRecordCount\n                if v > 0:\n                    bins += 1\n            chunks = self._chunks(OIDS, bins)\n            for chunk in chunks:\n                chunk.sort()\n                if len(chunk) > 0:\n                    sql = \"%s >= %s and %s <= %s\" % (OIDField, chunk[0],\n                                                     OIDField, chunk[len(chunk) -1])\n                    temp_base = \"a\" + uuid.uuid4().get_hex()[:6] + \"a\"\n                    temp_fc = r\"%s\\%s\" % (scratchGDB(), temp_base)\n                    temp_fc = self.query(where=sql,\n                                         returnFeatureClass=True,\n                                         out_fc=temp_fc)\n                    result_features.append(temp_fc)\n            return merge_feature_class(merges=result_features,\n                                       out_fc=out_path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef applyEdits(self,\n                   addFeatures=None,\n                   updateFeatures=None,\n                   deleteFeatures=None,\n                   gdbVersion=None,\n                   useGlobalIds=False,\n                   rollbackOnFailure=True,\n                   attachments=None):\n        \"\"\"\n           This operation adds, updates, and deletes features to the\n           associated feature layer or table in a single call.\n           Inputs:\n              addFeatures - The array of features to be added.  These\n                            features should be common.Feature objects, or\n                            they should be a list of dictionary features.\n              updateFeatures - The array of features to be updateded.\n                               These features should be common.Feature\n                               objects or a list of dictionary formed\n                               features.\n              deleteFeatures - string of OIDs to remove from service or a\n                               list of values.\n              gdbVersion - Geodatabase version to apply the edits.\n              useGlobalIds - instead of referencing the default Object ID\n                              field, the service will look at a GUID field\n                              to track changes.  This means the GUIDs will\n                              be passed instead of OIDs for delete,\n                              update or add features.\n              rollbackOnFailure - Optional parameter to specify if the\n                                  edits should be applied only if all\n                                  submitted edits succeed. If false, the\n                                  server will apply the edits that succeed\n                                  even if some of the submitted edits fail.\n                                  If true, the server will apply the edits\n                                  only if all edits succeed. The default\n                                  value is true.\n              attachments - Optional parameter which requires the layer's\n                            supportsApplyEditsWithGlobalIds property to be\n                            true.\n                            Use the attachments parameter to add, update or\n                            delete attachments. Applies only when the\n                            useGlobalIds parameter is set to true. For\n                            adds, the globalIds of the attachments provided\n                            by the client are preserved. When useGlobalIds\n                            is true, updates and deletes are identified by\n                            each feature or attachment globalId rather than\n                            their objectId or attachmentId.\n\n                            Dictionary Format:\n                            {\n                            \"adds\": [<attachment1>, <attachment2>],\n                            \"updates\": [<attachment1>, <attachment2>],\n                            \"deletes\": [\"<attachmentGlobalId1>\",\n                                        \"<attachmentGlobalId2>\"]\n                            }\n           Output:\n              dictionary of messages\n        \"\"\"\n        editURL = self._url + \"/applyEdits\"\n        params = {\"f\": \"json\",\n                  \"useGlobalIds\" : useGlobalIds,\n                  \"rollbackOnFailure\" : rollbackOnFailure\n                  }\n        if gdbVersion is not None:\n            params['gdbVersion'] = gdbVersion\n        if addFeatures is None:\n            addFeatures = []\n        if updateFeatures is None:\n            updateFeatures = []\n        if len(addFeatures) > 0 and \\\n           isinstance(addFeatures[0], Feature):\n            params['adds'] = json.dumps([f.asDictionary for f in addFeatures],\n                                        default=_date_handler)\n        elif len(addFeatures) > 0 and \\\n             isinstance(addFeatures[0], dict):\n            params['adds'] = json.dumps(addFeatures, default=_date_handler)\n        elif len(addFeatures) == 0:\n            params['adds'] = json.dumps(addFeatures)\n        if len(updateFeatures) > 0 and \\\n           isinstance(updateFeatures[0], Feature):\n            params['updates'] = json.dumps([f.asDictionary for f in updateFeatures],\n                                           default=_date_handler)\n        elif len(updateFeatures) > 0 and \\\n             isinstance(updateFeatures[0], dict):\n            params['updates'] = json.dumps(updateFeatures,\n                                           default=_date_handler)\n        elif updateFeatures is None or \\\n             len(updateFeatures) == 0:\n            updateFeatures = json.dumps([])\n        if deleteFeatures is not None and \\\n           isinstance(deleteFeatures, str):\n            params['deletes'] = deleteFeatures\n        elif deleteFeatures is not None and \\\n             isinstance(deleteFeatures, list):\n            params['deletes'] = \",\".join([str(f) for f in deleteFeatures])\n        else:\n            params['deletes'] = \"\"\n        if attachments is None:\n            params['attachments'] = \"\"\n        else:\n            params['attachments'] = attachments\n        res = self._post(url=editURL,\n                          param_dict=params,\n                          securityHandler=self._securityHandler,\n                          proxy_port=self._proxy_port,\n                          proxy_url=self._proxy_url)\n        return res", "response": "This method applies the edits provided by the server to the associated feature layer or table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a single feature to the service.", "response": "def addFeature(self, features,\n                   gdbVersion=None,\n                   rollbackOnFailure=True):\n        \"\"\" Adds a single feature to the service\n           Inputs:\n              feature - list of common.Feature object or a single\n                        common.Feature Object, a FeatureSet object, or a\n                        list of dictionary objects\n              gdbVersion - Geodatabase version to apply the edits\n              rollbackOnFailure - Optional parameter to specify if the\n                                  edits should be applied only if all\n                                  submitted edits succeed. If false, the\n                                  server will apply the edits that succeed\n                                  even if some of the submitted edits fail.\n                                  If true, the server will apply the edits\n                                  only if all edits succeed. The default\n                                  value is true.\n           Output:\n              JSON message as dictionary\n        \"\"\"\n        url = self._url + \"/addFeatures\"\n        params = {\n            \"f\" : \"json\"\n        }\n        if gdbVersion is not None:\n            params['gdbVersion'] = gdbVersion\n        if isinstance(rollbackOnFailure, bool):\n            params['rollbackOnFailure'] = rollbackOnFailure\n        if isinstance(features, list) and \\\n           len(features) > 0:\n            if isinstance(features[0], Feature):\n                params['features'] = json.dumps([feature.asDictionary for feature in features],\n                                                default=_date_handler)\n            elif isinstance(features[0], dict):\n                params['features'] = json.dumps(features,\n                                                default=_date_handler)\n        elif isinstance(features, Feature):\n            params['features'] = json.dumps([features.asDictionary],\n                                            default=_date_handler)\n        elif isinstance(features, FeatureSet):\n            params['features'] = json.dumps([feature.asDictionary for feature in features.features],\n                                            default=_date_handler)\n        else:\n            return None\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef securityHandler(self, value):\n        if isinstance(value, BaseSecurityHandler):\n            if isinstance(value, security.AGOLTokenSecurityHandler):\n                self._securityHandler = value\n            elif isinstance(value, security.OAuthSecurityHandler):\n                self._securityHandler = value\n            else:\n                pass", "response": "sets the security handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asDictionary(self):\n        if self._wkid == None and self._wkt is not None:\n            return {\"wkt\": self._wkt}\n        else:\n            return {\"wkid\": self._wkid}", "response": "returns the wkid id for use in json calls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the wkid id for use in json calls", "response": "def value(self):\n        \"\"\"returns the wkid id for use in json calls\"\"\"\n        if self._wkid == None and self._wkt is not None:\n            return {\"wkt\": self._wkt}\n        else:\n            return {\"wkid\": self._wkid}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the geometry spatial reference", "response": "def spatialReference(self):\n        \"\"\"returns the geometry spatial reference\"\"\"\n        if self._wkid == None and self._wkt is not None:\n            return {\"wkt\": self._wkt}\n        else:\n            return {\"wkid\": self._wkid}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asJSON(self):\n        value = self._json\n        if value is None:\n            value = json.dumps(self.asDictionary,\n                               default=_date_handler)\n            self._json = value\n        return self._json", "response": "returns a geometry as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the Point as an ESRI arcpy. Point object", "response": "def asArcPyObject(self):\n        \"\"\" returns the Point as an ESRI arcpy.Point object \"\"\"\n        if arcpyFound == False:\n            raise Exception(\"ArcPy is required to use this function\")\n        return arcpy.AsShape(self.asDictionary, True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asDictionary(self):\n        #\n        template = {\"x\" : self._x,\n                    \"y\" : self._y,\n                    \"spatialReference\" : self.spatialReference\n                    }\n        if not self._z is None:\n            template['z'] = self._z\n        if not self._m is None:\n            template['z'] = self._m\n        return template", "response": "returns the object as a python dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Point value as a list of x y z m", "response": "def asList(self):\n        \"\"\" returns a Point value as a list of [x,y,<z>,<m>] \"\"\"\n        base = [self._x, self._y]\n        if not self._z is None:\n            base.append(self._z)\n        elif not self._m is None:\n            base.append(self._m)\n        return base"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef X(self, value):\n        if isinstance(value, (int, float,\n                              long, types.NoneType)):\n            self._x = value", "response": "sets the X coordinate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Y(self, value):\n        if isinstance(value, (int, float,\n                              long, types.NoneType)):\n            self._y = value", "response": "sets the Y coordinate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the Z coordinate", "response": "def Z(self, value):\n        \"\"\" sets the Z coordinate \"\"\"\n        if isinstance(value, (int, float,\n                              long, types.NoneType)):\n            self._z = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __geomToPointList(self, geom):\n        if arcpyFound and isinstance(geom, arcpy.Multipoint):\n            feature_geom = []\n            fPart = []\n            for part in geom:\n                fPart = []\n                for pnt in part:\n                    fPart.append(Point(coord=[pnt.X, pnt.Y],\n                          wkid=geom.spatialReference.factoryCode,\n                          z=pnt.Z, m=pnt.M))\n                feature_geom.append(fPart)\n            return feature_geom", "response": "converts a geometry object to a list of Point objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef asDictionary(self):\n        #\n        value = self._dict\n        if value is None:\n            template = {\n                \"hasM\" : self._hasM,\n                \"hasZ\" : self._hasZ,\n                \"points\" : [],\n                \"spatialReference\" : self.spatialReference\n            }\n            for pt in self._points:\n                template['points'].append(pt.asList)\n            self._dict = template\n        return self._dict", "response": "returns the object as a python dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a geometry object to a list of Point objects", "response": "def __geomToPointList(self, geom):\n        \"\"\" converts a geometry object to a common.Geometry object \"\"\"\n        if arcpyFound and isinstance(geom, arcpy.Polyline):\n            feature_geom = []\n            fPart = []\n            wkt = None\n            wkid = None\n            for part in geom:\n                fPart = []\n                for pnt in part:\n                    if geom.spatialReference is None:\n                        if self._wkid is None and self._wkt is not None:\n                            wkt = self._wkt\n                        else:\n                            wkid = self._wkid\n                    else:\n                        wkid = geom.spatialReference.factoryCode\n                    fPart.append(Point(coord=[pnt.X, pnt.Y],\n                          wkid=wkid,\n                          wkt=wkt,\n                          z=pnt.Z, m=pnt.M))\n                feature_geom.append(fPart)\n            return feature_geom"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the object as a python dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the object as a python dictionary \"\"\"\n        value = self._dict\n        if value is None:\n            template = {\n                \"hasM\" : self._hasM,\n                \"hasZ\" : self._hasZ,\n                \"paths\" : [],\n                \"spatialReference\" : self.spatialReference\n            }\n            for part in self._paths:\n                lpart = []\n                for pt in part:\n                    lpart.append(pt.asList)\n                template['paths'].append(lpart)\n                del lpart\n            self._dict = template\n        return self._dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a geometry object to a list of Point objects", "response": "def __geomToPointList(self, geom):\n        \"\"\" converts a geometry object to a common.Geometry object \"\"\"\n        sr = geom.spatialReference\n        wkid = None\n        wkt = None\n        if sr is None:\n            if self._wkid is None and self._wkt is not None:\n                wkt = self._wkt\n            else:\n                wkid = self._wkid\n        else:\n            wkid = sr.factoryCode\n        g = json.loads(geom.JSON)\n        top = []\n        for gring in g['rings']:\n            ring = []\n            for g in gring:\n                ring.append(Point(coord=g, wkid=wkid, wkt=wkt, z=None, m=None))\n            top.append(ring)\n        return top"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the object as a python dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the object as a python dictionary \"\"\"\n        value = self._dict\n        if value is None:\n            template = {\n                \"hasM\" : self._hasM,\n                \"hasZ\" : self._hasZ,\n                \"rings\" : [],\n                \"spatialReference\" : self.spatialReference\n            }\n            for part in self._rings:\n                lpart = []\n                for pt in part:\n                    if isinstance(pt, list):\n                        lpart.append(pt)\n                    elif isinstance(pt, Point):\n                        lpart.append(pt.asList)\n                template['rings'].append(lpart)\n                del lpart\n            self._dict = template\n        return self._dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the envelope as a dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the envelope as a dictionary \"\"\"\n        template = {\n            \"xmin\" : self._xmin,\n            \"ymin\" : self._ymin,\n            \"xmax\" : self._xmax,\n            \"ymax\" : self._ymax,\n            \"spatialReference\" : self.spatialReference\n        }\n        if self._zmax is not None and \\\n           self._zmin is not None:\n            template['zmin'] = self._zmin\n            template['zmax'] = self._zmax\n\n        if self._mmin is not None and \\\n           self._mmax is not None:\n            template['mmax'] = self._mmax\n            template['mmin'] = self._mmin\n\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asArcPyObject(self):\n        env = self.asDictionary\n        ring = [[\n            Point(env['xmin'], env['ymin'], self._wkid),\n            Point(env['xmax'], env['ymin'], self._wkid),\n            Point(env['xmax'], env['ymax'], self._wkid),\n            Point(env['xmin'], env['ymax'], self._wkid)\n            ]]\n        return Polygon(rings=ring,\n                       wkid=self._wkid,\n                       wkt=self._wkid,\n                       hasZ=False,\n                       hasM=False).asArcPyObject", "response": "returns the Envelope as an ESRI arcpy. Polygon object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the response object", "response": "def _process_response(self, resp, out_folder=None):\n        \"\"\" processes the response object\"\"\"\n        CHUNK = 4056\n        maintype = self._mainType(resp)\n        contentDisposition = resp.headers.get('content-disposition')\n        contentEncoding = resp.headers.get('content-encoding')\n        contentType = resp.headers.get('content-type')\n        contentLength = resp.headers.get('content-length')\n        if maintype.lower() in ('image',\n                                'application/x-zip-compressed') or \\\n           contentType == 'application/x-zip-compressed' or \\\n           (contentDisposition is not None and \\\n            contentDisposition.lower().find('attachment;') > -1):\n            fname = self._get_file_name(\n                contentDisposition=contentDisposition,\n                url=resp.geturl())\n            if out_folder is None:\n                out_folder = tempfile.gettempdir()\n            if contentLength is not None:\n                max_length = int(contentLength)\n                if max_length < CHUNK:\n                    CHUNK = max_length\n            file_name = os.path.join(out_folder, fname)\n            with open(file_name, 'wb') as writer:\n                for data in self._chunk(response=resp):\n                    writer.write(data)\n                    del data\n                del writer\n            return file_name\n        else:\n            read = \"\"\n            for data in self._chunk(response=resp, size=4096):\n                if self.PY3 == True:\n                    read += data.decode('utf-8')\n                else:\n                    read += data\n                del data\n            try:\n                return json.loads(read.strip())\n            except:\n                return read\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_boundary(self):\n        if self.PY2:\n            return '===============%s==' % uuid.uuid4().get_hex()\n        elif self.PY3:\n            return '===============%s==' % uuid.uuid4().hex\n        else:\n            from random import choice\n            digits = \"0123456789\"\n            letters = \"abcdefghijklmnopqrstuvwxyz\"\n            return '===============%s==' % ''.join(choice(letters + digits) \\\n                                                   for i in range(15))", "response": "creates a boundary for multipart post"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a POST operation on a URL. Inputs: param_dict - key/value pair of values ex: {\"foo\": \"bar\"} files - key/value pair of file objects where the key is the input name and the value is the file path ex: {\"file\": r\"c:\\temp\\myfile.zip\"} securityHandler - object that handles the token or other site security. It must inherit from the base security class. ex: arcrest.AGOLSecurityHandler(\"SomeUsername\", \"SOMEPASSWORD\") additional_headers - are additional key/value headers that a user wants to pass during the operation. ex: {\"accept-encoding\": \"gzip\"} custom_handlers - this is additional web operation handlers as a list of objects. Ex: [CustomAuthHandler] proxy_url - url of the proxy proxy_port - default 80, port number of the proxy compress - default true, determines if gzip should be used of not for the web operation. out_folder - if the URL requested returns a file, this will be the disk save location file_name - if the operation returns a file and the file name is not given in the header or a user wishes to override the return saved file name, provide value here. Output: returns dictionary or string depending on web operation.", "response": "def _post(self, url,\n              param_dict={},\n              files={},\n              securityHandler=None,\n              additional_headers={},\n              custom_handlers=[],\n              proxy_url=None,\n              proxy_port=80,\n              compress=True,\n              out_folder=None,\n              file_name=None):\n        \"\"\"\n        Performs a POST operation on a URL.\n\n        Inputs:\n           param_dict - key/value pair of values\n              ex: {\"foo\": \"bar\"}\n           files - key/value pair of file objects where the key is\n              the input name and the value is the file path\n              ex: {\"file\": r\"c:\\temp\\myfile.zip\"}\n           securityHandler - object that handles the token or other site\n              security.  It must inherit from the base security class.\n              ex: arcrest.AGOLSecurityHandler(\"SomeUsername\", \"SOMEPASSWORD\")\n           additional_headers - are additional key/value headers that a user\n              wants to pass during the operation.\n              ex: {\"accept-encoding\": \"gzip\"}\n           custom_handlers - this is additional web operation handlers as a\n              list of objects.\n              Ex: [CustomAuthHandler]\n           proxy_url - url of the proxy\n           proxy_port - default 80, port number of the proxy\n           compress - default true, determines if gzip should be used of not for\n              the web operation.\n           out_folder - if the URL requested returns a file, this will be the\n              disk save location\n           file_name - if the operation returns a file and the file name is not\n             given in the header or a user wishes to override the return saved\n             file name, provide value here.\n        Output:\n           returns dictionary or string depending on web operation.\n        \"\"\"\n        self._last_method = \"POST\"\n        headers = {}\n        opener = None\n        return_value = None\n        handlers = [RedirectHandler()]\n        param_dict, handler, cj = self._processHandler(securityHandler, param_dict)\n        if handler is not None:\n            handlers.append(handler)\n        if cj is not None:\n            handlers.append(request.HTTPCookieProcessor(cj))\n        if isinstance(custom_handlers, list) and \\\n           len(custom_handlers) > 0:\n            for h in custom_handlers:\n                handlers.append(h)\n        if compress:\n            headers['Accept-Encoding'] = 'gzip'\n        else:\n            headers['Accept-Encoding'] = ''\n        for k,v in additional_headers.items():\n            headers[k] = v\n            del k,v\n        opener = request.build_opener(*handlers)\n        request.install_opener(opener)\n        opener.addheaders = [(k,v) for k,v in headers.items()]\n        if len(files) == 0:\n            data = urlencode(param_dict)\n            if self.PY3:\n                data = data.encode('ascii')\n            opener.data = data\n            resp = opener.open(url, data=data)\n        else:\n            mpf = MultiPartForm(param_dict=param_dict,\n                                files=files)\n            req = request.Request(url)\n            body = mpf.make_result\n            req.add_header('User-agent', self.useragent)\n            req.add_header('Content-type', mpf.get_content_type())\n            req.add_header('Content-length', len(body))\n            req.data = body\n            resp = request.urlopen(req)\n        self._last_code = resp.getcode()\n        self._last_url = resp.geturl()\n        return_value = self._process_response(resp=resp,\n                                              out_folder=out_folder)\n        if isinstance(return_value, dict):\n            if \"error\" in return_value and \\\n               'message' in return_value['error']:\n                if return_value['error']['message'].lower() == 'request not made over ssl':\n                    if url.startswith('http://'):\n                        url = url.replace('http://', 'https://')\n                        return self._post(url,\n                                     param_dict,\n                                     files,\n                                     securityHandler,\n                                     additional_headers,\n                                     custom_handlers,\n                                     proxy_url,\n                                     proxy_port,\n                                     compress,\n                                     out_folder,\n                                     file_name)\n            return return_value\n        else:\n            return return_value\n        return return_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a GET operation Inputs: Output: returns dictionary, string or None", "response": "def _get(self, url,\n             param_dict={},\n             securityHandler=None,\n             additional_headers=[],\n             handlers=[],\n             proxy_url=None,\n             proxy_port=None,\n             compress=True,\n             custom_handlers=[],\n             out_folder=None,\n             file_name=None):\n        \"\"\"\n        Performs a GET operation\n        Inputs:\n\n        Output:\n           returns dictionary, string or None\n        \"\"\"\n        self._last_method = \"GET\"\n        CHUNK = 4056\n        param_dict, handler, cj = self._processHandler(securityHandler, param_dict)\n        headers = [] + additional_headers\n        if compress:\n            headers.append(('Accept-encoding', 'gzip'))\n        else:\n            headers.append(('Accept-encoding', ''))\n        headers.append(('User-Agent', self.useragent))\n        if len(param_dict.keys()) == 0:\n            param_dict = None\n        if handlers is None:\n            handlers = []\n        if handler is not None:\n            handlers.append(handler)\n        handlers.append(RedirectHandler())\n        if cj is not None:\n            handlers.append(request.HTTPCookieProcessor(cj))\n        if proxy_url is not None:\n            if proxy_port is None:\n                proxy_port = 80\n            proxies = {\"http\":\"http://%s:%s\" % (proxy_url, proxy_port),\n                       \"https\":\"https://%s:%s\" % (proxy_url, proxy_port)}\n            proxy_support = request.ProxyHandler(proxies)\n            handlers.append(proxy_support)\n        opener = request.build_opener(*handlers)\n        opener.addheaders = headers\n        if param_dict is None:\n            resp = opener.open(url, data=param_dict)\n        elif len(str(urlencode(param_dict))) + len(url) >= 1999:\n            resp = opener.open(url, data=urlencode(param_dict))\n        else:\n            format_url = url + \"?%s\" % urlencode(param_dict)\n            resp = opener.open(fullurl=format_url)\n        self._last_code = resp.getcode()\n        self._last_url = resp.geturl()\n        #  Get some headers from the response\n        maintype = self._mainType(resp)\n        contentDisposition = resp.headers.get('content-disposition')\n        contentEncoding = resp.headers.get('content-encoding')\n        contentType = resp.headers.get('content-Type').split(';')[0].lower()\n        contentLength = resp.headers.get('content-length')\n        if maintype.lower() in ('image',\n                                'application/x-zip-compressed') or \\\n           contentType == 'application/x-zip-compressed' or \\\n           (contentDisposition is not None and \\\n           contentDisposition.lower().find('attachment;') > -1):\n\n            fname = self._get_file_name(\n                contentDisposition=contentDisposition,\n                url=url)\n            if out_folder is None:\n                out_folder = tempfile.gettempdir()\n            if contentLength is not None:\n                max_length = int(contentLength)\n                if max_length < CHUNK:\n                    CHUNK = max_length\n            file_name = os.path.join(out_folder, fname)\n            with open(file_name, 'wb') as writer:\n                for data in self._chunk(response=resp,\n                                        size=CHUNK):\n                    writer.write(data)\n                    writer.flush()\n                writer.flush()\n                del writer\n            return file_name\n        else:\n            read = \"\"\n            for data in self._chunk(response=resp,\n                                    size=CHUNK):\n                if self.PY3 == True:\n                    read += data.decode('utf-8')\n                else:\n                    read += data\n\n                del data\n            try:\n                results = json.loads(read)\n                if 'error' in results:\n                    if 'message' in results['error']:\n                        if results['error']['message'] == 'Request not made over ssl':\n                            if url.startswith('http://'):\n                                url = url.replace('http://', 'https://')\n                                return self._get(url,\n                                               param_dict,\n                                               securityHandler,\n                                               additional_headers,\n                                               handlers,\n                                               proxy_url,\n                                               proxy_port,\n                                               compress,\n                                               custom_handlers,\n                                               out_folder,\n                                               file_name)\n                return results\n            except:\n                return read"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a role to the role store. The role store can only be added to read - write store. This operation is available only when the role store is a read - write store such as ArcGIS Server store.", "response": "def addRole(self, name, description=\"\"):\n        \"\"\" Adds a role to the role store. This operation is available only\n            when the role store is a read-write store such as the default\n            ArcGIS Server store.\n            If the name of the role exists in the role store, an error will\n            be returned.\n            Input:\n               rolename - The name of the role. The name must be unique in the\n                      role store.\n               description - An optional field to add comments or a\n                             description for the role.\n            Output:\n               JSON message as dictionary\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"rolename\" : name,\n            \"description\" : description\n        }\n        aURL = self._url + \"/roles/add\"\n        return self._post(url=aURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a role to multiple users", "response": "def addUsersToRole(self, rolename, users):\n        \"\"\" Assigns a role to multiple users \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"rolename\" : rolename,\n            \"users\" : users\n        }\n        rURL = self._url + \"/roles/addUsersToRole\"\n        return self._post(url=rURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the privilege associated with a role. Input: rolename - name of the role Output: JSON Messages", "response": "def getPrivilegeForRole(self, rolename):\n        \"\"\"\n           Returns the privilege associated with a role.\n           Input:\n              rolename - name of the role\n           Output:\n              JSON Messages\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"rolename\" : rolename\n        }\n        pURL = self._url + \"/roles/getPrivilege\"\n        return self._post(url=pURL,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getRoles(self, startIndex=0, pageSize=10):\n        uURL = self._url + \"/roles/getRoles\"\n        params = {\n            \"f\" : \"json\",\n            \"startIndex\" : startIndex,\n            \"pageSize\" : pageSize\n        }\n        return self._post(url=uURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation returns a pageable view of the roles in the role nacacatalite store. The operation returns a dictionary that contains the roles for all available role accounts. The result is a pageable view of all available role accounts."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getRolesForUser(self, username, filter=None, maxCount=None):\n        uURL = self._url + \"/roles/getRolesForUser\"\n        params = {\n            \"f\" : \"json\",\n            \"username\" : username\n        }\n        if filter is not None:\n            params['filter'] = filter\n\n        if maxCount is not None:\n            params['maxCount'] = maxCount\n        return self._post(url=uURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation returns a list of role names that have been assigned to a particular user account. The list of roles that have been assigned to a particular user account is returned. The list of roles that have been assigned to a particular user account is returned."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addGraphic(self, layerName, geometry, symbol):\n        allowed_geomtypes = ['polygon', 'polyline', 'point', 'multipoint']\n        if not (geometry.type.lower() in allowed_geomtypes):\n            return False, layerName\n        geom = _unicode_convert(json.loads(geometry.JSON))\n        geomType = self.__look_up_geom(geometry.type.lower())\n        if layerName in self._storedFeatures:\n            self._storedFeatures[layerName]['featureSet']['features'].append({\"geometry\":geom,\n                                                                               \"symbol\":symbol.asDictionary})\n        else:\n            template_ld = {\n                \"layerDefinition\":{\n                    \"name\":layerName,\n                    \"geometryType\":geomType\n                    },\n                \"featureSet\":{\n                    \"geometryType\":geomType,\n                    \"features\":[{\"geometry\":geom,\n                                 \"symbol\":symbol.asDictionary}]\n                }\n            }\n            self._storedFeatures[layerName] = template_ld\n        return True, layerName", "response": "Adds a geometry into a Graphic Layer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __look_up_geom(self, geomType):\n\n        if geomType.lower() == \"point\":\n            return \"esriGeometryPoint\"\n        elif geomType.lower() == \"polyline\":\n            return \"esriGeometryPolyline\"\n        elif geomType.lower() == \"polygon\":\n            return \"esriGeometryPolygon\"\n        elif geomType.lower() == \"multipoint\":\n            return \"esriGeometryMultipoint\"\n        else:\n            return None", "response": "looks up the geometry type for a given geometry object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serverProperties(self):\n        return ServerProperties(url=self._url + \"/properties\",\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port,\n                               initialize=True)", "response": "gets the server properties for the site as an object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serverDirectories(self):\n        directs = []\n        url = self._url + \"/directories\"\n        params = {\n            \"f\" : \"json\"\n        }\n        res = self._get(url=url,\n                           param_dict=params,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        for direct in res['directories']:\n            directs.append(\n                ServerDirectory(url=url + \"/%s\" % direct[\"name\"],\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port,\n                                initialize=True))\n        return directs", "response": "returns the server directory object in a list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a new server directory. While registering the server directory, you can also specify the directory's cleanup parameters. You can also register a directory by using its JSON representation as a value of the directory parameter. Inputs: name - The name of the server directory. physicalPath - The absolute physical path of the server directory. directoryType - The type of server directory. cleanupMode - Defines if files in the server directory needs to be cleaned up. Default: NONE maxFileAge - Defines how long a file in the directory needs to be kept before it is deleted (in minutes). description - An optional description for the server directory.", "response": "def registerDirectory(self,name,physicalPath,directoryType,cleanupMode,\n                          maxFileAge,description):\n        \"\"\"\n        Registers a new server directory. While registering the server directory,\n        you can also specify the directory's cleanup parameters. You can also\n        register a directory by using its JSON representation as a value of the\n        directory parameter.\n        Inputs:\n            name - The name of the server directory.\n            physicalPath - The absolute physical path of the server directory.\n            directoryType - The type of server directory.\n            cleanupMode - Defines if files in the server directory needs to\n                            be cleaned up. Default: NONE\n            maxFileAge - Defines how long a file in the directory needs to be\n                            kept before it is deleted (in minutes).\n            description - An optional description for the server directory.\n        \"\"\"\n        url = self._url + \"/directories/register\"\n        params = {\n            \"f\" : \"json\",\n            \"name\" : name,\n            \"physicalPath\" : physicalPath,\n            \"directoryType\" : directoryType,\n            \"cleanupMode\" : cleanupMode,\n            \"maxFileAge\" : maxFileAge,\n            \"description\" : description\n        }\n\n        res = self._post(url=url,\n                         param_dict=params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister multiple new server directories. Inputs: json_dirs - Array of Server Directories in JSON format.", "response": "def registerDirs(self,json_dirs):\n        \"\"\"\n        Registers multiple new server directories.\n        Inputs:\n            json_dirs - Array of Server Directories in JSON format.\n        \"\"\"\n        url = self._url + \"/directories/registerDirs\"\n        params = {\n            \"f\" : \"json\",\n            \"directories\" : json_dirs\n        }\n\n        res = self._post(url=url,\n                         param_dict=params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the Jobs object", "response": "def Jobs(self):\n        \"\"\"get the Jobs object\"\"\"\n        url = self._url + \"/jobs\"\n        return Jobs(url=url,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port,\n                    initialize=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef registerWebAdaptor(self, webAdaptorURL, machineName, machineIP,\n                           isAdminEnabled, description, httpPort, httpsPort):\n        \"\"\"\n        You can use this operation to register the ArcGIS Web Adaptor\n        from your ArcGIS Server. By registering the Web Adaptor with the server, \n        you are telling the server to trust requests (including security \n        credentials) that have been submitted through this Web Adaptor. \n\n        Inputs:\n           webAdaptorURL - The URL of the web adaptor through which ArcGIS\n                            resources will be accessed.\n           machineName - The machine name on which the web adaptor is installed.\n           machineIP - The local IP address of the machine on which the web\n                            adaptor is installed.\n           isAdminEnabled - A boolean flag to indicate if administrative access\n                            is allowed through the web adaptor. The default is\n                            false.\n           description - An optional description for the web adaptor.\n           httpPort - An optional parameter to indicate the HTTP port of the\n                            web adaptor. If this parameter is not provided, it\n                            is derived from the URL.\n           httpsPort - An optional parameter to indicate the HTTPS port of the web\n                            adaptor. If this parameter is not provided, it is\n                            derived from the URL.\n        \"\"\"\n        url = self._url + \"/webadaptors/register\"\n        params = {\n            \"f\" : \"json\",\n            \"webAdaptorURL\" : webAdaptorURL,\n            \"machineName\" : machineName,\n            \"machineIP\" : machineIP,\n            \"isAdminEnabled\" : isAdminEnabled,\n            \"description\" : description,\n            \"httpPort\" : httpPort,\n            \"httpsPort\" :  httpsPort\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)", "response": "This operation registers a new ArcGIS Web Adaptor with the ArcGIS Server. This operation is performed on a web adaptor and returns the ID of the web adaptor that was registered with the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the ConfigurationStore object for this site", "response": "def configurationStore(self):\n        \"\"\"returns the ConfigurationStore object for this site\"\"\"\n        url = self._url + \"/configstore\"\n\n        return ConfigurationStore(url=url,\n                                  securityHandler=self._securityHandler,\n                                  proxy_url=self._proxy_url,\n                                  proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recover(self,runAsync=False):\n        url = self._url + \"/recover\"\n        params = {\n            \"f\" : \"json\",\n            \"runAsync\" : runAsync\n        }\n        return self._post(url=url,\n                          param_dict=params,\n                          securityHandler=self._securityHandler,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port)", "response": "This operation attempts to recover the shared configuration store for a site. This operation will attempt to recover the shared configuration store for a site from the local repository. If runAsync is set to True the operation will be performed asynchronously. If runAsync is set to True the operation will be performed asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RemoveAndAddFeatures(self, url, pathToFeatureClass, id_field, chunksize=1000):\n        fl = None\n\n        try:\n            if arcpyFound == False:\n                raise common.ArcRestHelperError({\n                    \"function\": \"RemoveAndAddFeatures\",\n                    \"line\": inspect.currentframe().f_back.f_lineno,\n                    \"filename\":  'featureservicetools',\n                    \"synerror\": \"ArcPy required for this function\"\n                })\n            arcpy.env.overwriteOutput = True\n            tempaddlayer= 'ewtdwedfew'\n            if not arcpy.Exists(pathToFeatureClass):\n                raise common.ArcRestHelperError({\n                    \"function\": \"RemoveAndAddFeatures\",\n                    \"line\": inspect.currentframe().f_back.f_lineno,\n                    \"filename\":  'featureservicetools',\n                    \"synerror\": \"%s does not exist\" % pathToFeatureClass\n                     }\n                    )\n\n            fields = arcpy.ListFields(pathToFeatureClass,wild_card=id_field)\n            if len(fields) == 0:\n                raise common.ArcRestHelperError({\n                    \"function\": \"RemoveAndAddFeatures\",\n                    \"line\": inspect.currentframe().f_back.f_lineno,\n                    \"filename\":  'featureservicetools',\n                    \"synerror\": \"%s field does not exist\" % id_field\n                })\n            strFld = True\n            if fields[0].type != 'String':\n                strFld = False\n\n            fl = FeatureLayer(\n                    url=url,\n                    securityHandler=self._securityHandler)\n\n            id_field_local = arcpy.AddFieldDelimiters(pathToFeatureClass, id_field)\n            idlist = []\n            print( arcpy.GetCount_management(in_rows=pathToFeatureClass).getOutput(0) + \" features in the layer\")\n            with arcpy.da.SearchCursor(pathToFeatureClass, (id_field)) as cursor:\n                allidlist = []\n\n                for row in cursor:\n                    if (strFld):\n                        idlist.append(\"'\" + row[0] +\"'\")\n                    else:\n                        idlist.append(row[0])\n                    if len(idlist) >= chunksize:\n                        allidlist.append(idlist)\n                        idlist = []\n\n                if len(idlist) > 0:\n                    allidlist.append(idlist)\n                for idlist in allidlist:\n                    idstring = ' in (' + ','.join(map(str,idlist)) + ')'\n                    sql = id_field + idstring\n                    sqlLocalFC = id_field_local + idstring\n                    results = fl.deleteFeatures(where=sql,\n                                                rollbackOnFailure=True)\n\n                    if 'error' in results:\n                        raise common.ArcRestHelperError({\n                            \"function\": \"RemoveAndAddFeatures\",\n                            \"line\": inspect.currentframe().f_back.f_lineno,\n                            \"filename\":  'featureservicetools',\n                            \"synerror\":results['error']\n                        })\n                    elif 'deleteResults' in results:\n                        print (\"%s features deleted\" % len(results['deleteResults']))\n                        for itm in results['deleteResults']:\n                            if itm['success'] != True:\n                                print (itm)\n                    else:\n                        print (results)\n\n                    arcpy.MakeFeatureLayer_management(pathToFeatureClass,tempaddlayer,sqlLocalFC)\n                    results = fl.addFeatures(fc=tempaddlayer)\n\n                    if 'error' in results:\n                        raise common.ArcRestHelperError({\n                            \"function\": \"RemoveAndAddFeatures\",\n                            \"line\": inspect.currentframe().f_back.f_lineno,\n                            \"filename\":  'featureservicetools',\n                            \"synerror\":results['error']\n                        })\n                    elif 'addResults' in results:\n                        print (\"%s features added\" % len(results['addResults']))\n                        for itm in results['addResults']:\n                            if itm['success'] != True:\n                                print (itm)\n                    else:\n                        print (results)\n                    idlist = []\n            if 'error' in results:\n                raise common.ArcRestHelperError({\n                    \"function\": \"RemoveAndAddFeatures\",\n                    \"line\": inspect.currentframe().f_back.f_lineno,\n                    \"filename\":  'featureservicetools',\n                    \"synerror\":results['error']\n                })\n            else:\n                print (results)\n        except arcpy.ExecuteError:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"create_report_layers_using_config\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n                \"arcpyError\": arcpy.GetMessages(2),\n            }\n                           )\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"AddFeaturesToFeatureLayer\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            gc.collect()", "response": "Removes all features in a feature service and uploads them to a feature class on disk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nenabling editing capabilities on a feature service.", "response": "def EnableEditingOnService(self, url, definition = None):\n        \"\"\"Enables editing capabilities on a feature service.\n\n        Args:\n            url (str): The URL of the feature service.\n            definition (dict): A dictionary containing valid definition values. Defaults to ``None``.\n        Returns:\n            dict: The existing feature service definition capabilities.\n\n        When ``definition`` is not provided (``None``), the following values are used by default:\n\n        +------------------------------+------------------------------------------+\n        |              Key             |                   Value                  |\n        +------------------------------+------------------------------------------+\n        | hasStaticData                | ``False``                                |\n        +------------------------------+------------------------------------------+\n        | allowGeometryUpdates         | ``True``                                 |\n        +------------------------------+------------------------------------------+\n        | enableEditorTracking         | ``False``                                |\n        +------------------------------+------------------------------------------+\n        | enableOwnershipAccessControl | ``False``                                |\n        +------------------------------+------------------------------------------+\n        | allowOthersToUpdate          | ``True``                                 |\n        +------------------------------+------------------------------------------+\n        | allowOthersToDelete          | ``True``                                 |\n        +------------------------------+------------------------------------------+\n        | capabilities                 | ``\"Query,Editing,Create,Update,Delete\"`` |\n        +------------------------------+------------------------------------------+\n\n        \"\"\"\n        adminFS = AdminFeatureService(url=url, securityHandler=self._securityHandler)\n\n        if definition is None:\n            definition = collections.OrderedDict()\n            definition['hasStaticData'] = False\n            definition['allowGeometryUpdates'] = True\n            definition['editorTrackingInfo'] = {}\n            definition['editorTrackingInfo']['enableEditorTracking'] = False\n            definition['editorTrackingInfo']['enableOwnershipAccessControl'] = False\n            definition['editorTrackingInfo']['allowOthersToUpdate'] = True\n            definition['editorTrackingInfo']['allowOthersToDelete'] = True\n            definition['capabilities'] = \"Query,Editing,Create,Update,Delete\"\n\n        existingDef = {}\n\n        existingDef['capabilities']  = adminFS.capabilities\n        existingDef['allowGeometryUpdates'] = adminFS.allowGeometryUpdates\n        enableResults = adminFS.updateDefinition(json_dict=definition)\n\n        if 'error' in enableResults:\n            return enableResults['error']\n        adminFS = None\n        del adminFS\n\n        print (enableResults)\n        return existingDef"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nenable Sync capability for an AGOL feature service.", "response": "def enableSync(self, url, definition = None):\n        \"\"\"Enables Sync capability for an AGOL feature service.\n\n        Args:\n            url (str): The URL of the feature service.\n            definition (dict): A dictionary containing valid definition values. Defaults to ``None``.\n        Returns:\n            dict: The result from :py:func:`arcrest.hostedservice.service.AdminFeatureService.updateDefinition`.\n\n        \"\"\"\n        adminFS = AdminFeatureService(url=url, securityHandler=self._securityHandler)\n\n        cap = str(adminFS.capabilities)\n        existingDef = {}\n        enableResults = 'skipped'\n        if 'Sync' in cap:\n            return \"Sync is already enabled\"\n        else:\n            capItems = cap.split(',')\n            capItems.append('Sync')\n            existingDef['capabilities'] = ','.join(capItems)\n            enableResults = adminFS.updateDefinition(json_dict=existingDef)\n\n            if 'error' in enableResults:\n                return enableResults['error']\n        adminFS = None\n        del adminFS\n        return enableResults"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetFeatureService(self, itemId, returnURLOnly=False):\n        admin = None\n        item = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            if self._securityHandler.valid == False:\n                self._valid = self._securityHandler.valid\n                self._message = self._securityHandler.message\n                return None\n\n            item = admin.content.getItem(itemId=itemId)\n            if item.type == \"Feature Service\":\n                if returnURLOnly:\n                    return item.url\n                else:\n                    fs = arcrest.agol.FeatureService(\n                       url=item.url,\n                       securityHandler=self._securityHandler)\n                    if fs.layers is None or len(fs.layers) == 0 :\n                        fs = arcrest.ags.FeatureService(\n                           url=item.url)\n                    return fs\n            return None\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"GetFeatureService\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            item = None\n            del item\n            del admin\n            gc.collect()", "response": "Retrieves a feature service by item ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a layer from a feature service by URL reference.", "response": "def GetLayerFromFeatureServiceByURL(self, url, layerName=\"\", returnURLOnly=False):\n        \"\"\"Obtains a layer from a feature service by URL reference.\n\n        Args:\n            url (str): The URL of the feature service.\n            layerName (str): The name of the layer. Defaults to ``\"\"``.\n            returnURLOnly (bool): A boolean value to return the URL of the layer. Defaults to ``False``.\n        Returns:\n            When ``returnURLOnly`` is ``True``, the URL of the layer is returned.\n\n            When ``False``, the result from :py:func:`arcrest.agol.services.FeatureService` or :py:func:`arcrest.ags.services.FeatureService`.\n\n        \"\"\"\n        fs = None\n        try:\n            fs = arcrest.agol.FeatureService(\n                    url=url,\n                    securityHandler=self._securityHandler)\n\n            return self.GetLayerFromFeatureService(fs=fs,layerName=layerName,returnURLOnly=returnURLOnly)\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"GetLayerFromFeatureServiceByURL\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            fs = None\n            del fs\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetLayerFromFeatureService(self, fs, layerName=\"\", returnURLOnly=False):\n        layers = None\n        table = None\n        layer = None\n        sublayer = None\n        try:\n            layers = fs.layers\n            if (layers is None or len(layers) == 0) and fs.url is not None:\n                fs = arcrest.ags.FeatureService(\n                                    url=fs.url)\n                layers = fs.layers\n            if layers is not None:\n                for layer in layers:\n                    if layer.name == layerName:\n                        if returnURLOnly:\n                            return fs.url + '/' + str(layer.id)\n                        else:\n                            return layer\n\n                    elif not layer.subLayers is None:\n                        for sublayer in layer.subLayers:\n                            if sublayer == layerName:\n                                return sublayer\n            if fs.tables is not None:\n                for table in fs.tables:\n                    if table.name == layerName:\n                        if returnURLOnly:\n                            return fs.url + '/' + str(layer.id)\n                        else:\n                            return table\n            return None\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"GetLayerFromFeatureService\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            layers = None\n            table = None\n            layer = None\n            sublayer = None\n            del layers\n            del table\n            del layer\n            del sublayer\n            gc.collect()", "response": "Gets a layer from a feature service by its name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef AddFeaturesToFeatureLayer(self, url, pathToFeatureClass, chunksize=0, lowerCaseFieldNames=False):\n        if arcpyFound == False:\n            raise common.ArcRestHelperError({\n                \"function\": \"AddFeaturesToFeatureLayer\",\n                \"line\": inspect.currentframe().f_back.f_lineno,\n                \"filename\":  'featureservicetools',\n                \"synerror\": \"ArcPy required for this function\"\n            })\n        fl = None\n        try:\n            fl = FeatureLayer(\n                   url=url,\n                   securityHandler=self._securityHandler)\n\n            if chunksize > 0:\n                fc = os.path.basename(pathToFeatureClass)\n                inDesc = arcpy.Describe(pathToFeatureClass)\n                oidName = inDesc.oidFieldName\n\n                arr = arcpy.da.FeatureClassToNumPyArray(pathToFeatureClass, (oidName))\n                syncSoFar = 0\n                messages = {'addResults':[],'errors':[]}\n                total = len(arr)\n                errorCount = 0\n                if total == '0':\n                    print (\"0 features in %s\" % pathToFeatureClass)\n                    return \"0 features in %s\" % pathToFeatureClass\n                print (\"%s features in layer\" % (total))\n\n                arcpy.env.overwriteOutput = True\n                if int(total) < int(chunksize):\n                    return fl.addFeatures(fc=pathToFeatureClass,lowerCaseFieldNames=lowerCaseFieldNames)\n                else:\n                    newArr = chunklist(arr,chunksize)\n                    exprList = [\"{0} >= {1} AND {0} <= {2}\".format(oidName, nArr[0][0], nArr[len(nArr)-1][0])\n                        for nArr in newArr]\n                    for expr in exprList:\n\n                        UploadLayer = arcpy.MakeFeatureLayer_management(pathToFeatureClass, 'TEMPCOPY', expr).getOutput(0)\n                        #print(arcpy.GetCount_management(in_rows=UploadLayer).getOutput(0) + \" features in the chunk\")\n                        results = fl.addFeatures(fc=UploadLayer,lowerCaseFieldNames=lowerCaseFieldNames)\n                        chunkCount = arcpy.GetCount_management(in_rows=UploadLayer).getOutput(0)\n                        print(chunkCount + \" features in the chunk\")\n                        if chunkCount > 0:\n\n                            if results is not None and 'addResults' in results and results['addResults'] is not None:\n                                featSucces = 0\n                                for result in results['addResults']:\n                                    if 'success' in result:\n                                        if result['success'] == False:\n                                            if 'error' in result:\n                                                errorCount  = errorCount + 1\n                                                print (\"\\tError info: %s\" % (result))\n                                        else:\n                                            featSucces = featSucces + 1\n                                syncSoFar = syncSoFar + featSucces\n                                print (\"%s features added in this chunk\" % (featSucces))\n                                print (\"%s/%s features added, %s errors\" % (syncSoFar,total,errorCount ))\n                                if 'addResults' in messages:\n                                    messages['addResults'] = messages['addResults'] + results['addResults']\n                                else:\n                                    messages['addResults'] = results['addResults']\n                            else:\n                                messages['errors'] = result\n                return messages\n            else:\n                return fl.addFeatures(fc=pathToFeatureClass,lowerCaseFieldNames=lowerCaseFieldNames)\n        except arcpy.ExecuteError:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                \"function\": \"AddFeaturesToFeatureLayer\",\n                \"line\": line,\n                \"filename\":  filename,\n                \"synerror\": synerror,\n                \"arcpyError\": arcpy.GetMessages(2),\n            }\n                           )\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"AddFeaturesToFeatureLayer\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            fl = None\n            del fl\n            gc.collect()", "response": "Adds local features to a hosted feature service layer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DeleteFeaturesFromFeatureLayer(self, url, sql, chunksize=0):\n        fl = None\n        try:\n            fl = FeatureLayer(\n                   url=url,\n                   securityHandler=self._securityHandler)\n            totalDeleted = 0\n            if chunksize > 0:\n                qRes = fl.query(where=sql, returnIDsOnly=True)\n                if 'error' in qRes:\n                    print (qRes)\n                    return qRes\n                elif 'objectIds' in qRes:\n                    oids = qRes['objectIds']\n                    total = len(oids)\n                    if total == 0:\n                        return  {'success':True,'message': \"No features matched the query\"}\n                    i = 0\n                    print (\"%s features to be deleted\" % total)\n                    while(i <= len(oids)):\n                        oidsDelete = ','.join(str(e) for e in oids[i:i+chunksize])\n                        if oidsDelete == '':\n                            continue\n                        else:\n                            results = fl.deleteFeatures(objectIds=oidsDelete)\n                        if 'deleteResults' in results:\n                            totalDeleted += len(results['deleteResults'])\n                            print (\"%s%% Completed: %s/%s \" % (int(totalDeleted / float(total) *100), totalDeleted, total))\n                            i += chunksize\n                        else:\n                            print (results)\n                            return {'success':True,'message': \"%s deleted\" % totalDeleted}\n                    qRes = fl.query(where=sql, returnIDsOnly=True)\n                    if 'objectIds' in qRes:\n                        oids = qRes['objectIds']\n                        if len(oids)> 0 :\n                            print (\"%s features to be deleted\" % len(oids))\n                            results = fl.deleteFeatures(where=sql)\n                            if 'deleteResults' in results:\n                                totalDeleted += len(results['deleteResults'])\n                                return  {'success':True,'message': \"%s deleted\" % totalDeleted}\n                            else:\n                                return results\n                    return  {'success':True,'message': \"%s deleted\" % totalDeleted}\n                else:\n                    print (qRes)\n            else:\n                results = fl.deleteFeatures(where=sql)\n                if results is not None:\n                    if 'deleteResults' in results:\n                        return  {'success':True,'message': totalDeleted + len(results['deleteResults'])}\n                    else:\n                        return results\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"DeleteFeaturesFromFeatureLayer\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            fl = None\n            del fl\n            gc.collect()", "response": "Removes features from a hosted feature service layer by SQL query."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef QueryAllFeatures(self, url=None,\n                         where=\"1=1\",\n                        out_fields=\"*\",\n                        timeFilter=None,\n                        geometryFilter=None,\n                        returnFeatureClass=False,\n                        out_fc=None,\n                        outSR=None,\n                        chunksize=1000,\n                        printIndent=\"\"):\n\n        \"\"\"Performs an SQL query against a hosted feature service layer\n        and returns all features regardless of service limit.\n\n        Args:\n            url (str): The URL of the feature service layer.\n            where - the selection sql statement\n            out_fields - the attribute fields to return\n            timeFilter - a TimeFilter object where either the start time\n                         or start and end time are defined to limit the\n                         search results for a given time.  The values in\n                         the timeFilter should be as UTC timestampes in\n                         milliseconds.  No checking occurs to see if they\n                         are in the right format.\n            geometryFilter - a GeometryFilter object to parse down a given\n                            query by another spatial dataset.\n            returnFeatureClass - Default False. If true, query will be\n                                 returned as feature class\n            chunksize (int): The maximum amount of features to query at a time. Defaults to 1000.\n            out_fc - only valid if returnFeatureClass is set to True.\n                        Output location of query.\n\n            Output:\n               A list of Feature Objects (default) or a path to the output featureclass if\n               returnFeatureClass is set to True.\n\n        \"\"\"\n        if (url is None):\n            return\n        fl = None\n        try:\n            fl = FeatureLayer(url=url, securityHandler=self._securityHandler)\n            qRes = fl.query(where=where,\n                            returnIDsOnly=True,\n                            timeFilter=timeFilter,\n                            geometryFilter=geometryFilter)\n\n            if 'error' in qRes:\n                print (printIndent + qRes)\n                return []\n            elif 'objectIds' in qRes:\n                oids = qRes['objectIds']\n                total = len(oids)\n                if total == 0:\n                    return fl.query(where=where,\n                                    returnGeometry=True,\n                                    out_fields=out_fields,\n                                    timeFilter=timeFilter,\n                                    geometryFilter=geometryFilter,\n                                    outSR=outSR)\n\n                print (printIndent + \"%s features to be downloaded\" % total)\n                chunksize = min(chunksize, fl.maxRecordCount)\n                combinedResults = None\n                totalQueried = 0\n                for chunk in chunklist(l=oids, n=chunksize):\n                    oidsQuery = \",\".join(map(str, chunk))\n                    if not oidsQuery:\n                        continue\n                    else:\n                        results = fl.query(objectIds=oidsQuery,\n                                           returnGeometry=True,\n                                           out_fields=out_fields,\n                                           timeFilter=timeFilter,\n                                            geometryFilter=geometryFilter,\n                                            outSR=outSR)\n                        if isinstance(results,FeatureSet):\n                            if combinedResults is None:\n                                combinedResults = results\n                            else:\n                                for feature in results.features:\n                                    combinedResults.features.append(feature)\n\n                            totalQueried += len(results.features)\n                            print(printIndent + \"{:.0%} Completed: {}/{}\".format(totalQueried / float(total), totalQueried, total))\n\n                        else:\n                            print (printIndent + results)\n                if returnFeatureClass == True:\n                    return combinedResults.save(*os.path.split(out_fc))\n                else:\n                    return combinedResults\n            else:\n                print (printIndent + qRes)\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"QueryAllFeatures\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            fl = None\n            del fl\n            gc.collect()", "response": "Query all features from a hosted feature service layer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dispose(self):\n        self._username = None\n        self._password = None\n        self._org_url = None\n        self._proxy_url = None\n        self._proxy_port = None\n        self._token_url = None\n        self._securityHandler = None\n        self._valid = None\n        self._message = None\n\n        del self._username\n        del self._password\n        del self._org_url\n        del self._proxy_url\n        del self._proxy_port\n        del self._token_url\n        del self._securityHandler\n        del self._valid\n        del self._message", "response": "Disposes the object from memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the contribution status of a user", "response": "def contributionStatus(self):\n        \"\"\"gets the contribution status of a user\"\"\"\n        import time\n        url = \"%s/contributors/%s/activeContribution\" % (self.root, quote(self.contributorUID))\n        params = {\n            \"agolUserToken\" : self._agolSH.token,\n            \"f\" : \"json\"\n        }\n        res = self._get(url=url,\n                         param_dict=params,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)\n        if'Status' in res and \\\n          res['Status'] == 'start':\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef user(self):\n        if self._user is None:\n            url = \"%s/users/%s\" % (self.root, self._username)\n            self._user = CMPUser(url=url,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url,\n                                 initialize=False)\n        return self._user", "response": "gets the user properties"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget or sets the public metadata url", "response": "def metadataURL(self, value):\n        \"\"\"gets/sets the public metadata url\"\"\"\n        if value != self._metadataURL:\n            self._metadataURL = value\n            self._metaFS = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef metadataContributer(self):\n        if self._metaFL is None:\n            fl = FeatureService(url=self._metadataURL,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port)\n            self._metaFS = fl\n        return self._metaFS", "response": "gets the metadata featurelayer object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef local_time_to_online(dt=None):\n    if dt is None:\n        dt = datetime.datetime.now()\n\n    is_dst = time.daylight and time.localtime().tm_isdst > 0\n    utc_offset =  (time.altzone if is_dst else time.timezone)\n\n    return (time.mktime(dt.timetuple())  * 1000) + (utc_offset *1000)", "response": "This function converts a local time object to a UTC timestamp for AGOL\n      "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef online_time_to_string(value, timeFormat, utcOffset=0):\n\n    try:\n        return datetime.datetime.fromtimestamp(value/1000 + utcOffset*3600).strftime(timeFormat)\n    except:\n        return \"\"\n    finally:\n        pass", "response": "Converts an online timestamp to a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_value(self, field_name, value):\n        if field_name in self.fields:\n            if not value is None:\n                self._dict['attributes'][field_name] = _unicode_convert(value)\n            else:\n                pass\n        elif field_name.upper() in ['SHAPE', 'SHAPE@', \"GEOMETRY\"]:\n            if isinstance(value, dict):\n                if 'geometry' in value:\n                    self._dict['geometry'] = value['geometry']\n                elif any(k in value.keys() for k in ['x','y','points','paths','rings', 'spatialReference']):\n                    self._dict['geometry'] = value\n            elif isinstance(value, AbstractGeometry):\n                self._dict['geometry'] = value.asDictionary\n            elif arcpyFound:\n                if isinstance(value, arcpy.Geometry) and \\\n                   value.type == self.geometryType:\n                    self._dict['geometry']=json.loads(value.JSON)\n            self._geom = None\n            self._geom = self.geometry\n        else:\n            return False\n        self._json = json.dumps(self._dict, default=_date_handler)\n        return True", "response": "sets an attribute value for a given field name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a value for a given field name", "response": "def get_value(self, field_name):\n        \"\"\" returns a value for a given field name \"\"\"\n        if field_name in self.fields:\n            return self._dict['attributes'][field_name]\n        elif field_name.upper() in ['SHAPE', 'SHAPE@', \"GEOMETRY\"]:\n            return self._dict['geometry']\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the feature as a dictionary", "response": "def asDictionary(self):\n        \"\"\"returns the feature as a dictionary\"\"\"\n        feat_dict = {}\n        if self._geom is not None:\n            if 'feature' in self._dict:\n                feat_dict['geometry'] = self._dict['feature']['geometry']\n            elif 'geometry' in self._dict:\n                feat_dict['geometry'] =  self._dict['geometry']\n        if 'feature' in self._dict:\n            feat_dict['attributes'] = self._dict['feature']['attributes']\n        else:\n            feat_dict['attributes'] = self._dict['attributes']\n        return self._dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef asRow(self):\n        fields = self.fields\n        row = [\"\"] * len(fields)\n        for k,v in self._attributes.items():\n            row[fields.index(k)] = v\n            del v\n            del k\n        if self.geometry is not None:\n            row.append(self.geometry)\n            fields.append(\"SHAPE@\")\n        return row, fields", "response": "converts a feature to a list for insertion into an insert cursor\n            Output :\n               [row items ] fields [ field names ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef geometry(self):\n        if arcpyFound:\n            if self._geom is None:\n                if 'feature' in self._dict:\n                    self._geom = arcpy.AsShape(self._dict['feature']['geometry'], esri_json=True)\n                elif 'geometry' in self._dict:\n                    self._geom = arcpy.AsShape(self._dict['geometry'], esri_json=True)\n            return self._geom\n        return None", "response": "returns the feature geometry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef geometry(self, value):\n        if isinstance(value, (Polygon, Point, Polyline, MultiPoint)):\n            if value.type == self.geometryType:\n                self._geom = value\n        elif arcpyFound:\n            if isinstance(value, arcpy.Geometry):\n                if value.type == self.geometryType:\n                    self._dict['geometry']=json.loads(value.JSON)\n                    self._geom = None\n                    self._geom = self.geometry", "response": "gets or sets a feature s geometry"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of feature fields", "response": "def fields(self):\n        \"\"\" returns a list of feature fields \"\"\"\n        if 'feature' in self._dict:\n            self._attributes = self._dict['feature']['attributes']\n        else:\n            self._attributes = self._dict['attributes']\n        return self._attributes.keys()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef geometryType(self):\n        if self._geomType is None:\n            if self.geometry is not None:\n                self._geomType = self.geometry.type\n            else:\n                self._geomType = \"Table\"\n        return self._geomType", "response": "returns the feature s geometry type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a dataset to a list of feature objects", "response": "def fc_to_features(dataset):\n        \"\"\"\n           converts a dataset to a list of feature objects\n           Input:\n              dataset - path to table or feature class\n           Output:\n              list of feature objects\n        \"\"\"\n        if arcpyFound:\n            desc = arcpy.Describe(dataset)\n            fields = [field.name for field in arcpy.ListFields(dataset) if field.type not in ['Geometry']]\n            date_fields = [field.name for field in arcpy.ListFields(dataset) if field.type =='Date']\n            non_geom_fields = copy.deepcopy(fields)\n            features = []\n            if hasattr(desc, \"shapeFieldName\"):\n                fields.append(\"SHAPE@JSON\")\n            del desc\n            with arcpy.da.SearchCursor(dataset, fields) as rows:\n                for row in rows:\n                    row = list(row)\n                    for df in date_fields:\n                        if row[fields.index(df)] != None:\n                            row[fields.index(df)] = int((_date_handler(row[fields.index(df)])))\n                    template = {\n                        \"attributes\" : dict(zip(non_geom_fields, row))\n                    }\n                    if \"SHAPE@JSON\" in fields:\n                        template['geometry'] = \\\n                            json.loads(row[fields.index(\"SHAPE@JSON\")])\n\n                    features.append(\n                        Feature(json_string=_unicode_convert(template))\n                    )\n                    del row\n            return features\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the mosaic method of the object", "response": "def mosaicMethod(self, value):\n        \"\"\"\n        get/set the mosaic method\n        \"\"\"\n        if value in self.__allowedMosaicMethods and \\\n           self._mosaicMethod != value:\n            self._mosaicMethod = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef value(self):\n        if self.mosaicMethod == \"esriMosaicNone\" or\\\n           self.mosaicMethod == \"esriMosaicCenter\" or \\\n           self.mosaicMethod == \"esriMosaicNorthwest\" or \\\n           self.mosaicMethod == \"esriMosaicNadir\":\n            return {\n                \"mosaicMethod\" : \"esriMosaicNone\",\n                \"where\" : self._where,\n                \"ascending\" : self._ascending,\n                \"fids\" : self.fids,\n                \"mosaicOperation\" : self._mosaicOperation\n            }\n        elif self.mosaicMethod == \"esriMosaicViewpoint\":\n            return {\n                \"mosaicMethod\" : \"esriMosaicViewpoint\",\n                \"viewpoint\" : self._viewpoint.asDictionary,\n                \"where\" : self._where,\n                \"ascending\" : self._ascending,\n                \"fids\" : self._fids,\n                \"mosaicOperation\" : self._mosaicOperation\n            }\n        elif self.mosaicMethod == \"esriMosaicAttribute\":\n            return {\n                \"mosaicMethod\" : \"esriMosaicAttribute\",\n                \"sortField\" : self._sortField,\n                \"sortValue\" : self._sortValue,\n                \"ascending\" : self._ascending,\n                \"where\" : self._where,\n                \"fids\" : self._fids,\n                \"mosaicOperation\" : self._mosaicOperation\n            }\n        elif self.mosaicMethod == \"esriMosaicLockRaster\":\n            return {\n                \"mosaicMethod\" : \"esriMosaicLockRaster\",\n                \"lockRasterIds\" : self._localRasterIds,\n                \"where\" : self._where,\n                \"ascending\" : self._ascending,\n                \"fids\" : self._fids,\n                \"mosaicOperation\" : self._mosaicOperation\n            }\n        elif self.mosaicMethod == \"esriMosaicSeamline\":\n            return {\n                \"mosaicMethod\" : \"esriMosaicSeamline\",\n                \"where\" : self._where,\n                \"fids\" : self._fids,\n                \"mosaicOperation\" : self._mosaicOperation\n            }\n        else:\n            raise AttributeError(\"Invalid Mosaic Method\")", "response": "Returns the value of the mosaic rule as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value(self):\n        return {\n            \"objectIdFieldName\" : self._objectIdFieldName,\n            \"displayFieldName\" : self._displayFieldName,\n            \"globalIdFieldName\" : self._globalIdFieldName,\n            \"geometryType\" : self._geometryType,\n            \"spatialReference\" : self._spatialReference,\n            \"hasZ\" : self._hasZ,\n            \"hasM\" : self._hasM,\n            \"fields\" : self._fields,\n            \"features\" : [f.asDictionary for f in self._features]\n        }", "response": "returns object as dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromJSON(jsonValue):\n        jd = json.loads(jsonValue)\n        features = []\n        if 'fields' in jd:\n            fields = jd['fields']\n        else:\n            fields = {'fields':[]}\n        if 'features' in jd:\n            for feat in jd['features']:\n                wkid = None\n                spatialReference =None\n                if 'spatialReference' in jd:\n                    spatialReference = jd['spatialReference']\n                    if 'wkid' in jd['spatialReference']:\n                        wkid = jd['spatialReference']['wkid']\n                    elif 'latestWkid' in jd['spatialReference']: # kept for compatibility\n                        wkid = jd['spatialReference']['latestWkid']\n                features.append(Feature(json_string=feat, wkid=wkid, spatialReference=spatialReference))\n        return FeatureSet(fields,\n                          features,\n                          hasZ=jd['hasZ'] if 'hasZ' in jd else False,\n                          hasM=jd['hasM'] if 'hasM' in jd else False,\n                          geometryType=jd['geometryType'] if 'geometryType' in jd else None,\n                          objectIdFieldName=jd['objectIdFieldName'] if 'objectIdFieldName' in jd else None,\n                          globalIdFieldName=jd['globalIdFieldName'] if 'globalIdFieldName' in jd else None,\n                          displayFieldName=jd['displayFieldName'] if 'displayFieldName' in jd else None,\n                          spatialReference=jd['spatialReference'] if 'spatialReference' in jd else None)", "response": "returns a featureset from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the featureset s spatial reference", "response": "def spatialReference(self, value):\n        \"\"\"sets the featureset's spatial reference\"\"\"\n        if isinstance(value, SpatialReference):\n            self._spatialReference = value\n        elif isinstance(value, int):\n            self._spatialReference = SpatialReference(wkid=value)\n        elif isinstance(value, str) and \\\n             str(value).isdigit():\n            self._spatialReference = SpatialReference(wkid=int(value))\n        elif isinstance(value, dict):\n            wkid = None\n            wkt = None\n            if 'wkid' in value and \\\n               str(value['wkid']).isdigit():\n                wkid = int(value['wkid'])\n            if 'latestWkid' in value and \\\n               str(value['latestWkid']).isdigit():\n                wkid = int(value['latestWkid'])\n            if 'wkt' in value:\n                wkt = value['wkt']\n            self._spatialReference = SpatialReference(wkid=wkid,wkt=wkt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave a feature class object to a feature class object.", "response": "def save(self, saveLocation, outName):\n        \"\"\"\n        Saves a featureset object to a feature class\n        Input:\n           saveLocation - output location of the data\n           outName - name of the table the data will be saved to\n                Types:\n                    *.csv - CSV file returned\n                    *.json - text file with json\n                    * If no extension, a shapefile if the path is a\n                        folder, a featureclass if the path is a GDB\n\n        \"\"\"\n        filename, file_extension = os.path.splitext(outName)\n        if (file_extension == \".csv\"):\n            res = os.path.join(saveLocation,outName)\n            import sys\n            if sys.version_info[0] == 2:\n                access = 'wb+'\n                kwargs = {}\n            else:\n                access = 'wt+'\n                kwargs = {'newline':''}\n            with open(res, access, **kwargs) as csvFile:\n                import csv\n                f = csv.writer(csvFile)\n                fields = []\n                #write the headers to the csv\n                for field in self.fields:\n                    fields.append(field['name'])\n                f.writerow(fields)\n\n                newRow = []\n                #Loop through the results and save each to a row\n                for feature in self:\n                    newRow = []\n                    for field in self.fields:\n                        newRow.append(feature.get_value(field['name']))\n                    f.writerow(newRow)\n                csvFile.close()\n            del csvFile\n        elif (file_extension == \".json\"):\n            res = os.path.join(saveLocation,outName)\n            with open(res, 'wb') as writer:\n\n                json.dump(self.value, writer, sort_keys = True, indent = 4, ensure_ascii=False)\n                writer.flush()\n                writer.close()\n            del writer\n\n        else:\n            tempDir =  tempfile.gettempdir()\n            tempFile = os.path.join(tempDir, \"%s.json\" % uuid.uuid4().hex)\n            with open(tempFile, 'wt') as writer:\n                writer.write(self.toJSON)\n                writer.flush()\n                writer.close()\n            del writer\n            res = json_to_featureclass(json_file=tempFile,\n                                       out_fc=os.path.join(saveLocation, outName))\n            os.remove(tempFile)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves users content and data.", "response": "def removeUserData(self, users=None):\n        \"\"\"Removes users' content and data.\n        \n        Args:\n            users (str): A comma delimited list of user names.\n                Defaults to ``None``.\n        \n        Warning:\n            When ``users`` is not provided (``None``), all users\n            in the organization will have their data deleted!\n        \n        \"\"\" \n        admin = None\n        portal = None\n        user = None\n        adminusercontent = None\n        userFolder = None\n        userContent = None\n        userItem = None\n        folderContent = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            if users is None:\n                print (\"You have selected to remove all users data, you must modify the code to do this\")\n                usersObj = []\n                commUsers = admin.portals.portalSelf.users(start=1, num=100)\n                commUsers = commUsers['users']\n                for user in commUsers:\n                    usersObj.append(user.userContent)\n                return\n            else:\n                usersObj = []\n                userStr = users.split(',')\n                for user in userStr:\n                    try:\n                        user = admin.content.users.user(str(user).strip())\n                        usersObj.append(user)\n                    except:\n                        print (\"%s does not exist\" % str(user).strip())\n\n            if usersObj:\n                for user in usersObj:\n                    print (\"Loading content for user: %s\" % user.username)\n\n                    itemsToDel = []\n                    for userItem in user.items:\n                        itemsToDel.append(userItem.id)\n                    if len(itemsToDel) > 0:\n                        print (user.deleteItems(items=\",\".join(itemsToDel)))\n                    if user.folders:\n                        for userFolder in user.folders:\n                            if (user.currentFolder['title'] != userFolder['title']):\n                                user.currentFolder = userFolder['title']\n                                itemsToDel = []\n                                for userItem in user.items:\n                                    itemsToDel.append(userItem.id)\n                                if len(itemsToDel) > 0:\n                                    print (user.deleteItems(items=\",\".join(itemsToDel)))\n\n                                print (user.deleteFolder())\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"removeUserData\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            portal = None\n            user = None\n            adminusercontent = None\n            userFolder = None\n            userContent = None\n            userItem = None\n            folderContent = None\n\n            del admin\n            del portal\n            del user\n            del adminusercontent\n            del userFolder\n            del userContent\n            del userItem\n            del folderContent\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef removeUserGroups(self, users=None):\n        admin = None\n        userCommunity = None\n        portal = None\n        groupAdmin = None\n        user = None\n        userCommData = None\n        group = None\n        try:\n\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            if users is None:\n                print (\"You have selected to remove all users groups, you must modify the code to do this\")\n                usersObj = []\n                commUsers = admin.portals.portalSelf.users(start=1, num=100)\n                usersObj = commUsers['users']\n\n                return\n            else:\n                usersObj = []\n                userStr = users.split(',')\n                for user in userStr:\n                    try:\n                        user = admin.community.users.user(str(user).strip())\n                        usersObj.append(user)\n                    except:\n                        print (\"%s does not exist\" % str(user).strip())\n            if usersObj:\n                for userCommData in usersObj:\n                    print (\"Loading groups for user: %s\" % userCommData.username)\n\n                    if userCommData.groups:\n                        for group in userCommData.groups:\n                            groupObj = admin.community.groups.group(groupId=group['id'])\n                            if groupObj.owner == userCommData.username:\n                                print (groupObj.delete())\n                    else:\n                        print (\"No Groups Found\")\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"removeUserGroups\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            userCommunity = None\n            portal = None\n            groupAdmin = None\n            user = None\n            userCommData = None\n            group = None\n\n            del admin\n            del userCommunity\n            del portal\n            del groupAdmin\n            del user\n            del userCommData\n            del group\n\n            gc.collect()", "response": "Removes users and groups from the organization."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef regions(self):\n        url = \"%s/regions\" % self.root\n        params = {\"f\": \"json\"}\n        return self._get(url=url,\n                            param_dict=params,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "gets the regions value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef portalSelf(self):\n        url = \"%s/self\" % self.root\n        return Portal(url=url,\n                      securityHandler=self._securityHandler,\n                      proxy_url=self._proxy_url,\n                      proxy_port=self._proxy_port,\n                      )", "response": "The portal to which the current user belongs. This is an organizational portal or the default portal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef portal(self, portalID=None):\n        if portalID is None:\n            portalID = self.portalSelf.id\n        url = \"%s/%s\" % (self.root, portalID)\n        return Portal(url=url,\n                  securityHandler=self._securityHandler,\n                  proxy_url=self._proxy_url,\n                  proxy_port=self._proxy_port,\n                  initalize=True)", "response": "returns a specific reference to a portal"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the portal id for a site if not known", "response": "def _findPortalId(self):\n        \"\"\"gets the portal id for a site if not known.\"\"\"\n        if not self.root.lower().endswith(\"/self\"):\n            url = self.root + \"/self\"\n        else:\n            url = self.root\n        params = {\n            \"f\" : \"json\"\n        }\n        res = self._get(url=url, param_dict=params,\n                           securityHandler=self._securityHandler,\n                           proxy_port=self._proxy_port,\n                           proxy_url=self._proxy_url)\n        if 'id' in res:\n            return res['id']\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the portal Id", "response": "def portalId(self):\n        \"\"\"gets the portal Id\"\"\"\n        if self._portalId is None:\n            self._portalId = self._findPortalId()\n        return self._portalId"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef featureServers(self):\n        if self.urls == {}:\n            return {}\n\n        featuresUrls = self.urls['urls']['features']\n        if 'https' in featuresUrls:\n            res = featuresUrls['https']\n        elif 'http' in featuresUrls:\n            res = featuresUrls['http']\n        else:\n            return None\n\n        services = []\n        for urlHost in res:\n            if self.isPortal:\n                services.append(AGSAdministration(\n                    url='%s/admin' % urlHost,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port))\n            else:\n                services.append(Services(\n                    url='https://%s/%s/ArcGIS/admin' % (urlHost, self.portalId),\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port))\n\n        return services", "response": "gets the hosting feature AGS Server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport the customer list to a csv file", "response": "def exportCustomers(self, outPath):\n        \"\"\"exports customer list to a csv file\n        Input:\n         outPath - save location of the customer list\n        \"\"\"\n        url = \"%s/customers/export\" % self.root\n        params = {\"f\":\"csv\"}\n        dirPath = None\n        fileName = None\n        if outPath is not None:\n            dirPath = os.path.dirname(outPath)\n            fileName = os.path.basename(outPath)\n        return self._get(url=url,\n                         param_dict=params,\n                         securityHandler=self._securityHandler, proxy_url=self._proxy_url,\n                        proxy_port=self._proxy_port,\n                        out_folder=dirPath,\n                        file_name=fileName)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks to see if a given service name and type is available for publishing a new service.", "response": "def isServiceNameAvailable(self,\n                               name,\n                               serviceType):\n        \"\"\"\n        Checks to see if a given service name and type are available for\n        publishing a new service. true indicates that the name and type is\n        not found in the organization's services and is available for\n        publishing. false means the requested name and type are not available.\n\n        Inputs:\n           name - requested name of service\n           serviceType - type of service allowed values: Feature Service or\n                         Map Service\n        \"\"\"\n        _allowedTypes = ['Feature Service', \"Map Service\"]\n        url = self._url + \"/isServiceNameAvailable\"\n        params = {\n            \"f\" : \"json\",\n            \"name\" : name,\n            \"type\" : serviceType\n        }\n        return self._get(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef servers(self):\n        url = \"%s/servers\" % self.root\n        return Servers(url=url,\n                       securityHandler=self._securityHandler,\n                       proxy_url=self._proxy_url,\n                       proxy_port=self._proxy_port)", "response": "gets the federated or registered servers for Portal"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassigning credit to a user. Inputs: usernames - list of users credits - number of credits to assign to the users Ouput: dictionary", "response": "def assignUserCredits(self, usernames, credits):\n        \"\"\"\n        assigns credit to a user.\n        Inputs:\n           usernames - list of users\n           credits - number of credits to assign to the users\n        Ouput:\n           dictionary\n        \"\"\"\n        userAssignments = []\n        for name in usernames:\n            userAssignments.append(\n                {\n                    \"username\" : name,\n                    \"credits\" : credits\n                }\n            )\n        params = {\n            \"userAssignments\" : userAssignments,\n            \"f\" : \"json\"\n        }\n        url = self.root + \"/assignUserCredits\"\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createRole(self, name, description):\n        params = {\n            \"name\" : name,\n            \"description\" : description,\n            \"f\" : \"json\"\n        }\n        url = self.root + \"/createRole\"\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "Creates a role for a portal site."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef roles(self):\n        return Roles(url=\"%s/roles\" % self.root,\n                     securityHandler=self._securityHandler,\n                     proxy_url=self._proxy_url,\n                     proxy_port=self._proxy_port)", "response": "gets the roles class that allows admins to manage custom roles on portal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the cost values for a given portal Inputs: tileStorage - int - numbe of tiles to store in MBs fileStorage - int - size of file to store in MBs featureStorage - int - size in MBs generateTileCount - int - number of tiles to genearte on site loadedTileCount -int- cost to host a certian number of tiles enrichVariableCount - int - cost to enrich data enrichReportCount - int - cost to generate an enrichment report serviceAreaCount - int - cost to generate x number of service areas geocodeCount - int - cost to generate x number of addresses", "response": "def cost(self,\n             tileStorage=0,\n             fileStorage=0,\n             featureStorage=0,\n             generatedTileCount=0,\n             loadedTileCount=0,\n             enrichVariableCount=0,\n             enrichReportCount=0,\n             serviceAreaCount=0,\n             geocodeCount=0):\n        \"\"\"\n        returns the cost values for a given portal\n        Inputs:\n         tileStorage - int - numbe of tiles to store in MBs\n         fileStorage - int - size of file to store in MBs\n         featureStorage - int - size in MBs\n         generateTileCount - int - number of tiles to genearte on site\n         loadedTileCount -int- cost to host a certian number of tiles\n         enrichVariableCount - int - cost to enrich data\n         enrichReportCount - int - cost to generate an enrichment report\n         serviceAreaCount - int - cost to generate x number of service\n          areas\n         geocodeCount - int - cost to generate x number of addresses\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"tileStorage\": tileStorage,\n            \"fileStorage\": fileStorage,\n            \"featureStorage\": featureStorage,\n            \"generatedTileCount\": generatedTileCount,\n            \"loadedTileCount\":loadedTileCount,\n            \"enrichVariableCount\": enrichVariableCount,\n            \"enrichReportCount\" : enrichReportCount,\n            \"serviceAreaCount\" : serviceAreaCount,\n            \"geocodeCount\" : geocodeCount\n        }\n        url = self._url + \"/cost\"\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef updateSecurityPolicy(self,\n                             minLength=8,\n                             minUpper=None,\n                             minLower=None,\n                             minLetter=None,\n                             minDigit=None,\n                             minOther=None,\n                             expirationInDays=None,\n                             historySize=None):\n        \"\"\"updates the Portals security policy\"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"minLength\" : minLength,\n            \"minUpper\": minUpper,\n            \"minLower\": minLower,\n            \"minLetter\": minLetter,\n            \"minDigit\": minDigit,\n            \"minOther\": minOther,\n            \"expirationInDays\" : expirationInDays,\n            \"historySize\": historySize\n        }\n        url = \"%s/securityPolicy/update\" % self.root\n        return self._post(url=url,\n                     param_dict=params,\n                     securityHandler=self._securityHandler,\n                     proxy_url=self._proxy_url,\n                     proxy_port=self._proxy_port)", "response": "This operation updates the Portals security policy. The Portals security policy is updated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef portalAdmin(self):\n        from ..manageportal import PortalAdministration\n        return PortalAdministration(admin_url=\"https://%s/portaladmin\" % self.portalHostname,\n                                    securityHandler=self._securityHandler,\n                                    proxy_url=self._proxy_url,\n                                    proxy_port=self._proxy_port,\n                                    initalize=False)", "response": "gets a reference to a portal administration class"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a user without sending an invitation email Inputs: invitationList - InvitationList class used to add users without sending an email subject - email subject html - email message sent to users in invitation list object", "response": "def addUser(self, invitationList,\n                subject, html):\n        \"\"\"\n        adds a user without sending an invitation email\n\n        Inputs:\n           invitationList - InvitationList class used to add users without\n            sending an email\n           subject - email subject\n           html - email message sent to users in invitation list object\n        \"\"\"\n        url = self._url + \"/invite\"\n        params = {\"f\" : \"json\"}\n        if isinstance(invitationList, parameters.InvitationList):\n            params['invitationList'] = invitationList.value()\n        params['html'] = html\n        params['subject'] = subject\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inviteByEmail(self,\n                   emails,\n                   subject,\n                   text,\n                   html,\n                   role=\"org_user\",\n                   mustApprove=True,\n                   expiration=1440):\n        \"\"\"Invites a user or users to a site.\n\n        Inputs:\n           emails - comma seperated list of emails\n           subject - title of email\n           text - email text\n           html - email text in html\n           role - site role (can't be administrator)\n           mustApprove - verifies if user that is join must be approved by\n            an administrator\n           expiration - time in seconds. Default is 1 day 1440\n        \"\"\"\n        url = self.root + \"/inviteByEmail\"\n        params = {\n            \"f\" : \"json\",\n            \"emails\": emails,\n            \"subject\": subject,\n            \"text\": text,\n            \"html\" : html,\n            \"role\" : role,\n            \"mustApprove\": mustApprove,\n            \"expiration\" : expiration\n        }\n        return self._post(url=url, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "Invites a user or users to a site."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the usage statistics value", "response": "def usage(self, startTime, endTime, vars=None, period=None,\n              groupby=None, name=None, stype=None, etype=None,\n              appId=None, deviceId=None, username=None, appOrgId=None,\n              userOrgId=None, hostOrgId=None):\n        \"\"\"\n        returns the usage statistics value\n        \"\"\"\n\n        url = self.root + \"/usage\"\n        startTime = str(int(local_time_to_online(dt=startTime)))\n        endTime = str(int(local_time_to_online(dt=endTime)))\n\n        params = {\n                    'f' : 'json',\n                    'startTime' : startTime,\n                    'endTime' : endTime,\n                    'vars' : vars,\n                    'period' : period,\n                    'groupby' : groupby,\n                    'name' : name,\n                    'stype' : stype,\n                    'etype' : etype,\n                    'appId' : appId,\n                    'deviceId' : deviceId,\n                    'username' : username,\n                    'appOrgId' : appOrgId,\n                    'userOrgId' : userOrgId,\n                    'hostOrgId' : hostOrgId,\n                 }\n\n        params = {key:item for key,item in params.items() if item is not None}\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all the server resources", "response": "def servers(self):\n        \"\"\"gets all the server resources\"\"\"\n        self.__init()\n        items = []\n        for k,v in self._json_dict.items():\n            if k == \"servers\":\n                for s in v:\n                    if 'id' in s:\n                        url = \"%s/%s\" % (self.root, s['id'])\n                        items.append(\n                            self.Server(url=url,\n                                        securityHandler=self._securityHandler,\n                                        proxy_url=self._proxy_url,\n                                        proxy_port=self._proxy_port))\n            del k,v\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deleteRole(self, roleID):\n        url = self._url + \"/%s/delete\" % roleID\n        params = {\n            \"f\" : \"json\"\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation deletes a role by ID. The roleID is the ID of the role in which the user has access to it. The roleID is the ID of the user who has access to it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow for the role name or description to be modified", "response": "def updateRole(self, roleID, name, description):\n        \"\"\"allows for the role name or description to be modified\"\"\"\n        params = {\n            \"name\" : name,\n            \"description\" : description,\n            \"f\" : \"json\"\n        }\n        url = self._url + \"/%s/update\"\n        return self._post(url=url,\n                             param_dict=params,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches the roles by name and returns the role s ID", "response": "def findRoleID(self, name):\n        \"\"\"searches the roles by name and returns the role's ID\"\"\"\n        for r in self:\n            if r['name'].lower() == name.lower():\n                return r['id']\n            del r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_config_value(config_file, section, variable):\n    try:\n        parser = ConfigParser.SafeConfigParser()\n        parser.read(config_file)\n        return parser.get(section, variable)\n    except:\n        return None", "response": "Extracts a config file value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprovide access to all user resources", "response": "def users(self):\n        \"\"\"\n        Provides access to all user resources\n        \"\"\"\n        return Users(url=\"%s/users\" % self.root,\n                     securityHandler=self._securityHandler,\n                     proxy_url=self._proxy_url,\n                     proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the refernce to the Items class which manages content on AGOL or Portal site.", "response": "def getItem(self, itemId):\n        \"\"\"gets the refernce to the Items class which manages content on a\n        given AGOL or Portal site.\n        \"\"\"\n        url = \"%s/items/%s\" % (self.root, itemId)\n        return Item(url=url,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FeatureContent(self):\n        return FeatureContent(url=\"%s/%s\" % (self.root, \"features\"),\n                              securityHandler=self._securityHandler,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port)", "response": "Feature Content class id the parent resource for feature\n        operations such as Analyze and Generate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef group(self, groupId):\n        url = self._url + \"/groups/%s\" % groupId\n        return Group(groupId=groupId,\n                      contentURL=url,\n                      securityHandler=self._securityHandler,\n                      proxy_url=self._proxy_url,\n                      proxy_port=self._proxy_port)", "response": "returns a group object that can be used to access the items that are shared with the group. The group s content provides access to the items that are physically stored\n        in the group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user(self, username=None):\n        if username is None:\n            username = self.__getUsername()\n\n        url = \"%s/%s\" % (self.root, username)\n        return User(url=url,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port,\n                    initalize=True)", "response": "gets the user s content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the thumbnail used for the item", "response": "def saveThumbnail(self,fileName,filePath):\n        \"\"\" URL to the thumbnail used for the item \"\"\"\n        if self._thumbnail is None:\n            self.__init()\n        param_dict = {}\n        if  self._thumbnail is not None:\n            imgUrl = self.root + \"/info/\" + self._thumbnail\n            onlineFileName, file_ext = splitext(self._thumbnail)\n            fileNameSafe = \"\".join(x for x in fileName if x.isalnum()) + file_ext\n            result = self._get(url=imgUrl,\n                               param_dict=param_dict,\n                               securityHandler=self._securityHandler,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port,\n                               out_folder=filePath,\n                               file_name=fileNameSafe)\n            return result\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a reference to the UserItem class", "response": "def userItem(self):\n        \"\"\"returns a reference to the UserItem class\"\"\"\n        if self.ownerFolder is not None:\n            url = \"%s/users/%s/%s/items/%s\" % (self.root.split('/items/')[0], self.owner,self.ownerFolder, self.id)\n        else:\n            url = \"%s/users/%s/items/%s\" % (self.root.split('/items/')[0], self.owner, self.id)\n        return UserItem(url=url,\n                        securityHandler=self._securityHandler,\n                        proxy_url=self._proxy_url,\n                        proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the data for an item on agol", "response": "def itemData(self, f=None, savePath=None):\n        \"\"\" returns data for an item on agol/portal\n\n        Inputs:\n           f - output format either zip of json\n           savePath - location to save the file\n        Output:\n           either JSON/text or filepath\n        \"\"\"\n\n        params = {\n        }\n        if f is not None and \\\n           f.lower() in ['zip', 'json']:\n            params['f'] = f\n        url = \"%s/data\" % self.root\n        if self.type in [\"Shapefile\", \"CityEngine Web Scene\", \"Web Scene\", \"KML\",\n                         \"Code Sample\",\n                         \"Code Attachment\", \"Operations Dashboard Add In\",\n                         \"CSV\", \"CSV Collection\", \"CAD Drawing\", \"Service Definition\",\n                         \"Microsoft Word\", \"Microsoft Powerpoint\",\n                         \"Microsoft Excel\", \"PDF\", \"Image\",\n                         \"Visio Document\", \"iWork Keynote\", \"iWork Pages\",\n                         \"iWork Numbers\", \"Map Document\", \"Map Package\",\n                         \"Basemap Package\", \"Tile Package\", \"Project Package\",\n                         \"Task File\", \"ArcPad Package\", \"Explorer Map\",\n                         \"Globe Document\", \"Scene Document\", \"Published Map\",\n                         \"Map Template\", \"Windows Mobile Package\", \"Pro Map\",\n                         \"Layout\", \"Layer\", \"Layer Package\", \"File Geodatabase\",\n                         \"Explorer Layer\", \"Geoprocessing Package\", \"Geoprocessing Sample\",\n                         \"Locator Package\", \"Rule Package\", \"Workflow Manager Package\",\n                         \"Desktop Application\", \"Desktop Application Template\",\n                         \"Code Sample\", \"Desktop Add In\", \"Explorer Add In\",\n                         \"ArcGIS Desktop Add-In\", \"ArcGIS Explorer Add-In\",\n                         \"ArcGIS Explorer application configuration\", \"ArcGIS Explorer document\",\n                         ]:\n            if savePath is None:\n                raise AttributeError('savePath must be provided for a item of type: %s' % self.type)\n            if os.path.isdir(savePath) == False:\n                os.makedirs(savePath)\n            result = self._get(url=url,\n                               param_dict=params,\n                               securityHandler=self._securityHandler,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port,\n                               out_folder=savePath,\n                               file_name=self.name)\n            return result\n        else:\n            results =  self._get(url, params,\n                                 proxy_port=self._proxy_port,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url)\n            return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a rating to an item between 1. 0 and 5. 0", "response": "def addRating(self, rating=5.0):\n        \"\"\"Adds a rating to an item between 1.0 and 5.0\"\"\"\n        if rating > 5.0:\n            rating = 5.0\n        elif rating < 1.0:\n            rating = 1.0\n        url = \"%s/addRating\" % self.root\n        params = {\n            \"f\": \"json\",\n            \"rating\" : \"%s\" % rating\n        }\n        return self._post(url,\n                             params,\n                             proxy_port=self._proxy_port,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deleteRating(self):\n        url = \"%s/deleteRating\" % self.root\n        params = {\n            \"f\": \"json\",\n        }\n        return self._post(url,\n                             params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)", "response": "Removes the rating the calling user added for the specified item\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a comment to a given item.", "response": "def addComment(self, comment):\n        \"\"\" adds a comment to a given item.  Must be authenticated \"\"\"\n        url = \"%s/addComment\" % self.root\n        params = {\n            \"f\" : \"json\",\n            \"comment\" : comment\n        }\n        return self._post(url, params, proxy_port=self._proxy_port,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns details of a single comment", "response": "def itemComment(self, commentId):\n        \"\"\" returns details of a single comment \"\"\"\n        url = \"%s/comments/%s\" % (self.root, commentId)\n        params = {\n            \"f\": \"json\"\n        }\n        return self._get(url,\n                            params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef itemComments(self):\n        url = \"%s/comments/\" % self.root\n        params = {\n            \"f\": \"json\"\n        }\n        return self._get(url,\n                            params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)", "response": "returns all comments for a given item"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a comment from an Item", "response": "def deleteComment(self, commentId):\n        \"\"\" removes a comment from an Item\n\n        Inputs:\n           commentId - unique id of comment to remove\n        \"\"\"\n        url = \"%s/comments/%s/delete\" % (self.root, commentId)\n        params = {\n            \"f\": \"json\",\n        }\n        return self._post(url,\n                             params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef packageInfo(self):\n        url = \"%s/item.pkinfo\" % self.root\n        params = {'f' : 'json'}\n        result = self._get(url=url,\n                           param_dict=params,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port,\n                           out_folder=tempfile.gettempdir())\n        return result", "response": "gets the item s package information file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport metadata to the various supported formats Inputs: exportFormats - export metadata to the following formats: fgdc, inspire, iso19139, iso19139-3.2, iso19115, arcgis, and default. default means the value will be ISO 19139 Metadata Implementation Specification GML3.2 or the default format set for your ArcGIS online organizational account. output - html or none. Html returns values as html text. saveFolder - Default is None. If provided the metadata file will be saved to that location. fileName - Default is None. If provided, this will be the name of the file on your local drive. Output: path to file or string", "response": "def metadata(self,\n                 exportFormat=\"default\",\n                 output=None,\n                 saveFolder=None,\n                 fileName=None):\n        \"\"\"\n        exports metadata to the various supported formats\n        Inputs:\n          exportFormats - export metadata to the following formats: fgdc,\n           inspire, iso19139, iso19139-3.2, iso19115, arcgis, and default.\n           default means the value will be ISO 19139 Metadata\n           Implementation Specification GML3.2 or the default format set\n           for your ArcGIS online organizational account.\n          output - html or none.  Html returns values as html text.\n          saveFolder - Default is None. If provided the metadata file will\n           be saved to that location.\n          fileName - Default is None. If provided, this will be the name of\n           the file on your local drive.\n        Output:\n         path to file or string\n        \"\"\"\n        url = \"%s/info/metadata/metadata.xml\" % self.root\n        allowedFormats = [\"fgdc\", \"inspire\", \"iso19139\",\n                          \"iso19139-3.2\", \"iso19115\", \"arcgis\", \"default\"]\n        if not exportFormat.lower() in allowedFormats:\n            raise Exception(\"Invalid exportFormat\")\n        if exportFormat.lower() == \"arcgis\":\n            params = {}\n        else:\n            params = {\n                \"format\" : exportFormat\n            }\n        if exportFormat.lower() == \"default\":\n            exportFormat = \"\"\n        params = {\n            \"format\" : exportFormat\n        }\n        if output is not None:\n            params['output'] = output\n        if saveFolder is None:\n            saveFolder = tempfile.gettempdir()\n        if fileName is None:\n            fileName = \"metadata.xml\"\n        if output is None:\n            result = self._get(url=url,\n                               param_dict=params,\n                               securityHandler=self._securityHandler,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port,\n                               out_folder=saveFolder,\n                               file_name=fileName)\n            if os.path.isfile(result) == False:\n                with open(os.path.join(saveFolder, fileName), 'wb') as writer:\n                    writer.write(result)\n                    writer.flush()\n                    writer.close()\n                return os.path.join(saveFolder, fileName)\n\n            return result\n        else:\n            return self._post(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate or adds the current item s metadata with the specified XML file.", "response": "def updateMetadata(self, metadataFile):\n        \"\"\"\n        updates or adds the current item's metadata\n        metadataFile is the path to the XML file to upload.\n        Output:\n         dictionary\n        \"\"\"\n        ip = ItemParameter()\n        ip.metadata = metadataFile\n        res = self.userItem.updateItem(itemParameters=ip,\n                                       metadata=metadataFile)\n        del ip\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the Item class of an Item", "response": "def item(self):\n        \"\"\"returns the Item class of an Item\"\"\"\n        url = self._contentURL\n        return Item(url=self._contentURL,\n                    securityHandler=self._securityHandler,\n                    proxy_url=self._proxy_url,\n                    proxy_port=self._proxy_port,\n                    initalize=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate an item s properties using the ItemParameter class.", "response": "def updateItem(self,\n                   itemParameters,\n                   clearEmptyFields=False,\n                   data=None,\n                   metadata=None,\n                   text=None,\n                   serviceUrl=None,\n                   multipart=False):\n        \"\"\"\n        updates an item's properties using the ItemParameter class.\n\n        Inputs:\n           itemParameters - property class to update\n           clearEmptyFields - boolean, cleans up empty values\n           data - updates the file property of the service like a .sd file\n           metadata - this is an xml file that contains metadata information\n           text - The text content for the item to be updated.\n           serviceUrl - this is a service url endpoint.\n           multipart - this is a boolean value that means the file will be\n              broken up into smaller pieces and uploaded.\n        \"\"\"\n        thumbnail = None\n        largeThumbnail = None\n        files = {}\n        params = {\n            \"f\": \"json\",\n\n        }\n        if clearEmptyFields:\n            params[\"clearEmptyFields\"] = clearEmptyFields\n        if serviceUrl is not None:\n            params['url'] = serviceUrl\n        if text is not None:\n            params['text'] = text\n        if isinstance(itemParameters, ItemParameter) == False:\n            raise AttributeError(\"itemParameters must be of type parameter.ItemParameter\")\n        keys_to_delete = ['id', 'owner', 'size', 'numComments',\n                          'numRatings', 'avgRating', 'numViews' ,\n                          'overwrite']\n        dictItem = itemParameters.value\n        for key in keys_to_delete:\n            if key in dictItem:\n                del dictItem[key]\n\n        for key in dictItem:\n            if key == \"thumbnail\":\n                files['thumbnail'] = dictItem['thumbnail']\n            elif key == \"largeThumbnail\":\n                files['largeThumbnail'] = dictItem['largeThumbnail']\n            elif key == \"metadata\":\n                metadata = dictItem['metadata']\n                if os.path.basename(metadata) != 'metadata.xml':\n                    tempxmlfile = os.path.join(tempfile.gettempdir(), \"metadata.xml\")\n                    if os.path.isfile(tempxmlfile) == True:\n                        os.remove(tempxmlfile)\n                    import shutil\n                    shutil.copy(metadata, tempxmlfile)\n\n                    metadata = tempxmlfile\n                files['metadata'] = dictItem['metadata']\n            else:\n                params[key] = dictItem[key]\n        if data is not None:\n            files['file'] = data\n        if metadata and os.path.isfile(metadata):\n            files['metadata'] = metadata\n        url = \"%s/update\" % self.root\n        if multipart:\n            itemID = self.id\n            params['multipart'] = True\n            params['fileName'] = os.path.basename(data)\n            res = self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)\n            itemPartJSON = self.addByPart(filePath=data)\n            res = self.commit(wait=True, additionalParams=\\\n                              {'type' : self.type })\n\n        else:\n            res = self._post(url=url,\n                 param_dict=params,\n                 files=files,\n                 securityHandler=self._securityHandler,\n                 proxy_url=self._proxy_url,\n                 proxy_port=self._proxy_port,\n                 force_form_post=True)\n        self.__init()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef status(self, jobId=None, jobType=None):\n        params = {\n            \"f\" : \"json\"\n        }\n        if jobType is not None:\n            params['jobType'] = jobType\n        if jobId is not None:\n            params[\"jobId\"] = jobId\n        url = \"%s/status\" % self.root\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)", "response": "The status of the asynchronous job. This operation returns the status of the asynchronous job."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef commit(self, wait=False, additionalParams={}):\n\n        url = \"%s/commit\" % self.root\n        params = {\n            \"f\" : \"json\",\n        }\n        for key, value in additionalParams.items():\n            params[key] = value\n        if wait == True:\n            res = self._post(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_port=self._proxy_port,\n                                proxy_url=self._proxy_url)\n            res = self.status()\n            import time\n            while res['status'].lower() in [\"partial\", \"processing\"]:\n                time.sleep(2)\n                res = self.status()\n            return res\n        else:\n            return self._post(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)", "response": "This operation commits the current state of the items in the current folder and returns the current state of the items in the current folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a file to the AGOL and Portal.", "response": "def addByPart(self, filePath):\n        \"\"\"\n           Allows for large file uploads to be split into 50 MB chunks and\n           to be sent to AGOL/Portal.  This resolves an issue in Python,\n           where the multi-part POST runs out of memory.\n           To use this function, an addItem() must be run first and that\n           item id must be passed into this function.\n\n           Once the file is uploaded, a commit() must be performed on the\n           data to have all the parts merged together.\n\n           No item properties will be inherited from the initial AddItem()\n           call unless it is an sd file.  Therefore you must call\n           updateItem() on the recently updated item.\n\n           Example:\n              fp = r\"c:\\temp\\big.zip\"\n              #.... AGOL init stuff\n              #....\n              usercontent = agol.content.usercontent(username)\n              res = usercontent.addItem(itemParameters=None,\n                                  filePath=fp,\n                                  overwrite=True,\n                                  multipart=True)\n              res = usercontent.addByPart(filePath=fp)\n              res = usercontent.commit(itemId)\n              usercontent.updateItem(updateItemParameters=ip)\n              # Item added and updated.\n           Inputs:\n              filePath - location of the file on disk\n              itemId - empty item added to AGOL/Portal\n              folder - folder id\n        \"\"\"\n        def read_in_chunks(file_object, chunk_size=10000000):\n            \"\"\"Generate file chunks of 10MB\"\"\"\n            while True:\n                data = file_object.read(chunk_size)\n                if not data:\n                    break\n                yield data\n        params = {\n        \"f\" : \"json\",\n        'itemType' : 'file'\n        }\n        url = '%s/addPart' % self.root\n        messages = []\n        files = {}\n        with open(filePath, 'rb') as f:\n            for part_num, piece in enumerate(read_in_chunks(f), start=1):\n                params['partNum'] = part_num\n                tempFile = os.path.join(os.environ['TEMP'], \"split.part%s\" % part_num)\n                files['file'] =  [tempFile, os.path.basename(filePath)]\n                with open(tempFile, 'wb') as writer:\n                    writer.write(piece)\n                    del writer\n                res = self._post(url=url,\n                                 param_dict=params,\n                                 files=files,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n                if os.path.isfile(tempFile):\n                    os.remove(tempFile)\n                del files\n                del tempFile\n                files = {}\n                messages.append(res)\n        return messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the property data into the class", "response": "def __init(self, folder='/'):\n        \"\"\"loads the property data into the class\"\"\"\n        params = {\n            \"f\" : \"json\"\n        }\n        if folder is None or folder == \"/\":\n            folder = 'root'\n        result_template = {\n            \"username\": \"\",\n            \"total\": 0,\n            \"start\": 1,\n            \"num\": 0,\n            \"nextStart\": 0,\n            \"currentFolder\": None,\n            \"items\": [],\n            \"folders\": []\n        }\n        nextStart = 1\n        self._json_dict = {}\n        self._json = \"\"\n        while nextStart > -1:\n            res = self.search(start=nextStart, num=100)\n            if self._location.find(res['username'].lower()) > -1:\n                self._location = self._location.replace(res['username'].lower(), res['username'])\n                self._url = self._url.replace(res['username'].lower(), res['username'])\n\n            nextStart = int(res['nextStart'])\n            result_template['username'] = res['username']\n            result_template[\"total\"] = res[\"total\"]\n            result_template['nextStart'] = res['nextStart']\n            result_template['start'] = res['start']\n            result_template['num'] = res['num']\n\n            #Added so the root has content to match when in a folder,\n            #not sure if this is best practice or not.  Did not add\n            #username and created\n            #if res['currentFolder'] is None:\n                #result_template['currentFolder'] = {\n                    #'title': 'root',\n                    #'id': None,\n                    #'created' : None,\n                    #'username' : None\n                #}\n                #result_template['folders'].insert(0, result_template['currentFolder'])\n            #else:\n            result_template['currentFolder'] = res['currentFolder']\n            for item in res['items']:\n                if item not in result_template['items']:\n                    result_template['items'].append(item)\n            #if 'folders' in res and \\\n               #folder.lower() == 'root':\n                #for folder in res['folders']:\n                    #if folder not in result_template['folders']:\n                        #result_template['folders'].append(folder)\n\n        self._json_dict = result_template\n        self._json = json.dumps(result_template)\n        attributes = [attr for attr in dir(self)\n                      if not attr.startswith('__') and \\\n                      not attr.startswith('_')]\n        for k,v in result_template.items():\n            if k in attributes:\n                setattr(self, \"_\"+ k, result_template[k])\n            else:\n                print( k, \" - attribute not implemented in Content.User class.\")\n\n        self._loadFolders()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self,\n               start=1,\n               num=10):\n        \"\"\"\n        Returns the items for the current location of the user's content\n        Inputs:\n           start -  The number of the first entry in the result set\n                    response. The index number is 1-based.\n                    The default value of start is 1 (that is, the first\n                    search result).\n                    The start parameter, along with the num parameter, can\n                    be used to paginate the search results.\n           num - The maximum number of results to be included in the result\n                 set response.\n                 The default value is 10, and the maximum allowed value is\n                 100.\n                 The start parameter, along with the num parameter, can be\n                 used to paginate the search results.\n\n           Output:\n             returns a list of dictionary\n        \"\"\"\n        url = self.location\n\n        params = {\n            \"f\" : \"json\",\n            \"num\" : num,\n            \"start\" : start\n        }\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "This method searches the user s content set and returns the items for the current location of the user s content set. The start and num parameters are the number of entries in the result set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef folders(self):\n        '''gets the property value for folders'''\n        if self._folders is None :\n            self.__init()\n        if self._folders is not None and isinstance(self._folders, list):\n            if len(self._folders) == 0:\n                self._loadFolders()\n        return self._folders", "response": "gets the property value for folders"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the current folder ( folder id", "response": "def currentFolder(self, value):\n        \"\"\"gets/sets the current folder (folder id)\"\"\"\n        if value is not None and value.lower() == self._currentFolder['title']:\n            return\n        if value is None:\n            self._location = self.root\n            self._currentFolder = {\n                    'title': 'root',\n                    'id': None,\n                    'created' : None,\n                    'username' : None\n                }\n            self.__init()\n        elif value == \"/\" or value.lower() == 'root':\n            self.location = self.root\n            self._currentFolder = {\n                    'title': 'root',\n                    'id': None,\n                    'created' : None,\n                    'username' : None\n                }\n            self.__init()\n        else:\n            for folder in self.folders:\n                if 'title' in folder:\n                    if folder['title'].lower() == value.lower():\n                        self._location = \"%s/%s\" % (self.root, folder['id'])\n                        self._currentFolder = folder\n                        self.__init(folder['title'])\n                        break"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef items(self):\n        '''gets the property value for items'''\n        self.__init()\n        items = []\n        for item in self._items:\n            items.append(\n                UserItem(url=\"%s/items/%s\" % (self.location, item['id']),\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                        proxy_port=self._proxy_port,\n                        initalize=True)\n            )\n        return items", "response": "gets the property value for items"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a relationship between two items.", "response": "def addRelationship(self,\n                        originItemId,\n                        destinationItemId,\n                        relationshipType):\n        \"\"\"\n        Adds a relationship of a certain type between two items.\n\n        Inputs:\n           originItemId - The item ID of the origin item of the\n                          relationship\n           destinationItemId - The item ID of the destination item of the\n                               relationship.\n           relationshipType - The type of relationship between the two\n                              items. Must be defined in Relationship types.\n        \"\"\"\n        url = \"%s/addRelationship\" % self.root\n        params = {\n            \"originItemId\" : originItemId,\n            \"destinationItemId\": destinationItemId,\n            \"relationshipType\" : relationshipType,\n            \"f\" : \"json\"\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish a hosted service based on an existing source item.", "response": "def publishItem(self,\n                    fileType,\n                    publishParameters=None,\n                    itemId=None,\n                    filePath=None,\n                    text=None,\n                    outputType=None,\n                    buildIntialCache=False,\n                    wait=False,\n                    overwrite=False\n                    ):\n        \"\"\"\n        Publishes a hosted service based on an existing source item.\n        Publishers can create feature services as well as tiled map\n        services.\n        Feature services can be created using input files of type csv,\n        shapefile, serviceDefinition, featureCollection, and\n        fileGeodatabase.\n\n        Inputs:\n           fileType - Item type.\n                      Values: serviceDefinition | shapefile | csv |\n                      tilePackage | featureService | featureCollection |\n                      fileGeodata | geojson | scenePackage\n           publishParameters - object describing the service to be created\n                               as part of the publish operation. Only\n                               required for CSV, Shapefiles, feature\n                               collection, and file geodatabase.\n           itemId - The ID of the item to be published.\n           text - The text in the file to be published. This ONLY applies\n                  to CSV files.\n           filePath - The file to be uploaded.\n           outputType - Only used when a feature service is published as a\n                        tile service.\n           buildIntialCache - default false.  Allows the user to prevent\n                              the creation of the initial cache for tiled\n                              services.\n        \"\"\"\n        _allowed_types = [\"serviceDefinition\", \"shapefile\", \"csv\",\n                          \"tilePackage\", \"featureService\",\n                          \"featureCollection\", \"fileGeodatabase\",\n                          \"geojson\", \"scenePackage\"]\n        if fileType.lower() not in [t.lower() for t in _allowed_types]:\n            raise AttributeError(\"Invalid fileType: %s\" % fileType)\n\n        url = \"%s/publish\" % self.location\n        params = {\n            \"f\" : \"json\",\n            'fileType': fileType\n        }\n\n        if isinstance(buildIntialCache, bool):\n            params['buildInitialCache'] = buildIntialCache\n        if publishParameters is not None and \\\n           isinstance(publishParameters, PublishCSVParameters) == False:\n            params['publishParameters'] = json.dumps(publishParameters.value)\n        elif isinstance(publishParameters, PublishCSVParameters):\n            params['publishParameters'] = json.dumps(publishParameters.value)\n\n        if itemId is not None:\n            params['itemId'] = itemId\n        if text is not None and fileType.lower() == 'csv':\n            params['text'] = text\n        if overwrite != False:\n            params['overwrite'] = overwrite\n        if filePath is not None:\n\n            files = {}\n            files['file'] = filePath\n            res = self._post(url=url,\n                             param_dict=params,\n                             files=files,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)\n        else:\n            res = self._post(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        if 'services' in res:\n            if len(res['services']) > 0:\n                if 'error' in res['services'][0]:\n                    if 'message' in res['services'][0]['error']:\n                        print(res['services'][0]['error']['message'])\n                    else:\n                        print(res['services'][0]['error'])\n                    raise Exception(\"Could not publish item: %s\" % itemId)\n                else:\n                    itemId = res['services'][0]['serviceItemId']\n                    ui = UserItem(url=\"%s/items/%s\" % (self.location, itemId),\n                                    securityHandler=self._securityHandler,\n                                    proxy_url=self._proxy_url,\n                                    proxy_port=self._proxy_port)\n                    if wait == True:\n                        status = \"partial\"\n                        while status != \"completed\":\n                            status = ui.status(jobId=res['services'][0]['jobId'], jobType=\"publish\")\n\n                            if status['status'] == 'failed':\n                                #if 'statusMessage' in status:\n                                    #print( status['statusMessage'])\n                                print (str(status))\n                                raise Exception(\"Could not publish item: %s\" % itemId)\n\n                            elif status['status'].lower() == \"completed\":\n                                break\n                            time.sleep(2)\n                    return ui\n            else:\n                print (res)\n                raise Exception(\"Could not publish item: %s\" % itemId)\n        else:\n            print (res)\n            raise Exception(\"Could not publish item: %s\" % itemId)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexporting a service item (POST only) to the specified output format. Available only to users with an organizational subscription. Invokable only by the service item owner or an administrator. Inputs: title - name of export item itemId - id of the item to export exportFormat - out format. Values: Shapefile, CSV or File Geodatabase, feature collection, GeoJson, or Scene Package tags - comma seperated list of quick descriptors, the default is export. snippet - short explination of the exported item exportParameters - A JSON object describing the layers to be exported and the export parameters for each layer. wait - optional - default false. Export item is an a synchronus operation. If true is specified, the process will wait till the operation is completed. Output: If wait is True: UserItem class else: job id for the export item.", "response": "def exportItem(self,\n                   title,\n                   itemId,\n                   exportFormat,\n                   tags=\"export\",\n                   snippet=None,\n                   exportParameters=None,\n                   wait=True):\n        \"\"\"\n        Exports a service item (POST only) to the specified output format.\n        Available only to users with an organizational subscription.\n        Invokable only by the service item owner or an administrator.\n\n        Inputs:\n           title - name of export item\n           itemId - id of the item to export\n           exportFormat - out format. Values: Shapefile, CSV or File\n                          Geodatabase, feature collection, GeoJson,\n                          or Scene Package\n           tags - comma seperated list of quick descriptors, the default is\n            export.\n           snippet - short explination of the exported item\n           exportParameters - A JSON object describing the layers to be\n                              exported and the export parameters for each\n                              layer.\n           wait - optional - default false. Export item is an a synchronus\n            operation. If true is specified, the process will wait till the\n            operation is completed.\n        Output:\n           If wait is True:\n              UserItem class\n           else:\n              job id for the export item.\n        \"\"\"\n        url = \"%s/export\" % self.location\n        params = {\n            \"f\" : \"json\",\n            \"title\" : title,\n            \"tags\" : tags,\n            \"itemId\" : itemId,\n            \"exportFormat\" : exportFormat,\n        }\n        if snippet is not None:\n            params['snippet'] = snippet\n        if exportParameters is not None:\n            params[\"exportParameters\"] = json.dumps(exportParameters)\n        res = self._post(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)\n        itemURL = \"%s/items/%s\" % (self.location, res['exportItemId'])\n        if self.currentFolder is not None or self.currentFolder['title'] != \"root\":\n            self.moveItems(items=res['exportItemId'], folder=self.currentFolder['id'])\n        ui = UserItem(url=itemURL,\n                      securityHandler=self._securityHandler,\n                      proxy_url=self._proxy_url,\n                      proxy_port=self._proxy_port)\n        if wait == True:\n            status = \"partial\"\n            while status != \"completed\":\n                status = ui.status(jobId=res['jobId'], jobType=\"export\")\n                if status['status'] == 'failed':\n                    raise Exception(\"Could not export item: %s\" % itemId)\n                elif status['status'].lower() == \"completed\":\n                    break\n                time.sleep(2)\n        else:\n            return res['jobId'], ui\n        return ui"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshare a batch of items with the specified list of groups. Users can only share items with groups to which they belong. This operation also allows a user to share items with everyone, in which case the items are publicly accessible, or with everyone in their organization. Inputs: everyone - boolean, makes item public org - boolean, shares with all of the organization items - comma seperated list of items to share groups - comma sperated list of groups to share with", "response": "def shareItems(self, items, groups=\"\", everyone=False,\n                   org=False):\n        \"\"\"\n        Shares a batch of items with the specified list of groups. Users\n        can only share items with groups to which they belong. This\n        operation also allows a user to share items with everyone, in which\n        case the items are publicly accessible, or with everyone in their\n        organization.\n\n        Inputs:\n           everyone - boolean, makes item public\n           org - boolean, shares with all of the organization\n           items - comma seperated list of items to share\n           groups - comma sperated list of groups to share with\n        \"\"\"\n        url = \"%s/shareItems\" % self.root\n        params = {\n            \"f\" : \"json\",\n            \"items\" : items,\n            \"everyone\" : everyone,\n            \"org\" : org,\n            \"groups\" : groups\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a folder in which items can be placed. The name of the folder is used to create the items.", "response": "def createFolder(self, name):\n        \"\"\"\n        Creates a folder in which items can be placed. Folders are only\n        visible to a user and solely used for organizing content within\n        that user's content space.\n        \"\"\"\n        url = \"%s/createFolder\" % self.root\n        params = {\n            \"f\" : \"json\",\n            \"title\" : name\n        }\n        self._folders = None\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addItem(self,\n                itemParameters,\n                filePath=None,\n                overwrite=False,\n                folder=None,\n                dataURL=None,\n                url=None,\n                text=None,\n                relationshipType=None,\n                originItemId=None,\n                destinationItemId=None,\n                serviceProxyParams=None,\n                metadata=None,\n                multipart=False):\n        \"\"\"\n        Adds an item to ArcGIS Online or Portal.\n        Te Add Item operation (POST only) is used to upload an item file,\n        submit text content, or submit the item URL to the specified user\n        folder depending on documented items and item types. This operation\n        is available only to the specified user.\n\n        Inputs:\n           itemParameters - required except for when multipart = True or SD\n                            file. This contains all the information\n                            regarding type, tags, etc...\n           filePath - if updating the item's content\n           overwrite - if the item exists, it overwrites it\n           folder - id of the folder to place the item\n           dataURL - The URL where the item can be downloaded. The resource\n                     will be downloaded and stored as a file type. Similar\n                     to uploading a file to be added, but instead of\n                     transferring the contents of the file, the URL of the\n                     data file is referenced and creates a file item.\n           url - The URL of the item to be submitted. The URL can be a URL\n                 to a service, a web mapping application, or any other\n                 content available at that URL.\n           text - The text content for the item to be submitted.\n           relationshipType - The type of relationship between the two\n                              items. See Relationship types for a complete\n                              listing of types.\n           originItemId - The item ID of the origin item of the\n                          relationship\n           destinationItemId - item ID of the destination item of the\n                               relationship.\n           serviceProxyParams -  JSON object that provides rate limiting\n                                 and referrer checks when accessing secured\n                                 services.\n           metadata - XML meta data file.\n           multipart - If true, the file is uploaded in multiple parts. Used\n                       for files over 100 MBs in size.\n        \"\"\"\n        params = {\n            \"f\" : \"json\"\n        }\n        res = \"\"\n        if itemParameters is not None:\n            for k,v in itemParameters.value.items():\n                if isinstance(v, bool):\n                    params[k] = json.dumps(v)\n                else:\n                    params[k] = v\n        if itemParameters.overwrite is not None:\n            params['overwrite'] = json.dumps(overwrite)\n        if itemParameters.overwrite != overwrite:\n            params['overwrite'] = json.dumps(overwrite)\n        if dataURL is not None:\n            params['dataURL'] = dataURL\n        if url is not None:\n            params['url'] = url\n        if text is not None:\n            params['text'] = text\n        if relationshipType is not None:\n            params['relationshipType'] = relationshipType\n        if originItemId is not None:\n            params['originItemId'] = originItemId\n        if destinationItemId is not None:\n            params['destinationItemId'] = destinationItemId\n        if serviceProxyParams is not None:\n            params['serviceProxyParams'] = serviceProxyParams\n        url = \"%s/addItem\" % self.location\n        files = {}\n        if multipart:\n            res = self._addItemMultiPart(\n                itemParameters=itemParameters,\n                filePath=filePath)\n        else:\n            if filePath is not None and os.path.isfile(filePath):\n                files['file'] = filePath\n                params[\"filename\"] = os.path.basename(filePath)\n            elif filePath is not None and multipart:\n                params[\"filename\"] = os.path.basename(filePath)\n            elif filePath is not None and not os.path.isfile(filePath):\n                print (\"{0} not found\".format(filePath))\n            if 'thumbnail' in params:\n                v = params['thumbnail']\n                del params['thumbnail']\n                files['thumbnail'] = v\n            if metadata is not None and os.path.isfile(metadata):\n                files['metadata'] = metadata\n            if len(files) < 1:\n                res = self._post(url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n            else:\n                params['itemType'] = 'file'\n                params['async'] = False\n                res = self._post(url=url,\n                                 param_dict=params,\n                                 files=files,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        if (isinstance(res, dict) and \\\n           \"id\" not in res):\n            raise Exception(\"Cannot add the item: %s\" % res)\n        elif (isinstance(res, (UserItem, Item)) and \\\n              res.id is None):\n            raise Exception(\"Cannot add the item: %s\" % str(res))\n        elif isinstance(res, (UserItem, Item)):\n            return res\n        else:\n            itemId = res['id']\n            return UserItem(url=\"%s/items/%s\" % (self.location, itemId),\n                            securityHandler=self._securityHandler,\n                        proxy_url=self._proxy_url,\n                        proxy_port=self._proxy_port)", "response": "This function is used to add an item to ArcGIS Online or Portal. It is used to upload a file or a file to ArcGIS Online or Portal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef analyze(self,\n                itemId=None,\n                filePath=None,\n                text=None,\n                fileType=\"csv\",\n                analyzeParameters=None):\n        \"\"\"\n        The Analyze call helps a client analyze a CSV file prior to\n        publishing or generating features using the Publish or Generate\n        operation, respectively.\n        Analyze returns information about the file including the fields\n        present as well as sample records. Analyze attempts to detect the\n        presence of location fields that may be present as either X,Y\n        fields or address fields.\n        Analyze packages its result so that publishParameters within the\n        JSON response contains information that can be passed back to the\n        server in a subsequent call to Publish or Generate. The\n        publishParameters subobject contains properties that describe the\n        resulting layer after publishing, including its fields, the desired\n        renderer, and so on. Analyze will suggest defaults for the renderer.\n        In a typical workflow, the client will present portions of the\n        Analyze results to the user for editing before making the call to\n        Publish or Generate.\n        If the file to be analyzed currently exists in the portal as an\n        item, callers can pass in its itemId. Callers can also directly\n        post the file. In this case, the request must be a multipart post\n        request pursuant to IETF RFC1867. The third option for text files\n        is to pass the text in as the value of the text parameter.\n\n        Inputs:\n           itemid - The ID of the item to be analyzed.\n           file - The file to be analyzed.\n           text - The text in the file to be analyzed.\n           filetype - The type of input file.\n           analyzeParameters - A AnalyzeParameters object that provides\n                               geocoding information\n        \"\"\"\n        files = []\n        url = self._url + \"/analyze\"\n        params = {\n            \"f\" : \"json\"\n\n        }\n        fileType = \"csv\"\n        params[\"fileType\"] = fileType\n        if analyzeParameters is not None and\\\n           isinstance(analyzeParameters, AnalyzeParameters):\n            params['analyzeParameters'] = analyzeParameters.value\n\n        if not (filePath is None) and \\\n           os.path.isfile(filePath):\n            params['text'] = open(filePath, 'rb').read()\n            return self._post(url=url, param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        elif itemId is not None:\n            params[\"fileType\"] = fileType\n            params['itemId'] = itemId\n            return self._post(url=url, param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        else:\n            raise AttributeError(\"either an Item ID or a file path must be given.\")", "response": "Analyze the contents of a CSV file and return the results."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(self,\n                 publishParameters,\n                 itemId=None,\n                 filePath=None,\n                 fileType=None,\n                 option='on'\n                 ):\n        \"\"\"\n        The Generate call helps a client generate features from a CSV file\n        or a shapefile.\n        CSV files that contain location fields (either address fields or X,\n        Y fields) are spatially enabled by the Generate operation.\n        The result of Generate is a JSON feature collection.\n        If the file to be analyzed already exists in the portal as an item,\n        callers can pass in its itemId. Callers can also directly post the\n        file. In this case, the request must be a multipart post request\n        pursuant to IETF RFC1867. The third option for text files is to\n        pass the text in as the value of the text parameter.\n        Generate requires that the caller pass in publish parameters that\n        describe the layers in the feature collection to be generated.\n\n        Inputs:\n           publishParameters - A JSON object describing the layer and\n                               service to be created as part of the Publish\n                               operation. The appropriate value for publish\n                               parameters depends on the file type being\n                               published. (Python Dictionary)\n           itemId - unique id of item to generate\n           filePath - path to zipped shapefile or csv\n           fileType - either shapefile or csv\n        \"\"\"\n        allowedFileTypes = ['shapefile', 'csv']\n        files = {}\n        url = self._url + \"/generate\"\n        params = {\n            \"f\" : \"json\"\n        }\n        params['publishParameters'] = publishParameters\n        params['option'] = option\n\n\n        if fileType.lower() not in allowedFileTypes and \\\n           filePath is not None:\n            raise AttributeError(\"fileType must be either shapefile or csv when specifying a file\")\n        if filePath is not None:\n            params['filetype'] = fileType\n            #Changed from type to filetype to generate a FC from zip\n            if fileType.lower() == \"csv\":\n                params['text'] = open(filePath,'rb').read()\n                return self._post(url=url, param_dict=params,\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port)\n            else:\n                files['file'] = filePath\n                res = self._post(url=url,\n                                 param_dict=params,\n                                 files=files,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n                return res\n        elif itemId is not None:\n            params[\"fileType\"] = fileType\n            params['itemId'] = itemId\n            return self._post(url=url, param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)", "response": "This method generates a new feature collection from a CSV file or shapefile."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __assembleURL(self, url, groupId):\n        from ..packages.six.moves.urllib_parse import urlparse\n        parsed = urlparse(url)\n        communityURL = \"%s://%s%s/sharing/rest/community/groups/%s\" % (parsed.scheme, parsed.netloc,\n                                                                        parsed.path.lower().split('/sharing/rest/')[0],\n                                                                        groupId)\n        return communityURL", "response": "private function that assembles the URL for the community. Group\n        class"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the community. Group class for the current group", "response": "def group(self):\n        \"\"\"returns the community.Group class for the current group\"\"\"\n        split_count = self._url.lower().find(\"/content/\")\n        len_count = len('/content/')\n        gURL = self._url[:self._url.lower().find(\"/content/\")] + \\\n            \"/community/\" + self._url[split_count+ len_count:]#self.__assembleURL(self._contentURL, self._groupId)\n\n        return CommunityGroup(url=gURL,\n                              securityHandler=self._securityHandler,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value(self):\n        return {\n            \"type\" : \"simple\",\n              \"symbol\" :  self.symbol.value,\n              \"label\" : self.label,\n              \"description\" : self.description,\n              \"rotationType\": self.rotationType,\n              \"rotationExpression\": self.rotationExpression\n        }", "response": "returns object as dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a unique value to the renderer", "response": "def addUniqueValue(self, value, label, description, symbol):\n        \"\"\"\n        adds a unique value to the renderer\n        \"\"\"\n        if self._uniqueValueInfos is None:\n            self._uniqueValueInfos = []\n        self._uniqueValueInfos.append(\n            {\n                \"value\" : value,\n                \"label\" : label,\n                \"description\" : description,\n                \"symbol\" : symbol\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef removeUniqueValue(self, value):\n        for v in self._uniqueValueInfos:\n            if v['value'] == value:\n                self._uniqueValueInfos.remove(v)\n                return True\n            del v\n        return False", "response": "removes a unique value from unique Value Info"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value(self):\n        return {\n            \"type\" : \"uniqueValue\",\n            \"field1\" : self._field1,\n            \"field2\" : self._field2,\n            \"field3\" : self._field3,\n            \"fieldDelimiter\" : self._fieldDelimiter,\n            \"defaultSymbol\" :  self._defaultSymbol.value,\n            \"defaultLabel\" : self._defaultLabel,\n            \"uniqueValueInfos\" : self._uniqueValueInfos,\n            \"rotationType\": self._rotationType,\n            \"rotationExpression\": self._rotationExpression\n        }", "response": "returns object as dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a classification break value to the renderer", "response": "def addClassBreak(self, classMinValue, classMaxValue, label, description, symbol):\n        \"\"\"\n        adds a classification break value to the renderer\n        \"\"\"\n        if self._classBreakInfos is None:\n            self._classBreakInfos = []\n        self._classBreakInfos.append(\n            {\n                \"classMinValue\" : classMinValue,\n                \"classMaxValue\" : classMaxValue,\n                \"label\" : label,\n                \"description\" : description,\n                \"symbol\" :  symbol\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a classification break value to the renderer", "response": "def removeClassBreak(self, label):\n        \"\"\"removes a classification break value to the renderer\"\"\"\n        for v in self._classBreakInfos:\n            if v['label'] == label:\n                self._classBreakInfos.remove(v)\n                return True\n            del v\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning object as dictionary", "response": "def value(self):\n        \"\"\"returns object as dictionary\"\"\"\n        return {\n            \"type\" : \"classBreaks\",\n            \"field\" : self._field,\n            \"classificationMethod\" : \"<classification method>\",\n            \"normalizationType\" : self._normalizationType,\n            \"normalizationField\" : self._normalizationField,\n            \"normalizationTotal\" : self._normalizationTotal,\n            \"defaultSymbol\": self._defaultSymbol.value,\n            \"defaultLabel\": self.defaultLabel,\n            \"backgroundFillSymbol\": self._backgroundFillSymbol,\n            \"minValue\" : self._minValue,\n            \"classBreakInfos\" : self.classBreakInfos,\n            \"rotationType\": self._rotationType,\n            \"rotationExpression\": self._rotationExpression\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading the items s thumbnail", "response": "def downloadThumbnail(self, outPath):\n        \"\"\"downloads the items's thumbnail\"\"\"\n        url = self._url + \"/info/thumbnail\"\n        params = {\n\n        }\n        return self._get(url=url,\n                            out_folder=outPath,\n                            file_name=None,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the properties of the object that is used to create the object", "response": "def __init(self):\n        \"\"\" populates all the properties for the map service \"\"\"\n\n        params = {\"f\": \"json\"}\n        json_dict = self._get(self._url, params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        self._json = json.dumps(json_dict)\n        self._json_dict = json_dict\n        attributes = [attr for attr in dir(self)\n                      if not attr.startswith('__') and \\\n                      not attr.startswith('_')]\n        for k,v in json_dict.items():\n            if k == \"tables\":\n                self._tables = []\n                for tbl in v:\n                    url = self._url + \"/%s\" % tbl['id']\n                    self._tables.append(\n                        TableLayer(url,\n                                   securityHandler=self._securityHandler,\n                                   proxy_port=self._proxy_port,\n                                   proxy_url=self._proxy_url)\n                    )\n            elif k == \"layers\":\n                self._layers = []\n                for lyr in v:\n                    url = self._url + \"/%s\" % lyr['id']\n                    layer_type = self._getLayerType(url)\n                    if layer_type == \"Feature Layer\":\n                        self._layers.append(\n                            FeatureLayer(url,\n                                         securityHandler=self._securityHandler,\n                                         proxy_port=self._proxy_port,\n                                         proxy_url=self._proxy_url)\n                        )\n                    elif layer_type == \"Raster Layer\":\n                        self._layers.append(\n                            RasterLayer(url,\n                                        securityHandler=self._securityHandler,\n                                        proxy_port=self._proxy_port,\n                                        proxy_url=self._proxy_url)\n                        )\n                    elif layer_type == \"Group Layer\":\n                        self._layers.append(\n                            GroupLayer(url,\n                                       securityHandler=self._securityHandler,\n                                       proxy_port=self._proxy_port,\n                                       proxy_url=self._proxy_url)\n                        )\n                    elif layer_type == \"Schematics Layer\":\n                        self._layers.append(\n                            SchematicsLayer(url,\n                                            securityHandler=self._securityHandler,\n                                            proxy_port=self._proxy_port,\n                                            proxy_url=self._proxy_url)\n                        )    \n                    else:\n                        print ('Type %s is not implemented' % layer_type)\n            elif k in attributes:\n                setattr(self, \"_\"+ k, json_dict[k])\n\n            else:\n                print (k, \" is not implemented for mapservice.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the security handler", "response": "def securityHandler(self, value):\n        \"\"\" sets the security handler \"\"\"\n        if isinstance(value, BaseSecurityHandler):\n            if isinstance(value, security.AGSTokenSecurityHandler):\n                self._securityHandler = value\n            else:\n                pass\n        elif value is None:\n            self._securityHandler = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getExtensions(self):\n        extensions = []\n        if isinstance(self.supportedExtensions, list):\n            for ext in self.supportedExtensions:\n                extensionURL = self._url + \"/exts/%s\" % ext\n                if ext == \"SchematicsServer\":\n                    extensions.append(SchematicsService(url=extensionURL,\n                                                        securityHandler=self._securityHandler,\n                                                        proxy_url=self._proxy_url,\n                                                        proxy_port=self._proxy_port))\n            return extensions\n        else:\n            extensionURL = self._url + \"/exts/%s\" % self.supportedExtensions\n            if self.supportedExtensions == \"SchematicsServer\":\n                extensions.append(SchematicsService(url=extensionURL,\n                                                    securityHandler=self._securityHandler,\n                                                    proxy_url=self._proxy_url,\n                                                    proxy_port=self._proxy_port))\n            return extensions", "response": "returns objects for all map service extensions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef allLayers(self):\n        url = self._url + \"/layers\"\n        params = {\n            \"f\" : \"json\"\n        }\n        res = self._get(url, param_dict=params,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        return_dict = {\n            \"layers\" : [],\n            \"tables\" : []\n        }\n        for k, v in res.items():\n            if k == \"layers\":\n                for val in v:\n                    return_dict['layers'].append(\n                        FeatureLayer(url=self._url + \"/%s\" % val['id'],\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port)\n                    )\n            elif k == \"tables\":\n                for val in v:\n                    return_dict['tables'].append(\n                        TableLayer(url=self._url + \"/%s\" % val['id'],\n                                   securityHandler=self._securityHandler,\n                                   proxy_url=self._proxy_url,\n                                   proxy_port=self._proxy_port)\n                    )\n            del k,v\n        return return_dict", "response": "returns all layers for the service"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform the map service find operation", "response": "def find(self, searchText, layers,\n             contains=True, searchFields=\"\",\n             sr=\"\", layerDefs=\"\",\n             returnGeometry=True, maxAllowableOffset=\"\",\n             geometryPrecision=\"\", dynamicLayers=\"\",\n             returnZ=False, returnM=False, gdbVersion=\"\"):\n        \"\"\" performs the map service find operation \"\"\"\n        url = self._url + \"/find\"\n        #print url\n        params = {\n            \"f\" : \"json\",\n            \"searchText\" : searchText,\n            \"contains\" : self._convert_boolean(contains),\n            \"searchFields\": searchFields,\n            \"sr\" : sr,\n            \"layerDefs\" : layerDefs,\n            \"returnGeometry\" : self._convert_boolean(returnGeometry),\n            \"maxAllowableOffset\" : maxAllowableOffset,\n            \"geometryPrecision\" : geometryPrecision,\n            \"dynamicLayers\" : dynamicLayers,\n            \"returnZ\" : self._convert_boolean(returnZ),\n            \"returnM\" : self._convert_boolean(returnM),\n            \"gdbVersion\" : gdbVersion,\n            \"layers\" : layers\n        }\n        res = self._get(url, params,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        qResults = []\n        for r in res['results']:\n            qResults.append(Feature(r))\n        return qResults"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getFeatureDynamicLayer(self, oid, dynamicLayer,\n                               returnZ=False, returnM=False):\n        \"\"\" The feature resource represents a single feature in a dynamic\n            layer in a map service\n        \"\"\"\n        url = self._url + \"/dynamicLayer/%s\" % oid\n        params = {\n            \"f\": \"json\",\n            \"returnZ\": returnZ,\n            \"returnM\" : returnM,\n            \"layer\": {\n                \"id\": 101,\n                \"source\" : dynamicLayer.asDictionary\n            }\n        }\n        return Feature(\n            json_string=self._get(url=url,\n                                     param_dict=params,\n                                     securityHandler=self._securityHandler,\n                                     proxy_port=self._proxy_port,\n                                     proxy_url=self._proxy_url)\n        )", "response": "The feature resource represents a single feature in a dynamic feature in a map service. The feature resource represents a single feature in a dynamic feature in a map service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exportMap(self,\n                  bbox,\n                  size=\"600,550\",\n                  dpi=200,\n                  imageSR=None,\n                  image_format=\"png\",\n                  layerDefFilter=None,\n                  layers=None,\n                  transparent=False,\n                  timeFilter=None,\n                  layerTimeOptions=None,\n                  dynamicLayers=None,\n                  mapScale=None\n                  ):\n        \"\"\"\n           The export operation is performed on a map service resource.\n           The result of this operation is a map image resource. This\n           resource provides information about the exported map image such\n           as its URL, its width and height, extent and scale.\n           Inputs:\n            bbox - envelope geometry object\n            size - size of image in pixels\n            dpi - dots per inch\n            imageSR - spatial reference of the output image\n            image_format - Description: The format of the exported image.\n                             The default format is .png.\n                             Values: png | png8 | png24 | jpg | pdf | bmp | gif\n                                     | svg | svgz | emf | ps | png32\n            layerDefFilter - Description: Allows you to filter the\n                             features of individual layers in the exported\n                             map by specifying definition expressions for\n                             those layers. Definition expression for a\n                             layer that is published with the service will\n                             be always honored.\n            layers - Determines which layers appear on the exported map.\n                     There are four ways to specify which layers are shown:\n                        show: Only the layers specified in this list will\n                              be exported.\n                        hide: All layers except those specified in this\n                              list will be exported.\n                        include: In addition to the layers exported by\n                                 default, the layers specified in this list\n                                 will be exported.\n                        exclude: The layers exported by default excluding\n                                 those specified in this list will be\n                                 exported.\n            transparent - If true, the image will be exported with the\n                          background color of the map set as its\n                          transparent color. The default is false. Only\n                          the .png and .gif formats support transparency.\n                          Internet Explorer 6 does not display transparency\n                          correctly for png24 image formats.\n            timeFilter - The time instant or time extent of the exported\n                         map image.\n            layerTimeOptions - The time options per layer. Users can\n                               indicate whether or not the layer should use\n                               the time extent specified by the time\n                               parameter or not, whether to draw the layer\n                               features cumulatively or not and the time\n                               offsets for the layer.\n                               see: http://resources.arcgis.com/en/help/arcgis-rest-api/index.html#/Export_Map/02r3000000v7000000/\n            dynamicLayers - Use dynamicLayers parameter to modify the layer\n                            drawing order, change layer drawing info, and\n                            change layer data source version for this request.\n                            New layers (dataLayer) can also be added to the\n                            dynamicLayers based on the map service registered\n                            workspaces.\n            mapScale - Use this parameter to export a map image at a specific\n                       scale, with the map centered around the center of the\n                       specified bounding box (bbox).\n\n        \"\"\"\n        params = {\n            \"f\" : \"json\"\n        }\n\n        if isinstance(bbox, Envelope):\n            vals = bbox.asDictionary\n            params['bbox'] = \"%s,%s,%s,%s\" % (vals['xmin'], vals['ymin'],\n                                              vals['xmax'], vals['ymax'])\n            params['bboxSR'] = vals['spatialReference']\n            if dpi is not None:\n                params['dpi'] = dpi\n            if size is not None:\n                params['size'] = size\n            if imageSR is not None and \\\n               isinstance(imageSR, SpatialReference):\n                params['imageSR'] = {'wkid': imageSR.wkid}\n            if image_format is not None:\n                params['format'] = image_format\n            if layerDefFilter is not None and \\\n               isinstance(layerDefFilter,\n                          filters.LayerDefinitionFilter):\n                params['layerDefs'] = layerDefFilter.filter\n            if layers is not None:\n                params['layers'] = layers\n            if transparent is not None:\n                params['transparent'] = transparent\n            if timeFilter is not None and \\\n               isinstance(timeFilter, filters.TimeFilter):\n                params['time'] = timeFilter.filter\n            if layerTimeOptions is not None:\n                params['layerTimeOptions'] = layerTimeOptions\n            if dynamicLayers is not None and \\\n               isinstance(dynamicLayers, DynamicData):\n                params['dynamicLayers'] = dynamicLayers.asDictionary\n            if mapScale is not None:\n                params['mapScale'] = mapScale\n            exportURL = self._url + \"/export\"\n            return self._get(url=exportURL,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)\n        else:\n            return None", "response": "This function returns the name of the exported map image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef estimateExportTilesSize(self,\n                                exportBy,\n                                levels,\n                                tilePackage=False,\n                                exportExtent=\"DEFAULTEXTENT\",\n                                areaOfInterest=None,\n                                async=True):\n        \"\"\"\n        The estimateExportTilesSize operation is an asynchronous task that\n        allows estimation of the size of the tile package or the cache data\n        set that you download using the Export Tiles operation. This\n        operation can also be used to estimate the tile count in a tile\n        package and determine if it will exceced the maxExportTileCount\n        limit set by the administrator of the service. The result of this\n        operation is Map Service Job. This job response contains reference\n        to Map Service Result resource that returns the total size of the\n        cache to be exported (in bytes) and the number of tiles that will\n        be exported.\n\n        Inputs:\n\n        tilePackage - Allows estimating the size for either a tile package\n         or a cache raster data set. Specify the value true for tile\n         packages format and false for Cache Raster data set. The default\n         value is False\n           Values: True | False\n        exportExtent - The extent (bounding box) of the tile package or the\n         cache dataset to be exported. If extent does not include a spatial\n         reference, the extent values are assumed to be in the spatial\n         reference of the map. The default value is full extent of the\n         tiled map service.\n\t   Syntax: <xmin>, <ymin>, <xmax>, <ymax>\n           Example 1: -104,35.6,-94.32,41\n        exportBy - The criteria that will be used to select the tile\n         service levels to export. The values can be Level IDs, cache scales\n         or the Resolution (in the case of image services).\n\t   Values: LevelID | Resolution | Scale\n        levels - Specify the tiled service levels for which you want to get\n         the estimates. The values should correspond to Level IDs, cache\n         scales or the Resolution as specified in exportBy parameter. The\n         values can be comma separated values or a range.\n\t   Example 1: 1,2,3,4,5,6,7,8,9\n\t   Example 2: 1-4,7-9\n        areaOfInterest - (Optional) The areaOfInterest polygon allows\n         exporting tiles within the specified polygon areas. This parameter\n         supersedes exportExtent parameter. Also excepts geometry.Polygon.\n\t   Example: { \"features\": [{\"geometry\":{\"rings\":[[[-100,35],\n             [-100,45],[-90,45],[-90,35],[-100,35]]],\n             \"spatialReference\":{\"wkid\":4326}}}]}\n        async - (optional) the estimate function is run asynchronously\n         requiring the tool status to be checked manually to force it to\n         run synchronously the tool will check the status until the\n         estimation completes.  The default is True, which means the status\n         of the job and results need to be checked manually.  If the value\n         is set to False, the function will wait until the task completes.\n           Values: True | False\n        \"\"\"\n        url = self._url + \"/estimateExportTilesSize\"\n        params = {\n            \"f\" : \"json\",\n            \"levels\" : levels,\n            \"exportBy\" : exportBy,\n            \"tilePackage\" : tilePackage,\n            \"exportExtent\" : exportExtent\n        }\n        params[\"levels\"] = levels\n        if not areaOfInterest is None:\n            if isinstance(areaOfInterest, Polygon):\n                template = { \"features\": [areaOfInterest.asDictionary]}\n                params['areaOfInterest'] = template\n            else:\n                params['areaOfInterest'] = areaOfInterest\n        if async == True:\n            return self._get(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)\n        else:\n            exportJob = self._get(url=url,\n                                     param_dict=params,\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port)\n            jobUrl = \"%s/jobs/%s\" % (url, exportJob['jobId'])\n            gpJob = GPJob(url=jobUrl,\n                          securityHandler=self._securityHandler,\n                          proxy_port=self._proxy_port,\n                          proxy_url=self._proxy_url)\n            status = gpJob.jobStatus\n            while status != \"esriJobSucceeded\":\n                if status in ['esriJobFailed',\n                              'esriJobCancelling',\n                              'esriJobCancelled']:\n                    return gpJob.messages\n                else:\n                    time.sleep(5)\n                    status = gpJob.jobStatus\n            return gpJob.results", "response": "This method is used to estimate the size of the tiles that will be exported for a specific tile package or a specific extent of a specific tile package or a specific extent of a specific tile dataset. This method is asynchronous and will be executed in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exportTiles(self,\n                    levels,\n                    exportBy=\"LevelID\",\n                    tilePackage=False,\n                    exportExtent=\"DEFAULT\",\n                    optimizeTilesForSize=True,\n                    compressionQuality=0,\n                    areaOfInterest=None,\n                    async=False\n                    ):\n        \"\"\"\n        The exportTiles operation is performed as an asynchronous task and\n        allows client applications to download map tiles from a server for\n        offline use. This operation is performed on a Map Service that\n        allows clients to export cache tiles. The result of this operation\n        is Map Service Job. This job response contains a reference to the\n        Map Service Result resource, which returns a URL to the resulting\n        tile package (.tpk) or a cache raster dataset.\n        exportTiles can be enabled in a service by using ArcGIS for Desktop\n        or the ArcGIS Server Administrator Directory. In ArcGIS for Desktop\n        make an admin or publisher connection to the server, go to service\n        properties, and enable Allow Clients to Export Cache Tiles in the\n        advanced caching page of the Service Editor. You can also specify\n        the maximum tiles clients will be allowed to download. The default\n        maximum allowed tile count is 100,000. To enable this capability\n        using the Administrator Directory, edit the service, and set the\n        properties exportTilesAllowed=true and maxExportTilesCount=100000.\n\n        At 10.2.2 and later versions, exportTiles is supported as an\n        operation of the Map Server. The use of the\n        http://Map Service/exportTiles/submitJob operation is deprecated.\n        You can provide arguments to the exportTiles operation as defined\n        in the following parameters table:\n\n        Inputs:\n         exportBy - The criteria that will be used to select the tile\n           service levels to export. The values can be Level IDs, cache\n           scales. or the resolution (in the case of image services).\n\t   Values: LevelID | Resolution | Scale\n        levels - Specifies the tiled service levels to export. The values\n          should correspond to Level IDs, cache scales. or the resolution\n          as specified in exportBy parameter. The values can be comma\n          separated values or a range. Make sure tiles are present at the\n          levels where you attempt to export tiles.\n\t   Example 1: 1,2,3,4,5,6,7,8,9\n\t   Example 2: 1-4,7-9\n        tilePackage - Allows exporting either a tile package or a cache\n          raster data set. If the value is true, output will be in tile\n          package format, and if the value is false, a cache raster data\n          set is returned. The default value is false\n\t   Values: true | false\n        exportExtent - The extent (bounding box) of the tile package or the\n          cache dataset to be exported. If extent does not include a\n          spatial reference, the extent values are assumed to be in the\n          spatial reference of the map. The default value is full extent of\n          the tiled map service.\n                       Syntax: <xmin>, <ymin>, <xmax>, <ymax>\n                       Example 1: -104,35.6,-94.32,41\n                       Example 2: {\"xmin\" : -109.55, \"ymin\" : 25.76,\n                        \"xmax\" : -86.39, \"ymax\" : 49.94,\n                        \"spatialReference\" : {\"wkid\" : 4326}}\n        optimizeTilesForSize - (Optional) Use this parameter to enable\n          compression of JPEG tiles and reduce the size of the downloaded\n          tile package or the cache raster data set. Compressing tiles\n          slightly compromises the quality of tiles but helps reduce the\n          size of the download. Try sample compressions to determine the\n          optimal compression before using this feature.\n\t   Values: true | false\n        compressionQuality - (Optional) When optimizeTilesForSize=true, you\n         can specify a compression factor. The value must be between 0 and\n         100. The value cannot be greater than the default compression\n         already set on the original tile. For example, if the default\n         value is 75, the value of compressionQuality must be between 0 and\n         75. A value greater than 75 in this example will attempt to up\n         sample an already compressed tile and will further degrade the\n         quality of tiles.\n        areaOfInterest - (Optional) The areaOfInterest polygon allows\n         exporting tiles within the specified polygon areas. This parameter\n         supersedes the exportExtent parameter. Must be geometry.Polygon\n         object.\n        Example: { \"features\": [{\"geometry\":{\"rings\":[[[-100,35],\n         [-100,45],[-90,45],[-90,35],[-100,35]]],\n         \"spatialReference\":{\"wkid\":4326}}}]}\n        async - default True, this value ensures the returns are returned\n         to the user instead of the user having the check the job status\n         manually.\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"tilePackage\" : tilePackage,\n            \"exportExtent\" : exportExtent,\n            \"optimizeTilesForSize\" : optimizeTilesForSize,\n            \"compressionQuality\" : compressionQuality,\n            \"exportBy\" : exportBy,\n            \"levels\" : levels\n        }\n        url = self._url + \"/exportTiles\"\n        if isinstance(areaOfInterest, Polygon):\n            geom = areaOfInterest.asDictionary()\n            template = { \"features\": [geom]}\n            params[\"areaOfInterest\"] = template\n        if async == True:\n            return self._get(url=url, param_dict=params,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)\n        else:\n            exportJob = self._get(url=url, param_dict=params,\n                                     securityHandler=self._securityHandler,\n                                     proxy_url=self._proxy_url,\n                                     proxy_port=self._proxy_port)\n            jobUrl = \"%s/jobs/%s\" % (url, exportJob['jobId'])\n            gpJob = GPJob(url=jobUrl,\n                          securityHandler=self._securityHandler,\n                          proxy_port=self._proxy_port,\n                          proxy_url=self._proxy_url)\n            status = gpJob.jobStatus\n            while status != \"esriJobSucceeded\":\n                if status in ['esriJobFailed',\n                                       'esriJobCancelling',\n                                       'esriJobCancelled']:\n                    return None\n                else:\n                    time.sleep(5)\n                    status = gpJob.jobStatus\n            allResults = gpJob.results\n            for k,v in allResults.items():\n                if k == \"out_service_url\":\n                    value = v['value']\n                    params = {\n                        \"f\" : \"json\"\n                    }\n                    gpRes = self._get(url=v['value'],\n                                         param_dict=params,\n                                         securityHandler=self._securityHandler,\n                                         proxy_url=self._proxy_url,\n                                         proxy_port=self._proxy_port)\n                    if tilePackage == True:\n                        files = []\n                        for f in gpRes['files']:\n                            name = f['name']\n                            dlURL = f['url']\n                            files.append(\n                                self._get(url=dlURL,\n                                          out_folder=tempfile.gettempdir(),\n                                          file_name=name,\n                                          param_dict=params,\n                                          securityHandler=self._securityHandler,\n                                          proxy_url=self._proxy_url,\n                                          proxy_port=self._proxy_port))\n                        return files\n                    else:\n                        return gpRes['folders']\n                else:\n                    return None", "response": "This operation is performed on a service that returns a URL to the tile package or a raster dataset for the requested tile count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the object from json string or dictionary", "response": "def fromJSON(value):\n        \"\"\"returns the object from json string or dictionary\"\"\"\n        if isinstance(value, str):\n            value = json.loads(value)\n        elif isinstance(value, dict): pass\n        else:\n            raise AttributeError(\"Invalid input\")\n        return Extension(typeName=value['typeName'],\n                         capabilities=value['capabilities'],\n                         enabled=value['enabled'] == \"true\",\n                         maxUploadFileSize=value['maxUploadFileSize'],\n                         allowedUploadFileType=value['allowedUploadFileTypes'],\n                         properties=value['properties'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef asList(self):\n        return [self._red, self._green, self._blue, self._alpha]", "response": "returns the value as the list object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the object as a dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the object as a dictionary \"\"\"\n        template = {\n            \"type\" : \"esriSMS\",\n            \"style\" : self._style,\n            \"color\" : self._color,\n            \"size\" : self._size,\n            \"angle\" : self._angle,\n            \"xoffset\" : self._xoffset,\n            \"yoffset\" : self._yoffset\n        }\n        if self._outlineColor is not None and \\\n           self._outlineWidth is not None:\n            template[\"outline\"] = {\n                \"color\" : self._outlineColor,\n                \"width\" : self._outlineWidth\n            }\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef outlineColor(self, value):\n        if isinstance(value, (list, Color)):\n            if value is list:\n                self._outlineColor = value\n            else:\n                self._outlineColor = value.asList", "response": "sets the outline color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning object as dictionary", "response": "def asDictionary(self):\n        \"\"\" returns object as dictionary \"\"\"\n        template = {\n            \"type\" : \"esriSFS\",\n            \"style\" : self._style,\n            \"color\" : self._color,\n            \"outline\" : self._outline\n        }\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a base64 string to a file", "response": "def base64ToImage(imgData, out_path, out_file):\n        \"\"\" converts a base64 string to a file \"\"\"\n        fh = open(os.path.join(out_path, out_file), \"wb\")\n        fh.write(imgData.decode('base64'))\n        fh.close()\n        del fh\n        return os.path.join(out_path, out_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the object as a dictionary", "response": "def asDictionary(self):\n        \"\"\" returns the object as a dictionary \"\"\"\n        template = {\n            \"type\" : \"esriPMS\",\n            \"url\" : self._url,\n            \"imageData\" : self._imageDate,\n            \"contentType\" : self._contentType,\n            \"width\" : self._width,\n            \"height\" : self._height,\n            \"angle\" : self._angle,\n            \"xoffset\" : self._xoffset,\n            \"yoffset\" : self._yoffset\n        }\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef asDictionary(self):\n        template = {\n            \"type\" : \"esriPMS\",\n            \"url\" : self._url,\n            \"imageData\" : self._imageDate,\n            \"contentType\" : self._contentType,\n            \"width\" : self._width,\n            \"height\" : self._height,\n            \"angle\" : self._angle,\n            \"xoffset\" : self._xoffset,\n            \"yoffset\" : self._yoffset,\n            \"xscale\" : self._xscale,\n            \"yscale\" : self._yscale,\n            \"outline\" : self._outline\n        }\n        return template", "response": "returns the object as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findAddressCandidates(self,\n                              addressDict=None,\n                              singleLine=None,\n                              maxLocations=10,\n                              outFields=\"*\",\n                              outSR=4326,\n                              searchExtent=None,\n                              location=None,\n                              distance=2000,\n                              magicKey=None,\n                              category=None):\n        \"\"\"\n        The findAddressCandidates operation is performed on a geocode\n        service resource. The result of this operation is a resource\n        representing the list of address candidates. This resource provides\n        information about candidates, including the address, location, and\n        match score. Locators published using ArcGIS Server 10 or later\n        support the single line address field for the findAddressCandidates\n        operation.\n        You can provide arguments to the findAddressCandidates operation as\n        query parameters defined in the following parameters table:\n\n        Inputs:\n            addressDict - The various address fields accepted by the\n             corresponding geocode service. These fields are listed in the\n             addressFields property of the JSON representation associated\n             geocode service resource.\n             Example: Suppose that addressFields of a geocode service\n             resource includes fields with the following names: Street,\n             City, State, and Zone. If you want to perform the\n             findAddressCandidates operation by providing values for the\n             Street and Zone fields, you'd set the query parameters as\n             Street=380+New+York+St&Zone=92373\n\n            singleLine - Specifies the location to be geocoded. The input\n             address components are formatted as a single string. The\n             singleLine parameter and <addressField> parameters should not\n             be passed in the same request.\n            maxLocations - The maximum number of locations to be returned\n             by a search, up to the maximum number allowed by the geocode\n             service. If not specified, the maximum number of candidates\n             for which the service is configured will be returned.\n            outFields - The list of fields to be included in the returned\n             result set. This list is a comma-delimited list of field\n             names. If you specify the shape field in the list of return\n             fields, it is ignored. For non-intersection addresses, you can\n             specify the candidate fields from the geocode service\n             resource. For intersection addresses, you can specify the\n             intersection candidate fields from the geocode service\n             resource.\n            outSR - The well-known ID (WKID) of the spatial reference or a\n             spatial reference JSON object for the returned address\n             candidates. For a list of valid WKID values, see Projected\n             coordinate systems and Geographic coordinate systems.\n            searchExtent - The spatial extent (bounding box) to be used in\n             geocoding. The response will return only the candidates that\n             are within this spatial extent. Unless the spatialReference is\n             included in the searchExtent, the coordinates are assumed to\n             be in the spatial reference of the locator.\n             Simple syntax: <xmin>, <ymin>, <xmax>, <ymax>\n            location - Defines an origin point location that is used with\n             the distance parameter to sort geocoding candidates based on\n             their proximity to the location. The distance parameter\n             specifies the radial distance from the location in meters. The\n             priority of candidates within this radius is boosted relative\n             to those outside the radius. This is useful in mobile\n             applications where a user searches for places in the vicinity\n             of their current GPS location; the location and distance\n             parameters can be used in this scenario. The location\n             parameter can be specified without specifying a distance. If\n             distance is not specified, it defaults to 2000 meters. The\n             location can be represented with a simple comma-separated\n             syntax (x,y), or as a JSON point object. If the spatial\n             reference of the location coordinates is different than that\n             of the geocode service, then it must be defined in the JSON\n             object. If the comma-separated syntax is used, or if the\n             spatial reference is not included in the JSON object, then the\n             spatial reference of the location is assumed to be the same as\n             that of the geocode service. This parameter was added at 10.3\n             and is only supported by geocode services published with\n             ArcGIS 10.3 for Server and later versions.\n            distance - Specifies the radius of an area around a point\n             location that is used to boost the rank of geocoding\n             candidates so that candidates closest to the location are\n             returned first. The distance value is in meters. If the\n             distance parameter is specified, the location parameter must\n             be specified as well. Unlike the searchExtent parameter, the\n             location and distance parameters allow searches to extend\n             beyond the specified search radius. They are not used to\n             filter results, but rather to rank resulting candidates based\n             on their distance from a location. You must pass a\n             searchExtent value in addition to location and distance if you\n             want to confine the search results to a specific area.\n            magicKey - The findAddressCandidates operation retrieves\n             results more quickly when you pass in valid singleLine and\n             magicKey values than when you don't pass in magicKey. However,\n             to get this advantage, you need to make a prior request to the\n             suggest operation, which provides a magicKey. This may or may\n             not be relevant to your workflow.\n             The suggest operation is often called on to improve the user\n             experience of search boxes by analyzing partial text and\n             providing complete names of places, addresses, points of\n             interest, and so on. For instance, typing Mbu into a search\n             box offers Mbuji-Mayi, Democratic Republic of the Congo as a\n             suggestion, so the user doesn't need to type the complete\n             name.\n             Looking at the suggestion process from another perspective, as\n             the user types, the suggest operation performs a text search,\n             which is a redundant part of the overall search that the\n             findAddressCandidates operation can also perform. The user\n             chooses a place name or type-narrowing the results to a\n             specific record. The results from suggest include text and\n             magicKey values that contain the information the user chose;\n             passing these values from suggest into findAddressCandidates\n             results in faster and more accurate find operations.\n             In summary, using the magicKey parameter in\n             findAddressCandidates is a two-step process:\n              1. Make a request to suggest. The response includes text and\n                 magicKey properties.\n              2. Make a request to findAddressCandidates and pass in the\n                 text and magicKey values returned from suggest as the\n                 singleLine and magicKey input parameters respectively.\n            category - The category parameter is only supported by geocode\n             services published using StreetMap Premium locators.\n        \"\"\"\n        url = self._url + \"/findAddressCandidates\"\n        params = {\n            \"f\" : \"json\",\n            \"distance\" : distance\n        }\n        if addressDict is None and \\\n           singleLine is None:\n            raise Exception(\"A singleline address or an address dictionary must be passed into this function\")\n        if not magicKey is None:\n            params['magicKey'] = magicKey\n        if not category is None:\n            params['category'] = category\n        if not addressDict is None:\n            params = params.update(addressDict)\n        if not singleLine is None:\n            params['SingleLine'] = singleLine\n        if not maxLocations is None:\n            params['maxLocations'] = maxLocations\n        if not outFields is None:\n            params['outFields'] = outFields\n        if not outSR is None:\n            params['outSR'] = {\"wkid\": outSR}\n        if not searchExtent is None:\n            params['searchExtent'] = searchExtent\n        if isinstance(location, Point):\n            params['location'] = location.asDictionary\n        elif isinstance(location, list):\n            params['location'] = \"%s,%s\" % (location[0], location[1])\n        return self._get(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This method returns a resource that contains a list of address candidates that are available for the given geocoded service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef geocodeAddresses(self,\n                         addresses,\n                         outSR=4326,\n                         sourceCountry=None,\n                         category=None):\n        \"\"\"\n        The geocodeAddresses operation is performed on a Geocode Service\n        resource. The result of this operation is a resource representing\n        the list of geocoded addresses. This resource provides information\n        about the addresses including the address, location, score, and\n        other geocode service-specific attributes.You can provide arguments\n        to the geocodeAddresses operation as query parameters defined in\n        the following parameters table.\n\n        Inputs:\n           addresses - A record set representing the addresses to be\n            geocoded. Each record must include an OBJECTID attribute with a\n            unique value, as well as various address fields accepted by the\n            corresponding geocode service. The field names that should be\n            used can be found in the JSON representation of the geocode\n            service resource under the addressFields property, for multiple\n            input field geocoding, or the singleLineAddressField property,\n            for single input field geocoding. The OBJECTID specified in the\n            request is reflected as ResultID in the response.\n            The maximum number of addresses that can be geocoded in a\n            single request is limited to the SuggestedBatchSize property of\n            the locator.\n            Syntax:\n             {\n                \"records\"  : [\n                {\n                   \"attributes\" : {\"<OBJECTID>\" : \"<OID11>\",\n                                   \"<field1>\" : \"<value11>\",\n                                   \"<field2>\" : \"<value12>\",\n                                   \"<field3>\" : \"<value13>\"\n                                   }\n                },\n                {\n                   \"attributes\" : {\"<OBJECTID>\" : \"<OID12>\",\n                                   \"<field1>\" : \"<value11>\",\n                                   \"<field2>\" : \"<value12>\",\n                                   \"<field3>\" : \"<value13>\"\n                                   }\n                }\n                ]\n             }\n           outSR - The well-known ID of the spatial reference, or a spatial\n            reference json object for the returned addresses. For a list of\n            valid WKID values, see Projected coordinate systems and\n            Geographic coordinate systems.\n           sourceCountry - The sourceCountry parameter is only supported by\n            geocode services published using StreetMap Premium locators.\n            Added at 10.3 and only supported by geocode services published\n            with ArcGIS 10.3 for Server and later versions.\n           category - The category parameter is only supported by geocode\n            services published using StreetMap Premium locators.\n        \"\"\"\n        params = {\n            \"f\" : \"json\"\n        }\n        url = self._url + \"/geocodeAddresses\"\n        params['outSR'] = outSR\n        params['sourceCountry'] = sourceCountry\n        params['category'] = category\n        params['addresses'] = addresses\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This method returns a resource representing the list of addresses that can be geocoded by the geocoded service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverseGeocode(self, location):\n        params = {\n            \"f\" : \"json\"\n        }\n        url = self._url + \"/reverseGeocode\"\n        if isinstance(location, Point):\n            params['location'] = location.asDictionary\n        elif isinstance(location, list):\n            params['location'] = \"%s,%s\" % (location[0], location[1])\n        else:\n            raise Exception(\"Invalid location\")\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation returns the address that is closest to the given location. The location parameter can be either a Point object or a list of points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef suggest(self,\n                text,\n                location,\n                distance=2000,\n                category=None\n                ):\n        \"\"\"\n        The suggest operation is performed on a geocode service resource.\n        The result of this operation is a resource representing a list of\n        suggested matches for the input text. This resource provides the\n        matching text as well as a unique ID value, which links a\n        suggestion to a specific place or address.\n        A geocode service must meet the following requirements to support\n        the suggest operation:\n          The address locator from which the geocode service was published\n          must support suggestions. Only address locators created using\n          ArcGIS 10.3 for Desktop and later can support suggestions. See\n          the Create Address Locator geoprocessing tool help topic for more\n          information.\n          The geocode service must have the Suggest capability enabled.\n          Only geocode services published using ArcGIS 10.3 for Server or\n          later support the Suggest capability.\n        The suggest operation allows character-by-character auto-complete\n        suggestions to be generated for user input in a client application.\n        This capability facilitates the interactive search user experience\n        by reducing the number of characters that need to be typed before\n        a suggested match is obtained. A client application can provide a\n        list of suggestions that is updated with each character typed by a\n        user until the address they are looking for appears in the list.\n\n        Inputs:\n           text - The input text provided by a user that is used by the\n            suggest operation to generate a list of possible matches. This\n            is a required parameter.\n           location -  Defines an origin point location that is used with\n            the distance parameter to sort suggested candidates based on\n            their proximity to the location. The distance parameter\n            specifies the radial distance from the location in meters. The\n            priority of candidates within this radius is boosted relative\n            to those outside the radius.\n            This is useful in mobile applications where a user wants to\n            search for places in the vicinity of their current GPS\n            location. It is also useful for web mapping applications where\n            a user wants to find places within or near the map extent.\n            The location parameter can be specified without specifying a\n            distance. If distance is not specified, it defaults to 2000\n            meters.\n            The object can be an common.geometry.Point or X/Y list object\n           distance - Specifies the radius around the point defined in the\n            location parameter to create an area, which is used to boost\n            the rank of suggested candidates so that candidates closest to\n            the location are returned first. The distance value is in\n            meters.\n            If the distance parameter is specified, the location parameter\n            must be specified as well.\n            It is important to note that the location and distance\n            parameters allow searches to extend beyond the specified search\n            radius. They are not used to filter results, but rather to rank\n            resulting candidates based on their distance from a location.\n           category - The category parameter is only supported by geocode\n            services published using StreetMap Premium locators.\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"text\" : text\n        }\n        url = self._url + \"/suggest\"\n        if isinstance(location, Point):\n            params['location'] = location.asDictionary\n        elif isinstance(location, list):\n            params['location'] = \"%s,%s\" % (location[0], location[1])\n        else:\n            raise Exception(\"Invalid location, please try again\")\n        if not category is None:\n            params['category'] = category\n        if not distance is None and \\\n           isinstance(distance, (int, float)):\n            params['distance'] = distance\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This method generates a list of suggested matches for the input text location and category."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __init(self):\n        params = {\n            \"f\" : \"json\"\n        }\n        json_dict = self._get(url=self._url, param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        attributes = [attr for attr in dir(self)\n                      if not attr.startswith('__') and \\\n                      not attr.startswith('_')]\n        for k,v in json_dict.items():\n            if k in attributes:\n                setattr(self, \"_\"+ k, json_dict[k])\n            else:\n                print( k, \" - attribute not implemented in RouteNetworkLayer.\")\n            del k,v", "response": "initializes all the properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef solve(self,stops,\n              method=\"POST\",\n              barriers=None,\n              polylineBarriers=None,\n              polygonBarriers=None,\n              travelMode=None,\n              attributeParameterValues=None,\n              returnDirections=None,\n              returnRoutes=True,\n              returnStops=False,\n              returnBarriers=False,\n              returnPolylineBarriers=True,\n              returnPolygonBarriers=True,\n              outSR=None,\n              ignoreInvalidLocations=True,\n              outputLines=None,\n              findBestSequence=False,\n              preserveFirstStop=True,\n              preserveLastStop=True,\n              useTimeWindows=False,\n              startTime=None,\n              startTimeIsUTC=False,\n              accumulateAttributeNames=None,\n              impedanceAttributeName=None,\n              restrictionAttributeNames=None,\n              restrictUTurns=None,\n              useHierarchy=True,\n              directionsLanguage=None,\n              directionsOutputType=None,\n              directionsStyleName=None,\n              directionsLengthUnits=None,\n              directionsTimeAttributeName=None,\n              outputGeometryPrecision=None,\n              outputGeometryPrecisionUnits=None,\n              returnZ=False\n              ):\n        \"\"\"The solve operation is performed on a network layer resource.\n        The solve operation is supported on a network layer whose layerType\n        is esriNAServerRouteLayer. You can provide arguments to the solve\n        route operation as query parameters.\n        Inputs:\n            stops - The set of stops loaded as network locations during analysis.\n                    Stops can be specified using a simple comma / semi-colon\n                    based syntax or as a JSON structure. If stops are not\n                    specified, preloaded stops from the map document are used in\n                    the analysis.\n            barriers - The set of barriers loaded as network locations during\n                       analysis. Barriers can be specified using a simple comma\n                       / semi-colon based syntax or as a JSON structure. If\n                       barriers are not specified, preloaded barriers from the\n                       map document are used in the analysis. If an empty json\n                       object is passed ('{}') preloaded barriers are ignored.\n            polylineBarriers - The set of polyline barriers loaded as network\n                               locations during analysis. If polyline barriers\n                               are not specified, preloaded polyline barriers\n                               from the map document are used in the analysis.\n                               If an empty json object is passed ('{}')\n                               preloaded polyline barriers are ignored.\n            polygonBarriers - The set of polygon barriers loaded as network\n                              locations during analysis. If polygon barriers\n                              are not specified, preloaded polygon barriers\n                              from the map document are used in the analysis.\n                              If an empty json object is passed ('{}') preloaded\n                              polygon barriers are ignored.\n\n            travelMode - Travel modes provide override values that help you\n                         quickly and consistently model a vehicle or mode of\n                         transportation. The chosen travel mode must be\n                         preconfigured on the network dataset that the routing\n                         service references.\n            attributeParameterValues - A set of attribute parameter values that\n                                       can be parameterized to determine which\n                                       network elements can be used by a vehicle.\n            returnDirections - If true, directions will be generated and returned\n                               with the analysis results. Default is true.\n            returnRoutes - If true, routes will be returned with the analysis\n                           results. Default is true.\n            returnStops -  If true, stops will be returned with the analysis\n                           results. Default is false.\n            returnBarriers -  If true, barriers will be returned with the analysis\n                              results. Default is false.\n            returnPolylineBarriers -  If true, polyline barriers will be returned\n                                      with the analysis results. Default is false.\n            returnPolygonBarriers - If true, polygon barriers will be returned with\n                                    the analysis results. Default is false.\n            outSR - The spatial reference of the geometries returned with the\n                    analysis results.\n            ignoreInvalidLocations - If true, the solver will ignore invalid\n                                     locations. Otherwise, it will raise an error.\n                                     The default is as defined in the network layer.\n            outputLines - The type of output lines to be generated in the result.\n                          The default is as defined in the network layer.\n            findBestSequence - If true, the solver should re-sequence the route in\n                               the optimal order. The default is as defined in the\n                               network layer.\n            preserveFirstStop - If true, the solver should keep the first stop\n                                fixed in the sequence. The default is as defined\n                                in the network layer.\n            preserveLastStop - If true, the solver should keep the last stop fixed\n                               in the sequence. The default is as defined in the\n                               network layer.\n            useTimeWindows - If true, the solver should consider time windows.\n                             The default is as defined in the network layer.\n            startTime - The time the route begins. If not specified, the solver\n                        will use the default as defined in the network layer.\n            startTimeIsUTC - The time zone of the startTime parameter.\n            accumulateAttributeNames - The list of network attribute names to be\n                                       accumulated with the analysis. The default is\n                                       as defined in the network layer. The value\n                                       should be specified as a comma separated list\n                                       of attribute names. You can also specify a\n                                       value of none to indicate that no network\n                                       attributes should be accumulated.\n            impedanceAttributeName - The network attribute name to be used as the\n                                     impedance attribute in analysis. The default is\n                                     as defined in the network layer.\n            restrictionAttributeNames -The list of network attribute names to be\n                                       used as restrictions with the analysis. The\n                                       default is as defined in the network layer.\n                                       The value should be specified as a comma\n                                       separated list of attribute names. You can\n                                       also specify a value of none to indicate that\n                                       no network attributes should be used as\n                                       restrictions.\n            restrictUTurns -  Specifies how U-Turns should be restricted in the\n                              analysis. The default is as defined in the network\n                              layer. Values: esriNFSBAllowBacktrack |\n                              esriNFSBAtDeadEndsOnly | esriNFSBNoBacktrack |\n                              esriNFSBAtDeadEndsAndIntersections\n            useHierarchy -  If true, the hierarchy attribute for the network should\n                            be used in analysis. The default is as defined in the\n                            network layer.\n            directionsLanguage - The language to be used when computing directions.\n                                 The default is as defined in the network layer. The\n                                 list of supported languages can be found in REST\n                                 layer description.\n            directionsOutputType -  Defines content, verbosity of returned\n                                    directions. The default is esriDOTStandard.\n                                    Values: esriDOTComplete | esriDOTCompleteNoEvents\n                                    | esriDOTInstructionsOnly | esriDOTStandard |\n                                    esriDOTSummaryOnly\n            directionsStyleName - The style to be used when returning the directions.\n                                  The default is as defined in the network layer. The\n                                  list of supported styles can be found in REST\n                                  layer description.\n            directionsLengthUnits - The length units to use when computing directions.\n                                    The default is as defined in the network layer.\n                                    Values: esriNAUFeet | esriNAUKilometers |\n                                    esriNAUMeters | esriNAUMiles |\n                                    esriNAUNauticalMiles | esriNAUYards |\n                                    esriNAUUnknown\n            directionsTimeAttributeName - The name of network attribute to use for\n                                          the drive time when computing directions.\n                                          The default is as defined in the network\n                                          layer.\n            outputGeometryPrecision -  The precision of the output geometry after\n                                       generalization. If 0, no generalization of\n                                       output geometry is performed. The default is\n                                       as defined in the network service\n                                       configuration.\n            outputGeometryPrecisionUnits - The units of the output geometry\n                                           precision. The default value is\n                                           esriUnknownUnits. Values: esriUnknownUnits\n                                           | esriCentimeters | esriDecimalDegrees |\n                                           esriDecimeters | esriFeet | esriInches |\n                                           esriKilometers | esriMeters | esriMiles |\n                                           esriMillimeters | esriNauticalMiles |\n                                           esriPoints | esriYards\n            returnZ - If true, Z values will be included in the returned routes and\n                       compressed geometry if the network dataset is Z-aware.\n                       The default is false.\n        \"\"\"\n\n        if not self.layerType == \"esriNAServerRouteLayer\":\n            raise ValueError(\"The solve operation is supported on a network \"\n                             \"layer of Route type only\")\n\n        url = self._url + \"/solve\"\n        params = {\n                    \"f\" : \"json\",\n                    \"stops\": stops\n                 }\n\n        if not barriers is None:\n            params['barriers'] = barriers\n        if not polylineBarriers is None:\n            params['polylineBarriers'] = polylineBarriers\n        if not polygonBarriers is None:\n            params['polygonBarriers'] = polygonBarriers\n        if not travelMode is None:\n            params['travelMode'] = travelMode\n        if not attributeParameterValues is None:\n            params['attributeParameterValues'] = attributeParameterValues\n        if not returnDirections is None:\n            params['returnDirections'] = returnDirections\n        if not returnRoutes is None:\n            params['returnRoutes'] = returnRoutes\n        if not returnStops is None:\n            params['returnStops'] = returnStops\n        if not returnBarriers is None:\n            params['returnBarriers'] = returnBarriers\n        if not returnPolylineBarriers is None:\n            params['returnPolylineBarriers'] = returnPolylineBarriers\n        if not returnPolygonBarriers is None:\n            params['returnPolygonBarriers'] = returnPolygonBarriers\n        if not outSR is None:\n            params['outSR'] = outSR\n        if not ignoreInvalidLocations is None:\n            params['ignoreInvalidLocations'] = ignoreInvalidLocations\n        if not outputLines is None:\n            params['outputLines'] = outputLines\n        if not findBestSequence is None:\n            params['findBestSequence'] = findBestSequence\n        if not preserveFirstStop is None:\n            params['preserveFirstStop'] = preserveFirstStop\n        if not preserveLastStop is None:\n            params['preserveLastStop'] = preserveLastStop\n        if not useTimeWindows is None:\n            params['useTimeWindows'] = useTimeWindows\n        if not startTime is None:\n            params['startTime'] = startTime\n        if not startTimeIsUTC is None:\n            params['startTimeIsUTC'] = startTimeIsUTC\n        if not accumulateAttributeNames is None:\n            params['accumulateAttributeNames'] = accumulateAttributeNames\n        if not impedanceAttributeName is None:\n            params['impedanceAttributeName'] = impedanceAttributeName\n        if not restrictionAttributeNames is None:\n            params['restrictionAttributeNames'] = restrictionAttributeNames\n        if not restrictUTurns is None:\n            params['restrictUTurns'] = restrictUTurns\n        if not useHierarchy is None:\n            params['useHierarchy'] = useHierarchy\n        if not directionsLanguage is None:\n            params['directionsLanguage'] = directionsLanguage\n        if not directionsOutputType is None:\n            params['directionsOutputType'] = directionsOutputType\n        if not directionsStyleName is None:\n            params['directionsStyleName'] = directionsStyleName\n        if not directionsLengthUnits is None:\n            params['directionsLengthUnits'] = directionsLengthUnits\n        if not directionsTimeAttributeName is None:\n            params['directionsTimeAttributeName'] = directionsTimeAttributeName\n        if not outputGeometryPrecision is None:\n            params['outputGeometryPrecision'] = outputGeometryPrecision\n        if not outputGeometryPrecisionUnits is None:\n            params['outputGeometryPrecisionUnits'] = outputGeometryPrecisionUnits\n        if not returnZ is None:\n            params['returnZ'] = returnZ\n\n        if method.lower() == \"post\":\n            return self._post(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        else:\n            return self._get(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)", "response": "This method is used to perform a solve operation on a resource in a network layer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef solveServiceArea(self,facilities,method=\"POST\",\n                         barriers=None,\n                         polylineBarriers=None,\n                         polygonBarriers=None,\n                         travelMode=None,\n                         attributeParameterValues=None,\n                         defaultBreaks=None,\n                         excludeSourcesFromPolygons=None,\n                         mergeSimilarPolygonRanges=None,\n                         outputLines=None,\n                         outputPolygons=None,\n                         overlapLines=None,\n                         overlapPolygons=None,\n                         splitLinesAtBreaks=None,\n                         splitPolygonsAtBreaks=None,\n                         trimOuterPolygon=None,\n                         trimPolygonDistance=None,\n                         trimPolygonDistanceUnits=None,\n                         returnFacilities=False,\n                         returnBarriers=False,\n                         returnPolylineBarriers=False,\n                         returnPolygonBarriers=False,\n                         outSR=None,\n                         accumulateAttributeNames=None,\n                         impedanceAttributeName=None,\n                         restrictionAttributeNames=None,\n                         restrictUTurns=None,\n                         outputGeometryPrecision=None,\n                         outputGeometryPrecisionUnits='esriUnknownUnits',\n                         useHierarchy=None,\n                         timeOfDay=None,\n                         timeOfDayIsUTC=None,\n                         travelDirection=None,\n                         returnZ=False):\n        \"\"\" The solve service area operation is performed on a network layer\n        resource of type service area (layerType is esriNAServerServiceArea).\n        You can provide arguments to the solve service area operation as\n        query parameters.\n        Inputs:\n            facilities - The set of facilities loaded as network locations\n                         during analysis. Facilities can be specified using\n                         a simple comma / semi-colon based syntax or as a\n                         JSON structure. If facilities are not specified,\n                         preloaded facilities from the map document are used\n                         in the analysis. If an empty json object is passed\n                         ('{}') preloaded facilities are ignored.\n            barriers - The set of barriers loaded as network locations during\n                       analysis. Barriers can be specified using a simple\n                       comma/semicolon-based syntax or as a JSON structure.\n                       If barriers are not specified, preloaded barriers from\n                       the map document are used in the analysis. If an empty\n                       json object is passed ('{}'), preloaded barriers are\n                       ignored.\n            polylineBarriers - The set of polyline barriers loaded as network\n                               locations during analysis. If polyline barriers\n                               are not specified, preloaded polyline barriers\n                               from the map document are used in the analysis.\n                               If an empty json object is passed ('{}'),\n                               preloaded polyline barriers are ignored.\n            polygonBarriers - The set of polygon barriers loaded as network\n                              locations during analysis. If polygon barriers\n                              are not specified, preloaded polygon barriers\n                              from the map document are used in the analysis.\n                              If an empty json object is passed ('{}'),\n                              preloaded polygon barriers are ignored.\n            travelMode - Travel modes provide override values that help you\n                         quickly and consistently model a vehicle or mode of\n                         transportation. The chosen travel mode must be\n                         preconfigured on the network dataset that the\n                         service area service references.\n            attributeParameterValues - A set of attribute parameter values that\n                                       can be parameterized to determine which\n                                       network elements can be used by a vehicle.\n            defaultBreaks - A comma-separated list of doubles. The default is\n                            defined in the network analysis layer.\n            excludeSourcesFromPolygons - A comma-separated list of string names.\n                                         The default is defined in the network\n                                         analysis layer.\n\n            mergeSimilarPolygonRanges - If true, similar ranges will be merged\n                                        in the result polygons. The default is\n                                        defined in the network analysis layer.\n            outputLines - The type of lines(s) generated. The default is as\n                          defined in the network analysis layer.\n            outputPolygons - The type of polygon(s) generated. The default is\n                             as defined in the network analysis layer.\n            overlapLines - Indicates if the lines should overlap from multiple\n                           facilities. The default is defined in the network\n                           analysis layer.\n            overlapPolygons - Indicates if the polygons for all facilities\n                              should overlap. The default is defined in the\n                              network analysis layer.\n            splitLinesAtBreaks - If true, lines will be split at breaks. The\n                                 default is defined in the network analysis\n                                 layer.\n            splitPolygonsAtBreaks - If true, polygons will be split at breaks.\n                                    The default is defined in the network\n                                    analysis layer.\n            trimOuterPolygon -  If true, the outermost polygon (at the maximum\n                                break value) will be trimmed. The default is\n                                defined in the network analysis layer.\n            trimPolygonDistance -  If polygons are being trimmed, provides the\n                                   distance to trim. The default is defined in\n                                   the network analysis layer.\n            trimPolygonDistanceUnits - If polygons are being trimmed, specifies\n                                       the units of the trimPolygonDistance. The\n                                       default is defined in the network analysis\n                                       layer.\n            returnFacilities - If true, facilities will be returned with the\n                               analysis results. Default is false.\n            returnBarriers - If true, barriers will be returned with the analysis\n                             results. Default is false.\n            returnPolylineBarriers - If true, polyline barriers will be returned\n                                     with the analysis results. Default is false.\n            returnPolygonBarriers - If true, polygon barriers will be returned\n                                    with the analysis results. Default is false.\n            outSR - The well-known ID of the spatial reference for the geometries\n                    returned with the analysis results. If outSR is not specified,\n                    the geometries are returned in the spatial reference of the map.\n            accumulateAttributeNames - The list of network attribute names to be\n                                       accumulated with the analysis. The default\n                                       is as defined in the network analysis layer.\n                                       The value should be specified as a comma\n                                       separated list of attribute names. You can\n                                       also specify a value of none to indicate that\n                                       no network attributes should be accumulated.\n            impedanceAttributeName - The network attribute name to be used as the\n                                     impedance attribute in analysis. The default\n                                     is as defined in the network analysis layer.\n            restrictionAttributeNames - The list of network attribute names to be\n                                        used as restrictions with the analysis. The\n                                        default is as defined in the network analysis\n                                        layer. The value should be specified as a\n                                        comma separated list of attribute names.\n                                        You can also specify a value of none to\n                                        indicate that no network attributes should\n                                        be used as restrictions.\n            restrictUTurns - Specifies how U-Turns should be restricted in the\n                             analysis. The default is as defined in the network\n                             analysis layer. Values: esriNFSBAllowBacktrack |\n                             esriNFSBAtDeadEndsOnly | esriNFSBNoBacktrack |\n                             esriNFSBAtDeadEndsAndIntersections\n            outputGeometryPrecision - The precision of the output geometry after\n                                      generalization. If 0, no generalization of\n                                      output geometry is performed. The default is\n                                      as defined in the network service configuration.\n            outputGeometryPrecisionUnits - The units of the output geometry precision.\n                                           The default value is esriUnknownUnits.\n                                           Values: esriUnknownUnits | esriCentimeters |\n                                           esriDecimalDegrees | esriDecimeters |\n                                           esriFeet | esriInches | esriKilometers |\n                                           esriMeters | esriMiles | esriMillimeters |\n                                           esriNauticalMiles | esriPoints | esriYards\n            useHierarchy - If true, the hierarchy attribute for the network should be\n                           used in analysis. The default is as defined in the network\n                           layer. This cannot be used in conjunction with outputLines.\n            timeOfDay - The date and time at the facility. If travelDirection is set\n                        to esriNATravelDirectionToFacility, the timeOfDay value\n                        specifies the arrival time at the facility. if travelDirection\n                        is set to esriNATravelDirectionFromFacility, the timeOfDay\n                        value is the departure time from the facility. The time zone\n                        for timeOfDay is specified by timeOfDayIsUTC.\n            timeOfDayIsUTC - The time zone or zones of the timeOfDay parameter. When\n                             set to false, which is the default value, the timeOfDay\n                             parameter refers to the time zone or zones in which the\n                             facilities are located. Therefore, the start or end times\n                             of the service areas are staggered by time zone.\n            travelDirection - Options for traveling to or from the facility. The\n                              default is defined in the network analysis layer.\n            returnZ - If true, Z values will be included in saPolygons and saPolylines\n                      geometry if the network dataset is Z-aware.\n    \"\"\"\n        if not self.layerType == \"esriNAServerServiceAreaLayer\":\n            raise ValueError(\"The solveServiceArea operation is supported on a network \"\n                             \"layer of Service Area type only\")\n\n        url = self._url + \"/solveServiceArea\"\n        params = {\n                \"f\" : \"json\",\n                \"facilities\": facilities\n                }\n\n        if not barriers is None:\n            params['barriers'] = barriers\n        if not polylineBarriers is None:\n            params['polylineBarriers'] = polylineBarriers\n        if not polygonBarriers is None:\n            params['polygonBarriers'] = polygonBarriers\n        if not travelMode is None:\n            params['travelMode'] = travelMode\n        if not attributeParameterValues is None:\n            params['attributeParameterValues'] = attributeParameterValues\n        if not defaultBreaks is None:\n            params['defaultBreaks'] = defaultBreaks\n        if not excludeSourcesFromPolygons is None:\n            params['excludeSourcesFromPolygons'] = excludeSourcesFromPolygons\n        if not mergeSimilarPolygonRanges is None:\n            params['mergeSimilarPolygonRanges'] = mergeSimilarPolygonRanges\n        if not outputLines is None:\n            params['outputLines'] = outputLines\n        if not outputPolygons is None:\n            params['outputPolygons'] = outputPolygons\n        if not overlapLines is None:\n            params['overlapLines'] = overlapLines\n        if not overlapPolygons is None:\n            params['overlapPolygons'] = overlapPolygons\n        if not splitLinesAtBreaks is None:\n            params['splitLinesAtBreaks'] = splitLinesAtBreaks\n        if not splitPolygonsAtBreaks is None:\n            params['splitPolygonsAtBreaks'] = splitPolygonsAtBreaks\n        if not trimOuterPolygon is None:\n            params['trimOuterPolygon'] = trimOuterPolygon\n        if not trimPolygonDistance is None:\n            params['trimPolygonDistance'] = trimPolygonDistance\n        if not trimPolygonDistanceUnits is None:\n            params['trimPolygonDistanceUnits'] = trimPolygonDistanceUnits\n        if not returnFacilities is None:\n            params['returnFacilities'] = returnFacilities\n        if not returnBarriers is None:\n            params['returnBarriers'] = returnBarriers\n        if not returnPolylineBarriers is None:\n            params['returnPolylineBarriers'] = returnPolylineBarriers\n        if not returnPolygonBarriers is None:\n            params['returnPolygonBarriers'] = returnPolygonBarriers\n        if not outSR is None:\n            params['outSR'] = outSR\n        if not accumulateAttributeNames is None:\n            params['accumulateAttributeNames'] = accumulateAttributeNames\n        if not impedanceAttributeName is None:\n            params['impedanceAttributeName'] = impedanceAttributeName\n        if not restrictionAttributeNames is None:\n            params['restrictionAttributeNames'] = restrictionAttributeNames\n        if not restrictUTurns is None:\n            params['restrictUTurns'] = restrictUTurns\n        if not outputGeometryPrecision is None:\n            params['outputGeometryPrecision'] = outputGeometryPrecision\n        if not outputGeometryPrecisionUnits is None:\n            params['outputGeometryPrecisionUnits'] = outputGeometryPrecisionUnits\n        if not useHierarchy is None:\n            params['useHierarchy'] = useHierarchy\n        if not timeOfDay is None:\n            params['timeOfDay'] = timeOfDay\n        if not timeOfDayIsUTC is None:\n            params['timeOfDayIsUTC'] = timeOfDayIsUTC\n        if not travelDirection is None:\n            params['travelDirection'] = travelDirection\n        if not returnZ is None:\n            params['returnZ'] = returnZ\n\n        if method.lower() == \"post\":\n            return self._post(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        else:\n            return self._get(url=url,\n                                param_dict=params,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)", "response": "This method solves the service area of a map layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload an item from the local disk to the local disk.", "response": "def download(self, itemID, savePath):\n        \"\"\"\n        downloads an item to local disk\n\n        Inputs:\n           itemID - unique id of item to download\n           savePath - folder to save the file in\n        \"\"\"\n        if os.path.isdir(savePath) == False:\n            os.makedirs(savePath)\n        url = self._url + \"/%s/download\" % itemID\n        params = {\n        }\n        if len(params.keys()):\n            url =  url + \"?%s\" % urlencode(params)\n        return self._get(url=url,\n                         param_dict=params,\n                         out_folder=savePath,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reports(self):\n        if self._metrics is None:\n            self.__init()\n        self._reports = []\n        for r in self._metrics:\n            url = self._url + \"/%s\" % six.moves.urllib.parse.quote_plus(r['reportname'])\n            self._reports.append(UsageReport(url=url,\n                                             securityHandler=self._securityHandler,\n                                             proxy_url=self._proxy_url,\n                                             proxy_port=self._proxy_port,\n                                             initialize=True))\n            del url\n        return self._reports", "response": "returns a list of usage reports on the server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new usage report. A usage report is created by submitting a JSON representation of the usage report to this operation. Inputs: reportname - the unique name of the report since - the time duration of the report. The supported values are: LAST_DAY, LAST_WEEK, LAST_MONTH, LAST_YEAR, CUSTOM LAST_DAY represents a time range spanning the previous 24 hours. LAST_WEEK represents a time range spanning the previous 7 days. LAST_MONTH represents a time range spanning the previous 30 days. LAST_YEAR represents a time range spanning the previous 365 days. CUSTOM represents a time range that is specified using the from and to parameters. fromValue - optional value - The timestamp (milliseconds since UNIX epoch, namely January 1, 1970, 00:00:00 GMT) for the beginning period of the report. Only valid when since is CUSTOM toValue - optional value - The timestamp (milliseconds since UNIX epoch, namely January 1, 1970, 00:00:00 GMT) for the ending period of the report.Only valid when since is CUSTOM. aggregationInterval - Optional. Aggregation interval in minutes. Server metrics are aggregated and returned for time slices aggregated using the specified aggregation interval. The time range for the report, specified using the since parameter (and from and to when since is CUSTOM) is split into multiple slices, each covering an aggregation interval. Server metrics are then aggregated for each time slice and returned as data points in the report data. When the aggregationInterval is not specified, the following defaults are used: LAST_DAY: 30 minutes LAST_WEEK: 4 hours LAST_MONTH: 24 hours LAST_YEAR: 1 week CUSTOM: 30 minutes up to 1 day, 4 hours up to 1 week, 1 day up to 30 days, and 1 week for longer periods. If the samplingInterval specified in Usage Reports Settings is more than the aggregationInterval, the samplingInterval is used instead. queries - A list of queries for which to generate the report. You need to specify the list as an array of JSON objects representing the queries. Each query specifies the list of metrics to be queries for a given set of resourceURIs. The queries parameter has the following sub-parameters: resourceURIs - Comma separated list of resource URIs for which to report metrics. Specifies services or folders for which to gather metrics. The resourceURI is formatted as below: services/ - Entire Site services/Folder/ - Folder within a Site. Reports metrics aggregated across all services within that Folder and Sub-Folders. services/Folder/ServiceName.ServiceType - Service in a specified folder, for example: services/Map_bv_999.MapServer. services/ServiceName.ServiceType - Service in the root folder, for example: Map_bv_999.MapServer. metrics - Comma separated list of metrics to be reported. Supported metrics are: RequestCount - the number of requests received RequestsFailed - the number of requests that failed RequestsTimedOut - the number of requests that timed out RequestMaxResponseTime - the maximum response time RequestAvgResponseTime - the average response time ServiceActiveInstances - the maximum number of active (running) service instances sampled at 1 minute intervals, for a specified service metadata - Can be any JSON Object. Typically used for storing presentation tier data for the usage report, such as report title, colors, line-styles, etc. Also used to denote visibility in ArcGIS Server Manager for reports created with the Administrator Directory. To make any report created in the Administrator Directory visible to Manager, include \"managerReport\":true in the metadata JSON object. When this value is not set (default), reports are not visible in Manager. This behavior can be extended to any client that wants to interact with the Administrator Directory. Any user-created value will need to be processed by the client. Example: >>> queryObj = [{ \"resourceURIs\": [\"services/Map_bv_999.MapServer\"], \"metrics\": [\"RequestCount\"] }] >>> obj.createReport( reportname=\"SampleReport\", queries=queryObj, metadata=\"This could be any String or JSON Object.\", since=\"LAST_DAY\" )", "response": "def createUsageReport(self,\n                          reportname,\n                          queries,\n                          metadata,\n                          since=\"LAST_DAY\",\n                          fromValue=None,\n                          toValue=None,\n                          aggregationInterval=None\n                          ):\n        \"\"\"\n        Creates a new usage report. A usage report is created by submitting\n        a JSON representation of the usage report to this operation.\n\n        Inputs:\n           reportname - the unique name of the report\n           since - the time duration of the report. The supported values\n              are: LAST_DAY, LAST_WEEK, LAST_MONTH, LAST_YEAR, CUSTOM\n              LAST_DAY represents a time range spanning the previous 24\n                 hours.\n              LAST_WEEK represents a time range spanning the previous 7\n                 days.\n              LAST_MONTH represents a time range spanning the previous 30\n                 days.\n              LAST_YEAR represents a time range spanning the previous 365\n                 days.\n              CUSTOM represents a time range that is specified using the\n                 from and to parameters.\n           fromValue - optional value - The timestamp (milliseconds since\n              UNIX epoch, namely January 1, 1970, 00:00:00 GMT) for the\n              beginning period of the report. Only valid when since is\n              CUSTOM\n           toValue - optional value - The timestamp (milliseconds since\n              UNIX epoch, namely January 1, 1970, 00:00:00 GMT) for the\n              ending period of the report.Only valid when since is\n              CUSTOM.\n           aggregationInterval - Optional. Aggregation interval in minutes.\n              Server metrics are aggregated and returned for time slices\n              aggregated using the specified aggregation interval. The time\n              range for the report, specified using the since parameter\n              (and from and to when since is CUSTOM) is split into multiple\n              slices, each covering an aggregation interval. Server metrics\n              are then aggregated for each time slice and returned as data\n              points in the report data.\n              When the aggregationInterval is not specified, the following\n              defaults are used:\n                 LAST_DAY: 30 minutes\n                 LAST_WEEK: 4 hours\n                 LAST_MONTH: 24 hours\n                 LAST_YEAR: 1 week\n                 CUSTOM: 30 minutes up to 1 day, 4 hours up to 1 week, 1\n                 day up to 30 days, and 1 week for longer periods.\n             If the samplingInterval specified in Usage Reports Settings is\n             more than the aggregationInterval, the samplingInterval is\n             used instead.\n           queries - A list of queries for which to generate the report.\n              You need to specify the list as an array of JSON objects\n              representing the queries. Each query specifies the list of\n              metrics to be queries for a given set of resourceURIs.\n              The queries parameter has the following sub-parameters:\n                 resourceURIs - Comma separated list of resource URIs for\n                 which to report metrics. Specifies services or folders\n                 for which to gather metrics.\n                    The resourceURI is formatted as below:\n                       services/ - Entire Site\n                       services/Folder/  - Folder within a Site. Reports\n                         metrics aggregated across all services within that\n                         Folder and Sub-Folders.\n                       services/Folder/ServiceName.ServiceType - Service in\n                         a specified folder, for example:\n                         services/Map_bv_999.MapServer.\n                       services/ServiceName.ServiceType - Service in the\n                         root folder, for example: Map_bv_999.MapServer.\n                 metrics - Comma separated list of metrics to be reported.\n                   Supported metrics are:\n                    RequestCount - the number of requests received\n                    RequestsFailed - the number of requests that failed\n                    RequestsTimedOut - the number of requests that timed out\n                    RequestMaxResponseTime - the maximum response time\n                    RequestAvgResponseTime - the average response time\n                    ServiceActiveInstances - the maximum number of active\n                      (running) service instances sampled at 1 minute\n                      intervals, for a specified service\n           metadata - Can be any JSON Object. Typically used for storing\n              presentation tier data for the usage report, such as report\n              title, colors, line-styles, etc. Also used to denote\n              visibility in ArcGIS Server Manager for reports created with\n              the Administrator Directory. To make any report created in\n              the Administrator Directory visible to Manager, include\n              \"managerReport\":true in the metadata JSON object. When this\n              value is not set (default), reports are not visible in\n              Manager. This behavior can be extended to any client that\n              wants to interact with the Administrator Directory. Any\n              user-created value will need to be processed by the client.\n\n        Example:\n        >>> queryObj = [{\n           \"resourceURIs\": [\"services/Map_bv_999.MapServer\"],\n           \"metrics\": [\"RequestCount\"]\n        }]\n        >>> obj.createReport(\n           reportname=\"SampleReport\",\n           queries=queryObj,\n           metadata=\"This could be any String or JSON Object.\",\n           since=\"LAST_DAY\"\n        )\n        \"\"\"\n        url = self._url + \"/add\"\n\n        params = {\n            \"f\" : \"json\",\n            \"usagereport\": {\n            \"reportname\" : reportname,\n            \"since\" : since,\n            \"metadata\" : metadata}\n        }\n        if isinstance(queries, dict):\n            params[\"usagereport\"][\"queries\"] = [queries]\n        elif isinstance(queries, list):\n            params[\"usagereport\"][\"queries\"] = queries\n        if aggregationInterval is not None:\n            params[\"usagereport\"]['aggregationInterval'] = aggregationInterval\n        if since.lower() == \"custom\":\n            params[\"usagereport\"]['to'] = toValue\n            params[\"usagereport\"]['from'] = fromValue\n        res =  self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)\n        #  Refresh the metrics object\n        self.__init()\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edit(self):\n\n        usagereport_dict = {\n            \"reportname\": self.reportname,\n            \"queries\": self._queries,\n            \"since\": self.since,\n            \"metadata\": self._metadata,\n            \"to\" : self._to,\n            \"from\" : self._from,\n            \"aggregationInterval\" : self._aggregationInterval\n        }\n        params = {\n            \"f\" : \"json\",\n            \"usagereport\" : json.dumps(usagereport_dict)\n        }\n        url = self._url + \"/edit\"\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "Edits the usage report. This operation is performed on a class that has the properties of the usage report as well as the usage report properties of the usage report. The properties of the usage report are not changed until the edit method is called."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of replices", "response": "def replicasResource(self):\n        \"\"\"returns a list of replices\"\"\"\n        if self._replicasResource is None:\n            self._replicasResource = {}\n            for replica in self.replicas:\n                self._replicasResource[\"replicaName\"] = replica.name\n                self._replicasResource[\"replicaID\"] = replica.guid\n        return self._replicasResource"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef services(self):\n        self._services = []\n        params = {\"f\": \"json\"}\n        if not self._url.endswith('/services'):\n            uURL = self._url + \"/services\"\n        else:\n            uURL = self._url\n        res = self._get(url=uURL, param_dict=params,\n                           securityHandler=self._securityHandler,\n                           proxy_port=self._proxy_port,\n                           proxy_url=self._proxy_url)\n        for k, v in res.items():\n            if k == \"foldersDetail\":\n                for item in v:\n                    if 'isDefault' in item and item['isDefault'] == False:\n                        fURL = self._url + \"/services/\" + item['folderName']\n                        resFolder = self._get(url=fURL, param_dict=params,\n                                                 securityHandler=self._securityHandler,\n                                                 proxy_port=self._proxy_port,\n                                                 proxy_url=self._proxy_url)\n                        for k1, v1 in resFolder.items():\n                            if k1 == \"services\":\n                                self._checkservice(k1,v1,fURL)\n            elif k == \"services\":\n                self._checkservice(k,v,uURL)\n        return self._services", "response": "returns all the services in the admin service s page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef editTileService(self,\n                        serviceDefinition=None,\n                        minScale=None,\n                        maxScale=None,\n                        sourceItemId=None,\n                        exportTilesAllowed=False,\n                        maxExportTileCount=100000):\n        \"\"\"\n        This post operation updates a Tile Service's properties\n\n        Inputs:\n           serviceDefinition - updates a service definition\n           minScale - sets the services minimum scale for caching\n           maxScale - sets the service's maximum scale for caching\n           sourceItemId - The Source Item ID is the GeoWarehouse Item ID of the map service\n           exportTilesAllowed - sets the value to let users export tiles\n           maxExportTileCount - sets the maximum amount of tiles to be exported\n             from a single call.\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n        }\n        if not serviceDefinition is None:\n            params[\"serviceDefinition\"] = serviceDefinition\n        if not minScale is None:\n            params['minScale'] = float(minScale)\n        if not maxScale is None:\n            params['maxScale'] = float(maxScale)\n        if not sourceItemId is None:\n            params[\"sourceItemId\"] = sourceItemId\n        if not exportTilesAllowed is None:\n            params[\"exportTilesAllowed\"] = exportTilesAllowed\n        if not maxExportTileCount is None:\n            params[\"maxExportTileCount\"] = int(maxExportTileCount)\n        url = self._url + \"/edit\"\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._securityHandler.proxy_url,\n                             proxy_port=self._securityHandler.proxy_port)", "response": "This operation updates a Tile Service s properties"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef securityHandler(self, value):\n        if isinstance(value, BaseSecurityHandler):\n            if isinstance(value, (security.AGOLTokenSecurityHandler,security.PortalTokenSecurityHandler,security.ArcGISTokenSecurityHandler)):\n                self._securityHandler = value\n\n            else:\n                raise AttributeError(\"Admin only supports security.AGOLTokenSecurityHandler\")", "response": "sets the security handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef updateDefinition(self, json_dict):\n        definition = None\n        if json_dict is not None:\n            if isinstance(json_dict,collections.OrderedDict) == True:\n                definition = json_dict\n            else:\n\n                definition = collections.OrderedDict()\n                if 'hasStaticData' in json_dict:\n                    definition['hasStaticData'] = json_dict['hasStaticData']\n                if 'allowGeometryUpdates' in json_dict:\n                    definition['allowGeometryUpdates'] = json_dict['allowGeometryUpdates']\n                if 'capabilities' in json_dict:\n                    definition['capabilities'] = json_dict['capabilities']\n                if 'editorTrackingInfo' in json_dict:\n                    definition['editorTrackingInfo'] = collections.OrderedDict()\n                    if 'enableEditorTracking' in json_dict['editorTrackingInfo']:\n                        definition['editorTrackingInfo']['enableEditorTracking'] = json_dict['editorTrackingInfo']['enableEditorTracking']\n\n                    if 'enableOwnershipAccessControl' in json_dict['editorTrackingInfo']:\n                        definition['editorTrackingInfo']['enableOwnershipAccessControl'] = json_dict['editorTrackingInfo']['enableOwnershipAccessControl']\n\n                    if 'allowOthersToUpdate' in json_dict['editorTrackingInfo']:\n                        definition['editorTrackingInfo']['allowOthersToUpdate'] = json_dict['editorTrackingInfo']['allowOthersToUpdate']\n\n                    if 'allowOthersToDelete' in json_dict['editorTrackingInfo']:\n                        definition['editorTrackingInfo']['allowOthersToDelete'] = json_dict['editorTrackingInfo']['allowOthersToDelete']\n\n                    if 'allowOthersToQuery' in json_dict['editorTrackingInfo']:\n                        definition['editorTrackingInfo']['allowOthersToQuery'] = json_dict['editorTrackingInfo']['allowOthersToQuery']\n                    if isinstance(json_dict['editorTrackingInfo'],dict):\n                        for k,v in json_dict['editorTrackingInfo'].items():\n                            if k not in definition['editorTrackingInfo']:\n                                definition['editorTrackingInfo'][k] = v\n                if isinstance(json_dict,dict):\n                    for k,v in json_dict.items():\n                        if k not in definition:\n                            definition[k] = v\n\n        params = {\n            \"f\" : \"json\",\n            \"updateDefinition\" : json.dumps(obj=definition,separators=(',', ':')),\n            \"async\" : False\n        }\n        uURL = self._url + \"/updateDefinition\"\n        res = self._post(url=uURL, param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url)\n        self.refresh()\n        return res", "response": "This operation updates the definition of a hosted feature service layer object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the object properties", "response": "def __init(self):\n        \"\"\" initializes the service \"\"\"\n        params = {\n            \"f\" : \"json\",\n        }\n        json_dict = self._get(self._url, params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        self._json = json.dumps(json_dict)\n        self._json_dict = json_dict\n        self.loadAttributes(json_dict=json_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_resp(password_hash, server_challenge):\n    # padding with zeros to make the hash 21 bytes long\n    password_hash += b'\\0' * (21 - len(password_hash))\n\n    res = b''\n    dobj = des.DES(password_hash[0:7])\n    res = res + dobj.encrypt(server_challenge[0:8])\n\n    dobj = des.DES(password_hash[7:14])\n    res = res + dobj.encrypt(server_challenge[0:8])\n\n    dobj = des.DES(password_hash[14:21])\n    res = res + dobj.encrypt(server_challenge[0:8])\n    return res", "response": "Calculates the LM response given a 16 - byte password hash and the server challenge."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_LM_hashed_password_v1(passwd):\n\n    # if the passwd provided is already a hash, we just return the first half\n    if re.match(r'^[\\w]{32}:[\\w]{32}$', passwd):\n        return binascii.unhexlify(passwd.split(':')[0])\n\n    # fix the password length to 14 bytes\n    passwd = passwd.upper()\n    lm_pw = passwd + '\\0' * (14 - len(passwd))\n    lm_pw = passwd[0:14]\n\n    # do hash\n    magic_str = b\"KGS!@#$%\"  # page 57 in [MS-NLMP]\n\n    res = b''\n    dobj = des.DES(lm_pw[0:7])\n    res = res + dobj.encrypt(magic_str)\n\n    dobj = des.DES(lm_pw[7:14])\n    res = res + dobj.encrypt(magic_str)\n\n    return res", "response": "create LanManager hashed password"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating NT hashed password", "response": "def create_NT_hashed_password_v1(passwd, user=None, domain=None):\n    \"create NT hashed password\"\n    # if the passwd provided is already a hash, we just return the second half\n    if re.match(r'^[\\w]{32}:[\\w]{32}$', passwd):\n        return binascii.unhexlify(passwd.split(':')[1])\n\n    digest = hashlib.new('md4', passwd.encode('utf-16le')).digest()\n    return digest"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_NT_hashed_password_v2(passwd, user, domain):\n    \"create NT hashed password\"\n    digest = create_NT_hashed_password_v1(passwd)\n\n    return hmac.new(digest, (user.upper() + domain).encode('utf-16le')).digest()", "response": "create NT hashed password"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a csv column", "response": "def _readcsv(self, path_to_csv):\n        \"\"\"reads a csv column\"\"\"\n        return np.genfromtxt(path_to_csv,\n                             dtype=None,\n                             delimiter=',',\n                             names=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of available data collections for a given country name.", "response": "def queryDataCollectionByName(self, countryName):\n        \"\"\"\n        returns a list of available data collections for a given country\n        name.\n\n        Inputs:\n           countryName - name of the country to file the data collection.\n        Output:\n           list or None. None implies could not find the countryName\n        \"\"\"\n        var = self._dataCollectionCodes\n        try:\n            return [x[0] for x in var[var['Countries'] == countryName]]\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a geometry object to a dictionary", "response": "def __geometryToDict(self, geom):\n        \"\"\"converts a geometry object to a dictionary\"\"\"\n        if isinstance(geom, dict):\n            return geom\n        elif isinstance(geom, Point):\n            pt = geom.asDictionary\n            return {\"geometry\": {\"x\" : pt['x'], \"y\" : pt['y']}}\n        elif isinstance(geom, Polygon):\n            poly = geom.asDictionary\n            return {\n                \"geometry\" : {\n                    \"rings\" : poly['rings'],\n                    'spatialReference' : poly['spatialReference']\n                }\n            }\n        elif isinstance(geom, list):\n            return [self.__geometryToDict(g) for g in geom]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lookUpReportsByCountry(self, countryName):\n\n        code = self.findCountryTwoDigitCode(countryName)\n\n        if code is None:\n            raise Exception(\"Invalid country name.\")\n        url = self._base_url + self._url_list_reports + \"/%s\" % code\n        params = {\n            \"f\" : \"json\",\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This method looks up a country by its name and returns a list of reports in that country. The list is empty if the country is not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enrich(self,\n               studyAreas,\n               dataCollections=None,\n               analysisVariables=None,\n               addDerivativeVariables=\"all\",\n               studyAreasOptions=None,\n               useData=None,\n               intersectingGeographies=None,\n               returnGeometry=False,\n               inSR=4326,\n               outSR=4326,\n               suppressNullValues=False,\n               forStorage=True\n               ):\n        \"\"\"\n        The GeoEnrichment service uses the concept of a study area to\n        define the location of the point or area that you want to enrich\n        with additional information. If one or many points are input as\n        a study area, the service will create a 1-mile ring buffer around\n        the point to collect and append enrichment data. You can optionally\n        change the ring buffer size or create drive-time service areas\n        around the point. The most common method to determine the center\n        point for a study areas is a set of one or many point locations\n        defined as XY locations. More specifically, one or many input\n        points (latitude and longitude) can be provided to the service to\n        set the study areas that you want to enrich with additional\n        information. You can create a buffer ring or drive-time service\n        area around the points to aggregate data for the study areas. You\n        can also return enrichment data for buffers around input line\n        features.\n\n        Inputs:\n           studyAreas - Required parameter to specify a list of input\n              features to be enriched. Study areas can be input XY point\n              locations.\n           dataCollections - A Data Collection is a preassembled list of\n              attributes that will be used to enrich the input features.\n              Enrichment attributes can describe various types of\n              information such as demographic characteristics and\n              geographic context of the locations or areas submitted as\n              input features in studyAreas.\n           analysisVariables - A Data Collection is a preassembled list of\n              attributes that will be used to enrich the input features.\n              With the analysisVariables parameter you can return a subset\n              of variables Enrichment attributes can describe various types\n              of information such as demographic characteristics and\n              geographic context of the locations or areas submitted as\n              input features in studyAreas.\n           addDerivativeVariables - Optional parameter to specify an array\n              of string values that describe what derivative variables to\n              include in the output.\n           studyAreasOptions - Optional parameter to specify enrichment\n              behavior. For points described as map coordinates, a 1-mile\n              ring area centered on each site will be used by default. You\n              can use this parameter to change these default settings.\n              With this parameter, the caller can override the default\n              behavior describing how the enrichment attributes are\n              appended to the input features described in studyAreas. For\n              example, you can change the output ring buffer to 5 miles,\n              change the number of output buffers created around each point,\n              and also change the output buffer type to a drive-time service\n              area rather than a simple ring buffer.\n           useData - Optional parameter to explicitly specify the country\n              or dataset to query.\n           intersectingGeographies - Optional parameter to explicitly\n              define the geographic layers used to provide geographic\n              context during the enrichment process. For example, you can\n              use this optional parameter to return the U.S. county and ZIP\n              Code that each input study area intersects.\n              You can intersect input features defined in the studyAreas\n              parameter with standard geography layers that are provided by\n              the GeoEnrichment service for each country. You can also\n              intersect features from a publicly available feature service.\n           returnGeometry - Optional parameter to request the output\n              geometries in the response.\n              When this parameter is set to true, the output geometries\n              associated with each feature will be included in the response.\n              The output geometries will be in the spatial reference system\n              defined by outSR.\n           inSR - Optional parameter to define the input geometries in the\n              studyAreas parameter in a specified spatial reference system.\n           outSR - Optional parameter to request the output geometries in a\n              specified spatial reference system.\n           suppressNullValues - Optional parameter to return only values\n              that are not NULL in the output response. Adding the optional\n              suppressNullValues parameter to any data collections\n              discovery method will reduce the size of the output that is\n              returned.\n           forStorage - Optional parameter to define if GeoEnrichment\n              output is being stored. The price for using the Enrich method\n              varies according to whether the data returned is being\n              persisted, i.e. being stored, or whether it is merely being\n              used in an interactive context and is discarded after being\n              viewed. If the data is being stored, the terms of use for the\n              GeoEnrichment service require that you specify the forStorage\n              parameter to true.\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"outSR\": outSR,\n            \"inSR\" : inSR,\n            \"suppressNullValues\" : suppressNullValues,\n            \"addDerivativeVariables\" : addDerivativeVariables,\n            \"studyareas\" : studyAreas,\n            \"forStorage\" : forStorage\n        }\n        params['returnGeometry'] = returnGeometry\n        if studyAreasOptions is not None:\n            params['studyAreasOptions'] = studyAreasOptions\n        if dataCollections is not None:\n            params['dataCollections'] = dataCollections\n\n        if useData is not None:\n            params['useData'] = useData\n        if intersectingGeographies is not None:\n            params['intersectingGeographies'] = intersectingGeographies\n        if analysisVariables is not None:\n            params['analysisVariables'] = analysisVariables\n        url = self._base_url + self._url_enrich_data\n        return self._get(url=url,\n                         param_dict=params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)", "response": "This method is used to enrich the input features with the input data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the current folder", "response": "def folderName(self, folder):\n        \"\"\"gets/set the current folder\"\"\"\n\n        if folder == \"\" or\\\n             folder == \"/\":\n            self._currentURL = self._url\n            self._services = None\n            self._description = None\n            self._folderName = None\n            self._webEncrypted = None\n            self.__init()\n            self._folderName = folder\n        elif folder in self.folders:\n            self._currentURL = self._url + \"/%s\" % folder\n            self._services = None\n            self._description = None\n            self._folderName = None\n            self._webEncrypted = None\n            self.__init()\n            self._folderName = folder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all folders", "response": "def folders(self):\n        \"\"\" returns a list of all folders \"\"\"\n        if self._folders is None:\n            self.__init()\n        if \"/\" not in self._folders:\n            self._folders.append(\"/\")\n        return self._folders"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the services in the current folder", "response": "def services(self):\n        \"\"\" returns the services in the current folder \"\"\"\n        self._services = []\n        params = {\n                    \"f\" : \"json\"\n                }\n        json_dict = self._get(url=self._currentURL,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        if \"services\" in json_dict.keys():\n            for s in json_dict['services']:\n                uURL = self._currentURL + \"/%s.%s\" % (s['serviceName'], s['type'])\n                self._services.append(\n                    AGSService(url=uURL,\n                               securityHandler=self._securityHandler,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port)\n                )\n        return self._services"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of a particular service type on AGS Input: service_type - Type of service to find. The allowed types are: (\"GPSERVER\", \"GLOBESERVER\", \"MAPSERVER\", \"GEOMETRYSERVER\", \"IMAGESERVER\", \"SEARCHSERVER\", \"GEODATASERVER\", \"GEOCODESERVER\", \"*\"). The default is * meaning find all service names. Output: returns a list of service names as <folder>/<name>.<type>", "response": "def find_services(self, service_type=\"*\"):\n        \"\"\"\n            returns a list of a particular service type on AGS\n            Input:\n              service_type - Type of service to find.  The allowed types\n                             are: (\"GPSERVER\", \"GLOBESERVER\", \"MAPSERVER\",\n                             \"GEOMETRYSERVER\", \"IMAGESERVER\",\n                             \"SEARCHSERVER\", \"GEODATASERVER\",\n                             \"GEOCODESERVER\", \"*\").  The default is *\n                             meaning find all service names.\n            Output:\n              returns a list of service names as <folder>/<name>.<type>\n        \"\"\"\n        allowed_service_types = (\"GPSERVER\", \"GLOBESERVER\", \"MAPSERVER\",\n                                 \"GEOMETRYSERVER\", \"IMAGESERVER\",\n                                 \"SEARCHSERVER\", \"GEODATASERVER\",\n                                 \"GEOCODESERVER\", \"*\")\n        lower_types = [l.lower() for l in service_type.split(',')]\n        for v in lower_types:\n            if v.upper() not in allowed_service_types:\n                return {\"message\" : \"%s is not an allowed service type.\" % v}\n        params = {\n            \"f\" : \"json\"\n        }\n        type_services = []\n        folders = self.folders\n        baseURL = self._url\n        for folder in folders:\n            if folder == \"/\":\n                url = baseURL\n            else:\n                url = baseURL + \"/%s\" % folder\n            res = self._get(url, params,\n                               securityHandler=self._securityHandler,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port)\n            if \"services\" in res:\n                for service in res['services']:\n                    if service_type == \"*\":\n                        service['URL'] = url + \"/%s.%s\" % (service['serviceName'],\n                                                           service['type'])\n                        type_services.append(service)\n                    if service['type'].lower() in lower_types:\n                        service['URL'] = url + \"/%s.%s\" % (service['serviceName'],\n                                                           service_type)\n                        type_services.append(service)\n                    del service\n            del res\n            del folder\n        return type_services"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new permission to a folder. The principal is assigned to all parent resources and the isAllowed flag is set to True. The principal is assigned to all child resources and the isAllowed flag is set to True. The folder is assigned to all child resources.", "response": "def addFolderPermission(self, principal, isAllowed=True, folder=None):\n        \"\"\"\n           Assigns a new permission to a role (principal). The permission\n           on a parent resource is automatically inherited by all child\n           resources\n           Input:\n              principal - name of role to assign/disassign accesss\n              isAllowed -  boolean which allows access\n           Output:\n              JSON message as dictionary\n        \"\"\"\n        if folder is not None:\n            uURL = self._url + \"/%s/%s\" % (folder, \"/permissions/add\")\n        else:\n            uURL = self._url + \"/permissions/add\"\n        params = {\n            \"f\" : \"json\",\n            \"principal\" : principal,\n            \"isAllowed\" : isAllowed\n        }\n        return self._post(url=uURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproviding a report on all items in a given folder Inputs: folder - folder to report on given services. None means root", "response": "def service_report(self, folder=None):\n        \"\"\"\n           provides a report on all items in a given folder\n           Inputs:\n              folder - folder to report on given services. None means root\n        \"\"\"\n        items = [\"description\", \"status\",\n                 \"instances\", \"iteminfo\",\n                 \"properties\"]\n        if folder is None:\n            uURL = self._url + \"/report\"\n        else:\n            uURL = self._url + \"/%s/report\" % folder\n        params = {\n            \"f\" : \"json\",\n            \"parameters\" : items\n        }\n        return self._get(url=uURL, param_dict=params,\n                            securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrename a published AGS Service Inputs: serviceName - old service name serviceType - type of service serviceNewName - new service name folder - location of where the service lives, none means root folder. Output: JSON message as dictionary", "response": "def rename_service(self, serviceName, serviceType,\n                       serviceNewName, folder=None):\n        \"\"\"\n           Renames a published AGS Service\n           Inputs:\n              serviceName - old service name\n              serviceType - type of service\n              serviceNewName - new service name\n              folder - location of where the service lives, none means\n                       root folder.\n           Output:\n              JSON message as dictionary\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n            \"serviceName\" : serviceName,\n            \"serviceType\" : serviceType,\n            \"serviceNewName\" : serviceNewName\n        }\n        if folder is None:\n            uURL = self._url + \"/renameService\"\n        else:\n            uURL = self._url + \"/%s/renameService\" % folder\n        return self._post(url=uURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exists(self, folderName, serviceName=None, serviceType=None):\n\n        url = self._url + \"/exists\"\n        params = {\n            \"f\" : \"json\",\n            \"folderName\" : folderName,\n            \"serviceName\" : serviceName,\n            \"type\" : serviceType\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation checks if a folder or a service exists in a root folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the object properties", "response": "def __init(self):\n        \"\"\" populates server admin information \"\"\"\n        params = {\n            \"f\" : \"json\"\n        }\n        json_dict = self._get(url=self._currentURL,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        self._json = json.dumps(json_dict)\n        self._json_dict = json_dict\n        attributes = [attr for attr in dir(self)\n                    if not attr.startswith('__') and \\\n                    not attr.startswith('_')]\n        for k,v in json_dict.items():\n            if k.lower() == \"extensions\":\n                self._extensions = []\n                for ext in v:\n                    self._extensions.append(Extension.fromJSON(ext))\n                    del ext\n            elif k in attributes:\n                setattr(self, \"_\"+ k, json_dict[k])\n            else:\n                print( k, \" - attribute not implemented in manageags.AGSService.\")\n            del k\n            del v"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmodify the extensions of the service.", "response": "def modifyExtensions(self,\n                         extensionObjects=[]):\n        \"\"\"\n        enables/disables a service extension type based on the name\n        \"\"\"\n\n        if len(extensionObjects) > 0 and \\\n           isinstance(extensionObjects[0], Extension):\n            self._extensions = extensionObjects\n            res = self.edit(str(self))\n            self._json = None\n            self.__init()\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow for the upload of new itemInfo files such as metadata.xml Inputs: folder - folder on ArcGIS Server filePath - full path of the file to upload Output: json as dictionary", "response": "def itemInfoUpload(self, folder, filePath):\n        \"\"\"\n        Allows for the upload of new itemInfo files such as metadata.xml\n        Inputs:\n           folder - folder on ArcGIS Server\n           filePath - full path of the file to upload\n        Output:\n           json as dictionary\n        \"\"\"\n        files = {}\n        url = self._url + \"/iteminfo/upload\"\n        params = {\n            \"f\" : \"json\",\n            \"folder\" : folder\n        }\n        files['file'] = filePath\n        return self._post(url=url,\n                          param_dict=params,\n                          files=files,\n                          securityHandler=self._securityHandler,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serviceManifest(self, fileType=\"json\"):\n\n        url = self._url + \"/iteminfo/manifest/manifest.%s\" % fileType\n        params = {}\n        f = self._get(url=url,\n                      param_dict=params,\n                      securityHandler=self._securityHandler,\n                      proxy_url=self._proxy_url,\n                      proxy_port=self._proxy_port,\n                      out_folder=tempfile.gettempdir(),\n                      file_name=os.path.basename(url))\n        if fileType == 'json':\n            return f\n        if fileType == 'xml':\n            return ET.ElementTree(ET.fromstring(f))", "response": "This resource returns the service manifest file and returns the data and other availabe resources that define the service origins and power the service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef findDataItems(self, parentPath=None, ancestorPath=None,\n                      type=None, id=None):\n        \"\"\"\n           You can use this operation to search through the various data\n           items registered in the server's data store.\n           Inputs:\n              parentPath - The path of the parent under which to find items\n              ancestorPath - The path of the ancestor under which to find\n                             items.\n              type - A filter for the type of the items\n              id - A filter to search by the ID of the item\n           Output:\n              dictionary\n        \"\"\"\n        params = {\n            \"f\" : \"json\",\n        }\n        if parentPath is not None:\n            params['parentPath'] = parentPath\n        if ancestorPath is not None:\n            params['ancestorPath'] = ancestorPath\n        if type is not None:\n            params['type'] = type\n        if id is not None:\n            params['id'] = id\n        fURL = self._url + \"/findItems\"\n        return self._post(url=fURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "This operation searches through the various data items registered in the server s data store. The operation returns a dictionary containing the items that are registered in the server s data store. The items are returned in the order they appear in the server s data store."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef startDataStoreMachine(self, dataStoreItemName, machineName):\n        url = self._url + \"/items/enterpriseDatabases/%s/machines/%s/start\" % (dataStoreItemName, machineName)\n        params = {\n            \"f\": \"json\"\n        }\n        return self._post(url=url, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)", "response": "Starts the database instance running on the Data Store machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the status of ArcGIS Data Store and provides a health check response. Inputs: dataStoreName - name of the datastore machineName - name of the machine", "response": "def validateDataStore(self, dataStoreName, machineName):\n        \"\"\"\n        Checks the status of ArcGIS Data Store and provides a health check\n        response.\n\n        Inputs:\n           dataStoreName - name of the datastore\n           machineName - name of the machine\n        \"\"\"\n        url = self._url + \"/items/enterpriseDatabases/%s/machines/%s/validate\" % (dataStoreName, machineName)\n        params = {\n            \"f\" : \"json\"\n        }\n        return self._post(url=url,\n                             param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the globe service layers", "response": "def layers(self):\n        \"\"\"gets the globe service layers\"\"\"\n        if self._layers is None:\n            self.__init()\n        lyrs = []\n        for lyr in self._layers:\n            lyr['object'] = GlobeServiceLayer(url=self._url + \"/%s\" % lyr['id'],\n                                              securityHandler=self._securityHandler,\n                                              proxy_port=self._proxy_port,\n                                              proxy_url=self._proxy_url)\n            lyrs.append(lyr)\n\n        return lyrs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(*argv):\n    try:\n        #   Inputs\n        #\n        adminUsername = argv[0]\n        adminPassword = argv[1]\n        siteURL = argv[2]\n        username = argv[3]\n        subFolders = argv[4].lower() == \"true\"\n        #   Logic\n        #\n        sh = arcrest.AGOLTokenSecurityHandler(adminUsername, adminPassword)\n        admin = arcrest.manageorg.Administration(url=siteURL,\n                                                 securityHandler=sh)\n        content = admin.content\n        if isinstance(content, arcrest.manageorg._content.Content):pass\n        usercontent = content.usercontent(username=username)\n        res = usercontent.listUserContent(username=adminUsername)\n        #   Delete Root Items\n        #\n        eItems = \"\"\n        itemsToErase = \",\".join([item['id'] for item in res['items']])\n        usercontent.deleteItems(items=itemsToErase)\n        #  Walk Each Folder and erase items if subfolder == True\n        #\n        if subFolders:\n            for folder in res['folders']:\n                c = usercontent.listUserContent(username=username, folderId=folder['id'])\n                itemsToErase = \",\".join([item['id'] for item in c['items']])\n                if len(itemsToErase.split(',')) > 0:\n                    usercontent.deleteItems(items=itemsToErase)\n                del c\n                usercontent.deleteFolder(folderId=folder['id'])\n                del folder\n\n        arcpy.AddMessage(\"User %s content has been deleted.\" % username)\n        arcpy.SetParameterAsText(4, True)\n    except arcpy.ExecuteError:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)\n        arcpy.AddError(\"ArcPy Error Message: %s\" % arcpy.GetMessages(2))\n    except FunctionError, f_e:\n        messages = f_e.args[0]\n        arcpy.AddError(\"error in function: %s\" % messages[\"function\"])\n        arcpy.AddError(\"error on line: %s\" % messages[\"line\"])\n        arcpy.AddError(\"error in file name: %s\" % messages[\"filename\"])\n        arcpy.AddError(\"with error message: %s\" % messages[\"synerror\"])\n        arcpy.AddError(\"ArcPy Error Message: %s\" % messages[\"arc\"])\n    except:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)", "response": "main entry point for the main driver of the main driver of the program"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(*argv):\n    try:\n        #   Inputs\n        #\n        adminUsername = argv[0]\n        adminPassword = argv[1]\n        siteURL = argv[2]\n        groupTitle = argv[3]\n        groupTags = argv[4]\n        description = argv[5]\n        access = argv[6]\n\n        #   Logic\n        #\n        #   Connect to the site\n        #\n        sh = arcrest.AGOLTokenSecurityHandler(adminUsername, adminPassword)\n        admin = arcrest.manageorg.Administration(url=siteURL,\n                                                securityHandler=sh,\n                                                initialize=True)\n        community = admin.community\n        #   Create Group\n        #\n        res = community.createGroup(title=groupTitle,\n                                    tags=groupTags,\n                                    description=description,\n                                    snippet=\"\",\n                                    phone=\"\",\n                                    access=access,\n                                    sortField=\"title\",\n                                    sortOrder=\"asc\",\n                                    isViewOnly=False,\n                                    isInvitationOnly=False,\n                                    thumbnail=None)\n        arcpy.SetParameterAsText(7, str(res))\n    except arcpy.ExecuteError:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)\n        arcpy.AddError(\"ArcPy Error Message: %s\" % arcpy.GetMessages(2))\n    except FunctionError, f_e:\n        messages = f_e.args[0]\n        arcpy.AddError(\"error in function: %s\" % messages[\"function\"])\n        arcpy.AddError(\"error on line: %s\" % messages[\"line\"])\n        arcpy.AddError(\"error in file name: %s\" % messages[\"filename\"])\n        arcpy.AddError(\"with error message: %s\" % messages[\"synerror\"])\n        arcpy.AddError(\"ArcPy Error Message: %s\" % messages[\"arc\"])\n    except:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)", "response": "main function of the main driver of the main function"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPMultiValue(gptype=j['dataType'])\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the GP object from a JSON string", "response": "def fromJSON(value):\n        \"\"\"loads the GP object from a JSON string \"\"\"\n        j = json.loads(value)\n        v = GPRecordSet()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromTable(table, paramName):\n        from ..common.spatial import recordset_to_json\n        g = GPRecordSet()\n        g.paramName = paramName\n        g.value = json.loads(recordset_to_json(table))\n        return g", "response": "Converts a table to a GPRecordSet object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loadFeatures(self, path_to_fc):\n        from ..common.spatial import featureclass_to_json\n        v = json.loads(featureclass_to_json(path_to_fc))\n        self.value = v", "response": "Loads a feature class features to the object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPFeatureRecordSetLayer()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a GPFeatureRecordSetLayer object from a feature class.", "response": "def fromFeatureClass(fc, paramName):\n        \"\"\"\n        returns a GPFeatureRecordSetLayer object from a feature class\n\n        Input:\n           fc - path to a feature class\n           paramName - name of the parameter\n        \"\"\"\n        from ..common.spatial import featureclass_to_json\n        val = json.loads(featureclass_to_json(fc))\n        v = GPFeatureRecordSetLayer()\n        v.value = val\n        v.paramName = paramName\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the GP object from a JSON string", "response": "def fromJSON(value):\n        \"\"\"loads the GP object from a JSON string \"\"\"\n        j = json.loads(value)\n        v = GPRasterDataLayer()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPRasterData()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the GP object from a JSON string", "response": "def fromJSON(value):\n        \"\"\"loads the GP object from a JSON string \"\"\"\n        j = json.loads(value)\n        v = GPDataFile()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPLinearUnit()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPDate()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        #from datetime import datetime\n        #if isinstance(value, datetime):\n            #v.value = local_time_to_online(value)\n        #else:\n            #v.value = value\n        #v.paramName = j['paramName']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPBoolean()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPLong()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromJSON(value):\n        j = json.loads(value)\n        v = GPString()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v", "response": "loads the GP object from a JSON string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the GP object from a JSON string", "response": "def fromJSON(value):\n        \"\"\"loads the GP object from a JSON string \"\"\"\n        j = json.loads(value)\n        v = GPDouble()\n        if \"defaultValue\" in j:\n            v.value = j['defaultValue']\n        else:\n            v.value = j['value']\n        if 'paramName' in j:\n            v.paramName = j['paramName']\n        elif 'name' in j:\n            v.paramName = j['name']\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a KMZ file from a json object.", "response": "def createKMZ(self, kmz_as_json):\n        \"\"\"\n           Creates a KMZ file from json.\n           See http://resources.arcgis.com/en/help/arcgis-rest-api/index.html#/Create_Kmz/02r3000001tm000000/\n           for more information.\n        \"\"\"\n        kmlURL = self._url + \"/createKmz\"\n        params = {\n            \"f\" : \"json\",\n            \"kml\" : kmz_as_json\n        }\n        return self._post(url=kmlURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_url=self._proxy_url,\n                             proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproviding a dictionary representation of the object", "response": "def asDictionary(self):\n        \"\"\" provides a dictionary representation of the object \"\"\"\n        template = {\n            \"type\" : \"simple\",\n            \"symbol\" :  self._symbol.asDictionary,\n            \"label\" : self._label,\n            \"description\" : self._description,\n            \"rotationType\": self._rotationType,\n            \"rotationExpression\": self._rotationExpression\n        }\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef asDictionary(self):\n        template = {\n            \"type\" : \"uniqueValue\",\n            \"field1\" : self._field1,\n            \"field2\" : self._field2,\n            \"field3\" : self._field3,\n            \"fieldDelimiter\" : self._fieldDelimiter,\n            \"defaultSymbol\" :  self._defaultSymbol.asDictionary,\n            \"defaultLabel\" : self._defaultLabel,\n            \"uniqueValueInfos\" : self._uniqueValueInfos,\n            \"rotationType\": self._rotationType,\n            \"rotationExpression\": self._rotationExpression\n        }\n        return template", "response": "returns object as dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef searchDiagrams(self,whereClause=None,relatedObjects=None,\n                       relatedSchematicObjects=None):\n        \"\"\"\n        The Schematic Search Diagrams operation is performed on the schematic\n        service resource. The result of this operation is an array of Schematic\n        Diagram Information Object.\n\n        It is used to search diagrams in the schematic service by criteria;\n        that is, diagrams filtered out via a where clause on any schematic\n        diagram class table field, diagrams that contain schematic features\n        associated with a specific set of GIS features/objects, or diagrams\n        that contain schematic features associated with the same GIS features/\n        objects related to another set of schematic features.\n\n        Inputs:\n            whereClause - A where clause for the query filter. Any legal SQL\n                          where clause operating on the fields in the schematic\n                          diagram class table is allowed. See the Schematic\n                          diagram class table fields section below to know the\n                          exact list of field names that can be used in this\n                          where clause.\n            relatedObjects - An array containing the list of the GIS features/\n                             objects IDs per feature class/table name that are in\n                             relation with schematic features in the resulting\n                             queried diagrams. Each GIS feature/object ID\n                             corresponds to a value of the OBJECTID field in the\n                             GIS feature class/table.\n            relatedSchematicObjects - An array containing the list of the\n                                      schematic feature names per schematic\n                                      feature class ID that have the same\n                                      associated GIS features/objects with\n                                      schematic features in the resulting\n                                      queried diagrams. Each schematic feature\n                                      name corresponds to a value of the\n                                      SCHEMATICTID field in the schematic\n                                      feature class.\n        \"\"\"\n        params = {\"f\" : \"json\"}\n        if whereClause:\n            params[\"where\"] = whereClause\n        if relatedObjects:\n            params[\"relatedObjects\"] = relatedObjects\n        if relatedSchematicObjects:\n            params[\"relatedSchematicObjects\"] = relatedSchematicObjects\n\n        exportURL = self._url + \"/searchDiagrams\"\n        return self._get(url=exportURL,\n                         param_dict=params,\n                         securityHandler=self._securityHandler,\n                         proxy_url=self._proxy_url,\n                         proxy_port=self._proxy_port)", "response": "This operation searches the diagrams for the specified set of GIS features and objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassembling the server url", "response": "def _validateurl(self, url):\n        \"\"\"assembles the server url\"\"\"\n        parsed = urlparse(url)\n        path = parsed.path.strip(\"/\")\n        if path:\n            parts = path.split(\"/\")\n            url_types = (\"admin\", \"manager\", \"rest\")\n            if any(i in parts for i in url_types):\n                while parts.pop() not in url_types:\n                    next\n            elif \"services\" in parts:\n                while parts.pop() not in \"services\":\n                    next\n            path = \"/\".join(parts)\n        else:\n            path = \"arcgis\"\n        self._adminUrl = \"%s://%s/%s/admin\" % (parsed.scheme, parsed.netloc, path)\n        return \"%s://%s/%s/rest/services\" % (parsed.scheme, parsed.netloc, path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __init(self, folder='root'):\n        params = {\n            \"f\" : \"json\"\n        }\n        if folder == \"root\":\n            url = self.root\n        else:\n            url = self.location\n        json_dict = self._get(url=url,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        self._json_dict = json_dict\n        self._json = json.dumps(json_dict)\n        attributes = [attr for attr in dir(self)\n                      if not attr.startswith('__') and \\\n                      not attr.startswith('_')]\n        for k,v in json_dict.items():\n            if k == \"folders\":\n                pass\n            elif k in attributes:\n                setattr(self, \"_\"+ k, json_dict[k])\n            else:\n                print(\"%s - attribute not implemented in ags.Server class.\" % k)\n        json_dict = self._get(url=self.root,\n                                 param_dict=params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        for k,v in json_dict.items():\n            if k == 'folders':\n                v.insert(0, 'root')\n                setattr(self, \"_\"+ k, v)", "response": "loads the property data into the class"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an instance of AGSAdministration class", "response": "def admin(self):\n        \"\"\"points to the adminstrative side of ArcGIS Server\"\"\"\n        if self._securityHandler is None:\n            raise Exception(\"Cannot connect to adminstrative server without authentication\")\n        from ..manageags import AGSAdministration\n        return AGSAdministration(url=self._adminUrl,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port,\n                                 initialize=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the services in the current folder", "response": "def services(self):\n        \"\"\"gets the services in the current folder\"\"\"\n        services = []\n        if self._services is None:\n            self.__init()\n        for service in self._services:\n            url = \"%s/%s/%s\" % (self.root, service['name'], service['type'])\n            if service['type'] == \"GPServer\":\n                services.append(GPService(url=url,\n                                          securityHandler=self._securityHandler,\n                                          proxy_url=self._proxy_url,\n                                          proxy_port=self._proxy_port))\n            elif service['type'] == \"MapServer\":\n                services.append(MapService(url=url,\n                                           securityHandler=self._securityHandler,\n                                           proxy_url=self._proxy_url,\n                                           proxy_port=self._proxy_port))\n            elif service['type'] == \"ImageServer\":\n                services.append(ImageService(url=url,\n                                             securityHandler=self._securityHandler,\n                                             proxy_url=self._proxy_url,\n                                             proxy_port=self._proxy_port))\n            elif service['type'] == \"FeatureServer\":\n                if self.currentFolder == 'root':\n                    serviceName = service['name']\n                else:\n                    serviceName = service['name'].split('/')[1]\n                url = \"%s/%s/%s\" % (self.location, serviceName, service['type'])\n                services.append(FeatureService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_url=self._proxy_url,\n                                               proxy_port=self._proxy_port))\n            elif service['type'] == \"GeometryServer\":\n                url = \"%s/%s/%s\" % (self.root, service['name'], service['type'])\n                services.append(GeometryService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_url=self._proxy_url,\n                                               proxy_port=self._proxy_port))\n            elif service['type'] == \"MobileServer\":\n                services.append(MobileService(url=url,\n                                              securityHandler=self._securityHandler,\n                                              proxy_url=self._proxy_url,\n                                              proxy_port=self._proxy_port))\n            elif service['type'] == \"NAServer\":\n                services.append(NetworkService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_port=self._proxy_port,\n                                               proxy_url=self._proxy_url))\n            elif service['type'] == \"GeocodeServer\":\n                services.append(GeocodeService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_port=self._proxy_port,\n                                               proxy_url=self._proxy_url))\n            elif service['type'] == \"GeoDataServer\":\n                services.append(GeoDataService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_port=self._proxy_port,\n                                               proxy_url=self._proxy_url))\n            elif service['type'] == \"GlobeServer\":\n                services.append(GlobeService(url=url,\n                                               securityHandler=self._securityHandler,\n                                               proxy_port=self._proxy_port,\n                                               proxy_url=self._proxy_url))\n            elif service['type'] == \"StreamServer\":\n                services.append(StreamService(url=url,\n                                             securityHandler=self._securityHandler,\n                                             proxy_port=self._proxy_port,\n                                             proxy_url=self._proxy_url))                \n            elif service['type'] in (\"IndexGenerator\", \"IndexingLauncher\", \"SearchServer\"):\n                pass\n            else:\n                print (service['type'], service['name'])\n        return services"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef currentFolder(self, value):\n        if value in self.folders:\n            if value.lower() != 'root':\n                self._currentFolder = value\n                self._location = \"%s/%s\" % (self.root, value)\n            else:\n                self._currentFolder = value\n                self._location = self.root\n            self.__init(folder=value)", "response": "gets / sets the current folder name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addUser(self, username, password,\n                firstname, lastname,\n                email, role):\n        \"\"\"adds a user to the invitation list\"\"\"\n        self._invites.append({\n            \"username\":username,\n            \"password\":password,\n            \"firstname\":firstname,\n            \"lastname\":lastname,\n            \"fullname\":\"%s %s\" % (firstname, lastname),\n            \"email\":email,\n            \"role\":role\n        })", "response": "adds a user to the invitation list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef removeByIndex(self, index):\n        if index < len(self._invites) -1 and \\\n           index >=0:\n            self._invites.remove(index)", "response": "removes a user from the invitation list by position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef value(self):\n        val = {}\n        if self.sourcelocale is not None:\n            val['sourcelocale'] = self.sourcelocale\n        if self.geocodeServiceUrl is not None:\n            val['geocodeServiceUrl'] = self.geocodeServiceUrl\n        if self.sourcecountry is not None:\n            val['sourcecountry'] = self.sourcecountry\n        if self.sourcecountryhint is not None:\n            val['sourcecountryhint'] = self.sourcecountryhint\n        return val", "response": "returns object as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the portal properties object from a dictionary", "response": "def fromDictionary(value):\n        \"\"\"creates the portal properties object from a dictionary\"\"\"\n        if isinstance(value, dict):\n            pp = PortalParameters()\n            for k,v in value.items():\n                setattr(pp, \"_%s\" % k, v)\n            return pp\n        else:\n            raise AttributeError(\"Invalid input.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the class as a dictionary", "response": "def value(self):\n        \"\"\" returns the class as a dictionary \"\"\"\n        val = {}\n        for k in self.__allowed_keys:\n            v = getattr(self, \"_\" + k)\n            if v is not None:\n                val[k] = v\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value(self):\n        r = {}\n        attributes = [attr for attr in dir(self)\n                      if not attr.startswith('__') and \\\n                      not attr.startswith('_')]\n        for a in attributes:\n            if a != \"value\":\n                val = getattr(self, a)\n                if val is not None:\n                    r[a] = val\n        return r", "response": "returns the class as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef thumbnail(self, value):\n        if os.path.isfile(value) and \\\n           self._thumbnail != value:\n            self._thumbnail = value\n        elif value is None:\n            self._thumbnail = None", "response": "gets or sets the thumbnail of the item"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the values as a dictionary", "response": "def value(self):\n        \"\"\"returns the values as a dictionary\"\"\"\n        val = {}\n        for k in self.__allowed_keys:\n            value = getattr(self, \"_\" + k)\n            if value is not None:\n                val[k] = value\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef locationType(self, value):\n        if value.lower() in self._allowed_locationType and \\\n           self._locationType.lower() != value.lower():\n            self._locationType = value.lower()", "response": "sets the location type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hasStaticData(self, value):\n        if self._hasStaticData != value and \\\n           isinstance(value, bool):\n            self._hasStaticData = value", "response": "sets the hasStaticData property"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the object as a dictionary", "response": "def value(self):\n        \"\"\"returns the object as a dictionary\"\"\"\n        return {\n            \"hasStaticData\":self._hasStaticData,\n            \"name\":self._name,\n            \"maxRecordCount\":self._maxRecordCount,\n            \"layerInfo\":self._layerInfo\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vector_tile(self, level, row, column, out_folder=None):\n        url = \"{url}/tile/{level}/{row}/{column}.pdf\".format(url=self._url,\n                                                             level=level,\n                                                             row=row,\n                                                             column=column)\n        params = {}\n        if out_folder is None:\n            out_folder = tempfile.gettempdir()\n        return self._get(url=url,\n                         param_dict=params,\n                         out_folder=out_folder,\n                         securityHandler=self._securityHandler,\n                         proxy_port=self._proxy_port,\n                         proxy_url=self._proxy_host)", "response": "This resource represents a single vector tile for the map. The vector tile is returned in PBF format. The vector tile is returned in PBF format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(*argv):\n    try:\n        adminUsername = argv[0]\n        adminPassword = argv[1]\n        siteURL = argv[2]\n        username = argv[3]\n        groupName = argv[4]\n        #   Logic\n        #\n        #   Connect to AGOL\n        #\n        sh = arcrest.AGOLTokenSecurityHandler(adminUsername, adminPassword)\n        admin = arcrest.manageorg.Administration(securityHandler=sh)\n        #   Get the group ID\n        #\n        community = admin.community\n        groupId = community.getGroupIDs(groupNames=[groupName])[0]\n        #   Add the User to the Group\n        #\n        groups = community.groups\n        res = groups.group(groupId=groupId).addUsersToGroups(users=username)\n        if len(res['notAdded'] ) == 0:\n            arcpy.SetParameterAsText(5, True)\n        else:\n            arcpy.SetParameterAsText(5, False)\n    except arcpy.ExecuteError:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)\n        arcpy.AddError(\"ArcPy Error Message: %s\" % arcpy.GetMessages(2))\n    except FunctionError, f_e:\n        messages = f_e.args[0]\n        arcpy.AddError(\"error in function: %s\" % messages[\"function\"])\n        arcpy.AddError(\"error on line: %s\" % messages[\"line\"])\n        arcpy.AddError(\"error in file name: %s\" % messages[\"filename\"])\n        arcpy.AddError(\"with error message: %s\" % messages[\"synerror\"])\n        arcpy.AddError(\"ArcPy Error Message: %s\" % messages[\"arc\"])\n    except:\n        line, filename, synerror = trace()\n        arcpy.AddError(\"error on line: %s\" % line)\n        arcpy.AddError(\"error in file name: %s\" % filename)\n        arcpy.AddError(\"with error message: %s\" % synerror)", "response": "main entry point for the main driver of the program"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shareItemsToGroup(self, shareToGroupName, items=None, groups=None):\n        admin = None\n        userCommunity = None\n        group_ids = None\n        results = None\n        item = None\n        res = None\n        group = None\n        groupContent = None\n        result = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n\n            userCommunity = admin.community\n            group_ids = userCommunity.getGroupIDs(groupNames=shareToGroupName)\n            results = []\n            if not items is None:\n                for item in items:\n                    item = admin.content.getItem(itemId = item)\n                    res = item.shareItem(\",\".join(group_ids),everyone=False,org=False)\n                    if 'error' in res:\n                        print (res)\n                    else:\n                        print (\"'%s' shared with '%s'\" % (item.title,shareToGroupName))\n                    results.append(res)\n            if not groups is None:\n                for groupId in groups:\n                    group = admin.content.group(groupId=groupId)\n\n                    if group is None:\n                        print (\"Group with ID {0} was not found\".format(groupId))\n\n                    elif group.hasError() == True:\n                        print (\"Group with ID {0} returned the following error {1}\".format(groupId,group.error))\n                    else:\n                        for itemJSON in group.items:\n                            if 'id' in itemJSON:\n                                item = admin.content.getItem(itemId = itemJSON['id'])\n                                res = item.shareItem(\",\".join(group_ids),everyone=False,org=False)\n                                if 'error' in res:\n                                    print (res)\n                                elif res.get('notSharedWith', []):\n                                    print (\"'%s' shared with '%s', not Shared With '%s'\" % \\\n                                          (item.title,shareToGroupName,\",\".join(res['notSharedWith'])))\n                                else:\n                                    print (\"'%s' shared with '%s'\" % (item.title,shareToGroupName))\n                                results.append(res)\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"shareItemsToGroup\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            userCommunity = None\n            group_ids = None\n\n            item = None\n            res = None\n            group = None\n            groupContent = None\n            result = None\n\n            del admin\n            del userCommunity\n            del group_ids\n\n            del item\n            del res\n            del group\n            del groupContent\n            del result\n            gc.collect()", "response": "Share already published items with a group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the items owned by a group.", "response": "def getGroupContentItems(self, groupName):\n        \"\"\"Gets all the items owned by a group(s).\n        \n        Args:\n            groupName (list): The name of the group(s) from which to get items.\n        Returns:\n            list: A list of items belonging to the group(s).\n        Notes:\n            If you want to get items from a single group, ``groupName`` can be passed as a :py:obj:`str`.\n        See Also:\n            :py:func:`getGroupContent` for retrieving all content, not just items.\n        \n        \"\"\"\n        admin = None\n        userCommunity = None\n        groupIds = None\n        groupId = None\n\n        groupContent = None\n        result = None\n        item = None\n        items = []\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n\n            userCommunity = admin.community\n            groupIds = userCommunity.getGroupIDs(groupNames=groupName)\n            #groupContent = admin.query(q=\"group:\" + group_ids , bbox=None, start=1, num=100, sortField=None,\n                       #sortOrder=\"asc\")\n\n            if not groupIds is None:\n                for groupId in groupIds:\n                    groupContent = admin.content.groupContent(groupId=groupId)\n                    if 'error' in groupContent:\n                        print (groupContent)\n                    else:\n                        for result in groupContent['items']:\n                            item = admin.content.getItem(itemId = result['id'])\n                            items.append(item)\n            return items\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"getGroupContent\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                )\n        finally:\n            admin = None\n            userCommunity = None\n            groupIds = None\n            groupId = None\n            groupContent = None\n            result = None\n            item = None\n\n\n            del admin\n            del userCommunity\n            del groupIds\n            del groupId\n            del groupContent\n            del result\n            del item\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all the content belonging to a group.", "response": "def getGroupContent(self, groupName, onlyInOrg=False, onlyInUser=False):\n        \"\"\"Gets all the content from a group.\n        \n        Args:\n            groupName (str): The name of the group from which to get items.\n            onlyInOrg (bool): A boolean value to only return content belonging to the current org.\n                Defaults to ``False``.\n            onlyInUser (bool): A boolean value to only return content belonging to the current user\n                credentials. Defaults to ``False``.\n        Returns:\n            list: A list of content belonging to the group.        \n        See Also:\n            :py:func:`getGroupContentItems` for retrieving only items.\n            \n        \"\"\"\n        admin = None\n        groups = None\n        q = None\n        results = None\n        res = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n\n            groups = admin.community.groups\n            q = groupName\n            #if onlyInOrg is True:\n                #q += \" orgid: %s\" % admin.portals.portalSelf.id\n            if onlyInUser is True:\n                q += \" owner: %s\" % self._securityHandler.username\n            results = groups.search(q = q)\n            if 'total' in results and 'results' in results:\n                if results['total'] > 0:\n                    for res in results['results']:\n                        group = admin.content.group(groupId=res['id'])\n                        return group.items\n\n            return None\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"getGroupContent\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            groups = None\n            q = None\n            results = None\n            res = None\n\n            del admin\n            del groups\n            del q\n            del results\n            del res\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an item s thumbnail and saves it to disk.", "response": "def getThumbnailForItem(self, itemId, fileName, filePath):\n        \"\"\"Gets an item's thumbnail and saves it to disk.\n        \n        Args:\n            itemId (str): The item's ID.\n            fileName (str): The name of the output image.\n            fileName (str): The directory on disk where to save the thumbnail.\n        Returns:\n            dict: The result from :py:func:`arcrest.manageorg._content.UserItem.saveThumbnail`\n        \n        \"\"\"\n        admin = None\n        item = None\n\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            item = admin.content.getItem(itemId = itemId)\n            return item.saveThumbnail(fileName=fileName,filePath=filePath)\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"getThumbnailForItem\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            item = None\n            del admin\n            del item\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new group.", "response": "def createGroup(self,\n                    title,\n                    tags,\n                    description=\"\",\n                    snippet=\"\",\n                    phone=\"\",\n                    access=\"org\", sortField=\"title\",\n                    sortOrder=\"asc\", isViewOnly=False,\n                    isInvitationOnly=False, thumbnail=None):\n        \"\"\"Creates a new group.\n        \n        Args:\n            title (str): The name of the new group, limited to 250 characters.\n            tags (str): A comma delimited list of tag names.\n            description (str): A description of the group that can be any length.\n            snippet (str): Snippet or summary of the group that has a character limit of 250 characters.\n                Defaults to ``\"\"``.\n            phone (str): Group contact information, limited to 250 characters. Defaults to ``\"\"``.\n            access (str): Sets the access level for the group. Defaults to ``\"org\"``.\n            sortField (str): Sets sort field for group items. Defaults to ``\"title\"``.\n            sortOrder (str): Sets sort order for group items. Defaults to ``\"asc\"``.\n            isViewOnly (bool): A boolean value to create a view-only group with no sharing. Defaults to ``False``.\n            isInvitationOnly (bool): A boolean value to not accept join requests. Defaults to ``False``.\n            thumbnail (str): The full pathname to the group thumbnail to upload. Defaults to ``None``.\n        Returns:\n            If sucessful, the result from :py:func:`arcrest.manageorg._community.Community.createGroup`.\n            \n            If the group already exists or there is an error, ``None`` is returned.\n        \n        +------------+----------------------------------------------------------------+\n        | Parameters |                      Possible Values                           |\n        +------------+----------------------------------------------------------------+\n        | access     | ``private|org|public``                                         |\n        +------------+----------------------------------------------------------------+\n        | sortField  | ``title|owner|avgrating|numviews|created|modified``            |\n        +------------+----------------------------------------------------------------+\n        | sortOrder  | ``asc|desc``                                                   |\n        +------------+----------------------------------------------------------------+\n            \n        \"\"\"\n        admin = None\n        userCommunity = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            userCommunity = admin.community\n            try:\n                groupExist = userCommunity.getGroupIDs(groupNames=title)\n                if len(groupExist) > 0:\n                    print (\"Group '%s' already exists\" % title)\n                    return None\n                return userCommunity.createGroup(title=title,\n                            tags=tags,\n                            description=description,\n                            snippet=snippet,\n                            phone=phone,\n                            access=access,\n                            sortField=sortField,\n                            sortOrder=sortOrder,\n                            isViewOnly=isViewOnly,\n                            isInvitationOnly=isInvitationOnly,\n                            thumbnail=thumbnail)\n            except Exception as e:\n                print (e)\n                return None\n\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"createGroup\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            userCommunity = None\n\n\n            del admin\n            del userCommunity\n\n\n            gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createRole(self, name, description=\"\", privileges=None):\n        admin = None\n        portal = None\n        setPrivResults = None\n        roleID = None\n        createResults = None\n        try:\n            admin = arcrest.manageorg.Administration(securityHandler=self._securityHandler)\n            portal = admin.portals.portalSelf\n            try:\n                roleID = portal.roles.findRoleID(name)\n                if roleID is None:\n                    createResults = portal.createRole(name=name,description=description)\n                    if 'success' in createResults:\n                        if createResults['success'] == True:\n\n                            setPrivResults = portal.roles.setPrivileges(createResults['id'],privileges)\n                            if 'success' in setPrivResults:\n                                print (\"%s role created\" % name)\n                            else:\n                                print (setPrivResults)\n                        else:\n                            print (createResults)\n                    else:\n                        print (createResults)\n                else:\n                    print (\"'%s' role already exists\" % name)\n\n            except Exception as e:\n                print (e)\n                return None\n\n\n        except:\n            line, filename, synerror = trace()\n            raise common.ArcRestHelperError({\n                        \"function\": \"createGroup\",\n                        \"line\": line,\n                        \"filename\":  filename,\n                        \"synerror\": synerror,\n                                        }\n                                        )\n        finally:\n            admin = None\n            portal = None\n            setPrivResults = None\n            roleID = None\n            createResults = None\n\n            del admin\n            del portal\n            del setPrivResults\n            del roleID\n            del createResults\n\n            gc.collect()", "response": "Creates a new role."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef administration(self):\n        from ..manageags._services import AGSService\n        url = self._url\n        res = search(\"/rest/\", url).span()\n        addText = \"/admin/\"\n        part1 = url[:res[1]].lower().replace('/rest/', '')\n        part2 = url[res[1]:].lower().replace('/featureserver', \".mapserver\")\n        adminURL = \"%s%s%s\" % (part1, addText, part2)\n        return AGSService(url=adminURL,\n                          securityHandler=self._securityHandler,\n                          proxy_url=self._proxy_url,\n                          proxy_port=self._proxy_port,\n                          initialize=False)", "response": "returns the admin object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef layers(self):\n        if self._layers is None:\n            self.__init()\n        self._getLayers()\n        return self._layers", "response": "gets the layers for the feature service"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _getLayers(self):\n        params = {\"f\": \"json\"}\n\n        json_dict = self._get(self._url, params,\n                                 securityHandler=self._securityHandler,\n                                 proxy_url=self._proxy_url,\n                                 proxy_port=self._proxy_port)\n        self._layers = []\n        if 'layers' in json_dict:\n            for l in json_dict[\"layers\"]:\n                self._layers.append(\n                    layer.FeatureLayer(url=self._url + \"/%s\" % l['id'],\n                                       securityHandler=self._securityHandler,\n                                       proxy_port=self._proxy_port,\n                                       proxy_url=self._proxy_url)\n                )", "response": "gets the layers for the featuer service"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a feature layer object", "response": "def create_feature_layer(ds, sql, name=\"layer\"):\n    \"\"\" creates a feature layer object \"\"\"\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    result = arcpy.MakeFeatureLayer_management(in_features=ds,\n                                               out_layer=name,\n                                               where_clause=sql)\n    return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a feature class to JSON", "response": "def featureclass_to_json(fc):\n    \"\"\"converts a feature class to JSON\"\"\"\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    desc = arcpy.Describe(fc)\n    if desc.dataType == \"Table\" or desc.dataType == \"TableView\":\n        return recordset_to_json(table=fc)\n    else:\n        return arcpy.FeatureSet(fc).JSON"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_to_featureclass(json_file, out_fc):\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    return arcpy.JSONToFeatures_conversion(in_json_file=json_file,\n                                    out_features=out_fc)[0]", "response": "Converts a json file to a feature class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all the data to pass to a feature service", "response": "def get_attachment_data(attachmentTable, sql,\n                        nameField=\"ATT_NAME\", blobField=\"DATA\",\n                        contentTypeField=\"CONTENT_TYPE\",\n                        rel_object_field=\"REL_OBJECTID\"):\n    \"\"\" gets all the data to pass to a feature service \"\"\"\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    ret_rows = []\n    with arcpy.da.SearchCursor(attachmentTable,\n                               [nameField,\n                                blobField,\n                                contentTypeField,\n                                rel_object_field],\n                               where_clause=sql) as rows:\n        for row in rows:\n            temp_f = os.environ['temp'] + os.sep + row[0]\n            writer = open(temp_f,'wb')\n            writer.write(row[1])\n            writer.flush()\n            writer.close()\n            del writer\n            ret_rows.append({\n                \"name\" : row[0],\n                \"blob\" : temp_f,\n                \"content\" : row[2],\n                \"rel_oid\" : row[3]\n            })\n            del row\n    return ret_rows"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_records_with_attachments(attachment_table, rel_object_field=\"REL_OBJECTID\"):\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    OIDs = []\n    with arcpy.da.SearchCursor(attachment_table,\n                               [rel_object_field]) as rows:\n        for row in rows:\n            if not str(row[0]) in OIDs:\n                OIDs.append(\"%s\" % str(row[0]))\n            del row\n    del rows\n    return OIDs", "response": "returns a list of ObjectIDs for rows in the attachment table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_OID_field(fs):\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    desc = arcpy.Describe(fs)\n    if desc.hasOID:\n        return desc.OIDFieldName\n    return None", "response": "returns a featureset s object id field"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_feature_class(merges, out_fc, cleanUp=True):\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    if cleanUp == False:\n        if len(merges) == 0:\n            return None\n        elif len(merges) == 1:\n            desc = arcpy.Describe(merges[0])\n            if hasattr(desc, 'shapeFieldName'):\n                return arcpy.CopyFeatures_management(merges[0], out_fc)[0]\n            else:\n                return arcpy.CopyRows_management(merges[0], out_fc)[0]\n        else:\n            return arcpy.Merge_management(inputs=merges,\n                                          output=out_fc)[0]\n    else:\n        if len(merges) == 0:\n            return None\n        elif len(merges) == 1:\n            desc = arcpy.Describe(merges[0])\n            if hasattr(desc, 'shapeFieldName'):\n                merged = arcpy.CopyFeatures_management(merges[0], out_fc)[0]\n            else:\n                merged = arcpy.CopyRows_management(merges[0], out_fc)[0]\n        else:\n            merged = arcpy.Merge_management(inputs=merges,\n                                        output=out_fc)[0]\n        for m in merges:\n            arcpy.Delete_management(m)\n            del m\n        return merged", "response": "merges a list of featureclasses into a single featureclass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getDateFields(fc):\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    return [field.name for field in arcpy.ListFields(fc, field_type=\"Date\")]", "response": "Returns a list of date fields that are of type DATE"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert rows based on a list features object", "response": "def insert_rows(fc,\n                features,\n                fields,\n                includeOIDField=False,\n                oidField=None):\n    \"\"\" inserts rows based on a list features object \"\"\"\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    icur = None\n    if includeOIDField:\n        arcpy.AddField_management(fc, \"FSL_OID\", \"LONG\")\n        fields.append(\"FSL_OID\")\n    if len(features) > 0:\n        fields.append(\"SHAPE@\")\n        workspace = os.path.dirname(fc)\n        with arcpy.da.Editor(workspace) as edit:\n            date_fields = getDateFields(fc)\n            icur = arcpy.da.InsertCursor(fc, fields)\n            for feat in features:\n                row = [\"\"] * len(fields)\n                drow = feat.asRow[0]\n                dfields = feat.fields\n                for field in fields:\n                    if field in dfields or \\\n                       (includeOIDField and field == \"FSL_OID\"):\n                        if field in date_fields:\n                            row[fields.index(field)] = toDateTime(drow[dfields.index(field)])\n                        elif field == \"FSL_OID\":\n                            row[fields.index(\"FSL_OID\")] = drow[dfields.index(oidField)]\n                        else:\n                            row[fields.index(field)] = drow[dfields.index(field)]\n                    del field\n                row[fields.index(\"SHAPE@\")] = feat.geometry\n                icur.insertRow(row)\n                del row\n                del drow\n                del dfields\n                del feat\n            del features\n            icur = None\n            del icur\n            del fields\n        return fc\n    else:\n        return fc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_feature_class(out_path,\n                         out_name,\n                         geom_type,\n                         wkid,\n                         fields,\n                         objectIdField):\n    \"\"\" creates a feature class in a given gdb or folder \"\"\"\n    if arcpyFound == False:\n        raise Exception(\"ArcPy is required to use this function\")\n    arcpy.env.overwriteOutput = True\n    field_names = []\n    fc =arcpy.CreateFeatureclass_management(out_path=out_path,\n                                            out_name=out_name,\n                                            geometry_type=lookUpGeometry(geom_type),\n                                            spatial_reference=arcpy.SpatialReference(wkid))[0]\n    for field in fields:\n        if field['name'] != objectIdField:\n            field_names.append(field['name'])\n            arcpy.AddField_management(out_path + os.sep + out_name,\n                                      field['name'],\n                                      lookUpFieldType(field['type']))\n    return fc, field_names", "response": "creates a feature class in a given gdb or folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts ArcGIS REST field types to Python types", "response": "def lookUpFieldType(field_type):\n    \"\"\" Converts the ArcGIS REST field types to Python Types\n        Input:\n           field_type - string - type of field as string\n        Output:\n           Python field type as string\n    \"\"\"\n    if field_type == \"esriFieldTypeDate\":\n        return \"DATE\"\n    elif field_type == \"esriFieldTypeInteger\":\n        return \"LONG\"\n    elif field_type == \"esriFieldTypeSmallInteger\":\n        return \"SHORT\"\n    elif field_type == \"esriFieldTypeDouble\":\n        return \"DOUBLE\"\n    elif field_type == \"esriFieldTypeString\":\n        return \"TEXT\"\n    elif field_type == \"esriFieldTypeBlob\":\n        return \"BLOB\"\n    elif field_type == \"esriFieldTypeSingle\":\n        return \"FLOAT\"\n    elif field_type == \"esriFieldTypeRaster\":\n        return \"RASTER\"\n    elif field_type == \"esriFieldTypeGUID\":\n        return \"GUID\"\n    elif field_type == \"esriFieldTypeGlobalID\":\n        return \"TEXT\"\n    else:\n        return \"TEXT\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload arcrest to disk", "response": "def download_arcrest():\n\n    \"\"\"downloads arcrest to disk\"\"\"\n    arcrest_name = \"arcrest.zip\"\n    arcresthelper_name = \"arcresthelper.zip\"\n    url = \"https://github.com/Esri/ArcREST/archive/master.zip\"\n    file_name = os.path.join(arcpy.env.scratchFolder, os.path.basename(url))\n    scratch_folder = os.path.join(arcpy.env.scratchFolder, \"temp34asdf3d\")\n    arcrest_zip = os.path.join(scratch_folder, arcrest_name )\n    arcresthelper_zip = os.path.join(scratch_folder, arcresthelper_name)\n    if sys.version_info.major == 3:\n        import urllib.request\n        urllib.request.urlretrieve(url, file_name)\n    else:\n        import urllib\n        urllib.urlretrieve(url, file_name)\n    if os.path.isdir(scratch_folder):\n        shutil.rmtree(scratch_folder)\n    os.makedirs(scratch_folder)\n    zip_obj = zipfile.ZipFile(file_name, 'r')\n    zip_obj.extractall(scratch_folder)\n    zip_obj.close()\n    del zip_obj\n    zip_obj = zipfile.ZipFile(arcrest_zip, 'w')\n    zipws(path=os.path.join(scratch_folder, \"arcrest-master\", \"src\", \"arcrest\"), zip=zip_obj, keep=True)\n    zip_obj.close()\n    del zip_obj\n    zip_obj = zipfile.ZipFile(arcresthelper_zip, 'w')\n    zipws(path=os.path.join(scratch_folder, \"arcrest-master\", \"src\", \"arcresthelper\"), zip=zip_obj, keep=True)\n    zip_obj.close()\n    del zip_obj\n    shutil.rmtree(os.path.join(scratch_folder, \"arcrest-master\"))\n    return arcrest_zip, arcresthelper_zip"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a token for a feature service", "response": "def _generateForTokenSecurity(self):\n        \"\"\" generates a token for a feature service \"\"\"\n        agolToken = self._agolSecurityHandler.token\n        url = self._url + \"/getProxyUserToken\"\n        params = {\"token\" : self._agolSecurityHandler.token,\n                  \"contributorUid\" : self._contributionUID}\n        res = self._post(url=url, param_dict=params,\n                         additional_headers={ \"Referer\": self._agolSecurityHandler._referer_url},\n                         proxy_port=self._proxy_port,\n                         proxy_url=self._proxy_url)\n        return res['token']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _initURL(self,\n                 org_url,\n                 referer_url):\n        \"\"\" sets proper URLs for AGOL \"\"\"\n\n\n        if org_url is not None and org_url != '':\n            if not org_url.startswith('http://') and not org_url.startswith('https://'):\n                org_url = 'https://' + org_url\n            self._org_url = org_url\n\n        if self._org_url.lower().find('/sharing/rest') > -1:\n            self._url = self._org_url\n        else:\n            self._url = self._org_url + \"/sharing/rest\"\n\n        if self._url.startswith('http://'):\n            self._surl = self._url.replace('http://', 'https://')\n        else:\n            self._surl = self._url\n\n        parsed_url = urlparse(self._org_url)\n        self._parsed_org_url = urlunparse((parsed_url[0],parsed_url[1],\"\",\"\",\"\",\"\"))#added 7/15/2015\n\n        if referer_url is None:\n            self._referer_url = parsed_url.netloc", "response": "sets proper URLs for AGOL"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting or sets the username", "response": "def username(self, value):\n        \"\"\"gets/sets the username\"\"\"\n        if isinstance(value, str):\n            self._username = value\n            self._handler = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef password(self, value):\n        if isinstance(value, str):\n            self._password = value\n            self._handler = None", "response": "gets or sets the current password"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef portalServerHandler(self, serverUrl, username=None):\n\n\n        from ..manageorg import Administration\n        admin = Administration(url=self._org_url,\n                               securityHandler=self,\n                               proxy_url=self._proxy_url,\n                               proxy_port=self._proxy_port)\n\n        token_url = admin.tokenURL\n\n        if username is None:\n            username = self._login_username\n\n        ptsh = PortalTokenSecurityHandler(username=username,\n                                          password=self._password,\n                                          org_url=self._org_url,\n                                          token_url=token_url,\n                                          proxy_url=self._proxy_url,\n                                          proxy_port=self._proxy_port,\n                                          jar=self.cookiejar,\n                                          handler=self.handler)\n\n        pssh = PortalServerSecurityHandler(tokenHandler=ptsh,\n                                           serverUrl=serverUrl,\n                                           referer=self._referer_url,\n                                           jar=self.cookiejar,\n                                           handler=self.handler)\n\n\n        return pssh", "response": "Returns a handler to access a federated server and a portal token security handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handler(self):\n        if hasNTLM:\n            if self._handler is None:\n                passman = request.HTTPPasswordMgrWithDefaultRealm()\n                passman.add_password(None, self._parsed_org_url, self._login_username, self._password)\n                self._handler = HTTPNtlmAuthHandler.HTTPNtlmAuthHandler(passman)\n            return self._handler\n        else:\n            raise Exception(\"Missing Ntlm python package.\")", "response": "gets the security handler for the class"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _initURL(self,\n                 org_url,\n                 referer_url):\n        \"\"\" sets proper URLs for AGOL \"\"\"\n        if org_url is not None and org_url != '':\n            if not org_url.startswith('http://') and not org_url.startswith('https://'):\n                org_url = 'https://' + org_url\n            self._org_url = org_url\n\n            if self._org_url.lower().find('/sharing/rest') > -1:\n                self._url = self._org_url\n            else:\n                self._url = self._org_url + \"/sharing/rest\"\n\n            if self._url.startswith('http://'):\n                self._surl = self._url.replace('http://', 'https://')\n            else:\n                self._surl = self._url\n\n            parsed_url = urlparse(self._org_url)\n            self._parsed_org_url = urlunparse((parsed_url[0],parsed_url[1],\"\",\"\",\"\",\"\"))\n\n        if referer_url is None:\n            parsed_org = urlparse(self._org_url)\n            self._referer_url = parsed_org.netloc\n\n            url = '{}/portals/self'.format( self._url)\n\n        parameters = {\n            'f': 'json'\n        }\n        portal_info = self._post(url=url,\n                                 param_dict=parameters,\n                                 securityHandler=self,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n        if 'user' in portal_info:\n            if 'username' in portal_info['user']:\n                self._username = portal_info['user']['username']", "response": "sets proper URLs for AGOL"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef certificate(self, value):\n        import os\n        if os.path.isfile(value):\n            self._certificatefile = value", "response": "gets or sets the certificate file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef key_file(self, value):\n        import os\n        if os.path.isfile(value):\n            self._keyfile = value", "response": "gets or sets the certificate file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _initURL(self, serverUrl=None):\n        self._serverUrl = serverUrl\n\n        parsed_url = urlparse(self._serverUrl)\n        self._parsed_org_url = urlunparse((parsed_url[0],parsed_url[1],\"\",\"\",\"\",\"\"))\n        self._referer = parsed_url.netloc", "response": "sets proper URLs for AGOL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the AGS server token", "response": "def token(self):\n        \"\"\"gets the AGS server token\"\"\"\n        return self._portalTokenHandler.servertoken(serverURL=self._serverUrl,\n                                                    referer=self._referer)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serverUrl(self, value):\n        if value.lower() != self._serverUrl.lower():\n            self._serverUrl = value", "response": "sets the server url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef referer(self, value):\n        if value is not None and \\\n           self._referer is not None and \\\n           self._referer.lower() != value.lower():\n            self._referer = value", "response": "sets the referer object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef token(self):\n        if self._token is None or \\\n           datetime.datetime.now() >= self._token_expires_on:\n            self._generateForOAuthSecurity(self._client_id,\n                                           self._secret_id,\n                                           self._token_url)\n        return self._token", "response": "obtains a token from the site"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _generateForOAuthSecurity(self, client_id,\n                                  secret_id, token_url=None):\n        \"\"\" generates a token based on the OAuth security model \"\"\"\n        grant_type=\"client_credentials\"\n        if token_url is None:\n            token_url = \"https://www.arcgis.com/sharing/rest/oauth2/token\"\n        params = {\n            \"client_id\" : client_id,\n            \"client_secret\" : secret_id,\n            \"grant_type\":grant_type,\n            \"f\" : \"json\"\n        }\n        token = self._post(url=token_url,\n                              param_dict=params,\n                              securityHandler=None,\n                              proxy_port=self._proxy_port,\n                              proxy_url=self._proxy_url)\n        if 'access_token' in token:\n            self._token = token['access_token']\n            self._expires_in = token['expires_in']\n            self._token_created_on = datetime.datetime.now()\n            self._token_expires_on = self._token_created_on + datetime.timedelta(seconds=int(token['expires_in']))\n            self._valid = True\n            self._message = \"Token Generated\"\n        else:\n            self._token = None\n            self._expires_in = None\n            self._token_created_on = None\n            self._token_expires_on = None\n            self._valid = False\n            self._message = token", "response": "Generates a token based on the OAuth security model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets proper URLs for AGOL", "response": "def _initURL(self):\n        \"\"\" sets proper URLs for AGOL \"\"\"\n\n        token = self._getTokenArcMap()\n        if 'error' in token:\n            self._valid = False\n            self._message = token['error']\n        else:\n            self._valid = True\n            self._message = \"Token Generated\"\n        self._org_url = arcpy.GetActivePortalURL()\n        if self._org_url.lower().find('/sharing/rest') > -1:\n            self._url = self._org_url\n        else:\n            self._url = self._org_url + \"/sharing/rest\"\n\n        if self._url.startswith('http://'):\n            self._surl = self._url.replace('http://', 'https://')\n        else:\n            self._surl  =  self._url\n\n        url = '{}/portals/self'.format( self._url)\n\n        parameters = {\n            'f': 'json'\n        }\n        portal_info = self._post(url=url,\n                                 param_dict=parameters,\n                                 securityHandler=self,\n                                 proxy_port=self._proxy_port,\n                                 proxy_url=self._proxy_url)\n\n        if 'user' in portal_info:\n            if 'username' in portal_info['user']:\n                self._username = portal_info['user']['username']\n\n\n        results = self._get(url= self._surl + '/portals/info',\n                               param_dict={'f':'json'},\n                               proxy_port=self._proxy_port,\n                               proxy_url=self._proxy_url)\n        if 'authInfo' in results and 'tokenServicesUrl' in results['authInfo']:\n\n            self._token_url = results['authInfo']['tokenServicesUrl']\n        else:\n            self._token_url = self._surl  + '/generateToken'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef referer_url(self, value):\n        if self._referer_url != value:\n            self._token = None\n            self._referer_url = value", "response": "sets the referer url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the token for the site", "response": "def token(self):\n        \"\"\" returns the token for the site \"\"\"\n        if self._token is None or \\\n           datetime.datetime.now() >= self._token_expires_on:\n            result = self._getTokenArcMap()\n            if 'error' in result:\n                self._valid = False\n                self._message = result\n            else:\n                self._valid = True\n                self._message = \"Token Generated\"\n        return self._token"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets proper URLs for AGOL", "response": "def _initURL(self, org_url=None,\n                 token_url=None,\n                 referer_url=None):\n        \"\"\" sets proper URLs for AGOL \"\"\"\n        if org_url is not None and org_url != '':\n            if not org_url.startswith('http://') and not org_url.startswith('https://'):\n                org_url = 'http://' + org_url\n            self._org_url = org_url\n        if not self._org_url.startswith('http://') and not self._org_url.startswith('https://'):\n            self._org_url = 'http://' + self._org_url\n\n        if self._org_url.lower().find('/sharing/rest') > -1:\n            self._url = self._org_url\n        else:\n            self._url = self._org_url + \"/sharing/rest\"\n\n        if self._url.startswith('http://'):\n            self._surl = self._url.replace('http://', 'https://')\n        else:\n            self._surl  =  self._url\n\n        if token_url is None:\n\n            results = self._get(url= self._surl + '/info',\n                                   param_dict={'f':'json'},\n                                   proxy_port=self._proxy_port,\n                                   proxy_url=self._proxy_url)\n            if 'authInfo' in results and 'tokenServicesUrl' in results['authInfo']:\n\n                self._token_url = results['authInfo']['tokenServicesUrl']\n            else:\n                self._token_url = self._surl  + '/generateToken'\n\n        else:\n            self._token_url = token_url\n        parsed_url = urlparse(self._org_url)\n        self._parsed_org_url = urlunparse((parsed_url[0],parsed_url[1],\"\",\"\",\"\",\"\"))\n\n        if referer_url is None:\n            self._referer_url = parsed_url.netloc"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the referer url for the token handler", "response": "def __getRefererUrl(self, url=None):\n        \"\"\"\n        gets the referer url for the token handler\n        \"\"\"\n        if url is None:\n            url = \"http://www.arcgis.com/sharing/rest/portals/self\"\n        params = {\n            \"f\" : \"json\",\n            \"token\" : self.token\n        }\n        val = self._get(url=url, param_dict=params,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        self._referer_url = \"arcgis.com\"#\"http://%s.%s\" % (val['urlKey'], val['customBaseUrl'])\n        self._token = None\n        return self._referer_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generateForTokenSecurity(self,\n                                  username,\n                                  password,\n                                  referer=None,\n                                  tokenUrl=None,\n                                  expiration=None,\n                                  proxy_url=None,\n                                  proxy_port=None):\n        \"\"\" generates a token for a feature service \"\"\"\n        if referer is None:\n            referer = self._referer_url\n        if tokenUrl is None:\n            tokenUrl  = self._token_url\n\n        query_dict = {'username': self._username,\n                      'password': self._password,\n                      'expiration': str(_defaultTokenExpiration),\n                      'referer': referer,\n                      'f': 'json'}\n        if expiration is not None:\n            query_dict['expiration'] = str(expiration)\n        self._token_created_on = datetime.datetime.now()\n        token = self._post(url=tokenUrl,\n                              param_dict=query_dict,\n                              securityHandler=None,\n                              proxy_port=self._proxy_port,\n                              proxy_url=self._proxy_url)\n        if 'error' in token:\n            self._token = None\n            return token\n\n\n        self._token_expires_on = datetime.datetime.fromtimestamp(token['expires'] / 1000) - \\\n            datetime.timedelta(seconds=10)\n        if \"token\" not in token:\n            self._token = None\n            return None\n        else:\n            httpPrefix = self._url\n            if token['ssl'] == True:\n                httpPrefix = self._surl\n            self._token = token['token']\n            return token['token'], httpPrefix", "response": "Generates a token for a feature service"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef token(self):\n        if self._token is None or \\\n           datetime.datetime.now() >= self._token_expires_on:\n            if self._referer_url is None:\n                self._generateForTokenSecurity(username=self._username,\n                                           password=self._password,\n                                           tokenUrl=self._token_url)\n            else:\n                self._generateForTokenSecurity(username=self._username,\n                                               password=self._password,\n                                               tokenUrl=self._token_url,\n                                               client=\"referer\")\n        return self._token", "response": "returns the token for the site"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef token(self):\n        if self._token is None or \\\n           datetime.datetime.now() >= self._token_expires_on:\n            if self._referer_url is None:\n                result = self._generateForTokenSecurity(username=self._username,\n                                                    password=self._password,\n                                                    tokenUrl=self._token_url)\n            else:\n                result = self._generateForTokenSecurity(username=self._username,\n                                                        password=self._password,\n                                                        tokenUrl=self._token_url,\n                                                        client=\"referer\")\n            if 'error' in result:\n                self._valid = False\n                self._message = result\n            else:\n                self._valid = True\n                self._message = \"Token Generated\"\n        return self._token", "response": "returns the token for the site"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the server token for the server", "response": "def servertoken(self,serverURL,referer):\n        \"\"\" returns the server token for the server \"\"\"\n        if self._server_token is None or self._server_token_expires_on is None or \\\n           datetime.datetime.now() >= self._server_token_expires_on or \\\n           self._server_url != serverURL:\n            self._server_url = serverURL\n            result = self._generateForServerTokenSecurity(serverURL=serverURL,\n                                                          token=self.token,\n                                                          tokenUrl=self._token_url,\n                                                          referer=referer)\n            if 'error' in result:\n                self._valid = False\n                self._message = result\n            else:\n                self._valid = True\n                self._message = \"Server Token Generated\"\n        return self._server_token"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a token for a feature service.", "response": "def _generateForServerTokenSecurity(self,\n                                        serverURL,\n                                        token,\n                                        tokenUrl,\n                                        referer,\n                                        expiration=None\n                                        ):\n        \"\"\" generates a token for a feature service \"\"\"\n\n        query_dict = {'serverURL':serverURL,\n                      'token': token,\n                      'expiration':str(_defaultTokenExpiration),\n                      'f': 'json',\n                      'request':'getToken',\n                      'referer':referer}\n        if expiration is not None:\n            query_dict['expiration'] = expiration\n        secHandler = None\n\n        if self.cookiejar is not None:\n            secHandler = self\n            if secHandler is not None:\n                secHandler._method = \"HANDLER\"\n\n        server_token = self._post(url=tokenUrl,\n                                  param_dict=query_dict,\n                                  securityHandler=secHandler,\n                                  proxy_port=self._proxy_port,\n                                  proxy_url=self._proxy_url)\n        if self.cookiejar is not None:\n            if secHandler is not None:\n                secHandler._method = \"TOKEN\"\n\n        if 'error' in server_token:\n            self._server_token = None\n            self._server_token_created_on = None\n            self._server_token_expires_on = None\n            self._server_expires_in = None\n\n            return server_token\n\n        else:\n            self._server_token = server_token['token']\n            self._server_token_created_on = datetime.datetime.now()\n\n            self._server_token_expires_on = datetime.datetime.fromtimestamp(server_token['expires'] /1000) - \\\n                datetime.timedelta(seconds=1)\n            self._server_expires_in = (self._server_token_expires_on - self._server_token_created_on).total_seconds()\n            return server_token['token']"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a token for a feature service", "response": "def _generateForTokenSecurity(self,\n                                  username, password,\n                                  tokenUrl,\n                                  expiration=None,\n                                  client='requestip'):\n        \"\"\" generates a token for a feature service \"\"\"\n\n        query_dict = {'username': username,\n                      'password': password,\n                      'expiration':str(_defaultTokenExpiration),\n                      'client': client,\n                      'f': 'json'}\n        if client == \"referer\":\n            query_dict['referer'] = self._referer_url\n        if expiration is not None:\n            query_dict['expiration'] = expiration\n\n        secHandler = None\n        if self.cookiejar is not None:\n            secHandler = self\n            if secHandler is not None:\n                secHandler._method = \"HANDLER\"\n        token = self._post(url=tokenUrl,\n                           param_dict=query_dict,\n                           securityHandler=secHandler,\n                           proxy_port=self._proxy_port,\n                           proxy_url=self._proxy_url)\n        if self.cookiejar is not None:\n            if secHandler is not None:\n                secHandler._method = \"TOKEN\"\n        if 'error' in token:\n            self._token = None\n            self._token_created_on = None\n            self._token_expires_on = None\n            self._expires_in = None\n\n            return token\n        elif 'status' in token:\n            self._token = None\n            self._token_created_on = None\n            self._token_expires_on = None\n            self._expires_in = None\n            #print token['message']\n            return token\n\n        else:\n            self._token = token['token']\n            self._token_created_on = datetime.datetime.now()\n            self._token_expires_on = datetime.datetime.fromtimestamp(token['expires'] /1000) - \\\n                datetime.timedelta(seconds=1)\n            self._expires_in = (self._token_expires_on - self._token_created_on).total_seconds()\n            return token['token']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a handler to access a federated server and a portal serverSecurityHandler object.", "response": "def portalServerHandler(self, serverUrl, username=None):\n        \"\"\"\n        returns a handler to access a federated server\n\n        serverUrl - url to the server. Example:\n                    https://server.site.com/arcgis\n        username - the portal site username. if None is passed, it obtains\n         it from the portal properties\n        Outout:\n          returns a PortalServerSecurityHandler object\n\n        Usage:\n        >>> # access the administration site\n        >>> serverUrl=\"https://mysite.site.com/arcgis\"\n        >>> newSH = sh.portalServerHandler(serverUrl=serverUrl,\n                                           username=None)\n        >>> agsAdmin = AGSAdministration(url=serverUrl, securityHandler=newSH)\n        >>> print agsAdmin.info\n        >>> # access a secure service from portal handler\n        >>> msUrl = \"https://mysite.site.com:6443/arcgis/rest/services/SampleWorldCities/MapServer\"\n        >>> ms = arcrest.ags.MapService(url=msUrl, securityHandler=newSH)\n        >>> print ms.mapName\n        \"\"\"\n\n        pssh = PortalServerSecurityHandler(tokenHandler=self,\n                                           serverUrl=serverUrl,\n                                           referer=self._referer_url)\n\n\n        return pssh"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getMachine(self, machineName):\n        url = self._url + \"/%s\" % machineName\n        return Machine(url=url,\n                       securityHandler=self._securityHandler,\n                       initialize=True,\n                       proxy_url=self._proxy_url,\n                       proxy_port=self._proxy_port)", "response": "returns a machine object for a given machineName"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef renameMachine(self, machineName, newMachineName):\n        params = {\n            \"f\" : \"json\",\n            \"machineName\" : machineName,\n            \"newMachineName\" : newMachineName\n        }\n        uURL = self._url + \"/rename\"\n        return self._post(url=uURL, param_dict=params,\n                             securityHandler=self._securityHandler,\n                             proxy_port=self._proxy_port,\n                             proxy_url=self._proxy_url                             )", "response": "This operation renames the server machine configuration. The server will be restarted if the server is restarted and the server is restarted. The server will be restarted if the server is restarted."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the SSL Certificates for a given machine", "response": "def exportCertificate(self, certificate, folder):\n        \"\"\"gets the SSL Certificates for a given machine\"\"\"\n        url = self._url + \"/sslcertificates/%s/export\" % certificate\n        params = {\n            \"f\" : \"json\",\n        }\n        return self._get(url=url,\n                         param_dict=params,\n                        out_folder=folder)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef asDictionary(self):\n        if self._json_dict is None:\n            self.__init(url=self._url)\n        return self._json_dict", "response": "returns object as a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the current version of the site", "response": "def currentVersion(self):\n        \"\"\" returns the current version of the site \"\"\"\n        if self._currentVersion is None:\n            self.__init(self._url)\n        return self._currentVersion"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef portals(self):\n        url = \"%s/portals\" % self.root\n        return _portals.Portals(url=url,\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)", "response": "returns the Portals class that provides administration access to a given organization"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef oauth2(self):\n        if self._url.endswith(\"/oauth2\"):\n            url = self._url\n        else:\n            url = self._url + \"/oauth2\"\n        return _oauth2.oauth2(oauth_url=url,\n                              securityHandler=self._securityHandler,\n                              proxy_url=self._proxy_url,\n                              proxy_port=self._proxy_port)", "response": "returns the oauth2 class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef community(self):\n        return _community.Community(url=self._url + \"/community\",\n                                    securityHandler=self._securityHandler,\n                                    proxy_url=self._proxy_url,\n                                    proxy_port=self._proxy_port)", "response": "returns the community root"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn access into the site s content", "response": "def content(self):\n        \"\"\"returns access into the site's content\"\"\"\n        return _content.Content(url=self._url + \"/content\",\n                                securityHandler=self._securityHandler,\n                                proxy_url=self._proxy_url,\n                                proxy_port=self._proxy_port)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self,\n              q,\n              t=None,\n              focus=None,\n              bbox=None,\n              start=1,\n              num=10,\n              sortField=None,\n              sortOrder=\"asc\",\n              useSecurity=True):\n        \"\"\"\n        This operation searches for content items in the portal. The\n        searches are performed against a high performance index that\n        indexes the most popular fields of an item. See the Search\n        reference page for information on the fields and the syntax of the\n        query.\n        The search index is updated whenever users add, update, or delete\n        content. There can be a lag between the time that the content is\n        updated and the time when it's reflected in the search results.\n        The results of a search only contain items that the user has\n        permission to access.\n\n        Inputs:\n           q - The query string used to search\n           t - type of content to search for.\n           focus - another content filter. Ex: files\n           bbox - The bounding box for a spatial search defined as minx,\n                  miny, maxx, or maxy. Search requires q, bbox, or both.\n                  Spatial search is an overlaps/intersects function of the\n                  query bbox and the extent of the document.\n                  Documents that have no extent (e.g., mxds, 3dds, lyr)\n                  will not be found when doing a bbox search.\n                  Document extent is assumed to be in the WGS84 geographic\n                  coordinate system.\n           start -  The number of the first entry in the result set\n                    response. The index number is 1-based.\n                    The default value of start is 1 (that is, the first\n                    search result).\n                    The start parameter, along with the num parameter, can\n                    be used to paginate the search results.\n           num - The maximum number of results to be included in the result\n                 set response.\n                 The default value is 10, and the maximum allowed value is\n                 100.\n                 The start parameter, along with the num parameter, can be\n                 used to paginate the search results.\n           sortField - Field to sort by. You can also sort by multiple\n                       fields (comma separated) for an item.\n                       The allowed sort field names are title, created,\n                       type, owner, modified, avgRating, numRatings,\n                       numComments, and numViews.\n           sortOrder - Describes whether the results return in ascending or\n                       descending order. Default is ascending.\n                       Values: asc | desc\n           useSecurity - boolean value that determines if the security\n                         handler object's token will be appended on the\n                         search call.  If the value is set to False, then\n                         the search will be performed without\n                         authentication.  This means only items that have\n                         been shared with everyone on AGOL or portal site\n                         will be found.  If it is set to True, then all\n                         items the user has permission to see based on the\n                         query passed will be returned.\n           Output:\n             returns a list of dictionary\n        \"\"\"\n        if self._url.endswith(\"/rest\"):\n            url = self._url + \"/search\"\n        else:\n            url = self._url + \"/rest/search\"\n\n        params = {\n            \"f\" : \"json\",\n            \"q\" : q,\n            \"sortOrder\" : sortOrder,\n            \"num\" : num,\n            \"start\" : start,\n            'restrict' : useSecurity\n        }\n        if not focus is None:\n            params['focus'] = focus\n        if not t is None:\n            params['t'] = t\n        if useSecurity and \\\n           self._securityHandler is not None and \\\n           self._securityHandler.method == \"token\":\n            params[\"token\"] = self._securityHandler.token\n        if sortField is not None:\n            params['sortField'] = sortField\n        if bbox is not None:\n            params['bbox'] = bbox\n\n        return self._get(url=url,\n                        param_dict=params,\n                        securityHandler=self._securityHandler,\n                        proxy_url=self._proxy_url,\n                        proxy_port=self._proxy_port)", "response": "This operation searches for content items in the portal."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hostingServers(self):\n        portals = self.portals\n        portal = portals.portalSelf\n        urls = portal.urls\n        if 'error' in urls:\n            print( urls)\n            return\n\n        services = []\n        if urls != {}:\n            if 'urls' in urls:\n                if 'features' in urls['urls']:\n                    if 'https' in urls['urls']['features']:\n                        for https in urls['urls']['features']['https']:\n                            if portal.isPortal == True:\n\n                                url = \"%s/admin\" % https\n                                #url = https\n                                services.append(AGSAdministration(url=url,\n                                             securityHandler=self._securityHandler,\n                                             proxy_url=self._proxy_url,\n                                             proxy_port=self._proxy_port))\n\n                            else:\n                                url = \"https://%s/%s/ArcGIS/rest/admin\" % (https, portal.portalId)\n                                services.append(Services(url=url,\n                                             securityHandler=self._securityHandler,\n                                             proxy_url=self._proxy_url,\n                                             proxy_port=self._proxy_port))\n                    elif 'http' in urls['urls']['features']:\n                        for http in urls['urls']['features']['http']:\n\n                            if (portal.isPortal == True):\n                                url = \"%s/admin\" % http\n                                services.append(AGSAdministration(url=url,\n                                                                  securityHandler=self._securityHandler,\n                                                                  proxy_url=self._proxy_url,\n                                                                  proxy_port=self._proxy_port,\n                                                                  initialize=True))\n\n                            else:\n                                url = \"http://%s/%s/ArcGIS/rest/admin\" % (http, portal.portalId)\n                                services.append(Services(url=url,\n                                                          securityHandler=self._securityHandler,\n                                                          proxy_url=self._proxy_url,\n                                                          proxy_port=self._proxy_port))\n\n                    else:\n                        print( \"Publishing servers not found\")\n                else:\n                    print (\"Publishing servers not found\")\n            else:\n                print( \"Publishing servers not found\")\n            return services\n        else:\n            for server in portal.servers['servers']:\n                url = server['adminUrl'] + \"/admin\"\n                sh = PortalServerSecurityHandler(tokenHandler=self._securityHandler,\n                                                   serverUrl=url,\n                                                   referer=server['name'].replace(\":6080\", \":6443\")\n                                                   )\n                services.append(\n                    AGSAdministration(url=url,\n                                      securityHandler=sh,\n                                      proxy_url=self._proxy_url,\n                                      proxy_port=self._proxy_port,\n                                      initialize=False)\n                    )\n            return services", "response": "Returns the objects to manage site s hosted services."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef editLogSettings(self,\n                        logLevel=\"WARNING\",\n                        logDir=None,\n                        maxLogFileAge=90,\n                        maxErrorReportsCount=10):\n        \"\"\"\n           The log settings are for the entire site.\n           Inputs:\n             logLevel -  Can be one of [OFF, SEVERE, WARNING, INFO, FINE,\n                         VERBOSE, DEBUG].\n             logDir - File path to the root of the log directory\n             maxLogFileAge - number of days that a server should save a log\n                             file.\n             maxErrorReportsCount - maximum number of error report files\n                                    per machine\n        \"\"\"\n        lURL = self._url + \"/settings/edit\"\n        allowed_levels =  (\"OFF\", \"SEVERE\", \"WARNING\", \"INFO\", \"FINE\", \"VERBOSE\", \"DEBUG\")\n        currentSettings= self.logSettings\n        currentSettings[\"f\"] =\"json\"\n\n        if logLevel.upper() in allowed_levels:\n            currentSettings['logLevel'] = logLevel.upper()\n        if logDir is not None:\n            currentSettings['logDir'] = logDir\n        if maxLogFileAge is not None and \\\n           isinstance(maxLogFileAge, int):\n            currentSettings['maxLogFileAge'] = maxLogFileAge\n        if maxErrorReportsCount is not None and \\\n           isinstance(maxErrorReportsCount, int) and\\\n           maxErrorReportsCount > 0:\n            currentSettings['maxErrorReportsCount'] = maxErrorReportsCount\n        return self._post(url=lURL, param_dict=currentSettings,\n                             securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "This operation allows you to edit the log settings for a single site. This operation is performed on a single site and returns the new log settings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a value to the coded value list", "response": "def add_codedValue(self, name, code):\n        \"\"\" adds a value to the coded value list \"\"\"\n        if self._codedValues is None:\n            self._codedValues = []\n        self._codedValues.append(\n            {\"name\": name, \"code\": code}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __init(self):\n        res = self._get(url=self._url,\n                           param_dict={\"f\": \"json\"},\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        self._json_dict = res\n        self._json_string = json.dumps(self._json_dict)\n        for k,v in self._json_dict.items():\n            setattr(self, k, v)", "response": "loads the json values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef areasAndLengths(self,\n                        polygons,\n                        lengthUnit,\n                        areaUnit,\n                        calculationType,\n                        ):\n        \"\"\"\n           The areasAndLengths operation is performed on a geometry service\n           resource. This operation calculates areas and perimeter lengths\n           for each polygon specified in the input array.\n\n           Inputs:\n              polygons - The array of polygons whose areas and lengths are\n                         to be computed.\n              lengthUnit - The length unit in which the perimeters of\n                           polygons will be calculated. If calculationType\n                           is planar, then lengthUnit can be any esriUnits\n                           constant. If lengthUnit is not specified, the\n                           units are derived from sr. If calculationType is\n                           not planar, then lengthUnit must be a linear\n                           esriUnits constant, such as esriSRUnit_Meter or\n                           esriSRUnit_SurveyMile. If lengthUnit is not\n                           specified, the units are meters. For a list of\n                           valid units, see esriSRUnitType Constants and\n                           esriSRUnit2Type Constant.\n              areaUnit - The area unit in which areas of polygons will be\n                         calculated. If calculationType is planar, then\n                         areaUnit can be any esriUnits constant. If\n                         areaUnit is not specified, the units are derived\n                         from sr. If calculationType is not planar, then\n                         areaUnit must be a linear esriUnits constant such\n                         as esriSRUnit_Meter or esriSRUnit_SurveyMile. If\n                         areaUnit is not specified, then the units are\n                         meters. For a list of valid units, see\n                         esriSRUnitType Constants and esriSRUnit2Type\n                         constant.\n                         The list of valid esriAreaUnits constants include,\n                         esriSquareInches | esriSquareFeet |\n                         esriSquareYards | esriAcres | esriSquareMiles |\n                         esriSquareMillimeters | esriSquareCentimeters |\n                         esriSquareDecimeters | esriSquareMeters | esriAres\n                         | esriHectares | esriSquareKilometers.\n              calculationType -  The type defined for the area and length\n                                 calculation of the input geometries. The\n                                 type can be one of the following values:\n                                 planar - Planar measurements use 2D\n                                          Euclidean distance to calculate\n                                          area and length. Th- should\n                                          only be used if the area or\n                                          length needs to be calculated in\n                                          the given spatial reference.\n                                          Otherwise, use preserveShape.\n                                 geodesic - Use this type if you want to\n                                          calculate an area or length using\n                                          only the vertices of the polygon\n                                          and define the lines between the\n                                          points as geodesic segments\n                                          independent of the actual shape\n                                          of the polygon. A geodesic\n                                          segment is the shortest path\n                                          between two points on an ellipsoid.\n                                 preserveShape - This type calculates the\n                                          area or length of the geometry on\n                                          the surface of the Earth\n                                          ellipsoid. The shape of the\n                                          geometry in its coordinate system\n                                          is preserved.\n           Output:\n              JSON as dictionary\n        \"\"\"\n        url = self._url + \"/areasAndLengths\"\n        params = {\n            \"f\" : \"json\",\n            \"lengthUnit\" : lengthUnit,\n            \"areaUnit\" : {\"areaUnit\" : areaUnit},\n            \"calculationType\" : calculationType\n        }\n        if isinstance(polygons, list) and len(polygons) > 0:\n            p = polygons[0]\n            if isinstance(p, Polygon):\n                params['sr'] = p.spatialReference['wkid']\n                params['polygons'] = [poly.asDictionary for poly in polygons]\n            del p\n        else:\n            return \"No polygons provided, please submit a list of polygon geometries\"\n        return self._get(url=url, param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)", "response": "This method calculates the areas and lengths of a polygon in a resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a list of common.Geometry objects to the geometry template value Input: geometries - list of common.Geometry objects Output: Dictionary in geometry service template", "response": "def __geometryListToGeomTemplate(self, geometries):\n        \"\"\"\n            converts a list of common.Geometry objects to the geometry\n            template value\n            Input:\n               geometries - list of common.Geometry objects\n            Output:\n               Dictionary in geometry service template\n        \"\"\"\n        template = {\"geometryType\": None,\n                    \"geometries\" : []}\n        if isinstance(geometries, list) and len(geometries) > 0:\n            for g in geometries:\n                if isinstance(g, Polyline):\n                    template['geometryType'] = \"esriGeometryPolyline\"\n                elif isinstance(g, Polygon):\n                    template['geometryType'] = \"esriGeometryPolygon\"\n                elif isinstance(g, Point):\n                    template['geometryType'] = \"esriGeometryPoint\"\n                elif isinstance(g, MultiPoint):\n                    template['geometryType'] = \"esriGeometryMultipoint\"\n                elif isinstance(g, Envelope):\n                    template['geometryType'] = \"esriGeometryEnvelope\"\n                else:\n                    raise AttributeError(\"Invalid geometry type\")\n                template['geometries'].append(g.asDictionary)\n                del g\n            return template\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a single geometry object to a geometry service geometry template value.", "response": "def __geometryToGeomTemplate(self, geometry):\n        \"\"\"\n           Converts a single geometry object to a geometry service geometry\n           template value.\n\n           Input:\n              geometry - ArcREST geometry object\n           Output:\n              python dictionary of geometry template\n        \"\"\"\n        template = {\"geometryType\": None,\n                    \"geometry\" : None}\n        if isinstance(geometry, Polyline):\n            template['geometryType'] = \"esriGeometryPolyline\"\n        elif isinstance(geometry, Polygon):\n            template['geometryType'] = \"esriGeometryPolygon\"\n        elif isinstance(geometry, Point):\n            template['geometryType'] = \"esriGeometryPoint\"\n        elif isinstance(geometry, MultiPoint):\n            template['geometryType'] = \"esriGeometryMultipoint\"\n        elif isinstance(geometry, Envelope):\n            template['geometryType'] = \"esriGeometryEnvelope\"\n        else:\n            raise AttributeError(\"Invalid geometry type\")\n        template['geometry'] = geometry.asDictionary\n        return template"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __geomToStringArray(self, geometries, returnType=\"str\"):\n        listGeoms = []\n        for g in geometries:\n            if isinstance(g, Point):\n                listGeoms.append(g.asDictionary)\n            elif isinstance(g, Polygon):\n                listGeoms.append(g.asDictionary) #json.dumps(\n            elif isinstance(g, Polyline):\n                listGeoms.append({'paths' : g.asDictionary['paths']})\n        if returnType == \"str\":\n            return json.dumps(listGeoms)\n        elif returnType == \"list\":\n            return listGeoms\n        else:\n            return json.dumps(listGeoms)", "response": "function to convert the geomtries to strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convexHull(self,\n                   geometries,\n                   sr=None):\n        \"\"\"\n        The convexHull operation is performed on a geometry service resource. \n        It returns the convex hull of the input geometry. The input geometry can \n        be a point, multipoint, polyline, or polygon. The convex hull is typically \n        a polygon but can also be a polyline or point in degenerate cases.\n        \n        Inputs:\n            geometries - array of geometries (structured as JSON geometry \n                         objects returned by the ArcGIS REST API).\n            sr - spatial reference of the input geometries WKID.\n        \"\"\"\n        url = self._url + \"/convexHull\"\n        params = {\n            \"f\" : \"json\"\n        }\n\n        if isinstance(geometries, list) and len(geometries) > 0:\n            g = geometries[0]\n            if sr is not None:\n                params['sr'] = sr\n            else:\n                params['sr'] = g._wkid\n            if isinstance(g, Polygon):\n                params['geometries'] = {\"geometryType\": \"esriGeometryPolygon\",\n                                        \"geometries\" : self.__geomToStringArray(geometries, \"list\")}\n            elif isinstance(g, Point):\n                params['geometries'] = {\"geometryType\": \"esriGeometryPoint\",\n                                        \"geometries\" : self.__geomToStringArray(geometries, \"list\")}\n            elif isinstance(g, Polyline):\n                params['geometries'] = {\"geometryType\": \"esriGeometryPolyline\",\n                                                        \"geometries\" : self.__geomToStringArray(geometries, \"list\")}\n        else:\n            return None\n        return self._get(url=url,\n                            param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_port=self._proxy_port,\n                            proxy_url=self._proxy_url)", "response": "This operation returns the convex hull of the input geometry. The convex hull is typically a point multipoint or polyline or a point in degenerate cases. The convex hull is typically a point in degenerate cases. The input geometry can also be a polygon or a point in degenerate cases."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef densify(self,\n                geometries,\n                sr,\n                maxSegmentLength,\n                lengthUnit,\n                geodesic=False,\n                ):\n        \"\"\"\n        The densify operation is performed on a geometry service resource. This \n        operation densifies geometries by plotting points between existing vertices.\n        \n        Inputs:\n            geometries - array of geometries to be densified (structured as JSON geometry \n                         objects returned by the ArcGIS REST API).\n            sr - spatial reference of the input geometries WKID.\n            maxSegmentLength - all segments longer than maxSegmentLength are replaced \n                               with sequences of lines no longer than maxSegmentLength.\n            geodesic - if set to true, geodesic distance is used to calculate maxSegmentLength.\n            lengthUnit - length unit of maxSegmentLength.\n        \"\"\"\n        url = self._url + \"/densify\"\n        params = {\n            \"f\" : \"json\",\n            \"sr\" : sr,\n            \"maxSegmentLength\" : maxSegmentLength,\n            \"lengthUnit\" : lengthUnit,\n            \"geodesic\" : geodesic\n        }\n        if isinstance(geometries, list) and len(geometries) > 0:\n            template = {\"geometryType\": None,\n                        \"geometries\" : []}\n            for g in geometries:\n                if isinstance(g, Polyline):\n                    template['geometryType'] = \"esriGeometryPolyline\"\n                elif isinstance(g, Polygon):\n                    template['geometryType'] = \"esriGeometryPolygon\"\n                else:\n                    raise AttributeError(\"Invalid geometry type\")\n                template['geometries'].append(g.asDictionary)\n            params['geometries'] = template\n        return self._get(url=url, param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port = self._proxy_port)", "response": "This operation densifies a set of geometries by plotting points between existing vertices."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef union(self,\n              sr,\n              geometries):\n        \"\"\"\n        The union operation is performed on a geometry service resource. This \n        operation constructs the set-theoretic union of the geometries in the \n        input array. All inputs must be of the same type.\n        \n        Inputs:\n            geometries - array of geometries to be unioned (structured as JSON \n                         geometry objects returned by the ArcGIS REST API).\n            sr - spatial reference of the input geometries.\n        \"\"\"\n        url = self._url + \"/union\"\n        params = {\n            \"f\" : \"json\",\n            \"sr\" : sr,\n            \"geometries\" : self.__geometryListToGeomTemplate(geometries=geometries)\n        }\n        return self._get(url=url, param_dict=params,\n                            securityHandler=self._securityHandler,\n                            proxy_url=self._proxy_url,\n                            proxy_port=self._proxy_port)", "response": "This operation constructs the set - theoretic union of the input array of geometries. The union operation is performed on a geometry service resource. The union operation is performed on a geometry service resource. The input array must be of the same type as the input array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the information into the class", "response": "def __init_url(self):\n        \"\"\"loads the information into the class\"\"\"\n        portals_self_url = \"{}/portals/self\".format(self._url)\n        params = {\n            \"f\" :\"json\"\n        }\n        if not self._securityHandler is None:\n            params['token'] = self._securityHandler.token\n        res = self._get(url=portals_self_url,\n                           param_dict=params,\n                           securityHandler=self._securityHandler,\n                           proxy_url=self._proxy_url,\n                           proxy_port=self._proxy_port)\n        if \"helperServices\" in res:\n            helper_services = res.get(\"helperServices\")\n            if \"hydrology\" in helper_services:\n                analysis_service = helper_services.get(\"elevation\")\n                if \"url\" in analysis_service:\n                    self._analysis_url = analysis_service.get(\"url\")\n        self._gpService = GPService(url=self._analysis_url,\n                                    securityHandler=self._securityHandler,\n                                    proxy_url=self._proxy_url,\n                                    proxy_port=self._proxy_port,\n                                    initialize=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_argument_parser(name=None, **kwargs):\n\n    if name is None:\n        name = \"default\"\n\n    if name in _parsers:\n        raise ValueError((\"kwargs besides 'name' can only be passed in the\"\n            \" first time. '%s' ArgumentParser already exists: %s\") % (\n            name, _parsers[name]))\n\n    kwargs.setdefault('formatter_class', argparse.ArgumentDefaultsHelpFormatter)\n    kwargs.setdefault('conflict_handler', 'resolve')\n    _parsers[name] = ArgumentParser(**kwargs)", "response": "Initializes a global ArgumentParser instance with the given name and keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_argument_parser(name=None, **kwargs):\n    if name is None:\n        name = \"default\"\n\n    if len(kwargs) > 0 or name not in _parsers:\n        init_argument_parser(name, **kwargs)\n\n    return _parsers[name]", "response": "Returns the global ArgumentParser instance with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the keys + values from a config file.", "response": "def parse(self, stream):\n        \"\"\"Parses the keys + values from a config file.\"\"\"\n\n        items = OrderedDict()\n        for i, line in enumerate(stream):\n            line = line.strip()\n            if not line or line[0] in [\"#\", \";\", \"[\"] or line.startswith(\"---\"):\n                continue\n            white_space = \"\\\\s*\"\n            key = \"(?P<key>[^:=;#\\s]+?)\"\n            value = white_space+\"[:=\\s]\"+white_space+\"(?P<value>.+?)\"\n            comment = white_space+\"(?P<comment>\\\\s[;#].*)?\"\n\n            key_only_match = re.match(\"^\" + key + comment + \"$\", line)\n            if key_only_match:\n                key = key_only_match.group(\"key\")\n                items[key] = \"true\"\n                continue\n\n            key_value_match = re.match(\"^\"+key+value+comment+\"$\", line)\n            if key_value_match:\n                key = key_value_match.group(\"key\")\n                value = key_value_match.group(\"value\")\n\n                if value.startswith(\"[\") and value.endswith(\"]\"):\n                    # handle special case of lists\n                    value = [elem.strip() for elem in value[1:-1].split(\",\")]\n\n                items[key] = value\n                continue\n\n            raise ConfigFileParserException(\"Unexpected line %s in %s: %s\" % (i,\n                getattr(stream, 'name', 'stream'), line))\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize(self, items):\n        r = StringIO()\n        for key, value in items.items():\n            if isinstance(value, list):\n                # handle special case of lists\n                value = \"[\"+\", \".join(map(str, value))+\"]\"\n            r.write(\"%s = %s\\n\" % (key, value))\n        return r.getvalue()", "response": "This method takes parsed values and\n            converts them back to a string representing config file contents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the keys and values from a config file.", "response": "def parse(self, stream):\n        \"\"\"Parses the keys and values from a config file.\"\"\"\n        yaml = self._load_yaml()\n\n        try:\n            parsed_obj = yaml.safe_load(stream)\n        except Exception as e:\n            raise ConfigFileParserException(\"Couldn't parse config file: %s\" % e)\n\n        if not isinstance(parsed_obj, dict):\n            raise ConfigFileParserException(\"The config file doesn't appear to \"\n                \"contain 'key: value' pairs (aka. a YAML mapping). \"\n                \"yaml.load('%s') returned type '%s' instead of 'dict'.\" % (\n                getattr(stream, 'name', 'stream'),  type(parsed_obj).__name__))\n\n        result = OrderedDict()\n        for key, value in parsed_obj.items():\n            if isinstance(value, list):\n                result[key] = value\n            else:\n                result[key] = str(value)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(self, items, default_flow_style=False):\n\n        # lazy-import so there's no dependency on yaml unless this class is used\n        yaml = self._load_yaml()\n\n        # it looks like ordering can't be preserved: http://pyyaml.org/ticket/29\n        items = dict(items)\n        return yaml.dump(items, default_flow_style=default_flow_style)", "response": "Returns a string representing the config file contents of the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsupport all the same args as the ArgumentParser. parse_args method.", "response": "def parse_args(self, args = None, namespace = None,\n                   config_file_contents = None, env_vars = os.environ):\n        \"\"\"Supports all the same args as the ArgumentParser.parse_args(..),\n        as well as the following additional args.\n\n        Additional Args:\n            args: a list of args as in argparse, or a string (eg. \"-x -y bla\")\n            config_file_contents: String. Used for testing.\n            env_vars: Dictionary. Used for testing.\n        \"\"\"\n        args, argv = self.parse_known_args(args = args,\n            namespace = namespace,\n            config_file_contents = config_file_contents,\n            env_vars = env_vars)\n        if argv:\n            self.error('unrecognized arguments: %s' % ' '.join(argv))\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_known_args(self, args = None, namespace = None,\n                         config_file_contents = None, env_vars = os.environ):\n        \"\"\"Supports all the same args as the ArgumentParser.parse_args(..),\n        as well as the following additional args.\n\n        Additional Args:\n            args: a list of args as in argparse, or a string (eg. \"-x -y bla\")\n            config_file_contents: String. Used for testing.\n            env_vars: Dictionary. Used for testing.\n        \"\"\"\n        if args is None:\n            args = sys.argv[1:]\n        elif isinstance(args, str):\n            args = args.split()\n        else:\n            args = list(args)\n\n        # normalize args by converting args like --key=value to --key value\n        normalized_args = list()\n        for arg in args:\n            if arg and arg[0] in self.prefix_chars and '=' in arg:\n                key, value =  arg.split('=', 1)\n                normalized_args.append(key)\n                normalized_args.append(value)\n            else:\n                normalized_args.append(arg)\n        args = normalized_args\n\n        for a in self._actions:\n            a.is_positional_arg = not a.option_strings\n\n        # maps a string describing the source (eg. env var) to a settings dict\n        # to keep track of where values came from (used by print_values()).\n        # The settings dicts for env vars and config files will then map\n        # the config key to an (argparse Action obj, string value) 2-tuple.\n        self._source_to_settings = OrderedDict()\n        if args:\n            a_v_pair = (None, list(args))  # copy args list to isolate changes\n            self._source_to_settings[_COMMAND_LINE_SOURCE_KEY] = {'': a_v_pair}\n\n        # handle auto_env_var_prefix __init__ arg by setting a.env_var as needed\n        if self._auto_env_var_prefix is not None:\n            for a in self._actions:\n                config_file_keys = self.get_possible_config_keys(a)\n                if config_file_keys and not (a.env_var or a.is_positional_arg\n                    or a.is_config_file_arg or a.is_write_out_config_file_arg or\n                    isinstance(a, argparse._VersionAction) or\n                    isinstance(a, argparse._HelpAction)):\n                    stripped_config_file_key = config_file_keys[0].strip(\n                        self.prefix_chars)\n                    a.env_var = (self._auto_env_var_prefix +\n                                 stripped_config_file_key).replace('-', '_').upper()\n\n        # add env var settings to the commandline that aren't there already\n        env_var_args = []\n        actions_with_env_var_values = [a for a in self._actions\n            if not a.is_positional_arg and a.env_var and a.env_var in env_vars\n                and not already_on_command_line(args, a.option_strings)]\n        for action in actions_with_env_var_values:\n            key = action.env_var\n            value = env_vars[key]\n            # Make list-string into list.\n            if action.nargs or isinstance(action, argparse._AppendAction):\n                element_capture = re.match('\\[(.*)\\]', value)\n                if element_capture:\n                    value = [val.strip() for val in element_capture.group(1).split(',') if val.strip()]\n            env_var_args += self.convert_item_to_command_line_arg(\n                action, key, value)\n\n        args = args + env_var_args\n\n        if env_var_args:\n            self._source_to_settings[_ENV_VAR_SOURCE_KEY] = OrderedDict(\n                [(a.env_var, (a, env_vars[a.env_var]))\n                    for a in actions_with_env_var_values])\n\n\n        # before parsing any config files, check if -h was specified.\n        supports_help_arg = any(\n            a for a in self._actions if isinstance(a, argparse._HelpAction))\n        skip_config_file_parsing = supports_help_arg and (\n            \"-h\" in args or \"--help\" in args)\n\n        # prepare for reading config file(s)\n        known_config_keys = dict((config_key, action) for action in self._actions\n            for config_key in self.get_possible_config_keys(action))\n\n        # open the config file(s)\n        config_streams = []\n        if config_file_contents is not None:\n            stream = StringIO(config_file_contents)\n            stream.name = \"method arg\"\n            config_streams = [stream]\n        elif not skip_config_file_parsing:\n            config_streams = self._open_config_files(args)\n\n        # parse each config file\n        for stream in reversed(config_streams):\n            try:\n                config_items = self._config_file_parser.parse(stream)\n            except ConfigFileParserException as e:\n                self.error(e)\n            finally:\n                if hasattr(stream, \"close\"):\n                    stream.close()\n\n            # add each config item to the commandline unless it's there already\n            config_args = []\n            for key, value in config_items.items():\n                if key in known_config_keys:\n                    action = known_config_keys[key]\n                    discard_this_key = already_on_command_line(\n                        args, action.option_strings)\n                else:\n                    action = None\n                    discard_this_key = self._ignore_unknown_config_file_keys or \\\n                        already_on_command_line(\n                            args,\n                            [self.get_command_line_key_for_unknown_config_file_setting(key)])\n\n                if not discard_this_key:\n                    config_args += self.convert_item_to_command_line_arg(\n                        action, key, value)\n                    source_key = \"%s|%s\" %(_CONFIG_FILE_SOURCE_KEY, stream.name)\n                    if source_key not in self._source_to_settings:\n                        self._source_to_settings[source_key] = OrderedDict()\n                    self._source_to_settings[source_key][key] = (action, value)\n\n            args = args + config_args\n\n\n        # save default settings for use by print_values()\n        default_settings = OrderedDict()\n        for action in self._actions:\n            cares_about_default_value = (not action.is_positional_arg or\n                action.nargs in [OPTIONAL, ZERO_OR_MORE])\n            if (already_on_command_line(args, action.option_strings) or\n                    not cares_about_default_value or\n                    action.default is None or\n                    action.default == SUPPRESS or\n                    isinstance(action, ACTION_TYPES_THAT_DONT_NEED_A_VALUE)):\n                continue\n            else:\n                if action.option_strings:\n                    key = action.option_strings[-1]\n                else:\n                    key = action.dest\n                default_settings[key] = (action, str(action.default))\n\n        if default_settings:\n            self._source_to_settings[_DEFAULTS_SOURCE_KEY] = default_settings\n\n        # parse all args (including commandline, config file, and env var)\n        namespace, unknown_args = argparse.ArgumentParser.parse_known_args(\n            self, args=args, namespace=namespace)\n        # handle any args that have is_write_out_config_file_arg set to true\n        # check if the user specified this arg on the commandline\n        output_file_paths = [getattr(namespace, a.dest, None) for a in self._actions\n                             if getattr(a, \"is_write_out_config_file_arg\", False)]\n        output_file_paths = [a for a in output_file_paths if a is not None]\n        self.write_config_file(namespace, output_file_paths, exit_after=True)\n        return namespace, unknown_args", "response": "Parse the arguments and return a dict of the command line settings and the set of known arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_config_file(self, parsed_namespace, output_file_paths, exit_after=False):\n        for output_file_path in output_file_paths:\n            # validate the output file path\n            try:\n                with open(output_file_path, \"w\") as output_file:\n                    pass\n            except IOError as e:\n                raise ValueError(\"Couldn't open %s for writing: %s\" % (\n                    output_file_path, e))\n        if output_file_paths:\n            # generate the config file contents\n            config_items = self.get_items_for_config_file_output(\n                self._source_to_settings, parsed_namespace)\n            file_contents = self._config_file_parser.serialize(config_items)\n            for output_file_path in output_file_paths:\n                with open(output_file_path, \"w\") as output_file:\n                    output_file.write(file_contents)\n            message = \"Wrote config file to \" + \", \".join(output_file_paths)\n            if exit_after:\n                self.exit(0, message)\n            else:\n                print(message)", "response": "Write the given settings to the given output files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute a commandline arg key to be used for a config file setting that doesn t correspond to any defined config file setting.", "response": "def get_command_line_key_for_unknown_config_file_setting(self, key):\n        \"\"\"Compute a commandline arg key to be used for a config file setting\n        that doesn't correspond to any defined configargparse arg (and so\n        doesn't have a user-specified commandline arg key).\n\n        Args:\n            key: The config file key that was being set.\n        \"\"\"\n        key_without_prefix_chars = key.strip(self.prefix_chars)\n        command_line_key = self.prefix_chars[0]*2 + key_without_prefix_chars\n\n        return command_line_key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the given settings back to a dictionary that can be passed to ConfigFormatParser. serialize", "response": "def get_items_for_config_file_output(self, source_to_settings,\n                                         parsed_namespace):\n        \"\"\"Converts the given settings back to a dictionary that can be passed\n        to ConfigFormatParser.serialize(..).\n\n        Args:\n            source_to_settings: the dictionary described in parse_known_args()\n            parsed_namespace: namespace object created within parse_known_args()\n        Returns:\n            an OrderedDict where keys are strings and values are either strings\n            or lists\n        \"\"\"\n        config_file_items = OrderedDict()\n        for source, settings in source_to_settings.items():\n            if source == _COMMAND_LINE_SOURCE_KEY:\n                _, existing_command_line_args = settings['']\n                for action in self._actions:\n                    config_file_keys = self.get_possible_config_keys(action)\n                    if config_file_keys and not action.is_positional_arg and \\\n                        already_on_command_line(existing_command_line_args,\n                                                action.option_strings):\n                        value = getattr(parsed_namespace, action.dest, None)\n                        if value is not None:\n                            if isinstance(value, bool):\n                                value = str(value).lower()\n                            config_file_items[config_file_keys[0]] = value\n\n            elif source == _ENV_VAR_SOURCE_KEY:\n                for key, (action, value) in settings.items():\n                    config_file_keys = self.get_possible_config_keys(action)\n                    if config_file_keys:\n                        value = getattr(parsed_namespace, action.dest, None)\n                        if value is not None:\n                            config_file_items[config_file_keys[0]] = value\n            elif source.startswith(_CONFIG_FILE_SOURCE_KEY):\n                for key, (action, value) in settings.items():\n                    config_file_items[key] = value\n            elif source == _DEFAULTS_SOURCE_KEY:\n                for key, (action, value) in settings.items():\n                    config_file_keys = self.get_possible_config_keys(action)\n                    if config_file_keys:\n                        value = getattr(parsed_namespace, action.dest, None)\n                        if value is not None:\n                            config_file_items[config_file_keys[0]] = value\n        return config_file_items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a config file or env var key + value to a list of commandline args.", "response": "def convert_item_to_command_line_arg(self, action, key, value):\n        \"\"\"Converts a config file or env var key + value to a list of\n        commandline args to append to the commandline.\n\n        Args:\n            action: The argparse Action object for this setting, or None if this\n                config file setting doesn't correspond to any defined\n                configargparse arg.\n            key: string (config file key or env var name)\n            value: parsed value of type string or list\n        \"\"\"\n        args = []\n\n        if action is None:\n            command_line_key = \\\n                self.get_command_line_key_for_unknown_config_file_setting(key)\n        else:\n            command_line_key = action.option_strings[-1]\n\n        # handle boolean value\n        if action is not None and isinstance(action, ACTION_TYPES_THAT_DONT_NEED_A_VALUE):\n            if value.lower() in (\"true\", \"yes\", \"1\"):\n                args.append( command_line_key )\n            elif value.lower() in (\"false\", \"no\", \"0\"):\n                # don't append when set to \"false\" / \"no\"\n                pass\n            else:\n                self.error(\"Unexpected value for %s: '%s'. Expecting 'true', \"\n                           \"'false', 'yes', 'no', '1' or '0'\" % (key, value))\n        elif isinstance(value, list):\n            if action is None or isinstance(action, argparse._AppendAction):\n                for list_elem in value:\n                    args.append( command_line_key )\n                    args.append( str(list_elem) )\n            elif (isinstance(action, argparse._StoreAction) and action.nargs in ('+', '*')) or (\n                isinstance(action.nargs, int) and action.nargs > 1):\n                args.append( command_line_key )\n                for list_elem in value:\n                    args.append( str(list_elem) )\n            else:\n                self.error((\"%s can't be set to a list '%s' unless its action type is changed \"\n                            \"to 'append' or nargs is set to '*', '+', or > 1\") % (key, value))\n        elif isinstance(value, str):\n            args.append( command_line_key )\n            args.append( value )\n        else:\n            raise ValueError(\"Unexpected value type %s for value: %s\" % (\n                type(value), value))\n\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _open_config_files(self, command_line_args):\n        # open any default config files\n        config_files = [open(f) for files in map(glob.glob, map(os.path.expanduser, self._default_config_files))\n                        for f in files]\n\n        # list actions with is_config_file_arg=True. Its possible there is more\n        # than one such arg.\n        user_config_file_arg_actions = [\n            a for a in self._actions if getattr(a, \"is_config_file_arg\", False)]\n\n        if not user_config_file_arg_actions:\n            return config_files\n\n        for action in user_config_file_arg_actions:\n            # try to parse out the config file path by using a clean new\n            # ArgumentParser that only knows this one arg/action.\n            arg_parser = argparse.ArgumentParser(\n                prefix_chars=self.prefix_chars,\n                add_help=False)\n\n            arg_parser._add_action(action)\n\n            # make parser not exit on error by replacing its error method.\n            # Otherwise it sys.exits(..) if, for example, config file\n            # is_required=True and user doesn't provide it.\n            def error_method(self, message):\n                pass\n            arg_parser.error = types.MethodType(error_method, arg_parser)\n\n            # check whether the user provided a value\n            parsed_arg = arg_parser.parse_known_args(args=command_line_args)\n            if not parsed_arg:\n                continue\n            namespace, _ = parsed_arg\n            user_config_file = getattr(namespace, action.dest, None)\n\n            if not user_config_file:\n                continue\n            # validate the user-provided config file path\n            user_config_file = os.path.expanduser(user_config_file)\n            if not os.path.isfile(user_config_file):\n                self.error('File not found: %s' % user_config_file)\n\n            config_files += [open(user_config_file)]\n\n        return config_files", "response": "Tries to parse config file path from within command_line_args."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string with all args settings and where they came from", "response": "def format_values(self):\n        \"\"\"Returns a string with all args and settings and where they came from\n        (eg. commandline, config file, enviroment variable or default)\n        \"\"\"\n        source_key_to_display_value_map = {\n            _COMMAND_LINE_SOURCE_KEY: \"Command Line Args: \",\n            _ENV_VAR_SOURCE_KEY: \"Environment Variables:\\n\",\n            _CONFIG_FILE_SOURCE_KEY: \"Config File (%s):\\n\",\n            _DEFAULTS_SOURCE_KEY: \"Defaults:\\n\"\n        }\n\n        r = StringIO()\n        for source, settings in self._source_to_settings.items():\n            source = source.split(\"|\")\n            source = source_key_to_display_value_map[source[0]] % tuple(source[1:])\n            r.write(source)\n            for key, (action, value) in settings.items():\n                if key:\n                    r.write(\"  %-19s%s\\n\" % (key+\":\", value))\n                else:\n                    if isinstance(value, str):\n                        r.write(\"  %s\\n\" % value)\n                    elif isinstance(value, list):\n                        r.write(\"  %s\\n\" % ' '.join(value))\n\n        return r.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eval(lisp):\n    '''\n    plash lisp is one dimensional lisp.\n    '''\n    macro_values = []\n    if not isinstance(lisp, list):\n        raise EvalError('eval root element must be a list')\n    for item in lisp:\n        if not isinstance(item, list):\n            raise EvalError('must evaluate list of list')\n        if not all(isinstance(i, str) for i in item):\n            raise EvalError(\n                'must evaluate list of list of strings. not a list of strings: {}'\n                .format(item))\n        name = item[0]\n        args = item[1:]\n        try:\n            macro = state['macros'][name]\n        except KeyError:\n            raise MacroNotFoundError(\"macro {} not found\".format(repr(name)))\n        try:\n            res = macro(*args)\n        except Exception as exc:\n            if os.getenv('PLASH_DEBUG', '').lower() in ('1', 'yes', 'true'):\n                raise\n            if isinstance(exc, MacroError):\n                # only raise that one time and don't have multiple wrapped MacroError\n                raise\n            raise MacroError(macro, name, sys.exc_info())\n        if not isinstance(res, str) and res is not None:\n            raise EvalError(\n                'eval macro must return string or None ({} returned {})'.\n                format(name, type(res)))\n        if res is not None:\n            macro_values.append(res)\n    return '\\n'.join(macro_values)", "response": "Evaluate the plash lisp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nthinning wrapper around plash map", "response": "def plash_map(*args):\n    from subprocess import check_output\n    'thin wrapper around plash map'\n    out = check_output(['plash', 'map'] + list(args))\n    if out == '':\n        return None\n    return out.decode().strip('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndefine a new package manager", "response": "def defpm(name, *lines):\n    'define a new package manager'\n\n    @register_macro(name, group='package managers')\n    @shell_escape_args\n    def package_manager(*packages):\n        if not packages:\n            return\n        sh_packages = ' '.join(pkg for pkg in packages)\n        expanded_lines = [line.format(sh_packages) for line in lines]\n        return eval([['run'] + expanded_lines])\n\n    package_manager.__doc__ = \"install packages with {}\".format(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhints the start of a new layer", "response": "def layer(command=None, *args):\n    'hints the start of a new layer'\n    if not command:\n        return eval([['hint', 'layer']])  # fall back to buildin layer macro\n    else:\n        lst = [['layer']]\n        for arg in args:\n            lst.append([command, arg])\n            lst.append(['layer'])\n        return eval(lst)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_env(*envs):\n    'import environment variables from host'\n    for env in envs:\n        parts = env.split(':', 1)\n        if len(parts) == 1:\n            export_as = env\n        else:\n            env, export_as = parts\n        env_val = os.environ.get(env)\n        if env_val is not None:\n            yield '{}={}'.format(export_as, shlex.quote(env_val))", "response": "import environment variables from host"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_file(fname, *lines):\n    'write lines to a file'\n    yield 'touch {}'.format(fname)\n    for line in lines:\n        yield \"echo {} >> {}\".format(line, fname)", "response": "write lines to a file"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates file content as expressions", "response": "def eval_file(file):\n    'evaluate file content as expressions'\n\n    fname = os.path.realpath(os.path.expanduser(file))\n    with open(fname) as f:\n        inscript = f.read()\n\n    sh = run_write_read(['plash', 'eval'], inscript.encode()).decode()\n\n    # we remove an possibly existing newline\n    # because else this macros would add one\n    if sh.endswith('\\n'):\n        return sh[:-1]\n\n    return sh"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating expressions passed as string", "response": "def eval_string(stri):\n    'evaluate expressions passed as string'\n    tokens = shlex.split(stri)\n\n    return run_write_read(['plash', 'eval'], '\\n'.join(tokens).encode()).decode()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eval_stdin():\n    'evaluate expressions read from stdin'\n    cmd = ['plash', 'eval']\n    p = subprocess.Popen(cmd, stdin=sys.stdin, stdout=sys.stdout)\n    exit = p.wait()\n    if exit:\n        raise subprocess.CalledProcessError(exit, cmd)", "response": "evaluate expressions read from stdin"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite lines to / entrypoint and hint it as default command", "response": "def entrypoint_script(*lines):\n    'write lines to /entrypoint and hint it as default command'\n    lines = list(lines)\n    if lines and not lines[0].startswith('#!'):\n        lines.insert(0, '#!/bin/sh')\n    return eval([['entrypoint', '/entrypoint'],\n                 ['write-script', '/entrypoint'] + lines])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses resolved map as image", "response": "def from_map(map_key):\n    'use resolved map as image'\n    image_id = subprocess.check_output(['plash', 'map',\n                                        map_key]).decode().strip('\\n')\n    if not image_id:\n        raise MapDoesNotExist('map {} not found'.format(repr(map_key)))\n    return hint('image', image_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_github(user_repo_pair, file='plashfile'):\n    \"build and use a file (default 'plashfile') from github repo\"\n    from urllib.request import urlopen\n    url = 'https://raw.githubusercontent.com/{}/master/{}'.format(\n        user_repo_pair, file)\n    with utils.catch_and_die([Exception], debug=url):\n        resp = urlopen(url)\n    plashstr = resp.read()\n    return utils.run_write_read(['plash', 'build', '--eval-stdin'],\n                                plashstr).decode().rstrip('\\n')", "response": "build and use a file from github repo"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fields(self):\n        fields = super(DynamicFieldsMixin, self).fields\n\n        if not hasattr(self, '_context'):\n            # We are being called before a request cycle\n            return fields\n\n        # Only filter if this is the root serializer, or if the parent is the\n        # root serializer with many=True\n        is_root = self.root == self\n        parent_is_list_root = self.parent == self.root and getattr(self.parent, 'many', False)\n        if not (is_root or parent_is_list_root):\n            return fields\n\n        try:\n            request = self.context['request']\n        except KeyError:\n            conf = getattr(settings, 'DRF_DYNAMIC_FIELDS', {})\n            if not conf.get('SUPPRESS_CONTEXT_WARNING', False) is True:\n                warnings.warn('Context does not have access to request. '\n                              'See README for more information.')\n            return fields\n\n        # NOTE: drf test framework builds a request object where the query\n        # parameters are found under the GET attribute.\n        params = getattr(\n            request, 'query_params', getattr(request, 'GET', None)\n        )\n        if params is None:\n            warnings.warn('Request object does not contain query paramters')\n\n        try:\n            filter_fields = params.get('fields', None).split(',')\n        except AttributeError:\n            filter_fields = None\n\n        try:\n            omit_fields = params.get('omit', None).split(',')\n        except AttributeError:\n            omit_fields = []\n\n        # Drop any fields that are not specified in the `fields` argument.\n        existing = set(fields.keys())\n        if filter_fields is None:\n            # no fields param given, don't filter.\n            allowed = existing\n        else:\n            allowed = set(filter(None, filter_fields))\n\n        # omit fields in the `omit` argument.\n        omitted = set(filter(None, omit_fields))\n\n        for field in existing:\n\n            if field not in allowed:\n                fields.pop(field, None)\n\n            if field in omitted:\n                fields.pop(field, None)\n\n        return fields", "response": "Returns a list of all the fields that are allowed to be set in the current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_admin_on_rest_handlers(admin, admin_handler):\n    add_route = admin.router.add_route\n    add_static = admin.router.add_static\n    static_folder = str(PROJ_ROOT / 'static')\n    a = admin_handler\n\n    add_route('GET', '', a.index_page, name='admin.index')\n    add_route('POST', '/token', a.token, name='admin.token')\n    add_static('/static', path=static_folder, name='admin.static')\n    add_route('DELETE', '/logout', a.logout, name='admin.logout')", "response": "Setup the routes and routes for the admin on rest handlers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning index page with initial state for admin", "response": "async def index_page(self, request):\n        \"\"\"\n        Return index page with initial state for admin\n        \"\"\"\n        context = {\"initial_state\": self.schema.to_json()}\n\n        return render_template(\n            self.template,\n            request,\n            context,\n            app_key=TEMPLATE_APP_KEY,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_datetime_serial(obj):\n    if isinstance(obj, (datetime, date)):\n        serial = obj.isoformat()\n        return serial\n\n    if ObjectId is not None and isinstance(obj, ObjectId):\n        # TODO: try to use bson.json_util instead\n        return str(obj)\n\n    raise TypeError(\"Type not serializable\")", "response": "JSON serializer for objects not serializable by default json code"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the query arguments in list request.", "response": "def validate_query_structure(query):\n    \"\"\"Validate query arguments in list request.\n\n    :param query: mapping with pagination and filtering information\n    \"\"\"\n    query_dict = dict(query)\n    filters = query_dict.pop('_filters', None)\n    if filters:\n        try:\n            f = json.loads(filters)\n        except ValueError:\n            msg = '_filters field can not be serialized'\n            raise JsonValidaitonError(msg)\n        else:\n            query_dict['_filters'] = f\n    try:\n        q = ListQuery(query_dict)\n    except t.DataError as exc:\n        msg = '_filters query invalid'\n        raise JsonValidaitonError(msg, **as_dict(exc))\n\n    return q"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a JSON string of the admin - on - rest version of the resource.", "response": "def to_json(self):\n        \"\"\"\n        Prepare data for the initial state of the admin-on-rest\n        \"\"\"\n        endpoints = []\n        for endpoint in self.endpoints:\n            list_fields = endpoint.fields\n            resource_type = endpoint.Meta.resource_type\n            table = endpoint.Meta.table\n\n            data = endpoint.to_dict()\n            data['fields'] = resource_type.get_type_of_fields(\n                list_fields,\n                table,\n            )\n            endpoints.append(data)\n\n        data = {\n            'title': self.title,\n            'endpoints': sorted(endpoints, key=lambda x: x['name']),\n        }\n\n        return json.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resources(self):\n        resources = []\n\n        for endpoint in self.endpoints:\n            resource_type = endpoint.Meta.resource_type\n            table = endpoint.Meta.table\n            url = endpoint.name\n\n            resources.append((resource_type, {'table': table, 'url': url}))\n\n        return resources", "response": "Return list of all registered resources."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn data types of fields that are in table.", "response": "def get_type_of_fields(fields, table):\n        \"\"\"\n        Return data types of `fields` that are in `table`. If a given\n        parameter is empty return primary key.\n\n        :param fields: list - list of fields that need to be returned\n        :param table: sa.Table - the current table\n        :return: list - list of the tuples `(field_name, fields_type)`\n        \"\"\"\n\n        if not fields:\n            fields = table.primary_key\n\n        actual_fields = [\n            field for field in table.c.items() if field[0] in fields\n        ]\n\n        data_type_fields = {\n            name: FIELD_TYPES.get(type(field_type.type), rc.TEXT_FIELD.value)\n            for name, field_type in actual_fields\n        }\n\n        return data_type_fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_type_for_inputs(table):\n        return [\n            dict(\n                type=INPUT_TYPES.get(\n                    type(field_type.type), rc.TEXT_INPUT.value\n                ),\n                name=name,\n                isPrimaryKey=(name in table.primary_key),\n                props=None,\n            ) for name, field_type in table.c.items()\n        ]", "response": "Return information about table s fields in dictionary type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the admin - on - rest admin", "response": "def _setup(app, *, schema,  title=None, app_key=APP_KEY, db=None):\n    \"\"\"Initialize the admin-on-rest admin\"\"\"\n\n    admin = web.Application(loop=app.loop)\n    app[app_key] = admin\n    loader = jinja2.FileSystemLoader([TEMPLATES_ROOT, ])\n    aiohttp_jinja2.setup(admin, loader=loader, app_key=TEMPLATE_APP_KEY)\n\n    if title:\n        schema.title = title\n\n    resources = [\n        init(db, info['table'], url=info['url'])\n        for init, info in schema.resources\n    ]\n\n    admin_handler = AdminOnRestHandler(\n        admin,\n        resources=resources,\n        loop=app.loop,\n        schema=schema,\n    )\n\n    admin['admin_handler'] = admin_handler\n    setup_admin_on_rest_handlers(admin, admin_handler)\n\n    return admin"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict with the all base information about the instance.", "response": "def to_dict(self):\n        \"\"\"\n        Return dict with the all base information about the instance.\n        \"\"\"\n        data = {\n            \"name\": self.name,\n            \"canEdit\": self.can_edit,\n            \"canCreate\": self.can_create,\n            \"canDelete\": self.can_delete,\n            \"perPage\": self.per_page,\n            \"showPage\": self.generate_data_for_show_page(),\n            \"editPage\": self.generate_data_for_edit_page(),\n            \"createPage\": self.generate_data_for_create_page(),\n        }\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_data_for_edit_page(self):\n\n        if not self.can_edit:\n            return {}\n\n        if self.edit_form:\n            return self.edit_form.to_dict()\n\n        return self.generate_simple_data_page()", "response": "Generate a custom representation of table s fields in dictionary type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_data_for_create_page(self):\n        if not self.can_create:\n            return {}\n\n        if self.create_form:\n            return self.create_form.to_dict()\n\n        return self.generate_simple_data_page()", "response": "Generate a custom representation of table s fields in dictionary type\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding the current user as follower of the given user.", "response": "async def follow_user(self, request):\n        \"\"\"Adds the current user as follower of the given user.\"\"\"\n        username = request.match_info['username']\n        session = await get_session(request)\n        user_id = session.get('user_id')\n\n        if not user_id:\n            raise web.HTTPNotAuthorized()\n\n        whom_id = await db.get_user_id(self.mongo.user, username)\n\n        if whom_id is None:\n            raise web.HTTPFound()\n\n        await self.mongo.follower.update(\n            {'who_id': ObjectId(user_id)},\n            {'$push': {'whom_id': whom_id}}, upsert=True)\n\n        return redirect(request, 'user_timeline', parts={\"username\": username})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def add_message(self, request):\n        session = await get_session(request)\n        user_id = session.get('user_id')\n        if not user_id:\n            raise web.HTTPNotAuthorized()\n        form = await request.post()\n\n        if form.get('text'):\n            user = await self.mongo.user.find_one(\n                {'_id': ObjectId(session['user_id'])},\n                {'email': 1, 'username': 1})\n\n            await self.mongo.message.insert(\n                {'author_id': ObjectId(user_id),\n                 'email': user['email'],\n                 'username': user['username'],\n                 'text': form['text'],\n                 'pub_date': datetime.datetime.utcnow()})\n        return redirect(request, 'timeline')", "response": "Registers a new message for the user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef robo_avatar_url(user_data, size=80):\n    hash = md5(str(user_data).strip().lower().encode('utf-8')).hexdigest()\n    url = \"https://robohash.org/{hash}.png?size={size}x{size}\".format(\n        hash=hash, size=size)\n    return url", "response": "Return the gravatar url for the given email address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts process and create screenshot.", "response": "def waitgrab(self, timeout=60, autocrop=True, cb_imgcheck=None):\n        '''start process and create screenshot.\n        Repeat screenshot until it is not empty and\n        cb_imgcheck callback function returns True\n        for current screenshot.\n\n        :param autocrop: True -> crop screenshot\n        :param timeout: int\n        :param cb_imgcheck: None or callback for testing img,\n                            True = accept img,\n                            False = reject img\n        '''\n        t = 0\n        sleep_time = 0.3  # for fast windows\n        repeat_time = 1\n        while 1:\n            log.debug('sleeping %s secs' % str(sleep_time))\n            time.sleep(sleep_time)\n            t += sleep_time\n            img = self.grab(autocrop=autocrop)\n            if img:\n                if not cb_imgcheck:\n                    break\n                if cb_imgcheck(img):\n                    break\n            sleep_time = repeat_time\n            repeat_time += 1  # progressive\n            if t > timeout:\n                msg = 'Timeout! elapsed time:%s timeout:%s ' % (t, timeout)\n                raise DisplayTimeoutError(msg)\n                break\n\n            log.debug('screenshot is empty, next try..')\n        assert img\n#        if not img:\n#            log.debug('screenshot is empty!')\n        return img"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nredirects the display to the new or old one.", "response": "def redirect_display(self, on):\n        '''\n        on:\n         * True -> set $DISPLAY to virtual screen\n         * False -> set $DISPLAY to original screen\n\n        :param on: bool\n        '''\n        d = self.new_display_var if on else self.old_display_var\n        if d is None:\n            log.debug('unset DISPLAY')\n            del os.environ['DISPLAY']\n        else:\n            log.debug('DISPLAY=%s', d)\n            os.environ['DISPLAY'] = d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start(self):\n        '''\n        start display\n\n        :rtype: self\n        '''\n        if self.use_xauth:\n            self._setup_xauth()\n        EasyProcess.start(self)\n\n        # https://github.com/ponty/PyVirtualDisplay/issues/2\n        # https://github.com/ponty/PyVirtualDisplay/issues/14\n        self.old_display_var = os.environ.get('DISPLAY', None)\n\n        self.redirect_display(True)\n\n        # wait until X server is active\n        start_time = time.time()\n        ok = False\n        d = self.new_display_var\n        while time.time() - start_time < X_START_TIMEOUT:\n            try:\n                exit_code = EasyProcess('xdpyinfo').call().return_code\n            except EasyProcessError:\n                log.warn('xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!')\n                time.sleep(X_START_WAIT)    # old method\n                ok = True\n                break\n\n            if exit_code != 0:\n                pass\n            else:\n                log.info('Successfully started X with display \"%s\".', d)\n                ok = True\n                break\n\n            time.sleep(X_START_TIME_STEP)\n        if not ok:\n            msg = 'Failed to start X on display \"%s\" (xdpyinfo check failed).'\n            raise XStartTimeoutError(msg % d)\n        return self", "response": "start display\n\n        :rtype: self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self):\n        '''\n        stop display\n\n        :rtype: self\n        '''\n        self.redirect_display(False)\n        EasyProcess.stop(self)\n        if self.use_xauth:\n            self._clear_xauth()\n        return self", "response": "stop display the current user"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up the Xauthority file and the XAUTHORITY environment variable.", "response": "def _setup_xauth(self):\n        '''\n        Set up the Xauthority file and the XAUTHORITY environment variable.\n        '''\n        handle, filename = tempfile.mkstemp(prefix='PyVirtualDisplay.',\n                                            suffix='.Xauthority')\n        self._xauth_filename = filename\n        os.close(handle)\n        # Save old environment\n        self._old_xauth = {}\n        self._old_xauth['AUTHFILE'] = os.getenv('AUTHFILE')\n        self._old_xauth['XAUTHORITY'] = os.getenv('XAUTHORITY')\n\n        os.environ['AUTHFILE'] = os.environ['XAUTHORITY'] = filename\n        cookie = xauth.generate_mcookie()\n        xauth.call('add', self.new_display_var, '.', cookie)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _clear_xauth(self):\n        '''\n        Clear the Xauthority file and restore the environment variables.\n        '''\n        os.remove(self._xauth_filename)\n        for varname in ['AUTHFILE', 'XAUTHORITY']:\n            if self._old_xauth[varname] is None:\n                del os.environ[varname]\n            else:\n                os.environ[varname] = self._old_xauth[varname]\n        self._old_xauth = None", "response": "Clear the Xauthority file and restore the environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetSecurityToken(self, username, password):\n        url = 'https://login.microsoftonline.com/extSTS.srf'\n        body = \"\"\"\n                <s:Envelope xmlns:s=\"http://www.w3.org/2003/05/soap-envelope\"\n                  xmlns:a=\"http://www.w3.org/2005/08/addressing\"\n                  xmlns:u=\"http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd\">\n              <s:Header>\n                <a:Action s:mustUnderstand=\"1\">http://schemas.xmlsoap.org/ws/2005/02/trust/RST/Issue</a:Action>\n                <a:ReplyTo>\n                  <a:Address>http://www.w3.org/2005/08/addressing/anonymous</a:Address>\n                </a:ReplyTo>\n                <a:To s:mustUnderstand=\"1\">https://login.microsoftonline.com/extSTS.srf</a:To>\n                <o:Security s:mustUnderstand=\"1\"\n                   xmlns:o=\"http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd\">\n                  <o:UsernameToken>\n                    <o:Username>%s</o:Username>\n                    <o:Password>%s</o:Password>\n                  </o:UsernameToken>\n                </o:Security>\n              </s:Header>\n              <s:Body>\n                <t:RequestSecurityToken xmlns:t=\"http://schemas.xmlsoap.org/ws/2005/02/trust\">\n                  <wsp:AppliesTo xmlns:wsp=\"http://schemas.xmlsoap.org/ws/2004/09/policy\">\n                    <a:EndpointReference>\n                      <a:Address>%s</a:Address>\n                    </a:EndpointReference>\n                  </wsp:AppliesTo>\n                  <t:KeyType>http://schemas.xmlsoap.org/ws/2005/05/identity/NoProofKey</t:KeyType>\n                  <t:RequestType>http://schemas.xmlsoap.org/ws/2005/02/trust/Issue</t:RequestType>\n                  <t:TokenType>urn:oasis:names:tc:SAML:1.0:assertion</t:TokenType>\n                </t:RequestSecurityToken>\n              </s:Body>\n            </s:Envelope>\"\"\" % (username, password, self.share_point_site)\n        headers = {'accept': 'application/json;odata=verbose'}\n\n        response = requests.post(url, body, headers=headers)\n\n        xmldoc = etree.fromstring(response.content)\n\n        token = xmldoc.find(\n            './/{http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd}BinarySecurityToken'\n        )\n        if token is not None:\n            return token.text\n        else:\n            raise Exception('Check username/password and rootsite')", "response": "Grabs a security Token for the given username and password"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetCookies(self):\n        sectoken = self.GetSecurityToken(self.Username, self.Password)\n        url = self.share_point_site+ '/_forms/default.aspx?wa=wsignin1.0'\n        response = requests.post(url, data=sectoken)\n        return response.cookies", "response": "Grabs the cookies form your Office Sharepoint site\n        and uses it as Authentication for rest of the calls\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AddList(self, listName, description, templateID):\n        templateIDs = {'Announcements': '104',\n                       'Contacts': '105',\n                       'Custom List': '100',\n                       'Custom List in Datasheet View': '120',\n                       'DataSources': '110',\n                       'Discussion Board': '108',\n                       'Document Library': '101',\n                       'Events': '106',\n                       'Form Library': '115',\n                       'Issues': '1100',\n                       'Links': '103',\n                       'Picture Library': '109',\n                       'Survey': '102',\n                       'Tasks': '107'}\n        IDnums = [100, 101, 102, 103, 104, 105, 106,\n                  107, 108, 109, 110, 115, 120, 1100]\n\n        # Let's automatically convert the different\n        # ways we can select the templateID\n        if type(templateID) == int:\n            templateID = str(templateID)\n        elif type(templateID) == str:\n            if templateID.isdigit():\n                pass\n            else:\n                templateID = templateIDs[templateID]\n\n        # Build Request\n        soap_request = soap('AddList')\n        soap_request.add_parameter('listName', listName)\n        soap_request.add_parameter('description', description)\n        soap_request.add_parameter('templateID', templateID)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('AddList'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Request\n        print(response)\n        if response == 200:\n            return response.text\n        else:\n            return response", "response": "Create a new list with the given name description and templateID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DeleteList(self, listName):\n\n        # Build Request\n        soap_request = soap('DeleteList')\n        soap_request.add_parameter('listName', listName)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('DeleteList'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Request\n        if response == 200:\n            return response.text\n        else:\n            return response", "response": "Delete a List with given name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetListCollection(self):\n        # Build Request\n        soap_request = soap('GetListCollection')\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('SiteData'),\n                                      headers=self._headers('GetListCollection'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            result = envelope[0][0][0].text\n            lists = envelope[0][0][1]\n            data = []\n            for _list in lists:\n                _list_data = {}\n                for item in _list:\n                    key = item.tag.replace('{http://schemas.microsoft.com/sharepoint/soap/}', '')\n                    value = item.text\n                    _list_data[key] = value\n                data.append(_list_data)\n\n            return data\n        else:\n            return response", "response": "Returns List information for current Site"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets Items from current list rowlimit defaulted to 0", "response": "def GetUsers(self, rowlimit=0):\n        \"\"\"Get Items from current list\n           rowlimit defaulted to 0 (no limit)\n        \"\"\"\n\n        # Build Request\n        soap_request = soap('GetListItems')\n        soap_request.add_parameter('listName', 'UserInfo')\n\n        # Set Row Limit\n        soap_request.add_parameter('rowLimit', str(rowlimit))\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('GetListItems'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code != 200:\n            raise ConnectionError('GetUsers GetListItems request failed')\n        try:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n        except:\n            raise ConnectionError(\"GetUsers GetListItems response failed to parse correctly\")\n        listitems = envelope[0][0][0][0][0]\n        data = []\n        for row in listitems:\n            # Strip the 'ows_' from the beginning with key[4:]\n            data.append({key[4:]: value for (key, value) in row.items() if key[4:]})\n\n            return {'py': {i['ImnName']: i['ID'] + ';#' + i['ImnName'] for i in data},\n                    'sp': {i['ID'] + ';#' + i['ImnName']: i['ImnName'] for i in data}}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef List(self, listName, exclude_hidden_fields=False):\n        return _List(self._session, listName, self._url, self._verify_ssl, self.users, self.huge_tree, self.timeout, exclude_hidden_fields=exclude_hidden_fields)", "response": "List the details of a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_to_internal(self, data):\n        for _dict in data:\n            keys = list(_dict.keys())[:]\n            for key in keys:\n                if key not in self._disp_cols:\n                    raise Exception(key + ' not a column in current List.')\n                _dict[self._disp_cols[key]['name']] = self._sp_type(key, _dict.pop(key))", "response": "Convert from internal to external"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting from Column Title to Column Title", "response": "def _convert_to_display(self, data):\n        \"\"\"From 'Column_x0020_Title' to  'Column Title'\"\"\"\n        for _dict in data:\n            keys = list(_dict.keys())[:]\n            for key in keys:\n                if key not in self._sp_cols:\n                    raise Exception(key + ' not a column in current List.')\n                _dict[self._sp_cols[key]['name']] = self._python_type(key, _dict.pop(key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns proper type from the schema", "response": "def _python_type(self, key, value):\n        \"\"\"Returns proper type from the schema\"\"\"\n        try:\n            field_type = self._sp_cols[key]['type']\n            if field_type in ['Number', 'Currency']:\n                return float(value)\n            elif field_type == 'DateTime':\n\n\n                # Need to remove the '123;#' from created dates, but we will do it for all dates\n                # self.date_format = re.compile('\\d+-\\d+-\\d+ \\d+:\\d+:\\d+')\n                value = self.date_format.search(value).group(0)\n                \n                # NOTE: I used to round this just date (7/28/2018)\n                return datetime.strptime(value, '%Y-%m-%d %H:%M:%S')\n            elif field_type == 'Boolean':\n                if value == '1':\n                    return 'Yes'\n                elif value == '0':\n                    return 'No'\n                else:\n                    return ''\n            elif field_type in ('User', 'UserMulti'):\n                # Sometimes the User no longer exists or\n                # has a diffrent ID number so we just remove the \"123;#\"\n                # from the beginning of their name\n                if value in self.users['sp']:\n                    return self.users['sp'][value]\n                elif '#' in value:\n                    return value.split('#')[1]\n                else:\n                    return value\n            else:\n                return value\n        except AttributeError:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning proper type from the schema", "response": "def _sp_type(self, key, value):\n        \"\"\"Returns proper type from the schema\"\"\"\n        try:\n            field_type = self._disp_cols[key]['type']\n            if field_type in ['Number', 'Currency']:\n                return value\n            elif field_type == 'DateTime':\n                return value.strftime('%Y-%m-%d %H:%M:%S')\n            elif field_type == 'Boolean':\n                if value == 'Yes':\n                    return '1'\n                elif value == 'No':\n                    return '0'\n                else:\n                    raise Exception(\"%s not a valid Boolean Value, only 'Yes' or 'No'\" % value)\n            elif field_type == 'User':\n                return self.users['py'][value]\n            else:\n                return value\n        except AttributeError:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget Items from current list.", "response": "def GetListItems(self, viewname=None, fields=None, query=None, rowlimit=0, debug=False):\n        \"\"\"Get Items from current list\n           rowlimit defaulted to 0 (unlimited)\n        \"\"\"\n\n        # Build Request\n        soap_request = soap('GetListItems')\n        soap_request.add_parameter('listName', self.listName)\n        # Convert Displayed View Name to View ID\n        if viewname:\n            soap_request.add_parameter('viewName', self.views[viewname]['Name'][1:-1])\n\n        # Add viewFields\n        if fields:\n            # Convert to SharePoint Style Column Names\n            for i, val in enumerate(fields):\n                fields[i] = self._disp_cols[val]['name']\n            viewfields = fields\n            soap_request.add_view_fields(fields)\n            # Check for viewname and query\n            if [viewname, query] == [None, None]:\n                # Add a query if the viewname and query are not provided\n                # We sort by 'ID' here Ascending is the default\n                soap_request.add_query({'OrderBy': ['ID']})\n\n        elif viewname:\n            viewfields = self.GetView(viewname)['fields']  ## Might be wrong\n        else:\n            # No fields or views provided so get everything\n            viewfields = [x for x in self._sp_cols]\n\n        # Add query\n        if query:\n\n            if 'Where' in query:\n                where = etree.Element('Where')\n\n                parents = []\n                parents.append(where)\n                for i, field in enumerate(query['Where']):\n                    if field == 'And':\n                        parents.append(etree.SubElement(parents[-1], 'And'))\n                    elif field == 'Or':\n                        if parents[-1].tag == 'Or':\n                            parents.pop()\n                        parents.append(etree.SubElement(parents[-1], 'Or'))\n                    else:\n                        _type = etree.SubElement(parents[-1], field[0])\n                        field_ref = etree.SubElement(_type, 'FieldRef')\n                        field_ref.set('Name', self._disp_cols[field[1]]['name'])\n                        if len(field) == 3:\n                            value = etree.SubElement(_type, 'Value')\n                            value.set('Type', self._disp_cols[field[1]]['type'])\n                            value.text = self._sp_type(field[1], field[2])\n\n                query['Where'] = where\n\n            soap_request.add_query(query)\n\n        # Set Row Limit\n        soap_request.add_parameter('rowLimit', str(rowlimit))\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('GetListItems'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            listitems = envelope[0][0][0][0][0]\n            data = []\n            for row in listitems:\n                # Strip the 'ows_' from the beginning with key[4:]\n                data.append({key[4:]: value for (key, value) in row.items() if key[4:] in viewfields})\n\n            self._convert_to_display(data)\n\n            if debug:\n                return response\n            else:\n                return data\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetList(self):\n\n        # Build Request\n        soap_request = soap('GetList')\n        soap_request.add_parameter('listName', self.listName)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('GetList'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            _list = envelope[0][0][0][0]\n            info = {key: value for (key, value) in _list.items()}\n            for row in _list[0].getchildren():\n                self.fields.append({key: value for (key, value) in row.items()})\n\n            for setting in _list[1].getchildren():\n                self.regional_settings[\n                    setting.tag.strip('{http://schemas.microsoft.com/sharepoint/soap/}')] = setting.text\n\n            for setting in _list[2].getchildren():\n                self.server_settings[\n                    setting.tag.strip('{http://schemas.microsoft.com/sharepoint/soap/}')] = setting.text\n            fields = envelope[0][0][0][0][0]\n\n        else:\n            raise Exception(\"ERROR:\", response.status_code, response.text)", "response": "Get Info on Current List\n          "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetView(self, viewname):\n\n        # Build Request\n        soap_request = soap('GetView')\n        soap_request.add_parameter('listName', self.listName)\n\n        if viewname == None:\n            views = self.GetViewCollection()\n            for view in views:\n                if 'DefaultView' in view:\n                    if views[view]['DefaultView'] == 'TRUE':\n                        viewname = view\n                        break\n\n        if self.listName not in ['UserInfo', 'User Information List']:\n            soap_request.add_parameter('viewName', self.views[viewname]['Name'][1:-1])\n        else:\n            soap_request.add_parameter('viewName', viewname)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Views'),\n                                      headers=self._headers('GetView'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            view = envelope[0][0][0][0]\n            info = {key: value for (key, value) in view.items()}\n            fields = [x.items()[0][1] for x in view[1]]\n            return {'info': info, 'fields': fields}\n\n        else:\n            raise Exception(\"ERROR:\", response.status_code, response.text)", "response": "Get Info on View Name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetViewCollection(self):\n\n        # Build Request\n        soap_request = soap('GetViewCollection')\n        soap_request.add_parameter('listName', self.listName)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Views'),\n                                      headers=self._headers('GetViewCollection'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            views = envelope[0][0][0][0]\n            data = []\n            for row in views.getchildren():\n                data.append({key: value for (key, value) in row.items()})\n            view = {}\n            for row in data:\n                view[row['DisplayName']] = row\n            return view\n\n        else:\n            return (\"ERROR\", response.status_code)", "response": "Get Views for Current List\n          "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate List Items kind = 'New', 'Update', or 'Delete' New: Provide data like so: data = [{'Title': 'New Title', 'Col1': 'New Value'}] Update: Provide data like so: data = [{'ID': 23, 'Title': 'Updated Title'}, {'ID': 28, 'Col1': 'Updated Value'}] Delete: Just provied a list of ID's data = [23, 28]", "response": "def UpdateListItems(self, data, kind):\n        \"\"\"Update List Items\n           kind = 'New', 'Update', or 'Delete'\n\n           New:\n           Provide data like so:\n               data = [{'Title': 'New Title', 'Col1': 'New Value'}]\n\n           Update:\n           Provide data like so:\n               data = [{'ID': 23, 'Title': 'Updated Title'},\n                       {'ID': 28, 'Col1': 'Updated Value'}]\n\n           Delete:\n           Just provied a list of ID's\n               data = [23, 28]\n        \"\"\"\n        if type(data) != list:\n            raise Exception('data must be a list of dictionaries')\n        # Build Request\n        soap_request = soap('UpdateListItems')\n        soap_request.add_parameter('listName', self.listName)\n        if kind != 'Delete':\n            self._convert_to_internal(data)\n        soap_request.add_actions(data, kind)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('UpdateListItems'),\n                                      data=str(soap_request),\n                                      verify=self._verify_ssl,\n                                      timeout=self.timeout)\n\n        # Parse Response\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            results = envelope[0][0][0][0]\n            data = {}\n            for result in results:\n                if result.text != '0x00000000' and result[0].text != '0x00000000':\n                    data[result.attrib['ID']] = (result[0].text, result[1].text)\n                else:\n                    data[result.attrib['ID']] = result[0].text\n            return data\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetAttachmentCollection(self, _id):\n\n        # Build Request\n        soap_request = soap('GetAttachmentCollection')\n        soap_request.add_parameter('listName', self.listName)\n        soap_request.add_parameter('listItemID', _id)\n        self.last_request = str(soap_request)\n\n        # Send Request\n        response = self._session.post(url=self._url('Lists'),\n                                      headers=self._headers('GetAttachmentCollection'),\n                                      data=str(soap_request),\n                                      verify=False,\n                                      timeout=self.timeout)\n\n        # Parse Request\n        if response.status_code == 200:\n            envelope = etree.fromstring(response.text.encode('utf-8'), parser=etree.XMLParser(huge_tree=self.huge_tree))\n            attaches = envelope[0][0][0][0]\n            attachments = []\n            for attachment in attaches.getchildren():\n                attachments.append(attachment.text)\n            return attachments\n        else:\n            return response", "response": "Get Attachments for given List Item ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list dict of the changes of the two dictionaries that exist in both dictionaries and user must provide an ID column for the new_cmp_dict", "response": "def changes(new_cmp_dict, old_cmp_dict, id_column, columns):\n    \"\"\"Return a list dict of the changes of the\n       rows that exist in both dictionaries\n       User must provide an ID column for old_cmp_dict\n    \"\"\"\n\n    update_ldict = []\n    same_keys = set(new_cmp_dict).intersection(set(old_cmp_dict))\n    for same_key in same_keys:\n        # Get the Union of the set of keys\n        # for both dictionaries to account\n        # for missing keys\n        old_dict = old_cmp_dict[same_key]\n        new_dict = new_cmp_dict[same_key]\n        dict_keys = set(old_dict).intersection(set(new_dict))\n\n        update_dict = {}\n        for dict_key in columns:\n            old_val = old_dict.get(dict_key, 'NaN')\n            new_val = new_dict.get(dict_key, 'NaN')\n            if old_val != new_val and new_val != 'NaN':\n                if id_column!=None:\n                    try:\n                        update_dict[id_column] = old_dict[id_column]\n                    except KeyError:\n                        print(\"Input Dictionary 'old_cmp_dict' must have ID column\")\n                update_dict[dict_key] = new_val\n        if update_dict:\n            update_ldict.append(update_dict)\n    return update_ldict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list dict of uggers the unique keys in new_cmp_dict", "response": "def unique(new_cmp_dict, old_cmp_dict):\n    \"\"\"Return a list dict of\n       the unique keys in new_cmp_dict\n    \"\"\"\n    newkeys = set(new_cmp_dict)\n    oldkeys = set(old_cmp_dict)\n    unique = newkeys - oldkeys\n    unique_ldict = []\n    for key in unique:\n        unique_ldict.append(new_cmp_dict[key])\n    return unique_ldict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef full_dict(ldict, keys):\n    if type(keys) == str:\n        keys = [keys]\n    else:\n        keys = keys\n\n    cmp_dict = {}\n    for line in ldict:\n        index = []\n        for key in keys:\n            index.append(str(line.get(key, '')))\n        index = '-'.join(index)\n        cmp_dict[index] = line\n\n    return cmp_dict", "response": "Return Comparison Dictionaries\n       from list dict on keys\n      "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef BooleanSlice(input_vertex: vertex_constructor_param_types, dimension: int, index: int, label: Optional[str]=None) -> Vertex:\n    return Boolean(context.jvm_view().BooleanSliceVertex, label, cast_to_vertex(input_vertex), cast_to_integer(dimension), cast_to_integer(index))", "response": "Takes the slice along a given dimension and index of a vertex\n    \n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Bernoulli(prob_true: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Boolean(context.jvm_view().BernoulliVertex, label, cast_to_double_vertex(prob_true))", "response": "Returns a Bernoulli vertex that is a shaped copy of prob_true."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Addition(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().AdditionVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))", "response": "Adds one vertex to another"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the arc tangent angle between x and y.", "response": "def ArcTan2(x: vertex_constructor_param_types, y: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Calculates the signed angle, in radians, between the positive x-axis and a ray to the point (x, y) from the origin\n    \n    :param x: x coordinate\n    :param y: y coordinate\n    \"\"\"\n    return Double(context.jvm_view().ArcTan2Vertex, label, cast_to_double_vertex(x), cast_to_double_vertex(y))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Difference(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().DifferenceVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))", "response": "Returns a Difference vertex that subtracts one vertex from another."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Division vertex that divides two nodes by another.", "response": "def Division(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Divides one vertex by another\n    \n    :param left: the vertex to be divided\n    :param right: the vertex to divide\n    \"\"\"\n    return Double(context.jvm_view().DivisionVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef MatrixMultiplication(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().MatrixMultiplicationVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))", "response": "Matrix multiplies one vertex by another. C = AB\n    \n    :param left: vertex A\n    :param right: vertex B"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the maximum between two vertices.", "response": "def Max(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Finds the maximum between two vertices\n    \n    :param left: one of the vertices to find the maximum of\n    :param right: one of the vertices to find the maximum of\n    \"\"\"\n    return Double(context.jvm_view().MaxVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the minimum between two vertices.", "response": "def Min(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Finds the minimum between two vertices\n    \n    :param left: one of the vertices to find the minimum of\n    :param right: one of the vertices to find the minimum of\n    \"\"\"\n    return Double(context.jvm_view().MinVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmultiplies one vertex by another.", "response": "def Multiplication(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Multiplies one vertex by another\n    \n    :param left: vertex to be multiplied\n    :param right: vertex to be multiplied\n    \"\"\"\n    return Double(context.jvm_view().MultiplicationVertex, label, cast_to_double_vertex(left), cast_to_double_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a vertex to the power of another base and exponent.", "response": "def Power(base: vertex_constructor_param_types, exponent: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Raises a vertex to the power of another\n    \n    :param base: the base vertex\n    :param exponent: the exponent vertex\n    \"\"\"\n    return Double(context.jvm_view().PowerVertex, label, cast_to_double_vertex(base), cast_to_double_vertex(exponent))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Abs(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().AbsVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the absolute value of the input vertex."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ArcCos(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().ArcCosVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the inverse cosine of a vertex."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ArcSin(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().ArcSinVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the inverse sin of a vertex."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ArcTan(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().ArcTanVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the inverse tan of a vertex."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Ceil(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().CeilVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns a ceiling value of the input vertex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Cos(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().CosVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the cosine of a vertex."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Exp(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().ExpVertex, label, cast_to_double_vertex(input_vertex))", "response": "Calculates the exponential of an input vertex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the Floor operator to a vertex.", "response": "def Floor(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Applies the Floor operator to a vertex.\n    This maps a vertex to the biggest integer less than or equal to its value\n    \n    :param input_vertex: the vertex to be floor'd\n    \"\"\"\n    return Double(context.jvm_view().FloorVertex, label, cast_to_double_vertex(input_vertex))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef LogGamma(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().LogGammaVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the log of the gamma of the input vertex."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Log(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().LogVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns the natural logarithm of a vertex."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies the Round operator to a vertex.", "response": "def Round(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Applies the Rounding operator to a vertex.\n    This maps a vertex to the nearest integer value\n    \n    :param input_vertex: the vertex to be rounded\n    \"\"\"\n    return Double(context.jvm_view().RoundVertex, label, cast_to_double_vertex(input_vertex))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Sigmoid(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().SigmoidVertex, label, cast_to_double_vertex(input_vertex))", "response": "Returns a sigmoid function that applies the sigmoid function to a vertex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the sine of a vertex.", "response": "def Sin(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Takes the sine of a vertex. Sin(vertex).\n    \n    :param input_vertex: the vertex\n    \"\"\"\n    return Double(context.jvm_view().SinVertex, label, cast_to_double_vertex(input_vertex))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking the slice along a given dimension and index of a vertex", "response": "def Slice(input_vertex: vertex_constructor_param_types, dimension: int, index: int, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Takes the slice along a given dimension and index of a vertex\n    \n    :param input_vertex: the input vertex\n    :param dimension: the dimension to extract along\n    :param index: the index of extraction\n    \"\"\"\n    return Double(context.jvm_view().SliceVertex, label, cast_to_double_vertex(input_vertex), cast_to_integer(dimension), cast_to_integer(index))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Sum(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().SumVertex, label, cast_to_double_vertex(input_vertex))", "response": "Computes a sum across all dimensions of the node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Take(input_vertex: vertex_constructor_param_types, index: Collection[int], label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().TakeVertex, label, cast_to_double_vertex(input_vertex), cast_to_long_array(index))", "response": "A vertex that extracts a scalar at a given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the tangent of a vertex.", "response": "def Tan(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Takes the tangent of a vertex. Tan(vertex).\n    \n    :param input_vertex: the vertex\n    \"\"\"\n    return Double(context.jvm_view().TanVertex, label, cast_to_double_vertex(input_vertex))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Beta(alpha: vertex_constructor_param_types, beta: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().BetaVertex, label, cast_to_double_vertex(alpha), cast_to_double_vertex(beta))", "response": "Returns a new vertex that is mapped to the beta of alpha and beta."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a ChiSquared vertex that maps some shape of k to a matching shaped ChiSquared vertex.", "response": "def ChiSquared(k: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    One to one constructor for mapping some shape of k to\n    a matching shaped ChiSquared.\n    \n    :param k: the number of degrees of freedom\n    \"\"\"\n    return Double(context.jvm_view().ChiSquaredVertex, label, cast_to_integer_vertex(k))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a Dirichlet vertex that matches a vector of concentration values.", "response": "def Dirichlet(concentration: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Matches a vector of concentration values to a Dirichlet distribution\n    \n    :param concentration: the concentration values of the dirichlet\n    \"\"\"\n    return Double(context.jvm_view().DirichletVertex, label, cast_to_double_vertex(concentration))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new exponential vertex that is equal to the given rate.", "response": "def Exponential(rate: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    One to one constructor for mapping some shape of rate to matching shaped exponential.\n    \n    :param rate: the rate of the Exponential with either the same shape as specified for this vertex or scalar\n    \"\"\"\n    return Double(context.jvm_view().ExponentialVertex, label, cast_to_double_vertex(rate))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Gamma(theta: vertex_constructor_param_types, k: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().GammaVertex, label, cast_to_double_vertex(theta), cast_to_double_vertex(k))", "response": "Returns a new vertex that maps some shape of theta and k to a Shaped Gamma vertex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new vertex that is the inverse Gamma of the given vertex.", "response": "def InverseGamma(alpha: vertex_constructor_param_types, beta: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    One to one constructor for mapping some shape of alpha and beta to\n    alpha matching shaped Inverse Gamma.\n    \n    :param alpha: the alpha of the Inverse Gamma with either the same shape as specified for this vertex or alpha scalar\n    :param beta: the beta of the Inverse Gamma with either the same shape as specified for this vertex or alpha scalar\n    \"\"\"\n    return Double(context.jvm_view().InverseGammaVertex, label, cast_to_double_vertex(alpha), cast_to_double_vertex(beta))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a Laplace vertex that maps some shape of mu and sigma to a matching shaped Laplace.", "response": "def Laplace(mu: vertex_constructor_param_types, beta: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    One to one constructor for mapping some shape of mu and sigma to\n    a matching shaped Laplace.\n    \n    :param mu: the mu of the Laplace with either the same shape as specified for this vertex or a scalar\n    :param beta: the beta of the Laplace with either the same shape as specified for this vertex or a scalar\n    \"\"\"\n    return Double(context.jvm_view().LaplaceVertex, label, cast_to_double_vertex(mu), cast_to_double_vertex(beta))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new Multivariate Gaussian with the given mu and covariance matrix.", "response": "def MultivariateGaussian(mu: vertex_constructor_param_types, covariance: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Matches a mu and covariance of some shape to a Multivariate Gaussian\n    \n    :param mu: the mu of the Multivariate Gaussian\n    :param covariance: the covariance matrix of the Multivariate Gaussian\n    \"\"\"\n    return Double(context.jvm_view().MultivariateGaussianVertex, label, cast_to_double_vertex(mu), cast_to_double_vertex(covariance))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Triangular(x_min: vertex_constructor_param_types, x_max: vertex_constructor_param_types, c: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().TriangularVertex, label, cast_to_double_vertex(x_min), cast_to_double_vertex(x_max), cast_to_double_vertex(c))", "response": "Return a vertex that maps some shape of xMin xMax and c to a shaped triangular vertex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Uniform(x_min: vertex_constructor_param_types, x_max: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Double(context.jvm_view().UniformVertex, label, cast_to_double_vertex(x_min), cast_to_double_vertex(x_max))", "response": "Returns a new Uniform vertex that maps some shape of mu and sigma to a shaped Uniform vertex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef IntegerAddition(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Integer(context.jvm_view().IntegerAdditionVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))", "response": "Adds one vertex to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef IntegerDifference(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Integer(context.jvm_view().IntegerDifferenceVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))", "response": "Subtracts one vertex from another."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef IntegerDivision(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Integer(context.jvm_view().IntegerDivisionVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))", "response": "Returns a vertex that divides one vertex by another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the maximum between two vertices.", "response": "def IntegerMax(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Finds the maximum between two vertices\n    \n    :param left: one of the vertices to find the maximum of\n    :param right: one of the vertices to find the maximum of\n    \"\"\"\n    return Integer(context.jvm_view().IntegerMaxVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the minimum between two vertices.", "response": "def IntegerMin(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Finds the minimum between two vertices\n    \n    :param left: one of the vertices to find the minimum of\n    :param right: one of the vertices to find the minimum of\n    \"\"\"\n    return Integer(context.jvm_view().IntegerMinVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmultiply one vertex by another.", "response": "def IntegerMultiplication(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Multiplies one vertex by another\n    \n    :param left: a vertex to be multiplied\n    :param right: a vertex to be multiplied\n    \"\"\"\n    return Integer(context.jvm_view().IntegerMultiplicationVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new vertex that is the power of two base vertexes.", "response": "def IntegerPower(left: vertex_constructor_param_types, right: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Raises one vertex to the power of another\n    \n    :param left: the base vertex\n    :param right: the exponent vertex\n    \"\"\"\n    return Integer(context.jvm_view().IntegerPowerVertex, label, cast_to_integer_vertex(left), cast_to_integer_vertex(right))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the absolute value of a vertex.", "response": "def IntegerAbs(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Takes the absolute value of a vertex\n    \n    :param input_vertex: the vertex\n    \"\"\"\n    return Integer(context.jvm_view().IntegerAbsVertex, label, cast_to_integer_vertex(input_vertex))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake the slice along a given dimension and index of a vertex", "response": "def IntegerSlice(input_vertex: vertex_constructor_param_types, dimension: int, index: int, label: Optional[str]=None) -> Vertex:\n    \"\"\"\n    Takes the slice along a given dimension and index of a vertex\n    \n    :param input_vertex: the input vertex\n    :param dimension: the dimension to extract along\n    :param index: the index of extraction\n    \"\"\"\n    return Integer(context.jvm_view().IntegerSliceVertex, label, cast_to_integer_vertex(input_vertex), cast_to_integer(dimension), cast_to_integer(index))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef IntegerSum(input_vertex: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Integer(context.jvm_view().IntegerSumVertex, label, cast_to_integer_vertex(input_vertex))", "response": "Computes a sum of the values of all dimensions in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef IntegerTake(input_vertex: vertex_constructor_param_types, index: Collection[int], label: Optional[str]=None) -> Vertex:\n    return Integer(context.jvm_view().IntegerTakeVertex, label, cast_to_integer_vertex(input_vertex), cast_to_long_array(index))", "response": "A vertex that extracts a scalar at a given index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Poisson(mu: vertex_constructor_param_types, label: Optional[str]=None) -> Vertex:\n    return Integer(context.jvm_view().PoissonVertex, label, cast_to_double_vertex(mu))", "response": "Returns a new vertex that maps some shape of mu to a shaped Poisson tensor or scalar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Assert(predicate: vertex_constructor_param_types, error_message: str, label: Optional[str]=None) -> Vertex:\n    return Boolean(context.jvm_view().AssertVertex, label, cast_to_vertex(predicate), error_message)", "response": "A helper method that creates an assert vertex that is all true on the current node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef traceplot(trace: sample_types, labels: List[Union[str, Tuple[str, str]]] = None, ax: Any = None,\n              x0: int = 0) -> Any:\n    \"\"\"\n    Plot samples values.\n\n    :param trace:  result of MCMC run\n    :param labels: labels of vertices to be plotted. if None, all vertices are plotted.\n    :param ax: Matplotlib axes\n    :param x0: index of first data point, used for sample stream plots\n    \"\"\"\n\n    if labels is None:\n        labels = list(trace.keys())\n\n    if ax is None:\n        _, ax = plt.subplots(len(labels), 1, squeeze=False)\n\n    for index, label in enumerate(labels):\n        data = [sample for sample in trace[label]]\n\n        ax[index][0].set_title(label)\n        ax[index][0].plot(__integer_xaxis(ax[index][0], x0, len(data)), data)\n\n    __pause_for_crude_animation()\n\n    return ax", "response": "Plots samples values for the MCMC run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsample from a list of vertices in a Bayesian Network.", "response": "def sample(net: BayesNet,\n           sample_from: Iterable[Vertex],\n           sampling_algorithm: PosteriorSamplingAlgorithm = None,\n           draws: int = 500,\n           drop: int = 0,\n           down_sample_interval: int = 1,\n           plot: bool = False,\n           ax: Any = None) -> sample_types:\n    \"\"\"\n    :param net: Bayesian Network containing latent variables.\n    :param sample_from: Vertices to include in the returned samples.\n    :param sampling_algorithm: The posterior sampling algorithm to use.\n        Options are :class:`keanu.algorithm.MetropolisHastingsSampler`, :class:`keanu.algorithm.NUTSSampler` and :class:`keanu.algorithm.ForwardSampler`\n        If not set, :class:`keanu.algorithm.MetropolisHastingsSampler` is chosen with 'prior' as its proposal distribution.\n    :param draws: The number of samples to take.\n    :param drop: The number of samples to drop before collecting anything.\n        If this is zero then no samples will be dropped before collecting.\n    :param down_sample_interval: Collect 1 sample for every `down_sample_interval`.\n        If this is 1 then there will be no down-sampling.\n        If this is 2 then every other sample will be taken.\n        If this is 3 then 2 samples will be dropped before one is taken.\n        And so on.\n    :param plot: Flag for plotting the trace after sampling.\n        Call `matplotlib.pyplot.show <https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html>`_ to display the plot.\n    :param Axes ax: `matplotlib.axes.Axes <https://matplotlib.org/api/axes_api.html>`_.\n        If not set, a new one is created.\n\n    :raises ValueError: If `sample_from` contains vertices without labels.\n\n    :return: Dictionary of samples at an index (tuple) for each vertex label (str). If all the vertices in `sample_from` are scalar, the dictionary is only keyed by label.\n    \"\"\"\n\n    sample_from = list(sample_from)\n    id_to_label = __check_if_vertices_are_labelled(sample_from)\n\n    if sampling_algorithm is None:\n        sampling_algorithm = MetropolisHastingsSampler(proposal_distribution=\"prior\", latents=sample_from)\n\n    vertices_unwrapped: JavaList = k.to_java_object_list(sample_from)\n\n    probabilistic_model = ProbabilisticModel(net) if (\n        isinstance(sampling_algorithm, MetropolisHastingsSampler) or\n        isinstance(sampling_algorithm, ForwardSampler)) else ProbabilisticModelWithGradient(net)\n\n    network_samples: JavaObject = sampling_algorithm.get_sampler().getPosteriorSamples(\n        probabilistic_model.unwrap(), vertices_unwrapped, draws).drop(drop).downSample(down_sample_interval)\n\n    if __all_scalar(sample_from):\n        vertex_samples = __create_single_indexed_samples(network_samples, vertices_unwrapped, id_to_label)\n    else:\n        vertex_samples = __create_multi_indexed_samples(vertices_unwrapped, network_samples, id_to_label)\n\n    if plot:\n        traceplot(vertex_samples, ax=ax)\n\n    return vertex_samples"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates samples from a list of vertices.", "response": "def generate_samples(net: BayesNet,\n                     sample_from: Iterable[Vertex],\n                     sampling_algorithm: PosteriorSamplingAlgorithm = None,\n                     drop: int = 0,\n                     down_sample_interval: int = 1,\n                     live_plot: bool = False,\n                     refresh_every: int = 100,\n                     ax: Any = None) -> sample_generator_types:\n    \"\"\"\n    :param net: Bayesian Network containing latent variables.\n    :param sample_from: Vertices to include in the returned samples.\n    :param sampling_algorithm: The posterior sampling algorithm to use.\n        Options are :class:`keanu.algorithm.MetropolisHastingsSampler` and :class:`keanu.algorithm.NUTSSampler`.\n        If not set, :class:`keanu.algorithm.MetropolisHastingsSampler` is chosen with 'prior' as its proposal distribution.\n    :param drop: The number of samples to drop before collecting anything.\n        If this is zero then no samples will be dropped before collecting.\n    :param down_sample_interval: Collect 1 sample for every `down_sample_interval`.\n        If this is 1 then there will be no down-sampling.\n        If this is 2 then every other sample will be taken.\n        If this is 3 then 2 samples will be dropped before one is taken.\n    :param live_plot: Flag for plotting the trace while sampling.\n        Call `matplotlib.pyplot.show <https://matplotlib.org/api/_as_gen/matplotlib.pyplot.show.html>`_ to display the plot.\n    :param refresh_every: Period of plot updates (in sample number).\n    :param Axes ax: `matplotlib.axes.Axes <https://matplotlib.org/api/axes_api.html>`_.\n        If not set, a new one is created.\n\n    :raises ValueError: If `sample_from` contains vertices without labels.\n\n    :return: Dictionary of samples at an index (tuple) for each vertex label (str). If all the vertices in `sample_from` are scalar, the dictionary is only keyed by label.\n    \"\"\"\n    sample_from = list(sample_from)\n    id_to_label = __check_if_vertices_are_labelled(sample_from)\n\n    if sampling_algorithm is None:\n        sampling_algorithm = MetropolisHastingsSampler(proposal_distribution=\"prior\", latents=sample_from)\n\n    vertices_unwrapped: JavaList = k.to_java_object_list(sample_from)\n\n    probabilistic_model = ProbabilisticModel(net) if isinstance(\n        sampling_algorithm, MetropolisHastingsSampler) else ProbabilisticModelWithGradient(net)\n    samples: JavaObject = sampling_algorithm.get_sampler().generatePosteriorSamples(probabilistic_model.unwrap(),\n                                                                                    vertices_unwrapped)\n    samples = samples.dropCount(drop).downSampleInterval(down_sample_interval)\n    sample_iterator: JavaObject = samples.stream().iterator()\n\n    all_are_scalar = __all_scalar(sample_from)\n\n    return _samples_generator(\n        sample_iterator,\n        vertices_unwrapped,\n        live_plot=live_plot,\n        refresh_every=refresh_every,\n        ax=ax,\n        all_scalar=all_are_scalar,\n        id_to_label=id_to_label)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a file and add all snippets to the snippet_store dictionary", "response": "def read_file_snippets(file, snippet_store):\n    \"\"\"Parse a file and add all snippets to the snippet_store dictionary\"\"\"\n    start_reg = re.compile(\"(.*%%SNIPPET_START%% )([a-zA-Z0-9]+)\")\n    end_reg = re.compile(\"(.*%%SNIPPET_END%% )([a-zA-Z0-9]+)\")\n    open_snippets = {}\n    with open(file, encoding=\"utf-8\") as w:\n        lines = w.readlines()\n\n        for line in lines:\n            printd(\"Got Line: {}\".format(line))\n            # Check whether we're entering or leaving a snippet\n            m = start_reg.match(line)\n            if m:\n                printd(\"Opened Snippet {}\".format(m.group(2)))\n                if m.group(2) in snippet_store:\n                    record_error(\"Repeat definition of Snippet {}\".format(m.group(2)))\n                elif m.group(2) in open_snippets:\n                    record_error(\"Snippet already opened {}\".format(m.group(2)))\n                else:\n                    printd(\"Added {} to open snippets list\".format(m.group(2)))\n                    open_snippets[m.group(2)] = []\n                continue\n\n            m = end_reg.match(line)\n            if m:\n                printd(\"Found end of Snippet {}\".format(m.group(2)))\n                if m.group(2) not in open_snippets:\n                    record_error(\"Reached Snippet End but no start\")\n                elif m.group(2) in snippet_store:\n                    record_error(\"Repeat definition of Snippet {}\".format(m.group(2)))\n                else:\n                    snippet_store[m.group(2)] = open_snippets[m.group(2)]\n                    del open_snippets[m.group(2)]\n                continue\n\n            # If we've got this far, then we're just a normal line, so we can add this to all open snippets\n            for snippet in open_snippets.values():\n                printd(\"Adding Line to snippet\")\n                snippet.append(line)\n\n        # Now, warn about any unclosed snippets\n        for opened in open_snippets:\n            record_error(\"Snippet {} left open - ignoring\".format(opened))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_block_whitespace(string_list):\n    min_ws = min([(len(x) - len(x.lstrip())) for x in string_list if x != '\\n'])\n    return [x[min_ws:] if x != '\\n' else x for x in string_list]", "response": "Treats a list of strings as a code block and strips\n        whitespace so that the min whitespace line sits at char 0 of line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing args and process all files in the input directory and process all new files in the output directory", "response": "def main():\n    \"\"\"Parse args (expects source and dest doc directories and snippet source dir)\n       read all snippets and then process the input files\n       writing out the new versions to the output location\"\"\"\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_dir\", help=\"The Input file directory\", default=\"doc_templates/\")\n    parser.add_argument(\"--output_dir\", help=\"Where to store the processed files\", default=\"current_docs/\")\n    parser.add_argument(\"--java_src_dir\", help=\"Where Java snippet source files are located\",\n                        default=\"src/test/java/io/improbable/snippet/\")\n    parser.add_argument(\"--python_src_dir\", help=\"Where Python snippet source files are located\",\n                        default=\"src/test/python/\")\n    parser.add_argument(\"--debug\", action='store_true', help=\"Turn on script debugging\")\n\n    args = parser.parse_args()\n    if args.debug:\n        logging.basicConfig(level=logging.DEBUG)\n\n    snippet_store = {}\n    for_all_files_in_dir(args.java_src_dir, lambda x: read_file_snippets(args.java_src_dir + x, snippet_store))\n    for_all_files_in_dir(args.python_src_dir, lambda x: read_file_snippets(args.python_src_dir + x, snippet_store))\n    stripped_snippet_store = {k: strip_block_whitespace(v) for k, v in snippet_store.items()}\n    printd(str(stripped_snippet_store))\n    check_output_dir_exists(args.output_dir)\n    for_all_in_subdirs(args.input_dir, lambda x: do_rewrites(x,\n                                                             args.input_dir,\n                                                             args.output_dir,\n                                                             stripped_snippet_store))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a proxy vertex for the given label and adds to the sequence item .", "response": "def add_double_proxy_for(self, label: str, shape: Collection[int] = None) -> Vertex:\n        \"\"\"\n        Creates a proxy vertex for the given label and adds to the sequence item\n        \"\"\"\n        if shape is None:\n            return Vertex._from_java_vertex(self.unwrap().addDoubleProxyFor(_VertexLabel(label).unwrap()))\n        else:\n            return Vertex._from_java_vertex(self.unwrap().addDoubleProxyFor(_VertexLabel(label).unwrap(), shape))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a proxy vertex for the given label and adds to the sequence item .", "response": "def add_integer_proxy_for(self, label: str, shape: Collection[int] = None) -> Vertex:\n        \"\"\"\n        Creates a proxy vertex for the given label and adds to the sequence item\n        \"\"\"\n        if shape is None:\n            return Vertex._from_java_vertex(self.unwrap().addIntegerProxyFor(_VertexLabel(label).unwrap()))\n        else:\n            return Vertex._from_java_vertex(self.unwrap().addIntegerProxyFor(_VertexLabel(label).unwrap(), shape))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a boolean proxy vertex for the given label and adds to the sequence item .", "response": "def add_boolean_proxy_for(self, label: str, shape: Collection[int] = None) -> Vertex:\n        \"\"\"\n        Creates a proxy vertex for the given label and adds to the sequence item\n        \"\"\"\n        if shape is None:\n            return Vertex._from_java_vertex(self.unwrap().addBooleanProxyFor(_VertexLabel(label).unwrap()))\n        else:\n            return Vertex._from_java_vertex(self.unwrap().addBooleanProxyFor(_VertexLabel(label).unwrap(), shape))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares for streaming and send HTTP headers.", "response": "async def prepare(self, request):\n        \"\"\"Prepare for streaming and send HTTP headers.\n\n        :param request: regular aiohttp.web.Request.\n        \"\"\"\n        if request.method != 'GET':\n            raise HTTPMethodNotAllowed(request.method, ['GET'])\n\n        if not self.prepared:\n            writer = await super().prepare(request)\n            self._loop = request.app.loop\n            self._ping_task = self._loop.create_task(self._ping())\n            # explicitly enabling chunked encoding, since content length\n            # usually not known beforehand.\n            self.enable_chunked_encoding()\n            return writer\n        else:\n            # hackish way to check if connection alive\n            # should be updated once we have proper API in aiohttp\n            # https://github.com/aio-libs/aiohttp/issues/3105\n            if request.protocol.transport is None:\n                # request disconnected\n                raise asyncio.CancelledError()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send(self, data, id=None, event=None, retry=None):\n        buffer = io.StringIO()\n        if id is not None:\n            buffer.write(self.LINE_SEP_EXPR.sub('', 'id: {}'.format(id)))\n            buffer.write(self._sep)\n\n        if event is not None:\n            buffer.write(self.LINE_SEP_EXPR.sub('', 'event: {}'.format(event)))\n            buffer.write(self._sep)\n\n        for chunk in self.LINE_SEP_EXPR.split(data):\n            buffer.write('data: {}'.format(chunk))\n            buffer.write(self._sep)\n\n        if retry is not None:\n            if not isinstance(retry, int):\n                raise TypeError('retry argument must be int')\n            buffer.write('retry: {}'.format(retry))\n            buffer.write(self._sep)\n\n        buffer.write(self._sep)\n        await self.write(buffer.getvalue().encode('utf-8'))", "response": "Send data using EventSource protocol."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits for the response to be sent to the client.", "response": "async def wait(self):\n        \"\"\"EventSourceResponse object is used for streaming data to the client,\n        this method returns future, so we can wain until connection will\n        be closed or other task explicitly call ``stop_streaming`` method.\n        \"\"\"\n        if self._ping_task is None:\n            raise RuntimeError('Response is not started')\n        with contextlib.suppress(asyncio.CancelledError):\n            await self._ping_task"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ping_interval(self, value):\n\n        if not isinstance(value, int):\n            raise TypeError(\"ping interval must be int\")\n        if value < 0:\n            raise ValueError(\"ping interval must be greater then 0\")\n\n        self._ping_interval = value", "response": "Setter for ping_interval property."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a parser. Args: segmenter (str): Segmenter to use. options (:obj:`dict`, optional): Optional settings. Returns: Parser (:obj:`budou.parser.Parser`) Raises: ValueError: If unsupported segmenter is specified.", "response": "def get_parser(segmenter, **options):\n  \"\"\"Gets a parser.\n\n  Args:\n    segmenter (str): Segmenter to use.\n    options (:obj:`dict`, optional): Optional settings.\n\n  Returns:\n    Parser (:obj:`budou.parser.Parser`)\n\n  Raises:\n    ValueError: If unsupported segmenter is specified.\n  \"\"\"\n  if segmenter == 'nlapi':\n    return NLAPIParser(**options)\n  elif segmenter == 'mecab':\n    return MecabParser()\n  elif segmenter == 'tinysegmenter':\n    return TinysegmenterParser()\n  else:\n    raise ValueError('Segmenter {} is not supported.'.format(segmenter))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_attributes(attributes=None, classname=None):\n  if not attributes:\n    attributes = {}\n  attributes.setdefault('class', DEFAULT_CLASS_NAME)\n  # If `classname` is specified, it overwrites `class` property in `attributes`.\n  if classname:\n    attributes['class'] = classname\n  return attributes", "response": "Parses attributes and class property."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove unnecessary break lines and white spaces.", "response": "def preprocess(source):\n  \"\"\"Removes unnecessary break lines and white spaces.\n\n  Args:\n    source (str): Input sentence.\n\n  Returns:\n    Preprocessed sentence. (str)\n  \"\"\"\n  doc = html5lib.parseFragment(source)\n  source = ET.tostring(doc, encoding='utf-8', method='text').decode('utf-8')\n  source = source.replace(u'\\n', u'').strip()\n  source = re.sub(r'\\s\\s+', u' ', source)\n  return source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef segment(self, source, language=None):\n    if language and not language in self.supported_languages:\n      raise ValueError(\n          'Language {} is not supported by NLAPI segmenter'.format(language))\n\n    chunks = ChunkList()\n    results = tinysegmenter.tokenize(source)\n    seek = 0\n    for word in results:\n      word = word.strip()\n      if not word:\n        continue\n      if source[seek: seek + len(word)] != word:\n        assert source[seek] == ' '\n        assert source[seek + 1: seek + len(word) + 1] == word\n        chunks.append(Chunk.space())\n        seek += 1\n\n      dependency = None\n      if word in _PARTICLES or word in _AUX_VERBS or is_hiragana(word):\n        dependency = False\n\n      chunk = Chunk(word, dependency=dependency)\n      if chunk.is_punct():\n        chunk.dependency = chunk.is_open_punct()\n      chunks.append(chunk)\n      seek += len(word)\n    chunks.resolve_dependencies()\n    return chunks", "response": "Returns a list of chunks from the given source string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of chunks from the given source string.", "response": "def segment(self, source, language=None):\n    \"\"\"Returns a chunk list from the given sentence.\n\n    Args:\n      source (str): Source string to segment.\n      language (:obj:`str`, optional): A language code.\n\n    Returns:\n      A chunk list. (:obj:`budou.chunk.ChunkList`)\n\n    Raises:\n      ValueError: If :obj:`language` is given and it is not included in\n                  :obj:`supported_languages`.\n    \"\"\"\n    if language and not language in self.supported_languages:\n      raise ValueError(\n          'Language {} is not supported by MeCab segmenter'.format(language))\n\n    chunks = ChunkList()\n    seek = 0\n    source_str = source.encode('utf-8') if six.PY2 else source\n    results = self.tagger.parse(source_str).split('\\n')[:-2]\n    for row in results:\n      if six.PY2:\n        row = row.decode('utf-8')\n      token = row.split('\\t')\n      word = token[0]\n      labels = token[3].split('-')\n      pos = labels[0]\n      label = labels[1] if len(labels) > 1 else None\n      if source[seek: seek + len(word)] != word:\n        assert source[seek] == ' '\n        assert source[seek + 1: seek + len(word) + 1] == word\n        chunks.append(Chunk.space())\n        seek += 1\n\n      dependency = None\n      if pos in _DEPENDENT_POS_FORWARD:\n        dependency = True\n      elif pos in _DEPENDENT_POS_BACKWARD:\n        dependency = False\n      elif label in _DEPENDENT_LABEL_FORWARD:\n        dependency = True\n      elif label in _DEPENDENT_LABEL_BACKWARD:\n        dependency = False\n\n      chunk = Chunk(word, pos=pos, label=label, dependency=dependency)\n      if chunk.is_punct():\n        chunk.dependency = chunk.is_open_punct()\n      chunks.append(chunk)\n      seek += len(word)\n    chunks.resolve_dependencies()\n    return chunks"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(source, segmenter='nlapi', language=None, max_length=None,\n          classname=None, attributes=None, **kwargs):\n  \"\"\"Parses input source.\n\n  Args:\n    source (str): Input source to process.\n    segmenter (:obj:`str`, optional): Segmenter to use [default: nlapi].\n    language (:obj:`str`, optional): Language code.\n    max_length (:obj:`int`, optional): Maximum length of a chunk.\n    classname (:obj:`str`, optional): Class name of output SPAN tags.\n    attributes (:obj:`dict`, optional): Attributes for output SPAN tags.\n\n  Returns:\n    Results in a dict. :code:`chunks` holds a list of chunks\n    (:obj:`budou.chunk.ChunkList`) and :code:`html_code` holds the output HTML\n    code.\n  \"\"\"\n  parser = get_parser(segmenter, **kwargs)\n  return parser.parse(\n      source, language=language, max_length=max_length, classname=classname,\n      attributes=attributes)", "response": "Parses input source.\n\n  Args:\n    source (str): Input source to process.\n    segmenter (:obj:`str`, optional): Segmenter to use [default: nlapi].\n    language (:obj:`str`, optional): Language code.\n    max_length (:obj:`int`, optional): Maximum length of a chunk.\n    classname (:obj:`str`, optional): Class name of output SPAN tags.\n    attributes (:obj:`dict`, optional): Attributes for output SPAN tags.\n\n  Returns:\n    Results in a dict. :code:`chunks` holds a list of chunks\n    (:obj:`budou.chunk.ChunkList`) and :code:`html_code` holds the output HTML\n    code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authenticate(json_path=None):\n  msg = ('budou.authentication() is deprecated. '\n         'Please use budou.get_parser() to obtain a parser instead.')\n  warnings.warn(msg, DeprecationWarning)\n  parser = get_parser('nlapi', credentials_path=json_path)\n  return parser", "response": "Returns a Natural Language API parser by authenticating the API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef segment(self, source, language=None):\n    if language and not language in self.supported_languages:\n      raise ValueError(\n          'Language {} is not supported by NLAPI segmenter'.format(language))\n\n    chunks, language = self._get_source_chunks(source, language=language)\n    if self.use_entity:\n      entities = self._get_entities(source, language=language)\n      chunks = self._group_chunks_by_entities(chunks, entities)\n    chunks.resolve_dependencies()\n    return chunks", "response": "Returns a list of chunks from the given source string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_source_chunks(self, input_text, language=None):\n    chunks = ChunkList()\n    seek = 0\n    result = self._get_annotations(input_text, language=language)\n    tokens = result['tokens']\n    language = result['language']\n    for i, token in enumerate(tokens):\n      word = token['text']['content']\n      begin_offset = token['text']['beginOffset']\n      label = token['dependencyEdge']['label']\n      pos = token['partOfSpeech']['tag']\n      if begin_offset > seek:\n        chunks.append(Chunk.space())\n        seek = begin_offset\n      chunk = Chunk(word, pos, label)\n      if chunk.label in _DEPENDENT_LABEL:\n        # Determining concatenating direction based on syntax dependency.\n        chunk.dependency = i < token['dependencyEdge']['headTokenIndex']\n      if chunk.is_punct():\n        chunk.dependency = chunk.is_open_punct()\n      chunks.append(chunk)\n      seek += len(word)\n    return chunks, language", "response": "Returns a list of chunks retrieved from Syntax Analysis results."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngroups chunks by entities retrieved from NL API Entity Analysis.", "response": "def _group_chunks_by_entities(self, chunks, entities):\n    \"\"\"Groups chunks by entities retrieved from NL API Entity Analysis.\n\n    Args:\n      chunks (:obj:`budou.chunk.ChunkList`): List of chunks to be processed.\n      entities (:obj:`list` of :obj:`dict`): List of entities.\n\n    Returns:\n      A chunk list. (:obj:`budou.chunk.ChunkList`)\n    \"\"\"\n    for entity in entities:\n      chunks_to_concat = chunks.get_overlaps(\n          entity['beginOffset'], len(entity['content']))\n      if not chunks_to_concat:\n        continue\n      new_chunk_word = u''.join([chunk.word for chunk in chunks_to_concat])\n      new_chunk = Chunk(new_chunk_word)\n      chunks.swap(chunks_to_concat, new_chunk)\n    return chunks"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of annotations retrieved from the given text.", "response": "def _get_annotations(self, text, language=''):\n    \"\"\"Returns the list of annotations retrieved from the given text.\n\n    Args:\n      text (str): Input text.\n      language (:obj:`str`, optional): Language code.\n\n    Returns:\n      Results in a dictionary. :code:`tokens` contains the list of annotations\n      and :code:`language` contains the inferred language from the input.\n    \"\"\"\n    body = {\n        'document': {\n            'type': 'PLAIN_TEXT',\n            'content': text,\n        },\n        'features': {\n            'extract_syntax': True,\n        },\n        'encodingType': 'UTF32',\n    }\n    if language:\n      body['document']['language'] = language\n\n    request = self.service.documents().annotateText(body=body)\n    response = request.execute()\n    tokens = response.get('tokens', [])\n    language = response.get('language')\n\n    return {'tokens': tokens, 'language': language}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of entities retrieved from the given text.", "response": "def _get_entities(self, text, language=''):\n    \"\"\"Returns the list of entities retrieved from the given text.\n\n    Args:\n      text (str): Input text.\n      language (:obj:`str`, optional): Language code.\n\n    Returns:\n      List of entities.\n    \"\"\"\n    body = {\n        'document': {\n            'type': 'PLAIN_TEXT',\n            'content': text,\n        },\n        'encodingType': 'UTF32',\n    }\n    if language:\n      body['document']['language'] = language\n\n    request = self.service.documents().analyzeEntities(body=body)\n    response = request.execute()\n    result = []\n    for entity in response.get('entities', []):\n      mentions = entity.get('mentions', [])\n      if not mentions:\n        continue\n      entity_text = mentions[0]['text']\n      offset = entity_text['beginOffset']\n      for word in entity_text['content'].split():\n        result.append({'content': word, 'beginOffset': offset})\n        offset += len(word)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a value by a key.", "response": "def get(self, key):\n    \"\"\"Gets a value by a key.\n\n    Args:\n      key (str): Key to retrieve the value.\n\n    Returns: Retrieved value.\n    \"\"\"\n    self._create_file_if_none_exists()\n    with open(self.filename, 'rb') as file_object:\n      cache_pickle = pickle.load(file_object)\n      val = cache_pickle.get(key, None)\n      return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, key, val):\n    self._create_file_if_none_exists()\n    with open(self.filename, 'r+b') as file_object:\n      cache_pickle = pickle.load(file_object)\n      cache_pickle[key] = val\n      file_object.seek(0)\n      pickle.dump(cache_pickle, file_object)", "response": "Sets a value in a key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize(self):\n    return {\n        'word': self.word,\n        'pos': self.pos,\n        'label': self.label,\n        'dependency': self.dependency,\n        'has_cjk': self.has_cjk(),\n    }", "response": "Returns serialized chunk data in dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the word of the chunk contains any CJK characters.", "response": "def has_cjk(self):\n    \"\"\"Checks if the word of the chunk contains CJK characters.\n\n    This is using unicode codepoint ranges from\n    https://github.com/nltk/nltk/blob/develop/nltk/tokenize/util.py#L149\n\n    Returns:\n      bool: True if the chunk has any CJK character.\n    \"\"\"\n    cjk_codepoint_ranges = [\n        (4352, 4607), (11904, 42191), (43072, 43135), (44032, 55215),\n        (63744, 64255), (65072, 65103), (65381, 65500), (131072, 196607)]\n    for char in self.word:\n      if any([start <= ord(char) <= end\n              for start, end in cjk_codepoint_ranges]):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_overlaps(self, offset, length):\n    # In case entity's offset points to a space just before the entity.\n    if ''.join([chunk.word for chunk in self])[offset] == ' ':\n      offset += 1\n    index = 0\n    result = ChunkList()\n    for chunk in self:\n      if offset < index + len(chunk.word) and index < offset + length:\n        result.append(chunk)\n      index += len(chunk.word)\n    return result", "response": "Returns a list of chunks that overlap with the given range."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswap old consecutive chunks with new chunk.", "response": "def swap(self, old_chunks, new_chunk):\n    \"\"\"Swaps old consecutive chunks with new chunk.\n\n    Args:\n      old_chunks (:obj:`budou.chunk.ChunkList`): List of consecutive Chunks to\n          be removed.\n      new_chunk (:obj:`budou.chunk.Chunk`): A Chunk to be inserted.\n    \"\"\"\n    indexes = [self.index(chunk) for chunk in old_chunks]\n    del self[indexes[0]:indexes[-1] + 1]\n    self.insert(indexes[0], new_chunk)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_dependencies(self):\n    self._concatenate_inner(True)\n    self._concatenate_inner(False)\n    self._insert_breaklines()", "response": "Resolves chunk dependency by concatenating them."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _concatenate_inner(self, direction):\n    tmp_bucket = []\n    source_chunks = self if direction else self[::-1]\n    target_chunks = ChunkList()\n    for chunk in source_chunks:\n      if (\n          # if the chunk has matched dependency, do concatenation.\n          chunk.dependency == direction or\n          # if the chunk is SPACE, concatenate to the previous chunk.\n          (direction is False and chunk.is_space())\n          ):\n        tmp_bucket.append(chunk)\n        continue\n      tmp_bucket.append(chunk)\n      if not direction:\n        tmp_bucket = tmp_bucket[::-1]\n      new_word = ''.join([tmp_chunk.word for tmp_chunk in tmp_bucket])\n      new_chunk = Chunk(new_word, pos=chunk.pos, label=chunk.label,\n                        dependency=chunk.dependency)\n      target_chunks.append(new_chunk)\n      tmp_bucket = ChunkList()\n    if tmp_bucket:\n      target_chunks += tmp_bucket\n    if not direction:\n      target_chunks = target_chunks[::-1]\n    self.list = target_chunks", "response": "Concatenates chunks based on each chunk s dependency."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert a breakline instead of a trailing space if the chunk is in CJK.", "response": "def _insert_breaklines(self):\n    \"\"\"Inserts a breakline instead of a trailing space if the chunk is in CJK.\n    \"\"\"\n    target_chunks = ChunkList()\n    for chunk in self:\n      if chunk.word[-1] == ' ' and chunk.has_cjk():\n        chunk.word = chunk.word[:-1]\n        target_chunks.append(chunk)\n        target_chunks.append(chunk.breakline())\n      else:\n        target_chunks.append(chunk)\n    self.list = target_chunks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef html_serialize(self, attributes, max_length=None):\n    doc = ET.Element('span')\n    for chunk in self:\n      if (chunk.has_cjk() and\n          not (max_length and len(chunk.word) > max_length)):\n        ele = ET.Element('span')\n        ele.text = chunk.word\n        for key, val in attributes.items():\n          ele.attrib[key] = val\n        doc.append(ele)\n      else:\n        # add word without span tag for non-CJK text (e.g. English)\n        # by appending it after the last element\n        if doc.getchildren():\n          if doc.getchildren()[-1].tail is None:\n            doc.getchildren()[-1].tail = chunk.word\n          else:\n            doc.getchildren()[-1].tail += chunk.word\n        else:\n          if doc.text is None:\n            doc.text = chunk.word\n          else:\n            doc.text += chunk.word\n    result = ET.tostring(doc, encoding='utf-8').decode('utf-8')\n    result = html5lib.serialize(\n        html5lib.parseFragment(result), sanitize=True,\n        quote_attr_values='always')\n    return result", "response": "Returns the HTML code of the chunk in this list with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef poll(target, step, args=(), kwargs=None, timeout=None, max_tries=None, check_success=is_truthy,\n         step_function=step_constant, ignore_exceptions=(), poll_forever=False, collect_values=None, *a, **k):\n    \"\"\"Poll by calling a target function until a certain condition is met. You must specify at least a target\n    function to be called and the step -- base wait time between each function call.\n\n    :param step: Step defines the amount of time to wait (in seconds)\n    :param args: Arguments to be passed to the target function\n    :type kwargs: dict\n    :param kwargs: Keyword arguments to be passed to the target function\n    :param timeout: The target function will be called until the time elapsed is greater than the maximum timeout\n    (in seconds). NOTE that the actual execution time of the function *can* exceed the time specified in the timeout.\n    For instance, if the target function takes 10 seconds to execute and the timeout is 21 seconds, the polling\n    function will take a total of 30 seconds (two iterations of the target --20s which is less than the timeout--21s,\n    and a final iteration)\n    :param max_tries: Maximum number of times the target function will be called before failing\n    :param check_success: A callback function that accepts the return value of the target function. It should\n    return true if you want the polling function to stop and return this value. It should return false if you want it\n    to continue executing. The default is a callback that tests for truthiness (anything not False, 0, or empty\n    collection).\n    :param step_function: A callback function that accepts each iteration's \"step.\" By default, this is constant,\n    but you can also pass a function that will increase or decrease the step. As an example, you can increase the wait\n    time between calling the target function by 10 seconds every iteration until the step is 100 seconds--at which\n    point it should remain constant at 100 seconds\n\n    >>> def my_step_function(step):\n    >>>     step += 10\n    >>>     return max(step, 100)\n\n    :type ignore_exceptions: tuple\n    :param ignore_exceptions: You can specify a tuple of exceptions that should be caught and ignored on every\n    iteration. If the target function raises one of these exceptions, it will be caught and the exception\n    instance will be pushed to the queue of values collected during polling. Any other exceptions raised will be\n    raised as normal.\n    :param poll_forever: If set to true, this function will retry until an exception is raised or the target's\n    return value satisfies the check_success function. If this is not set, then a timeout or a max_tries must be set.\n    :type collect_values: Queue\n    :param collect_values: By default, polling will create a new Queue to store all of the target's return values.\n    Optionally, you can specify your own queue to collect these values for access to it outside of function scope.\n    :return: Polling will return first value from the target function that meets the condions of the check_success\n    callback. By default, this will be the first value that is not None, 0, False, '', or an empty collection.\n    \"\"\"\n\n    assert (timeout is not None or max_tries is not None) or poll_forever, \\\n        ('You did not specify a maximum number of tries or a timeout. Without either of these set, the polling '\n         'function will poll forever. If this is the behavior you want, pass \"poll_forever=True\"')\n\n    assert not ((timeout is not None or max_tries is not None) and poll_forever), \\\n        'You cannot specify both the option to poll_forever and max_tries/timeout.'\n\n    kwargs = kwargs or dict()\n    values = collect_values or Queue()\n\n    max_time = time.time() + timeout if timeout else None\n    tries = 0\n\n    last_item = None\n    while True:\n\n        if max_tries is not None and tries >= max_tries:\n            raise MaxCallException(values, last_item)\n\n        try:\n            val = target(*args, **kwargs)\n            last_item = val\n        except ignore_exceptions as e:\n            last_item = e\n        else:\n            # Condition passes, this is the only \"successful\" exit from the polling function\n            if check_success(val):\n                return val\n\n        values.put(last_item)\n        tries += 1\n\n        # Check the time after to make sure the poll function is called at least once\n        if max_time is not None and time.time() >= max_time:\n            raise TimeoutException(values, last_item)\n\n        time.sleep(step)\n        step = step_function(step)", "response": "Poll the target function for a certain amount of time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the subdirectory that an etextno will be found in a gutenberg mirror.", "response": "def _etextno_to_uri_subdirectory(etextno):\n    \"\"\"Returns the subdirectory that an etextno will be found in a gutenberg\n    mirror. Generally, one finds the subdirectory by separating out each digit\n    of the etext number, and uses it for a directory. The exception here is for\n    etext numbers less than 10, which are prepended with a 0 for the directory\n    traversal.\n\n    >>> _etextno_to_uri_subdirectory(1)\n    '0/1'\n    >>> _etextno_to_uri_subdirectory(19)\n    '1/19'\n    >>> _etextno_to_uri_subdirectory(15453)\n    '1/5/4/5/15453'\n    \"\"\"\n    str_etextno = str(etextno).zfill(2)\n    all_but_last_digit = list(str_etextno[:-1])\n    subdir_part = \"/\".join(all_but_last_digit)\n    subdir = \"{}/{}\".format(subdir_part, etextno)  # etextno not zfilled\n    return subdir"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _format_download_uri_for_extension(etextno, extension, mirror=None):\n    mirror = mirror or _GUTENBERG_MIRROR\n    root = mirror.strip().rstrip('/')\n    path = _etextno_to_uri_subdirectory(etextno)\n\n    uri = '{root}/{path}/{etextno}{extension}'.format(\n        root=root,\n        path=path,\n        etextno=etextno,\n        extension=extension)\n\n    return uri", "response": "Returns the download location on the Project Gutenberg servers for a given text and extension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the download location on the Project Gutenberg servers for the given text.", "response": "def _format_download_uri(etextno, mirror=None, prefer_ascii=False):\n    \"\"\"Returns the download location on the Project Gutenberg servers for a\n    given text.\n\n    Use prefer_ascii to control whether you want to fetch plaintext us-ascii\n    file first (default old behavior) or if you prefer UTF-8 then 8-bits then\n    plaintext.\n\n    Raises:\n        UnknownDownloadUri: If no download location can be found for the text.\n    \"\"\"\n    mirror = mirror or _GUTENBERG_MIRROR\n    if not _does_mirror_exist(mirror):\n        raise UnknownDownloadUriException(\n            'Could not reach Gutenberg mirror \"{:s}\". Try setting a '\n            'different mirror (https://www.gutenberg.org/MIRRORS.ALL) for '\n            '--mirror flag or GUTENBERG_MIRROR environment variable.'\n            .format(mirror))\n\n    # Check https://www.gutenberg.org/files/ for details about available\n    # extensions ;\n    #  - .txt is plaintext us-ascii\n    #  - -8.txt is 8-bit plaintext, multiple encodings\n    #  - -0.txt is UTF-8\n    ascii_first = ('.txt', '-0.txt', '-8.txt')\n    utf8_first = ('-0.txt', '-8.txt', '.txt')\n    extensions = ascii_first if prefer_ascii else utf8_first\n    for extension in extensions:\n        uri = _format_download_uri_for_extension(etextno, extension, mirror)\n        if _does_uri_exist(uri):\n            return uri\n\n    raise UnknownDownloadUriException(\n        'Failed to find a textual download candidate for {} on {}. '\n        'Either the book does not exist or it is only available in '\n        'non-textual formats.'\n        .format(etextno, mirror))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a unicode representation of the full body of a Project Gutenberg text.", "response": "def load_etext(etextno, refresh_cache=False, mirror=None, prefer_ascii=False):\n    \"\"\"Returns a unicode representation of the full body of a Project Gutenberg\n    text. After making an initial remote call to Project Gutenberg's servers,\n    the text is persisted locally.\n\n    \"\"\"\n    etextno = validate_etextno(etextno)\n    cached = os.path.join(_TEXT_CACHE, '{}.txt.gz'.format(etextno))\n\n    if refresh_cache:\n        remove(cached)\n    if not os.path.exists(cached):\n        makedirs(os.path.dirname(cached))\n        download_uri = _format_download_uri(etextno, mirror, prefer_ascii)\n        response = requests.get(download_uri)\n        # Ensure proper UTF-8 saving. There might be instances of ebooks or\n        # mirrors which advertise a broken encoding, and this will break\n        # downstream usages. For example, #55517 from aleph.gutenberg.org:\n        #\n        # from gutenberg.acquire import load_etext\n        # print(load_etext(55517, refresh_cache=True)[0:1000])\n        #\n        # response.encoding will be 'ISO-8859-1' while the file is UTF-8\n        if response.encoding != response.apparent_encoding:\n            response.encoding = response.apparent_encoding\n        text = response.text\n        with closing(gzip.open(cached, 'w')) as cache:\n            cache.write(text.encode('utf-8'))\n\n    with closing(gzip.open(cached, 'r')) as cache:\n        text = cache.read().decode('utf-8')\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _main():\n    from argparse import ArgumentParser, FileType\n    from gutenberg import Error\n    from gutenberg._util.os import reopen_encoded\n\n    parser = ArgumentParser(description='Download a Project Gutenberg text')\n    parser.add_argument('etextno', type=int)\n    parser.add_argument('outfile', type=FileType('w'))\n    parser.add_argument('--mirror', '-m', type=str, default=None)\n    parser.add_argument('--prefer-ascii', '-a', type=bool, default=False)\n    args = parser.parse_args()\n\n    try:\n        text = load_etext(args.etextno,\n                          mirror=args.mirror,\n                          prefer_ascii=args.prefer_ascii)\n        with reopen_encoded(args.outfile, 'w', 'utf8') as outfile:\n            outfile.write(text)\n    except Error as error:\n        parser.error(str(error))", "response": "The main function of the module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makedirs(*args, **kwargs):\n    try:\n        os.makedirs(*args, **kwargs)\n    except OSError as ex:\n        if ex.errno != errno.EEXIST:\n            raise", "response": "Wrapper around os. makedirs that doesn t raise an exception if the the\nCTYPE directory already exists."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(path):\n    if not os.path.exists(path):\n        return\n\n    if os.path.isdir(path):\n        return shutil.rmtree(path)\n\n    if os.path.isfile(path):\n        return os.remove(path)", "response": "Wrapper that switches between os. remove and shutil. rmtree depending on whether the provided path is a file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef determine_encoding(path, default=None):\n    byte_order_marks = (\n        ('utf-8-sig', (codecs.BOM_UTF8, )),\n        ('utf-16', (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE)),\n        ('utf-32', (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE)),\n    )\n\n    try:\n        with open(path, 'rb') as infile:\n            raw = infile.read(4)\n    except IOError:\n        return default\n\n    for encoding, boms in byte_order_marks:\n        if any(raw.startswith(bom) for bom in boms):\n            return encoding\n\n    return default", "response": "Determines the encoding of a file based on byte order marks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking sure that a file was opened with some valid encoding.", "response": "def reopen_encoded(fileobj, mode='r', fallback_encoding=None):\n    \"\"\"Makes sure that a file was opened with some valid encoding.\n\n    Arguments:\n        fileobj (file): The file-object.\n        mode (str, optional): The mode in which to re-open the file.\n        fallback_encoding (str, optional): The encoding in which to re-open\n            the file if it does not specify an encoding itself.\n\n    Returns:\n        file: The re-opened file.\n\n    \"\"\"\n    encoding = determine_encoding(fileobj.name, fallback_encoding)\n    fileobj.close()\n    return open(fileobj.name, mode, encoding=encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip_headers(text):\n    lines = text.splitlines()\n    sep = str(os.linesep)\n\n    out = []\n    i = 0\n    footer_found = False\n    ignore_section = False\n\n    for line in lines:\n        reset = False\n\n        if i <= 600:\n            # Check if the header ends here\n            if any(line.startswith(token) for token in TEXT_START_MARKERS):\n                reset = True\n\n            # If it's the end of the header, delete the output produced so far.\n            # May be done several times, if multiple lines occur indicating the\n            # end of the header\n            if reset:\n                out = []\n                continue\n\n        if i >= 100:\n            # Check if the footer begins here\n            if any(line.startswith(token) for token in TEXT_END_MARKERS):\n                footer_found = True\n\n            # If it's the beginning of the footer, stop output\n            if footer_found:\n                break\n\n        if any(line.startswith(token) for token in LEGALESE_START_MARKERS):\n            ignore_section = True\n            continue\n        elif any(line.startswith(token) for token in LEGALESE_END_MARKERS):\n            ignore_section = False\n            continue\n\n        if not ignore_section:\n            out.append(line.rstrip(sep))\n            i += 1\n\n    return sep.join(out)", "response": "Remove lines that are part of the Project Gutenberg header or footer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _main():\n    from argparse import ArgumentParser, FileType\n    from gutenberg import Error\n    from gutenberg._util.os import reopen_encoded\n\n    parser = ArgumentParser(description='Remove headers and footers from a '\n                                        'Project Gutenberg text')\n    parser.add_argument('infile', type=FileType('r'))\n    parser.add_argument('outfile', type=FileType('w'))\n    args = parser.parse_args()\n\n    try:\n        with reopen_encoded(args.infile, 'r', 'utf8') as infile:\n            text = infile.read()\n            clean_text = strip_headers(text)\n\n        with reopen_encoded(args.outfile, 'w', 'utf8') as outfile:\n            outfile.write(clean_text)\n    except Error as error:\n        parser.error(str(error))", "response": "The main function of the module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_metadata(feature_name, etextno):\n    metadata_values = MetadataExtractor.get(feature_name).get_metadata(etextno)\n    return frozenset(metadata_values)", "response": "Looks up the value of a meta - data feature for a given text."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks up all the texts that have meta - data matching some criterion.", "response": "def get_etexts(feature_name, value):\n    \"\"\"Looks up all the texts that have meta-data matching some criterion.\n\n    Arguments:\n        feature_name (str): The meta-data on which to select the texts.\n        value (str): The value of the meta-data on which to filter the texts.\n\n    Returns:\n        frozenset: The set of all the Project Gutenberg text identifiers that\n            match the provided query.\n\n    Raises:\n        UnsupportedFeature: If there is no MetadataExtractor registered that\n            can extract meta-data for the given feature name.\n\n    \"\"\"\n    matching_etexts = MetadataExtractor.get(feature_name).get_etexts(value)\n    return frozenset(matching_etexts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _uri_to_etext(cls, uri_ref):\n        try:\n            return validate_etextno(int(os.path.basename(uri_ref.toPython())))\n        except InvalidEtextIdException:\n            return None", "response": "Converts the representation used to identify a text in the the\n        meta - data RDF graph to a human - friendly integer text identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _implementations(cls):\n        if cls.__implementations:\n            return cls.__implementations\n\n        cls.__implementations = {}\n        for implementation in all_subclasses(MetadataExtractor):\n            try:\n                feature_name = implementation.feature_name()\n                cls.__implementations[feature_name] = implementation\n            except NotImplementedError:\n                pass\n        return cls.__implementations", "response": "Returns all the concrete subclasses of MetadataExtractor.\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the MetadataExtractor that can extract information about the specified feature name.", "response": "def get(feature_name):\n        \"\"\"Returns the MetadataExtractor that can extract information about the\n        provided feature name.\n\n        Raises:\n            UnsupportedFeature: If no extractor exists for the feature name.\n\n        \"\"\"\n        implementations = MetadataExtractor._implementations()\n        try:\n            return implementations[feature_name]\n        except KeyError:\n            raise UnsupportedFeatureException(\n                'no MetadataExtractor registered for feature \"{feature_name}\" '\n                '(try any of the following: {supported_features})'\n                .format(feature_name=feature_name,\n                        supported_features=', '.join(sorted(implementations))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the metadata cache object to use.", "response": "def set_metadata_cache(cache):\n    \"\"\"Sets the metadata cache object to use.\n\n    \"\"\"\n    global _METADATA_CACHE\n\n    if _METADATA_CACHE and _METADATA_CACHE.is_open:\n        _METADATA_CACHE.close()\n\n    _METADATA_CACHE = cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new metadata cache instance appropriate for this platform.", "response": "def _create_metadata_cache(cache_location):\n    \"\"\"Creates a new metadata cache instance appropriate for this platform.\n\n    \"\"\"\n    cache_url = os.getenv('GUTENBERG_FUSEKI_URL')\n    if cache_url:\n        return FusekiMetadataCache(cache_location, cache_url)\n\n    try:\n        return SleepycatMetadataCache(cache_location)\n    except InvalidCacheException:\n        logging.warning('Unable to create cache based on BSD-DB. '\n                        'Falling back to SQLite backend. '\n                        'Performance may be degraded significantly.')\n\n    return SqliteMetadataCache(cache_location)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_metadata(refresh_cache=False):\n    cache = get_metadata_cache()\n\n    if refresh_cache:\n        cache.refresh()\n\n    if not cache.is_open:\n        cache.open()\n\n    return cache.graph", "response": "Returns a graph representing all Project Gutenberg texts and their associated metadata."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens an existing cache.", "response": "def open(self):\n        \"\"\"Opens an existing cache.\n\n        \"\"\"\n        try:\n            self.graph.open(self.cache_uri, create=False)\n            self._add_namespaces(self.graph)\n            self.is_open = True\n        except Exception:\n            raise InvalidCacheException('The cache is invalid or not created')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npopulate a new cache.", "response": "def populate(self):\n        \"\"\"Populates a new cache.\n\n        \"\"\"\n        if self.exists:\n            raise CacheAlreadyExistsException('location: %s' % self.cache_uri)\n\n        self._populate_setup()\n\n        with closing(self.graph):\n            with self._download_metadata_archive() as metadata_archive:\n                for fact in self._iter_metadata_triples(metadata_archive):\n                    self._add_to_graph(fact)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrefresh the cache by deleting the old one and creating a new one.", "response": "def refresh(self):\n        \"\"\"Refresh the cache by deleting the old one and creating a new one.\n\n        \"\"\"\n        if self.exists:\n            self.delete()\n        self.populate()\n        self.open()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _download_metadata_archive(self):\n        with tempfile.NamedTemporaryFile(delete=False) as metadata_archive:\n            shutil.copyfileobj(urlopen(self.catalog_source), metadata_archive)\n        yield metadata_archive.name\n        remove(metadata_archive.name)", "response": "Makes a remote call to the Project Gutenberg servers and downloads\n            the entire Project Gutenberg meta - data catalog. The function returns a file - pointer to the file - pointer to the file - object that is returned by the function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _metadata_is_invalid(cls, fact):\n        return any(isinstance(token, URIRef) and ' ' in token\n                   for token in fact)", "response": "Determines if the fact is well formed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield all meta - data of Project Gutenberg texts contained in the catalog dump.", "response": "def _iter_metadata_triples(cls, metadata_archive_path):\n        \"\"\"Yields all meta-data of Project Gutenberg texts contained in the\n        catalog dump.\n\n        \"\"\"\n        pg_rdf_regex = re.compile(r'pg\\d+.rdf$')\n        with closing(tarfile.open(metadata_archive_path)) as metadata_archive:\n            for item in metadata_archive:\n                if pg_rdf_regex.search(item.name):\n                    with disable_logging():\n                        extracted = metadata_archive.extractfile(item)\n                        graph = Graph().parse(extracted)\n                    for fact in graph:\n                        if cls._metadata_is_invalid(fact):\n                            logging.info('skipping invalid triple %s', fact)\n                        else:\n                            yield fact"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _populate_setup(self):\n        makedirs(os.path.dirname(self._cache_marker))\n        with codecs.open(self._cache_marker, 'w', encoding='utf-8') as fobj:\n            fobj.write(self.cache_uri)\n        self.graph.open(self.cache_uri)", "response": "Create a marker file and graph for the cache_uri."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self):\n        MetadataCache.delete(self)\n        try:\n            self.graph.query('DELETE WHERE { ?s ?p ?o . }')\n        except ResultException:\n            # this is often just a false positive since Jena Fuseki does not\n            # return tuples for a deletion query, so swallowing the exception\n            # here is fine\n            logging.exception('error when deleting graph')", "response": "Deletes the local marker file and also any data in the Fuseki server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that the cache location is valid and raises an exception if not.", "response": "def _check_can_be_instantiated(cls, cache_location):\n        \"\"\"Pre-conditions: the cache location is the URL to a Fuseki server\n        and the SPARQLWrapper library exists (transitive dependency of\n        RDFlib's sparqlstore).\n\n        \"\"\"\n        if not any(cache_location.startswith(prefix)\n                   for prefix in cls._CACHE_URL_PREFIXES):\n            raise InvalidCacheException('cache location is not a Fuseki url')\n\n        try:\n            from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore\n        except ImportError:\n            raise InvalidCacheException('unable to import sparql store')\n        del SPARQLUpdateStore"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _metadata_is_invalid(cls, fact):\n        return (MetadataCache._metadata_is_invalid(fact)\n                or any(isinstance(token, BNode) for token in fact))", "response": "Returns True if the given fact is invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef all_subclasses(cls):\n    subclasses = cls.__subclasses__()\n    descendants = (descendant for subclass in subclasses\n                   for descendant in all_subclasses(subclass))\n    return set(subclasses) | set(descendants)", "response": "Recursively returns all the subclasses of the provided class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n\n    scheme_names = sorted(six.iterkeys(SCHEME))\n    version_str = pkg_resources.get_distribution('ansi2html').version\n    parser = optparse.OptionParser(\n        usage=main.__doc__,\n        version=\"%%prog %s\" % version_str)\n    parser.add_option(\n        \"-p\", \"--partial\", dest=\"partial\",\n        default=False, action=\"store_true\",\n        help=\"Process lines as them come in.  No headers are produced.\")\n    parser.add_option(\n        \"-L\", \"--latex\", dest=\"latex\",\n        default=False, action=\"store_true\",\n        help=\"Export as LaTeX instead of HTML.\")\n    parser.add_option(\n        \"-i\", \"--inline\", dest=\"inline\",\n        default=False, action=\"store_true\",\n        help=\"Inline style without headers or template.\")\n    parser.add_option(\n        \"-H\", \"--headers\", dest=\"headers\",\n        default=False, action=\"store_true\",\n        help=\"Just produce the <style> tag.\")\n    parser.add_option(\n        \"-f\", '--font-size', dest='font_size', metavar='SIZE',\n        default=\"normal\",\n        help=\"Set the global font size in the output.\")\n    parser.add_option(\n        \"-l\", '--light-background', dest='light_background',\n        default=False, action=\"store_true\",\n        help=\"Set output to 'light background' mode.\")\n    parser.add_option(\n        \"-W\", '--no-line-wrap', dest='no_line_wrap',\n        default=False, action=\"store_true\",\n        help=\"Disable line wrapping.\")\n    parser.add_option(\n        \"-a\", '--linkify', dest='linkify',\n        default=False, action=\"store_true\",\n        help=\"Transform URLs into <a> links.\")\n    parser.add_option(\n        \"-u\", '--unescape', dest='escaped',\n        default=True, action=\"store_false\",\n        help=\"Do not escape XML tags found in the input.\")\n    parser.add_option(\n        \"-m\", '--markup-lines', dest=\"markup_lines\",\n        default=False, action=\"store_true\",\n        help=\"Surround lines with <span id='line-n'>..</span>.\")\n    parser.add_option(\n        '--input-encoding', dest='input_encoding', metavar='ENCODING',\n        default='utf-8',\n        help=\"Specify input encoding\")\n    parser.add_option(\n        '--output-encoding', dest='output_encoding', metavar='ENCODING',\n        default='utf-8',\n        help=\"Specify output encoding\")\n    parser.add_option(\n        '-s', '--scheme', dest='scheme', metavar='SCHEME',\n        default='ansi2html', choices=scheme_names,\n        help=(\"Specify color palette scheme. Default: %%default. Choices: %s\"\n              % scheme_names))\n    parser.add_option(\n        '-t', '--title', dest='output_title',\n        default='',\n        help=\"Specify output title\")\n\n    opts, args = parser.parse_args()\n\n    conv = Ansi2HTMLConverter(\n        latex=opts.latex,\n        inline=opts.inline,\n        dark_bg=not opts.light_background,\n        line_wrap=not opts.no_line_wrap,\n        font_size=opts.font_size,\n        linkify=opts.linkify,\n        escaped=opts.escaped,\n        markup_lines=opts.markup_lines,\n        output_encoding=opts.output_encoding,\n        scheme=opts.scheme,\n        title=opts.output_title,\n    )\n\n    if six.PY3:\n        try:\n            sys.stdin = io.TextIOWrapper(sys.stdin.detach(), opts.input_encoding, \"replace\")\n        except io.UnsupportedOperation:\n            # This only fails in the test suite...\n            pass\n\n    def _read(input_bytes):\n        if six.PY3:\n            return input_bytes\n        else:\n            return input_bytes.decode(opts.input_encoding)\n\n    def _print(output_unicode, end='\\n'):\n        if hasattr(sys.stdout, 'buffer'):\n            output_bytes = (output_unicode + end).encode(opts.output_encoding)\n            sys.stdout.buffer.write(output_bytes)\n        elif not six.PY3:\n            sys.stdout.write((output_unicode + end).encode(opts.output_encoding))\n        else:\n            sys.stdout.write(output_unicode + end)\n\n    # Produce only the headers and quit\n    if opts.headers:\n        _print(conv.produce_headers(), end='')\n        return\n\n    full = not bool(opts.partial or opts.inline)\n    if six.PY3:\n        output = conv.convert(\"\".join(sys.stdin.readlines()), full=full, ensure_trailing_newline=True)\n        _print(output, end='')\n    else:\n        output = conv.convert(six.u(\"\").join(\n            map(_read, sys.stdin.readlines())\n        ), full=full, ensure_trailing_newline=True)\n        _print(output, end='')", "response": "This is the main function for the main function. It is the main function that is used to generate the main HTML. It is responsible for running the main function in a separate process."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncollapses the cursor commands into a list of tokens.", "response": "def _collapse_cursor(self, parts):\n        \"\"\" Act on any CursorMoveUp commands by deleting preceding tokens \"\"\"\n\n        final_parts = []\n        for part in parts:\n\n            # Throw out empty string tokens (\"\")\n            if not part:\n                continue\n\n            # Go back, deleting every token in the last 'line'\n            if part == CursorMoveUp:\n                if final_parts:\n                    final_parts.pop()\n\n                while final_parts and '\\n' not in final_parts[-1]:\n                    final_parts.pop()\n\n                continue\n\n            # Otherwise, just pass this token forward\n            final_parts.append(part)\n\n        return final_parts"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the contents of ansi into the object", "response": "def prepare(self, ansi='', ensure_trailing_newline=False):\n        \"\"\" Load the contents of 'ansi' into this object \"\"\"\n\n        body, styles = self.apply_regex(ansi)\n\n        if ensure_trailing_newline and _needs_extra_newline(body):\n            body += '\\n'\n\n        self._attrs = {\n            'dark_bg': self.dark_bg,\n            'line_wrap': self.line_wrap,\n            'font_size': self.font_size,\n            'body': body,\n            'styles': styles,\n        }\n\n        return self._attrs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        if self.has_rust_extensions():\n            log.info(\"running build_rust\")\n            build_rust = self.get_finalized_command(\"build_rust\")\n            build_rust.inplace = self.inplace\n            build_rust.run()\n\n        _build_ext.run(self)", "response": "Run build_rust sub command"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the Cargo. toml file to get the name of the shared library.", "response": "def get_lib_name(self):\n        \"\"\" Parse Cargo.toml to get the name of the shared library. \"\"\"\n        # We import in here to make sure the the setup_requires are already installed\n        import toml\n\n        cfg = toml.load(self.path)\n        name = cfg.get(\"lib\", {}).get(\"name\")\n        if name is None:\n            name = cfg.get(\"package\", {}).get(\"name\")\n        if name is None:\n            raise Exception(\n                \"Can not parse library name from Cargo.toml. \"\n                \"Cargo.toml missing value for 'name' key \"\n                \"in both the [package] section and the [lib] section\"\n            )\n        name = re.sub(r\"[./\\\\-]\", \"_\", name)\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_rust_extensions(*directories, **kwargs):\n\n    # Get the file used to mark a Rust extension\n    libfile = kwargs.get(\"libfile\", \"lib.rs\")\n\n    # Get the directories to explore\n    directories = directories or [os.getcwd()]\n\n    extensions = []\n    for directory in directories:\n        for base, dirs, files in os.walk(directory):\n            if libfile in files:\n                dotpath = os.path.relpath(base).replace(os.path.sep, \".\")\n                tomlpath = os.path.join(base, \"Cargo.toml\")\n                ext = RustExtension(dotpath, tomlpath, **kwargs)\n                ext.libfile = os.path.join(base, libfile)\n                extensions.append(ext)\n\n    return extensions", "response": "This function will recursively find Rust extensions in the given directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, event, fn):\n\n        # TODO: Can we check the method signature?\n        self._handler_dict.setdefault(event, [])\n        if fn not in self._handler_dict[event]:\n            self._handler_dict[event].append(fn)", "response": "Registers the given function as a handler to be applied to the given event."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply all middleware functions registered against the given event to the given document.", "response": "def apply(self, event, document, *args, **kwargs):\n        \"\"\"\n        Applies all middleware functions registered against the given\n        event in order to the given document.\n        \"\"\"\n        for fn in self._handler_dict.get(event, []):\n            fn(document, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deregister_all(self, *events):\n        if events:\n            for event in events:\n                self._handler_dict[event] = []\n        else:\n            self._handler_dict = {}", "response": "Deregisters all handler functions or those registered against the given events."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unpack_scope(cls, scope):\n        query = {}\n        projection = {}\n        options = {}\n\n        if isinstance(scope, tuple):\n            if len(scope) > 3:\n                raise ValueError(\"Invalid scope\")\n            if len(scope) >= 1:\n                query = scope[0]\n            if len(scope) >= 2:\n                projection = scope[1]\n            if len(scope) == 3:\n                options = scope[2]\n        elif isinstance(scope, dict):\n            query = scope\n        else:\n            raise ValueError(\"Invalid scope\")\n\n        return query, projection, options", "response": "Unpacks the response from a scope function. The function should return\n        either a query a projection a query and an query options hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_fn(cls, f):\n        def inner(self, *args, **kwargs):\n            try:\n                query, projection, options = cls.unpack_scope(f(*args, **kwargs))\n                new_query = deepcopy(self.query)\n                new_projection = deepcopy(self.projection)\n                new_options = deepcopy(self.options)\n                deep_merge(query, new_query)\n                new_projection.update(projection)\n                new_options.update(options)\n                return ScopeBuilder(self.model, self.fns, new_query,\n                    new_projection, new_options)\n            except ValueError:\n                raise ValueError(\"Scope function \\\"{}\\ returns an invalid scope\".format(f.__name__))\n\n        setattr(cls, f.__name__, inner)", "response": "Registers a scope function on this builder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cursor(self):\n        if not self._active_cursor:\n            self._active_cursor = self.model.find(self.query,\n                                                  self.projection or None,\n                                                  **self.options)\n        return self._active_cursor", "response": "Returns a cursor for the currently assembled query creating it if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ensure_object_id(cls, id):\n        if isinstance(id, ObjectId):\n            return id\n\n        if isinstance(id, basestring) and OBJECTIDEXPR.match(id):\n            return ObjectId(id)\n\n        return id", "response": "Checks whether the given id is an ObjectId instance and if not wraps it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply schema defaults to this document.", "response": "def apply_defaults(self):\n        \"\"\"Apply schema defaults to this document.\"\"\"\n        self.emit('will_apply_defaults')\n        self.schema.apply_defaults(self)\n        self.emit('did_apply_defaults')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_by_id(cls, id):\n        obj = cls.find_one(cls._id_spec(id))\n        if not obj:\n            raise NotFoundException(cls.collection, id)\n        return obj", "response": "Finds a single document by its ID. Throws a\n            if the document does not exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreloads the current model s data from the underlying database record updating it in - place.", "response": "def reload(self):\n        \"\"\"Reloads the current model's data from the underlying\n        database record, updating it in-place.\"\"\"\n        self.emit('will_reload')\n        self.populate(self.collection.find_one(type(self)._id_spec(self['_id'])))\n        self.emit('did_reload')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a handler function whenever an instance of the model has emitted the given event.", "response": "def on(cls, event, handler_func=None):\n        \"\"\"\n        Registers a handler function whenever an instance of the model\n        emits the given event.\n\n        This method can either called directly, passing a function reference:\n\n            MyModel.on('did_save', my_function)\n\n        ...or as a decorator of the function to be registered.\n\n            @MyModel.on('did_save')\n            def myfunction(my_model):\n                pass\n\n        \"\"\"\n        if handler_func:\n            cls.handler_registrar().register(event, handler_func)\n            return\n\n        def register(fn):\n            cls.handler_registrar().register(event, fn)\n            return fn\n\n        return register"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _emit(self, event, document, *args, **kwargs):\n        self.handler_registrar().apply(event, document, *args, **kwargs)", "response": "Internal method to call the handler function registered with the event name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef emit(self, event, *args, **kwargs):\n        self._emit(event, self, *args, **kwargs)", "response": "Emits an event call to all handler functions registered against this object s class and the given event type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef static_method(cls, f):\n        setattr(cls, f.__name__, staticmethod(f))\n        return f", "response": "Decorator which dynamically binds static methods to the model for later use."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef class_method(cls, f):\n        setattr(cls, f.__name__, classmethod(f))\n        return f", "response": "Decorator which dynamically binds class methods to the model for later use."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scope(cls, f):\n        if not hasattr(cls, \"scopes\"):\n            cls.scopes = copy(STANDARD_SCOPES)\n\n        cls.scopes.append(f)\n\n        def create_builder(self, *args, **kwargs):\n            bldr = ScopeBuilder(cls, cls.scopes)\n            return getattr(bldr, f.__name__)(*args, **kwargs)\n\n        setattr(cls, f.__name__, classmethod(create_builder))\n        return f", "response": "Decorator which can dynamically attach a query scope to the model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the module name associated with a frame num_frames_back in the caller s stack.", "response": "def _module_name_from_previous_frame(num_frames_back):\n    \"\"\"\n    Returns the module name associated with a frame `num_frames_back` in the\n    call stack. This function adds 1 to account for itself, so `num_frames_back`\n    should be given relative to the caller.\n    \"\"\"\n    frm = inspect.stack()[num_frames_back + 1]\n    return inspect.getmodule(frm[0]).__name__"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new mongothon model class.", "response": "def create_model(schema, collection, class_name=None):\n    \"\"\"\n    Main entry point to creating a new mongothon model. Both\n    schema and Pymongo collection objects must be provided.\n\n    Returns a new class which can be used as a model class.\n\n    The class name of the model class by default is inferred\n    from the provided collection (converted to camel case).\n    Optionally, a class_name argument can be provided to\n    override this.\n    \"\"\"\n    if not class_name:\n        class_name = camelize(str(collection.name))\n\n    model_class = type(class_name,\n                       (Model,),\n                       dict(schema=schema, _collection_factory=staticmethod(lambda: collection)))\n\n    # Since we are dynamically creating this class here, we modify __module__ on the\n    # created class to point back to the module from which `create_model` was called\n    model_class.__module__ = _module_name_from_previous_frame(1)\n\n    return model_class"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_model_offline(schema, collection_factory, class_name):\n    model_class = type(class_name,\n                       (Model,),\n                       dict(schema=schema, _collection_factory=staticmethod(collection_factory)))\n\n    # Since we are dynamically creating this class here, we modify __module__ on the\n    # created class to point back to the module from which `create_model_offline` was called\n    model_class.__module__ = _module_name_from_previous_frame(1)\n\n    return model_class", "response": "Create a new Mongothon model without instantiating it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps the given value in a Document or DocumentList as applicable.", "response": "def wrap(value):\n    \"\"\"\n    Wraps the given value in a Document or DocumentList as applicable.\n    \"\"\"\n    if isinstance(value, Document) or isinstance(value, DocumentList):\n        return value\n    elif isinstance(value, dict):\n        return Document(value)\n    elif isinstance(value, list):\n        return DocumentList(value)\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unwrap(value):\n    if isinstance(value, Document):\n        return value.to_dict()\n    elif isinstance(value, DocumentList):\n        return value.to_list()\n    else:\n        return value", "response": "Unwraps the given Document or DocumentList as applicable."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the change state to reflect a change to a field.", "response": "def note_change(self, key, value):\n        \"\"\"\n        Updates change state to reflect a change to a field. Takes care of ignoring\n        no-ops, reversions and takes appropriate steps if the field was previously\n        deleted or added to ensure the change state purely reflects the diff since\n        last reset.\n        \"\"\"\n        # If we're changing the value and we haven't done so already, note it.\n        if value != self._instance[key] and key not in self._previous and key not in self._added:\n            self._previous[key] = self._instance[key]\n\n        # If we're setting the value back to the original value, discard the change note\n        if key in self._previous and value == self._previous[key]:\n            del self._previous[key]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the change state to reflect the addition of a field.", "response": "def note_addition(self, key, value):\n        \"\"\"\n        Updates the change state to reflect the addition of a field. Detects previous\n        changes and deletions of the field and acts accordingly.\n        \"\"\"\n        # If we're adding a field we previously deleted, remove the deleted note.\n        if key in self._deleted:\n            # If the key we're adding back has a different value, then it's a change\n            if value != self._deleted[key]:\n                self._previous[key] = self._deleted[key]\n            del self._deleted[key]\n        else:\n            self._added.append(key)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef note_deletion(self, key):\n        # If we'rew deleting a key we previously added, then there is no diff\n        if key in self._added:\n            self._added.remove(key)\n        else:\n            # If the deleted key was previously changed, use the original value\n            if key in self._previous:\n                self._deleted[key] = self._previous[key]\n                del self._previous[key]\n            else:\n                self._deleted[key] = self._instance[key]", "response": "Notes the deletion of a key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict containing just the fields which have changed on this Document since it was created or last saved.", "response": "def changes(self):\n        \"\"\"\n        Returns a dict containing just the fields which have changed on this\n        Document since it was created or last saved, together with both their\n        previous and current values\n\n            doc['name']             # => 'bob'\n            doc['name'] = 'clive'\n            doc.changes             # => {'name': ('bob', clive')}\n        \"\"\"\n        return {key: (self._previous[key], self._instance[key])\n                for key in self._previous}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets all change tracking in this document and all child Documents and DocumentLists.", "response": "def reset_all_changes(self):\n        \"\"\"\n        Resets change tracking in this document, recursing into child Documents and\n        DocumentLists.\n        \"\"\"\n        self.reset_changes()\n        for value in self.values():\n            if isinstance(value, Document) or isinstance(value, DocumentList):\n                value.reset_all_changes()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef populate(self, other):\n        self.clear()\n        self.update(other)\n        self.reset_all_changes()", "response": "Like update but clears the contents first."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, buffer):\n        log.debug(\"parsing a %d byte packet\" % len(buffer))\n        (opcode,) = struct.unpack(str(\"!H\"), buffer[:2])\n        log.debug(\"opcode is %d\" % opcode)\n        packet = self.__create(opcode)\n        packet.buffer = buffer\n        return packet.decode()", "response": "This method is used to parse an existing datagram into its\n        corresponding TftpPacket object. The buffer is the raw bytes off of the network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __create(self, opcode):\n        tftpassert(opcode in self.classes,\n                   \"Unsupported opcode: %d\" % opcode)\n\n        packet = self.classes[opcode]()\n\n        return packet", "response": "This method returns the appropriate class object corresponding to\n        the passed opcode."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_dup(self, pkt):\n        log.debug(\"Recording a dup of %s\", pkt)\n        s = str(pkt)\n        if s in self.dups:\n            self.dups[s] += 1\n        else:\n            self.dups[s] = 1\n        tftpassert(self.dups[s] < MAX_DUPS, \"Max duplicates reached\")", "response": "This method adds a dup for a packet to the metrics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare current time with last_update time and raise an exception if we are over the timeout time.", "response": "def checkTimeout(self, now):\n        \"\"\"Compare current time with last_update time, and raise an exception\n        if we're over the timeout time.\"\"\"\n        log.debug(\"checking for timeout on session %s\", self)\n        if now - self.last_update > self.timeout:\n            raise TftpTimeout(\"Timeout waiting for traffic\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef end(self, close_fileobj=True):\n        log.debug(\"in TftpContext.end - closing socket\")\n        self.sock.close()\n        if close_fileobj and self.fileobj is not None and not self.fileobj.closed:\n            log.debug(\"self.fileobj is open - closing\")\n            self.fileobj.close()", "response": "Perform session cleanup, since the end method should always be\n        called explicitely by the calling code, this works better than the\n        destructor.\n        Set close_fileobj to False so fileobj can be returned open."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cycle(self):\n        try:\n            (buffer, (raddress, rport)) = self.sock.recvfrom(MAX_BLKSIZE)\n        except socket.timeout:\n            log.warning(\"Timeout waiting for traffic, retrying...\")\n            raise TftpTimeout(\"Timed-out waiting for traffic\")\n\n        # Ok, we've received a packet. Log it.\n        log.debug(\"Received %d bytes from %s:%s\",\n                        len(buffer), raddress, rport)\n        # And update our last updated time.\n        self.last_update = time.time()\n\n        # Decode it.\n        recvpkt = self.factory.parse(buffer)\n\n        # Check for known \"connection\".\n        if raddress != self.address:\n            log.warning(\"Received traffic from %s, expected host %s. Discarding\"\n                        % (raddress, self.host))\n\n        if self.tidport and self.tidport != rport:\n            log.warning(\"Received traffic from %s:%s but we're \"\n                        \"connected to %s:%s. Discarding.\"\n                        % (raddress, rport,\n                        self.host, self.tidport))\n\n        # If there is a packethook defined, call it. We unconditionally\n        # pass all packets, it's up to the client to screen out different\n        # kinds of packets. This way, the client is privy to things like\n        # negotiated options.\n        if self.packethook:\n            self.packethook(recvpkt)\n\n        # And handle it, possibly changing state.\n        self.state = self.state.handle(recvpkt, raddress, rport)\n        # If we didn't throw any exceptions here, reset the retry_count to\n        # zero.\n        self.retry_count = 0", "response": "This method is called by the protocol class when we have a new connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the state cycle.", "response": "def start(self, buffer):\n        \"\"\"Start the state cycle. Note that the server context receives an\n        initial packet in its start method. Also note that the server does not\n        loop on cycle(), as it expects the TftpServer object to manage\n        that.\"\"\"\n        log.debug(\"In TftpContextServer.start\")\n        self.metrics.start_time = time.time()\n        log.debug(\"Set metrics.start_time to %s\", self.metrics.start_time)\n        # And update our last updated time.\n        self.last_update = time.time()\n\n        pkt = self.factory.parse(buffer)\n        log.debug(\"TftpContextServer.start() - factory returned a %s\", pkt)\n\n        # Call handle once with the initial packet. This should put us into\n        # the download or the upload state.\n        self.state = self.state.handle(pkt,\n                                       self.host,\n                                       self.port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfinish up the context.", "response": "def end(self):\n        \"\"\"Finish up the context.\"\"\"\n        TftpContext.end(self, not self.filelike_fileobj)\n        self.metrics.end_time = time.time()\n        log.debug(\"Set metrics.end_time to %s\" % self.metrics.end_time)\n        self.metrics.compute()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes the packet s buffer from the instance variables.", "response": "def encode(self):\n        \"\"\"Encode the packet's buffer from the instance variables.\"\"\"\n        tftpassert(self.filename, \"filename required in initial packet\")\n        tftpassert(self.mode, \"mode required in initial packet\")\n        # Make sure filename and mode are bytestrings.\n        filename = self.filename\n        mode = self.mode\n        if not isinstance(filename, bytes):\n            filename = filename.encode('ascii')\n        if not isinstance(self.mode, bytes):\n            mode = mode.encode('ascii')\n\n        ptype = None\n        if self.opcode == 1: ptype = \"RRQ\"\n        else:                ptype = \"WRQ\"\n        log.debug(\"Encoding %s packet, filename = %s, mode = %s\",\n            ptype, filename, mode)\n        for key in self.options:\n            log.debug(\"    Option %s = %s\", key, self.options[key])\n\n        fmt = b\"!H\"\n        fmt += b\"%dsx\" % len(filename)\n        if mode == b\"octet\":\n            fmt += b\"5sx\"\n        else:\n            raise AssertionError(\"Unsupported mode: %s\" % mode)\n        # Add options. Note that the options list must be bytes.\n        options_list = []\n        if len(list(self.options.keys())) > 0:\n            log.debug(\"there are options to encode\")\n            for key in self.options:\n                # Populate the option name\n                name = key\n                if not isinstance(name, bytes):\n                    name = name.encode('ascii')\n                options_list.append(name)\n                fmt += b\"%dsx\" % len(name)\n                # Populate the option value\n                value = self.options[key]\n                # Work with all strings.\n                if isinstance(value, int):\n                    value = str(value)\n                if not isinstance(value, bytes):\n                    value = value.encode('ascii')\n                options_list.append(value)\n                fmt += b\"%dsx\" % len(value)\n\n        log.debug(\"fmt is %s\", fmt)\n        log.debug(\"options_list is %s\", options_list)\n        log.debug(\"size of struct is %d\", struct.calcsize(fmt))\n        \n        self.buffer = struct.pack(fmt,\n                                  self.opcode,\n                                  filename,\n                                  mode,\n                                  *options_list)\n\n        log.debug(\"buffer is %s\", repr(self.buffer))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encode(self):\n        if len(self.data) == 0:\n            log.debug(\"Encoding an empty DAT packet\")\n        data = self.data\n        if not isinstance(self.data, bytes):\n            data = self.data.encode('ascii')\n        fmt = b\"!HH%ds\" % len(data)\n        self.buffer = struct.pack(fmt,\n                                  self.opcode,\n                                  self.blocknumber,\n                                  data)\n        return self", "response": "Encode the DAT packet and return self for easy method chaining."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode(self):\n        # We know the first 2 bytes are the opcode. The second two are the\n        # block number.\n        (self.blocknumber,) = struct.unpack(str(\"!H\"), self.buffer[2:4])\n        log.debug(\"decoding DAT packet, block number %d\", self.blocknumber)\n        log.debug(\"should be %d bytes in the packet total\", len(self.buffer))\n        # Everything else is data.\n        self.data = self.buffer[4:]\n        log.debug(\"found %d bytes of data\", len(self.data))\n        return self", "response": "Decode self. buffer into instance variables. It returns self for\n        easy method chaining."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode(self):\n        fmt = b\"!HH%dsx\" % len(self.errmsgs[self.errorcode])\n        log.debug(\"encoding ERR packet with fmt %s\", fmt)\n        self.buffer = struct.pack(fmt,\n                                  self.opcode,\n                                  self.errorcode,\n                                  self.errmsgs[self.errorcode])\n        return self", "response": "Encode the DAT packet based on instance variables populating\n        self. buffer and returning self."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(self):\n        \"Decode self.buffer, populating instance variables and return self.\"\n        buflen = len(self.buffer)\n        tftpassert(buflen >= 4, \"malformed ERR packet, too short\")\n        log.debug(\"Decoding ERR packet, length %s bytes\", buflen)\n        if buflen == 4:\n            log.debug(\"Allowing this affront to the RFC of a 4-byte packet\")\n            fmt = b\"!HH\"\n            log.debug(\"Decoding ERR packet with fmt: %s\", fmt)\n            self.opcode, self.errorcode = struct.unpack(fmt,\n                                                        self.buffer)\n        else:\n            log.debug(\"Good ERR packet > 4 bytes\")\n            fmt = b\"!HH%dsx\" % (len(self.buffer) - 5)\n            log.debug(\"Decoding ERR packet with fmt: %s\", fmt)\n            self.opcode, self.errorcode, self.errmsg = struct.unpack(fmt,\n                                                                     self.buffer)\n        log.error(\"ERR packet - errorcode: %d, message: %s\"\n                     % (self.errorcode, self.errmsg))\n        return self", "response": "Decode self. buffer populating instance variables and return self."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handleOACK(self, pkt):\n        if len(pkt.options.keys()) > 0:\n            if pkt.match_options(self.context.options):\n                log.info(\"Successful negotiation of options\")\n                # Set options to OACK options\n                self.context.options = pkt.options\n                for key in self.context.options:\n                    log.info(\"    %s = %s\" % (key, self.context.options[key]))\n            else:\n                log.error(\"Failed to negotiate options\")\n                raise TftpException(\"Failed to negotiate options\")\n        else:\n            raise TftpException(\"No options found in OACK\")", "response": "This method handles an OACK from the server syncing any accepted ArcGIS options."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef returnSupportedOptions(self, options):\n        # We support the options blksize and tsize right now.\n        # FIXME - put this somewhere else?\n        accepted_options = {}\n        for option in options:\n            if option == 'blksize':\n                # Make sure it's valid.\n                if int(options[option]) > MAX_BLKSIZE:\n                    log.info(\"Client requested blksize greater than %d \"\n                             \"setting to maximum\" % MAX_BLKSIZE)\n                    accepted_options[option] = MAX_BLKSIZE\n                elif int(options[option]) < MIN_BLKSIZE:\n                    log.info(\"Client requested blksize less than %d \"\n                             \"setting to minimum\" % MIN_BLKSIZE)\n                    accepted_options[option] = MIN_BLKSIZE\n                else:\n                    accepted_options[option] = options[option]\n            elif option == 'tsize':\n                log.debug(\"tsize option is set\")\n                accepted_options['tsize'] = 0\n            else:\n                log.info(\"Dropping unsupported option '%s'\" % option)\n        log.debug(\"Returning these accepted options: %s\", accepted_options)\n        return accepted_options", "response": "This method takes a list of options from a client and returns the ones that are supported."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sendACK(self, blocknumber=None):\n        log.debug(\"In sendACK, passed blocknumber is %s\", blocknumber)\n        if blocknumber is None:\n            blocknumber = self.context.next_block\n        log.info(\"Sending ack to block %d\" % blocknumber)\n        ackpkt = TftpPacketACK()\n        ackpkt.blocknumber = blocknumber\n        self.context.sock.sendto(ackpkt.encode().buffer,\n                                 (self.context.host,\n                                  self.context.tidport))\n        self.context.last_pkt = ackpkt", "response": "This method sends an ACK packet to the specified block number. If blocknumber is None the next_block property in the current context is used."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendError(self, errorcode):\n        log.debug(\"In sendError, being asked to send error %d\", errorcode)\n        errpkt = TftpPacketERR()\n        errpkt.errorcode = errorcode\n        if self.context.tidport == None:\n            log.debug(\"Error packet received outside session. Discarding\")\n        else:\n            self.context.sock.sendto(errpkt.encode().buffer,\n                                     (self.context.host,\n                                      self.context.tidport))\n        self.context.last_pkt = errpkt", "response": "This method sends an error packet to the Tftp server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sendOACK(self):\n        log.debug(\"In sendOACK with options %s\", self.context.options)\n        pkt = TftpPacketOACK()\n        pkt.options = self.context.options\n        self.context.sock.sendto(pkt.encode().buffer,\n                                 (self.context.host,\n                                  self.context.tidport))\n        self.context.last_pkt = pkt", "response": "This method sends an OACK packet with the options from the current\n        context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nre-sending the last sent packet due to a timeout.", "response": "def resendLast(self):\n        \"Resend the last sent packet due to a timeout.\"\n        log.warning(\"Resending packet %s on sessions %s\"\n            % (self.context.last_pkt, self))\n        self.context.metrics.resent_bytes += len(self.context.last_pkt.buffer)\n        self.context.metrics.add_dup(self.context.last_pkt)\n        sendto_port = self.context.tidport\n        if not sendto_port:\n            # If the tidport wasn't set, then the remote end hasn't even\n            # started talking to us yet. That's not good. Maybe it's not\n            # there.\n            sendto_port = self.context.port\n        self.context.sock.sendto(self.context.last_pkt.encode().buffer,\n                                 (self.context.host, sendto_port))\n        if self.context.packethook:\n            self.context.packethook(self.context.last_pkt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handleDat(self, pkt):\n        log.info(\"Handling DAT packet - block %d\" % pkt.blocknumber)\n        log.debug(\"Expecting block %s\", self.context.next_block)\n        if pkt.blocknumber == self.context.next_block:\n            log.debug(\"Good, received block %d in sequence\", pkt.blocknumber)\n\n            self.sendACK()\n            self.context.next_block += 1\n\n            log.debug(\"Writing %d bytes to output file\", len(pkt.data))\n            self.context.fileobj.write(pkt.data)\n            self.context.metrics.bytes += len(pkt.data)\n            # Check for end-of-file, any less than full data packet.\n            if len(pkt.data) < self.context.getBlocksize():\n                log.info(\"End of file detected\")\n                return None\n\n        elif pkt.blocknumber < self.context.next_block:\n            if pkt.blocknumber == 0:\n                log.warning(\"There is no block zero!\")\n                self.sendError(TftpErrors.IllegalTftpOp)\n                raise TftpException(\"There is no block zero!\")\n            log.warning(\"Dropping duplicate block %d\" % pkt.blocknumber)\n            self.context.metrics.add_dup(pkt)\n            log.debug(\"ACKing block %d again, just in case\", pkt.blocknumber)\n            self.sendACK(pkt.blocknumber)\n\n        else:\n            # FIXME: should we be more tolerant and just discard instead?\n            msg = \"Whoa! Received future block %d but expected %d\" \\\n                % (pkt.blocknumber, self.context.next_block)\n            log.error(msg)\n            raise TftpException(msg)\n\n        # Default is to ack\n        return TftpStateExpectDAT(self.context)", "response": "This method handles a DAT packet."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles an initial RRQ packet as a server.", "response": "def handle(self, pkt, raddress, rport):\n        \"Handle an initial RRQ packet as a server.\"\n        log.debug(\"In TftpStateServerRecvRRQ.handle\")\n        sendoack = self.serverInitial(pkt, raddress, rport)\n        path = self.full_path\n        log.info(\"Opening file %s for reading\" % path)\n        if os.path.exists(path):\n            # Note: Open in binary mode for win32 portability, since win32\n            # blows.\n            self.context.fileobj = open(path, \"rb\")\n        elif self.context.dyn_file_func:\n            log.debug(\"No such file %s but using dyn_file_func\", path)\n            self.context.fileobj = \\\n                self.context.dyn_file_func(self.context.file_to_transfer, raddress=raddress, rport=rport)\n\n            if self.context.fileobj is None:\n                log.debug(\"dyn_file_func returned 'None', treating as \"\n                          \"FileNotFound\")\n                self.sendError(TftpErrors.FileNotFound)\n                raise TftpException(\"File not found: %s\" % path)\n        else:\n            log.warn(\"File not found: %s\", path)\n            self.sendError(TftpErrors.FileNotFound)\n            raise TftpException(\"File not found: {}\".format(path))\n\n        # Options negotiation.\n        if sendoack and 'tsize' in self.context.options:\n            # getting the file size for the tsize option. As we handle\n            # file-like objects and not only real files, we use this seeking\n            # method instead of asking the OS\n            self.context.fileobj.seek(0, os.SEEK_END)\n            tsize = str(self.context.fileobj.tell())\n            self.context.fileobj.seek(0, 0)\n            self.context.options['tsize'] = tsize\n\n        if sendoack:\n            # Note, next_block is 0 here since that's the proper\n            # acknowledgement to an OACK.\n            # FIXME: perhaps we do need a TftpStateExpectOACK class...\n            self.sendOACK()\n            # Note, self.context.next_block is already 0.\n        else:\n            self.context.next_block = 1\n            log.debug(\"No requested options, starting send...\")\n            self.context.pending_complete = self.sendDAT()\n        # Note, we expect an ack regardless of whether we sent a DAT or an\n        # OACK.\n        return TftpStateExpectACK(self.context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(self, pkt, raddress, rport):\n        \"Handle an initial WRQ packet as a server.\"\n        log.debug(\"In TftpStateServerRecvWRQ.handle\")\n        sendoack = self.serverInitial(pkt, raddress, rport)\n        path = self.full_path\n        if self.context.upload_open:\n            f = self.context.upload_open(path, self.context)\n            if f is None:\n                self.sendError(TftpErrors.AccessViolation)\n                raise TftpException(\"Dynamic path %s not permitted\" % path)\n            else:\n                self.context.fileobj = f\n        else:\n            log.info(\"Opening file %s for writing\" % path)\n            if os.path.exists(path):\n                # FIXME: correct behavior?\n                log.warning(\"File %s exists already, overwriting...\" % (\n                    self.context.file_to_transfer))\n            # FIXME: I think we should upload to a temp file and not overwrite\n            # the existing file until the file is successfully uploaded.\n            self.make_subdirs()\n            self.context.fileobj = open(path, \"wb\")\n\n        # Options negotiation.\n        if sendoack:\n            log.debug(\"Sending OACK to client\")\n            self.sendOACK()\n        else:\n            log.debug(\"No requested options, expecting transfer to begin...\")\n            self.sendACK()\n        # Whether we're sending an oack or not, we're expecting a DAT for\n        # block 1\n        self.context.next_block = 1\n        # We may have sent an OACK, but we're expecting a DAT as the response\n        # to either the OACK or an ACK, so lets unconditionally use the\n        # TftpStateExpectDAT state.\n        return TftpStateExpectDAT(self.context)", "response": "Handle an initial WRQ packet as a server."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles a packet we just received.", "response": "def handle(self, pkt, raddress, rport):\n        \"\"\"Handle a packet we just received.\"\"\"\n        log.debug(\"In TftpStateServerStart.handle\")\n        if isinstance(pkt, TftpPacketRRQ):\n            log.debug(\"Handling an RRQ packet\")\n            return TftpStateServerRecvRRQ(self.context).handle(pkt,\n                                                               raddress,\n                                                               rport)\n        elif isinstance(pkt, TftpPacketWRQ):\n            log.debug(\"Handling a WRQ packet\")\n            return TftpStateServerRecvWRQ(self.context).handle(pkt,\n                                                               raddress,\n                                                               rport)\n        else:\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Invalid packet to begin up/download: %s\" % pkt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles a packet hopefully an ACK since we just sent a DAT.", "response": "def handle(self, pkt, raddress, rport):\n        \"Handle a packet, hopefully an ACK since we just sent a DAT.\"\n        if isinstance(pkt, TftpPacketACK):\n            log.debug(\"Received ACK for packet %d\" % pkt.blocknumber)\n            # Is this an ack to the one we just sent?\n            if self.context.next_block == pkt.blocknumber:\n                if self.context.pending_complete:\n                    log.info(\"Received ACK to final DAT, we're done.\")\n                    return None\n                else:\n                    log.debug(\"Good ACK, sending next DAT\")\n                    self.context.next_block += 1\n                    log.debug(\"Incremented next_block to %d\",\n                        self.context.next_block)\n                    self.context.pending_complete = self.sendDAT()\n\n            elif pkt.blocknumber < self.context.next_block:\n                log.warning(\"Received duplicate ACK for block %d\"\n                    % pkt.blocknumber)\n                self.context.metrics.add_dup(pkt)\n\n            else:\n                log.warning(\"Oooh, time warp. Received ACK to packet we \"\n                         \"didn't send yet. Discarding.\")\n                self.context.metrics.errors += 1\n            return self\n        elif isinstance(pkt, TftpPacketERR):\n            log.error(\"Received ERR packet from peer: %s\" % str(pkt))\n            raise TftpException(\"Received ERR packet from peer: %s\" % str(pkt))\n        else:\n            log.warning(\"Discarding unsupported packet: %s\" % str(pkt))\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the packet in response to an ACK which should be a DAT.", "response": "def handle(self, pkt, raddress, rport):\n        \"\"\"Handle the packet in response to an ACK, which should be a DAT.\"\"\"\n        if isinstance(pkt, TftpPacketDAT):\n            return self.handleDat(pkt)\n\n        # Every other packet type is a problem.\n        elif isinstance(pkt, TftpPacketACK):\n            # Umm, we ACK, you don't.\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received ACK from peer when expecting DAT\")\n\n        elif isinstance(pkt, TftpPacketWRQ):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received WRQ from peer when expecting DAT\")\n\n        elif isinstance(pkt, TftpPacketERR):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received ERR from peer: \" + str(pkt))\n\n        else:\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received unknown packet type from peer: \" + str(pkt))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle(self, pkt, raddress, rport):\n        if not self.context.tidport:\n            self.context.tidport = rport\n            log.debug(\"Set remote port for session to %s\", rport)\n\n        # If we're going to successfully transfer the file, then we should see\n        # either an OACK for accepted options, or an ACK to ignore options.\n        if isinstance(pkt, TftpPacketOACK):\n            log.info(\"Received OACK from server\")\n            try:\n                self.handleOACK(pkt)\n            except TftpException:\n                log.error(\"Failed to negotiate options\")\n                self.sendError(TftpErrors.FailedNegotiation)\n                raise\n            else:\n                log.debug(\"Sending first DAT packet\")\n                self.context.pending_complete = self.sendDAT()\n                log.debug(\"Changing state to TftpStateExpectACK\")\n                return TftpStateExpectACK(self.context)\n\n        elif isinstance(pkt, TftpPacketACK):\n            log.info(\"Received ACK from server\")\n            log.debug(\"Apparently the server ignored our options\")\n            # The block number should be zero.\n            if pkt.blocknumber == 0:\n                log.debug(\"Ack blocknumber is zero as expected\")\n                log.debug(\"Sending first DAT packet\")\n                self.context.pending_complete = self.sendDAT()\n                log.debug(\"Changing state to TftpStateExpectACK\")\n                return TftpStateExpectACK(self.context)\n            else:\n                log.warning(\"Discarding ACK to block %s\" % pkt.blocknumber)\n                log.debug(\"Still waiting for valid response from server\")\n                return self\n\n        elif isinstance(pkt, TftpPacketERR):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received ERR from server: %s\" % pkt)\n\n        elif isinstance(pkt, TftpPacketRRQ):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received RRQ from server while in upload\")\n\n        elif isinstance(pkt, TftpPacketDAT):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received DAT from server while in upload\")\n\n        else:\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received unknown packet type from server: %s\" % pkt)\n\n        # By default, no state change.\n        return self", "response": "Handle a packet from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the packet in response to an RRQ to the server.", "response": "def handle(self, pkt, raddress, rport):\n        \"\"\"Handle the packet in response to an RRQ to the server.\"\"\"\n        if not self.context.tidport:\n            self.context.tidport = rport\n            log.info(\"Set remote port for session to %s\" % rport)\n\n        # Now check the packet type and dispatch it properly.\n        if isinstance(pkt, TftpPacketOACK):\n            log.info(\"Received OACK from server\")\n            try:\n                self.handleOACK(pkt)\n            except TftpException as err:\n                log.error(\"Failed to negotiate options: %s\" % str(err))\n                self.sendError(TftpErrors.FailedNegotiation)\n                raise\n            else:\n                log.debug(\"Sending ACK to OACK\")\n\n                self.sendACK(blocknumber=0)\n\n                log.debug(\"Changing state to TftpStateExpectDAT\")\n                return TftpStateExpectDAT(self.context)\n\n        elif isinstance(pkt, TftpPacketDAT):\n            # If there are any options set, then the server didn't honour any\n            # of them.\n            log.info(\"Received DAT from server\")\n            if self.context.options:\n                log.info(\"Server ignored options, falling back to defaults\")\n                self.context.options = { 'blksize': DEF_BLKSIZE }\n            return self.handleDat(pkt)\n\n        # Every other packet type is a problem.\n        elif isinstance(pkt, TftpPacketACK):\n            # Umm, we ACK, the server doesn't.\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received ACK from server while in download\")\n\n        elif isinstance(pkt, TftpPacketWRQ):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received WRQ from server while in download\")\n\n        elif isinstance(pkt, TftpPacketERR):\n            self.sendError(TftpErrors.IllegalTftpOp)\n            log.debug(\"Received ERR packet: %s\", pkt)\n            if pkt.errorcode == TftpErrors.FileNotFound:\n                raise TftpFileNotFoundError(\"File not found\")\n            else:\n                raise TftpException(\"Received ERR from server: {}\".format(pkt))\n\n        else:\n            self.sendError(TftpErrors.IllegalTftpOp)\n            raise TftpException(\"Received unknown packet type from server: %s\" % pkt)\n\n        # By default, no state change.\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a server listening on the supplied IP and port.", "response": "def listen(self, listenip=\"\", listenport=DEF_TFTP_PORT,\n               timeout=SOCK_TIMEOUT):\n        \"\"\"Start a server listening on the supplied interface and port. This\n        defaults to INADDR_ANY (all interfaces) and UDP port 69. You can also\n        supply a different socket timeout value, if desired.\"\"\"\n        tftp_factory = TftpPacketFactory()\n\n        # Don't use new 2.5 ternary operator yet\n        # listenip = listenip if listenip else '0.0.0.0'\n        if not listenip: listenip = '0.0.0.0'\n        log.info(\"Server requested on ip %s, port %s\" % (listenip, listenport))\n        try:\n            # FIXME - sockets should be non-blocking\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            self.sock.bind((listenip, listenport))\n            _, self.listenport = self.sock.getsockname()\n        except socket.error as err:\n            # Reraise it for now.\n            raise err\n\n        self.is_running.set()\n\n        log.info(\"Starting receive loop...\")\n        while True:\n            log.debug(\"shutdown_immediately is %s\" % self.shutdown_immediately)\n            log.debug(\"shutdown_gracefully is %s\" % self.shutdown_gracefully)\n            if self.shutdown_immediately:\n                log.warning(\"Shutting down now. Session count: %d\" %\n                         len(self.sessions))\n                self.sock.close()\n                for key in self.sessions:\n                    self.sessions[key].end()\n                self.sessions = []\n                break\n\n            elif self.shutdown_gracefully:\n                if not self.sessions:\n                    log.warning(\"In graceful shutdown mode and all \"\n                             \"sessions complete.\")\n                    self.sock.close()\n                    break\n\n            # Build the inputlist array of sockets to select() on.\n            inputlist = []\n            inputlist.append(self.sock)\n            for key in self.sessions:\n                inputlist.append(self.sessions[key].sock)\n\n            # Block until some socket has input on it.\n            log.debug(\"Performing select on this inputlist: %s\", inputlist)\n            try:\n                readyinput, readyoutput, readyspecial = \\\n                        select.select(inputlist, [], [], SOCK_TIMEOUT)\n            except select.error as err:\n                if err[0] == EINTR:\n                    # Interrupted system call\n                    log.debug(\"Interrupted syscall, retrying\")\n                    continue\n                else:\n                    raise\n\n            deletion_list = []\n\n            # Handle the available data, if any. Maybe we timed-out.\n            for readysock in readyinput:\n                # Is the traffic on the main server socket? ie. new session?\n                if readysock == self.sock:\n                    log.debug(\"Data ready on our main socket\")\n                    buffer, (raddress, rport) = self.sock.recvfrom(MAX_BLKSIZE)\n\n                    log.debug(\"Read %d bytes\", len(buffer))\n\n                    if self.shutdown_gracefully:\n                        log.warning(\"Discarding data on main port, \"\n                                 \"in graceful shutdown mode\")\n                        continue\n\n                    # Forge a session key based on the client's IP and port,\n                    # which should safely work through NAT.\n                    key = \"%s:%s\" % (raddress, rport)\n\n                    if not key in self.sessions:\n                        log.debug(\"Creating new server context for \"\n                                     \"session key = %s\" % key)\n                        self.sessions[key] = TftpContextServer(raddress,\n                                                               rport,\n                                                               timeout,\n                                                               self.root,\n                                                               self.dyn_file_func,\n                                                               self.upload_open)\n                        try:\n                            self.sessions[key].start(buffer)\n                        except TftpException as err:\n                            deletion_list.append(key)\n                            log.error(\"Fatal exception thrown from \"\n                                      \"session %s: %s\" % (key, str(err)))\n                    else:\n                        log.warning(\"received traffic on main socket for \"\n                                 \"existing session??\")\n                    log.info(\"Currently handling these sessions:\")\n                    for session_key, session in list(self.sessions.items()):\n                        log.info(\"    %s\" % session)\n\n                else:\n                    # Must find the owner of this traffic.\n                    for key in self.sessions:\n                        if readysock == self.sessions[key].sock:\n                            log.debug(\"Matched input to session key %s\"\n                                % key)\n                            try:\n                                self.sessions[key].cycle()\n                                if self.sessions[key].state == None:\n                                    log.info(\"Successful transfer.\")\n                                    deletion_list.append(key)\n                            except TftpException as err:\n                                deletion_list.append(key)\n                                log.error(\"Fatal exception thrown from \"\n                                          \"session %s: %s\"\n                                          % (key, str(err)))\n                            # Break out of for loop since we found the correct\n                            # session.\n                            break\n                    else:\n                        log.error(\"Can't find the owner for this packet. \"\n                                  \"Discarding.\")\n\n            log.debug(\"Looping on all sessions to check for timeouts\")\n            now = time.time()\n            for key in self.sessions:\n                try:\n                    self.sessions[key].checkTimeout(now)\n                except TftpTimeout as err:\n                    log.error(str(err))\n                    self.sessions[key].retry_count += 1\n                    if self.sessions[key].retry_count >= TIMEOUT_RETRIES:\n                        log.debug(\"hit max retries on %s, giving up\" %\n                            self.sessions[key])\n                        deletion_list.append(key)\n                    else:\n                        log.debug(\"resending on session %s\" % self.sessions[key])\n                        self.sessions[key].state.resendLast()\n\n            log.debug(\"Iterating deletion list.\")\n            for key in deletion_list:\n                log.info('')\n                log.info(\"Session %s complete\" % key)\n                if key in self.sessions:\n                    log.debug(\"Gathering up metrics from session before deleting\")\n                    self.sessions[key].end()\n                    metrics = self.sessions[key].metrics\n                    if metrics.duration == 0:\n                        log.info(\"Duration too short, rate undetermined\")\n                    else:\n                        log.info(\"Transferred %d bytes in %.2f seconds\"\n                            % (metrics.bytes, metrics.duration))\n                        log.info(\"Average rate: %.2f kbps\" % metrics.kbps)\n                    log.info(\"%.2f bytes in resent data\" % metrics.resent_bytes)\n                    log.info(\"%d duplicate packets\" % metrics.dupcount)\n                    log.debug(\"Deleting session %s\" % key)\n                    del self.sessions[key]\n                    log.debug(\"Session list is now %s\" % self.sessions)\n                else:\n                    log.warning(\n                        \"Strange, session %s is not on the deletion list\" % key)\n\n        self.is_running.clear()\n\n        log.debug(\"server returning from while loop\")\n        self.shutdown_gracefully = self.shutdown_immediately = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping the server gracefully.", "response": "def stop(self, now=False):\n        \"\"\"Stop the server gracefully. Do not take any new transfers,\n        but complete the existing ones. If force is True, drop everything\n        and stop. Note, immediately will not interrupt the select loop, it\n        will happen when the server returns on ready data, or a timeout.\n        ie. SOCK_TIMEOUT\"\"\"\n        if now:\n            self.shutdown_immediately = True\n        else:\n            self.shutdown_gracefully = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests all releases of economic data.", "response": "def all_releases(self,response_type=None,params=None):\n        \"\"\"\n        Function to request all releases of economic data.\n        `<https://research.stlouisfed.org/docs/api/fred/releases.html>`_\n\n        :arg str response_type: File extension of response. Options are 'xml', 'json',\n                            'dict','df','numpy','csv','tab,'pipe'. Required.\n        :arg str realtime_start: The start of the real-time period. Format \"YYYY-MM-DD\"\n        :arg str realtime_end: The end of the real-time period. Format \"YYYY-MM-DD\"\n        :arg int limit: The maximum number of results to return. Options 1 to 1000\n        :arg int offset: Data offset. Options >=0\n        :arg str order_by: Order results by values of the specified attribute. Options are  'release_id',\n                            'name', 'press_release', 'realtime_start', 'realtime_end'\n        :arg str sort_order: Sort results for attribute values specified by order_by. Options are 'asc','desc'\n        :arg bool ssl_verify: To verify HTTPs.\n        \"\"\"\n        path='/releases?'\n        response_type = response_type if response_type else self.response_type\n        if response_type != 'xml': params['file_type'] = 'json'\n        response = _get_request(self.url_root,self.api_key,path,response_type,params,self.ssl_verify)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to request FRED related tags for a particular release. FRED tags are attributes assigned to series. Series are assigned tags and releases. Indirectly through series, it is possible to get the tags for a category. No tags exist for a release that does not have series. `<https://research.stlouisfed.org/docs/api/fred/release_related_tags.html>`_ :arg int release_id: The id for a release. Required. :arg str tag_names: Tag names that series match. Separate with semicolon as in \"income;bea\". Required :arg str response_type: File extension of response. Options are 'xml', 'json', 'dict','df','numpy','csv','tab,'pipe'. Required. :arg str realtime_start: The start of the real-time period. Format \"YYYY-MM-DD\" :arg str realtime_end: The end of the real-time period. Format \"YYYY-MM-DD\" :arg int limit: The maximum number of results to return. Options 1 to 1000 :arg int offset: Data offset. Options >=0 :arg str order_by: Order results by values of the specified attribute. Options are 'series_count', 'popularity', 'created', 'name', 'group_id' :arg str sort_order: Sort results for attribute values specified by order_by. Options are 'asc','desc' :arg str exclude_tag_names: Tag names to exclude. Separate with semicolon as in \"income;bea\" :arg str tag_group_id: Tag ID to filter tags by. Options are 'freq', 'gen', 'geo', 'geot', 'rls', 'seas', 'src' :arg str search_text: The words to find matching tags with. For example 'mortgage rates' :arg bool ssl_verify: To verify HTTPs.", "response": "def related_tags(self,release_id=None,tag_names=None,response_type=None,params=None):\n        \"\"\"\n        Function to request FRED related tags for a particular release.\n        FRED tags are attributes assigned to series.\n        Series are assigned tags and releases. Indirectly through series,\n        it is possible to get the tags for a category. No tags exist for a\n        release that does not have series.\n        `<https://research.stlouisfed.org/docs/api/fred/release_related_tags.html>`_\n\n        :arg int release_id: The id for a release. Required.\n        :arg str tag_names: Tag names that series match. Separate with semicolon as in \"income;bea\". Required\n        :arg str response_type: File extension of response. Options are 'xml', 'json',\n                            'dict','df','numpy','csv','tab,'pipe'. Required.\n        :arg str realtime_start: The start of the real-time period. Format \"YYYY-MM-DD\"\n        :arg str realtime_end: The end of the real-time period. Format \"YYYY-MM-DD\"\n        :arg int limit: The maximum number of results to return. Options 1 to 1000\n        :arg int offset: Data offset. Options >=0\n        :arg str order_by: Order results by values of the specified attribute. Options are 'series_count',\n                            'popularity', 'created', 'name', 'group_id'\n        :arg str sort_order: Sort results for attribute values specified by order_by. Options are 'asc','desc'\n        :arg str exclude_tag_names: Tag names to exclude. Separate with semicolon as in \"income;bea\"\n        :arg str tag_group_id: Tag ID to filter tags by. Options are 'freq', 'gen', 'geo', 'geot', 'rls', 'seas', 'src'\n        :arg str search_text: The words to find matching tags with. For example 'mortgage rates'\n        :arg bool ssl_verify: To verify HTTPs.\n        \"\"\"\n        path='/release/related_tags?'\n        params['release_id'], params['tag_names'] = release_id, tag_names\n        response_type = response_type if response_type else self.response_type\n        if response_type != 'xml': params['file_type'] = 'json'\n        response = _get_request(self.url_root,self.api_key,path,response_type,params,self.ssl_verify)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_params(*frb_fred_params):\n    def _wrapper(func):\n        @wraps(func)\n        def _wrapped(*args, **kwargs):\n            params = kwargs.pop('params', {})\n            for p in frb_fred_params:\n                if p in kwargs:\n                    params[p] = kwargs.pop(p)\n            return func(*args,params=params,**kwargs)\n        return _wrapped\n    return _wrapper", "response": "Decorator that returns a function that takes all accepted parameters from the method s kwargs and puts them in the params argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to request the vintage dates in history when a series data values were revised or new data values were released.", "response": "def vintage_dates(self,series_id=None,response_type=None,params=None):\n        \"\"\"\n        Function to request the dates in history when a series' data values were\n        revised or new data values were released. Vintage dates are the release dates\n        for a series excluding release dates when the data for the series did not change.\n        `<https://research.stlouisfed.org/docs/api/fred/series_vintagedates.html>`_\n\n        :arg int series_id: The id for a series. Required.\n        :arg str response_type: File extension of response. Options are 'xml', 'json',\n                        'dict','df','numpy','csv','tab,'pipe'. Required.\n        :arg str realtime_start: The start of the real-time period. Format \"YYYY-MM-DD\"\n        :arg str realtime_end: The end of the real-time period. Format \"YYYY-MM-DD\"\n        :arg int limit: The maximum number of results to return. Options 1 to 1000\n        :arg int offset: Data offset. Options >=0\n        :arg str sort_order: Sort results by vintage_date. Options are 'asc','desc'\n        :arg bool ssl_verify: To verify HTTPs.\n        \"\"\"\n        path = '/series/vintagedates?'\n        params['series_id'] = series_id\n        response_type = response_type if response_type else self.response_type\n        if response_type != 'xml': params['file_type'] = 'json'\n        response = _get_request(self.url_root,self.api_key,path,response_type,params,self.ssl_verify)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self,search_text=None,response_type=None,params=None):\n        path = '/series/search?'\n        params['search_text'] = search_text\n        response_type = response_type if response_type else self.response_type\n        if response_type != 'xml': params['file_type'] = 'json'\n        response = _get_request(self.url_root,self.api_key,path,response_type,params,self.ssl_verify)\n        return response", "response": "Search the economic data series for words that match the search text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_tags(self,series_search_text=None,response_type=None,params=None):\n        path = '/series/search/tags?'\n        params['series_search_text'] = series_search_text\n        response_type = response_type if response_type else self.response_type\n        if response_type != 'xml': params['file_type'] = 'json'\n        response = _get_request(self.url_root,self.api_key,path,response_type,params,self.ssl_verify)\n        return response", "response": "This function is used to request the FRED tags for a series search."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_related_tags(self,series_search_text=None,tag_names=None,response_type=None,params=None):\n        path = '/series/search/related_tags?'\n        params['series_search_text'], params['tag_names'] = series_search_text, tag_names\n        response_type = response_type if response_type else self.response_type\n        if response_type != 'xml': params['file_type'] = 'json'\n        response = _get_request(self.url_root,self.api_key,path,response_type,params,self.ssl_verify)\n        return response", "response": "This function is used to request the related FRED tags for one or more economic data series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _fetch(url, ssl_verify = True):\n    req = Request(url)\n    if ssl_verify:\n        page = urlopen(req)\n    else:\n        ctx = ssl.create_default_context()\n        ctx.check_hostname = False\n        ctx.verify_mode = ssl.CERT_NONE\n\n        page = urlopen(req, context=ctx)\n    content = page.read().decode('utf-8')\n    page.close()\n    return content", "response": "Helper funcation to fetch content from a given url."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _url_builder(url_root,api_key,path,params):\n    params['api_key'] = api_key\n    url_end = urlencode(params)\n    url = \"%s%s%s\" % (url_root,path,url_end)\n    return url", "response": "Helper funcation to build a parameterized url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a DataFrame to a parameterized url.", "response": "def _convert(frame):\n    \"\"\"\n    Helper funcation to build a parameterized url.\n    \"\"\"\n    frame = frame.convert_objects(convert_numeric=True)\n    for column in frame:\n        if column in c.dates:\n            frame[column] = frame[column].astype('datetime64')\n    return frame"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dict(content):\n    if _has_pandas:\n        data = _data_frame(content).to_dict(orient='records')\n    else:\n        response = loads(content)\n        key = [x for x in response.keys() if x in c.response_data][0]\n        data = response[key]\n    return data", "response": "Helper funcation that converts text - based get response\n    to a python dictionary for additional manipulation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_request(url_root,api_key,path,response_type,params, ssl_verify):\n    url = _url_builder(url_root,api_key,path,params)\n    content = _fetch(url, ssl_verify)\n    response = _dispatch(response_type)(content)\n    return response", "response": "Helper funcation that requests a get response from FRED."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing an Atom feed from a local XML file.", "response": "def parse_atom_file(filename: str) -> AtomFeed:\n    \"\"\"Parse an Atom feed from a local XML file.\"\"\"\n    root = parse_xml(filename).getroot()\n    return _parse_atom(root)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_atom_bytes(data: bytes) -> AtomFeed:\n    root = parse_xml(BytesIO(data)).getroot()\n    return _parse_atom(root)", "response": "Parse an Atom feed from a byte - string containing XML data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_link(element: Element) -> Optional[str]:\n    link = get_text(element, 'link')\n    if link is not None:\n        return link\n\n    guid = get_child(element, 'guid')\n    if guid is not None and guid.attrib.get('isPermaLink') == 'true':\n        return get_text(element, 'guid')\n\n    return None", "response": "Attempt to retrieve item link."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_rss_file(filename: str) -> RSSChannel:\n    root = parse_xml(filename).getroot()\n    return _parse_rss(root)", "response": "Parse an RSS feed from a local XML file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_rss_bytes(data: bytes) -> RSSChannel:\n    root = parse_xml(BytesIO(data)).getroot()\n    return _parse_rss(root)", "response": "Parse an RSS feed from a byte - string containing XML data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_json_feed_file(filename: str) -> JSONFeed:\n    with open(filename) as f:\n        try:\n            root = json.load(f)\n        except json.decoder.JSONDecodeError:\n            raise FeedJSONError('Not a valid JSON document')\n\n    return parse_json_feed(root)", "response": "Parse a JSON feed from a local json file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a JSON feed from a byte - string containing JSON data.", "response": "def parse_json_feed_bytes(data: bytes) -> JSONFeed:\n    \"\"\"Parse a JSON feed from a byte-string containing JSON data.\"\"\"\n    try:\n        root = json.loads(data)\n    except json.decoder.JSONDecodeError:\n        raise FeedJSONError('Not a valid JSON document')\n\n    return parse_json_feed(root)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing an OPML document from a local XML file.", "response": "def parse_opml_file(filename: str) -> OPML:\n    \"\"\"Parse an OPML document from a local XML file.\"\"\"\n    root = parse_xml(filename).getroot()\n    return _parse_opml(root)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_opml_bytes(data: bytes) -> OPML:\n    root = parse_xml(BytesIO(data)).getroot()\n    return _parse_opml(root)", "response": "Parse an OPML document from a byte - string containing XML data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_feed_list(opml_obj: OPML) -> List[str]:\n    rv = list()\n\n    def collect(obj):\n        for outline in obj.outlines:\n            if outline.type == 'rss' and outline.xml_url:\n                rv.append(outline.xml_url)\n\n            if outline.outlines:\n                collect(outline)\n\n    collect(opml_obj)\n    return rv", "response": "Walk an OPML document to extract the list of feed it contains."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simple_parse_file(filename: str) -> Feed:\n    pairs = (\n        (rss.parse_rss_file, _adapt_rss_channel),\n        (atom.parse_atom_file, _adapt_atom_feed),\n        (json_feed.parse_json_feed_file, _adapt_json_feed)\n    )\n    return _simple_parse(pairs, filename)", "response": "Parse an Atom RSS or JSON feed from a local file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef simple_parse_bytes(data: bytes) -> Feed:\n    pairs = (\n        (rss.parse_rss_bytes, _adapt_rss_channel),\n        (atom.parse_atom_bytes, _adapt_atom_feed),\n        (json_feed.parse_json_feed_bytes, _adapt_json_feed)\n    )\n    return _simple_parse(pairs, data)", "response": "Parse an Atom RSS or JSON feed from a byte - string containing data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the distance a volume has moved during simple shear. Considers Lees - Edwards boundary conditions.", "response": "def get_shear_distance(a):\n    \"\"\"\n    Returns the distance a volume has moved during simple shear. Considers\n    either Lees-Edwards boundary conditions or sheared cells.\n    \"\"\"\n    cx, cy, cz = a.cell\n    if 'shear_dx' in a.info:\n        assert abs(cx[1]) < 1e-12, 'cx[1] = {0}'.format(cx[1])\n        assert abs(cx[2]) < 1e-12, 'cx[2] = {0}'.format(cx[2])\n        assert abs(cy[0]) < 1e-12, 'cx[0] = {0}'.format(cy[0])\n        assert abs(cy[2]) < 1e-12, 'cy[2] = {0}'.format(cy[2])\n        assert abs(cz[0]) < 1e-12, 'cz[0] = {0}'.format(cz[0])\n        assert abs(cz[1]) < 1e-12, 'cz[1] = {0}'.format(cz[1])\n        dx, dy, dz = a.info['shear_dx']\n    else:\n        assert abs(cx[1]) < 1e-12, 'cx[1] = {0}'.format(cx[1])\n        assert abs(cx[2]) < 1e-12, 'cx[2] = {0}'.format(cx[2])\n        assert abs(cy[0]) < 1e-12, 'cy[0] = {0}'.format(cy[0])\n        assert abs(cy[2]) < 1e-12, 'cy[2] = {0}'.format(cy[2])\n        dx, dy, sz = cz\n    return dx, dy"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_XIJ(nat, i_now, dr_now, dr_old):\n    # Do an element-wise outer product\n    dr_dr = dr_now.reshape(-1,3,1)*dr_old.reshape(-1,1,3)\n\n    xij = np.zeros([nat,3,3])\n    for i in range(3):\n        for j in range(3):\n            # For each atom, sum over all neighbors\n            xij[:,i,j] = np.bincount(i_now, weights=dr_dr[:,i,j])\n\n    return xij", "response": "Calculates the X_ij matrix for the given natural and neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_YIJ(nat, i_now, dr_old):\n    # Just do an element-wise outer product\n    dr_dr = dr_old.reshape(-1,3,1)*dr_old.reshape(-1,1,3)\n\n    yij = np.zeros([nat,3,3])\n    for i in range(3):\n        for j in range(3):\n            # For each atom, sum over all neighbors\n            yij[:,i,j] = np.bincount(i_now, weights=dr_dr[:,i,j])\n\n    return yij", "response": "Calculates the YIJ matrix for a given natural and i_now."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes inverse for each matrix in a list of matrices.", "response": "def array_inverse(A):\n    \"\"\"\n    Compute inverse for each matrix in a list of matrices.\n    This is faster than calling numpy.linalg.inv for each matrix.\n    \"\"\"\n    A = np.ascontiguousarray(A, dtype=float)\n    b = np.identity(A.shape[2], dtype=A.dtype)\n\n    n_eq = A.shape[1]\n    n_rhs = A.shape[2]\n    pivots = np.zeros(n_eq, np.intc)\n    identity  = np.eye(n_eq)\n    def lapack_inverse(a):\n        b = np.copy(identity)\n        pivots = np.zeros(n_eq, np.intc)\n        results = np.linalg.lapack_lite.dgesv(n_eq, n_rhs, a, n_eq, pivots, b, n_eq, 0)\n        if results['info'] > 0:\n            raise np.linalg.LinAlgError('Singular matrix')\n        return b\n\n    return np.array([lapack_inverse(a) for a in A])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate delta_ij + epsilon_ij i. e. the deformation gradient matrix", "response": "def get_delta_plus_epsilon(nat, i_now, dr_now, dr_old):\n    \"\"\"\n    Calculate delta_ij+epsilon_ij, i.e. the deformation gradient matrix\n    \"\"\"\n    XIJ = get_XIJ(nat, i_now, dr_now, dr_old)\n    YIJ = get_YIJ(nat, i_now, dr_old)\n\n    YIJ_invert = array_inverse(YIJ)\n\n    # Perform sum_k X_ik Y_jk^-1\n    epsilon = np.sum(XIJ.reshape(-1,3,1,3)*YIJ_invert.reshape(-1,1,3,3), axis=3)\n\n    return epsilon"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the D^2_min norm of Falk and Langer", "response": "def get_D_square_min(atoms_now, atoms_old, i_now, j_now, delta_plus_epsilon=None):\n    \"\"\"\n    Calculate the D^2_min norm of Falk and Langer\n    \"\"\"\n    nat = len(atoms_now)\n    assert len(atoms_now) == len(atoms_old)\n\n    pos_now = atoms_now.positions\n    pos_old = atoms_old.positions\n\n    # Compute current and old distance vectors. Note that current distance\n    # vectors cannot be taken from the neighbor calculation, because neighbors\n    # are calculated from the sheared cell while these distance need to come\n    # from the unsheared cell. Taking the distance from the unsheared cell\n    # make periodic boundary conditions (and flipping of cell) a lot easier.\n    dr_now = mic(pos_now[i_now] - pos_now[j_now], atoms_now.cell)\n    dr_old = mic(pos_old[i_now] - pos_old[j_now], atoms_old.cell)\n\n    # Sanity check: Shape needs to be identical!\n    assert dr_now.shape == dr_old.shape\n\n    if delta_plus_epsilon is None:\n        # Get minimum strain tensor\n        delta_plus_epsilon = get_delta_plus_epsilon(nat, i_now, dr_now, dr_old)\n\n    # Spread epsilon out for each neighbor index\n    delta_plus_epsilon_n = delta_plus_epsilon[i_now]\n\n    # Compute D^2_min\n    d_sq_n = np.sum(\n        (\n        dr_now-\n        np.sum(delta_plus_epsilon_n.reshape(-1,3,3)*dr_old.reshape(-1,1,3),\n               axis=2)\n        )**2,\n        axis=1)\n\n    # For each atom, sum over all neighbors\n    d_sq = np.bincount(i_now, weights=d_sq_n)\n\n    return delta_plus_epsilon, d_sq"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dhms(secs):\n    dhms = [0, 0, 0, 0]\n    dhms[0] = int(secs // 86400)\n    s = secs % 86400\n    dhms[1] = int(s // 3600)\n    s = secs % 3600\n    dhms[2] = int(s // 60)\n    s = secs % 60\n    dhms[3] = int(s+.5)\n    return dhms", "response": "return days hours minutes and seconds"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hms(secs):\n    hms = [0, 0, 0]\n    hms[0] = int(secs // 3600)\n    s = secs % 3600\n    hms[1] = int(s // 60)\n    s = secs % 60\n    hms[2] = int(s+.5)\n    return hms", "response": "return hours minutes and seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns hours minutes and seconds string e. g. 02 : 00 : 45", "response": "def hms_string(secs):\n    \"\"\"return hours,minutes and seconds string, e.g. 02:00:45\"\"\"\n    l = hms(secs)\n\n    def extend10(n):\n        if n < 10:\n            return '0' + str(n)\n        else:\n            return str(n)\n\n    return extend10(l[0]) + ':' + extend10(l[1]) + ':' + extend10(l[2])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_enclosing_orthorhombic_box(cell):\n    \n    # Cell vectors\n    cx, cy, cz = cell\n    \n    # The cell has eight corners, one is at the origin, three at cx, cy, cz\n    # and the last ones are...\n    c1 = cx+cy\n    c2 = cx+cz\n    c3 = cy+cz\n    c4 = cx+cy+cz\n    \n    corners = np.array([[0,0,0],cx,cy,cz,c1,c2,c3,c4])\n    lower = np.min(corners, axis=0)\n    upper = np.max(corners, axis=0)\n    \n    return lower, upper", "response": "Returns the lower and upper bounds of the orthorhombic box that encloses the parallelepiped spanned by the three cell vectors of cell."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef voropp_for_non_orthorhombic_cells(_a, q='%v', voropp_path=VOROPP_PATH,\n                                      fast=False, dump=None):\n    \"\"\"\n    Run voro++ on current configuration and return selected quantities.\n    Parameter *q* can be a list of voro++ output quantities.\n    Run 'voro++ -hc' to see options. Will take care of Lees-Edwards boundary\n    conditions by embedding a sheared cell in its periodic images and then\n    throwing away the border (will hence be slower).\n    \"\"\"\n    \n    # Make a copy because we will modify the Atoms object\n    a = _a.copy()\n    nat = len(a)\n    # Wrap into cell\n    a.set_scaled_positions(a.get_scaled_positions()%1.0)\n\n    # shear_dx should go into the cell\n    if 'shear_dx' in a.info:\n        lx, ly, lz = a.get_cell().diagonal()\n        cx, cy, cz = a.get_cell()\n        assert abs(cz[0]) < 1e-12\n        assert abs(cz[1]) < 1e-12\n        shear_dx = a.info['shear_dx']\n        cz[0] = shear_dx[0]\n        cz[1] = shear_dx[1]\n        a.set_cell([cx, cy, cz], scale_atoms=False)\n        a.set_scaled_positions(a.get_scaled_positions()%1.0)\n        \n    cx, cy, cz = a.get_cell()\n   \n    if fast:\n        # Make 2 copies of the box in each direction. Could fail!\n        a *= ( 2, 2, 2 )\n\n        # Translate such that the box with the lowest indices sits in the middle\n        a.translate(cx/2+cy/2+cz/2)\n    else:\n        # Make 3 copies of the box in each direction\n        a *= ( 3, 3, 3 )\n       \n        # Translate such that the box with the lowest indices sits in the middle\n        a.translate(cx+cy+cz)\n        \n    # Wrap back to box\n    a.set_scaled_positions(a.get_scaled_positions()%1.0)\n\n    # Get enclosing box\n    lower, upper = get_enclosing_orthorhombic_box(a.get_cell())\n    elx, ely, elz = upper-lower\n    \n    # Shift and set cell such that the general system is enclosed in the\n    # orthorhombic box\n    a.translate(-lower)\n    a.set_cell([elx,ely,elz], scale_atoms=False)\n    \n    # Dump snapshot for debugging purposes\n    if dump:\n        write(dump, a)\n    \n    # Do Voronoi analysis    \n    x, y, z = a.get_positions().T\n    f = open('tmp.voronoi', 'w')\n    for jn, ( jx, jy, jz ) in enumerate(zip(x, y, z)):\n        print >> f, jn, jx, jy, jz\n    f.close()\n    if isinstance(q, str) or isinstance(q, unicode):\n        c = '%s' % format(q)\n    else:\n        c = reduce(lambda x,y: '{0} {1}'.format(x,y), map(lambda x: '%'+x, q))\n    os.system('{0} -o -p -c \"%i {1}\" 0 {2} 0 {3} 0 {4} tmp.voronoi' \\\n              .format(voropp_path, c, elx, ely, elz))\n    r = np.loadtxt('tmp.voronoi.vol', unpack=True)\n    os.remove('tmp.voronoi')\n    os.remove('tmp.voronoi.vol')\n    \n    # Sort particles according to their ids\n    r = r[:,np.array(r[0,:], dtype=int)]\n    # Use only the lowest indices (i.e. the box in the middle)\n    if r.shape[0] == 2:\n        return r[1,:nat]\n    else:\n        return r[1:,:nat]", "response": "Returns a Voropp object for non orthorhombic cells."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef voropp(a, q='%v', voropp_path=VOROPP_PATH, fast=False, dump=None):\n    cx, cy, cz = a.get_cell()\n    lx, ly, lz = np.linalg.norm(cx), np.linalg.norm(cy), np.linalg.norm(cz)\n    if abs(lx*ly*lz - a.get_volume()) > 1e-6 or 'shear_dx' in a.info:\n        return voropp_for_non_orthorhombic_cells(a, q, voropp_path, fast, dump)\n\n    x, y, z = a.get_positions().T\n    f = open('tmp.voronoi', 'w')\n    for jn, ( jx, jy, jz ) in enumerate(zip(x, y, z)):\n        print >> f, jn, jx, jy, jz\n    f.close()\n    if isinstance(q, str) or isinstance(q, unicode):\n        c = '%s' % format(q)\n    else:\n        c = reduce(lambda x,y: '{0} {1}'.format(x,y), map(lambda x: '%'+x, q))\n    os.system('{0} -o -p -c \"%i {1}\" 0 {2} 0 {3} 0 {4} tmp.voronoi' \\\n              .format(voropp_path, c, lx, ly, lz))\n    r = np.loadtxt('tmp.voronoi.vol', unpack=True)\n    os.remove('tmp.voronoi')\n    os.remove('tmp.voronoi.vol')\n    \n    # Sort particles according to their ids\n    r = r[:,np.array(r[0,:], dtype=int)]\n    if r.shape[0] == 2:\n        return r[1,:]\n    else:\n        return r[1:,:]", "response": "Run voropp on current configuration and return selected quantities."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stress_invariants(s):\n    s = np.asarray(s)\n    if s.shape == (6,):\n        s = s.reshape(1,-1)\n    elif s.shape == (3,3):\n        s = s.reshape(1,-1,-1)\n    if len(s.shape) == 3:\n        s = np.transpose([s[:,0,0],s[:,1,1],s[:,2,2],\n                          (s[:,0,1]+s[:,1,0])/2,\n                          (s[:,1,2]+s[:,2,1])/2,\n                          (s[:,2,0]+s[:,0,2])/2])\n    I1 = s[:,0]+s[:,1]+s[:,2]\n    I2 = s[:,0]*s[:,1]+s[:,1]*s[:,2]+s[:,2]*s[:,0]-s[:,3]**2-s[:,4]**2-s[:,5]**2\n    I3 = s[:,0]*s[:,1]*s[:,2]+2*s[:,3]*s[:,4]*s[:,5]-s[:,3]**2*s[:,2]-s[:,4]**2*s[:,0]-s[:,5]**2*s[:,1]\n\n    J2 = I1**2/3-I2\n    J3 = 2*I1**3/27-I1*I2/3+I3\n\n    # Return hydrostatic pressure, octahedral shear stress and J3\n    return -I1/3, np.sqrt(2*J2/3), J3", "response": "Receives a list of stress tensors and returns the three invariants."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a parameter set from convenient Python dictionary to the format expected by the Fortran kernels.", "response": "def convpar(p):\n    \"\"\"\n    Convert a parameter set from convenient Python dictionary to the format\n    expected by the Fortran kernels.\n    \"\"\"\n\n    if 'el' not in p:\n        return p\n\n    els = p['el']\n    nel = len(els)\n\n    q = { }\n    for name, values in p.items():\n\n        if isinstance(values, dict):\n            # This is a dictionary. We need to first understand what it is and\n            # then convert to the appropriate list\n            m = 0\n            for itype, value in values:\n                if itype[0] == '_':\n                    continue\n                # Ask ASE to turn this into a list of symbols\n                syms = string2symbols(itype)\n                # Now turn this into a list of indices\n                nums = [ els.index(sym) for sym in syms ]\n                # We need to know the maximum number of symbols\n                m = max(m, nums)\n\n            default = 0.0\n            if '__default__' in values:\n                default = values['__default__']\n            if m == 2:\n                # These are pair indices\n                new_values = [ default ]*pair_index(nel,nel,nel)\n            elif m == 3:\n                # These are triplet indices\n                new_values = [ default ]*triplet_index(nel,nel,nel,nel)\n            else:\n                raise RuntimeError(\"Parameter '%s' appears to involve \" \\\n                                   \"interaction between %i atoms. Do not know \"\\\n                                   \"how to handle this.\" % ( name, nel ))\n\n            for itype, value in values:\n                if itype[0] == '_':\n                    continue\n                # Ask ASE to turn this into a list of symbols\n                syms = string2symbols(itype)\n                # Now turn this into a list of indices\n                nums = [ els.index(sym) for sym in syms ]\n                if len(nums) == m:\n                    # Set value\n                    if m == 2:\n                        i,j = nums\n                        new_values[pair_index(i,j,nel)] = value\n                    elif m == 3:\n                        i,j,k = nums\n                        new_values[triple_index(i,j,k,nel)] = value\n                else:\n                    # We have fewer values than we need\n                    if m == 3 and len(nums) == 1:\n                        [k] = nums\n                        for i in range(nel):\n                            for j in range(nel):\n                                # There is six possible permutations\n                                new_values[triple_index(i,j,k,nel)] = value\n                                new_values[triple_index(i,k,j,nel)] = value\n                                new_values[triple_index(k,j,i,nel)] = value\n                                new_values[triple_index(j,k,i,nel)] = value\n                                new_values[triple_index(k,i,j,nel)] = value\n                                new_values[triple_index(i,j,k,nel)] = value\n                    elif m == 3 and len(nums) == 2:\n                        [i,j] = nums\n                        for k in range(nel):\n                            # There is six possible permutations\n                            new_values[triple_index(i,j,k,nel)] = value\n                            new_values[triple_index(i,k,j,nel)] = value\n                            new_values[triple_index(k,j,i,nel)] = value\n                            new_values[triple_index(j,k,i,nel)] = value\n                            new_values[triple_index(k,i,j,nel)] = value\n                            new_values[triple_index(i,j,k,nel)] = value\n                    else:\n                        raise RuntimeError(\"Parameter '%s' appears to involve \" \\\n                                           \"interaction between %i atoms, but \" \\\n                                           \"only %i elements were provied. Do \" \\\n                                           \"not know how to handle this.\" \\\n                                           % ( name, nel, len(nums) ))\n            values = new_values\n\n        q[name] = values\n    return q"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scanmeta(f):\n    print(f)\n    if isinstance(f, str):\n        f = io.open(f, mode='r', encoding='latin-1')\n\n    done = False\n\n    l = f.readline()\n    s = None\n    while l and s is None:\n        i = l.find('!')\n        if i >= 0:\n            l = l[i+1:]\n            i = l.find('@meta')\n            if i >= 0:\n                l = l[i+5:]\n                i = l.find('@endmeta')\n                if i >= 0:\n                    s = l[:i]\n                    done = True\n                else:\n                    s = l\n        l = f.readline()\n    \n    if not done and not l:\n        return { }\n\n    while l and not done:\n        i = l.find('!')\n        if i >= 0:\n            l = l[i+1:]\n            i = l.find('@endmeta')\n            if i >= 0:\n                s += ' '+l[:i]\n                done = True\n            else:\n                s += ' '+l\n\n        l = f.readline()\n\n    s = map(lambda x: x.split(':'), s.split())\n    d = { }\n    for x in s:\n        if len(x) > 2 or len(x) == 0:\n            raise RuntimeError('Syntax error in meta information.')\n        elif len(x) == 2:\n            d[x[0]] = x[1]\n        else:\n            d[x[0]] = None\n\n    return d", "response": "Scan a file for meta information and store that into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mic(dr, cell, pbc=None):\n    # Check where distance larger than 1/2 cell. Particles have crossed\n    # periodic boundaries then and need to be unwrapped.\n    rec = np.linalg.inv(cell)\n    if pbc is not None:\n        rec *= np.array(pbc, dtype=int).reshape(3,1)\n    dri = np.round(np.dot(dr, rec))\n\n    # Unwrap\n    return dr - np.dot(dri, cell)", "response": "Apply minimum image convention to an array of distance vectors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef s_from_dhms(time):\n    dhms_s = { 's' : 1, 'm' : 60, 'h' : 3600, 'd' : 86400 }\n    time = time.lower()\n    word_list = re.findall('\\d*[^\\d]*',time)\n    seconds=0 \n    for word in word_list:\n        if word != '':\n            sec = 1\n            for t in list(dhms_s.keys()):\n                nw = word.replace(t,'')\n                if nw != word:\n                    sec = dhms_s[t]\n                    word = nw\n                    break\n            try:\n                seconds += int(word) * sec\n            except:\n                raise RuntimeError('unknown format in timestring ' + time)\n    return seconds", "response": "return seconds from dhms"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread atom information from an atoms. dat file.", "response": "def read_atoms(fn, cycfn=None, pos_only=False, conv=1.0):\n    \"\"\"\n    Read atom information from an atoms.dat file (i.e., tblmd, MDCORE input file)\n    \"\"\"\n    f = paropen(fn, \"r\")\n\n    l = f.readline().lstrip()\n    while len(l) > 0 and ( l[0] == '#' or l[0] == '<' ):\n        l = f.readline().lstrip()\n\n    n_atoms = int(l)\n\n    l = f.readline().lstrip()\n    while len(l) > 0 and ( l[0] == '#' or l[0] == '<' ):\n        l = f.readline().lstrip()\n\n    l = f.readline().lstrip()\n    while len(l) > 0 and ( l[0] == '#' or l[0] == '<' ):\n        l = f.readline().lstrip()\n\n    #\n    # Read positions\n    #\n\n    forces = np.zeros( [ n_atoms, 3 ] )\n    groups = np.zeros( [ n_atoms ] )\n    gamma  = np.zeros( [ n_atoms ] )\n    T      = np.zeros( [ n_atoms ] )\n\n    ats = [ ]\n    for i in range(n_atoms):\n        s = l.split()\n        #      type   x            y            z\n        sym = None\n        try:\n            Z    = int(s[0])\n            sym  = ase.data.chemical_symbols[Z]\n        except:\n            sym  = s[0]\n        a = ase.Atom(sym, ( float(s[2])*conv, float(s[3])*conv, float(s[4])*conv ) )\n        groups[i] = int(s[5])\n        gamma[i]  = float(s[6])\n        T[i]      = float(s[7])\n\n        ats += [ a ]\n        l = f.readline()\n    this = ase.Atoms(ats, pbc=True)\n\n    if not pos_only:\n        while l and l == \"\":\n            l = f.readline().strip()\n\n        while l:\n            key = l.strip(\" <-#\\r\\n\")\n\n            if key.upper() == \"VELOCITIES\":\n                for i in range(n_atoms):\n                    s = f.readline().split()\n                    m = this[i].mass\n                    if m is None:\n                        m = ase.data.atomic_masses[ase.data.chemical_symbols.index(this[i].symbol)]\n                    this[i].momentum = ( m*float(s[0]), m*float(s[1]), m*float(s[2]) )\n\n                l = None\n\n            elif key.upper() == \"FORCES\":\n                for i in range(n_atoms):\n                    s = f.readline().split()\n                    forces[i] =  np.array( [ float(s[0]), float(s[1]), float(s[2]) ] )\n\n                l = None\n\n            elif key.upper() == \"CHARGES\":\n                for i in this:\n                    l = f.readline()\n                    if l and len(l.split()) == 1:\n                        i.charge = float(l)\n\n                l = None\n\n            elif key.upper() == \"CELL\" or key.upper().split()[0:2] == (\"BOX\", \"VECTORS\" ):\n                l1 = f.readline()\n                l2 = f.readline()\n                l3 = f.readline()\n\n                this.set_cell( [ [float(x) for x in l1.split()],\n                                 [float(x) for x in l2.split()],\n                                 [float(x) for x in l3.split()] ] )\n\n                l = None\n\n            else:\n                aux = [ ]\n                l = f.readline().strip()\n                while l and l[0] not in [ '<', '#' ]:\n                    s = l.split()\n\n                    aux += [ [float(x) for x in s] ]\n\n                    l = f.readline().strip()\n\n                if len(aux) == n_atoms:\n                    this.set_array(key, np.asarray(aux))\n                else:\n                    print(\"Warning: Encountered field '%s' which does not seem to be per-atom data.\" % key)\n\n            if l is None:\n                l = f.readline().strip()\n            while l and l == \"\":\n                l = f.readline().strip()\n\n\n    f.close()\n\n    this.set_array(\"forces\", forces)\n    this.set_array(\"groups\", groups)\n    this.set_array(\"gamma\", gamma)\n    this.set_array(\"T\", T)\n\n    if cycfn:\n        read_cyc(this, cycfn, conv=conv)\n\n    return this"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the lattice information from a cyc. dat file.", "response": "def read_cyc(this, fn, conv=1.0):\n    \"\"\" Read the lattice information from a cyc.dat file (i.e., tblmd input file)\n    \"\"\"\n    f = paropen(fn, \"r\")\n    f.readline()\n    f.readline()\n    f.readline()\n    f.readline()\n    cell = np.array( [ [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ], [ 0.0, 0.0, 0.0 ] ] )\n    l = f.readline()\n    s = map(float, l.split())\n    cell[0, 0] = s[0]*conv\n    cell[1, 0] = s[1]*conv\n    cell[2, 0] = s[2]*conv\n    l = f.readline()\n    s = map(float, l.split())\n    cell[0, 1] = s[0]*conv\n    cell[1, 1] = s[1]*conv\n    cell[2, 1] = s[2]*conv\n    l = f.readline()\n    s = map(float, l.split())\n    cell[0, 2] = s[0]*conv\n    cell[1, 2] = s[1]*conv\n    cell[2, 2] = s[2]*conv\n    this.set_cell(cell)\n    this.set_pbc(True)\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_atoms(fn, this, cycfn=None, conv=1.0, symbols=True):\n    f = paropen(fn, \"w\")\n\n    f.write(\"<--- Number of atoms\\n\")\n    f.write(\"%i\\n\" % len(this))\n    f.write(\"<--- Number of occupied orbitals\\n\")\n    f.write(\"%f\\n\" % 0.0)\n    f.write(\"<--- Atom positions\\n\")\n\n    groups = None\n    if this.has(\"groups\"):\n        groups = this.get_array(\"groups\")\n\n    gamma = None\n    if this.has(\"gamma\"):\n        gamma = this.get_array(\"gamma\")\n\n    T = None\n    if this.has(\"T\"):\n        T = this.get_array(\"T\")\n\n    for idx, i in enumerate(this):\n        group_str = \"1\"\n        if groups is not None:\n            group_str = \"%i\" % groups[idx]\n        gamma_str = \"0.0\"\n        if gamma is not None:\n            gamma_str = \"%20.10e\" % gamma[idx]\n        T_str = \"0.0\"\n        if T is not None:\n            T_str = \"%20.10e\" % T[idx]\n\n        sym = i.symbol\n\n        r = i.position\n\n        if symbols:\n            f.write(\"%s   %f   %20.10e  %20.10e  %20.10e   %s %s %s\\n\" % (sym, ase.data.atomic_masses[ase.data.chemical_symbols.index(sym)], r[0]*conv, r[1]*conv, r[2]*conv, group_str, gamma_str, T_str))\n        else:\n            f.write(\"%i   %f   %20.10e  %20.10e  %20.10e   %s %s %s\\n\" % (ase.data.chemical_symbols.index(sym), ase.data.atomic_masses[ase.data.chemical_symbols.index(sym)], r[0]*conv, r[1]*conv, r[2]*conv, group_str, gamma_str, T_str))\n\n\n    f.write(\"<--- Velocities\\n\")\n    for i in this:\n        m = i.mass\n        if m is None:\n            m = ase.data.atomic_masses[ase.data.chemical_symbols.index(i.symbol)]\n        if i.momentum is not None:\n            v = i.momentum/m\n        else:\n            v = [ 0.0, 0.0, 0.0 ]\n        f.write(\"%20.10e %20.10e %20.10e\\n\" % ( v[0], v[1], v[2] ))\n\n    f.write(\"<--- Forces\\n\")\n    for i in this:\n        f.write(\"0 0 0\\n\")\n\n    f.write(\"<--- cell\\n\")\n    cell = this.get_cell()\n    f.write(\"%f %f %f\\n\" % tuple(cell[0, :]))\n    f.write(\"%f %f %f\\n\" % tuple(cell[1, :]))\n    f.write(\"%f %f %f\\n\" % tuple(cell[2, :]))\n\n    for name, aux in this.arrays.items():\n        if not name in atoms_default_fields:\n            f.write(\"<--- %s\\n\" % name)\n            if aux.dtype == int:\n                if len(aux.shape) == 1:\n                    for i in this:\n                        f.write(\" %i\\n\" % aux[i.index])\n                else:\n                    for i in this:\n                        f.write(( aux.shape[1]*\" %i\" + \"\\n\" ) % tuple(aux[i.index].tolist()))\n            else:\n                if len(aux.shape) == 1:\n                    for i in this:\n                        f.write(\" %e\\n\" % aux[i.index])\n                else:\n                    for i in this:\n                        f.write(( aux.shape[1]*\" %e\" + \"\\n\" ) % tuple(aux[i.index].tolist()))\n\n    f.close()\n\n    if cycfn:\n        write_cyc(cycfn, this, conv=conv)", "response": "Write atom information to an atom. dat file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the lattice information to a cyc. dat file", "response": "def write_cyc(fn, this, conv=1.0):\n    \"\"\" Write the lattice information to a cyc.dat file (i.e., tblmd input file)\n    \"\"\"\n\n    lattice = this.get_cell()\n\n    f = paropen(fn, \"w\")\n    f.write(\"<------- Simulation box definition\\n\")\n    f.write(\"<------- Barostat (on = 1, off = 0)\\n\")\n    f.write(\"  0\\n\")\n    f.write(\"<------- Box vectors (start)\\n\")\n    f.write(\"  %20.10f %20.10f %20.10f\\n\" % (lattice[0][0]*conv, lattice[1][0]*conv, lattice[2][0]*conv))\n    f.write(\"  %20.10f %20.10f %20.10f\\n\" % (lattice[0][1]*conv, lattice[1][1]*conv, lattice[2][1]*conv))\n    f.write(\"  %20.10f %20.10f %20.10f\\n\" % (lattice[0][2]*conv, lattice[1][2]*conv, lattice[2][2]*conv))\n    f.write(\"<------- Box vectors (end)\\n\")\n    f.write(\"  %20.10f %20.10f %20.10f\\n\" % (lattice[0][0]*conv, lattice[1][0]*conv, lattice[2][0]*conv))\n    f.write(\"  %20.10f %20.10f %20.10f\\n\" % (lattice[0][1]*conv, lattice[1][1]*conv, lattice[2][1]*conv))\n    f.write(\"  %20.10f %20.10f %20.10f\\n\" % (lattice[0][2]*conv, lattice[1][2]*conv, lattice[2][2]*conv))\n    f.write(\"<------- Mass and gamma of the box (used in connection with the barostat)\\n\")\n    f.write(\"  240 0.005\\n\")\n    f.write(\"<------- Stress tensor (start)\\n\")\n    f.write(\"  0 0 0\\n\")\n    f.write(\"  0 0 0\\n\")\n    f.write(\"  0 0 0\\n\")\n    f.write(\"<------- Stress tensor (end)\\n\")\n    f.write(\"  0 0 0\\n\")\n    f.write(\"  0 0 0\\n\")\n    f.write(\"  0 0 0\\n\")\n    f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_potential_energy(self, a):\n        e = 0.0\n        for c in self.calcs:\n            e += c.get_potential_energy(a)\n        return e", "response": "Calculate the potential energy of an object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nassign an atoms object.", "response": "def set_atoms(self, a):\n        \"\"\"Assign an atoms object.\"\"\"\n        for c in self.calcs:\n            if hasattr(c, \"set_atoms\"):\n                c.set_atoms(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_node(self, node_name, graph=None):\n        if not graph:\n            graph = self.graph\n        if node_name not in graph:\n            raise KeyError('node %s does not exist' % node_name)\n        graph.pop(node_name)\n\n        for node, edges in six.iteritems(graph):\n            if node_name in edges:\n                edges.remove(node_name)", "response": "Deletes this node and all edges referencing it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rename_edges(self, old_task_name, new_task_name, graph=None):\n        if not graph:\n            graph = self.graph\n        for node, edges in graph.items():\n\n            if node == old_task_name:\n                graph[new_task_name] = copy(edges)\n                del graph[old_task_name]\n\n            else:\n                if old_task_name in edges:\n                    edges.remove(old_task_name)\n                    edges.add(new_task_name)", "response": "Rename the edges of a task in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all predecessors of the given node", "response": "def predecessors(self, node, graph=None):\n        \"\"\" Returns a list of all predecessors of the given node \"\"\"\n        if graph is None:\n            graph = self.graph\n        return [key for key in graph if node in graph[key]]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all nodes ultimately downstream of the given node in the dependency graph in topological order.", "response": "def all_downstreams(self, node, graph=None):\n        \"\"\"Returns a list of all nodes ultimately downstream\n        of the given node in the dependency graph, in\n        topological order.\"\"\"\n        if graph is None:\n            graph = self.graph\n        nodes = [node]\n        nodes_seen = set()\n        i = 0\n        while i < len(nodes):\n            downstreams = self.downstream(nodes[i], graph)\n            for downstream_node in downstreams:\n                if downstream_node not in nodes_seen:\n                    nodes_seen.add(downstream_node)\n                    nodes.append(downstream_node)\n            i += 1\n        return list(\n            filter(\n                lambda node: node in nodes_seen,\n                self.topological_sort(graph=graph)\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_leaves(self, graph=None):\n        if graph is None:\n            graph = self.graph\n        return [key for key in graph if not graph[key]]", "response": "Return a list of all leaves in the graph"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(self, graph_dict):\n\n        self.reset_graph()\n        for new_node in six.iterkeys(graph_dict):\n            self.add_node(new_node)\n        for ind_node, dep_nodes in six.iteritems(graph_dict):\n            if not isinstance(dep_nodes, list):\n                raise TypeError('dict values must be lists')\n            for dep_node in dep_nodes:\n                self.add_edge(ind_node, dep_node)", "response": "Reset the graph and build the tree from the passed dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all nodes in the graph with no dependencies.", "response": "def ind_nodes(self, graph=None):\n        \"\"\" Returns a list of all nodes in the graph with no dependencies. \"\"\"\n        if graph is None:\n            graph = self.graph\n\n        dependent_nodes = set(\n            node for dependents in six.itervalues(graph) for node in dependents\n        )\n        return [node for node in graph.keys() if node not in dependent_nodes]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate(self, graph=None):\n        graph = graph if graph is not None else self.graph\n        if len(self.ind_nodes(graph)) == 0:\n            return (False, 'no independent nodes detected')\n        try:\n            self.topological_sort(graph)\n        except ValueError:\n            return (False, 'failed topological sort')\n        return (True, 'valid')", "response": "Returns (Boolean, message) of whether DAG is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef orthogonal(name, shape, scale=1.1, dtype=tf.sg_floatx, summary=True, regularizer=None, trainable=True):\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    # pick the one with the correct shape\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    # create variable\n    x = tf.get_variable(name,\n                        initializer=tf.constant(scale * q[:shape[0], :shape[1]], dtype=dtype),\n                        regularizer=regularizer, trainable=trainable)\n    # add summary\n    if summary:\n        tf.sg_summary_param(x)\n    return x", "response": "r Creates a tensor variable of which initial values are of\n    an orthogonal ndarray."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_fans(shape):\n    if len(shape) == 2:\n        fan_in = shape[0]\n        fan_out = shape[1]\n    elif len(shape) == 4 or len(shape) == 5:\n        # assuming convolution kernels (2D or 3D).\n        kernel_size = np.prod(shape[:2])\n        fan_in = shape[-2] * kernel_size\n        fan_out = shape[-1] * kernel_size\n    else:\n        # no specific assumptions\n        fan_in = np.sqrt(np.prod(shape))\n        fan_out = np.sqrt(np.prod(shape))\n    return fan_in, fan_out", "response": "r Returns the size of input dimension and output dimension given shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sg_dense(tensor, opt):\n    # parameter initialize\n    w = tf.sg_initializer.he_uniform('W', (opt.in_dim, opt.dim),\n                                     regularizer=opt.regularizer, summary=opt.summary)\n    b = tf.sg_initializer.constant('b', opt.dim, summary=opt.summary) if opt.bias else 0\n\n    # apply transform\n    out = tf.matmul(tensor, w) + b\n\n    return out", "response": "rApplies a full connection to a 2 - D tensor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sg_aconv(tensor, opt):\n    # default options\n    opt += tf.sg_opt(size=(3, 3), rate=2, pad='SAME')\n    opt.size = opt.size if isinstance(opt.size, (tuple, list)) else [opt.size, opt.size]\n\n    # parameter tf.sg_initializer\n    w = tf.sg_initializer.he_uniform('W', (opt.size[0], opt.size[1], opt.in_dim, opt.dim),\n                                     regularizer=opt.regularizer, summary=opt.summary)\n    b = tf.sg_initializer.constant('b', opt.dim, summary=opt.summary) if opt.bias else 0\n\n    # apply convolution\n    out = tf.nn.atrous_conv2d(tensor, w, rate=opt.rate, padding=opt.pad) + b\n\n    return out", "response": "rApplies a 2 - D atrous convolution."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_upconv1d(tensor, opt):\n    # default options\n    opt += tf.sg_opt(size=4, stride=2, pad='SAME')\n    opt.size = [opt.size, 1]\n    opt.stride = [1, opt.stride, 1, 1]\n\n    # parameter tf.sg_initializer\n    w = tf.sg_initializer.he_uniform('W', (opt.size[0], opt.size[1], opt.dim, opt.in_dim),\n                                     regularizer=opt.regularizer, summary=opt.summary)\n    b = tf.sg_initializer.constant('b', opt.dim, summary=opt.summary) if opt.bias else 0\n\n    # make 4-D tensor\n    tensor = tensor.sg_expand_dims(axis=2)\n\n    # tedious shape handling for conv2d_transpose\n    shape = tensor.get_shape().as_list()\n    if opt.pad == \"SAME\":\n        out_shape = [tf.shape(tensor)[0], shape[1] * opt.stride[1], shape[2] * opt.stride[2], opt.dim]\n    else:\n        out_shape = [tf.shape(tensor)[0], (shape[1] - 1) * opt.stride[1] + opt.size[0],\n                     (shape[2] - 1) * opt.stride[2] + opt.size[1], opt.dim]\n\n    # apply convolution\n    out = tf.nn.conv2d_transpose(tensor, w, output_shape=tf.stack(out_shape),\n                                 strides=opt.stride, padding=opt.pad) + b\n    # reset shape is needed because conv2d_transpose() erase all shape information.\n    # noinspection PyUnresolvedReferences\n    out.set_shape([None, out_shape[1], out_shape[2], opt.dim])\n\n    # squeeze\n    out = out.sq_squeeze(axis=2)\n\n    return out", "response": "rApplies 1 - D convolution or convolution transpose."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sg_emb(**kwargs):\n    opt = tf.sg_opt(kwargs)\n    assert opt.name is not None, 'name is mandatory.'\n\n    if opt.emb is None:\n        # initialize embedding matrix\n        assert opt.voca_size is not None, 'voca_size is mandatory.'\n        assert opt.dim is not None, 'dim is mandatory.'\n        w = tf.sg_initializer.he_uniform(opt.name, (opt.voca_size - 1, opt.dim), summary=opt.summary)\n    else:\n        # use given embedding matrix\n        w = tf.sg_initializer.external(opt.name, value=opt.emb, summary=opt.summary)\n\n    # 1st row should be zero and not be updated by backprop because of zero padding.\n    emb = tf.concat([tf.zeros((1, opt.dim), dtype=tf.sg_floatx), w], 0)\n\n    return emb", "response": "r Returns a look - up table for embedding."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ln_rnn(x, gamma, beta):\n    # calc layer mean, variance for final axis\n    mean, variance = tf.nn.moments(x, axes=[len(x.get_shape()) - 1], keep_dims=True)\n\n    # apply layer normalization\n    x = (x - mean) / tf.sqrt(variance + tf.sg_eps)\n\n    # apply parameter\n    return gamma * x + beta", "response": "rApplies layer normalization.\n    Normalizes the last dimension of the tensor x."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sg_rnn(tensor, opt):\n    # layer normalization\n    # noinspection PyPep8\n    ln = lambda v: _ln_rnn(v, gamma, beta) if opt.ln else v\n\n    # step function\n    def step(hh, x):\n        # simple rnn\n        y = ln(tf.matmul(x, w) + tf.matmul(hh, u) + (b if opt.bias else 0))\n        return y\n\n    # parameter initialize\n    w = tf.sg_initializer.orthogonal('W', (opt.in_dim, opt.dim), summary=opt.summary)\n    u = tf.sg_initializer.identity('U', opt.dim, summary=opt.summary)\n    if opt.bias:\n        b = tf.sg_initializer.constant('b', opt.dim, summary=opt.summary)\n\n    # layer normalization parameters\n    if opt.ln:\n        # offset, scale parameter\n        beta = tf.sg_initializer.constant('beta', opt.dim, summary=opt.summary)\n        gamma = tf.sg_initializer.constant('gamma', opt.dim, value=1, summary=opt.summary)\n\n    # initial state\n    init_h = opt.init_state if opt.init_state is not None \\\n        else tf.zeros((tensor.get_shape().as_list()[0], opt.dim), dtype=tf.sg_floatx)\n\n    # do rnn loop\n    h, out = init_h, []\n    for i in range(tensor.get_shape().as_list()[1]):\n        # apply step func\n        h = step(h, tensor[:, i, :])\n        # save result\n        out.append(h.sg_expand_dims(axis=1))\n\n    # merge tensor\n    out = tf.concat(out, 1)\n\n    # apply mask\n    if opt.mask is None:\n        if opt.last_only:\n            return out[:, -1, :]\n        else:\n            return out\n    else:\n        # apply mask\n        out *= opt.mask.sg_expand_dims(axis=2).sg_float()\n\n        if opt.last_only:\n            # calc sequence length using given mask\n            seq_len = opt.mask.sg_int().sg_sum(axis=1)\n            # get last output\n            rev = tf.reverse_sequence(out, seq_len, seq_axis=1)\n            return rev[:, 0, :]\n        else:\n            return out", "response": "rApplies a simple rnn.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sg_gru(tensor, opt):\n\n    # layer normalization\n    # noinspection PyPep8\n    ln = lambda v: _ln_rnn(v, gamma, beta) if opt.ln else v\n\n    # step func\n    def step(hh, x):\n        # update gate\n        z = tf.sigmoid(ln(tf.matmul(x, w_z) + tf.matmul(hh, u_z) + (b_z if opt.bias else 0)))\n        # reset gate\n        r = tf.sigmoid(ln(tf.matmul(x, w_r) + tf.matmul(hh, u_r) + (b_r if opt.bias else 0)))\n        # h_hat\n        h_hat = tf.tanh(ln(tf.matmul(x, w_h) + tf.matmul(r * hh, u_h) + (b_h if opt.bias else 0)))\n        # final output\n        y = (1. - z) * h_hat + z * hh\n        return y\n\n    # parameter initialize\n    w_z = tf.sg_initializer.orthogonal('W_z', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_z = tf.sg_initializer.identity('U_z', opt.dim, summary=opt.summary)\n    w_r = tf.sg_initializer.orthogonal('W_r', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_r = tf.sg_initializer.identity('U_r', opt.dim, summary=opt.summary)\n    w_h = tf.sg_initializer.orthogonal('W_h', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_h = tf.sg_initializer.identity('U_h', opt.dim, summary=opt.summary)\n    if opt.bias:\n        b_z = tf.sg_initializer.constant('b_z', opt.dim, summary=opt.summary)\n        b_r = tf.sg_initializer.constant('b_r', opt.dim, summary=opt.summary)\n        b_h = tf.sg_initializer.constant('b_h', opt.dim, summary=opt.summary)\n\n    # layer normalization parameters\n    if opt.ln:\n        # offset, scale parameter\n        beta = tf.sg_initializer.constant('beta', opt.dim, summary=opt.summary)\n        gamma = tf.sg_initializer.constant('gamma', opt.dim, value=1, summary=opt.summary)\n\n    # initial state\n    init_h = opt.init_state if opt.init_state is not None \\\n        else tf.zeros((tensor.get_shape().as_list()[0], opt.dim), dtype=tf.sg_floatx)\n\n    # do rnn loop\n    h, out = init_h, []\n    for i in range(tensor.get_shape().as_list()[1]):\n        # apply step function\n        h = step(h, tensor[:, i, :])\n        # save result\n        # noinspection PyUnresolvedReferences\n        out.append(h.sg_expand_dims(axis=1))\n\n    # merge tensor\n    out = tf.concat(out, 1)\n\n    # apply mask\n    if opt.mask is None:\n        if opt.last_only:\n            return out[:, -1, :]\n        else:\n            return out\n    else:\n        # apply mask\n        out *= opt.mask.sg_expand_dims(axis=2).sg_float()\n\n        if opt.last_only:\n            # calc sequence length using given mask\n            seq_len = opt.mask.sg_int().sg_sum(axis=1)\n            # get last output\n            rev = tf.reverse_sequence(out, seq_len, seq_axis=1)\n            return rev[:, 0, :]\n        else:\n            return out", "response": "r Applies a GRU to the given tensor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_lstm(tensor, opt):\n    # layer normalization\n    # noinspection PyPep8\n    ln = lambda v: _ln_rnn(v, gamma, beta) if opt.ln else v\n\n    # step func\n    def step(hh, cc, x):\n        # forget gate\n        f = tf.sigmoid(ln(tf.matmul(x, w_f) + tf.matmul(hh, u_f) + (b_f if opt.bias else 0)))\n        # input gate\n        ii = tf.sigmoid(ln(tf.matmul(x, w_i) + tf.matmul(hh, u_i) + (b_i if opt.bias else 0)))\n        # new cell value\n        c_new = tf.tanh(ln(tf.matmul(x, w_c) + tf.matmul(hh, u_c) + (b_c if opt.bias else 0)))\n        # out gate\n        o = tf.sigmoid(ln(tf.matmul(x, w_o) + tf.matmul(hh, u_o) + (b_o if opt.bias else 0)))\n        # cell update\n        cell = f * cc + ii * c_new\n        # final output\n        y = o * tf.tanh(cell)\n        return y, cell\n\n    # parameter initialize\n    w_i = tf.sg_initializer.orthogonal('W_i', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_i = tf.sg_initializer.identity('U_i', opt.dim, summary=opt.summary)\n    w_f = tf.sg_initializer.orthogonal('W_f', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_f = tf.sg_initializer.identity('U_f', opt.dim, summary=opt.summary)\n    w_o = tf.sg_initializer.orthogonal('W_o', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_o = tf.sg_initializer.identity('U_o', opt.dim, summary=opt.summary)\n    w_c = tf.sg_initializer.orthogonal('W_c', (opt.in_dim, opt.dim), summary=opt.summary)\n    u_c = tf.sg_initializer.identity('U_c', opt.dim, summary=opt.summary)\n    if opt.bias:\n        b_i = tf.sg_initializer.constant('b_i', opt.dim, summary=opt.summary)\n        b_f = tf.sg_initializer.constant('b_f', opt.dim, summary=opt.summary)\n        b_o = tf.sg_initializer.constant('b_o', opt.dim, value=1, summary=opt.summary)\n        b_c = tf.sg_initializer.constant('b_c', opt.dim, summary=opt.summary)\n\n    # layer normalization parameters\n    if opt.ln:\n        # offset, scale parameter\n        beta = tf.sg_initializer.constant('beta', opt.dim, summary=opt.summary)\n        gamma = tf.sg_initializer.constant('gamma', opt.dim, value=1, summary=opt.summary)\n\n    # initial state\n    init_h = opt.init_state if opt.init_state is not None \\\n        else tf.zeros((tensor.get_shape().as_list()[0], opt.dim), dtype=tf.sg_floatx)\n\n    # do rnn loop\n    h, c, out = init_h, init_h, []\n    for i in range(tensor.get_shape().as_list()[1]):\n        # apply step function\n        h, c = step(h, c, tensor[:, i, :])\n        # save result\n        out.append(h.sg_expand_dims(axis=1))\n\n    # merge tensor\n    out = tf.concat(out, 1)\n\n    # apply mask\n    if opt.mask is None:\n        if opt.last_only:\n            return out[:, -1, :]\n        else:\n            return out\n    else:\n        # apply mask\n        out *= opt.mask.sg_expand_dims(axis=2).sg_float()\n\n        if opt.last_only:\n            # calc sequence length using given mask\n            seq_len = opt.mask.sg_int().sg_sum(axis=1)\n            # get last output\n            rev = tf.reverse_sequence(out, seq_len, seq_axis=1)\n            return rev[:, 0, :]\n        else:\n            return out", "response": "r Applies an LSTM to the input tensor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sg_ce(tensor, opt):\n    opt += tf.sg_opt(one_hot=False)\n    assert opt.target is not None, 'target is mandatory.'\n\n    if opt.one_hot:\n        out = tf.identity(tf.nn.softmax_cross_entropy_with_logits(labels=opt.target, logits=tensor), 'ce')\n    else:\n        out = tf.identity(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=opt.target, logits=tensor), 'ce')\n\n    # masking loss\n    if opt.mask:\n        out *= tf.not_equal(opt.target, tf.zeros_like(opt.target)).sg_float()\n\n    # add summary\n    tf.sg_summary_loss(out, name=opt.name)\n\n    return out", "response": "r Returns softmax cross entropy loss between tensor and target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sg_hinge(tensor, opt):\n    assert opt.target is not None, 'target is mandatory.'\n\n    # default margin\n    opt += tf.sg_opt(margin=1)\n\n    # reshape target\n    shape = tensor.get_shape().as_list()\n    broadcast_shape = [-1] + [1] * (len(shape) - 2) + [shape[-1]]\n    target = tf.cast(tf.reshape(opt.target, broadcast_shape), tf.sg_floatx)\n    \n    # hinge loss\n    out = tf.identity(tf.maximum(opt.margin - target * tensor, 0), 'hinge')\n\n    # add summary\n    tf.sg_summary_loss(out, name=opt.name)\n\n    return out", "response": "r Returns hinge loss between tensor and target."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sg_float(tensor, opt):\n    return tf.cast(tensor, tf.sg_floatx, name=opt.name)", "response": "Casts a tensor to floatx."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sg_int(tensor, opt):\n    return tf.cast(tensor, tf.sg_intx, name=opt.name)", "response": "Casts a tensor to intx."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sg_expand_dims(tensor, opt):\n    opt += tf.sg_opt(axis=-1)\n    return tf.expand_dims(tensor, opt.axis, name=opt.name)", "response": "r Inserts a new axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sg_squeeze(tensor, opt):\n    opt += tf.sg_opt(axis=[-1])\n    opt.axis = opt.axis if isinstance(opt.axis, (tuple, list)) else [opt.axis]\n    return tf.squeeze(tensor, opt.axis, name=opt.name)", "response": "r Removes axis of size 1 from the shape of a tensor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sg_flatten(tensor, opt):\n    dim = np.prod(tensor.get_shape().as_list()[1:])\n    return tf.reshape(tensor, [-1, dim], name=opt.name)", "response": "r Reshapes a tensor to batch_size x - 1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sg_argmax(tensor, opt):\n    opt += tf.sg_opt(axis=tensor.get_shape().ndims-1)\n    return tf.argmax(tensor, opt.axis, opt.name)", "response": "r Returns the indices of the maximum values along the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sg_one_hot(tensor, opt):\n    assert opt.depth is not None, 'depth is mandatory.'\n    return tf.one_hot(tensor, opt.depth, name=opt.name)", "response": "r Converts a tensor into a one - hot tensor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sg_mean(tensor, opt):\n    return tf.reduce_mean(tensor, axis=opt.axis, keep_dims=opt.keep_dims, name=opt.name)", "response": "r Computes the mean of elements across axis of a tensor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sg_prod(tensor, opt):\n    return tf.reduce_prod(tensor, axis=opt.axis, keep_dims=opt.keep_dims, name=opt.name)", "response": "r Computes the product of elements across axis of a tensor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_all(tensor, opt):\n    return tf.reduce_all(tensor, axis=opt.axis, keep_dims=opt.keep_dims, name=opt.name)", "response": "r Computes the logical and of elements across axis of a tensor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_pool1d(tensor, opt):\n\n    # default stride and pad\n    opt += tf.sg_opt(stride=2, pad='VALID')\n    opt += tf.sg_opt(size=opt.stride)\n\n    if opt.avg:\n        out = tf.nn.avg_pool(tensor.sg_expand_dims(axis=2),\n                             (1, opt.size, 1, 1), (1, opt.stride, 1, 1), opt.pad)\n    else:\n        out = tf.nn.max_pool(tensor.sg_expand_dims(axis=2),\n                             (1, opt.size, 1, 1), (1, opt.stride, 1, 1), opt.pad)\n\n    return tf.identity(out.sg_squeeze(axis=2), name=opt.name)", "response": "r Performs the 1 - D pooling on the tensor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sg_lookup(tensor, opt):\n    assert opt.emb is not None, 'emb is mandatory.'\n    return tf.nn.embedding_lookup(opt.emb, tensor, name=opt.name)", "response": "r Returns the tensor which is the embedding matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sg_reverse_seq(tensor, opt):\n    # default sequence dimension\n    opt += tf.sg_opt(axis=1)\n    seq_len = tf.not_equal(tensor, tf.zeros_like(tensor)).sg_int().sg_sum(axis=opt.axis)\n    return tf.reverse_sequence(tensor, seq_len, opt.axis, name=opt.name)", "response": "r Reverses variable length slices."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sg_periodic_shuffle(tensor, opt):\n    # default factor\n    opt += tf.sg_opt(factor=2)\n\n    # get current shape\n    batch, row, col, channel = tensor.get_shape().as_list()\n\n    # get target channel num\n    channel_target = channel // (opt.factor * opt.factor)\n    channel_factor = channel // channel_target\n\n    # intermediate shape for shuffling\n    shape_1 = [batch, row, col, channel_factor // opt.factor, channel_factor // opt.factor]\n    shape_2 = [batch, row * opt.factor, col * opt.factor, 1]\n\n    # reshape and transpose for periodic shuffling for each channel\n    out = []\n    for i in range(channel_target):\n        out.append((tensor[:, :, :, i*channel_factor:(i+1)*channel_factor])\n                   .sg_reshape(shape=shape_1)\n                   .sg_transpose(perm=(0, 1, 3, 2, 4))\n                   .sg_reshape(shape=shape_2))\n\n    # final output\n    out = tf.concat(out, 3)\n\n    return tf.identity(out, name=opt.name)", "response": "r Periodic shuffle transformation for SubPixel CNN."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sg_context(**kwargs):\n    global _context\n\n    # set options when enter\n    context_now = tf.sg_opt(kwargs)\n    _context += [context_now]\n\n    # if named context\n    if context_now.name:\n        context_now.scope_name = context_now.name\n        context_now.name = None\n        with tf.variable_scope(context_now.scope_name):\n            yield\n    else:\n        yield\n\n    # clear options when exit\n    del _context[-1]", "response": "r Context helper for computational graph building."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sg_sugar_func(func):\n    @wraps(func)\n    def wrapper(tensor, **kwargs):\n        # call sugar function\n        out = func(tensor, tf.sg_opt(kwargs))\n        # save node info for reuse\n        out._sugar = tf.sg_opt(func=func, arg=tf.sg_opt(kwargs)+sg_get_context(), prev=tensor)\n        # inject reuse function\n        out.sg_reuse = types.MethodType(sg_reuse, out)\n        return out\n\n    return wrapper", "response": "r Decorates a function func so that it can be a sugar function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_reuse(tensor, **opt):\n    opt = tf.sg_opt(opt)\n    assert hasattr(tensor, '_sugar'), 'cannot reuse this node.'\n    assert opt.input is not None, 'input is mandatory.'\n\n    # get all nodes in this graph\n    nodes, prev = [tensor], tensor._sugar.prev\n    while prev is not None:\n        nodes = [prev] + nodes\n        prev = prev._sugar.prev if hasattr(prev, '_sugar') else None\n\n    # create graph again for this input\n    out = opt.input\n    for node in nodes[1:]:  # exclude head node\n        if node._sugar.is_layer:\n            fn = tf.sg_layer_func(node._sugar.func)\n            if node._sugar.arg.scope_name:\n                with tf.variable_scope(node._sugar.arg.scope_name):\n                    out = fn(out, **(node._sugar.arg + tf.sg_opt(name=node._sugar.name, reuse=True)))\n            else:\n                out = fn(out, **(node._sugar.arg + tf.sg_opt(name=node._sugar.name, reuse=True)))\n        else:\n            out = node._sugar.func(out, node._sugar.arg)\n\n    return out", "response": "r Reconstructs computational graph of tensor so all the parameters\n    can be reused and replace its input tensor with opt. input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sg_input(shape=None, dtype=sg_floatx, name=None):\n    if shape is None:\n        return tf.placeholder(dtype, shape=None, name=name)\n    else:\n        if not isinstance(shape, (list, tuple)):\n            shape = [shape]\n        return tf.placeholder(dtype, shape=[None] + list(shape), name=name)", "response": "r Creates a placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sg_inject(path, mod_name):\n    # import module\n    import sys\n    if path not in list(sys.path):\n        sys.path.append(path)\n    globals()[mod_name] = importlib.import_module(mod_name)\n    # find functions\n    for func_name in dir(globals()[mod_name]):\n        if isinstance(globals()[mod_name].__dict__.get(func_name), types.FunctionType):\n            if not func_name.startswith('_'):\n                # inject to tf.Variable type\n                exec('tf.Variable.%s = %s.%s' % (func_name, mod_name, func_name))\n                # inject to tf.Tensor type\n                exec('tf.Tensor.%s = %s.%s' % (func_name, mod_name, func_name))", "response": "r Converts all functions in the given Python module to sugar functions\n    so that they can be used in a chainable manner."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sg_arg():\n    if not tf.app.flags.FLAGS.__dict__['__parsed']:\n        tf.app.flags.FLAGS._parse_flags()\n    return tf.sg_opt(tf.app.flags.FLAGS.__dict__['__flags'])", "response": "r Returns current command line options"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_summary_loss(tensor, prefix='losses', name=None):\n    # defaults\n    prefix = '' if prefix is None else prefix + '/'\n    # summary name\n    name = prefix + _pretty_name(tensor) if name is None else prefix + name\n    # summary statistics\n    _scalar(name, tf.reduce_mean(tensor))\n    _histogram(name + '-h', tensor)", "response": "r Register tensor to summary report as loss"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_summary_gradient(tensor, gradient, prefix=None, name=None):\n    # defaults\n    prefix = '' if prefix is None else prefix + '/'\n    # summary name\n    name = prefix + _pretty_name(tensor) if name is None else prefix + name\n    # summary statistics\n    # noinspection PyBroadException\n    _scalar(name + '/grad', tf.reduce_mean(tf.abs(gradient)))\n    _histogram(name + '/grad-h', tf.abs(gradient))", "response": "r Register tensor to summary report as gradient"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sg_summary_param(tensor, prefix=None, name=None):\n    # defaults\n    prefix = '' if prefix is None else prefix + '/'\n    # summary name\n    name = prefix + _pretty_name(tensor) if name is None else prefix + name\n    # summary statistics\n    _scalar(name + '/abs', tf.reduce_mean(tf.abs(tensor)))\n    _histogram(name + '/abs-h', tf.abs(tensor))", "response": "r Register tensor to summary report as parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sg_summary_image(tensor, prefix=None, name=None):\n    # defaults\n    prefix = '' if prefix is None else prefix + '/'\n    # summary name\n    name = prefix + _pretty_name(tensor) if name is None else prefix + name\n    # summary statistics\n    if not tf.get_variable_scope().reuse:\n        tf.summary.image(name + '-im', tensor)", "response": "r Registers a tensor to summary report as image."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sg_summary_audio(tensor, sample_rate=16000, prefix=None, name=None):\n    # defaults\n    prefix = '' if prefix is None else prefix + '/'\n    # summary name\n    name = prefix + _pretty_name(tensor) if name is None else prefix + name\n    # summary statistics\n    if not tf.get_variable_scope().reuse:\n        tf.summary.audio(name + '-au', tensor, sample_rate)", "response": "r Register tensor to summary report as audio\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sg_leaky_relu(x, opt):\n    return tf.where(tf.greater(x, 0), x, 0.01 * x, name=opt.name)", "response": "r Leaky Relu operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_train(**kwargs):\n    opt = tf.sg_opt(kwargs)\n    assert opt.loss is not None, 'loss is mandatory.'\n\n    # default training options\n    opt += tf.sg_opt(optim='MaxProp', lr=0.001, beta1=0.9, beta2=0.99, category='', ep_size=100000)\n\n    # get optimizer\n    train_op = sg_optim(opt.loss, optim=opt.optim, lr=0.001,\n                        beta1=opt.beta1, beta2=opt.beta2, category=opt.category)\n\n    # for console logging\n    loss_ = opt.loss\n\n    # use only first loss when multiple GPU case\n    if isinstance(opt.loss, (tuple, list)):\n        loss_ = opt.loss[0]\n\n    # define train function\n    # noinspection PyUnusedLocal\n    @sg_train_func\n    def train_func(sess, arg):\n        return sess.run([loss_, train_op])[0]\n\n    # run train function\n    train_func(**opt)", "response": "r Trains the model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sg_print(tensor_list):\n    # to list\n    if type(tensor_list) is not list and type(tensor_list) is not tuple:\n        tensor_list = [tensor_list]\n\n    # evaluate tensor list with queue runner\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n        sg_init(sess)\n        with tf.sg_queue_context():\n            res = sess.run(tensor_list)\n            for r in res:\n                print(r, r.shape, r.dtype)\n\n    if len(res) == 1:\n        return res[0]\n    else:\n        return res", "response": "r Simple tensor printing function for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sg_restore(sess, save_path, category=''):\n    # to list\n    if not isinstance(category, (tuple, list)):\n        category = [category]\n\n    # make variable list to load\n    var_list = {}\n    for cat in category:\n        for t in tf.global_variables():\n            if t.name.startswith(cat):\n                var_list[t.name[:-2]] = t\n\n    # restore parameters\n    saver = tf.train.Saver(var_list)\n    saver.restore(sess, save_path)", "response": "r Restores previously saved variables."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sg_train_func(func):\n    @wraps(func)\n    def wrapper(**kwargs):\n        r\"\"\" Manages arguments of `tf.sg_opt`.\n\n        Args:\n          **kwargs:\n            lr: A Python Scalar (optional). Learning rate. Default is .001.\n\n            save_dir: A string. The root path to which checkpoint and log files are saved.\n              Default is `asset/train`.\n            max_ep: A positive integer. Maximum number of epochs. Default is 1000.\n            ep_size: A positive integer. Number of Total batches in an epoch.\n              For proper display of log. Default is 1e5.\n\n            save_interval: A Python scalar. The interval of saving checkpoint files.\n              By default, for every 600 seconds, a checkpoint file is written.\n            log_interval: A Python scalar. The interval of recoding logs.\n              By default, for every 60 seconds, logging is executed.\n            max_keep: A positive integer. Maximum number of recent checkpoints to keep. Default is 5.\n            keep_interval: A Python scalar. How often to keep checkpoints. Default is 1 hour.\n\n            eval_metric: A list of tensors containing the value to evaluate. Default is [].\n\n            tqdm: Boolean. If True (Default), progress bars are shown. If False, a series of loss\n                will be shown on the console.\n        \"\"\"\n        opt = tf.sg_opt(kwargs)\n\n        # default training options\n        opt += tf.sg_opt(lr=0.001,\n                         save_dir='asset/train',\n                         max_ep=1000, ep_size=100000,\n                         save_interval=600, log_interval=60,\n                         eval_metric=[],\n                         max_keep=5, keep_interval=1,\n                         tqdm=True)\n\n        # training epoch and loss\n        epoch, loss = -1, None\n\n        # checkpoint saver\n        saver = tf.train.Saver(max_to_keep=opt.max_keep,\n                               keep_checkpoint_every_n_hours=opt.keep_interval)\n\n        # add evaluation summary\n        for m in opt.eval_metric:\n            tf.sg_summary_metric(m)\n\n        # summary writer\n        log_dir = opt.save_dir + '/run-%02d%02d-%02d%02d' % tuple(time.localtime(time.time()))[1:5]\n        summary_writer = tf.summary.FileWriter(log_dir)\n\n        # console logging function\n        def console_log(sess_):\n            if epoch >= 0:\n                tf.sg_info('\\tEpoch[%03d:gs=%d] - loss = %s' %\n                           (epoch, sess_.run(tf.sg_global_step()),\n                            ('NA' if loss is None else '%8.6f' % loss)))\n\n        # create supervisor\n        sv = tf.train.Supervisor(logdir=opt.save_dir,\n                                 saver=saver,\n                                 save_model_secs=opt.save_interval,\n                                 summary_writer=summary_writer,\n                                 save_summaries_secs=opt.log_interval,\n                                 global_step=tf.sg_global_step(),\n                                 local_init_op=tf.sg_phase().assign(True))\n\n        # create session\n        with sv.managed_session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n\n            # console logging loop\n            if not opt.tqdm:\n                sv.loop(opt.log_interval, console_log, args=(sess, ))\n\n            # get start epoch\n            _step = sess.run(tf.sg_global_step())\n            ep = _step // opt.ep_size\n\n            # check if already finished\n            if ep <= opt.max_ep:\n\n                # logging\n                tf.sg_info('Training started from epoch[%03d]-step[%d].' % (ep, _step))\n\n                # epoch loop\n                for ep in range(ep, opt.max_ep + 1):\n\n                    # update epoch info\n                    start_step = sess.run(tf.sg_global_step()) % opt.ep_size\n                    epoch = ep\n\n                    # create progressbar iterator\n                    if opt.tqdm:\n                        iterator = tqdm(range(start_step, opt.ep_size), total=opt.ep_size, initial=start_step,\n                                        desc='train', ncols=70, unit='b', leave=False)\n                    else:\n                        iterator = range(start_step, opt.ep_size)\n\n                    # batch loop\n                    for _ in iterator:\n\n                        # exit loop\n                        if sv.should_stop():\n                            break\n\n                        # call train function\n                        batch_loss = func(sess, opt)\n\n                        # loss history update\n                        if batch_loss is not None and \\\n                                not np.isnan(batch_loss.all()) and not np.isinf(batch_loss.all()):\n                            if loss is None:\n                                loss = np.mean(batch_loss)\n                            else:\n                                loss = loss * 0.9 + np.mean(batch_loss) * 0.1\n\n                    # log epoch information\n                    console_log(sess)\n\n                # save last version\n                saver.save(sess, opt.save_dir + '/model.ckpt', global_step=sess.run(tf.sg_global_step()))\n\n                # logging\n                tf.sg_info('Training finished at epoch[%d]-step[%d].' % (ep, sess.run(tf.sg_global_step())))\n            else:\n                tf.sg_info('Training already finished at epoch[%d]-step[%d].' %\n                           (ep - 1, sess.run(tf.sg_global_step())))\n\n    return wrapper", "response": "r Decorates a function to be used as sg_train_func."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sg_regularizer_loss(scale=1.0):\n    return scale * tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))", "response": "r Returns the regularizer loss of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies vgg 19 model.", "response": "def sg_vgg_19(tensor, opt):\n    r\"\"\"Applies vgg 19 model.\n    \n    Note that the fc layers in the original architecture \n      will be replaced with fully convolutional layers.\n      For convenience, We still call them fc layers, though.\n    \n    Args:\n      tensor: A `Tensor`.\n      opt:\n        num_class: An integer. Number of class. Default is 1000.\n        conv_only: Boolean. If True, fc layers are not applied. Default is False.\n        squeeze: Boolean. If True (default), the dimensions with size 1 in the final outputs will be removed.\n        act: String. 'relu' (default). the activation function name\n        bn: True or False(default). If True, batch normal will be applied\n        reuse: Boolean(Optional). If True, all variables will be loaded from previous network.\n        name: String(Optional). If provided, used as the scope name of this network\n    \n    Returns:\n      A `Tensor`.\n    \"\"\"\n    opt += tf.sg_opt(num_class=1000, conv_only=False, squeeze=True, act='relu')\n\n    # convolution layers\n    with tf.sg_context(name=opt.name, act=opt.act, bn=opt.bn, reuse=opt.reuse):\n        conv = (tensor\n                .sg_conv(dim=64, name='conv1_1')\n                .sg_conv(name='conv1_2')\n                .sg_pool()\n                .sg_conv(dim=128, name='conv2_1')\n                .sg_conv(name='conv2_2')\n                .sg_pool()\n                .sg_conv(dim=256, name='conv3_1')\n                .sg_conv(name='conv3_2')\n                .sg_conv(name='conv3_3')\n                .sg_conv(name='conv3_4')\n                .sg_pool()\n                .sg_conv(dim=512, name='conv4_1')\n                .sg_conv(name='conv4_2')\n                .sg_conv(name='conv4_3')\n                .sg_conv(name='conv4_4')\n                .sg_pool()\n                .sg_conv(dim=512, name='conv5_1')\n                .sg_conv(name='conv5_2')\n                .sg_conv(name='conv5_3')\n                .sg_conv(name='conv5_4')\n                .sg_pool())\n\n    # fully convolution layers\n    with tf.sg_context(name=opt.name, act=opt.act, pad='VALID', bn=opt.bn, reuse=opt.reuse):\n        fc = (conv\n              .sg_conv(dim=4096, size=7, dout=opt.dout, name='fc1')\n              .sg_conv(dim=4096, size=1, dout=opt.dout, name='fc2')\n              .sg_conv(dim=opt.num_class, size=1, act='linear', name='fc3'))\n\n    if opt.conv_only:\n        return conv\n    else:\n        if opt.squeeze:\n            return fc.sg_squeeze(axis=(1, 2))\n        else:\n            return fc"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies basic architecture of residual net.", "response": "def sg_resnet_layer(x, opt):\n    r\"\"\"Applies basic architecture of residual net.\n    \n    Note that the fc layers in the original architecture \n      will be replaced with fully convolutional layers.\n      For convenience, We still call them fc layers, though.\n    \n    Args:\n      x: A `Tensor`.\n      opt:\n          dim: An integer. Dimension for this resnet layer\n          num: Number of times to repeat\n          act: String. 'relu' (default). the activation function name\n          reuse: Boolean(Optional). If True, all variables will be loaded from previous network.\n          name: String. (optional) Used as convolution layer prefix\n\n    Returns:\n      A `Tensor`. \n    \"\"\"\n    assert opt.dim is not None, 'dim is mandatory.'\n    assert opt.num is not None, 'num is mandatory.'\n\n    # default stride\n    opt += tf.sg_opt(stride=1, act='relu')\n\n    # format convolutional layer name\n    def cname(index):\n        return opt.name if opt.name is None else opt.name + '_%d' % index\n\n    with tf.sg_context(bias=False, reuse=opt.reuse):\n        # 1st block\n        out = (x\n               .sg_bypass(act=opt.act, bn=True, name=cname(0))\n               .sg_conv(dim=opt.dim, size=1, act=opt.act, stride=opt.stride, bn=True, name=cname(1))\n               .sg_conv(dim=opt.dim, size=3, act=opt.act, bn=True, name=cname(2))\n               .sg_conv(dim=opt.dim*4, size=1, name=cname(3)))\n        out += x.sg_conv(dim=opt.dim * 4, size=1, stride=opt.stride, name=cname(4))\n\n        # middle blocks\n        for i in range(1, opt.num):\n            out_new = (out\n                       .sg_bypass(act=opt.act, name=cname(4 * i + 1))\n                       .sg_conv(dim=opt.dim, size=1, act=opt.act, bn=True, name=cname(4 * i + 2))\n                       .sg_conv(dim=opt.dim, size=3, act=opt.act, bn=True, name=cname(4 * i + 3))\n                       .sg_conv(dim=opt.dim*4, size=1, name=cname(4 * i + 4)))\n            out += out_new\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sg_densenet_layer(x, opt):\n    assert opt.dim is not None, 'dim is mandatory.'\n    assert opt.num is not None, 'num is mandatory.'\n\n    # default stride\n    opt += tf.sg_opt(stride=1, act='relu', trans=True)\n\n    # format convolutional layer name\n    def cname(index):\n        return opt.name if opt.name is None else opt.name + '_%d' % index\n\n    # dense layer\n    with tf.sg_context(bias=False, reuse=opt.reuse):\n        out = x\n        for i in range(opt.num):\n            # dense block\n            out_new = (out\n                       .sg_bypass(act=opt.act, bn=True, name=cname(3 * i + 1))\n                       .sg_conv(dim=opt.dim // 4, size=1, act=opt.act, bn=True, name=cname(3 * i + 2))\n                       .sg_conv(dim=opt.dim, size=3, name=cname(3 * i + 3)))\n            out = tf.concat([out_new, out], 3)\n\n        # transition layer\n        if opt.trans:\n            out = (out\n                   .sg_bypass(act=opt.act, bn=True, name=cname(3 * i + 4))\n                   .sg_conv(size=1, name=cname(3 * i + 5))\n                   .sg_pool(avg=True))\n\n    return out", "response": "Applies basic architecture of densenet layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all of the files in the given base directory optionally only including whose extension matches the ext string or list of strings.", "response": "def list_files(base_path, ext=None):\n    \"\"\"Lists all of the files in the given base directory, optionally only\n    including whose extension(s) match the ext string/list of strings.\n    This is non-recursive.\n\n    Args:\n        base_path: The directory in which to search.\n        ext: The extension(s) to match in the given directory. If None, this\n            matches all file extensions.\n\n    Returns:\n        A list of filenames relative to the given base path.\n    \"\"\"\n    if not os.path.isdir(base_path):\n        raise ValueError(\"Path does not exist: %s\" % base_path)\n\n    files = []\n    for entry in os.listdir(base_path):\n        if os.path.isfile(os.path.join(base_path, entry)):\n            _, entry_ext = os.path.splitext(entry)\n            entry_ext = entry_ext.lstrip('.')\n\n            if (ext is None) or \\\n                (isinstance(ext, str) and entry_ext == ext) or \\\n                (isinstance(ext, list) and entry_ext in ext):\n                files.append(entry)\n\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deep_merge_dict(a, b):\n    if not isinstance(a, dict):\n        raise TypeError(\"a must be a dict, but found %s\" % a.__class__.__name__)\n    if not isinstance(b, dict):\n        raise TypeError(\"b must be a dict, but found %s\" % b.__class__.__name__)\n\n    _a = copy(a)\n    _b = copy(b)\n\n    for key_b, val_b in iteritems(_b):\n        # if it's a sub-dictionary\n        if isinstance(val_b, dict):\n            if key_b not in _a or not isinstance(_a[key_b], dict):\n                _a[key_b] = {}\n\n            # perform the deep merge recursively\n            _a[key_b] = deep_merge_dict(_a[key_b], val_b)\n        else:\n            _a[key_b] = val_b\n\n    # b should now be deep-merged into a\n    return _a", "response": "Deep merges dictionary b into dictionary a."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy_tree(src_path, dest_path):\n    files_copied = 0\n    if os.path.isdir(src_path):\n        # if the destination folder doesn't exist, create it\n        if not os.path.isdir(dest_path):\n            os.makedirs(dest_path)\n\n        for entry in os.listdir(src_path):\n            src_entry_path = os.path.join(src_path, entry)\n            dest_entry_path = os.path.join(dest_path, entry)\n            # if it's a sub-folder\n            if os.path.isdir(src_entry_path):\n                # copy its contents recursively\n                files_copied += copy_tree(src_entry_path, dest_entry_path)\n            else:\n                copy_file_if_modified(src_entry_path, dest_entry_path)\n                files_copied += 1\n\n    return files_copied", "response": "Copies the entire folder tree from the given source pathto the given destination path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_url_file_ext(url):\n    # get the last part of the path component\n    filename = url.split('/')[-1]\n    name, ext = os.path.splitext(filename)\n\n    # handle case of files with leading dot\n    if not ext and name and name[0] == '.':\n        ext = name\n\n    return ext", "response": "Attempts to extract the file extension from the given URL."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_quickstart(project_path):\n    ensure_path_exists(project_path)\n    ensure_file_exists(os.path.join(project_path, \"config.yml\"), DEFAULT_CONFIG_CONTENT)\n    ensure_path_exists(os.path.join(project_path, 'models'))\n    ensure_path_exists(os.path.join(project_path, 'data'))\n    ensure_path_exists(os.path.join(project_path, 'themes'))\n    ensure_path_exists(os.path.join(project_path, 'templates'))\n    ensure_path_exists(os.path.join(project_path, 'templatetags'))\n    ensure_path_exists(os.path.join(project_path, 'views'))\n    ensure_path_exists(os.path.join(project_path, 'assets'))", "response": "Generates all of the basic paths for a Statik project within the given project path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_project_config_file(path, default_config_file_name):\n    _path, _config_file_path = None, None\n    path = os.path.abspath(path)\n\n    if os.path.isdir(path):\n        _path = path\n        # use the default config file\n        _config_file_path = os.path.join(_path, default_config_file_name)\n        logger.debug(\"Using default project configuration file path: %s\", _config_file_path)\n    elif path.endswith(\".yml\"):\n        _path = os.path.dirname(path)\n        _config_file_path = path\n        logger.debug(\"Using custom project configuration file path: %s\", _config_file_path)\n\n    return _path, _config_file_path", "response": "Attempts to extract the project config file s absolute path from the given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dict_strip(d):\n    _d = deepcopy(d)\n    for k, v in iteritems(d):\n        if isinstance(v, str):\n            _d[k] = v.strip()\n        elif isinstance(v, dict):\n            _d[k] = dict_strip(v)\n\n    return _d", "response": "Strips whitespace from the string values of the given dictionary ( recursively."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun through the given list of base paths and returns the first file with the given prefix and extension combination that actually exists. Returns None if no file was found.", "response": "def find_first_file_with_ext(base_paths, prefix, exts):\n    \"\"\"Runs through the given list of file extensions and returns the first file with the given base\n    path and extension combination that actually exists.\n\n    Args:\n        base_paths: The base paths in which to search for files.\n        prefix: The filename prefix of the file for which to search.\n        exts: An ordered list of file extensions for which to search.\n\n    Returns:\n        On success, a 2-tuple containing the base path in which the file was found, and the extension of the file.\n        On failure, returns (None, None).\n    \"\"\"\n    for base_path in base_paths:\n        for ext in exts:\n            filename = os.path.join(base_path, \"%s%s\" % (prefix, ext))\n            if os.path.exists(filename) and os.path.isfile(filename):\n                logger.debug(\"Found first file with relevant extension: %s\", filename)\n                return base_path, ext\n\n    logger.debug(\"No files found for prefix %s, extensions %s\", prefix, \", \".join(exts))\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns through the array and returns the elements that contain duplicate Taxonomy.", "response": "def find_duplicates_in_array(array):\n    \"\"\"Runs through the array and returns the elements that contain\n    more than one duplicate\n\n    Args:\n        array: The array to check for duplicates.\n\n    Returns:\n        Array of the elements that are duplicates. Returns empty list if\n        there are no duplicates.\n    \"\"\"\n    duplicates = []\n    non_duplicates = []\n\n    if len(array) != len(set(array)):\n        for item in array:\n            if item not in non_duplicates:\n                non_duplicates.append(item)\n            elif item in non_duplicates and item not in duplicates:\n                duplicates.append(item)\n\n    return duplicates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the error message optionally using the given context.", "response": "def render(self, context=None):\n        \"\"\"Renders the error message, optionally using the given context (which, if specified,\n        will override the internal context).\"\"\"\n        ctx = context.render() if context else self.get_error_context().render()\n        return \"%s: %s%s%s\" % (\n            self.get_error_kind(),\n            self.get_error_message(),\n            (\" (%s).\" % ctx) if ctx else \"\",\n            self.get_additional_error_detail()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_requirements(filename):\n    data = []\n    for line in read_file(filename):\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        if '+' in line[:4]:\n            repo_link, egg_name = line.split('#egg=')\n            if not egg_name:\n                raise ValueError('Unknown requirement: {0}'\n                                    .format(line))\n\n            DEPENDENCY_LINKS.append(line)\n\n            line = egg_name\n\n        data.append(line)\n\n    return data", "response": "Parse a requirements file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattempt to scan for additional relationships for this model based on all of the other models and relationships.", "response": "def find_additional_rels(self, all_models):\n        \"\"\"Attempts to scan for additional relationship fields for this model based on all of the other models'\n        structures and relationships.\n        \"\"\"\n        for model_name, model in iteritems(all_models):\n            if model_name != self.name:\n                for field_name in model.field_names:\n                    field = model.fields[field_name]\n                    # if this field type references the current model\n                    if field.field_type == self.name and field.back_populates is not None and \\\n                            (isinstance(field, StatikForeignKeyField) or isinstance(field, StatikManyToManyField)):\n                        self.additional_rels[field.back_populates] = {\n                            'to_model': model_name,\n                            'back_populates': field_name,\n                            'secondary': (model_name, field.field_type)\n                                if isinstance(field, StatikManyToManyField) else None\n                        }\n                        logger.debug(\n                            'Additional relationship %s.%s -> %s (%s)',\n                            self.name,\n                            field.back_populates,\n                            model_name,\n                            self.additional_rels[field.back_populates]\n                        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the in - memory SQLite database from the model configuration.", "response": "def create_db(self, models):\n        \"\"\"Creates the in-memory SQLite database from the model\n        configuration.\"\"\"\n        # first create the table definitions\n        self.tables = dict(\n            [\n                (model_name, self.create_model_table(model))\n                for model_name, model in iteritems(models)\n            ]\n        )\n        # now create the tables in memory\n        logger.debug(\"Creating %d database table(s)...\", len(self.tables))\n        try:\n            self.Base.metadata.create_all(self.engine)\n        except Exception as exc:\n            raise StatikError(\n                message=\"Failed to create in-memory data model.\",\n                orig_exc=exc\n            )\n        self.load_all_model_data(models)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sort_models(self):\n        model_names = [\n            table.name for table in self.Base.metadata.sorted_tables if table.name in self.models\n        ]\n        logger.debug(\"Unsorted models: %s\", model_names)\n        model_count = len(model_names)\n\n        swapped = True\n        sort_round = 0\n        while swapped:\n            sort_round += 1\n            logger.debug('Sorting round: %d (%s)', sort_round, model_names)\n\n            sorted_models = []\n            for i in range(model_count):\n                model = self.models[model_names[i]]\n                # check if this model has any dependencies which haven't been taken care of in this round\n                for foreign_model_name in model.foreign_models:\n                    if foreign_model_name not in sorted_models:\n                        sorted_models.append(foreign_model_name)\n\n                if model.name not in sorted_models:\n                    sorted_models.append(model.name)\n\n            # we're done here (no changes after this sorting round)\n            if model_names == sorted_models:\n                swapped = False\n\n            model_names = sorted_models\n\n        logger.debug(\"Sorted models: %s (%d rounds)\", model_names, sort_round)\n        return model_names", "response": "Sorts the database models appropriately based on their relationships so that we load our data\n            in the appropriate order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the table corresponding to the given model.", "response": "def create_model_table(self, model):\n        \"\"\"Creates the table for the given model.\n\n        Args:\n            model: A StatikModel instance.\n\n        Returns:\n            A SQLAlchemy model instance for the table corresponding to this\n            particular model.\n        \"\"\"\n        try:\n            return db_model_factory(self.Base, model, self.models)\n        except Exception as exc:\n            raise ModelError(\n                model.name,\n                message=\"failed to create in-memory table.\",\n                orig_exc=exc,\n                context=self.error_context\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the data for the specified model from the given path.", "response": "def load_model_data(self, path, model):\n        \"\"\"Loads the data for the specified model from the given path.\n        \"\"\"\n        if os.path.isdir(path):\n            # try find a model data collection\n            if os.path.isfile(os.path.join(path, '_all.yml')):\n                self.load_model_data_collection(path, model)\n            self.load_model_data_from_files(path, model)\n            self.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self, query, additional_locals=None, safe_mode=False):\n        logger.debug(\"Attempting to execute database query: %s\", query)\n\n        if safe_mode and not isinstance(query, dict):\n            raise SafetyViolationError(\n                context=self.error_context\n            )\n\n        if isinstance(query, dict):\n            logger.debug(\"Executing query in safe mode (MLAlchemy)\")\n            return mlalchemy.parse_query(query).to_sqlalchemy(self.session, self.tables).all()\n        else:\n            logger.debug(\"Executing unsafe query (Python exec())\")\n            if additional_locals is not None:\n                for k, v in iteritems(additional_locals):\n                    locals()[k] = v\n\n            exec(\n                compile(\n                    'result = %s' % query.strip(),\n                    '<string>',\n                    'exec'\n                ),\n                globals(),\n                locals()\n            )\n            return locals()['result']", "response": "Executes the given SQLAlchemy query string and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting the Statik site generator using the given parameters.", "response": "def generate(input_path, output_path=None, in_memory=False, safe_mode=False, error_context=None):\n    \"\"\"Executes the Statik site generator using the given parameters.\n    \"\"\"\n    project = StatikProject(input_path, safe_mode=safe_mode, error_context=error_context)\n    return project.generate(output_path=output_path, in_memory=in_memory)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(self, output_path=None, in_memory=False):\n        result = dict() if in_memory else 0\n        logger.info(\"Generating Statik build...\")\n        try:\n            if output_path is None and not in_memory:\n                raise InternalError(\n                    \"If project is not to be generated in-memory, an output path must be specified\"\n                )\n\n            self.error_context.update(filename=self.config_file_path)\n            self.config = self.config or StatikConfig(self.config_file_path)\n\n            if self.config.encoding is not None:\n                logger.debug(\"Using encoding: %s\", self.config.encoding)\n            else:\n                logger.debug(\"Using encoding: %s\", self.config.encoding)\n            self.error_context.clear()\n\n            self.models = self.load_models()\n            self.template_engine = StatikTemplateEngine(self)\n\n            if self.config.external_database is not None:\n                self.config.external_database.write_files(output_path, self.models)\n\n            self.views = self.load_views()\n            if not self.views:\n                raise NoViewsError()\n\n            self.db = self.load_db_data(self.models)\n            self.project_context = self.load_project_context()\n\n            in_memory_result = self.process_views()\n\n            if in_memory:\n                result = in_memory_result\n            else:\n                # dump the in-memory output to files\n                file_count = self.dump_in_memory_result(in_memory_result, output_path)\n                logger.info('Wrote %d output file(s) to folder: %s', file_count, output_path)\n                # copy any assets across, recursively\n                self.copy_assets(output_path)\n                result = file_count\n            \n            logger.info(\"Success!\")\n\n        except StatikError as exc:\n            logger.debug(traceback.format_exc())\n            logger.error(exc.render())\n            # re-raise the error to stop execution\n            raise exc\n        \n        except Exception as exc:\n            logger.debug(traceback.format_exc())\n            _exc = StatikError(\n                message=\"Failed to build project. Run Statik in verbose mode (-v) to see \" +\n                    \"additional traceback information about this error.\",\n                orig_exc=exc,\n                context=self.error_context\n            )\n            logger.error(_exc.render())\n            raise _exc\n\n        finally:\n            try:\n                # make sure to destroy the database engine (to provide for the possibility of\n                # database engine reloads when watching for changes)\n                if self.db is not None:\n                    self.db.shutdown()\n\n            except Exception as e:\n                logger.exception(\"Unable to clean up properly: %s\", e)\n\n        return result", "response": "Executes the Statik project generator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the views for this project from the project directory structure.", "response": "def load_views(self):\n        \"\"\"Loads the views for this project from the project directory\n        structure.\"\"\"\n        view_path = os.path.join(self.path, StatikProject.VIEWS_DIR)\n        logger.debug(\"Loading views from: %s\", view_path)\n        if not os.path.isdir(view_path):\n            raise MissingProjectFolderError(StatikProject.VIEWS_DIR)\n\n        view_files = list_files(view_path, ['yml', 'yaml'])\n        logger.debug(\"Found %d view(s) in project\", len(view_files))\n        views = {}\n        for view_file in view_files:\n            view_name = extract_filename(view_file)\n            views[view_name] = StatikView(\n                filename=os.path.join(view_path, view_file),\n                encoding=self.config.encoding,\n                name=view_name,\n                models=self.models,\n                template_engine=self.template_engine,\n                error_context=self.error_context\n            )\n\n        return views"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the project context from the database and models for common use amongst the project s views.", "response": "def load_project_context(self):\n        \"\"\"Loads the project context (static and dynamic) from the database/models for common use\n        amongst the project's views.\"\"\"\n        try:\n            # just make a copy of the project context\n            context = StatikContext(\n                initial={\n                    \"project_name\": self.config.project_name,\n                    \"base_path\": self.config.base_path\n                },\n                static=self.config.context_static,\n                dynamic=self.config.context_dynamic\n            )\n            logger.debug(\"Built project context: %s\", context)\n            return context.build(db=self.db, safe_mode=self.safe_mode)\n\n        except StatikError as exc:\n            raise exc\n        \n        except Exception as exc:\n            raise ProjectConfigurationError(\n                message=\"Failed to build context data from project configuration file.\",\n                orig_exc=exc\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the loaded views to generate the required output data.", "response": "def process_views(self):\n        \"\"\"Processes the loaded views to generate the required output data.\"\"\"\n        output = {}\n        logger.debug(\"Processing %d view(s)...\", len(self.views))\n        for view_name, view in iteritems(self.views):\n            try:\n                output = deep_merge_dict(\n                    output,\n                    view.process(\n                        self.db,\n                        safe_mode=self.safe_mode,\n                        extra_context=self.project_context\n                    )\n                )\n            except StatikError as exc:\n                # just re-raise it\n                raise exc\n\n            except Exception as exc:\n                # for unhandled view-related exceptions, raise our own exception\n                raise ViewError(\n                    message=\"Failed to render view \\\"%s\\\".\" % view_name,\n                    orig_exc=exc\n                )\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy all assets from the source path to the destination path.", "response": "def copy_assets(self, output_path):\n        \"\"\"Copies all asset files from the source path to the destination\n        path. If no such source path exists, no asset copying will be performed.\n        \"\"\"\n        src_paths = []\n\n        # if we have a theme\n        if self.config.theme is not None:\n            # assume it's in the folder: \"themes/theme_name/assets\"\n            src_paths.append(os.path.join(\n                self.path,\n                StatikProject.THEMES_DIR,\n                self.config.theme,\n                StatikProject.ASSETS_DIR\n            ))\n            # NOTE: Adding the theme's assets directory *before* the project's internal assets\n            #       directory always ensures that the project's own assets are copied *after* the\n            #       theme's, thereby ensuring that the project's assets folder takes precedence\n            #       over the theme's.\n\n        # always attempt to copy from our base assets folder\n        if os.path.isabs(self.config.assets_src_path):\n            src_paths.append(self.config.assets_src_path)\n        else:\n            src_paths.append(os.path.join(self.path, self.config.assets_src_path))\n\n        for src_path in src_paths:\n            if os.path.exists(src_path) and os.path.isdir(src_path):\n                dest_path = self.config.assets_dest_path\n                if not os.path.isabs(dest_path):\n                    dest_path = os.path.join(output_path, dest_path)\n\n                asset_count = copy_tree(src_path, dest_path)\n                logger.info(\"Copied %s asset(s) from %s to %s\", asset_count, src_path, dest_path)\n            else:\n                logger.info(\n                    \"Missing assets source path - skipping copying of assets: %s\",\n                    src_path\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate remote path including parent directories if needed", "response": "def mkdir_p(sftp, path):\n    \"\"\"Create remote path including parent directories if needed\n    https://stackoverflow.com/a/14819803\n    \"\"\"\n    try:\n        sftp.chdir(path)\n    except IOError:\n        dirname, basename = os.path.split(path.rstrip('/'))\n        mkdir_p(sftp, dirname)\n        sftp.mkdir(basename)\n        sftp.chdir(basename)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef echo_arguments(*args, **kwargs):\n    args_string = ', '.join(map(lambda x: str(x), args))\n    kwargs_string = ', '.join(map(lambda k, v: \"%s=%s\" % (k, v), iteritems(kwargs)))\n    string_lst = filter(lambda x: bool(x), [args_string, kwargs_string])\n    return \"ditto(%s)\" % \", \".join(string_lst)", "response": "Echoes all parameters back as text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autogen(project_path):\n    generate_quickstart(project_path)\n\n    project = StatikProject(project_path)\n    project.config = StatikConfig(project.config_file_path)\n\n    models = list(project.load_models().values())\n\n    logger.info('Creating view and template for home page (index.html).')\n    generate_yaml_file(os.path.join(project_path, StatikProject.VIEWS_DIR, 'index.yaml'),\n                        {   \n                            'path': '/',\n                            'template': 'index'\n                        }\n    )\n    generate_index_file(os.path.join(project_path, StatikProject.TEMPLATES_DIR, 'index.jinja2'))\n\n    for model in models:\n        logger.info('Creating view and template for model: %s' % model.name)\n        generate_yaml_file(os.path.join(project_path, StatikProject.VIEWS_DIR, '%s.yaml' % model.name),\n                            {   \n                                'path': {\n                                    'template': '/%s/{{ %s.pk }}' % (model.name, model.name),\n                                    'for-each': {\n                                        '%s' % model.name: 'session.query(%s).all()' % model.name\n                                    }\n                                },\n                                'template': ('%s' % model.name),\n                            }\n        )\n        generate_model_file(os.path.join(project_path, StatikProject.TEMPLATES_DIR, '%s.jinja2' % model.name),\n                            project,\n                            model,\n                            model.fields.values())", "response": "Autogenerates views and templates for all the models in the project."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_yaml_file(filename, contents):\n    with open(filename, 'w') as file:\n        file.write(yaml.dump(contents, default_flow_style=False))", "response": "Creates a yaml file with the given content."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_index_file(filename):\n    with open(filename, 'w') as file:\n        content = open(os.path.join(os.path.dirname(__file__), 'templates/index_page.html'), 'r').read()\n        file.write(content)", "response": "Constructs a default home page for the project."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_model_file(filename, project, model, fields):\n    for field in fields:\n        field.type = field.__class__.__name__\n\n    content = open(os.path.join(os.path.dirname(__file__), 'templates/model_page.html'), 'r').read()\n\n    engine = StatikTemplateEngine(project)\n    template = engine.create_template(content)\n\n    # create context and update from project.config\n    context = {'model': model,\n                'fields': fields}\n    context.update(dict(project.config.context_static))\n    string = template.render(context)\n\n    with open(filename, 'w') as file:\n        file.write(string)", "response": "Generates a model file for a given instance of a model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the dynamic context based on our current dynamic context entity and the given database.", "response": "def build_dynamic(self, db, extra=None, safe_mode=False):\n        \"\"\"Builds the dynamic context based on our current dynamic context entity and the given\n        database.\"\"\"\n        result = dict()\n        for var, query in iteritems(self.dynamic):\n            result[var] = db.query(query, safe_mode=safe_mode, additional_locals=extra)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_for_each(self, db, safe_mode=False, extra=None):\n        result = dict()\n        for var, query in iteritems(self.for_each):\n            result[var] = db.query(\n                query,\n                additional_locals=extra,\n                safe_mode=safe_mode\n            )\n        return result", "response": "Builds the for - each context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build(self, db=None, safe_mode=False, for_each_inst=None, extra=None):\n        result = copy(self.initial)\n        result.update(self.static)\n        if self.dynamic:\n            result.update(self.build_dynamic(db, extra=extra, safe_mode=safe_mode))\n        if self.for_each and for_each_inst:\n            result.update(self.build_for_each(db, safe_mode=safe_mode, extra=extra))\n        if isinstance(extra, dict):\n            result.update(extra)\n        return result", "response": "Builds a dictionary that can be used as context for template rendering."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls the given function and converts any template - related errors to a Statik TemplateError instance. Returns the result returned by the function itself.", "response": "def template_exception_handler(fn, error_context, filename=None):\n    \"\"\"Calls the given function, attempting to catch any template-related errors, and\n    converts the error to a Statik TemplateError instance. Returns the result returned\n    by the function itself.\"\"\"\n    error_message = None\n    if filename:\n        error_context.update(filename=filename)\n    try:\n        return fn()\n    except jinja2.TemplateSyntaxError as exc:\n        error_context.update(filename=exc.filename, line_no=exc.lineno)\n        error_message = exc.message\n    except jinja2.TemplateError as exc:\n        error_message = exc.message\n    except Exception as exc:\n        error_message = \"%s\" % exc\n\n    raise TemplateError(message=error_message, context=error_context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the provider with the given name.", "response": "def get_provider(self, name):\n        \"\"\"Allows for lazy instantiation of providers (Jinja2 templating is heavy, so only instantiate it if\n        necessary).\"\"\"\n        if name not in self.providers:\n            cls = self.provider_classes[name]\n            # instantiate the provider\n            self.providers[name] = cls(self)\n        return self.providers[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_template(self, name):\n        # hopefully speeds up loading of templates a little, especially when loaded multiple times\n        if name in self.cached_templates:\n            logger.debug(\"Using cached template: %s\", name)\n            return self.cached_templates[name]\n\n        logger.debug(\"Attempting to find template by name: %s\", name)\n        name_with_ext, provider_name, base_path = self.find_template_details(name)\n\n        full_path = None\n        if base_path is not None:\n            full_path = os.path.join(base_path, name_with_ext)\n\n        # load it with the relevant provider\n        template = template_exception_handler(\n            lambda: self.get_provider(provider_name).load_template(\n                name_with_ext,\n                full_path=full_path\n            ),\n            self.error_context,\n            filename=full_path\n        )\n\n        # cache it for potential later use\n        self.cached_templates[name] = template\n        return template", "response": "Attempts to load the relevant template from our templating system and environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_template(self, s, provider_name=None):\n        if provider_name is None:\n            provider_name = self.supported_providers[0]\n        return template_exception_handler(\n            lambda: self.get_provider(provider_name).create_template(s),\n            self.error_context\n        )", "response": "Creates a template from the given string based on the specified provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_field(model_name, field_name, field_type, all_models, **kwargs):\n    field_type_parts = field_type.split('->')\n    _field_type = field_type_parts[0].strip().split('[]')[0].strip()\n    back_populates = field_type_parts[1].strip() if len(field_type_parts) > 1 else None\n    error_context = kwargs.pop('error_context', StatikErrorContext())\n    _kwargs = copy(kwargs)\n    _kwargs['back_populates'] = back_populates\n\n    if _field_type not in FIELD_TYPES and _field_type not in all_models:\n        raise InvalidFieldTypeError(\n            model_name,\n            field_name,\n            context=error_context\n        )\n\n    if _field_type in FIELD_TYPES:\n        return FIELD_TYPES[_field_type](field_name, **_kwargs)\n\n    if field_type_parts[0].strip().endswith('[]'):\n        return StatikManyToManyField(field_name, _field_type, **_kwargs)\n\n    return StatikForeignKeyField(field_name, _field_type, **_kwargs)", "response": "Helper function to construct a Statik Field object from the given field name and field type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwatches the given project path for filesystem changes and automatically rebuilds the project when they change.", "response": "def watch(project_path, output_path, host='0.0.0.0', port=8000, min_reload_time=2.0,\n          open_browser=True, safe_mode=False, error_context=None):\n    \"\"\"Watches the given project path for filesystem changes, and automatically rebuilds the project when\n    changes are detected. Also serves an HTTP server on the given host/port.\n\n    Args:\n        project_path: The path to the Statik project to be watched.\n        output_path: The path into which to write the output files.\n        host: The host IP/hostname to which to bind when serving output files.\n        port: The port to which to bind when serving output files.\n        min_reload_time: The minimum time (in seconds) between reloads when files change.\n        open_browser: Whether or not to automatically open the web browser at the served URL.\n        safe_mode: Whether or not to run Statik in safe mode.\n        error_context: An optional StatikErrorContext instance for detailed error reporting.\n    \"\"\"\n    error_context = error_context or StatikErrorContext()\n    project = StatikProject(project_path, safe_mode=safe_mode, error_context=error_context)\n    project.generate(output_path=output_path, in_memory=False)\n\n    watch_folders = [\n        StatikProject.MODELS_DIR,\n        StatikProject.DATA_DIR,\n        StatikProject.VIEWS_DIR,\n        StatikProject.TEMPLATES_DIR,\n        project.config.assets_src_path\n    ]\n\n    # let the template tags folder be optional\n    template_tags_folder = os.path.join(project.path, StatikProject.TEMPLATETAGS_DIR)\n    if os.path.exists(template_tags_folder) and os.path.isdir(template_tags_folder):\n        watch_folders.append(StatikProject.TEMPLATETAGS_DIR)\n\n    # if theming is enabled, watch the specific theme's folder for changes\n    if project.config.theme is not None:\n        watch_folders.append(os.path.join(StatikProject.THEMES_DIR, project.config.theme))\n\n    watch_folders = [f if os.path.isabs(f) else os.path.join(project.path, f) for f in watch_folders]\n    for folder in watch_folders:\n        if not os.path.exists(folder) or not os.path.isdir(folder):\n            raise MissingProjectFolderError(folder)\n\n    httpwatcher.watch(\n        output_path,\n        watch_paths=watch_folders,\n        on_reload=lambda: safe_wrap_project_generate(\n            project,\n            output_path\n        ),\n        host=host,\n        port=port,\n        server_base_path=project.config.base_path,\n        watcher_interval=min_reload_time,\n        recursive=True,\n        open_browser=open_browser\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paginate(db_query, items_per_page, offset=0, start_page=1):\n    return Paginator(db_query, items_per_page, offset=offset, start_page=start_page)", "response": "Instantiates a Paginator instance for database queries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the reverse URL for this path.", "response": "def render_reverse(self, inst=None, context=None):\n        \"\"\"Renders the reverse URL for this path.\"\"\"\n        rendered = self.render(inst=inst, context=context)\n        parts = rendered.split('/')\n        # we only prettify URLs for these files\n        if parts[-1] in ['index.html', 'index.htm']:\n            return ('/'.join(parts[:-1])) + '/'\n        return rendered"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(\n            cls,\n            path,\n            template_engine=None,\n            output_filename=None,\n            output_ext=None,\n            view_name=None\n        ):\n        \"\"\"Create the relevant subclass of StatikView based on the given path variable and\n        parameters.\"\"\"\n        # if it's a complex view\n        if isinstance(path, dict):\n            return StatikViewComplexPath(\n                path,\n                template_engine,\n                output_filename=output_filename,\n                output_ext=output_ext,\n                view_name=view_name\n            )\n        elif isinstance(path, basestring):\n            return StatikViewSimplePath(\n                path,\n                output_filename=output_filename,\n                output_ext=output_ext,\n                view_name=view_name\n            )\n        else:\n            raise ValueError(\n                \"Unrecognised structure for \\\"path\\\" configuration in view: %s\" % view_name\n            )", "response": "Create a StatikView based on the given path variable and parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, context, db=None, safe_mode=False, extra_context=None):\n        if not db:\n            raise MissingParameterError(\n                \"db\",\n                context=self.error_context\n            )\n        rendered_views = dict()\n        path_instances = db.query(self.path.query, safe_mode=safe_mode)\n        extra_ctx = copy(extra_context) if extra_context else dict()\n\n        for inst in path_instances:\n            extra_ctx.update({\n                self.path.variable: inst\n            })\n            ctx = context.build(\n                db=db,\n                safe_mode=safe_mode,\n                for_each_inst=inst,\n                extra=extra_ctx\n            )\n            inst_path = self.path.render(inst=inst, context=ctx)\n            rendered_view = self.template.render(ctx)\n            rendered_views = deep_merge_dict(\n                rendered_views,\n                dict_from_path(inst_path, final_value=rendered_view)\n            )\n        return rendered_views", "response": "Renders the given context using the specified database returning a dictionary containing path segments and rendered view contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(self, db, safe_mode=False, extra_context=None):\n        return self.renderer.render(\n            self.context,\n            db,\n            safe_mode=safe_mode,\n            extra_context=extra_context\n        )", "response": "Renders this view given the specified StatikDatabase instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup(self):\n\n        self.log.debug(\"Cleaning up %s temporary directory\" % self.tmp_dir)\n        shutil.rmtree(self.tmp_dir, ignore_errors=True)", "response": "Cleanup the temporary directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_number_of_layers(self, number_of_layers):\n\n        # Only positive numbers are correct\n        if number_of_layers <= 0:\n            raise SquashError(\n                \"Number of layers to squash cannot be less or equal 0, provided: %s\" % number_of_layers)\n\n        # Do not squash if provided number of layer to squash is bigger\n        # than number of actual layers in the image\n        if number_of_layers > len(self.old_image_layers):\n            raise SquashError(\n                \"Cannot squash %s layers, the %s image contains only %s layers\" % (number_of_layers, self.image, len(self.old_image_layers)))", "response": "Validates that the number of layers to squash is a valid number of layers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _files_in_layers(self, layers, directory):\n        files = {}\n\n        for layer in layers:\n            self.log.debug(\"Generating list of files in layer '%s'...\" % layer)\n            tar_file = os.path.join(directory, layer, \"layer.tar\")\n            with tarfile.open(tar_file, 'r', format=tarfile.PAX_FORMAT) as tar:\n                files[layer] = [self._normalize_path(\n                    x) for x in tar.getnames()]\n            self.log.debug(\"Done, found %s files\" % len(files[layer]))\n\n        return files", "response": "Prepare a list of files in all layers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_tmp_directory(self, tmp_dir):\n\n        if tmp_dir:\n            if os.path.exists(tmp_dir):\n                raise SquashError(\n                    \"The '%s' directory already exists, please remove it before you proceed\" % tmp_dir)\n            os.makedirs(tmp_dir)\n        else:\n            tmp_dir = tempfile.mkdtemp(prefix=\"docker-squash-\")\n\n        self.log.debug(\"Using %s as the temporary directory\" % tmp_dir)\n\n        return tmp_dir", "response": "Creates a temporary directory that is used to work on layers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _layers_to_squash(self, layers, from_layer):\n        to_squash = []\n        to_leave = []\n        should_squash = True\n\n        for l in reversed(layers):\n            if l == from_layer:\n                should_squash = False\n\n            if should_squash:\n                to_squash.append(l)\n            else:\n                to_leave.append(l)\n\n        to_squash.reverse()\n        to_leave.reverse()\n\n        return to_squash, to_leave", "response": "Returns a list of layer IDs that should be squashed from a given layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the image to a tar archive under specified name", "response": "def _save_image(self, image_id, directory):\n        \"\"\" Saves the image as a tar archive under specified name \"\"\"\n\n        for x in [0, 1, 2]:\n            self.log.info(\"Saving image %s to %s directory...\" %\n                          (image_id, directory))\n            self.log.debug(\"Try #%s...\" % (x + 1))\n\n            try:\n                image = self.docker.get_image(image_id)\n\n                if docker.version_info[0] < 3:\n                    # Docker library prior to 3.0.0 returned the requests\n                    # object directly which cold be used to read from\n                    self.log.debug(\"Extracting image using HTTPResponse object directly\")\n                    self._extract_tar(image, directory)\n                else:\n                    # Docker library >=3.0.0 returns iterator over raw data\n                    self.log.debug(\"Extracting image using iterator over raw data\")\n\n                    fd_r, fd_w = os.pipe()\n\n                    r = os.fdopen(fd_r, 'rb')\n                    w = os.fdopen(fd_w, 'wb')\n\n                    extracter = threading.Thread(target=self._extract_tar, args=(r,directory))\n                    extracter.start()\n\n                    for chunk in image:\n                        w.write(chunk)\n\n                    w.flush()\n                    w.close()\n\n                    extracter.join()\n                    r.close()\n                self.log.info(\"Image saved!\")\n                return True\n            except Exception as e:\n                self.log.exception(e)\n                self.log.warn(\n                    \"An error occured while saving the %s image, retrying...\" % image_id)\n\n        raise SquashError(\"Couldn't save %s image!\" % image_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _unpack(self, tar_file, directory):\n\n        self.log.info(\"Unpacking %s tar file to %s directory\" %\n                      (tar_file, directory))\n\n        with tarfile.open(tar_file, 'r') as tar:\n            tar.extractall(path=directory)\n\n        self.log.info(\"Archive unpacked!\")", "response": "Unpacks a tar file to a directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_layers(self, layers, image_id):\n\n        for layer in self.docker.history(image_id):\n            layers.append(layer['Id'])", "response": "Reads the JSON metadata for the specified layer and image id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the provided image name and returns the name and tag part of the image name.", "response": "def _parse_image_name(self, image):\n        \"\"\"\n        Parses the provided image name and splits it in the\n        name and tag part, if possible. If no tag is provided\n        'latest' is used.\n        \"\"\"\n        if ':' in image and '/' not in image.split(':')[-1]:\n            image_tag = image.split(':')[-1]\n            image_name = image[:-(len(image_tag) + 1)]\n        else:\n            image_tag = \"latest\"\n            image_name = image\n\n        return (image_name, image_tag)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _dump_json(self, data, new_line=False):\n\n        # We do not want any spaces between keys and values in JSON\n        json_data = json.dumps(data, separators=(',', ':'))\n\n        if new_line:\n            json_data = \"%s\\n\" % json_data\n\n        # Generate sha256sum of the JSON data, may be handy\n        sha = hashlib.sha256(json_data.encode('utf-8')).hexdigest()\n\n        return json_data, sha", "response": "Helper function to marshal object into JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _move_layers(self, layers, src, dest):\n        for layer in layers:\n            layer_id = layer.replace('sha256:', '')\n\n            self.log.debug(\"Moving unmodified layer '%s'...\" % layer_id)\n            shutil.move(os.path.join(src, layer_id), dest)", "response": "Move all the layers from src to dest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _marker_files(self, tar, members):\n        marker_files = {}\n\n        self.log.debug(\n            \"Searching for marker files in '%s' archive...\" % tar.name)\n\n        for member in members:\n            if '.wh.' in member.name:\n                self.log.debug(\"Found '%s' marker file\" % member.name)\n                marker_files[member] = tar.extractfile(member)\n\n        self.log.debug(\"Done, found %s files\" % len(marker_files))\n\n        return marker_files", "response": "Searches for marker files in the specified archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _proc_pax(self, filetar):\n    # Read the header information.\n    buf = filetar.fileobj.read(self._block(self.size))\n\n    # A pax header stores supplemental information for either\n    # the following file (extended) or all following files\n    # (global).\n    if self.type == tarfile.XGLTYPE:\n        pax_headers = filetar.pax_headers\n    else:\n        pax_headers = filetar.pax_headers.copy()\n\n    # Parse pax header information. A record looks like that:\n    # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n    # of the complete record including the length field itself and\n    # the newline. keyword and value are both UTF-8 encoded strings.\n    regex = re.compile(r\"(\\d+) ([^=]+)=\", re.U)\n    pos = 0\n    while True:\n        match = regex.match(buf, pos)\n        if not match:\n            break\n\n        length, keyword = match.groups()\n        length = int(length)\n        value = buf[match.end(2) + 1:match.start(1) + length - 1]\n\n        try:\n            keyword = keyword.decode(\"utf8\")\n        except Exception:\n            pass\n\n        try:\n            value = value.decode(\"utf8\")\n        except Exception:\n            pass\n\n        pax_headers[keyword] = value\n        pos += length\n\n    # Fetch the next header.\n    try:\n        next = self.fromtarfile(filetar)\n    except tarfile.HeaderError:\n        raise tarfile.SubsequentHeaderError(\"missing or bad subsequent header\")\n\n    if self.type in (tarfile.XHDTYPE, tarfile.SOLARIS_XHDTYPE):\n        # Patch the TarInfo object with the extended header info.\n        next._apply_pax_info(pax_headers, filetar.encoding, filetar.errors)\n        next.offset = self.offset\n\n        if \"size\" in pax_headers:\n            # If the extended header replaces the size field,\n            # we need to recalculate the offset where the next\n            # header starts.\n            offset = next.offset_data\n            if next.isreg() or next.type not in tarfile.SUPPORTED_TYPES:\n                offset += next._block(next.size)\n            filetar.offset = offset\n\n    return next", "response": "Process an extended or global header as described in POSIX. 1 - 2001."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a POSIX. 1 - 2001 extended or global header sequence that contains a list of keyword value pairs. The values must be unicode objects.", "response": "def _create_pax_generic_header(cls, pax_headers, type=tarfile.XHDTYPE):\n    \"\"\"Return a POSIX.1-2001 extended or global header sequence\n       that contains a list of keyword, value pairs. The values\n       must be unicode objects.\n    \"\"\"\n    records = []\n    for keyword, value in pax_headers.iteritems():\n\n        try:\n            keyword = keyword.encode(\"utf8\")\n        except Exception:\n            pass\n\n        try:\n            value = value.encode(\"utf8\")\n        except Exception:\n            pass\n\n        l = len(keyword) + len(value) + 3   # ' ' + '=' + '\\n'\n        n = p = 0\n        while True:\n            n = l + len(str(p))\n            if n == p:\n                break\n            p = n\n        records.append(\"%d %s=%s\\n\" % (p, keyword, value))\n    records = \"\".join(records)\n\n    # We use a hardcoded \"././@PaxHeader\" name like star does\n    # instead of the one that POSIX recommends.\n    info = {}\n    info[\"name\"] = \"././@PaxHeader\"\n    info[\"type\"] = type\n    info[\"size\"] = len(records)\n    info[\"magic\"] = tarfile.POSIX_MAGIC\n\n    # Create pax header + record blocks.\n    return cls._create_header(info, tarfile.USTAR_FORMAT) + \\\n        cls._create_payload(records)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the JSON file and return as OrderedDict", "response": "def _read_json_file(self, json_file):\n        \"\"\" Helper function to read JSON file as OrderedDict \"\"\"\n\n        self.log.debug(\"Reading '%s' JSON file...\" % json_file)\n\n        with open(json_file, 'r') as f:\n            return json.load(f, object_pairs_hook=OrderedDict)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_layer_paths(self, old_image_config, old_image_manifest, layers_to_move):\n\n        # In manifest.json we do not have listed all layers\n        # but only layers that do contain some data.\n        current_manifest_layer = 0\n\n        layer_paths_to_move = []\n        layer_paths_to_squash = []\n\n        # Iterate over image history, from base image to top layer\n        for i, layer in enumerate(old_image_config['history']):\n\n            # If it's not an empty layer get the id\n            # (directory name) where the layer's data is\n            # stored\n            if not layer.get('empty_layer', False):\n                layer_id = old_image_manifest['Layers'][\n                    current_manifest_layer].rsplit('/')[0]\n\n                # Check if this layer should be moved or squashed\n                if len(layers_to_move) > i:\n                    layer_paths_to_move.append(layer_id)\n                else:\n                    layer_paths_to_squash.append(layer_id)\n\n                current_manifest_layer += 1\n\n        return layer_paths_to_squash, layer_paths_to_move", "response": "Read the paths to move or squash layers from the old image manifest."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the id used to name the directory to store the squashed layer content in the archive.", "response": "def _generate_squashed_layer_path_id(self):\n        \"\"\"\n        This function generates the id used to name the directory to\n        store the squashed layer content in the archive.\n\n        This mimics what Docker does here: https://github.com/docker/docker/blob/v1.10.0-rc1/image/v1/imagev1.go#L42\n        To make it simpler we do reuse old image metadata and\n        modify it to what it should look which means to be exact\n        as https://github.com/docker/docker/blob/v1.10.0-rc1/image/v1/imagev1.go#L64\n        \"\"\"\n\n        # Using OrderedDict, because order of JSON elements is important\n        v1_metadata = OrderedDict(self.old_image_config)\n\n        # Update image creation date\n        v1_metadata['created'] = self.date\n\n        # Remove unnecessary elements\n        # Do not fail if key is not found\n        for key in 'history', 'rootfs', 'container':\n            v1_metadata.pop(key, None)\n\n        # Docker internally changes the order of keys between\n        # exported metadata (why oh why?!). We need to add 'os'\n        # element after 'layer_id'\n        operating_system = v1_metadata.pop('os', None)\n\n        # The 'layer_id' element is the chain_id of the\n        # squashed layer\n        v1_metadata['layer_id'] = \"sha256:%s\" % self.chain_ids[-1]\n\n        # Add back 'os' element\n        if operating_system:\n            v1_metadata['os'] = operating_system\n\n        # The 'parent' element is the name of the directory (inside the\n        # exported tar archive) of the last layer that we move\n        # (layer below squashed layer)\n\n        if self.layer_paths_to_move:\n            if self.layer_paths_to_squash:\n                parent = self.layer_paths_to_move[-1]\n            else:\n                parent = self.layer_paths_to_move[0]\n\n            v1_metadata['parent'] = \"sha256:%s\" % parent\n\n        # The 'Image' element is the id of the layer from which we squash\n        if self.squash_id:\n            # Update image id, should be one layer below squashed layer\n            v1_metadata['config']['Image'] = self.squash_id\n        else:\n            v1_metadata['config']['Image'] = \"\"\n\n        # Get the sha256sum of the JSON exported metadata,\n        # we do not care about the metadata anymore\n        sha = self._dump_json(v1_metadata)[1]\n\n        return sha"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the local file to the desired path.", "response": "def write_local_file(self, outputfile, path):\n        \"\"\"Write file to the desired path.\"\"\"\n        self.logger.info(\"Writing file to %s\", path)\n        outputfile.seek(0)\n        with open(path, 'wb') as fd:\n            copyfileobj(outputfile, fd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves a new backup file.", "response": "def _save_new_backup(self, database):\n        \"\"\"\n        Save a new backup file.\n        \"\"\"\n        self.logger.info(\"Backing Up Database: %s\", database['NAME'])\n        # Get backup and name\n        filename = self.connector.generate_filename(self.servername)\n        outputfile = self.connector.create_dump()\n        # Apply trans\n        if self.compress:\n            compressed_file, filename = utils.compress_file(outputfile, filename)\n            outputfile = compressed_file\n        if self.encrypt:\n            encrypted_file, filename = utils.encrypt_file(outputfile, filename)\n            outputfile = encrypted_file\n        # Set file name\n        filename = self.filename if self.filename else filename\n        self.logger.debug(\"Backup size: %s\", utils.handle_size(outputfile))\n        # Store backup\n        outputfile.seek(0)\n        if self.path is None:\n            self.write_to_storage(outputfile, filename)\n        else:\n            self.write_local_file(outputfile, self.path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _explore_storage(self):\n        path = ''\n        dirs = [path]\n        while dirs:\n            path = dirs.pop()\n            subdirs, files = self.media_storage.listdir(path)\n            for media_filename in files:\n                yield os.path.join(path, media_filename)\n            dirs.extend([os.path.join(path, subdir) for subdir in subdirs])", "response": "Generator of all files contained in media storage."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_tar(self, name):\n        fileobj = utils.create_spooled_temporary_file()\n        mode = 'w:gz' if self.compress else 'w'\n        tar_file = tarfile.open(name=name, fileobj=fileobj, mode=mode)\n        for media_filename in self._explore_storage():\n            tarinfo = tarfile.TarInfo(media_filename)\n            media_file = self.media_storage.open(media_filename)\n            tarinfo.size = len(media_file)\n            tar_file.addfile(tarinfo, media_file)\n        # Close the TAR for writing\n        tar_file.close()\n        return fileobj", "response": "Create a TAR file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate backup file and write it to storage.", "response": "def backup_mediafiles(self):\n        \"\"\"\n        Create backup file and write it to storage.\n        \"\"\"\n        # Create file name\n        extension = \"tar%s\" % ('.gz' if self.compress else '')\n        filename = utils.filename_generate(extension,\n                                           servername=self.servername,\n                                           content_type=self.content_type)\n        tarball = self._create_tar(filename)\n        # Apply trans\n        if self.encrypt:\n            encrypted_file = utils.encrypt_file(tarball, filename)\n            tarball, filename = encrypted_file\n\n        self.logger.debug(\"Backup size: %s\", utils.handle_size(tarball))\n        # Store backup\n        tarball.seek(0)\n        if self.path is None:\n            self.write_to_storage(tarball, filename)\n        else:\n            self.write_local_file(tarball, self.path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a byte value to a human readable string.", "response": "def bytes_to_str(byteVal, decimals=1):\n    \"\"\"\n    Convert bytes to a human readable string.\n\n    :param byteVal: Value to convert in bytes\n    :type byteVal: int or float\n\n    :param decimal: Number of decimal to display\n    :type decimal: int\n\n    :returns: Number of byte with the best unit of measure\n    :rtype: str\n    \"\"\"\n    for unit, byte in BYTES:\n        if (byteVal >= byte):\n            if decimals == 0:\n                return '%s %s' % (int(round(byteVal / byte, 0)), unit)\n            return '%s %s' % (round(byteVal / byte, decimals), unit)\n    return '%s B' % byteVal"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to the admins defined by the DBBACKUP_ADMINS setting.", "response": "def mail_admins(subject, message, fail_silently=False, connection=None,\n                html_message=None):\n    \"\"\"Sends a message to the admins, as defined by the DBBACKUP_ADMINS setting.\"\"\"\n    if not settings.ADMINS:\n        return\n    mail = EmailMultiAlternatives('%s%s' % (settings.EMAIL_SUBJECT_PREFIX, subject),\n                                  message, settings.SERVER_EMAIL, [a[1] for a in settings.ADMINS],\n                                  connection=connection)\n    if html_message:\n        mail.attach_alternative(html_message, 'text/html')\n    mail.send(fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions decorator for sending uncaught exceptions to admins.", "response": "def email_uncaught_exception(func):\n    \"\"\"\n    Function decorator for send email with uncaught exceptions to admins.\n    Email is sent to ``settings.DBBACKUP_FAILURE_RECIPIENTS``\n    (``settings.ADMINS`` if not defined). The message contains a traceback\n    of error.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            func(*args, **kwargs)\n        except:\n            logger = logging.getLogger('dbbackup')\n            exc_type, exc_value, tb = sys.exc_info()\n            tb_str = ''.join(traceback.format_tb(tb))\n            msg = '%s: %s\\n%s' % (exc_type.__name__, exc_value, tb_str)\n            logger.error(msg)\n            raise\n        finally:\n            connection.close()\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_spooled_temporary_file(filepath=None, fileobj=None):\n    spooled_file = tempfile.SpooledTemporaryFile(\n        max_size=settings.TMP_FILE_MAX_SIZE,\n        dir=settings.TMP_DIR)\n    if filepath:\n        fileobj = open(filepath, 'r+b')\n    if fileobj is not None:\n        fileobj.seek(0)\n        copyfileobj(fileobj, spooled_file, settings.TMP_FILE_READ_SIZE)\n    return spooled_file", "response": "Create a spooled temporary file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencrypt input file using GPG and remove. GPG extension to its name.", "response": "def encrypt_file(inputfile, filename):\n    \"\"\"\n    Encrypt input file using GPG and remove .gpg extension to its name.\n\n    :param inputfile: File to encrypt\n    :type inputfile: ``file`` like object\n\n    :param filename: File's name\n    :type filename: ``str``\n\n    :returns: Tuple with file and new file's name\n    :rtype: :class:`tempfile.SpooledTemporaryFile`, ``str``\n    \"\"\"\n    import gnupg\n    tempdir = tempfile.mkdtemp(dir=settings.TMP_DIR)\n    try:\n        filename = '%s.gpg' % filename\n        filepath = os.path.join(tempdir, filename)\n        try:\n            inputfile.seek(0)\n            always_trust = settings.GPG_ALWAYS_TRUST\n            g = gnupg.GPG()\n            result = g.encrypt_file(inputfile, output=filepath,\n                                    recipients=settings.GPG_RECIPIENT,\n                                    always_trust=always_trust)\n            inputfile.close()\n            if not result:\n                msg = 'Encryption failed; status: %s' % result.status\n                raise EncryptionError(msg)\n            return create_spooled_temporary_file(filepath), filename\n        finally:\n            if os.path.exists(filepath):\n                os.remove(filepath)\n    finally:\n        os.rmdir(tempdir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncompressing input file using gzip and change its name.", "response": "def compress_file(inputfile, filename):\n    \"\"\"\n    Compress input file using gzip and change its name.\n\n    :param inputfile: File to compress\n    :type inputfile: ``file`` like object\n\n    :param filename: File's name\n    :type filename: ``str``\n\n    :returns: Tuple with compressed file and new file's name\n    :rtype: :class:`tempfile.SpooledTemporaryFile`, ``str``\n    \"\"\"\n    outputfile = create_spooled_temporary_file()\n    new_filename = filename + '.gz'\n    zipfile = gzip.GzipFile(filename=filename, fileobj=outputfile, mode=\"wb\")\n    try:\n        inputfile.seek(0)\n        copyfileobj(inputfile, zipfile, settings.TMP_FILE_READ_SIZE)\n    finally:\n        zipfile.close()\n    return outputfile, new_filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uncompress_file(inputfile, filename):\n    zipfile = gzip.GzipFile(fileobj=inputfile, mode=\"rb\")\n    try:\n        outputfile = create_spooled_temporary_file(fileobj=zipfile)\n    finally:\n        zipfile.close()\n    new_basename = os.path.basename(filename).replace('.gz', '')\n    return outputfile, new_basename", "response": "Uncompress this file using gzip and change its name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef timestamp(value):\n    value = value if timezone.is_naive(value) else timezone.localtime(value)\n    return value.strftime(settings.DATE_FORMAT)", "response": "Returns the timestamp of a datetime. datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef datefmt_to_regex(datefmt):\n    new_string = datefmt\n    for pat, reg in PATTERN_MATCHNG:\n        new_string = new_string.replace(pat, reg)\n    return re.compile(r'(%s)' % new_string)", "response": "Convert a strftime format string to a regex."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a datetime from a file name.", "response": "def filename_to_date(filename, datefmt=None):\n    \"\"\"\n    Return a datetime from a file name.\n\n    :param datefmt: strftime format string, ``settings.DATE_FORMAT`` is used\n                    if is ``None``\n    :type datefmt: ``str`` or ``NoneType``\n\n    :returns: Date guessed or nothing if no date found\n    :rtype: ``datetime.datetime`` or ``NoneType``\n    \"\"\"\n    datefmt = datefmt or settings.DATE_FORMAT\n    datestring = filename_to_datestring(filename, datefmt)\n    if datestring is not None:\n        return datetime.strptime(datestring, datefmt)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a new backup filename.", "response": "def filename_generate(extension, database_name='', servername=None, content_type='db', wildcard=None):\n    \"\"\"\n    Create a new backup filename.\n\n    :param extension: Extension of backup file\n    :type extension: ``str``\n\n    :param database_name: If it is database backup specify its name\n    :type database_name: ``str``\n\n    :param servername: Specify server name or by default ``settings.DBBACKUP_HOSTNAME``\n    :type servername: ``str``\n\n    :param content_type: Content type to backup, ``'media'`` or ``'db'``\n    :type content_type: ``str``\n\n    :param wildcard: Replace datetime with this wilecard regex\n    :type content_type: ``str``\n\n    :returns: Computed file name\n    :rtype: ``str`\n    \"\"\"\n    if content_type == 'db':\n        if '/' in database_name:\n            database_name = os.path.basename(database_name)\n        if '.' in database_name:\n            database_name = database_name.split('.')[0]\n        template = settings.FILENAME_TEMPLATE\n    elif content_type == 'media':\n        template = settings.MEDIA_FILENAME_TEMPLATE\n    else:\n        template = settings.FILENAME_TEMPLATE\n\n    params = {\n        'servername': servername or settings.HOSTNAME,\n        'datetime': wildcard or datetime.now().strftime(settings.DATE_FORMAT),\n        'databasename': database_name,\n        'extension': extension,\n        'content_type': content_type\n    }\n    if callable(template):\n        filename = template(**params)\n    else:\n        filename = template.format(**params)\n        filename = REG_FILENAME_CLEAN.sub('-', filename)\n        filename = filename[1:] if filename.startswith('-') else filename\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the specified storage class configured with options.", "response": "def get_storage(path=None, options=None):\n    \"\"\"\n    Get the specified storage configured with options.\n\n    :param path: Path in Python dot style to module containing the storage\n                 class. If empty settings.DBBACKUP_STORAGE will be used.\n    :type path: ``str``\n\n    :param options: Parameters for configure the storage, if empty\n                    settings.DBBACKUP_STORAGE_OPTIONS will be used.\n    :type options: ``dict``\n\n    :return: Storage configured\n    :rtype: :class:`.Storage`\n    \"\"\"\n    path = path or settings.STORAGE\n    options = options or settings.STORAGE_OPTIONS\n    if not path:\n        raise ImproperlyConfigured('You must specify a storage class using '\n                                   'DBBACKUP_STORAGE settings.')\n    return Storage(path, **options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all backups except given filter.", "response": "def list_backups(self, encrypted=None, compressed=None, content_type=None,\n                     database=None, servername=None):\n        \"\"\"\n        List stored files except given filter. If filter is None, it won't be\n        used. ``content_type`` must be ``'db'`` for database backups or\n        ``'media'`` for media backups.\n\n        :param encrypted: Filter by encrypted or not\n        :type encrypted: ``bool`` or ``None``\n\n        :param compressed: Filter by compressed or not\n        :type compressed: ``bool`` or ``None``\n\n        :param content_type: Filter by media or database backup, must be\n                             ``'db'`` or ``'media'``\n\n        :type content_type: ``str`` or ``None``\n\n        :param database: Filter by source database's name\n        :type: ``str`` or ``None``\n\n        :param servername: Filter by source server's name\n        :type: ``str`` or ``None``\n\n        :returns: List of files\n        :rtype: ``list`` of ``str``\n        \"\"\"\n        if content_type not in ('db', 'media', None):\n            msg = \"Bad content_type %s, must be 'db', 'media', or None\" % (\n                content_type)\n            raise TypeError(msg)\n        # TODO: Make better filter for include only backups\n        files = [f for f in self.list_directory() if utils.filename_to_datestring(f)]\n        if encrypted is not None:\n            files = [f for f in files if ('.gpg' in f) == encrypted]\n        if compressed is not None:\n            files = [f for f in files if ('.gz' in f) == compressed]\n        if content_type == 'media':\n            files = [f for f in files if '.tar' in f]\n        elif content_type == 'db':\n            files = [f for f in files if '.tar' not in f]\n        if database:\n            files = [f for f in files if database in f]\n        if servername:\n            files = [f for f in files if servername in f]\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the older backup s file name.", "response": "def get_older_backup(self, encrypted=None, compressed=None,\n                         content_type=None, database=None, servername=None):\n        \"\"\"\n        Return the older backup's file name.\n\n        :param encrypted: Filter by encrypted or not\n        :type encrypted: ``bool`` or ``None``\n\n        :param compressed: Filter by compressed or not\n        :type compressed: ``bool`` or ``None``\n\n        :param content_type: Filter by media or database backup, must be\n                             ``'db'`` or ``'media'``\n\n        :type content_type: ``str`` or ``None``\n\n        :param database: Filter by source database's name\n        :type: ``str`` or ``None``\n\n        :param servername: Filter by source server's name\n        :type: ``str`` or ``None``\n\n        :returns: Older file\n        :rtype: ``str``\n\n        :raises: FileNotFound: If no backup file is found\n        \"\"\"\n        files = self.list_backups(encrypted=encrypted, compressed=compressed,\n                                  content_type=content_type, database=database,\n                                  servername=servername)\n        if not files:\n            raise FileNotFound(\"There's no backup file available.\")\n        return min(files, key=utils.filename_to_date)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean_old_backups(self, encrypted=None, compressed=None,\n                          content_type=None, database=None, servername=None,\n                          keep_number=None):\n        \"\"\"\n        Delete olders backups and hold the number defined.\n\n        :param encrypted: Filter by encrypted or not\n        :type encrypted: ``bool`` or ``None``\n\n        :param compressed: Filter by compressed or not\n        :type compressed: ``bool`` or ``None``\n\n        :param content_type: Filter by media or database backup, must be\n                             ``'db'`` or ``'media'``\n\n        :type content_type: ``str`` or ``None``\n\n        :param database: Filter by source database's name\n        :type: ``str`` or ``None``\n\n        :param servername: Filter by source server's name\n        :type: ``str`` or ``None``\n\n        :param keep_number: Number of files to keep, other will be deleted\n        :type keep_number: ``int`` or ``None``\n        \"\"\"\n        if keep_number is None:\n            keep_number = settings.CLEANUP_KEEP if content_type == 'db' \\\n                else settings.CLEANUP_KEEP_MEDIA\n        keep_filter = settings.CLEANUP_KEEP_FILTER\n        files = self.list_backups(encrypted=encrypted, compressed=compressed,\n                                  content_type=content_type, database=database,\n                                  servername=servername)\n        files = sorted(files, key=utils.filename_to_date, reverse=True)\n        files_to_delete = [fi for i, fi in enumerate(files) if i >= keep_number]\n        for filename in files_to_delete:\n            if keep_filter(filename):\n                continue\n            self.delete_file(filename)", "response": "Delete olders backups and hold the number defined."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the database to restore.", "response": "def _get_database(self, options):\n        \"\"\"Get the database to restore.\"\"\"\n        database_name = options.get('database')\n        if not database_name:\n            if len(settings.DATABASES) > 1:\n                errmsg = \"Because this project contains more than one database, you\"\\\n                    \" must specify the --database option.\"\n                raise CommandError(errmsg)\n            database_name = list(settings.DATABASES.keys())[0]\n        if database_name not in settings.DATABASES:\n            raise CommandError(\"Database %s does not exist.\" % database_name)\n        return database_name, settings.DATABASES[database_name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _restore_backup(self):\n        input_filename, input_file = self._get_backup_file(database=self.database_name,\n                                                           servername=self.servername)\n        self.logger.info(\"Restoring backup for database '%s' and server '%s'\",\n                         self.database_name, self.servername)\n        self.logger.info(\"Restoring: %s\" % input_filename)\n\n        if self.decrypt:\n            unencrypted_file, input_filename = utils.unencrypt_file(input_file, input_filename,\n                                                                    self.passphrase)\n            input_file.close()\n            input_file = unencrypted_file\n        if self.uncompress:\n            uncompressed_file, input_filename = utils.uncompress_file(input_file, input_filename)\n            input_file.close()\n            input_file = uncompressed_file\n\n        self.logger.info(\"Restore tempfile created: %s\", utils.handle_size(input_file))\n        if self.interactive:\n            self._ask_confirmation()\n\n        input_file.seek(0)\n        self.connector = get_connector(self.database_name)\n        self.connector.restore_dump(input_file)", "response": "Restores the specified database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a connector from its database key in setttings.", "response": "def get_connector(database_name=None):\n    \"\"\"\n    Get a connector from its database key in setttings.\n    \"\"\"\n    from django.db import connections, DEFAULT_DB_ALIAS\n    # Get DB\n    database_name = database_name or DEFAULT_DB_ALIAS\n    connection = connections[database_name]\n    engine = connection.settings_dict['ENGINE']\n    connector_settings = settings.CONNECTORS.get(database_name, {})\n    connector_path = connector_settings.get('CONNECTOR', CONNECTOR_MAPPING[engine])\n    connector_module_path = '.'.join(connector_path.split('.')[:-1])\n    module = import_module(connector_module_path)\n    connector_name = connector_path.split('.')[-1]\n    connector = getattr(module, connector_name)\n    return connector(database_name, **connector_settings)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmix of database and connector settings.", "response": "def settings(self):\n        \"\"\"Mix of database and connector settings.\"\"\"\n        if not hasattr(self, '_settings'):\n            sett = self.connection.settings_dict.copy()\n            sett.update(settings.CONNECTORS.get(self.database_name, {}))\n            self._settings = sett\n        return self._settings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlaunch a shell command line.", "response": "def run_command(self, command, stdin=None, env=None):\n        \"\"\"\n        Launch a shell command line.\n\n        :param command: Command line to launch\n        :type command: str\n        :param stdin: Standard input of command\n        :type stdin: file\n        :param env: Environment variable used in command\n        :type env: dict\n        :return: Standard output of command\n        :rtype: file\n        \"\"\"\n        cmd = shlex.split(command)\n        stdout = SpooledTemporaryFile(max_size=settings.TMP_FILE_MAX_SIZE,\n                                      dir=settings.TMP_DIR)\n        stderr = SpooledTemporaryFile(max_size=settings.TMP_FILE_MAX_SIZE,\n                                      dir=settings.TMP_DIR)\n        full_env = os.environ.copy() if self.use_parent_env else {}\n        full_env.update(self.env)\n        full_env.update(env or {})\n        try:\n            if isinstance(stdin, (ContentFile, SFTPStorageFile)):\n                process = Popen(cmd, stdin=PIPE, stdout=stdout, stderr=stderr, env=full_env)\n                process.communicate(input=stdin.read())\n            else:\n                process = Popen(cmd, stdin=stdin, stdout=stdout, stderr=stderr, env=full_env)\n            process.wait()\n            if process.poll():\n                stderr.seek(0)\n                raise exceptions.CommandConnectorError(\n                    \"Error running: {}\\n{}\".format(command, stderr.read().decode('utf-8')))\n            stdout.seek(0)\n            stderr.seek(0)\n            return stdout, stderr\n        except OSError as err:\n            raise exceptions.CommandConnectorError(\n                \"Error running: {}\\n{}\".format(command, str(err)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning all RainCloudyFaucetZone managed by faucet.", "response": "def _assign_zones(self):\n        \"\"\"Assign all RainCloudyFaucetZone managed by faucet.\"\"\"\n        for zone_id in range(1, 5):\n            zone = \\\n                RainCloudyFaucetZone(\n                    parent=self._parent,\n                    controller=self._controller,\n                    faucet=self,\n                    zone_id=zone_id)\n\n            if zone not in self.zones:\n                self.zones.append(zone)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_zone_by_id(self, zone_id):\n        if not self.zones:\n            return None\n\n        zone = list(filter(\n            lambda zone: zone.id == zone_id, self.zones))\n\n        return zone[0] if zone else None", "response": "Return zone by id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_zone_name(self, zoneid, name):\n        # zone starts with index 0\n        zoneid -= 1\n        data = {\n            '_set_zone_name': 'Set Name',\n            'select_zone': str(zoneid),\n            'zone_name': name,\n        }\n        self._controller.post(data)", "response": "Private method to override zone name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning watering time from zone.", "response": "def watering_time(self):\n        \"\"\"Return watering_time from zone.\"\"\"\n        # zone starts with index 0\n        index = self.id - 1\n        auto_watering_time =\\\n            self._attributes['rain_delay_mode'][index]['auto_watering_time']\n\n        manual_watering_time =\\\n            self._attributes['rain_delay_mode'][index]['manual_watering_time']\n\n        if auto_watering_time > manual_watering_time:\n            watering_time = auto_watering_time\n        else:\n            watering_time = manual_watering_time\n\n        return watering_time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning if zone is configured to automatic watering.", "response": "def auto_watering(self):\n        \"\"\"Return if zone is configured to automatic watering.\"\"\"\n        value = \"zone{}\".format(self.id)\n        return find_program_status(self._parent.html['home'], value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preupdate(self, force_refresh=True):\n        ddata = MANUAL_OP_DATA.copy()\n\n        # force update to make sure status is accurate\n        if force_refresh:\n            self.update()\n\n        # select current controller and faucet\n        ddata['select_controller'] = \\\n            self._parent.controllers.index(self._controller)\n        ddata['select_faucet'] = \\\n            self._controller.faucets.index(self._faucet)\n\n        # check if zone is scheduled automatically (zone1_program_toggle)\n        # only add zoneX_program_toogle to ddata when needed,\n        # otherwise the field will be always on\n        for zone in self._faucet.zones:\n            attr = 'zone{}_program_toggle'.format(zone.id)\n            if zone.auto_watering:\n                ddata[attr] = 'on'\n\n        # check if zone current watering manually (zone1_select_manual_mode)\n        for zone in self._faucet.zones:\n            attr = 'zone{}_select_manual_mode'.format(zone.id)\n            if zone.watering_time and attr in ddata.keys():\n                ddata[attr] = zone.watering_time\n\n        # check if rain delay is selected (zone0_rain_delay_select)\n        for zone in self._faucet.zones:\n            attr = 'zone{}_rain_delay_select'.format(zone.id - 1)\n            value = zone.rain_delay\n            if value and attr in ddata.keys():\n                if int(value) >= 2 and int(value) <= 7:\n                    value = str(value) + 'days'\n                else:\n                    value = str(value) + 'day'\n                ddata[attr] = value\n\n        return ddata", "response": "Return a dict with all current options prior submitting request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubmitting data to the controller.", "response": "def submit_action(self, ddata):\n        \"\"\"Post data.\"\"\"\n        self._controller.post(ddata,\n                              url=HOME_ENDPOINT,\n                              referer=HOME_ENDPOINT)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef controller(self):\n        if hasattr(self, 'controllers'):\n            if len(self.controllers) > 1:\n                # in the future, we should support more controllers\n                raise TypeError(\"Only one controller per account.\")\n            return self.controllers[0]\n        raise AttributeError(\"There is no controller assigned.\")", "response": "Show current linked controllers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassign the given list of faucets to the controller.", "response": "def _assign_faucets(self, faucets):\n        \"\"\"Assign RainCloudyFaucet objects to self.faucets.\"\"\"\n        if not faucets:\n            raise TypeError(\"Controller does not have a faucet assigned.\")\n\n        for faucet_id in faucets:\n            self.faucets.append(\n                RainCloudyFaucet(self._parent, self, faucet_id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubmit GET request to update information.", "response": "def _get_cu_and_fu_status(self):\n        \"\"\"Submit GET request to update information.\"\"\"\n        # adjust headers\n        headers = HEADERS.copy()\n        headers['Accept'] = '*/*'\n        headers['X-Requested-With'] = 'XMLHttpRequest'\n        headers['X-CSRFToken'] = self._parent.csrftoken\n\n        args = '?controller_serial=' + self.serial \\\n               + '&faucet_serial=' + self.faucet.serial\n\n        req = self._parent.client.get(STATUS_ENDPOINT + args,\n                                      headers=headers)\n\n        # token probably expired, then try again\n        if req.status_code == 403:\n            self._parent.login()\n            self.update()\n        elif req.status_code == 200:\n            self.attributes = req.json()\n        else:\n            req.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _refresh_html_home(self):\n        req = self._parent.client.get(HOME_ENDPOINT)\n        if req.status_code == 403:\n            self._parent.login()\n            self.update()\n        elif req.status_code == 200:\n            self._parent.html['home'] = generate_soup_html(req.text)\n        else:\n            req.raise_for_status()", "response": "Function to refresh the self. html['home'] object which provides the status if zones are scheduled to start automatically."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(self, value):\n        data = {\n            '_set_controller_name': 'Set Name',\n            'controller_name': value,\n        }\n        self.post(data, url=SETUP_ENDPOINT, referer=SETUP_ENDPOINT)", "response": "Set a new name to controller."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing current linked faucet.", "response": "def faucet(self):\n        \"\"\"Show current linked faucet.\"\"\"\n        if hasattr(self, 'faucets'):\n            if len(self.faucets) > 1:\n                # in the future, we should support more faucets\n                raise TypeError(\"Only one faucet per account.\")\n            return self.faucets[0]\n        raise AttributeError(\"There is no faucet assigned.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding controller serial and faucet serial from the setup page.", "response": "def serial_finder(data):\n    \"\"\"\n    Find controller serial and faucet_serial from the setup page.\n\n    <select id=\"id_select_controller2\" name=\"select_controller\" >\n        <option value='0' selected='selected'>1 - Controller001</option>\n    </select>\n\n    :param data: text to be parsed\n    :type data: BeautilSoup object\n    :return: a dict with controller_serial and faucet_serial\n    :rtype: dict\n    :raises IndexError: if controller_serial was not found on the data\n    \"\"\"\n    if not isinstance(data, BeautifulSoup):\n        raise TypeError(\"Function requires BeautifulSoup HTML element.\")\n\n    try:\n\n        # The setup page contains a select box for each controller and each\n        # faucet\n        controllersElement = data.find_all('select',\n                                           {'id': 'id_select_controller2'})\n\n        faucetsElement = data.find_all('select',\n                                       {'id': 'id_select_faucet2'})\n\n        controllerSerial = controllersElement[0].text.split('-')[1].strip()\n        faucetSerial = faucetsElement[0].text.split('-')[1].strip()\n\n        # currently only one faucet is supported on the code\n        # we have plans to support it in the future\n        parsed_dict = {}\n        parsed_dict['controller_serial'] = controllerSerial\n        parsed_dict['faucet_serial'] = [faucetSerial]\n        return parsed_dict\n\n    except (AttributeError, IndexError, ValueError):\n        raise RainCloudyException(\n            'Could not find any valid controller or faucet')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind on the HTML document if zoneX has the program status.", "response": "def find_program_status(data, zone):\n    \"\"\"\n    Find on the HTML document if zoneX has the configuration\n    of the auto-schedule/program (auto_watering) enabled.\n\n    # expected result if enabled\n    #<input checked=\"checked\" class=\"switch\" id=\"id_zone2_program_toggle\" \\\n        name=\"zone2_program_toggle\" onchange=\"submit()\" type=\"checkbox\"/>\n\n    # expected result if disabled\n    #<input class=\"switch\" id=\"id_zone1_program_toggle\" \\\n        name=\"zone1_program_toggle\" onchange=\"submit()\" type=\"checkbox\"/>\n\n    :param data: BeautifulSoup object\n    :param zone: zone name from class='switch'\n    :return: boolean if zone has program enabled\n    :rtype: boolean\n    :raises TypeError: if data is not a BeautifulSoup object\n    :raises IndexError: if object not found\n    \"\"\"\n    if not isinstance(data, BeautifulSoup):\n        raise TypeError(\"Function requires BeautilSoup HTML element.\")\n\n    try:\n        child = data.find_all('input', {'class': 'switch'})\n        zone_id = 'id_{0}_program_toggle'.format(zone)\n        for member in child:\n            if member.get('type') == 'checkbox' and \\\n               member.get('id') == zone_id:\n                return bool(member.has_attr('checked'))\n        raise IndexError\n    except (AttributeError, IndexError, ValueError):\n        raise RainCloudyException(\n            'Could not find any valid controller or faucet')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the controller name of a given type.", "response": "def find_controller_or_faucet_name(data, p_type):\n    \"\"\"\n    Find on the HTML document the controller name.\n\n    # expected result\n    <label for=\"select_controller\">\n     <span class=\"more_info\" id=\"#styling-type-light\" data-hasqtip=\"26\" \\\n     title=\"Select Control Unit to display.\" >Control Unit:</span></label><br/>\n     <select class=\"simpleselect\" id=\"id_select_controller\" \\\n       name=\"select_controller\" onchange=\"submit()\" >\n          <option value=\"0\" selected=\"selected\">HERE_IS_CONTROLLER_NAME\n\n    :param data: BeautifulSoup object\n    :param p_type: parameter type. (controller or faucet)\n    :return: controller or valve name\n    :rtype: string.\n    :raises TypeError: if data is not a BeautifulSoup object\n    :raises IndexError: return None because controller name was not found\n    \"\"\"\n    if not isinstance(data, BeautifulSoup):\n        raise TypeError(\"Function requires BeautilSoup HTML element.\")\n\n    if not (p_type == 'controller' or p_type == 'faucet'):\n        raise TypeError(\"Function p_type must be controller or faucet\")\n\n    try:\n        search_field = 'id_select_{0}'.format(p_type)\n        child = data.find('select', {'id': search_field})\n        return child.get_text().strip()\n    except AttributeError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_zone_name(data, zone_id):\n    if not isinstance(data, BeautifulSoup):\n        raise TypeError(\"Function requires BeautilSoup HTML element.\")\n\n    table = data.find('table', {'class': 'zone_table'})\n    table_body = table.find('tbody')\n    rows = table_body.find_all('span', {'class': 'more_info'})\n    for row in rows:\n        if row.get_text().startswith(str(zone_id)):\n            return row.get_text()[4:].strip()\n    return None", "response": "Find the controller name for a given zone id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_payment_query_listener(sender, order=None, payment=None, **kwargs):\n    payment.amount = order.total\n    payment.currency = order.currency\n\n    logger.debug(\"new_payment_query_listener, amount=%s, currency=%s\",\n                 payment.amount, payment.currency)", "response": "This is a callback function that is called when a new payment is received."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when payment status changes.", "response": "def payment_status_changed_listener(sender, instance, old_status, new_status, **kwargs):\n    \"\"\"\n    Here we will actually do something, when payment is accepted.\n    E.g. lets change an order status.\n    \"\"\"\n    logger.debug(\"payment_status_changed_listener, old=%s, new=%s\", old_status,\n                 new_status)\n    if old_status != 'paid' and new_status == 'paid':\n        # Ensures that we process order only one\n        instance.order.status = 'P'\n        instance.order.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_backend_choices(currency=None):\n    choices = []\n    backends_names = getattr(settings, 'GETPAID_BACKENDS', [])\n\n    for backend_name in backends_names:\n        backend = import_module(backend_name)\n        if currency:\n            if currency in backend.PaymentProcessor.BACKEND_ACCEPTED_CURRENCY:\n                choices.append(\n                    (backend_name, backend.PaymentProcessor.BACKEND_NAME)\n                )\n        else:\n            choices.append(\n                (backend_name, backend.PaymentProcessor.BACKEND_NAME)\n            )\n    return choices", "response": "Get active backends modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef online(cls, payload, ip, req_sig):\n\n        from getpaid.models import Payment\n\n        params = json.loads(payload)\n        order_data = params.get('order', {})\n        pos_id = order_data.get('merchantPosId')\n        payment_id = order_data.get('extOrderId')\n\n        key2 = cls.get_backend_setting('key2')\n\n        if pos_id != cls.get_backend_setting('pos_id'):\n            logger.warning('Received message for different pos: {}'.format(pos_id))\n            return 'ERROR'\n\n        req_sig_dict = cls.parse_payu_sig(req_sig)\n        sig = cls.compute_sig(payload, key2, algorithm=req_sig_dict.get('algorithm', 'md5'))\n\n        if sig != req_sig_dict['signature']:\n            logger.warning('Received message with malformed signature. Payload: {}'.format(payload))\n            return 'ERROR'\n\n        try:\n            payment = Payment.objects.get(id=payment_id)\n        except Payment.DoesNotExist:\n            logger.warning('Received message for nonexistent payment: {}.\\nPayload: {}'.format(payment_id, payload))\n            return 'ERROR'\n        status = order_data['status']\n        if payment.status != 'paid':\n            if status == 'COMPLETED':\n                payment.external_id = order_data['orderId']\n                payment.amount = Decimal(order_data['totalAmount']) / Decimal(100)\n                payment.amount_paid = payment.amount\n                payment.currenct = order_data['currencyCode']\n                payment.paid_on = pendulum.parse(params['localReceiptDateTime']).in_tz('utc')\n                payment.description = order_data['description']\n                payment.change_status('paid')\n\n            elif status == 'PENDING':\n                payment.change_status('in_progress')\n            elif status in ['CANCELED', 'REJECTED']:\n                payment.change_status('cancelled')\n        return 'OK'", "response": "Receive and analyze request from payment service with information on payment status change."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the url for the payment.", "response": "def get_gateway_url(self, request):\n        \"\"\"\n        Tricky process that requires to get auth key, send order via POST and\n        then present final URL for redirection to finalize payment.\n        \"\"\"\n\n        grant_type = self.get_backend_setting('grant_type', 'client_credentials')\n        if grant_type == 'client_credentials':\n            client_id = self.get_backend_setting('client_id')\n            client_secret = self.get_backend_setting('client_secret')\n            url = \"{gateway_url}pl/standard/user/oauth/authorize?\" \\\n                  \"grant_type={grant_type}&\" \\\n                  \"client_id={client_id}&\" \\\n                  \"client_secret={client_secret}\".format(gateway_url=self._GATEWAY_URL,\n                                                         grant_type=grant_type, client_id=client_id,\n                                                         client_secret=client_secret)\n        elif grant_type == 'trusted_merchant':\n            raise ImproperlyConfigured('grant_type not yet supported')\n        else:\n            raise ImproperlyConfigured('grant_type should be one of: \"trusted_merchant\", \"client_credentials\"')\n\n        response = requests.get(url)\n        assert response.status_code == 200\n\n        response_data = response.json()\n        access_token = response_data['access_token']\n        token_type = response_data['token_type']\n\n        headers = {\"Authorization\": \"{token_type} {access_token}\".format(\n            token_type=token_type.title(), access_token=access_token)}\n\n        pos_id = self.get_backend_setting('pos_id', None)\n\n        user_data = {\n            'email': None,\n            'lang': None,\n        }\n\n        signals.user_data_query.send(\n            sender=None, order=self.payment.order, user_data=user_data)\n\n        if not user_data['email']:\n            raise ImproperlyConfigured\n\n        buyer_info = dict(  # dane kupuj\u0105cego\n            email=user_data['email'],\n        )\n\n        if user_data['lang'] and user_data['lang'].lower() in self._ACCEPTED_LANGS:\n            buyer_info['language'] = user_data['lang'].lower()\n        elif self.get_backend_setting('lang', False\n                                      ) and (self.get_backend_setting('lang').lower() in self._ACCEPTED_LANGS):\n            buyer_info['language'] = six.text_type(self.get_backend_setting('lang').lower())\n\n        customer_id = user_data.get('id', None)\n        if customer_id:\n            buyer_info['extCustomerId'] = customer_id\n\n        customer_first_name = user_data.get('first_name', None)\n        if customer_first_name:\n            buyer_info['firstName'] = customer_first_name\n\n        customer_last_name = user_data.get('last_name', None)\n        if customer_last_name:\n            buyer_info['last_Namme'] = customer_last_name\n\n        customer_phone = user_data.get('phone', None)\n        if customer_phone:\n            buyer_info['phone'] = customer_phone\n\n        current_site = getpaid_utils.get_domain(request)\n        use_ssl = self.get_backend_setting('ssl_return', True)\n\n        notify_url = \"http{}://{}{}\".format(\n            's' if use_ssl else '',\n            current_site,\n            reverse('getpaid:payu_rest:confirm')\n        )\n\n        params = dict(\n            customerIp=getpaid_utils.get_ip_address(request),\n            merchantPosId=pos_id,\n            description=self.get_order_description(self.payment, self.payment.order),\n            currencyCode=self.payment.currency.upper(),\n            totalAmount=str(int(self.payment.amount * 100)),\n            buyer=buyer_info,\n            products=[dict(\n                name='Payment #{} from {}'.format(self.payment.pk, current_site),\n                unitPrice=str(int(self.payment.amount * 100)),\n                quantity=\"1\",\n                # ### optional:\n                # virtual=True,\n                # listingDate='',\n            )],\n\n            # ### optional:\n            notifyUrl=notify_url,\n            extOrderId=str(self.payment.pk),\n            # validityTime='',\n            # additionalDescription='',\n            continueUrl='http://127.0.0.1:8000/',\n            # payMethods=None,\n        )\n\n        order_url = \"{gateway_url}api/v2_1/orders\".format(gateway_url=self._GATEWAY_URL)\n\n        order_register = requests.post(order_url, json=params, headers=headers, allow_redirects=False)\n        order_register_data = order_register.json()\n        status = order_register_data.get('status', {}).get('statusCode', '')\n        if status != 'SUCCESS':\n            logger.error('Houston, we have a problem with this payment trajectory: {}'.format(status))\n            return reverse('getpaid:failure-fallback', kwargs=dict(pk=self.payment.pk)), 'GET', {}\n        final_url = order_register_data.get('redirectUri')\n\n        return final_url, 'GET', {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_order_description(self, payment, order):\n        template = getattr(settings, 'GETPAID_ORDER_DESCRIPTION', None)\n        if template:\n            return Template(template).render(Context({\"payment\": payment, \"order\": order}))\n        else:\n            return six.text_type(order)", "response": "Renders order description using django template provided in settings. GETPAID_ORDER_DESCRIPTION or returns unicode representation of order object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_backend_setting(cls, name, default=None):\n        backend_settings = get_backend_settings(cls.BACKEND)\n        if default is not None:\n            return backend_settings.get(name, default)\n        else:\n            try:\n                return backend_settings[name]\n            except KeyError:\n                raise ImproperlyConfigured(\"getpaid '%s' requires backend '%s' setting\" % (cls.BACKEND, name))", "response": "Reads name setting from backend settings dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the URL for a payment to Gateway", "response": "def get_gateway_url(self, request):\n        \"\"\"\n        Routes a payment to Gateway, should return URL for redirection.\n        \"\"\"\n        params = {\n            'id': self.get_backend_setting('id'),\n            'description': self.get_order_description(self.payment, self.payment.order),\n            'amount': self.payment.amount,\n            'currency': self.payment.currency,\n            'type': 0,  # 0 = show \"return\" button after finished payment\n            'control': self.payment.pk,\n            'URL': self.get_URL(self.payment.pk),\n            'URLC': self.get_URLC(),\n            'api_version': 'dev',\n        }\n\n        user_data = {\n            'email': None,\n            'lang': None,\n        }\n        signals.user_data_query.send(sender=None, order=self.payment.order, user_data=user_data)\n\n        if user_data['email']:\n            params['email'] = user_data['email']\n\n        if user_data['lang'] and user_data['lang'].lower() in self._ACCEPTED_LANGS:\n            params['lang'] = user_data['lang'].lower()\n        elif self.get_backend_setting('lang', False\n                                      ) and self.get_backend_setting('lang').lower() in self._ACCEPTED_LANGS:\n            params['lang'] = self.get_backend_setting('lang').lower()\n\n        if self.get_backend_setting('onlinetransfer', False):\n            params['onlinetransfer'] = 1\n        if self.get_backend_setting('p_email', False):\n            params['p_email'] = self.get_backend_setting('p_email')\n        if self.get_backend_setting('p_info', False):\n            params['p_info'] = self.get_backend_setting('p_info')\n        if self.get_backend_setting('tax', False):\n            params['tax'] = 1\n\n        gateway_url = self.get_backend_setting('gateway_url', self._GATEWAY_URL)\n\n        if self.get_backend_setting('method', 'get').lower() == 'post':\n            return gateway_url, 'POST', params\n        elif self.get_backend_setting('method', 'get').lower() == 'get':\n            for key in params.keys():\n                params[key] = six.text_type(params[key]).encode('utf-8')\n            return gateway_url + '?' + urlencode(params), \"GET\", {}\n        else:\n            raise ImproperlyConfigured('Dotpay payment backend accepts only GET or POST')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Future that tracks when a Channel is ready.", "response": "def channel_ready_future(channel):\n    \"\"\"Creates a Future that tracks when a Channel is ready.\n\n  Cancelling the Future does not affect the channel's state machine.\n  It merely decouples the Future from channel state machine.\n\n  Args:\n    channel: A Channel object.\n\n  Returns:\n    A Future object that matures when the channel connectivity is\n    ChannelConnectivity.READY.\n  \"\"\"\n    fut = channel._loop.create_future()\n    def _set_result(state):\n        if not fut.done() and state is _grpc.ChannelConnectivity.READY:\n            fut.set_result(None)\n    fut.add_done_callback(lambda f: channel.unsubscribe(_set_result))\n    channel.subscribe(_set_result, try_to_connect=True)\n    return fut"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insecure_channel(target, options=None, *, loop=None, executor=None,\n                    standalone_pool_for_streaming=False):\n    \"\"\"Creates an insecure Channel to a server.\n\n  Args:\n    target: The server address\n    options: An optional list of key-value pairs (channel args in gRPC runtime)\n    to configure the channel.\n\n  Returns:\n    A Channel object.\n  \"\"\"\n    return Channel(_grpc.insecure_channel(target, options), loop, executor, standalone_pool_for_streaming)", "response": "Creates an insecure Channel to a server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef secure_channel(target, credentials, options=None, *, loop=None, executor=None,\n                   standalone_pool_for_streaming=False):\n    \"\"\"Creates a secure Channel to a server.\n\n  Args:\n    target: The server address.\n    credentials: A ChannelCredentials instance.\n    options: An optional list of key-value pairs (channel args in gRPC runtime)\n    to configure the channel.\n\n  Returns:\n    A Channel object.\n  \"\"\"\n    return Channel(_grpc.secure_channel(target, credentials, options),\n                   loop, executor, standalone_pool_for_streaming)", "response": "Creates a secure Channel to a server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an ASYNC context manager that can be used to ensure the call is closed outside the scope.", "response": "def with_scope(self, request, timeout=None, metadata=None, credentials=None,\n                        *, standalone_pool = None):\n        \"\"\"\n        Return an ASYNC context manager to ensure the call is closed outside the scope::\n        \n            async with mystub.mymethod.with_scope(...) as iter:\n                async for i in iter:\n                    ...\n        \"\"\"\n        return _utils.IteratorScope(self(request, timeout, metadata, credentials, standalone_pool=standalone_pool))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def with_call(self,\n                  request_iterator,\n                  timeout=None,\n                  metadata=None,\n                  credentials=None):\n        \"\"\"Synchronously invokes the underlying RPC on the client.\n\n    Args:\n      request_iterator: An ASYNC iterator that yields request values for the RPC.\n      timeout: An optional duration of time in seconds to allow for the RPC.\n               If None, the timeout is considered infinite.\n      metadata: Optional :term:`metadata` to be transmitted to the\n        service-side of the RPC.\n      credentials: An optional CallCredentials for the RPC.\n\n    Returns:\n      The response value for the RPC and a Call object for the RPC.\n\n    Raises:\n      RpcError: Indicating that the RPC terminated with non-OK status. The\n        raised RpcError will also be a Call for the RPC affording the RPC's\n        metadata, status code, and details.\n    \"\"\"\n        fut = self.future(request_iterator, timeout, metadata, credentials)\n        try:\n            result = await fut\n            return (result, fut)\n        finally:\n            if not fut.done():\n                fut.cancel()", "response": "Synchronously invokes the underlying RPC on the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef future(self,\n               request_iterator,\n               timeout=None,\n               metadata=None,\n               credentials=None):\n        \"\"\"Asynchronously invokes the underlying RPC on the client.\n\n    Args:\n      request_iterator: An ASYNC iterator that yields request values for the RPC.\n      timeout: An optional duration of time in seconds to allow for the RPC.\n               If None, the timeout is considered infinite.\n      metadata: Optional :term:`metadata` to be transmitted to the\n        service-side of the RPC.\n      credentials: An optional CallCredentials for the RPC.\n\n    Returns:\n        An object that is both a Call for the RPC and a Future. In the event of\n        RPC completion, the return Call-Future's result value will be the\n        response message of the RPC. Should the event terminate with non-OK\n        status, the returned Call-Future's exception value will be an RpcError.\n    \"\"\"\n        return _utils.wrap_future_call(\n                    self._inner.future(\n                        _utils.WrappedAsyncIterator(request_iterator, self._loop),\n                        timeout,\n                        metadata,\n                        credentials\n                    ),\n                    self._loop,\n                    self._executor)", "response": "Asynchronously invokes the underlying RPC on the client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        return self._loop.run_in_executor(self._executor, self._channel.close)", "response": "Close the channel and return a future."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate a config field against a type.", "response": "def config_field_type(field, cls):\n    \"\"\"Validate a config field against a type.\n\n    Similar functionality to :func:`validate_field_matches_type` but returns :obj:`honeycomb.defs.ConfigField`\n    \"\"\"\n    return defs.ConfigField(lambda _: isinstance(_, cls),\n                            lambda: CONFIG_FIELD_TYPE_ERROR.format(field, cls.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating a JSON file configuration against a list of fields.", "response": "def validate_config(config_json, fields):\n    \"\"\"Validate a JSON file configuration against list of :obj:`honeycomb.defs.ConfigField`.\"\"\"\n    for field_name, validator_obj in six.iteritems(fields):\n        field_value = config_json.get(field_name, None)\n        if field_value is None:\n            raise exceptions.ConfigFieldMissing(field_name)\n\n        if not validator_obj.validator_func(field_value):\n            raise exceptions.ConfigFieldValidationError(field_name, field_value, validator_obj.get_error_message())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config_parameters(plugin_path):\n    json_config_path = os.path.join(plugin_path, defs.CONFIG_FILE_NAME)\n    with open(json_config_path, \"r\") as f:\n        config = json.load(f)\n    return config.get(defs.PARAMETERS, [])", "response": "Return the parameters section from config. json."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating parameters in config file.", "response": "def validate_config_parameters(config_json, allowed_keys, allowed_types):\n    \"\"\"Validate parameters in config file.\"\"\"\n    custom_fields = config_json.get(defs.PARAMETERS, [])\n    for field in custom_fields:\n        validate_field(field, allowed_keys, allowed_types)\n        default = field.get(defs.DEFAULT)\n        field_type = field.get(defs.TYPE)\n        if default:\n            validate_field_matches_type(field[defs.VALUE], default, field_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates a config field against a specific type.", "response": "def validate_field_matches_type(field, value, field_type, select_items=None, _min=None, _max=None):\n    \"\"\"Validate a config field against a specific type.\"\"\"\n    if (field_type == defs.TEXT_TYPE and not isinstance(value, six.string_types)) or \\\n       (field_type == defs.STRING_TYPE and not isinstance(value, six.string_types)) or \\\n       (field_type == defs.BOOLEAN_TYPE and not isinstance(value, bool)) or \\\n       (field_type == defs.INTEGER_TYPE and not isinstance(value, int)):\n        raise exceptions.ConfigFieldTypeMismatch(field, value, field_type)\n\n    if field_type == defs.INTEGER_TYPE:\n        if _min and value < _min:\n            raise exceptions.ConfigFieldTypeMismatch(field, value, \"must be higher than {}\".format(_min))\n        if _max and value > _max:\n            raise exceptions.ConfigFieldTypeMismatch(field, value, \"must be lower than {}\".format(_max))\n\n    if field_type == defs.SELECT_TYPE:\n        from honeycomb.utils.plugin_utils import get_select_items\n        items = get_select_items(select_items)\n        if value not in items:\n            raise exceptions.ConfigFieldTypeMismatch(field, value, \"one of: {}\".format(\", \".join(items)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a string to a pythonized parameter.", "response": "def get_truetype(value):\n    \"\"\"Convert a string to a pythonized parameter.\"\"\"\n    if value in [\"true\", \"True\", \"y\", \"Y\", \"yes\"]:\n        return True\n    if value in [\"false\", \"False\", \"n\", \"N\", \"no\"]:\n        return False\n    if value.isdigit():\n        return int(value)\n    return str(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_field(field, allowed_keys, allowed_types):\n    for key, value in field.items():\n        if key not in allowed_keys:\n            raise exceptions.ParametersFieldError(key, \"property\")\n        if key == defs.TYPE:\n            if value not in allowed_types:\n                raise exceptions.ParametersFieldError(value, key)\n        if key == defs.VALUE:\n            if not is_valid_field_name(value):\n                raise exceptions.ParametersFieldError(value, \"field name\")", "response": "Validate field is allowed and valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_valid_field_name(value):\n    leftovers = re.sub(r\"\\w\", \"\", value)\n    leftovers = re.sub(r\"-\", \"\", leftovers)\n    if leftovers != \"\" or value[0].isdigit() or value[0] in [\"-\", \"_\"] or \" \" in value:\n        return False\n    return True", "response": "Ensure field name is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_config(ctx, configfile):\n    from honeycomb.commands.service.run import run as service_run\n    # from honeycomb.commands.service.logs import logs as service_logs\n    from honeycomb.commands.service.install import install as service_install\n    from honeycomb.commands.integration.install import install as integration_install\n    from honeycomb.commands.integration.configure import configure as integration_configure\n\n    VERSION = \"version\"\n    SERVICES = defs.SERVICES\n    INTEGRATIONS = defs.INTEGRATIONS\n\n    required_top_keys = [VERSION, SERVICES]\n    supported_versions = [1]\n\n    def validate_yml(config):\n        for key in required_top_keys:\n            if key not in config:\n                raise exceptions.ConfigFieldMissing(key)\n\n        version = config.get(VERSION)\n        if version not in supported_versions:\n            raise exceptions.ConfigFieldTypeMismatch(VERSION, version,\n                                                     \"one of: {}\".format(repr(supported_versions)))\n\n    def install_plugins(services, integrations):\n        for cmd, kwargs in [(service_install, {SERVICES: services}),\n                            (integration_install, {INTEGRATIONS: integrations})]:\n            try:\n                ctx.invoke(cmd, **kwargs)\n            except SystemExit:\n                # If a plugin is already installed honeycomb will exit abnormally\n                pass\n\n    def parameters_to_string(parameters_dict):\n        return [\"{}={}\".format(k, v) for k, v in parameters_dict.items()]\n\n    def configure_integrations(integrations):\n        for integration in integrations:\n            args_list = parameters_to_string(config[INTEGRATIONS][integration].get(defs.PARAMETERS, dict()))\n            ctx.invoke(integration_configure, integration=integration, args=args_list)\n\n    def run_services(services, integrations):\n        # TODO: Enable support with multiple services as daemon, and run service.logs afterwards\n        #       tricky part is that services launched as daemon are exited with os._exit(0) so you\n        #       can't catch it.\n        for service in services:\n            args_list = parameters_to_string(config[SERVICES][service].get(defs.PARAMETERS, dict()))\n            ctx.invoke(service_run, service=service, integration=integrations, args=args_list)\n\n    # TODO: Silence normal stdout and follow honeycomb.debug.json instead\n    #       This would make monitoring containers and collecting logs easier\n    with open(configfile, \"rb\") as fh:\n        config = yaml.load(fh.read())\n\n    validate_yml(config)\n    services = config.get(SERVICES).keys()\n    integrations = config.get(INTEGRATIONS).keys() if config.get(INTEGRATIONS) else []\n\n    install_plugins(services, integrations)\n    configure_integrations(integrations)\n    run_services(services, integrations)", "response": "Process a yaml config with instructions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plugin_path(home, plugin_type, plugin_name, editable=False):\n    if editable:\n        plugin_path = plugin_name\n    else:\n        plugin_path = os.path.join(home, plugin_type, plugin_name)\n\n    return os.path.realpath(plugin_path)", "response": "Return path to plugin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_plugin(pkgpath, plugin_type, install_path, register_func):\n    service_name = os.path.basename(pkgpath)\n    if os.path.exists(os.path.join(install_path, service_name)):\n        raise exceptions.PluginAlreadyInstalled(pkgpath)\n\n    if os.path.exists(pkgpath):\n        logger.debug(\"%s exists in filesystem\", pkgpath)\n        if os.path.isdir(pkgpath):\n            pip_status = install_dir(pkgpath, install_path, register_func)\n        else:  # pkgpath is file\n            pip_status = install_from_zip(pkgpath, install_path, register_func)\n    else:\n        logger.debug(\"cannot find %s locally, checking github repo\", pkgpath)\n        click.secho(\"Collecting {}..\".format(pkgpath))\n        pip_status = install_from_repo(pkgpath, plugin_type, install_path, register_func)\n\n    if pip_status == 0:\n        click.secho(\"[+] Great success!\")\n    else:\n        # TODO: rephrase\n        click.secho(\"[-] Service installed but something was odd with dependency install, please review debug logs\")", "response": "Install specified plugin.\n\n    :param pkgpath: Name of plugin to be downloaded from online repo or path to plugin folder or zip file.\n    :param install_path: Path where plugin will be installed.\n    :param register_func: Method used to register and validate plugin."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_deps(pkgpath):\n    if os.path.exists(os.path.join(pkgpath, \"requirements.txt\")):\n        logger.debug(\"installing dependencies\")\n        click.secho(\"[*] Installing dependencies\")\n        pipargs = [\"install\", \"--target\", os.path.join(pkgpath, defs.DEPS_DIR), \"--ignore-installed\",\n                   \"-r\", os.path.join(pkgpath, \"requirements.txt\")]\n        logger.debug(\"running pip %s\", pipargs)\n        return subprocess.check_call([sys.executable, \"-m\", \"pip\"] + pipargs)\n    return 0", "response": "Install plugin dependencies using pip."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_file(src, dst):\n    try:\n        fin = os.open(src, READ_FLAGS)\n        stat = os.fstat(fin)\n        fout = os.open(dst, WRITE_FLAGS, stat.st_mode)\n        for x in iter(lambda: os.read(fin, BUFFER_SIZE), b\"\"):\n            os.write(fout, x)\n    finally:\n        try:\n            os.close(fin)\n        except Exception as exc:\n            logger.debug(\"Failed to close file handle when copying: {}\".format(exc))\n        try:\n            os.close(fout)\n        except Exception as exc:\n            logger.debug(\"Failed to close file handle when copying: {}\".format(exc))", "response": "Copy a single file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy a full directory structure.", "response": "def copy_tree(src, dst, symlinks=False, ignore=[]):\n    \"\"\"Copy a full directory structure.\n\n    :param src: Source path\n    :param dst: Destination path\n    :param symlinks: Copy symlinks\n    :param ignore: Subdirs/filenames to ignore\n    \"\"\"\n    names = os.listdir(src)\n\n    if not os.path.exists(dst):\n        os.makedirs(dst)\n    errors = []\n    for name in names:\n        if name in ignore:\n            continue\n        srcname = os.path.join(src, name)\n        dstname = os.path.join(dst, name)\n        try:\n            if symlinks and os.path.islink(srcname):\n                linkto = os.readlink(srcname)\n                os.symlink(linkto, dstname)\n            elif os.path.isdir(srcname):\n                copy_tree(srcname, dstname, symlinks, ignore)\n            else:\n                copy_file(srcname, dstname)\n        except (IOError, os.error) as exc:\n            errors.append((srcname, dstname, str(exc)))\n        except CTError as exc:\n            errors.extend(exc.errors)\n    if errors:\n        raise CTError(errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install_dir(pkgpath, install_path, register_func, delete_after_install=False):\n    logger.debug(\"%s is a directory, attempting to validate\", pkgpath)\n    plugin = register_func(pkgpath)\n    logger.debug(\"%s looks good, copying to %s\", pkgpath, install_path)\n    try:\n        copy_tree(pkgpath, os.path.join(install_path, plugin.name))\n        if delete_after_install:\n            logger.debug(\"deleting %s\", pkgpath)\n            shutil.rmtree(pkgpath)\n        pkgpath = os.path.join(install_path, plugin.name)\n    except (OSError, CTError) as exc:\n        # TODO: handle package name exists (upgrade? overwrite?)\n        logger.debug(str(exc), exc_info=True)\n        raise exceptions.PluginAlreadyInstalled(plugin.name)\n\n    return install_deps(pkgpath)", "response": "Install plugin from specified directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall plugin from zipfile.", "response": "def install_from_zip(pkgpath, install_path, register_func, delete_after_install=False):\n    \"\"\"Install plugin from zipfile.\"\"\"\n    logger.debug(\"%s is a file, attempting to load zip\", pkgpath)\n    pkgtempdir = tempfile.mkdtemp(prefix=\"honeycomb_\")\n    try:\n        with zipfile.ZipFile(pkgpath) as pkgzip:\n            pkgzip.extractall(pkgtempdir)\n    except zipfile.BadZipfile as exc:\n        logger.debug(str(exc))\n        raise click.ClickException(str(exc))\n    if delete_after_install:\n        logger.debug(\"deleting %s\", pkgpath)\n        os.remove(pkgpath)\n    logger.debug(\"installing from unzipped folder %s\", pkgtempdir)\n    return install_dir(pkgtempdir, install_path, register_func, delete_after_install=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install_from_repo(pkgname, plugin_type, install_path, register_func):\n    rsession = requests.Session()\n    rsession.mount(\"https://\", HTTPAdapter(max_retries=3))\n\n    logger.debug(\"trying to install %s from online repo\", pkgname)\n    pkgurl = \"{}/{}s/{}.zip\".format(defs.GITHUB_RAW, plugin_type, pkgname)\n    try:\n        logger.debug(\"Requesting HTTP HEAD: %s\", pkgurl)\n        r = rsession.head(pkgurl)\n        r.raise_for_status()\n        total_size = int(r.headers.get(\"content-length\", 0))\n        pkgsize = _sizeof_fmt(total_size)\n        with click.progressbar(length=total_size, label=\"Downloading {} {} ({})..\"\n                               .format(plugin_type, pkgname, pkgsize)) as bar:\n            r = rsession.get(pkgurl, stream=True)\n            with tempfile.NamedTemporaryFile(delete=False) as f:\n                downloaded_bytes = 0\n                for chunk in r.iter_content(chunk_size=1):  # TODO: Consider increasing to reduce cycles\n                    if chunk:\n                        f.write(chunk)\n                        downloaded_bytes += len(chunk)\n                        bar.update(downloaded_bytes)\n        return install_from_zip(f.name, install_path, register_func, delete_after_install=True)\n    except requests.exceptions.HTTPError as exc:\n        logger.debug(str(exc))\n        raise exceptions.PluginNotFoundInOnlineRepo(pkgname)\n    except requests.exceptions.ConnectionError as exc:\n        logger.debug(str(exc))\n        raise exceptions.PluginRepoConnectionError()", "response": "Install plugin from online repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_remote_plugins(installed_plugins, plugin_type):\n    click.secho(\"\\n[*] Additional plugins from online repository:\")\n    try:\n        rsession = requests.Session()\n        rsession.mount(\"https://\", HTTPAdapter(max_retries=3))\n\n        r = rsession.get(\"{0}/{1}s/{1}s.txt\".format(defs.GITHUB_RAW, plugin_type))\n        logger.debug(\"fetching %ss from remote repo\", plugin_type)\n        plugins = [_ for _ in r.text.splitlines() if _ not in installed_plugins]\n        click.secho(\" \".join(plugins))\n\n    except requests.exceptions.ConnectionError as exc:\n        logger.debug(str(exc), exc_info=True)\n        raise click.ClickException(\"Unable to fetch {} information from online repository\".format(plugin_type))", "response": "List remote plugins from online repo."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist local plugins with details.", "response": "def list_local_plugins(plugin_type, plugins_path, plugin_details):\n    \"\"\"List local plugins with details.\"\"\"\n    installed_plugins = list()\n    for plugin in next(os.walk(plugins_path))[1]:\n        s = plugin_details(plugin)\n        installed_plugins.append(plugin)\n        click.secho(s)\n\n    if not installed_plugins:\n        click.secho(\"[*] You do not have any {0}s installed, \"\n                    \"try installing one with `honeycomb {0} install`\".format(plugin_type))\n\n    return installed_plugins"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse command line arguments based on the plugin s parameters config. json.", "response": "def parse_plugin_args(command_args, config_args):\n    \"\"\"Parse command line arguments based on the plugin's parameters config.\n\n    :param command_args: Command line arguments as provided by the user in `key=value` format.\n    :param config_args: Plugin parameters parsed from config.json.\n\n    :returns: Validated dictionary of parameters that will be passed to plugin class\n    \"\"\"\n    parsed_args = dict()\n    for arg in command_args:\n        kv = arg.split(\"=\")\n        if len(kv) != 2:\n            raise click.UsageError(\"Invalid parameter '{}', must be in key=value format\".format(arg))\n        parsed_args[kv[0]] = config_utils.get_truetype(kv[1])\n\n    for arg in config_args:\n        value = arg[defs.VALUE]\n        value_type = arg[defs.TYPE]\n        if value in parsed_args:\n            # will raise if invalid\n            config_utils.validate_field_matches_type(value, parsed_args[value], value_type,\n                                                     arg.get(defs.ITEMS), arg.get(defs.MIN), arg.get(defs.MAX))\n        elif defs.DEFAULT in arg:  # Has a default field\n            # return default values for unset parameters\n            parsed_args[value] = arg[defs.DEFAULT]\n        elif arg[defs.REQUIRED]:  # requires field is true\n            \"\"\"parameter was not supplied by user, but it's required and has no default value\"\"\"\n            raise exceptions.RequiredFieldMissing(value)\n    return parsed_args"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of possible select items.", "response": "def get_select_items(items):\n    \"\"\"Return list of possible select items.\"\"\"\n    option_items = list()\n    for item in items:\n        if isinstance(item, dict) and defs.VALUE in item and defs.LABEL in item:\n            option_items.append(item[defs.VALUE])\n        else:\n            raise exceptions.ParametersFieldError(item, \"a dictionary with {} and {}\"\n                                                  .format(defs.LABEL, defs.VALUE))\n    return option_items"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_plugin_args(plugin_path):\n    args = config_utils.get_config_parameters(plugin_path)\n    args_format = \"{:20} {:10} {:^15} {:^10} {:25}\"\n    title = args_format.format(defs.NAME.upper(), defs.TYPE.upper(), defs.DEFAULT.upper(),\n                               defs.REQUIRED.upper(), defs.DESCRIPTION.upper())\n    click.secho(title)\n    click.secho(\"-\" * len(title))\n    for arg in args:\n        help_text = \" ({})\".format(arg[defs.HELP_TEXT]) if defs.HELP_TEXT in arg else \"\"\n        options = _parse_select_options(arg)\n        description = arg[defs.LABEL] + options + help_text\n        click.secho(args_format.format(arg[defs.VALUE], arg[defs.TYPE], str(arg.get(defs.DEFAULT, None)),\n                                       str(arg.get(defs.REQUIRED, False)), description))", "response": "Print plugin parameters table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show(ctx, service, remote):\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    service_path = plugin_utils.get_plugin_path(home, defs.SERVICES, service)\n\n    def collect_local_info(service, service_path):\n        logger.debug(\"loading {} from {}\".format(service, service_path))\n        service = register_service(service_path)\n        try:\n            with open(os.path.join(service_path, \"requirements.txt\"), \"r\") as fh:\n                info[\"requirements\"] = \" \".join(fh.readlines())\n        except IOError:\n            pass\n        info[\"name\"] = service.name\n        info[\"label\"] = service.label\n        info[\"location\"] = service_path\n\n        return info\n\n    def collect_remote_info(service):\n        rsession = requests.Session()\n        rsession.mount(\"https://\", HTTPAdapter(max_retries=3))\n\n        try:\n            r = rsession.get(defs.GITHUB_RAW_URL.format(plugin_type=defs.SERVICES,\n                                                        plugin=service, filename=\"config.json\"))\n            service_config = r.json()\n            info[\"name\"] = service_config[defs.SERVICE][defs.NAME]\n            info[\"label\"] = service_config[defs.SERVICE][defs.LABEL]\n            info[\"location\"] = defs.GITHUB_URL.format(plugin_type=defs.SERVICES, plugin=info[\"name\"])\n        except requests.exceptions.HTTPError as exc:\n            logger.debug(str(exc), exc_info=True)\n            raise click.ClickException(\"Cannot find package {}\".format(service))\n        except requests.exceptions.ConnectionError as exc:\n            logger.debug(str(exc), exc_info=True)\n            raise click.ClickException(\"Unable to reach remote repository {}\".format(service))\n\n        try:\n            r = rsession.get(defs.GITHUB_RAW_URL.format(plugin_type=defs.SERVICES, plugin=info[\"name\"],\n                                                        filename=\"requirements.txt\"))\n            r.raise_for_status()\n            info[\"requirements\"] = \" \".join(r.text.split(\"\\n\"))\n        except requests.exceptions.HTTPError as exc:\n            logger.debug(str(exc), exc_info=True)\n            info[\"requirements\"] = None\n        except requests.exceptions.ConnectionError as exc:\n            logger.debug(str(exc), exc_info=True)\n            raise click.ClickException(\"Unable to reach remote repository {}\".format(service))\n\n        return info\n\n    info = {\"commit_revision\": \"N/A\", \"commit_date\": \"N/A\", \"requirements\": \"None\"}\n\n    if os.path.exists(service_path):\n        info[\"installed\"] = True\n        if remote:\n            click.secho(\"[*] Fetching info from online repository\")\n            info.update(collect_remote_info(service))\n        else:\n            info.update(collect_local_info(service, service_path))\n    else:\n        logger.debug(\"cannot find {} locally\".format(service))\n        if not remote:\n            click.secho(\"[*] Cannot find service locally, checking online repository\")\n        info[\"installed\"] = False\n        info.update(collect_remote_info(service))\n    logger.debug(info)\n    click.secho(PKG_INFO_TEMPLATE.format(**info))", "response": "Show detailed information about a package."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef configure_integration(path):\n    integration = register_integration(path)\n    integration_args = {}\n    try:\n        with open(os.path.join(path, ARGS_JSON)) as f:\n            integration_args = json.loads(f.read())\n    except Exception as exc:\n        logger.debug(str(exc), exc_info=True)\n        raise click.ClickException(\"Cannot load {} integration args, please configure it first.\"\n                                   .format(os.path.basename(path)))\n\n    click.secho(\"[*] Adding integration {}\".format(integration.name))\n    logger.debug(\"Adding integration %s\", integration.name,\n                 extra={\"integration\": integration.name, \"args\": integration_args})\n    configured_integration = ConfiguredIntegration(name=integration.name, integration=integration, path=path)\n    configured_integration.data = integration_args\n    configured_integration.integration.module = get_integration_module(path).IntegrationActionsClass(integration_args)\n\n    configured_integrations.append(configured_integration)", "response": "Configure and enable an integration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend Alert to relevant integrations.", "response": "def send_alert_to_subscribed_integrations(alert):\n    \"\"\"Send Alert to relevant integrations.\"\"\"\n    valid_configured_integrations = get_valid_configured_integrations(alert)\n\n    for configured_integration in valid_configured_integrations:\n        threading.Thread(target=create_integration_alert_and_call_send, args=(alert, configured_integration)).start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of relevant integrations for alert filtered by alert_type.", "response": "def get_valid_configured_integrations(alert):\n    \"\"\"Return a list of integrations for alert filtered by alert_type.\n\n    :returns: A list of relevant integrations\n    \"\"\"\n    if not configured_integrations:\n        return []\n\n    # Collect all integrations that are configured for specific alert_type\n    # or have no specific supported_event_types (i.e., all alert types)\n    valid_configured_integrations = [\n        _ for _ in configured_integrations if _.integration.integration_type == IntegrationTypes.EVENT_OUTPUT.name and\n        (not _.integration.supported_event_types or alert.alert_type in _.integration.supported_event_types)\n    ]\n\n    return valid_configured_integrations"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_integration_alert_and_call_send(alert, configured_integration):\n    integration_alert = IntegrationAlert(\n        alert=alert,\n        configured_integration=configured_integration,\n        status=IntegrationAlertStatuses.PENDING.name,\n        retries=configured_integration.integration.max_send_retries\n    )\n\n    send_alert_to_configured_integration(integration_alert)", "response": "Create an IntegrationAlert object and send it to the configured integration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_alert_to_configured_integration(integration_alert):\n    try:\n        alert = integration_alert.alert\n        configured_integration = integration_alert.configured_integration\n        integration = configured_integration.integration\n        integration_actions_instance = configured_integration.integration.module\n\n        alert_fields = dict()\n        if integration.required_fields:\n            if not all([hasattr(alert, _) for _ in integration.required_fields]):\n                logger.debug(\"Alert does not have all required_fields (%s) for integration %s, skipping\",\n                             integration.required_fields,\n                             integration.name)\n                return\n\n        exclude_fields = [\"alert_type\", \"service_type\"]\n        alert_fields = {}\n        for field in alert.__slots__:\n            if hasattr(alert, field) and field not in exclude_fields:\n                alert_fields[field] = getattr(alert, field)\n\n        logger.debug(\"Sending alert %s to %s\", alert_fields, integration.name)\n        output_data, output_file_content = integration_actions_instance.send_event(alert_fields)\n\n        if integration.polling_enabled:\n            integration_alert.status = IntegrationAlertStatuses.POLLING.name\n            polling_integration_alerts.append(integration_alert)\n        else:\n            integration_alert.status = IntegrationAlertStatuses.DONE.name\n\n        integration_alert.send_time = get_current_datetime_utc()\n        integration_alert.output_data = json.dumps(output_data)\n        # TODO: do something with successfully handled alerts? They are all written to debug log file\n\n    except exceptions.IntegrationMissingRequiredFieldError as exc:\n        logger.exception(\"Send response formatting for integration alert %s failed. Missing required fields\",\n                         integration_alert,\n                         exc.message)\n\n        integration_alert.status = IntegrationAlertStatuses.ERROR_MISSING_SEND_FIELDS.name\n\n    except exceptions.IntegrationOutputFormatError:\n        logger.exception(\"Send response formatting for integration alert %s failed\", integration_alert)\n\n        integration_alert.status = IntegrationAlertStatuses.ERROR_SENDING_FORMATTING.name\n\n    except exceptions.IntegrationSendEventError as exc:\n        integration_send_retries = integration_alert.retries if integration_alert.retries <= MAX_SEND_RETRIES \\\n            else MAX_SEND_RETRIES  # making sure we do not exceed celery max retries\n        send_retries_left = integration_send_retries - 1\n        integration_alert.retries = send_retries_left\n\n        logger.error(\"Sending integration alert %s failed. Message: %s. Retries left: %s\",\n                     integration_alert,\n                     exc.message,\n                     send_retries_left)\n\n        if send_retries_left == 0:\n            integration_alert.status = IntegrationAlertStatuses.ERROR_SENDING.name\n\n        if send_retries_left > 0:\n            sleep(SEND_ALERT_DATA_INTERVAL)\n            send_alert_to_configured_integration(integration_alert)", "response": "Send an IntegrationAlert to the configured integration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npoll the integration information for waiting integration alerts.", "response": "def poll_integration_information_for_waiting_integration_alerts():\n    \"\"\"poll_integration_information_for_waiting_integration_alerts.\"\"\"\n    if not polling_integration_alerts:\n        return\n\n    logger.debug(\"Polling information for waiting integration alerts\")\n\n    for integration_alert in polling_integration_alerts:\n        configured_integration = integration_alert.configured_integration\n        integration = configured_integration.integration\n        polling_duration = integration.polling_duration\n\n        if get_current_datetime_utc() - integration_alert.send_time > polling_duration:\n            logger.debug(\"Polling duration expired for integration alert %s\", integration_alert)\n            integration_alert.status = IntegrationAlertStatuses.ERROR_POLLING.name\n        else:\n            integration_alert.status = IntegrationAlertStatuses.IN_POLLING.name\n\n            poll_integration_alert_data(integration_alert)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef poll_integration_alert_data(integration_alert):\n    logger.info(\"Polling information for integration alert %s\", integration_alert)\n    try:\n        configured_integration = integration_alert.configured_integration\n        integration_actions_instance = configured_integration.integration.module\n\n        output_data, output_file_content = integration_actions_instance.poll_for_updates(\n            json.loads(integration_alert.output_data)\n        )\n\n        integration_alert.status = IntegrationAlertStatuses.DONE.name\n        integration_alert.output_data = json.dumps(output_data)\n        polling_integration_alerts.remove(integration_alert)\n\n    except exceptions.IntegrationNoMethodImplementationError:\n        logger.error(\"No poll_for_updates function found for integration alert %s\", integration_alert)\n\n        integration_alert.status = IntegrationAlertStatuses.ERROR_POLLING.name\n\n    except exceptions.IntegrationPollEventError:\n        # This does not always indicate an error, this is also raised when need to try again later\n        logger.debug(\"Polling for integration alert %s failed\", integration_alert)\n\n    except exceptions.IntegrationOutputFormatError:\n        logger.error(\"Integration alert %s formatting error\", integration_alert)\n\n        integration_alert.status = IntegrationAlertStatuses.ERROR_POLLING_FORMATTING.name\n\n    except Exception:\n        logger.exception(\"Error polling integration alert %s\", integration_alert)\n\n        integration_alert.status = IntegrationAlertStatuses.ERROR_POLLING.name", "response": "Poll for updates on waiting IntegrationAlerts."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows status of installed service ( s ).", "response": "def status(ctx, services, show_all):\n    \"\"\"Show status of installed service(s).\"\"\"\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    services_path = os.path.join(home, SERVICES)\n\n    def print_status(service):\n        service_dir = os.path.join(services_path, service)\n        if os.path.exists(service_dir):\n            pidfile = service_dir + \".pid\"\n            if os.path.exists(pidfile):\n                try:\n                    with open(pidfile) as fh:\n                        pid = int(fh.read().strip())\n                    os.kill(pid, 0)\n                    status = \"running (pid: {})\".format(pid)\n                except OSError:\n                    status = \"not running (stale pidfile)\"\n            else:\n                status = \"not running\"\n        else:\n            status = \"no such service\"\n        click.secho(\"{} - {}\".format(service, status))\n\n    if show_all:\n        for service in next(os.walk(services_path))[1]:\n            print_status(service)\n    elif services:\n        for service in services:\n            print_status(service)\n    else:\n        raise click.UsageError(\"You must specify a service name or use --show-all\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns a function in a loop until the result or timeout occurs.", "response": "def wait_until(func,\n               check_return_value=True,\n               total_timeout=60,\n               interval=0.5,\n               exc_list=None,\n               error_message=\"\",\n               *args,\n               **kwargs):\n    \"\"\"Run a command in a loop until desired result or timeout occurs.\n\n    :param func: Function to call and wait for\n    :param bool check_return_value: Examine return value\n    :param int total_timeout: Wait timeout,\n    :param float interval: Sleep interval between retries\n    :param list exc_list: Acceptable exception list\n    :param str error_message: Default error messages\n    :param args: args to pass to func\n    :param kwargs: lwargs to pass to fun\n    \"\"\"\n    start_function = time.time()\n    while time.time() - start_function < total_timeout:\n\n        try:\n            logger.debug(\"executing {} with args {} {}\".format(func, args, kwargs))\n            return_value = func(*args, **kwargs)\n            if not check_return_value or (check_return_value and return_value):\n                return return_value\n\n        except Exception as exc:\n            if exc_list and any([isinstance(exc, x) for x in exc_list]):\n                pass\n            else:\n                raise\n\n        time.sleep(interval)\n\n    raise TimeoutException(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch json log file for a key = value pair.", "response": "def search_json_log(filepath, key, value):\n    \"\"\"Search json log file for a key=value pair.\n\n    :param filepath: Valid path to a json file\n    :param key: key to match\n    :param value: value to match\n    :returns: First matching line in json log file, parsed by :py:func:`json.loads`\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as fh:\n            for line in fh.readlines():\n                    log = json.loads(line)\n                    if key in log and log[key] == value:\n                        return log\n    except IOError:\n        pass\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists commands from folder.", "response": "def list_commands(self, ctx):\n        \"\"\"List commands from folder.\"\"\"\n        rv = []\n        files = [_ for _ in next(os.walk(self.folder))[2] if not _.startswith(\"_\") and _.endswith(\".py\")]\n        for filename in files:\n            rv.append(filename[:-3])\n        rv.sort()\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_command(self, ctx, name):\n        plugin = os.path.basename(self.folder)\n        try:\n            command = importlib.import_module(\"honeycomb.commands.{}.{}\".format(plugin, name))\n        except ImportError:\n            raise click.UsageError(\"No such command {} {}\\n\\n{}\".format(plugin, name, self.get_help(ctx)))\n        return getattr(command, name)", "response": "Fetch command from folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, home, iamroot, config, verbose):\n    _mkhome(home)\n    setup_logging(home, verbose)\n\n    logger.debug(\"Honeycomb v%s\", __version__, extra={\"version\": __version__})\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    try:\n        is_admin = os.getuid() == 0\n    except AttributeError:\n        is_admin = ctypes.windll.shell32.IsUserAnAdmin()\n\n    if is_admin:\n        if not iamroot:\n            raise click.ClickException(\"Honeycomb should not run as a privileged user, if you are just \"\n                                       \"trying to bind to a low port try running `setcap 'cap_net_bind_service=+ep' \"\n                                       \"$(which honeycomb)` instead. If you insist, use --iamroot\")\n        logger.warn(\"running as root!\")\n\n    ctx.obj[\"HOME\"] = home\n\n    logger.debug(\"ctx: {}\".format(ctx.obj))\n\n    if config:\n        return process_config(ctx, config)", "response": "Honeypot is a honeypot framework."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconfigure logging for honeycomb.", "response": "def setup_logging(home, verbose):\n    \"\"\"Configure logging for honeycomb.\"\"\"\n    logging.setLoggerClass(MyLogger)\n    logging.config.dictConfig({\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"console\": {\n                \"format\": \"%(levelname)-8s [%(asctime)s %(name)s] %(filename)s:%(lineno)s %(funcName)s: %(message)s\",\n            },\n            \"json\": {\n                \"()\": jsonlogger.JsonFormatter,\n                \"format\": \"%(levelname)s %(asctime)s %(name)s %(filename)s %(lineno)s %(funcName)s %(message)s\",\n            },\n        },\n        \"handlers\": {\n            \"default\": {\n                \"level\": \"DEBUG\" if verbose else \"INFO\",\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"console\",\n            },\n            \"file\": {\n                \"level\": \"DEBUG\",\n                \"class\": \"logging.handlers.WatchedFileHandler\",\n                \"filename\": os.path.join(home, DEBUG_LOG_FILE),\n                \"formatter\": \"json\",\n            },\n        },\n        \"loggers\": {\n            \"\": {\n                \"handlers\": [\"default\", \"file\"],\n                \"level\": \"DEBUG\",\n                \"propagate\": True,\n            },\n        }\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makeRecord(self, name, level, fn, lno, msg, args, exc_info, func=None, extra=None, sinfo=None):\n        # See below commented section for a simple example of what the docstring refers to\n        if six.PY2:\n            rv = logging.LogRecord(name, level, fn, lno, msg, args, exc_info, func)\n        else:\n            rv = logging.LogRecord(name, level, fn, lno, msg, args, exc_info, func, sinfo)\n\n        if extra is None:\n            extra = dict()\n        extra.update({\"pid\": os.getpid(), \"uid\": os.getuid(), \"gid\": os.getgid(), \"ppid\": os.getppid()})\n\n        for key in extra:\n            # if (key in [\"message\", \"asctime\"]) or (key in rv.__dict__):\n            #     raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\n            rv.__dict__[key] = extra[key]\n        return rv", "response": "Override default logger to allow overriding of internal attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops a running service daemon.", "response": "def stop(ctx, service, editable):\n    \"\"\"Stop a running service daemon.\"\"\"\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    service_path = plugin_utils.get_plugin_path(home, SERVICES, service, editable)\n\n    logger.debug(\"loading {}\".format(service))\n    service = register_service(service_path)\n\n    try:\n        with open(os.path.join(service_path, ARGS_JSON)) as f:\n            service_args = json.loads(f.read())\n    except IOError as exc:\n        logger.debug(str(exc), exc_info=True)\n        raise click.ClickException(\"Cannot load service args, are you sure server is running?\")\n\n    # get our service class instance\n    service_module = get_service_module(service_path)\n    service_obj = service_module.service_class(alert_types=service.alert_types, service_args=service_args)\n\n    # prepare runner\n    runner = myRunner(service_obj,\n                      pidfile=service_path + \".pid\",\n                      stdout=open(os.path.join(service_path, \"stdout.log\"), \"ab\"),\n                      stderr=open(os.path.join(service_path, \"stderr.log\"), \"ab\"))\n\n    click.secho(\"[*] Stopping {}\".format(service.name))\n    try:\n        runner._stop()\n    except daemon.runner.DaemonRunnerStopFailureError as exc:\n        logger.debug(str(exc), exc_info=True)\n        raise click.ClickException(\"Unable to stop service, are you sure it is running?\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing detailed information about a package.", "response": "def show(ctx, integration, remote):\n    \"\"\"Show detailed information about a package.\"\"\"\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    integration_path = plugin_utils.get_plugin_path(home, defs.INTEGRATIONS, integration)\n\n    def collect_local_info(integration, integration_path):\n        logger.debug(\"loading {} from {}\".format(integration, integration_path))\n        integration = register_integration(integration_path)\n        try:\n            with open(os.path.join(integration_path, \"requirements.txt\"), \"r\") as fh:\n                info[\"requirements\"] = \" \".join(fh.readlines())\n        except IOError:\n            pass\n        info[\"name\"] = integration.name\n        info[\"label\"] = integration.label\n        info[\"location\"] = integration_path\n\n        return info\n\n    def collect_remote_info(integration):\n        rsession = requests.Session()\n        rsession.mount(\"https://\", HTTPAdapter(max_retries=3))\n\n        try:\n            r = rsession.get(defs.GITHUB_RAW_URL.format(plugin_type=defs.INTEGRATIONS,\n                                                        plugin=integration, filename=\"config.json\"))\n            integration_config = r.json()\n            info[\"name\"] = integration_config[DISPLAY_NAME]\n            info[\"label\"] = integration_config[defs.DESCRIPTION]\n            info[\"location\"] = defs.GITHUB_URL.format(plugin_type=defs.INTEGRATIONS, plugin=info[\"name\"])\n        except requests.exceptions.HTTPError as exc:\n            logger.debug(str(exc), exc_info=True)\n            raise click.ClickException(\"Cannot find package {}\".format(integration))\n        except requests.exceptions.ConnectionError as exc:\n            logger.debug(str(exc), exc_info=True)\n            raise click.ClickException(\"Unable to reach remote repository {}\".format(integration))\n\n        try:\n            r = rsession.get(defs.GITHUB_RAW_URL.format(plugin_type=defs.INTEGRATIONS,\n                             plugin=info[\"name\"], filename=\"requirements.txt\"))\n            r.raise_for_status()\n            info[\"requirements\"] = \" \".join(r.text.split(\"\\n\"))\n        except requests.exceptions.HTTPError as exc:\n            logger.debug(str(exc), exc_info=True)\n            info[\"requirements\"] = None\n        except requests.exceptions.ConnectionError as exc:\n            logger.debug(str(exc), exc_info=True)\n            raise click.ClickException(\"Unable to reach remote repository {}\".format(integration))\n\n        return info\n\n    info = {\"commit_revision\": \"N/A\", \"commit_date\": \"N/A\", \"requirements\": \"None\"}\n\n    if os.path.exists(integration_path):\n        info[\"installed\"] = True\n        if remote:\n            click.secho(\"[*] Fetching info from online repository\")\n            info.update(collect_remote_info(integration))\n        else:\n            info.update(collect_local_info(integration, integration_path))\n    else:\n        logger.debug(\"cannot find {} locally\".format(integration))\n        if not remote:\n            click.secho(\"[*] Cannot find integration locally, checking online repository\")\n        info[\"installed\"] = False\n        info.update(collect_remote_info(integration))\n    logger.debug(info)\n    click.secho(PKG_INFO_TEMPLATE.format(**info))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logs(ctx, services, num, follow):\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    services_path = os.path.join(home, SERVICES)\n\n    tail_threads = []\n    for service in services:\n        logpath = os.path.join(services_path, service, LOGS_DIR, STDOUTLOG)\n        if os.path.exists(logpath):\n            logger.debug(\"tailing %s\", logpath)\n            # TODO: Print log lines from multiple services sorted by timestamp\n            t = threading.Thread(target=Tailer, kwargs={\"name\": service,\n                                                        \"nlines\": num,\n                                                        \"filepath\": logpath,\n                                                        \"follow\": follow})\n            t.daemon = True\n            t.start()\n            tail_threads.append(t)\n\n    if tail_threads:\n        while tail_threads[0].isAlive():\n            tail_threads[0].join(0.1)", "response": "Show logs of daemonized services."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_integration_module(integration_path):\n    # add custom paths so imports would work\n    paths = [\n        os.path.join(__file__, \"..\", \"..\"),  # to import integrationmanager\n        os.path.join(integration_path, \"..\"),  # to import integration itself\n        os.path.join(integration_path, DEPS_DIR),  # to import integration deps\n    ]\n\n    for path in paths:\n        path = os.path.realpath(path)\n        logger.debug(\"adding %s to path\", path)\n        sys.path.insert(0, path)\n\n    # get our integration class instance\n    integration_name = os.path.basename(integration_path)\n    logger.debug(\"importing %s\", \".\".join([integration_name, INTEGRATION]))\n    return importlib.import_module(\".\".join([integration_name, INTEGRATION]))", "response": "Get the integration module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a honeycomb integration.", "response": "def register_integration(package_folder):\n    \"\"\"Register a honeycomb integration.\n\n    :param package_folder: Path to folder with integration to load\n    :returns: Validated integration object\n    :rtype: :func:`honeycomb.utils.defs.Integration`\n    \"\"\"\n    logger.debug(\"registering integration %s\", package_folder)\n    package_folder = os.path.realpath(package_folder)\n    if not os.path.exists(package_folder):\n        raise IntegrationNotFound(os.path.basename(package_folder))\n\n    json_config_path = os.path.join(package_folder, CONFIG_FILE_NAME)\n    if not os.path.exists(json_config_path):\n        raise ConfigFileNotFound(json_config_path)\n\n    with open(json_config_path, \"r\") as f:\n        config_json = json.load(f)\n\n    # Validate integration and alert config\n    validate_config(config_json, defs.INTEGRATION_VALIDATE_CONFIG_FIELDS)\n    validate_config_parameters(config_json,\n                               defs.INTEGRATION_PARAMETERS_ALLOWED_KEYS,\n                               defs.INTEGRATION_PARAMETERS_ALLOWED_TYPES)\n\n    integration_type = _create_integration_object(config_json)\n\n    return integration_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads and run a specific service.", "response": "def run(ctx, service, args, show_args, daemon, editable, integration):\n    \"\"\"Load and run a specific service.\"\"\"\n    home = ctx.obj[\"HOME\"]\n    service_path = plugin_utils.get_plugin_path(home, SERVICES, service, editable)\n    service_log_path = os.path.join(service_path, LOGS_DIR)\n\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    logger.debug(\"loading {} ({})\".format(service, service_path))\n    service = register_service(service_path)\n\n    if show_args:\n        return plugin_utils.print_plugin_args(service_path)\n\n    # get our service class instance\n    service_module = get_service_module(service_path)\n    service_args = plugin_utils.parse_plugin_args(args, config_utils.get_config_parameters(service_path))\n    service_obj = service_module.service_class(alert_types=service.alert_types, service_args=service_args)\n\n    if not os.path.exists(service_log_path):\n        os.mkdir(service_log_path)\n\n    # prepare runner\n    if daemon:\n        runner = myRunner(service_obj,\n                          pidfile=service_path + \".pid\",\n                          stdout=open(os.path.join(service_log_path, STDOUTLOG), \"ab\"),\n                          stderr=open(os.path.join(service_log_path, STDERRLOG), \"ab\"))\n\n        files_preserve = []\n        for handler in logging.getLogger().handlers:\n            if hasattr(handler, \"stream\"):\n                if hasattr(handler.stream, \"fileno\"):\n                    files_preserve.append(handler.stream.fileno())\n            if hasattr(handler, \"socket\"):\n                files_preserve.append(handler.socket.fileno())\n\n        runner.daemon_context.files_preserve = files_preserve\n        runner.daemon_context.signal_map.update({\n            signal.SIGTERM: service_obj._on_server_shutdown,\n            signal.SIGINT: service_obj._on_server_shutdown,\n        })\n        logger.debug(\"daemon_context\", extra={\"daemon_context\": vars(runner.daemon_context)})\n\n    for integration_name in integration:\n        integration_path = plugin_utils.get_plugin_path(home, INTEGRATIONS, integration_name, editable)\n        configure_integration(integration_path)\n\n    click.secho(\"[+] Launching {} {}\".format(service.name, \"in daemon mode\" if daemon else \"\"))\n    try:\n        # save service_args for external reference (see test)\n        with open(os.path.join(service_path, ARGS_JSON), \"w\") as f:\n            f.write(json.dumps(service_args))\n        runner._start() if daemon else service_obj.run()\n    except KeyboardInterrupt:\n        service_obj._on_server_shutdown()\n\n    click.secho(\"[*] {} has stopped\".format(service.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads lines from file.", "response": "def read_lines(self, file_path, empty_lines=False, signal_ready=True):\n        \"\"\"Fetch lines from file.\n\n        In case the file handler changes (logrotate), reopen the file.\n\n        :param file_path: Path to file\n        :param empty_lines: Return empty lines\n        :param signal_ready: Report signal ready on start\n        \"\"\"\n        file_handler, file_id = self._get_file(file_path)\n        file_handler.seek(0, os.SEEK_END)\n\n        if signal_ready:\n            self.signal_ready()\n\n        while self.thread_server.is_alive():\n            line = six.text_type(file_handler.readline(), \"utf-8\")\n            if line:\n                yield line\n                continue\n            elif empty_lines:\n                yield line\n\n            time.sleep(0.1)\n\n            if file_id != self._get_file_id(os.stat(file_path)) and os.path.isfile(file_path):\n                file_handler, file_id = self._get_file(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nservice run loop function. Run the desired docker container with parameters and start parsing the monitored file for alerts.", "response": "def on_server_start(self):\n        \"\"\"Service run loop function.\n\n        Run the desired docker container with parameters and start parsing the monitored file for alerts.\n        \"\"\"\n        self._container = self._docker_client.containers.run(self.docker_image_name, detach=True, **self.docker_params)\n        self.signal_ready()\n\n        for log_line in self.get_lines():\n            try:\n                alert_dict = self.parse_line(log_line)\n                if alert_dict:\n                    self.add_alert_to_queue(alert_dict)\n            except Exception:\n                self.logger.exception(None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops the container before shutting down.", "response": "def on_server_shutdown(self):\n        \"\"\"Stop the container before shutting down.\"\"\"\n        if not self._container:\n            return\n        self._container.stop()\n        self._container.remove(v=True, force=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef uninstall(ctx, yes, integrations):\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n\n    for integration in integrations:\n        integration_path = plugin_utils.get_plugin_path(home, INTEGRATIONS, integration)\n        plugin_utils.uninstall_plugin(integration_path, yes)", "response": "Uninstall a single integration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install(ctx, services, delete_after_install=False):\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    services_path = os.path.join(home, SERVICES)\n\n    installed_all_plugins = True\n    for service in services:\n        try:\n            plugin_utils.install_plugin(service, SERVICE, services_path, register_service)\n        except exceptions.PluginAlreadyInstalled as exc:\n            click.echo(exc)\n            installed_all_plugins = False\n\n    if not installed_all_plugins:\n        raise ctx.exit(errno.EEXIST)", "response": "Install a honeypot service from the online library local path or zipfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the service module.", "response": "def get_service_module(service_path):\n    \"\"\"Add custom paths to sys and import service module.\n\n    :param service_path: Path to service folder\n    \"\"\"\n    # add custom paths so imports would work\n    paths = [\n        os.path.dirname(__file__),  # this folder, to catch base_service\n        os.path.realpath(os.path.join(service_path, \"..\")),  # service's parent folder for import\n        os.path.realpath(os.path.join(service_path)),  # service's folder for local imports\n        os.path.realpath(os.path.join(service_path, DEPS_DIR)),  # deps dir\n    ]\n\n    for path in paths:\n        path = os.path.realpath(path)\n        logger.debug(\"adding %s to path\", path)\n        sys.path.insert(0, path)\n\n    # get our service class instance\n    service_name = os.path.basename(service_path)\n    module = \".\".join([service_name, service_name + \"_service\"])\n    logger.debug(\"importing %s\", module)\n    return importlib.import_module(module)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_service(package_folder):\n    logger.debug(\"registering service %s\", package_folder)\n    package_folder = os.path.realpath(package_folder)\n    if not os.path.exists(package_folder):\n        raise ServiceNotFound(os.path.basename(package_folder))\n\n    json_config_path = os.path.join(package_folder, CONFIG_FILE_NAME)\n    if not os.path.exists(json_config_path):\n        raise ConfigFileNotFound(json_config_path)\n\n    with open(json_config_path, \"r\") as f:\n        config_json = json.load(f)\n\n    # Validate service and alert config\n    config_utils.validate_config(config_json, defs.SERVICE_ALERT_VALIDATE_FIELDS)\n\n    config_utils.validate_config(config_json.get(defs.SERVICE_CONFIG_SECTION_KEY, {}),\n                                 defs.SERVICE_CONFIG_VALIDATE_FIELDS)\n    _validate_supported_platform(config_json)\n    _validate_alert_configs(config_json)\n    config_utils.validate_config_parameters(config_json,\n                                            defs.SERVICE_ALLOWED_PARAMTER_KEYS,\n                                            defs.SERVICE_ALLOWED_PARAMTER_TYPES)\n\n    service_type = _create_service_object(config_json)\n    service_type.alert_types = _create_alert_types(config_json, service_type)\n\n    return service_type", "response": "Register a service in a folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install(ctx, integrations, delete_after_install=False):\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    home = ctx.obj[\"HOME\"]\n    integrations_path = os.path.join(home, INTEGRATIONS)\n\n    installed_all_plugins = True\n    for integration in integrations:\n        try:\n            plugin_utils.install_plugin(integration, INTEGRATION, integrations_path, register_integration)\n        except exceptions.PluginAlreadyInstalled as exc:\n            click.echo(exc)\n            installed_all_plugins = False\n\n    if not installed_all_plugins:\n        raise ctx.exit(errno.EEXIST)", "response": "Install a honeycomb integration from the online library local path or zipfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures an integration with default parameters.", "response": "def configure(ctx, integration, args, show_args, editable):\n    \"\"\"Configure an integration with default parameters.\n\n    You can still provide one-off integration arguments to :func:`honeycomb.commands.service.run` if required.\n    \"\"\"\n    home = ctx.obj[\"HOME\"]\n    integration_path = plugin_utils.get_plugin_path(home, defs.INTEGRATIONS, integration, editable)\n\n    logger.debug(\"running command %s (%s)\", ctx.command.name, ctx.params,\n                 extra={\"command\": ctx.command.name, \"params\": ctx.params})\n\n    logger.debug(\"loading {} ({})\".format(integration, integration_path))\n    integration = register_integration(integration_path)\n\n    if show_args:\n        return plugin_utils.print_plugin_args(integration_path)\n\n    # get our integration class instance\n    integration_args = plugin_utils.parse_plugin_args(args, config_utils.get_config_parameters(integration_path))\n\n    args_file = os.path.join(integration_path, defs.ARGS_JSON)\n    with open(args_file, \"w\") as f:\n        data = json.dumps(integration_args)\n        logger.debug(\"writing %s to %s\", data, args_file)\n        f.write(json.dumps(integration_args))\n\n    click.secho(\"[*] {0} has been configured, make sure to test it with `honeycomb integration test {0}`\"\n                .format(integration.name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_match_history(self, account_id=None, **kwargs):\n        if 'account_id' not in kwargs:\n            kwargs['account_id'] = account_id\n        url = self.__build_url(urls.GET_MATCH_HISTORY, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)", "response": "Returns a dictionary containing a list of the most recent Dota matches for the given account."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_match_history_by_seq_num(self, start_at_match_seq_num=None, **kwargs):\n        if 'start_at_match_seq_num' not in kwargs:\n            kwargs['start_at_match_seq_num'] = start_at_match_seq_num\n        url = self.__build_url(urls.GET_MATCH_HISTORY_BY_SEQ_NUM, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)", "response": "Returns a dictionary containing a list of Dota matches in the order they were recorded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary containing the details for a Dota 2 match.", "response": "def get_match_details(self, match_id=None, **kwargs):\n        \"\"\"Returns a dictionary containing the details for a Dota 2 match\n\n        :param match_id: (int, optional)\n        :return: dictionary of matches, see :doc:`responses </responses>`\n        \"\"\"\n        if 'match_id' not in kwargs:\n            kwargs['match_id'] = match_id\n        url = self.__build_url(urls.GET_MATCH_DETAILS, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_league_listing(self):\n        url = self.__build_url(urls.GET_LEAGUE_LISTING)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)", "response": "Returns a dictionary containing a list of all ticketed leagues"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary containing a list of ticked games in progress", "response": "def get_live_league_games(self):\n        \"\"\"Returns a dictionary containing a list of ticked games in progress\n\n        :return: dictionary of live games, see :doc:`responses </responses>`\n        \"\"\"\n        url = self.__build_url(urls.GET_LIVE_LEAGUE_GAMES)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary containing a in - game teams containing a team info.", "response": "def get_team_info_by_team_id(self, start_at_team_id=None, **kwargs):\n        \"\"\"Returns a dictionary containing a in-game teams\n\n        :param start_at_team_id: (int, optional)\n        :param teams_requested: (int, optional)\n        :return: dictionary of teams, see :doc:`responses </responses>`\n        \"\"\"\n        if 'start_at_team_id' not in kwargs:\n            kwargs['start_at_team_id'] = start_at_team_id\n        url = self.__build_url(urls.GET_TEAM_INFO_BY_TEAM_ID, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_player_summaries(self, steamids=None, **kwargs):\n        if not isinstance(steamids, collections.Iterable):\n            steamids = [steamids]\n\n        base64_ids = list(map(convert_to_64_bit, filter(lambda x: x is not None, steamids)))\n\n        if 'steamids' not in kwargs:\n            kwargs['steamids'] = base64_ids\n        url = self.__build_url(urls.GET_PLAYER_SUMMARIES, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)", "response": "Returns a dictionary containing a player summaries for the given list of steam ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_heroes(self, **kwargs):\n        url = self.__build_url(urls.GET_HEROES, language=self.language, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)", "response": "Returns a dictionary of in - game heroes used to parse ids into localised names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary that includes community funded tournament prize pools for a given league.", "response": "def get_tournament_prize_pool(self, leagueid=None, **kwargs):\n        \"\"\"Returns a dictionary that includes community funded tournament prize pools\n\n        :param leagueid: (int, optional)\n        :return: dictionary of prize pools, see :doc:`responses </responses>`\n        \"\"\"\n        if 'leagueid' not in kwargs:\n            kwargs['leagueid'] = leagueid\n        url = self.__build_url(urls.GET_TOURNAMENT_PRIZE_POOL, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary that includes top MMR live games.", "response": "def get_top_live_games(self, partner='', **kwargs):\n        \"\"\"Returns a dictionary that includes top MMR live games\n\n        :param partner: (int, optional)\n        :return: dictionary of prize pools, see :doc:`responses </responses>`\n        \"\"\"\n        if 'partner' not in kwargs:\n            kwargs['partner'] = partner\n        url = self.__build_url(urls.GET_TOP_LIVE_GAME, **kwargs)\n        req = self.executor(url)\n        if self.logger:\n            self.logger.info('URL: {0}'.format(url))\n        if not self.__check_http_err(req.status_code):\n            return response.build(req, url, self.raw_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __build_url(self, api_call, **kwargs):\n        kwargs['key'] = self.api_key\n        if 'language' not in kwargs:\n            kwargs['language'] = self.language\n        if 'format' not in kwargs:\n            kwargs['format'] = self.__format\n        api_query = urlencode(kwargs)\n\n        return \"{0}{1}?{2}\".format(urls.BASE_URL,\n                                   api_call,\n                                   api_query)", "response": "Builds the url for the resource based on the api_call and kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nraising an exception if we get an http error", "response": "def __check_http_err(self, status_code):\n        \"\"\"Raises an exception if we get a http error\"\"\"\n        if status_code == 403:\n            raise exceptions.APIAuthenticationError(self.api_key)\n        elif status_code == 503:\n            raise exceptions.APITimeoutError()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the lobby and set the hero name to the lobby s hero name", "response": "def hero_id(response):\n    \"\"\"\n    Parse the lobby, will be available as ``hero_name``\n    \"\"\"\n    for player in response['players']:\n        for hero in heroes['heroes']:\n            if hero['id'] == player['hero_id']:\n                player['hero_name'] = hero['localized_name']\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef leaver(response):\n    for player in response['players']:\n        for leaver in leavers:\n            if leaver['id'] == player['leaver_status']:\n                player['leaver_status_name'] = leaver['name']\n                player['leaver_status_description'] = leaver['description']\n\n    return response", "response": "Parse the lobby status and set the name and description of the leaver."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef item_id(response):\n    dict_keys = ['item_0', 'item_1', 'item_2',\n                 'item_3', 'item_4', 'item_5']\n    new_keys = ['item_0_name', 'item_1_name', 'item_2_name',\n                'item_3_name', 'item_4_name', 'item_5_name']\n\n    for player in response['players']:\n        for key, new_key in zip(dict_keys, new_keys):\n            for item in items['items']:\n                if item['id'] == player[key]:\n                    player[new_key] = item['localized_name']\n\n    return response", "response": "Parse the item ids and set the item names in the items dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_review_average(obj):\n    total = 0\n    reviews = get_reviews(obj)\n    if not reviews:\n        return False\n    for review in reviews:\n        average = review.get_average_rating()\n        if average:\n            total += review.get_average_rating()\n    if total > 0:\n        return total / reviews.count()\n    return False", "response": "Returns the review average for an object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_category_averages(obj, normalize_to=100):\n    context = {'reviewed_item': obj}\n    ctype = ContentType.objects.get_for_model(obj)\n    reviews = models.Review.objects.filter(\n        content_type=ctype, object_id=obj.id)\n    category_averages = {}\n    for review in reviews:\n        review_category_averages = review.get_category_averages(normalize_to)\n        if review_category_averages:\n            for category, average in review_category_averages.items():\n                if category not in category_averages:\n                    category_averages[category] = review_category_averages[\n                        category]\n                else:\n                    category_averages[category] += review_category_averages[\n                        category]\n    if reviews and category_averages:\n        for category, average in category_averages.items():\n            category_averages[category] = \\\n                category_averages[category] / models.Rating.objects.filter(\n                    category=category, value__isnull=False,\n                    review__content_type=ctype,\n                    review__object_id=obj.id).exclude(value='').count()\n    else:\n        category_averages = {}\n        for category in models.RatingCategory.objects.filter(\n                counts_for_average=True):\n            category_averages[category] = 0.0\n    context.update({'category_averages': category_averages})\n    return context", "response": "Renders all the sub - averages for each category."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the average for all reviews of the given object.", "response": "def total_review_average(obj, normalize_to=100):\n    \"\"\"Returns the average for all reviews of the given object.\"\"\"\n    ctype = ContentType.objects.get_for_model(obj)\n    total_average = 0\n    reviews = models.Review.objects.filter(\n        content_type=ctype, object_id=obj.id)\n    for review in reviews:\n        total_average += review.get_average_rating(normalize_to)\n    if reviews:\n        total_average /= reviews.count()\n    return total_average"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_has_reviewed(obj, user):\n    ctype = ContentType.objects.get_for_model(obj)\n    try:\n        models.Review.objects.get(user=user, content_type=ctype,\n                                  object_id=obj.id)\n    except models.Review.DoesNotExist:\n        return False\n    return True", "response": "Returns True if the user has already reviewed the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a datetime instance from the Unix time value of the timestamp with millisecond precision precision.", "response": "def datetime(self) -> hints.Datetime:\n        \"\"\"\n        Creates a :class:`~datetime.datetime` instance (assumes UTC) from the Unix time value of the timestamp\n        with millisecond precision.\n\n        :return: Timestamp in datetime form.\n        :rtype: :class:`~datetime.datetime`\n        \"\"\"\n        mills = self.int\n        return datetime.datetime.utcfromtimestamp(mills // 1000.0).replace(microsecond=mills % 1000 * 1000)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new ULID from current timestamp and randomness.", "response": "def new() -> ulid.ULID:\n    \"\"\"\n    Create a new :class:`~ulid.ulid.ULID` instance.\n\n    The timestamp is created from :func:`~time.time`.\n    The randomness is created from :func:`~os.urandom`.\n\n    :return: ULID from current timestamp\n    :rtype: :class:`~ulid.ulid.ULID`\n    \"\"\"\n    timestamp = int(time.time() * 1000).to_bytes(6, byteorder='big')\n    randomness = os.urandom(10)\n    return ulid.ULID(timestamp + randomness)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(value: ULIDPrimitive) -> ulid.ULID:\n    if isinstance(value, ulid.ULID):\n        return value\n    if isinstance(value, uuid.UUID):\n        return from_uuid(value)\n    if isinstance(value, str):\n        len_value = len(value)\n        if len_value == 36:\n            return from_uuid(uuid.UUID(value))\n        if len_value == 32:\n            return from_uuid(uuid.UUID(value))\n        if len_value == 26:\n            return from_str(value)\n        if len_value == 16:\n            return from_randomness(value)\n        if len_value == 10:\n            return from_timestamp(value)\n        raise ValueError('Cannot create ULID from string of length {}'.format(len_value))\n    if isinstance(value, (int, float)):\n        return from_int(int(value))\n    if isinstance(value, (bytes, bytearray)):\n        return from_bytes(value)\n    if isinstance(value, memoryview):\n        return from_bytes(value.tobytes())\n    raise ValueError('Cannot create ULID from type {}'.format(value.__class__.__name__))", "response": "Parse a ULID value into a ULID object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new ULID from the given bytes.", "response": "def from_bytes(value: hints.Buffer) -> ulid.ULID:\n    \"\"\"\n    Create a new :class:`~ulid.ulid.ULID` instance from the given :class:`~bytes`,\n    :class:`~bytearray`, or :class:`~memoryview` value.\n\n    :param value: 16 bytes\n    :type value: :class:`~bytes`, :class:`~bytearray`, or :class:`~memoryview`\n    :return: ULID from buffer value\n    :rtype: :class:`~ulid.ulid.ULID`\n    :raises ValueError: when the value is not 16 bytes\n    \"\"\"\n    length = len(value)\n    if length != 16:\n        raise ValueError('Expects bytes to be 128 bits; got {} bytes'.format(length))\n\n    return ulid.ULID(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_int(value: int) -> ulid.ULID:\n    if value < 0:\n        raise ValueError('Expects positive integer')\n\n    length = (value.bit_length() + 7) // 8\n    if length > 16:\n        raise ValueError('Expects integer to be 128 bits; got {} bytes'.format(length))\n\n    return ulid.ULID(value.to_bytes(16, byteorder='big'))", "response": "Create a new ULID from a 128 bit integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new ULID instance from a base32 encoded string.", "response": "def from_str(value: str) -> ulid.ULID:\n    \"\"\"\n    Create a new :class:`~ulid.ulid.ULID` instance from the given :class:`~str` value.\n\n    :param value: Base32 encoded string\n    :type value: :class:`~str`\n    :return: ULID from string value\n    :rtype: :class:`~ulid.ulid.ULID`\n    :raises ValueError: when the value is not 26 characters or malformed\n    \"\"\"\n    return ulid.ULID(base32.decode_ulid(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_uuid(value: uuid.UUID) -> ulid.ULID:\n    return ulid.ULID(value.bytes)", "response": "Create a new ULID instance from the given UUID value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_timestamp(timestamp: TimestampPrimitive) -> ulid.ULID:\n    if isinstance(timestamp, datetime.datetime):\n        timestamp = timestamp.timestamp()\n    if isinstance(timestamp, (int, float)):\n        timestamp = int(timestamp * 1000.0).to_bytes(6, byteorder='big')\n    elif isinstance(timestamp, str):\n        timestamp = base32.decode_timestamp(timestamp)\n    elif isinstance(timestamp, memoryview):\n        timestamp = timestamp.tobytes()\n    elif isinstance(timestamp, ulid.Timestamp):\n        timestamp = timestamp.bytes\n    elif isinstance(timestamp, ulid.ULID):\n        timestamp = timestamp.timestamp().bytes\n\n    if not isinstance(timestamp, (bytes, bytearray)):\n        raise ValueError('Expected datetime, int, float, str, memoryview, Timestamp, ULID, '\n                         'bytes, or bytearray; got {}'.format(type(timestamp).__name__))\n\n    length = len(timestamp)\n    if length != 6:\n        raise ValueError('Expects timestamp to be 48 bits; got {} bytes'.format(length))\n\n    randomness = os.urandom(10)\n    return ulid.ULID(timestamp + randomness)", "response": "Create a new ULID from a Unix timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new ULID from a given randomness value.", "response": "def from_randomness(randomness: RandomnessPrimitive) -> ulid.ULID:\n    \"\"\"\n    Create a new :class:`~ulid.ulid.ULID` instance using the given randomness value of a supported type.\n\n    The following types are supported for randomness values:\n\n    * :class:`~int`\n    * :class:`~float`\n    * :class:`~str`\n    * :class:`~memoryview`\n    * :class:`~ulid.ulid.Randomness`\n    * :class:`~ulid.ulid.ULID`\n    * :class:`~bytes`\n    * :class:`~bytearray`\n\n    :param randomness: Random bytes\n    :type randomness: See docstring for types\n    :return: ULID using new timestamp and given randomness\n    :rtype: :class:`~ulid.ulid.ULID`\n    :raises ValueError: when the value is an unsupported type\n    :raises ValueError: when the value is a string and cannot be Base32 decoded\n    :raises ValueError: when the value is or was converted to something 80 bits\n    \"\"\"\n    if isinstance(randomness, (int, float)):\n        randomness = int(randomness).to_bytes(10, byteorder='big')\n    elif isinstance(randomness, str):\n        randomness = base32.decode_randomness(randomness)\n    elif isinstance(randomness, memoryview):\n        randomness = randomness.tobytes()\n    elif isinstance(randomness, ulid.Randomness):\n        randomness = randomness.bytes\n    elif isinstance(randomness, ulid.ULID):\n        randomness = randomness.randomness().bytes\n\n    if not isinstance(randomness, (bytes, bytearray)):\n        raise ValueError('Expected int, float, str, memoryview, Randomness, ULID, '\n                         'bytes, or bytearray; got {}'.format(type(randomness).__name__))\n\n    length = len(randomness)\n    if length != 10:\n        raise ValueError('Expects randomness to be 80 bits; got {} bytes'.format(length))\n\n    timestamp = int(time.time() * 1000).to_bytes(6, byteorder='big')\n    return ulid.ULID(timestamp + randomness)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode the given bytes instance to a Base32 string using Base32 encoding.", "response": "def encode(value: hints.Buffer) -> str:\n    \"\"\"\n    Encode the given :class:`~bytes` instance to a :class:`~str` using Base32 encoding.\n\n    .. note:: You should only use this method if you've got a :class:`~bytes` instance\n        and you are unsure of what it represents. If you know the the _meaning_ of the\n        :class:`~bytes` instance, you should call the `encode_*` method explicitly for\n        better performance.\n\n    :param value: Bytes to encode\n    :type value: :class:`~bytes`, :class:`~bytearray`, or :class:`~memoryview`\n    :return: Value encoded as a Base32 string\n    :rtype: :class:`~str`\n    :raises ValueError: when the value is not 6, 10, or 16 bytes long\n    \"\"\"\n    length = len(value)\n\n    # Order here is based on assumed hot path.\n    if length == 16:\n        return encode_ulid(value)\n    if length == 6:\n        return encode_timestamp(value)\n    if length == 10:\n        return encode_randomness(value)\n\n    raise ValueError('Expects bytes in sizes of 6, 10, or 16; got {}'.format(length))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding the given buffer as a base32 string using the ULID - 262 - 1 bit encoding.", "response": "def encode_ulid(value: hints.Buffer) -> str:\n    \"\"\"\n    Encode the given buffer to a :class:`~str` using Base32 encoding.\n\n    .. note:: This uses an optimized strategy from the `NUlid` project for encoding ULID\n        bytes specifically and is not meant for arbitrary encoding.\n\n    :param value: Bytes to encode\n    :type value: :class:`~bytes`, :class:`~bytearray`, or :class:`~memoryview`\n    :return: Value encoded as a Base32 string\n    :rtype: :class:`~str`\n    :raises ValueError: when the value is not 16 bytes\n    \"\"\"\n    length = len(value)\n    if length != 16:\n        raise ValueError('Expects 16 bytes for timestamp + randomness; got {}'.format(length))\n\n    encoding = ENCODING\n\n    return \\\n        encoding[(value[0] & 224) >> 5] + \\\n        encoding[value[0] & 31] + \\\n        encoding[(value[1] & 248) >> 3] + \\\n        encoding[((value[1] & 7) << 2) | ((value[2] & 192) >> 6)] + \\\n        encoding[((value[2] & 62) >> 1)] + \\\n        encoding[((value[2] & 1) << 4) | ((value[3] & 240) >> 4)] + \\\n        encoding[((value[3] & 15) << 1) | ((value[4] & 128) >> 7)] + \\\n        encoding[(value[4] & 124) >> 2] + \\\n        encoding[((value[4] & 3) << 3) | ((value[5] & 224) >> 5)] + \\\n        encoding[value[5] & 31] + \\\n        encoding[(value[6] & 248) >> 3] + \\\n        encoding[((value[6] & 7) << 2) | ((value[7] & 192) >> 6)] + \\\n        encoding[(value[7] & 62) >> 1] + \\\n        encoding[((value[7] & 1) << 4) | ((value[8] & 240) >> 4)] + \\\n        encoding[((value[8] & 15) << 1) | ((value[9] & 128) >> 7)] + \\\n        encoding[(value[9] & 124) >> 2] + \\\n        encoding[((value[9] & 3) << 3) | ((value[10] & 224) >> 5)] + \\\n        encoding[value[10] & 31] + \\\n        encoding[(value[11] & 248) >> 3] + \\\n        encoding[((value[11] & 7) << 2) | ((value[12] & 192) >> 6)] + \\\n        encoding[(value[12] & 62) >> 1] + \\\n        encoding[((value[12] & 1) << 4) | ((value[13] & 240) >> 4)] + \\\n        encoding[((value[13] & 15) << 1) | ((value[14] & 128) >> 7)] + \\\n        encoding[(value[14] & 124) >> 2] + \\\n        encoding[((value[14] & 3) << 3) | ((value[15] & 224) >> 5)] + \\\n        encoding[value[15] & 31]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode_timestamp(timestamp: hints.Buffer) -> str:\n    length = len(timestamp)\n    if length != 6:\n        raise ValueError('Expects 6 bytes for timestamp; got {}'.format(length))\n\n    encoding = ENCODING\n\n    return \\\n        encoding[(timestamp[0] & 224) >> 5] + \\\n        encoding[timestamp[0] & 31] + \\\n        encoding[(timestamp[1] & 248) >> 3] + \\\n        encoding[((timestamp[1] & 7) << 2) | ((timestamp[2] & 192) >> 6)] + \\\n        encoding[((timestamp[2] & 62) >> 1)] + \\\n        encoding[((timestamp[2] & 1) << 4) | ((timestamp[3] & 240) >> 4)] + \\\n        encoding[((timestamp[3] & 15) << 1) | ((timestamp[4] & 128) >> 7)] + \\\n        encoding[(timestamp[4] & 124) >> 2] + \\\n        encoding[((timestamp[4] & 3) << 3) | ((timestamp[5] & 224) >> 5)] + \\\n        encoding[timestamp[5] & 31]", "response": "Encodes the given buffer to a Base32 string using the NUlid encoding."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_randomness(randomness: hints.Buffer) -> str:\n    length = len(randomness)\n    if length != 10:\n        raise ValueError('Expects 10 bytes for randomness; got {}'.format(length))\n\n    encoding = ENCODING\n\n    return \\\n        encoding[(randomness[0] & 248) >> 3] + \\\n        encoding[((randomness[0] & 7) << 2) | ((randomness[1] & 192) >> 6)] + \\\n        encoding[(randomness[1] & 62) >> 1] + \\\n        encoding[((randomness[1] & 1) << 4) | ((randomness[2] & 240) >> 4)] + \\\n        encoding[((randomness[2] & 15) << 1) | ((randomness[3] & 128) >> 7)] + \\\n        encoding[(randomness[3] & 124) >> 2] + \\\n        encoding[((randomness[3] & 3) << 3) | ((randomness[4] & 224) >> 5)] + \\\n        encoding[randomness[4] & 31] + \\\n        encoding[(randomness[5] & 248) >> 3] + \\\n        encoding[((randomness[5] & 7) << 2) | ((randomness[6] & 192) >> 6)] + \\\n        encoding[(randomness[6] & 62) >> 1] + \\\n        encoding[((randomness[6] & 1) << 4) | ((randomness[7] & 240) >> 4)] + \\\n        encoding[((randomness[7] & 15) << 1) | ((randomness[8] & 128) >> 7)] + \\\n        encoding[(randomness[8] & 124) >> 2] + \\\n        encoding[((randomness[8] & 3) << 3) | ((randomness[9] & 224) >> 5)] + \\\n        encoding[randomness[9] & 31]", "response": "Encodes the given randomness bytes into a base32 string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(value: str) -> bytes:\n    length = len(value)\n\n    # Order here is based on assumed hot path.\n    if length == 26:\n        return decode_ulid(value)\n    if length == 10:\n        return decode_timestamp(value)\n    if length == 16:\n        return decode_randomness(value)\n\n    raise ValueError('Expects string in lengths of 10, 16, or 26; got {}'.format(length))", "response": "Decodes the given Base32 encoded string to a base32 encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode the given Base32 encoded ULID to bytes.", "response": "def decode_ulid(value: str) -> bytes:\n    \"\"\"\n    Decode the given Base32 encoded :class:`~str` instance to :class:`~bytes`.\n\n    .. note:: This uses an optimized strategy from the `NUlid` project for decoding ULID\n        strings specifically and is not meant for arbitrary decoding.\n\n    :param value: String to decode\n    :type value: :class:`~str`\n    :return: Value decoded from Base32 string\n    :rtype: :class:`~bytes`\n    :raises ValueError: when value is not 26 characters\n    :raises ValueError: when value cannot be encoded in ASCII\n    \"\"\"\n    encoded = str_to_bytes(value, 26)\n\n    decoding = DECODING\n\n    return bytes((\n        ((decoding[encoded[0]] << 5) | decoding[encoded[1]]) & 0xFF,\n        ((decoding[encoded[2]] << 3) | (decoding[encoded[3]] >> 2)) & 0xFF,\n        ((decoding[encoded[3]] << 6) | (decoding[encoded[4]] << 1) | (decoding[encoded[5]] >> 4)) & 0xFF,\n        ((decoding[encoded[5]] << 4) | (decoding[encoded[6]] >> 1)) & 0xFF,\n        ((decoding[encoded[6]] << 7) | (decoding[encoded[7]] << 2) | (decoding[encoded[8]] >> 3)) & 0xFF,\n        ((decoding[encoded[8]] << 5) | (decoding[encoded[9]])) & 0xFF,\n        ((decoding[encoded[10]] << 3) | (decoding[encoded[11]] >> 2)) & 0xFF,\n        ((decoding[encoded[11]] << 6) | (decoding[encoded[12]] << 1) | (decoding[encoded[13]] >> 4)) & 0xFF,\n        ((decoding[encoded[13]] << 4) | (decoding[encoded[14]] >> 1)) & 0xFF,\n        ((decoding[encoded[14]] << 7) | (decoding[encoded[15]] << 2) | (decoding[encoded[16]] >> 3)) & 0xFF,\n        ((decoding[encoded[16]] << 5) | (decoding[encoded[17]])) & 0xFF,\n        ((decoding[encoded[18]] << 3) | (decoding[encoded[19]] >> 2)) & 0xFF,\n        ((decoding[encoded[19]] << 6) | (decoding[encoded[20]] << 1) | (decoding[encoded[21]] >> 4)) & 0xFF,\n        ((decoding[encoded[21]] << 4) | (decoding[encoded[22]] >> 1)) & 0xFF,\n        ((decoding[encoded[22]] << 7) | (decoding[encoded[23]] << 2) | (decoding[encoded[24]] >> 3)) & 0xFF,\n        ((decoding[encoded[24]] << 5) | (decoding[encoded[25]])) & 0xFF\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding the given Base32 encoded string to a base32 encoded string.", "response": "def decode_timestamp(timestamp: str) -> bytes:\n    \"\"\"\n    Decode the given Base32 encoded :class:`~str` instance to :class:`~bytes`.\n\n    The given :class:`~str` are expected to represent the first 10 characters of a ULID, which\n    are the timestamp in milliseconds.\n\n    .. note:: This uses an optimized strategy from the `NUlid` project for decoding ULID\n        strings specifically and is not meant for arbitrary decoding.\n\n    :param timestamp: String to decode\n    :type timestamp: :class:`~str`\n    :return: Value decoded from Base32 string\n    :rtype: :class:`~bytes`\n    :raises ValueError: when value is not 10 characters\n    :raises ValueError: when value cannot be encoded in ASCII\n    \"\"\"\n    encoded = str_to_bytes(timestamp, 10)\n\n    decoding = DECODING\n\n    return bytes((\n        ((decoding[encoded[0]] << 5) | decoding[encoded[1]]) & 0xFF,\n        ((decoding[encoded[2]] << 3) | (decoding[encoded[3]] >> 2)) & 0xFF,\n        ((decoding[encoded[3]] << 6) | (decoding[encoded[4]] << 1) | (decoding[encoded[5]] >> 4)) & 0xFF,\n        ((decoding[encoded[5]] << 4) | (decoding[encoded[6]] >> 1)) & 0xFF,\n        ((decoding[encoded[6]] << 7) | (decoding[encoded[7]] << 2) | (decoding[encoded[8]] >> 3)) & 0xFF,\n        ((decoding[encoded[8]] << 5) | (decoding[encoded[9]])) & 0xFF\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode_randomness(randomness: str) -> bytes:\n    encoded = str_to_bytes(randomness, 16)\n\n    decoding = DECODING\n\n    return bytes((\n        ((decoding[encoded[0]] << 3) | (decoding[encoded[1]] >> 2)) & 0xFF,\n        ((decoding[encoded[1]] << 6) | (decoding[encoded[2]] << 1) | (decoding[encoded[3]] >> 4)) & 0xFF,\n        ((decoding[encoded[3]] << 4) | (decoding[encoded[4]] >> 1)) & 0xFF,\n        ((decoding[encoded[4]] << 7) | (decoding[encoded[5]] << 2) | (decoding[encoded[6]] >> 3)) & 0xFF,\n        ((decoding[encoded[6]] << 5) | (decoding[encoded[7]])) & 0xFF,\n        ((decoding[encoded[8]] << 3) | (decoding[encoded[9]] >> 2)) & 0xFF,\n        ((decoding[encoded[9]] << 6) | (decoding[encoded[10]] << 1) | (decoding[encoded[11]] >> 4)) & 0xFF,\n        ((decoding[encoded[11]] << 4) | (decoding[encoded[12]] >> 1)) & 0xFF,\n        ((decoding[encoded[12]] << 7) | (decoding[encoded[13]] << 2) | (decoding[encoded[14]] >> 3)) & 0xFF,\n        ((decoding[encoded[14]] << 5) | (decoding[encoded[15]])) & 0xFF\n    ))", "response": "Decode the given Base32 encoded string to a 16 - bit value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the given string to bytes and validate it is within Base32 character set.", "response": "def str_to_bytes(value: str, expected_length: int) -> bytes:\n    \"\"\"\n    Convert the given string to bytes and validate it is within the Base32 character set.\n\n    :param value: String to convert to bytes\n    :type value: :class:`~str`\n    :param expected_length: Expected length of the input string\n    :type expected_length: :class:`~int`\n    :return: Value converted to bytes.\n    :rtype: :class:`~bytes`\n    \"\"\"\n    length = len(value)\n    if length != expected_length:\n        raise ValueError('Expects {} characters for decoding; got {}'.format(expected_length, length))\n\n    try:\n        encoded = value.encode('ascii')\n    except UnicodeEncodeError as ex:\n        raise ValueError('Expects value that can be encoded in ASCII charset: {}'.format(ex))\n\n    decoding = DECODING\n\n    # Confirm all bytes are valid Base32 decode characters.\n    # Note: ASCII encoding handles the out of range checking for us.\n    for byte in encoded:\n        if decoding[byte] > 31:\n            raise ValueError('Non-base32 character found: \"{}\"'.format(chr(byte)))\n\n    return encoded"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the MAC address of the local interface or remote host.", "response": "def get_mac_address(\n        interface=None, ip=None, ip6=None,\n        hostname=None, network_request=True\n):\n    # type: (Optional[str], Optional[str], Optional[str], Optional[str], bool) -> Optional[str]\n    \"\"\"Get a Unicast IEEE 802 MAC-48 address from a local interface or remote host.\n\n    You must only use one of the first four arguments. If none of the arguments\n    are selected, the default network interface for the system will be used.\n\n    Exceptions will be handled silently and returned as a None.\n    For the time being, it assumes you are using Ethernet.\n\n    NOTES:\n    * You MUST provide str-typed arguments, REGARDLESS of Python version.\n    * localhost/127.0.0.1 will always return '00:00:00:00:00:00'\n\n    Args:\n        interface (str): Name of a local network interface (e.g \"Ethernet 3\", \"eth0\", \"ens32\")\n        ip (str): Canonical dotted decimal IPv4 address of a remote host (e.g 192.168.0.1)\n        ip6 (str): Canonical shortened IPv6 address of a remote host (e.g ff02::1:ffe7:7f19)\n        hostname (str): DNS hostname of a remote host (e.g \"router1.mycorp.com\", \"localhost\")\n        network_request (bool): Send a UDP packet to a remote host to populate\n        the ARP/NDP tables for IPv4/IPv6. The port this packet is sent to can\n        be configured using the module variable `getmac.PORT`.\n    Returns:\n        Lowercase colon-separated MAC address, or None if one could not be\n        found or there was an error.\n    \"\"\"\n    if (hostname and hostname == 'localhost') or (ip and ip == '127.0.0.1'):\n        return '00:00:00:00:00:00'\n\n    # Resolve hostname to an IP address\n    if hostname:\n        ip = socket.gethostbyname(hostname)\n\n    # Populate the ARP table by sending a empty UDP packet to a high port\n    if network_request and (ip or ip6):\n        try:\n            if ip:\n                s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                s.sendto(b'', (ip, PORT))\n            else:\n                s = socket.socket(socket.AF_INET6, socket.SOCK_DGRAM)\n                s.sendto(b'', (ip6, PORT))\n        except Exception:\n            log.error(\"Failed to send ARP table population packet\")\n            if DEBUG:\n                log.debug(traceback.format_exc())\n\n    # Setup the address hunt based on the arguments specified\n    if ip6:\n        if not socket.has_ipv6:\n            log.error(\"Cannot get the MAC address of a IPv6 host: \"\n                      \"IPv6 is not supported on this system\")\n            return None\n        elif ':' not in ip6:\n            log.error(\"Invalid IPv6 address: %s\", ip6)\n            return None\n        to_find = ip6\n        typ = IP6\n    elif ip:\n        to_find = ip\n        typ = IP4\n    else:  # Default to searching for interface\n        typ = INTERFACE\n        if interface:\n            to_find = interface\n        else:\n            # Default to finding MAC of the interface with the default route\n            if WINDOWS and network_request:\n                to_find = _fetch_ip_using_dns()\n                typ = IP4\n            elif WINDOWS:\n                to_find = 'Ethernet'\n            elif BSD:\n                if OPENBSD:\n                    to_find = _get_default_iface_openbsd()  # type: ignore\n                else:\n                    to_find = _get_default_iface_freebsd()  # type: ignore\n                if not to_find:\n                    to_find = 'em0'\n            else:\n                to_find = _hunt_linux_default_iface()  # type: ignore\n                if not to_find:\n                    to_find = 'en0'\n\n    mac = _hunt_for_mac(to_find, typ, network_request)\n    log.debug(\"Raw MAC found: %s\", mac)\n\n    # Check and format the result to be lowercase, colon-separated\n    if mac is not None:\n        mac = str(mac)\n        if not PY2:  # Strip bytestring conversion artifacts\n            mac = mac.replace(\"b'\", '').replace(\"'\", '')\\\n                     .replace('\\\\n', '').replace('\\\\r', '')\n        mac = mac.strip().lower().replace(' ', '').replace('-', ':')\n\n        # Fix cases where there are no colons\n        if ':' not in mac and len(mac) == 12:\n            log.debug(\"Adding colons to MAC %s\", mac)\n            mac = ':'.join(mac[i:i + 2] for i in range(0, len(mac), 2))\n\n        # Pad single-character octets with a leading zero (e.g Darwin's ARP output)\n        elif len(mac) < 17:\n            log.debug(\"Length of MAC %s is %d, padding single-character \"\n                      \"octets with zeros\", mac, len(mac))\n            parts = mac.split(':')\n            new_mac = []\n            for part in parts:\n                if len(part) == 1:\n                    new_mac.append('0' + part)\n                else:\n                    new_mac.append(part)\n            mac = ':'.join(new_mac)\n\n        # MAC address should ALWAYS be 17 characters before being returned\n        if len(mac) != 17:\n            log.warning(\"MAC address %s is not 17 characters long!\", mac)\n            mac = None\n        elif mac.count(':') != 5:\n            log.warning(\"MAC address %s is missing ':' characters\", mac)\n            mac = None\n    return mac"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries a variety of methods to get a MAC address.", "response": "def _hunt_for_mac(to_find, type_of_thing, net_ok=True):\n    # type: (Optional[str], int, bool) -> Optional[str]\n    \"\"\"Tries a variety of methods to get a MAC address.\n\n    Format of method lists:\n    Tuple:  (regex, regex index, command, command args)\n            Command args is a list of strings to attempt to use as arguments\n    lambda: Function to call\n    \"\"\"\n    if to_find is None:\n        log.warning(\"_hunt_for_mac() failed: to_find is None\")\n        return None\n    if not PY2 and isinstance(to_find, bytes):\n        to_find = str(to_find, 'utf-8')\n\n    if WINDOWS and type_of_thing == INTERFACE:\n        methods = [\n            # getmac - Connection Name\n            (r'\\r\\n' + to_find + r'.*' + MAC_RE_DASH + r'.*\\r\\n',\n             0, 'getmac.exe', ['/NH /V']),\n\n            # ipconfig\n            (to_find + r'(?:\\n?[^\\n]*){1,8}Physical Address[ .:]+' + MAC_RE_DASH + r'\\r\\n',\n             0, 'ipconfig.exe', ['/all']),\n\n            # getmac - Network Adapter (the human-readable name)\n            (r'\\r\\n.*' + to_find + r'.*' + MAC_RE_DASH + r'.*\\r\\n',\n             0, 'getmac.exe', ['/NH /V']),\n\n            # wmic - WMI command line utility\n            lambda x: _popen('wmic.exe', 'nic where \"NetConnectionID = \\'%s\\'\" get '\n                                         'MACAddress /value' % x).strip().partition('=')[2],\n        ]\n    elif (WINDOWS or WSL) and type_of_thing in [IP4, IP6, HOSTNAME]:\n        methods = [\n            # arp -a - Parsing result with a regex\n            (MAC_RE_DASH, 0, 'arp.exe', ['-a %s' % to_find]),\n        ]\n\n        # Add methods that make network requests\n        # Insert it *after* arp.exe since that's probably faster.\n        if net_ok and type_of_thing != IP6 and not WSL:\n            methods.insert(1, _windows_ctypes_host)\n    elif (DARWIN or FREEBSD) and type_of_thing == INTERFACE:\n        methods = [\n            (r'ether ' + MAC_RE_COLON,\n             0, 'ifconfig', [to_find]),\n\n            # Alternative match for ifconfig if it fails\n            (to_find + r'.*ether ' + MAC_RE_COLON,\n             0, 'ifconfig', ['']),\n\n            (MAC_RE_COLON,\n             0, 'networksetup', ['-getmacaddress %s' % to_find]),\n        ]\n    elif FREEBSD and type_of_thing in [IP4, IP6, HOSTNAME]:\n        methods = [\n            (r'\\(' + re.escape(to_find) + r'\\)\\s+at\\s+' + MAC_RE_COLON,\n             0, 'arp', [to_find])\n        ]\n    elif OPENBSD and type_of_thing == INTERFACE:\n        methods = [\n            (r'lladdr ' + MAC_RE_COLON,\n             0, 'ifconfig', [to_find]),\n        ]\n    elif OPENBSD and type_of_thing in [IP4, IP6, HOSTNAME]:\n        methods = [\n            (re.escape(to_find) + r'[ ]+' + MAC_RE_COLON,\n             0, 'arp', ['-an']),\n        ]\n    elif type_of_thing == INTERFACE:\n        methods = [\n            _read_sys_iface_file,\n            _fcntl_iface,\n\n            # Fast modern Ubuntu ifconfig\n            (r'ether ' + MAC_RE_COLON,\n             0, 'ifconfig', [to_find]),\n\n            # Fast ifconfig\n            (r'HWaddr ' + MAC_RE_COLON,\n             0, 'ifconfig', [to_find]),\n\n            # ip link (Don't use 'list' due to SELinux [Android 24+])\n            (to_find + r'.*\\n.*link/ether ' + MAC_RE_COLON,\n             0, 'ip', ['link %s' % to_find, 'link']),\n\n            # netstat\n            (to_find + r'.*HWaddr ' + MAC_RE_COLON,\n             0, 'netstat', ['-iae']),\n\n            # More variations of ifconfig\n            (to_find + r'.*ether ' + MAC_RE_COLON,\n             0, 'ifconfig', ['']),\n            (to_find + r'.*HWaddr ' + MAC_RE_COLON,\n             0, 'ifconfig', ['', '-a', '-v']),\n\n            # Tru64 ('-av')\n            (to_find + r'.*Ether ' + MAC_RE_COLON,\n             0, 'ifconfig', ['-av']),\n            _uuid_lanscan_iface,\n        ]\n    elif type_of_thing in [IP4, IP6, HOSTNAME]:\n        esc = re.escape(to_find)\n        methods = [\n            _read_arp_file,\n            lambda x: _popen('ip', 'neighbor show %s' % x)\n            .partition(x)[2].partition('lladdr')[2].strip().split()[0],\n\n            (r'\\(' + esc + r'\\)\\s+at\\s+' + MAC_RE_COLON,\n             0, 'arp', [to_find, '-an', '-an %s' % to_find]),\n\n            # Darwin oddness\n            (r'\\(' + esc + r'\\)\\s+at\\s+' + MAC_RE_DARWIN,\n             0, 'arp', [to_find, '-a', '-a %s' % to_find]),\n            _uuid_ip,\n        ]\n    else:\n        log.critical(\"Reached end of _hunt_for_mac() if-else chain!\")\n        return None\n    return _try_methods(methods, to_find)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _try_methods(methods, to_find=None):\n    # type: (list, Optional[str]) -> Optional[str]\n    \"\"\"Runs the methods specified by _hunt_for_mac().\n\n    We try every method and see if it returned a MAC address. If it returns\n    None or raises an exception, we continue and try the next method.\n    \"\"\"\n    found = None\n    for m in methods:\n        try:\n            if isinstance(m, tuple):\n                for arg in m[3]:  # list(str)\n                    if DEBUG:\n                        log.debug(\"Trying: '%s %s'\", m[2], arg)\n                    # Arguments: (regex, _popen(command, arg), regex index)\n                    found = _search(m[0], _popen(m[2], arg), m[1])\n                    if DEBUG:\n                        log.debug(\"Result: %s\\n\", found)\n                    if found:  # Skip remaining args AND remaining methods\n                        break\n            elif callable(m):\n                if DEBUG:\n                    log.debug(\"Trying: '%s' (to_find: '%s')\", m.__name__, str(to_find))\n                if to_find is not None:\n                    found = m(to_find)\n                else:\n                    found = m()\n                if DEBUG:\n                    log.debug(\"Result: %s\\n\", found)\n            else:\n                log.critical(\"Invalid type '%s' for method '%s'\", type(m), str(m))\n        except Exception as ex:\n            if DEBUG:\n                log.debug(\"Exception: %s\", str(ex))\n            if DEBUG >= 2:\n                log.debug(traceback.format_exc())\n            continue\n        if found:  # Skip remaining methods\n            break\n    return found", "response": "Runs the methods specified by _hunt_for_mac. Returns None if no method returns a MAC address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the default interface on Linux.", "response": "def _get_default_iface_linux():\n    # type: () -> Optional[str]\n    \"\"\"Get the default interface by reading /proc/net/route.\n\n    This is the same source as the `route` command, however it's much\n    faster to read this file than to call `route`. If it fails for whatever\n    reason, we can fall back on the system commands (e.g for a platform\n    that has a route command, but maybe doesn't use /proc?).\n    \"\"\"\n    data = _read_file('/proc/net/route')\n    if data is not None and len(data) > 1:\n        for line in data.split('\\n')[1:-1]:\n            iface_name, dest = line.split('\\t')[:2]\n            if dest == '00000000':\n                return iface_name\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef package_version():\n    version_path = os.path.join(os.path.dirname(__file__), 'version.py')\n\n    version = read_version(version_path)\n    write_version(version_path, version)\n\n    return version", "response": "Get the package version via Git Tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef waitforqueues(queues, timeout=None):\n    lock = threading.Condition(threading.Lock())\n\n    prepare_queues(queues, lock)\n    try:\n        wait_queues(queues, lock, timeout)\n    finally:\n        reset_queues(queues)\n\n    return filter(lambda q: not q.empty(), queues)", "response": "Waits for one or more queues to be ready or until timeout expires."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_queues(queues, lock):\n    for queue in queues:\n        queue._pebble_lock = lock\n        with queue.mutex:\n            queue._pebble_old_method = queue._put\n            queue._put = MethodType(new_method, queue)", "response": "Replaces the queue. _put method in order to notify the waiting Condition."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_queues(queues):\n    for queue in queues:\n        with queue.mutex:\n            queue._put = queue._pebble_old_method\n        delattr(queue, '_pebble_old_method')\n        delattr(queue, '_pebble_lock')", "response": "Resets original queue. _put method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef waitforthreads(threads, timeout=None):\n    old_function = None\n    lock = threading.Condition(threading.Lock())\n\n    def new_function(*args):\n        old_function(*args)\n        with lock:\n            lock.notify_all()\n\n    old_function = prepare_threads(new_function)\n    try:\n        wait_threads(threads, lock, timeout)\n    finally:\n        reset_threads(old_function)\n\n    return filter(lambda t: not t.is_alive(), threads)", "response": "Waits for one or more Threads to exit or until timeout expires."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing the get_ident() function in order to notify the waiting Condition.", "response": "def prepare_threads(new_function):\n    \"\"\"Replaces threading._get_ident() function in order to notify\n    the waiting Condition.\"\"\"\n    with _waitforthreads_lock:\n        if hasattr(threading, 'get_ident'):\n            old_function = threading.get_ident\n            threading.get_ident = new_function\n        else:\n            old_function = threading._get_ident\n            threading._get_ident = new_function\n\n        return old_function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_threads(old_function):\n    with _waitforthreads_lock:\n        if hasattr(threading, 'get_ident'):\n            threading.get_ident = old_function\n        else:\n            threading._get_ident = old_function", "response": "Resets original threading. get_ident function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sighandler(signals):\n    def wrap(function):\n        set_signal_handlers(signals, function)\n\n        @wraps(function)\n        def wrapper(*args, **kwargs):\n            return function(*args, **kwargs)\n\n        return wrapper\n\n    return wrap", "response": "Decorator to set the signal handlers of given signals."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef worker_thread(context):\n    queue = context.task_queue\n    parameters = context.worker_parameters\n\n    if parameters.initializer is not None:\n        if not run_initializer(parameters.initializer, parameters.initargs):\n            context.state = ERROR\n            return\n\n    for task in get_next_task(context, parameters.max_tasks):\n        execute_next_task(task)\n        queue.task_done()", "response": "The worker thread routines."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef schedule(self, function, args=(), kwargs={}):\n        self._check_pool_state()\n\n        future = Future()\n        payload = TaskPayload(function, args, kwargs)\n        task = Task(next(self._task_counter), future, None, payload)\n\n        self._context.task_queue.put(task)\n\n        return future", "response": "Schedules a function to be run in the pool. Returns a new Future object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator equivalent to map ( function iterables ).", "response": "def map(self, function, *iterables, **kwargs):\n        \"\"\"Returns an iterator equivalent to map(function, iterables).\n\n        *chunksize* controls the size of the chunks the iterable will\n        be broken into before being passed to the function. If None\n        the size will be controlled by the Pool.\n\n        \"\"\"\n        self._check_pool_state()\n\n        timeout = kwargs.get('timeout')\n        chunksize = kwargs.get('chunksize', 1)\n\n        if chunksize < 1:\n            raise ValueError(\"chunksize must be >= 1\")\n\n        futures = [self.schedule(process_chunk, args=(function, chunk))\n                   for chunk in iter_chunks(chunksize, *iterables)]\n\n        map_future = MapFuture(futures)\n        if not futures:\n            map_future.set_result(MapResults(futures))\n            return map_future\n\n        def done_map(_):\n            if not map_future.done():\n                map_future.set_result(MapResults(futures, timeout=timeout))\n\n        for future in futures:\n            future.add_done_callback(done_map)\n            setattr(future, 'map_future', map_future)\n\n        return map_future"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndo its best to stop the process.", "response": "def stop_process(process):\n    \"\"\"Does its best to stop the process.\"\"\"\n    process.terminate()\n    process.join(3)\n\n    if process.is_alive() and os.name != 'nt':\n        try:\n            os.kill(process.pid, signal.SIGKILL)\n            process.join()\n        except OSError:\n            return\n\n    if process.is_alive():\n        raise RuntimeError(\"Unable to terminate PID %d\" % os.getpid())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(function, *args, **kwargs):\n    try:\n        return function(*args, **kwargs)\n    except Exception as error:\n        error.traceback = format_exc()\n        return error", "response": "Runs the given function returning its results or exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_execute(function, *args, **kwargs):\n    try:\n        return function(*args, **kwargs)\n    except Exception as error:\n        error.traceback = format_exc()\n        return RemoteException(error, error.traceback)", "response": "Runs the given function returning its results or exception."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_result(pipe, data):\n    try:\n        pipe.send(data)\n    except (pickle.PicklingError, TypeError) as error:\n        error.traceback = format_exc()\n        pipe.send(RemoteException(error, error.traceback))", "response": "Send result handling pickling and communication errors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process(*args, **kwargs):\n    timeout = kwargs.get('timeout')\n\n    # decorator without parameters\n    if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n        return _process_wrapper(args[0], timeout)\n    else:\n        # decorator with parameters\n        if timeout is not None and not isinstance(timeout, (int, float)):\n            raise TypeError('Timeout expected to be None or integer or float')\n\n        def decorating_function(function):\n            return _process_wrapper(function, timeout)\n\n        return decorating_function", "response": "Decorator for processing a function in a concurrent process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _worker_handler(future, worker, pipe, timeout):\n    result = _get_result(future, pipe, timeout)\n\n    if isinstance(result, BaseException):\n        if isinstance(result, ProcessExpired):\n            result.exitcode = worker.exitcode\n\n        future.set_exception(result)\n    else:\n        future.set_result(result)\n\n    if worker.is_alive():\n        stop_process(worker)", "response": "This function is called by the worker thread when the worker is done processing the task."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the actual function in separate process and returns its result.", "response": "def _function_handler(function, args, kwargs, pipe):\n    \"\"\"Runs the actual function in separate process and returns its result.\"\"\"\n    signal.signal(signal.SIGINT, signal.SIG_IGN)\n\n    result = process_execute(function, *args, **kwargs)\n\n    send_result(pipe, result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwaits for result and handles communication errors.", "response": "def _get_result(future, pipe, timeout):\n    \"\"\"Waits for result and handles communication errors.\"\"\"\n    counter = count(step=SLEEP_UNIT)\n\n    try:\n        while not pipe.poll(SLEEP_UNIT):\n            if timeout is not None and next(counter) >= timeout:\n                return TimeoutError('Task Timeout', timeout)\n            elif future.cancelled():\n                return CancelledError()\n\n        return pipe.recv()\n    except (EOFError, OSError):\n        return ProcessExpired('Abnormal termination')\n    except Exception as error:\n        return error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _function_lookup(name, module):\n    try:\n        return _registered_functions[name]\n    except KeyError:  # force function registering\n        __import__(module)\n        mod = sys.modules[module]\n        getattr(mod, name)\n\n        return _registered_functions[name]", "response": "Searches the function between the registered ones."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef task_transaction(channel):\n    with channel.lock:\n        if channel.poll(0):\n            task = channel.recv()\n            channel.send(Acknowledgement(os.getpid(), task.id))\n        else:\n            raise RuntimeError(\"Race condition between workers\")\n\n    return task", "response": "Ensures a task is fetched and acknowledged atomically."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef schedule(self, task):\n        self.task_manager.register(task)\n        self.worker_manager.dispatch(task)", "response": "Schedules a new Task in the PoolManager."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_next_message(self, timeout):\n        message = self.worker_manager.receive(timeout)\n\n        if isinstance(message, Acknowledgement):\n            self.task_manager.task_start(message.task, message.worker)\n        elif isinstance(message, Result):\n            self.task_manager.task_done(message.task, message.result)", "response": "Processes the next message coming from the workers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_tasks(self):\n        for task in self.task_manager.timeout_tasks():\n            self.task_manager.task_done(\n                task.id, TimeoutError(\"Task timeout\", task.timeout))\n            self.worker_manager.stop_worker(task.worker_id)\n\n        for task in self.task_manager.cancelled_tasks():\n            self.task_manager.task_done(\n                task.id, CancelledError())\n            self.worker_manager.stop_worker(task.worker_id)", "response": "Handles timing out Tasks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_workers(self):\n        for expiration in self.worker_manager.inspect_workers():\n            self.handle_worker_expiration(expiration)\n\n        self.worker_manager.create_workers()", "response": "Handles unexpected processes termination."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the tasks result and run the callback.", "response": "def task_done(self, task_id, result):\n        \"\"\"Set the tasks result and run the callback.\"\"\"\n        try:\n            task = self.tasks.pop(task_id)\n        except KeyError:\n            return  # result of previously timeout Task\n        else:\n            if task.future.cancelled():\n                task.set_running_or_notify_cancel()\n            elif isinstance(result, BaseException):\n                task.future.set_exception(result)\n            else:\n                task.future.set_result(result)\n\n            self.task_done_callback()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inspect_workers(self):\n        workers = tuple(self.workers.values())\n        expired = tuple(w for w in workers if not w.is_alive())\n\n        for worker in expired:\n            self.workers.pop(worker.pid)\n\n        return ((w.pid, w.exitcode) for w in expired if w.exitcode != 0)", "response": "Updates the status of the workers and returns the workers which have unexpectedly ended."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over zipped iterables in chunks.", "response": "def iter_chunks(chunksize, *iterables):\n    \"\"\"Iterates over zipped iterables in chunks.\"\"\"\n    iterables = iter(zip(*iterables))\n\n    while 1:\n        chunk = tuple(islice(iterables, chunksize))\n\n        if not chunk:\n            return\n\n        yield chunk"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_initializer(initializer, initargs):\n    try:\n        initializer(*initargs)\n        return True\n    except Exception as error:\n        logging.exception(error)\n        return False", "response": "Runs the Pool initializer dealing with errors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef join(self, timeout=None):\n        if self._context.state == RUNNING:\n            raise RuntimeError('The Pool is still running')\n        if self._context.state == CLOSED:\n            self._wait_queue_depletion(timeout)\n            self.stop()\n            self.join()\n        else:\n            self._context.task_queue.put(None)\n            self._stop_pool()", "response": "Joins the pool waiting until all workers are done."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels the future. Returns True if any of the elements of the iterables is cancelled.", "response": "def cancel(self):\n        \"\"\"Cancel the future.\n\n        Returns True if any of the elements of the iterables is cancelled.\n        False otherwise.\n        \"\"\"\n        super(MapFuture, self).cancel()\n\n        return any(tuple(f.cancel() for f in self._futures))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels the process map future. Returns True if any of the iterables is cancelled False otherwise.", "response": "def cancel(self):\n        \"\"\"Cancel the future.\n\n        Returns True if any of the elements of the iterables is cancelled.\n        False otherwise.\n        \"\"\"\n        super(ProcessMapFuture, self).cancel()\n\n        return any(tuple(f.cancel() for f in self._futures))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the decorated function within a concurrent thread, taking care of the result and error management. Decorated functions will return a concurrent.futures.Future object once called.", "response": "def thread(function):\n    \"\"\"Runs the decorated function within a concurrent thread,\n    taking care of the result and error management.\n\n    Decorated functions will return a concurrent.futures.Future object\n    once called.\n\n    \"\"\"\n    @wraps(function)\n    def wrapper(*args, **kwargs):\n        future = Future()\n\n        launch_thread(_function_handler, function, args, kwargs, future)\n\n        return future\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _function_handler(function, args, kwargs, future):\n    future.set_running_or_notify_cancel()\n\n    try:\n        result = function(*args, **kwargs)\n    except BaseException as error:\n        error.traceback = format_exc()\n        future.set_exception(error)\n    else:\n        future.set_result(result)", "response": "Runs the actual function in separate thread and returns its result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nposting fields and files to an http host as multipart / form - data.", "response": "def post_multipart(host, selector, fields, files):\n    \"\"\"\n    Post fields and files to an http host as multipart/form-data.\n    fields is a sequence of (name, value) elements for regular form fields.\n    files is a sequence of (name, filename, value) elements for data to be uploaded as files\n    Return the server's response page.\n    \"\"\"\n    content_type, body = encode_multipart_formdata(fields, files)\n    h = httplib.HTTP(host)\n    h.putrequest('POST', selector)\n    h.putheader('content-type', content_type)\n    h.putheader('content-length', str(len(body)))\n    h.endheaders()\n    h.send(body)\n    errcode, errmsg, headers = h.getreply()\n    return h.file.read()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode_multipart_formdata(fields, files):\n    BOUNDARY = '----------ThIs_Is_tHe_bouNdaRY_$'\n    CRLF = '\\r\\n'\n    L = []\n    for (key, value) in fields:\n        L.append('--' + BOUNDARY)\n        L.append('Content-Disposition: form-data; name=\"%s\"' % key)\n        L.append('')\n        L.append(value)\n    for (key, filename, value) in files:\n        L.append('--' + BOUNDARY)\n        L.append('Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (key, filename))\n        L.append('Content-Type: %s' % guess_content_type(filename))\n        L.append('')\n        L.append(value)\n    L.append('--' + BOUNDARY + '--')\n    L.append('')\n    body = CRLF.join(L)\n    content_type = 'multipart/form-data; boundary=%s' % BOUNDARY\n    return content_type, body", "response": "Encode multipart form data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_cities_csv(filename=\"places2k.txt\", output=\"cities.csv\"):\n    with open(filename, 'r') as city_file:\n        with open(output, 'w') as out:\n            for line in city_file:\n                # Drop Puerto Rico (just looking for the 50 states)\n                if line[0:2] == \"PR\":\n                    continue\n                    # Per census.gov, characters 9-72 are the name of the city or place. Cut ,off the last part, which is city, town, etc.\n                #                    print \" \".join(line[9:72].split()[:-1])\n                out.write(\" \".join(line[9:72].split()[:-1]) + '\\n')", "response": "Takes the places2k. txt from USPS and creates a simple file of all cities."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_address(self, address, line_number=-1):\n        return Address(address, self, line_number, self.logger)", "response": "Parse an address and return an Address object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_suffixes(self, filename):\n        with open(filename, 'r') as f:\n            for line in f:\n                # Make sure we have key and value\n                if len(line.split(',')) != 2:\n                    continue\n                    # Strip off newlines.\n                self.suffixes[line.strip().split(',')[0]] = line.strip().split(',')[1]", "response": "Load the suffix dictionary from a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload all cities from a file in lowercase for easier matching.", "response": "def load_cities(self, filename):\n        \"\"\"\n        Load up all cities in lowercase for easier matching. The file should have one city per line, with no extra\n        characters. This isn't strictly required, but will vastly increase the accuracy.\n        \"\"\"\n        with open(filename, 'r') as f:\n            for line in f:\n                self.cities.append(line.strip().lower())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_streets(self, filename):\n        with open(filename, 'r') as f:\n            for line in f:\n                self.streets.append(line.strip().lower())", "response": "Load all the streets from a file in lowercase for easier matching."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a basic address and attempts to clean it up, extract reasonably assured bits that may throw off the rest of the parsing, and return the cleaned address.", "response": "def preprocess_address(self, address):\n        \"\"\"\n        Takes a basic address and attempts to clean it up, extract reasonably assured bits that may throw off the\n        rest of the parsing, and return the cleaned address.\n        \"\"\"\n        # Run some basic cleaning\n        address = address.replace(\"# \", \"#\")\n        address = address.replace(\" & \", \"&\")\n        # Clear the address of things like 'X units', which shouldn't be in an address anyway. We won't save this for now.\n        if re.search(r\"-?-?\\w+ units\", address, re.IGNORECASE):\n            address = re.sub(r\"-?-?\\w+ units\", \"\", address, flags=re.IGNORECASE)\n            # Sometimes buildings are put in parantheses.\n        # building_match = re.search(r\"\\(.*\\)\", address, re.IGNORECASE)\n        # if building_match:\n        #     self.building = self._clean(building_match.group().replace('(', '').replace(')', ''))\n        #     address = re.sub(r\"\\(.*\\)\", \"\", address, flags=re.IGNORECASE)\n        # Now let's get the apartment stuff out of the way. Using only sure match regexes, delete apartment parts from\n        # the address. This prevents things like \"Unit\" being the street name.\n        apartment_regexes = [r'#\\w+ & \\w+', '#\\w+ rm \\w+', \"#\\w+-\\w\", r'apt #{0,1}\\w+', r'apartment #{0,1}\\w+', r'#\\w+',\n                             r'# \\w+', r'rm \\w+', r'unit #?\\w+', r'units #?\\w+', r'- #{0,1}\\w+', r'no\\s?\\d+\\w*',\n                             r'style\\s\\w{1,2}', r'townhouse style\\s\\w{1,2}']\n        for regex in apartment_regexes:\n            apartment_match = re.search(regex, address, re.IGNORECASE)\n            if apartment_match:\n            #                print \"Matched regex: \", regex, apartment_match.group()\n                self.apartment = self._clean(apartment_match.group())\n                address = re.sub(regex, \"\", address, flags=re.IGNORECASE)\n            # Now check for things like \",  ,\" which throw off dstk\n        address = re.sub(r\"\\,\\s*\\,\", \",\", address)\n        return address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the given token is a valid zip code.", "response": "def check_zip(self, token):\n        \"\"\"\n        Returns true if token is matches a zip code (5 numbers). Zip code must be the last token in an address (minus anything\n        removed during preprocessing such as --2 units.\n        \"\"\"\n        if self.zip is None:\n            # print \"last matched\", self.last_matched\n            if self.last_matched is not None:\n                return False\n                # print \"zip check\", len(token) == 5, re.match(r\"\\d{5}\", token)\n            if len(token) == 5 and re.match(r\"\\d{5}\", token):\n                self.zip = self._clean(token)\n\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_state(self, token):\n        # print \"zip\", self.zip\n        if len(token) == 2 and self.state is None:\n            if token.capitalize() in self.parser.states.keys():\n                self.state = self._clean(self.parser.states[token.capitalize()])\n                return True\n            elif token.upper() in self.parser.states.values():\n                self.state = self._clean(token.upper())\n                return True\n        if self.state is None and self.street_suffix is None and len(self.comma_separated_address) > 1:\n            if token.capitalize() in self.parser.states.keys():\n                self.state = self._clean(self.parser.states[token.capitalize()])\n                return True\n            elif token.upper() in self.parser.states.values():\n                self.state = self._clean(token.upper())\n                return True\n        return False", "response": "Check if state is in either the keys or values of our states list. Must come before the suffix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_city(self, token):\n        shortened_cities = {'saint': 'st.'}\n        if self.city is None and self.state is not None and self.street_suffix is None:\n            if token.lower() in self.parser.cities:\n                self.city = self._clean(token.capitalize())\n                return True\n            return False\n            # Check that we're in the correct location, and that we have at least one comma in the address\n        if self.city is None and self.apartment is None and self.street_suffix is None and len(\n                self.comma_separated_address) > 1:\n            if token.lower() in self.parser.cities:\n                self.city = self._clean(token.capitalize())\n                return True\n            return False\n        # Multi word cities\n        if self.city is not None and self.street_suffix is None and self.street is None:\n            print \"Checking for multi part city\", token.lower(), token.lower() in shortened_cities.keys()\n            if token.lower() + ' ' + self.city in self.parser.cities:\n                self.city = self._clean((token.lower() + ' ' + self.city).capitalize())\n                return True\n            if token.lower() in shortened_cities.keys():\n                token = shortened_cities[token.lower()]\n                print \"Checking for shorted multi part city\", token.lower() + ' ' + self.city\n                if token.lower() + ' ' + self.city.lower() in self.parser.cities:\n                    self.city = self._clean(token.capitalize() + ' ' + self.city.capitalize())\n                    return True", "response": "Check if the given token is a known city."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the given token is a valid apartment number.", "response": "def check_apartment_number(self, token):\n        \"\"\"\n        Finds apartment, unit, #, etc, regardless of spot in string. This needs to come after everything else has been ruled out,\n        because it has a lot of false positives.\n        \"\"\"\n        apartment_regexes = [r'#\\w+ & \\w+', '#\\w+ rm \\w+', \"#\\w+-\\w\", r'apt #{0,1}\\w+', r'apartment #{0,1}\\w+', r'#\\w+',\n                             r'# \\w+', r'rm \\w+', r'unit #?\\w+', r'units #?\\w+', r'- #{0,1}\\w+', r'no\\s?\\d+\\w*',\n                             r'style\\s\\w{1,2}', r'\\d{1,4}/\\d{1,4}', r'\\d{1,4}', r'\\w{1,2}']\n        for regex in apartment_regexes:\n            if re.match(regex, token.lower()):\n                self.apartment = self._clean(token)\n                return True\n            #        if self.apartment is None and re.match(apartment_regex_number, token.lower()):\n            ##            print \"Apt regex\"\n            #            self.apartment = token\n            #            return True\n            ## If we come on apt or apartment and already have an apartment number, add apt or apartment to the front\n        if self.apartment and token.lower() in ['apt', 'apartment']:\n        #            print \"Apt in a_n\"\n            self.apartment = self._clean(token + ' ' + self.apartment)\n            return True\n\n        if not self.street_suffix and not self.street and not self.apartment:\n        #            print \"Searching for unmatched term: \", token, token.lower(),\n            if re.match(r'\\d?\\w?', token.lower()):\n                self.apartment = self._clean(token)\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the given token is a street suffix. If not it will return the abbreviation with the first letter capitalized and a period after it.", "response": "def check_street_suffix(self, token):\n        \"\"\"\n        Attempts to match a street suffix. If found, it will return the abbreviation, with the first letter capitalized\n        and a period after it. E.g. \"St.\" or \"Ave.\"\n        \"\"\"\n        # Suffix must come before street\n        # print \"Suffix check\", token, \"suffix\", self.street_suffix, \"street\", self.street\n        if self.street_suffix is None and self.street is None:\n            # print \"upper\", token.upper()\n            if token.upper() in self.parser.suffixes.keys():\n                suffix = self.parser.suffixes[token.upper()]\n                self.street_suffix = self._clean(suffix.capitalize() + '.')\n                return True\n            elif token.upper() in self.parser.suffixes.values():\n                self.street_suffix = self._clean(token.capitalize() + '.')\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_street(self, token):\n        # First check for single word streets between a prefix and a suffix\n        if self.street is None and self.street_suffix is not None and self.street_prefix is None and self.house_number is None:\n            self.street = self._clean(token.capitalize())\n            return True\n        # Now check for multiple word streets. This check must come after the check for street_prefix and house_number for this reason.\n        elif self.street is not None and self.street_suffix is not None and self.street_prefix is None and self.house_number is None:\n            self.street = self._clean(token.capitalize() + ' ' + self.street)\n            return True\n        if not self.street_suffix and not self.street and token.lower() in self.parser.streets:\n            self.street = self._clean(token)\n            return True\n        return False", "response": "Check if a street is present in the list of available streets."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the given token is a street prefix.", "response": "def check_street_prefix(self, token):\n        \"\"\"\n        Finds street prefixes, such as N. or Northwest, before a street name. Standardizes to 1 or two letters, followed\n        by a period.\n        \"\"\"\n        if self.street and not self.street_prefix and token.lower().replace('.', '') in self.parser.prefixes.keys():\n            self.street_prefix = self._clean(self.parser.prefixes[token.lower().replace('.', '')])\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the given token is a house number.", "response": "def check_house_number(self, token):\n        \"\"\"\n        Attempts to find a house number, generally the first thing in an address. If anything is in front of it,\n        we assume it is a building name.\n        \"\"\"\n        if self.street and self.house_number is None and re.match(street_num_regex, token.lower()):\n            if '/' in token:\n                token = token.split('/')[0]\n            if '-' in token:\n                token = token.split('-')[0]\n            self.house_number = self._clean(str(token))\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_building(self, token):\n        if self.street and self.house_number:\n            if not self.building:\n                self.building = self._clean(token)\n            else:\n                self.building = self._clean(token + ' ' + self.building)\n            return True\n        return False", "response": "Check if we have leftover building names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef guess_unmatched(self, token):\n        # Check if this is probably an apartment:\n        if token.lower() in ['apt', 'apartment']:\n            return False\n            # Stray dashes are likely useless\n        if token.strip() == '-':\n            return True\n            # Almost definitely not a street if it is one or two characters long.\n        if len(token) <= 2:\n            return False\n            # Let's check for a suffix-less street.\n        if self.street_suffix is None and self.street is None and self.street_prefix is None and self.house_number is None:\n            # Streets will just be letters\n            if re.match(r\"[A-Za-z]\", token):\n                if self.line_number >= 0:\n                    pass\n                #                    print \"{0}: Guessing suffix-less street: \".format(self.line_number), token\n                else:\n                #                    print \"Guessing suffix-less street: \", token\n                    pass\n                self.street = self._clean(token.capitalize())\n                return True\n        return False", "response": "Guesses whether the given token is unambiguous."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the address in a human readable format", "response": "def full_address(self):\n        \"\"\"\n        Print the address in a human readable format\n        \"\"\"\n        addr = \"\"\n        # if self.building:\n        #     addr = addr + \"(\" + self.building + \") \"\n        if self.house_number:\n            addr = addr + self.house_number\n        if self.street_prefix:\n            addr = addr + \" \" + self.street_prefix\n        if self.street:\n            addr = addr + \" \" + self.street\n        if self.street_suffix:\n            addr = addr + \" \" + self.street_suffix\n        if self.apartment:\n            addr = addr + \" \" + self.apartment\n        if self.city:\n            addr = addr + \", \" + self.city\n        if self.state:\n            addr = addr + \", \" + self.state\n        if self.zip:\n            addr = addr + \" \" + self.zip\n        return addr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dstk_parse(self, address, parser, pre_parsed_address=None):\n        if pre_parsed_address:\n            dstk_address = pre_parsed_address\n        else:\n            if self.logger: self.logger.debug(\"Asking DSTK for address parse {0}\".format(address.encode(\"ascii\", \"ignore\")))\n            dstk_address = parser.dstk.street2coordinates(address)\n            # if self.logger: self.logger.debug(\"dstk return: {0}\".format(dstk_address))\n        if 'confidence' not in dstk_address:\n            raise InvalidAddressException(\"Could not deal with DSTK return: {0}\".format(dstk_address))\n        if dstk_address['street_address'] == \"\":\n            raise InvalidAddressException(\"Empty street address in DSTK return: {0}\".format(dstk_address))\n        if dstk_address['street_number']  is None or dstk_address['street_name'] is None:\n            raise InvalidAddressException(\"House number or street name was Non in DSTK return: {0}\".format(dstk_address))\n        if dstk_address['confidence'] < parser.required_confidence:\n            raise DSTKConfidenceTooLowException(\"Required confidence: {0}. Got confidence: {1}. Address: {2}. Return: {3}.\".format(parser.required_confidence, dstk_address['confidence'], address.encode(\"ascii\", \"ignore\"), dstk_address))\n        self.confidence = dstk_address['confidence']\n        if 'street_address' in dstk_address:\n            intersections = self._get_dstk_intersections(address, dstk_address['street_address'])\n        if self.logger: self.logger.debug(\"Confidence: {0}.\".format(dstk_address['confidence']))\n        if self.logger: self.logger.debug(\"Address: {0}.\".format(address))\n        if self.logger: self.logger.debug(\"Return: {0}.\".format(dstk_address))\n        # if self.logger: self.logger.debug(\"\")\n\n        addr = dstk_address\n        if addr is None:\n            raise InvalidAddressException(\"DSTK could not parse address: {0}\".format(self.original))\n        if \"street_number\" in addr:\n            if addr[\"street_number\"] not in address:\n                raise InvalidAddressException(\"DSTK returned a house number not in the original address: {0}\".format(addr))\n            self.house_number = addr[\"street_number\"]\n        else:\n            raise InvalidAddressException(\"(dstk) Addresses must have house numbers: {0}\".format(addr))\n\n        if \"locality\" in addr:\n            self.city = addr[\"locality\"]\n            # DSTK shouldn't be returning unknown cities\n            if addr[\"locality\"] not in address:\n                raise InvalidAddressException(\"DSTK returned a city not in the address. City: {0}, Address: {1}.\".format(self.city, address))\n        if \"region\" in addr:\n            self.state = addr[\"region\"]\n            # if \"fips_county\" in addr:\n            # self.zip = addr[\"fips_county\"]\n        if \"latitude\" in addr:\n            self.lat = addr[\"latitude\"]\n        if \"longitude\" in addr:\n            self.lng = addr[\"longitude\"]\n            # Try and find the apartment\n        # First remove the street_address (this doesn't include apartment)\n        if \"street_address\" in addr:\n            apartment = address.replace(addr[\"street_address\"], '')\n        # Make sure the city doesn't somehow come before the street in the original string.\n\n            # try:\n            #     end_pos = re.search(\"(\" + addr[\"locality\"] + \")\", apartment).start(1) - 1\n            #     # self.apartment = apartment[:end_pos]\n            # except Exception:\n            #     pass\n            # self.apartment = None\n        # Now that we have an address, try to parse out street suffix, prefix, and street\n        if self.apartment:\n            street_addr = addr[\"street_address\"].replace(self.apartment, '')\n        else:\n            street_addr = addr[\"street_address\"]\n\n        # We should be left with only prefix, street, suffix. Go for suffix first.\n        split_addr = street_addr.split()\n        if len(split_addr) == 0:\n            if self.logger: self.logger.debug(\"Could not split street_address: {0}\".format(addr))\n            raise InvalidAddressException(\"Could not split street_address: {0}\".format(addr))\n        # Get rid of house_number\n        if split_addr[0] == self.house_number:\n            split_addr = split_addr[1:]\n        if self.logger: self.logger.debug(\"Checking {0} for suffixes\".format(split_addr[-1].upper()))\n        if split_addr[-1].upper() in parser.suffixes.keys() or split_addr[-1].upper() in parser.suffixes.values():\n            self.street_suffix = split_addr[-1]\n            split_addr = split_addr[:-1]\n        if self.logger: self.logger.debug(\"Checking {0} for prefixes\".format(split_addr[0].lower()))\n        if split_addr[0].lower() in parser.prefixes.keys() or split_addr[0].upper() in parser.prefixes.values() or \\\n                                split_addr[0].upper() + '.' in parser.prefixes.values():\n            if split_addr[0][-1] == '.':\n                self.street_prefix = split_addr[0].upper()\n            else:\n                self.street_prefix = split_addr[0].upper() + '.'\n            if self.logger: self.logger.debug(\"Saving prefix: {0}\".format(self.street_prefix))\n            split_addr = split_addr[1:]\n        if self.logger: self.logger.debug(\"Saving street: {0}\".format(split_addr))\n        self.street = \" \".join(split_addr)\n        # DSTK shouldn't be guessing cities that come before streets.\n        match = re.search(self.street, address)\n        if match is None:\n            raise InvalidAddressException(\"DSTK picked a street not in the original address. Street: {0}. Address: {1}.\".format(self.street, address))\n        street_position = match\n        match = re.search(self.city, address)\n        if match is None:\n            raise InvalidAddressException(\"DSTK picked a city not in the original address. City: {0}. Address: {1}.\".format(self.city, address))\n        city_position = match\n        if city_position.start(0) < street_position.end(0):\n            raise InvalidAddressException(\"DSTK picked a street that comes after the city. Street: {0}. City: {1}. Address: {2}.\".format(self.street, self.city, address))\n        if self.logger: self.logger.debug(\"Successful DSTK address: {0}, house: {1}, street: {2}\\n\".format(self.original, self.house_number, self.street))", "response": "Parse an address string and return a dict of the relevant information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_dstk_intersections(self, address, dstk_address):\n        # Normalize both addresses\n        normalized_address = self._normalize(address)\n        normalized_dstk_address = self._normalize(dstk_address)\n        address_uniques = set(normalized_address) - set(normalized_dstk_address)\n        dstk_address_uniques = set(normalized_dstk_address) - set(normalized_address)\n        if self.logger: self.logger.debug(\"Address Uniques {0}\".format(address_uniques))\n        if self.logger: self.logger.debug(\"DSTK Address Uniques {0}\".format(dstk_address_uniques))\n        return (len(address_uniques), len(dstk_address_uniques))", "response": "Find the unique tokens in the original address and the returned address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _normalize(self, address):\n        normalized_address = []\n        if self.logger: self.logger.debug(\"Normalizing Address: {0}\".format(address))\n        for token in address.split():\n            if token.upper() in self.parser.suffixes.keys():\n                normalized_address.append(self.parser.suffixes[token.upper()].lower())\n            elif token.upper() in self.parser.suffixes.values():\n                normalized_address.append(token.lower())\n            elif token.upper().replace('.', '') in self.parser.suffixes.values():\n                normalized_address.append(token.lower().replace('.', ''))\n            elif token.lower() in self.parser.prefixes.keys():\n                normalized_address.append(self.parser.prefixes[token.lower()].lower())\n            elif token.upper() in self.parser.prefixes.values():\n                normalized_address.append(token.lower()[:-1])\n            elif token.upper() + '.' in self.parser.prefixes.values():\n                normalized_address.append(token.lower())\n            else:\n                normalized_address.append(token.lower())\n        return normalized_address", "response": "Normalizes the address to make matching original to return easier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an empty set.", "response": "def empty():\n    \"\"\"\n    Create an empty set.\n    \"\"\"\n    if not hasattr(empty, '_instance'):\n        empty._instance = Interval(AtomicInterval(OPEN, inf, -inf, OPEN))\n    return empty._instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a string and create an Interval instance.", "response": "def from_string(string, conv, bound=r'.+?', disj=r' ?\\| ?', sep=r', ?', left_open=r'\\(',\n                left_closed=r'\\[', right_open=r'\\)', right_closed=r'\\]', pinf=r'\\+inf', ninf=r'-inf'):\n    \"\"\"\n    Parse given string and create an Interval instance.\n    A converter function has to be provided to convert a bound (as string) to a value.\n\n    :param string: string to parse.\n    :param conv: function that converts a bound (as string) to an object.\n    :param bound: pattern that matches a value.\n    :param disj: pattern that matches the disjunctive operator (default matches '|').\n    :param sep: pattern that matches a bounds separator (default matches ',').\n    :param left_open: pattern that matches a left open boundary (default matches '(').\n    :param left_closed: pattern that matches a left closed boundary (default matches '[').\n    :param right_open: pattern that matches a right open boundary (default matches ')').\n    :param right_closed: pattern that matches a right closed boundary (default matches ']').\n    :param pinf: pattern that matches a positive infinity (default matches '+inf').\n    :param ninf: pattern that matches a negative infinity (default matches '-inf').\n    :return: an Interval instance.\n    \"\"\"\n\n    re_left_boundary = r'(?P<left>{}|{})'.format(left_open, left_closed)\n    re_right_boundary = r'(?P<right>{}|{})'.format(right_open, right_closed)\n    re_bounds = r'(?P<lower>{bound})({sep}(?P<upper>{bound}))?'.format(bound=bound, sep=sep)\n    re_interval = r'{}(|{}){}'.format(re_left_boundary, re_bounds, re_right_boundary)\n    re_intervals = r'{}(?P<disj>{})?'.format(re_interval, disj)\n\n    intervals = []\n    has_more = True\n\n    def _convert(bound):\n        if re.match(pinf, bound):\n            return inf\n        elif re.match(ninf, bound):\n            return -inf\n        else:\n            return conv(bound)\n\n    while has_more:\n        match = re.match(re_intervals, string)\n        if match is None:\n            has_more = False\n        else:\n            group = match.groupdict()\n\n            left = re.match(left_closed + '$', group['left']) is not None\n            right = re.match(right_closed + '$', group['right']) is not None\n\n            lower = group.get('lower', None)\n            upper = group.get('upper', None)\n            lower = _convert(lower) if lower is not None else inf\n            upper = _convert(upper) if upper is not None else lower\n\n            intervals.append(AtomicInterval(left, lower, upper, right))\n            string = string[match.end():]\n\n    return Interval(*intervals)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_string(interval, conv=repr, disj=' | ', sep=',', left_open='(',\n              left_closed='[', right_open=')', right_closed=']', pinf='+inf', ninf='-inf'):\n    \"\"\"\n    Export given interval (or atomic interval) to string.\n\n    :param interval: an Interval or AtomicInterval instance.\n    :param conv: function that is used to represent a bound (default is `repr`).\n    :param disj: string representing disjunctive operator (default is ' | ').\n    :param sep: string representing bound separator (default is ',').\n    :param left_open: string representing left open boundary (default is '(').\n    :param left_closed: string representing left closed boundary (default is '[').\n    :param right_open: string representing right open boundary (default is ')').\n    :param right_closed: string representing right closed boundary (default is ']').\n    :param pinf: string representing a positive infinity (default is '+inf').\n    :param ninf: string representing a negative infinity (default is '-inf').\n    :return: a string representation for given interval.\n    \"\"\"\n    interval = Interval(interval) if isinstance(interval, AtomicInterval) else interval\n\n    if interval.is_empty():\n        return '{}{}'.format(left_open, right_open)\n\n    def _convert(bound):\n        if bound == inf:\n            return pinf\n        elif bound == -inf:\n            return ninf\n        else:\n            return conv(bound)\n\n    exported_intervals = []\n    for item in interval:\n        left = left_open if item.left == OPEN else left_closed\n        right = right_open if item.right == OPEN else right_closed\n\n        lower = _convert(item.lower)\n        upper = _convert(item.upper)\n\n        if item.lower == item.upper:\n            exported_intervals.append('{}{}{}'.format(left, lower, right))\n        else:\n            exported_intervals.append('{}{}{}{}{}'.format(left, lower, sep, upper, right))\n\n    return disj.join(exported_intervals)", "response": "Export given interval to string representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports an interval from a list of 4 - tuple.", "response": "def from_data(data, conv=None, pinf=float('inf'), ninf=float('-inf')):\n    \"\"\"\n    Import an interval from a piece of data.\n\n    :param data: a list of 4-uples (left, lower, upper, right).\n    :param conv: function that is used to convert \"lower\" and \"upper\" to bounds, default to identity.\n    :param pinf: value used to represent positive infinity.\n    :param ninf: value used to represent negative infinity.\n    :return: an Interval instance.\n    \"\"\"\n    intervals = []\n    conv = (lambda v: v) if conv is None else conv\n\n    def _convert(bound):\n        if bound == pinf:\n            return inf\n        elif bound == ninf:\n            return -inf\n        else:\n            return conv(bound)\n\n    for item in data:\n        left, lower, upper, right = item\n        intervals.append(AtomicInterval(\n            left,\n            _convert(lower),\n            _convert(upper),\n            right\n        ))\n    return Interval(*intervals)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_data(interval, conv=None, pinf=float('inf'), ninf=float('-inf')):\n    interval = Interval(interval) if isinstance(interval, AtomicInterval) else interval\n    conv = (lambda v: v) if conv is None else conv\n\n    data = []\n\n    def _convert(bound):\n        if bound == inf:\n            return pinf\n        elif bound == -inf:\n            return ninf\n        else:\n            return conv(bound)\n\n    for item in interval:\n        data.append((\n            item.left,\n            _convert(item.lower),\n            _convert(item.upper),\n            item.right\n        ))\n    return data", "response": "Export given interval or atomic interval to a list of 4 - tuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_empty(self):\n        return (\n            self._lower > self._upper or\n            (self._lower == self._upper and (self._left == OPEN or self._right == OPEN))\n        )", "response": "Test interval emptiness.\n\n        :return: True if interval is empty, False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new Interval instance with the provided values replaced.", "response": "def replace(self, left=None, lower=None, upper=None, right=None, ignore_inf=True):\n        \"\"\"\n        Create a new interval based on the current one and the provided values.\n\n        Callable can be passed instead of values. In that case, it is called with the current\n        corresponding value except if ignore_inf if set (default) and the corresponding\n        bound is an infinity.\n\n        :param left: (a function of) left boundary.\n        :param lower: (a function of) value of the lower bound.\n        :param upper: (a function of) value of the upper bound.\n        :param right: (a function of) right boundary.\n        :param ignore_inf: ignore infinities if functions are provided (default is True).\n        :return: an Interval instance\n        \"\"\"\n        if callable(left):\n            left = left(self._left)\n        else:\n            left = self._left if left is None else left\n\n        if callable(lower):\n            lower = self._lower if ignore_inf and self._lower in [-inf, inf] else lower(self._lower)\n        else:\n            lower = self._lower if lower is None else lower\n\n        if callable(upper):\n            upper = self._upper if ignore_inf and self._upper in [-inf, inf] else upper(self._upper)\n        else:\n            upper = self._upper if upper is None else upper\n\n        if callable(right):\n            right = right(self._right)\n        else:\n            right = self._right if right is None else right\n\n        return AtomicInterval(left, lower, upper, right)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if two atomic intervals have any overlapping value.", "response": "def overlaps(self, other, permissive=False):\n        \"\"\"\n        Test if intervals have any overlapping value.\n\n        If 'permissive' is set to True (default is False), then [1, 2) and [2, 3] are considered as having\n        an overlap on value 2 (but not [1, 2) and (2, 3]).\n\n        :param other: an atomic interval.\n        :param permissive: set to True to consider contiguous intervals as well.\n        :return True if intervals overlap, False otherwise.\n        \"\"\"\n        if not isinstance(other, AtomicInterval):\n            raise TypeError('Only AtomicInterval instances are supported.')\n\n        if self._lower > other.lower:\n            first, second = other, self\n        else:\n            first, second = self, other\n\n        if first._upper == second._lower:\n            if permissive:\n                return first._right == CLOSED or second._left == CLOSED\n            else:\n                return first._right == CLOSED and second._left == CLOSED\n\n        return first._upper > second._lower"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_atomic(self):\n        lower = self._intervals[0].lower\n        left = self._intervals[0].left\n        upper = self._intervals[-1].upper\n        right = self._intervals[-1].right\n\n        return AtomicInterval(left, lower, upper, right)", "response": "Return the smallest atomic interval containing this interval."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new Interval instance based on the current interval and the provided values.", "response": "def replace(self, left=None, lower=None, upper=None, right=None, ignore_inf=True):\n        \"\"\"\n        Create a new interval based on the current one and the provided values.\n\n        If current interval is not atomic, it is extended or restricted such that\n        its enclosure satisfies the new bounds. In other words, its new enclosure\n        will be equal to self.to_atomic().replace(left, lower, upper, right).\n\n        Callable can be passed instead of values. In that case, it is called with the current\n        corresponding value except if ignore_inf if set (default) and the corresponding\n        bound is an infinity.\n\n        :param left: (a function of) left boundary.\n        :param lower: (a function of) value of the lower bound.\n        :param upper: (a function of) value of the upper bound.\n        :param right: (a function of) right boundary.\n        :param ignore_inf: ignore infinities if functions are provided (default is True).\n        :return: an Interval instance\n        \"\"\"\n        enclosure = self.to_atomic()\n\n        if callable(left):\n            left = left(enclosure._left)\n        else:\n            left = enclosure._left if left is None else left\n\n        if callable(lower):\n            lower = enclosure._lower if ignore_inf and enclosure._lower in [-inf, inf] else lower(enclosure._lower)\n        else:\n            lower = enclosure._lower if lower is None else lower\n\n        if callable(upper):\n            upper = enclosure._upper if ignore_inf and enclosure._upper in [-inf, inf] else upper(enclosure._upper)\n        else:\n            upper = enclosure._upper if upper is None else upper\n\n        if callable(right):\n            right = right(enclosure._right)\n        else:\n            right = enclosure._right if right is None else right\n\n        n_interval = self & AtomicInterval(left, lower, upper, right)\n\n        if len(n_interval) > 1:\n            lowest = n_interval[0].replace(left=left, lower=lower)\n            highest = n_interval[-1].replace(upper=upper, right=right)\n            return Interval(*[lowest] + n_interval[1:-1] + [highest])\n        else:\n            return Interval(n_interval[0].replace(left, lower, upper, right))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies given function on each of the underlying AtomicInterval instances and returns a new Interval instance.", "response": "def apply(self, func):\n        \"\"\"\n        Apply given function on each of the underlying AtomicInterval instances and return a new\n        Interval instance. The function is expected to return an AtomicInterval, an Interval\n        or a 4-uple (left, lower, upper, right).\n\n        :param func: function to apply on each of the underlying AtomicInterval instances.\n        :return: an Interval instance.\n        \"\"\"\n        intervals = []\n\n        for interval in self:\n            value = func(interval)\n\n            if isinstance(value, (Interval, AtomicInterval)):\n                intervals.append(value)\n            elif isinstance(value, tuple):\n                intervals.append(AtomicInterval(*value))\n            else:\n                raise TypeError('Unsupported return type {} for {}'.format(type(value), value))\n\n        return Interval(*intervals)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef overlaps(self, other, permissive=False):\n        if isinstance(other, AtomicInterval):\n            for interval in self._intervals:\n                if interval.overlaps(other, permissive=permissive):\n                    return True\n            return False\n        elif isinstance(other, Interval):\n            for o_interval in other._intervals:\n                if self.overlaps(o_interval, permissive=permissive):\n                    return True\n            return False\n        else:\n            raise TypeError('Unsupported type {} for {}'.format(type(other), other))", "response": "Test if two sets of intervals overlap."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a Tartiflette Engine to an application that will handle GraphQL requests.", "response": "def register_graphql_handlers(\n    app: \"Application\",\n    engine_sdl: str = None,\n    engine_schema_name: str = \"default\",\n    executor_context: dict = None,\n    executor_http_endpoint: str = \"/graphql\",\n    executor_http_methods: List[str] = None,\n    engine: Engine = None,\n    subscription_ws_endpoint: Optional[str] = None,\n    graphiql_enabled: bool = False,\n    graphiql_options: Optional[Dict[str, Any]] = None,\n) -> \"Application\":\n    \"\"\"Register a Tartiflette Engine to an app\n\n    Pass a SDL or an already initialized Engine, not both, not neither.\n\n    Keyword Arguments:\n        app {aiohttp.web.Application} -- The application to register to.\n        engine_sdl {str} -- The SDL defining your API (default: {None})\n        engine_schema_name {str} -- The name of your sdl (default: {\"default\"})\n        executor_context {dict} -- Context dict that will be passed to the resolvers (default: {None})\n        executor_http_endpoint {str} -- Path part of the URL the graphql endpoint will listen on (default: {\"/graphql\"})\n        executor_http_methods {list[str]} -- List of HTTP methods allowed on the endpoint (only GET and POST are supported) (default: {None})\n        engine {Engine} -- An already initialized Engine (default: {None})\n        subscription_ws_endpoint {Optional[str]} -- Path part of the URL the WebSocket GraphQL subscription endpoint will listen on (default: {None})\n        graphiql_enabled {bool} -- Determines whether or not we should handle a GraphiQL endpoint (default: {False})\n        graphiql_options {dict} -- Customization options for the GraphiQL instance (default: {None})\n\n    Raises:\n        Exception -- On bad sdl/engine parameter combinaison.\n        Exception -- On unsupported HTTP Method.\n\n    Return:\n        The app object.\n    \"\"\"\n    # pylint: disable=too-many-arguments,too-many-locals\n    if (not engine_sdl and not engine) or (engine and engine_sdl):\n        raise Exception(\n            \"an engine OR an engine_sdl should be passed here, not both, not none\"\n        )\n\n    if not executor_context:\n        executor_context = {}\n\n    executor_context[\"app\"] = app\n\n    if not executor_http_methods:\n        executor_http_methods = [\"GET\", \"POST\"]\n\n    if not engine:\n        engine = Engine(engine_sdl, engine_schema_name)\n\n    app[\"ttftt_engine\"] = engine\n\n    for method in executor_http_methods:\n        try:\n            app.router.add_route(\n                method,\n                executor_http_endpoint,\n                partial(\n                    getattr(Handlers, \"handle_%s\" % method.lower()),\n                    executor_context,\n                ),\n            )\n        except AttributeError:\n            raise Exception(\"Unsupported < %s > http method\" % method)\n\n    _set_subscription_ws_handler(app, subscription_ws_endpoint, engine)\n\n    _set_graphiql_handler(\n        app,\n        graphiql_enabled,\n        graphiql_options,\n        executor_http_endpoint,\n        executor_http_methods,\n        subscription_ws_endpoint,\n    )\n\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when the application is shutting down.", "response": "async def on_shutdown(app):\n    \"\"\"app SHUTDOWN event handler\n    \"\"\"\n    for method in app.get(\"close_methods\", []):\n        logger.debug(\"Calling < %s >\", method)\n        if asyncio.iscoroutinefunction(method):\n            await method()\n        else:\n            method()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a config file from the given path.", "response": "def _load_from_file(path):\n        \"\"\"Load a config file from the given path.\n\n        Load all normalizations from the config file received as\n        argument. It expects to find a YAML file with a list of\n        normalizations and arguments under the key 'normalizations'.\n\n        Args:\n            path: Path to YAML file.\n        \"\"\"\n        config = []\n\n        try:\n            with open(path, 'r') as config_file:\n                config = yaml.load(config_file)['normalizations']\n        except EnvironmentError as e:\n            raise ConfigError('Problem while loading file: %s' %\n                              e.args[1] if len(e.args) > 1 else e)\n        except (TypeError, KeyError) as e:\n            raise ConfigError('Config file has an unexpected structure: %s' % e)\n        except yaml.YAMLError:\n            raise ConfigError('Invalid YAML file syntax')\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_normalization(normalization):\n        parsed_normalization = None\n\n        if isinstance(normalization, dict):\n            if len(normalization.keys()) == 1:\n                items = list(normalization.items())[0]\n                if len(items) == 2: # Two elements tuple\n                    # Convert to string if no normalization options\n                    if items[1] and isinstance(items[1], dict):\n                        parsed_normalization = items\n                    else:\n                        parsed_normalization = items[0]\n        elif isinstance(normalization, STR_TYPE):\n            parsed_normalization = normalization\n\n        return parsed_normalization", "response": "Parse a normalization item."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a list of normalizations and returns a list of parsed normalizations.", "response": "def _parse_normalizations(self, normalizations):\n        \"\"\"Returns a list of parsed normalizations.\n\n        Iterates over a list of normalizations, removing those\n        not correctly defined. It also transform complex items\n        to have a common format (list of tuples and strings).\n\n        Args:\n            normalizations: List of normalizations to parse.\n\n        Returns:\n            A list of normalizations after being parsed and curated.\n        \"\"\"\n        parsed_normalizations = []\n\n        if isinstance(normalizations, list):\n            for item in normalizations:\n                normalization = self._parse_normalization(item)\n                if normalization:\n                    parsed_normalizations.append(normalization)\n        else:\n            raise ConfigError('List expected. Found %s' % type(normalizations))\n\n        return parsed_normalizations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize_logger(debug):\n    level = logging.DEBUG if debug else logging.INFO\n    logger = logging.getLogger('cucco')\n    logger.setLevel(level)\n    formatter = logging.Formatter('%(asctime)s %(levelname).1s %(message)s')\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(level)\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n\n    return logger", "response": "Initialize the logger to be used by the library."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing all files found in a given path.", "response": "def batch(ctx, path, recursive, watch):\n    \"\"\"\n    Normalize files in a path.\n\n    Apply normalizations over all files found in a given path.\n    The normalizations applied will be those defined in the config\n    file. If no config is specified, the default normalizations will\n    be used.\n    \"\"\"\n    batch = Batch(ctx.obj['config'], ctx.obj['cucco'])\n\n    if os.path.exists(path):\n        if watch:\n            batch.watch(path, recursive)\n        elif os.path.isfile(path):\n            batch.process_file(path)\n        else:\n            batch.process_files(path, recursive)\n    else:\n        click.echo('Error: Specified path doesn\\'t exists', err=True)\n        sys.exit(-1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize(ctx, text):\n    if text:\n        click.echo(ctx.obj['cucco'].normalize(text))\n    else:\n        for line in sys.stdin:\n            click.echo(ctx.obj['cucco'].normalize(line))", "response": "Normalize text or piped input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cli(ctx, config, debug, language, verbose):\n    ctx.obj = {}\n\n    try:\n        ctx.obj['config'] = Config(normalizations=config,\n                                   language=language,\n                                   debug=debug,\n                                   verbose=verbose)\n    except ConfigError as e:\n        click.echo(e.message)\n        sys.exit(-1)\n\n    ctx.obj['cucco'] = Cucco(ctx.obj['config'])", "response": "A base command line interface for Cucco."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding all the files found in a given path.", "response": "def files_generator(path, recursive):\n    \"\"\"Yield files found in a given path.\n\n    Walk over a given path finding and yielding all\n    files found on it. This can be done only on the root\n    directory or recursively.\n\n    Args:\n        path: Path to the directory.\n        recursive: Whether to find files recursively or not.\n\n    Yields:\n        A tuple for each file in the given path containing\n        the path and the name of the file.\n    \"\"\"\n    if recursive:\n        for (path, _, files) in os.walk(path):\n            for file in files:\n                if not file.endswith(BATCH_EXTENSION):\n                    yield (path, file)\n    else:\n        for file in os.listdir(path):\n            if (os.path.isfile(os.path.join(path, file)) and\n                    not file.endswith(BATCH_EXTENSION)):\n                yield (path, file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a file applying normalizations to every single line in the original file.", "response": "def process_file(self, path):\n        \"\"\"Process a file applying normalizations.\n\n        Get a file as input and generate a new file with the\n        result of applying normalizations to every single line\n        in the original file. The extension for the new file\n        will be the one defined in BATCH_EXTENSION.\n\n        Args:\n            path: Path to the file.\n        \"\"\"\n        if self._config.verbose:\n            self._logger.info('Processing file \"%s\"', path)\n\n        output_path = '%s%s' % (path, BATCH_EXTENSION)\n\n        with open(output_path, 'w') as file:\n            for line in lines_generator(path):\n                file.write('%s\\n' % self._cucco.normalize(\n                           line.encode().decode('utf-8')))\n\n        self._logger.debug('Created file \"%s\"', output_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating over all files in a given directory and process them.", "response": "def process_files(self, path, recursive=False):\n        \"\"\"Apply normalizations over all files in the given directory.\n\n        Iterate over all files in a given directory. Normalizations\n        will be applied to each file, storing the result in a new file.\n        The extension for the new file will be the one defined in\n        BATCH_EXTENSION.\n\n        Args:\n            path: Path to the directory.\n            recursive: Whether to find files recursively or not.\n        \"\"\"\n        self._logger.info('Processing files in \"%s\"', path)\n\n        for (path, file) in files_generator(path, recursive):\n            if not file.endswith(BATCH_EXTENSION):\n                self.process_file(os.path.join(path, file))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop_watching(self):\n        self._watch = False\n\n        if self._observer:\n            self._logger.info('Stopping watcher')\n            self._observer.stop()\n            self._logger.info('Watcher stopped')", "response": "Stop watching for files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwatches for new or changed files in a directory and apply normalizations over them.", "response": "def watch(self, path, recursive=False):\n        \"\"\"Watch for files in a directory and apply normalizations.\n\n        Watch for new or changed files in a directory and apply\n        normalizations over them.\n\n        Args:\n            path: Path to the directory.\n            recursive: Whether to find files recursively or not.\n        \"\"\"\n        self._logger.info('Initializing watcher for path \"%s\"', path)\n\n        handler = FileHandler(self)\n        self._observer = Observer()\n        self._observer.schedule(handler, path, recursive)\n\n        self._logger.info('Starting watcher')\n        self._observer.start()\n        self._watch = True\n\n        try:\n            self._logger.info('Waiting for file events')\n            while self._watch:\n                time.sleep(1)\n        except KeyboardInterrupt: # pragma: no cover\n            self.stop_watching()\n\n        self._observer.join()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_event(self, event):\n        if (not event.is_directory and\n                not event.src_path.endswith(BATCH_EXTENSION)):\n            self._logger.info('Detected file change: %s', event.src_path)\n            self._batch.process_file(event.src_path)", "response": "Process events received by the server and apply normalization for those those\n        events referencing a new or changed file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_created(self, event):\n        self._logger.debug('Detected create event on watched path: %s', event.src_path)\n\n        self._process_event(event)", "response": "Called every time a new file is created."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall every time a new file is modified.", "response": "def on_modified(self, event):\n        \"\"\"Function called everytime a new file is modified.\n\n        Args:\n            event: Event to process.\n        \"\"\"\n        self._logger.debug('Detected modify event on watched path: %s', event.src_path)\n\n        self._process_event(event)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_stop_words(self, language=None):\n        self._logger.debug('Loading stop words')\n\n        loaded = False\n\n        if language:\n            file_path = 'data/stop-' + language\n            loaded = self._parse_stop_words_file(os.path.join(PATH, file_path))\n        else:\n            for file in os.listdir(os.path.join(PATH, 'data')):\n                loaded = self._parse_stop_words_file(os.path.join(PATH, 'data', file)) or loaded\n\n        return loaded", "response": "Load stop words into the __stop_words set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_normalizations(normalizations):\n        str_type = str if sys.version_info[0] > 2 else (str, unicode)\n\n        for normalization in normalizations:\n            yield (normalization, {}) if isinstance(normalization, str_type) else normalization", "response": "Parse and yield all normalizations and\n            arguments found on it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the stop words file and save each word found in it in a set containing the language of the file.", "response": "def _parse_stop_words_file(self, path):\n        \"\"\"Load stop words from the given path.\n\n        Parse the stop words file, saving each word found in it in a set\n        for the language of the file. This language is obtained from\n        the file name. If the file doesn't exist, the method will have\n        no effect.\n\n        Args:\n            path: Path to the stop words file.\n\n        Returns:\n            A boolean indicating whether the file was loaded.\n        \"\"\"\n        language = None\n        loaded = False\n\n        if os.path.isfile(path):\n            self._logger.debug('Loading stop words in %s', path)\n\n            language = path.split('-')[-1]\n\n            if not language in self.__stop_words:\n                self.__stop_words[language] = set()\n\n            with codecs.open(path, 'r', 'UTF-8') as file:\n                loaded = True\n                for word in file:\n                    self.__stop_words[language].add(word.strip())\n\n        return loaded"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize a given text applying all normalizations.", "response": "def normalize(self, text, normalizations=None):\n        \"\"\"Normalize a given text applying all normalizations.\n\n        Normalizations to apply can be specified through a list of\n        parameters and will be executed in that order.\n\n        Args:\n            text: The text to be processed.\n            normalizations: List of normalizations to apply.\n\n        Returns:\n            The text normalized.\n        \"\"\"\n        for normalization, kwargs in self._parse_normalizations(\n                normalizations or self._config.normalizations):\n            try:\n                text = getattr(self, normalization)(text, **kwargs)\n            except AttributeError as e:\n                self._logger.debug('Invalid normalization: %s', e)\n\n\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving accent marks from input text.", "response": "def remove_accent_marks(text, excluded=None):\n        \"\"\"Remove accent marks from input text.\n\n        This function removes accent marks in the text, but leaves\n        unicode characters defined in the 'excluded' parameter.\n\n        Args:\n            text: The text to be processed.\n            excluded: Set of unicode characters to exclude.\n\n        Returns:\n            The text without accent marks.\n        \"\"\"\n        if excluded is None:\n            excluded = set()\n\n        return unicodedata.normalize(\n            'NFKC', ''.join(\n                c for c in unicodedata.normalize(\n                    'NFKD', text) if unicodedata.category(c) != 'Mn' or c in excluded))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving stop words from the given text.", "response": "def remove_stop_words(self, text, ignore_case=True, language=None):\n        \"\"\"Remove stop words.\n\n        Stop words are loaded on class instantiation according\n        to the specified language.\n\n        Args:\n            text: The text to be processed.\n            ignore_case: Whether or not to ignore case.\n            language: Code of the language to use (defaults to 'en').\n\n        Returns:\n            The text without stop words.\n        \"\"\"\n        if not language:\n            language = self._config.language\n\n        if language not in self.__stop_words:\n            if not self._load_stop_words(language):\n                self._logger.error('No stop words file for the given language')\n                return text\n\n        return ' '.join(word for word in text.split(' ') if (\n            word.lower() if ignore_case else word) not in self.__stop_words[language])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove custom characters from text or replaces them with a string if specified.", "response": "def replace_characters(self, text, characters, replacement=''):\n        \"\"\"Remove characters from text.\n\n        Removes custom characters from input text or replaces them\n        with a string if specified.\n\n        Args:\n            text: The text to be processed.\n            characters: Characters that will be replaced.\n            replacement: New text that will replace the custom characters.\n\n        Returns:\n            The text without the given characters.\n        \"\"\"\n        if not characters:\n            return text\n\n        characters = ''.join(sorted(characters))\n        if characters in self._characters_regexes:\n            characters_regex = self._characters_regexes[characters]\n        else:\n            characters_regex = re.compile(\"[%s]\" % re.escape(characters))\n            self._characters_regexes[characters] = characters_regex\n\n        return characters_regex.sub(replacement, text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_punctuation(self, text, excluded=None, replacement=''):\n        if excluded is None:\n            excluded = set()\n        elif not isinstance(excluded, set):\n            excluded = set(excluded)\n        punct = ''.join(self.__punctuation.difference(excluded))\n\n        return self.replace_characters(\n            text, characters=punct, replacement=replacement)", "response": "Replace punctuation symbols in text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace symbols in text with new ones if specified.", "response": "def replace_symbols(\n            text,\n            form='NFKD',\n            excluded=None,\n            replacement=''):\n        \"\"\"Replace symbols in text.\n\n        Removes symbols from input text or replaces them with a\n        string if specified.\n\n        Args:\n            text: The text to be processed.\n            form: Unicode form.\n            excluded: Set of unicode characters to exclude.\n            replacement: New text that will replace symbols.\n\n        Returns:\n            The text without symbols.\n        \"\"\"\n        if excluded is None:\n            excluded = set()\n\n        categories = set(['Mn', 'Sc', 'Sk', 'Sm', 'So'])\n\n        return ''.join(c if unicodedata.category(c) not in categories or c in excluded\n                       else replacement for c in unicodedata.normalize(form, text))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_cases(self, target):\n        if target in self.targets:\n            return self._reverse_map[target]\n\n        raise KeyError(\"Target 0x{:08X} does not exist.\".format(target))", "response": "Return a list of all cases that are related to the given target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport IDB to a NetworkX graph.", "response": "def get_idb_graph():\n    \"\"\"Export IDB to a NetworkX graph.\n\n    Use xrefs to and from functions to build a DiGraph containing all\n    the functions in the IDB and all the links between them.\n    The graph can later be used to perform analysis on the IDB.\n\n    :return: nx.DiGraph()\n    \"\"\"\n    digraph = nx.DiGraph()\n\n    for function in functions():\n        for xref in itertools.chain(function.xrefs_from, function.xrefs_to):\n            frm = _try_get_function_start(xref.frm)\n            to = _try_get_function_start(xref.to)\n\n            digraph.add_edge(frm, to)\n\n    return digraph"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef name(self):\n        return self.TYPES.get(self._type, self.TYPES[idaapi.o_idpspec0])", "response": "Name of the xref type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reg(self):\n        if self.type.is_displ or self.type.is_phrase:\n            size = core.get_native_size()\n            return base.get_register_name(self.reg_id, size)\n\n        if self.type.is_reg:\n            return base.get_register_name(self.reg_id, self.size)\n\n        else:\n            raise exceptions.SarkOperandWithoutReg(\"Operand does not have a register.\")", "response": "Name of the register used in the operand."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_reg(self, reg_name):\n        return any(operand.has_reg(reg_name) for operand in self.operands)", "response": "Check if a register is used in the instruction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nname of all registers used by the instruction.", "response": "def regs(self):\n        \"\"\"Names of all registers used by the instruction.\"\"\"\n        regs = set()\n        for operand in self.operands:\n            if not operand.type.has_reg:\n                continue\n            regs.update(operand.regs)\n        return regs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes the title unique.", "response": "def _make_unique_title(self, title):\n        \"\"\"Make the title unique.\n\n        Adds a counter to the title to prevent duplicates.\n\n        Prior to IDA 6.8, two graphs with the same title could crash IDA.\n        This has been fixed (https://www.hex-rays.com/products/ida/6.8/index.shtml).\n        The code will not change for support of older versions and as it is\n        more usable this way.\n        \"\"\"\n        unique_title = title\n\n        for counter in itertools.count():\n            unique_title = \"{}-{}\".format(title, counter)\n            if not idaapi.find_tform(unique_title):\n                break\n\n        return unique_title"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the handler of a given node.", "response": "def _get_handler(self, node_id):\n        \"\"\"Get the handler of a given node.\"\"\"\n        handler = self._get_attrs(node_id).get(self.HANDLER, self._default_handler)\n\n        # Here we make sure the handler is an instance of `BasicNodeHandler` or inherited\n        # types. While generally being bad Python practice, we still need it here as an\n        # invalid handler can cause IDA to crash.\n        if not isinstance(handler, BasicNodeHandler):\n            idaapi.msg((\"Invalid handler for node {}: {}. All handlers must inherit from\"\n                        \"`BasicNodeHandler`.\").format(node_id, handler))\n            handler = self._default_handler\n        return handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_handling_triplet(self, node_id):\n        handler = self._get_handler(node_id)\n        value = self[node_id]\n        attrs = self._get_attrs(node_id)\n\n        return handler, value, attrs", "response": "Internal method to get the handling triples for a node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the node info based on its attributes.", "response": "def _OnNodeInfo(self, node_id):\n        \"\"\"Sets the node info based on its attributes.\"\"\"\n        handler, value, attrs = self._get_handling_triplet(node_id)\n        frame_color = handler.on_frame_color(value, attrs)\n\n        node_info = idaapi.node_info_t()\n\n        if frame_color is not None:\n            node_info.frame_color = frame_color\n\n        flags = node_info.get_flags_for_valid()\n\n        self.SetNodeInfo(node_id, node_info, flags)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the string at the given EA.", "response": "def get_string(ea):\n    \"\"\"Read the string at the given ea.\n\n    This function uses IDA's string APIs and does not implement any special logic.\n    \"\"\"\n    # We get the item-head because the `GetStringType` function only works on the head of an item.\n    string_type = idc.GetStringType(idaapi.get_item_head(ea))\n\n    if string_type is None:\n        raise exceptions.SarkNoString(\"No string at 0x{:08X}\".format(ea))\n\n    string = idc.GetString(ea, strtype=string_type)\n\n    if not string:\n        raise exceptions.SarkNoString(\"No string at 0x{:08X}\".format(ea))\n\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the file - offset mapped to the current address.", "response": "def copy_current_file_offset():\n    \"\"\"Get the file-offset mapped to the current address.\"\"\"\n    start, end = sark.get_selection()\n\n    try:\n        file_offset = sark.core.get_fileregion_offset(start)\n        clipboard.copy(\"0x{:08X}\".format(file_offset))\n\n    except sark.exceptions.NoFileOffset:\n        message(\"The current address cannot be mapped to a valid offset of the input file.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_func(func_ea):\n    if isinstance(func_ea, idaapi.func_t):\n        return func_ea\n    func = idaapi.get_func(func_ea)\n    if func is None:\n        raise exceptions.SarkNoFunction(\"No function at 0x{:08X}\".format(func_ea))\n\n    return func", "response": "get_func - Returns an IDA function object for the given address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_addresses(start=None, end=None):\n    if start in (None, idaapi.BADADDR):\n        start = idaapi.cvar.inf.minEA\n\n    if end in (None, idaapi.BADADDR):\n        end = idaapi.cvar.inf.maxEA\n\n    return start, end", "response": "Set missing addresses to start and end of IDB."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_name(address, name, anyway=False):\n    success = idaapi.set_name(address, name, idaapi.SN_NOWARN | idaapi.SN_NOCHECK)\n    if success:\n        return\n\n    if anyway:\n        success = idaapi.do_name_anyway(address, name)\n        if success:\n            return\n\n        raise exceptions.SarkSetNameFailed(\"Failed renaming 0x{:08X} to {!r}.\".format(address, name))\n\n    raise exceptions.SarkErrorNameAlreadyExists(\n        \"Can't rename 0x{:08X}. Name {!r} already exists.\".format(address, name))", "response": "Set the name of an address in IDA."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbeing both addresses in the same function?", "response": "def is_same_function(ea1, ea2):\n    \"\"\"Are both addresses in the same function?\"\"\"\n    func1 = idaapi.get_func(ea1)\n    func2 = idaapi.get_func(ea2)\n    # This is bloated code. `None in (func1, func2)` will not work because of a\n    # bug in IDAPython in the way functions are compared.\n    if any(func is None for func in (func1, func2)):\n        return False\n\n    return func1.startEA == func2.startEA"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an IDA flowchart to a NetworkX graph.", "response": "def get_nx_graph(ea):\n    \"\"\"Convert an IDA flowchart to a NetworkX graph.\"\"\"\n    nx_graph = networkx.DiGraph()\n    func = idaapi.get_func(ea)\n    flowchart = FlowChart(func)\n    for block in flowchart:\n        # Make sure all nodes are added (including edge-less nodes)\n        nx_graph.add_node(block.startEA)\n\n        for pred in block.preds():\n            nx_graph.add_edge(pred.startEA, block.startEA)\n        for succ in block.succs():\n            nx_graph.add_edge(block.startEA, succ.startEA)\n\n    return nx_graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef codeblocks(start=None, end=None, full=True):\n    if full:\n        for function in functions(start, end):\n            fc = FlowChart(f=function.func_t)\n            for block in fc:\n                yield block\n\n    else:\n        start, end = fix_addresses(start, end)\n\n        for code_block in FlowChart(bounds=(start, end)):\n            yield code_block", "response": "Get all CodeBlock s in a given range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef struct_member_error(err, sid, name, offset, size):\n    exception, msg = STRUCT_ERROR_MAP[err]\n    struct_name = idc.GetStrucName(sid)\n    return exception(('AddStructMember(struct=\"{}\", member=\"{}\", offset={}, size={}) '\n                      'failed: {}').format(\n        struct_name,\n        name,\n        offset,\n        size,\n        msg\n    ))", "response": "Create and format a struct member exception."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a structure. Args: name: The structure's name Returns: The sturct ID Raises: exceptions.SarkStructAlreadyExists: A struct with the same name already exists exceptions.SarkCreationFailed: Struct creation failed", "response": "def create_struct(name):\n    \"\"\"Create a structure.\n\n    Args:\n        name: The structure's name\n\n    Returns:\n        The sturct ID\n\n    Raises:\n        exceptions.SarkStructAlreadyExists: A struct with the same name already exists\n        exceptions.SarkCreationFailed:  Struct creation failed\n    \"\"\"\n    sid = idc.GetStrucIdByName(name)\n    if sid != idaapi.BADADDR:\n        # The struct already exists.\n        raise exceptions.SarkStructAlreadyExists(\"A struct names {!r} already exists.\".format(name))\n\n    sid = idc.AddStrucEx(-1, name, 0)\n    if sid == idaapi.BADADDR:\n        raise exceptions.SarkStructCreationFailed(\"Struct creation failed.\")\n\n    return sid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a struct by it s name.", "response": "def get_struct(name):\n    \"\"\"Get a struct by it's name.\n\n    Args:\n        name: The name of the struct\n\n    Returns:\n        The struct's id\n\n    Raises:\n        exceptions.SarkStructNotFound: is the struct does not exist.\n    \"\"\"\n    sid = idc.GetStrucIdByName(name)\n    if sid == idaapi.BADADDR:\n        raise exceptions.SarkStructNotFound()\n\n    return sid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_common_register(start, end):\n    registers = defaultdict(int)\n    for line in lines(start, end):\n        insn = line.insn\n\n        for operand in insn.operands:\n\n            if not operand.type.has_phrase:\n                continue\n\n            if not operand.base:\n                continue\n\n            register_name = operand.base\n            registers[register_name] += 1\n\n    return max(registers.iteritems(), key=operator.itemgetter(1))[0]", "response": "Get the register most commonly used in accessing structs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _enum_member_error(err, eid, name, value, bitmask):\n    exception, msg = ENUM_ERROR_MAP[err]\n    enum_name = idaapi.get_enum_name(eid)\n    return exception(('add_enum_member(enum=\"{}\", member=\"{}\", value={}, bitmask=0x{:08X}) '\n                      'failed: {}').format(\n        enum_name,\n        name,\n        value,\n        bitmask,\n        msg\n    ))", "response": "Format enum member error."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an existing enum ID", "response": "def _get_enum(name):\n    \"\"\"Get an existing enum ID\"\"\"\n    eid = idaapi.get_enum(name)\n    if eid == idaapi.BADADDR:\n        raise exceptions.EnumNotFound('Enum \"{}\" does not exist.'.format(name))\n    return eid"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_enum(name=None, index=None, flags=idaapi.hexflag(), bitfield=False):\n    if name is not None:\n        with ignored(exceptions.EnumNotFound):\n            _get_enum(name)\n            raise exceptions.EnumAlreadyExists()\n\n    if index is None or index < 0:\n        index = idaapi.get_enum_qty()\n\n    eid = idaapi.add_enum(index, name, flags)\n\n    if eid == idaapi.BADADDR:\n        raise exceptions.EnumCreationFailed('Failed creating enum \"{}\"'.format(name))\n\n    if bitfield:\n        idaapi.set_enum_bf(eid, bitfield)\n\n    return Enum(eid=eid)", "response": "Create a new enum."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an enum member.", "response": "def _add_enum_member(enum, name, value, bitmask=DEFMASK):\n    \"\"\"Add an enum member.\"\"\"\n    error = idaapi.add_enum_member(enum, name, value, bitmask)\n\n    if error:\n        raise _enum_member_error(error, enum, name, value, bitmask)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iter_bitmasks(eid):\n    bitmask = idaapi.get_first_bmask(eid)\n\n    yield bitmask\n\n    while bitmask != DEFMASK:\n        bitmask = idaapi.get_next_bmask(eid, bitmask)\n        yield bitmask", "response": "Iterate all bitmasks in a given enum."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _iter_enum_member_values(eid, bitmask):\n    value = idaapi.get_first_enum_member(eid, bitmask)\n\n    yield value\n    while value != DEFMASK:\n        value = idaapi.get_next_enum_member(eid, value, bitmask)\n        yield value", "response": "Iterate member values with given bitmask inside the enum\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating serial and CID of enum members with given value and bitmask.", "response": "def _iter_serial_enum_member(eid, value, bitmask):\n    \"\"\"Iterate serial and CID of enum members with given value and bitmask.\n\n    Here only valid values are returned, as `idaapi.BADNODE` always indicates\n    an invalid member.\n    \"\"\"\n    cid, serial = idaapi.get_first_serial_enum_member(eid, value, bitmask)\n    while cid != idaapi.BADNODE:\n        yield cid, serial\n        cid, serial = idaapi.get_next_serial_enum_member(cid, serial)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _iter_enum_constant_ids(eid):\n    for bitmask in _iter_bitmasks(eid):\n        for value in _iter_enum_member_values(eid, bitmask):\n            for cid, serial in _iter_serial_enum_member(eid, value, bitmask):\n                yield cid", "response": "Iterate the constant IDs of all members in the given enum."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an enum member to the resource.", "response": "def add(self, name, value, bitmask=DEFMASK):\n        \"\"\"Add an enum member\n\n        Args:\n            name: Name of the member\n            value: value of the member\n            bitmask: bitmask. Only use if enum is a bitfield.\n        \"\"\"\n        _add_enum_member(self._eid, name, value, bitmask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an enum member by name", "response": "def remove(self, name):\n        \"\"\"Remove an enum member by name\"\"\"\n        member = self[name]\n        serial = member.serial\n        value = member.value\n        bmask = member.bmask\n\n        success = idaapi.del_enum_member(self._eid, value, serial, bmask)\n        if not success:\n            raise exceptions.CantDeleteEnumMember(\"Can't delete enum member {!r}.\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the enum name.", "response": "def name(self, name):\n        \"\"\"Set the enum name.\"\"\"\n        success = idaapi.set_enum_name(self.eid, name)\n        if not success:\n            raise exceptions.CantRenameEnum(\"Cant rename enum {!r} to {!r}.\".format(self.name, name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the name of the IDB.", "response": "def name(self, name):\n        \"\"\"Set the member name.\n\n        Note that a member name cannot appear in other enums, or generally\n        anywhere else in the IDB.\n        \"\"\"\n        success = idaapi.set_enum_member_name(self.cid, name)\n        if not success:\n            raise exceptions.CantRenameEnumMember(\n                \"Failed renaming {!r} to {!r}. Does the name exist somewhere else?\".format(self.name, name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes the object input and returns a tuple of output object length consumed.", "response": "def hex_encode(input, errors='strict'):\n    \"\"\" Encodes the object input and returns a tuple (output\n        object, length consumed).\n\n        errors defines the error handling to apply. It defaults to\n        'strict' handling which is the only currently supported\n        error handling for this codec.\n\n    \"\"\"\n    assert errors == 'strict'\n    temp = binascii.b2a_hex(input)\n    output = \" \".join(temp[i:i + 2] for i in xrange(0, len(temp), 2))\n    return (output, len(input))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding the object input and returns a tuple of output object and length consumed.", "response": "def hex_decode(input, errors='strict'):\n    \"\"\" Decodes the object input and returns a tuple (output\n        object, length consumed).\n\n        input must be an object which provides the bf_getreadbuf\n        buffer slot. Python strings, buffer objects and memory\n        mapped files are examples of objects providing this slot.\n\n        errors defines the error handling to apply. It defaults to\n        'strict' handling which is the only currently supported\n        error handling for this codec.\n\n    \"\"\"\n    assert errors == 'strict'\n    output = binascii.a2b_hex(\"\".join(char for char in input if char in hexdigits))\n    return (output, len(input))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all functions in the IDB.", "response": "def functions(start=None, end=None):\n    \"\"\"Get all functions in range.\n\n    Args:\n        start: Start address of the range. Defaults to IDB start.\n        end: End address of the range. Defaults to IDB end.\n\n    Returns:\n        This is a generator that iterates over all the functions in the IDB.\n    \"\"\"\n    start, end = fix_addresses(start, end)\n\n    for func_t in idautils.Functions(start, end):\n        yield Function(func_t)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding the xrefs from the function s lines.", "response": "def xrefs_from(self):\n        \"\"\"Xrefs from the function.\n\n        This includes the xrefs from every line in the function, as `Xref` objects.\n        Xrefs are filtered to exclude code references that are internal to the function. This\n        means that every xrefs to the function's code will NOT be returned (yet, references\n        to the function's data will be returnd). To get those extra xrefs, you need to iterate\n        the function's lines yourself.\n        \"\"\"\n        for line in self.lines:\n            for xref in line.xrefs_from:\n                if xref.type.is_flow:\n                    continue\n\n                if xref.to in self and xref.iscode:\n                    continue\n\n                yield xref"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_name(self, name, anyway=False):\n        set_name(self.startEA, name, anyway=anyway)", "response": "Set the name of the IDA entry in the IDB."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions color in IDA View", "response": "def color(self):\n        \"\"\"Function color in IDA View\"\"\"\n        color = idc.GetColor(self.ea, idc.CIC_FUNC)\n        if color == 0xFFFFFFFF:\n            return None\n\n        return color"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef color(self, color):\n        if color is None:\n            color = 0xFFFFFFFF\n\n        idc.SetColor(self.ea, idc.CIC_FUNC, color)", "response": "Function Color in IDA View."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate lines in range.", "response": "def lines(start=None, end=None, reverse=False, selection=False):\n    \"\"\"Iterate lines in range.\n\n    Args:\n        start: Starting address, start of IDB if `None`.\n        end: End address, end of IDB if `None`.\n        reverse: Set to true to iterate in reverse order.\n        selection: If set to True, replaces start and end with current selection.\n\n    Returns:\n        iterator of `Line` objects.\n    \"\"\"\n    if selection:\n        start, end = get_selection()\n\n    else:\n        start, end = fix_addresses(start, end)\n\n    if not reverse:\n        item = idaapi.get_item_head(start)\n        while item < end:\n            yield Line(item)\n            item += idaapi.get_item_size(item)\n\n    else:  # if reverse:\n        item = idaapi.get_item_head(end - 1)\n        while item >= start:\n            yield Line(item)\n            item = idaapi.get_item_head(item - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the type of the Line", "response": "def type(self):\n        \"\"\"return the type of the Line \"\"\"\n        properties = {self.is_code: \"code\",\n                      self.is_data: \"data\",\n                      self.is_string: \"string\",\n                      self.is_tail: \"tail\",\n                      self.is_unknown: \"unknown\"}\n        for k, v in properties.items():\n            if k: return v"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef color(self):\n        color = idc.GetColor(self.ea, idc.CIC_ITEM)\n        if color == 0xFFFFFFFF:\n            return None\n\n        return color", "response": "Line color in IDA View"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlines Color in IDA View.", "response": "def color(self, color):\n        \"\"\"Line Color in IDA View.\n\n        Set color to `None` to clear the color.\n        \"\"\"\n        if color is None:\n            color = 0xFFFFFFFF\n\n        idc.SetColor(self.ea, idc.CIC_ITEM, color)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngrabs an image of a Qt widget and return it as PNG buffer.", "response": "def capture_widget(widget, path=None):\n    \"\"\"Grab an image of a Qt widget\n\n    Args:\n        widget: The Qt Widget to capture\n        path (optional): The path to save to. If not provided - will return image data.\n\n    Returns:\n        If a path is provided, the image will be saved to it.\n        If not, the PNG buffer will be returned.\n    \"\"\"\n    if use_qt5:\n        pixmap = widget.grab()\n    else:\n        pixmap = QtGui.QPixmap.grabWidget(widget)\n\n    if path:\n        pixmap.save(path)\n\n    else:\n        image_buffer = QtCore.QBuffer()\n        image_buffer.open(QtCore.QIODevice.ReadWrite)\n\n        pixmap.save(image_buffer, \"PNG\")\n\n        return image_buffer.data().data()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the Qt widget of the IDA window with the given title.", "response": "def get_widget(title):\n    \"\"\"Get the Qt widget of the IDA window with the given title.\"\"\"\n    tform = idaapi.find_tform(title)\n    if not tform:\n        raise exceptions.FormNotFound(\"No form titled {!r} found.\".format(title))\n\n    return form_to_widget(tform)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets IDA s top level window.", "response": "def get_window():\n    \"\"\"Get IDA's top level window.\"\"\"\n    tform = idaapi.get_current_tform()\n\n    # Required sometimes when closing IDBs and not IDA.\n    if not tform:\n        tform = idaapi.find_tform(\"Output window\")\n\n    widget = form_to_widget(tform)\n    window = widget.window()\n    return window"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a top - level menu.", "response": "def add_menu(self, name):\n        \"\"\"Add a top-level menu.\n\n        The menu manager only allows one menu of the same name. However, it does\n        not make sure that there are no pre-existing menus of that name.\n        \"\"\"\n        if name in self._menus:\n            raise exceptions.MenuAlreadyExists(\"Menu name {!r} already exists.\".format(name))\n        menu = self._menu.addMenu(name)\n        self._menus[name] = menu"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a top - level menu.", "response": "def remove_menu(self, name):\n        \"\"\"Remove a top-level menu.\n\n        Only removes menus created by the same menu manager.\n        \"\"\"\n        if name not in self._menus:\n            raise exceptions.MenuNotFound(\n                \"Menu {!r} was not found. It might be deleted, or belong to another menu manager.\".format(name))\n\n        self._menu.removeAction(self._menus[name].menuAction())\n        del self._menus[name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclearing all menus created by this manager.", "response": "def clear(self):\n        \"\"\"Clear all menus created by this manager.\"\"\"\n        for menu in self._menus.itervalues():\n            self._menu.removeAction(menu.menuAction())\n        self._menus = {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_by_flags(self, flags):\n        for reg in self._reg_infos:\n            if reg.flags & flags == flags:\n                yield reg", "response": "Iterate all register infos matching the given flags."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the single entry matching the given flags. Raises ValueError if more than one entry is found.", "response": "def get_single_by_flags(self, flags):\n        \"\"\"Get the register info matching the flag. Raises ValueError if more than one are found.\"\"\"\n        regs = list(self.get_by_flags(flags))\n        if len(regs) != 1:\n            raise ValueError(\"Flags do not return unique resigter. {!r}\", regs)\n\n        return regs[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef segments(seg_type=None):\n\n    for index in xrange(idaapi.get_segm_qty()):\n        seg = Segment(index=index)\n        if (seg_type is None) or (seg.type == seg_type):\n            yield Segment(index=index)", "response": "Iterate segments based on type\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the next segment.", "response": "def next(self):\n        \"\"\"Get the next segment.\"\"\"\n        seg = Segment(segment_t=idaapi.get_next_seg(self.ea))\n\n        if seg.ea <= self.ea:\n            raise exceptions.NoMoreSegments(\"This is the last segment. No segments exist after it.\")\n\n        return seg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prev(self):\n        seg = Segment(segment_t=idaapi.get_prev_seg(self.ea))\n\n        if seg.ea >= self.ea:\n            raise exceptions.NoMoreSegments(\"This is the first segment. no segments exist before it.\")\n\n        return seg", "response": "Get the previous segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compare_version(a, b):  # Ignore PyDocStyleBear\n\n    def _range(q):\n        \"\"\"Convert a version string to array of integers.\n\n        \"1.2.3\" -> [1, 2, 3]\n\n        :param q: str\n        :return: List[int]\n        \"\"\"\n        r = []\n        for n in q.replace(\"-\", \".\").split(\".\"):\n            try:\n                r.append(int(n))\n            except ValueError:\n                # sort rc*, alpha, beta etc. lower than their non-annotated counterparts\n                r.append(-1)\n        return r\n\n    def _append_zeros(x, num_zeros):\n        \"\"\"Append `num_zeros` zeros to a copy of `x` and return it.\n\n        :param x: List[int]\n        :param num_zeros: int\n        :return: List[int]\n        \"\"\"\n        nx = list(x)\n        for _ in range(num_zeros):\n            nx.append(0)\n        return nx\n\n    def _cardinal(x, y):\n        \"\"\"Make both input lists be of same cardinality.\n\n        :param x: List[int]\n        :param y: List[int]\n        :return: List[int]\n        \"\"\"\n        lx, ly = len(x), len(y)\n        if lx == ly:\n            return x, y\n        elif lx > ly:\n            return x, _append_zeros(y, lx - ly)\n        else:\n            return _append_zeros(x, ly - lx), y\n\n    left, right = _cardinal(_range(a), _range(b))\n\n    return (left > right) - (left < right)", "response": "Compare two version strings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ecosystem_solver(ecosystem_name, parser_kwargs=None, fetcher_kwargs=None):\n    from .python import PythonSolver\n\n    if ecosystem_name.lower() == \"pypi\":\n        source = Source(url=\"https://pypi.org/simple\", warehouse_api_url=\"https://pypi.org/pypi\", warehouse=True)\n        return PythonSolver(parser_kwargs, fetcher_kwargs={\"source\": source})\n\n    raise NotImplementedError(\"Unknown ecosystem: {}\".format(ecosystem_name))", "response": "Get Solver subclass instance for particular ecosystem."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check(self, version):  # Ignore PyDocStyleBear\n\n        def _compare_spec(spec):\n            if len(spec) == 1:\n                spec = (\"=\", spec[0])\n\n            token = Tokens.operators.index(spec[0])\n            comparison = compare_version(version, spec[1])\n            if token in [Tokens.EQ1, Tokens.EQ2]:\n                return comparison == 0\n            elif token == Tokens.GT:\n                return comparison == 1\n            elif token == Tokens.LT:\n                return comparison == -1\n            elif token == Tokens.GTE:\n                return comparison >= 0\n            elif token == Tokens.LTE:\n                return comparison <= 0\n            elif token == Tokens.NEQ:\n                return comparison != 0\n            else:\n                raise ValueError(\"Invalid comparison token\")\n\n        results, intermediaries = False, False\n        for spec in self.spec:\n            if isinstance(spec, list):\n                intermediary = True\n                for sub in spec:\n                    intermediary &= _compare_spec(sub)\n                intermediaries |= intermediary\n            elif isinstance(spec, tuple):\n                results |= _compare_spec(spec)\n\n        return results or intermediaries", "response": "Check if version fits into our dependency specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef solve(self, dependencies, graceful=True, all_versions=False):  # Ignore PyDocStyleBear\n\n        def _compare_version_index_url(v1, v2):\n            \"\"\"Get a wrapper around compare version to omit index url when sorting.\"\"\"\n            return compare_version(v1[0], v2[0])\n\n        solved = {}\n        for dep in self.dependency_parser.parse(dependencies):\n            _LOGGER.debug(\"Fetching releases for: {}\".format(dep))\n\n            name, releases = self.release_fetcher.fetch_releases(dep.name)\n\n            if name in solved:\n                raise SolverException(\"Dependency: {} is listed multiple times\".format(name))\n\n            if not releases:\n                if graceful:\n                    _LOGGER.info(\"No releases found for package %s\", dep.name)\n                else:\n                    raise SolverException(\"No releases found for package {}\".format(dep.name))\n\n            releases = [release for release in releases if release in dep]\n            matching = sorted(releases, key=cmp_to_key(_compare_version_index_url))\n\n            _LOGGER.debug(\"  matching: %s\", matching)\n\n            if all_versions:\n                solved[name] = matching\n            else:\n                if not matching:\n                    solved[name] = None\n                else:\n                    if self._highest_dependency_version:\n                        solved[name] = matching[-1]\n                    else:\n                        solved[name] = matching[0]\n\n        return solved", "response": "Solve dependencies against upstream repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pip_compile(*packages: str):\n    result = None\n    packages = \"\\n\".join(packages)\n\n    with tempfile.TemporaryDirectory() as tmp_dirname, cwd(tmp_dirname):\n        with open(\"requirements.in\", \"w\") as requirements_file:\n            requirements_file.write(packages)\n\n        runner = CliRunner()\n\n        try:\n            result = runner.invoke(cli, [\"requirements.in\"], catch_exceptions=False)\n        except Exception as exc:\n            raise ThothPipCompileError(str(exc)) from exc\n\n        if result.exit_code != 0:\n            error_msg = (\n                f\"pip-compile returned non-zero ({result.exit_code:d}) \" f\"output: {result.output_bytes.decode():s}\"\n            )\n            raise ThothPipCompileError(error_msg)\n\n    return result.output_bytes.decode()", "response": "Run pip - compile to pin down packages also resolve their transitive dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _print_version(ctx, _, value):\n    if not value or ctx.resilient_parsing:\n        return\n    click.echo(analyzer_version)\n    ctx.exit()", "response": "Print solver version and exit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli(ctx=None, verbose=0):\n    if ctx:\n        ctx.auto_envvar_prefix = \"THOTH_SOLVER\"\n\n    if verbose:\n        _LOG.setLevel(logging.DEBUG)\n\n    _LOG.debug(\"Debug mode is on\")", "response": "Thoth solver command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pypi(\n    click_ctx,\n    requirements,\n    index=None,\n    python_version=3,\n    exclude_packages=None,\n    output=None,\n    subgraph_check_api=None,\n    no_transitive=True,\n    no_pretty=False,\n):\n    \"\"\"Manipulate with dependency requirements using PyPI.\"\"\"\n    requirements = [requirement.strip() for requirement in requirements.split(\"\\\\n\") if requirement]\n\n    if not requirements:\n        _LOG.error(\"No requirements specified, exiting\")\n        sys.exit(1)\n\n    if not subgraph_check_api:\n        _LOG.info(\n            \"No subgraph check API provided, no queries will be done for dependency subgraphs that should be avoided\"\n        )  # Ignore PycodestyleBear (E501)\n\n    result = resolve_python(\n        requirements,\n        index_urls=index.split(\",\") if index else (\"https://pypi.org/simple\",),\n        python_version=int(python_version),\n        transitive=not no_transitive,\n        exclude_packages=set(map(str.strip, (exclude_packages or \"\").split(\",\"))),\n        subgraph_check_api=subgraph_check_api,\n    )\n\n    print_command_result(\n        click_ctx,\n        result,\n        analyzer=analyzer_name,\n        analyzer_version=analyzer_version,\n        output=output or \"-\",\n        pretty=not no_pretty,\n    )", "response": "Manipulate with dependency requirements using PyPI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering and normalize the output of pipdeptree entry.", "response": "def _create_entry(entry: dict, source: Source = None) -> dict:\n    \"\"\"Filter and normalize the output of pipdeptree entry.\"\"\"\n    entry[\"package_name\"] = entry[\"package\"].pop(\"package_name\")\n    entry[\"package_version\"] = entry[\"package\"].pop(\"installed_version\")\n\n    if source:\n        entry[\"index_url\"] = source.url\n        entry[\"sha256\"] = []\n        for item in source.get_package_hashes(entry[\"package_name\"], entry[\"package_version\"]):\n            entry[\"sha256\"].append(item[\"sha256\"])\n\n    entry.pop(\"package\")\n    for dependency in entry[\"dependencies\"]:\n        dependency.pop(\"key\", None)\n        dependency.pop(\"installed_version\", None)\n\n    return entry"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_environment_details(python_bin: str) -> list:\n    cmd = \"{} -m pipdeptree --json\".format(python_bin)\n    output = run_command(cmd, is_json=True).stdout\n    return [_create_entry(entry) for entry in output]", "response": "Get information about packages in environment where packages get installed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nasks the given subgraph check API if the given package in the given version should be included in the resolution.", "response": "def _should_resolve_subgraph(subgraph_check_api: str, package_name: str, package_version: str, index_url: str) -> bool:\n    \"\"\"Ask the given subgraph check API if the given package in the given version should be included in the resolution.\n\n    This subgraph resolving avoidence serves two purposes - we don't need to\n    resolve dependency subgraphs that were already analyzed and we also avoid\n    analyzing of \"core\" packages (like setuptools) where not needed as they\n    can break installation environment.\n    \"\"\"\n    _LOGGER.info(\n        \"Checking if the given dependency subgraph for package %r in version %r from index %r should be resolved\",\n        package_name,\n        package_version,\n        index_url,\n    )\n\n    response = requests.get(\n        subgraph_check_api,\n        params={\"package_name\": package_name, \"package_version\": package_version, \"index_url\": index_url},\n    )\n\n    if response.status_code == 200:\n        return True\n    elif response.status_code == 208:\n        # This is probably not the correct HTTP status code to be used here, but which one should be used?\n        return False\n\n    response.raise_for_status()\n    raise ValueError(\n        \"Unreachable code - subgraph check API responded with unknown HTTP status \"\n        \"code %s for package %r in version %r from index %r\",\n        package_name,\n        package_version,\n        index_url,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls a requirement in a specific version of a package.", "response": "def _install_requirement(\n    python_bin: str, package: str, version: str = None, index_url: str = None, clean: bool = True\n) -> None:\n    \"\"\"Install requirements specified using suggested pip binary.\"\"\"\n    previous_version = _pipdeptree(python_bin, package)\n\n    try:\n        cmd = \"{} -m pip install --force-reinstall --no-cache-dir --no-deps {}\".format(python_bin, quote(package))\n        if version:\n            cmd += \"=={}\".format(quote(version))\n        if index_url:\n            cmd += ' --index-url \"{}\" '.format(quote(index_url))\n            # Supply trusted host by default so we do not get errors - it safe to\n            # do it here as package indexes are managed by Thoth.\n            trusted_host = urlparse(index_url).netloc\n            cmd += \" --trusted-host {}\".format(trusted_host)\n\n        _LOGGER.debug(\"Installing requirement %r in version %r\", package, version)\n        run_command(cmd)\n        yield\n    finally:\n        if clean:\n            _LOGGER.debug(\"Removing installed package %r\", package)\n            cmd = \"{} -m pip uninstall --yes {}\".format(python_bin, quote(package))\n            result = run_command(cmd, raise_on_error=False)\n\n            if result.return_code != 0:\n                _LOGGER.warning(\n                    \"Failed to restore previous environment by removing package %r (installed version %r), \"\n                    \"the error is not fatal but can affect future actions: %s\",\n                    package,\n                    version,\n                    result.stderr,\n                )\n\n            _LOGGER.debug(\n                \"Restoring previous environment setup after installation of %r (%s)\", package, previous_version\n            )\n            if previous_version:\n                cmd = \"{} -m pip install --force-reinstall --no-cache-dir --no-deps {}=={}\".format(\n                    python_bin, quote(package), quote(previous_version[\"package\"][\"installed_version\"])\n                )\n                result = run_command(cmd, raise_on_error=False)\n\n                if result.return_code != 0:\n                    _LOGGER.warning(\n                        \"Failed to restore previous environment for package %r (installed version %r), \"\n                        \", the error is not fatal but can affect future actions (previous version: %r): %s\",\n                        package,\n                        version,\n                        previous_version,\n                        result.stderr,\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget pip dependency tree by executing pipdeptree tool.", "response": "def _pipdeptree(python_bin, package_name: str = None, warn: bool = False) -> typing.Optional[dict]:\n    \"\"\"Get pip dependency tree by executing pipdeptree tool.\"\"\"\n    cmd = \"{} -m pipdeptree --json\".format(python_bin)\n\n    _LOGGER.debug(\"Obtaining pip dependency tree using: %r\", cmd)\n    output = run_command(cmd, is_json=True).stdout\n\n    if not package_name:\n        return output\n\n    for entry in output:\n        # In some versions pipdeptree does not work with --packages flag, do the logic on out own.\n        # TODO: we should probably do difference of reference this output and original environment\n        if entry[\"package\"][\"key\"].lower() == package_name.lower():\n            return entry\n\n    # The given package was not found.\n    if warn:\n        _LOGGER.warning(\"Package %r was not found in pipdeptree output %r\", package_name, output)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_dependency_specification(dep_spec: typing.List[tuple]) -> str:\n    return \",\".join(dep_range[0] + dep_range[1] for dep_range in dep_spec)", "response": "Get string representation of dependency specification as provided by PythonDependencyParser."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _do_resolve_index(\n    python_bin: str,\n    solver: PythonSolver,\n    *,\n    all_solvers: typing.List[PythonSolver],\n    requirements: typing.List[str],\n    exclude_packages: set = None,\n    transitive: bool = True,\n    subgraph_check_api: str = None,\n) -> dict:\n    \"\"\"Perform resolution of requirements against the given solver.\"\"\"\n    index_url = solver.release_fetcher.index_url\n    source = solver.release_fetcher.source\n\n    packages_seen = set()\n    packages = []\n    errors = []\n    unresolved = []\n    unparsed = []\n    exclude_packages = exclude_packages or {}\n    queue = deque()\n\n    for requirement in requirements:\n        _LOGGER.debug(\"Parsing requirement %r\", requirement)\n        try:\n            dependency = PythonDependencyParser.parse_python(requirement)\n        except Exception as exc:\n            unparsed.append({\"requirement\": requirement, \"details\": str(exc)})\n            continue\n\n        if dependency.name in exclude_packages:\n            continue\n\n        version_spec = _get_dependency_specification(dependency.spec)\n        resolved_versions = _resolve_versions(solver, source, dependency.name, version_spec)\n        if not resolved_versions:\n            _LOGGER.warning(\"No versions were resolved for dependency %r in version %r\", dependency.name, version_spec)\n            unresolved.append({\"package_name\": dependency.name, \"version_spec\": version_spec, \"index\": index_url})\n        else:\n            for version in resolved_versions:\n                entry = (dependency.name, version)\n                packages_seen.add(entry)\n                queue.append(entry)\n\n    while queue:\n        package_name, package_version = queue.pop()\n        _LOGGER.info(\"Using index %r to discover package %r in version %r\", index_url, package_name, package_version)\n        try:\n            with _install_requirement(python_bin, package_name, package_version, index_url):\n                package_info = _pipdeptree(python_bin, package_name, warn=True)\n        except CommandError as exc:\n            _LOGGER.debug(\n                \"There was an error during package %r in version %r discovery from %r: %s\",\n                package_name,\n                package_version,\n                index_url,\n                exc,\n            )\n            errors.append(\n                {\n                    \"package_name\": package_name,\n                    \"index\": index_url,\n                    \"version\": package_version,\n                    \"type\": \"command_error\",\n                    \"details\": exc.to_dict(),\n                }\n            )\n            continue\n\n        if package_info is None:\n            errors.append(\n                {\n                    \"package_name\": package_name,\n                    \"index\": index_url,\n                    \"version\": package_version,\n                    \"type\": \"not_site_package\",\n                    \"details\": {\n                        \"message\": \"Failed to get information about installed package, probably not site package\"\n                    },\n                }\n            )\n            continue\n\n        if package_info[\"package\"][\"installed_version\"] != package_version:\n            _LOGGER.warning(\n                \"Requested to install version %r of package %r, but installed version is %r, error is not fatal\",\n                package_version,\n                package_name,\n                package_info[\"package\"][\"installed_version\"],\n            )\n\n        if package_info[\"package\"][\"package_name\"] != package_name:\n            _LOGGER.warning(\n                \"Requested to install package %r, but installed package name is %r, error is not fatal\",\n                package_name,\n                package_info[\"package\"][\"package_name\"],\n            )\n\n        entry = _create_entry(package_info, source)\n        packages.append(entry)\n\n        for dependency in entry[\"dependencies\"]:\n            dependency_name, dependency_range = dependency[\"package_name\"], dependency[\"required_version\"]\n            dependency[\"resolved_versions\"] = []\n\n            for dep_solver in all_solvers:\n                _LOGGER.info(\n                    \"Resolving dependency versions for %r with range %r from %r\",\n                    dependency_name,\n                    dependency_range,\n                    dep_solver.release_fetcher.index_url,\n                )\n                resolved_versions = _resolve_versions(\n                    dep_solver, dep_solver.release_fetcher.source, dependency_name, dependency_range\n                )\n                _LOGGER.debug(\n                    \"Resolved versions for package %r with range specifier %r: %s\",\n                    dependency_name,\n                    dependency_range,\n                    resolved_versions,\n                )\n                dependency[\"resolved_versions\"].append(\n                    {\"versions\": resolved_versions, \"index\": dep_solver.release_fetcher.index_url}\n                )\n\n                if not transitive:\n                    continue\n\n                for version in resolved_versions:\n                    # Did we check this package already - do not check indexes, we manually insert them.\n                    seen_entry = (dependency_name, version)\n                    if seen_entry not in packages_seen and (\n                        not subgraph_check_api\n                        or (\n                            subgraph_check_api\n                            and _should_resolve_subgraph(subgraph_check_api, dependency_name, version, index_url)\n                        )\n                    ):\n                        _LOGGER.debug(\n                            \"Adding package %r in version %r for next resolution round\", dependency_name, version\n                        )\n                        packages_seen.add(seen_entry)\n                        queue.append((dependency_name, version))\n\n    return {\"tree\": packages, \"errors\": errors, \"unparsed\": unparsed, \"unresolved\": unresolved}", "response": "Perform resolution of requirements against the given solver."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve(\n    requirements: typing.List[str],\n    index_urls: list = None,\n    python_version: int = 3,\n    exclude_packages: set = None,\n    transitive: bool = True,\n    subgraph_check_api: str = None,\n) -> dict:\n    \"\"\"Resolve given requirements for the given Python version.\"\"\"\n    assert python_version in (2, 3), \"Unknown Python version\"\n\n    if subgraph_check_api and not transitive:\n        _LOGGER.error(\"The check against subgraph API cannot be done if no transitive dependencies are resolved\")\n        sys.exit(2)\n\n    python_bin = \"python3\" if python_version == 3 else \"python2\"\n    run_command(\"virtualenv -p python3 venv\")\n    python_bin = \"venv/bin/\" + python_bin\n\n    run_command(\"{} -m pip install pipdeptree\".format(python_bin))\n    environment_details = _get_environment_details(python_bin)\n\n    result = {\"tree\": [], \"errors\": [], \"unparsed\": [], \"unresolved\": [], \"environment\": environment_details}\n\n    all_solvers = []\n    for index_url in index_urls:\n        source = Source(index_url)\n        all_solvers.append(PythonSolver(fetcher_kwargs={\"source\": source}))\n\n    for solver in all_solvers:\n        solver_result = _do_resolve_index(\n            python_bin=python_bin,\n            solver=solver,\n            all_solvers=all_solvers,\n            requirements=requirements,\n            exclude_packages=exclude_packages,\n            transitive=transitive,\n            subgraph_check_api=subgraph_check_api,\n        )\n\n        result[\"tree\"].extend(solver_result[\"tree\"])\n        result[\"errors\"].extend(solver_result[\"errors\"])\n        result[\"unparsed\"].extend(solver_result[\"unparsed\"])\n        result[\"unresolved\"].extend(solver_result[\"unresolved\"])\n\n    return result", "response": "Resolve given requirements for the given Python version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch package and index_url for a package_name.", "response": "def fetch_releases(self, package_name):\n        \"\"\"Fetch package and index_url for a package_name.\"\"\"\n        package_name = self.source.normalize_package_name(package_name)\n        releases = self.source.get_package_versions(package_name)\n        releases_with_index_url = [(item, self.index_url) for item in releases]\n        return package_name, releases_with_index_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a single dependency specification of a single dependency.", "response": "def parse_python(spec):  # Ignore PyDocStyleBear\n        \"\"\"Parse PyPI specification of a single dependency.\n\n        :param spec: str, for example \"Django>=1.5,<1.8\"\n        :return: [Django [[('>=', '1.5'), ('<', '1.8')]]]\n        \"\"\"\n\n        def _extract_op_version(spec):\n            # https://www.python.org/dev/peps/pep-0440/#compatible-release\n            if spec.operator == \"~=\":\n                version = spec.version.split(\".\")\n                if len(version) in {2, 3, 4}:\n                    if len(version) in {3, 4}:\n                        del version[-1]  # will increase the last but one in next line\n                    version[-1] = str(int(version[-1]) + 1)\n                else:\n                    raise ValueError(\"%r must not be used with %r\" % (spec.operator, spec.version))\n                return [(\">=\", spec.version), (\"<\", \".\".join(version))]\n            # Trailing .* is permitted per\n            # https://www.python.org/dev/peps/pep-0440/#version-matching\n            elif spec.operator == \"==\" and spec.version.endswith(\".*\"):\n                try:\n                    result = check_output([\"/usr/bin/semver-ranger\", spec.version], universal_newlines=True).strip()\n                    gte, lt = result.split()\n                    return [(\">=\", gte.lstrip(\">=\")), (\"<\", lt.lstrip(\"<\"))]\n                except ValueError:\n                    _LOGGER.warning(\"couldn't resolve ==%s\", spec.version)\n                    return spec.operator, spec.version\n            # https://www.python.org/dev/peps/pep-0440/#arbitrary-equality\n            # Use of this operator is heavily discouraged, so just convert it to 'Version matching'\n            elif spec.operator == \"===\":\n                return \"==\", spec.version\n            else:\n                return spec.operator, spec.version\n\n        def _get_pip_spec(requirements):\n            \"\"\"There is no `specs` field In Pip 8+, take info from `specifier` field.\"\"\"\n            if hasattr(requirements, \"specs\"):\n                return requirements.specs\n            elif hasattr(requirements, \"specifier\"):\n                specs = [_extract_op_version(spec) for spec in requirements.specifier]\n                if len(specs) == 0:\n                    # TODO: I'm not sure with this one\n                    # we should probably return None instead and let pip deal with this\n                    specs = [(\">=\", \"0.0.0\")]\n                return specs\n\n        _LOGGER.info(\"Parsing dependency %r\", spec)\n        # create a temporary file and store the spec there since\n        # `parse_requirements` requires a file\n        with NamedTemporaryFile(mode=\"w+\", suffix=\"pysolve\") as f:\n            f.write(spec)\n            f.flush()\n            parsed = parse_requirements(f.name, session=f.name)\n            dependency = [Dependency(x.name, _get_pip_spec(x.req)) for x in parsed].pop()\n\n        return dependency"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(obj):\n\n    if not isinstance(obj, bytes):\n        raise TypeError(\"object type must be bytes\")\n\n    info = {\n        \"type\": dict(),\n        \"extension\": dict(),\n        \"mime\": dict()\n    }\n\n    stream = \" \".join(['{:02X}'.format(byte) for byte in obj])\n\n    for element in data:\n        for signature in element[\"signature\"]:\n            offset = element[\"offset\"] * 2 + element[\"offset\"]\n            if signature == stream[offset:len(signature) + offset]:\n                for key in [\"type\", \"extension\", \"mime\"]:\n                    info[key][element[key]] = len(signature)\n\n    for key in [\"type\", \"extension\", \"mime\"]:\n        info[key] = [element for element in sorted(info[key], key=info[key].get, reverse=True)]\n\n    return Info(info[\"type\"], info[\"extension\"], info[\"mime\"])", "response": "Determines file format and picks suitable file types extensions and MIME types and returns a new object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvisualize bottleneck matching between two diagrams.", "response": "def bottleneck_matching(I1, I2, matchidx, D, labels=[\"dgm1\", \"dgm2\"], ax=None):\n    \"\"\" Visualize bottleneck matching between two diagrams\n\n    Parameters\n    ===========\n\n    I1: array\n        A diagram\n    I2: array\n        A diagram\n    matchidx: tuples of matched indices\n        if input `matching=True`, then return matching\n    D: array\n        cross-similarity matrix\n    labels: list of strings\n        names of diagrams for legend. Default = [\"dgm1\", \"dgm2\"], \n    ax: matplotlib Axis object\n        For plotting on a particular axis.\n\n    \"\"\"\n\n    plot_diagrams([I1, I2], labels=labels, ax=ax) \n    cp = np.cos(np.pi / 4)\n    sp = np.sin(np.pi / 4)\n    R = np.array([[cp, -sp], [sp, cp]])\n    if I1.size == 0:\n        I1 = np.array([[0, 0]])\n    if I2.size == 0:\n        I2 = np.array([[0, 0]])\n    I1Rot = I1.dot(R)\n    I2Rot = I2.dot(R)\n    dists = [D[i, j] for (i, j) in matchidx]\n    (i, j) = matchidx[np.argmax(dists)]\n    if i >= I1.shape[0] and j >= I2.shape[0]:\n        return\n    if i >= I1.shape[0]:\n        diagElem = np.array([I2Rot[j, 0], 0])\n        diagElem = diagElem.dot(R.T)\n        plt.plot([I2[j, 0], diagElem[0]], [I2[j, 1], diagElem[1]], \"g\")\n    elif j >= I2.shape[0]:\n        diagElem = np.array([I1Rot[i, 0], 0])\n        diagElem = diagElem.dot(R.T)\n        plt.plot([I1[i, 0], diagElem[0]], [I1[i, 1], diagElem[1]], \"g\")\n    else:\n        plt.plot([I1[i, 0], I2[j, 0]], [I1[i, 1], I2[j, 1]], \"g\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_diagrams(\n    diagrams,\n    plot_only=None,\n    title=None,\n    xy_range=None,\n    labels=None,\n    colormap=\"default\",\n    size=20,\n    ax_color=np.array([0.0, 0.0, 0.0]),\n    diagonal=True,\n    lifetime=False,\n    legend=True,\n    show=False,\n    ax=None\n):\n    \"\"\"A helper function to plot persistence diagrams. \n\n    Parameters\n    ----------\n    diagrams: ndarray (n_pairs, 2) or list of diagrams\n        A diagram or list of diagrams. If diagram is a list of diagrams, \n        then plot all on the same plot using different colors.\n    plot_only: list of numeric\n        If specified, an array of only the diagrams that should be plotted.\n    title: string, default is None\n        If title is defined, add it as title of the plot.\n    xy_range: list of numeric [xmin, xmax, ymin, ymax]\n        User provided range of axes. This is useful for comparing \n        multiple persistence diagrams.\n    labels: string or list of strings\n        Legend labels for each diagram. \n        If none are specified, we use H_0, H_1, H_2,... by default.\n    colormap: string, default is 'default'\n        Any of matplotlib color palettes. \n        Some options are 'default', 'seaborn', 'sequential'. \n        See all available styles with\n        \n        .. code:: python\n        \n            import matplotlib as mpl\n            print(mpl.styles.available)\n\n    size: numeric, default is 20\n        Pixel size of each point plotted.\n    ax_color: any valid matplotlib color type. \n        See [https://matplotlib.org/api/colors_api.html](https://matplotlib.org/api/colors_api.html) for complete API.\n    diagonal: bool, default is True\n        Plot the diagonal x=y line.\n    lifetime: bool, default is False. If True, diagonal is turned to False.\n        Plot life time of each point instead of birth and death. \n        Essentially, visualize (x, y-x).\n    legend: bool, default is True\n        If true, show the legend.\n    show: bool, default is False\n        Call plt.show() after plotting. If you are using self.plot() as part \n        of a subplot, set show=False and call plt.show() only once at the end.\n    \"\"\"\n\n    ax = ax or plt.gca()\n    plt.style.use(colormap)\n\n    xlabel, ylabel = \"Birth\", \"Death\"\n\n    if labels is None:\n        # Provide default labels for diagrams if using self.dgm_\n        labels = [\n            \"$H_0$\",\n            \"$H_1$\",\n            \"$H_2$\",\n            \"$H_3$\",\n            \"$H_4$\",\n            \"$H_5$\",\n            \"$H_6$\",\n            \"$H_7$\",\n            \"$H_8$\",\n        ]\n\n    if not isinstance(diagrams, list):\n        # Must have diagrams as a list for processing downstream\n        diagrams = [diagrams]\n\n    if plot_only:\n        diagrams = [diagrams[i] for i in plot_only]\n        labels = [labels[i] for i in plot_only]\n\n    if not isinstance(labels, list):\n        labels = [labels] * len(diagrams)\n\n    # Construct copy with proper type of each diagram\n    # so we can freely edit them.\n    diagrams = [dgm.astype(np.float32, copy=True) for dgm in diagrams]\n\n    # find min and max of all visible diagrams\n    concat_dgms = np.concatenate(diagrams).flatten()\n    has_inf = np.any(np.isinf(concat_dgms))\n    finite_dgms = concat_dgms[np.isfinite(concat_dgms)]\n\n    # clever bounding boxes of the diagram\n    if not xy_range:\n        # define bounds of diagram\n        ax_min, ax_max = np.min(finite_dgms), np.max(finite_dgms)\n        x_r = ax_max - ax_min\n\n        # Give plot a nice buffer on all sides.\n        # ax_range=0 when only one point,\n        buffer = 1 if xy_range == 0 else x_r / 5\n\n        x_down = ax_min - buffer / 2\n        x_up = ax_max + buffer\n\n        y_down, y_up = x_down, x_up\n    else:\n        x_down, x_up, y_down, y_up = xy_range\n\n    yr = y_up - y_down\n\n    if lifetime:\n\n        # Don't plot landscape and diagonal at the same time.\n        diagonal = False\n\n        # reset y axis so it doesn't go much below zero\n        y_down = -yr * 0.05\n        y_up = y_down + yr\n\n        # set custom ylabel\n        ylabel = \"Lifetime\"\n\n        # set diagrams to be (x, y-x)\n        for dgm in diagrams:\n            dgm[:, 1] -= dgm[:, 0]\n\n        # plot horizon line\n        ax.plot([x_down, x_up], [0, 0], c=ax_color)\n\n    # Plot diagonal\n    if diagonal:\n        ax.plot([x_down, x_up], [x_down, x_up], \"--\", c=ax_color)\n\n    # Plot inf line\n    if has_inf:\n        # put inf line slightly below top\n        b_inf = y_down + yr * 0.95\n        ax.plot([x_down, x_up], [b_inf, b_inf], \"--\", c=\"k\", label=r\"$\\infty$\")\n\n        # convert each inf in each diagram with b_inf\n        for dgm in diagrams:\n            dgm[np.isinf(dgm)] = b_inf\n\n    # Plot each diagram\n    for dgm, label in zip(diagrams, labels):\n\n        # plot persistence pairs\n        ax.scatter(dgm[:, 0], dgm[:, 1], size, label=label, edgecolor=\"none\")\n\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n\n    ax.set_xlim([x_down, x_up])\n    ax.set_ylim([y_down, y_up])\n    ax.set_aspect('equal', 'box')\n\n    if title is not None:\n        ax.set_title(title)\n\n    if legend is True:\n        ax.legend(loc=\"lower right\")\n\n    if show is True:\n        plt.show()", "response": "A helper function to plot a list of persistence diagrams."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform the persistent entropy values of a family of persistence barcodes (or persistence diagrams). Assumes that the input diagrams are from a determined dimension. If the infinity bars have any meaning in your experiment and you want to keep them, remember to give the value you desire to val_Inf. Parameters ----------- dgms: ndarray (n_pairs, 2) or list of diagrams array or list of arrays of birth/death pairs of a persistence barcode of a determined dimension. keep_inf: bool, default False if False, the infinity bars are removed. if True, the infinity bars remain. val_inf: float, default None substitution value to infinity. normalize: bool, default False if False, the persistent entropy values are not normalized. if True, the persistent entropy values are normalized. Returns -------- ps: ndarray (n_pairs,) array of persistent entropy values corresponding to each persistence barcode.", "response": "def persistent_entropy(\n    dgms, keep_inf=False, val_inf=None, normalize=False\n):\n    \"\"\"\n    Perform the persistent entropy values of a family of persistence barcodes (or persistence diagrams).\n    Assumes that the input diagrams are from a determined dimension. If the infinity bars have any meaning\n    in your experiment and you want to keep them, remember to give the value you desire to val_Inf.\n\n    Parameters\n    -----------\n    dgms: ndarray (n_pairs, 2) or list of diagrams   \n        array or list of arrays of birth/death pairs of a persistence barcode of a determined dimension.\n    keep_inf: bool, default False\n        if False, the infinity bars are removed.\n        if True, the infinity bars remain.\n    val_inf: float, default None\n        substitution value to infinity.\n    normalize: bool, default False\n        if False, the persistent entropy values are not normalized.\n        if True, the persistent entropy values are normalized.\n          \n    Returns\n    --------\n\n    ps: ndarray (n_pairs,)\n        array of persistent entropy values corresponding to each persistence barcode.\n\n    \"\"\"\n\n    if isinstance(dgms, list) == False:\n        dgms = [dgms]\n\n    # Step 1: Remove infinity bars if keep_inf = False. If keep_inf = True, infinity value is substituted by val_inf.\n\n    if keep_inf == False:\n        dgms = [(dgm[dgm[:, 1] != np.inf]) for dgm in dgms]\n    if keep_inf == True:\n        if val_inf != None:\n            dgms = [\n                np.where(dgm == np.inf, val_inf, dgm)\n                for dgm in dgms\n            ]\n        else:\n            raise Exception(\n                \"Remember: You need to provide a value to infinity bars if you want to keep them.\"\n            )\n\n    # Step 2: Persistent entropy computation.\n    ps = []\n    for dgm in dgms:\n        l = dgm[:, 1] - dgm[:, 0]\n        if all(l > 0):\n            L = np.sum(l)\n            p = l / L\n            E = -np.sum(p * np.log(p))\n            if normalize == True:\n                E = E / np.log(len(l))\n            ps.append(E)\n        else:\n            raise Exception(\"A bar is born after dying\")\n\n    return np.array(ps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evalHeatKernel(dgm1, dgm2, sigma):\n    kSigma = 0\n    I1 = np.array(dgm1)\n    I2 = np.array(dgm2)\n    for i in range(I1.shape[0]):\n        p = I1[i, 0:2]\n        for j in range(I2.shape[0]):\n            q = I2[j, 0:2]\n            qc = I2[j, 1::-1]\n            kSigma += np.exp(-(np.sum((p - q) ** 2)) / (8 * sigma)) - np.exp(\n                -(np.sum((p - qc) ** 2)) / (8 * sigma)\n            )\n    return kSigma / (8 * np.pi * sigma)", "response": "Evaluate continuous heat - based kernel between dgm1 and dgm2 and return the k - sigma of the kernel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the pseudo - metric between two diagrams", "response": "def heat(dgm1, dgm2, sigma=0.4):\n    \"\"\"\n    Return the pseudo-metric between two diagrams based on the continuous\n    heat kernel as described in \"A Stable Multi-Scale Kernel for Topological Machine Learning\" by Jan Reininghaus, Stefan Huber, Ulrich Bauer, and Roland Kwitt (CVPR 2015)\n\n    Parameters\n    -----------\n\n    dgm1: np.array (m,2)\n        A persistence diagram\n    dgm2: np.array (n,2)\n        A persistence diagram\n    sigma: float\n        Heat diffusion parameter (larger sigma makes blurrier)\n    Returns\n    --------\n\n    dist: float\n        heat kernel distance between dgm1 and dgm2\n\n    \"\"\"\n    return np.sqrt(\n        evalHeatKernel(dgm1, dgm1, sigma)\n        + evalHeatKernel(dgm2, dgm2, sigma)\n        - 2 * evalHeatKernel(dgm1, dgm2, sigma)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bottleneck(dgm1, dgm2, matching=False):\n\n    return_matching = matching\n\n    S = np.array(dgm1)\n    S = S[np.isfinite(S[:, 1]), :]\n    T = np.array(dgm2)\n    T = T[np.isfinite(T[:, 1]), :]\n\n    N = S.shape[0]\n    M = T.shape[0]\n\n    # Step 1: Compute CSM between S and T, including points on diagonal\n    # L Infinity distance\n    Sb, Sd = S[:, 0], S[:, 1]\n    Tb, Td = T[:, 0], T[:, 1]\n    D1 = np.abs(Sb[:, None] - Tb[None, :])\n    D2 = np.abs(Sd[:, None] - Td[None, :])\n    DUL = np.maximum(D1, D2)\n\n    # Put diagonal elements into the matrix, being mindful that Linfinity\n    # balls meet the diagonal line at a diamond vertex\n    D = np.zeros((N + M, N + M))\n    D[0:N, 0:M] = DUL\n    UR = np.max(D) * np.ones((N, N))\n    np.fill_diagonal(UR, 0.5 * (S[:, 1] - S[:, 0]))\n    D[0:N, M::] = UR\n    UL = np.max(D) * np.ones((M, M))\n    np.fill_diagonal(UL, 0.5 * (T[:, 1] - T[:, 0]))\n    D[N::, 0:M] = UL\n\n    # Step 2: Perform a binary search + Hopcroft Karp to find the\n    # bottleneck distance\n    N = D.shape[0]\n    ds = np.unique(D.flatten())\n    ds = ds[ds > 0]\n    ds = np.sort(ds)\n    bdist = ds[-1]\n    matching = {}\n    while len(ds) >= 1:\n        idx = 0\n        if len(ds) > 1:\n            idx = bisect_left(range(ds.size), int(ds.size / 2))\n        d = ds[idx]\n        graph = {}\n        for i in range(N):\n            graph[\"%s\" % i] = {j for j in range(N) if D[i, j] <= d}\n        res = HopcroftKarp(graph).maximum_matching()\n        if len(res) == 2 * N and d < bdist:\n            bdist = d\n            matching = res\n            ds = ds[0:idx]\n        else:\n            ds = ds[idx + 1 : :]\n\n    if return_matching:\n        matchidx = [(i, matching[\"%i\" % i]) for i in range(N)]\n        return bdist, (matchidx, D)\n    else:\n        return bdist", "response": "This function calculates the bottleneck distance between two persistence diagrams."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sliced_wasserstein(PD1, PD2, M=50):\n\n    diag_theta = np.array(\n        [np.cos(0.25 * np.pi), np.sin(0.25 * np.pi)], dtype=np.float32\n    )\n\n    l_theta1 = [np.dot(diag_theta, x) for x in PD1]\n    l_theta2 = [np.dot(diag_theta, x) for x in PD2]\n\n    if (len(l_theta1) != PD1.shape[0]) or (len(l_theta2) != PD2.shape[0]):\n        raise ValueError(\"The projected points and origin do not match\")\n\n    PD_delta1 = [[np.sqrt(x ** 2 / 2.0)] * 2 for x in l_theta1]\n    PD_delta2 = [[np.sqrt(x ** 2 / 2.0)] * 2 for x in l_theta2]\n\n    # i have the input now to compute the sw\n    sw = 0\n    theta = 0.5\n    step = 1.0 / M\n    for i in range(M):\n        l_theta = np.array(\n            [np.cos(theta * np.pi), np.sin(theta * np.pi)], dtype=np.float32\n        )\n\n        V1 = [np.dot(l_theta, x) for x in PD1] + [np.dot(l_theta, x) for x in PD_delta2]\n\n        V2 = [np.dot(l_theta, x) for x in PD2] + [np.dot(l_theta, x) for x in PD_delta1]\n\n        sw += step * cityblock(sorted(V1), sorted(V2))\n        theta += step\n\n    return sw", "response": "This function calculates the Sliced Wasserstein distance between two points."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert diagrams or list of diagrams to persistence images.", "response": "def transform(self, diagrams):\n        \"\"\" Convert diagram or list of diagrams to a persistence image.\n\n        Parameters\n        -----------\n\n        diagrams : list of or singleton diagram, list of pairs. [(birth, death)]\n            Persistence diagrams to be converted to persistence images. It is assumed they are in (birth, death) format. Can input a list of diagrams or a single diagram.\n\n        \"\"\"\n        # if diagram is empty, return empty image\n        if len(diagrams) == 0:\n            return np.zeros((self.nx, self.ny))\n        # if first entry of first entry is not iterable, then diagrams is singular and we need to make it a list of diagrams\n        try:\n            singular = not isinstance(diagrams[0][0], collections.Iterable)\n        except IndexError:\n            singular = False\n\n        if singular:\n            diagrams = [diagrams]\n\n        dgs = [np.copy(diagram, np.float64) for diagram in diagrams]\n        landscapes = [PersImage.to_landscape(dg) for dg in dgs]\n\n        if not self.specs:\n            self.specs = {\n                \"maxBD\": np.max([np.max(np.vstack((landscape, np.zeros((1, 2))))) \n                                 for landscape in landscapes] + [0]),\n                \"minBD\": np.min([np.min(np.vstack((landscape, np.zeros((1, 2))))) \n                                 for landscape in landscapes] + [0]),\n            }\n        imgs = [self._transform(dgm) for dgm in landscapes]\n\n        # Make sure we return one item.\n        if singular:\n            imgs = imgs[0]\n\n        return imgs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndefine a weighting function for the current object.", "response": "def weighting(self, landscape=None):\n        \"\"\" Define a weighting function, \n                for stability results to hold, the function must be 0 at y=0.    \n        \"\"\"\n\n        # TODO: Implement a logistic function\n        # TODO: use self.weighting_type to choose function\n\n        if landscape is not None:\n            if len(landscape) > 0:\n                maxy = np.max(landscape[:, 1])\n            else: \n                maxy = 1\n\n        def linear(interval):\n            # linear function of y such that f(0) = 0 and f(max(y)) = 1\n            d = interval[1]\n            return (1 / maxy) * d if landscape is not None else d\n\n        def pw_linear(interval):\n            \"\"\" This is the function defined as w_b(t) in the original PI paper\n\n                Take b to be maxy/self.ny to effectively zero out the bottom pixel row\n            \"\"\"\n\n            t = interval[1]\n            b = maxy / self.ny\n\n            if t <= 0:\n                return 0\n            if 0 < t < b:\n                return t / b\n            if b <= t:\n                return 1\n\n        return linear"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the kernel function for the current cluster.", "response": "def kernel(self, spread=1):\n        \"\"\" This will return whatever kind of kernel we want to use.\n            Must have signature (ndarray size NxM, ndarray size 1xM) -> ndarray size Nx1\n        \"\"\"\n        # TODO: use self.kernel_type to choose function\n\n        def gaussian(data, pixel):\n            return mvn.pdf(data, mean=pixel, cov=spread)\n\n        return gaussian"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show(self, imgs, ax=None):\n\n        ax = ax or plt.gca()\n\n        if type(imgs) is not list:\n            imgs = [imgs]\n\n        for i, img in enumerate(imgs):\n            ax.imshow(img, cmap=plt.get_cmap(\"plasma\"))\n            ax.axis(\"off\")", "response": "Visualize the persistence image\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve the orm_path of a model class.", "response": "def resolve_orm_path(model, orm_path):\n    \"\"\"\n    Follows the queryset-style query path of ``orm_path`` starting from ``model`` class.  If the\n    path ends up referring to a bad field name, ``django.db.models.fields.FieldDoesNotExist`` will\n    be raised.\n\n    \"\"\"\n\n    bits = orm_path.split('__')\n    endpoint_model = reduce(get_model_at_related_field, [model] + bits[:-1])\n    if bits[-1] == 'pk':\n        field = endpoint_model._meta.pk\n    else:\n        field = endpoint_model._meta.get_field(bits[-1])\n    return field"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the related model class for the given model and attribute.", "response": "def get_model_at_related_field(model, attr):\n    \"\"\"\n    Looks up ``attr`` as a field of ``model`` and returns the related model class.  If ``attr`` is\n    not a relationship field, ``ValueError`` is raised.\n\n    \"\"\"\n\n    field = model._meta.get_field(attr)\n\n    if hasattr(field, 'related_model'):\n        return field.related_model\n\n    raise ValueError(\"{model}.{attr} ({klass}) is not a relationship field.\".format(**{\n        'model': model.__name__,\n        'attr': attr,\n        'klass': field.__class__.__name__,\n    }))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a boolean indicating if the fields contains a relationship to multiple items.", "response": "def contains_plural_field(model, fields):\n    \"\"\" Returns a boolean indicating if ``fields`` contains a relationship to multiple items. \"\"\"\n    source_model = model\n    for orm_path in fields:\n        model = source_model\n        bits = orm_path.lstrip('+-').split('__')\n        for bit in bits[:-1]:\n            field = model._meta.get_field(bit)\n            if field.many_to_many or field.one_to_many:\n                return True\n            model = get_model_at_related_field(model, bit)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_json_response_object(self, datatable):\n\n        # Ensure the object list is calculated.\n        # Calling get_records() will do this implicitly, but we want simultaneous access to the\n        # 'total_initial_record_count', and 'unpaged_record_count' values.\n        datatable.populate_records()\n\n        draw = getattr(self.request, self.request.method).get('draw', None)\n        if draw is not None:\n            draw = escape_uri_path(draw)\n        response_data = {\n            'draw': draw,\n            'recordsFiltered': datatable.unpaged_record_count,\n            'recordsTotal': datatable.total_initial_record_count,\n            'data': [dict(record, **{\n                'DT_RowId': record.pop('pk'),\n                'DT_RowData': record.pop('_extra_data'),\n            }) for record in datatable.get_records()],\n        }\n        return response_data", "response": "Returns the JSON - compatible dictionary that will be serialized for an AJAX response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize_to_json(self, response_data):\n\n        indent = None\n        if settings.DEBUG:\n            indent = 4\n\n        # Serialize to JSON with Django's encoder: Adds date/time, decimal,\n        # and UUID support.\n        return json.dumps(response_data, indent=indent, cls=DjangoJSONEncoder)", "response": "Serialize the compiled data object to JSON."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when accessed via AJAX on the request method specified by the Datatable.", "response": "def get_ajax(self, request, *args, **kwargs):\n        \"\"\" Called when accessed via AJAX on the request method specified by the Datatable. \"\"\"\n\n        response_data = self.get_json_response_object(self._datatable)\n        response = HttpResponse(self.serialize_to_json(response_data),\n                                content_type=\"application/json\")\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngather and returns the final Datatable instance for processing.", "response": "def get_datatable(self, **kwargs):\n        \"\"\" Gathers and returns the final :py:class:`Datatable` instance for processing. \"\"\"\n        if hasattr(self, '_datatable'):\n            return self._datatable\n\n        datatable_class = self.get_datatable_class()\n        if datatable_class is None:\n            class AutoMeta:\n                model = self.model or self.get_queryset().model\n            opts = AutoMeta()\n            datatable_class = Datatable\n        else:\n            opts = datatable_class.options_class(datatable_class._meta)\n\n        kwargs = self.get_datatable_kwargs(**kwargs)\n        for meta_opt in opts.__dict__:\n            if meta_opt in kwargs:\n                setattr(opts, meta_opt, kwargs.pop(meta_opt))\n\n        datatable_class = type('%s_Synthesized' % (datatable_class.__name__,), (datatable_class,), {\n            '__module__': datatable_class.__module__,\n            'Meta': opts,\n        })\n        self._datatable = datatable_class(**kwargs)\n        return self._datatable"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_active_ajax_datatable(self):\n        data = getattr(self.request, self.request.method)\n        datatables_dict = self.get_datatables(only=data['datatable'])\n        return list(datatables_dict.values())[0]", "response": "Returns the active datatable according to the GET variable from an AJAX request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict of the datatables served by this view.", "response": "def get_datatables(self, only=None):\n        \"\"\" Returns a dict of the datatables served by this view. \"\"\"\n        if not hasattr(self, '_datatables'):\n            self._datatables = {}\n            datatable_classes = self.get_datatable_classes()\n            for name, datatable_class in datatable_classes.items():\n                if only and name != only:\n                    continue\n                queryset_getter_name = 'get_%s_datatable_queryset' % (name,)\n                queryset_getter = getattr(self, queryset_getter_name, None)\n                if queryset_getter is None:\n                    raise ValueError(\"%r must declare a method %r.\" % (self.__class__.__name__,\n                                                                       queryset_getter_name))\n\n                queryset = queryset_getter()\n                if datatable_class is None:\n                    class AutoMeta:\n                        model = queryset.model\n                    opts = AutoMeta()\n                    datatable_class = Datatable\n                else:\n                    opts = datatable_class.options_class(datatable_class._meta)\n\n                kwargs = self.get_default_datatable_kwargs(object_list=queryset)\n                kwargs_getter_name = 'get_%s_datatable_kwargs' % (name,)\n                kwargs_getter = getattr(self, kwargs_getter_name, None)\n                if kwargs_getter:\n                    kwargs = kwargs_getter(**kwargs)\n                if 'url' in kwargs:\n                    kwargs['url'] = kwargs['url'] + \"?datatable=%s\" % (name,)\n\n                for meta_opt in opts.__dict__:\n                    if meta_opt in kwargs:\n                        setattr(opts, meta_opt, kwargs.pop(meta_opt))\n\n                datatable_class = type('%s_Synthesized' % (datatable_class.__name__,), (datatable_class,), {\n                    '__module__': datatable_class.__module__,\n                    'Meta': opts,\n                })\n\n                self._datatables[name] = datatable_class(**kwargs)\n        return self._datatables"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default_datatable_kwargs(self, **kwargs):\n\n        kwargs['view'] = self\n\n        # This is provided by default, but if the view is instantiated outside of the request cycle\n        # (such as for the purposes of embedding that view's datatable elsewhere), the request may\n        # not be required, so the user may not have a compelling reason to go through the trouble of\n        # putting it on self.\n        if hasattr(self, 'request'):\n            kwargs['url'] = self.request.path\n            kwargs['query_config'] = getattr(self.request, self.request.method)\n        else:\n            kwargs['query_config'] = {}\n\n        return kwargs", "response": "Builds the default set of kwargs for initializing a Datatable class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_column_for_modelfield(model_field):\n\n    # If the field points to another model, we want to get the pk field of that other model and use\n    # that as the real field.  It is possible that a ForeignKey points to a model with table\n    # inheritance, however, so we need to traverse the internal OneToOneField as well, so this will\n    # climb the 'pk' field chain until we have something real.\n    while model_field.related_model:\n        model_field = model_field.related_model._meta.pk\n    for ColumnClass, modelfield_classes in COLUMN_CLASSES:\n        if isinstance(model_field, tuple(modelfield_classes)):\n            return ColumnClass", "response": "Return the built - in Column class for a model field class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value of the source field.", "response": "def get_source_value(self, obj, source, **kwargs):\n        \"\"\"\n        Treat ``field`` as a nested sub-Column instance, which explicitly stands in as the object\n        to which term coercions and the query type lookup are delegated.\n        \"\"\"\n        result = []\n        for sub_source in self.expand_source(source):\n            # Call super() to get default logic, but send it the 'sub_source'\n            sub_result = super(CompoundColumn, self).get_source_value(obj, sub_source, **kwargs)\n            result.extend(sub_result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_flat_db_sources(self, model):\n        sources = []\n        for source in self.sources:\n            for sub_source in self.expand_source(source):\n                target_field = self.resolve_source(model, sub_source)\n                if target_field:\n                    sources.append(sub_source)\n        return sources", "response": "Return a flattened representation of the individual sources lists."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_source_handler(self, model, source):\n        if isinstance(source, Column):\n            return source\n\n        # Generate a generic handler for the source\n        modelfield = resolve_orm_path(model, source)\n        column_class = get_column_for_modelfield(modelfield)\n        return column_class()", "response": "Returns the handler for the source."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dispatch(self, request, *args, **kwargs):\n        if request.GET.get(self.xeditable_fieldname_param):\n            return self.get_ajax_xeditable_choices(request, *args, **kwargs)\n        return super(XEditableMixin, self).dispatch(request, *args, **kwargs)", "response": "Introduces the ensure_csrf_cookie decorator and handles xeditable choices ajax."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_ajax_xeditable_choices(self, request, *args, **kwargs):\n        field_name = request.GET.get(self.xeditable_fieldname_param)\n        if not field_name:\n            return HttpResponseBadRequest(\"Field name must be given\")\n\n        queryset = self.get_queryset()\n        if not self.model:\n            self.model = queryset.model\n\n        # Sanitize the requested field name by limiting valid names to the datatable_options columns\n        from datatableview.views import legacy\n        if isinstance(self, legacy.LegacyDatatableMixin):\n            columns = self._get_datatable_options()['columns']\n            for name in columns:\n                if isinstance(name, (list, tuple)):\n                    name = name[1]\n                if name == field_name:\n                    break\n            else:\n                return HttpResponseBadRequest(\"Invalid field name\")\n        else:\n            datatable = self.get_datatable()\n            if not hasattr(datatable, 'config'):\n                datatable.configure()\n            if field_name not in datatable.config['columns']:\n                return HttpResponseBadRequest(\"Invalid field name\")\n\n        field = self.model._meta.get_field(field_name)\n        choices = self.get_field_choices(field, field_name)\n        return HttpResponse(json.dumps(choices))", "response": "Get the list of field choices for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post(self, request, *args, **kwargs):\n        self.object_list = None\n        form = self.get_xeditable_form(self.get_xeditable_form_class())\n        if form.is_valid():\n            obj = self.get_update_object(form)\n            if obj is None:\n                data = json.dumps({\n                    'status': 'error',\n                    'message': \"Object does not exist.\"\n                })\n                return HttpResponse(data, content_type=\"application/json\", status=404)\n            return self.update_object(form, obj)\n        else:\n            data = json.dumps({\n                'status': 'error',\n                'message': \"Invalid request\",\n                'form_errors': form.errors,\n            })\n            return HttpResponse(data, content_type=\"application/json\", status=400)", "response": "Builds a dynamic form that targets only the field in question and saves the modification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dict of keyword arguments to be sent to the xeditable form class.", "response": "def get_xeditable_form_kwargs(self):\n        \"\"\" Returns a dict of keyword arguments to be sent to the xeditable form class. \"\"\"\n        kwargs = {\n            'model': self.get_queryset().model,\n        }\n        if self.request.method in ('POST', 'PUT'):\n            kwargs.update({\n                'data': self.request.POST,\n            })\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_update_object(self, form):\n        pk = form.cleaned_data['pk']\n        queryset = self.get_queryset()\n        try:\n            obj = queryset.get(pk=pk)\n        except queryset.model.DoesNotExist:\n            obj = None\n\n        return obj", "response": "Returns the target object based on the update form s pk and the table s queryset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_object(self, form, obj):\n        field_name = form.cleaned_data['name']\n        value = form.cleaned_data['value']\n        setattr(obj, field_name, value)\n        save_kwargs = {}\n        if CAN_UPDATE_FIELDS:\n            save_kwargs['update_fields'] = [field_name]\n        obj.save(**save_kwargs)\n\n        data = json.dumps({\n            'status': 'success',\n        })\n        return HttpResponse(data, content_type=\"application/json\")", "response": "Updates the value of the attribute in the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the valid choices for the given field.", "response": "def get_field_choices(self, field, field_name):\n        \"\"\"\n        Returns the valid choices for ``field``.  The ``field_name`` argument is given for\n        convenience.\n        \"\"\"\n        if self.request.GET.get('select2'):\n            names = ['id', 'text']\n        else:\n            names = ['value', 'text']\n        choices_getter = getattr(self, 'get_field_%s_choices', None)\n        if choices_getter is None:\n            if isinstance(field, ForeignKey):\n                choices_getter = self._get_foreignkey_choices\n            else:\n                choices_getter = self._get_default_choices\n        return [dict(zip(names, choice)) for choice in choices_getter(field, field_name)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of form field instances from the passed in attrs plus anyother fields on the base classes.", "response": "def get_declared_columns(bases, attrs, with_base_columns=True):\n    \"\"\"\n    Create a list of form field instances from the passed in 'attrs', plus any\n    similar fields on the base classes (in 'bases'). This is used by both the\n    Form and ModelForm metclasses.\n\n    If 'with_base_columns' is True, all fields from the bases are used.\n    Otherwise, only fields in the 'declared_fields' attribute on the bases are\n    used. The distinction is useful in ModelForm subclassing.\n    Also integrates any additional media definitions\n    \"\"\"\n    local_columns = [\n        (column_name, attrs.pop(column_name)) \\\n                for column_name, obj in list(six.iteritems(attrs)) \\\n                if isinstance(obj, Column)\n    ]\n    local_columns.sort(key=lambda x: x[1].creation_counter)\n\n    # If this class is subclassing another Form, add that Form's columns.\n    # Note that we loop over the bases in *reverse*. This is necessary in\n    # order to preserve the correct order of columns.\n    if with_base_columns:\n        for base in bases[::-1]:\n            if hasattr(base, 'base_columns'):\n                local_columns = list(six.iteritems(base.base_columns)) + local_columns\n    else:\n        for base in bases[::-1]:\n            if hasattr(base, 'declared_columns'):\n                local_columns = list(six.iteritems(base.declared_columns)) + local_columns\n\n    return OrderedDict(local_columns)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nswitch the original queryset to a ValuesQuerySet selecting values according to what each column has declared in its columns.", "response": "def populate_records(self):\n        \"\"\"\n        Switches the original queryset to a ``ValuesQuerySet``, selecting values according to what\n        each column has declared in its :py:attr:`~datatableview.columns.Column.sources` list.\n        \"\"\"\n\n        self.object_list = self.get_valuesqueryset(self.object_list)\n        super(ValuesDatatable, self).populate_records()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmodifies the ``obj`` values dict to alias the selected values to the column name that asked for its selection. For example, a datatable that declares a column ``'blog'`` which has a related lookup source ``'blog__name'`` will ensure that the selected value exists in ``obj`` at both keys ``blog__name`` and ``blog`` (the former because that was how it was selected, the latter because that was the column name used to select it). :Example: ``{'pk': 1, 'blog__name': \"My Blog\"}`` ``{'pk': 1: 'blog__name': \"My Blog\", 'blog': \"My Blog\"}`` When a column declares multiple :py:attr:`~datatableview.columns.Column.sources`, the column name's entry in ``obj`` will be a list of each of those values. :Example: ``{'pk': 1, 'blog__name': \"My Blog\", 'blog__id': 5}`` ``{'pk': 1: 'blog__name': \"My Blog\", 'blog__id': 5, 'blog': [\"My Blog\", 5]}`` In every situation, the original selected values will always be retained in ``obj``.", "response": "def preload_record_data(self, obj):\n        \"\"\"\n        Modifies the ``obj`` values dict to alias the selected values to the column name that asked\n        for its selection.\n\n        For example, a datatable that declares a column ``'blog'`` which has a related lookup source\n        ``'blog__name'`` will ensure that the selected value exists in ``obj`` at both keys\n        ``blog__name`` and ``blog`` (the former because that was how it was selected, the latter\n        because that was the column name used to select it).\n\n        :Example:\n\n            ``{'pk': 1, 'blog__name': \"My Blog\"}``\n            ``{'pk': 1: 'blog__name': \"My Blog\", 'blog': \"My Blog\"}``\n\n        When a column declares multiple :py:attr:`~datatableview.columns.Column.sources`, the column\n        name's entry in ``obj`` will be a list of each of those values.\n\n        :Example:\n\n            ``{'pk': 1, 'blog__name': \"My Blog\", 'blog__id': 5}``\n            ``{'pk': 1: 'blog__name': \"My Blog\", 'blog__id': 5, 'blog': [\"My Blog\", 5]}``\n\n        In every situation, the original selected values will always be retained in ``obj``.\n        \"\"\"\n        data = {}\n\n        for orm_path, column_name in self.value_queries.items():\n            value = obj[orm_path]\n            if column_name not in data:\n                data[column_name] = value\n            else:\n                if not isinstance(data[column_name], (tuple, list)):\n                    data[column_name] = [data[column_name]]\n                data[column_name].append(value)\n        obj.update(data)\n        return super(ValuesDatatable, self).preload_record_data(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_virtual_columns(self, *names):\n        from .views.legacy import get_field_definition\n        virtual_columns = {}\n        for name in names:\n            field = get_field_definition(name)\n            column = TextColumn(sources=field.fields, label=field.pretty_name,\n                                processor=field.callback)\n            column.name = field.pretty_name if field.pretty_name else field.fields[0]\n            virtual_columns[name] = column\n\n        # Make sure it's in the same order as originally defined\n        new_columns = OrderedDict()\n        for name in self._meta.columns:  # Can't use self.config yet, hasn't been generated\n            if self.columns.get(name):\n                column = self.columns[name]\n            else:\n                column = virtual_columns[name]\n            new_columns[column.name] = column\n        self.columns = new_columns", "response": "Resolve all virtual columns in the current object to the ones that are not already defined."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_value_field(self, model, field_name):\n        fields = fields_for_model(model, fields=[field_name])\n        self.fields['value'] = fields[field_name]", "response": "Adds a value field to this form that uses the appropriate formfield for the named target\n        field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the name field corresponds to a field on the model.", "response": "def clean_name(self):\n        \"\"\" Validates that the ``name`` field corresponds to a field on the model. \"\"\"\n        field_name = self.cleaned_data['name']\n        # get_all_field_names is deprecated in Django 1.8, this also fixes proxied models\n        if hasattr(self.model._meta, 'get_fields'):\n            field_names = [field.name for field in self.model._meta.get_fields()]\n        else:\n            field_names = self.model._meta.get_all_field_names()\n        if field_name not in field_names:\n            raise ValidationError(\"%r is not a valid field.\" % field_name)\n        return field_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing a field definition into its component parts even if some are missing.", "response": "def get_field_definition(field_definition):\n    \"\"\" Normalizes a field definition into its component parts, even if some are missing. \"\"\"\n    if not isinstance(field_definition, (tuple, list)):\n        field_definition = [field_definition]\n    else:\n        field_definition = list(field_definition)\n\n    if len(field_definition) == 1:\n        field = [None, field_definition, None]\n    elif len(field_definition) == 2:\n        field = field_definition + [None]\n    elif len(field_definition) == 3:\n        field = field_definition\n    else:\n        raise ValueError(\"Invalid field definition format.\")\n\n    if not isinstance(field[1], (tuple, list)):\n        field[1] = (field[1],)\n    field[1] = tuple(name for name in field[1] if name is not None)\n\n    return FieldDefinitionTuple(*field)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_datatable_options(self):\n        if not hasattr(self, '_datatable_options'):\n            self._datatable_options = self.get_datatable_options()\n\n            # Convert sources from list to tuple, so that modern Column tracking dicts can hold the\n            # field definitions as keys.\n            columns = self._datatable_options.get('columns', [])\n            for i, column in enumerate(columns):\n                if len(column) >= 2 and isinstance(column[1], list):\n                    column = list(column)\n                    column[1] = tuple(column[1])\n                    columns[i] = tuple(column)\n\n        return self._datatable_options", "response": "Returns a promise that resolves when we only run get_datatable_options on one of the tables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cache_key(datatable_class, view=None, user=None, **kwargs):\n\n    datatable_name = datatable_class.__name__\n    if datatable_name.endswith('_Synthesized'):\n        datatable_name = datatable_name[:-12]\n    datatable_id = '%s.%s' % (datatable_class.__module__, datatable_name)\n    if CACHE_KEY_HASH:\n        datatable_id = _hash_key_component(datatable_id)\n\n    cache_key = 'datatable_%s' % (datatable_id,)\n\n    if view:\n        if not inspect.isclass(view):\n            # Reduce view to its class\n            view = view.__class__\n\n        view_id = '%s.%s' % (view.__module__, view.__name__)\n        if CACHE_KEY_HASH:\n            view_id = _hash_key_component(view_id)\n        cache_key += '__view_%s' % (view_id,)\n\n    if user and user.is_authenticated():\n        cache_key += '__user_%s' % (user.pk,)\n\n    # All other kwargs are used directly to create a hashed suffix\n    # Order the kwargs by key name, then convert them to their repr() values.\n    items = sorted(kwargs.items(), key=lambda item: item[0])\n    values = []\n    for k, v in items:\n        values.append('%r:%r' % (k, v))\n\n    if values:\n        kwargs_id = '__'.join(values)\n        kwargs_id = _hash_key_component(kwargs_id)\n        cache_key += '__kwargs_%s' % (kwargs_id,)\n\n    log.debug(\"Cache key derived for %r: %r (from kwargs %r)\", datatable_class, cache_key, values)\n\n    return cache_key", "response": "Returns a cache key for the given datatable class view and user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the cached object list under the appropriate key.", "response": "def get_cached_data(datatable, **kwargs):\n    \"\"\" Returns the cached object list under the appropriate key, or None if not set. \"\"\"\n    cache_key = '%s%s' % (CACHE_PREFIX, datatable.get_cache_key(**kwargs))\n    data = cache.get(cache_key)\n    log.debug(\"Reading data from cache at %r: %r\", cache_key, data)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores the data in the cache under the appropriate key.", "response": "def cache_data(datatable, data, **kwargs):\n    \"\"\" Stores the object list in the cache under the appropriate key. \"\"\"\n    cache_key = '%s%s' % (CACHE_PREFIX, datatable.get_cache_key(**kwargs))\n    log.debug(\"Setting data to cache at %r: %r\", cache_key, data)\n    cache.set(cache_key, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keyed_helper(helper):\n\n    @wraps(helper)\n    def wrapper(instance=None, key=None, attr=None, *args, **kwargs):\n        if set((instance, key, attr)) == {None}:\n            # helper was called in place with neither important arg\n            raise ValueError(\"If called directly, helper function '%s' requires either a model\"\n                             \" instance, or a 'key' or 'attr' keyword argument.\" % helper.__name__)\n\n        if instance is not None:\n            return helper(instance, *args, **kwargs)\n\n        if key is None and attr is None:\n            attr = 'self'\n\n        if attr:\n            if attr == 'self':\n                key = lambda obj: obj\n            else:\n                key = operator.attrgetter(attr)\n\n        # Helper is used directly in the columns declaration.  A new callable is\n        # returned to take the place of a callback.\n        @wraps(helper)\n        def helper_wrapper(instance, *args, **kwargs):\n            return helper(key(instance), *args, **kwargs)\n        return helper_wrapper\n\n    wrapper._is_wrapped = True\n    return wrapper", "response": "A keyed helper function that returns a single object that can be used in the view s custom callbacks."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the HTML for the canon model.", "response": "def link_to_model(instance, text=None, *args, **kwargs):\n    \"\"\"\n    Returns HTML in the form::\n\n        <a href=\"{{ instance.get_absolute_url }}\">{{ text }}</a>\n\n    If ``text`` is provided and isn't empty, it will be used as the hyperlinked text.\n\n    If ``text`` isn't available, then ``kwargs['rich_value']`` will be consulted instead.\n\n    Failing those checks, the helper will fall back to simply using ``unicode(instance)`` as the\n    link text.\n\n    If the helper is called in place (rather than providing the helper reference directly), it can\n    receive a special ``key`` argument, which is a mapping function that will receiving the instance\n    (once it is available) and return some value from that instance.  That new value will be sent to\n    the helper in the place of the instance.\n\n    Examples::\n\n        # Generate a simple href tag for instance.get_absolute_url()\n        name = columns.TextColumn(\"Name\", sources=['name'],\n                                          processor=link_to_model)\n\n        # Generate an href tag for instance.relatedobject.get_absolute_url()\n        # Note that without the use of link_to_model(key=...), the object going into\n        # the link_to_model helper would be the row instance, not the thing looked up by the\n        # column's sources.\n        name = columns.TextColumn(\"Name\", sources=['relatedobject__name'],\n                                          processor=link_to_model(key=getattr('relatedobject')))\n    \"\"\"\n    if not text:\n        text = kwargs.get('rich_value') or six.text_type(instance)\n    return u\"\"\"<a href=\"{0}\">{1}</a>\"\"\".format(instance.get_absolute_url(), text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a unicode \u2714 or \u2718 configurable by pre - calling the helper with true_value and false_value arguments based on the incoming value.", "response": "def make_boolean_checkmark(value, true_value=\"&#10004;\", false_value=\"&#10008;\", *args, **kwargs):\n    \"\"\"\n    Returns a unicode \u2714 or \u2718, configurable by pre-calling the helper with ``true_value`` and/or\n    ``false_value`` arguments, based on the incoming value.\n\n    The value at ``kwargs['default_value']`` is checked to see if it casts to a boolean ``True`` or\n    ``False``, and returns the appropriate representation.\n\n    Examples::\n\n        # A DateTimeField can be sent to the helper to detect whether\n        # or not it is None, and have a checkmark reflect that.\n        is_published = columns.DateTimeColumn(\"Published\", sources=['published_date'],\n                                              processor=make_boolean_checkmark)\n\n        # Make the 'false_value' blank so that only True-like items have an icon\n        is_published = columns.DateTimeColumn(\"Published\", sources=['published_date'],\n                                              processor=make_boolean_checkmark(false_value=\"\"))\n\n    \"\"\"\n    value = kwargs.get('default_value', value)\n    if value:\n        return true_value\n    return false_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a function that returns the value of the column k.", "response": "def itemgetter(k, ellipsis=False, key=None):\n    \"\"\"\n    Looks up ``k`` as an index of the column's value.\n\n    If ``k`` is a ``slice`` type object, then ``ellipsis`` can be given as a string to use to\n    indicate truncation.  Alternatively, ``ellipsis`` can be set to ``True`` to use a default\n    ``'...'``.\n\n    If a ``key`` is given, it may be a function which maps the target value to something else\n    before the item lookup takes place.\n\n    Examples::\n\n        # Choose an item from a list source.\n        winner = columns.TextColumn(\"Winner\", sources=['get_rankings'],\n                                    processor=itemgetter(0))\n\n        # Take instance.description[:30] and append \"...\" to the end if truncation occurs.\n        description = columns.TextColumn(\"Description\", sources=['description'],\n                                         processor=itemgetter(slice(None, 30), ellipsis=True))\n\n    \"\"\"\n    def helper(instance, *args, **kwargs):\n        default_value = kwargs.get('default_value')\n        if default_value is None:\n            default_value = instance\n        value = default_value[k]\n        if ellipsis and isinstance(k, slice) and isinstance(value, six.string_types) and \\\n                len(default_value) > len(value):\n            if ellipsis is True:\n                value += \"...\"\n            else:\n                value += ellipsis\n        return value\n\n    if key:\n        helper = keyed_helper(helper)(key=key)\n    return helper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a function that will return the value of the attribute attr on the object.", "response": "def attrgetter(attr, key=None):\n    \"\"\"\n    Looks up ``attr`` on the target value. If the result is a callable, it will be called in place\n    without arguments.\n\n    If a ``key`` is given, it may be a function which maps the target value to something else\n    before the attribute lookup takes place.\n\n    Examples::\n\n        # Explicitly selecting the sources and then using a processor to allow the model\n        # method to organize the data itself, you can still provide all the necessary\n        # ORM hints to the column.\n        # This is definitely superior to having sources=['get_address'].\n        address = columns.TextColumn(\"Address\", sources=['street', 'city', 'state', 'zip'],\n                                     processor=attrgetter('get_address'))\n\n    \"\"\"\n    def helper(instance, *args, **kwargs):\n        value = instance\n        for bit in attr.split('.'):\n            value = getattr(value, bit)\n            if callable(value):\n                value = value()\n        return value\n\n    if key:\n        helper = keyed_helper(helper)(key=key)\n    return helper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_date(format_string, localize=False, key=None):\n\n    if localize is not False and localtime is None:\n        raise Exception(\"Cannot use format_date argument 'localize' with Django < 1.5\")\n\n    def helper(value, *args, **kwargs):\n        inner_localize = kwargs.get('localize', localize)\n        if inner_localize is not False and localtime is None:\n            raise Exception(\"Cannot use format_date argument 'localize' with Django < 1.5\")\n\n        if key:\n            value = key(value)\n        else:\n            value = kwargs.get('default_value', value)\n        if not value:  # Empty or missing default_value\n            return \"\"\n        if localize:\n            value = localtime(value)\n        return value.strftime(format_string)\n\n    if key:\n        return keyed_helper(helper)(key=key)\n    return helper", "response": "Returns a helper that formats a date string ahead of time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format(format_string, cast=lambda x: x):\n\n    def helper(instance, *args, **kwargs):\n        value = kwargs.get('default_value')\n        if value is None:\n            value = instance\n        value = cast(value)\n        return format_string.format(value, obj=instance)\n    return helper", "response": "A pre - called helper that can supply a modern string format for the items in the order they appear in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XEditable object for the given instance of the record.", "response": "def make_xeditable(instance=None, extra_attrs=[], *args, **kwargs):\n    \"\"\"\n    Converts the contents of the column into an ``<a>`` tag with the required DOM attributes to\n    power the X-Editable UI.\n\n    The following keyword arguments are all optional, but may be provided when pre-calling the\n    helper, to customize the output of the helper once it is run per object record:\n\n        * ``type`` - Defaults to the basic type of the HTML input (\"text\", \"number\", \"datetime\")\n        * ``title`` - Defaults to an empty string, controls the HTML \"title\" attribute.\n        * ``placeholder`` - Defaults to whatever \"title\" is, controls the HTML \"placeholder\" attribute.\n        * ``url`` - Defaults to the ``request.path`` of the view, which will automatically serve the X-Editable interface as long as it inherits from ``XEditableDatatableView``.\n        * ``source`` - Defaults to the ``request.path`` of the view, which will automatically serve X-Editable requests for ``choices`` data about a field.\n\n    Supplying a list of names via ``extra_attrs`` will enable arbitrary other keyword arguments to\n    be rendered in the HTML as attribute as well.  ``extra_attrs`` serves as a whitelist of extra\n    names so that unintended kwargs don't get rendered without your permission.\n    \"\"\"\n\n    if instance is None:\n        # Preloading kwargs into the helper for deferred execution\n        helper = partial(make_xeditable, extra_attrs=extra_attrs, *args, **kwargs)\n        return helper\n\n    # Immediate finalization, return the xeditable structure\n    data = kwargs.get('default_value', instance)\n    rich_data = kwargs.get('rich_value', data)\n\n    # Compile values to appear as \"data-*\" attributes on the anchor tag\n    default_attr_names = ['pk', 'type', 'url', 'source', 'title', 'placeholder']\n    valid_attr_names = set(default_attr_names + list(extra_attrs))\n    attrs = {}\n    for k, v in kwargs.items():\n        if k in valid_attr_names:\n            if k.startswith('data_'):\n                k = k[5:]\n            attrs['data-{0}'.format(k)] = v\n\n    attrs['data-xeditable'] = \"xeditable\"\n\n    # Assign default values where they are not provided\n\n    field_name = kwargs['field_name']  # sent as a default kwarg to helpers\n    if isinstance(field_name, (tuple, list)):\n        # Legacy syntax\n        field_name = field_name[1]\n        if isinstance(field_name, (tuple, list)):\n            raise ValueError(\"'make_xeditable' helper needs a single-field data column,\"\n                             \" not {0!r}\".format(field_name))\n    attrs['data-name'] = field_name\n\n    if isinstance(rich_data, Model):\n        attrs['data-value'] = rich_data.pk\n    else:\n        attrs['data-value'] = rich_data\n\n    if 'data-pk' not in attrs:\n        attrs['data-pk'] = instance.pk\n\n    if 'data-url' not in attrs:\n        # Look for a backup data-url\n        provider_name = 'get_update_url'\n        url_provider = getattr(kwargs.get('view'), provider_name, None)\n        if not url_provider:\n            url_provider = getattr(instance, provider_name, None)\n            if not url_provider and 'view' in kwargs:\n                url_provider = lambda field_name: kwargs['view'].request.path\n            else:\n                raise ValueError(\"'make_xeditable' cannot determine a value for 'url'.\")\n        if url_provider:\n            attrs['data-url'] = url_provider(field_name=field_name)\n\n    if 'data-placeholder' not in attrs:\n        attrs['data-placeholder'] = attrs.get('data-title', \"\")\n\n    if 'data-type' not in attrs:\n        if hasattr(instance, '_meta'):\n            # Try to fetch a reasonable type from the field's class\n            if field_name == 'pk':  # special field name not in Model._meta.fields\n                field = instance._meta.pk\n            else:\n                field = resolve_orm_path(instance, field_name)\n\n            if field.choices:\n                field_type = 'select'\n            else:\n                field_type = XEDITABLE_FIELD_TYPES.get(field.get_internal_type(), 'text')\n        else:\n            field_type = 'text'\n        attrs['data-type'] = field_type\n\n    # type=select elements need to fetch their valid choice options from an AJAX endpoint.\n    # Register the view for this lookup.\n    if attrs['data-type'] in ('select', 'select2'):\n        if 'data-source' not in attrs:\n            if 'view' in kwargs:\n                attrs['data-source'] = \"{url}?{field_param}={fieldname}\".format(**{\n                    'url': kwargs['view'].request.path,\n                    'field_param': kwargs['view'].xeditable_fieldname_param,\n                    'fieldname': field_name,\n                })\n                if attrs['data-type'] == 'select2':\n                    attrs['data-source'] += '&select2=true'\n            else:\n                raise ValueError(\"'make_xeditable' cannot determine a value for 'source'.\")\n\n        # Choice fields will want to display their readable label instead of db data\n        data = getattr(instance, 'get_{0}_display'.format(field_name), lambda: data)()\n\n    data = u\"\"\"<a href=\"#\"{attrs}>{data}</a>\"\"\".format(attrs=flatatt(attrs), data=data)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a pre - called processor that wraps the execution of the given function.", "response": "def make_processor(func, arg=None):\n    \"\"\"\n    A pre-called processor that wraps the execution of the target callable ``func``.\n\n    This is useful for when ``func`` is a third party mapping function that can take your column's\n    value and return an expected result, but doesn't understand all of the extra kwargs that get\n    sent to processor callbacks.  Because this helper proxies access to ``func``, it can hold back\n    the extra kwargs for a successful call.\n\n    ``func`` will be called once per object record, a single positional argument being the column\n    data retrieved via the column's :py:attr:`~datatableview.columns.Column.sources`\n\n    An optional ``arg`` may be given, which will be forwarded as a second positional argument to\n    ``func``.  This was originally intended to simplify using Django template filter functions as\n    ``func``.  If you need to sent more arguments, consider wrapping your ``func`` in a\n    ``functools.partial``, and use that as ``func`` instead.\n    \"\"\"\n    def helper(instance, *args, **kwargs):\n        value = kwargs.get('default_value')\n        if value is None:\n            value = instance\n        if arg is not None:\n            extra_arg = [arg]\n        else:\n            extra_arg = []\n        return func(value, *extra_arg)\n    return helper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_kitten(client):\n\t'''\n\t\tUpload a picture of a kitten. We don't ship one, so get creative!\n\t'''\n\n\t# Here's the metadata for the upload. All of these are optional, including\n\t# this config dict itself.\n\tconfig = {\n\t\t'album': album,\n\t\t'name':  'Catastrophe!',\n\t\t'title': 'Catastrophe!',\n\t\t'description': 'Cute kitten being cute on {0}'.format(datetime.now())\n\t}\n\n\tprint(\"Uploading image... \")\n\timage = client.upload_from_path(image_path, config=config, anon=False)\n\tprint(\"Done\")\n\tprint()\n\n\treturn image", "response": "Upload a kitten image to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if date is in dst.", "response": "def _isdst(dt):\n    \"\"\"Check if date is in dst.\n    \"\"\"\n    if type(dt) == datetime.date:\n        dt = datetime.datetime.combine(dt, datetime.datetime.min.time())\n    dtc = dt.replace(year=datetime.datetime.now().year)\n    if time.localtime(dtc.timestamp()).tm_isdst == 1:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mktime(time_struct):\n    try:\n        return time.mktime(time_struct)\n    except OverflowError:\n        dt = datetime.datetime(*time_struct[:6])\n        ep = datetime.datetime(1970, 1, 1)\n        diff = dt - ep\n        ts = diff.days * 24 * 3600 + diff.seconds + time.timezone\n        if time_struct.tm_isdst == 1:\n            ts -= 3600\n        # Guess if DST is in effect for -1\n        if time_struct.tm_isdst == -1 and _isdst(dt):\n            ts -= 3600\n        return ts", "response": "Custom mktime because Windows can t be arsed to properly do pre - Epoch\nAttributeNames dates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _gmtime(timestamp):\n    try:\n        return time.gmtime(timestamp)\n    except OSError:\n        dt = datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=timestamp)\n        dst = int(_isdst(dt))\n        return time.struct_time(dt.timetuple()[:8] + tuple([dst]))", "response": "Custom gmtime because yada yada.\n    is not available"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to guess whether a string represents a time or a time delta and returns the appropriate object.", "response": "def guesstype(timestr):\n    \"\"\"Tries to guess whether a string represents a time or a time delta and\n    returns the appropriate object.\n\n    :param timestr (required)\n        The string to be analyzed\n    \"\"\"\n    timestr_full = \" {} \".format(timestr)\n    if timestr_full.find(\" in \") != -1 or timestr_full.find(\" ago \") != -1:\n        return Chronyk(timestr)\n\n    comps = [\"second\", \"minute\", \"hour\", \"day\", \"week\", \"month\", \"year\"]\n    for comp in comps:\n        if timestr_full.find(comp) != -1:\n            return ChronykDelta(timestr)\n\n    return Chronyk(timestr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _round(num):\n    deci = num - math.floor(num)\n    if deci > 0.8:\n        return int(math.floor(num) + 1)\n    else:\n        return int(math.floor(num))", "response": "A custom rounding function that s a bit more strict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a datetime object.", "response": "def datetime(self, timezone=None):\n        \"\"\"Returns a datetime object.\n\n        This object retains all information, including timezones.\n\n        :param timezone = self.timezone\n            The timezone (in seconds west of UTC) to return the value in. By\n            default, the timezone used when constructing the class is used\n            (local one by default). To use UTC, use timezone = 0. To use the\n            local tz, use timezone = chronyk.LOCALTZ.\n        \"\"\"\n        if timezone is None:\n            timezone = self.timezone\n        return _dtfromtimestamp(self.__timestamp__ - timezone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a datetime. date object.", "response": "def date(self, timezone=None):\n        \"\"\"Returns a datetime.date object.\n        This object retains all information, including timezones.\n        \n        :param timezone = self.timezone\n            The timezone (in seconds west of UTC) to return the value in. By\n            default, the timezone used when constructing the class is used\n            (local one by default). To use UTC, use timezone = 0. To use the\n            local tz, use timezone = chronyk.LOCALTZ.\n        \"\"\"\n        if timezone is None:\n            timezone = self.timezone\n        return _dfromtimestamp(self.__timestamp__ - timezone)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef timestamp(self, timezone=None):\n        if timezone is None:\n            timezone = self.timezone\n        return self.__timestamp__ - timezone", "response": "Returns a timestamp in the specified timezone."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a ctime string.", "response": "def ctime(self, timezone=None):\n        \"\"\"Returns a ctime string.\n\n        :param timezone = self.timezone\n            The timezone (in seconds west of UTC) to return the value in. By\n            default, the timezone used when constructing the class is used\n            (local one by default). To use UTC, use timezone = 0. To use the\n            local tz, use timezone = chronyk.LOCALTZ.\n        \"\"\"\n        if timezone is None:\n            timezone = self.timezone\n        return time.ctime(self.__timestamp__ - timezone)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a time string.", "response": "def timestring(self, pattern=\"%Y-%m-%d %H:%M:%S\", timezone=None):\n        \"\"\"Returns a time string.\n\n        :param pattern = \"%Y-%m-%d %H:%M:%S\"\n            The format used. By default, an ISO-type format is used. The\n            syntax here is identical to the one used by time.strftime() and\n            time.strptime().\n\n        :param timezone = self.timezone\n            The timezone (in seconds west of UTC) to return the value in. By\n            default, the timezone used when constructing the class is used\n            (local one by default). To use UTC, use timezone = 0. To use the\n            local tz, use timezone = chronyk.LOCALTZ.\n        \"\"\"\n        if timezone is None:\n            timezone = self.timezone\n        timestamp = self.__timestamp__ - timezone\n        timestamp -= LOCALTZ\n        return _strftime(pattern, _gmtime(timestamp))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relativestring(\n            self, now=None, minimum=10, maximum=3600 * 24 * 30,\n            pattern=\"%Y-%m-%d\", timezone=None, maxunits=1):\n        \"\"\"Returns a relative time string (e.g. \"10 seconds ago\").\n\n        :param now = time.time()\n            The timestamp to compare this time to. By default, the current\n            local time is used.\n\n        :param minimum = 10\n            Amount in seconds under which \"just now\" is returned instead of a\n            numerical description. A value <= 0 disables this.\n\n        :param maximum = 3600 * 24 * 30 (30 days)\n            Amount in seconds above which the actual date is returned instead\n            of a numerical description. A value < 0 disables this.\n\n        :param pattern = \"%Y-%m-%d\"\n            The string format to use when maximum is exceeded. The syntax here\n            is identical to the one used by Chronyk.timestring(), which in turn\n            is the same as the one used by time.strptime() and time.strftime().\n\n        :param timezone = self.timezone\n            The timezone (in seconds west of UTC) to return the result in. By\n            default, the value used when constructing the class (local tz by\n            default) is used. To use UTC, use timezone=0. To use the local TZ,\n            use timezone=chronyk.LOCALTZ.\n\n        :param maxunits = 1\n            The maximum amount of units to return. This is identical to the\n            parameter of the same name of ChronykDelta's timestring method.\n        \"\"\"\n\n        if now is None:\n            now = time.time()\n        if timezone is None:\n            timezone = self.timezone\n\n        diff = now - (self.__timestamp__ - timezone)\n        future = diff < 0\n        diff = abs(diff)\n\n        if diff < minimum:\n            return \"just now\"\n        if diff > maximum and maximum > 0:\n            return self.timestring(pattern)\n\n        timestring = ChronykDelta(diff).timestring(maxunits=maxunits)\n        if timestring == \"1 day\":\n            return \"tomorrow\" if future else \"yesterday\"\n\n        if future:\n            return \"in {}\".format(timestring)\n        else:\n            return \"{} ago\".format(timestring)", "response": "Returns a relative time string for the current time."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string representation of this amount of time.", "response": "def timestring(self, maxunits=3):\n        \"\"\"Returns a string representation of this amount of time, like:\n        \"2 hours and 30 minutes\" or \"4 days, 2 hours and 40 minutes\"\n\n        :param maxunits = 3\n            The maximum amount of units to use.\n\n            1: \"2 hours\"\n            4: \"4 days, 2 hours, 5 minuts and 46 seconds\"\n\n        This method ignores the sign of the amount of time (that rhimes).\n        \"\"\"\n\n        try:\n            assert maxunits >= 1\n        except:\n            raise ValueError(\"Values < 1 for maxunits are not supported.\")\n\n        values = collections.OrderedDict()\n\n        seconds = abs(self.seconds)\n\n        values[\"year\"] = _round(seconds / (3600 * 24 * 365))\n        values[\"year\"] = values[\"year\"] if values[\"year\"] > 0 else 0\n        seconds -= values[\"year\"] * 3600 * 24 * 365\n\n        values[\"month\"] = _round(seconds / (3600 * 24 * 30))\n        values[\"month\"] = values[\"month\"] if values[\"month\"] > 0 else 0\n        seconds -= values[\"month\"] * 3600 * 24 * 30\n\n        values[\"day\"] = _round(seconds / (3600 * 24))\n        values[\"day\"] = values[\"day\"] if values[\"day\"] > 0 else 0\n        seconds -= values[\"day\"] * 3600 * 24\n\n        values[\"hour\"] = _round(seconds / 3600)\n        values[\"hour\"] = values[\"hour\"] if values[\"hour\"] > 0 else 0\n        seconds -= values[\"hour\"] * 3600\n\n        values[\"minute\"] = _round(seconds / 60)\n        values[\"minute\"] = values[\"minute\"] if values[\"minute\"] > 0 else 0\n        values[\"second\"] = _round(seconds - values[\"minute\"] * 60)\n\n        for k, v in values.items():\n            if v == 0:\n                values.pop(k)\n            else:\n                break\n\n        textsegs = []\n        for k, v in list(values.items())[:maxunits]:\n            if v > 0:\n                textsegs.append(_pluralstr(k, v))\n\n        if len(textsegs) == 0:\n            return \"\"\n        if len(textsegs) == 1:\n            return textsegs[0]\n\n        return \", \".join(textsegs[:-1]) + \" and \" + textsegs[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ticket(self, ticket_id):\n        url = 'tickets/%d' % ticket_id\n        ticket = self._api._get(url)\n        return Ticket(**ticket)", "response": "Fetches the ticket for the given ticket ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a ticket with the given subject and optionally with attachments.", "response": "def create_ticket(self, subject, **kwargs):\n        \"\"\"\n            Creates a ticket\n            To create ticket with attachments,\n            pass a key 'attachments' with value as list of fully qualified file paths in string format.\n            ex: attachments = ('/path/to/attachment1', '/path/to/attachment2')\n        \"\"\"\n\n        url = 'tickets'\n        status = kwargs.get('status', 2)\n        priority = kwargs.get('priority', 1)\n        data = {\n            'subject': subject,\n            'status': status,\n            'priority': priority,\n        }\n        data.update(kwargs)\n        if 'attachments' in data:\n            ticket = self._create_ticket_with_attachment(url, data)\n            return Ticket(**ticket)\n\n        ticket = self._api._post(url, data=json.dumps(data))\n        return Ticket(**ticket)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an outbound email", "response": "def create_outbound_email(self, subject, description, email, email_config_id, **kwargs):\n        \"\"\"Creates an outbound email\"\"\"\n        url = 'tickets/outbound_email'\n        priority = kwargs.get('priority', 1)\n        data = {\n            'subject': subject,\n            'description': description,\n            'priority': priority,\n            'email': email,\n            'email_config_id': email_config_id,\n        }\n        data.update(kwargs)\n        ticket = self._api._post(url, data=json.dumps(data))\n        return Ticket(**ticket)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_ticket(self, ticket_id, **kwargs):\n        url = 'tickets/%d' % ticket_id\n        ticket = self._api._put(url, data=json.dumps(kwargs))\n        return Ticket(**ticket)", "response": "Updates a ticket from a given ticket ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_tickets(self, **kwargs):\n\n        filter_name = 'new_and_my_open'\n        if 'filter_name' in kwargs:\n            filter_name = kwargs['filter_name']\n            del kwargs['filter_name']\n\n        url = 'tickets'\n        if filter_name is not None:\n            url += '?filter=%s&' % filter_name\n        else:\n            url += '?'\n        page = 1 if not 'page' in kwargs else kwargs['page']\n        per_page = 100 if not 'per_page' in kwargs else kwargs['per_page']\n        tickets = []\n\n        # Skip pagination by looping over each page and adding tickets if 'page' key is not in kwargs.\n        # else return the requested page and break the loop\n        while True:\n            this_page = self._api._get(url + 'page=%d&per_page=%d'\n                                       % (page, per_page), kwargs)\n            tickets += this_page\n            if len(this_page) < per_page or 'page' in kwargs:\n                break\n            page += 1\n\n        return [Ticket(**t) for t in tickets]", "response": "List all tickets optionally filtered by a view."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all contacts optionally filtered by a query.", "response": "def list_contacts(self, **kwargs):\n        \"\"\"\n        List all contacts, optionally filtered by a query. Specify filters as\n        query keyword argument, such as:\n\n        email=abc@xyz.com,\n        mobile=1234567890,\n        phone=1234567890,\n\n        contacts can be filtered by state and company_id such as:\n\n        state=[blocked/deleted/unverified/verified]\n        company_id=1234\n\n        contacts updated after a timestamp can be filtered such as;\n\n        _updated_since=2018-01-19T02:00:00Z\n\n        Passing None means that no named filter will be passed to\n        Freshdesk, which returns list of all contacts\n\n        \"\"\"\n\n        url = 'contacts?'\n        page = 1 if not 'page' in kwargs else kwargs['page']\n        per_page = 100 if not 'per_page' in kwargs else kwargs['per_page']\n\n        contacts = []\n\n        # Skip pagination by looping over each page and adding tickets if 'page' key is not in kwargs.\n        # else return the requested page and break the loop\n        while True:\n            this_page = self._api._get(url + 'page=%d&per_page=%d'\n                                       % (page, per_page), kwargs)\n            contacts += this_page\n            if len(this_page) < per_page or 'page' in kwargs:\n                break\n\n            page += 1\n\n        return [Contact(**c) for c in contacts]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all agents optionally filtered by a view.", "response": "def list_agents(self, **kwargs):\n        \"\"\"List all agents, optionally filtered by a view. Specify filters as\n        keyword arguments, such as:\n\n        {\n            email='abc@xyz.com',\n            phone=873902,\n            mobile=56523,\n            state='fulltime'\n        }\n\n        Passing None means that no named filter will be passed to\n        Freshdesk, which returns list of all agents\n\n        Multiple filters are AND'd together.\n        \"\"\"\n\n        url = 'agents?'\n        page = 1 if not 'page' in kwargs else kwargs['page']\n        per_page = 100 if not 'per_page' in kwargs else kwargs['per_page']\n\n        agents = []\n\n        # Skip pagination by looping over each page and adding tickets if 'page' key is not in kwargs.\n        # else return the requested page and break the loop\n        while True:\n            this_page = self._api._get(url + 'page=%d&per_page=%d'\n                                       % (page, per_page), kwargs)\n            agents += this_page\n            if len(this_page) < per_page or 'page' in kwargs:\n                break\n            page += 1\n\n        return [Agent(**a) for a in agents]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_agent(self, agent_id):\n        url = 'agents/%s' % agent_id\n        return Agent(**self._api._get(url))", "response": "Fetches the agent for the given agent ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get(self, url, params={}):\n        req = self._session.get(self._api_prefix + url, params=params)\n        return self._action(req)", "response": "Wrapper around request. get to use the API prefix. Returns a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping around request. post to use the API prefix. Returns a JSON response.", "response": "def _post(self, url, data={}, **kwargs):\n        \"\"\"Wrapper around request.post() to use the API prefix. Returns a JSON response.\"\"\"\n        if 'files' in kwargs:\n            req = self._session.post(self._api_prefix + url, auth=self._session.auth, data=data, **kwargs)\n            return self._action(req)\n\n        req = self._session.post(self._api_prefix + url, data=data, **kwargs)\n        return self._action(req)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap around request. put to use the API prefix. Returns a JSON response.", "response": "def _put(self, url, data={}):\n        \"\"\"Wrapper around request.put() to use the API prefix. Returns a JSON response.\"\"\"\n        req = self._session.put(self._api_prefix + url, data=data)\n        return self._action(req)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping around request. delete to use the API prefix. Returns a JSON response.", "response": "def _delete(self, url):\n        \"\"\"Wrapper around request.delete() to use the API prefix. Returns a JSON response.\"\"\"\n        req = self._session.delete(self._api_prefix + url)\n        return self._action(req)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_tickets(self, **kwargs):\n\n        filter_name = 'all_tickets'\n        if 'filter_name' in kwargs and kwargs['filter_name'] is not None:\n            filter_name = kwargs['filter_name']\n            del kwargs['filter_name']\n\n        url = 'helpdesk/tickets/filter/%s?format=json' % filter_name\n        page = 1\n        tickets = []\n\n        # Skip pagination by looping over each page and adding tickets\n        while True:\n            this_page = self._api._get(url + '&page=%d' % page, kwargs)\n            if len(this_page) == 0:\n                break\n            tickets += this_page\n            page += 1\n\n        return [self.get_ticket(t['display_id']) for t in tickets]", "response": "List all tickets optionally filtered by a view."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all contacts optionally filtered by a query.", "response": "def list_contacts(self, **kwargs):\n        \"\"\"\n        List all contacts, optionally filtered by a query. Specify filters as\n        query keyword argument, such as: \n        \n        query= email is abc@xyz.com,\n        query= mobile is 1234567890,\n        query= phone is 1234567890,\n\n        contacts can be filtered by name such as;\n        \n        letter=Prenit\n\n        Passing None means that no named filter will be passed to\n        Freshdesk, which returns list of all contacts\n\n        \"\"\"\n\n        url = 'contacts.json?'\n        if 'query' in kwargs.keys():\n            filter_query = kwargs.pop('query')\n            url = url + \"query={}\".format(filter_query)\n\n        if 'state' in kwargs.keys():\n            state_query = kwargs.pop('state')\n            url = url + \"state={}\".format(state_query)    \n\n        if 'letter' in kwargs.keys():\n            name_query = kwargs.pop('letter')\n            url = url + \"letter={}\".format(name_query)        \n                \n        contacts = self._api._get(url)    \n        return [Contact(**c['user']) for c in contacts]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_agents(self, **kwargs):\n\n        url = 'agents.json?'\n        if 'query' in kwargs.keys():\n            filter_query = kwargs.pop('query')\n            url = url + \"query={}\".format(filter_query)\n\n        if 'state' in kwargs.keys():\n            state_query = kwargs.pop('state')\n            url = url + \"state={}\".format(state_query)    \n                \n        agents = self._api._get(url)    \n        return [Agent(**a['agent']) for a in agents]", "response": "List all agents in the system optionally filtered by a query."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get(self, url, params={}):\n        r = requests.get(self._api_prefix + url,\n            params=params,\n            headers=self.headers,\n            auth=self.auth,\n        )\n        return self._action(r)", "response": "Wrapper around request. get to use the API prefix. Returns a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _post(self, url, data={}):\n        r = requests.post(self._api_prefix + url,\n            data=json.dumps(data),\n            headers=self.headers,\n            auth=self.auth,\n            allow_redirects=False,\n        )\n        return self._action(r)", "response": "Wrapper around request. post to use the API prefix. Returns a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _put(self, url, data={}):\n        r = requests.put(self._api_prefix + url,\n            data=json.dumps(data),\n            headers=self.headers,\n            auth=self.auth,\n            allow_redirects=False,\n        )\n        return self._action(r)", "response": "Wrapper around request. put to use the API prefix. Returns a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap around request. delete to use the API prefix. Returns a JSON response.", "response": "def _delete(self, url):\n        \"\"\"Wrapper around request.delete() to use the API prefix. Returns a JSON response.\"\"\"\n        r = requests.delete(self._api_prefix + url,\n            headers=self.headers,\n            auth=self.auth,\n            allow_redirects=False,\n        )\n        return self._action(r)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn JSON response or raise exception if errors are present", "response": "def _action(self, res):\n        \"\"\"Returns JSON response or raise exception if errors are present\"\"\"\n        try:\n            j = res.json()\n        except:\n            res.raise_for_status()\n            j = {}\n\n        if 'Retry-After' in res.headers:\n            raise HTTPError('403 Forbidden: API rate-limit has been reached until {}.'\n                            'See http://freshdesk.com/api#ratelimit'.format(res.headers['Retry-After']))\n\n        if 'require_login' in j:\n            raise HTTPError('403 Forbidden: API key is incorrect for this domain')\n\n        if 'error' in j:\n            raise HTTPError('{}: {}'.format(j.get('description'),\n                                            j.get('errors')))\n\n        # Catch any other errors\n        try:\n            res.raise_for_status()\n        except Exception as e:\n            raise HTTPError(\"{}: {}\".format(e, j))\n\n        return j"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef headTail_breaks(values, cuts):\n    values = np.array(values)\n    mean = np.mean(values)\n    cuts.append(mean)\n    if len(values) > 1:\n        return headTail_breaks(values[values >= mean], cuts)\n    return cuts", "response": "helper function for headTailBreak"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the quantiles for an array of values y and k", "response": "def quantile(y, k=4):\n    \"\"\"\n    Calculates the quantiles for an array\n\n    Parameters\n    ----------\n    y : array\n        (n,1), values to classify\n    k : int\n        number of quantiles\n\n    Returns\n    -------\n    q         : array\n                (n,1), quantile values\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import mapclassify as mc\n    >>> x = np.arange(1000)\n    >>> mc.classifiers.quantile(x)\n    array([249.75, 499.5 , 749.25, 999.  ])\n    >>> mc.classifiers.quantile(x, k = 3)\n    array([333., 666., 999.])\n\n    Note that if there are enough ties that the quantile values repeat, we\n    collapse to pseudo quantiles in which case the number of classes will be\n    less than k\n\n    >>> x = [1.0] * 100\n    >>> x.extend([3.0] * 40)\n    >>> len(x)\n    140\n    >>> y = np.array(x)\n    >>> mc.classifiers.quantile(y)\n    array([1., 3.])\n    \"\"\"\n\n    w = 100. / k\n    p = np.arange(w, 100 + w, w)\n    if p[-1] > 100.0:\n        p[-1] = 100.0\n    q = np.array([stats.scoreatpercentile(y, pct) for pct in p])\n    q = np.unique(q)\n    k_q = len(q)\n    if k_q < k:\n        Warn('Warning: Not enough unique values in array to form k classes',\n             UserWarning)\n        Warn('Warning: setting k to %d' % k_q, UserWarning)\n    return q"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbin categorical data and qualitative data.", "response": "def binC(y, bins):\n    \"\"\"\n    Bin categorical/qualitative data\n\n    Parameters\n    ----------\n    y    : array\n           (n,q), categorical values\n    bins : array\n           (k,1),  unique values associated with each bin\n\n    Return\n    ------\n    b : array\n        (n,q), bin membership, values between 0 and k-1\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import mapclassify as mc\n    >>> np.random.seed(1)\n    >>> x = np.random.randint(2, 8, (10, 3))\n    >>> bins = list(range(2, 8))\n    >>> x\n    array([[7, 5, 6],\n           [2, 3, 5],\n           [7, 2, 2],\n           [3, 6, 7],\n           [6, 3, 4],\n           [6, 7, 4],\n           [6, 5, 6],\n           [4, 6, 7],\n           [4, 6, 3],\n           [3, 2, 7]])\n    >>> y = mc.classifiers.binC(x, bins)\n    >>> y\n    array([[5, 3, 4],\n           [0, 1, 3],\n           [5, 0, 0],\n           [1, 4, 5],\n           [4, 1, 2],\n           [4, 5, 2],\n           [4, 3, 4],\n           [2, 4, 5],\n           [2, 4, 1],\n           [1, 0, 5]])\n    \"\"\"\n\n    if np.ndim(y) == 1:\n        k = 1\n        n = np.shape(y)[0]\n    else:\n        n, k = np.shape(y)\n    b = np.zeros((n, k), dtype='int')\n    for i, bin in enumerate(bins):\n        b[np.nonzero(y == bin)] = i\n\n    # check for non-binned items and warn if needed\n    vals = set(y.flatten())\n    for val in vals:\n        if val not in bins:\n            Warn('value not in bin: {}'.format(val), UserWarning)\n            Warn('bins: {}'.format(bins), UserWarning)\n\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbin the array y into k - 1 - array and return the result as a new array.", "response": "def bin(y, bins):\n    \"\"\"\n    bin interval/ratio data\n\n    Parameters\n    ----------\n    y : array\n        (n,q), values to bin\n    bins : array\n           (k,1), upper bounds of each bin (monotonic)\n\n    Returns\n    -------\n    b : array\n        (n,q), values of values between 0 and k-1\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import mapclassify as mc\n    >>> np.random.seed(1)\n    >>> x = np.random.randint(2, 20, (10, 3))\n    >>> bins = [10, 15, 20]\n    >>> b = mc.classifiers.bin(x, bins)\n    >>> x\n    array([[ 7, 13, 14],\n           [10, 11, 13],\n           [ 7, 17,  2],\n           [18,  3, 14],\n           [ 9, 15,  8],\n           [ 7, 13, 12],\n           [16,  6, 11],\n           [19,  2, 15],\n           [11, 11,  9],\n           [ 3,  2, 19]])\n    >>> b\n    array([[0, 1, 1],\n           [0, 1, 1],\n           [0, 2, 0],\n           [2, 0, 1],\n           [0, 1, 0],\n           [0, 1, 1],\n           [2, 0, 1],\n           [2, 0, 1],\n           [1, 1, 0],\n           [0, 0, 2]])\n    \"\"\"\n    if np.ndim(y) == 1:\n        k = 1\n        n = np.shape(y)[0]\n    else:\n        n, k = np.shape(y)\n    b = np.zeros((n, k), dtype='int')\n    i = len(bins)\n    if type(bins) != list:\n        bins = bins.tolist()\n    binsc = copy.copy(bins)\n    while binsc:\n        i -= 1\n        c = binsc.pop(-1)\n        b[np.nonzero(y <= c)] = i\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new base - 1 - d array with binning of x into bins and counts of values in a 1 - d array.", "response": "def bin1d(x, bins):\n    \"\"\"\n    Place values of a 1-d array into bins and determine counts of values in\n    each bin\n\n    Parameters\n    ----------\n    x : array\n        (n, 1), values to bin\n    bins : array\n           (k,1), upper bounds of each bin (monotonic)\n\n    Returns\n    -------\n    binIds : array\n             1-d array of integer bin Ids\n\n    counts : int\n            number of elements of x falling in each bin\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import mapclassify as mc\n    >>> x = np.arange(100, dtype = 'float')\n    >>> bins = [25, 74, 100]\n    >>> binIds, counts = mc.classifiers.bin1d(x, bins)\n    >>> binIds\n    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n           2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n    >>> counts\n    array([26, 49, 25])\n    \"\"\"\n    left = [-float(\"inf\")]\n    left.extend(bins[0:-1])\n    right = bins\n    cuts = list(zip(left, right))\n    k = len(bins)\n    binIds = np.zeros(x.shape, dtype='int')\n    while cuts:\n        k -= 1\n        l, r = cuts.pop(-1)\n        binIds += (x > l) * (x <= r) * k\n    counts = np.bincount(binIds, minlength=len(bins))\n    return (binIds, counts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the total sum of squares for a vector y classified into the base class y", "response": "def _fit(y, classes):\n    \"\"\"Calculate the total sum of squares for a vector y classified into\n    classes\n\n    Parameters\n    ----------\n    y : array\n        (n,1), variable to be classified\n\n    classes : array\n              (k,1), integer values denoting class membership\n\n    \"\"\"\n    tss = 0\n    for class_def in classes:\n        yc = y[class_def]\n        css = yc - yc.mean()\n        css *= css\n        tss += sum(css)\n    return tss"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gadf(y, method=\"Quantiles\", maxk=15, pct=0.8):\n\n    y = np.array(y)\n    adam = (np.abs(y - np.median(y))).sum()\n    for k in range(2, maxk + 1):\n        cl = kmethods[method](y, k)\n        gadf = 1 - cl.adcm / adam\n        if gadf > pct:\n            break\n    return (k, cl, gadf)", "response": "Evaluate the Goodness of Absolute Deviation Fit of a Classifier at k = 15 and maxk = 15 and pct = 0. 8"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update(self, data, *args, **kwargs):\n        if data is not None:\n            data = np.asarray(data).flatten()\n            data = np.append(data.flatten(), self.y)\n        else:\n            data = self.y\n        self.__init__(data, *args, **kwargs)", "response": "Update the internal state of the object with the new data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures and create a classifier that will consume data and produce a new class. This is a simple classifier that will produce a new class with the same configuration as the class.", "response": "def make(cls, *args, **kwargs):\n        \"\"\"\n        Configure and create a classifier that will consume data and produce\n        classifications, given the configuration options specified by this\n        function.\n\n        Note that this like a *partial application* of the relevant class\n        constructor. `make` creates a function that returns classifications; it\n        does not actually do the classification.\n\n        If you want to classify data directly, use the appropriate class\n        constructor, like Quantiles, Max_Breaks, etc.\n\n        If you *have* a classifier object, but want to find which bins new data\n        falls into, use find_bin.\n\n        Parameters\n        ----------\n        *args           : required positional arguments\n                          all positional arguments required by the classifier,\n                          excluding the input data.\n        rolling         : bool\n                          a boolean configuring the outputted classifier to use\n                          a rolling classifier rather than a new classifier for\n                          each input. If rolling, this adds the current data to\n                          all of the previous data in the classifier, and\n                          rebalances the bins, like a running median\n                          computation.\n        return_object   : bool\n                          a boolean configuring the outputted classifier to\n                          return the classifier object or not\n        return_bins     : bool\n                          a boolean configuring the outputted classifier to\n                          return the bins/breaks or not\n        return_counts   : bool\n                          a boolean configuring the outputted classifier to\n                          return the histogram of objects falling into each bin\n                          or not\n\n        Returns\n        -------\n        A function that consumes data and returns their bins (and object,\n        bins/breaks, or counts, if requested).\n\n        Note\n        ----\n        This is most useful when you want to run a classifier many times\n        with a given configuration, such as when classifying many columns of an\n        array or dataframe using the same configuration.\n\n        Examples\n        --------\n        >>> import libpysal as ps\n        >>> import mapclassify as mc\n        >>> import geopandas as gpd\n        >>> df = gpd.read_file(ps.examples.get_path('columbus.dbf'))\n        >>> classifier = mc.Quantiles.make(k=9)\n        >>> cl = df[['HOVAL', 'CRIME', 'INC']].apply(classifier)\n        >>> cl[\"HOVAL\"].values[:10]\n        array([8, 7, 2, 4, 1, 3, 8, 5, 7, 8])\n        >>> cl[\"CRIME\"].values[:10]\n        array([0, 1, 3, 4, 6, 2, 0, 5, 3, 4])\n        >>> cl[\"INC\"].values[:10]\n        array([7, 8, 5, 0, 3, 5, 0, 3, 6, 4])\n        >>> import pandas as pd; from numpy import linspace as lsp\n        >>> data = [lsp(3,8,num=10), lsp(10, 0, num=10), lsp(-5, 15, num=10)]\n        >>> data = pd.DataFrame(data).T\n        >>> data\n                  0          1          2\n        0  3.000000  10.000000  -5.000000\n        1  3.555556   8.888889  -2.777778\n        2  4.111111   7.777778  -0.555556\n        3  4.666667   6.666667   1.666667\n        4  5.222222   5.555556   3.888889\n        5  5.777778   4.444444   6.111111\n        6  6.333333   3.333333   8.333333\n        7  6.888889   2.222222  10.555556\n        8  7.444444   1.111111  12.777778\n        9  8.000000   0.000000  15.000000\n        >>> data.apply(mc.Quantiles.make(rolling=True))\n           0  1  2\n        0  0  4  0\n        1  0  4  0\n        2  1  4  0\n        3  1  3  0\n        4  2  2  1\n        5  2  1  2\n        6  3  0  4\n        7  3  0  4\n        8  4  0  4\n        9  4  0  4\n        >>> dbf = ps.io.open(ps.examples.get_path('baltim.dbf'))\n        >>> data = dbf.by_col_array('PRICE', 'LOTSZ', 'SQFT')\n        >>> my_bins = [1, 10, 20, 40, 80]\n        >>> cl = [mc.User_Defined.make(bins=my_bins)(a) for a in data.T]\n        >>> len(cl)\n        3\n        >>> cl[0][:10]\n        array([4, 5, 5, 5, 4, 4, 5, 4, 4, 5])\n        \"\"\"\n\n        # only flag overrides return flag\n        to_annotate = copy.deepcopy(kwargs)\n        return_object = kwargs.pop('return_object', False)\n        return_bins = kwargs.pop('return_bins', False)\n        return_counts = kwargs.pop('return_counts', False)\n\n        rolling = kwargs.pop('rolling', False)\n        if rolling:\n            #  just initialize a fake classifier\n            data = list(range(10))\n            cls_instance = cls(data, *args, **kwargs)\n            #  and empty it, since we'll be using the update\n            cls_instance.y = np.array([])\n        else:\n            cls_instance = None\n\n        #  wrap init in a closure to make a consumer.\n        #  Qc Na: \"Objects/Closures are poor man's Closures/Objects\"\n        def classifier(data, cls_instance=cls_instance):\n            if rolling:\n                cls_instance.update(data, inplace=True, **kwargs)\n                yb = cls_instance.find_bin(data)\n            else:\n                cls_instance = cls(data, *args, **kwargs)\n                yb = cls_instance.yb\n            outs = [yb, None, None, None]\n            outs[1] = cls_instance if return_object else None\n            outs[2] = cls_instance.bins if return_bins else None\n            outs[3] = cls_instance.counts if return_counts else None\n            outs = [a for a in outs if a is not None]\n            if len(outs) == 1:\n                return outs[0]\n            else:\n                return outs\n\n        #  for debugging/jic, keep around the kwargs.\n        #  in future, we might want to make this a thin class, so that we can\n        #  set a custom repr. Call the class `Binner` or something, that's a\n        #  pre-configured Classifier that just consumes data, bins it, &\n        #  possibly updates the bins.\n        classifier._options = to_annotate\n        return classifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the total sum of squares around all class means", "response": "def get_tss(self):\n        \"\"\"\n        Total sum of squares around class means\n\n        Returns sum of squares over all class means\n        \"\"\"\n        tss = 0\n        for class_def in self.classes:\n            if len(class_def) > 0:\n                yc = self.y[class_def]\n                css = yc - yc.mean()\n                css *= css\n                tss += sum(css)\n        return tss"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_adcm(self):\n        adcm = 0\n        for class_def in self.classes:\n            if len(class_def) > 0:\n                yc = self.y[class_def]\n                yc_med = np.median(yc)\n                ycd = np.abs(yc - yc_med)\n                adcm += sum(ycd)\n        return adcm", "response": "Calculates the absolute deviation around class median and calculates the absolute deviations of each observation about its class\n        median."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the gadf of the current object based on the goodness of absolute deviation of fit", "response": "def get_gadf(self):\n        \"\"\"\n        Goodness of absolute deviation of fit\n        \"\"\"\n        adam = (np.abs(self.y - np.median(self.y))).sum()\n        gadf = 1 - self.adcm / adam\n        return gadf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the bin index of the input or inputs that are in the current bin estimate.", "response": "def find_bin(self, x):\n        \"\"\"\n        Sort input or inputs according to the current bin estimate\n\n        Parameters\n        ----------\n        x       :   array or numeric\n                    a value or array of values to fit within the estimated\n                    bins\n\n        Returns\n        -------\n        a bin index or array of bin indices that classify the input into one of\n        the classifiers' bins.\n\n        Note that this differs from similar functionality in\n        numpy.digitize(x, classi.bins, right=True).\n\n        This will always provide the closest bin, so data \"outside\" the classifier,\n        above and below the max/min breaks, will be classified into the nearest bin.\n\n        numpy.digitize returns k+1 for data greater than the greatest bin, but retains 0\n        for data below the lowest bin.\n        \"\"\"\n        x = np.asarray(x).flatten()\n        right = np.digitize(x, self.bins, right=True)\n        if right.max() == len(self.bins):\n            right[right == len(self.bins)] = len(self.bins) - 1\n        return right"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, y=None, inplace=False, **kwargs):\n        kwargs.update({'k': kwargs.pop('k', self.k)})\n        kwargs.update({'pct': kwargs.pop('pct', self.pct)})\n        kwargs.update({'truncate': kwargs.pop('truncate', self._truncated)})\n        if inplace:\n            self._update(y, **kwargs)\n        else:\n            new = copy.deepcopy(self)\n            new._update(y, **kwargs)\n            return new", "response": "Update the internal state of the object with new data or change classification parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates sum of squares for a class", "response": "def _ss(self, class_def):\n        \"\"\"calculates sum of squares for a class\"\"\"\n        yc = self.y[class_def]\n        css = yc - yc.mean()\n        css *= css\n        return sum(css)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates cost of moving a from class1 to class2", "response": "def _swap(self, class1, class2, a):\n        \"\"\"evaluate cost of moving a from class1 to class2\"\"\"\n        ss1 = self._ss(class1)\n        ss2 = self._ss(class2)\n        tss1 = ss1 + ss2\n        class1c = copy.copy(class1)\n        class2c = copy.copy(class2)\n        class1c.remove(a)\n        class2c.append(a)\n        ss1 = self._ss(class1c)\n        ss2 = self._ss(class2c)\n        tss2 = ss1 + ss2\n        if tss1 < tss2:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bounding_box_list(input_doc_fname, input_doc, full_page_box_list,\n                       set_of_page_nums_to_crop, argparse_args, chosen_PdfFileWriter):\n    \"\"\"Calculate a bounding box for each page in the document.  The first\n    argument is the filename of the document's original PDF file, the second is\n    the PdfFileReader for the document.  The argument full_page_box_list is a list\n    of the full-page-size boxes (which is used to correct for any nonzero origins\n    in the PDF coordinates).  The set_of_page_nums_to_crop argument is the set of page\n    numbers to crop; it is passed so that unnecessary calculations can be\n    skipped.  The argparse_args argument should be passed the args parsed from\n    the command line by argparse.  The chosen_PdfFileWriter is the PdfFileWriter\n    class from whichever pyPdf package was chosen by the main program.  The\n    function returns the list of bounding boxes.\"\"\"\n    global args, page_nums_to_crop, PdfFileWriter\n    args = argparse_args # Make args available to all funs in module, as a global.\n    page_nums_to_crop = set_of_page_nums_to_crop # Make the set of pages global, too.\n    PdfFileWriter = chosen_PdfFileWriter # Be sure correct PdfFileWriter is set.\n\n    if args.gsBbox:\n        if args.verbose:\n            print(\"\\nUsing Ghostscript to calculate the bounding boxes.\")\n        bbox_list = ex.get_bounding_box_list_ghostscript(input_doc_fname,\n                                             args.resX, args.resY, args.fullPageBox)\n    else:\n        if not hasPIL:\n            print(\"\\nError in pdfCropMargins: No version of the PIL package (or a\"\n                  \"\\nfork like Pillow) was found.  Either install that Python\"\n                  \"\\npackage or use the Ghostscript flag '--gsBbox' (or '-gs') if you\"\n                  \"\\nhave Ghostscript installed.\", file=sys.stderr)\n            ex.cleanup_and_exit(1)\n        bbox_list = get_bounding_box_list_render_image(input_doc_fname, input_doc)\n\n    # Now we need to use the full page boxes to translate for non-zero origin.\n    bbox_list = correct_bounding_box_list_for_nonzero_origin(bbox_list,\n                                                             full_page_box_list)\n\n    return bbox_list", "response": "Calculate a bounding box for each page in the document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef correct_bounding_box_list_for_nonzero_origin(bbox_list, full_box_list):\n\n    corrected_box_list = []\n    for bbox, full_box in zip(bbox_list, full_box_list):\n        left_x = full_box[0]\n        lower_y = full_box[1]\n        corrected_box_list.append([bbox[0]+left_x, bbox[1]+lower_y,\n                                 bbox[2]+left_x, bbox[3]+lower_y])\n    return corrected_box_list", "response": "Corrects the bounding box list for the image that is at zero origin."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the bounding box list by directly rendering each page of the PDF and then rendering each image file.", "response": "def get_bounding_box_list_render_image(pdf_file_name, input_doc):\n    \"\"\"Calculate the bounding box list by directly rendering each page of the PDF as\n    an image file.  The MediaBox and CropBox values in input_doc should have\n    already been set to the chosen page size before the rendering.\"\"\"\n\n    program_to_use = \"pdftoppm\" # default to pdftoppm\n    if args.gsRender: program_to_use = \"Ghostscript\"\n\n    # Threshold value set in range 0-255, where 0 is black, with 191 default.\n    if not args.threshold: args.threshold = 191\n    threshold = args.threshold\n    if not args.numSmooths: args.numSmooths = 0\n    if not args.numBlurs: args.numBlurs = 0\n\n    temp_dir = ex.program_temp_directory # use the program default; don't delete dir!\n\n    temp_image_file_root = os.path.join(temp_dir, ex.temp_file_prefix + \"PageImage\")\n    if args.verbose:\n        print(\"\\nRendering the PDF to images using the \" + program_to_use + \" program,\"\n              \"\\nthis may take a while...\")\n\n    # Do the rendering of all the files.\n    render_pdf_file_to_image_files(pdf_file_name, temp_image_file_root, program_to_use)\n\n    # Currently assuming that sorting the output will always put them in correct order.\n    outfiles = sorted(glob.glob(temp_image_file_root + \"*\"))\n\n    if args.verbose:\n        print(\"\\nAnalyzing the page images with PIL to find bounding boxes,\"\n              \"\\nusing the threshold \" + str(args.threshold) + \".\"\n              \"  Finding the bounding box for page:\\n\")\n\n    bounding_box_list = []\n\n    for page_num, tmp_image_file_name in enumerate(outfiles):\n        curr_page = input_doc.getPage(page_num)\n\n        # Open the image in PIL.  Retry a few times on fail in case race conditions.\n        max_num_tries = 3\n        time_between_tries = 1\n        curr_num_tries = 0\n        while True:\n            try:\n                # PIL for some reason fails in Python 3.4 if you open the image\n                # from a file you opened yourself.  Works in Python 2 and earlier\n                # Python 3.  So original code is commented out, and path passed.\n                #\n                # tmpImageFile = open(tmpImageFileName)\n                # im = Image.open(tmpImageFile)\n                im = Image.open(tmp_image_file_name)\n                break\n            except (IOError, UnicodeDecodeError) as e:\n                curr_num_tries += 1\n                if args.verbose:\n                    print(\"Warning: Exception opening image\", tmp_image_file_name,\n                          \"on try\", curr_num_tries, \"\\nError is\", e, file=sys.stderr)\n                # tmpImageFile.close() # see above comment\n                if curr_num_tries > max_num_tries: raise # re-raise exception\n                time.sleep(time_between_tries)\n\n        # Apply any blur or smooth operations specified by the user.\n        for i in range(args.numBlurs):\n            im = im.filter(ImageFilter.BLUR)\n        for i in range(args.numSmooths):\n            im = im.filter(ImageFilter.SMOOTH_MORE)\n\n        # Convert the image to black and white, according to a threshold.\n        # Make a negative image, because that works with the PIL getbbox routine.\n\n        if args.verbose:\n            print(page_num+1, end=\" \") # page num numbering from 1\n        # Note that the point method calls the function on each pixel, replacing it.\n        #im = im.point(lambda p: p > threshold and 255) # create a positive image\n        #im = im.point(lambda p: p < threshold and 255)  # create a negative image\n        # Below code is easier to understand than tricky use of \"and\" in evaluation.\n        im = im.point(lambda p: 255 if p < threshold else 0)  # create a negative image\n\n        if args.showImages:\n            im.show() # usually for debugging or param-setting\n\n        # Calculate the bounding box of the negative image, and append to list.\n        bounding_box = calculate_bounding_box_from_image(im, curr_page)\n        bounding_box_list.append(bounding_box)\n\n        # Clean up the image files after they are no longer needed.\n        # tmpImageFile.close() # see above comment\n        os.remove(tmp_image_file_name)\n\n    if args.verbose:\n        print()\n    return bounding_box_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders all the pages of the PDF file at pdf_file_name to image files with path and filename prefix given by output_filename_root.", "response": "def render_pdf_file_to_image_files(pdf_file_name, output_filename_root, program_to_use):\n    \"\"\"Render all the pages of the PDF file at pdf_file_name to image files with\n    path and filename prefix given by output_filename_root.  Any directories must\n    have already been created, and the calling program is responsible for\n    deleting any directories or image files.  The program program_to_use,\n    currently either the string \"pdftoppm\" or the string \"Ghostscript\", will be\n    called externally.  The image type that the PDF is converted into must to be\n    directly openable by PIL.\"\"\"\n\n    res_x = str(args.resX)\n    res_y = str(args.resY)\n    if program_to_use == \"Ghostscript\":\n        if ex.system_os == \"Windows\": # Windows PIL is more likely to know BMP\n            ex.render_pdf_file_to_image_files__ghostscript_bmp(\n                                  pdf_file_name, output_filename_root, res_x, res_y)\n        else: # Linux and Cygwin should be fine with PNG\n            ex.render_pdf_file_to_image_files__ghostscript_png(\n                                  pdf_file_name, output_filename_root, res_x, res_y)\n    elif program_to_use == \"pdftoppm\":\n        use_gray = False # this is currently hardcoded, but can be changed to use pgm\n        if use_gray:\n            ex.render_pdf_file_to_image_files_pdftoppm_pgm(\n                pdf_file_name, output_filename_root, res_x, res_y)\n        else:\n            ex.render_pdf_file_to_image_files_pdftoppm_ppm(\n                pdf_file_name, output_filename_root, res_x, res_y)\n    else:\n        print(\"Error in renderPdfFileToImageFile: Unrecognized external program.\",\n              file=sys.stderr)\n        ex.cleanup_and_exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_bounding_box_from_image(im, curr_page):\n    xMax, y_max = im.size\n    bounding_box = im.getbbox() # note this uses ltrb convention\n    if not bounding_box:\n        #print(\"\\nWarning: could not calculate a bounding box for this page.\"\n        #      \"\\nAn empty page is assumed.\", file=sys.stderr)\n        bounding_box = (xMax/2, y_max/2, xMax/2, y_max/2)\n\n    bounding_box = list(bounding_box) # make temporarily mutable\n\n    # Compensate for reversal of the image y convention versus PDF.\n    bounding_box[1] = y_max - bounding_box[1]\n    bounding_box[3] = y_max - bounding_box[3]\n\n    full_page_box = curr_page.mediaBox # should have been set already to chosen box\n\n    # Convert pixel units to PDF's bp units.\n    convert_x = float(full_page_box.getUpperRight_x()\n                     - full_page_box.getLowerLeft_x()) / xMax\n    convert_y = float(full_page_box.getUpperRight_y()\n                     - full_page_box.getLowerLeft_y()) / y_max\n\n    # Get final box; note conversion to lower-left point, upper-right point format.\n    final_box = [\n        bounding_box[0] * convert_x,\n        bounding_box[3] * convert_y,\n        bounding_box[2] * convert_x,\n        bounding_box[1] * convert_y]\n\n    return final_box", "response": "This function uses a PIL routine to get the bounding box of the rendered\n    image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_temporary_filename(extension=\"\", use_program_temp_dir=True):\n    dir_name = None # uses the regular system temp dir if None\n    if use_program_temp_dir: dir_name = program_temp_directory\n    tmp_output_file = tempfile.NamedTemporaryFile(delete=False,\n                     prefix=temp_file_prefix, suffix=extension, dir=dir_name, mode=\"wb\")\n    tmp_output_file.close() # this deletes the file, too, but it is empty in this case\n    return tmp_output_file.name", "response": "Return the string for a temporary file with the given extension or suffix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the canonical form of the absolute path from a possibly relative path.", "response": "def get_canonical_absolute_expanded_path(path):\n    \"\"\"Get the canonical form of the absolute path from a possibly relative path\n    (which may have symlinks, etc.)\"\"\"\n    return os.path.normcase(\n               os.path.normpath(\n                   os.path.realpath( # remove any symbolic links\n                       os.path.abspath( # may not be needed with realpath, to be safe\n                           os.path.expanduser(path)))))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if paths refer to the same file or directory.", "response": "def samefile(path1, path2):\n    \"\"\"Test if paths refer to the same file or directory.\"\"\"\n    if system_os == \"Linux\" or system_os == \"Cygwin\":\n        return os.path.samefile(path1, path2)\n    return (get_canonical_absolute_expanded_path(path1) ==\n            get_canonical_absolute_expanded_path(path2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_parent_directory(path):\n    if not os.path.isdir(path): path = os.path.dirname(path)\n    return os.path.abspath(os.path.join(path, os.path.pardir))", "response": "Like os. path. dirname except it returns the absolute name of the parent\n    of the dirname directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand any globbing if system_os is Windows.", "response": "def glob_if_windows_os(path, exact_num_args=False):\n    \"\"\"Expands any globbing if system_os is Windows (DOS doesn't do it).  The\n    argument exactNumFiles can be set to an integer to check for an exact\n    number of matching files.  Returns a list.\"\"\"\n    if system_os != \"Windows\": return [path]\n    globbed = glob.glob(path)\n    if not globbed:\n        print(\"\\nWarning in pdfCropMargins: The wildcards in the path\\n   \"\n              + path + \"\\nfailed to expand.  Treating as literal.\",\n              file=sys.stderr)\n        globbed = [path]\n    if exact_num_args and len(globbed) != exact_num_args:\n        print(\"\\nError in pdfCropMargins: The wildcards in the path\\n   \"\n              + path + \"\\nexpand to the wrong number of files.\",\n              file=sys.stderr)\n        cleanup_and_exit(1)\n    return globbed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_windows_path_to_cygwin(path):\n    if len(path) > 2 and path[1] == \":\" and path[2] == \"\\\\\":\n        newpath = cygwin_full_path_prefix + \"/\" + path[0]\n        if len(path) > 3: newpath += \"/\" + path[3:]\n        path = newpath\n    path = path.replace(\"\\\\\", \"/\")\n    return path", "response": "Convert a Windows path to a Cygwin path. Just handles the basic case."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_program_temp_directory():\n    if os.path.exists(program_temp_directory):\n        max_retries = 3\n        curr_retries = 0\n        time_between_retries = 1\n        while True:\n            try:\n                shutil.rmtree(program_temp_directory)\n                break\n            except IOError:\n                curr_retries += 1\n                if curr_retries > max_retries:\n                    raise # re-raise the exception\n                time.sleep(time_between_retries)\n            except:\n                print(\"Cleaning up temp dir...\", file=sys.stderr)\n                raise", "response": "Remove the global temp directory and all its contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_external_subprocess_output(command_list, print_output=False, indent_string=\"\",\n                      split_lines=True, ignore_called_process_errors=False, env=None):\n    \"\"\"Run the command and arguments in the command_list.  Will search the system\n    PATH.  Returns the output as a list of lines.   If print_output is True the\n    output is echoed to stdout, indented (or otherwise prefixed) by indent_string.\n    Waits for command completion.  Called process errors can be set to be\n    ignored if necessary.\"\"\"\n\n    # Note ghostscript bounding box output writes to stderr!  So we need to\n    # be sure to capture the stderr along with the stdout.\n\n    print_output = False # Useful for debugging to set True.\n\n    use_popen = True # Needs to be True to set ignore_called_process_errors True\n    if use_popen: # Use lower-level Popen call.\n        p = subprocess.Popen(command_list, stdout=subprocess.PIPE,\n                             stderr=subprocess.STDOUT, env=env)\n        output, errout = p.communicate()\n        returncode = p.poll()\n        if not ignore_called_process_errors and returncode != 0:\n            raise subprocess.CalledProcessError(returncode, command_list, output=output)\n    else: # Use a check_output call.\n        # Note this does not work correctly if shell=True.\n        output = subprocess.check_output(command_list, stderr=subprocess.STDOUT,\n                                         shell=False, env=env)\n\n    output = output.decode(\"utf-8\")\n\n    if split_lines or print_output:\n        split_output = output.splitlines()\n    if split_lines:\n        output = split_output\n    if print_output:\n        print()\n        for line in split_output:\n            print(indent_string + line)\n        sys.stdout.flush()\n    return output", "response": "Run the command and arguments in the system\n    PATH."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the command and arguments in the command_list.", "response": "def call_external_subprocess(command_list,\n                       stdin_filename=None, stdout_filename=None, stderr_filename=None,\n                       env=None):\n    \"\"\"Run the command and arguments in the command_list.  Will search the system\n    PATH for commands to execute, but no shell is started.  Redirects any selected\n    outputs to the given filename.  Waits for command completion.\"\"\"\n\n    if stdin_filename: stdin = open(stdin_filename, \"r\")\n    else: stdin = None\n    if stdout_filename: stdout = open(stdout_filename, \"w\")\n    else: stdout = None\n    if stderr_filename: stderr = open(stderr_filename, \"w\")\n    else: stderr = None\n\n    subprocess.check_call(command_list, stdin=stdin, stdout=stdout, stderr=stderr,\n                          env=env)\n\n    if stdin_filename: stdin.close()\n    if stdout_filename: stdout.close()\n    if stderr_filename: stderr.close()\n\n    # The older way to do the above with os.system is below, just for reference.\n    # command = \" \".join(command_list)\n    # if stdin_filename: command += \" < \" + stdin_filename\n    # if stdout_filename: command += \" > \" + stdout_filename\n    # if stderr_filename: command += \" 2> \" + stderr_filename\n    # os.system(command)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the command and arguments in the list as a background process.", "response": "def run_external_subprocess_in_background(command_list, env=None):\n    \"\"\"Runs the command and arguments in the list as a background process.\"\"\"\n    if system_os == \"Windows\":\n        DETACHED_PROCESS = 0x00000008\n        p = subprocess.Popen(command_list, shell=False, stdin=None, stdout=None,\n                stderr=None, close_fds=True, creationflags=DETACHED_PROCESS, env=env)\n    else:\n        p = subprocess.Popen(command_list, shell=False, stdin=None, stdout=None,\n                stderr=None, close_fds=True, env=env)\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a Python function with a timeout.", "response": "def function_call_with_timeout(fun_name, fun_args, secs=5):\n    \"\"\"Run a Python function with a timeout.  No interprocess communication or\n    return values are handled.  Setting secs to 0 gives infinite timeout.\"\"\"\n    from multiprocessing import Process, Queue\n    p = Process(target=fun_name, args=tuple(fun_args))\n    p.start()\n    curr_secs = 0\n    no_timeout = False\n    if secs == 0: no_timeout = True\n    else: timeout = secs\n    while p.is_alive() and not no_timeout:\n        if curr_secs > timeout:\n            print(\"Process time has exceeded timeout, terminating it.\")\n            p.terminate()\n            return False\n        time.sleep(0.1)\n        curr_secs += 0.1\n    p.join() # Blocks if process hasn't terminated.\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_pdf_with_ghostscript_to_tmp_file(input_doc_fname):\n\n    if not gs_executable: init_and_test_gs_executable(exit_on_fail=True)\n    temp_file_name = get_temporary_filename(extension=\".pdf\")\n    gs_run_command = [gs_executable, \"-dSAFER\", \"-o\", temp_file_name,\n                    \"-dPDFSETTINGS=/prepress\", \"-sDEVICE=pdfwrite\", input_doc_fname]\n    try:\n        gs_output = get_external_subprocess_output(gs_run_command, print_output=True,\n                                             indent_string=\"   \", env=gs_environment)\n    except subprocess.CalledProcessError:\n        print(\"\\nError in pdfCropMargins:  Ghostscript returned a non-zero exit\"\n              \"\\nstatus when attempting to fix the file:\\n   \", input_doc_fname,\n              file=sys.stderr)\n        cleanup_and_exit(1)\n    except UnicodeDecodeError:\n        print(\"\\nWarning in pdfCropMargins:  In attempting to repair the PDF file\"\n              \"\\nGhostscript produced a message containing characters which cannot\"\n              \"\\nbe decoded by the 'utf-8' codec.  Ignoring and hoping for the best.\",\n              file=sys.stderr)\n    return temp_file_name", "response": "Attempt to fix a bad PDF file with Ghostscript command writing the output\n    PDF to a temporary file and returning the filename."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall Ghostscript to get the bounding box list.", "response": "def get_bounding_box_list_ghostscript(input_doc_fname, res_x, res_y, full_page_box):\n    \"\"\"Call Ghostscript to get the bounding box list.  Cannot set a threshold\n    with this method.\"\"\"\n\n    if not gs_executable: init_and_test_gs_executable(exit_on_fail=True)\n    res = str(res_x) + \"x\" + str(res_y)\n    box_arg = \"-dUseMediaBox\" # should be default, but set anyway\n    if \"c\" in full_page_box: box_arg = \"-dUseCropBox\"\n    if \"t\" in full_page_box: box_arg = \"-dUseTrimBox\"\n    if \"a\" in full_page_box: box_arg = \"-dUseArtBox\"\n    if \"b\" in full_page_box: box_arg = \"-dUseBleedBox\" # may not be defined in gs\n    gs_run_command = [gs_executable, \"-dSAFER\", \"-dNOPAUSE\", \"-dBATCH\", \"-sDEVICE=bbox\",\n                    box_arg, \"-r\"+res, input_doc_fname]\n    # Set printOutput to True for debugging or extra-verbose with Ghostscript's output.\n    # Note Ghostscript writes the data to stderr, so the command below must capture it.\n    try:\n        gs_output = get_external_subprocess_output(gs_run_command,\n                          print_output=False, indent_string=\"   \", env=gs_environment)\n    except UnicodeDecodeError:\n        print(\"\\nError in pdfCropMargins:  In attempting to get the bounding boxes\"\n              \"\\nGhostscript encountered characters which cannot be decoded by the\"\n              \"\\n'utf-8' codec.\",\n              file=sys.stderr)\n        cleanup_and_exit(1)\n\n    bounding_box_list = []\n    for line in gs_output:\n        split_line = line.split()\n        if split_line and split_line[0] == r\"%%HiResBoundingBox:\":\n            del split_line[0]\n            if len(split_line) != 4:\n                print(\"\\nWarning from pdfCropMargins: Ignoring this unparsable line\"\n                      \"\\nwhen finding the bounding boxes with Ghostscript:\",\n                      line, \"\\n\", file=sys.stderr)\n                continue\n            # Note gs reports values in order left, bottom, right, top,\n            # i.e., lower left point followed by top right point.\n            bounding_box_list.append([float(split_line[0]),\n                                    float(split_line[1]),\n                                    float(split_line[2]),\n                                    float(split_line[3])])\n\n    if not bounding_box_list:\n        print(\"\\nError in pdfCropMargins: Ghostscript failed to find any bounding\"\n              \"\\nboxes in the document.\", file=sys.stderr)\n        cleanup_and_exit(1)\n    return bounding_box_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_pdf_file_to_image_files_pdftoppm_ppm(pdf_file_name, root_output_file_path,\n                                           res_x=150, res_y=150, extra_args=None):\n    \"\"\"Use the pdftoppm program to render a PDF file to .png images.  The\n    root_output_file_path is prepended to all the output files, which have numbers\n    and extensions added.  Extra arguments can be passed as a list in extra_args.\n    Return the command output.\"\"\"\n\n    if extra_args is None: extra_args = []\n\n    if not pdftoppm_executable:\n        init_and_test_pdftoppm_executable(prefer_local=False, exit_on_fail=True)\n\n    if old_pdftoppm_version:\n        # We only have -r, not -rx and -ry.\n        command = [pdftoppm_executable] + extra_args + [\"-r\", res_x, pdf_file_name,\n                                              root_output_file_path]\n    else:\n        command = [pdftoppm_executable] + extra_args + [\"-rx\", res_x, \"-ry\", res_y,\n                                              pdf_file_name, root_output_file_path]\n    comm_output = get_external_subprocess_output(command)\n    return comm_output", "response": "Use the pdftoppm program to render a PDF file to. png images."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing Ghostscript to render a PDF file to. png images.", "response": "def render_pdf_file_to_image_files__ghostscript_png(pdf_file_name,\n                                                    root_output_file_path,\n                                                    res_x=150, res_y=150):\n    \"\"\"Use Ghostscript to render a PDF file to .png images.  The root_output_file_path\n    is prepended to all the output files, which have numbers and extensions added.\n    Return the command output.\"\"\"\n    # For gs commands see\n    # http://ghostscript.com/doc/current/Devices.htm#File_formats\n    # http://ghostscript.com/doc/current/Devices.htm#PNG\n    if not gs_executable: init_and_test_gs_executable(exit_on_fail=True)\n    command = [gs_executable, \"-dBATCH\", \"-dNOPAUSE\", \"-sDEVICE=pnggray\",\n               \"-r\"+res_x+\"x\"+res_y, \"-sOutputFile=\"+root_output_file_path+\"-%06d.png\",\n               pdf_file_name]\n    comm_output = get_external_subprocess_output(command, env=gs_environment)\n    return comm_output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_preview(viewer_path, pdf_file_name):\n    try:\n        cmd = [viewer_path, pdf_file_name]\n        run_external_subprocess_in_background(cmd)\n    except (subprocess.CalledProcessError, OSError, IOError) as e:\n        print(\"\\nWarning from pdfCropMargins: The argument to the '--viewer' option:\"\n              \"\\n   \", viewer_path, \"\\nwas not found or failed to execute correctly.\\n\",\n              file=sys.stderr)\n    return", "response": "Run the PDF viewer at the path viewer_path on the file pdf_file_name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns main, catching any exceptions and cleaning up the temp directories.", "response": "def main():\n    \"\"\"Run main, catching any exceptions and cleaning up the temp directories.\"\"\"\n\n    cleanup_and_exit = sys.exit # Function to do cleanup and exit before the import.\n    exit_code = 0\n\n    # Imports are done here inside the try block so some ugly (and useless)\n    # traceback info is avoided on user's ^C (KeyboardInterrupt, EOFError on Windows).\n    try:\n        from . import external_program_calls as ex # Creates tmp dir as side effect.\n        cleanup_and_exit = ex.cleanup_and_exit # Switch to the real one, deletes temp dir.\n\n        from . import main_pdfCropMargins # Imports external_program_calls, don't do first.\n        main_pdfCropMargins.main_crop() # Run the actual program.\n\n    except (KeyboardInterrupt, EOFError): # Windows raises EOFError on ^C.\n        print(\"\\nGot a KeyboardInterrupt, cleaning up and exiting...\\n\",\n              file=sys.stderr)\n\n    except SystemExit:\n        exit_code = sys.exc_info()[1]\n        print()\n\n    except:\n        # Echo back the unexpected error so the user can see it.\n        print(\"\\nCaught an unexpected exception in the pdfCropMargins program.\",\n                                                               file=sys.stderr)\n        print(\"Unexpected error: \", sys.exc_info()[0], file=sys.stderr)\n        print(\"Error message   : \", sys.exc_info()[1], file=sys.stderr)\n        print()\n        exit_code = 1\n        import traceback\n        max_traceback_length = 30\n        traceback.print_tb(sys.exc_info()[2], limit=max_traceback_length)\n        # raise # Re-raise the error.\n\n    finally:\n        # Some people like to hit multiple ^C chars, which kills cleanup.\n        # Call cleanup again each time.\n        for i in range(30): # Give up after 30 tries.\n            try:\n                cleanup_and_exit(exit_code)\n            except (KeyboardInterrupt, EOFError):\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_default_filename(infile_path, is_cropped_file=True):\n\n    if is_cropped_file: suffix = prefix = args.stringCropped\n    else: suffix = prefix = args.stringUncropped\n\n    # Use modified basename as output path; program writes default output to CWD.\n    file_name = os.path.basename(infile_path)\n    nameBeforeExtension, extension = os.path.splitext(file_name)\n    if extension not in {\".pdf\", \".PDF\"}: extension += \".pdf\"\n\n    sep = args.stringSeparator\n    if args.usePrefix: name = prefix + sep + nameBeforeExtension + extension\n    else: name = nameBeforeExtension + sep + suffix + extension\n\n    return name", "response": "Generate the default filename for the input\n    file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake two pyPdf boxes and returns the pyPdf box which is their intersection.", "response": "def intersect_boxes(box1, box2):\n    \"\"\"Takes two pyPdf boxes (such as page.mediaBox) and returns the pyPdf\n    box which is their intersection.\"\"\"\n    if not box1 and not box2: return None\n    if not box1: return box2\n    if not box2: return box1\n    intersect = RectangleObject([0, 0, 0, 0]) # Note [llx,lly,urx,ury] == [l,b,r,t]\n    intersect.upperRight = (min(box1.upperRight[0], box2.upperRight[0]),\n                            min(box1.upperRight[1], box2.upperRight[1]))\n    intersect.lowerLeft = (max(box1.lowerLeft[0], box2.lowerLeft[0]),\n                           max(box1.lowerLeft[1], box2.lowerLeft[1]))\n    return intersect"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_full_page_box_assigning_media_and_crop(page):\n\n    # Find the page rotation angle (degrees).\n    # Note rotation is clockwise, and four values are allowed: 0 90 180 270\n    try:\n        rotation = page[\"/Rotate\"].getObject() # this works, needs try\n        #rotation = page.get(\"/Rotate\", 0) # from the PyPDF2 source, default 0\n    except KeyError:\n        rotation = 0\n    while rotation >= 360: rotation -= 360\n    while rotation < 0: rotation += 360\n\n    # Save the rotation value in the page's namespace so we can restore it later.\n    page.rotationAngle = rotation\n\n    # Un-rotate the page, leaving it with an rotation of 0.\n    page.rotateClockwise(-rotation)\n\n    # Save copies of some values in the page's namespace, to possibly restore later.\n    page.originalMediaBox = page.mediaBox\n    page.originalCropBox = page.cropBox\n\n    first_loop = True\n    for box_string in args.fullPageBox:\n        if box_string == \"m\": f_box = page.mediaBox\n        if box_string == \"c\": f_box = page.cropBox\n        if box_string == \"t\": f_box = page.trimBox\n        if box_string == \"a\": f_box = page.artBox\n        if box_string == \"b\": f_box = page.bleedBox\n\n        # Take intersection over all chosen boxes.\n        if first_loop:\n            full_box = f_box\n        else:\n            full_box = intersect_boxes(full_box, f_box)\n\n        first_loop = False\n\n    # Do any absolute pre-cropping specified for the page (after modifying any\n    # absolutePreCrop arguments to take into account rotations to the page).\n    a = mod_box_for_rotation(args.absolutePreCrop, rotation)\n    full_box = RectangleObject([float(full_box.lowerLeft[0]) + a[0],\n                                float(full_box.lowerLeft[1]) + a[1],\n                                float(full_box.upperRight[0]) - a[2],\n                                float(full_box.upperRight[1]) - a[3]])\n\n    page.mediaBox = full_box\n    page.cropBox = full_box\n\n    return full_box", "response": "This function returns the full PDF box that is assigned to the MediaBox and CropBox."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of all the full - page box values for each page.", "response": "def get_full_page_box_list_assigning_media_and_crop(input_doc, quiet=False):\n    \"\"\"Get a list of all the full-page box values for each page.  The argument\n    input_doc should be a PdfFileReader object.  The boxes on the list are in the\n    simple 4-float list format used by this program, not RectangleObject format.\"\"\"\n\n    full_page_box_list = []\n    rotation_list = []\n\n    if args.verbose and not quiet:\n        print(\"\\nOriginal full page sizes, in PDF format (lbrt):\")\n\n    for page_num in range(input_doc.getNumPages()):\n\n        # Get the current page and find the full-page box.\n        curr_page = input_doc.getPage(page_num)\n        full_page_box = get_full_page_box_assigning_media_and_crop(curr_page)\n\n        if args.verbose and not quiet:\n            # want to display page num numbering from 1, so add one\n            print(\"\\t\"+str(page_num+1), \"  rot =\",\n                  curr_page.rotationAngle, \"\\t\", full_page_box)\n\n        # Convert the RectangleObject to floats in an ordinary list and append.\n        ordinary_box = [float(b) for b in full_page_box]\n        full_page_box_list.append(ordinary_box)\n\n        # Append the rotation value to the rotation_list.\n        rotation_list.append(curr_page.rotationAngle)\n\n    return full_page_box_list, rotation_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a list of full - page boxes and bounding boxes for each page calculate and return another list giving the list of all the pages to crop down to.", "response": "def calculate_crop_list(full_page_box_list, bounding_box_list, angle_list,\n                                                               page_nums_to_crop):\n    \"\"\"Given a list of full-page boxes (media boxes) and a list of tight\n    bounding boxes for each page, calculate and return another list giving the\n    list of bounding boxes to crop down to.  The parameter `angle_list` is\n    a list of rotation angles which correspond to the pages.  The pages\n    selected to crop are in the set `page_nums_to_crop`.\"\"\"\n\n    # Definition: the deltas are the four differences, one for each margin,\n    # between the original full page box and the final, cropped full-page box.\n    # In the usual case where margin sizes decrease these are the same as the\n    # four margin-reduction values (in absolute points).   The deltas are\n    # usually positive but they can be negative due to either percentRetain>100\n    # or a large enough absolute offset (in which case the size of the\n    # corresponding margin will increase).  When percentRetain<0 the deltas are\n    # always greater than the absolute difference between the full page and a\n    # tight bounding box, and so part of the text within the tight bounding box\n    # will also be cropped (unless absolute offsets are used to counter that).\n\n    num_pages = len(bounding_box_list)\n    page_range = range(num_pages)\n    num_pages_to_crop = len(page_nums_to_crop)\n\n    # Handle the '--samePageSize' option.\n    # Note that this is always done first, even before evenodd is handled.  It\n    # is only applied to the pages in the set `page_nums_to_crop`.\n\n    order_n = 0\n    if args.samePageSizeOrderStat:\n        args.samePageSize = True\n        order_n = min(args.samePageSizeOrderStat[0], num_pages_to_crop - 1)\n        order_n = max(order_n, 0)\n\n    if args.samePageSize:\n        if args.verbose:\n            print(\"\\nSetting each page size to the smallest box bounding all the pages.\")\n            if order_n != 0:\n                print(\"But ignoring the largest {} pages in calculating each edge.\"\n                        .format(order_n))\n\n        same_size_bounding_box = [\n              # We want the smallest of the left and bottom edges.\n              sorted(full_page_box_list[pg][0] for pg in page_nums_to_crop),\n              sorted(full_page_box_list[pg][1] for pg in page_nums_to_crop),\n              # We want the largest of the right and top edges.\n              sorted((full_page_box_list[pg][2] for pg in page_nums_to_crop), reverse=True),\n              sorted((full_page_box_list[pg][3] for pg in page_nums_to_crop), reverse=True)\n              ]\n        same_size_bounding_box = [sortlist[order_n] for sortlist in same_size_bounding_box]\n\n        new_full_page_box_list = []\n        for p_num, box in enumerate(full_page_box_list):\n            if p_num not in page_nums_to_crop:\n                new_full_page_box_list.append(box)\n            else:\n                new_full_page_box_list.append(same_size_bounding_box)\n        full_page_box_list = new_full_page_box_list\n\n    # Handle the '--evenodd' option if it was selected.\n    if args.evenodd:\n        even_page_nums_to_crop = {p_num for p_num in page_nums_to_crop if p_num % 2 == 0}\n        odd_page_nums_to_crop = {p_num for p_num in page_nums_to_crop if p_num % 2 != 0}\n\n        if args.uniform:\n            uniform_set_with_even_odd = True\n        else:\n            uniform_set_with_even_odd = False\n\n        # Recurse on even and odd pages, after resetting some options.\n        if args.verbose:\n            print(\"\\nRecursively calculating crops for even and odd pages.\")\n        args.evenodd = False # Avoid infinite recursion.\n        args.uniform = True  # --evenodd implies uniform, just on each separate group\n        even_crop_list = calculate_crop_list(full_page_box_list, bounding_box_list,\n                                             angle_list, even_page_nums_to_crop)\n        odd_crop_list = calculate_crop_list(full_page_box_list, bounding_box_list,\n                                            angle_list, odd_page_nums_to_crop)\n\n        # Recombine the even and odd pages.\n        combine_even_odd = []\n        for p_num in page_range:\n            if p_num % 2 == 0:\n                combine_even_odd.append(even_crop_list[p_num])\n            else:\n                combine_even_odd.append(odd_crop_list[p_num])\n\n        # Handle the case where --uniform was set with --evenodd.\n        if uniform_set_with_even_odd:\n            min_bottom_margin = min(box[1] for p_num, box in enumerate(combine_even_odd)\n                                                          if p_num in page_nums_to_crop)\n            max_top_margin = max(box[3] for p_num, box in enumerate(combine_even_odd)\n                                                       if p_num in page_nums_to_crop)\n            combine_even_odd = [[box[0], min_bottom_margin, box[2], max_top_margin]\n                              for box in combine_even_odd]\n        return combine_even_odd\n\n    # Before calculating the crops we modify the percentRetain and\n    # absoluteOffset values for all the pages according to any specified.\n    # rotations for the pages.  This is so, for example, uniform cropping is\n    # relative to what the user actually sees.\n    rotated_percent_retain = [mod_box_for_rotation(args.percentRetain, angle_list[m_val])\n                                                         for m_val in range(num_pages)]\n    rotated_absolute_offset = [mod_box_for_rotation(args.absoluteOffset, angle_list[m_val])\n                                                         for m_val in range(num_pages)]\n\n    # Calculate the list of deltas to be used to modify the original page\n    # sizes.  Basically, a delta is the absolute diff between the full and\n    # tight-bounding boxes, scaled according to the user's percentRetain, with\n    # any absolute offset then added (lb) or subtracted (tr) as appropriate.\n    #\n    # The deltas are all positive unless absoluteOffset changes that or\n    # percent>100.  They are added (lb) or subtracted (tr) as appropriate.\n\n    delta_list = []\n    for p_num, t_box, f_box in zip(list(range(len(full_page_box_list))),\n                                               bounding_box_list, full_page_box_list):\n        deltas = [abs(t_box[m_val] - f_box[m_val]) for m_val in range(4)]\n        adj_deltas = [deltas[m_val] * (100.0-rotated_percent_retain[p_num][m_val]) / 100.0\n                     for m_val in range(4)]\n        adj_deltas = [adj_deltas[m_val] + rotated_absolute_offset[p_num][m_val] for m_val in range(4)]\n        delta_list.append(adj_deltas)\n\n    # Handle the '--uniform' options if one was selected.\n    if args.uniformOrderPercent:\n        percent_val = args.uniformOrderPercent[0]\n        if percent_val < 0.0: percent_val = 0.0\n        if percent_val > 100.0: percent_val = 100.0\n        args.uniformOrderStat = [int(round(num_pages_to_crop * percent_val / 100.0))]\n\n    if args.uniform or args.uniformOrderStat or args.uniformOrderStat4:\n        if args.verbose:\n            print(\"\\nAll the selected pages will be uniformly cropped.\")\n        # Expand to tuples containing page nums, to better print verbose information.\n        delta_list = [(delta_list[j], j+1) for j in page_range] # Note +1 added here.\n\n        # Only look at the deltas which correspond to pages selected for cropping.\n        # The values will then be sorted for each margin and selected.\n        crop_delta_list = [delta_list[j] for j in page_range if j in page_nums_to_crop]\n\n        # Handle order stats; m_vals are the four index values into the sorted\n        # delta lists, one per margin.\n        m_vals = [0, 0, 0, 0]\n        if args.uniformOrderStat4:\n            m_vals = args.uniformOrderStat4\n        elif args.uniformOrderStat:\n            m_vals = [args.uniformOrderStat[0]] * 4\n        fixed_m_vals = []\n        for m_val in m_vals:\n            if m_val < 0 or m_val >= num_pages_to_crop:\n                print(\"\\nWarning: The selected order statistic is out of range.\",\n                      \"Setting to closest value.\", file=sys.stderr)\n                if m_val >= num_pages_to_crop:\n                    m_val = num_pages_to_crop - 1\n                if m_val < 0:\n                    m_val = 0\n            fixed_m_vals.append(m_val)\n        m_vals = fixed_m_vals\n        if args.verbose and (args.uniformOrderStat or args.uniformOrderPercent\n                                                   or args.uniformOrderStat4):\n            print(\"\\nPer-margin, the\", m_vals,\n                  \"smallest delta values over the selected pages\\nwill be ignored\"\n                  \" when choosing common, uniform delta values.\")\n\n        # Get a sorted list of (delta, page_num) tuples for each margin.\n        left_vals = sorted([(box[0][0], box[1]) for box in crop_delta_list])\n        lower_vals = sorted([(box[0][1], box[1]) for box in crop_delta_list])\n        right_vals = sorted([(box[0][2], box[1]) for box in crop_delta_list])\n        upper_vals = sorted([(box[0][3], box[1]) for box in crop_delta_list])\n        delta_list = [[left_vals[m_vals[0]][0], lower_vals[m_vals[1]][0],\n                      right_vals[m_vals[2]][0], upper_vals[m_vals[3]][0]]] * num_pages\n\n        if args.verbose:\n            delta_page_nums = [left_vals[m_vals[0]][1], lower_vals[m_vals[1]][1],\n                               right_vals[m_vals[2]][1], upper_vals[m_vals[3]][1]]\n            print(\"\\nThe smallest delta values actually used to set the uniform\"\n                  \" cropping\\namounts (ignoring any '-m' skips and pages in ranges\"\n                  \" not cropped) were\\nfound on these pages, numbered from 1:\\n   \",\n                  delta_page_nums)\n            print(\"\\nThe final delta values themselves are:\\n   \", delta_list[0])\n\n    # Apply the delta modifications to the full boxes to get the final sizes.\n    final_crop_list = []\n    for f_box, deltas in zip(full_page_box_list, delta_list):\n        final_crop_list.append((f_box[0] + deltas[0], f_box[1] + deltas[1],\n                                f_box[2] - deltas[2], f_box[3] - deltas[3]))\n\n    # Set the page ratios if user chose that option.\n    if args.setPageRatios:\n        ratio = args.setPageRatios[0]\n        if args.verbose:\n            print(\"\\nSetting all page width to height ratios to:\", ratio)\n        ratio_set_crop_list = []\n        for left, bottom, right, top in final_crop_list:\n            width = right - left\n            horizontal_center = (right + left) / 2.0\n            height = top - bottom\n            vertical_center = (top + bottom) / 2.0\n            new_height = width / ratio\n            if new_height < height:\n                new_width = height * ratio\n                assert new_width >= width\n                ratio_set_crop_list.append((horizontal_center - new_width/2.0, bottom,\n                                            horizontal_center + new_width/2.0, top))\n            else:\n                ratio_set_crop_list.append((left, vertical_center - new_height/2.0,\n                                           right, vertical_center + new_height/2.0))\n        final_crop_list = ratio_set_crop_list\n\n    return final_crop_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_cropped_metadata(input_doc, output_doc, metadata_info):\n\n    # Setting metadata with pyPdf requires low-level pyPdf operations, see\n    # http://stackoverflow.com/questions/2574676/change-metadata-of-pdf-file-with-pypdf\n    if not metadata_info:\n        # In case it's null, just set values to empty strings.  This class just holds\n        # data temporary in the same format; this is not sent into PyPDF2.\n        class MetadataInfo(object):\n            author = \"\"\n            creator = \"\"\n            producer = \"\"\n            subject = \"\"\n            title = \"\"\n        metadata_info = MetadataInfo()\n\n    output_info_dict = output_doc._info.getObject()\n\n    # Check Producer metadata attribute to see if this program cropped document before.\n    producer_mod = PRODUCER_MODIFIER\n    already_cropped_by_this_program = False\n    old_producer_string = metadata_info.producer\n    if old_producer_string and old_producer_string.endswith(producer_mod):\n        if args.verbose:\n            print(\"\\nThe document was already cropped at least once by this program.\")\n        already_cropped_by_this_program = True\n        producer_mod = \"\" # No need to pile up suffixes each time on Producer.\n\n    # Note that all None metadata attributes are currently set to the empty string\n    # when passing along the metadata information.\n    def st(item):\n        if item is None: return \"\"\n        else: return item\n\n    output_info_dict.update({\n          NameObject(\"/Author\"): createStringObject(st(metadata_info.author)),\n          NameObject(\"/Creator\"): createStringObject(st(metadata_info.creator)),\n          NameObject(\"/Producer\"): createStringObject(st(metadata_info.producer)\n                                                                 + producer_mod),\n          NameObject(\"/Subject\"): createStringObject(st(metadata_info.subject)),\n          NameObject(\"/Title\"): createStringObject(st(metadata_info.title))\n          })\n\n    return already_cropped_by_this_program", "response": "Set the metadata for the output document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply the crop list to the pages of the input PDFFileReader object.", "response": "def apply_crop_list(crop_list, input_doc, page_nums_to_crop,\n                                          already_cropped_by_this_program):\n    \"\"\"Apply the crop list to the pages of the input PdfFileReader object.\"\"\"\n\n    if args.restore and not already_cropped_by_this_program:\n        print(\"\\nWarning from pdfCropMargins: The Producer string indicates that\"\n              \"\\neither this document was not previously cropped by pdfCropMargins\"\n              \"\\nor else it was modified by another program after that.  Trying the\"\n              \"\\nundo anyway...\", file=sys.stderr)\n\n    if args.restore and args.verbose:\n        print(\"\\nRestoring the document to margins saved for each page in the ArtBox.\")\n\n    if args.verbose and not args.restore:\n        print(\"\\nNew full page sizes after cropping, in PDF format (lbrt):\")\n\n    # Copy over each page, after modifying the appropriate PDF boxes.\n    for page_num in range(input_doc.getNumPages()):\n\n        curr_page = input_doc.getPage(page_num)\n\n        # Restore any rotation which was originally on the page.\n        curr_page.rotateClockwise(curr_page.rotationAngle)\n\n        # Only do the restore from ArtBox if '--restore' option was selected.\n        if args.restore:\n            if not curr_page.artBox:\n                print(\"\\nWarning from pdfCropMargins: Attempting to restore pages from\"\n                      \"\\nthe ArtBox in each page, but page\", page_num, \"has no readable\"\n                      \"\\nArtBox.  Leaving that page unchanged.\", file=sys.stderr)\n                continue\n            curr_page.mediaBox = curr_page.artBox\n            curr_page.cropBox = curr_page.artBox\n            continue\n\n        # Do the save to ArtBox if that option is chosen and Producer is set.\n        if not args.noundosave and not already_cropped_by_this_program:\n            curr_page.artBox = intersect_boxes(curr_page.mediaBox, curr_page.cropBox)\n\n        # Reset the CropBox and MediaBox to their saved original values\n        # (which were set in getFullPageBox, in the curr_page object's namespace).\n        curr_page.mediaBox = curr_page.originalMediaBox\n        curr_page.cropBox = curr_page.originalCropBox\n\n        # Copy the original page without further mods if it wasn't in the range\n        # selected for cropping.\n        if page_num not in page_nums_to_crop:\n            continue\n\n        # Convert the computed \"box to crop to\" into a RectangleObject (for pyPdf).\n        new_cropped_box = RectangleObject(crop_list[page_num])\n\n        if args.verbose:\n            print(\"\\t\"+str(page_num+1)+\"\\t\", new_cropped_box) # page numbering from 1\n\n        if not args.boxesToSet:\n            args.boxesToSet = [\"m\", \"c\"]\n\n        # Now set any boxes which were selected to be set via the --boxesToSet option.\n        if \"m\" in args.boxesToSet: curr_page.mediaBox = new_cropped_box\n        if \"c\" in args.boxesToSet: curr_page.cropBox = new_cropped_box\n        if \"t\" in args.boxesToSet: curr_page.trimBox = new_cropped_box\n        if \"a\" in args.boxesToSet: curr_page.artBox = new_cropped_box\n        if \"b\" in args.boxesToSet: curr_page.bleedBox = new_cropped_box\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the output document and copy over the relevant info.", "response": "def setup_output_document(input_doc, tmp_input_doc, metadata_info,\n                                                    copy_document_catalog=True):\n    \"\"\"Create the output `PdfFileWriter` objects and copy over the relevant info.\"\"\"\n    # NOTE: Inserting pages from a PdfFileReader into multiple PdfFileWriters\n    # seems to cause problems (writer can hang on write), so only one is used.\n    # This is why the tmp_input_doc file was created earlier, to get copies of\n    # the page objects which are independent of those in input_doc.  An ugly\n    # hack for a nasty bug to track down.\n\n    # NOTE: You can get the _root_object attribute (dict for the document\n    # catalog) from the output document after calling cloneReaderDocumentRoot\n    # or else you can just directly get it from the input_doc.trailer dict, as\n    # below (which is from the code for cloneReaderDocumentRoot), but you\n    # CANNOT set the full _root_object to be the _root_object attribute for the\n    # actual output_doc or else only blank pages show up in acroread (whether\n    # or not there is any attempt to explicitly copy the pages over).  The same\n    # is true for using cloneDocumentFromReader (which just calls\n    # cloneReaderDocumentRoot followed by appendPagesFromReader).  At least the\n    # '/Pages' key and value in _root_object cause problems, so they are\n    # skipped in the partial copy.  Probably a bug in PyPDF2.  See the original\n    # code for the routines on the github pages below.\n    #\n    # https://github.com/mstamy2/PyPDF2/blob/master/PyPDF2/pdf.py\n    # https://github.com/mstamy2/PyPDF2/blob/master/PyPDF2/generic.py\n    #\n    # Files still can change zoom mode on clicking outline links, but that is\n    # an Adobe implementation problem, and happens even in the uncropped files:\n    # https://superuser.com/questions/278302/\n\n    output_doc = PdfFileWriter()\n\n    def root_objects_not_indirect(input_doc, root_object):\n        \"\"\"This can expand some of the `IndirectObject` objects in  a root object to\n        see the actual values.  Currently only used for debugging.  May mess up the\n        input doc and require a temporary one.\"\"\"\n        if isinstance(root_object, dict):\n            return {root_objects_not_indirect(input_doc, key):\n                    root_objects_not_indirect(input_doc, value) for\n                                                  key, value in root_object.items()}\n        elif isinstance(root_object, list):\n            return [root_objects_not_indirect(input_doc, item) for item in root_object]\n        elif isinstance(root_object, IndirectObject):\n            return input_doc.getObject(root_object)\n        else:\n            return root_object\n\n    doc_cat_whitelist = args.docCatWhitelist.split()\n    if \"ALL\" in doc_cat_whitelist:\n        doc_cat_whitelist = [\"ALL\"]\n\n    doc_cat_blacklist = args.docCatBlacklist.split()\n    if \"ALL\" in doc_cat_blacklist:\n        doc_cat_blacklist = [\"ALL\"]\n\n    # Partially copy over document catalog data from input_doc to output_doc.\n    if not copy_document_catalog or (\n            not doc_cat_whitelist and doc_cat_blacklist == [\"ALL\"]):\n        # Check this first, to completely skip the possibly problematic code getting\n        # document catalog items when possible.  Does not print a skipped list, though.\n        if args.verbose:\n            print(\"\\nNot copying any document catalog items to the cropped document.\")\n    else:\n        try:\n            root_object = input_doc.trailer[\"/Root\"]\n\n            copied_items = []\n            skipped_items = []\n            for key, value in root_object.items():\n                # Some possible keys can be:\n                #\n                # /Type -- required, must have value /Catalog\n                # /Pages -- required, indirect ref to page tree; skip, will change\n                # /PageMode -- set to /UseNone, /UseOutlines, /UseThumbs, /Fullscreen,\n                #              /UseOC, or /UseAttachments, with /UseNone default.\n                # /OpenAction -- action to take when document is opened, like zooming\n                # /PageLayout -- set to /SinglePage, /OneColumn, /TwoColumnLeft,\n                #                /TwoColumnRight, /TwoPageLeft, /TwoPageRight\n                # /Names -- a name dictionary to avoid having to use object numbers\n                # /Outlines -- indirect ref to document outline, i.e., bookmarks\n                # /Dests -- a dict of destinations in the PDF\n                # /ViewerPreferences -- a viewer preferences dict\n                # /MetaData -- XMP metadata, as opposed to other metadata\n                # /PageLabels -- alternate numbering for pages, only affect PDF viewers\n                if key == \"/Pages\":\n                    skipped_items.append(key)\n                    continue\n                if doc_cat_whitelist != [\"ALL\"] and key not in doc_cat_whitelist:\n                    if doc_cat_blacklist == [\"ALL\"] or key in doc_cat_blacklist:\n                        skipped_items.append(key)\n                        continue\n                copied_items.append(key)\n                output_doc._root_object[NameObject(key)] = value\n\n            if args.verbose:\n                print(\"\\nCopied these items from the document catalog:\\n   \", end=\"\")\n                print(*copied_items)\n                print(\"Skipped copy of these items from the document catalog:\\n   \", end=\"\")\n                print(*skipped_items)\n\n        except (KeyboardInterrupt, EOFError):\n            raise\n        except: # Just catch any errors here; don't know which might be raised.\n            # On exception just warn and get a new PdfFileWriter object, to be safe.\n            print(\"\\nWarning: The document catalog data could not be copied to the\"\n                  \"\\nnew, cropped document.  Try fixing the PDF document using\"\n                  \"\\n'--gsFix' if you have Ghostscript installed.\", file=sys.stderr)\n            output_doc = PdfFileWriter()\n\n    #output_doc.appendPagesFromReader(input_doc) # Works, but wait and test more.\n    for page in [input_doc.getPage(i) for i in range(input_doc.getNumPages())]:\n        output_doc.addPage(page)\n\n    tmp_output_doc = PdfFileWriter()\n    #tmp_output_doc.appendPagesFromReader(tmp_input_doc)  # Works, but test more.\n    for page in [tmp_input_doc.getPage(i) for i in range(tmp_input_doc.getNumPages())]:\n        tmp_output_doc.addPage(page)\n\n    ##\n    ## Copy the metadata from input_doc to output_doc, modifying the Producer string\n    ## if this program didn't already set it.  Get bool for whether this program\n    ## cropped the document already.\n    ##\n\n    already_cropped_by_this_program = set_cropped_metadata(input_doc, output_doc,\n                                                           metadata_info)\n    return output_doc, tmp_output_doc, already_cropped_by_this_program"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main_crop():\n\n    ##\n    ## Process some of the command-line arguments.\n    ##\n\n    if args.verbose:\n        print(\"\\nProcessing the PDF with pdfCropMargins (version\", __version__+\")...\")\n        print(\"System type:\", ex.system_os)\n\n    if len(args.pdf_input_doc) > 1:\n        print(\"\\nError in pdfCropMargins: Only one input PDF document is allowed.\"\n              \"\\nFound more than one on the command line:\", file=sys.stderr)\n        for f in args.pdf_input_doc:\n            print(\"   \", f, file=sys.stderr)\n        ex.cleanup_and_exit(1)\n\n    input_doc_fname = ex.glob_if_windows_os(args.pdf_input_doc[0], exact_num_args=1)[0]\n    if not input_doc_fname.endswith((\".pdf\",\".PDF\")):\n        print(\"\\nWarning in pdfCropMargins: The file extension is neither '.pdf'\"\n              \"\\nnor '.PDF'; continuing anyway.\\n\", file=sys.stderr)\n    if args.verbose:\n        print(\"\\nThe input document's filename is:\\n   \", input_doc_fname)\n    if not os.path.isfile(input_doc_fname):\n        print(\"\\nError in pdfCropMargins: The specified input file\\n   \"\n              + input_doc_fname + \"\\nis not a file or does not exist.\",\n              file=sys.stderr)\n        ex.cleanup_and_exit(1)\n\n    if not args.outfile:\n        if args.verbose: print(\"\\nUsing the default-generated output filename.\")\n        output_doc_fname = generate_default_filename(input_doc_fname)\n    else:\n        output_doc_fname = ex.glob_if_windows_os(args.outfile[0], exact_num_args=1)[0]\n    if args.verbose:\n        print(\"\\nThe output document's filename will be:\\n   \", output_doc_fname)\n\n    if os.path.lexists(output_doc_fname) and args.noclobber:\n        print(\"\\nOption '--noclobber' is set, refusing to overwrite an existing\"\n              \"\\nfile with filename:\\n   \", output_doc_fname, file=sys.stderr)\n        ex.cleanup_and_exit(1)\n\n    if os.path.lexists(output_doc_fname) and ex.samefile(input_doc_fname,\n                                                                output_doc_fname):\n        print(\"\\nError in pdfCropMargins: The input file is the same as\"\n              \"\\nthe output file.\\n\", file=sys.stderr)\n        ex.cleanup_and_exit(1)\n\n    if args.gsBbox and len(args.fullPageBox) > 1:\n        print(\"\\nWarning: only one --fullPageBox value can be used with the -gs option.\",\n              \"\\nIgnoring all but the first one.\", file=sys.stderr)\n        args.fullPageBox = [args.fullPageBox[0]]\n    elif args.gsBbox and not args.fullPageBox: args.fullPageBox = [\"c\"] # gs default\n    elif not args.fullPageBox: args.fullPageBox = [\"m\", \"c\"] # usual default\n\n    if args.verbose:\n        print(\"\\nFor the full page size, using values from the PDF box\"\n              \"\\nspecified by the intersection of these boxes:\", args.fullPageBox)\n\n    if args.absolutePreCrop: args.absolutePreCrop *= 4 # expand to 4 offsets\n    # See if all four offsets are explicitly set and use those if so.\n    if args.absolutePreCrop4: args.absolutePreCrop = args.absolutePreCrop4\n    if args.verbose:\n        print(\"\\nThe absolute pre-crops to be applied to each margin, in units of bp,\"\n              \" are:\\n   \", args.absolutePreCrop)\n\n    if args.percentRetain: args.percentRetain *= 4 # expand to 4 percents\n    # See if all four percents are explicitly set and use those if so.\n    if args.percentRetain4: args.percentRetain = args.percentRetain4\n    if args.verbose:\n        print(\"\\nThe percentages of margins to retain are:\\n   \",\n              args.percentRetain)\n\n    if args.absoluteOffset: args.absoluteOffset *= 4 # expand to 4 offsets\n    # See if all four offsets are explicitly set and use those if so.\n    if args.absoluteOffset4: args.absoluteOffset = args.absoluteOffset4\n    if args.verbose:\n        print(\"\\nThe absolute offsets to be applied to each margin, in units of bp,\"\n              \" are:\\n   \", args.absoluteOffset)\n\n    # Parse the page ratio into a float if user chose that option.\n    if args.setPageRatios:\n        ratio = args.setPageRatios[0].split(\":\")\n        if len(ratio) > 2:\n            print(\"\\nError in pdfCropMargins: Bad format in aspect ratio command line\"\n                  \" argument.\\nToo many colons.\")\n            ex.cleanup_and_exit(1)\n        try:\n            if len(ratio) == 2:\n                args.setPageRatios[0] = float(ratio[0])/float(ratio[1])\n            else:\n                args.setPageRatios[0] = float(ratio[0])\n        except ValueError:\n            print(\"\\nError in pdfCropMargins: Bad format in aspect ratio command line\"\n                  \" argument.\\nCannot convert to a float.\")\n            ex.cleanup_and_exit(1)\n\n    # Set executable paths to non-default locations if set.\n    if args.pdftoppmPath: ex.set_pdftoppm_executable_to_string(args.pdftoppmPath)\n    if args.ghostscriptPath: ex.set_gs_executable_to_string(args.ghostscriptPath)\n\n    # If the option settings require pdftoppm, make sure we have a running\n    # version.  If '--gsBbox' isn't chosen then assume that PDF pages are to be\n    # explicitly rendered.  In that case we either need pdftoppm or gs to do the\n    # rendering.\n    gs_render_fallback_set = False # Set True if we switch to gs option as a fallback.\n    if not args.gsBbox and not args.gsRender:\n        found_pdftoppm = ex.init_and_test_pdftoppm_executable(\n                                                   prefer_local=args.pdftoppmLocal)\n        if args.verbose:\n            print(\"\\nFound pdftoppm program at:\", found_pdftoppm)\n        if not found_pdftoppm:\n            args.gsRender = True\n            gs_render_fallback_set = True\n            if args.verbose:\n                print(\"\\nNo pdftoppm executable found; using Ghostscript for rendering.\")\n\n    # If any options require Ghostscript, make sure it it installed.\n    if args.gsBbox or args.gsFix or args.gsRender:\n        found_gs = ex.init_and_test_gs_executable()\n        if args.verbose:\n            print(\"\\nFound Ghostscript program at:\", found_gs)\n    if args.gsBbox and not found_gs:\n        print(\"\\nError in pdfCropMargins: The '--gsBbox' option was specified but\"\n              \"\\nthe Ghostscript executable could not be located.  Is it\"\n              \"\\ninstalled and in the PATH for command execution?\\n\", file=sys.stderr)\n        ex.cleanup_and_exit(1)\n    if args.gsFix and not found_gs:\n        print(\"\\nError in pdfCropMargins: The '--gsFix' option was specified but\"\n              \"\\nthe Ghostscript executable could not be located.  Is it\"\n              \"\\ninstalled and in the PATH for command execution?\\n\", file=sys.stderr)\n        ex.cleanup_and_exit(1)\n    if args.gsRender and not found_gs:\n        if gs_render_fallback_set:\n            print(\"\\nError in pdfCropMargins: Neither Ghostscript nor pdftoppm\"\n                  \"\\nwas found in the PATH for command execution.  At least one is\"\n                  \"\\nrequired.\\n\", file=sys.stderr)\n        else:\n            print(\"\\nError in pdfCropMargins: The '--gsRender' option was specified but\"\n                  \"\\nthe Ghostscript executable could not be located.  Is it\"\n                  \"\\ninstalled and in the PATH for command execution?\\n\", file=sys.stderr)\n        ex.cleanup_and_exit(1)\n\n    # Give a warning message if incompatible option combinations have been selected.\n    if args.gsBbox and args.threshold:\n        print(\"\\nWarning in pdfCropMargins: The '--threshold' option is ignored\"\n              \"\\nwhen the '--gsBbox' option is also selected.\\n\", file=sys.stderr)\n    if args.gsBbox and args.numBlurs:\n        print(\"\\nWarning in pdfCropMargins: The '--numBlurs' option is ignored\"\n              \"\\nwhen the '--gsBbox' option is also selected.\\n\", file=sys.stderr)\n    if args.gsBbox and args.numSmooths:\n        print(\"\\nWarning in pdfCropMargins: The '--numSmooths' option is ignored\"\n              \"\\nwhen the '--gsBbox' option is also selected.\\n\", file=sys.stderr)\n\n    ##\n    ## Open the input document in a PdfFileReader object.  Due to an apparent bug\n    ## in pyPdf we open two PdfFileReader objects for the file.  The time required should\n    ## still be small relative to finding the bounding boxes of pages.  The bug is\n    ## that writing a PdfFileWriter tends to hang on certain files if 1) pages from\n    ## the same PdfFileReader are shared between two PdfFileWriter objects, or 2)\n    ## the PdfFileWriter is written, the pages are modified, and there is an attempt\n    ## to write the same PdfFileWriter to a different file.\n    ##\n\n    if args.gsFix:\n        if args.verbose:\n            print(\"\\nAttempting to fix the PDF input file before reading it...\")\n        fixed_input_doc_fname = ex.fix_pdf_with_ghostscript_to_tmp_file(input_doc_fname)\n    else:\n        fixed_input_doc_fname = input_doc_fname\n\n    # Open the input file object.\n    # TODO: Need try except since might fail for permissions.\n    fixed_input_doc_file_object = open(fixed_input_doc_fname, \"rb\")\n\n    try:\n        input_doc = PdfFileReader(fixed_input_doc_file_object)\n        tmp_input_doc = PdfFileReader(fixed_input_doc_file_object)\n    except (KeyboardInterrupt, EOFError):\n        raise\n    except: # Can raise various exceptions, just catch the rest here.\n        print(\"\\nError in pdfCropMargins: The pyPdf module failed in an attempt\"\n              \"\\nto read the input file.  Is the file a PDF file?  If so then it\"\n              \"\\nmay be corrupted.  If you have Ghostscript, try the '--gsFix'\"\n              \"\\noption (assuming you are not using it already).  That option can\"\n              \"\\nalso convert some PostScript files to a readable format.\",\n              file=sys.stderr)\n        ex.cleanup_and_exit(1)\n\n    ##\n    ## See if the document needs to be decrypted.\n    ##\n\n    if args.password:\n        try:\n            input_doc.decrypt(args.password)\n            tmp_input_doc.decrypt(args.password)\n        except KeyError:\n            print(\"\\nDecrypting with the password from the '--password' option\"\n                  \"\\nfailed.\", file=sys.stderr)\n            ex.cleanup_and_exit(1)\n    else: # try decrypting with an empty password\n        try:\n            input_doc.decrypt(\"\")\n            tmp_input_doc.decrypt(\"\")\n        except KeyError:\n            pass # document apparently wasn't encrypted with an empty password\n\n    ##\n    ## Print out some data and metadata in verbose mode.\n    ##\n\n    if args.verbose:\n        print(\"\\nThe input document has %s pages.\" % input_doc.getNumPages())\n\n    try: # This is needed because the call sometimes just raises an error.\n        metadata_info = input_doc.getDocumentInfo()\n    except:\n        print(\"\\nWarning: Document metadata could not be read.\", file=sys.stderr)\n        metadata_info = None\n\n    if args.verbose and not metadata_info:\n        print(\"\\nNo readable metadata in the document.\")\n    elif args.verbose:\n        try:\n            print(\"\\nThe document's metadata, if set:\\n\")\n            print(\"   The Author attribute set in the input document is:\\n      %s\"\n                  % (metadata_info.author))\n            print(\"   The Creator attribute set in the input document is:\\n      %s\"\n                  % (metadata_info.creator))\n            print(\"   The Producer attribute set in the input document is:\\n      %s\"\n                  % (metadata_info.producer))\n            print(\"   The Subject attribute set in the input document is:\\n      %s\"\n                  % (metadata_info.subject))\n            print(\"   The Title attribute set in the input document is:\\n      %s\"\n                  % (metadata_info.title))\n        # Some metadata cannot be decoded or encoded, at least on Windows.  Could\n        # print from a function instead to write all the lines which can be written.\n        except (UnicodeDecodeError, UnicodeEncodeError):\n            print(\"\\nWarning: Could not write all the document's metadata to the screen.\"\n                  \"\\nGot a UnicodeEncodeError or a UnicodeDecodeError.\")\n\n    ##\n    ## Now compute the set containing the pyPdf page number of all the pages\n    ## which the user has selected for cropping from the command line.  Most\n    ## calculations are still carried-out for all the pages in the document.\n    ## (There are a few optimizations for expensive operations like finding\n    ## bounding boxes; the rest is negligible).  This keeps the correspondence\n    ## between page numbers and the positions of boxes in the box lists.  The\n    ## function apply_crop_list then just ignores the cropping information for any\n    ## pages which were not selected.\n    ##\n\n    all_page_nums = set(range(0, input_doc.getNumPages()))\n    page_nums_to_crop = set() # Note that this set holds page num MINUS ONE, start at 0.\n    if args.pages:\n        # Parse any page range specifier argument.\n        for page_num_or_range in args.pages.split(\",\"):\n            split_range = page_num_or_range.split(\"-\")\n            try:\n                if len(split_range) == 1:\n                    # Note pyPdf page nums start at 0, not 1 like usual PDF pages,\n                    # subtract 1.\n                    page_nums_to_crop.add(int(split_range[0])-1)\n                else:\n                    page_nums_to_crop.update(\n                        set(range(int(split_range[0])-1, int(split_range[1]))))\n            except ValueError:\n                print(\n                    \"\\nError in pdfCropMargins: The page range specified on the command\",\n                    \"\\nline contains a non-integer value or otherwise cannot be parsed.\",\n                    file=sys.stderr)\n                ex.cleanup_and_exit(1)\n        page_nums_to_crop = page_nums_to_crop & all_page_nums # intersect chosen with actual\n    else:\n        page_nums_to_crop = all_page_nums\n\n    # Print out the pages to crop in verbose mode.\n    if args.verbose and args.pages:\n        print(\"\\nThese pages of the document will be cropped:\", end=\"\")\n        p_num_list = sorted(list(page_nums_to_crop))\n        num_pages_to_crop = len(p_num_list)\n        for i in range(num_pages_to_crop):\n            if i % 10 == 0 and i != num_pages_to_crop - 1:\n                print(\"\\n   \", end=\"\")\n            print(\"%5d\" % (p_num_list[i]+1), \" \", end=\"\")\n        print()\n    elif args.verbose:\n        print(\"\\nAll the pages of the document will be cropped.\")\n\n    ##\n    ## Get a list with the full-page boxes for each page: (left,bottom,right,top)\n    ## This function also sets the MediaBox and CropBox of the pages to the\n    ## chosen full-page size as a side-effect, saving the old boxes.\n    ##\n\n    full_page_box_list, rotation_list = get_full_page_box_list_assigning_media_and_crop(\n                                                                              input_doc)\n    tmp_full_page_box_list, tmp_rotation_list = get_full_page_box_list_assigning_media_and_crop(\n                                                            tmp_input_doc, quiet=True)\n\n    ##\n    ## Define a PdfFileWriter object and copy input_doc info over to it.\n    ##\n\n    output_doc, tmp_output_doc, already_cropped_by_this_program = setup_output_document(\n                                                   input_doc, tmp_input_doc, metadata_info)\n\n    ##\n    ## Write out the PDF document again, with the CropBox and MediaBox reset.\n    ## This temp version is only used for calculating the bounding boxes of\n    ## pages.  Note we are writing from tmp_output_doc (due to an apparent bug\n    ## discussed above).  After this tmp_input_doc and tmp_output_doc are no longer\n    ## needed.\n    ##\n\n    if not args.restore:\n        doc_with_crop_and_media_boxes_name = ex.get_temporary_filename(\".pdf\")\n        doc_with_crop_and_media_boxes_object = open(\n                                     doc_with_crop_and_media_boxes_name, \"wb\")\n\n        if args.verbose:\n            print(\"\\nWriting out the PDF with the CropBox and MediaBox redefined.\")\n\n        try:\n            tmp_output_doc.write(doc_with_crop_and_media_boxes_object)\n        except (KeyboardInterrupt, EOFError):\n            raise\n        except: # PyPDF2 can raise various exceptions.\n            print(\"\\nError in pdfCropMargins: The pyPdf program failed in trying to\"\n                  \"\\nwrite out a PDF file of the document.  The document may be\"\n                  \"\\ncorrupted.  If you have Ghostscript, try using the '--gsFix'\"\n                  \"\\noption (assuming you are not already using it).\", file=sys.stderr)\n            ex.cleanup_and_exit(1)\n\n        doc_with_crop_and_media_boxes_object.close()\n\n    ##\n    ## Calculate the bounding_box_list containing tight page bounds for each page.\n    ##\n\n    if not args.restore:\n        bounding_box_list = get_bounding_box_list(doc_with_crop_and_media_boxes_name,\n                input_doc, full_page_box_list, page_nums_to_crop, args, PdfFileWriter)\n        if args.verbose:\n            print(\"\\nThe bounding boxes are:\")\n            for pNum, b in enumerate(bounding_box_list):\n                print(\"\\t\", pNum+1, \"\\t\", b)\n\n    ##\n    ## Calculate the crop_list based on the fullpage boxes and the bounding boxes.\n    ##\n\n    if not args.restore:\n        crop_list = calculate_crop_list(full_page_box_list, bounding_box_list,\n                                     rotation_list, page_nums_to_crop)\n    else:\n        crop_list = None # Restore, not needed in this case.\n\n    ##\n    ## Apply the calculated crops to the pages of the PdfFileReader input_doc.\n    ## These pages are copied to the PdfFileWriter output_doc.\n    ##\n\n    apply_crop_list(crop_list, input_doc, page_nums_to_crop,\n                                          already_cropped_by_this_program)\n\n    ##\n    ## Write the final PDF out to a file.\n    ##\n\n    if args.verbose: print(\"\\nWriting the cropped PDF file.\")\n\n    # TODO: Try and except on the open, since it might fail for permissions.\n    output_doc_stream = open(output_doc_fname, \"wb\")\n\n    try:\n        output_doc.write(output_doc_stream)\n    except (KeyboardInterrupt, EOFError):\n        raise\n    except: # PyPDF2 can raise various exceptions.\n        try:\n            # We know the write succeeded on tmp_output_doc or we wouldn't be here.\n            # Malformed document catalog info can cause write failures, so get\n            # a new output_doc without that data and try the write again.\n            print(\"\\nWrite failure, trying one more time...\", file=sys.stderr)\n            output_doc_stream.close()\n            output_doc_stream = open(output_doc_fname, \"wb\")\n            output_doc, tmp_output_doc, already_cropped = setup_output_document(\n                    input_doc, tmp_input_doc, metadata_info, copy_document_catalog=False)\n            output_doc.write(output_doc_stream)\n            print(\"\\nWarning: Document catalog data caused a write failure.  A retry\"\n                  \"\\nwithout that data succeeded.  No document catalog information was\"\n                  \"\\ncopied to the cropped output file.  Try fixing the PDF file.  If\"\n                  \"\\nyou have ghostscript installed, run pdfCropMargins with the '--gsFix'\"\n                  \"\\noption.  You can also try blacklisting some of the document catalog\"\n                  \"\\nitems using the '--dcb' option.\", file=sys.stderr)\n        except (KeyboardInterrupt, EOFError):\n            raise\n        except: # Give up... PyPDF2 can raise many errors for many reasons.\n            print(\"\\nError in pdfCropMargins: The pyPdf program failed in trying to\"\n                  \"\\nwrite out a PDF file of the document.  The document may be\"\n                  \"\\ncorrupted.  If you have Ghostscript, try using the '--gsFix'\"\n                  \"\\noption (assuming you are not already using it).\", file=sys.stderr)\n            ex.cleanup_and_exit(1)\n\n    output_doc_stream.close()\n\n    # We're finished with this open file; close it and let temp dir removal delete it.\n    fixed_input_doc_file_object.close()\n\n    ##\n    ## Now handle the options which apply after the file is written.\n    ##\n\n    def do_preview(output_doc_fname):\n        viewer = args.preview\n        if args.verbose:\n            print(\"\\nPreviewing the output document with viewer:\\n   \", viewer)\n        ex.show_preview(viewer, output_doc_fname)\n        return\n\n    # Handle the '--queryModifyOriginal' option.\n    if args.queryModifyOriginal:\n        if args.preview:\n            print(\"\\nRunning the preview viewer on the file, will query whether or not\"\n                  \"\\nto modify the original file after the viewer is launched in the\"\n                  \"\\nbackground...\\n\")\n            do_preview(output_doc_fname)\n            # Give preview time to start; it may write startup garbage to the terminal...\n            query_wait_time = 2 # seconds\n            time.sleep(query_wait_time)\n            print()\n        while True:\n            query_string = \"\\nModify the original file to the cropped file \" \\\n                \"(saving the original)? [yn] \"\n            if ex.python_version[0] == \"2\":\n                query_result = raw_input(query_string).decode(\"utf-8\")\n            else:\n                query_result = input(query_string)\n            if query_result in [\"y\", \"Y\"]:\n                args.modifyOriginal = True\n                print(\"\\nModifying the original file.\")\n                break\n            elif query_result in [\"n\", \"N\"]:\n                print(\"\\nNot modifying the original file.  The cropped file is saved\"\n                      \" as:\\n   {0}\".format(output_doc_fname))\n                args.modifyOriginal = False\n                break\n            else:\n                print(\"Response must be in the set {y,Y,n,N}, none recognized.\")\n                continue\n\n    # Handle the '--modifyOriginal' option.\n    if args.modifyOriginal:\n        generated_uncropped_filename = generate_default_filename(\n                                                  input_doc_fname, is_cropped_file=False)\n\n        # Remove any existing file with the name generated_uncropped_filename unless a\n        # relevant noclobber option is set or it isn't a file.\n        if os.path.exists(generated_uncropped_filename):\n            if (os.path.isfile(generated_uncropped_filename)\n                    and not args.noclobberOriginal and not args.noclobber):\n                if args.verbose:\n                    print(\"\\nRemoving the file\\n   \", generated_uncropped_filename)\n                try:\n                    os.remove(generated_uncropped_filename)\n                except OSError:\n                    print(\"Removing the file {} failed.  Maybe a permission error?\"\n                          \"\\nFiles are as if option '--modifyOriginal' were not set.\"\n                          .format(generated_uncropped_filename))\n                    args.modifyOriginal = False # Failed.\n            else:\n                print(\"\\nA noclobber option is set or else not a file; refusing to\"\n                    \" overwrite:\\n   \", generated_uncropped_filename,\n                    \"\\nFiles are as if option '--modifyOriginal' were not set.\",\n                    file=sys.stderr)\n                args.modifyOriginal = False # Failed.\n\n        # Move the original file to the name for uncropped files.  Silently do nothing\n        # if the file exists (should have been removed above).\n        if not os.path.exists(generated_uncropped_filename):\n            if args.verbose: print(\"\\nDoing a file move:\\n   \", input_doc_fname,\n                                   \"\\nis moving to:\\n   \", generated_uncropped_filename)\n            shutil.move(input_doc_fname, generated_uncropped_filename)\n\n        # Move the cropped file to the original file's name.  Silently do nothing if\n        # the file exists (should have been moved above).\n        if not os.path.exists(input_doc_fname):\n            if args.verbose: print(\"\\nDoing a file move:\\n   \", output_doc_fname,\n                                   \"\\nis moving to:\\n   \", input_doc_fname)\n            shutil.move(output_doc_fname, input_doc_fname)\n\n    # Handle any previewing which still needs to be done.\n    if args.preview and not args.queryModifyOriginal: # already previewed in query mod\n        if args.modifyOriginal: # already swapped to original filename in this case\n            do_preview(input_doc_fname)\n        else: # the usual case, preview the output filename\n            do_preview(output_doc_fname)\n\n    if args.verbose: print(\"\\nFinished this run of pdfCropMargins.\\n\")", "response": "This function is called by main function in order to crop the PDF."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, s):\n        pretty_str = s\n        for pair in self.help_string_replacement_pairs:\n            pretty_str = pretty_str.replace(pair[0], pair[1])\n        # Define ^^s as the bell control char for now, so fill will treat it right.\n        pretty_str = pretty_str.replace(\"^^s\", \"\\a\")\n\n        def do_fill(match_obj):\n            \"\"\"Fill function for regexp to apply to ^^f matches.\"\"\"\n            st = pretty_str[match_obj.start()+3:match_obj.end()-3] # get substring\n            st = re.sub(\"\\n\\s*\\n\", \"^^p\", st).split(\"^^p\") # multi-new to para\n            st = [\" \".join(s.split()) for s in st] # multi-whites to single\n            wrapper = textwrap.TextWrapper( # indent formatted paras\n                initial_indent=\" \"*self.init_indent,\n                subsequent_indent=\" \"*self.subs_indent,\n                width=self.line_width)\n            return \"\\n\\n\".join([wrapper.fill(s) for s in st]) # wrap each para\n\n        # Do the fill on all the fill sections.\n        pretty_str = re.sub(r\"\\^\\^f.*?\\^\\^f\", do_fill, pretty_str, flags=re.DOTALL)\n        pretty_str = pretty_str.replace(\"\\a\", \" \") # bell character back to space\n        pretty_str = pretty_str.replace(\"^^n\", \"\\n\") # replace ^^n with newline\n        self.outstream.write(pretty_str)\n        self.outstream.flush()", "response": "Write the string s to the output stream associated with the available base class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the static folder of the given Flask app instance or module / blueprint.", "response": "def get_static_folder(app_or_blueprint):\n    \"\"\"Return the static folder of the given Flask app\n    instance, or module/blueprint.\n\n    In newer Flask versions this can be customized, in older\n    ones (<=0.6) the folder is fixed.\n    \"\"\"\n    if not hasattr(app_or_blueprint, 'static_folder'):\n        # I believe this is for app objects in very old Flask\n        # versions that did not support custom static folders.\n        return path.join(app_or_blueprint.root_path, 'static')\n\n    if not app_or_blueprint.has_static_folder:\n        # Use an exception type here that is not hidden by spit_prefix.\n        raise TypeError(('The referenced blueprint %s has no static '\n                         'folder.') % app_or_blueprint)\n    return app_or_blueprint.static_folder"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setdefault(self, key, value):\n        try:\n            super(FlaskConfigStorage, self).setdefault(key, value)\n        except RuntimeError:\n            self._defaults.__setitem__(key, value)", "response": "Set the value of a key to a value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef split_prefix(self, ctx, item):\n        app = ctx._app\n        try:\n            if hasattr(app, 'blueprints'):\n                blueprint, name = item.split('/', 1)\n                directory = get_static_folder(app.blueprints[blueprint])\n                endpoint = '%s.static' % blueprint\n                item = name\n            else:\n                # Module support for Flask < 0.7\n                module, name = item.split('/', 1)\n                directory = get_static_folder(app.modules[module])\n                endpoint = '%s.static' % module\n                item = name\n        except (ValueError, KeyError):\n            directory = get_static_folder(app)\n            endpoint = 'static'\n\n        return directory, item, endpoint", "response": "Split the prefix of the item into a directory item and endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_item_to_flask_url(self, ctx, item, filepath=None):\n        if ctx.environment._app.config.get(\"FLASK_ASSETS_USE_S3\"):\n            try:\n                from flask_s3 import url_for\n            except ImportError as e:\n                print(\"You must have Flask S3 to use FLASK_ASSETS_USE_S3 option\")\n                raise e\n        elif ctx.environment._app.config.get(\"FLASK_ASSETS_USE_CDN\"):\n            try:\n                from flask_cdn import url_for\n            except ImportError as e:\n                print(\"You must have Flask CDN to use FLASK_ASSETS_USE_CDN option\")\n                raise e\n        elif ctx.environment._app.config.get(\"FLASK_ASSETS_USE_AZURE\"):\n            try:\n                from flask_azure_storage import url_for\n            except ImportError as e:\n                print(\"You must have Flask Azure Storage to use FLASK_ASSETS_USE_AZURE option\")\n                raise e\n        else:\n            from flask import url_for\n\n        directory, rel_path, endpoint = self.split_prefix(ctx, item)\n\n        if filepath is not None:\n            filename = filepath[len(directory)+1:]\n        else:\n            filename = rel_path\n\n        flask_ctx = None\n        if not _request_ctx_stack.top:\n            flask_ctx = ctx.environment._app.test_request_context()\n            flask_ctx.push()\n        try:\n            url = url_for(endpoint, filename=filename)\n            # In some cases, url will be an absolute url with a scheme and hostname.\n            # (for example, when using werkzeug's host matching).\n            # In general, url_for() will return a http url. During assets build, we\n            # we don't know yet if the assets will be served over http, https or both.\n            # Let's use // instead. url_for takes a _scheme argument, but only together\n            # with external=True, which we do not want to force every time. Further,\n            # this _scheme argument is not able to render // - it always forces a colon.\n            if url and url.startswith('http:'):\n                url = url[5:]\n            return url\n        finally:\n            if flask_ctx:\n                flask_ctx.pop()", "response": "Converts a relative path to a Flask static url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_yaml(self, path):\n        bundles = YAMLLoader(path).load_bundles()\n        for name in bundles:\n            self.register(name, bundles[name])", "response": "Register bundles from a YAML configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_module(self, path):\n        bundles = PythonLoader(path).load_bundles()\n        for name in bundles:\n            self.register(name, bundles[name])", "response": "Register bundles from a Python module"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_unhandled_exception(exc_type, exc_value, exc_traceback):\n    if issubclass(exc_type, KeyboardInterrupt):\n        # call the default excepthook saved at __excepthook__\n        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n        return\n    logger = logging.getLogger(__name__) # type: ignore\n    logger.critical(\"Unhandled exception\", exc_info=(exc_type, exc_value, exc_traceback))", "response": "Handler for unhandled exceptions that will write to the logs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the transcriptions of the utterances to the target directory.", "response": "def write_transcriptions(utterances: List[Utterance],\n                         tgt_dir: Path, ext: str, lazy: bool) -> None:\n    \"\"\" Write the utterance transcriptions to files in the tgt_dir. Is lazy and\n    checks if the file already exists.\n\n    Args:\n        utterances: A list of Utterance objects to be written.\n        tgt_dir: The directory in which to write the text of the utterances,\n            one file per utterance.\n        ext: The file extension for the utterances. Typically something like\n            \"phonemes\", or \"phonemes_and_tones\".\n\n    \"\"\"\n\n    tgt_dir.mkdir(parents=True, exist_ok=True)\n    for utter in utterances:\n        out_path = tgt_dir / \"{}.{}\".format(utter.prefix, ext)\n        if lazy and out_path.is_file():\n            continue\n        with out_path.open(\"w\") as f:\n            print(utter.text, file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_duplicates(utterances: List[Utterance]) -> List[Utterance]:\n\n    filtered_utters = []\n    utter_set = set() # type: Set[Tuple[int, int, str]]\n    for utter in utterances:\n        if (utter.start_time, utter.end_time, utter.text) in utter_set:\n            continue\n        filtered_utters.append(utter)\n        utter_set.add((utter.start_time, utter.end_time, utter.text))\n\n    return filtered_utters", "response": "Removes utterances with the same start_time end_time and text. Other\n    metadata isn t considered."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_empty_text(utterances: List[Utterance]) -> List[Utterance]:\n    return [utter for utter in utterances if utter.text.strip() != \"\"]", "response": "Removes empty text from a list of utterances"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the total duration of a list of utterances in milliseconds", "response": "def total_duration(utterances: List[Utterance]) -> int:\n\n    \"\"\"Get the duration of an entire list of utterances in milliseconds\n    Args:\n        utterances: The list of utterance we are finding the duration of\n    \"\"\"\n    return sum([duration(utter) for utter in utterances])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a dictionary mapping from speakers to their utterances.", "response": "def make_speaker_utters(utterances: List[Utterance]) -> Dict[str, List[Utterance]]:\n    \"\"\" Creates a dictionary mapping from speakers to their utterances. \"\"\"\n\n    speaker_utters = defaultdict(list) # type: DefaultDict[str, List[Utterance]]\n    for utter in utterances:\n        speaker_utters[utter.speaker].append(utter)\n\n    return speaker_utters"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a list of utterances and itemizes them by speaker and returns a list of tuples of the form Speaker Name duration.", "response": "def speaker_durations(utterances: List[Utterance]) -> List[Tuple[str, int]]:\n    \"\"\" Takes a list of utterances and itemizes them by speaker, returning a\n    list of tuples of the form (Speaker Name, duration).\n    \"\"\"\n\n    speaker_utters = make_speaker_utters(utterances)\n\n    speaker_duration_tuples = [] # type: List[Tuple[str, int]]\n    for speaker in speaker_utters:\n        speaker_duration_tuples.append((speaker, total_duration(speaker_utters[speaker])))\n\n    return speaker_duration_tuples"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves utterances that are too short in the .", "response": "def remove_too_short(utterances: List[Utterance],\n                     _winlen=25, winstep=10) -> List[Utterance]:\n    \"\"\" Removes utterances that will probably have issues with CTC because of\n    the number of frames being less than the number of tokens in the\n    transcription. Assuming char tokenization to minimize false negatives.\n    \"\"\"\n    def is_too_short(utterance: Utterance) -> bool:\n        charlen = len(utterance.text)\n        if (duration(utterance) / winstep) < charlen:\n            return True\n        else:\n            return False\n\n    return [utter for utter in utterances if not is_too_short(utter)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the minimum edit distance between two sequences.", "response": "def min_edit_distance(\n        source: Sequence[T], target: Sequence[T],\n        ins_cost: Callable[..., int] = lambda _x: 1,\n        del_cost: Callable[..., int] = lambda _x: 1,\n        sub_cost: Callable[..., int] = lambda x, y: 0 if x == y else 1) -> int:\n    \"\"\"Calculates the minimum edit distance between two sequences.\n\n    Uses the Levenshtein weighting as a default, but offers keyword arguments\n    to supply functions to measure the costs for editing with different\n    elements.\n\n    Args:\n        ins_cost: A function describing the cost of inserting a given char\n        del_cost: A function describing the cost of deleting a given char\n        sub_cost: A function describing the cost of substituting one char for\n\n    Returns:\n        The edit distance between the two input sequences.\n\n    \"\"\"\n\n    # Initialize an m+1 by n+1 array. Note that the strings start from index 1,\n    # with index 0 being used to denote the empty string.\n    n = len(target)\n    m = len(source)\n    distance = np.zeros((m+1, n+1), dtype=np.int16)\n\n    # Initialize the zeroth row and column to be the distance from the empty\n    # string.\n    for i in range(1, m+1):\n        distance[i, 0] = distance[i-1, 0] + ins_cost(source[i-1])\n    for j in range(1, n+1):\n        distance[0, j] = distance[0, j-1] + ins_cost(target[j-1])\n\n    # Do the dynamic programming to fill in the matrix with the edit distances.\n    for j in range(1, n+1):\n        for i in range(1, m+1):\n            distance[i, j] = min(\n                    distance[i-1, j] + ins_cost(source[i-1]),\n                    distance[i-1, j-1] + sub_cost(source[i-1],target[j-1]),\n                    distance[i, j-1] + del_cost(target[j-1]))\n\n    return int(distance[len(source), len(target)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a minimum edit distance alignment between two strings.", "response": "def min_edit_distance_align(\n        # TODO Wrangle the typing errors in this function.\n        # TODO This could work on generic sequences but for now it relies on\n        # empty strings.\n        #source: Sequence[str], target: Sequence[str],\n        #ins_cost: Callable[..., int] = lambda _x: 1,\n        #del_cost: Callable[..., int] = lambda _x: 1,\n        #sub_cost: Callable[..., int] = lambda x, y: 0 if x == y else 1\n        #) -> List[Tuple[str, str]]:\n        source, target,\n        ins_cost = lambda _x: 1,\n        del_cost = lambda _x: 1,\n        sub_cost = lambda x, y: 0 if x == y else 1):\n    \"\"\"Finds a minimum cost alignment between two strings.\n\n    Uses the Levenshtein weighting as a default, but offers keyword arguments\n    to supply functions to measure the costs for editing with different\n    characters. Note that the alignment may not be unique.\n\n    Args:\n        ins_cost: A function describing the cost of inserting a given char\n        del_cost: A function describing the cost of deleting a given char\n        sub_cost: A function describing the cost of substituting one char for\n\n    Returns:\n        A sequence of tuples representing character level alignments between\n        the source and target strings.\n    \"\"\"\n\n    # Initialize an m+1 by n+1 array to hold the distances, and an equal sized\n    # array to store the backpointers. Note that the strings start from index\n    # 1, with index 0 being used to denote the empty string.\n    n = len(target)\n    m = len(source)\n    dist = [[0]*(n+1) for _ in range(m+1)]\n    bptrs = [[[]]*(n+1) for _ in range(m+1)] # type: List[List[List]]\n\n    # Adjust the initialization of the first column and row of the matrices to\n    # their appropriate values.\n    for i in range(1, m+1):\n        dist[i][0] = i\n        bptrs[i][0] = (i-1, 0)\n    for j in range(1, n+1):\n        dist[0][j] = j\n        bptrs[0][j] = (0, j-1)\n\n    # Do the dynamic programming to fill in the matrix with the edit distances.\n    for j in range(1, n+1):\n        for i in range(1, m+1):\n            options = [\n                    (dist[i-1][j] + ins_cost(target[j-1]),\n                        (i-1, j)),\n                    (dist[i-1][j-1] + sub_cost(source[i-1],target[j-1]),\n                        (i-1, j-1)),\n                    (dist[i][j-1] + del_cost(source[i-1]),\n                        (i, j-1))]\n            (minimum, pointer) = sorted(options)[0]\n            dist[i][j] = minimum\n            bptrs[i][j] = pointer\n\n    # Put the backtrace in a list, and reverse it to get a forward trace.\n    bt = [(m,n)]\n    cell = bptrs[m][n]\n    while True:\n        if not cell:\n            # If it's an empty list or tuple, as will be the case at the start\n            # of the trace\n            break\n        bt.append(cell)\n        if bptrs[cell[0]][cell[1]]:\n            cell = bptrs[cell[0]][cell[1]]\n        else:\n            break\n    trace = list(reversed(bt))\n\n    # Construct an alignment between source and target using the trace.\n    alignment = []\n    for i in range(1, len(trace)):\n        current = trace[i]\n        prev = trace[i-1]\n\n        # If the cell is diagonal from the previous one, it's a substitution or\n        # there wasn't a change.\n        if current[0] - prev[0] == 1 and current[1] - prev[1] == 1:\n            alignment.append((source[current[0]-1], target[current[1]-1]))\n        # Otherwise if it moves only on the source side, it's a deletion\n        elif current[0] - prev[0] == 1:\n            alignment.append((source[current[0]-1], \"\"))\n        # Otherwise if it moves only on the target side, it's an insertion\n        elif current[1] - prev[1] == 1:\n            alignment.append((\"\", target[current[1]-1]))\n\n    return alignment"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cluster_alignment_errors(alignment):\n    # TODO Review documentation and consider for inclusion in API.\n    \"\"\"Clusters alignments\n    Takes an alignment created by min_edit_distance_align() and groups\n    consecutive errors together. This is useful, because there are often\n    many possible alignments, and so often we can't meaningfully distinguish\n    between alignment errors at the character level, so it makes many-to-many\n    mistakes more readable.\"\"\"\n\n    newalign = []\n    mistakes = ([],[])\n    for align_item in alignment:\n        if align_item[0] == align_item[1]:\n            if mistakes != ([],[]):\n                newalign.append((tuple(mistakes[0]), tuple(mistakes[1])))\n                mistakes = ([],[])\n            newalign.append((tuple([align_item[0]]), tuple([align_item[1]])))\n        else:\n            if align_item[0] != \"\":\n                mistakes[0].append(align_item[0])\n            if align_item[1] != \"\":\n                mistakes[1].append(align_item[1])\n    if mistakes != ([],[]):\n        newalign.append((tuple(mistakes[0]), tuple(mistakes[1])))\n        mistakes = ([],[])\n\n    return newalign", "response": "Cluster alignment errors into one or more cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the word error rate of a sequence against a gold - standard reference sequence.", "response": "def word_error_rate(ref: Sequence[T], hyp: Sequence[T]) -> float:\n    \"\"\" Calculate the word error rate of a sequence against a reference.\n\n    Args:\n        ref: The gold-standard reference sequence\n        hyp: The hypothesis to be evaluated against the reference.\n\n    Returns:\n        The word error rate of the supplied hypothesis with respect to the\n        reference string.\n\n    Raises:\n        persephone.exceptions.EmptyReferenceException: If the length of the reference sequence is 0.\n\n    \"\"\"\n\n    if len(ref) == 0:\n        raise EmptyReferenceException(\n            \"Cannot calculating word error rate against a length 0 \"\\\n            \"reference sequence.\")\n\n    distance = min_edit_distance(ref, hyp)\n    return 100 * float(distance) / len(ref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_metagraph(model_path_prefix: Union[str, Path]) -> tf.train.Saver:\n\n    model_path_prefix = str(model_path_prefix)\n    metagraph = tf.train.import_meta_graph(model_path_prefix + \".meta\")\n    return metagraph", "response": "Loads the meta graph from disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dense_to_human_readable(dense_repr: Sequence[Sequence[int]], index_to_label: Dict[int, str]) -> List[List[str]]:\n\n    transcripts = []\n    for dense_r in dense_repr:\n        non_empty_phonemes = [phn_i for phn_i in dense_r if phn_i != 0]\n        transcript = [index_to_label[index] for index in non_empty_phonemes]\n        transcripts.append(transcript)\n\n    return transcripts", "response": "Converts a dense representation of model decoded output into human readable transcripts using a mapping from indices to labels."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(model_path_prefix: Union[str, Path],\n           input_paths: Sequence[Path],\n           label_set: Set[str],\n           *,\n           feature_type: str = \"fbank\", #TODO Make this None and infer feature_type from dimension of NN input layer.\n           batch_size: int = 64,\n           feat_dir: Optional[Path]=None,\n           batch_x_name: str=\"batch_x:0\",\n           batch_x_lens_name: str=\"batch_x_lens:0\",\n           output_name: str=\"hyp_dense_decoded:0\") -> List[List[str]]:\n    \"\"\"Use an existing tensorflow model that exists on disk to decode\n    WAV files.\n\n    Args:\n        model_path_prefix: The path to the saved tensorflow model.\n                           This is the full prefix to the \".ckpt\" file.\n        input_paths: A sequence of `pathlib.Path`s to WAV files to put through\n                     the model provided.\n        label_set: The set of all the labels this model uses.\n        feature_type: The type of features this model uses.\n                      Note that this MUST match the type of features that the\n                      model was trained on initially.\n        feat_dir: Any files that require preprocessing will be\n                                  saved to the path specified by this.\n        batch_x_name: The name of the tensorflow input for batch_x\n        batch_x_lens_name: The name of the tensorflow input for batch_x_lens\n        output_name: The name of the tensorflow output\n    \"\"\"\n\n    if not input_paths:\n        raise PersephoneException(\"No untranscribed WAVs to transcribe.\")\n\n    model_path_prefix = str(model_path_prefix)\n\n    for p in input_paths:\n        if not p.exists():\n            raise PersephoneException(\n                \"The WAV file path {} does not exist\".format(p)\n            )\n\n    preprocessed_file_paths = []\n    for p in input_paths:\n        prefix = p.stem\n        # Check the \"feat\" directory as per the filesystem conventions of a Corpus\n        feature_file_ext = \".{}.npy\".format(feature_type)\n        conventional_npy_location =  p.parent.parent / \"feat\" / (Path(prefix + feature_file_ext))\n        if conventional_npy_location.exists():\n            # don't need to preprocess it\n            preprocessed_file_paths.append(conventional_npy_location)\n        else:\n            if not feat_dir:\n                feat_dir = p.parent.parent / \"feat\"\n            if not feat_dir.is_dir():\n                os.makedirs(str(feat_dir))\n\n            mono16k_wav_path = feat_dir / \"{}.wav\".format(prefix)\n            feat_path = feat_dir / \"{}.{}.npy\".format(prefix, feature_type)\n            feat_extract.convert_wav(p, mono16k_wav_path)\n            preprocessed_file_paths.append(feat_path)\n    # preprocess the file that weren't found in the features directory\n    # as per the filesystem conventions\n    if feat_dir:\n        feat_extract.from_dir(feat_dir, feature_type)\n\n    fn_batches = utils.make_batches(preprocessed_file_paths, batch_size)\n    # Load the model and perform decoding.\n    metagraph = load_metagraph(model_path_prefix)\n    with tf.Session() as sess:\n        metagraph.restore(sess, model_path_prefix)\n\n        for fn_batch in fn_batches:\n            batch_x, batch_x_lens = utils.load_batch_x(fn_batch)\n\n        # TODO These placeholder names should be a backup if names from a newer\n        # naming scheme aren't present. Otherwise this won't generalize to\n        # different architectures.\n        feed_dict = {batch_x_name: batch_x,\n                     batch_x_lens_name: batch_x_lens}\n\n        dense_decoded = sess.run(output_name, feed_dict=feed_dict)\n\n    # Create a human-readable representation of the decoded.\n    indices_to_labels = labels.make_indices_to_labels(label_set)\n    human_readable = dense_to_human_readable(dense_decoded, indices_to_labels)\n\n    return human_readable", "response": "This function decodes the WAV files into a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranscribe an untranscribed dataset.", "response": "def transcribe(self, restore_model_path: Optional[str]=None) -> None:\n        \"\"\" Transcribes an untranscribed dataset. Similar to eval() except\n        no reference translation is assumed, thus no LER is calculated.\n        \"\"\"\n\n        saver = tf.train.Saver()\n        with tf.Session(config=allow_growth_config) as sess:\n            if restore_model_path:\n                saver.restore(sess, restore_model_path)\n            else:\n                if self.saved_model_path:\n                    saver.restore(sess, self.saved_model_path)\n                else:\n                    raise PersephoneException(\"No model to use for transcription.\")\n\n            batch_gen = self.corpus_reader.untranscribed_batch_gen()\n\n            hyp_batches = []\n            for batch_i, batch in enumerate(batch_gen):\n\n                batch_x, batch_x_lens, feat_fn_batch = batch\n\n                feed_dict = {self.batch_x: batch_x,\n                             self.batch_x_lens: batch_x_lens}\n\n                [dense_decoded] = sess.run([self.dense_decoded], feed_dict=feed_dict)\n                hyps = self.corpus_reader.human_readable(dense_decoded)\n\n                # Prepare dir for transcription\n                hyps_dir = os.path.join(self.exp_dir, \"transcriptions\")\n                if not os.path.isdir(hyps_dir):\n                    os.mkdir(hyps_dir)\n\n                hyp_batches.append((hyps,feat_fn_batch))\n\n            with open(os.path.join(hyps_dir, \"hyps.txt\"), \"w\",\n                      encoding=ENCODING) as hyps_f:\n                for hyp_batch, fn_batch in hyp_batches:\n                    for hyp, fn in zip(hyp_batch, fn_batch):\n                        print(fn, file=hyps_f)\n                        print(\" \".join(hyp), file=hyps_f)\n                        print(\"\", file=hyps_f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eval(self, restore_model_path: Optional[str]=None) -> None:\n\n        saver = tf.train.Saver()\n        with tf.Session(config=allow_growth_config) as sess:\n            if restore_model_path:\n                logger.info(\"restoring model from %s\", restore_model_path)\n                saver.restore(sess, restore_model_path)\n            else:\n                assert self.saved_model_path, \"{}\".format(self.saved_model_path)\n                logger.info(\"restoring model from %s\", self.saved_model_path)\n                saver.restore(sess, self.saved_model_path)\n\n            test_x, test_x_lens, test_y = self.corpus_reader.test_batch()\n\n            feed_dict = {self.batch_x: test_x,\n                         self.batch_x_lens: test_x_lens,\n                         self.batch_y: test_y}\n\n            test_ler, dense_decoded, dense_ref = sess.run(\n                [self.ler, self.dense_decoded, self.dense_ref],\n                feed_dict=feed_dict)\n            hyps, refs = self.corpus_reader.human_readable_hyp_ref(\n                dense_decoded, dense_ref)\n            # Log hypotheses\n            hyps_dir = os.path.join(self.exp_dir, \"test\")\n            if not os.path.isdir(hyps_dir):\n                os.mkdir(hyps_dir)\n            with open(os.path.join(hyps_dir, \"hyps\"), \"w\",\n                      encoding=ENCODING) as hyps_f:\n                for hyp in hyps:\n                    print(\" \".join(hyp), file=hyps_f)\n            with open(os.path.join(hyps_dir, \"refs\"), \"w\",\n                      encoding=ENCODING) as refs_f:\n                for ref in refs:\n                    print(\" \".join(ref), file=refs_f)\n\n            test_per = utils.batch_per(hyps, refs)\n            assert test_per == test_ler\n            with open(os.path.join(hyps_dir, \"test_per\"), \"w\",\n                      encoding=ENCODING) as per_f:\n                print(\"LER: %f\" % (test_ler), file=per_f)", "response": "Evaluates the model on a test set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noutput best scores to the filesystem", "response": "def output_best_scores(self, best_epoch_str: str) -> None:\n        \"\"\"Output best scores to the filesystem\"\"\"\n        BEST_SCORES_FILENAME = \"best_scores.txt\"\n        with open(os.path.join(self.exp_dir, BEST_SCORES_FILENAME),\n                  \"w\", encoding=ENCODING) as best_f:\n            print(best_epoch_str, file=best_f, flush=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef train(self, early_stopping_steps: int = 10, min_epochs: int = 30,\n              max_valid_ler: float = 1.0, max_train_ler: float = 0.3,\n              max_epochs: int = 100, restore_model_path: Optional[str]=None,\n              epoch_callback: Optional[Callable[[Dict], None]]=None) -> None:\n        \"\"\" Train the model.\n\n            min_epochs: minimum number of epochs to run training for.\n            max_epochs: maximum number of epochs to run training for.\n            early_stopping_steps: Stop training after this number of steps\n                                  if no LER improvement has been made.\n            max_valid_ler: Maximum LER for the validation set.\n                           Training will continue until this is met or another\n                           stopping condition occurs.\n            max_train_ler: Maximum LER for the training set.\n                           Training will continue until this is met or another\n                           stopping condition occurs.\n            restore_model_path: The path to restore a model from.\n            epoch_callback: A callback that is called at the end of each training epoch.\n                            The parameters passed to the callable will be the epoch number,\n                            the current training LER and the current validation LER.\n                            This can be useful for progress reporting.\n        \"\"\"\n        logger.info(\"Training model\")\n        best_valid_ler = 2.0\n        steps_since_last_record = 0\n\n        #Get information about training for the names of output files.\n        frame = inspect.currentframe()\n        # pylint: disable=deprecated-method\n        # It was a mistake to deprecate this in Python 3.5\n        if frame:\n            args, _, _, values = inspect.getargvalues(frame)\n            with open(os.path.join(self.exp_dir, \"train_description.txt\"), \n                      \"w\", encoding=ENCODING) as desc_f:\n                for arg in args:\n                    if type(values[arg]) in [str, int, float] or isinstance(\n                            values[arg], type(None)):\n                        print(\"%s=%s\" % (arg, values[arg]), file=desc_f)\n                    else:\n                        print(\"%s=%s\" % (arg, values[arg].__dict__), file=desc_f)\n                print(\"num_train=%s\" % (self.corpus_reader.num_train), file=desc_f)\n                print(\"batch_size=%s\" % (self.corpus_reader.batch_size), file=desc_f)\n        else:\n            logger.error(\"Couldn't find frame information, failed to write train_description.txt\")\n\n\n        # Load the validation set\n        valid_x, valid_x_lens, valid_y = self.corpus_reader.valid_batch()\n\n        saver = tf.train.Saver()\n\n        with tf.Session(config=allow_growth_config) as sess:\n\n            if restore_model_path:\n                logger.info(\"Restoring model from path %s\", restore_model_path)\n                saver.restore(sess, restore_model_path)\n            else:\n                sess.run(tf.global_variables_initializer())\n\n            # Prepare directory to output hypotheses to\n            hyps_dir = os.path.join(self.exp_dir, \"decoded\")\n            if not os.path.isdir(hyps_dir):\n                os.mkdir(hyps_dir)\n\n            best_epoch_str = None\n\n            training_log_path = os.path.join(self.exp_dir, \"train_log.txt\")\n            if os.path.exists(training_log_path):\n                logger.error(\"Error, overwriting existing log file at path {}\".format(training_log_path))\n            with open(training_log_path, \"w\",\n                      encoding=ENCODING) as out_file:\n                for epoch in itertools.count(start=1):\n                    print(\"\\nexp_dir %s, epoch %d\" % (self.exp_dir, epoch))\n                    batch_gen = self.corpus_reader.train_batch_gen()\n\n                    train_ler_total = 0\n                    print(\"\\tBatch...\", end=\"\")\n                    for batch_i, batch in enumerate(batch_gen):\n                        print(\"%d...\" % batch_i, end=\"\")\n                        sys.stdout.flush()\n                        batch_x, batch_x_lens, batch_y = batch\n\n                        feed_dict = {self.batch_x: batch_x,\n                                    self.batch_x_lens: batch_x_lens,\n                                    self.batch_y: batch_y}\n\n                        _, ler, = sess.run([self.optimizer, self.ler],\n                                        feed_dict=feed_dict)\n\n                        train_ler_total += ler\n                    #else:\n                    #    raise PersephoneException(\"No training data was provided.\"\n                    #                              \" Check your batch generation.\")\n\n                    feed_dict = {self.batch_x: valid_x,\n                                self.batch_x_lens: valid_x_lens,\n                                self.batch_y: valid_y}\n\n                    try:\n                        valid_ler, dense_decoded, dense_ref = sess.run(\n                            [self.ler, self.dense_decoded, self.dense_ref],\n                            feed_dict=feed_dict)\n                    except tf.errors.ResourceExhaustedError:\n                        import pprint\n                        print(\"Ran out of memory allocating a batch:\")\n                        pprint.pprint(feed_dict)\n                        logger.critical(\"Ran out of memory allocating a batch: %s\", pprint.pformat(feed_dict))\n                        raise\n                    hyps, refs = self.corpus_reader.human_readable_hyp_ref(\n                        dense_decoded, dense_ref)\n                    # Log hypotheses\n                    with open(os.path.join(hyps_dir, \"epoch%d_hyps\" % epoch),\n                              \"w\", encoding=ENCODING) as hyps_f:\n                        for hyp in hyps:\n                            print(\" \".join(hyp), file=hyps_f)\n                    if epoch == 0:\n                        with open(os.path.join(hyps_dir, \"refs\"), \"w\", \n                                  encoding=ENCODING) as refs_f:\n                            for ref in refs:\n                                print(\" \".join(ref), file=refs_f)\n\n                    valid_per = utils.batch_per(hyps, refs)\n\n                    epoch_str = \"Epoch %d. Training LER: %f, validation LER: %f\" % (\n                        epoch, (train_ler_total / (batch_i + 1)), valid_ler)\n                    print(epoch_str, flush=True, file=out_file)\n                    if best_epoch_str is None:\n                        best_epoch_str = epoch_str\n\n                    # Call the callback here if it was defined\n                    if epoch_callback:\n                        epoch_callback({\n                            \"epoch\": epoch,\n                            \"training_ler\": (train_ler_total / (batch_i + 1)), # current training LER\n                            \"valid_ler\": valid_ler, # Current validation LER\n                        })\n\n                    # Implement early stopping.\n                    if valid_ler < best_valid_ler:\n                        print(\"New best valid_ler\", file=out_file)\n                        best_valid_ler = valid_ler\n                        best_epoch_str = epoch_str\n                        steps_since_last_record = 0\n\n                        # Save the model.\n                        checkpoint_path = os.path.join(self.exp_dir, \"model\", \"model_best.ckpt\")\n                        if not os.path.exists(os.path.dirname(checkpoint_path)):\n                            os.mkdir(os.path.dirname(checkpoint_path))\n                        saver.save(sess, checkpoint_path)\n                        self.saved_model_path = checkpoint_path\n\n                        # Output best hyps\n                        with open(os.path.join(hyps_dir, \"best_hyps\"),\n                                  \"w\", encoding=ENCODING) as hyps_f:\n                            for hyp in hyps:\n                                print(\" \".join(hyp), file=hyps_f)\n\n                    else:\n                        print(\"Steps since last best valid_ler: %d\" % (steps_since_last_record), file=out_file)\n                        steps_since_last_record += 1\n                        if epoch >= max_epochs:\n                            self.output_best_scores(best_epoch_str)\n                            break\n                        if steps_since_last_record >= early_stopping_steps:\n                            if epoch >= min_epochs:\n                                # Then we've done the minimum number of epochs.\n                                if valid_ler <= max_valid_ler and ler <= max_train_ler:\n                                    # Then training error has moved sufficiently\n                                    # towards convergence.\n                                    print(\"Stopping since best validation score hasn't been\"\n                                        \" beaten in %d epochs and at least %d have been\"\n                                        \" done. The valid ler (%d) is below %d and\"\n                                        \" the train ler (%d) is below %d.\" %\n                                        (early_stopping_steps, min_epochs, valid_ler,\n                                        max_valid_ler, ler, max_train_ler),\n                                        file=out_file, flush=True)\n                                    self.output_best_scores(best_epoch_str)\n                                    break\n                                else:\n                                    # Keep training because we haven't achieved\n                                    # convergence.\n                                    continue\n                            else:\n                                # Keep training because we haven't done the minimum\n                                # numper of epochs.\n                                continue\n\n                # Check we actually saved a checkpoint\n                if not self.saved_model_path:\n                    raise PersephoneException(\n                        \"No checkpoint was saved so model evaluation cannot be performed. \"\n                        \"This can happen if the validaion LER never converges.\")\n                # Finally, run evaluation on the test set.\n                self.eval(restore_model_path=self.saved_model_path)", "response": "Train the model.\n\n            min_epochs: minimum number of epochs to run training for.\n            max_epochs: maximum number of epochs to run training for.\n            early_stopping_steps: Stop training after this number of steps\n                                  if no LER improvement has been made.\n            max_valid_ler: Maximum LER for the validation set.\n                           Training will continue until this is met or another\n                           stopping condition occurs.\n            max_train_ler: Maximum LER for the training set.\n                           Training will continue until this is met or another\n                           stopping condition occurs.\n            restore_model_path: The path to restore a model from.\n            epoch_callback: A callback that is called at the end of each training epoch.\n                            The parameters passed to the callable will be the epoch number,\n                            the current training LER and the current validation LER.\n                            This can be useful for progress reporting."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_no_set_overlap(train: Sequence[str], valid: Sequence[str], test: Sequence[str]) -> None:\n\n    logger.debug(\"Ensuring that the training, validation and test data sets have no overlap\")\n    train_s = set(train)\n    valid_s = set(valid)\n    test_s = set(test)\n\n    if train_s & valid_s:\n        logger.warning(\"train and valid have overlapping items: {}\".format(train_s & valid_s))\n        raise PersephoneException(\"train and valid have overlapping items: {}\".format(train_s & valid_s))\n    if train_s & test_s:\n        logger.warning(\"train and test have overlapping items: {}\".format(train_s & test_s))\n        raise PersephoneException(\"train and test have overlapping items: {}\".format(train_s & test_s))\n    if valid_s & test_s:\n        logger.warning(\"valid and test have overlapping items: {}\".format(valid_s & test_s))\n        raise PersephoneException(\"valid and test have overlapping items: {}\".format(valid_s & test_s))", "response": "Ensures that no training set data has creeped into the validation set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_untranscribed_wavs(wav_path: Path, transcription_path: Path, label_type: str) -> List[str]:\n    audio_files = wav_path.glob(\"**/*.wav\")\n    transcription_files = transcription_path.glob(\"**/*.{}\".format(label_type))\n\n    transcription_file_prefixes = [t_file.stem for t_file in transcription_files]\n\n    untranscribed_prefixes = [] # type: List[str]\n    for a_file in audio_files:\n        if a_file.stem not in transcription_file_prefixes:\n            untranscribed_prefixes.append(a_file.stem)\n    return untranscribed_prefixes", "response": "Find the untranscribed wavs in the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_untranscribed_prefixes_from_file(target_directory: Path) -> List[str]:\n\n    untranscribed_prefix_fn = target_directory / \"untranscribed_prefixes.txt\"\n    if untranscribed_prefix_fn.exists():\n        with untranscribed_prefix_fn.open() as f:\n            prefixes = f.readlines()\n\n        return [prefix.strip() for prefix in prefixes]\n    else:\n        #logger.warning(\"Attempting to get untranscribed prefixes but the file ({})\"\n        #                \" that should specify these does not exist\".format(untranscribed_prefix_fn))\n        pass\n    return []", "response": "Returns a list of all untranscribed prefixes from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef determine_labels(target_dir: Path, label_type: str) -> Set[str]:\n    logger.info(\"Finding phonemes of type %s in directory %s\", label_type, target_dir)\n\n    label_dir = target_dir / \"label/\"\n    if not label_dir.is_dir():\n        raise FileNotFoundError(\n            \"The directory {} does not exist.\".format(target_dir))\n\n    phonemes = set() # type: Set[str]\n    for fn in os.listdir(str(label_dir)):\n        if fn.endswith(str(label_type)):\n            with (label_dir / fn).open(\"r\", encoding=ENCODING) as f:\n                try:\n                    line_phonemes = set(f.readline().split())\n                except UnicodeDecodeError:\n                    logger.error(\"Unicode decode error on file %s\", fn)\n                    print(\"Unicode decode error on file {}\".format(fn))\n                    raise\n                phonemes = phonemes.union(line_phonemes)\n    return phonemes", "response": "Returns a set of all phonemes found in the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_elan(cls: Type[CorpusT], org_dir: Path, tgt_dir: Path,\n                  feat_type: str = \"fbank\", label_type: str = \"phonemes\",\n                  utterance_filter: Callable[[Utterance], bool] = None,\n                  label_segmenter: Optional[LabelSegmenter] = None,\n                  speakers: List[str] = None, lazy: bool = True,\n                  tier_prefixes: Tuple[str, ...] = (\"xv\", \"rf\")) -> CorpusT:\n        \"\"\" Construct a `Corpus` from ELAN files.\n\n        Args:\n            org_dir: A path to the directory containing the unpreprocessed\n                data.\n            tgt_dir: A path to the directory where the preprocessed data will\n                be stored.\n            feat_type: A string describing the input speech features. For\n                       example, \"fbank\" for log Mel filterbank features.\n            label_type: A string describing the transcription labels. For example,\n                         \"phonemes\" or \"tones\".\n            utterance_filter: A function that returns False if an utterance\n                should not be included in the corpus and True otherwise. This\n                can be used to remove undesirable utterances for training, such as\n                codeswitched utterances.\n            label_segmenter: An object that has an attribute `segment_labels`,\n                which is creates new `Utterance` instances from old ones,\n                by segmenting the tokens in their `text` attribute. Note,\n                `LabelSegmenter` might be better as a function, the only issue\n                is it needs to carry with it a list of labels. This could\n                potentially be a function attribute.\n            speakers: A list of speakers to filter for. If `None`, utterances\n                from all speakers are included.\n            tier_prefixes: A collection of strings that prefix ELAN tiers to\n                filter for. For example, if this is `(\"xv\", \"rf\")`, then tiers\n                named \"xv\", \"xv@Mark\", \"rf@Rose\" would be extracted if they\n                existed.\n\n        \"\"\"\n        # This currently bails out if label_segmenter is not provided\n        if not label_segmenter:\n            raise ValueError(\"A label segmenter must be provided via label_segmenter\")\n\n        # In case path is supplied as a string, make it a Path\n        if isinstance(tgt_dir, str):\n            tgt_dir = Path(tgt_dir)\n\n        # Read utterances from org_dir.\n        utterances = elan.utterances_from_dir(org_dir,\n                                              tier_prefixes=tier_prefixes)\n\n        # Filter utterances based on some criteria (such as codeswitching).\n        if utterance_filter:\n            utterances = [utter for utter in utterances if utterance_filter(utter)]\n        utterances = utterance.remove_duplicates(utterances)\n\n        # Segment the labels in the utterances appropriately\n        if label_segmenter:\n            utterances = [label_segmenter.segment_labels(utter) for utter in utterances]\n\n        # Remove utterances without transcriptions.\n        utterances = utterance.remove_empty_text(utterances)\n\n        # Remove utterances with exceptionally short wav_files that are too\n        # short for CTC to work.\n        utterances = utterance.remove_too_short(utterances)\n\n        tgt_dir.mkdir(parents=True, exist_ok=True)\n\n        # TODO A lot of these methods aren't ELAN-specific. preprocess.elan was\n        # only used to get the utterances. There could be another Corpus\n        # factory method that takes Utterance objects. the fromElan and\n        # fromPangloss constructors could call this.\n\n        # Writes the transcriptions to the tgt_dir/label/ dir\n        utterance.write_transcriptions(utterances, (tgt_dir / \"label\"),\n                               label_type, lazy=lazy)\n        # Extracts utterance level WAV information from the input file.\n        wav.extract_wavs(utterances, (tgt_dir / \"wav\"), lazy=lazy)\n\n        corpus = cls(feat_type, label_type, tgt_dir,\n                     labels=label_segmenter.labels, speakers=speakers)\n        corpus.utterances = utterances\n        return corpus", "response": "Constructs a Corpus instance from ELAN files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the required directories in the target directory.", "response": "def set_and_check_directories(self, tgt_dir: Path) -> None:\n        \"\"\"\n        Make sure that the required directories exist in the target directory.\n        set variables accordingly.\n        \"\"\"\n        logger.info(\"Setting up directories for corpus in %s\", tgt_dir)\n\n        # Check directories exist.\n        if not tgt_dir.is_dir():\n            raise FileNotFoundError(\n                \"The directory {} does not exist.\".format(tgt_dir))\n        if not self.wav_dir.is_dir():\n            raise PersephoneException(\n                \"The supplied path requires a 'wav' subdirectory.\")\n        self.feat_dir.mkdir(parents=True, exist_ok=True)\n        if not self.label_dir.is_dir():\n            raise PersephoneException(\n                \"The supplied path requires a 'label' subdirectory.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating mappings from label to index and index to label", "response": "def initialize_labels(self, labels: Set[str]) -> Tuple[dict, dict]:\n        \"\"\"Create mappings from label to index and index to label\"\"\"\n        logger.debug(\"Creating mappings for labels\")\n\n        label_to_index = {label: index for index, label in enumerate(\n                                 [\"pad\"] + sorted(list(labels)))}\n        index_to_label = {index: phn for index, phn in enumerate(\n                                 [\"pad\"] + sorted(list(labels)))}\n\n        return label_to_index, index_to_label"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_feats(self) -> None:\n\n        logger.debug(\"Preparing input features\")\n        self.feat_dir.mkdir(parents=True, exist_ok=True)\n\n        should_extract_feats = False\n        for path in self.wav_dir.iterdir():\n            if not path.suffix == \".wav\":\n                logger.info(\"Non wav file found in wav directory: %s\", path)\n                continue\n            prefix = os.path.basename(os.path.splitext(str(path))[0])\n            mono16k_wav_path = self.feat_dir / \"{}.wav\".format(prefix)\n            feat_path = self.feat_dir / \"{}.{}.npy\".format(prefix, self.feat_type)\n            if not feat_path.is_file():\n                # Then we should extract feats\n                should_extract_feats = True\n                if not mono16k_wav_path.is_file():\n                    feat_extract.convert_wav(path, mono16k_wav_path)\n\n        # TODO Should be extracting feats on a per-file basis. Right now we\n        # check if any feats files don't exist and then do all the feature\n        # extraction.\n        if should_extract_feats:\n            feat_extract.from_dir(self.feat_dir, self.feat_type)", "response": "Prepares the input features for the current class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits the utterances into training validation and test sets.", "response": "def make_data_splits(self, max_samples: int) -> None:\n        \"\"\" Splits the utterances into training, validation and test sets.\"\"\"\n\n        train_f_exists = self.train_prefix_fn.is_file()\n        valid_f_exists = self.valid_prefix_fn.is_file()\n        test_f_exists = self.test_prefix_fn.is_file()\n\n        if train_f_exists and valid_f_exists and test_f_exists:\n            logger.debug(\"Split for training, validation and tests specified by files\")\n            self.train_prefixes = self.read_prefixes(self.train_prefix_fn)\n            self.valid_prefixes = self.read_prefixes(self.valid_prefix_fn)\n            self.test_prefixes = self.read_prefixes(self.test_prefix_fn)\n            return\n\n        # Otherwise we now need to load prefixes for other cases addressed\n        # below\n        prefixes = self.determine_prefixes()\n        prefixes = utils.filter_by_size(\n            self.feat_dir, prefixes, self.feat_type, max_samples)\n\n        if not train_f_exists and not valid_f_exists and not test_f_exists:\n            logger.debug(\"No files supplied to define the split for training, validation\"\n                         \" and tests. Using default.\")\n            train_prefixes, valid_prefixes, test_prefixes = self.divide_prefixes(prefixes)\n            self.train_prefixes = train_prefixes\n            self.valid_prefixes = valid_prefixes\n            self.test_prefixes = test_prefixes\n            self.write_prefixes(train_prefixes, self.train_prefix_fn)\n            self.write_prefixes(valid_prefixes, self.valid_prefix_fn)\n            self.write_prefixes(test_prefixes, self.test_prefix_fn)\n        elif not train_f_exists and valid_f_exists and test_f_exists:\n            # Then we just make all other prefixes training prefixes.\n            self.valid_prefixes = self.read_prefixes(self.valid_prefix_fn)\n            self.test_prefixes = self.read_prefixes(self.test_prefix_fn)\n            train_prefixes = list(\n                set(prefixes) - set(self.valid_prefixes))\n            self.train_prefixes = list(\n                set(train_prefixes) - set(self.test_prefixes))\n            self.write_prefixes(self.train_prefixes, self.train_prefix_fn)\n        else:\n            raise NotImplementedError(\n                \"The following case has not been implemented:\" + \n                \"{} exists - {}\\n\".format(self.train_prefix_fn, train_f_exists) +\n                \"{} exists - {}\\n\".format(self.valid_prefix_fn, valid_f_exists) +\n                \"{} exists - {}\\n\".format(self.test_prefix_fn, test_f_exists))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef divide_prefixes(prefixes: List[str], seed:int=0) -> Tuple[List[str], List[str], List[str]]:\n        if len(prefixes) < 3:\n            raise PersephoneException(\n                \"{} cannot be split into 3 groups as it only has {} items\".format(prefixes, len(prefixes))\n            )\n        Ratios = namedtuple(\"Ratios\", [\"train\", \"valid\", \"test\"])\n        ratios=Ratios(.90, .05, .05)\n        train_end = int(ratios.train*len(prefixes))\n        valid_end = int(train_end + ratios.valid*len(prefixes))\n\n        # We must make sure that at least one element exists in test\n        if valid_end == len(prefixes):\n            valid_end -= 1\n\n        # If train_end and valid_end are the same we end up with no valid_prefixes\n        # so we must ensure at least one prefix is placed in this category\n        if train_end == valid_end:\n            train_end -= 1\n\n        random.seed(seed)\n        random.shuffle(prefixes)\n\n        train_prefixes = prefixes[:train_end]\n        valid_prefixes = prefixes[train_end:valid_end]\n        test_prefixes = prefixes[valid_end:]\n\n        assert train_prefixes, \"Got empty set for training data\"\n        assert valid_prefixes, \"Got empty set for validation data\"\n        assert test_prefixes, \"Got empty set for testing data\"\n\n        return train_prefixes, valid_prefixes, test_prefixes", "response": "Divide data into training validation and test subsets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef indices_to_labels(self, indices: Sequence[int]) -> List[str]:\n\n        return [(self.INDEX_TO_LABEL[index]) for index in indices]", "response": "Converts a sequence of indices into their corresponding labels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a sequence of labels into their corresponding indices.", "response": "def labels_to_indices(self, labels: Sequence[str]) -> List[int]:\n        \"\"\" Converts a sequence of labels into their corresponding indices.\"\"\"\n\n        return [self.LABEL_TO_INDEX[label] for label in labels]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prefixes_to_fns(self, prefixes: List[str]) -> Tuple[List[str], List[str]]:\n        # TODO Return pathlib.Paths\n        feat_fns = [str(self.feat_dir / (\"%s.%s.npy\" % (prefix, self.feat_type)))\n                    for prefix in prefixes]\n        label_fns = [str(self.label_dir / (\"%s.%s\" % (prefix, self.label_type)))\n                      for prefix in prefixes]\n        return feat_fns, label_fns", "response": "Fetches the file paths to the features files and labels files corresponding to the provided list of features"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_train_fns(self) -> Tuple[List[str], List[str]]:\n        return self.prefixes_to_fns(self.train_prefixes)", "response": "Fetches the training set of the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching the validation set of the corpus.", "response": "def get_valid_fns(self) -> Tuple[List[str], List[str]]:\n        \"\"\" Fetches the validation set of the corpus.\"\"\"\n        return self.prefixes_to_fns(self.valid_prefixes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplay the WAV files and compare with the transcription.", "response": "def review(self) -> None:\n        \"\"\" Used to play the WAV files and compare with the transcription. \"\"\"\n\n        for prefix in self.determine_prefixes():\n            print(\"Utterance: {}\".format(prefix))\n            wav_fn = self.feat_dir / \"{}.wav\".format(prefix)\n            label_fn = self.label_dir / \"{}.{}\".format(prefix,self.label_type)\n            with label_fn.open() as f:\n                transcript = f.read().strip()\n            print(\"Transcription: {}\".format(transcript))\n            subprocess.run([\"play\", str(wav_fn)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npickle the Corpus object in tgt_dir and saves it in a file in tgt_dir.", "response": "def pickle(self) -> None:\n        \"\"\" Pickles the Corpus object in a file in tgt_dir. \"\"\"\n\n        pickle_path = self.tgt_dir / \"corpus.p\"\n        logger.debug(\"pickling %r object and saving it to path %s\", self, pickle_path)\n        with pickle_path.open(\"wb\") as f:\n            pickle.dump(self, f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the git working directory is in a clean state.", "response": "def is_git_directory_clean(path_to_repo: Path,\n                           search_parent_dirs: bool = True,\n                           check_untracked: bool = False) -> None:\n    \"\"\"\n    Check that the git working directory is in a clean state\n    and raise exceptions if not.\n    :path_to_repo: The path of the git repo\n    \"\"\"\n    repo = Repo(str(path_to_repo), search_parent_directories=search_parent_dirs)\n    logger.debug(\"is_git_directory_clean check for repo in path={} from \"\\\n                  \"cwd={} with search_parent_directories={}\".format(\n                        path_to_repo, os.getcwd(), search_parent_dirs))\n\n    # If there are changes to already tracked files\n    if repo.is_dirty():\n        raise DirtyRepoException(\"Changes to the index or working tree.\"\n                                 \"Commit them first .\")\n    if check_untracked:\n        if repo.untracked_files:\n            raise DirtyRepoException(\"Untracked files. Commit them first.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef target_list_to_sparse_tensor(target_list):\n    indices = []\n    vals = []\n    for t_i, target in enumerate(target_list):\n        for seq_i, val in enumerate(target):\n            indices.append([t_i, seq_i])\n            vals.append(val)\n    shape = [len(target_list), np.asarray(indices).max(0)[1]+1]\n    return (np.array(indices), np.array(vals), np.array(shape))", "response": "Make a TensorFlow SparseTensor from a list of targets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zero_pad(matrix, to_length):\n\n    assert matrix.shape[0] <= to_length\n    if not matrix.shape[0] <= to_length:\n        logger.error(\"zero_pad cannot be performed on matrix with shape {}\"\n                     \" to length {}\".format(matrix.shape[0], to_length))\n        raise ValueError\n    result = np.zeros((to_length,) + matrix.shape[1:])\n    result[:matrix.shape[0]] = matrix\n    return result", "response": "Zero pads along the 0th dimension to make sure the utterance array\n    x is of length to_length."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collapse(batch_x, time_major=False):\n\n    new_batch_x = []\n    for utterance in batch_x:\n        swapped = np.swapaxes(utterance, 0, 1)\n        concatenated = np.concatenate(swapped, axis=1)\n        new_batch_x.append(concatenated)\n    new_batch_x = np.array(new_batch_x)\n    if time_major:\n        new_batch_x = np.transpose(new_batch_x, (1, 0, 2))\n    return new_batch_x", "response": "Converts timit into an array of format batch_size freq x num_deltas time. Essentially multiple channels are collapsed to one."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_batch_x(path_batch,\n                 flatten = False,\n                 time_major = False):\n    \"\"\" Loads a batch of input features given a list of paths to numpy\n    arrays in that batch.\"\"\"\n\n    utterances = [np.load(str(path)) for path in path_batch]\n    utter_lens = [utterance.shape[0] for utterance in utterances]\n    max_len = max(utter_lens)\n    batch_size = len(path_batch)\n    shape = (batch_size, max_len) + tuple(utterances[0].shape[1:])\n    batch = np.zeros(shape)\n    for i, utt in enumerate(utterances):\n        batch[i] = zero_pad(utt, max_len)\n    if flatten:\n        batch = collapse(batch, time_major=time_major)\n    return batch, np.array(utter_lens)", "response": "Loads a batch of input features given a list of paths to numpy\n    arrays in that batch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef batch_per(hyps: Sequence[Sequence[T]],\n              refs: Sequence[Sequence[T]]) -> float:\n    \"\"\" Calculates the phoneme error rate of a batch.\"\"\"\n\n    macro_per = 0.0\n    for i in range(len(hyps)):\n        ref = [phn_i for phn_i in refs[i] if phn_i != 0]\n        hyp = [phn_i for phn_i in hyps[i] if phn_i != 0]\n        macro_per += distance.edit_distance(ref, hyp)/len(ref)\n    return macro_per/len(hyps)", "response": "Calculates the phoneme error rate of a batch."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of prefixes to files in the directory.", "response": "def get_prefixes(dirname: str, extension: str) -> List[str]:\n    \"\"\" Returns a list of prefixes to files in the directory (which might be a whole\n    corpus, or a train/valid/test subset. The prefixes include the path leading\n    up to it, but only the filename up until the first observed period '.'\n    \"\"\"\n\n    prefixes = []\n    for root, _, filenames in os.walk(dirname):\n        for filename in filenames:\n            if filename.endswith(extension):\n                # Then it's an input feature file and its prefix will\n                # correspond to a training example\n                prefixes.append(os.path.join(root, filename.split(\".\")[0]))\n    return sorted(prefixes)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_by_size(feat_dir: Path, prefixes: List[str], feat_type: str,\n                   max_samples: int) -> List[str]:\n    \"\"\" Sorts the files by their length and returns those with less\n    than or equal to max_samples length. Returns the filename prefixes of\n    those files. The main job of the method is to filter, but the sorting\n    may give better efficiency when doing dynamic batching unless it gets\n    shuffled downstream.\n    \"\"\"\n\n    # TODO Tell the user what utterances we are removing.\n    prefix_lens = get_prefix_lens(Path(feat_dir), prefixes, feat_type)\n    prefixes = [prefix for prefix, length in prefix_lens\n                if length <= max_samples]\n    return prefixes", "response": "Sort the files by their length and return those with less\nFormula than or equal to max_samples length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wav_length(fn: str) -> float:\n\n    args = [config.SOX_PATH, fn, \"-n\", \"stat\"]\n    p = subprocess.Popen(\n        args, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n    length_line = str(p.communicate()[1]).split(\"\\\\n\")[1].split()\n    print(length_line)\n    assert length_line[0] == \"Length\"\n    return float(length_line[-1])", "response": "Returns the length of the WAV file in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngrouping utterances into batches for decoding.", "response": "def make_batches(paths: Sequence[Path], batch_size: int) -> List[Sequence[Path]]:\n    \"\"\" Group utterances into batches for decoding.  \"\"\"\n\n    return [paths[i:i+batch_size]\n            for i in range(0, len(paths), batch_size)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pull_en_words() -> None:\n\n    ENGLISH_WORDS_URL = \"https://github.com/dwyl/english-words.git\"\n    en_words_path = Path(config.EN_WORDS_PATH)\n    if not en_words_path.is_file():\n        subprocess.run([\"git\", \"clone\",\n                        ENGLISH_WORDS_URL, str(en_words_path.parent)])", "response": "Fetch a repository containing English words."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of English words which can be used to filter out English words which can be used to filter out English code - switched sentences.", "response": "def get_en_words() -> Set[str]:\n    \"\"\"\n    Returns a list of English words which can be used to filter out\n    code-switched sentences.\n    \"\"\"\n\n    pull_en_words()\n\n    with open(config.EN_WORDS_PATH) as words_f:\n        raw_words = words_f.readlines()\n    en_words = set([word.strip().lower() for word in raw_words])\n    NA_WORDS_IN_EN_DICT = set([\"kore\", \"nani\", \"karri\", \"imi\", \"o\", \"yaw\", \"i\",\n                           \"bi\", \"aye\", \"imi\", \"ane\", \"kubba\", \"kab\", \"a-\",\n                           \"ad\", \"a\", \"mak\", \"selim\", \"ngai\", \"en\", \"yo\",\n                           \"wud\", \"mani\", \"yak\", \"manu\", \"ka-\", \"mong\",\n                           \"manga\", \"ka-\", \"mane\", \"kala\", \"name\", \"kayo\",\n                           \"kare\", \"laik\", \"bale\", \"ni\", \"rey\", \"bu\",\n                           \"re\", \"iman\", \"bom\", \"wam\",\n                           \"alu\", \"nan\", \"kure\", \"kuri\", \"wam\", \"ka\", \"ng\",\n                           \"yi\", \"na\", \"m\", \"arri\", \"e\", \"kele\", \"arri\", \"nga\",\n                           \"kakan\", \"ai\", \"ning\", \"mala\", \"ti\", \"wolk\",\n                           \"bo\", \"andi\", \"ken\", \"ba\", \"aa\", \"kun\", \"bini\",\n                           \"wo\", \"bim\", \"man\", \"bord\", \"al\", \"mah\", \"won\",\n                           \"ku\", \"ay\", \"belen\", \"wen\", \"yah\", \"muni\",\n                           \"bah\", \"di\", \"mm\", \"anu\", \"nane\", \"ma\", \"kum\",\n                           \"birri\", \"ray\", \"h\", \"kane\", \"mumu\", \"bi\", \"ah\",\n                           \"i-\", \"n\", \"mi\", \"bedman\", \"rud\", \"le\", \"babu\",\n                           \"da\", \"kakkak\", \"yun\", \"ande\", \"naw\", \"kam\", \"bolk\",\n                           \"woy\", \"u\", \"bi-\",\n                           ])\n    EN_WORDS_NOT_IN_EN_DICT = set([\"screenprinting\"])\n    en_words = en_words.difference(NA_WORDS_IN_EN_DICT)\n    en_words = en_words | EN_WORDS_NOT_IN_EN_DICT\n    return en_words"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef segment_str(text: str, phoneme_inventory: Set[str] = PHONEMES) -> str:\n\n    text = text.lower()\n    text = segment_into_tokens(text, phoneme_inventory)\n    return text", "response": "Takes as input a string in Kunwinjku and segments it into phoneme - like\n    units based on the standard orthographic rules specified at Kunwinjku http://bininjgunwok. orgau."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsorts the annotations by their start_time.", "response": "def sort_annotations(annotations: List[Tuple[int, int, str]]\n                     ) -> List[Tuple[int, int, str]]:\n    \"\"\" Sorts the annotations by their start_time. \"\"\"\n    return sorted(annotations, key=lambda x: x[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef utterances_from_tier(eafob: Eaf, tier_name: str) -> List[Utterance]:\n\n    try:\n        speaker = eafob.tiers[tier_name][2][\"PARTICIPANT\"]\n    except KeyError:\n        speaker = None # We don't know the name of the speaker.\n\n    tier_utterances = []\n\n    annotations = sort_annotations(\n        list(eafob.get_annotation_data_for_tier(tier_name)))\n\n    for i, annotation in enumerate(annotations):\n        eaf_stem = eafob.eaf_path.stem\n        utter_id = \"{}.{}.{}\".format(eaf_stem, tier_name, i)\n        start_time = eafob.time_origin + annotation[0]\n        end_time = eafob.time_origin + annotation[1]\n        text = annotation[2]\n        utterance = Utterance(eafob.media_path, eafob.eaf_path, utter_id,\n                              start_time, end_time, text, speaker)\n        tier_utterances.append(utterance)\n\n    return tier_utterances", "response": "Returns the utterances found in the given Eaf object in the given tier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef utterances_from_eaf(eaf_path: Path, tier_prefixes: Tuple[str, ...]) -> List[Utterance]:\n\n    if not eaf_path.is_file():\n        raise FileNotFoundError(\"Cannot find {}\".format(eaf_path))\n\n    eaf = Eaf(eaf_path)\n    utterances = []\n    for tier_name in sorted(list(eaf.tiers)): # Sorting for determinism\n        for tier_prefix in tier_prefixes:\n            if tier_name.startswith(tier_prefix):\n                utterances.extend(utterances_from_tier(eaf, tier_name))\n                break\n    return utterances", "response": "Extracts utterances from the ELAN. eaf XML file at eaf_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef utterances_from_dir(eaf_dir: Path,\n                        tier_prefixes: Tuple[str, ...]) -> List[Utterance]:\n    \"\"\" Returns the utterances found in ELAN files in a directory.\n\n    Recursively explores the directory, gathering ELAN files and extracting\n    utterances from them for tiers that start with the specified prefixes.\n\n    Args:\n        eaf_dir: A path to the directory to be searched\n        tier_prefixes: Stings matching the start of ELAN tier names that are to\n            be extracted. For example, if you want to extract from tiers \"xv-Jane\"\n            and \"xv-Mark\", then tier_prefixes = [\"xv\"] would do the job.\n\n    Returns:\n        A list of Utterance objects.\n\n    \"\"\"\n\n    logger.info(\n        \"EAF from directory: {}, searching with tier_prefixes {}\".format(\n            eaf_dir, tier_prefixes))\n\n    utterances = []\n    for eaf_path in eaf_dir.glob(\"**/*.eaf\"):\n        eaf_utterances = utterances_from_eaf(eaf_path, tier_prefixes)\n        utterances.extend(eaf_utterances)\n    return utterances", "response": "Returns the utterances found in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the media descriptor for the first available media file.", "response": "def initialize_media_descriptor(self) -> None:\n        \"\"\"\n        Returns the media descriptor for the first media descriptor where\n        the file can be found.\n        \"\"\"\n\n        for md in self.media_descriptors:\n            media_path = self.get_media_path(md)\n            if media_path.is_file():\n                self.media_descriptor = md\n                return\n\n        raise FileNotFoundError(\n            \"\"\"Cannot find media file corresponding to {}.\n            Tried looking for the following files: {}.\n            \"\"\".format(self.eaf_path, [self.get_media_path(md)\n                                       for md in self.media_descriptors]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_batch(self, fn_batch):\n\n        # TODO Assumes targets are available, which is how its distinct from\n        # utils.load_batch_x(). These functions need to change names to be\n        # clearer.\n\n        inverse = list(zip(*fn_batch))\n        feat_fn_batch = inverse[0]\n        target_fn_batch = inverse[1]\n\n        batch_inputs, batch_inputs_lens = utils.load_batch_x(feat_fn_batch,\n                                                             flatten=False)\n        batch_targets_list = []\n        for targets_path in target_fn_batch:\n            with open(targets_path, encoding=ENCODING) as targets_f:\n                target_indices = self.corpus.labels_to_indices(targets_f.readline().split())\n                batch_targets_list.append(target_indices)\n        batch_targets = utils.target_list_to_sparse_tensor(batch_targets_list)\n\n        return batch_inputs, batch_inputs_lens, batch_targets", "response": "Loads a batch with the given prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngroup utterances into batches for decoding.", "response": "def make_batches(self, utterance_fns: Sequence[Path]) -> List[Sequence[Path]]:\n        \"\"\" Group utterances into batches for decoding.  \"\"\"\n\n        return utils.make_batches(utterance_fns, self.batch_size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates batches of batch_size from training data.", "response": "def train_batch_gen(self) -> Iterator:\n        \"\"\" Returns a generator that outputs batches in the training data.\"\"\"\n\n        if len(self.train_fns) == 0:\n            raise PersephoneException(\"\"\"No training data available; cannot\n                                       generate training batches.\"\"\")\n\n        # Create batches of batch_size and shuffle them.\n        fn_batches = self.make_batches(self.train_fns)\n\n\n        if self.rand:\n            random.shuffle(fn_batches)\n\n        for fn_batch in fn_batches:\n            logger.debug(\"Batch of training filenames: %s\",\n                          pprint.pformat(fn_batch))\n            yield self.load_batch(fn_batch)\n        else:\n            raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef valid_batch(self):\n\n        valid_fns = list(zip(*self.corpus.get_valid_fns()))\n        return self.load_batch(valid_fns)", "response": "Returns a single batch with all the validation cases."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef untranscribed_batch_gen(self):\n\n        feat_fns = self.corpus.get_untranscribed_fns()\n        fn_batches = self.make_batches(feat_fns)\n\n        for fn_batch in fn_batches:\n            batch_inputs, batch_inputs_lens = utils.load_batch_x(fn_batch,\n                                                             flatten=False)\n            yield batch_inputs, batch_inputs_lens, fn_batch", "response": "A generator for all the untranscribed data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef human_readable_hyp_ref(self, dense_decoded, dense_y):\n\n        hyps = []\n        refs = []\n        for i in range(len(dense_decoded)):\n            ref = [phn_i for phn_i in dense_y[i] if phn_i != 0]\n            hyp = [phn_i for phn_i in dense_decoded[i] if phn_i != 0]\n            ref = self.corpus.indices_to_labels(ref)\n            hyp = self.corpus.indices_to_labels(hyp)\n            refs.append(ref)\n            hyps.append(hyp)\n\n        return hyps, refs", "response": "Returns a human readable version of the hypothesis for manual\n        inspection along with the reference."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a human readable version of a dense representation of a sequence of class names.", "response": "def human_readable(self, dense_repr: Sequence[Sequence[int]]) -> List[List[str]]:\n        \"\"\" Returns a human readable version of a dense representation of\n        either or reference to facilitate simple manual inspection.\n        \"\"\"\n\n        transcripts = []\n        for dense_r in dense_repr:\n            non_empty_phonemes = [phn_i for phn_i in dense_r if phn_i != 0]\n            transcript = self.corpus.indices_to_labels(non_empty_phonemes)\n            transcripts.append(transcript)\n\n        return transcripts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_time(self) -> None:\n\n        def get_number_of_frames(feat_fns):\n            \"\"\" fns: A list of numpy files which contain a number of feature\n            frames. \"\"\"\n\n            total = 0\n            for feat_fn in feat_fns:\n                num_frames = len(np.load(feat_fn))\n                total += num_frames\n\n            return total\n\n        def numframes_to_minutes(num_frames):\n            # TODO Assumes 10ms strides for the frames. This should generalize to\n            # different frame stride widths, as should feature preparation.\n            minutes = ((num_frames*10)/1000)/60\n            return minutes\n\n        total_frames = 0\n\n        train_fns = [train_fn[0] for train_fn in self.train_fns]\n        num_train_frames = get_number_of_frames(train_fns)\n        total_frames += num_train_frames\n        num_valid_frames = get_number_of_frames(self.corpus.get_valid_fns()[0])\n        total_frames += num_valid_frames\n        num_test_frames = get_number_of_frames(self.corpus.get_test_fns()[0])\n        total_frames += num_test_frames\n\n        print(\"Train duration: %0.3f\" % numframes_to_minutes(num_train_frames))\n        print(\"Validation duration: %0.3f\" % numframes_to_minutes(num_valid_frames))\n        print(\"Test duration: %0.3f\" % numframes_to_minutes(num_test_frames))\n        print(\"Total duration: %0.3f\" % numframes_to_minutes(total_frames))", "response": "Calculates the total time of the recordings in the current corpus."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lstm_cell(hidden_size):\n\n    return tf.contrib.rnn.LSTMCell(\n        hidden_size, use_peepholes=True, state_is_tuple=True)", "response": "Wrapper function to create an LSTM cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_desc(self) -> None:\n\n        path = os.path.join(self.exp_dir, \"model_description.txt\")\n        with open(path, \"w\") as desc_f:\n            for key, val in self.__dict__.items():\n                print(\"%s=%s\" % (key, val), file=desc_f)\n\n        import json\n        json_path = os.path.join(self.exp_dir, \"model_description.json\")\n        desc = { } #type: Dict[str, Any]\n        # For use in decoding from a saved model\n        desc[\"topology\"] = {\n            \"batch_x_name\" : self.batch_x.name, #type: ignore\n            \"batch_x_lens_name\" : self.batch_x_lens.name, #type: ignore\n            \"dense_decoded_name\" : self.dense_decoded.name #type: ignore\n        }\n        desc[\"model_type\"] = str(self.__class__)\n        for key, val in self.__dict__.items():\n            if isinstance(val, int):\n                desc[str(key)] = val\n            elif isinstance(val, tf.Tensor):\n                desc[key] = {\n                    \"type\": \"tf.Tensor\",\n                    \"name\": val.name, #type: ignore\n                    \"shape\": str(val.shape), #type: ignore\n                    \"dtype\" : str(val.dtype), #type: ignore\n                    \"value\" : str(val),\n                }\n            elif isinstance(val, tf.SparseTensor): #type: ignore\n                desc[key] = {\n                    \"type\": \"tf.SparseTensor\",\n                    \"value\": str(val), #type: ignore\n                }\n            else:\n                desc[str(key)] = str(val)\n        with open(json_path, \"w\") as json_desc_f:\n            json.dump(desc, json_desc_f, skipkeys=True)", "response": "Writes a description of the current model to the exp_dir."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a wav contains data", "response": "def empty_wav(wav_path: Union[Path, str]) -> bool:\n    \"\"\"Check if a wav contains data\"\"\"\n    with wave.open(str(wav_path), 'rb') as wav_f:\n        return wav_f.getnframes() == 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_energy(rate, sig):\n\n    mfcc = python_speech_features.mfcc(sig, rate, appendEnergy=True)\n    energy_row_vec = mfcc[:, 0]\n    energy_col_vec = energy_row_vec[:, np.newaxis]\n    return energy_col_vec", "response": "Extracts the energy of frames from a single audio file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngrab log Mel filterbank deltas and double deltas.", "response": "def fbank(wav_path, flat=True):\n    \"\"\" Currently grabs log Mel filterbank, deltas and double deltas.\"\"\"\n\n    (rate, sig) = wav.read(wav_path)\n    if len(sig) == 0:\n        logger.warning(\"Empty wav: {}\".format(wav_path))\n    fbank_feat = python_speech_features.logfbank(sig, rate, nfilt=40)\n    energy = extract_energy(rate, sig)\n    feat = np.hstack([energy, fbank_feat])\n    delta_feat = python_speech_features.delta(feat, 2)\n    delta_delta_feat = python_speech_features.delta(delta_feat, 2)\n    all_feats = [feat, delta_feat, delta_delta_feat]\n    if not flat:\n        all_feats = np.array(all_feats)\n        # Make time the first dimension for easy length normalization padding\n        # later.\n        all_feats = np.swapaxes(all_feats, 0, 1)\n        all_feats = np.swapaxes(all_feats, 1, 2)\n    else:\n        all_feats = np.concatenate(all_feats, axis=1)\n\n    # Log Mel Filterbank, with delta, and double delta\n    feat_fn = wav_path[:-3] + \"fbank.npy\"\n    np.save(feat_fn, all_feats)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mfcc(wav_path):\n\n    (rate, sig) = wav.read(wav_path)\n    feat = python_speech_features.mfcc(sig, rate, appendEnergy=True)\n    delta_feat = python_speech_features.delta(feat, 2)\n    all_feats = [feat, delta_feat]\n    all_feats = np.array(all_feats)\n    # Make time the first dimension for easy length normalization padding later.\n    all_feats = np.swapaxes(all_feats, 0, 1)\n    all_feats = np.swapaxes(all_feats, 1, 2)\n\n    feat_fn = wav_path[:-3] + \"mfcc13_d.npy\"\n    np.save(feat_fn, all_feats)", "response": "Grabs MFCC features with energy and derivates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dir(dirpath: Path, feat_type: str) -> None:\n\n    logger.info(\"Extracting features from directory {}\".format(dirpath))\n\n    dirname = str(dirpath)\n\n    def all_wavs_processed() -> bool:\n        \"\"\"\n        True if all wavs in the directory have corresponding numpy feature\n        file; False otherwise.\n        \"\"\"\n\n        for fn in os.listdir(dirname):\n            prefix, ext = os.path.splitext(fn)\n            if ext == \".wav\":\n                if not os.path.exists(\n                        os.path.join(dirname, \"%s.%s.npy\" % (prefix, feat_type))):\n                    return False\n        return True\n\n    if all_wavs_processed():\n        # Then nothing needs to be done here\n        logger.info(\"All WAV files already preprocessed\")\n        return\n    # Otherwise, go on and process everything...\n\n    # If pitch features are needed as part of this, extract them\n    if feat_type == \"pitch\" or feat_type == \"fbank_and_pitch\":\n        kaldi_pitch(dirname, dirname)\n\n    # Then apply file-wise feature extraction\n    for filename in os.listdir(dirname):\n        logger.info(\"Preparing %s features for %s\", feat_type, filename)\n        path = os.path.join(dirname, filename)\n        if path.endswith(\".wav\"):\n            if empty_wav(path):\n                raise PersephoneException(\"Can't extract features for {} since it is an empty WAV file. Remove it from the corpus.\".format(path))\n            if feat_type == \"fbank\":\n                fbank(path)\n            elif feat_type == \"fbank_and_pitch\":\n                fbank(path)\n                prefix = os.path.splitext(filename)[0]\n                combine_fbank_and_pitch(dirname, prefix)\n            elif feat_type == \"pitch\":\n                # Already extracted pitch at the start of this function.\n                pass\n            elif feat_type == \"mfcc13_d\":\n                mfcc(path)\n            else:\n                logger.warning(\"Feature type not found: %s\", feat_type)\n                raise PersephoneException(\"Feature type not found: %s\" % feat_type)", "response": "Extracts features from the WAV files in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_wav(org_wav_fn: Path, tgt_wav_fn: Path) -> None:\n    if not org_wav_fn.exists():\n        raise FileNotFoundError\n    args = [config.FFMPEG_PATH,\n            \"-i\", str(org_wav_fn), \"-ac\", \"1\", \"-ar\", \"16000\", str(tgt_wav_fn)]\n    subprocess.run(args)", "response": "Converts the wav into a 16bit mono 16000Hz wav."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts pitch features from wavs and pitch_feats files. Assumes 16k mono wav files.", "response": "def kaldi_pitch(wav_dir: str, feat_dir: str) -> None:\n    \"\"\" Extract Kaldi pitch features. Assumes 16k mono wav files.\"\"\"\n\n    logger.debug(\"Make wav.scp and pitch.scp files\")\n    # Make wav.scp and pitch.scp files\n    prefixes = []\n    for fn in os.listdir(wav_dir):\n        prefix, ext = os.path.splitext(fn)\n        if ext == \".wav\":\n            prefixes.append(prefix)\n\n    wav_scp_path = os.path.join(feat_dir, \"wavs.scp\")\n    with open(wav_scp_path, \"w\") as wav_scp:\n        for prefix in prefixes:\n            logger.info(\"Writing wav file: %s\", os.path.join(wav_dir, prefix + \".wav\"))\n            print(prefix, os.path.join(wav_dir, prefix + \".wav\"), file=wav_scp)\n\n    pitch_scp_path = os.path.join(feat_dir, \"pitch_feats.scp\")\n    with open(pitch_scp_path, \"w\") as pitch_scp:\n        for prefix in prefixes:\n            logger.info(\"Writing scp file: %s\", os.path.join(feat_dir, prefix + \".pitch.txt\"))\n            print(prefix, os.path.join(feat_dir, prefix + \".pitch.txt\"), file=pitch_scp)\n\n    # Call Kaldi pitch feat extraction\n    args = [os.path.join(config.KALDI_ROOT, \"src/featbin/compute-kaldi-pitch-feats\"),\n            \"scp:%s\" % (wav_scp_path), \"scp,t:%s\" % pitch_scp_path]\n    logger.info(\"Extracting pitch features from wavs listed in {}\".format(\n        wav_scp_path))\n    subprocess.run(args)\n\n    # Convert the Kaldi pitch *.txt files to numpy arrays.\n    for fn in os.listdir(feat_dir):\n        if fn.endswith(\".pitch.txt\"):\n            pitch_feats = []\n            with open(os.path.join(feat_dir, fn)) as f:\n                for line in f:\n                    sp = line.split()\n                    if len(sp) > 1:\n                        pitch_feats.append([float(sp[0]), float(sp[1])])\n            prefix, _ = os.path.splitext(fn)\n            out_fn = prefix + \".npy\"\n            a = np.array(pitch_feats)\n            np.save(os.path.join(feat_dir, out_fn), a)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the number of the current experiment directory.", "response": "def get_exp_dir_num(parent_dir: str) -> int:\n    \"\"\" Gets the number of the current experiment directory.\"\"\"\n    return max([int(fn.split(\".\")[0])\n                for fn in os.listdir(parent_dir) if fn.split(\".\")[0].isdigit()]\n                    + [-1])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _prepare_directory(directory_path: str) -> str:\n    exp_num = get_exp_dir_num(directory_path)\n    exp_num = exp_num + 1\n    exp_dir = os.path.join(directory_path, str(exp_num))\n    if not os.path.isdir(exp_dir):\n        os.makedirs(exp_dir)\n    return exp_dir", "response": "Prepare the directory structure required for the experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prep_exp_dir(directory=EXP_DIR):\n    if not os.path.isdir(directory):\n        os.makedirs(directory)\n    exp_dir = _prepare_directory(directory)\n    try:\n        # Get the directory this file is in, so we can grab the git repo.\n        dirname = os.path.dirname(os.path.realpath(__file__))\n        repo = Repo(dirname, search_parent_directories=True)\n        with open(os.path.join(exp_dir, \"git_hash.txt\"), \"w\") as f:\n            print(\"SHA1 hash: {hexsha}\".format(hexsha=repo.head.commit.hexsha), file=f)\n    except git.exc.InvalidGitRepositoryError: # pylint: disable=no-member\n        # Then the package was probably installed via pypi. Get the version\n        # number instead.\n        with open(os.path.join(exp_dir, \"version.txt\"), \"w\") as f:\n            print(\"Persephone version {}\".format(persephone.__version__), file=f)\n\n    return exp_dir", "response": "Prepare an experiment directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transcribe(model_path, corpus):\n\n    exp_dir = prep_exp_dir()\n    model = get_simple_model(exp_dir, corpus)\n    model.transcribe(model_path)", "response": "Applies a trained model to untranscribed data in a Corpus."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract a portion of a WAV file from the specified location.", "response": "def trim_wav_ms(in_path: Path, out_path: Path,\n                start_time: int, end_time: int) -> None:\n    \"\"\" Extracts part of a WAV File.\n\n    First attempts to call sox. If sox is unavailable, it backs off to\n    pydub+ffmpeg.\n\n    Args:\n        in_path: A path to the source file to extract a portion of\n        out_path: A path describing the to-be-created WAV file.\n        start_time: The point in the source WAV file at which to begin\n            extraction.\n        end_time: The point in the source WAV file at which to end extraction.\n\n    \"\"\"\n\n    try:\n        trim_wav_sox(in_path, out_path, start_time, end_time)\n    except FileNotFoundError:\n        # Then sox isn't installed, so use pydub/ffmpeg\n        trim_wav_pydub(in_path, out_path, start_time, end_time)\n    except subprocess.CalledProcessError:\n        # Then there is an issue calling sox. Perhaps the input file is an mp4\n        # or some other filetype not supported out-of-the-box by sox. So we try\n        # using pydub/ffmpeg.\n        trim_wav_pydub(in_path, out_path, start_time, end_time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntrims the wav file from start_time to end_time.", "response": "def trim_wav_pydub(in_path: Path, out_path: Path,\n                start_time: int, end_time: int) -> None:\n    \"\"\" Crops the wav file. \"\"\"\n\n    logger.info(\n        \"Using pydub/ffmpeg to create {} from {}\".format(out_path, in_path) +\n        \" using a start_time of {} and an end_time of {}\".format(start_time,\n                                                                 end_time))\n\n    if out_path.is_file():\n        return\n\n    # TODO add logging here\n    #print(\"in_fn: {}\".format(in_fn))\n    #print(\"out_fn: {}\".format(out_fn))\n    in_ext = in_path.suffix[1:]\n    out_ext = out_path.suffix[1:]\n    audio = AudioSegment.from_file(str(in_path), in_ext)\n    trimmed = audio[start_time:end_time]\n    # pydub evidently doesn't actually use the parameters when outputting wavs,\n    # since it doesn't use FFMPEG to deal with outputtting WAVs. This is a bit\n    # of a leaky abstraction. No warning is given, so normalization to 16Khz\n    # mono wavs has to happen later. Leaving the parameters here in case it\n    # changes\n    trimmed.export(str(out_path), format=out_ext,\n                   parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncrop the wav file at in_path so that the audio between start_time and end_time is output to out_path. Measured in milliseconds.", "response": "def trim_wav_sox(in_path: Path, out_path: Path,\n                 start_time: int, end_time: int) -> None:\n    \"\"\" Crops the wav file at in_fn so that the audio between start_time and\n    end_time is output to out_fn. Measured in milliseconds.\n    \"\"\"\n\n    if out_path.is_file():\n        logger.info(\"Output path %s already exists, not trimming file\", out_path)\n        return\n\n    start_time_secs = millisecs_to_secs(start_time)\n    end_time_secs = millisecs_to_secs(end_time)\n    args = [config.SOX_PATH, str(in_path), str(out_path),\n            \"trim\", str(start_time_secs), \"=\" + str(end_time_secs)]\n    logger.info(\"Cropping file %s, from start time %d (seconds) to end time %d (seconds), outputting to %s\",\n                in_path, start_time_secs, end_time_secs, out_path)\n    subprocess.run(args, check=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_wavs(utterances: List[Utterance], tgt_dir: Path,\n                 lazy: bool) -> None:\n    \"\"\" Extracts WAVs from the media files associated with a list of Utterance\n    objects and stores it in a target directory.\n\n    Args:\n        utterances: A list of Utterance objects, which include information\n            about the source media file, and the offset of the utterance in the\n            media_file.\n        tgt_dir: The directory in which to write the output WAVs.\n        lazy: If True, then existing WAVs will not be overwritten if they have\n            the same name\n    \"\"\"\n    tgt_dir.mkdir(parents=True, exist_ok=True)\n    for utter in utterances:\n        wav_fn = \"{}.{}\".format(utter.prefix, \"wav\")\n        out_wav_path = tgt_dir / wav_fn\n        if lazy and out_wav_path.is_file():\n            logger.info(\"File {} already exists and lazy == {}; not \" \\\n                         \"writing.\".format(out_wav_path, lazy))\n            continue\n        logger.info(\"File {} does not exist and lazy == {}; creating \" \\\n                     \"it.\".format(out_wav_path, lazy))\n        trim_wav_ms(utter.org_media_path, out_wav_path,\n                    utter.start_time, utter.end_time)", "response": "Extracts WAVs from the media files associated with a list of Utterances and stores them in a target directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_labels(sent: Sequence[str], labels: Set[str] = None) -> List[str]:\n\n    if labels:\n        return [tok for tok in sent if tok in labels]\n    return list(sent)", "response": "Returns only the tokens present in the sentence that are in labels."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filtered_error_rate(hyps_path: Union[str, Path], refs_path: Union[str, Path], labels: Set[str]) -> float:\n    if isinstance(hyps_path, Path):\n        hyps_path = str(hyps_path)\n    if isinstance(refs_path, Path):\n        refs_path = str(refs_path)\n\n    with open(hyps_path) as hyps_f:\n        lines = hyps_f.readlines()\n        hyps = [filter_labels(line.split(), labels) for line in lines]\n    with open(refs_path) as refs_f:\n        lines = refs_f.readlines()\n        refs = [filter_labels(line.split(), labels) for line in lines]\n\n    # For the case where there are no tokens left after filtering.\n    only_empty = True\n    for entry in hyps:\n        if entry is not []:\n            only_empty = False\n            break # found something so can move on immediately\n    if only_empty:\n        return -1\n\n    return utils.batch_per(hyps, refs)", "response": "Returns the error rate of hypotheses in hyps_path against references in refs_path after filtering only for labels in labels."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fmt_latex_output(hyps: Sequence[Sequence[str]],\n                     refs: Sequence[Sequence[str]],\n                     prefixes: Sequence[str],\n                     out_fn: Path,\n                    ) -> None:\n    \"\"\" Output the hypotheses and references to a LaTeX source file for\n    pretty printing.\n    \"\"\"\n\n    alignments_ = [min_edit_distance_align(ref, hyp)\n                  for hyp, ref in zip(hyps, refs)]\n\n    with out_fn.open(\"w\") as out_f:\n        print(latex_header(), file=out_f)\n\n        print(\"\\\\begin{document}\\n\"\n              \"\\\\begin{longtable}{ll}\", file=out_f)\n        print(r\"\\toprule\", file=out_f)\n        for sent in zip(prefixes, alignments_):\n            prefix = sent[0]\n            alignments = sent[1:]\n            print(\"Utterance ID: &\", prefix.strip().replace(r\"_\", r\"\\_\"), r\"\\\\\", file=out_f)\n            for i, alignment in enumerate(alignments):\n                ref_list = []\n                hyp_list = []\n                for arrow in alignment:\n                    if arrow[0] == arrow[1]:\n                        # Then don't highlight it; it's correct.\n                        ref_list.append(arrow[0])\n                        hyp_list.append(arrow[1])\n                    else:\n                        # Then highlight the errors.\n                        ref_list.append(\"\\\\hl{%s}\" % arrow[0])\n                        hyp_list.append(\"\\\\hl{%s}\" % arrow[1])\n                print(\"Ref: &\", \"\".join(ref_list), r\"\\\\\", file=out_f)\n                print(\"Hyp: &\", \"\".join(hyp_list), r\"\\\\\", file=out_f)\n            print(r\"\\midrule\", file=out_f)\n\n        print(r\"\\end{longtable}\", file=out_f)\n        print(r\"\\end{document}\", file=out_f)", "response": "Output the hypotheses and references to a LaTeX source file for a LaTeX language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting some information about different error types.", "response": "def fmt_error_types(hyps: Sequence[Sequence[str]],\n                    refs: Sequence[Sequence[str]]\n                   ) -> str:\n    \"\"\" Format some information about different error types: insertions, deletions and substitutions.\"\"\"\n\n    alignments = [min_edit_distance_align(ref, hyp)\n                  for hyp, ref in zip(hyps, refs)]\n\n    arrow_counter = Counter() # type: Dict[Tuple[str, str], int]\n    for alignment in alignments:\n        arrow_counter.update(alignment)\n    sub_count = sum([count for arrow, count in arrow_counter.items()\n                if arrow[0] != arrow[1] and arrow[0] != \"\" and arrow[1] != \"\"])\n    dels = [(arrow[0], count) for arrow, count in arrow_counter.items()\n            if arrow[0] != arrow[1] and arrow[0] != \"\" and arrow[1] == \"\"]\n    del_count = sum([count for arrow, count in dels])\n    ins_count = sum([count for arrow, count in arrow_counter.items()\n                if arrow[0] != arrow[1] and arrow[0] == \"\" and arrow[1] != \"\"])\n    total = sum([count for _, count in arrow_counter.items()])\n\n    fmt_pieces = []\n    fmt = \"{:15}{:<4}\\n\"\n    fmt_pieces.append(fmt.format(\"Substitutions\", sub_count))\n    fmt_pieces.append(fmt.format(\"Deletions\", del_count))\n    fmt_pieces.append(fmt.format(\"Insertions\", ins_count))\n    fmt_pieces.append(\"\\n\")\n    fmt_pieces.append(\"Deletions:\\n\")\n    fmt_pieces.extend([\"{:4}{:<4}\\n\".format(label, count)\n                       for label, count in\n                       sorted(dels, reverse=True, key=lambda x: x[1])])\n\n    return \"\".join(fmt_pieces)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fmt_confusion_matrix(hyps: Sequence[Sequence[str]],\n                         refs: Sequence[Sequence[str]],\n                         label_set: Set[str] = None,\n                         max_width: int = 25) -> str:\n    \"\"\" Formats a confusion matrix over substitutions, ignoring insertions\n    and deletions. \"\"\"\n\n    if not label_set:\n        # Then determine the label set by reading\n        raise NotImplementedError()\n\n    alignments = [min_edit_distance_align(ref, hyp)\n                  for hyp, ref in zip(hyps, refs)]\n\n    arrow_counter = Counter() # type: Dict[Tuple[str, str], int]\n    for alignment in alignments:\n        arrow_counter.update(alignment)\n\n    ref_total = Counter() # type: Dict[str, int]\n    for alignment in alignments:\n        ref_total.update([arrow[0] for arrow in alignment])\n\n    labels = [label for label, count\n              in sorted(ref_total.items(), key=lambda x: x[1], reverse=True)\n              if label != \"\"][:max_width]\n\n    format_pieces = []\n    fmt = \"{:3} \"*(len(labels)+1)\n    format_pieces.append(fmt.format(\" \", *labels))\n    fmt = \"{:3} \" + (\"{:<3} \" * (len(labels)))\n    for ref in labels:\n        # TODO\n        ref_results = [arrow_counter[(ref, hyp)] for hyp in labels]\n        format_pieces.append(fmt.format(ref, *ref_results))\n\n    return \"\\n\".join(format_pieces)", "response": "Formats a confusion matrix over substitutions ignoring insertions and deletions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat automatic hypotheses that have not previously been transcribed in LaTeX.", "response": "def fmt_latex_untranscribed(hyps: Sequence[Sequence[str]],\n                            prefixes: Sequence[str],\n                            out_fn: Path) -> None:\n    \"\"\" Formats automatic hypotheses that have not previously been\n    transcribed in LaTeX. \"\"\"\n\n    hyps_prefixes = list(zip(hyps, prefixes))\n    def utter_id_key(hyp_prefix):\n        hyp, prefix = hyp_prefix\n        prefix_split = prefix.split(\".\")\n        return (prefix_split[0], int(prefix_split[1]))\n    hyps_prefixes.sort(key=utter_id_key)\n\n    with out_fn.open(\"w\") as out_f:\n        print(latex_header(), file=out_f)\n        print(\"\\\\begin{document}\\n\"\n              \"\\\\begin{longtable}{ll}\", file=out_f)\n        print(r\"\\toprule\", file=out_f)\n        for hyp, prefix in hyps_prefixes:\n            print(\"Utterance ID: &\", prefix.strip().replace(r\"_\", r\"\\_\"), \"\\\\\\\\\", file=out_f)\n            print(\"Hypothesis: &\", hyp, r\"\\\\\", file=out_f)\n            print(\"\\\\midrule\", file=out_f)\n        print(r\"\\end{longtable}\", file=out_f)\n        print(r\"\\end{document}\", file=out_f)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef segment_into_chars(utterance: str) -> str:\n\n    if not isinstance(utterance, str):\n        raise TypeError(\"Input type must be a string. Got {}.\".format(type(utterance)))\n\n    utterance.strip()\n    utterance = utterance.replace(\" \", \"\")\n    return \" \".join(utterance)", "response": "Segments an utterance into space delimited characters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsegments an utterance into a list of tokens based on an inventory of tokens.", "response": "def segment_into_tokens(utterance: str, token_inventory: Iterable[str]):\n    \"\"\"\n    Segments an utterance (a string) into tokens based on an inventory of\n    tokens (a list or set of strings).\n\n    The approach: Given the rest of the utterance, find the largest token (in\n    character length) that is found in the token_inventory, and treat that as a\n    token before segmenting the rest of the string.\n\n    Note: Your orthography may open the door to ambiguities in the\n    segmentation. Hopefully not, but another alternative it to simply segment\n    on characters with segment_into_chars()\n    \"\"\"\n\n    if not isinstance(utterance, str):\n        raise TypeError(\"Input type must be a string. Got {}.\".format(type(utterance)))\n\n    # Token inventory needs to be hashable for speed\n    token_inventory = set(token_inventory)\n    # Get the size of the longest token in the inventory\n    max_len = len(sorted(list(token_inventory), key=lambda x: len(x))[-1])\n\n    def segment_token(utterance):\n        if utterance == \"\":\n            return \"\", \"\"\n\n        for i in range(max_len, 0, -1):\n            if utterance[:i] in token_inventory:\n                return utterance[:i], utterance[i:]\n        # If the next character is preventing segmentation, move on.\n        # TODO This needs to be logged with a warning on the first occurrence.\n        return \"\", utterance[1:]\n\n    tokens = []\n    head, tail = segment_token(utterance)\n    tokens.append(head)\n    while tail != \"\":\n        head, tail = segment_token(tail)\n        tokens.append(head)\n    tokens = [tok for tok in tokens if tok != \"\"]\n\n    return \" \".join(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a mapping from indices to labels.", "response": "def make_indices_to_labels(labels: Set[str]) -> Dict[int, str]:\n    \"\"\" Creates a mapping from indices to labels. \"\"\"\n\n    return {index: label for index, label in\n            enumerate([\"pad\"] + sorted(list(labels)))}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a list of sentences in french and preprocesses them.", "response": "def preprocess_french(trans, fr_nlp, remove_brackets_content=True):\n    \"\"\" Takes a list of sentences in french and preprocesses them.\"\"\"\n\n    if remove_brackets_content:\n        trans = pangloss.remove_content_in_brackets(trans, \"[]\")\n    # Not sure why I have to split and rejoin, but that fixes a Spacy token\n    # error.\n    trans = fr_nlp(\" \".join(trans.split()[:]))\n    #trans = fr_nlp(trans)\n    trans = \" \".join([token.lower_ for token in trans if not token.is_punct])\n\n    return trans"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef trim_wavs(org_wav_dir=ORG_WAV_DIR,\n              tgt_wav_dir=TGT_WAV_DIR,\n              org_xml_dir=ORG_XML_DIR):\n    \"\"\" Extracts sentence-level transcriptions, translations and wavs from the\n    Na Pangloss XML and WAV files. But otherwise doesn't preprocess them.\"\"\"\n\n    logging.info(\"Trimming wavs...\")\n\n    if not os.path.exists(os.path.join(tgt_wav_dir, \"TEXT\")):\n        os.makedirs(os.path.join(tgt_wav_dir, \"TEXT\"))\n    if not os.path.exists(os.path.join(tgt_wav_dir, \"WORDLIST\")):\n        os.makedirs(os.path.join(tgt_wav_dir, \"WORDLIST\"))\n\n    for fn in os.listdir(org_xml_dir):\n        path = os.path.join(org_xml_dir, fn)\n        prefix, _ = os.path.splitext(fn)\n\n        if os.path.isdir(path):\n            continue\n        if not path.endswith(\".xml\"):\n            continue\n\n        logging.info(\"Trimming wavs from {}\".format(fn))\n\n        rec_type, _, times, _ = pangloss.get_sents_times_and_translations(path)\n\n        # Extract the wavs given the times.\n        for i, (start_time, end_time) in enumerate(times):\n            if prefix.endswith(\"PLUSEGG\"):\n                in_wav_path = os.path.join(org_wav_dir, prefix.upper()[:-len(\"PLUSEGG\")]) + \".wav\"\n            else:\n                in_wav_path = os.path.join(org_wav_dir, prefix.upper()) + \".wav\"\n            headmic_path = os.path.join(org_wav_dir, prefix.upper()) + \"_HEADMIC.wav\"\n            if os.path.isfile(headmic_path):\n                in_wav_path = headmic_path\n\n            out_wav_path = os.path.join(tgt_wav_dir, rec_type, \"%s.%d.wav\" % (prefix, i))\n            if not os.path.isfile(in_wav_path):\n                raise PersephoneException(\"{} not a file.\".format(in_wav_path))\n            start_time = start_time * ureg.seconds\n            end_time = end_time * ureg.seconds\n            wav.trim_wav_ms(Path(in_wav_path), Path(out_wav_path),\n                            start_time.to(ureg.milliseconds).magnitude,\n                            end_time.to(ureg.milliseconds).magnitude)", "response": "Extracts sentence - level transcriptions translations and wavs from the\n    Na Pangloss XML and WAV files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare_labels(label_type, org_xml_dir=ORG_XML_DIR, label_dir=LABEL_DIR):\n\n    if not os.path.exists(os.path.join(label_dir, \"TEXT\")):\n        os.makedirs(os.path.join(label_dir, \"TEXT\"))\n    if not os.path.exists(os.path.join(label_dir, \"WORDLIST\")):\n        os.makedirs(os.path.join(label_dir, \"WORDLIST\"))\n\n    for path in Path(org_xml_dir).glob(\"*.xml\"):\n        fn = path.name\n        prefix, _ = os.path.splitext(fn)\n\n        rec_type, sents, _, _ = pangloss.get_sents_times_and_translations(str(path))\n        # Write the sentence transcriptions to file\n        sents = [preprocess_na(sent, label_type) for sent in sents]\n        for i, sent in enumerate(sents):\n            if sent.strip() == \"\":\n                # Then there's no transcription, so ignore this.\n                continue\n            out_fn = \"%s.%d.%s\" % (prefix, i, label_type)\n            sent_path = os.path.join(label_dir, rec_type, out_fn)\n            with open(sent_path, \"w\") as sent_f:\n                print(sent, file=sent_f)", "response": "Prepare the neural network output targets."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares the input features.", "response": "def prepare_feats(feat_type, org_wav_dir=ORG_WAV_DIR, feat_dir=FEAT_DIR, tgt_wav_dir=TGT_WAV_DIR,\n                  org_xml_dir=ORG_XML_DIR, label_dir=LABEL_DIR):\n    \"\"\" Prepare the input features.\"\"\"\n\n    if not os.path.isdir(TGT_DIR):\n        os.makedirs(TGT_DIR)\n\n    if not os.path.isdir(FEAT_DIR):\n        os.makedirs(FEAT_DIR)\n\n    if not os.path.isdir(os.path.join(feat_dir, \"WORDLIST\")):\n        os.makedirs(os.path.join(feat_dir, \"WORDLIST\"))\n    if not os.path.isdir(os.path.join(feat_dir, \"TEXT\")):\n        os.makedirs(os.path.join(feat_dir, \"TEXT\"))\n\n    # Extract utterances from WAVS.\n    trim_wavs(org_wav_dir=org_wav_dir,\n              tgt_wav_dir=tgt_wav_dir,\n              org_xml_dir=org_xml_dir)\n\n    # TODO Currently assumes that the wav trimming from XML has already been\n    # done.\n    prefixes = []\n    for fn in os.listdir(os.path.join(tgt_wav_dir, \"WORDLIST\")):\n        if fn.endswith(\".wav\"):\n            pre, _ = os.path.splitext(fn)\n            prefixes.append(os.path.join(\"WORDLIST\", pre))\n    for fn in os.listdir(os.path.join(tgt_wav_dir, \"TEXT\")):\n        if fn.endswith(\".wav\"):\n            pre, _ = os.path.splitext(fn)\n            prefixes.append(os.path.join(\"TEXT\", pre))\n\n    if feat_type==\"phonemes_onehot\":\n        import numpy as np\n        #prepare_labels(\"phonemes\")\n        for prefix in prefixes:\n            label_fn = os.path.join(label_dir, \"%s.phonemes\" % prefix)\n            out_fn = os.path.join(feat_dir, \"%s.phonemes_onehot\" %  prefix)\n            try:\n                with open(label_fn) as label_f:\n                    labels = label_f.readlines()[0].split()\n            except FileNotFoundError:\n                continue\n            indices = [PHONEMES_TO_INDICES[label] for label in labels]\n            one_hots = [[0]*len(PHONEMES) for _ in labels]\n            for i, index in enumerate(indices):\n                one_hots[i][index] = 1\n                one_hots = np.array(one_hots)\n                np.save(out_fn, one_hots)\n    else:\n        # Otherwise, \n        for prefix in prefixes:\n            # Convert the wave to 16k mono.\n            wav_fn = os.path.join(tgt_wav_dir, \"%s.wav\" % prefix)\n            mono16k_wav_fn = os.path.join(feat_dir, \"%s.wav\" % prefix)\n            if not os.path.isfile(mono16k_wav_fn):\n                logging.info(\"Normalizing wav {} to a 16k 16KHz mono {}\".format(\n                    wav_fn, mono16k_wav_fn))\n                feat_extract.convert_wav(wav_fn, mono16k_wav_fn)\n\n        # Extract features from the wavs.\n        feat_extract.from_dir(Path(os.path.join(feat_dir, \"WORDLIST\")), feat_type=feat_type)\n        feat_extract.from_dir(Path(os.path.join(feat_dir, \"TEXT\")), feat_type=feat_type)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the Na text prefixes.", "response": "def get_story_prefixes(label_type, label_dir=LABEL_DIR):\n    \"\"\" Gets the Na text prefixes. \"\"\"\n    prefixes = [prefix for prefix in os.listdir(os.path.join(label_dir, \"TEXT\"))\n                if prefix.endswith(\".%s\" % label_type)]\n    prefixes = [os.path.splitext(os.path.join(\"TEXT\", prefix))[0]\n                for prefix in prefixes]\n    return prefixes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_data_splits(label_type, train_rec_type=\"text_and_wordlist\", max_samples=1000,\n                     seed=0, tgt_dir=TGT_DIR):\n    \"\"\" Creates a file with a list of prefixes (identifiers) of utterances to\n    include in the test set. Test utterances must never be wordlists. Assumes\n    preprocessing of label dir has already been done.\"\"\"\n\n    feat_dir = os.path.join(tgt_dir, \"feat\")\n    test_prefix_fn=os.path.join(tgt_dir, \"test_prefixes.txt\")\n    valid_prefix_fn=os.path.join(tgt_dir, \"valid_prefixes.txt\")\n    with open(test_prefix_fn) as f:\n        prefixes = f.readlines()\n        test_prefixes = [(\"TEXT/\" + prefix).strip() for prefix in prefixes]\n    with open(valid_prefix_fn) as f:\n        prefixes = f.readlines()\n        valid_prefixes = [(\"TEXT/\" + prefix).strip() for prefix in prefixes]\n\n    label_dir = os.path.join(tgt_dir, \"label\")\n    prefixes = get_story_prefixes(label_type, label_dir=label_dir)\n    prefixes = list(set(prefixes) - set(valid_prefixes))\n    prefixes = list(set(prefixes) - set(test_prefixes))\n    prefixes = utils.filter_by_size(\n        feat_dir, prefixes, \"fbank\", max_samples)\n\n    if train_rec_type == \"text\":\n        train_prefixes = prefixes\n    else:\n        wordlist_prefixes = [prefix for prefix in os.listdir(os.path.join(label_dir, \"WORDLIST\"))\n                             if prefix.endswith(\"phonemes\")]\n        wordlist_prefixes = [os.path.splitext(os.path.join(\"WORDLIST\", prefix))[0]\n                             for prefix in wordlist_prefixes]\n        wordlist_prefixes = utils.filter_by_size(\n                feat_dir, wordlist_prefixes, \"fbank\", max_samples)\n        if train_rec_type == \"wordlist\":\n            prefixes = wordlist_prefixes\n        elif train_rec_type == \"text_and_wordlist\":\n            prefixes.extend(wordlist_prefixes)\n        else:\n            raise PersephoneException(\"train_rec_type='%s' not supported.\" % train_rec_type)\n        train_prefixes = prefixes\n    random.seed(seed)\n    random.shuffle(train_prefixes)\n\n    return train_prefixes, valid_prefixes, test_prefixes", "response": "Creates a file with a list of prefixes of utterances to\n    include in the test set and a list of words to train set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of the stories in the Na corpus.", "response": "def get_stories(label_type):\n    \"\"\" Returns a list of the stories in the Na corpus. \"\"\"\n\n    prefixes = get_story_prefixes(label_type)\n    texts = list(set([prefix.split(\".\")[0].split(\"/\")[1] for prefix in prefixes]))\n    return texts"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_data_splits(self, max_samples, valid_story=None, test_story=None):\n        # TODO Make this also work with wordlists.\n        if valid_story or test_story:\n            if not (valid_story and test_story):\n                raise PersephoneException(\n                    \"We need a valid story if we specify a test story \"\n                    \"and vice versa. This shouldn't be required but for \"\n                    \"now it is.\")\n\n            train, valid, test = make_story_splits(valid_story, test_story,\n                                                   max_samples,\n                                                   self.label_type,\n                                                   tgt_dir=str(self.tgt_dir))\n        else:\n            train, valid, test = make_data_splits(self.label_type,\n                                                  train_rec_type=self.train_rec_type,\n                                                  max_samples=max_samples,\n                                                  tgt_dir=str(self.tgt_dir))\n        self.train_prefixes = train\n        self.valid_prefixes = valid\n        self.test_prefixes = test", "response": "Split data into train valid and test groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the set of prefixes to a file in the test_story directory.", "response": "def output_story_prefixes(self):\n        \"\"\" Writes the set of prefixes to a file this is useful for pretty\n        printing in results.latex_output. \"\"\"\n\n        if not self.test_story:\n            raise NotImplementedError(\n                \"I want to write the prefixes to a file\"\n                \"called <test_story>_prefixes.txt, but there's no test_story.\")\n\n        fn = os.path.join(TGT_DIR, \"%s_prefixes.txt\" % self.test_story)\n        with open(fn, \"w\") as f:\n            for utter_id in self.test_prefixes:\n                print(utter_id.split(\"/\")[1], file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_sents_times_and_translations(xml_fn):\n\n    tree = ElementTree.parse(xml_fn)\n    root = tree.getroot()\n    if \"WORDLIST\" in root.tag or root.tag == \"TEXT\":\n        transcriptions = []\n        times = []\n        translations = []\n        for child in root:\n            # If it's a sentence or a word (this will be dictated by root_tag)\n            if child.tag == \"S\" or child.tag == \"W\":\n                forms = child.findall(\"FORM\")\n                if len(forms) > 1:\n                    # Assuming there is kindOf=\"phono\" available.\n                    for form in forms:\n                        if form.attrib[\"kindOf\"] == \"phono\":\n                            transcription = form.text\n                else:\n                    transcription = child.find(\"FORM\").text\n                audio_info = child.find(\"AUDIO\")\n                if audio_info is not None:\n                    start_time = float(audio_info.attrib[\"start\"])\n                    end_time = float(audio_info.attrib[\"end\"])\n                    time = (start_time, end_time)\n                    translation = [trans.text for trans in child.findall(\"TRANSL\")]\n                    transcriptions.append(transcription)\n                    times.append(time)\n                    translations.append(translation)\n\n        return root.tag, transcriptions, times, translations\n    logger.critical('the root tag, %s, does not contain \"WORDLIST\", and is not \"TEXT\"', root.tag)\n    assert False, root.tag", "response": "Given an XML filename loads the transcriptions their start end times and translations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an entry to data_files", "response": "def add_data_file(data_files, target, source):\n    \"\"\"Add an entry to data_files\"\"\"\n    for t, f in data_files:\n        if t == target:\n            break\n    else:\n        data_files.append((target, []))\n        f = data_files[-1][1]\n    if source not in f:\n        f.append(source)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nderive q home from the environment", "response": "def get_q_home(env):\n    \"\"\"Derive q home from the environment\"\"\"\n    q_home = env.get('QHOME')\n    if q_home:\n        return q_home\n    for v in ['VIRTUAL_ENV', 'HOME']:\n        prefix = env.get(v)\n        if prefix:\n            q_home = os.path.join(prefix, 'q')\n            if os.path.isdir(q_home):\n                return q_home\n    if WINDOWS:\n        q_home = os.path.join(env['SystemDrive'], r'\\q')\n        if os.path.isdir(q_home):\n            return q_home\n    raise RuntimeError('No suitable QHOME.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_q_version(q_home):\n    with open(os.path.join(q_home, 'q.k')) as f:\n        for line in f:\n            if line.startswith('k:'):\n                return line[2:5]\n    return '2.2'", "response": "Return version of q installed at q_home"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn console size as a tuple", "response": "def console_size(fd=1):\n    \"\"\"Return console size as a (LINES, COLUMNS) tuple\"\"\"\n    try:\n        import fcntl\n        import termios\n        import struct\n    except ImportError:\n        size = os.getenv('LINES', 25), os.getenv('COLUMNS', 80)\n    else:\n        size = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,\n                                               b'1234'))\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(q_prompt=False):\n    lines, columns = console_size()\n    q(r'\\c %d %d' % (lines, columns))\n    if len(sys.argv) > 1:\n        try:\n            q(r'\\l %s' % sys.argv[1])\n        except kerr as e:\n            print(e)\n            raise SystemExit(1)\n        else:\n            del sys.argv[1]\n    if q_prompt:\n        q()\n    ptp.run()", "response": "Run a prompt - toolkit based REPL"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_unit(a):\n    typestr = a.dtype.str\n    i = typestr.find('[')\n    if i == -1:\n        raise TypeError(\"Expected a datetime64 array, not %s\", a.dtype)\n    return typestr[i + 1: -1]", "response": "Extract the time unit from array s dtype"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef array(self, dtype=None):\n    t = self._t\n    # timestamp (12) through last enum (76)\n    if 11 <= t < 77:\n        dtype = dtypeof(self)\n        a = numpy.empty(len(self), dtype)\n        k2a(a, self)\n        return a\n    # table (98)\n    if t == 98:\n        if dtype is None:\n            dtype = list(zip(self.cols, (dtypeof(c) for c in self.flip.value)))\n        dtype = numpy.dtype(dtype)\n        a = numpy.empty(int(self.count), dtype)\n        for c in dtype.fields:\n            k2a(a[c], self[c])\n        return a\n    return numpy.array(list(self), dtype)", "response": "An implementation of __array__ ( self dtype = None )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select(self, columns=(), by=(), where=(), **kwds):\n        return self._seu('select', columns, by, where, kwds)", "response": "select from self\n\n        >>> t = q('([]a:1 2 3; b:10 20 30)')\n        >>> t.select('a', where='b > 20').show()\n        a\n        -\n        3"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute all the records in the table.", "response": "def exec_(self, columns=(), by=(), where=(), **kwds):\n        \"\"\"exec from self\n\n        >>> t = q('([]a:1 2 3; b:10 20 30)')\n        >>> t.exec_('a', where='b > 10').show()\n        2 3\n        \"\"\"\n        return self._seu('exec', columns, by, where, kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate from self >>> t = q('([]a:1 2 3; b:10 20 30)') >>> t.update('a*2', ... where='b > 20').show() # doctest: +NORMALIZE_WHITESPACE a b ---- 1 10 2 20 6 30", "response": "def update(self, columns=(), by=(), where=(), **kwds):\n        \"\"\"update from self\n\n        >>> t = q('([]a:1 2 3; b:10 20 30)')\n        >>> t.update('a*2',\n        ...          where='b > 20').show()  # doctest: +NORMALIZE_WHITESPACE\n        a b\n        ----\n        1 10\n        2 20\n        6 30\n        \"\"\"\n        return self._seu('update', columns, by, where, kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a q dictionary from a mapping object s .", "response": "def dict(cls, *args, **kwds):\n        \"\"\"Construct a q dictionary\n\n        K.dict() -> new empty q dictionary (q('()!()')\n        K.dict(mapping) -> new dictionary initialized from a mapping object's\n            (key, value) pairs\n        K.dict(iterable) -> new dictionary initialized from an iterable\n            yielding (key, value) pairs\n        K.dict(**kwargs) -> new dictionary initialized with the name=value\n            pairs in the keyword argument list.\n            For example: K.dict(one=1, two=2)\n        \"\"\"\n        if args:\n            if len(args) > 1:\n                raise TypeError(\"Too many positional arguments\")\n            x = args[0]\n            keys = []\n            vals = []\n            try:\n                x_keys = x.keys\n            except AttributeError:\n                for k, v in x:\n                    keys.append(k)\n                    vals.append(v)\n            else:\n                keys = x_keys()\n                vals = [x[k] for k in keys]\n            return q('!', keys, vals)\n        else:\n            if kwds:\n                keys = []\n                vals = []\n                for k, v in kwds.items():\n                    keys.append(k)\n                    vals.append(v)\n                return q('!', keys, vals)\n            else:\n                return q('()!()')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging lines into chunks according to q rules", "response": "def logical_lines(lines):\n    \"\"\"Merge lines into chunks according to q rules\"\"\"\n    if isinstance(lines, string_types):\n        lines = StringIO(lines)\n    buf = []\n    for line in lines:\n        if buf and not line.startswith(' '):\n            chunk = ''.join(buf).strip()\n            if chunk:\n                yield chunk\n            buf[:] = []\n\n        buf.append(line)\n    chunk = ''.join(buf).strip()\n    if chunk:\n        yield chunk"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning q code. Options: -l (dir|script) - pre-load database or script -h host:port - execute on the given host -o var - send output to a variable named var. -i var1,..,varN - input variables -1/-2 - redirect stdout/stderr", "response": "def q(line, cell=None, _ns=None):\n    \"\"\"Run q code.\n\n    Options:\n       -l (dir|script) - pre-load database or script\n       -h host:port - execute on the given host\n       -o var - send output to a variable named var.\n       -i var1,..,varN - input variables\n       -1/-2 - redirect stdout/stderr\n    \"\"\"\n    if cell is None:\n        return pyq.q(line)\n\n    if _ns is None:\n        _ns = vars(sys.modules['__main__'])\n    input = output = None\n    preload = []\n    outs = {}\n    try:\n        h = pyq.q('0i')\n        if line:\n            for opt, value in getopt(line.split(), \"h:l:o:i:12\")[0]:\n                if opt == '-l':\n                    preload.append(value)\n                elif opt == '-h':\n                    h = pyq.K(str(':' + value))\n                elif opt == '-o':\n                    output = str(value)  # (see #673)\n                elif opt == '-i':\n                    input = str(value).split(',')\n                elif opt in ('-1', '-2'):\n                    outs[int(opt[1])] = None\n        if outs:\n            if int(h) != 0:\n                raise ValueError(\"Cannot redirect remote std stream\")\n            for fd in outs:\n                tmpfd, tmpfile = mkstemp()\n                try:\n                    pyq.q(r'\\%d %s' % (fd, tmpfile))\n                finally:\n                    os.unlink(tmpfile)\n                    os.close(tmpfd)\n        r = None\n        for script in preload:\n            h(pyq.kp(r\"\\l \" + script))\n        if input is not None:\n            for chunk in logical_lines(cell):\n                func = \"{[%s]%s}\" % (';'.join(input), chunk)\n                args = tuple(_ns[i] for i in input)\n                if r != Q_NONE:\n                    r.show()\n                r = h((pyq.kp(func),) + args)\n                if outs:\n                    _forward_outputs(outs)\n        else:\n            for chunk in logical_lines(cell):\n                if r != Q_NONE:\n                    r.show()\n                r = h(pyq.kp(chunk))\n                if outs:\n                    _forward_outputs(outs)\n    except pyq.kerr as e:\n        print(\"'%s\" % e)\n    else:\n        if output is not None:\n            if output.startswith('q.'):\n                pyq.q('@[`.;;:;]', output[2:], r)\n            else:\n                _ns[output] = r\n        else:\n            if r != Q_NONE:\n                return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_ipython_extension(ipython):\n    ipython.register_magic_function(q, 'line_cell')\n    fmr = ipython.display_formatter.formatters['text/plain']\n    fmr.for_type(pyq.K, _q_formatter)", "response": "Register %q and %%q magics and pretty display for K objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of tokens for the prompt", "response": "def get_prompt_tokens(_):\n    \"\"\"Return a list of tokens for the prompt\"\"\"\n    namespace = q(r'\\d')\n    if namespace == '.':\n        namespace = ''\n    return [(Token.Generic.Prompt, 'q%s)' % namespace)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding completions for the current document.", "response": "def get_completions(self, document, complete_event):\n        \"\"\"Yield completions\"\"\"\n        # Detect a file handle\n        m = HSYM_RE.match(document.text_before_cursor)\n        if m:\n            text = m.group(1)\n            doc = Document(text, len(text))\n            for c in self.path_completer.get_completions(doc, complete_event):\n                yield c\n        else:\n            # Get word/text before cursor.\n            word_before_cursor = document.get_word_before_cursor(False)\n            for words, meta in self.words_info:\n                for a in words:\n                    if a.startswith(word_before_cursor):\n                        yield Completion(a, -len(word_before_cursor),\n                                         display_meta=meta)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate a snuggs expression.", "response": "def eval(source, kwd_dict=None, **kwds):\n    \"\"\"Evaluate a snuggs expression.\n\n    Parameters\n    ----------\n    source : str\n        Expression source.\n    kwd_dict : dict\n        A dict of items that form the evaluation context. Deprecated.\n    kwds : dict\n        A dict of items that form the valuation context.\n\n    Returns\n    -------\n    object\n\n    \"\"\"\n    kwd_dict = kwd_dict or kwds\n    with ctx(kwd_dict):\n        return handleLine(source)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_matchers(self, crontab):\n        '''\n        This constructs the full matcher struct.\n        '''\n        crontab = _aliases.get(crontab, crontab)\n        ct = crontab.split()\n        if len(ct) == 5:\n            ct.insert(0, '0')\n            ct.append('*')\n        elif len(ct) == 6:\n            ct.insert(0, '0')\n        _assert(len(ct) == 7,\n            \"improper number of cron entries specified; got %i need 5 to 7\"%(len(ct,)))\n\n        matchers = [_Matcher(which, entry) for which, entry in enumerate(ct)]\n\n        return Matcher(*matchers)", "response": "This constructs the full matcher struct."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next(self, now=None, increments=_increments, delta=True, default_utc=WARN_CHANGE):\n        '''\n        How long to wait in seconds before this crontab entry can next be\n        executed.\n        '''\n        if default_utc is WARN_CHANGE and (isinstance(now, _number_types) or (now and not now.tzinfo) or now is None):\n            warnings.warn(WARNING_CHANGE_MESSAGE, FutureWarning, 2)\n            default_utc = False\n\n        now = now or (datetime.utcnow() if default_utc and default_utc is not WARN_CHANGE else datetime.now())\n        if isinstance(now, _number_types):\n            now = datetime.utcfromtimestamp(now) if default_utc else datetime.fromtimestamp(now)\n\n        # handle timezones if the datetime object has a timezone and get a\n        # reasonable future/past start time\n        onow, now = now, now.replace(tzinfo=None)\n        tz = onow.tzinfo\n        future = now.replace(microsecond=0) + increments[0]()\n        if future < now:\n            # we are going backwards...\n            _test = lambda: future.year < self.matchers.year\n            if now.microsecond:\n                future = now.replace(microsecond=0)\n        else:\n            # we are going forwards\n            _test = lambda: self.matchers.year < future.year\n\n        # Start from the year and work our way down. Any time we increment a\n        # higher-magnitude value, we reset all lower-magnitude values. This\n        # gets us performance without sacrificing correctness. Still more\n        # complicated than a brute-force approach, but also orders of\n        # magnitude faster in basically all cases.\n        to_test = ENTRIES - 1\n        while to_test >= 0:\n            if not self._test_match(to_test, future):\n                inc = increments[to_test](future, self.matchers)\n                future += inc\n                for i in xrange(0, to_test):\n                    future = increments[ENTRIES+i](future, inc)\n                try:\n                    if _test():\n                        return None\n                except:\n                    print(future, type(future), type(inc))\n                    raise\n                to_test = ENTRIES-1\n                continue\n            to_test -= 1\n\n        # verify the match\n        match = [self._test_match(i, future) for i in xrange(ENTRIES)]\n        _assert(all(match),\n            \"\\nYou have discovered a bug with crontab, please notify the\\n\" \\\n            \"author with the following information:\\n\" \\\n            \"crontab: %r\\n\" \\\n            \"now: %r\", ' '.join(m.input for m in self.matchers), now)\n\n        if not delta:\n            onow = now = datetime(1970, 1, 1)\n\n        delay = future - now\n        if tz:\n            delay += _fix_none(onow.utcoffset())\n            if hasattr(tz, 'localize'):\n                delay -= _fix_none(tz.localize(future).utcoffset())\n            else:\n                delay -= _fix_none(future.replace(tzinfo=tz).utcoffset())\n\n        return delay.days * 86400 + delay.seconds + delay.microseconds / 1000000.", "response": "Get the next crontab entry in the crontab."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _tostring(value):\n        '''Convert value to XML compatible string'''\n        if value is True:\n            value = 'true'\n        elif value is False:\n            value = 'false'\n        elif value is None:\n            value = ''\n        return unicode(value)", "response": "Convert value to XML compatible string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fromstring(value):\n        '''Convert XML string value to None, boolean, int or float'''\n        # NOTE: Is this even possible ?\n        if value is None:\n            return None\n\n        # FIXME: In XML, booleans are either 0/false or 1/true (lower-case !)\n        if value.lower() == 'true':\n            return True\n        elif value.lower() == 'false':\n            return False\n\n        # FIXME: Using int() or float() is eating whitespaces unintendedly here\n        try:\n            return int(value)\n        except ValueError:\n            pass\n\n        try:\n            # Test for infinity and NaN values\n            if float('-inf') < float(value) < float('inf'):\n                return float(value)\n        except ValueError:\n            pass\n\n        return value", "response": "Convert XML string value to None boolean int or float"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef etree(self, data, root=None):\n        '''Convert data structure into a list of etree.Element'''\n        result = self.list() if root is None else root\n        if isinstance(data, (self.dict, dict)):\n            for key, value in data.items():\n                value_is_list = isinstance(value, (self.list, list))\n                value_is_dict = isinstance(value, (self.dict, dict))\n                # Add attributes and text to result (if root)\n                if root is not None:\n                    # Handle attribute prefixes (BadgerFish)\n                    if self.attr_prefix is not None:\n                        if key.startswith(self.attr_prefix):\n                            key = key.lstrip(self.attr_prefix)\n                            # @xmlns: {$: xxx, svg: yyy} becomes xmlns=\"xxx\" xmlns:svg=\"yyy\"\n                            if value_is_dict:\n                                raise ValueError('XML namespaces not yet supported')\n                            else:\n                                result.set(key, self._tostring(value))\n                            continue\n                    # Handle text content (BadgerFish, GData)\n                    if self.text_content is not None:\n                        if key == self.text_content:\n                            result.text = self._tostring(value)\n                            continue\n                    # Treat scalars as text content, not children (GData)\n                    if self.attr_prefix is None and self.text_content is not None:\n                        if not value_is_dict and not value_is_list:\n                            result.set(key, self._tostring(value))\n                            continue\n                # Add other keys as one or more children\n                values = value if value_is_list else [value]\n                for value in values:\n                    elem = self.element(key)\n                    if elem is None:\n                        continue\n                    result.append(elem)\n                    # Treat scalars as text content, not children (Parker)\n                    if not isinstance(value, (self.dict, dict, self.list, list)):\n                        if self.text_content:\n                            value = {self.text_content: value}\n                    self.etree(value, root=elem)\n        else:\n            if self.text_content is None and root is not None:\n                root.text = self._tostring(data)\n            else:\n                elem = self.element(self._tostring(data))\n                if elem is not None:\n                    result.append(elem)\n        return result", "response": "Convert a dict into a list of etree. Element"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts etree. Element into a dictionary", "response": "def data(self, root):\n        '''Convert etree.Element into a dictionary'''\n        value = self.dict()\n        children = [node for node in root if isinstance(node.tag, basestring)]\n        for attr, attrval in root.attrib.items():\n            attr = attr if self.attr_prefix is None else self.attr_prefix + attr\n            value[attr] = self._fromstring(attrval)\n        if root.text and self.text_content is not None:\n            text = root.text.strip()\n            if text:\n                if self.simple_text and len(children) == len(root.attrib) == 0:\n                    value = self._fromstring(text)\n                else:\n                    value[self.text_content] = self._fromstring(text)\n        count = Counter(child.tag for child in children)\n        for child in children:\n            if count[child.tag] == 1:\n                value.update(self.data(child))\n            else:\n                result = value.setdefault(child.tag, self.list())\n                result += self.data(child).values()\n        # if simple_text, elements with no children nor attrs become '', not {}\n        if isinstance(value, dict) and not value and self.simple_text:\n            value = ''\n        return self.dict([(root.tag, value)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data(self, root, preserve_root=False):\n        '''Convert etree.Element into a dictionary'''\n        # If preserve_root is False, return the root element. This is easiest\n        # done by wrapping the XML in a dummy root element that will be ignored.\n        if preserve_root:\n            new_root = root.makeelement('dummy_root', {})\n            new_root.insert(0, root)\n            root = new_root\n\n        # If no children, just return the text\n        children = [node for node in root if isinstance(node.tag, basestring)]\n        if len(children) == 0:\n            return self._fromstring(root.text)\n\n        # Element names become object properties\n        count = Counter(child.tag for child in children)\n        result = self.dict()\n        for child in children:\n            if count[child.tag] == 1:\n                result[child.tag] = self.data(child)\n            else:\n                result.setdefault(child.tag, self.list()).append(self.data(child))\n\n        return result", "response": "Convert etree. Element into a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts etree. Element into a dictionary", "response": "def data(self, root):\n        '''Convert etree.Element into a dictionary'''\n\n        value = self.dict()\n\n        # Add attributes specific 'attributes' key\n        if root.attrib:\n            value['attributes'] = self.dict()\n            for attr, attrval in root.attrib.items():\n                value['attributes'][unicode(attr)] = self._fromstring(attrval)\n\n        # Add children to specific 'children' key\n        children_list = self.list()\n        children = [node for node in root if isinstance(node.tag, basestring)]\n\n        # Add root text\n        if root.text and self.text_content is not None:\n            text = root.text.strip()\n            if text:\n                if self.simple_text and len(children) == len(root.attrib) == 0:\n                    value = self._fromstring(text)\n                else:\n                    children_list = [self._fromstring(text), ]\n\n        for child in children:\n            child_data = self.data(child)\n            children_list.append(child_data)\n\n        # Flatten children\n        if len(root.attrib) == 0 and len(children_list) == 1:\n            value = children_list[0]\n\n        elif len(children_list) > 0:\n            value['children'] = children_list\n\n        return self.dict([(unicode(root.tag), value)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef etree(self, data, root=None):\n        '''Convert data structure into a list of etree.Element'''\n        result = self.list() if root is None else root\n        if isinstance(data, (self.dict, dict)):\n            for key, value in data.items():\n                if isinstance(value, (self.dict, dict)):\n                    elem = self.element(key)\n                    if elem is None:\n                        continue\n                    result.append(elem)\n\n                    if 'attributes' in value:\n                        for k, v in value['attributes'].items():\n                            elem.set(k, self._tostring(v))\n                    # else:\n                    #     raise ValueError('Cobra requires \"attributes\" key for each element')\n\n                    if 'children' in value:\n                        for v in value['children']:\n                            self.etree(v, root=elem)\n                else:\n                    elem = self.element(key)\n                    if elem is None:\n                        continue\n                    elem.text = self._tostring(value)\n                    result.append(elem)\n        else:\n            if root is not None:\n                root.text = self._tostring(data)\n            else:\n                elem = self.element(self._tostring(data))\n                if elem is not None:\n                    result.append(elem)\n\n        return result", "response": "Convert data structure into a list of etree. Element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef who_likes(obj):\n    return Like.objects.filter(\n        receiver_content_type=ContentType.objects.get_for_model(obj),\n        receiver_object_id=obj.pk\n    )", "response": "Return a queryset of objects who likes obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of likes for the given user.", "response": "def likes(user, *models):\n    \"\"\"\n    Usage:\n        {% likes user as var %}\n    Or\n        {% likes user [model1, model2] as var %}\n    \"\"\"\n    content_types = []\n    model_list = models or settings.PINAX_LIKES_LIKABLE_MODELS.keys()\n    for model in model_list:\n        if not _allowed(model):\n            continue\n        app, model = model.split(\".\")\n        content_types.append(\n            ContentType.objects.get(app_label=app, model__iexact=model)\n        )\n    return Like.objects.filter(sender=user, receiver_content_type__in=content_types)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncounts the number of likes for the given object", "response": "def likes_count(obj):\n    \"\"\"\n    Usage:\n\n        {% likes_count obj %}\n    or\n        {% likes_count obj as var %}\n    or\n        {{ obj|likes_count }}\n    \"\"\"\n    return Like.objects.filter(\n        receiver_content_type=ContentType.objects.get_for_model(obj),\n        receiver_object_id=obj.pk\n    ).count()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a single like.", "response": "def render_like(parser, token):\n    \"\"\"\n    {% likes user as like_list %}\n    <ul>\n        {% for like in like_list %}\n            <li>{% render_like like %}</li>\n        {% endfor %}\n    </ul>\n    \"\"\"\n\n    tokens = token.split_contents()\n    var = tokens[1]\n\n    return LikeRenderer(var)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef liked(parser, token):\n    tag, objects, _, user, _, varname = token.split_contents()\n    return LikedObjectsNode(objects, user, varname)", "response": "A helper function to get a list of objects that are liked by a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef by_col(cls, df, cols, w=None, inplace=False, pvalue='sim', outvals=None, **stat_kws):\n        if outvals is None:\n            outvals = []\n            outvals.extend(['bb', 'p_sim_bw', 'p_sim_bb'])\n            pvalue = ''\n        return _univariate_handler(df, cols, w=w, inplace=inplace, pvalue=pvalue,\n                                   outvals=outvals, stat=cls,\n                                   swapname='bw', **stat_kws)", "response": "This function computes a Join_Count statistic on a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Moran_BV_matrix(variables, w, permutations=0, varnames=None):\n    try:\n        # check if pandas is installed\n        import pandas\n        if isinstance(variables, pandas.DataFrame):\n            # if yes use variables as df and convert to numpy_array\n            varnames = pandas.Index.tolist(variables.columns)\n            variables_n = []\n            for var in varnames:\n                variables_n.append(variables[str(var)].values)\n        else:\n            variables_n = variables\n    except ImportError:\n        variables_n = variables\n    \n    results = _Moran_BV_Matrix_array(variables=variables_n, w=w,\n                                     permutations=permutations,\n                                     varnames=varnames)\n    return results", "response": "Bivariate Moran Matrix\n\n    Calculates bivariate Moran between all pairs of a set of variables.\n\n    Parameters\n    ----------\n    variables    : array or pandas.DataFrame\n                   sequence of variables to be assessed\n    w            : W\n                   a spatial weights object\n    permutations : int\n                   number of permutations\n    varnames     : list, optional if variables is an array\n                   Strings for variable names. Will add an\n                   attribute to `Moran_BV` objects in results needed for plotting\n                   in `splot` or `.plot()`. Default =None.\n                   Note: If variables is a `pandas.DataFrame` varnames\n                   will automatically be generated\n    Returns\n    -------\n    results      : dictionary\n                   (i,  j) is the key for the pair of variables, values are\n                   the Moran_BV objects.\n\n    Examples\n    --------\n    \n    open dbf\n\n    >>> import libpysal\n    >>> f = libpysal.io.open(libpysal.examples.get_path(\"sids2.dbf\"))\n\n    pull of selected variables from dbf and create numpy arrays for each\n\n    >>> varnames = ['SIDR74',  'SIDR79',  'NWR74',  'NWR79']\n    >>> vars = [np.array(f.by_col[var]) for var in varnames]\n\n    create a contiguity matrix from an external gal file\n\n    >>> w = libpysal.io.open(libpysal.examples.get_path(\"sids2.gal\")).read()\n\n    create an instance of Moran_BV_matrix\n\n    >>> from esda.moran import Moran_BV_matrix\n    >>> res = Moran_BV_matrix(vars,  w,  varnames = varnames)\n\n    check values\n\n    >>> round(res[(0,  1)].I,7)\n    0.1936261\n    >>> round(res[(3,  0)].I,7)\n    0.3770138"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbasing calculation for MORAN_BV_Matrix_array", "response": "def _Moran_BV_Matrix_array(variables, w, permutations=0, varnames=None):\n    \"\"\"\n    Base calculation for MORAN_BV_Matrix\n    \"\"\"\n    if varnames is None:\n        varnames = ['x{}'.format(i) for i in range(k)]\n\n    k = len(variables)\n    rk = list(range(0, k - 1))\n    results = {}\n    for i in rk:\n        for j in range(i + 1, k):\n            y1 = variables[i]\n            y2 = variables[j]\n            results[i, j] = Moran_BV(y1, y2, w, permutations=permutations)\n            results[j, i] = Moran_BV(y2, y1, w, permutations=permutations)\n            results[i, j].varnames = {'x': varnames[i], 'y': varnames[j]}\n            results[j, i].varnames = {'x': varnames[j], 'y': varnames[i]}\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to compute a Moran_BV statistic on a dataframe Arguments --------- df : pandas.DataFrame a pandas dataframe with a geometry column X : list of strings column name or list of column names to use as X values to compute the bivariate statistic. If no Y is provided, pairwise comparisons among these variates are used instead. Y : list of strings column name or list of column names to use as Y values to compute the bivariate statistic. if no Y is provided, pariwise comparisons among the X variates are used instead. w : pysal weights object a weights object aligned with the dataframe. If not provided, this is searched for in the dataframe's metadata inplace : bool a boolean denoting whether to operate on the dataframe inplace or to return a series contaning the results of the computation. If operating inplace, the derived columns will be named 'column_moran_local' pvalue : string a string denoting which pvalue should be returned. Refer to the the Moran_BV statistic's documentation for available p-values outvals : list of strings list of arbitrary attributes to return as columns from the Moran_BV statistic **stat_kws : keyword arguments options to pass to the underlying statistic. For this, see the documentation for the Moran_BV statistic. Returns -------- If inplace, None, and operation is conducted on dataframe in memory. Otherwise, returns a copy of the dataframe with the relevant columns attached. See Also --------- For further documentation, refer to the Moran_BV class in pysal.esda", "response": "def by_col(cls, df, x, y=None, w=None, inplace=False, pvalue='sim', outvals=None, **stat_kws):\n        \"\"\"\n        Function to compute a Moran_BV statistic on a dataframe\n\n        Arguments\n        ---------\n        df          :   pandas.DataFrame\n                        a pandas dataframe with a geometry column\n        X           :   list of strings\n                        column name or list of column names to use as X values to compute\n                        the bivariate statistic. If no Y is provided, pairwise comparisons\n                        among these variates are used instead.\n        Y           :   list of strings\n                        column name or list of column names to use as Y values to compute\n                        the bivariate statistic. if no Y is provided, pariwise comparisons\n                        among the X variates are used instead.\n        w           :   pysal weights object\n                        a weights object aligned with the dataframe. If not provided, this\n                        is searched for in the dataframe's metadata\n        inplace     :   bool\n                        a boolean denoting whether to operate on the dataframe inplace or to\n                        return a series contaning the results of the computation. If\n                        operating inplace, the derived columns will be named\n                        'column_moran_local'\n        pvalue      :   string\n                        a string denoting which pvalue should be returned. Refer to the\n                        the Moran_BV statistic's documentation for available p-values\n        outvals     :   list of strings\n                        list of arbitrary attributes to return as columns from the\n                        Moran_BV statistic\n        **stat_kws  :   keyword arguments\n                        options to pass to the underlying statistic. For this, see the\n                        documentation for the Moran_BV statistic.\n\n\n        Returns\n        --------\n        If inplace, None, and operation is conducted on dataframe in memory. Otherwise,\n        returns a copy of the dataframe with the relevant columns attached.\n\n        See Also\n        ---------\n        For further documentation, refer to the Moran_BV class in pysal.esda\n        \"\"\"\n        return _bivariate_handler(df, x, y=y, w=w, inplace=inplace,\n                                  pvalue = pvalue, outvals = outvals,\n                                  swapname=cls.__name__.lower(), stat=cls,**stat_kws)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to compute a Moran_Rate statistic on a dataframe Arguments --------- df : pandas.DataFrame a pandas dataframe with a geometry column events : string or list of strings one or more names where events are stored populations : string or list of strings one or more names where the populations corresponding to the events are stored. If one population column is provided, it is used for all event columns. If more than one population column is provided but there is not a population for every event column, an exception will be raised. w : pysal weights object a weights object aligned with the dataframe. If not provided, this is searched for in the dataframe's metadata inplace : bool a boolean denoting whether to operate on the dataframe inplace or to return a series contaning the results of the computation. If operating inplace, the derived columns will be named 'column_moran_rate' pvalue : string a string denoting which pvalue should be returned. Refer to the the Moran_Rate statistic's documentation for available p-values outvals : list of strings list of arbitrary attributes to return as columns from the Moran_Rate statistic **stat_kws : keyword arguments options to pass to the underlying statistic. For this, see the documentation for the Moran_Rate statistic. Returns -------- If inplace, None, and operation is conducted on dataframe in memory. Otherwise, returns a copy of the dataframe with the relevant columns attached. See Also --------- For further documentation, refer to the Moran_Rate class in pysal.esda", "response": "def by_col(cls, df, events, populations, w=None, inplace=False,\n               pvalue='sim', outvals=None, swapname='',  **stat_kws):\n        \"\"\"\n        Function to compute a Moran_Rate statistic on a dataframe\n\n        Arguments\n        ---------\n        df          :   pandas.DataFrame\n                        a pandas dataframe with a geometry column\n        events      :   string or  list of strings\n                        one or more names where events are stored\n        populations :   string or list of strings\n                        one or more names where the populations corresponding to the\n                        events are stored. If one population column is provided, it is\n                        used for all event columns. If more than one population column\n                        is provided but there is not a population for every event\n                        column, an exception will be raised.\n        w           :   pysal weights object\n                        a weights object aligned with the dataframe. If not provided, this\n                        is searched for in the dataframe's metadata\n        inplace     :   bool\n                        a boolean denoting whether to operate on the dataframe inplace or to\n                        return a series contaning the results of the computation. If\n                        operating inplace, the derived columns will be named\n                        'column_moran_rate'\n        pvalue      :   string\n                        a string denoting which pvalue should be returned. Refer to the\n                        the Moran_Rate statistic's documentation for available p-values\n        outvals     :   list of strings\n                        list of arbitrary attributes to return as columns from the\n                        Moran_Rate statistic\n        **stat_kws  :   keyword arguments\n                        options to pass to the underlying statistic. For this, see the\n                        documentation for the Moran_Rate statistic.\n\n        Returns\n        --------\n        If inplace, None, and operation is conducted on dataframe in memory. Otherwise,\n        returns a copy of the dataframe with the relevant columns attached.\n\n        See Also\n        ---------\n        For further documentation, refer to the Moran_Rate class in pysal.esda\n        \"\"\"\n        if not inplace:\n            new = df.copy()\n            cls.by_col(new, events, populations, w=w, inplace=True,\n                              pvalue=pvalue, outvals=outvals, swapname=swapname,\n                              **stat_kws)\n            return new\n        if isinstance(events, str):\n            events = [events]\n        if isinstance(populations, str):\n            populations = [populations]\n        if len(populations) < len(events):\n            populations = populations * len(events)\n        if len(events) != len(populations):\n            raise ValueError('There is not a one-to-one matching between events and '\n                              'populations!\\nEvents: {}\\n\\nPopulations:'\n                              ' {}'.format(events, populations))\n        adjusted = stat_kws.pop('adjusted', True)\n\n        if isinstance(adjusted, bool):\n            adjusted = [adjusted] * len(events)\n        if swapname is '':\n            swapname = cls.__name__.lower()\n\n        rates = [assuncao_rate(df[e], df[pop]) if adj\n                 else df[e].astype(float) / df[pop]\n                 for e,pop,adj in zip(events, populations, adjusted)]\n        names = ['-'.join((e,p)) for e,p in zip(events, populations)]\n        out_df = df.copy()\n        rate_df = out_df.from_items(list(zip(names, rates))) #trick to avoid importing pandas\n        stat_df = _univariate_handler(rate_df, names, w=w, inplace=False,\n                                      pvalue = pvalue, outvals = outvals,\n                                      swapname=swapname,\n                                      stat=Moran, #how would this get done w/super?\n                                      **stat_kws)\n        for col in stat_df.columns:\n            df[col] = stat_df[col]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __crand(self):\n        lisas = np.zeros((self.n, self.permutations))\n        n_1 = self.n - 1\n        prange = list(range(self.permutations))\n        k = self.w.max_neighbors + 1\n        nn = self.n - 1\n        rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n        ids = np.arange(self.w.n)\n        ido = self.w.id_order\n        w = [self.w.weights[ido[i]] for i in ids]\n        wc = [self.w.cardinalities[ido[i]] for i in ids]\n\n        zx = self.zx\n        zy = self.zy\n        for i in range(self.w.n):\n            idsi = ids[ids != i]\n            np.random.shuffle(idsi)\n            tmp = zy[idsi[rids[:, 0:wc[i]]]]\n            lisas[i] = zx[i] * (w[i] * tmp).sum(1)\n        self.rlisas = (n_1 / self.den) * lisas", "response": "This function generates a conditional randomization of the set of entries for each observation i with ni neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flatten(l, unique=True):\n    l = reduce(lambda x, y: x + y, l)\n    if not unique:\n        return list(l)\n    return list(set(l))", "response": "flatten a list of lists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sum_by_n(d, w, n):\n    t = len(d)\n    h = t // n #must be floor!\n    d = d * w\n    return np.array([sum(d[i: i + h]) for i in range(0, t, h)])", "response": "A utility function to summarize a data array into n values by weighting the array with another weight array w."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef indirect_age_standardization(e, b, s_e, s_b, n, alpha=0.05):\n    smr = standardized_mortality_ratio(e, b, s_e, s_b, n)\n    s_r_all = sum(s_e * 1.0) / sum(s_b * 1.0)\n    adjusted_r = s_r_all * smr\n\n    e_by_n = sum_by_n(e, 1.0, n)\n    log_smr = np.log(smr)\n    log_smr_sd = 1.0 / np.sqrt(e_by_n)\n    norm_thres = norm.ppf(1 - 0.5 * alpha)\n    log_smr_lower = log_smr - norm_thres * log_smr_sd\n    log_smr_upper = log_smr + norm_thres * log_smr_sd\n    smr_lower = np.exp(log_smr_lower) * s_r_all\n    smr_upper = np.exp(log_smr_upper) * s_r_all\n    res = list(zip(adjusted_r, smr_lower, smr_upper))\n    return res", "response": "A utility function to compute rate through an indirect age standardization of a standard population."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef by_col(cls, df, e,b, inplace=False, **kwargs):\n        if not inplace:\n            new = df.copy()\n            cls.by_col(new, e, b, inplace=True, **kwargs)\n            return new\n        if isinstance(e, str):\n            e = [e]\n        if isinstance(b, str):\n            b = [b]\n        if len(b) == 1 and len(e) > 1:\n            b = b * len(e)\n        try:\n            assert len(e) == len(b)\n        except AssertionError:\n            raise ValueError('There is no one-to-one mapping between event'\n                             ' variable and population at risk variable!')\n        for ei, bi in zip(e,b):\n            ename = ei\n            bname = bi\n            ei = df[ename]\n            bi = df[bname]\n            outcol = '_'.join(('-'.join((ename, bname)), cls.__name__.lower()))\n            df[outcol] = cls(ei, bi, **kwargs).r", "response": "Compute smoothing by columns in a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes smoothing by columns in a dataframe.", "response": "def by_col(cls, df, e,b, w=None, inplace=False, **kwargs):\n        \"\"\"\n        Compute smoothing by columns in a dataframe.\n\n        Parameters\n        -----------\n        df      :  pandas.DataFrame\n                   a dataframe containing the data to be smoothed\n        e       :  string or list of strings\n                   the name or names of columns containing event variables to be\n                   smoothed\n        b       :  string or list of strings\n                   the name or names of columns containing the population\n                   variables to be smoothed\n        w       :  pysal.weights.W or list of pysal.weights.W\n                   the spatial weights object or objects to use with the\n                   event-population pairs. If not provided and a weights object\n                   is in the dataframe's metadata, that weights object will be\n                   used.\n        inplace :  bool\n                   a flag denoting whether to output a copy of `df` with the\n                   relevant smoothed columns appended, or to append the columns\n                   directly to `df` itself.\n        **kwargs:  optional keyword arguments\n                   optional keyword options that are passed directly to the\n                   smoother.\n\n        Returns\n        ---------\n        a copy of `df` containing the columns. Or, if `inplace`, this returns\n        None, but implicitly adds columns to `df`.\n        \"\"\"\n        if not inplace:\n            new = df.copy()\n            cls.by_col(new, e, b, w=w, inplace=True, **kwargs)\n            return new\n        if isinstance(e, str):\n            e = [e]\n        if isinstance(b, str):\n            b = [b]\n        if w is None:\n            found = False\n            for k in df._metadata:\n                w = df.__dict__.get(w, None)\n                if isinstance(w, W):\n                    found = True\n            if not found:\n                raise Exception('Weights not provided and no weights attached to frame!'\n                                    ' Please provide a weight or attach a weight to the'\n                                    ' dataframe')\n        if isinstance(w, W):\n            w = [w] * len(e)\n        if len(b) == 1 and len(e) > 1:\n            b = b * len(e)\n        try:\n            assert len(e) == len(b)\n        except AssertionError:\n            raise ValueError('There is no one-to-one mapping between event'\n                             ' variable and population at risk variable!')\n        for ei, bi, wi in zip(e, b, w):\n            ename = ei\n            bname = bi\n            ei = df[ename]\n            bi = df[bname]\n            outcol = '_'.join(('-'.join((ename, bname)), cls.__name__.lower()))\n            df[outcol] = cls(ei, bi, w=wi, **kwargs).r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the smoothing by columns in a dataframe.", "response": "def by_col(cls, df, e,b, w=None, s=None, **kwargs):\n        \"\"\"\n        Compute smoothing by columns in a dataframe.\n\n        Parameters\n        -----------\n        df      :  pandas.DataFrame\n                   a dataframe containing the data to be smoothed\n        e       :  string or list of strings\n                   the name or names of columns containing event variables to be\n                   smoothed\n        b       :  string or list of strings\n                   the name or names of columns containing the population\n                   variables to be smoothed\n        w       :  pysal.weights.W or list of pysal.weights.W\n                   the spatial weights object or objects to use with the\n                   event-population pairs. If not provided and a weights object\n                   is in the dataframe's metadata, that weights object will be\n                   used.\n        s       :  string or list of strings\n                   the name or names of columns to use as a standard population\n                   variable for the events `e` and at-risk populations `b`.\n        inplace :  bool\n                   a flag denoting whether to output a copy of `df` with the\n                   relevant smoothed columns appended, or to append the columns\n                   directly to `df` itself.\n        **kwargs:  optional keyword arguments\n                   optional keyword options that are passed directly to the\n                   smoother.\n\n        Returns\n        ---------\n        a copy of `df` containing the columns. Or, if `inplace`, this returns\n        None, but implicitly adds columns to `df`.\n        \"\"\"\n        if s is None:\n            raise Exception('Standard population variable \"s\" must be supplied.')\n        import pandas as pd\n        if isinstance(e, str):\n            e = [e]\n        if isinstance(b, str):\n            b = [b]\n        if isinstance(s, str):\n            s = [s]\n        if w is None:\n            found = False\n            for k in df._metadata:\n                w = df.__dict__.get(w, None)\n                if isinstance(w, W):\n                    found = True\n                    break\n            if not found:\n                raise Exception('Weights not provided and no weights attached to frame!'\n                                    ' Please provide a weight or attach a weight to the'\n                                    ' dataframe.')\n        if isinstance(w, W):\n            w = [w] * len(e)\n        if not all(isinstance(wi, W) for wi in w):\n            raise Exception('Weights object must be an instance of '\n                            ' libpysal.weights.W!')\n        b = b * len(e) if len(b) == 1 and len(e) > 1 else b\n        s = s * len(e) if len(s) == 1 and len(e) > 1 else s\n        try:\n            assert len(e) == len(b)\n            assert len(e) == len(s)\n            assert len(e) == len(w)\n        except AssertionError:\n            raise ValueError('There is no one-to-one mapping between event'\n                             ' variable and population at risk variable, and '\n                             ' standard population variable, and spatial '\n                             ' weights!')\n        rdf = []\n        max_len = 0\n        for ei, bi, wi, si in zip(e, b, w, s):\n            ename = ei\n            bname = bi\n            h = len(ei) // wi.n\n            outcol = '_'.join(('-'.join((ename, bname)), cls.__name__.lower()))\n            this_r = cls(df[ei], df[bi], w=wi, s=df[si], **kwargs).r\n            max_len = 0 if len(this_r) > max_len else max_len\n            rdf.append((outcol, this_r.tolist()))\n        padded = (r[1] + [None] * max_len for r in rdf)\n        rdf = list(zip((r[0] for r in rdf), padded))\n        rdf = pd.DataFrame.from_items(rdf)\n        return rdf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing smoothing by columns in a dataframe.", "response": "def by_col(cls, df, e, b, x_grid, y_grid, geom_col='geometry', **kwargs):\n        \"\"\"\n        Compute smoothing by columns in a dataframe. The bounding box and point\n        information is computed from the geometry column.\n\n        Parameters\n        -----------\n        df      :  pandas.DataFrame\n                   a dataframe containing the data to be smoothed\n        e       :  string or list of strings\n                   the name or names of columns containing event variables to be\n                   smoothed\n        b       :  string or list of strings\n                   the name or names of columns containing the population\n                   variables to be smoothed\n        x_grid  :  integer\n                   number of grid cells to use along the x-axis\n        y_grid  :  integer\n                   number of grid cells to use along the y-axis\n        geom_col:  string\n                   the name of the column in the dataframe containing the\n                   geometry information.\n        **kwargs:  optional keyword arguments\n                   optional keyword options that are passed directly to the\n                   smoother.\n        Returns\n        ---------\n        a new dataframe of dimension (x_grid*y_grid, 3), containing the\n        coordinates of the grid cells and the rates associated with those grid\n        cells.\n        \"\"\"\n        import pandas as pd\n        # prep for application over multiple event/population pairs\n        if isinstance(e, str):\n            e = [e]\n        if isinstance(b, str):\n            b = [b]\n        if len(e) > len(b):\n            b = b * len(e)\n        if isinstance(x_grid, (int, float)):\n            x_grid = [x_grid] * len(e)\n        if isinstance(y_grid, (int, float)):\n            y_grid = [y_grid] * len(e)\n\n        bbox = get_bounding_box(df[geom_col])\n        bbox = [[bbox.left, bbox.lower], [bbox.right, bbox.upper]]\n        data = get_points_array(df[geom_col])\n        res = []\n        for ename, bname, xgi, ygi in zip(e, b, x_grid, y_grid):\n            r = cls(bbox, data, df[ename], df[bname], xgi, ygi, **kwargs)\n            grid = np.asarray(r.grid).reshape(-1,2)\n            name = '_'.join(('-'.join((ename, bname)), cls.__name__.lower()))\n            colnames = ('_'.join((name, suffix)) for suffix in ['X', 'Y', 'R'])\n            items = [(name, col) for name,col in zip(colnames, [grid[:,0],\n                                                                grid[:,1],\n                                                                r.r])]\n            res.append(pd.DataFrame.from_items(items))\n        outdf = pd.concat(res)\n        return outdf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef by_col(cls, df, e, b, t=None, geom_col='geometry', inplace=False, **kwargs):\n        import pandas as pd\n        if not inplace:\n            new = df.copy()\n            cls.by_col(new, e, b, t=t, geom_col=geom_col, inplace=True, **kwargs)\n            return new\n        import pandas as pd\n        # prep for application over multiple event/population pairs\n        if isinstance(e, str):\n            e = [e]\n        if isinstance(b, str):\n            b = [b]\n        if len(e) > len(b):\n            b = b * len(e)\n\n        data = get_points_array(df[geom_col])\n\n        #Headbanging_Triples doesn't take **kwargs, so filter its arguments\n        # (self, data, w, k=5, t=3, angle=135.0, edgecor=False):\n\n        w = kwargs.pop('w', None)\n        if w is None:\n            found = False\n            for k in df._metadata:\n                w = df.__dict__.get(w, None)\n                if isinstance(w, W):\n                    found = True\n            if not found:\n                raise Exception('Weights not provided and no weights attached to frame!'\n                                    ' Please provide a weight or attach a weight to the'\n                                    ' dataframe')\n\n        k = kwargs.pop('k', 5)\n        t = kwargs.pop('t', 3)\n        angle = kwargs.pop('angle', 135.0)\n        edgecor = kwargs.pop('edgecor', False)\n\n        hbt = Headbanging_Triples(data, w, k=k, t=t, angle=angle,\n                                  edgecor=edgecor)\n\n        res = []\n        for ename, bname in zip(e, b):\n            r = cls(df[ename], df[bname], hbt, **kwargs).r\n            name = '_'.join(('-'.join((ename, bname)), cls.__name__.lower()))\n            df[name] = r", "response": "Compute smoothing by columns in a dataframe."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes a univariate descriptive statistic over columns cols in df.", "response": "def _univariate_handler(df, cols, stat=None, w=None, inplace=True,\n                        pvalue = 'sim', outvals = None, swapname='', **kwargs):\n    \"\"\"\n    Compute a univariate descriptive statistic `stat` over columns `cols` in\n    `df`.\n\n    Parameters\n    ----------\n    df          : pandas.DataFrame\n                  the dataframe containing columns to compute the descriptive\n                  statistics\n    cols        : string or list of strings\n                  one or more names of columns in `df` to use to compute\n                  exploratory descriptive statistics.\n    stat        : callable\n                  a function that takes data as a first argument and any number\n                  of configuration keyword arguments and returns an object\n                  encapsulating the exploratory statistic results\n    w           : pysal.weights.W\n                  the spatial weights object corresponding to the dataframe\n    inplace     : bool\n                  a flag denoting whether to add the statistic to the dataframe\n                  in memory, or to construct a copy of the dataframe and append\n                  the results to the copy\n    pvalue      : string\n                  the name of the pvalue on the results object wanted\n    outvals     : list of strings\n                  names of attributes of the dataframe to attempt to flatten\n                  into a column\n    swapname    : string\n                  suffix to replace generic identifier with. Each caller of this\n                  function should set this to a unique column suffix\n    **kwargs    : optional keyword arguments\n                  options that are passed directly to the statistic\n    \"\"\"\n    ### Preprocess\n    if not inplace:\n        new_df = df.copy()\n        _univariate_handler(new_df, cols, stat=stat, w=w, pvalue=pvalue,\n                                   inplace=True, outvals=outvals,\n                                   swapname=swapname, **kwargs)\n        return new_df\n    if w is None:\n        for name in df._metadata:\n            this_obj = df.__dict__.get(name)\n            if isinstance(this_obj, W):\n                w = this_obj\n    if w is None:\n        raise Exception('Weights not provided and no weights attached to frame!'\n                            ' Please provide a weight or attach a weight to the'\n                            ' dataframe')\n    ### Prep indexes\n    if outvals is None:\n        outvals = []\n    outvals.insert(0,'_statistic')\n    if pvalue.lower() in ['all', 'both', '*']:\n        raise NotImplementedError(\"If you want more than one type of PValue,add\"\n                                  \" the targeted pvalue type to outvals. For example:\"\n                                  \" Geary(df, cols=['HOVAL'], w=w, outvals=['p_z_sim', \"\n                                  \"'p_rand']\")\n    # this is nontrivial, since we\n    # can't know which p_value types are on the object without computing it.\n    # This is because we don't flag them with @properties, so they're just\n    # arbitrarily assigned post-facto. One solution might be to post-process the\n    # objects, determine which pvalue types are available, and then grab them\n    # all if needed.\n\n    if pvalue is not '':\n        outvals.append('p_'+pvalue.lower())\n    if isinstance(cols, str):\n        cols = [cols]\n\n    ### Make closure around weights & apply columnwise\n    def column_stat(column):\n        return stat(column.values, w=w, **kwargs)\n    stat_objs = df[cols].apply(column_stat)\n\n    ### Assign into dataframe\n    for col in cols:\n        stat_obj = stat_objs[col]\n        y = kwargs.get('y')\n        if y is not None:\n            col += '-' + y.name\n        outcols = ['_'.join((col, val)) for val in outvals]\n        for colname, attname in zip(outcols, outvals):\n            df[colname] = stat_obj.__getattribute__(attname)\n    if swapname is not '':\n        df.columns = [_swap_ending(col, swapname) if col.endswith('_statistic') else col\n                      for col in df.columns]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _bivariate_handler(df, x, y=None, w=None, inplace=True, pvalue='sim',\n                       outvals=None, **kwargs):\n    \"\"\"\n    Compute a descriptive bivariate statistic over two sets of columns, `x` and\n    `y`, contained in `df`.\n\n    Parameters\n    ----------\n    df          : pandas.DataFrame\n                  dataframe in which columns `x` and `y` are contained\n    x           : string or list of strings\n                  one or more column names to use as variates in the bivariate\n                  statistics\n    y           : string or list of strings\n                  one or more column names to use as variates in the bivariate\n                  statistics\n    w           : pysal.weights.W\n                  spatial weights object corresponding to the dataframe `df`\n    inplace     : bool\n                  a flag denoting whether to add the statistic to the dataframe\n                  in memory, or to construct a copy of the dataframe and append\n                  the results to the copy\n    pvalue      : string\n                  the name of the pvalue on the results object wanted\n    outvals     : list of strings\n                  names of attributes of the dataframe to attempt to flatten\n                  into a column\n    swapname    : string\n                  suffix to replace generic identifier with. Each caller of this\n                  function should set this to a unique column suffix\n    **kwargs    : optional keyword arguments\n                  options that are passed directly to the statistic\n    \"\"\"\n    real_swapname = kwargs.pop('swapname', '')\n    if isinstance(y, str):\n        y = [y]\n    if isinstance(x, str):\n        x = [x]\n    if not inplace:\n        new_df = df.copy()\n        _bivariate_handler(new_df, x, y=y, w=w, inplace=True,\n                           swapname=real_swapname,\n                           pvalue=pvalue, outvals=outvals, **kwargs)\n        return new_df\n    if y is None:\n        y = x\n    for xi,yi in _it.product(x,y):\n        if xi == yi:\n            continue\n        _univariate_handler(df, cols=xi, w=w, y=df[yi], inplace=True,\n                            pvalue=pvalue, outvals=outvals, swapname='', **kwargs)\n    if real_swapname is not '':\n        df.columns = [_swap_ending(col, real_swapname)\n                      if col.endswith('_statistic')\n                      else col for col in df.columns]", "response": "Compute a descriptive bivariate statistic over two sets of columns x and y contained in df."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nswap ending of a string with ending provided", "response": "def _swap_ending(s, ending, delim='_'):\n    \"\"\"\n    Replace the ending of a string, delimited into an arbitrary\n    number of chunks by `delim`, with the ending provided\n\n    Parameters\n    ----------\n    s       :   string\n                string to replace endings\n    ending  :   string\n                string used to replace ending of `s`\n    delim   :   string\n                string that splits s into one or more parts\n\n    Returns\n    -------\n    new string where the final chunk of `s`, delimited by `delim`, is replaced\n    with `ending`.\n    \"\"\"\n    parts = [x for x in s.split(delim)[:-1] if x != '']\n    parts.append(ending)\n    return delim.join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef with_metaclass(meta, *bases):\n    class metaclass(meta):\n        __call__ = type.__call__\n        __init__ = type.__init__\n        def __new__(cls, name, this_bases, d):\n            if this_bases is None:\n                return type.__new__(cls, name, (), d)\n            return meta(name, bases, d)\n    return metaclass(\"NewBase\", None, {})", "response": "Create a base class with a metaclass."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a boolean indicating whether i is SymPy iterable.", "response": "def iterable(i, exclude=(string_types, dict, NotIterable)):\n    \"\"\"\n    Return a boolean indicating whether ``i`` is SymPy iterable.\n    True also indicates that the iterator is finite, i.e. you e.g.\n    call list(...) on the instance.\n\n    When SymPy is working with iterables, it is almost always assuming\n    that the iterable is not a string or a mapping, so those are excluded\n    by default. If you want a pure Python definition, make exclude=None. To\n    exclude multiple items, pass them as a tuple.\n\n    See also: is_sequence\n\n    Examples\n    ========\n\n    >>> from sympy.utilities.iterables import iterable\n    >>> from sympy import Tuple\n    >>> things = [[1], (1,), set([1]), Tuple(1), (j for j in [1, 2]), {1:2}, '1', 1]\n    >>> for i in things:\n    ...     print('%s %s' % (iterable(i), type(i)))\n    True <... 'list'>\n    True <... 'tuple'>\n    True <... 'set'>\n    True <class 'sympy.core.containers.Tuple'>\n    True <... 'generator'>\n    False <... 'dict'>\n    False <... 'str'>\n    False <... 'int'>\n\n    >>> iterable({}, exclude=None)\n    True\n    >>> iterable({}, exclude=str)\n    True\n    >>> iterable(\"no\", exclude=str)\n    False\n\n    \"\"\"\n    try:\n        iter(i)\n    except TypeError:\n        return False\n    if exclude:\n        return not isinstance(i, exclude)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_sequence(i, include=None):\n    return (hasattr(i, '__getitem__') and\n            iterable(i) or\n            bool(include) and\n            isinstance(i, include))", "response": "Return a boolean indicating whether i is a sequence in the SymPy\n    sense."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_int(n):\n    try:\n        result = int(n)\n        if result != n:\n            raise TypeError\n    except TypeError:\n        raise ValueError('%s is not an integer' % n)\n    return result", "response": "Convert the argument to an integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default_sort_key(item, order=None):\n\n    from sympy.core import S, Basic\n    from sympy.core.sympify import sympify, SympifyError\n    from sympy.core.compatibility import iterable\n\n    if isinstance(item, Basic):\n        return item.sort_key(order=order)\n\n    if iterable(item, exclude=string_types):\n        if isinstance(item, dict):\n            args = item.items()\n            unordered = True\n        elif isinstance(item, set):\n            args = item\n            unordered = True\n        else:\n            # e.g. tuple, list\n            args = list(item)\n            unordered = False\n\n        args = [default_sort_key(arg, order=order) for arg in args]\n\n        if unordered:\n            # e.g. dict, set\n            args = sorted(args)\n\n        cls_index, args = 10, (len(args), tuple(args))\n    else:\n        if not isinstance(item, string_types):\n            try:\n                item = sympify(item)\n            except SympifyError:\n                # e.g. lambda x: x\n                pass\n            else:\n                if isinstance(item, Basic):\n                    # e.g int -> Integer\n                    return default_sort_key(item)\n                # e.g. UndefinedFunction\n\n        # e.g. str\n        cls_index, args = 0, (1, (str(item),))\n\n    return (cls_index, 0, item.__class__.__name__\n            ), args, S.One.sort_key(), S.One", "response": "Return a key that can be used for sorting a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _nodes(e):\n    from .basic import Basic\n\n    if isinstance(e, Basic):\n        return e.count(Basic)\n    elif iterable(e):\n        return 1 + sum(_nodes(ei) for ei in e)\n    elif isinstance(e, dict):\n        return 1 + sum(_nodes(k) + _nodes(v) for k, v in e.items())\n    else:\n        return 1", "response": "A helper for ordered() which returns the number of nodes in the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ordered(seq, keys=None, default=True, warn=False):\n    d = defaultdict(list)\n    if keys:\n        if not isinstance(keys, (list, tuple)):\n            keys = [keys]\n        keys = list(keys)\n        f = keys.pop(0)\n        for a in seq:\n            d[f(a)].append(a)\n    else:\n        if not default:\n            raise ValueError('if default=False then keys must be provided')\n        d[None].extend(seq)\n\n    for k in sorted(d.keys()):\n        if len(d[k]) > 1:\n            if keys:\n                d[k] = ordered(d[k], keys, default, warn)\n            elif default:\n                d[k] = ordered(d[k], (_nodes, default_sort_key,),\n                               default=False, warn=warn)\n            elif warn:\n                from sympy.utilities.iterables import uniq\n                u = list(uniq(d[k]))\n                if len(u) > 1:\n                    raise ValueError(\n                        'not enough keys to break ties: %s' % u)\n        for v in d[k]:\n            yield v\n        d.pop(k)", "response": "Return an iterator of the given sequence where keys are used to break ties in\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a sequence of symbols with names taken from names argument.", "response": "def symbols(names, **args):\n    \"\"\"\n    Transform strings into instances of :class:`Symbol` class.\n    :func:`symbols` function returns a sequence of symbols with names taken\n    from ``names`` argument, which can be a comma or whitespace delimited\n    string, or a sequence of strings::\n        >>> from symengine import symbols\n        >>> x, y, z = symbols('x,y,z')\n        >>> a, b, c = symbols('a b c')\n    The type of output is dependent on the properties of input arguments::\n        >>> symbols('x')\n        x\n        >>> symbols('x,')\n        (x,)\n        >>> symbols('x,y')\n        (x, y)\n        >>> symbols(('a', 'b', 'c'))\n        (a, b, c)\n        >>> symbols(['a', 'b', 'c'])\n        [a, b, c]\n        >>> symbols(set(['a', 'b', 'c']))\n        set([a, b, c])\n    If an iterable container is needed for a single symbol, set the ``seq``\n    argument to ``True`` or terminate the symbol name with a comma::\n        >>> symbols('x', seq=True)\n        (x,)\n    To reduce typing, range syntax is supported to create indexed symbols.\n    Ranges are indicated by a colon and the type of range is determined by\n    the character to the right of the colon. If the character is a digit\n    then all contiguous digits to the left are taken as the nonnegative\n    starting value (or 0 if there is no digit left of the colon) and all\n    contiguous digits to the right are taken as 1 greater than the ending\n    value::\n        >>> symbols('x:10')\n        (x0, x1, x2, x3, x4, x5, x6, x7, x8, x9)\n        >>> symbols('x5:10')\n        (x5, x6, x7, x8, x9)\n        >>> symbols('x5(:2)')\n        (x50, x51)\n        >>> symbols('x5:10,y:5')\n        (x5, x6, x7, x8, x9, y0, y1, y2, y3, y4)\n        >>> symbols(('x5:10', 'y:5'))\n        ((x5, x6, x7, x8, x9), (y0, y1, y2, y3, y4))\n    If the character to the right of the colon is a letter, then the single\n    letter to the left (or 'a' if there is none) is taken as the start\n    and all characters in the lexicographic range *through* the letter to\n    the right are used as the range::\n        >>> symbols('x:z')\n        (x, y, z)\n        >>> symbols('x:c')  # null range\n        ()\n        >>> symbols('x(:c)')\n        (xa, xb, xc)\n        >>> symbols(':c')\n        (a, b, c)\n        >>> symbols('a:d, x:z')\n        (a, b, c, d, x, y, z)\n        >>> symbols(('a:d', 'x:z'))\n        ((a, b, c, d), (x, y, z))\n    Multiple ranges are supported; contiguous numerical ranges should be\n    separated by parentheses to disambiguate the ending number of one\n    range from the starting number of the next::\n        >>> symbols('x:2(1:3)')\n        (x01, x02, x11, x12)\n        >>> symbols(':3:2')  # parsing is from left to right\n        (00, 01, 10, 11, 20, 21)\n    Only one pair of parentheses surrounding ranges are removed, so to\n    include parentheses around ranges, double them. And to include spaces,\n    commas, or colons, escape them with a backslash::\n        >>> symbols('x((a:b))')\n        (x(a), x(b))\n        >>> symbols('x(:1\\,:2)')  # or 'x((:1)\\,(:2))'\n        (x(0,0), x(0,1))\n    \"\"\"\n    result = []\n\n    if isinstance(names, string_types):\n        marker = 0\n        literals = ['\\,', '\\:', '\\ ']\n        for i in range(len(literals)):\n            lit = literals.pop(0)\n            if lit in names:\n                while chr(marker) in names:\n                    marker += 1\n                lit_char = chr(marker)\n                marker += 1\n                names = names.replace(lit, lit_char)\n                literals.append((lit_char, lit[1:]))\n\n        def literal(s):\n            if literals:\n                for c, l in literals:\n                    s = s.replace(c, l)\n            return s\n\n        names = names.strip()\n        as_seq = names.endswith(',')\n        if as_seq:\n            names = names[:-1].rstrip()\n        if not names:\n            raise ValueError('no symbols given')\n\n        # split on commas\n        names = [n.strip() for n in names.split(',')]\n        if not all(n for n in names):\n            raise ValueError('missing symbol between commas')\n        # split on spaces\n        for i in range(len(names) - 1, -1, -1):\n            names[i: i + 1] = names[i].split()\n\n        cls = args.pop('cls', Symbol)\n        seq = args.pop('seq', as_seq)\n\n        for name in names:\n            if not name:\n                raise ValueError('missing symbol')\n\n            if ':' not in name:\n                symbol = cls(literal(name), **args)\n                result.append(symbol)\n                continue\n\n            split = _range.split(name)\n            # remove 1 layer of bounding parentheses around ranges\n            for i in range(len(split) - 1):\n                if i and ':' in split[i] and split[i] != ':' and \\\n                        split[i - 1].endswith('(') and \\\n                        split[i + 1].startswith(')'):\n                    split[i - 1] = split[i - 1][:-1]\n                    split[i + 1] = split[i + 1][1:]\n            for i, s in enumerate(split):\n                if ':' in s:\n                    if s[-1].endswith(':'):\n                        raise ValueError('missing end range')\n                    a, b = s.split(':')\n                    if b[-1] in string.digits:\n                        a = 0 if not a else int(a)\n                        b = int(b)\n                        split[i] = [str(c) for c in range(a, b)]\n                    else:\n                        a = a or 'a'\n                        split[i] = [string.ascii_letters[c] for c in range(\n                            string.ascii_letters.index(a),\n                            string.ascii_letters.index(b) + 1)]  # inclusive\n                    if not split[i]:\n                        break\n                else:\n                    split[i] = [s]\n            else:\n                seq = True\n                if len(split) == 1:\n                    names = split[0]\n                else:\n                    names = [''.join(s) for s in cartes(*split)]\n                if literals:\n                    result.extend([cls(literal(s), **args) for s in names])\n                else:\n                    result.extend([cls(s, **args) for s in names])\n\n        if not seq and len(result) <= 1:\n            if not result:\n                return ()\n            return result[0]\n\n        return tuple(result)\n    else:\n        for name in names:\n            result.append(symbols(name, **args))\n\n        return type(names)(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating symbols and inject them into the global namespace.", "response": "def var(names, **args):\n    \"\"\"\n    Create symbols and inject them into the global namespace.\n\n    INPUT:\n-            s -- a string, either a single variable name, or\n-                 a space separated list of variable names, or\n-                 a list of variable names.\n\n    This calls :func:`symbols` with the same arguments and puts the results\n    into the *global* namespace. It's recommended not to use :func:`var` in\n    library code, where :func:`symbols` has to be used::\n\n    Examples\n    ========\n\n    >>> from symengine import var\n\n    >>> var('x')\n    x\n    >>> x\n    x\n\n    >>> var('a,ab,abc')\n    (a, ab, abc)\n    >>> abc\n    abc\n\n    See :func:`symbols` documentation for more details on what kinds of\n    arguments can be passed to :func:`var`.\n\n    \"\"\"\n    def traverse(symbols, frame):\n        \"\"\"Recursively inject symbols to the global namespace. \"\"\"\n        for symbol in symbols:\n            if isinstance(symbol, Basic):\n                frame.f_globals[symbol.__str__()] = symbol\n            # Once we hace an undefined function class\n            # implemented, put a check for function here\n            else:\n                traverse(symbol, frame)\n\n    from inspect import currentframe\n    frame = currentframe().f_back\n\n    try:\n        syms = symbols(names, **args)\n\n        if syms is not None:\n            if isinstance(syms, Basic):\n                frame.f_globals[syms.__str__()] = syms\n            # Once we hace an undefined function class\n            # implemented, put a check for function here\n            else:\n                traverse(syms, frame)\n    finally:\n        del frame  # break cyclic dependencies as stated in inspect docs\n\n    return syms"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _combine_attribute_arguments(self, attr_dict, attr):\n        # Note: Code & comments unchanged from DirectedHypergraph\n        \"\"\"Combines attr_dict and attr dictionaries, by updating attr_dict\n            with attr.\n\n        :param attr_dict: dictionary of attributes of the node.\n        :param attr: keyword arguments of attributes of the node;\n                    attr's values will override attr_dict's values\n                    if both are provided.\n        :returns: dict -- single dictionary of [combined] attributes.\n        :raises: AttributeError -- attr_dict argument must be a dictionary.\n\n        \"\"\"\n        # If no attribute dict was passed, treat the keyword\n        # arguments as the dict\n        if attr_dict is None:\n            attr_dict = attr\n        # Otherwise, combine the passed attribute dict with\n        # the keyword arguments\n        else:\n            try:\n                attr_dict.update(attr)\n            except AttributeError:\n                raise AttributeError(\"attr_dict argument \\\n                                     must be a dictionary.\")\n        return attr_dict", "response": "Combines attr_dict and attr with keyword arguments of attr."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a hyperedge to the hypergraph along with any related nodes.", "response": "def add_hyperedge(self, nodes, attr_dict=None, **attr):\n        \"\"\"Adds a hyperedge to the hypergraph, along with any related\n            attributes of the hyperedge.\n            This method will automatically add any node from the node set\n            that was not in the hypergraph.\n            A hyperedge without a \"weight\" attribute specified will be\n            assigned the default value of 1.\n\n        :param nodes: iterable container of references to nodes in the\n                    hyperedge to be added.\n        :param attr_dict: dictionary of attributes of the hyperedge being\n                        added.\n        :param attr: keyword arguments of attributes of the hyperedge;\n                    attr's values will override attr_dict's values\n                    if both are provided.\n        :returns: str -- the ID of the hyperedge that was added.\n        :raises: ValueError -- nodes arguments cannot be empty.\n\n        Examples:\n        ::\n\n            >>> H = UndirectedHypergraph()\n            >>> x = H.add_hyperedge([\"A\", \"B\", \"C\"])\n            >>> y = H.add_hyperedge((\"A\", \"D\"), weight=2)\n            >>> z = H.add_hyperedge(set([\"B\", \"D\"]), {color: \"red\"})\n\n        \"\"\"\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        # Don't allow empty node set (invalid hyperedge)\n        if not nodes:\n            raise ValueError(\"nodes argument cannot be empty.\")\n\n        # Use frozensets for node sets to allow for hashable keys\n        frozen_nodes = frozenset(nodes)\n\n        is_new_hyperedge = not self.has_hyperedge(frozen_nodes)\n        if is_new_hyperedge:\n            # Add nodes to graph (if not already present)\n            self.add_nodes(frozen_nodes)\n\n            # Create new hyperedge name to use as reference for that hyperedge\n            hyperedge_id = self._assign_next_hyperedge_id()\n\n            # For each node in the node set, add hyperedge to the node's star\n            for node in frozen_nodes:\n                self._star[node].add(hyperedge_id)\n\n            # Add the hyperedge ID as the hyperedge that the node set composes\n            self._node_set_to_hyperedge[frozen_nodes] = hyperedge_id\n\n            # Assign some special attributes to this hyperedge. We assign\n            # a default weight of 1 to the hyperedge. We also store the\n            # original node set in order to return them exactly as the\n            # user passed them into add_hyperedge.\n            self._hyperedge_attributes[hyperedge_id] = \\\n                {\"nodes\": nodes, \"__frozen_nodes\": frozen_nodes, \"weight\": 1}\n        else:\n            # If its not a new hyperedge, just get its ID to update attributes\n            hyperedge_id = self._node_set_to_hyperedge[frozen_nodes]\n\n        # Set attributes and return hyperedge ID\n        self._hyperedge_attributes[hyperedge_id].update(attr_dict)\n        return hyperedge_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_hyperedges(self, hyperedges, attr_dict=None, **attr):\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        hyperedge_ids = []\n\n        for nodes in hyperedges:\n            hyperedge_id = self.add_hyperedge(nodes, attr_dict.copy())\n            hyperedge_ids.append(hyperedge_id)\n\n        return hyperedge_ids", "response": "Adds multiple hyperedges to the graph along with any related\n            attributes of the hyperedges."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a hyperedge and its attributes from the hypergraph.", "response": "def remove_hyperedge(self, hyperedge_id):\n        \"\"\"Removes a hyperedge and its attributes from the hypergraph.\n\n        :param hyperedge_id: ID of the hyperedge to be removed.\n        :raises: ValueError -- No such hyperedge exists.\n\n        Examples:\n        ::\n\n            >>> H = UndirectedHypergraph()\n            >>> hyperedge_list = ([\"A\", \"B\", \"C\"],\n                                  (\"A\", \"D\"),\n                                  set([\"B\", \"D\"]))\n            >>> hyperedge_ids = H.add_hyperedges(hyperedge_list)\n            >>> H.remove_hyperedge(hyperedge_ids[0])\n            >>> BD_id = H.get_hyperedge_id(set([\"B\", \"D\"]))\n            >>> H.remove_hyperedge(BD_id)\n\n        \"\"\"\n        if not self.has_hyperedge_id(hyperedge_id):\n            raise ValueError(\"No such hyperedge exists.\")\n\n        frozen_nodes = \\\n            self._hyperedge_attributes[hyperedge_id][\"__frozen_nodes\"]\n\n        # Remove this hyperedge from the star of every node in the hyperedge\n        for node in frozen_nodes:\n            self._star[node].remove(hyperedge_id)\n\n        # Remove this set as the composer of the hyperedge\n        del self._node_set_to_hyperedge[frozen_nodes]\n\n        # Remove hyperedge's attributes dictionary\n        del self._hyperedge_attributes[hyperedge_id]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hyperedge_id(self, nodes):\n        frozen_nodes = frozenset(nodes)\n\n        if not self.has_hyperedge(frozen_nodes):\n            raise ValueError(\"No such hyperedge exists.\")\n\n        return self._node_set_to_hyperedge[frozen_nodes]", "response": "This method returns the ID of the hyperedge that this node set comprises."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a hyperedge ID and the name of an attribute retrieve a copy of that hyperedge s attribute.", "response": "def get_hyperedge_attribute(self, hyperedge_id, attribute_name):\n        # Note: Code unchanged from DirectedHypergraph\n        \"\"\"Given a hyperedge ID and the name of an attribute, get a copy\n        of that hyperedge's attribute.\n\n        :param hyperedge_id: ID of the hyperedge to retrieve the attribute of.\n        :param attribute_name: name of the attribute to retrieve.\n        :returns: attribute value of the attribute_name key for the\n                specified hyperedge.\n        :raises: ValueError -- No such hyperedge exists.\n        :raises: ValueError -- No such attribute exists.\n\n        Examples:\n        ::\n\n            >>> H = UndirectedHypergraph()\n            >>> hyperedge_list = ([\"A\", \"B\", \"C\"],\n                                  (\"A\", \"D\"),\n                                  set([\"B\", \"D\"]))\n            >>> hyperedge_ids = H.add_hyperedges(hyperedge_list)\n            >>> attribute = H.get_hyperedge_attribute(hyperedge_ids[0])\n\n        \"\"\"\n        if not self.has_hyperedge_id(hyperedge_id):\n            raise ValueError(\"No such hyperedge exists.\")\n        elif attribute_name not in self._hyperedge_attributes[hyperedge_id]:\n            raise ValueError(\"No such attribute exists.\")\n        else:\n            return copy.\\\n                copy(self._hyperedge_attributes[hyperedge_id][attribute_name])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a hyperedge ID get a dictionary of copies of that hyperedge s attributes.", "response": "def get_hyperedge_attributes(self, hyperedge_id):\n        \"\"\"Given a hyperedge ID, get a dictionary of copies of that hyperedge's\n        attributes.\n\n        :param hyperedge_id: ID of the hyperedge to retrieve the attributes of.\n        :returns: dict -- copy of each attribute of the specified hyperedge_id\n                (except the private __frozen_nodes entry).\n        :raises: ValueError -- No such hyperedge exists.\n\n        \"\"\"\n        if not self.has_hyperedge_id(hyperedge_id):\n            raise ValueError(\"No such hyperedge exists.\")\n        dict_to_copy = self._hyperedge_attributes[hyperedge_id].items()\n        attributes = {}\n        for attr_name, attr_value in dict_to_copy:\n            if attr_name != \"__frozen_nodes\":\n                attributes[attr_name] = copy.copy(attr_value)\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_star(self, node):\n        if node not in self._node_attributes:\n            raise ValueError(\"No such node exists.\")\n        return self._star[node].copy()", "response": "Given a node get a copy of that node s star that is the set of hyperedge_ids that the node belongs to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting an undirected hypergraph from a file where nodes are represented as strings.", "response": "def write(self, file_name, delim=',', sep='\\t'):\n        \"\"\"Writes an undirected hypergraph from a file, where nodes are\n        represented as strings.\n        Each column is separated by \"sep\", and the individual nodes are\n        delimited by \"delim\".\n        The header line is currently ignored, but columns should be of\n        the format:\n        node1[delim]..nodeM[sep]node1[delim]..nodeN[sep]weight\n\n        As a concrete example, an arbitrary line with delim=',' and\n        sep='    ' (4 spaces) may look like:\n        ::\n\n            x1,x2,x3,x5    12\n\n        which defines a hyperedge of weight 12 from a node set containing\n        nodes \"x1\", \"x2\", \"x3\", and \"x5\".\n\n        \"\"\"\n        out_file = open(file_name, 'w')\n\n        # write first header line\n        out_file.write(\"nodes\" + sep + \"weight\\n\")\n\n        for hyperedge_id in self.get_hyperedge_id_set():\n            line = \"\"\n            # Write each node to the line, separated by delim\n            for node in self.get_hyperedge_nodes(hyperedge_id):\n                line += node + delim\n            # Remove last (extra) delim\n            line = line[:-1]\n\n            # Write the weight to the line and end the line\n            line += sep + str(self.get_hyperedge_weight(hyperedge_id)) + \"\\n\"\n\n            out_file.write(line)\n\n        out_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _F_outdegree(H, F):\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    return F([len(H.get_forward_star(node))\n             for node in H.get_node_set()])", "response": "Returns the result of a function F applied to the set of outdegrees in\n    in the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the result of a function F applied to the list of indegrees in in the hypergraph.", "response": "def _F_indegree(H, F):\n    \"\"\"Returns the result of a function F applied to the list of indegrees in\n    in the hypergraph.\n\n    :param H: the hypergraph whose indegrees will be operated on.\n    :param F: function to execute on the list of indegrees in the hypergraph.\n    :returns: result of the given function F.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    return F([len(H.get_backward_star(node))\n             for node in H.get_node_set()])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _F_hyperedge_tail_cardinality(H, F):\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    return F([len(H.get_hyperedge_tail(hyperedge_id))\n             for hyperedge_id in H.get_hyperedge_id_set()])", "response": "Returns the result of a function F applied to the set of cardinalities of the hyperedge tails in the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the result of a function F applied to the set of cardinalities of the hyperedge heads in the hypergraph.", "response": "def _F_hyperedge_head_cardinality(H, F):\n    \"\"\"Returns the result of a function F applied to the set of cardinalities\n    of hyperedge heads in the hypergraph.\n\n    :param H: the hypergraph whose head cardinalities will be\n                    operated on.\n    :param F: function to execute on the set of cardinalities in the\n            hypergraph.\n    :returns: result of the given function F.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    return F([len(H.get_hyperedge_head(hyperedge_id))\n             for hyperedge_id in H.get_hyperedge_id_set()])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of 2 - tuples for each hyperedge s cardinality.", "response": "def hyperedge_cardinality_pairs_list(H):\n    \"\"\"Returns a list of 2-tuples of (\\|tail\\|, \\|head\\|) for each hyperedge\n    in the hypergraph.\n\n    :param H: the hypergraph whose cardinality ratios will be\n            operated on.\n    :returns: list -- list of 2-tuples for each hyperedge's cardinality.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    return [(len(H.get_hyperedge_tail(hyperedge_id)),\n            len(H.get_hyperedge_head(hyperedge_id)))\n            for hyperedge_id in H.hyperedge_id_iterator()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the result of a function F applied to the set of cardinality ratios between the tail and head sets of the given hypergraph.", "response": "def _F_hyperedge_cardinality_ratio(H, F):\n    \"\"\"Returns the result of a function F applied to the set of cardinality\n    ratios between the tail and the head sets (specifically, |tail|/|head|) of\n    hyperedges in the hypergraph.\n\n    :param H: the hypergraph whose cardinality ratios will be\n                    operated on.\n    :param F: function to execute on the set of cardinality ratios in the\n            hypergraph.\n    :returns: result of the given function F.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    # Since |head| can potentially be 0 (causing a division by 0 exception),\n    # we use numpy's float64 to have division by 0 result in inf, which is\n    # then cast back to a float for our final result\n    return F([float(tail_card / np.float64(head_card))\n             for tail_card, head_card in hyperedge_cardinality_pairs_list(H)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a mapping between the set of nodes and integer indices.", "response": "def get_node_mapping(H):\n    \"\"\"Generates mappings between the set of nodes and integer indices (where\n    every node corresponds to exactly 1 integer index).\n\n    :param H: the hypergraph to find the node mapping on.\n    :returns: dict -- for each integer index, maps the index to the node.\n              dict -- for each node, maps the node to the integer index.\n\n    \"\"\"\n    node_set = H.get_node_set()\n    nodes_to_indices, indices_to_nodes = {}, {}\n\n    node_index = 0\n    for node in node_set:\n        nodes_to_indices.update({node: node_index})\n        indices_to_nodes.update({node_index: node})\n        node_index += 1\n\n    return indices_to_nodes, nodes_to_indices"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_hyperedge_id_mapping(H):\n    if not isinstance(H, UndirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to undirected hypergraphs\")\n\n    indices_to_hyperedge_ids, hyperedge_ids_to_indices = {}, {}\n    hyperedge_index = 0\n    for hyperedge_id in H.hyperedge_id_iterator():\n        hyperedge_ids_to_indices.update({hyperedge_id: hyperedge_index})\n        indices_to_hyperedge_ids.update({hyperedge_index: hyperedge_id})\n        hyperedge_index += 1\n\n    return indices_to_hyperedge_ids, hyperedge_ids_to_indices", "response": "Generates mappings between the set of hyperedge IDs and integer indices of the hyperedge IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the diagonal edge weight matrix W of the hyperedge weights.", "response": "def get_hyperedge_weight_matrix(H, hyperedge_ids_to_indices):\n    \"\"\"Creates the diagonal matrix W of hyperedge weights as a sparse matrix.\n\n    :param H: the hypergraph to find the weights.\n    :param hyperedge_weights: the mapping from the indices of hyperedge IDs to\n                            the corresponding hyperedge weights.\n    :returns: sparse.csc_matrix -- the diagonal edge weight matrix as a\n            sparse matrix.\n\n    \"\"\"\n    # Combined 2 methods into 1; this could be written better\n    hyperedge_weights = {}\n    for hyperedge_id in H.hyperedge_id_iterator():\n        hyperedge_weights.update({hyperedge_ids_to_indices[hyperedge_id]:\n                                 H.get_hyperedge_weight(hyperedge_id)})\n\n    hyperedge_weight_vector = []\n    for i in range(len(hyperedge_weights.keys())):\n        hyperedge_weight_vector.append(hyperedge_weights.get(i))\n\n    return sparse.diags([hyperedge_weight_vector], [0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the diagonal matrix of hyperedge degrees D_e as a sparse matrix where a hyperedge degree is the cardinality of the hyperedge.", "response": "def get_hyperedge_degree_matrix(M):\n    \"\"\"Creates the diagonal matrix of hyperedge degrees D_e as a sparse matrix,\n    where a hyperedge degree is the cardinality of the hyperedge.\n\n    :param M: the incidence matrix of the hypergraph to find the D_e matrix on.\n    :returns: sparse.csc_matrix -- the diagonal hyperedge degree matrix as a\n            sparse matrix.\n\n    \"\"\"\n    degrees = M.sum(0).transpose()\n    new_degree = []\n    for degree in degrees:\n        new_degree.append(int(degree[0:]))\n\n    return sparse.diags([new_degree], [0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fast_inverse(M):\n    diags = M.diagonal()\n    new_diag = []\n    for value in diags:\n        new_diag.append(1.0/value)\n\n    return sparse.diags([new_diag], [0])", "response": "Computes the inverse of a diagonal matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef node_iterator(self):\n        return iter(self._node_attributes)\n\n\tdef has_hypernode(self, hypernode):\n        \"\"\"Determines if a specific hypernode is present in the hypergraph.\n\n        :param node: reference to hypernode whose presence is being checked.\n        :returns: bool -- true iff the node exists in the hypergraph.\n\n        \"\"\"\n        return hypernode in self._hypernode_attributes", "response": "Provides an iterator over the nodes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_hypernode(self, hypernode, composing_nodes=set(), attr_dict=None, **attr):\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        # If the hypernode hasn't previously been added, add it along\n        # with its attributes\n        if not self.has_hypernode(hypernode):\n        \tattr_dict[\"__composing_nodes\"] = composing_nodes\n        \tadded_nodes = composing_nodes\n        \tremoved_nodes = set()\n            self._hypernode_attributes[hypernode] = attr_dict\n        # Otherwise, just update the hypernode's attributes\n        else:\n            self._hypernode_attributes[hypernode].update(attr_dict)\n            added_nodes = composing_nodes - self._hypernode_attributes\\\n            \t\t\t  [hypernode][\"__composing_nodes\"]\n\t\t\tremoved_nodes = self._hypernode_attributes\\\n            \t\t\t  \t[hypernode][\"__composing_nodes\"] - composing_nodes\n        \n        # For every \"composing node\" added to this hypernode, update\n        # those nodes attributes to be members of this hypernode\n\t\tfor node in added_nodes:\n\t\t\t_add_hypernode_membership(node, hypernode)\n\t\t# For every \"composing node\" added to this hypernode, update\n        # those nodes attributes to no longer be members of this hypernode\n        for node in remove_nodes:\n\t\t\t_remove_hypernode_membership(node, hypernode)", "response": "Adds a hypernode to the hypergraph along with any related attributes of the hypernode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the min-cut algorithm described in the paper: Zhou, Dengyong, Jiayuan Huang, and Bernhard Scholkopf. \"Learning with hypergraphs: Clustering, classification, and embedding.\" Advances in neural information processing systems. 2006. (http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_630.pdf) This algorithm uses the normalized Laplacian to partition the hypergraph into two disjoint components. :param H: the hypergraph to perform the hypergraph-cut algorithm on. :param threshold: The threshold value for the partitioning algorithm. Typically, the value zero is selected for this purpose. :returns: set -- the S set of nodes in the S-T partition set -- the T set of nodes in the S-T partition :raises: TypeError -- Algorithm only applicable to undirected hypergraphs", "response": "def normalized_hypergraph_cut(H, threshold=0):\n    \"\"\"Executes the min-cut algorithm described in the paper:\n    Zhou, Dengyong, Jiayuan Huang, and Bernhard Scholkopf.\n    \"Learning with hypergraphs: Clustering, classification, and embedding.\"\n    Advances in neural information processing systems. 2006.\n    (http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_630.pdf)\n\n    This algorithm uses the normalized Laplacian to partition the hypergraph\n    into two disjoint components.\n\n    :param H: the hypergraph to perform the hypergraph-cut algorithm on.\n    :param threshold: The threshold value for the partitioning algorithm.\n                    Typically, the value zero is selected for this purpose.\n    :returns: set -- the S set of nodes in the S-T partition\n              set -- the T set of nodes in the S-T partition\n    :raises: TypeError -- Algorithm only applicable to undirected hypergraphs\n\n    \"\"\"\n    if not isinstance(H, UndirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to undirected hypergraphs\")\n\n    # TODO: make sure that the hypergraph is connected\n\n    # Get index<->node mappings and index<->hyperedge_id mappings for matrices\n    indices_to_nodes, nodes_to_indices = \\\n        umat.get_node_mapping(H)\n    indices_to_hyperedge_ids, hyperedge_ids_to_indices = \\\n        umat.get_hyperedge_id_mapping(H)\n\n    delta = _compute_normalized_laplacian(H,\n                                          nodes_to_indices,\n                                          hyperedge_ids_to_indices)\n\n    # Since the eigs method in sparse.linalg library doesn't find\n    # all the eigenvalues and eigenvectors, it doesn't give us an\n    # exact and correct solution. Therefore, we should use the\n    # numpy library which works on dense graphs. This might be\n    # problematic for large graphs.\n    # New note: I think we only need the 2 smallest eigenvalues, which\n    # can be found with the sparse solver. Look into this if run-time\n    # becomes an issue.\n\n    # eigenvalues,eigenvectors = linalg.eigs(delta,k=numberOfEigenValues)\n    eigenvalues, eigenvectors = np.linalg.eig(delta.todense())\n\n    second_min_index = np.argsort(eigenvalues)[1]\n    second_eigenvector = eigenvectors[:, second_min_index]\n    partition_index = [i for i in range(len(second_eigenvector))\n                       if second_eigenvector[i] >= threshold]\n\n    S, T = set(), set()\n    for key, value in nodes_to_indices.items():\n        if value in partition_index:\n            S.add(key)\n        else:\n            T.add(key)\n\n    return S, T"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _compute_normalized_laplacian(H,\n                                  nodes_to_indices,\n                                  hyperedge_ids_to_indices):\n    \"\"\"Computes the normalized Laplacian as described in the paper:\n    Zhou, Dengyong, Jiayuan Huang, and Bernhard Scholkopf.\n    \"Learning with hypergraphs: Clustering, classification, and embedding.\"\n    Advances in neural information processing systems. 2006.\n    (http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_630.pdf)\n\n    :param H: the hypergraph to compute the normalized Laplacian\n                    matrix for.\n    :param nodes_to_indices: for each node, maps the node to its\n                            corresponding integer index.\n    :param hyperedge_ids_to_indices: for each hyperedge ID, maps the hyperedge\n                                    ID to its corresponding integer index.\n    :returns: sparse.csc_matrix -- the normalized Laplacian matrix as a sparse\n            matrix.\n\n    \"\"\"\n    M = umat.get_incidence_matrix(H,\n                                  nodes_to_indices, hyperedge_ids_to_indices)\n    W = umat.get_hyperedge_weight_matrix(H, hyperedge_ids_to_indices)\n    D_v = umat.get_vertex_degree_matrix(M, W)\n    D_e = umat.get_hyperedge_degree_matrix(M)\n\n    D_v_sqrt = D_v.sqrt()\n    D_v_sqrt_inv = np.real(umat.fast_inverse(D_v_sqrt).todense())\n    D_v_sqrt_inv = sparse.csc_matrix(D_v_sqrt_inv)\n    D_e_inv = umat.fast_inverse(D_e)\n    M_trans = M.transpose()\n\n    theta = D_v_sqrt_inv * M * W * D_e_inv * M_trans * D_v_sqrt_inv\n\n    node_count = len(H.get_node_set())\n    I = sparse.eye(node_count)\n\n    delta = I - theta\n    return delta", "response": "Computes the normalized Laplacian matrix for the given hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the stationary distribution of a random walk on the given hypergraph.", "response": "def stationary_distribution(H, pi=None, P=None):\n    \"\"\"Computes the stationary distribution of a random walk on the given\n    hypergraph using the iterative approach explained in the paper:\n    (http://pages.cs.wisc.edu/~shuchi/courses/787-F09/scribe-notes/lec15.pdf)\n\n    :param H: the hypergraph to find the stationary distribution on.\n    :param pi: the initial distribution over the nodes. If not provided,\n            it will be created with a random distribution.\n    :param P: the transition matrix for the hypergraph. If not provided,\n            it will be created.\n    :returns: list -- list of the stationary probabilities for all nodes\n            in the hypergraph.\n    :raises: TypeError -- Algorithm only applicable to undirected hypergraphs\n\n    \"\"\"\n    if not isinstance(H, UndirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to undirected hypergraphs\")\n\n    indices_to_nodes, nodes_to_indices = \\\n        umat.get_node_mapping(H)\n    indices_to_hyperedge_ids, hyperedge_ids_to_indices = \\\n        umat.get_hyperedge_id_mapping(H)\n\n    if P is None:\n        P = _compute_transition_matrix(H,\n                                       nodes_to_indices,\n                                       hyperedge_ids_to_indices)\n\n    node_count = len(H.get_node_set())\n    if pi is None:\n        pi = _create_random_starter(node_count)\n    pi_star = _create_random_starter(node_count)\n    while not _has_converged(pi_star, pi):\n        pi = pi_star\n        pi_star = pi * P\n\n    return pi"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compute_transition_matrix(H,\n                               nodes_to_indices,\n                               hyperedge_ids_to_indices):\n    \"\"\"Computes the transition matrix for a random walk on the given\n    hypergraph as described in the paper:\n    Zhou, Dengyong, Jiayuan Huang, and Bernhard Scholkopf.\n    \"Learning with hypergraphs: Clustering, classification, and embedding.\"\n    Advances in neural information processing systems. 2006.\n    (http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_630.pdf)\n\n    :param H: the hypergraph to find the transition matrix of.\n    :param nodes_to_indices: for each node, maps the node to its\n                            corresponding integer index.\n    :param hyperedge_ids_to_indices: for each hyperedge ID, maps the hyperedge\n                                    ID to its corresponding integer index.\n    :returns: sparse.csc_matrix -- the transition matrix as a sparse matrix.\n\n    \"\"\"\n    M = umat.get_incidence_matrix(H,\n                                  nodes_to_indices, hyperedge_ids_to_indices)\n    W = umat.get_hyperedge_weight_matrix(H, hyperedge_ids_to_indices)\n    D_v = umat.get_vertex_degree_matrix(M, W)\n    D_e = umat.get_hyperedge_degree_matrix(M)\n\n    D_v_inv = umat.fast_inverse(D_v)\n    D_e_inv = umat.fast_inverse(D_e)\n    M_trans = M.transpose()\n\n    P = D_v_inv * M * W * D_e_inv * M_trans\n\n    return P", "response": "Computes the transition matrix for a random walk on the given hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a random starter for the random walk.", "response": "def _create_random_starter(node_count):\n    \"\"\"Creates the random starter for the random walk.\n\n    :param node_count: number of nodes to create the random vector.\n    :returns: list -- list of starting probabilities for each node.\n\n    \"\"\"\n    pi = np.zeros(node_count, dtype=float)\n    for i in range(node_count):\n        pi[i] = random.random()\n    summation = np.sum(pi)\n    for i in range(node_count):\n        pi[i] = pi[i] / summation\n\n    return pi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the random walk has converged.", "response": "def _has_converged(pi_star, pi):\n    \"\"\"Checks if the random walk has converged.\n\n    :param pi_star: the new vector\n    :param pi: the old vector\n    :returns: bool-- True iff pi has converged.\n\n    \"\"\"\n    node_count = pi.shape[0]\n    EPS = 10e-6\n    for i in range(node_count):\n        if pi[i] - pi_star[i] > EPS:\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an element with a specific priority.", "response": "def add_element(self, priority, element, count=None):\n        \"\"\"Adds an element with a specific priority.\n\n        :param priority: priority of the element.\n        :param element: element to add.\n\n        \"\"\"\n        if count is None:\n            count = next(self.counter)\n        entry = [priority, count, element]\n        self.element_finder[element] = entry\n        heapq.heappush(self.pq, entry)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_top_priority(self):\n        if self.is_empty():\n            raise IndexError(\"Priority queue is empty.\")\n        _, _, element = heapq.heappop(self.pq)\n        if element in self.element_finder:\n            del self.element_finder[element]\n        return element", "response": "Pops the element that has the top priority. Returns the element with the lowest priority."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete an element from the priority queue.", "response": "def delete_element(self, element):\n        \"\"\"Deletes an element (lazily).\n\n        :raises: ValueError -- No such element in the priority queue.\n\n        \"\"\"\n        if element not in self.element_finder:\n            raise ValueError(\"No such element in the priority queue.\")\n        entry = self.element_finder[element]\n        entry[1] = self.INVALID"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the priority of an element.", "response": "def reprioritize(self, priority, element):\n        \"\"\"Updates the priority of an element.\n\n        :raises: ValueError -- No such element in the priority queue.\n\n        \"\"\"\n        if element not in self.element_finder:\n            raise ValueError(\"No such element in the priority queue.\")\n        entry = self.element_finder[element]\n        self.add_element(priority, element, entry[1])\n        entry[1] = self.INVALID"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contains_element(self, element):\n        return (element in self.element_finder) and \\\n            (self.element_finder[element][1] != self.INVALID)", "response": "Determines if an element is contained in the priority queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_empty(self):\n        while self.pq:\n            if self.pq[0][1] != self.INVALID:\n                return False\n            else:\n                _, _, element = heapq.heappop(self.pq)\n                if element in self.element_finder:\n                    del self.element_finder[element]\n        return True", "response": "Determines if the priority queue has any elements. Returns True iff the priority queue has no elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the Visit algorithm on a given hypergraph and returns a set of nodes that were visited in this hypergraph.", "response": "def visit(H, source_node):\n    \"\"\"Executes the 'Visit' algorithm described in the paper:\n    Giorgio Gallo, Giustino Longo, Stefano Pallottino, Sang Nguyen,\n    Directed hypergraphs and applications, Discrete Applied Mathematics,\n    Volume 42, Issues 2-3, 27 April 1993, Pages 177-201, ISSN 0166-218X,\n    http://dx.doi.org/10.1016/0166-218X(93)90045-P.\n    (http://www.sciencedirect.com/science/article/pii/0166218X9390045P)\n\n    The Visit algorithm begins from a source node and traverses a hyperedge\n    after any node in the hyperedge's tail has been reached.\n\n    :param H: the hypergraph to perform the 'Visit' algorithm on.\n    :param source_node: the initial node to begin traversal from.\n    :returns: set -- nodes that were visited in this traversal.\n              dict -- mapping from each node to the ID of the hyperedge that\n              preceeded it in this traversal; will map a node to None\n              if that node wasn't visited or if that node is the source\n              node.\n              dict -- mapping from each hyperedge ID to the node that preceeded\n              it in this traversal.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    node_set = H.get_node_set()\n    # Pv keeps track of the ID of the hyperedge that directely\n    # preceeded each node in the traversal\n    Pv = {node: None for node in node_set}\n\n    hyperedge_id_set = H.get_hyperedge_id_set()\n    # Pe keeps track of the node that directedly preceeded\n    # each hyperedge in the traversal\n    Pe = {hyperedge_id: None for hyperedge_id in hyperedge_id_set}\n\n    # Explicitly tracks the set of visited nodes\n    visited_nodes = set([source_node])\n\n    Q = Queue()\n    Q.put(source_node)\n\n    while not Q.empty():\n        current_node = Q.get()\n        # At current_node, we can traverse each hyperedge in its forward star\n        for hyperedge_id in H.get_forward_star(current_node):\n            if Pe[hyperedge_id] is not None:\n                continue\n            Pe[hyperedge_id] = current_node\n            # Traversing a hyperedge in current_node's forward star yields\n            # the set of head nodes of the hyperedge; visit each head node\n            for head_node in H.get_hyperedge_head(hyperedge_id):\n                if head_node in visited_nodes:\n                    continue\n                Pv[head_node] = hyperedge_id\n                Q.put(head_node)\n                visited_nodes.add(head_node)\n\n    return visited_nodes, Pv, Pe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a target node is connected to a source node.", "response": "def is_connected(H, source_node, target_node):\n    \"\"\"Checks if a target node is connected to a source node. That is,\n    this method determines if a target node can be visited from the source\n    node in the sense of the 'Visit' algorithm.\n\n    Refer to 'visit's documentation for more details.\n\n    :param H: the hypergraph to check connectedness on.\n    :param source_node: the node to check connectedness to.\n    :param target_node: the node to check connectedness of.\n    :returns: bool -- whether target_node can be visited from source_node.\n\n    \"\"\"\n    visited_nodes, Pv, Pe = visit(H, source_node)\n    return target_node in visited_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_b_connected(H, source_node, target_node):\n    b_visited_nodes, Pv, Pe, v = b_visit(H, source_node)\n    return target_node in b_visited_nodes", "response": "Checks if a target node is B - connected to a source node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a target node is F - connected to a source node.", "response": "def is_f_connected(H, source_node, target_node):\n    \"\"\"Checks if a target node is F-connected to a source node.\n\n    A node t is F-connected to a node s iff s if B-connected to t.\n    Refer to 'f_visit's or 'is_b_connected's documentation for more details.\n\n    :param H: the hypergraph to check F-connectedness on.\n    :param source_node: the node to check F-connectedness to.\n    :param target_node: the node to check F-connectedness of.\n    :returns: bool -- whether target_node can be visited from source_node.\n\n    \"\"\"\n    f_visited_nodes, Pv, Pe, v = f_visit(H, source_node)\n    return target_node in f_visited_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a subhypergraph induced from the set of nodes that are preceeded by the given predecessor vector.", "response": "def get_hypertree_from_predecessors(H, Pv, source_node,\n                                    node_weights=None, attr_name=\"weight\"):\n    \"\"\"Gives the hypertree (i.e., the subhypergraph formed from the union of\n    the set of paths from an execution of, e.g., the SBT algorithm) defined by\n    Pv beginning at a source node. Returns a dictionary mapping each node to\n    the ID of the hyperedge that preceeded it in the path (i.e., a Pv vector).\n    Assigns the node weights (if provided) as attributes of the nodes (e.g.,\n    the rank of that node in a specific instance of the SBT algorithm, or the\n    cardinality of that node in a B-Visit traversal, etc.).\n\n    :note: The IDs of the hyperedges in the subhypergraph returned may be\n        different than those in the original hypergraph (even though the\n        tail and head sets are identical).\n\n    :param H: the hypergraph which the path algorithm was executed on.\n    :param Pv: dictionary mapping each node to the ID of the hyperedge that\n            preceeded it in the path.\n    :param source_node: the root of the executed path algorithm.\n    :param node_weights: [optional] dictionary mapping each node to some weight\n                        measure.\n    :param attr_name: key into the nodes' attribute dictionaries for their\n                    weight values (if node_weights is provided).\n    :returns: DirectedHypergraph -- subhypergraph induced by the path\n            algorithm specified by the predecessor vector (Pv) from a\n            source node.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    sub_H = DirectedHypergraph()\n\n    # If node weights are not provided, simply collect all the nodes that are\n    # will be in the hypertree\n    if node_weights is None:\n        nodes = [node for node in Pv.keys() if Pv[node] is not None]\n        nodes.append(source_node)\n    # If node weights are provided, collect all the nodes that will be in the\n    # tree and pair them with their corresponding weights\n    else:\n        nodes = [(node, {attr_name: node_weights[node]})\n                 for node in Pv.keys() if Pv[node] is not None]\n        nodes.append((source_node, {attr_name: node_weights[source_node]}))\n    # Add the collected elements to the hypergraph\n    sub_H.add_nodes(nodes)\n\n    # Add all hyperedges, specified by Pv, to the hypergraph\n    hyperedges = [(H.get_hyperedge_tail(hyperedge_id),\n                   H.get_hyperedge_head(hyperedge_id),\n                   H.get_hyperedge_attributes(hyperedge_id))\n                  for hyperedge_id in Pv.values() if hyperedge_id is not None]\n    sub_H.add_hyperedges(hyperedges)\n\n    return sub_H"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hyperpath_from_predecessors(H, Pv, source_node, destination_node,\n                                    node_weights=None, attr_name=\"weight\"):\n    \"\"\"Gives the hyperpath (DirectedHypergraph) representing the shortest\n    B-hyperpath from the source to the destination, given a predecessor\n    function and source and destination nodes.\n\n    :note: The IDs of the hyperedges in the subhypergraph returned may be\n        different than those in the original hypergraph (even though the\n        tail and head sets are identical).\n\n    :param H: the hypergraph which the path algorithm was executed on.\n    :param Pv: dictionary mapping each node to the ID of the hyperedge that\n            preceeded it in the path.\n    :param source_node: the source node of the path.\n    :param destination_node: the destination node of the path.\n    :returns: DirectedHypergraph -- shortest B-hyperpath from source_node to\n            destination_node.\n    :raises: TypeError -- Algorithm only applicable to directed hypergraphs\n    :raises: KeyError -- Node key in predecessor is not in H\n    :raises: KeyError -- Hyperedge key in predecessor is not in H\n    :raises: ValueError -- Multiple nodes without predecessor\n    :raises: ValueError -- Hypertree does not have source node\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    # Check that Pv is a valid predecessor function:\n    # - keys must be nodes in H mapping to hyperedges in H\n    # - exactly one node must map to None (i.e., only one node\n    #   without predecessor)\n    nodes_without_predecessor = 0\n    for node, hyperedge_id in Pv.items():\n        if not H.has_node(node):\n            raise KeyError(\n                \"Node key %s in predecessor is not in H\" % node)\n\n        if hyperedge_id is None:\n            nodes_without_predecessor += 1\n        elif not H.has_hyperedge_id(hyperedge_id):\n            raise KeyError(\n                \"Hyperedge key %s in predecessor is not in H\" % hyperedge_id)\n\n    if nodes_without_predecessor > 1:\n        raise ValueError(\n            \"Multiple nodes without predecessor. %s received\" % Pv)\n    elif nodes_without_predecessor == 0:\n        raise ValueError(\n            \"Hypertree does not have source node. %s received\" % Pv)\n\n    path = DirectedHypergraph()\n\n    # keep track of which nodes are or have been processed\n    processedOrInQueue = {n: False for n in Pv}\n    nodesToProcess = [destination_node]\n    processedOrInQueue[destination_node] = True\n    while nodesToProcess:\n        node = nodesToProcess.pop(0)\n        hyperedge_id = Pv[node]\n        if hyperedge_id:\n            for n in H.get_hyperedge_tail(hyperedge_id):\n                if not processedOrInQueue[n]:\n                    nodesToProcess.append(n)\n                    processedOrInQueue[n] = True\n            path.add_hyperedge(H.get_hyperedge_tail(hyperedge_id),\n                               H.get_hyperedge_head(hyperedge_id),\n                               weight=H.get_hyperedge_weight(\n                               hyperedge_id))\n        elif not path.has_node(node):\n            path.add_node(node)\n\n    return path", "response": "Returns the shortest B - hyperpath from the source to the destination given a predecessor function Pv source and destination nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an undirected hypergraph that has the same nodes and hyperedges as the given H except that for all the nodes in the given H all the hyperedges in the given H are decomposed into a new graph.", "response": "def to_graph_decomposition(H):\n    \"\"\"Returns an UndirectedHypergraph object that has the same nodes (and\n    corresponding attributes) as the given H, except that for all\n    hyperedges in the given H, each node in the hyperedge is pairwise\n    connected to every other node also in that hyperedge in the new H.\n    Said another way, each of the original hyperedges are decomposed in the\n    new H into cliques (aka the \"2-section\" or \"clique graph\").\n\n    :param H: the H to decompose into a graph.\n    :returns: UndirectedHypergraph -- the decomposed H.\n    :raises: TypeError -- Transformation only applicable to\n            undirected Hs\n\n    \"\"\"\n    if not isinstance(H, UndirectedHypergraph):\n        raise TypeError(\"Transformation only applicable to \\\n                        undirected Hs\")\n\n    G = UndirectedHypergraph()\n\n    nodes = [(node, H.get_node_attributes(node_attributes))\n             for node in G.node_iterator()]\n    G.add_nodes(nodes)\n\n    edges = [(node_a, node_b)\n             for hyperedge_id in H.hyperedge_id_iterator()\n             for node_a in H.get_hyperedge_nodes(hyperedge_id)\n             for node_b in H.get_hyperedge_nodes(hyperedge_id)\n             if node_a != node_b]\n\n    G.add_hyperedges(edges)\n\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a NetworkX Graph object representing the graph decomposition of the given H.", "response": "def to_networkx_graph(H):\n    \"\"\"Returns a NetworkX Graph object that is the graph decomposition of\n    the given H.\n    See \"to_graph_decomposition()\" for more details.\n\n    :param H: the H to decompose into a graph.\n    :returns: nx.Graph -- NetworkX Graph object representing the\n            decomposed H.\n    :raises: TypeError -- Transformation only applicable to\n            undirected Hs\n\n    \"\"\"\n    import networkx as nx\n\n    if not isinstance(H, UndirectedHypergraph):\n        raise TypeError(\"Transformation only applicable to \\\n                        undirected Hs\")\n\n    G = to_graph_decomposition(H)\n\n    nx_graph = nx.Graph()\n\n    for node in G.node_iterator():\n        nx_graph.add_node(node, G.get_node_attributes(node))\n\n    for hyperedge_id in G.hyperedge_id_iterator():\n        edge_nodes = G.get_hyperedge_nodes(hyperedge_id)\n        edge_attributes = G.get_hyperedge_attributes(hyperedge_id)\n        nx_graph.add_edge(edge_nodes[0], edge_nodes[1], edge_attributes)\n\n    return nx_graph"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_networkx_graph(nx_graph):\n    import networkx as nx\n\n    if not isinstance(nx_graph, nx.Graph):\n        raise TypeError(\"Transformation only applicable to undirected \\\n                        NetworkX graphs\")\n\n    G = UndirectedHypergraph()\n\n    for node in nx_graph.nodes_iter():\n        G.add_node(node, copy.copy(nx_graph.node[node]))\n\n    for edge in nx_graph.edges_iter():\n        G.add_hyperedge([edge[0], edge[1]],\n                        copy.copy(nx_graph[edge[0]][edge[1]]))\n\n    return G", "response": "Returns an UndirectedHypergraph object that is the graph equivalent of the undirected graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stationary_distribution(H, pi=None, P=None):\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to undirected hypergraphs\")\n\n    for node in H.node_iterator():\n        if len(H.get_forward_star(node)) == 0:\n            raise AssertionError(\"Each node must have at least 1 outgoing \\\n                                  hyperedge (even if it's only a self-loop).\")\n\n    indices_to_nodes, nodes_to_indices = \\\n        dmat.get_node_mapping(H)\n    indices_to_hyperedge_ids, hyperedge_ids_to_indices = \\\n        dmat.get_hyperedge_id_mapping(H)\n\n    if P is None:\n        P = _compute_transition_matrix(H,\n                                       nodes_to_indices,\n                                       hyperedge_ids_to_indices)\n\n    node_count = len(H.get_node_set())\n    if pi is None:\n        pi = _create_random_starter(node_count)\n    pi_star = _create_random_starter(node_count)\n    while not _has_converged(pi_star, pi):\n        pi = pi_star\n        pi_star = pi * P\n\n    return pi", "response": "This function computes the stationary distribution of a random walk on the given hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compute_transition_matrix(H,\n                               nodes_to_indices,\n                               hyperedge_ids_to_indices):\n    \"\"\"Computes the transition matrix for a random walk on the given\n    hypergraph as described in the paper:\n    Aurelien Ducournau, Alain Bretto, Random walks in directed hypergraphs and\n    application to semi-supervised image segmentation,\n    Computer Vision and Image Understanding, Volume 120, March 2014,\n    Pages 91-102, ISSN 1077-3142, http://dx.doi.org/10.1016/j.cviu.2013.10.012.\n    (http://www.sciencedirect.com/science/article/pii/S1077314213002038)\n\n    :param H: the hypergraph to find the transition matrix of.\n    :param nodes_to_indices: for each node, maps the node to its\n                            corresponding integer index.\n    :param hyperedge_ids_to_indices: for each hyperedge ID, maps the hyperedge\n                                    ID to its corresponding integer index.\n    :returns: sparse.csc_matrix -- the transition matrix as a sparse matrix.\n\n    \"\"\"\n    M_out = dmat.get_tail_incidence_matrix(H,\n                                           nodes_to_indices,\n                                           hyperedge_ids_to_indices)\n    M_in = dmat.get_head_incidence_matrix(H,\n                                          nodes_to_indices,\n                                          hyperedge_ids_to_indices)\n    W = dmat.get_hyperedge_weight_matrix(H, hyperedge_ids_to_indices)\n    D_v_out = dmat.get_vertex_degree_matrix(M_out, W)\n    D_e_in = dmat.get_hyperedge_degree_matrix(M_in)\n\n    D_v_out_inv = dmat.fast_inverse(D_v_out)\n    D_e_in_inv = dmat.fast_inverse(D_e_in)\n    M_in_trans = M_in.transpose()\n\n    P = D_v_out_inv * M_out * W * D_e_in_inv * M_in_trans\n\n    return P", "response": "Computes the transition matrix for a random walk on the given hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a DirectedHypergraph object that has the same nodes and edges as the given hypergraph and with the same attributes as the given hypergraph.", "response": "def to_graph_decomposition(H):\n    \"\"\"Returns a DirectedHypergraph object that has the same nodes (and\n    corresponding attributes) as the given hypergraph, except that for all\n    hyperedges in the given hypergraph, each node in the tail of the hyperedge\n    is pairwise connected to each node in the head of the hyperedge in the\n    new hypergraph.\n    Said another way, each of the original hyperedges are decomposed in the\n    new hypergraph into fully-connected bipartite components.\n\n    :param H: the hypergraph to decompose into a graph.\n    :returns: DirectedHypergraph -- the decomposed hypergraph.\n    :raises: TypeError -- Transformation only applicable to\n            directed hypergraphs\n\n    \"\"\"\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Transformation only applicable to \\\n                        directed hypergraphs\")\n\n    G = DirectedHypergraph()\n\n    nodes = [(node, H.get_node_attributes(node_attributes))\n             for node in G.node_iterator()]\n    G.add_nodes(nodes)\n\n    edges = [([tail_node], [head_node])\n             for hyperedge_id in H.hyperedge_id_iterator()\n             for tail_node in H.get_hyperedge_tail(hyperedge_id)\n             for head_node in H.get_hyperedge_head(hyperedge_id)]\n    G.add_hyperedges(edges)\n\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a NetworkX DiGraph object representing the graph decomposition of the given hypergraph.", "response": "def to_networkx_digraph(H):\n    \"\"\"Returns a NetworkX DiGraph object that is the graph decomposition of\n    the given hypergraph.\n    See \"to_graph_decomposition()\" for more details.\n\n    :param H: the hypergraph to decompose into a graph.\n    :returns: nx.DiGraph -- NetworkX DiGraph object representing the\n            decomposed hypergraph.\n    :raises: TypeError -- Transformation only applicable to\n            directed hypergraphs\n\n    \"\"\"\n    import networkx as nx\n\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Transformation only applicable to \\\n                        directed hypergraphs\")\n\n    G = to_graph_decomposition(H)\n\n    nx_graph = nx.DiGraph()\n\n    for node in G.node_iterator():\n        nx_graph.add_node(node, G.get_node_attributes(node))\n\n    for hyperedge_id in G.hyperedge_id_iterator():\n        tail_node = G.get_hyperedge_tail(hyperedge_id).pop()\n        head_node = G.get_hyperedge_head(hyperedge_id).pop()\n        edge_attributes = G.get_hyperedge_attributes(hyperedge_id)\n        nx_graph.add_edge(tail_node, head_node, edge_attributes)\n\n    return nx_graph"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a DirectedHypergraph object that is the graph equivalent to the NetworkX DiGraph object.", "response": "def from_networkx_digraph(nx_digraph):\n    \"\"\"Returns a DirectedHypergraph object that is the graph equivalent of the\n    given NetworkX DiGraph object.\n\n    :param nx_digraph: the NetworkX directed graph object to transform.\n    :returns: DirectedHypergraph -- hypergraph object equivalent to the\n            NetworkX directed graph.\n    :raises: TypeError -- Transformation only applicable to directed\n            NetworkX graphs\n\n    \"\"\"\n    import networkx as nx\n\n    if not isinstance(nx_digraph, nx.DiGraph):\n        raise TypeError(\"Transformation only applicable to directed \\\n                        NetworkX graphs\")\n\n    G = DirectedHypergraph()\n\n    for node in nx_digraph.nodes_iter():\n        G.add_node(node, copy.copy(nx_digraph.node[node]))\n\n    for edge in nx_digraph.edges_iter():\n        tail_node = edge[0]\n        head_node = edge[1]\n        G.add_hyperedge(tail_node,\n                        head_node,\n                        copy.copy(nx_digraph[tail_node][head_node]))\n\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tail_incidence_matrix(H, nodes_to_indices, hyperedge_ids_to_indices):\n    if not isinstance(H, DirectedHypergraph):\n        raise TypeError(\"Algorithm only applicable to directed hypergraphs\")\n\n    rows, cols = [], []\n    for hyperedge_id, hyperedge_index in hyperedge_ids_to_indices.items():\n        for node in H.get_hyperedge_tail(hyperedge_id):\n            # get the mapping between the node and its ID\n            rows.append(nodes_to_indices.get(node))\n            cols.append(hyperedge_index)\n\n    values = np.ones(len(rows), dtype=int)\n    node_count = len(H.get_node_set())\n    hyperedge_count = len(H.get_hyperedge_id_set())\n\n    return sparse.csc_matrix((values, (rows, cols)),\n                             shape=(node_count, hyperedge_count))", "response": "Returns the incidence matrix of the tail nodes of the given hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a node to the graph along with any related attributes of the node.", "response": "def add_node(self, node, attr_dict=None, **attr):\n        \"\"\"Adds a node to the graph, along with any related attributes\n           of the node.\n\n        :param node: reference to the node being added.\n        :param attr_dict: dictionary of attributes of the node.\n        :param attr: keyword arguments of attributes of the node;\n                    attr's values will override attr_dict's values\n                    if both are provided.\n\n        Examples:\n        ::\n\n            >>> H = DirectedHypergraph()\n            >>> attributes = {label: \"positive\"}\n            >>> H.add_node(\"A\", attributes)\n            >>> H.add_node(\"B\", label=\"negative\")\n            >>> H.add_node(\"C\", attributes, root=True)\n\n        \"\"\"\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        # If the node hasn't previously been added, add it along\n        # with its attributes\n        if not self.has_node(node):\n            self._node_attributes[node] = attr_dict\n            self._forward_star[node] = set()\n            self._backward_star[node] = set()\n        # Otherwise, just update the node's attributes\n        else:\n            self._node_attributes[node].update(attr_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_nodes(self, nodes, attr_dict=None, **attr):\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        for node in nodes:\n            # Note: This won't behave properly if the node is actually a tuple\n            if type(node) is tuple:\n                # See (\"B\", {label=\"negative\"}) in the documentation example\n                new_node, node_attr_dict = node\n                # Create a new dictionary and load it with node_attr_dict and\n                # attr_dict, with the former (node_attr_dict) taking precedence\n                new_dict = attr_dict.copy()\n                new_dict.update(node_attr_dict)\n                self.add_node(new_node, new_dict)\n            else:\n                # See \"A\" in the documentation example\n                self.add_node(node, attr_dict.copy())", "response": "Adds multiple nodes to the graph along with any related attributes of the nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trim_node(self, node):\n    \n        fs = self.get_forward_star(node)\n        bs = self.get_backward_star(node)\n        remove_set = set()\n    \n        def get_attrs(H, hyperedge):\n            #copies the attribute dictionary of a hyperedge except for the head and tail\n            new_attrs = {}\n            old_attrs = H.get_hyperedge_attributes(hyperedge)\n        \n            for key in old_attrs:\n                if key not in {'head', 'tail'}:\n                    new_attrs[key] = old_attrs[key]\n            return new_attrs\n    \n        for hedge in fs:\n            tail = set(self.get_hyperedge_tail(hedge))\n            head = set(self.get_hyperedge_head(hedge))\n            if len(tail) > 1:\n                new_tail = tail - {node}\n                attrs = get_attrs(self, hedge)\n                self.add_hyperedge(new_tail, head, attrs)\n            remove_set.add(hedge)\n            \n        for hedge in bs:\n            tail = set(self.get_hyperedge_tail(hedge))\n            head = set(self.get_hyperedge_head(hedge))\n            if len(head) > 1:\n                new_head = head - {node}\n                attrs = get_attrs(self, hedge)\n                self.add_hyperedge(tail, new_head, attrs)\n            remove_set.add(hedge)\n\n        for hedge in remove_set:\n            self.remove_hyperedge(hedge)\n            \n        self.remove_node(node)", "response": "Removes a node from the hypergraph. Modifies hypredges with the \n        head or tail so that they no longer include \n        the trimmed node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a node and the name of an attribute return a copy of that node s attribute.", "response": "def get_node_attribute(self, node, attribute_name):\n        \"\"\"Given a node and the name of an attribute, get a copy\n        of that node's attribute.\n\n        :param node: reference to the node to retrieve the attribute of.\n        :param attribute_name: name of the attribute to retrieve.\n        :returns: attribute value of the attribute_name key for the\n                specified node.\n        :raises: ValueError -- No such node exists.\n        :raises: ValueError -- No such attribute exists.\n\n        \"\"\"\n        if not self.has_node(node):\n            raise ValueError(\"No such node exists.\")\n        elif attribute_name not in self._node_attributes[node]:\n            raise ValueError(\"No such attribute exists.\")\n        else:\n            return copy.\\\n                copy(self._node_attributes[node][attribute_name])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_node_attributes(self, node):\n        if not self.has_node(node):\n            raise ValueError(\"No such node exists.\")\n        attributes = {}\n        for attr_name, attr_value in self._node_attributes[node].items():\n            attributes[attr_name] = copy.copy(attr_value)\n        return attributes", "response": "Given a node get a dictionary with copies of that node s\n        attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_hyperedge(self, tail, head, attr_dict=None, **attr):\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        # Don't allow both empty tail and head containers (invalid hyperedge)\n        if not tail and not head:\n            raise ValueError(\"tail and head arguments \\\n                             cannot both be empty.\")\n\n        # Use frozensets for tail and head sets to allow for hashable keys\n        frozen_tail = frozenset(tail)\n        frozen_head = frozenset(head)\n\n        # Initialize a successor dictionary for the tail and head, respectively\n        if frozen_tail not in self._successors:\n            self._successors[frozen_tail] = {}\n        if frozen_head not in self._predecessors:\n            self._predecessors[frozen_head] = {}\n\n        is_new_hyperedge = not self.has_hyperedge(frozen_tail, frozen_head)\n        if is_new_hyperedge:\n            # Add tail and head nodes to graph (if not already present)\n            self.add_nodes(frozen_head)\n            self.add_nodes(frozen_tail)\n\n            # Create new hyperedge name to use as reference for that hyperedge\n            hyperedge_id = self._assign_next_hyperedge_id()\n\n            # Add hyperedge to the forward-star and to the backward-star\n            # for each node in the tail and head sets, respectively\n            for node in frozen_tail:\n                self._forward_star[node].add(hyperedge_id)\n            for node in frozen_head:\n                self._backward_star[node].add(hyperedge_id)\n\n            # Add the hyperedge as the successors and predecessors\n            # of the tail set and head set, respectively\n            self._successors[frozen_tail][frozen_head] = hyperedge_id\n            self._predecessors[frozen_head][frozen_tail] = hyperedge_id\n\n            # Assign some special attributes to this hyperedge. We assign\n            # a default weight of 1 to the hyperedge. We also store the\n            # original tail and head sets in order to return them exactly\n            # as the user passed them into add_hyperedge.\n            self._hyperedge_attributes[hyperedge_id] = \\\n                {\"tail\": tail, \"__frozen_tail\": frozen_tail,\n                 \"head\": head, \"__frozen_head\": frozen_head,\n                 \"weight\": 1}\n        else:\n            # If its not a new hyperedge, just get its ID to update attributes\n            hyperedge_id = self._successors[frozen_tail][frozen_head]\n\n        # Set attributes and return hyperedge ID\n        self._hyperedge_attributes[hyperedge_id].update(attr_dict)\n        return hyperedge_id", "response": "Adds a hyperedge to the hypergraph along with any related attributes of the hyperedge."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds multiple hyperedges to the graph along with any related node attributes of the hyperedges.", "response": "def add_hyperedges(self, hyperedges, attr_dict=None, **attr):\n        \"\"\"Adds multiple hyperedges to the graph, along with any related\n            attributes of the hyperedges.\n            If any node in the tail or head of any hyperedge has not\n            previously been added to the hypergraph, it will automatically\n            be added here. Hyperedges without a \"weight\" attribute specified\n            will be assigned the default value of 1.\n\n        :param hyperedges: iterable container to either tuples of\n                    (tail reference, head reference) OR tuples of\n                    (tail reference, head reference, attribute dictionary);\n                    if an attribute dictionary is provided in the tuple,\n                    its values will override both attr_dict's and attr's\n                    values.\n        :param attr_dict: dictionary of attributes shared by all\n                    the hyperedges.\n        :param attr: keyword arguments of attributes of the hyperedges;\n                    attr's values will override attr_dict's values\n                    if both are provided.\n        :returns: list -- the IDs of the hyperedges added in the order\n                    specified by the hyperedges container's iterator.\n\n        See also:\n        add_hyperedge\n\n        Examples:\n        ::\n\n            >>> H = DirectedHypergraph()\n            >>> xyz = hyperedge_list = (([\"A\", \"B\"], [\"C\", \"D\"]),\n                                        ((\"A\", \"C\"), (\"B\"), {'weight': 2}),\n                                        (set([\"D\"]), set([\"A\", \"C\"])))\n            >>> H.add_hyperedges(hyperedge_list)\n\n        \"\"\"\n        attr_dict = self._combine_attribute_arguments(attr_dict, attr)\n\n        hyperedge_ids = []\n\n        for hyperedge in hyperedges:\n            if len(hyperedge) == 3:\n                # See (\"A\", \"C\"), (\"B\"), {weight: 2}) in the\n                # documentation example\n                tail, head, hyperedge_attr_dict = hyperedge\n                # Create a new dictionary and load it with node_attr_dict and\n                # attr_dict, with the former (node_attr_dict) taking precedence\n                new_dict = attr_dict.copy()\n                new_dict.update(hyperedge_attr_dict)\n                hyperedge_id = self.add_hyperedge(tail, head, new_dict)\n            else:\n                # See ([\"A\", \"B\"], [\"C\", \"D\"]) in the documentation example\n                tail, head = hyperedge\n                hyperedge_id = \\\n                    self.add_hyperedge(tail, head, attr_dict.copy())\n            hyperedge_ids.append(hyperedge_id)\n\n        return hyperedge_ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_hyperedge(self, hyperedge_id):\n        if not self.has_hyperedge_id(hyperedge_id):\n            raise ValueError(\"No such hyperedge exists.\")\n\n        frozen_tail = \\\n            self._hyperedge_attributes[hyperedge_id][\"__frozen_tail\"]\n        frozen_head = \\\n            self._hyperedge_attributes[hyperedge_id][\"__frozen_head\"]\n\n        # Remove this hyperedge from the forward-star of every tail node\n        for node in frozen_tail:\n            self._forward_star[node].remove(hyperedge_id)\n        # Remove this hyperedge from the backward-star of every head node\n        for node in frozen_head:\n            self._backward_star[node].remove(hyperedge_id)\n\n        # Remove frozen_head as a successor of frozen_tail\n        del self._successors[frozen_tail][frozen_head]\n        # If that tail is no longer the tail of any hyperedge, remove it\n        # from the successors dictionary\n        if self._successors[frozen_tail] == {}:\n            del self._successors[frozen_tail]\n        # Remove frozen_tail as a predecessor of frozen_head\n        del self._predecessors[frozen_head][frozen_tail]\n        # If that head is no longer the head of any hyperedge, remove it\n        # from the predecessors dictionary\n        if self._predecessors[frozen_head] == {}:\n            del self._predecessors[frozen_head]\n\n        # Remove hyperedge's attributes dictionary\n        del self._hyperedge_attributes[hyperedge_id]", "response": "Removes a hyperedge and its attributes from the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_hyperedge_id(self, tail, head):\n        frozen_tail = frozenset(tail)\n        frozen_head = frozenset(head)\n\n        if not self.has_hyperedge(frozen_tail, frozen_head):\n            raise ValueError(\"No such hyperedge exists.\")\n\n        return self._successors[frozen_tail][frozen_head]", "response": "This method returns the ID of the hyperedge that has that set of nodes in the specified tail and head sets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_forward_star(self, node):\n        if node not in self._node_attributes:\n            raise ValueError(\"No such node exists.\")\n        return self._forward_star[node].copy()", "response": "Given a node get a copy of that node s forward star."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a node get a copy of that node s backward star.", "response": "def get_backward_star(self, node):\n        \"\"\"Given a node, get a copy of that node's backward star.\n\n        :param node: node to retrieve the backward-star of.\n        :returns: set -- set of hyperedge_ids for the hyperedges\n                in the node's backward star.\n        :raises: ValueError -- No such node exists.\n\n        \"\"\"\n        if node not in self._node_attributes:\n            raise ValueError(\"No such node exists.\")\n        return self._backward_star[node].copy()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_successors(self, tail):\n        frozen_tail = frozenset(tail)\n        # If this node set isn't any tail in the hypergraph, then it has\n        # no successors; thus, return an empty list\n        if frozen_tail not in self._successors:\n            return set()\n\n        return set(self._successors[frozen_tail].values())", "response": "Given a tail set of nodes return a list of hyperedge_ids of which the node set is the tail of each edge."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_predecessors(self, head):\n        frozen_head = frozenset(head)\n        # If this node set isn't any head in the hypergraph, then it has\n        # no predecessors; thus, return an empty list\n        if frozen_head not in self._predecessors:\n            return set()\n\n        return set(self._predecessors[frozen_head].values())", "response": "Given a head set of nodes get a list of edges of which the node set\nCOOKIE is the head of each edge."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_B_hypergraph(self):\n        for hyperedge_id in self._hyperedge_attributes:\n            head = self.get_hyperedge_head(hyperedge_id)\n            if len(head) > 1:\n                return False\n        return True", "response": "Indicates whether the hypergraph is a B - hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nindicate whether the hypergraph is an F - hypergraph.", "response": "def is_F_hypergraph(self):\n        \"\"\"Indicates whether the hypergraph is an F-hypergraph.\n        In an F-hypergraph, all hyperedges are F-hyperedges -- that is, every\n        hyperedge has exactly one node in the tail.\n\n        :returns: bool -- True iff the hypergraph is an F-hypergraph.\n\n        \"\"\"\n        for hyperedge_id in self._hyperedge_attributes:\n            tail = self.get_hyperedge_tail(hyperedge_id)\n            if len(tail) > 1:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_BF_hypergraph(self):\n        for hyperedge_id in self._hyperedge_attributes:\n            tail = self.get_hyperedge_tail(hyperedge_id)\n            head = self.get_hyperedge_head(hyperedge_id)\n            if len(tail) > 1 and len(head) > 1:\n                return False\n        return True", "response": "Indicates whether the hypergraph is a BF - hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new DirectedHypergraph object that is the symmetric image of the current hypergraph.", "response": "def get_symmetric_image(self):\n        \"\"\"Creates a new DirectedHypergraph object that is the symmetric\n        image of this hypergraph (i.e., identical hypergraph with all\n        edge directions reversed).\n        Copies of each of the nodes' and hyperedges' attributes are stored\n        and used in the new hypergraph.\n\n        :returns: DirectedHypergraph -- a new hypergraph that is the symmetric\n                image of the current hypergraph.\n\n        \"\"\"\n        new_H = self.copy()\n\n        # No change to _node_attributes necessary, as nodes remain the same\n\n        # Reverse the tail and head (and __frozen_tail and __frozen_head) for\n        # every hyperedge\n        for hyperedge_id in self.get_hyperedge_id_set():\n            attr_dict = new_H._hyperedge_attributes[hyperedge_id]\n            attr_dict[\"tail\"], attr_dict[\"head\"] = \\\n                attr_dict[\"head\"], attr_dict[\"tail\"]\n            attr_dict[\"__frozen_tail\"], attr_dict[\"__frozen_head\"] = \\\n                attr_dict[\"__frozen_head\"], attr_dict[\"__frozen_tail\"]\n\n        # Reverse the definition of forward star and backward star\n        new_H._forward_star, new_H._backward_star = \\\n            new_H._backward_star, new_H._forward_star\n\n        # Reverse the definition of successor and predecessor\n        new_H._successors, new_H._predecessors = \\\n            new_H._predecessors, new_H._successors\n\n        return new_H"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new DirectedHypergraph that is the subhypergraph of the current node set that is the induced subhypergraph of the provided set of nodes.", "response": "def get_induced_subhypergraph(self, nodes):\n        \"\"\"Gives a new hypergraph that is the subhypergraph of the current\n        hypergraph induced by the provided set of nodes. That is, the induced\n        subhypergraph's node set corresponds precisely to the nodes provided,\n        and the coressponding hyperedges in the subhypergraph are only those\n        from the original graph consist of tail and head sets that are subsets\n        of the provided nodes.\n\n        :param nodes: the set of nodes to find the induced subhypergraph of.\n        :returns: DirectedHypergraph -- the subhypergraph induced on the\n                provided nodes.\n\n        \"\"\"\n        sub_H = self.copy()\n        sub_H.remove_nodes(sub_H.get_node_set() - set(nodes))\n        return sub_H"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, file_name, delim=',', sep='\\t'):\n        in_file = open(file_name, 'r')\n\n        # Skip the header line\n        in_file.readline()\n\n        line_number = 2\n        for line in in_file.readlines():\n            line = line.strip()\n            # Skip empty lines\n            if not line:\n                continue\n\n            words = line.split(sep)\n            if not (2 <= len(words) <= 3):\n                raise \\\n                    IOError(\"Line {} \".format(line_number) +\n                            \"contains {} \".format(len(words)) +\n                            \"columns -- must contain only 2 or 3.\")\n\n            tail = set(words[0].split(delim))\n            head = set(words[1].split(delim))\n            if len(words) == 3:\n                weight = float(words[2].split(delim)[0])\n            else:\n                weight = 1\n            self.add_hyperedge(tail, head, weight=weight)\n\n            line_number += 1\n\n        in_file.close()", "response": "Read a directed hypergraph from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, file_name, delim=',', sep='\\t'):\n        out_file = open(file_name, 'w')\n\n        # write first header line\n        out_file.write(\"tail\" + sep + \"head\" + sep + \"weight\\n\")\n\n        for hyperedge_id in self.get_hyperedge_id_set():\n            line = \"\"\n            # Write each tail node to the line, separated by delim\n            for tail_node in self.get_hyperedge_tail(hyperedge_id):\n                line += tail_node + delim\n            # Remove last (extra) delim\n            line = line[:-1]\n\n            # Add sep between columns\n            line += sep\n\n            # Write each head node to the line, separated by delim\n            for head_node in self.get_hyperedge_head(hyperedge_id):\n                line += head_node + delim\n            # Remove last (extra) delim\n            line = line[:-1]\n\n            # Write the weight to the line and end the line\n            line += sep + str(self.get_hyperedge_weight(hyperedge_id)) + \"\\n\"\n\n            out_file.write(line)\n\n        out_file.close()", "response": "Write a directed hypergraph to a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_hyperedge_attributes_consistency(self):\n        # required_attrs are attributes that every hyperedge must have.\n        required_attrs = ['weight', 'tail', 'head',\n                          '__frozen_tail', '__frozen_head']\n\n        # Get list of hyperedge_ids from the hyperedge attributes dict\n        hyperedge_ids_from_attributes = set(self._hyperedge_attributes.keys())\n\n        # Perform consistency checks on each hyperedge id.\n        for hyperedge_id in hyperedge_ids_from_attributes:\n\n            # Check 1.1: make sure every hyperedge id has a weight,\n            # tail, head, frozen tail, and frozen head\n            hyperedge_attr_dict = self._hyperedge_attributes[hyperedge_id]\n            for required_attr in required_attrs:\n                if required_attr not in hyperedge_attr_dict:\n                    raise ValueError(\n                        'Consistency Check 1.1 Failed: hyperedge ' +\n                        'attribute dictionary for hyperedge_id ' +\n                        '%s is missing required attribute %s' %\n                        (hyperedge_id, required_attr))\n\n            # Check 1.2: make sure frozenset(tail) == __frozen_tail\n            if frozenset(hyperedge_attr_dict['tail']) != \\\n               hyperedge_attr_dict['__frozen_tail']:\n                raise ValueError(\n                    'Consistency Check 1.2 Failed: frozenset ' +\n                    'tail is different from __frozen_tail ' +\n                    'attribute for hyperedge id %s' % (hyperedge_id))\n\n            # Check 1.3: make sure frozenset(head) == __frozen_head\n            if frozenset(hyperedge_attr_dict['head']) != \\\n               hyperedge_attr_dict['__frozen_head']:\n                raise ValueError(\n                    'Consistency Check 1.3 Failed: frozenset ' +\n                    'head is different from __frozen_head ' +\n                    'attribute for hyperedge id %s' % (hyperedge_id))\n\n            # get tail and head frozenset\n            tailset = hyperedge_attr_dict['__frozen_tail']\n            headset = hyperedge_attr_dict['__frozen_head']\n\n            # Check 1.4: make sure successors dictionary contains the\n            # hyperedge id. Need to also check that tailset and\n            # headset are entries into the dict.\n            if tailset not in self._successors or \\\n               headset not in self._successors[tailset] or \\\n               self._successors[tailset][headset] != hyperedge_id:\n                raise ValueError(\n                    'Consistency Check 1.4 Failed: hyperedge ' +\n                    'id %s not in self._successors.' % (hyperedge_id))\n\n            # Check 1.5: make sure predecessors dictionary contains\n            # the hyperedge id. Need to also check that headset and\n            # tailset are entries into the dict.\n            if headset not in self._predecessors or \\\n               tailset not in self._predecessors[headset] or \\\n               self._predecessors[headset][tailset] != hyperedge_id:\n                raise ValueError(\n                    'Consistency Check 1.5 Failed: hyperedge ' +\n                    'id %s not in self._predecessors.' % (hyperedge_id))\n\n            # Check 1.6: make sure every tail node in tailset\n            # contains the hyperedge_id in the forward star.\n            for tail_node in tailset:\n                if hyperedge_id not in self._forward_star[tail_node]:\n                    raise ValueError(\n                        'Consistency Check 1.6 Failed: hyperedge ' +\n                        'id ' + hyperedge_id + ' is not in the ' +\n                        'forward star of tail node ' + tail_node)\n\n            # Check 1.7: make sure every head node in headset\n            # contains the hyperedge_id in the backward star.\n            for head_node in headset:\n                if hyperedge_id not in self._backward_star[head_node]:\n                    raise ValueError(\n                        'Consistency Check 1.7 Failed: hyperedge ' +\n                        'id ' + hyperedge_id + ' is not in the ' +\n                        'backward star of head node ' + tail_node)", "response": "Checks that the hyperedge attributes are consistent and that they are not already in the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_node_attributes_consistency(self):\n        # Get list of nodes from the node attributes dict\n        nodes_from_attributes = set(self._node_attributes.keys())\n\n        # Perform consistency checks on each node.\n        for node in nodes_from_attributes:\n\n            # Check 2.1: make sure that the forward star for the node\n            # exists.\n            if node not in self._forward_star:\n                raise ValueError(\n                    'Consistency Check 2.1 Failed: node ' +\n                    '%s not in forward star dict' % (str(node)))\n\n            # Check 2.2: make sure that the backward star for the node\n            # exists.\n            if node not in self._backward_star:\n                raise ValueError(\n                    'Consistency Check 2.2 Failed: node ' +\n                    '%s not in backward star dict' % (str(node)))\n\n            # Get backward star and forward star\n            node_fstar = self._forward_star[node]\n            node_bstar = self._backward_star[node]\n\n            # Check 2.3: make sure every hyperedge id in the forward\n            # star contains the node in the tail\n            for hyperedge_id in node_fstar:\n                if hyperedge_id not in self._hyperedge_attributes or \\\n                   node not in \\\n                   self._hyperedge_attributes[hyperedge_id]['tail']:\n                    raise ValueError(\n                        'Consistency Check 2.3 Failed: node %s ' % str(node) +\n                        'has hyperedge id %s in the forward ' % hyperedge_id +\n                        'star, but %s is not in the tail of ' % str(node) +\n                        '%s' % hyperedge_id)\n\n            # Check 2.4: make sure every hyperedge id in the backward\n            # star contains the node in the head\n            for hyperedge_id in node_bstar:\n                if hyperedge_id not in self._hyperedge_attributes or \\\n                   node not in \\\n                   self._hyperedge_attributes[hyperedge_id]['head']:\n                    raise ValueError(\n                        'Consistency Check 2.4 Failed: node %s ' % str(node) +\n                        'has hyperedge id %s in the forward ' % hyperedge_id +\n                        'star, but %s is not in the tail of ' % str(node) +\n                        '%s' % hyperedge_id)", "response": "Checks that the node attributes of the node are consistent with the hyperedges in the hypergraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_predecessor_successor_consistency(self):\n        # Check 3.1: ensure that predecessors has the same headsets\n        # that successors has\n        predecessor_heads = set(self._predecessors.keys())\n        successor_heads = set()\n        for key, value in self._successors.items():\n            successor_heads |= set(value.keys())\n        if predecessor_heads != successor_heads:\n            raise ValueError(\n                'Consistency Check 3.1 Failed: successors and predecessors ' +\n                'do not contain the same head sets \\n' +\n                'predecessor heads: %s \\n' % (predecessor_heads) +\n                'successor heads: %s' % (successor_heads))\n\n        # Check 3.2: ensure that predecessors has the same tailsets\n        # that successors has\n        predecessor_tails = set()\n        successor_tails = set(self._successors.keys())\n        for key, value in self._predecessors.items():\n            predecessor_tails |= set(value.keys())\n        if successor_tails != predecessor_tails:\n            raise ValueError(\n                'Consistency Check 3.2 Failed: successors and predecessors ' +\n                'do not contain the same tail sets \\n' +\n                'predecessor tails: %s \\n' % (predecessor_tails) +\n                'successor tails: %s' % (successor_tails))\n\n        # Check 3.3: iterate through predecessors; check successor\n        # symmetry\n        for headset in self._predecessors.keys():\n            for tailset in self._predecessors[headset].keys():\n                if self._predecessors[headset][tailset] != \\\n                        self._successors[tailset][headset]:\n                    raise ValueError(\n                        'Consistency Check 3.3 Failed: ' +\n                        'headset = %s, ' % headset +\n                        'tailset = %s, ' % tailset +\n                        'but predecessors[headset][tailset] = ' +\n                        '%s ' % self._predecessors[headset][tailset] +\n                        'and successors[tailset][headset] = ' +\n                        '%s ' % self._successors[tailset][headset])", "response": "Checks that successors and predecessors are consistent."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_hyperedge_id_consistency(self):\n        # Get list of hyperedge_ids from the hyperedge attributes dict\n        hyperedge_ids_from_attributes = set(self._hyperedge_attributes.keys())\n\n        # get hyperedge ids in the forward star\n        forward_star_hyperedge_ids = set()\n        for hyperedge_id_set in self._forward_star.values():\n            forward_star_hyperedge_ids.update(hyperedge_id_set)\n\n        # get hyperedge ids in the backward star\n        backward_star_hyperedge_ids = set()\n        for hyperedge_id_set in self._backward_star.values():\n            backward_star_hyperedge_ids.update(hyperedge_id_set)\n\n        # Check 4.1: hyperedge ids in the forward star must be the\n        # same as the hyperedge ids from attributes\n        if forward_star_hyperedge_ids != hyperedge_ids_from_attributes:\n            raise ValueError(\n                'Consistency Check 4.1 Failed: hyperedge ids ' +\n                'are different in the forward star ' +\n                'values and the hyperedge ids from ' +\n                'attribute keys.')\n\n        # Check 4.2: hyperedge ids in the backward star must be the\n        # same as the hyperedge ids from attributes\n        if backward_star_hyperedge_ids != hyperedge_ids_from_attributes:\n            raise ValueError(\n                'Consistency Check 4.2 Failed: hyperedge ids ' +\n                'are different in the backward star ' +\n                'values and the hyperedge ids from ' +\n                'attribute keys.')\n\n        # Note that by Check 4.1 and 4.2, forward_star_hyperedge_ids =\n        # backward_star_hyperedge_ids\n\n        # get hyperedge ids in the predecessors dict\n        predecessor_hyperedge_ids = set()\n        for all_tails_from_predecessor in self._predecessors.values():\n            for hyperedge_id in all_tails_from_predecessor.values():\n                predecessor_hyperedge_ids.add(hyperedge_id)\n\n        # get hyperedge ids in the successors dict\n        successor_hyperedge_ids = set()\n        for all_heads_from_successor in self._successors.values():\n            for hyperedge_id in all_heads_from_successor.values():\n                successor_hyperedge_ids.add(hyperedge_id)\n\n        # Check 4.3: hyperedge ids in the predecessor dict must be the\n        # same as the hyperedge ids from attributes\n        if predecessor_hyperedge_ids != hyperedge_ids_from_attributes:\n            raise ValueError(\n                'Consistency Check 4.3 Failed: hyperedge ids are ' +\n                'different in the predecessor values and ' +\n                'hyperedge ids from attribute keys.')\n\n        # Check 4.4: hyperedge ids in the successor dict must be the\n        # same as the hyperedge ids from attributes\n        if successor_hyperedge_ids != hyperedge_ids_from_attributes:\n            raise ValueError(\n                'Consistency Check 4.4 Failed: hyperedge ids are ' +\n                'different in the successor values and ' +\n                'hyperedge ids from attribute keys.')", "response": "Check for misplaced hyperedge ids in the attributes and hyperedge ids in the attributes dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the nodes in the node attributes dict are consistent with the hyperedges in the attribute dict.", "response": "def _check_node_consistency(self):\n        \"\"\"Consistency Check 5: check for misplaced nodes\n\n        :raises: ValueError -- detected inconsistency among dictionaries\n\n        \"\"\"\n        # Get list of nodes from the node attributes dict\n        nodes_from_attributes = set(self._node_attributes.keys())\n\n        # Get list of hyperedge_ids from the hyperedge attributes dict\n        hyperedge_ids_from_attributes = set(self._hyperedge_attributes.keys())\n\n        # Check 5.1: all nodes in the forward star must be in the\n        # nodes from attributes\n        forward_diff = set(self._forward_star.keys()) - nodes_from_attributes\n        if forward_diff != set():\n            raise ValueError(\n                'Consistency Check 5.1 Failed: nodes %s ' % forward_diff +\n                '(from forward star keys) is not in the node ' +\n                'attribute dict.')\n\n        # Check 5.2: all nodes in the backward star must be in the\n        # nodes from attributes\n        backward_diff = set(self._backward_star.keys()) - nodes_from_attributes\n        if backward_diff != set():\n            raise ValueError(\n                'Consistency Check 5.2 Failed: node %s ' % backward_diff +\n                '(from backward star keys) is not in the node ' +\n                'attribute dict.')\n\n        # Note that, by Check 5.1 and 5.2, self._forward_star.keys() =\n        # self._backward_star.keys().\n\n        # Check 5.3: all nodes in hyperedge_attributes dictionary must\n        # be in the nodes from attributes.\n        for hyperedge_id in hyperedge_ids_from_attributes:\n            for tailnode in \\\n                    self._hyperedge_attributes[hyperedge_id]['tail']:\n                if tailnode not in nodes_from_attributes:\n                    raise ValueError(\n                        'Consistency Check 5.3.1 Failed: tail ' +\n                        'node %s of ' % tailnode +\n                        'of hyperedge id %s ' % hyperedge_id +\n                        'is not in node attribute dict')\n\n            for headnode in self._hyperedge_attributes[hyperedge_id]['head']:\n                if headnode not in nodes_from_attributes:\n                    raise ValueError(\n                        'Consistency Check 5.3.2 Failed: head ' +\n                        'node %s of ' % headnode +\n                        'of hyperedge id %s ' % hyperedge_id +\n                        'is not in node attribute dict')\n\n        # get set of nodes in predecessor dictionary.\n        # adds both nodes in headset and nodes in tailset.\n        nodes_in_predecessor_dict = set()\n        for headset in self._predecessors.keys():\n            nodes_in_predecessor_dict.update(headset)\n            for tailset in self._predecessors[headset].keys():\n                nodes_in_predecessor_dict.update(tailset)\n\n        # get set of nodes in successor dictionary.\n        # adds both nodes in headset and nodes in tailset.\n        nodes_in_successor_dict = set()\n        for headset in self._successors.keys():\n            nodes_in_successor_dict.update(headset)\n            for tailset in self._successors[headset].keys():\n                nodes_in_successor_dict.update(tailset)\n\n        # Check 5.4: the set of nodes in successor dict is the same as\n        # the set of nodes in the predecessor dict\n        if nodes_in_predecessor_dict != nodes_in_successor_dict:\n            raise ValueError(\n                'Consistency Check 5.4 Failed: nodes in ' +\n                'successor dict are different than nodes ' +\n                'in predecessor dict')\n\n        # Check 5.5: all nodes in predecessor and successor dict must\n        # be in the nodes from attributes (since 5.4 ensures they're the same)\n        for node in nodes_in_predecessor_dict:\n            if node not in nodes_from_attributes:\n                raise ValueError(\n                    'Consistency Check 5.5 Failed: node %s ' % node +\n                    'from predecessor or successor dictionary ' +\n                    'is not in node attribute dict')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_consistency(self):\n        # TODO: is ValueError the proper exception to raise? Should\n        # we make a new exception (\"ConsistencyException\")?\n\n        # TODO: many of these for loops can be replaced by list\n        # comprehension; however the errors currently report the exact\n        # condition that fails. Using list comprehension would allow\n        # us to report which check fails, but not which node/hyperedge\n        # id/etc.x\n\n        self._check_hyperedge_attributes_consistency()\n        self._check_node_attributes_consistency()\n        self._check_predecessor_successor_consistency()\n        self._check_hyperedge_id_consistency()\n        self._check_node_consistency()", "response": "Compares the contents of the six dictionaries and ensures that they are consistent with each other raising a ValueErrorif there is any inconsistency among the hypergraphs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getall(self, key, default=_marker):\n        identity = self._title(key)\n        res = [v for i, k, v in self._impl._items if i == identity]\n        if res:\n            return res\n        if not res and default is not _marker:\n            return default\n        raise KeyError('Key not found: %r' % key)", "response": "Return a list of all values matching the key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extend(self, *args, **kwargs):\n        self._extend(args, kwargs, 'extend', self._extend_items)", "response": "Extend current MultiDict with more values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn value for key set value to default.", "response": "def setdefault(self, key, default=None):\n        \"\"\"Return value for key, set value to default if key is not present.\"\"\"\n        identity = self._title(key)\n        for i, k, v in self._impl._items:\n            if i == identity:\n                return v\n        self.add(key, default)\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves specified key and return the corresponding value. If default is given KeyError is raised.", "response": "def popone(self, key, default=_marker):\n        \"\"\"Remove specified key and return the corresponding value.\n\n        If key is not found, d is returned if given, otherwise\n        KeyError is raised.\n\n        \"\"\"\n        identity = self._title(key)\n        for i in range(len(self._impl._items)):\n            if self._impl._items[i][0] == identity:\n                value = self._impl._items[i][2]\n                del self._impl._items[i]\n                self._impl.incr_version()\n                return value\n        if default is _marker:\n            raise KeyError(key)\n        else:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove all occurrences of key and return the list of corresponding values. If default is given the list of corresponding values is returned otherwise KeyError is raised.", "response": "def popall(self, key, default=_marker):\n        \"\"\"Remove all occurrences of key and return the list of corresponding\n        values.\n\n        If key is not found, default is returned if given, otherwise\n        KeyError is raised.\n\n        \"\"\"\n        found = False\n        identity = self._title(key)\n        ret = []\n        for i in range(len(self._impl._items)-1, -1, -1):\n            item = self._impl._items[i]\n            if item[0] == identity:\n                ret.append(item[2])\n                del self._impl._items[i]\n                self._impl.incr_version()\n                found = True\n        if not found:\n            if default is _marker:\n                raise KeyError(key)\n            else:\n                return default\n        else:\n            ret.reverse()\n            return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef popitem(self):\n        if self._impl._items:\n            i = self._impl._items.pop(0)\n            self._impl.incr_version()\n            return i[1], i[2]\n        else:\n            raise KeyError(\"empty multidict\")", "response": "Remove and return an arbitrary ( key value pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, *args, **kwargs):\n        self._extend(args, kwargs, 'update', self._update_items)", "response": "Update the dictionary from * other* overwriting existing keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the total yield and its associated statistical uncertainty.", "response": "def total(self, xbin1=1, xbin2=-2):\n        \"\"\"\n        Return the total yield and its associated statistical uncertainty.\n        \"\"\"\n        return self.hist.integral(xbin1=xbin1, xbin2=xbin2, error=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of unique systematic names from OverallSys and HistoSys", "response": "def sys_names(self):\n        \"\"\"\n        Return a list of unique systematic names from OverallSys and HistoSys\n        \"\"\"\n        names = {}\n        for osys in self.overall_sys:\n            names[osys.name] = None\n        for hsys in self.histo_sys:\n            names[hsys.name] = None\n        return names.keys()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_sys(self):\n        names = self.sys_names()\n        for name in names:\n            osys = self.GetOverallSys(name)\n            hsys = self.GetHistoSys(name)\n            yield name, osys, hsys", "response": "Iterate over sys_name overall_sys and histo_sys."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sys_hist(self, name=None):\n        if name is None:\n            low = self.hist.Clone(shallow=True)\n            high = self.hist.Clone(shallow=True)\n            return low, high\n        osys = self.GetOverallSys(name)\n        hsys = self.GetHistoSys(name)\n        if osys is None:\n            osys_high, osys_low = 1., 1.\n        else:\n            osys_high, osys_low = osys.high, osys.low\n        if hsys is None:\n            hsys_high = self.hist.Clone(shallow=True)\n            hsys_low = self.hist.Clone(shallow=True)\n        else:\n            hsys_high = hsys.high.Clone(shallow=True)\n            hsys_low = hsys.low.Clone(shallow=True)\n        return hsys_low * osys_low, hsys_high * osys_high", "response": "Return the effective low and high histograms for a given systematic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef total(self, xbin1=1, xbin2=-2):\n        integral, stat_error = self.hist.integral(\n            xbin1=xbin1, xbin2=xbin2, error=True)\n        # sum systematics in quadrature\n        ups = [0]\n        dns = [0]\n        for sys_name in self.sys_names():\n            sys_low, sys_high = self.sys_hist(sys_name)\n            up = sys_high.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            dn = sys_low.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            if up > 0:\n                ups.append(up**2)\n            else:\n                dns.append(up**2)\n            if dn > 0:\n                ups.append(dn**2)\n            else:\n                dns.append(dn**2)\n        syst_error = (sqrt(sum(ups)), sqrt(sum(dns)))\n        return integral, stat_error, syst_error", "response": "Return the total yield and its associated statistical and systematic uncertainties."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of unique systematic names from OverallSys and HistoSys", "response": "def sys_names(self):\n        \"\"\"\n        Return a list of unique systematic names from OverallSys and HistoSys\n        \"\"\"\n        names = []\n        for sample in self.samples:\n            names.extend(sample.sys_names())\n        return list(set(names))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the effective total low and high histograms for a given systematic.", "response": "def sys_hist(self, name=None, where=None):\n        \"\"\"\n        Return the effective total low and high histogram for a given\n        systematic over samples in this channel.\n        If a sample does not contain the named systematic then its nominal\n        histogram is used for both low and high variations.\n\n        Parameters\n        ----------\n\n        name : string, optional (default=None)\n            The systematic name otherwise nominal if None\n\n        where : callable, optional (default=None)\n            A callable taking one argument: the sample, and returns True if\n            this sample should be included in the total.\n\n        Returns\n        -------\n\n        total_low, total_high : histograms\n            The total low and high histograms for this systematic\n\n        \"\"\"\n        total_low, total_high = None, None\n        for sample in self.samples:\n            if where is not None and not where(sample):\n                continue\n            low, high = sample.sys_hist(name)\n            if total_low is None:\n                total_low = low.Clone(shallow=True)\n            else:\n                total_low += low\n            if total_high is None:\n                total_high = high.Clone(shallow=True)\n            else:\n                total_high += high\n        return total_low, total_high"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the total yield and its associated statistical and systematic uncertainties.", "response": "def total(self, where=None, xbin1=1, xbin2=-2):\n        \"\"\"\n        Return the total yield and its associated statistical and\n        systematic uncertainties.\n        \"\"\"\n        nominal, _ = self.sys_hist(None, where=where)\n        integral, stat_error = nominal.integral(\n            xbin1=xbin1, xbin2=xbin2, error=True)\n        ups = [0]\n        dns = [0]\n        for sys_name in self.sys_names():\n            low, high = self.sys_hist(sys_name, where=where)\n            up = high.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            dn = low.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            if up > 0:\n                ups.append(up**2)\n            else:\n                dns.append(up**2)\n            if dn > 0:\n                ups.append(dn**2)\n            else:\n                dns.append(dn**2)\n        syst_error = (sqrt(sum(ups)), sqrt(sum(dns)))\n        return integral, stat_error, syst_error"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getse(op, arg=None):\n    try:\n        return _se[op]\n    except KeyError:\n        # Continue to opcodes with an effect that depends on arg\n        pass\n\n    if arg is None:\n        raise ValueError(\"Opcode stack behaviour depends on arg\")\n\n    def get_func_tup(arg, nextra):\n        if arg > 0xFFFF:\n            raise ValueError(\"Can only split a two-byte argument\")\n        return (nextra + 1 + (arg & 0xFF) + 2*((arg >> 8) & 0xFF),\n                1)\n\n    if op == CALL_FUNCTION:\n        return get_func_tup(arg, 0)\n    elif op == CALL_FUNCTION_VAR:\n        return get_func_tup(arg, 1)\n    elif op == CALL_FUNCTION_KW:\n        return get_func_tup(arg, 1)\n    elif op == CALL_FUNCTION_VAR_KW:\n        return get_func_tup(arg, 2)\n\n    elif op == BUILD_TUPLE:\n        return arg, 1\n    elif op == BUILD_LIST:\n        return arg, 1\n    elif python_version == '2.7' and op == BUILD_SET:\n        return arg, 1\n    elif op == UNPACK_SEQUENCE:\n        return 1, arg\n    elif op == BUILD_SLICE:\n        return arg, 1\n    elif op == DUP_TOPX:\n        return arg, arg*2\n    elif op == RAISE_VARARGS:\n        return 1+arg, 1\n    elif op == MAKE_FUNCTION:\n        return 1+arg, 1\n    elif op == MAKE_CLOSURE:\n        if python_version == '2.4':\n            raise ValueError(\"The stack effect of MAKE_CLOSURE depends on TOS\")\n        else:\n            return 2+arg, 1\n    else:\n        raise ValueError(\"The opcode %r isn't recognized or has a special \"\n                         \"flow control\" % op)", "response": "Get the stack effect of an opcode as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef printcodelist(codelist, to=sys.stdout):\n\n    labeldict = {}\n    pendinglabels = []\n    for i, (op, arg) in enumerate(codelist):\n        if isinstance(op, Label):\n            pendinglabels.append(op)\n        elif op is SetLineno:\n            pass\n        else:\n            while pendinglabels:\n                labeldict[pendinglabels.pop()] = i\n\n    lineno = None\n    islabel = False\n    for i, (op, arg) in enumerate(codelist):\n        if op is SetLineno:\n            lineno = arg\n            print >> to\n            continue\n\n        if isinstance(op, Label):\n            islabel = True\n            continue\n\n        if lineno is None:\n            linenostr = ''\n        else:\n            linenostr = str(lineno)\n            lineno = None\n\n        if islabel:\n            islabelstr = '>>'\n            islabel = False\n        else:\n            islabelstr = ''\n\n        if op in hasconst:\n            argstr = repr(arg)\n        elif op in hasjump:\n            try:\n                argstr = 'to ' + str(labeldict[arg])\n            except KeyError:\n                argstr = repr(arg)\n        elif op in hasarg:\n            argstr = str(arg)\n        else:\n            argstr = ''\n\n        print >> to, '%3s     %2s %4d %-20s %s' % (\n            linenostr,\n            islabelstr,\n            i,\n            op,\n            argstr)", "response": "Print a code list. Print it nicely."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recompile(filename):\n    # Most of the code here based on the compile.py module.\n    import os\n    import imp\n    import marshal\n    import struct\n\n    f = open(filename, 'U')\n    try:\n        timestamp = long(os.fstat(f.fileno()).st_mtime)\n    except AttributeError:\n        timestamp = long(os.stat(filename).st_mtime)\n    codestring = f.read()\n    f.close()\n    if codestring and codestring[-1] != '\\n':\n        codestring = codestring + '\\n'\n    try:\n        codeobject = compile(codestring, filename, 'exec')\n    except SyntaxError:\n        print >> sys.stderr, \"Skipping %s - syntax error.\" % filename\n        return\n    cod = Code.from_code(codeobject)\n    message = \"reassembled %r imported.\\n\" % filename\n    cod.code[:0] = [ # __import__('sys').stderr.write(message)\n        (LOAD_GLOBAL, '__import__'),\n        (LOAD_CONST, 'sys'),\n        (CALL_FUNCTION, 1),\n        (LOAD_ATTR, 'stderr'),\n        (LOAD_ATTR, 'write'),\n        (LOAD_CONST, message),\n        (CALL_FUNCTION, 1),\n        (POP_TOP, None),\n        ]\n    codeobject2 = cod.to_code()\n    fc = open(filename+'c', 'wb')\n    fc.write('\\0\\0\\0\\0')\n    fc.write(struct.pack('<l', timestamp))\n    marshal.dump(codeobject2, fc)\n    fc.flush()\n    fc.seek(0, 0)\n    fc.write(imp.get_magic())\n    fc.close()", "response": "Create a. pyc by disassembling the file and assembling it again printing\n    a message that the reassembled file was loaded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisassemble a Python code object into a Code object.", "response": "def from_code(cls, co):\n        \"\"\"Disassemble a Python code object into a Code object.\"\"\"\n        co_code = co.co_code\n        labels = dict((addr, Label()) for addr in findlabels(co_code))\n        linestarts = dict(cls._findlinestarts(co))\n        cellfree = co.co_cellvars + co.co_freevars\n\n        code = CodeList()\n        n = len(co_code)\n        i = 0\n        extended_arg = 0\n        while i < n:\n            op = Opcode(ord(co_code[i]))\n            if i in labels:\n                code.append((labels[i], None))\n            if i in linestarts:\n                code.append((SetLineno, linestarts[i]))\n            i += 1\n            if op in hascode:\n                lastop, lastarg = code[-1]\n                if lastop != LOAD_CONST:\n                    raise ValueError(\n                        \"%s should be preceded by LOAD_CONST code\" % op)\n                code[-1] = (LOAD_CONST, Code.from_code(lastarg))\n            if op not in hasarg:\n                code.append((op, None))\n            else:\n                arg = ord(co_code[i]) + ord(co_code[i+1])*256 + extended_arg\n                extended_arg = 0\n                i += 2\n                if op == opcode.EXTENDED_ARG:\n                    extended_arg = arg << 16\n                elif op in hasconst:\n                    code.append((op, co.co_consts[arg]))\n                elif op in hasname:\n                    code.append((op, co.co_names[arg]))\n                elif op in hasjabs:\n                    code.append((op, labels[arg]))\n                elif op in hasjrel:\n                    code.append((op, labels[i + arg]))\n                elif op in haslocal:\n                    code.append((op, co.co_varnames[arg]))\n                elif op in hascompare:\n                    code.append((op, cmp_op[arg]))\n                elif op in hasfree:\n                    code.append((op, cellfree[arg]))\n                else:\n                    code.append((op, arg))\n\n        varargs = bool(co.co_flags & CO_VARARGS)\n        varkwargs = bool(co.co_flags & CO_VARKEYWORDS)\n        newlocals = bool(co.co_flags & CO_NEWLOCALS)\n        args = co.co_varnames[:co.co_argcount + varargs + varkwargs]\n        if co.co_consts and isinstance(co.co_consts[0], basestring):\n            docstring = co.co_consts[0]\n        else:\n            docstring = None\n        return cls(code = code,\n                   freevars = co.co_freevars,\n                   args = args,\n                   varargs = varargs,\n                   varkwargs = varkwargs,\n                   newlocals = newlocals,\n                   name = co.co_name,\n                   filename = co.co_filename,\n                   firstlineno = co.co_firstlineno,\n                   docstring = docstring,\n                   )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compute_stacksize(self):\n        # This is done by scanning the code, and computing for each opcode\n        # the stack state at the opcode.\n        code = self.code\n\n        # A mapping from labels to their positions in the code list\n        label_pos = dict((op, pos)\n                         for pos, (op, arg) in enumerate(code)\n                         if isinstance(op, Label))\n\n        # sf_targets are the targets of SETUP_FINALLY opcodes. They are recorded\n        # because they have special stack behaviour. If an exception was raised\n        # in the block pushed by a SETUP_FINALLY opcode, the block is popped\n        # and 3 objects are pushed. On return or continue, the block is popped\n        # and 2 objects are pushed. If nothing happened, the block is popped by\n        # a POP_BLOCK opcode and 1 object is pushed by a (LOAD_CONST, None)\n        # operation.\n        #\n        # Our solution is to record the stack state of SETUP_FINALLY targets\n        # as having 3 objects pushed, which is the maximum. However, to make\n        # stack recording consistent, the get_next_stacks function will always\n        # yield the stack state of the target as if 1 object was pushed, but\n        # this will be corrected in the actual stack recording.\n\n        sf_targets = set(label_pos[arg]\n                         for op, arg in code\n                         if op == SETUP_FINALLY)\n\n        # What we compute - for each opcode, its stack state, as an n-tuple.\n        # n is the number of blocks pushed. For each block, we record the number\n        # of objects pushed.\n        stacks = [None] * len(code)\n\n        def get_next_stacks(pos, curstack):\n            \"\"\"Get a code position and the stack state before the operation\n            was done, and yield pairs (pos, curstack) for the next positions\n            to be explored - those are the positions to which you can get\n            from the given (pos, curstack).\n\n            If the given position was already explored, nothing will be yielded.\n            \"\"\"\n            op, arg = code[pos]\n\n            if isinstance(op, Label):\n                # We should check if we already reached a node only if it is\n                # a label.\n                if pos in sf_targets:\n                    curstack = curstack[:-1] + (curstack[-1] + 2,)\n                if stacks[pos] is None:\n                    stacks[pos] = curstack\n                else:\n                    if stacks[pos] != curstack:\n                        raise ValueError(\"Inconsistent code\")\n                    return\n\n            def newstack(n):\n                # Return a new stack, modified by adding n elements to the last\n                # block\n                if curstack[-1] + n < 0:\n                    raise ValueError(\"Popped a non-existing element\")\n                return curstack[:-1] + (curstack[-1]+n,)\n\n            if not isopcode(op):\n                # label or SetLineno - just continue to next line\n                yield pos+1, curstack\n\n            elif op in (STOP_CODE, RETURN_VALUE, RAISE_VARARGS):\n                # No place in particular to continue to\n                pass\n\n            elif op == MAKE_CLOSURE and python_version == '2.4':\n                # This is only relevant in Python 2.4 - in Python 2.5 the stack\n                # effect of MAKE_CLOSURE can be calculated from the arg.\n                # In Python 2.4, it depends on the number of freevars of TOS,\n                # which should be a code object.\n                if pos == 0:\n                    raise ValueError(\"MAKE_CLOSURE can't be the first opcode\")\n                lastop, lastarg = code[pos-1]\n                if lastop != LOAD_CONST:\n                    raise ValueError(\n                        \"MAKE_CLOSURE should come after a LOAD_CONST op\")\n                try:\n                    nextrapops = len(lastarg.freevars)\n                except AttributeError:\n                    try:\n                        nextrapops = len(lastarg.co_freevars)\n                    except AttributeError:\n                        raise ValueError(\n                            \"MAKE_CLOSURE preceding const should \"\n                            \"be a code or a Code object\")\n\n                yield pos+1, newstack(-arg-nextrapops)\n\n            elif op not in hasflow:\n                # Simple change of stack\n                pop, push = getse(op, arg)\n                yield pos+1, newstack(push - pop)\n\n            elif op in (JUMP_FORWARD, JUMP_ABSOLUTE):\n                # One possibility for a jump\n                yield label_pos[arg], curstack\n\n            elif python_version < '2.7' and op in (JUMP_IF_FALSE, JUMP_IF_TRUE):\n                # Two possibilities for a jump\n                yield label_pos[arg], curstack\n                yield pos+1, curstack\n\n            elif python_version >= '2.7' and op in (POP_JUMP_IF_FALSE, POP_JUMP_IF_TRUE):\n                # Two possibilities for a jump\n                yield label_pos[arg], newstack(-1)\n                yield pos+1, newstack(-1)\n\n            elif python_version >= '2.7' and op in (JUMP_IF_TRUE_OR_POP, JUMP_IF_FALSE_OR_POP):\n                # Two possibilities for a jump\n                yield label_pos[arg], curstack\n                yield pos+1, newstack(-1)\n\n            elif op == FOR_ITER:\n                # FOR_ITER pushes next(TOS) on success, and pops TOS and jumps\n                # on failure\n                yield label_pos[arg], newstack(-1)\n                yield pos+1, newstack(1)\n\n            elif op == BREAK_LOOP:\n                # BREAK_LOOP jumps to a place specified on block creation, so\n                # it is ignored here\n                pass\n\n            elif op == CONTINUE_LOOP:\n                # CONTINUE_LOOP jumps to the beginning of a loop which should\n                # already ave been discovered, but we verify anyway.\n                # It pops a block.\n                if python_version == '2.6':\n                  pos, stack = label_pos[arg], curstack[:-1]\n                  if stacks[pos] != stack: #this could be a loop with a 'with' inside\n                    yield pos, stack[:-1] + (stack[-1]-1,)\n                  else:\n                    yield pos, stack\n                else:\n                  yield label_pos[arg], curstack[:-1]\n\n            elif op == SETUP_LOOP:\n                # We continue with a new block.\n                # On break, we jump to the label and return to current stack\n                # state.\n                yield label_pos[arg], curstack\n                yield pos+1, curstack + (0,)\n\n            elif op == SETUP_EXCEPT:\n                # We continue with a new block.\n                # On exception, we jump to the label with 3 extra objects on\n                # stack\n                yield label_pos[arg], newstack(3)\n                yield pos+1, curstack + (0,)\n\n            elif op == SETUP_FINALLY:\n                # We continue with a new block.\n                # On exception, we jump to the label with 3 extra objects on\n                # stack, but to keep stack recording consistent, we behave as\n                # if we add only 1 object. Extra 2 will be added to the actual\n                # recording.\n                yield label_pos[arg], newstack(1)\n                yield pos+1, curstack + (0,)\n\n            elif python_version == '2.7' and op == SETUP_WITH:\n                yield label_pos[arg], curstack\n                yield pos+1, newstack(-1) + (1,)\n\n            elif op == POP_BLOCK:\n                # Just pop the block\n                yield pos+1, curstack[:-1]\n\n            elif op == END_FINALLY:\n                # Since stack recording of SETUP_FINALLY targets is of 3 pushed\n                # objects (as when an exception is raised), we pop 3 objects.\n                yield pos+1, newstack(-3)\n\n            elif op == WITH_CLEANUP:\n                # Since WITH_CLEANUP is always found after SETUP_FINALLY\n                # targets, and the stack recording is that of a raised\n                # exception, we can simply pop 1 object and let END_FINALLY\n                # pop the remaining 3.\n                if python_version == '2.7':\n                  yield pos+1, newstack(2)\n                else:\n                  yield pos+1, newstack(-1)\n\n            else:\n                assert False, \"Unhandled opcode: %r\" % op\n\n\n        # Now comes the calculation: open_positions holds positions which are\n        # yet to be explored. In each step we take one open position, and\n        # explore it by adding the positions to which you can get from it, to\n        # open_positions. On the way, we update maxsize.\n        # open_positions is a list of tuples: (pos, stack state)\n        maxsize = 0\n        open_positions = [(0, (0,))]\n        while open_positions:\n            pos, curstack = open_positions.pop()\n            maxsize = max(maxsize, sum(curstack))\n            open_positions.extend(get_next_stacks(pos, curstack))\n\n        return maxsize", "response": "Compute the maximum stack usage of the current stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_code(self):\n        co_argcount = len(self.args) - self.varargs - self.varkwargs\n        co_stacksize = self._compute_stacksize()\n        co_flags = self._compute_flags()\n\n        co_consts = [self.docstring]\n        co_names = []\n        co_varnames = list(self.args)\n\n        co_freevars = tuple(self.freevars)\n\n        # We find all cellvars beforehand, for two reasons:\n        # 1. We need the number of them to construct the numeric argument\n        #    for ops in \"hasfree\".\n        # 2. We need to put arguments which are cell vars in the beginning\n        #    of co_cellvars\n        cellvars = set(arg for op, arg in self.code\n                       if isopcode(op) and op in hasfree\n                       and arg not in co_freevars)\n        co_cellvars = [x for x in self.args if x in cellvars]\n\n        def index(seq, item, eq=operator.eq, can_append=True):\n            \"\"\"Find the index of item in a sequence and return it.\n            If it is not found in the sequence, and can_append is True,\n            it is appended to the sequence.\n\n            eq is the equality operator to use.\n            \"\"\"\n            for i, x in enumerate(seq):\n                if eq(x, item):\n                    return i\n            else:\n                if can_append:\n                    seq.append(item)\n                    return len(seq) - 1\n                else:\n                    raise IndexError(\"Item not found\")\n\n        # List of tuples (pos, label) to be filled later\n        jumps = []\n        # A mapping from a label to its position\n        label_pos = {}\n        # Last SetLineno\n        lastlineno = self.firstlineno\n        lastlinepos = 0\n\n        co_code = array('B')\n        co_lnotab = array('B')\n        for i, (op, arg) in enumerate(self.code):\n            if isinstance(op, Label):\n                label_pos[op] = len(co_code)\n\n            elif op is SetLineno:\n                incr_lineno = arg - lastlineno\n                incr_pos = len(co_code) - lastlinepos\n                lastlineno = arg\n                lastlinepos = len(co_code)\n\n                if incr_lineno == 0 and incr_pos == 0:\n                    co_lnotab.append(0)\n                    co_lnotab.append(0)\n                else:\n                    while incr_pos > 255:\n                        co_lnotab.append(255)\n                        co_lnotab.append(0)\n                        incr_pos -= 255\n                    while incr_lineno > 255:\n                        co_lnotab.append(incr_pos)\n                        co_lnotab.append(255)\n                        incr_pos = 0\n                        incr_lineno -= 255\n                    if incr_pos or incr_lineno:\n                        co_lnotab.append(incr_pos)\n                        co_lnotab.append(incr_lineno)\n\n            elif op == opcode.EXTENDED_ARG:\n                raise ValueError(\"EXTENDED_ARG not supported in Code objects\")\n\n            elif not op in hasarg:\n                co_code.append(op)\n\n            else:\n                if op in hasconst:\n                    if isinstance(arg, Code) and i < len(self.code)-1 and \\\n                       self.code[i+1][0] in hascode:\n                        arg = arg.to_code()\n                    arg = index(co_consts, arg, operator.is_)\n                elif op in hasname:\n                    arg = index(co_names, arg)\n                elif op in hasjump:\n                    # arg will be filled later\n                    jumps.append((len(co_code), arg))\n                    arg = 0\n                elif op in haslocal:\n                    arg = index(co_varnames, arg)\n                elif op in hascompare:\n                    arg = index(cmp_op, arg, can_append=False)\n                elif op in hasfree:\n                    try:\n                        arg = index(co_freevars, arg, can_append=False) \\\n                              + len(cellvars)\n                    except IndexError:\n                        arg = index(co_cellvars, arg)\n                else:\n                    # arg is ok\n                    pass\n\n                if arg > 0xFFFF:\n                    co_code.append(opcode.EXTENDED_ARG)\n                    co_code.append((arg >> 16) & 0xFF)\n                    co_code.append((arg >> 24) & 0xFF)\n                co_code.append(op)\n                co_code.append(arg & 0xFF)\n                co_code.append((arg >> 8) & 0xFF)\n\n        for pos, label in jumps:\n            jump = label_pos[label]\n            if co_code[pos] in hasjrel:\n                jump -= pos+3\n            if jump > 0xFFFF:\n                raise NotImplementedError(\"Extended jumps not implemented\")\n            co_code[pos+1] = jump & 0xFF\n            co_code[pos+2] = (jump >> 8) & 0xFF\n\n        co_code = co_code.tostring()\n        co_lnotab = co_lnotab.tostring()\n\n        co_consts = tuple(co_consts)\n        co_names = tuple(co_names)\n        co_varnames = tuple(co_varnames)\n        co_nlocals = len(co_varnames)\n        co_cellvars = tuple(co_cellvars)\n\n        return types.CodeType(co_argcount, co_nlocals, co_stacksize, co_flags,\n                              co_code, co_consts, co_names, co_varnames,\n                              self.filename, self.name, self.firstlineno, co_lnotab,\n                              co_freevars, co_cellvars)", "response": "Assemble a Python code object from a Code object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef qqgraph(h1, h2, quantiles=None):\n    if quantiles is None:\n        quantiles = max(min(len(h1), len(h2)) / 2, 1)\n    nq = quantiles\n    # position where to compute the quantiles in [0, 1]\n    xq = array('d', [0.] * nq)\n    # array to contain the quantiles\n    yq1 = array('d', [0.] * nq)\n    # array to contain the quantiles\n    yq2 = array('d', [0.] * nq)\n\n    for i in range(nq):\n        xq[i] = float(i + 1) / nq\n\n    h1.GetQuantiles(nq, yq1, xq)\n    h2.GetQuantiles(nq, yq2, xq)\n\n    xq_plus = array('d', [0.] * nq)\n    xq_minus = array('d', [0.] * nq)\n    yq2_plus = array('d', [0.] * nq)\n    yq2_minus = array('d', [0.] * nq)\n\n    \"\"\"\n    KS_cv: KS critical value\n\n               1.36\n    KS_cv = -----------\n             sqrt( N )\n\n    Where 1.36 is for alpha = 0.05 (confidence level 1-5%=95%, about 2 sigma)\n\n    For 1 sigma (alpha=0.32, CL=68%), the value in the nominator is 0.9561,\n    it is gotten by GetCriticalValue(1, 1 - 0.68).\n\n    Notes\n    -----\n\n    * For 1-sample KS test (data and theoretic), N should be n\n\n    * For 2-sample KS test (2 data set), N should be sqrt(m*n/(m+n))!\n      Here is the case m or n (size of samples) should be effective size\n      for a histogram\n\n    * Critical value here is valid for only for sample size >= 80 (some\n      references say 35) which means, for example, for a unweighted histogram,\n      it must have more than 80 (or 35) entries filled and then confidence\n      band is reliable.\n\n    \"\"\"\n\n    esum1 = effective_sample_size(h1)\n    esum2 = effective_sample_size(h2)\n\n    # one sigma band\n    KS_cv = (critical_value(1, 1 - 0.68) /\n             sqrt((esum1 * esum2) / (esum1 + esum2)))\n\n    for i in range(nq):\n        # upper limit\n        xq_plus[i] = float(xq[i] + KS_cv)\n        # lower limit\n        xq_minus[i] = float(xq[i] - KS_cv)\n\n    h2.GetQuantiles(nq, yq2_plus, xq_plus)\n    h2.GetQuantiles(nq, yq2_minus, xq_minus)\n\n    yq2_err_plus = array('d', [0.] * nq)\n    yq2_err_minus = array('d', [0.] * nq)\n    for i in range(nq):\n        yq2_err_plus[i] = yq2_plus[i] - yq2[i]\n        yq2_err_minus[i] = yq2[i] - yq2_minus[i]\n\n    # forget the last point, so number of points: (nq - 1)\n    gr = Graph(nq - 1)\n    for i in range(nq - 1):\n        gr[i] = (yq1[i], yq2[i])\n        # confidence level band\n        gr.SetPointEYlow(i, yq2_err_minus[i])\n        gr.SetPointEYhigh(i, yq2_err_plus[i])\n\n    return gr", "response": "Returns a Graph of a quantile - quantile plot and confidence band"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef effective_sample_size(h):\n    sum = 0\n    ew = 0\n    w = 0\n    for bin in h.bins(overflow=False):\n        sum += bin.value\n        ew = bin.error\n        w += ew * ew\n    esum = sum * sum / w\n    return esum", "response": "Calculate the effective sample size for a histogram\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump(obj, root_file, proto=0, key=None):\n    if isinstance(root_file, string_types):\n        root_file = root_open(root_file, 'recreate')\n        own_file = True\n    else:\n        own_file = False\n    ret = Pickler(root_file, proto).dump(obj, key)\n    if own_file:\n        root_file.Close()\n    return ret", "response": "Dump an object into a ROOT TFile."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(root_file, use_proxy=True, key=None):\n    if isinstance(root_file, string_types):\n        root_file = root_open(root_file)\n        own_file = True\n    else:\n        own_file = False\n    obj = Unpickler(root_file, use_proxy).load(key)\n    if own_file:\n        root_file.Close()\n    return obj", "response": "Load an object from a ROOT file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(self, obj, key=None):\n        if key is None:\n            key = '_pickle'\n        with preserve_current_directory():\n            self.__file.cd()\n            if sys.version_info[0] < 3:\n                pickle.Pickler.dump(self, obj)\n            else:\n                super(Pickler, self).dump(obj)\n            s = ROOT.TObjString(self.__io.getvalue())\n            self.__io.reopen()\n            s.Write(key)\n            self.__file.GetFile().Flush()\n            self.__pmap.clear()", "response": "Write a pickled representation of obj to the open TFile."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, key=None):\n        if key is None:\n            key = '_pickle'\n        obj = None\n        if _compat_hooks:\n            save = _compat_hooks[0]()\n        try:\n            self.__n += 1\n            s = self.__file.Get(key + ';{0:d}'.format(self.__n))\n            self.__io.setvalue(s.GetName())\n            if sys.version_info[0] < 3:\n                obj = pickle.Unpickler.load(self)\n            else:\n                obj = super(Unpickler, self).load()\n            self.__io.reopen()\n        finally:\n            if _compat_hooks:\n                save = _compat_hooks[1](save)\n        return obj", "response": "Read a pickled object representation from the open file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_ROOT_classes():\n    class_index = \"http://root.cern.ch/root/html/ClassIndex.html\"\n    for s in minidom.parse(urlopen(class_index)).getElementsByTagName(\"span\"):\n        if (\"class\", \"typename\") in s.attributes.items():\n            class_name = s.childNodes[0].nodeValue\n            try:\n                yield getattr(QROOT, class_name)\n            except AttributeError:\n                pass", "response": "Iterator over all available ROOT classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef izip_exact(*iterables):\n    rest = [chain(i, _throw()) for i in iterables[1:]]\n    first = chain(iterables[0], _check(rest))\n    return zip(*[first] + rest)", "response": "A lazy izip that ensures that all iterables have the same length."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CMS_label(text=\"Preliminary 2012\", sqrts=8, pad=None):\n    if pad is None:\n        pad = ROOT.gPad\n    with preserve_current_canvas():\n        pad.cd()\n        left_margin = pad.GetLeftMargin()\n        top_margin = pad.GetTopMargin()\n        ypos = 1 - top_margin / 2.\n        l = ROOT.TLatex(left_margin, ypos, \"CMS \" + text)\n        l.SetTextAlign(12) # left-middle\n        l.SetNDC()\n        # The text is 90% as tall as the margin it lives in.\n        l.SetTextSize(0.90 * top_margin)\n        l.Draw()\n        keepalive(pad, l)\n        # Draw sqrt(s) label, if desired\n        if sqrts:\n            right_margin = pad.GetRightMargin()\n            p = ROOT.TLatex(1 - right_margin, ypos,\n                            \"#sqrt{{s}}={0:d}TeV\".format(sqrts))\n            p.SetTextAlign(32) # right-middle\n            p.SetNDC()\n            p.SetTextSize(0.90 * top_margin)\n            p.Draw()\n            keepalive(pad, p)\n        else:\n            p = None\n        pad.Modified()\n        pad.Update()\n    return l, p", "response": "Add a CMS Preliminary style label to the current Pad."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_channel(name, samples, data=None, verbose=False):\n    if verbose:\n        llog = log['make_channel']\n        llog.info(\"creating channel {0}\".format(name))\n    # avoid segfault if name begins with a digit by using \"channel_\" prefix\n    chan = Channel('channel_{0}'.format(name))\n    chan.SetStatErrorConfig(0.05, \"Poisson\")\n\n    if data is not None:\n        if verbose:\n            llog.info(\"setting data\")\n        chan.SetData(data)\n\n    for sample in samples:\n        if verbose:\n            llog.info(\"adding sample {0}\".format(sample.GetName()))\n        chan.AddSample(sample)\n\n    return chan", "response": "Create a Channel from a list of Samples"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_measurement(name,\n                     channels,\n                     lumi=1.0, lumi_rel_error=0.1,\n                     output_prefix='./histfactory',\n                     POI=None,\n                     const_params=None,\n                     verbose=False):\n    \"\"\"\n    Create a Measurement from a list of Channels\n    \"\"\"\n    if verbose:\n        llog = log['make_measurement']\n        llog.info(\"creating measurement {0}\".format(name))\n\n    if not isinstance(channels, (list, tuple)):\n        channels = [channels]\n\n    # Create the measurement\n    meas = Measurement('measurement_{0}'.format(name), '')\n    meas.SetOutputFilePrefix(output_prefix)\n    if POI is not None:\n        if isinstance(POI, string_types):\n            if verbose:\n                llog.info(\"setting POI {0}\".format(POI))\n            meas.SetPOI(POI)\n        else:\n            if verbose:\n                llog.info(\"adding POIs {0}\".format(', '.join(POI)))\n            for p in POI:\n                meas.AddPOI(p)\n\n    if verbose:\n        llog.info(\"setting lumi={0:f} +/- {1:f}\".format(lumi, lumi_rel_error))\n    meas.lumi = lumi\n    meas.lumi_rel_error = lumi_rel_error\n\n    for channel in channels:\n        if verbose:\n            llog.info(\"adding channel {0}\".format(channel.GetName()))\n        meas.AddChannel(channel)\n\n    if const_params is not None:\n        if verbose:\n            llog.info(\"adding constant parameters {0}\".format(\n                ', '.join(const_params)))\n        for param in const_params:\n            meas.AddConstantParam(param)\n\n    return meas", "response": "Create a Measurement from a list of Channels and a list of Lumi parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a workspace containing the model for a measurement.", "response": "def make_workspace(measurement, channel=None, name=None, silence=False):\n    \"\"\"\n    Create a workspace containing the model for a measurement\n\n    If `channel` is None then include all channels in the model\n\n    If `silence` is True, then silence HistFactory's output on\n    stdout and stderr.\n    \"\"\"\n    context = silence_sout_serr if silence else do_nothing\n    with context():\n        hist2workspace = ROOT.RooStats.HistFactory.HistoToWorkspaceFactoryFast(\n            measurement)\n        if channel is not None:\n            workspace = hist2workspace.MakeSingleChannelModel(\n                measurement, channel)\n        else:\n            workspace = hist2workspace.MakeCombinedModel(measurement)\n    workspace = asrootpy(workspace)\n    keepalive(workspace, measurement)\n    if name is not None:\n        workspace.SetName('workspace_{0}'.format(name))\n    return workspace"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef measurements_from_xml(filename,\n                          collect_histograms=True,\n                          cd_parent=False,\n                          silence=False):\n    \"\"\"\n    Read in a list of Measurements from XML\n    \"\"\"\n    if not os.path.isfile(filename):\n        raise OSError(\"the file {0} does not exist\".format(filename))\n    silence_context = silence_sout_serr if silence else do_nothing\n\n    filename = os.path.abspath(os.path.normpath(filename))\n\n    if cd_parent:\n        xml_directory = os.path.dirname(filename)\n        parent = os.path.abspath(os.path.join(xml_directory, os.pardir))\n        cd_context = working_directory\n    else:\n        parent = None\n        cd_context = do_nothing\n\n    log.info(\"parsing XML in {0} ...\".format(filename))\n    with cd_context(parent):\n        parser = ROOT.RooStats.HistFactory.ConfigParser()\n        with silence_context():\n            measurements_vect = parser.GetMeasurementsFromXML(filename)\n        # prevent measurements_vect from being garbage collected\n        ROOT.SetOwnership(measurements_vect, False)\n        measurements = []\n        for m in measurements_vect:\n            if collect_histograms:\n                with silence_context():\n                    m.CollectHistograms()\n            measurements.append(asrootpy(m))\n    return measurements", "response": "Read in a list of Measurements from XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_measurement(measurement,\n                      root_file=None,\n                      xml_path=None,\n                      output_path=None,\n                      output_suffix=None,\n                      write_workspaces=False,\n                      apply_xml_patches=True,\n                      silence=False):\n    \"\"\"\n    Write a measurement and RooWorkspaces for all contained channels\n    into a ROOT file and write the XML files into a directory.\n\n    Parameters\n    ----------\n\n    measurement : HistFactory::Measurement\n        An asrootpy'd ``HistFactory::Measurement`` object\n\n    root_file : ROOT TFile or string, optional (default=None)\n        A ROOT file or string file name. The measurement and workspaces\n        will be written to this file. If ``root_file is None`` then a\n        new file will be created with the same name as the measurement and\n        with the prefix ``ws_``.\n\n    xml_path : string, optional (default=None)\n        A directory path to write the XML into. If None, a new directory with\n        the same name as the measurement and with the prefix ``xml_`` will be\n        created.\n\n    output_path : string, optional (default=None)\n        If ``root_file is None``, create the ROOT file under this path.\n        If ``xml_path is None``, create the XML directory under this path.\n\n    output_suffix : string, optional (default=None)\n        If ``root_file is None`` then a new file is created with the same name\n        as the measurement and with the prefix ``ws_``. ``output_suffix`` will\n        append a suffix to this file name (before the .root extension).\n        If ``xml_path is None``, then a new directory is created with the\n        same name as the measurement and with the prefix ``xml_``.\n        ``output_suffix`` will append a suffix to this directory name.\n\n    write_workspaces : bool, optional (default=False)\n        If True then also write a RooWorkspace for each channel and for all\n        channels combined.\n\n    apply_xml_patches : bool, optional (default=True)\n        Apply fixes on the output of ``Measurement::PrintXML()`` to avoid known\n        HistFactory bugs. Some of the patches assume that the ROOT file\n        containing the histograms will exist one directory level up from the\n        XML and that hist2workspace, or any tool that later reads the XML will\n        run from that same directory containing the ROOT file.\n\n    silence : bool, optional (default=False)\n        If True then capture and silence all stdout/stderr output from\n        HistFactory.\n\n    \"\"\"\n    context = silence_sout_serr if silence else do_nothing\n\n    output_name = measurement.name\n    if output_suffix is not None:\n        output_name += '_{0}'.format(output_suffix)\n    output_name = output_name.replace(' ', '_')\n\n    if xml_path is None:\n        xml_path = 'xml_{0}'.format(output_name)\n        if output_path is not None:\n            xml_path = os.path.join(output_path, xml_path)\n\n    if not os.path.exists(xml_path):\n        mkdir_p(xml_path)\n\n    if root_file is None:\n        root_file = 'ws_{0}.root'.format(output_name)\n        if output_path is not None:\n            root_file = os.path.join(output_path, root_file)\n\n    own_file = False\n    if isinstance(root_file, string_types):\n        root_file = root_open(root_file, 'recreate')\n        own_file = True\n\n    with preserve_current_directory():\n        root_file.cd()\n\n        log.info(\"writing histograms and measurement in {0} ...\".format(\n            root_file.GetName()))\n        with context():\n            measurement.writeToFile(root_file)\n        # get modified measurement\n        out_m = root_file.Get(measurement.name)\n        log.info(\"writing XML in {0} ...\".format(xml_path))\n        with context():\n            out_m.PrintXML(xml_path)\n\n        if write_workspaces:\n            log.info(\"writing combined model in {0} ...\".format(\n                root_file.GetName()))\n            workspace = make_workspace(measurement, silence=silence)\n            workspace.Write()\n            for channel in measurement.channels:\n                log.info(\"writing model for channel `{0}` in {1} ...\".format(\n                    channel.name, root_file.GetName()))\n                workspace = make_workspace(\n                    measurement, channel=channel, silence=silence)\n                workspace.Write()\n\n    if apply_xml_patches:\n        # patch the output XML to avoid HistFactory bugs\n        patch_xml(glob(os.path.join(xml_path, '*.xml')),\n                  root_file=os.path.basename(root_file.GetName()))\n\n    if own_file:\n        root_file.Close()", "response": "Write a measurement into a ROOT file and write the XML files into a directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies patches to HistFactory XML output from PrintXML alues.", "response": "def patch_xml(files, root_file=None, float_precision=3):\n    \"\"\"\n    Apply patches to HistFactory XML output from PrintXML\n    \"\"\"\n    if float_precision < 0:\n        raise ValueError(\"precision must be greater than 0\")\n\n    def fix_path(match):\n        path = match.group(1)\n        if path:\n            head, tail = os.path.split(path)\n            new_path = os.path.join(os.path.basename(head), tail)\n        else:\n            new_path = ''\n        return '<Input>{0}</Input>'.format(new_path)\n\n    for xmlfilename in files:\n        xmlfilename = os.path.abspath(os.path.normpath(xmlfilename))\n        patched_xmlfilename = '{0}.tmp'.format(xmlfilename)\n        log.info(\"patching {0} ...\".format(xmlfilename))\n        fin = open(xmlfilename, 'r')\n        fout = open(patched_xmlfilename, 'w')\n        for line in fin:\n            if root_file is not None:\n                line = re.sub(\n                    'InputFile=\"[^\"]*\"',\n                    'InputFile=\"{0}\"'.format(root_file), line)\n            line = line.replace(\n                '<StatError Activate=\"True\"  InputFile=\"\"  '\n                'HistoName=\"\"  HistoPath=\"\"  />',\n                '<StatError Activate=\"True\" />')\n            line = re.sub(\n                '<Combination OutputFilePrefix=\"(\\S*)\" >',\n                '<Combination OutputFilePrefix=\"hist2workspace\" >', line)\n            line = re.sub('\\w+=\"\"', '', line)\n            line = re.sub('\\s+/>', ' />', line)\n            line = re.sub('(\\S)\\s+</', r'\\1</', line)\n            # HistFactory bug:\n            line = re.sub('InputFileHigh=\"\\S+\"', '', line)\n            line = re.sub('InputFileLow=\"\\S+\"', '', line)\n            # HistFactory bug:\n            line = line.replace(\n                '<ParamSetting Const=\"True\"></ParamSetting>', '')\n            # chop off floats to desired precision\n            line = re.sub(\n                r'\"(\\d*\\.\\d{{{0:d},}})\"'.format(float_precision + 1),\n                lambda x: '\"{0}\"'.format(\n                    str(round(float(x.group(1)), float_precision))),\n                line)\n            line = re.sub('\"\\s\\s+(\\S)', r'\" \\1', line)\n            line = re.sub('<Input>(.*)</Input>', fix_path, line)\n            fout.write(line)\n        fin.close()\n        fout.close()\n        shutil.move(patched_xmlfilename, xmlfilename)\n        if not os.path.isfile(os.path.join(\n                              os.path.dirname(xmlfilename),\n                              'HistFactorySchema.dtd')):\n            rootsys = os.getenv('ROOTSYS', None)\n            if rootsys is not None:\n                dtdfile = os.path.join(rootsys, 'etc/HistFactorySchema.dtd')\n                target = os.path.dirname(xmlfilename)\n                if os.path.isfile(dtdfile):\n                    log.info(\"copying {0} to {1} ...\".format(dtdfile, target))\n                    shutil.copy(dtdfile, target)\n                else:\n                    log.warning(\"{0} does not exist\".format(dtdfile))\n            else:\n                log.warning(\n                    \"$ROOTSYS is not set so cannot find HistFactorySchema.dtd\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits a HistoSys into normalization and shape.", "response": "def split_norm_shape(histosys, nominal_hist):\n    \"\"\"\n    Split a HistoSys into normalization (OverallSys) and shape (HistoSys)\n    components.\n\n    It is recommended to use OverallSys as much as possible, which tries to\n    enforce continuity up to the second derivative during\n    interpolation/extrapolation. So, if there is indeed a shape variation, then\n    factorize it into shape and normalization components.\n    \"\"\"\n    up = histosys.GetHistoHigh()\n    dn = histosys.GetHistoLow()\n    up = up.Clone(name=up.name + '_shape')\n    dn = dn.Clone(name=dn.name + '_shape')\n    n_nominal = nominal_hist.integral(overflow=True)\n    n_up = up.integral(overflow=True)\n    n_dn = dn.integral(overflow=True)\n    if n_up != 0:\n        up.Scale(n_nominal / n_up)\n    if n_dn != 0:\n        dn.Scale(n_nominal / n_dn)\n    shape = HistoSys(histosys.GetName(), low=dn, high=up)\n    norm = OverallSys(histosys.GetName(),\n                      low=n_dn / n_nominal if n_nominal != 0 else 1.,\n                      high=n_up / n_nominal if n_nominal != 0 else 1.)\n    return norm, shape"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path(self):\n        ''' Get the path of the wrapped folder '''\n        if isinstance(self.dir, Directory):\n            return self.dir._path\n        elif isinstance(self.dir, ROOT.TDirectory):\n            return self.dir.GetPath()\n        elif isinstance(self.dir, _FolderView):\n            return self.dir.path()\n        else:\n            return str(self.dir)", "response": "Get the path of the wrapped folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Get(self, path):\n        ''' Get the (modified) object from path '''\n        self.getting = path\n        try:\n            obj = self.dir.Get(path)\n            return self.apply_view(obj)\n        except DoesNotExist as dne:\n            #print dir(dne)\n            raise DoesNotExist(\n                str(dne) + \"[{0}]\".format(self.__class__.__name__))", "response": "Get the object from the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Get(self, path):\n        ''' Merge the objects at path in all subdirectories '''\n        return self.merge_views(x.Get(path) for x in self.dirs)", "response": "Merge the objects at path in all subdirectories"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fixup_msg(lvl, msg):\n    if \"switching to batch mode...\" in msg and lvl == logging.ERROR:\n        return logging.WARNING, msg\n    return lvl, msg", "response": "Fixup for the ERROR to a WARNING message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef python_logging_error_handler(level, root_says_abort, location, msg):\n    from ..utils import quickroot as QROOT\n\n    if not Initialized.value:\n        try:\n            QROOT.kTRUE\n        except AttributeError:\n            # Python is exiting. Do nothing.\n            return\n        QROOT.kInfo, QROOT.kWarning, QROOT.kError, QROOT.kFatal, QROOT.kSysError\n        QROOT.gErrorIgnoreLevel\n        Initialized.value = True\n\n    try:\n        QROOT.kTRUE\n    except RuntimeError:\n        # Note: If the above causes us problems, it's because this logging\n        #       handler has been called multiple times already with an\n        #       exception. In that case we need to force upstream to raise it.\n        _, exc, traceback = sys.exc_info()\n        caller = sys._getframe(2)\n        re_execute_with_exception(caller, exc, traceback)\n\n    if level < QROOT.gErrorIgnoreLevel:\n        # Needed to silence some \"normal\" startup warnings\n        # (copied from PyROOT Utility.cxx)\n        return\n\n    if sys.version_info[0] >= 3:\n        location = location.decode('utf-8')\n        msg = msg.decode('utf-8')\n\n    log = ROOT_log.getChild(location.replace(\"::\", \".\"))\n\n    if level >= QROOT.kSysError or level >= QROOT.kFatal:\n        lvl = logging.CRITICAL\n    elif level >= QROOT.kError:\n        lvl = logging.ERROR\n    elif level >= QROOT.kWarning:\n        lvl = logging.WARNING\n    elif level >= QROOT.kInfo:\n        lvl = logging.INFO\n    else:\n        lvl = logging.DEBUG\n\n    if not SANE_REGEX.match(msg):\n        # Not ASCII characters. Escape them.\n        msg = repr(msg)[1:-1]\n\n    # Apply fixups to improve consistency of errors/warnings\n    lvl, msg = fixup_msg(lvl, msg)\n\n    log.log(lvl, msg)\n\n    # String checks are used because we need a way of (un)forcing abort without\n    # modifying a global variable (gErrorAbortLevel) for the multithread tests\n    abort = lvl >= ABORT_LEVEL or \"rootpy.ALWAYSABORT\" in msg or root_says_abort\n    if abort and not \"rootpy.NEVERABORT\" in msg:\n        caller = sys._getframe(1)\n\n        try:\n            # We can't raise an exception from here because ctypes/PyROOT swallows it.\n            # Hence the need for dark magic, we re-raise it within a trace.\n            from .. import ROOTError\n            raise ROOTError(level, location, msg)\n        except RuntimeError:\n            _, exc, traceback = sys.exc_info()\n\n        if SHOWTRACE.enabled:\n            from traceback import print_stack\n            print_stack(caller)\n\n        if DANGER.enabled:\n            # Avert your eyes, dark magic be within...\n            re_execute_with_exception(caller, exc, traceback)\n\n    if root_says_abort:\n        log.critical(\"abort().. expect a stack trace\")\n        ctypes.CDLL(None).abort()", "response": "A Python error handler for ROOT which maps ROOT s errors and warnings on ROOT s errors and warnings to Python s error handlers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef preserve_current_canvas():\n    old = ROOT.gPad\n    try:\n        yield\n    finally:\n        if old:\n            old.cd()\n        elif ROOT.gPad:\n            # Put things back how they were before.\n            with invisible_canvas():\n                # This is a round-about way of resetting gPad to None.\n                # No other technique I tried could do it.\n                pass", "response": "Context manager which ensures that the current canvas remains the current one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef invisible_canvas():\n    with preserve_current_canvas():\n        with preserve_batch_state():\n            ROOT.gROOT.SetBatch()\n            c = ROOT.TCanvas()\n        try:\n            c.cd()\n            yield c\n        finally:\n            c.Close()\n            c.IsA().Destructor(c)", "response": "Context manager that returns a temporary canvas drawn in batch mode invisible\n            to the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef thread_specific_tmprootdir():\n    with preserve_current_directory():\n        dname = \"rootpy-tmp/thread/{0}\".format(\n                threading.current_thread().ident)\n        d = ROOT.gROOT.mkdir(dname)\n        if not d:\n            d = ROOT.gROOT.GetDirectory(dname)\n            assert d, \"Unexpected failure, can't cd to tmpdir.\"\n        d.cd()\n        yield d", "response": "Context manager which makes a directory that can be used to store the current thread s directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_directory(robject):\n    if (not hasattr(robject, 'GetDirectory') or\n        not hasattr(robject, 'SetDirectory')):\n        log.warning(\"Cannot set the directory of a `{0}`\".format(\n            type(robject)))\n        # Do nothing\n        yield\n    else:\n        old_dir = robject.GetDirectory()\n        try:\n            robject.SetDirectory(ROOT.gDirectory)\n            yield\n        finally:\n            robject.SetDirectory(old_dir)", "response": "Context manager to temporarily set the directory of a ROOT object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef working_directory(path):\n    prev_cwd = os.getcwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(prev_cwd)", "response": "A context manager that changes the working directory to the given path and then restores the previous working directory on exit."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_methods(cls):\n        def name(fn):\n            return fn.__get__(cls).__name__.replace(\"_\", \"-\")\n        return sorted(name(f) for f in cls.__dict__.values()\n                      if isinstance(f, staticmethod))", "response": "Return a list of all available binning methods in the class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the number of samples in the doane.", "response": "def sturges_doane(data):\n        \"\"\"\n        References\n        ----------\n        .. [1] D. Wilkinson, \"The Grammar of Graphics\", 2005.\n               http://books.google.it/books?id=_kRX4LoFfGQC&lpg=PA133&ots=APHb0-p6tY&dq=doane%20binning%20histogram&hl=it&pg=PA133#v=onepage&q=doane%20binning%20histogram&f=false\n        \"\"\"\n        n = len(data)\n        return np.log10(n) * np.log2(n) + 3"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreference ---------- .. [1] K. Knuth, \"Optimal Data-Based Binning for Histograms\", 2006. http://arxiv.org/pdf/physics/0605197v1.pdf", "response": "def knuth(data):\n        \"\"\"\n        References\n        ----------\n        .. [1] K. Knuth, \"Optimal Data-Based Binning for Histograms\", 2006.\n               http://arxiv.org/pdf/physics/0605197v1.pdf\n        \"\"\"\n        import scipy.optimize as optimize\n\n        def f(data):\n            from scipy.special import gammaln\n\n            m, M = np.min(data), np.max(data)\n            n = len(data)\n\n            def fff(x):\n                k = x[0]  # number of bins\n                if k <= 0:\n                    return float(\"+inf\")\n                binning = np.linspace(m, M, k + 1)\n                histo, bincenters = np.histogram(data, binning)\n\n                return -(n * np.log(k) + gammaln(k / 2.) - gammaln(n + k / 2.) +\n                         k * gammaln(1. / 2.) + np.sum(gammaln(histo + 0.5)))\n            return fff\n\n        k0 = np.sqrt(len(data))\n        return optimize.fmin(f(data), np.array([k0]), disp=False)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lock(path, poll_interval=5, max_age=60):\n    if max_age < 30:\n        raise ValueError(\"`max_age` must be at least 30 seconds\")\n    if poll_interval < 1:\n        raise ValueError(\"`poll_interval` must be at least 1 second\")\n    if poll_interval >= max_age:\n        raise ValueError(\"`poll_interval` must be less than `max_age`\")\n    proc = '{0:d}@{1}'.format(os.getpid(), platform.node())\n    lock = LockFile(path)\n    log.debug(\"{0} attempting to lock {1}\".format(proc, path))\n    while not lock.i_am_locking():\n        if lock.is_locked():\n            # Protect against race condition\n            try:\n                # Check age of the lock file\n                age = time.time() - os.stat(lock.lock_file)[stat.ST_MTIME]\n                # Break the lock if too old (considered stale)\n                if age > max_age:\n                    lock.break_lock()\n                    # What if lock was released and reacquired in the meantime?\n                    # We don't want to break a fresh lock!\n                    # If a lock is stale then we may have many threads\n                    # attempting to break it here at the \"same time\".\n                    # Avoid the possibility of some thread trying to break the\n                    # lock after it has already been broken and after the first\n                    # other thread attempting to acquire the lock by sleeping\n                    # for 0.5 seconds below.\n                    log.warning(\n                        \"{0} broke lock on {1} \"\n                        \"that is {2:d} seconds old\".format(\n                            proc, path, int(age)))\n            except OSError:\n                # Lock was released just now\n                # os.path.exists(lock.lock_file) is False\n                # OSError may be raised by os.stat() or lock.break_lock() above\n                pass\n        time.sleep(0.5)\n        try:\n            log.debug(\n                \"{0} waiting for {1:d} seconds \"\n                \"for lock on {2} to be released\".format(\n                    proc, poll_interval, path))\n            # Use float() here since acquire sleeps for timeout/10\n            lock.acquire(timeout=float(poll_interval))\n        except LockTimeout:\n            pass\n    log.debug(\"{0} locked {1}\".format(proc, path))\n    yield lock\n    lock.release()\n    log.debug(\"{0} released lock on {1}\".format(proc, path))", "response": "A thread - safe way to acquire a file lock."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef proxy_global(name, no_expand_macro=False, fname='func', args=()):\n    if no_expand_macro:  # pragma: no cover\n        # handle older ROOT versions without _ExpandMacroFunction wrapping\n        @property\n        def gSomething_no_func(self):\n            glob = self(getattr(ROOT, name))\n            # create a fake func() that just returns self\n            def func():\n                return glob\n            glob.func = func\n            return glob\n        return gSomething_no_func\n\n    @property\n    def gSomething(self):\n        obj_func = getattr(getattr(ROOT, name), fname)\n        try:\n            obj = obj_func(*args)\n        except ReferenceError:  # null pointer\n            return None\n        # asrootpy\n        return self(obj)\n\n    return gSomething", "response": "Proxy a global variable to the asrootpy ROOT object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an entry to the legend.", "response": "def AddEntry(self, thing, label=None, style=None):\n        \"\"\"\n        Add an entry to the legend.\n\n        If `label` is None, `thing.GetTitle()` will be used as the label.\n\n        If `style` is None, `thing.legendstyle` is used if present,\n        otherwise `P`.\n        \"\"\"\n        if isinstance(thing, HistStack):\n            things = thing\n        else:\n            things = [thing]\n        for thing in things:\n            if getattr(thing, 'inlegend', True):\n                thing_label = thing.GetTitle() if label is None else label\n                thing_style = getattr(thing, 'legendstyle', 'P') if style is None else style\n                super(Legend, self).AddEntry(thing, thing_label, thing_style)\n                keepalive(self, thing)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_seh():\n    if ON_RTD:\n        return lambda x: x\n\n    ErrorHandlerFunc_t = ctypes.CFUNCTYPE(\n        None, ctypes.c_int, ctypes.c_bool,\n        ctypes.c_char_p, ctypes.c_char_p)\n\n    # Required to avoid strange dynamic linker problem on OSX.\n    # See https://github.com/rootpy/rootpy/issues/256\n    import ROOT\n\n    dll = get_dll(\"libCore\")\n\n    SetErrorHandler = None\n    try:\n        if dll:\n            SetErrorHandler = dll._Z15SetErrorHandlerPFvibPKcS0_E\n    except AttributeError:\n        pass\n\n    if not SetErrorHandler:\n        log.warning(\n            \"Couldn't find SetErrorHandler. \"\n            \"Please submit a rootpy bug report.\")\n        return lambda x: None\n\n    SetErrorHandler.restype = ErrorHandlerFunc_t\n    SetErrorHandler.argtypes = ErrorHandlerFunc_t,\n\n    def _SetErrorHandler(fn):\n        \"\"\"\n        Set ROOT's warning/error handler. Returns the existing one.\n        \"\"\"\n        log.debug(\"called SetErrorHandler()\")\n        eh = ErrorHandlerFunc_t(fn)\n        # ``eh`` can get garbage collected unless kept alive, leading to a segfault.\n        _keep_alive.append(eh)\n        return SetErrorHandler(eh)\n\n    return _SetErrorHandler", "response": "Returns a function which can be used to set the ROOT s warning error handler with a\n    python function and returns the existing error handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the index of the f_code variable in the threadstate structure.", "response": "def get_f_code_idx():\n    \"\"\"\n    How many pointers into PyFrame is the ``f_code`` variable?\n    \"\"\"\n    frame = sys._getframe()\n    frame_ptr = id(frame)\n\n    LARGE_ENOUGH = 20\n\n    # Look through the frame object until we find the f_tstate variable, whose\n    # value we know from above.\n    ptrs = [ctypes.c_voidp.from_address(frame_ptr+i*svp)\n            for i in range(LARGE_ENOUGH)]\n\n    # Find its index into the structure\n    ptrs = [p.value for p in ptrs]\n\n    fcode_ptr = id(frame.f_code)\n    try:\n        threadstate_idx = ptrs.index(fcode_ptr)\n    except ValueError:\n        log.critical(\"rootpy bug! Please report this.\")\n        raise\n    return threadstate_idx"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_frame_pointers(frame=None):\n    if frame is None:\n        frame = sys._getframe(2)\n    frame = id(frame)\n\n    # http://hg.python.org/cpython/file/3aa530c2db06/Include/frameobject.h#l28\n    F_TRACE_OFFSET = 6\n    Ppy_object = ctypes.POINTER(ctypes.py_object)\n    trace = Ppy_object.from_address(frame+(F_CODE_IDX+F_TRACE_OFFSET)*svp)\n\n    LASTI_OFFSET = F_TRACE_OFFSET + 4\n\n    lasti_addr  = LASTI_OFFSET\n    lineno_addr = LASTI_OFFSET + ctypes.sizeof(ctypes.c_int)\n\n    f_lineno = ctypes.c_int.from_address(lineno_addr)\n    f_lasti = ctypes.c_int.from_address(lasti_addr)\n\n    return trace, f_lineno, f_lasti", "response": "Obtain writable pointers to frame. f_trace and frame. f_lineno."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmodifying the linetrace on a frame.", "response": "def set_linetrace_on_frame(f, localtrace=None):\n    \"\"\"\n    Non-portable function to modify linetracing.\n\n    Remember to enable global tracing with :py:func:`sys.settrace`, otherwise no\n    effect!\n    \"\"\"\n    traceptr, _, _ = get_frame_pointers(f)\n    if localtrace is not None:\n        # Need to incref to avoid the frame causing a double-delete\n        ctypes.pythonapi.Py_IncRef(localtrace)\n        # Not sure if this is the best way to do this, but it works.\n        addr = id(localtrace)\n    else:\n        addr = 0\n\n    traceptr.contents = ctypes.py_object.from_address(addr)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef re_execute_with_exception(frame, exception, traceback):\n    if sys.gettrace() == globaltrace:\n        # If our trace handler is already installed, that means that this\n        # function has been called twice before the line tracer had a chance to\n        # run. That can happen if more than one exception was logged.\n        return\n\n    call_lineno = frame.f_lineno\n\n    def intercept_next_line(f, why, *args):\n        if f is not frame:\n            return\n        set_linetrace_on_frame(f)\n        # Undo modifications to the callers code (ick ick ick)\n        back_like_nothing_happened()\n        # Raise exception in (almost) the perfect place (except for duplication)\n        if sys.version_info[0] < 3:\n            #raise exception.__class__, exception, traceback\n            raise exception\n        raise exception.with_traceback(traceback)\n\n    set_linetrace_on_frame(frame, intercept_next_line)\n\n    linestarts = list(dis.findlinestarts(frame.f_code))\n    linestarts = [a for a, l in linestarts if l >= call_lineno]\n\n    # Jump target\n    dest = linestarts[0]\n\n    oc = frame.f_code.co_code[frame.f_lasti]\n    if sys.version_info[0] < 3:\n        oc = ord(oc)\n    opcode_size = 2 if oc >= opcode.HAVE_ARGUMENT else 0\n    # Opcode to overwrite\n    where = frame.f_lasti + 1 + opcode_size\n\n    #dis.disco(frame.f_code)\n    pc = PyCodeObject.from_address(id(frame.f_code))\n    back_like_nothing_happened = pc.co_code.contents.inject_jump(where, dest)\n    #print(\"#\"*100)\n    #dis.disco(frame.f_code)\n\n    sys.settrace(globaltrace)", "response": "Re - execute a frame with an exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _inject_jump(self, where, dest):\n    # We're about to do dangerous things to a function's code content.\n    # We can't make a lock to prevent the interpreter from using those\n    # bytes, so the best we can do is to set the check interval to be high\n    # and just pray that this keeps other threads at bay.\n    if sys.version_info[0] < 3:\n        old_check_interval = sys.getcheckinterval()\n        sys.setcheckinterval(2**20)\n    else:\n        old_check_interval = sys.getswitchinterval()\n        sys.setswitchinterval(1000)\n\n    pb = ctypes.pointer(self.ob_sval)\n    orig_bytes = [pb[where + i][0] for i in range(3)]\n\n    v = struct.pack(\"<BH\", opcode.opmap[\"JUMP_ABSOLUTE\"], dest)\n\n    # Overwrite code to cause it to jump to the target\n    if sys.version_info[0] < 3:\n        for i in range(3):\n            pb[where + i][0] = ord(v[i])\n    else:\n        for i in range(3):\n            pb[where + i][0] = v[i]\n\n    def tidy_up():\n        \"\"\"\n        Put the bytecode back to how it was. Good as new.\n        \"\"\"\n        if sys.version_info[0] < 3:\n            sys.setcheckinterval(old_check_interval)\n        else:\n            sys.setswitchinterval(old_check_interval)\n        for i in range(3):\n            pb[where + i][0] = orig_bytes[i]\n\n    return tidy_up", "response": "Injects jump instructions into the bytecode at where."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix_ipython_startup(fn):\n    BADSTR = 'TPython::Exec( \"\" )'\n    GOODSTR = 'TPython::Exec( \"\" );'\n    if sys.version_info[0] < 3:\n        consts = fn.im_func.func_code.co_consts\n    else:\n        consts = fn.__code__.co_consts\n    if BADSTR not in consts:\n        return\n    idx = consts.index(BADSTR)\n    orig_refcount = sys.getrefcount(consts)\n    del consts\n\n    PyTuple_SetItem = ctypes.pythonapi.PyTuple_SetItem\n    PyTuple_SetItem.argtypes = (ctypes.py_object,\n                                ctypes.c_size_t,\n                                ctypes.py_object)\n\n    if sys.version_info[0] < 3:\n        consts = ctypes.py_object(fn.im_func.func_code.co_consts)\n    else:\n        consts = ctypes.py_object(fn.im_func.__code__.co_consts)\n\n    for _ in range(orig_refcount - 2):\n        ctypes.pythonapi.Py_DecRef(consts)\n    try:\n        ctypes.pythonapi.Py_IncRef(GOODSTR)\n        PyTuple_SetItem(consts, idx, GOODSTR)\n    finally:\n        for _ in range(orig_refcount - 2):\n            ctypes.pythonapi.Py_IncRef(consts)", "response": "Fix IPython startup to not print"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, value=None):\n        'Updates the ProgressBar to a new value.'\n\n        if value is not None and value is not UnknownLength:\n            if (self.maxval is not UnknownLength\n                    and not 0 <= value <= self.maxval\n                    and not value < self.currval):\n\n                raise ValueError('Value out of range')\n\n            self.currval = value\n\n        if self.start_time is None:\n            self.start()\n            self.update(value)\n        if not self._need_update():\n            return\n\n        if self.redirect_stderr and sys.stderr.tell():\n            self.fd.write('\\r' + ' ' * self.term_width + '\\r')\n            self._stderr.write(sys.stderr.getvalue())\n            self._stderr.flush()\n            sys.stderr = StringIO()\n\n        if self.redirect_stdout and sys.stdout.tell():\n            self.fd.write('\\r' + ' ' * self.term_width + '\\r')\n            self._stdout.write(sys.stdout.getvalue())\n            self._stdout.flush()\n            sys.stdout = StringIO()\n\n        now = time.time()\n        self.seconds_elapsed = now - self.start_time\n        self.next_update = self.currval + self.update_interval\n        self.fd.write('\\r' + self._format_line())\n        self.last_update_time = now", "response": "Updates the ProgressBar to a new value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self):\n        '''Starts measuring time, and prints the bar at 0%.\n\n        It returns self so you can use it like this:\n\n        >>> pbar = ProgressBar().start()\n        >>> for i in range(100):\n        ...    # do something\n        ...    pbar.update(i+1)\n        ...\n        >>> pbar.finish()\n        '''\n\n        if self.redirect_stderr:\n            self._stderr = sys.stderr\n            sys.stderr = StringIO()\n\n        if self.redirect_stdout:\n            self._stdout = sys.stdout\n            sys.stdout = StringIO()\n\n        if self.maxval is None:\n            self.maxval = self._DEFAULT_MAXVAL\n\n        self.num_intervals = max(100, self.term_width)\n        self.next_update = 0\n\n        if self.maxval is not UnknownLength:\n            if self.maxval < 0:\n                raise ValueError('Value out of range')\n            self.update_interval = self.maxval / self.num_intervals\n\n        self.start_time = self.last_update_time = time.time()\n        self.update(0)\n\n        return self", "response": "Starts measuring time and prints the bar at 0%. This method returns self so you can use it like this."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef finish(self):\n        'Puts the ProgressBar bar in the finished state.'\n\n        self.finished = True\n        self.update(self.maxval)\n        self.fd.write('\\n')\n        if self.signal_set:\n            signal.signal(signal.SIGWINCH, signal.SIG_DFL)\n\n        if self.redirect_stderr:\n            self._stderr.write(sys.stderr.getvalue())\n            sys.stderr = self._stderr\n\n        if self.redirect_stdout:\n            self._stdout.write(sys.stdout.getvalue())\n            sys.stdout = self._stdout", "response": "Puts the ProgressBar bar in the finished state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Draw(self, *args, **kwargs):\n        self.reset()\n        output = None\n        while self._rollover():\n            if output is None:\n                # Make our own copy of the drawn histogram\n                output = self._tree.Draw(*args, **kwargs)\n                if output is not None:\n                    output = output.Clone()\n                    # Make it memory resident (histograms)\n                    if hasattr(output, 'SetDirectory'):\n                        output.SetDirectory(0)\n            else:\n                newoutput = self._tree.Draw(*args, **kwargs)\n                if newoutput is not None:\n                    if isinstance(output, _GraphBase):\n                        output.Append(newoutput)\n                    else:  # histogram\n                        output += newoutput\n        return output", "response": "Draw the histogram for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an interactive python console with the given header.", "response": "def interact_plain(header=UP_LINE, local_ns=None,\n                   module=None, dummy=None,\n                   stack_depth=1, global_ns=None):\n    \"\"\"\n    Create an interactive python console\n    \"\"\"\n    frame = sys._getframe(stack_depth)\n\n    variables = {}\n\n    if local_ns is not None:\n        variables.update(local_ns)\n    else:\n        variables.update(frame.f_locals)\n\n    if global_ns is not None:\n        variables.update(local_ns)\n    else:\n        variables.update(frame.f_globals)\n\n    shell = code.InteractiveConsole(variables)\n    return shell.interact(banner=header)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a matplotlib hist plot from a ROOT histogram, stack or list of histograms. Parameters ---------- hists : Hist, list of Hist, HistStack The histogram(s) to be plotted stacked : bool, optional (default=True) If True then stack the histograms with the first histogram on the bottom, otherwise overlay them with the first histogram in the background. reverse : bool, optional (default=False) If True then reverse the order of the stack or overlay. xpadding : float or 2-tuple of floats, optional (default=0) Padding to add on the left and right sides of the plot as a fraction of the axes width after the padding has been added. Specify unique left and right padding with a 2-tuple. ypadding : float or 2-tuple of floats, optional (default=.1) Padding to add on the top and bottom of the plot as a fraction of the axes height after the padding has been added. Specify unique top and bottom padding with a 2-tuple. yerror_in_padding : bool, optional (default=True) If True then make the padding inclusive of the y errors otherwise only pad around the y values. logy : bool, optional (default=None) Apply special treatment of a log-scale y-axis to display the histogram correctly. If None (the default) then automatically determine if the y-axis is log-scale. snap : bool, optional (default=True) If True (the default) then the origin is an implicit lower bound of the histogram unless the histogram has both positive and negative bins. axes : matplotlib Axes instance, optional (default=None) The axes to plot on. If None then use the global current axes. kwargs : additional keyword arguments, optional All additional keyword arguments are passed to matplotlib's fill_between for the filled regions and matplotlib's step function for the edges. Returns ------- The return value from matplotlib's hist function, or list of such return values if a stack or list of histograms was plotted.", "response": "def hist(hists,\n         stacked=True,\n         reverse=False,\n         xpadding=0, ypadding=.1,\n         yerror_in_padding=True,\n         logy=None,\n         snap=True,\n         axes=None,\n         **kwargs):\n    \"\"\"\n    Make a matplotlib hist plot from a ROOT histogram, stack or\n    list of histograms.\n\n    Parameters\n    ----------\n\n    hists : Hist, list of Hist, HistStack\n        The histogram(s) to be plotted\n\n    stacked : bool, optional (default=True)\n        If True then stack the histograms with the first histogram on the\n        bottom, otherwise overlay them with the first histogram in the\n        background.\n\n    reverse : bool, optional (default=False)\n        If True then reverse the order of the stack or overlay.\n\n    xpadding : float or 2-tuple of floats, optional (default=0)\n        Padding to add on the left and right sides of the plot as a fraction of\n        the axes width after the padding has been added. Specify unique left\n        and right padding with a 2-tuple.\n\n    ypadding : float or 2-tuple of floats, optional (default=.1)\n        Padding to add on the top and bottom of the plot as a fraction of\n        the axes height after the padding has been added. Specify unique top\n        and bottom padding with a 2-tuple.\n\n    yerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the y errors otherwise\n        only pad around the y values.\n\n    logy : bool, optional (default=None)\n        Apply special treatment of a log-scale y-axis to display the histogram\n        correctly. If None (the default) then automatically determine if the\n        y-axis is log-scale.\n\n    snap : bool, optional (default=True)\n        If True (the default) then the origin is an implicit lower bound of the\n        histogram unless the histogram has both positive and negative bins.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        All additional keyword arguments are passed to matplotlib's\n        fill_between for the filled regions and matplotlib's step function\n        for the edges.\n\n    Returns\n    -------\n\n    The return value from matplotlib's hist function, or list of such return\n    values if a stack or list of histograms was plotted.\n\n    \"\"\"\n    if axes is None:\n        axes = plt.gca()\n    if logy is None:\n        logy = axes.get_yscale() == 'log'\n    curr_xlim = axes.get_xlim()\n    curr_ylim = axes.get_ylim()\n    was_empty = not axes.has_data()\n    returns = []\n    if isinstance(hists, _Hist):\n        # This is a single plottable object.\n        returns = _hist(hists, axes=axes, logy=logy, **kwargs)\n        _set_bounds(hists, axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    elif stacked:\n        # draw the top histogram first so its edges don't cover the histograms\n        # beneath it in the stack\n        if not reverse:\n            hists = list(hists)[::-1]\n        for i, h in enumerate(hists):\n            kwargs_local = kwargs.copy()\n            if i == len(hists) - 1:\n                low = h.Clone()\n                low.Reset()\n            else:\n                low = sum(hists[i + 1:])\n            high = h + low\n            high.alpha = getattr(h, 'alpha', None)\n            proxy = _hist(high, bottom=low, axes=axes, logy=logy, **kwargs)\n            returns.append(proxy)\n        if not reverse:\n            returns = returns[::-1]\n        _set_bounds(sum(hists), axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    else:\n        for h in _maybe_reversed(hists, reverse):\n            returns.append(_hist(h, axes=axes, logy=logy, **kwargs))\n        if reverse:\n            returns = returns[::-1]\n        _set_bounds(hists[max(range(len(hists)), key=lambda idx: hists[idx].max())],\n                    axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    return returns"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a matplotlib bar plot from a ROOT histogram, stack or list of histograms. Parameters ---------- hists : Hist, list of Hist, HistStack The histogram(s) to be plotted stacked : bool or string, optional (default=True) If True then stack the histograms with the first histogram on the bottom, otherwise overlay them with the first histogram in the background. If 'cluster', then the bars will be arranged side-by-side. reverse : bool, optional (default=False) If True then reverse the order of the stack or overlay. xerr : bool, optional (default=False) If True, x error bars will be displayed. yerr : bool or string, optional (default=True) If False, no y errors are displayed. If True, an individual y error will be displayed for each hist in the stack. If 'linear' or 'quadratic', a single error bar will be displayed with either the linear or quadratic sum of the individual errors. xpadding : float or 2-tuple of floats, optional (default=0) Padding to add on the left and right sides of the plot as a fraction of the axes width after the padding has been added. Specify unique left and right padding with a 2-tuple. ypadding : float or 2-tuple of floats, optional (default=.1) Padding to add on the top and bottom of the plot as a fraction of the axes height after the padding has been added. Specify unique top and bottom padding with a 2-tuple. yerror_in_padding : bool, optional (default=True) If True then make the padding inclusive of the y errors otherwise only pad around the y values. rwidth : float, optional (default=0.8) The relative width of the bars as a fraction of the bin width. snap : bool, optional (default=True) If True (the default) then the origin is an implicit lower bound of the histogram unless the histogram has both positive and negative bins. axes : matplotlib Axes instance, optional (default=None) The axes to plot on. If None then use the global current axes. kwargs : additional keyword arguments, optional All additional keyword arguments are passed to matplotlib's bar function. Returns ------- The return value from matplotlib's bar function, or list of such return values if a stack or list of histograms was plotted.", "response": "def bar(hists,\n        stacked=True,\n        reverse=False,\n        xerr=False, yerr=True,\n        xpadding=0, ypadding=.1,\n        yerror_in_padding=True,\n        rwidth=0.8,\n        snap=True,\n        axes=None,\n        **kwargs):\n    \"\"\"\n    Make a matplotlib bar plot from a ROOT histogram, stack or\n    list of histograms.\n\n    Parameters\n    ----------\n\n    hists : Hist, list of Hist, HistStack\n        The histogram(s) to be plotted\n\n    stacked : bool or string, optional (default=True)\n        If True then stack the histograms with the first histogram on the\n        bottom, otherwise overlay them with the first histogram in the\n        background. If 'cluster', then the bars will be arranged side-by-side.\n\n    reverse : bool, optional (default=False)\n        If True then reverse the order of the stack or overlay.\n\n    xerr : bool, optional (default=False)\n        If True, x error bars will be displayed.\n\n    yerr : bool or string, optional (default=True)\n        If False, no y errors are displayed.  If True, an individual y\n        error will be displayed for each hist in the stack.  If 'linear' or\n        'quadratic', a single error bar will be displayed with either the\n        linear or quadratic sum of the individual errors.\n\n    xpadding : float or 2-tuple of floats, optional (default=0)\n        Padding to add on the left and right sides of the plot as a fraction of\n        the axes width after the padding has been added. Specify unique left\n        and right padding with a 2-tuple.\n\n    ypadding : float or 2-tuple of floats, optional (default=.1)\n        Padding to add on the top and bottom of the plot as a fraction of\n        the axes height after the padding has been added. Specify unique top\n        and bottom padding with a 2-tuple.\n\n    yerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the y errors otherwise\n        only pad around the y values.\n\n    rwidth : float, optional (default=0.8)\n        The relative width of the bars as a fraction of the bin width.\n\n    snap : bool, optional (default=True)\n        If True (the default) then the origin is an implicit lower bound of the\n        histogram unless the histogram has both positive and negative bins.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        All additional keyword arguments are passed to matplotlib's bar\n        function.\n\n    Returns\n    -------\n\n    The return value from matplotlib's bar function, or list of such return\n    values if a stack or list of histograms was plotted.\n\n    \"\"\"\n    if axes is None:\n        axes = plt.gca()\n    curr_xlim = axes.get_xlim()\n    curr_ylim = axes.get_ylim()\n    was_empty = not axes.has_data()\n    logy = kwargs.pop('log', axes.get_yscale() == 'log')\n    kwargs['log'] = logy\n    returns = []\n    if isinstance(hists, _Hist):\n        # This is a single histogram.\n        returns = _bar(hists, xerr=xerr, yerr=yerr,\n                       axes=axes, **kwargs)\n        _set_bounds(hists, axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    elif stacked == 'cluster':\n        nhists = len(hists)\n        hlist = _maybe_reversed(hists, reverse)\n        for i, h in enumerate(hlist):\n            width = rwidth / nhists\n            offset = (1 - rwidth) / 2 + i * width\n            returns.append(_bar(\n                h, offset, width,\n                xerr=xerr, yerr=yerr, axes=axes, **kwargs))\n        _set_bounds(sum(hists), axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    elif stacked is True:\n        nhists = len(hists)\n        hlist = _maybe_reversed(hists, reverse)\n        toterr = bottom = None\n        if yerr == 'linear':\n            toterr = [sum([h.GetBinError(i) for h in hists])\n                      for i in range(1, hists[0].nbins(0) + 1)]\n        elif yerr == 'quadratic':\n            toterr = [sqrt(sum([h.GetBinError(i) ** 2 for h in hists]))\n                      for i in range(1, hists[0].nbins(0) + 1)]\n        for i, h in enumerate(hlist):\n            err = None\n            if yerr is True:\n                err = True\n            elif yerr and i == (nhists - 1):\n                err = toterr\n            returns.append(_bar(\n                h,\n                xerr=xerr, yerr=err,\n                bottom=list(bottom.y()) if bottom else None,\n                axes=axes, **kwargs))\n            if bottom is None:\n                bottom = h.Clone()\n            else:\n                bottom += h\n        _set_bounds(bottom, axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    else:\n        hlist = _maybe_reversed(hists, reverse)\n        for h in hlist:\n            returns.append(_bar(h, xerr=xerr, yerr=yerr,\n                                axes=axes, **kwargs))\n        _set_bounds(hists[max(range(len(hists)), key=lambda idx: hists[idx].max())],\n                    axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    return returns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a matplotlib errorbar plot from a ROOT histogram or graph or list of histograms and graphs. Parameters ---------- hists : Hist, Graph or list of Hist and Graph The histogram(s) and/or Graph(s) to be plotted xerr : bool, optional (default=True) If True, x error bars will be displayed. yerr : bool or string, optional (default=True) If False, no y errors are displayed. If True, an individual y error will be displayed for each hist in the stack. If 'linear' or 'quadratic', a single error bar will be displayed with either the linear or quadratic sum of the individual errors. xpadding : float or 2-tuple of floats, optional (default=0) Padding to add on the left and right sides of the plot as a fraction of the axes width after the padding has been added. Specify unique left and right padding with a 2-tuple. ypadding : float or 2-tuple of floats, optional (default=.1) Padding to add on the top and bottom of the plot as a fraction of the axes height after the padding has been added. Specify unique top and bottom padding with a 2-tuple. xerror_in_padding : bool, optional (default=True) If True then make the padding inclusive of the x errors otherwise only pad around the x values. yerror_in_padding : bool, optional (default=True) If True then make the padding inclusive of the y errors otherwise only pad around the y values. emptybins : bool, optional (default=True) If True (the default) then plot bins with zero content otherwise only show bins with nonzero content. snap : bool, optional (default=True) If True (the default) then the origin is an implicit lower bound of the histogram unless the histogram has both positive and negative bins. axes : matplotlib Axes instance, optional (default=None) The axes to plot on. If None then use the global current axes. kwargs : additional keyword arguments, optional All additional keyword arguments are passed to matplotlib's errorbar function. Returns ------- The return value from matplotlib's errorbar function, or list of such return values if a list of histograms and/or graphs was plotted.", "response": "def errorbar(hists,\n             xerr=True, yerr=True,\n             xpadding=0, ypadding=.1,\n             xerror_in_padding=True,\n             yerror_in_padding=True,\n             emptybins=True,\n             snap=True,\n             axes=None,\n             **kwargs):\n    \"\"\"\n    Make a matplotlib errorbar plot from a ROOT histogram or graph\n    or list of histograms and graphs.\n\n    Parameters\n    ----------\n\n    hists : Hist, Graph or list of Hist and Graph\n        The histogram(s) and/or Graph(s) to be plotted\n\n    xerr : bool, optional (default=True)\n        If True, x error bars will be displayed.\n\n    yerr : bool or string, optional (default=True)\n        If False, no y errors are displayed.  If True, an individual y\n        error will be displayed for each hist in the stack.  If 'linear' or\n        'quadratic', a single error bar will be displayed with either the\n        linear or quadratic sum of the individual errors.\n\n    xpadding : float or 2-tuple of floats, optional (default=0)\n        Padding to add on the left and right sides of the plot as a fraction of\n        the axes width after the padding has been added. Specify unique left\n        and right padding with a 2-tuple.\n\n    ypadding : float or 2-tuple of floats, optional (default=.1)\n        Padding to add on the top and bottom of the plot as a fraction of\n        the axes height after the padding has been added. Specify unique top\n        and bottom padding with a 2-tuple.\n\n    xerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the x errors otherwise\n        only pad around the x values.\n\n    yerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the y errors otherwise\n        only pad around the y values.\n\n    emptybins : bool, optional (default=True)\n        If True (the default) then plot bins with zero content otherwise only\n        show bins with nonzero content.\n\n    snap : bool, optional (default=True)\n        If True (the default) then the origin is an implicit lower bound of the\n        histogram unless the histogram has both positive and negative bins.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        All additional keyword arguments are passed to matplotlib's errorbar\n        function.\n\n    Returns\n    -------\n\n    The return value from matplotlib's errorbar function, or list of such\n    return values if a list of histograms and/or graphs was plotted.\n\n    \"\"\"\n    if axes is None:\n        axes = plt.gca()\n    curr_xlim = axes.get_xlim()\n    curr_ylim = axes.get_ylim()\n    was_empty = not axes.has_data()\n    if isinstance(hists, (_Hist, _Graph1DBase)):\n        # This is a single plottable object.\n        returns = _errorbar(\n            hists, xerr, yerr,\n            axes=axes, emptybins=emptybins, **kwargs)\n        _set_bounds(hists, axes=axes,\n                    was_empty=was_empty,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    xerror_in_padding=xerror_in_padding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap)\n    else:\n        returns = []\n        for h in hists:\n            returns.append(errorbar(\n                h, xerr=xerr, yerr=yerr, axes=axes,\n                xpadding=xpadding, ypadding=ypadding,\n                xerror_in_padding=xerror_in_padding,\n                yerror_in_padding=yerror_in_padding,\n                snap=snap,\n                emptybins=emptybins,\n                **kwargs))\n    return returns"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef step(h, logy=None, axes=None, **kwargs):\n    if axes is None:\n        axes = plt.gca()\n    if logy is None:\n        logy = axes.get_yscale() == 'log'\n    _set_defaults(h, kwargs, ['common', 'line'])\n    if kwargs.get('color') is None:\n        kwargs['color'] = h.GetLineColor('mpl')\n    y = np.array(list(h.y()) + [0.])\n    if logy:\n        np.clip(y, 1E-300, 1E300, out=y)\n    return axes.step(list(h.xedges()), y, where='post', **kwargs)", "response": "Make a matplotlib step plot from a ROOT histogram."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfills the region between two histograms or graphs.", "response": "def fill_between(a, b, logy=None, axes=None, **kwargs):\n    \"\"\"\n    Fill the region between two histograms or graphs.\n\n    Parameters\n    ----------\n\n    a : Hist\n        A rootpy Hist\n\n    b : Hist\n        A rootpy Hist\n\n    logy : bool, optional (default=None)\n        If True then clip the region between 1E-300 and 1E300.\n        If None (the default) then automatically determine if the axes are\n        log-scale and if this clipping should be performed.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        Additional keyword arguments are passed directly to\n        matplotlib's fill_between function.\n\n    Returns\n    -------\n\n    Returns the value from matplotlib's fill_between function.\n\n    \"\"\"\n    if axes is None:\n        axes = plt.gca()\n    if logy is None:\n        logy = axes.get_yscale() == 'log'\n    if not isinstance(a, _Hist) or not isinstance(b, _Hist):\n        raise TypeError(\n            \"fill_between only operates on 1D histograms\")\n    a.check_compatibility(b, check_edges=True)\n    x = []\n    top = []\n    bottom = []\n    for abin, bbin in zip(a.bins(overflow=False), b.bins(overflow=False)):\n        up = max(abin.value, bbin.value)\n        dn = min(abin.value, bbin.value)\n        x.extend([abin.x.low, abin.x.high])\n        top.extend([up, up])\n        bottom.extend([dn, dn])\n    x = np.array(x)\n    top = np.array(top)\n    bottom = np.array(bottom)\n    if logy:\n        np.clip(top, 1E-300, 1E300, out=top)\n        np.clip(bottom, 1E-300, 1E300, out=bottom)\n    return axes.fill_between(x, top, bottom, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hist2d(h, axes=None, colorbar=False, **kwargs):\n    if axes is None:\n        axes = plt.gca()\n    X, Y = np.meshgrid(list(h.x()), list(h.y()))\n    x = X.ravel()\n    y = Y.ravel()\n    z = np.array(h.z()).T\n    # returns of hist2d: (counts, xedges, yedges, Image)\n    return_values = axes.hist2d(x, y, weights=z.ravel(),\n                                bins=(list(h.xedges()), list(h.yedges())),\n                                **kwargs)\n    if colorbar:\n        mappable = return_values[-1]\n        plt.colorbar(mappable, ax=axes)\n    return return_values", "response": "Draw a 2D matplotlib histogram plot from a ROOT histogram."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imshow(h, axes=None, colorbar=False, **kwargs):\n    kwargs.setdefault('aspect', 'auto')\n\n    if axes is None:\n        axes = plt.gca()\n    z = np.array(h.z()).T\n\n    axis_image= axes.imshow(\n        z,\n        extent=[\n            h.xedges(1), h.xedges(h.nbins(0) + 1),\n            h.yedges(1), h.yedges(h.nbins(1) + 1)],\n        interpolation='nearest',\n        origin='lower',\n        **kwargs)\n    if colorbar:\n        plt.colorbar(axis_image, ax=axes)\n    return axis_image", "response": "Draw a matplotlib imshow plot from a 2D ROOT histogram."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef contour(h, axes=None, zoom=None, label_contour=False, **kwargs):\n    if axes is None:\n        axes = plt.gca()\n    x = np.array(list(h.x()))\n    y = np.array(list(h.y()))\n    z = np.array(h.z()).T\n    if zoom is not None:\n        from scipy import ndimage\n        if hasattr(zoom, '__iter__'):\n            zoom = list(zoom)\n            x = ndimage.zoom(x, zoom[0])\n            y = ndimage.zoom(y, zoom[1])\n        else:\n            x = ndimage.zoom(x, zoom)\n            y = ndimage.zoom(y, zoom)\n        z = ndimage.zoom(z, zoom)\n    return_values = axes.contour(x, y, z, **kwargs)\n    if label_contour:\n        plt.clabel(return_values)\n    return return_values", "response": "Draw a matplotlib contour plot from a 2D ROOT histogram."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the internal state of the object.", "response": "def _post_init(self):\n        \"\"\"\n        The standard rootpy _post_init method that is used to initialize both\n        new Trees and Trees retrieved from a File.\n        \"\"\"\n        if not hasattr(self, '_buffer'):\n            # only set _buffer if model was not specified in the __init__\n            self._buffer = TreeBuffer()\n        self.read_branches_on_demand = False\n        self._branch_cache = {}\n        self._current_entry = 0\n        self._always_read = []\n        self.userdata = UserData()\n        self._inited = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef branch_type(cls, branch):\n        typename = branch.GetClassName()\n        if not typename:\n            leaf = branch.GetListOfLeaves()[0]\n            typename = leaf.GetTypeName()\n            # check if leaf has multiple elements\n            leaf_count = leaf.GetLeafCount()\n            if leaf_count:\n                length = leaf_count.GetMaximum()\n            else:\n                length = leaf.GetLen()\n            if length > 1:\n                typename = '{0}[{1:d}]'.format(typename, length)\n        return typename", "response": "Return the string representation of the type of a branch"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates this tree s TreeBuffer object and initialize it with the tree s branch types.", "response": "def create_buffer(self, ignore_unsupported=False):\n        \"\"\"\n        Create this tree's TreeBuffer\n        \"\"\"\n        bufferdict = OrderedDict()\n        for branch in self.iterbranches():\n            # only include activated branches\n            if not self.GetBranchStatus(branch.GetName()):\n                continue\n            if not BaseTree.branch_is_supported(branch):\n                log.warning(\n                    \"ignore unsupported branch `{0}`\".format(branch.GetName()))\n                continue\n            bufferdict[branch.GetName()] = Tree.branch_type(branch)\n        self.set_buffer(TreeBuffer(\n            bufferdict,\n            ignore_unsupported=ignore_unsupported))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates branches from a TreeBuffer or dict mapping names to type names", "response": "def create_branches(self, branches):\n        \"\"\"\n        Create branches from a TreeBuffer or dict mapping names to type names\n\n        Parameters\n        ----------\n        branches : TreeBuffer or dict\n        \"\"\"\n        if not isinstance(branches, TreeBuffer):\n            branches = TreeBuffer(branches)\n        self.set_buffer(branches, create_branches=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the internal TreeBuffer with the items from a TreeBuffer into this Tree s TreeBuffer.", "response": "def update_buffer(self, treebuffer, transfer_objects=False):\n        \"\"\"\n        Merge items from a TreeBuffer into this Tree's TreeBuffer\n\n        Parameters\n        ----------\n        buffer : rootpy.tree.buffer.TreeBuffer\n            The TreeBuffer to merge into this Tree's buffer\n\n        transfer_objects : bool, optional (default=False)\n            If True then all objects and collections on the input buffer will\n            be transferred to this Tree's buffer.\n        \"\"\"\n        self._buffer.update(treebuffer)\n        if transfer_objects:\n            self._buffer.set_objects(treebuffer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the TreeBuffer for this Tree.", "response": "def set_buffer(self, treebuffer,\n                   branches=None,\n                   ignore_branches=None,\n                   create_branches=False,\n                   visible=True,\n                   ignore_missing=False,\n                   ignore_duplicates=False,\n                   transfer_objects=False):\n        \"\"\"\n        Set the Tree buffer\n\n        Parameters\n        ----------\n        treebuffer : rootpy.tree.buffer.TreeBuffer\n            a TreeBuffer\n\n        branches : list, optional (default=None)\n            only include these branches from the TreeBuffer\n\n        ignore_branches : list, optional (default=None)\n            ignore these branches from the TreeBuffer\n\n        create_branches : bool, optional (default=False)\n            If True then the branches in the TreeBuffer should be created.\n            Use this option if initializing the Tree. A ValueError is raised\n            if an attempt is made to create a branch with the same name as one\n            that already exists in the Tree. If False the addresses of existing\n            branches will be set to point at the addresses in this buffer.\n\n        visible : bool, optional (default=True)\n            If True then the branches will be added to the buffer and will be\n            accessible as attributes of the Tree.\n\n        ignore_missing : bool, optional (default=False)\n            If True then any branches in this buffer that do not exist in the\n            Tree will be ignored, otherwise a ValueError will be raised. This\n            option is only valid when ``create_branches`` is False.\n\n        ignore_duplicates : bool, optional (default=False)\n            If False then raise a ValueError if the tree already has a branch\n            with the same name as an entry in the buffer. If True then skip\n            branches that already exist. This option is only valid when\n            ``create_branches`` is True.\n\n        transfer_objects : bool, optional (default=False)\n            If True, all tree objects and collections will be transferred from\n            the buffer into this Tree's buffer.\n        \"\"\"\n        # determine branches to keep while preserving branch order\n        if branches is None:\n            branches = treebuffer.keys()\n        if ignore_branches is not None:\n            branches = [b for b in branches if b not in ignore_branches]\n\n        if create_branches:\n            for name in branches:\n                value = treebuffer[name]\n                if self.has_branch(name):\n                    if ignore_duplicates:\n                        log.warning(\n                            \"Skipping entry in buffer with the same name \"\n                            \"as an existing branch: `{0}`\".format(name))\n                        continue\n                    raise ValueError(\n                        \"Attempting to create two branches \"\n                        \"with the same name: `{0}`\".format(name))\n                if isinstance(value, Scalar):\n                    self.Branch(name, value,\n                        '{0}/{1}'.format(\n                            name, value.type))\n                elif isinstance(value, Array):\n                    length = value.length_name or len(value)\n                    self.Branch(name, value,\n                        '{0}[{2}]/{1}'.format(\n                            name, value.type, length))\n                else:\n                    self.Branch(name, value)\n        else:\n            for name in branches:\n                value = treebuffer[name]\n                if self.has_branch(name):\n                    self.SetBranchAddress(name, value)\n                elif not ignore_missing:\n                    raise ValueError(\n                        \"Attempting to set address for \"\n                        \"branch `{0}` which does not exist\".format(name))\n                else:\n                    log.warning(\n                        \"Skipping entry in buffer for which no \"\n                        \"corresponding branch in the \"\n                        \"tree exists: `{0}`\".format(name))\n        if visible:\n            newbuffer = TreeBuffer()\n            for branch in branches:\n                if branch in treebuffer:\n                    newbuffer[branch] = treebuffer[branch]\n            newbuffer.set_objects(treebuffer)\n            self.update_buffer(newbuffer, transfer_objects=transfer_objects)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of branch names that match a pattern in the specified list of patterns.", "response": "def glob(self, patterns, exclude=None):\n        \"\"\"\n        Return a list of branch names that match ``pattern``.\n        Exclude all matched branch names which also match a pattern in\n        ``exclude``. ``exclude`` may be a string or list of strings.\n\n        Parameters\n        ----------\n        patterns: str or list\n            branches are matched against this pattern or list of patterns where\n            globbing is performed with '*'.\n\n        exclude : str or list, optional (default=None)\n            branches matching this pattern or list of patterns are excluded\n            even if they match a pattern in ``patterns``.\n\n        Returns\n        -------\n        matches : list\n            List of matching branch names\n        \"\"\"\n        if isinstance(patterns, string_types):\n            patterns = [patterns]\n        if isinstance(exclude, string_types):\n            exclude = [exclude]\n        matches = []\n        for pattern in patterns:\n            matches += fnmatch.filter(self.iterbranchnames(), pattern)\n            if exclude is not None:\n                for exclude_pattern in exclude:\n                    matches = [match for match in matches\n                               if not fnmatch.fnmatch(match, exclude_pattern)]\n        return matches"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an entry. Tree collections are reset.", "response": "def GetEntry(self, entry):\n        \"\"\"\n        Get an entry. Tree collections are reset\n        (see ``rootpy.tree.treeobject``)\n\n        Parameters\n        ----------\n        entry : int\n            entry index\n\n        Returns\n        -------\n        ROOT.TTree.GetEntry : int\n            The number of bytes read\n        \"\"\"\n        if not (0 <= entry < self.GetEntries()):\n            raise IndexError(\"entry index out of range: {0:d}\".format(entry))\n        self._buffer.reset_collections()\n        return super(BaseTree, self).GetEntry(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef csv(self, sep=',', branches=None,\n            include_labels=True, limit=None,\n            stream=None):\n        \"\"\"\n        Print csv representation of tree only including branches\n        of basic types (no objects, vectors, etc..)\n\n        Parameters\n        ----------\n        sep : str, optional (default=',')\n            The delimiter used to separate columns\n\n        branches : list, optional (default=None)\n            Only include these branches in the CSV output. If None, then all\n            basic types will be included.\n\n        include_labels : bool, optional (default=True)\n            Include a first row of branch names labelling each column.\n\n        limit : int, optional (default=None)\n            Only include up to a maximum of ``limit`` rows in the CSV.\n\n        stream : file, (default=None)\n            Stream to write the CSV output on. By default the CSV will be\n            written to ``sys.stdout``.\n        \"\"\"\n        supported_types = (Scalar, Array, stl.string)\n        if stream is None:\n            stream = sys.stdout\n        if not self._buffer:\n            self.create_buffer(ignore_unsupported=True)\n        if branches is None:\n            branchdict = OrderedDict([\n                (name, self._buffer[name])\n                for name in self.iterbranchnames()\n                if isinstance(self._buffer[name], supported_types)])\n        else:\n            branchdict = OrderedDict()\n            for name in branches:\n                if not isinstance(self._buffer[name], supported_types):\n                    raise TypeError(\n                        \"selected branch `{0}` \"\n                        \"is not a scalar or array type\".format(name))\n                branchdict[name] = self._buffer[name]\n        if not branchdict:\n            raise RuntimeError(\n                \"no branches selected or no \"\n                \"branches of scalar or array types exist\")\n        if include_labels:\n            # expand array types to f[0],f[1],f[2],...\n            print(sep.join(\n                name if isinstance(value, (Scalar, BaseChar, stl.string))\n                    else sep.join('{0}[{1:d}]'.format(name, idx)\n                                  for idx in range(len(value)))\n                        for name, value in branchdict.items()),\n                file=stream)\n        # even though 'entry' is not used, enumerate or simply iterating over\n        # self is required to update the buffer with the new branch values at\n        # each tree entry.\n        for i, entry in enumerate(self):\n            line = []\n            for value in branchdict.values():\n                if isinstance(value, (Scalar, BaseChar)):\n                    token = str(value.value)\n                elif isinstance(value, stl.string):\n                    token = str(value)\n                else:\n                    token = sep.join(map(str, value))\n                line.append(token)\n            print(sep.join(line), file=stream)\n            if limit is not None and i + 1 == limit:\n                break", "response": "Print the CSV representation of the tree only including basic types and branches."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetEntries(self, cut=None, weighted_cut=None, weighted=False):\n        if weighted_cut:\n            hist = Hist(1, -1, 2)\n            branch = self.GetListOfBranches()[0].GetName()\n            weight = self.GetWeight()\n            self.SetWeight(1)\n            self.Draw('{0}=={1}>>{2}'.format(branch, branch, hist.GetName()),\n                      weighted_cut * cut)\n            self.SetWeight(weight)\n            entries = hist.Integral()\n        elif cut:\n            entries = super(BaseTree, self).GetEntries(str(cut))\n        else:\n            entries = super(BaseTree, self).GetEntries()\n        if weighted:\n            entries *= self.GetWeight()\n        return entries", "response": "Get the number of entries in the Tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the maximum value of an anonymization.", "response": "def GetMaximum(self, expression, cut=None):\n        \"\"\"\n        TODO: we need a better way of determining the maximum value of an\n        expression.\n        \"\"\"\n        if cut:\n            self.Draw(expression, cut, 'goff')\n        else:\n            self.Draw(expression, '', 'goff')\n        vals = self.GetV1()\n        n = self.GetSelectedRows()\n        vals = [vals[i] for i in range(min(n, 10000))]\n        return max(vals)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetMinimum(self, expression, cut=None):\n        if cut:\n            self.Draw(expression, cut, \"goff\")\n        else:\n            self.Draw(expression, \"\", \"goff\")\n        vals = self.GetV1()\n        n = self.GetSelectedRows()\n        vals = [vals[i] for i in range(min(n, 10000))]\n        return min(vals)", "response": "Get the minimum value of an anonymization."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies the tree while supporting a rootpy. tree. cut. Cut selection in addition to a simple string.", "response": "def CopyTree(self, selection, *args, **kwargs):\n        \"\"\"\n        Copy the tree while supporting a rootpy.tree.cut.Cut selection in\n        addition to a simple string.\n        \"\"\"\n        return super(BaseTree, self).CopyTree(str(selection), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Draw(self,\n             expression,\n             selection=\"\",\n             options=\"\",\n             hist=None,\n             create_hist=False,\n             **kwargs):\n        \"\"\"\n        Draw a TTree with a selection as usual, but return the created\n        histogram.\n\n        Parameters\n        ----------\n        expression : str\n            The expression to draw. Multidimensional expressions are separated\n            by \":\". rootpy reverses the expressions along each dimension so the\n            order matches the order of the elements identifying a location in\n            the resulting histogram. By default ROOT takes the expression \"Y:X\"\n            to mean Y versus X but we argue that this is counterintuitive and\n            that the order should be \"X:Y\" so that the expression along the\n            first dimension identifies the location along the first axis, etc.\n\n        selection : str or rootpy.tree.Cut, optional (default=\"\")\n            The cut expression. Only entries satisfying this selection are\n            included in the filled histogram.\n\n        options : str, optional (default=\"\")\n            Draw options passed to ROOT.TTree.Draw\n\n        hist : ROOT.TH1, optional (default=None)\n            The histogram to be filled. If not specified, rootpy will attempt\n            to find what ROOT created and return that.\n\n        create_hist : bool (default=False)\n            If True and `hist`` is not specified and a histogram name is not\n            specified in the draw expression, then override ROOT's\n            default behaviour and fill a new histogram. ROOT will otherwise add\n            points to a TGraph or TPolyMarker3D if not drawing in more than\n            two dimensions.\n\n        kwargs : dict, optional\n            Remaining keword arguments are used to set the style attributes of\n            the histogram.\n\n        Returns\n        -------\n        If ``hist`` is specified, None is returned. If ``hist`` is left\n        unspecified, an attempt is made to retrieve the generated histogram\n        which is then returned.\n\n        \"\"\"\n        if isinstance(expression, string_types):\n            # Check that we have a valid draw expression\n            exprmatch = re.match(BaseTree.DRAW_PATTERN, expression)\n            if not exprmatch:\n                raise ValueError(\n                    \"not a valid draw expression: `{0}`\".format(expression))\n            exprdict = exprmatch.groupdict()\n\n            # Reverse variable order to match order in hist constructor\n            fields = re.split('(?<!:):(?!:)', exprdict['branches'])\n            num_dimensions = len(fields)\n            expression = ':'.join(fields[:3][::-1] + fields[3:])\n            if exprdict['redirect'] is not None:\n                expression += exprdict['redirect']\n\n        else:  # expression is list, tuple, ...\n            fields = expression\n            num_dimensions = len(fields)\n            expression = ':'.join(fields[:3][::-1] + fields[3:])\n            exprdict = {\n                'branches': None,\n                'redirect': None,\n                'name': None,\n                'binning': None,\n                }\n\n        if not isinstance(selection, Cut):\n            # Let Cut handle any extra processing (i.e. ternary operators)\n            selection = Cut(selection)\n\n        graphics = 'goff' not in options\n\n        if hist is not None:\n            if not isinstance(hist, ROOT.TH1):\n                raise TypeError(\"Cannot draw into a `{0}`\".format(type(hist)))\n\n            # Check that the dimensionality of the expression and object match\n            if num_dimensions != hist.GetDimension():\n                raise TypeError(\n                    \"The dimensionality of the expression `{0}` ({1:d}) \"\n                    \"does not match the dimensionality of a `{2}`\".format(\n                        expression, num_dimensions, hist.__class__.__name__))\n            # Handle graphics ourselves\n            if graphics:\n                if options:\n                    options += ' '\n                options += 'goff'\n            if exprdict['name'] is None:\n                # Draw into histogram supplied by user\n                expression = '{0}>>+{1}'.format(expression, hist.GetName())\n            else:\n                if exprdict['name'] != hist.GetName():\n                    # If the user specified a name to draw into then check that\n                    # this is consistent with the specified object.\n                    raise ValueError(\n                        \"The name specified in the draw \"\n                        \"expression `{0}` does not match the \"\n                        \"name of the specified object `{1}`\".format(\n                            exprdict['name'],\n                            hist.GetName()))\n                # Check that binning is not specified\n                if exprdict['binning'] is not None:\n                    raise ValueError(\n                        \"When specifying the object to draw into, do not \"\n                        \"specify a binning in the draw expression\")\n        else:\n            if create_hist and exprdict['name'] is None:\n                if num_dimensions > 4:\n                    raise ValueError(\n                        \"Cannot create a histogram for expressions with \"\n                        \"more than 4 dimensions\")\n                newname = '{0}_{1}'.format(self.__class__.__name__, uuid())\n                expression += '>>{0}'.format(newname)\n                exprdict['name'] = newname\n\n            pad = ROOT.gPad\n            own_pad = False\n\n            if graphics and not pad:\n                # Create a new canvas if one doesn't exist yet\n                own_pad = True\n                pad = Canvas()\n\n        #  Note: TTree.Draw() pollutes gDirectory, make a temporary one\n        with thread_specific_tmprootdir():\n            if hist is not None:\n                # If a custom histogram is specified (i.e, it's not being\n                # created root side), then temporarily put it into the\n                # temporary thread-specific directory.\n                context = set_directory(hist)\n            else:\n                context = do_nothing()\n            with context:\n                super(BaseTree, self).Draw(expression, selection, options)\n\n        if hist is None:\n            # Retrieve histogram made by TTree.Draw\n            if num_dimensions == 1 or exprdict['name'] is not None:\n                # a TH1\n                hist = asrootpy(self.GetHistogram(), warn=False)\n            elif num_dimensions == 2:\n                # a TGraph\n                hist = asrootpy(pad.GetPrimitive('Graph'), warn=False)\n            else:\n                # ROOT: For a three and four dimensional Draw the TPolyMarker3D\n                # is unnamed, and cannot be retrieved. Why, ROOT?\n                log.warning(\n                    \"Cannot retrieve the TPolyMarker3D for \"\n                    \"3D and 4D expressions\")\n                if graphics and own_pad:\n                    # Since we cannot access the TPolyMarker3D we use self to\n                    # keep the canvas alive\n                    keepalive(self, pad)\n            if hist: # is not None\n                if isinstance(hist, Plottable):\n                    hist.decorate(**kwargs)\n                # ROOT, don't try to delete this object! (See issue #277)\n                hist.SetBit(ROOT.kCanDelete, False)\n                if graphics:\n                    if own_pad:\n                        # The usual bug is that the histogram is garbage\n                        # collected and we want the canvas to keep the\n                        # histogram alive, but here the canvas has been\n                        # created locally and we are returning the histogram,\n                        # so we want the histogram to keep the canvas alive.\n                        keepalive(hist, pad)\n                    # Redraw the histogram since we may have specified style\n                    # attributes in **kwargs\n                    hist.Draw()\n            if graphics:\n                pad.Modified()\n                pad.Update()\n        return hist", "response": "Draw a ROOT TTree with a selection as usual but return the created TTree or TPolyMarker3D histogram."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_array(self, *args, **kwargs):\n        from root_numpy import tree2array\n        return tree2array(self, *args, **kwargs)", "response": "Convert this tree into a NumPy structured array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef color_key(tkey):\n    name = tkey.GetName()\n    classname = tkey.GetClassName()\n    for class_regex, color in _COLOR_MATCHER:\n        if class_regex.match(classname):\n            return colored(name, color=color)\n    return name", "response": "Function which returns a colorized TKey name given its type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nestimate a covariance matrix given data.", "response": "def cov(m, y=None, rowvar=1, bias=0, ddof=None, weights=None, repeat_weights=0):\n    \"\"\"\n    Estimate a covariance matrix, given data.\n\n    Covariance indicates the level to which two variables vary together.\n    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\n    then the covariance matrix element :math:`C_{ij}` is the covariance of\n    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\n    of :math:`x_i`.\n\n    Parameters\n    ----------\n    m : array_like\n        A 1-D or 2-D array containing multiple variables and observations.\n        Each row of `m` represents a variable, and each column a single\n        observation of all those variables. Also see `rowvar` below.\n    y : array_like, optional\n        An additional set of variables and observations. `y` has the same\n        form as that of `m`.\n    rowvar : int, optional\n        If `rowvar` is non-zero (default), then each row represents a\n        variable, with observations in the columns. Otherwise, the relationship\n        is transposed: each column represents a variable, while the rows\n        contain observations.\n    bias : int, optional\n        Default normalization is by ``(N - 1)``, where ``N`` is the number of\n        observations given (unbiased estimate). If `bias` is 1, then\n        normalization is by ``N``. These values can be overridden by using\n        the keyword ``ddof`` in numpy versions >= 1.5.\n    ddof : int, optional\n        .. versionadded:: 1.5\n        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is\n        the number of observations; this overrides the value implied by\n        ``bias``. The default value is ``None``.\n    weights : array-like, optional\n        A 1-D array of weights with a length equal to the number of\n        observations.\n    repeat_weights : int, optional\n        The default treatment of weights in the weighted covariance is to first\n        normalize them to unit sum and use the biased weighted covariance\n        equation. If `repeat_weights` is 1 then the weights must represent an\n        integer number of occurrences of each observation and both a biased and\n        unbiased weighted covariance is defined because the total sample size\n        can be determined.\n\n    Returns\n    -------\n    out : ndarray\n        The covariance matrix of the variables.\n\n    See Also\n    --------\n    corrcoef : Normalized covariance matrix\n\n    Examples\n    --------\n    Consider two variables, :math:`x_0` and :math:`x_1`, which\n    correlate perfectly, but in opposite directions:\n\n    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n    >>> x\n    array([[0, 1, 2],\n           [2, 1, 0]])\n\n    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance\n    matrix shows this clearly:\n\n    >>> np.cov(x)\n    array([[ 1., -1.],\n           [-1.,  1.]])\n\n    Note that element :math:`C_{0,1}`, which shows the correlation between\n    :math:`x_0` and :math:`x_1`, is negative.\n\n    Further, note how `x` and `y` are combined:\n\n    >>> x = [-2.1, -1,  4.3]\n    >>> y = [3,  1.1,  0.12]\n    >>> X = np.vstack((x,y))\n    >>> print np.cov(X)\n    [[ 11.71        -4.286     ]\n     [ -4.286        2.14413333]]\n    >>> print np.cov(x, y)\n    [[ 11.71        -4.286     ]\n     [ -4.286        2.14413333]]\n    >>> print np.cov(x)\n    11.71\n\n    \"\"\"\n    import numpy as np\n    # Check inputs\n    if ddof is not None and ddof != int(ddof):\n        raise ValueError(\n            \"ddof must be integer\")\n\n    X = np.array(m, ndmin=2, dtype=float)\n    if X.size == 0:\n        # handle empty arrays\n        return np.array(m)\n    if X.shape[0] == 1:\n        rowvar = 1\n    if rowvar:\n        axis = 0\n        tup = (slice(None), np.newaxis)\n    else:\n        axis = 1\n        tup = (np.newaxis, slice(None))\n\n    if y is not None:\n        y = np.array(y, copy=False, ndmin=2, dtype=float)\n        X = np.concatenate((X, y), axis)\n\n    if ddof is None:\n        if bias == 0:\n            ddof = 1\n        else:\n            ddof = 0\n\n    if weights is not None:\n        weights = np.array(weights, dtype=float)\n        weights_sum = weights.sum()\n        if weights_sum <= 0:\n            raise ValueError(\n                \"sum of weights is non-positive\")\n        X -= np.average(X, axis=1-axis, weights=weights)[tup]\n\n        if repeat_weights:\n            # each weight represents a number of repetitions of an observation\n            # the total sample size can be determined in this case and we have\n            # both an unbiased and biased weighted covariance\n            fact = weights_sum - ddof\n        else:\n            # normalize weights so they sum to unity\n            weights /= weights_sum\n            # unbiased weighted covariance is not defined if the weights are\n            # not integral frequencies (repeat-type)\n            fact = (1. - np.power(weights, 2).sum())\n    else:\n        weights = 1\n        X -= X.mean(axis=1-axis)[tup]\n        if rowvar:\n            N = X.shape[1]\n        else:\n            N = X.shape[0]\n        fact = float(N - ddof)\n\n    if not rowvar:\n        return (np.dot(weights * X.T, X.conj()) / fact).squeeze()\n    else:\n        return (np.dot(weights * X, X.T.conj()) / fact).squeeze()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef corrcoef(x, y=None, rowvar=1, bias=0, ddof=None, weights=None,\n             repeat_weights=0):\n    \"\"\"\n    Return correlation coefficients.\n\n    Please refer to the documentation for `cov` for more detail.  The\n    relationship between the correlation coefficient matrix, `P`, and the\n    covariance matrix, `C`, is\n\n    .. math:: P_{ij} = \\\\frac{ C_{ij} } { \\\\sqrt{ C_{ii} * C_{jj} } }\n\n    The values of `P` are between -1 and 1, inclusive.\n\n    Parameters\n    ----------\n    x : array_like\n        A 1-D or 2-D array containing multiple variables and observations.\n        Each row of `m` represents a variable, and each column a single\n        observation of all those variables. Also see `rowvar` below.\n    y : array_like, optional\n        An additional set of variables and observations. `y` has the same\n        shape as `m`.\n    rowvar : int, optional\n        If `rowvar` is non-zero (default), then each row represents a\n        variable, with observations in the columns. Otherwise, the relationship\n        is transposed: each column represents a variable, while the rows\n        contain observations.\n    bias : int, optional\n        Default normalization is by ``(N - 1)``, where ``N`` is the number of\n        observations (unbiased estimate). If `bias` is 1, then\n        normalization is by ``N``. These values can be overridden by using\n        the keyword ``ddof`` in numpy versions >= 1.5.\n    ddof : {None, int}, optional\n        .. versionadded:: 1.5\n        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is\n        the number of observations; this overrides the value implied by\n        ``bias``. The default value is ``None``.\n    weights : array-like, optional\n        A 1-D array of weights with a length equal to the number of\n        observations.\n    repeat_weights : int, optional\n        The default treatment of weights in the weighted covariance is to first\n        normalize them to unit sum and use the biased weighted covariance\n        equation. If `repeat_weights` is 1 then the weights must represent an\n        integer number of occurrences of each observation and both a biased and\n        unbiased weighted covariance is defined because the total sample size\n        can be determined.\n\n    Returns\n    -------\n    out : ndarray\n        The correlation coefficient matrix of the variables.\n\n    See Also\n    --------\n    cov : Covariance matrix\n\n    \"\"\"\n    import numpy as np\n    c = cov(x, y, rowvar, bias, ddof, weights, repeat_weights)\n    if c.size == 0:\n        # handle empty arrays\n        return c\n    try:\n        d = np.diag(c)\n    except ValueError:  # scalar covariance\n        return 1\n    return c / np.sqrt(np.multiply.outer(d, d))", "response": "Returns the correlation coefficients of the given data sets and the given data sets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string representation of the current locale.", "response": "def safe(self, parentheses=True):\n        \"\"\"\n        Returns a string representation with special characters\n        replaced by safer characters for use in file names.\n        \"\"\"\n        if not self:\n            return \"\"\n        string = str(self)\n        string = string.replace(\"**\", \"_pow_\")\n        string = string.replace(\"*\", \"_mul_\")\n        string = string.replace(\"/\", \"_div_\")\n        string = string.replace(\"==\", \"_eq_\")\n        string = string.replace(\"<=\", \"_leq_\")\n        string = string.replace(\">=\", \"_geq_\")\n        string = string.replace(\"<\", \"_lt_\")\n        string = string.replace(\">\", \"_gt_\")\n        string = string.replace(\"&&\", \"_and_\")\n        string = string.replace(\"||\", \"_or_\")\n        string = string.replace(\"!\", \"not_\")\n        if parentheses:\n            string = string.replace(\"(\", \"L\")\n            string = string.replace(\")\", \"R\")\n        else:\n            string = string.replace(\"(\", \"\")\n            string = string.replace(\")\", \"\")\n        string = string.replace(\" \", \"\")\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string representation for use in LaTeX", "response": "def latex(self):\n        \"\"\"\n        Returns a string representation for use in LaTeX\n        \"\"\"\n        if not self:\n            return \"\"\n        s = str(self)\n        s = s.replace(\"==\", \" = \")\n        s = s.replace(\"<=\", \" \\leq \")\n        s = s.replace(\">=\", \" \\geq \")\n        s = s.replace(\"&&\", r\" \\text{ and } \")\n        s = s.replace(\"||\", r\" \\text{ or } \")\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace all occurrences of name with newname", "response": "def replace(self, name, newname):\n        \"\"\"\n        Replace all occurrences of name with newname\n        \"\"\"\n        if not re.match(\"[a-zA-Z]\\w*\", name):\n            return None\n        if not re.match(\"[a-zA-Z]\\w*\", newname):\n            return None\n\n        def _replace(match):\n            return match.group(0).replace(match.group('name'), newname)\n\n        pattern = re.compile(\"(\\W|^)(?P<name>\" + name + \")(\\W|$)\")\n        cut = re.sub(pattern, _replace, str(self))\n        return Cut(cut)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the offsets in a byte code which are start of lines in the source", "response": "def _findlinestarts(code):\n        \"\"\"Find the offsets in a byte code which are start of lines in the source\n        Generate pairs offset,lineno as described in Python/compile.c\n        This is a modified version of dis.findlinestarts, which allows multiplelinestarts\n        with the same line number\"\"\"\n        lineno = code.co_firstlineno\n        addr = 0\n        for byte_incr, line_incr in zip(code.co_lnotab[0::2], code.co_lnotab[1::2]):\n            if byte_incr:\n                yield addr, lineno\n                addr += byte_incr\n            lineno += line_incr\n        yield addr, lineno"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisassembling a Python code object into a Code object.", "response": "def from_code(cls, co):\n        \"\"\"Disassemble a Python code object into a Code object\"\"\"\n        free_cell_isection = set(co.co_cellvars) & set(co.co_freevars)\n        if free_cell_isection:\n            print(co.co_name + ': has non-empty co.co_cellvars & co.co_freevars', free_cell_isection)\n            return None\n\n        co_code = co.co_code\n        labels = {addr: Label() for addr in findlabels(co_code)}\n        linestarts = dict(cls._findlinestarts(co))\n        cellfree = co.co_cellvars + co.co_freevars\n        code = []\n        extended_arg = 0\n        is_generator = False\n        is_coroutine = False\n\n        for i in range(0, len(co_code), 2):\n            if i in labels:\n                code.append((labels[i], None))\n            if i in linestarts:\n                code.append((SetLineno, linestarts[i]))\n            op = Opcode(co_code[i])\n            arg = co_code[i+1] | extended_arg\n            if op in hascode:\n                lastop, lastarg = code[-2]\n                if lastop != LOAD_CONST:\n                    raise ValueError(\"%s should be preceded by LOAD_CONST\" % op)\n\n                sub_code = Code.from_code(lastarg)\n                if sub_code is None:\n                    print(co.co_name + ': has unexpected subcode block')\n                    return None\n\n                code[-2] = (LOAD_CONST, sub_code)\n            if op == opcode.EXTENDED_ARG:\n                extended_arg = arg << 8\n            else:\n                if op not in hasarg:\n                    code.append((op, None))\n                    continue\n                extended_arg = 0\n                byteplay_arg = co.co_consts[arg] if op in hasconst else \\\n                               co.co_names[arg] if op in hasname else \\\n                               labels[arg] if op in hasjabs else \\\n                               labels[i + 2 + arg] if op in hasjrel else \\\n                               co.co_varnames[arg] if op in haslocal else \\\n                               cmp_op[arg] if op in hascompare else \\\n                               cellfree[arg] if op in hasfree else \\\n                               arg\n                code.append((op, byteplay_arg))\n\n            if op == YIELD_VALUE or op == YIELD_FROM:\n                is_generator = True\n\n            if op in coroutine_opcodes:\n                is_coroutine = True\n\n        varargs = not not co.co_flags & CO_VARARGS\n        varkwargs = not not co.co_flags & CO_VARKEYWORDS\n\n        force_coroutine = not is_coroutine and (co.co_flags & CO_COROUTINE)\n        force_iterable_coroutine = co.co_flags & CO_ITERABLE_COROUTINE\n        force_async_generator = co.co_flags & CO_ASYNC_GENERATOR\n\n        is_generator = False if force_async_generator else is_generator\n        force_generator = not is_generator and (co.co_flags & CO_GENERATOR)\n\n        assert not (force_coroutine and force_iterable_coroutine)\n        assert not (force_coroutine and force_async_generator)\n        assert not (force_iterable_coroutine and force_async_generator)\n        future_generator_stop = co.co_flags & CO_FUTURE_GENERATOR_STOP\n\n        return cls(code=code,\n                   freevars=co.co_freevars,\n                   args=co.co_varnames[:co.co_argcount + varargs + varkwargs + co.co_kwonlyargcount],\n                   kwonly=co.co_kwonlyargcount,\n                   varargs=varargs,\n                   varkwargs=varkwargs,\n                   newlocals=not not co.co_flags & CO_NEWLOCALS,\n                   name=co.co_name,\n                   filename=co.co_filename,\n                   firstlineno=co.co_firstlineno,\n                   docstring=co.co_consts[0] if co.co_consts and isinstance(co.co_consts[0], str) else None,\n                   force_generator=force_generator,\n                   force_coroutine=force_coroutine,\n                   force_iterable_coroutine=force_iterable_coroutine,\n                   force_async_generator=force_async_generator,\n                   future_generator_stop=future_generator_stop)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the image file to disk.", "response": "def save_image(self, image_file):\n        \"\"\"\n        Saves the image file to disk.\n        \"\"\"\n        self.ensure_pyplot()\n        command = 'plt.gcf().savefig(\"%s\")'%image_file\n        #print 'SAVEFIG', command  # dbg\n        self.process_input_line('bookmark ipy_thisdir', store_history=False)\n        self.process_input_line('cd -b ipy_savedir', store_history=False)\n        self.process_input_line(command, store_history=False)\n        self.process_input_line('cd -b ipy_thisdir', store_history=False)\n        self.process_input_line('bookmark -d ipy_thisdir', store_history=False)\n        self.clear_cout()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_pure_python(self, content):\n        output = []\n        savefig = False # keep up with this to clear figure\n        multiline = False # to handle line continuation\n        multiline_start = None\n        fmtin = self.promptin\n\n        ct = 0\n\n        for lineno, line in enumerate(content):\n\n            line_stripped = line.strip()\n            if not len(line):\n                output.append(line)\n                continue\n\n            # handle decorators\n            if line_stripped.startswith('@'):\n                output.extend([line])\n                if 'savefig' in line:\n                    savefig = True # and need to clear figure\n                continue\n\n            # handle comments\n            if line_stripped.startswith('#'):\n                output.extend([line])\n                continue\n\n            # deal with lines checking for multiline\n            continuation  = u'   %s:'% ''.join(['.']*(len(str(ct))+2))\n            if not multiline:\n                modified = u\"%s %s\" % (fmtin % ct, line_stripped)\n                output.append(modified)\n                ct += 1\n                try:\n                    ast.parse(line_stripped)\n                    output.append(u'')\n                except Exception: # on a multiline\n                    multiline = True\n                    multiline_start = lineno\n            else: # still on a multiline\n                modified = u'%s %s' % (continuation, line)\n                output.append(modified)\n                try:\n                    mod = ast.parse(\n                            '\\n'.join(content[multiline_start:lineno+1]))\n                    if isinstance(mod.body[0], ast.FunctionDef):\n                        # check to see if we have the whole function\n                        for element in mod.body[0].body:\n                            if isinstance(element, ast.Return):\n                                multiline = False\n                    else:\n                        output.append(u'')\n                        multiline = False\n                except Exception:\n                    pass\n\n            if savefig: # clear figure if plotted\n                self.ensure_pyplot()\n                self.process_input_line('plt.clf()', store_history=False)\n                self.clear_cout()\n                savefig = False\n\n        return output", "response": "Process pure python code."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_markerstyle(inputstyle, mode, inputmode=None):\n    mode = mode.lower()\n    if mode not in ('mpl', 'root'):\n        raise ValueError(\"`{0}` is not valid `mode`\".format(mode))\n    if inputmode is None:\n        if inputstyle in markerstyles_root2mpl:\n            inputmode = 'root'\n        elif inputstyle in markerstyles_mpl2root or '$' in str(inputstyle):\n            inputmode = 'mpl'\n        elif inputstyle in markerstyles_text2root:\n            inputmode = 'root'\n            inputstyle = markerstyles_text2root[inputstyle]\n        else:\n            raise ValueError(\n                \"`{0}` is not a valid `markerstyle`\".format(inputstyle))\n    if inputmode == 'root':\n        if inputstyle not in markerstyles_root2mpl:\n            raise ValueError(\n                \"`{0}` is not a valid ROOT `markerstyle`\".format(\n                    inputstyle))\n        if mode == 'root':\n            return inputstyle\n        return markerstyles_root2mpl[inputstyle]\n    else:\n        if '$' in str(inputstyle):\n            if mode == 'root':\n                return 1\n            else:\n                return inputstyle\n        if inputstyle not in markerstyles_mpl2root:\n            raise ValueError(\n                \"`{0}` is not a valid matplotlib `markerstyle`\".format(\n                    inputstyle))\n        if mode == 'mpl':\n            return inputstyle\n        return markerstyles_mpl2root[inputstyle]", "response": "Convert a ROOT marker style to a matplotlib or description."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a ROOT line style to a matplotlib or text line style.", "response": "def convert_linestyle(inputstyle, mode, inputmode=None):\n    \"\"\"\n    Convert *inputstyle* to ROOT or matplotlib format.\n\n    Output format is determined by *mode* ('root' or 'mpl').  The *inputstyle*\n    may be a ROOT line style, a matplotlib line style, or a description\n    such as 'solid' or 'dotted'.\n    \"\"\"\n    mode = mode.lower()\n    if mode not in ('mpl', 'root'):\n        raise ValueError(\n            \"`{0}` is not a valid `mode`\".format(mode))\n    try:\n        inputstyle = int(inputstyle)\n        if inputstyle < 1:\n            inputstyle = 1\n    except (TypeError, ValueError):\n        pass\n    if inputmode is None:\n        if inputstyle in linestyles_root2mpl:\n            inputmode = 'root'\n        elif inputstyle in linestyles_mpl2root:\n            inputmode = 'mpl'\n        elif inputstyle in linestyles_text2root:\n            inputmode = 'root'\n            inputstyle = linestyles_text2root[inputstyle]\n        else:\n            raise ValueError(\n                \"`{0}` is not a valid `linestyle`\".format(\n                    inputstyle))\n    if inputmode == 'root':\n        if inputstyle not in linestyles_root2mpl:\n            raise ValueError(\n                \"`{0}` is not a valid ROOT `linestyle`\".format(\n                    inputstyle))\n        if mode == 'root':\n            return inputstyle\n        return linestyles_root2mpl[inputstyle]\n    else:\n        if inputstyle not in linestyles_mpl2root:\n            raise ValueError(\n                \"`{0}` is not a valid matplotlib `linestyle`\".format(\n                    inputstyle))\n        if mode == 'mpl':\n            return inputstyle\n        return linestyles_mpl2root[inputstyle]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a ROOT fillstyle to a matplotlib or ROOT format.", "response": "def convert_fillstyle(inputstyle, mode, inputmode=None):\n    \"\"\"\n    Convert *inputstyle* to ROOT or matplotlib format.\n\n    Output format is determined by *mode* ('root' or 'mpl').  The *inputstyle*\n    may be a ROOT fill style, a matplotlib hatch style, None, 'none', 'hollow',\n    or 'solid'.\n    \"\"\"\n    mode = mode.lower()\n    if mode not in ('mpl', 'root'):\n        raise ValueError(\"`{0}` is not a valid `mode`\".format(mode))\n    if inputmode is None:\n        try:\n            # inputstyle is a ROOT linestyle\n            inputstyle = int(inputstyle)\n            inputmode = 'root'\n        except (TypeError, ValueError):\n            if inputstyle is None:\n                inputmode = 'mpl'\n            elif inputstyle in fillstyles_text2root:\n                inputmode = 'root'\n                inputstyle = fillstyles_text2root[inputstyle]\n            elif inputstyle[0] in fillstyles_mpl2root:\n                inputmode = 'mpl'\n            else:\n                raise ValueError(\n                    \"`{0}` is not a valid `fillstyle`\".format(inputstyle))\n    if inputmode == 'root':\n        if mode == 'root':\n            return inputstyle\n        if inputstyle in fillstyles_root2mpl:\n            return fillstyles_root2mpl[inputstyle]\n        raise ValueError(\n            \"`{0}` is not a valid `fillstyle`\".format(inputstyle))\n    else:\n        if inputstyle is not None and inputstyle[0] not in fillstyles_mpl2root:\n            raise ValueError(\n                \"`{0}` is not a valid matplotlib `fillstyle`\".format(\n                    inputstyle))\n        if mode == 'mpl':\n            return inputstyle\n        if inputstyle is None:\n            return fillstyles_mpl2root[inputstyle]\n        return fillstyles_mpl2root[inputstyle[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_color(color, mode):\n    mode = mode.lower()\n    if mode not in ('mpl', 'root'):\n        raise ValueError(\n            \"`{0}` is not a valid `mode`\".format(mode))\n    try:\n        # color is an r,g,b tuple\n        color = tuple([float(x) for x in color[:3]])\n        if max(color) > 1.:\n            color = tuple([x / 255. for x in color])\n        if mode == 'root':\n            return ROOT.TColor.GetColor(*color)\n        return color\n    except (ValueError, TypeError):\n        pass\n    if isinstance(color, string_types):\n        if color in _cnames:\n            # color is a matplotlib letter or an html color name\n            color = _cnames[color]\n        if color[0] == '#':\n            # color is a hex value\n            color = color.lstrip('#')\n            lv = len(color)\n            color = tuple(int(color[i:i + lv // 3], 16)\n                          for i in range(0, lv, lv // 3))\n            if lv == 3:\n                color = tuple(x * 16 + x for x in color)\n            return convert_color(color, mode)\n        # color is a shade of gray, i.e. '0.3'\n        return convert_color((color, color, color), mode)\n    try:\n        # color is a TColor\n        color = ROOT.TColor(color)\n        color = color.GetRed(), color.GetGreen(), color.GetBlue()\n        return convert_color(color, mode)\n    except (TypeError, ReferenceError):\n        pass\n    try:\n        # color is a ROOT color index\n        if color < 0:\n            color = 0\n        color = ROOT.gROOT.GetColor(color)\n        # Protect against the case a histogram with a custom color\n        # is saved in a ROOT file\n        if not color:\n            # Just return black\n            color = ROOT.gROOT.GetColor(1)\n        color = color.GetRed(), color.GetGreen(), color.GetBlue()\n        return convert_color(color, mode)\n    except (TypeError, ReferenceError):\n        pass\n    raise ValueError(\"'{0!s}' is not a valid `color`\".format(color))", "response": "Convert a color to a ROOT TColor if mode = root or to a TColor if mode = mpl."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _clone_post_init(self, obj=None, **kwargs):\n        # Initialize the extra attributes\n        if obj is None or obj is self:\n            # We must be asrootpy-ing a ROOT object\n            # or freshly init-ing a rootpy object\n            for attr, value in Plottable.EXTRA_ATTRS.items():\n                # Use the default value\n                setattr(self, attr, value)\n        else:\n            for attr, value in Plottable.EXTRA_ATTRS.items():\n                setattr(self, attr, getattr(obj, attr))\n\n        # Create aliases from deprecated to current attributes\n        for depattr, newattr in Plottable.EXTRA_ATTRS_DEPRECATED.items():\n            setattr(Plottable, depattr,\n                    property(\n                        fget=Plottable._get_attr_depr(depattr, newattr),\n                        fset=Plottable._set_attr_depr(depattr, newattr)))\n\n        if obj is None or obj is self:\n            # We must be asrootpy-ing a ROOT object\n            # or freshly init-ing a rootpy object\n            # Initialize style attrs to style of TObject\n            if isinstance(self, ROOT.TAttLine):\n                self._linecolor = Color(ROOT.TAttLine.GetLineColor(self))\n                self._linestyle = LineStyle(ROOT.TAttLine.GetLineStyle(self))\n                self._linewidth = ROOT.TAttLine.GetLineWidth(self)\n            else:  # HistStack\n                self._linecolor = Color(Plottable.DEFAULT_DECOR['linecolor'])\n                self._linestyle = LineStyle(Plottable.DEFAULT_DECOR['linestyle'])\n                self._linewidth = Plottable.DEFAULT_DECOR['linewidth']\n\n            if isinstance(self, ROOT.TAttFill):\n                self._fillcolor = Color(ROOT.TAttFill.GetFillColor(self))\n                self._fillstyle = FillStyle(ROOT.TAttFill.GetFillStyle(self))\n            else:  # HistStack\n                self._fillcolor = Color(Plottable.DEFAULT_DECOR['fillcolor'])\n                self._fillstyle = FillStyle(Plottable.DEFAULT_DECOR['fillstyle'])\n\n            if isinstance(self, ROOT.TAttMarker):\n                self._markercolor = Color(ROOT.TAttMarker.GetMarkerColor(self))\n                self._markerstyle = MarkerStyle(ROOT.TAttMarker.GetMarkerStyle(self))\n                self._markersize = ROOT.TAttMarker.GetMarkerSize(self)\n            else:  # HistStack\n                self._markercolor = Color(Plottable.DEFAULT_DECOR['markercolor'])\n                self._markerstyle = MarkerStyle(Plottable.DEFAULT_DECOR['markerstyle'])\n                self._markersize = Plottable.DEFAULT_DECOR['markersize']\n\n            if obj is None:\n                # Populate defaults if we are not asrootpy-ing existing object\n                decor = dict(**Plottable.DEFAULT_DECOR)\n                decor.update(Plottable.EXTRA_ATTRS)\n                if 'color' in kwargs:\n                    decor.pop('linecolor', None)\n                    decor.pop('fillcolor', None)\n                    decor.pop('markercolor', None)\n                decor.update(kwargs)\n                self.decorate(**decor)\n\n        else:\n            # Initialize style attrs to style of the other object\n            if isinstance(obj, ROOT.TAttLine):\n                self.SetLineColor(obj.GetLineColor())\n                self.SetLineStyle(obj.GetLineStyle())\n                self.SetLineWidth(obj.GetLineWidth())\n            if isinstance(obj, ROOT.TAttFill):\n                self.SetFillColor(obj.GetFillColor())\n                self.SetFillStyle(obj.GetFillStyle())\n            if isinstance(obj, ROOT.TAttMarker):\n                self.SetMarkerColor(obj.GetMarkerColor())\n                self.SetMarkerStyle(obj.GetMarkerStyle())\n                self.SetMarkerSize(obj.GetMarkerSize())\n            if kwargs:\n                self.decorate(**kwargs)", "response": "This method is called by Plottable. _clone_post_init when the object is created."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecorating this object with the options specified in kwargs.", "response": "def decorate(self, other=None, **kwargs):\n        \"\"\"\n        Apply style options to a Plottable object.\n\n        Returns a reference to self.\n        \"\"\"\n        if 'color' in kwargs:\n            incompatible = []\n            for othercolor in ('linecolor', 'fillcolor', 'markercolor'):\n                if othercolor in kwargs:\n                    incompatible.append(othercolor)\n            if incompatible:\n                raise ValueError(\n                    \"Setting both the `color` and the `{0}` attribute{1} \"\n                    \"is ambiguous. Please set only one.\".format(\n                        ', '.join(incompatible),\n                        's' if len(incompatible) != 1 else ''))\n        if other is not None:\n            decor = other.decorators\n            if 'color' in kwargs:\n                decor.pop('linecolor', None)\n                decor.pop('fillcolor', None)\n                decor.pop('markercolor', None)\n            decor.update(kwargs)\n            kwargs = decor\n        for key, value in kwargs.items():\n            if key in Plottable.EXTRA_ATTRS_DEPRECATED:\n                newkey = Plottable.EXTRA_ATTRS_DEPRECATED[key]\n                warnings.warn(\n                    \"`{0}` is deprecated and will be removed in \"\n                    \"future versions. Use `{1}` instead\".format(\n                        key, newkey),\n                    DeprecationWarning)\n                key = newkey\n            if key in Plottable.EXTRA_ATTRS:\n                setattr(self, key, value)\n            elif key == 'markerstyle':\n                self.SetMarkerStyle(value)\n            elif key == 'markercolor':\n                self.SetMarkerColor(value)\n            elif key == 'markersize':\n                self.SetMarkerSize(value)\n            elif key == 'fillcolor':\n                self.SetFillColor(value)\n            elif key == 'fillstyle':\n                self.SetFillStyle(value)\n            elif key == 'linecolor':\n                self.SetLineColor(value)\n            elif key == 'linestyle':\n                self.SetLineStyle(value)\n            elif key == 'linewidth':\n                self.SetLineWidth(value)\n            elif key == 'color':\n                self.SetColor(value)\n            else:\n                raise AttributeError(\n                    \"unknown decoration attribute: `{0}`\".format(key))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the color of the line.", "response": "def SetLineColor(self, color):\n        \"\"\"\n        *color* may be any color understood by ROOT or matplotlib.\n\n        For full documentation of accepted *color* arguments, see\n        :class:`rootpy.plotting.style.Color`.\n        \"\"\"\n        self._linecolor = Color(color)\n        if isinstance(self, ROOT.TAttLine):\n            ROOT.TAttLine.SetLineColor(self, self._linecolor('root'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SetLineStyle(self, style):\n        self._linestyle = LineStyle(style)\n        if isinstance(self, ROOT.TAttLine):\n            ROOT.TAttLine.SetLineStyle(self, self._linestyle('root'))", "response": "Sets the line style for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef SetFillColor(self, color):\n        self._fillcolor = Color(color)\n        if isinstance(self, ROOT.TAttFill):\n            ROOT.TAttFill.SetFillColor(self, self._fillcolor('root'))", "response": "Sets the fill color of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetFillStyle(self, style):\n        self._fillstyle = FillStyle(style)\n        if isinstance(self, ROOT.TAttFill):\n            ROOT.TAttFill.SetFillStyle(self, self._fillstyle('root'))", "response": "Sets the fill style for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the color of the marker.", "response": "def SetMarkerColor(self, color):\n        \"\"\"\n        *color* may be any color understood by ROOT or matplotlib.\n\n        For full documentation of accepted *color* arguments, see\n        :class:`rootpy.plotting.style.Color`.\n        \"\"\"\n        self._markercolor = Color(color)\n        if isinstance(self, ROOT.TAttMarker):\n            ROOT.TAttMarker.SetMarkerColor(self, self._markercolor('root'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the marker style for this object.", "response": "def SetMarkerStyle(self, style):\n        \"\"\"\n        *style* may be any marker style understood by ROOT or matplotlib.\n\n        For full documentation of accepted *style* arguments, see\n        :class:`rootpy.plotting.style.MarkerStyle`.\n        \"\"\"\n        self._markerstyle = MarkerStyle(style)\n        if isinstance(self, ROOT.TAttMarker):\n            ROOT.TAttMarker.SetMarkerStyle(self, self._markerstyle('root'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef SetColor(self, color):\n        self.SetFillColor(color)\n        self.SetLineColor(color)\n        self.SetMarkerColor(color)", "response": "Set color attributes of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw the ROOT object.", "response": "def Draw(self, *args, **kwargs):\n        \"\"\"\n        Parameters\n        ----------\n        args : positional arguments\n            Positional arguments are passed directly to ROOT's Draw\n        kwargs : keyword arguments\n            If keyword arguments are present, then a clone is drawn instead\n            with DrawCopy, where the name, title, and style attributes are\n            taken from ``kwargs``.\n\n        Returns\n        -------\n        If ``kwargs`` is not empty and a clone is drawn, then the clone is\n        returned, otherwise None is returned.\n        \"\"\"\n        if kwargs:\n            return self.DrawCopy(*args, **kwargs)\n\n        pad = ROOT.gPad\n        own_pad = False\n        if not pad:\n            # avoid circular import by delaying import until needed here\n            from .canvas import Canvas\n            pad = Canvas()\n            own_pad = True\n        if self.visible:\n            if self.drawstyle:\n                self.__class__.__bases__[-1].Draw(self,\n                    \" \".join((self.drawstyle, ) + args))\n            else:\n                self.__class__.__bases__[-1].Draw(self, \" \".join(args))\n            pad.Modified()\n            pad.Update()\n        if own_pad:\n            keepalive(self, pad)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DrawCopy(self, *args, **kwargs):\n        copy = self.Clone(**kwargs)\n        copy.Draw(*args)\n        return copy", "response": "Returns a copy of the current object with the same attributes and attributes taken from ROOT s Draw."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getitem(self, index):\n        if index >= getattr(self.tree, self.size):\n            raise IndexError(index)\n        if self.__cache_objects and index in self.__cache:\n            return self.__cache[index]\n        obj = self.tree_object_cls(self.tree, self.name, self.prefix, index)\n        if self.__cache_objects:\n            self.__cache[index] = obj\n        return obj", "response": "getitem returns the item at the given index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rp_module_level_in_stack():\n    from traceback import extract_stack\n    from rootpy import _ROOTPY_SOURCE_PATH\n    modlevel_files = [filename for filename, _, func, _ in extract_stack()\n                      if func == \"<module>\"]\n\n    return any(path.startswith(_ROOTPY_SOURCE_PATH) for path in modlevel_files)", "response": "Returns true if we re during a rootpy import"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmonitoring for correct deletion of weakref - able objects.", "response": "def monitor_deletion():\n    \"\"\"\n    Function for checking for correct deletion of weakref-able objects.\n\n    Example usage::\n\n        monitor, is_alive = monitor_deletion()\n        obj = set()\n        monitor(obj, \"obj\")\n        assert is_alive(\"obj\") # True because there is a ref to `obj` is_alive\n        del obj\n        assert not is_alive(\"obj\") # True because there `obj` is deleted\n\n    \"\"\"\n    monitors = {}\n\n    def set_deleted(x):\n        def _(weakref):\n            del monitors[x]\n        return _\n\n    def monitor(item, name):\n        monitors[name] = ref(item, set_deleted(name))\n\n    def is_alive(name):\n        return monitors.get(name, None) is not None\n\n    return monitor, is_alive"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing a list of histograms and stacks and or graphs on a base object.", "response": "def draw(plottables, pad=None, same=False,\n         xaxis=None, yaxis=None,\n         xtitle=None, ytitle=None,\n         xlimits=None, ylimits=None,\n         xdivisions=None, ydivisions=None,\n         logx=False, logy=False,\n         **kwargs):\n    \"\"\"\n    Draw a list of histograms, stacks, and/or graphs.\n\n    Parameters\n    ----------\n    plottables : Hist, Graph, HistStack, or list of such objects\n        List of objects to draw.\n\n    pad : Pad or Canvas, optional (default=None)\n        The pad to draw onto. If None then use the current global pad.\n\n    same : bool, optional (default=False)\n        If True then use 'SAME' draw option for all objects instead of\n        all but the first. Use this option if you are drawing onto a pad\n        that already holds drawn objects.\n\n    xaxis : TAxis, optional (default=None)\n        Use this x-axis or use the x-axis of the first plottable if None.\n\n    yaxis : TAxis, optional (default=None)\n        Use this y-axis or use the y-axis of the first plottable if None.\n\n    xtitle : str, optional (default=None)\n        Set the x-axis title.\n\n    ytitle : str, optional (default=None)\n        Set the y-axis title.\n\n    xlimits : tuple, optional (default=None)\n        Set the x-axis limits with a 2-tuple of (min, max)\n\n    ylimits : tuple, optional (default=None)\n        Set the y-axis limits with a 2-tuple of (min, max)\n\n    xdivisions : int, optional (default=None)\n        Set the number of divisions for the x-axis\n\n    ydivisions : int, optional (default=None)\n        Set the number of divisions for the y-axis\n\n    logx : bool, optional (default=False)\n        If True, then set the x-axis to log scale.\n\n    logy : bool, optional (default=False)\n        If True, then set the y-axis to log scale.\n\n    kwargs : dict\n        All extra arguments are passed to get_limits when determining the axis\n        limits.\n\n    Returns\n    -------\n    (xaxis, yaxis), (xmin, xmax, ymin, ymax) : tuple\n        The axes and axes bounds.\n\n    See Also\n    --------\n    get_limits\n\n    \"\"\"\n    context = preserve_current_canvas if pad else do_nothing\n    if not isinstance(plottables, (tuple, list)):\n        plottables = [plottables]\n    elif not plottables:\n        raise ValueError(\"plottables is empty\")\n    with context():\n        if pad is not None:\n            pad.cd()\n        # get the axes limits\n        xmin, xmax, ymin, ymax = get_limits(plottables,\n                                            logx=logx, logy=logy,\n                                            **kwargs)\n        if xlimits is not None:\n            xmin, xmax = xlimits\n        if ylimits is not None:\n            ymin, ymax = ylimits\n        if not same:\n            obj = plottables.pop(0)\n            if isinstance(obj, ROOT.THStack):\n                obj.SetMinimum(ymin)\n                obj.SetMaximum(ymax)\n            obj.Draw()\n            xaxis = obj.xaxis\n            yaxis = obj.yaxis\n        # draw the plottables\n        for i, obj in enumerate(plottables):\n            if i == 0 and isinstance(obj, ROOT.THStack):\n                # use SetMin/Max for y-axis\n                obj.SetMinimum(ymin)\n                obj.SetMaximum(ymax)\n                # ROOT: please fix this...\n            obj.Draw('SAME')\n        # set the axes limits and titles\n        if xaxis is not None:\n            xaxis.SetLimits(xmin, xmax)\n            xaxis.SetRangeUser(xmin, xmax)\n            if xtitle is not None:\n                xaxis.SetTitle(xtitle)\n            if xdivisions is not None:\n                xaxis.SetNdivisions(xdivisions)\n        if yaxis is not None:\n            yaxis.SetLimits(ymin, ymax)\n            yaxis.SetRangeUser(ymin, ymax)\n            if ytitle is not None:\n                yaxis.SetTitle(ytitle)\n            if ydivisions is not None:\n                yaxis.SetNdivisions(ydivisions)\n        if pad is None:\n            pad = ROOT.gPad\n        pad.SetLogx(bool(logx))\n        pad.SetLogy(bool(logy))\n        # redraw axes on top\n        # axes ticks sometimes get hidden by filled histograms\n        pad.RedrawAxis()\n    return (xaxis, yaxis), (xmin, xmax, ymin, ymax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives x1, x2, a, b, where: x1 - x0 x3 - x2 a = ------- , b = ------- x3 - x0 x3 - x0 determine the points x0 and x3: x0 x1 x2 x3 |----------|-----------------|--------|", "response": "def _limits_helper(x1, x2, a, b, snap=False):\n    \"\"\"\n    Given x1, x2, a, b, where:\n\n        x1 - x0         x3 - x2\n    a = ------- ,   b = -------\n        x3 - x0         x3 - x0\n\n    determine the points x0 and x3:\n\n    x0         x1                x2       x3\n    |----------|-----------------|--------|\n\n    \"\"\"\n    if x2 < x1:\n        raise ValueError(\"x2 < x1\")\n    if a + b >= 1:\n        raise ValueError(\"a + b >= 1\")\n    if a < 0:\n        raise ValueError(\"a < 0\")\n    if b < 0:\n        raise ValueError(\"b < 0\")\n    if snap:\n        if x1 >= 0:\n            x1 = 0\n            a = 0\n        elif x2 <= 0:\n            x2 = 0\n            b = 0\n        if x1 == x2 == 0:\n            # garbage in garbage out\n            return 0., 1.\n    elif x1 == x2:\n        # garbage in garbage out\n        return x1 - 1., x1 + 1.\n    if a == 0 and b == 0:\n        return x1, x2\n    elif a == 0:\n        return x1, (x2 - b * x1) / (1 - b)\n    elif b == 0:\n        return (x1 - a * x2) / (1 - a), x2\n    x0 = ((b / a) * x1 + x2 - (x2 - x1) / (1 - a - b)) / (1 + b / a)\n    x3 = (x2 - x1) / (1 - a - b) + x0\n    return x0, x3"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_limits(plottables,\n               xpadding=0,\n               ypadding=0.1,\n               xerror_in_padding=True,\n               yerror_in_padding=True,\n               snap=True,\n               logx=False,\n               logy=False,\n               logx_crop_value=1E-5,\n               logy_crop_value=1E-5,\n               logx_base=10,\n               logy_base=10):\n    \"\"\"\n    Get the axes limits that should be used for a 1D histogram, graph, or stack\n    of histograms.\n\n    Parameters\n    ----------\n\n    plottables : Hist, Graph, HistStack, or list of such objects\n        The object(s) for which visually pleasing plot boundaries are\n        requested.\n\n    xpadding : float or 2-tuple, optional (default=0)\n        The horizontal padding as a fraction of the final plot width.\n\n    ypadding : float or 2-tuple, optional (default=0.1)\n        The vertical padding as a fraction of the final plot height.\n\n    xerror_in_padding : bool, optional (default=True)\n        If False then exclude the x error bars from the calculation of the plot\n        width.\n\n    yerror_in_padding : bool, optional (default=True)\n        If False then exclude the y error bars from the calculation of the plot\n        height.\n\n    snap : bool, optional (default=True)\n        Make the minimum or maximum of the vertical range the x-axis depending\n        on if the plot maximum and minimum are above or below the x-axis. If\n        the plot maximum is above the x-axis while the minimum is below the\n        x-axis, then this option will have no effect.\n\n    logx : bool, optional (default=False)\n        If True, then the x-axis is log scale.\n\n    logy : bool, optional (default=False)\n        If True, then the y-axis is log scale.\n\n    logx_crop_value : float, optional (default=1E-5)\n        If an x-axis is using a logarithmic scale then crop all non-positive\n        values with this value.\n\n    logy_crop_value : float, optional (default=1E-5)\n        If the y-axis is using a logarithmic scale then crop all non-positive\n        values with this value.\n\n    logx_base : float, optional (default=10)\n        The base used for the logarithmic scale of the x-axis.\n\n    logy_base : float, optional (default=10)\n        The base used for the logarithmic scale of the y-axis.\n\n    Returns\n    -------\n\n    xmin, xmax, ymin, ymax : tuple of plot boundaries\n        The computed x and y-axis ranges.\n\n    \"\"\"\n    try:\n        import numpy as np\n        use_numpy = True\n    except ImportError:\n        use_numpy = False\n\n    if not isinstance(plottables, (list, tuple)):\n        plottables = [plottables]\n\n    xmin = float('+inf')\n    xmax = float('-inf')\n    ymin = float('+inf')\n    ymax = float('-inf')\n\n    for h in plottables:\n\n        if isinstance(h, HistStack):\n            h = h.sum\n\n        if not isinstance(h, (_Hist, _Graph1DBase)):\n            raise TypeError(\n                \"unable to determine plot axes ranges \"\n                \"from object of type `{0}`\".format(\n                    type(h)))\n\n        if use_numpy:\n            y_array_min = y_array_max = np.array(list(h.y()))\n            if yerror_in_padding:\n                y_array_min = y_array_min - np.array(list(h.yerrl()))\n                y_array_max = y_array_max + np.array(list(h.yerrh()))\n            _ymin = y_array_min.min()\n            _ymax = y_array_max.max()\n        else:\n            y_array_min = y_array_max = list(h.y())\n            if yerror_in_padding:\n                y_array_min = multisub(y_array_min, list(h.yerrl()))\n                y_array_max = multiadd(y_array_max, list(h.yerrh()))\n            _ymin = min(y_array_min)\n            _ymax = max(y_array_max)\n\n        if isinstance(h, _Graph1DBase):\n            if use_numpy:\n                x_array_min = x_array_max = np.array(list(h.x()))\n                if xerror_in_padding:\n                    x_array_min = x_array_min - np.array(list(h.xerrl()))\n                    x_array_max = x_array_max + np.array(list(h.xerrh()))\n                _xmin = x_array_min.min()\n                _xmax = x_array_max.max()\n            else:\n                x_array_min = x_array_max = list(h.x())\n                if xerror_in_padding:\n                    x_array_min = multisub(x_array_min, list(h.xerrl()))\n                    x_array_max = multiadd(x_array_max, list(h.xerrh()))\n                _xmin = min(x_array_min)\n                _xmax = max(x_array_max)\n        else:\n            _xmin = h.xedgesl(1)\n            _xmax = h.xedgesh(h.nbins(0))\n\n        if logy:\n            _ymin = max(logy_crop_value, _ymin)\n            _ymax = max(logy_crop_value, _ymax)\n        if logx:\n            _xmin = max(logx_crop_value, _xmin)\n            _xmax = max(logx_crop_value, _xmax)\n\n        if _xmin < xmin:\n            xmin = _xmin\n        if _xmax > xmax:\n            xmax = _xmax\n        if _ymin < ymin:\n            ymin = _ymin\n        if _ymax > ymax:\n            ymax = _ymax\n\n    if isinstance(xpadding, (list, tuple)):\n        if len(xpadding) != 2:\n            raise ValueError(\"xpadding must be of length 2\")\n        xpadding_left = xpadding[0]\n        xpadding_right = xpadding[1]\n    else:\n        xpadding_left = xpadding_right = xpadding\n\n    if isinstance(ypadding, (list, tuple)):\n        if len(ypadding) != 2:\n            raise ValueError(\"ypadding must be of length 2\")\n        ypadding_top = ypadding[0]\n        ypadding_bottom = ypadding[1]\n    else:\n        ypadding_top = ypadding_bottom = ypadding\n\n    if logx:\n        x0, x3 = _limits_helper(\n            log(xmin, logx_base), log(xmax, logx_base),\n            xpadding_left, xpadding_right)\n        xmin = logx_base ** x0\n        xmax = logx_base ** x3\n    else:\n        xmin, xmax = _limits_helper(\n            xmin, xmax, xpadding_left, xpadding_right)\n\n    if logy:\n        y0, y3 = _limits_helper(\n            log(ymin, logy_base), log(ymax, logy_base),\n            ypadding_bottom, ypadding_top, snap=False)\n        ymin = logy_base ** y0\n        ymax = logy_base ** y3\n    else:\n        ymin, ymax = _limits_helper(\n            ymin, ymax, ypadding_bottom, ypadding_top, snap=snap)\n\n    return xmin, xmax, ymin, ymax", "response": "Returns the limits for a 1D histogram graph or stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_band(low_hist, high_hist, middle_hist=None):\n    npoints = low_hist.nbins(0)\n    band = Graph(npoints)\n    for i in range(npoints):\n        center = low_hist.x(i + 1)\n        width = low_hist.xwidth(i + 1)\n        low, high = low_hist.y(i + 1), high_hist.y(i + 1)\n        if middle_hist is not None:\n            middle = middle_hist.y(i + 1)\n        else:\n            middle = (low + high) / 2.\n        yerrh = max(high - middle, low - middle, 0)\n        yerrl = abs(min(high - middle, low - middle, 0))\n        band.SetPoint(i, center, middle)\n        band.SetPointError(i, width / 2., width / 2.,\n                           yerrl, yerrh)\n    return band", "response": "Convert the low and high histograms into a TGraphAsymmErrors centered at\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef canvases_with(drawable):\n    return [c for c in ROOT.gROOT.GetListOfCanvases()\n            if drawable in find_all_primitives(c)]", "response": "Return a list of all canvases where drawable has been painted."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the tick lengths in pixels", "response": "def tick_length_pixels(pad, xaxis, yaxis, xlength, ylength=None):\n    \"\"\"\n    Set the axes tick lengths in pixels\n    \"\"\"\n    if ylength is None:\n        ylength = xlength\n    xaxis.SetTickLength(xlength / float(pad.height_pixels))\n    yaxis.SetTickLength(ylength / float(pad.width_pixels))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(origin, target, type):\n    _origin = origin.upper()\n    if _origin == 'ROOTCODE':\n        _origin = root_type_codes\n    elif _origin == 'ROOTNAME':\n        _origin = root_type_names\n    elif _origin == 'ARRAY':\n        _origin = python_codes\n    elif _origin == 'NUMPY':\n        _origin = numpy_codes\n    else:\n        raise ValueError(\"{0} is not a valid type\".format(origin))\n\n    _target = target.upper()\n    if _target == 'ROOTCODE':\n        _target = root_type_codes\n    elif _target == 'ROOTNAME':\n        _target = root_type_names\n    elif _target == 'ARRAY':\n        _target = python_codes\n    elif _target == 'NUMPY':\n        _target = numpy_codes\n    else:\n        raise ValueError(\"{0} is not a valid type\".format(target))\n\n    if type not in _origin:\n        raise ValueError(\"{0} is not a valid {1} type\".format(type, origin))\n\n    return _target[_origin.index(type)]", "response": "convert type from origin to target\n    origin and target must be ROOTCODE ROOTNAME ARRAY or NUMPY"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the value to the default", "response": "def reset(self):\n        \"\"\"Reset the value to the default\"\"\"\n        if self.resetable:\n            for i in range(len(self)):\n                self[i] = self.default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef LHCb_label(side=\"L\", status=\"final\", text=\"\", pad=None):\n\n    if pad is None:\n        pad = ROOT.gPad\n\n    with preserve_current_canvas():\n        pad.cd()\n        if side == \"L\":\n            l = ROOT.TPaveText(pad.GetLeftMargin() + 0.05,\n                               0.87 - pad.GetTopMargin(),\n                               pad.GetLeftMargin() + 0.30,\n                               0.95 - pad.GetTopMargin(),\n                               \"BRNDC\")\n        elif side == \"R\":\n            l = ROOT.TPaveText(0.70 - pad.GetRightMargin(),\n                               0.75 - pad.GetTopMargin(),\n                               0.95 - pad.GetRightMargin(),\n                               0.85 - pad.GetTopMargin(),\n                               \"BRNDC\")\n        else:\n            raise TypeError(\"Unknown side '{0}'\".format(side))\n\n        if status == \"final\":\n            l.AddText(\"LHCb\")\n        elif status == \"preliminary\":\n            l.AddText(\"#splitline{LHCb}{#scale[1.0]{Preliminary}}\")\n        elif status == \"unofficial\":\n            l.AddText(\"#splitline{LHCb}{#scale[1.0]{Unofficial}}\")\n        elif status == \"custom\":\n            l.AddText(text)\n        else:\n            raise TypeError(\"Unknown status '{0}'\".format(status))\n\n        l.SetFillColor(0)\n        l.SetTextAlign(12)\n        l.SetBorderSize(0)\n        l.Draw()\n\n        keepalive(pad, l)\n\n        pad.Modified()\n        pad.Update()\n\n    return l, None", "response": "Add an LHCb label to the current pad."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef minimize(func,\n             minimizer_type=None,\n             minimizer_algo=None,\n             strategy=None,\n             retry=0,\n             scan=False,\n             print_level=None):\n    \"\"\"\n    Minimize a RooAbsReal function\n\n    Parameters\n    ----------\n\n    func : RooAbsReal\n        The function to minimize\n\n    minimizer_type : string, optional (default=None)\n        The minimizer type: \"Minuit\" or \"Minuit2\".\n        If None (the default) then use the current global default value.\n\n    minimizer_algo : string, optional (default=None)\n        The minimizer algorithm: \"Migrad\", etc.\n        If None (the default) then use the current global default value.\n\n    strategy : int, optional (default=None)\n        Set the MINUIT strategy. Accepted values\n        are 0, 1, and 2 and represent MINUIT strategies for dealing\n        most efficiently with fast FCNs (0), expensive FCNs (2)\n        and 'intermediate' FCNs (1). If None (the default) then use\n        the current global default value.\n\n    retry : int, optional (default=0)\n        Number of times to retry failed minimizations. The strategy is\n        incremented to a maximum of 2 from its initial value and remains at 2\n        for additional retries.\n\n    scan : bool, optional (default=False)\n        If True then run Minuit2's scan algorithm before running the main\n        ``minimizer_algo`` (\"Migrad\").\n\n    print_level : int, optional (default=None)\n        The verbosity level for the minimizer algorithm.\n        If None (the default) then use the global default print level.\n        If negative then all non-fatal messages will be suppressed.\n\n    Returns\n    -------\n\n    minimizer : RooMinimizer\n        The minimizer. Get the RooFitResult with ``minimizer.save()``.\n\n    \"\"\"\n    llog = log['minimize']\n\n    min_opts = ROOT.Math.MinimizerOptions\n    if minimizer_type is None:\n        minimizer_type = min_opts.DefaultMinimizerType()\n    if minimizer_algo is None:\n        minimizer_algo = min_opts.DefaultMinimizerAlgo()\n    if strategy is None:\n        strategy = min_opts.DefaultStrategy()\n    if print_level is None:\n        print_level = min_opts.DefaultPrintLevel()\n\n    if print_level < 0:\n        msg_service = ROOT.RooMsgService.instance()\n        msg_level = msg_service.globalKillBelow()\n        msg_service.setGlobalKillBelow(ROOT.RooFit.FATAL)\n\n    minim = Minimizer(func)\n    minim.setPrintLevel(print_level)\n    minim.setStrategy(strategy)\n\n    if scan:\n        llog.info(\"running scan algorithm ...\")\n        minim.minimize('Minuit2', 'Scan')\n\n    llog.info(\"minimizing with {0} {1} using strategy {2}\".format(\n        minimizer_type, minimizer_algo, strategy))\n    status = minim.minimize(minimizer_type, minimizer_algo)\n\n    iretry = 0\n    while iretry < retry and status not in (0, 1):\n        if strategy < 2:\n            strategy += 1\n            minim.setStrategy(strategy)\n        llog.warning(\"minimization failed with status {0:d}\".format(status))\n        llog.info(\"retrying minimization with strategy {0:d}\".format(strategy))\n        status = minim.minimize(minimizer_type, minimizer_algo)\n\n    if status in (0, 1):\n        llog.info(\"found minimum\")\n    else:\n        llog.warning(\"minimization failed with status {0:d}\".format(status))\n\n    if print_level < 0:\n        msg_service.setGlobalKillBelow(msg_level)\n\n    return minim", "response": "Minimize a function in a tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_code(self, from_function=False):\n\n        num_fastnames = sum(1 for op, arg in self.code if isopcode(op) and op in haslocal)\n        is_function = self.newlocals or num_fastnames > 0 or len(self.args) > 0\n        nested = is_function and from_function\n\n        co_flags = {op[0] for op in self.code}\n\n        is_generator = self.force_generator or (YIELD_VALUE in co_flags or YIELD_FROM in co_flags)\n        no_free = (not self.freevars) and (not co_flags & hasfree)\n\n        if version_info >= (3, 5):\n            is_native_coroutine = bool(self.force_coroutine or (co_flags & coroutine_opcodes))\n            assert not (is_native_coroutine and self.force_iterable_coroutine)\n\n        co_flags =\\\n            (not(STORE_NAME in co_flags or LOAD_NAME in co_flags or DELETE_NAME in co_flags)) |\\\n            (self.newlocals and CO_NEWLOCALS) |\\\n            (self.varargs and CO_VARARGS) |\\\n            (self.varkwargs and CO_VARKEYWORDS) |\\\n            (is_generator and CO_GENERATOR) |\\\n            (no_free and CO_NOFREE) |\\\n            (nested and CO_NESTED)\n\n        if version_info >= (3, 5):\n            co_flags |= (is_native_coroutine and CO_COROUTINE) |\\\n                        (self.force_iterable_coroutine and CO_ITERABLE_COROUTINE) |\\\n                        (self.future_generator_stop and CO_FUTURE_GENERATOR_STOP)\n\n        co_consts = [self.docstring]\n        co_names = []\n        co_varnames = list(self.args)\n        co_freevars = tuple(self.freevars)\n\n        # Find all cellvars beforehand for two reasons\n        # Need the number of them to construct the numeric arg for ops in hasfree\n        # Need to put args which are cells in the beginning of co_cellvars\n        cellvars = {arg for op, arg in self.code\n                    if isopcode(op) and op in hasfree\n                    and arg not in co_freevars}\n        co_cellvars = [jumps for jumps in self.args if jumps in cellvars]\n\n        def index(seq, item, eq=True, can_append=True):\n            for i, x in enumerate(seq):\n                if x == item if eq else x is item:\n                    return i\n            if can_append:\n                seq.append(item)\n                return len(seq) - 1\n            else:\n                raise IndexError(\"Item not found\")\n\n        jumps = []\n        label_pos = {}\n        lastlineno = self.firstlineno\n        lastlinepos = 0\n        co_code = bytearray()\n        co_lnotab = bytearray()\n\n        for i, (op, arg) in enumerate(self.code):\n            if isinstance(op, Label):\n                label_pos[op] = len(co_code)\n            elif op is SetLineno:\n                incr_lineno = arg - lastlineno\n                incr_pos = len(co_code) - lastlinepos\n                lastlineno = arg\n                lastlinepos += incr_pos\n                if incr_lineno != 0 or incr_pos != 0:\n                    while incr_pos > 255:\n                        co_lnotab += b\"\\xFF\\0\"\n                        incr_pos -= 255\n                    while incr_lineno > 255:\n                        co_lnotab += (0xFF00|incr_pos).to_bytes(2, \"little\")\n                        incr_pos = 0\n                        incr_lineno -= 255\n                    if incr_pos or incr_lineno:\n                        co_lnotab += bytes((incr_pos, incr_lineno))\n            elif op == opcode.EXTENDED_ARG:\n                self.code[i + 1][1] |= 1 << 32\n            elif op not in hasarg:\n                co_code.append(op)\n            else:\n                if op in hasconst:\n                    if isinstance(arg, Code) and\\\n                            i + 2 < len(self.code) and self.code[i + 2][0] in hascode:\n                        arg = arg.to_code(from_function=is_function)\n                        assert arg is not None\n                    arg = index(co_consts, arg, 0)\n                elif op in hasname:\n                    arg = index(co_names, arg)\n                elif op in hasjump:\n                    jumps.append((len(co_code), arg))\n                    co_code += op.to_bytes(3, \"little\")\n                    continue\n                elif op in haslocal:\n                    arg = index(co_varnames, arg)\n                elif op in hascompare:\n                    arg = index(cmp_op, arg, can_append=False)\n                elif op in hasfree:\n                    try:\n                        arg = index(co_freevars, arg, can_append=False) + len(cellvars)\n                    except IndexError:\n                        arg = index(co_cellvars, arg)\n                if arg > 0xFFFF:\n                    co_code += (opcode.EXTENDED_ARG | ((arg & 0xFFFF0000) >> 8)).to_bytes(3, \"little\")\n                co_code += (op | (arg << 8)).to_bytes(3, \"little\")\n\n        for pos, label in jumps:\n            jump = label_pos[label]\n            if co_code[pos] in hasjrel:\n                jump -= pos + 3\n            if jump > 0xFFFF:\n                raise NotImplementedError(\"Extended jumps not implemented\")\n            co_code[pos + 1] = jump & 0xFF\n            co_code[pos + 2] = jump >> 8\n\n        co_argcount = len(self.args) - self.varargs - self.varkwargs - self.kwonly\n        co_stacksize = self._compute_stacksize()\n\n        return CodeType(co_argcount, self.kwonly, len(co_varnames), co_stacksize, co_flags,\n                        bytes(co_code), tuple(co_consts), tuple(co_names), tuple(co_varnames),\n                        self.filename, self.name, self.firstlineno, bytes(co_lnotab), co_freevars,\n                        tuple(co_cellvars))", "response": "Assemble a Python code object from a Code object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_string(obj):\n    if inspect.isclass(obj):\n        if issubclass(obj, Object):\n            return obj._ROOT.__name__\n        if issubclass(obj, string_types):\n            return 'string'\n        return obj.__name__\n    if not isinstance(obj, string_types):\n        raise TypeError(\"expected string or class\")\n    return obj", "response": "Make a string from a class or a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile and load the reflection dictionary for a type.", "response": "def generate(declaration, headers=None, has_iterators=False):\n    \"\"\"Compile and load the reflection dictionary for a type.\n\n    If the requested dictionary has already been cached, then load that instead.\n\n    Parameters\n    ----------\n    declaration : str\n        A type declaration (for example \"vector<int>\")\n    headers : str or list of str\n        A header file or list of header files required to compile the dictionary\n        for this type.\n    has_iterators : bool\n        If True, then include iterators in the dictionary generation.\n    \"\"\"\n    global NEW_DICTS\n    # FIXME: _rootpy_dictionary_already_exists returns false positives\n    # if a third-party module provides \"incomplete\" dictionaries.\n    #if compiled._rootpy_dictionary_already_exists(declaration):\n    #    log.debug(\"generate({0}) => already available\".format(declaration))\n    #    return\n    log.debug(\"requesting dictionary for {0}\".format(declaration))\n    if headers:\n        if isinstance(headers, string_types):\n            headers = sorted(headers.split(';'))\n        log.debug(\"using the headers {0}\".format(', '.join(headers)))\n        unique_name = ';'.join([declaration] + headers)\n    else:\n        unique_name = declaration\n    unique_name = unique_name.replace(' ', '')\n\n    # If the library is already loaded, do nothing\n    if unique_name in LOADED_DICTS:\n        log.debug(\"dictionary for {0} is already loaded\".format(declaration))\n        return\n\n    if sys.version_info[0] < 3:\n        libname = hashlib.sha512(unique_name).hexdigest()[:16]\n    else:\n        libname = hashlib.sha512(unique_name.encode('utf-8')).hexdigest()[:16]\n    libnameso = libname + \".so\"\n\n    if ROOT.gROOT.GetVersionInt() < 53403:\n        # check for this class in the global TClass list and remove it\n        # fixes infinite recursion in ROOT < 5.34.03\n        # (exact ROOT versions where this is required is unknown)\n        cls = ROOT.gROOT.GetClass(declaration)\n        if cls and not cls.IsLoaded():\n            log.debug(\"removing {0} from gROOT.GetListOfClasses()\".format(\n                declaration))\n            ROOT.gROOT.GetListOfClasses().Remove(cls)\n\n    # If a .so already exists for this class, use it.\n    if exists(pjoin(DICTS_PATH, libnameso)):\n        log.debug(\"loading previously generated dictionary for {0}\"\n                    .format(declaration))\n        if (ROOT.gInterpreter.Load(pjoin(DICTS_PATH, libnameso))\n                not in (0, 1)):\n            raise RuntimeError(\n                \"failed to load the library for '{0}' @ {1}\".format(\n                    declaration, libname))\n        LOADED_DICTS[unique_name] = None\n        return\n\n    with lock(pjoin(DICTS_PATH, \"lock\"), poll_interval=5, max_age=60):\n        # This dict was not previously generated so we must create it now\n        log.info(\"generating dictionary for {0} ...\".format(declaration))\n        includes = ''\n        if headers is not None:\n            for header in headers:\n                if re.match('^<.+>$', header):\n                    includes += '#include {0}\\n'.format(header)\n                else:\n                    includes += '#include \"{0}\"\\n'.format(header)\n        source = LINKDEF % locals()\n        sourcepath = os.path.join(DICTS_PATH, '{0}.C'.format(libname))\n        log.debug(\"source path: {0}\".format(sourcepath))\n        with open(sourcepath, 'w') as sourcefile:\n            sourcefile.write(source)\n        log.debug(\"include path: {0}\".format(\n            ROOT.gSystem.GetIncludePath()))\n        if (ROOT.gSystem.CompileMacro(\n                sourcepath, 'k-', libname, DICTS_PATH) != 1):\n            raise RuntimeError(\n                \"failed to compile the library for '{0}'\".format(\n                    sourcepath))\n\n    LOADED_DICTS[unique_name] = None\n    NEW_DICTS = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensure_built(self, headers=None):\n        if not self.params:\n            return\n        else:\n            for child in self.params:\n                child.ensure_built(headers=headers)\n        if headers is None:\n            headers = self.guess_headers\n        generate(str(self), headers,\n                 has_iterators=self.name in HAS_ITERATORS)", "response": "Make sure that a dictionary exists for this type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nguesses the headers required for this object.", "response": "def guess_headers(self):\n        \"\"\"\n        Attempt to guess what headers may be required in order to use this\n        type. Returns `guess_headers` of all children recursively.\n\n        * If the typename is in the :const:`KNOWN_TYPES` dictionary, use the\n            header specified there\n        * If it's an STL type, include <{type}>\n        * If it exists in the ROOT namespace and begins with T,\n          include <{type}.h>\n        \"\"\"\n        name = self.name.replace(\"*\", \"\")\n        headers = []\n        if name in KNOWN_TYPES:\n            headers.append(KNOWN_TYPES[name])\n        elif name in STL:\n            headers.append('<{0}>'.format(name))\n        elif hasattr(ROOT, name) and name.startswith(\"T\"):\n            headers.append('<{0}.h>'.format(name))\n        elif '::' in name:\n            headers.append('<{0}.h>'.format(name.replace('::', '/')))\n        elif name == 'allocator':\n            headers.append('<memory>')\n        else:\n            try:\n                # is this just a basic type?\n                CPPGrammar.BASIC_TYPE.parseString(name, parseAll=True)\n            except ParseException as e:\n                # nope... I don't know what it is\n                log.warning(\n                    \"unable to guess headers required for {0}\".format(name))\n        if self.params:\n            for child in self.params:\n                headers.extend(child.guess_headers)\n        # remove duplicates\n        return list(set(headers))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the class definition for this type", "response": "def cls(self):\n        \"\"\"\n        Return the class definition for this type\n        \"\"\"\n        # TODO: register the resulting type?\n        return SmartTemplate(self.name)(\", \".join(map(str, self.params)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_string(cls, string):\n        cls.TYPE.setParseAction(cls.make)\n        try:\n            return cls.TYPE.parseString(string, parseAll=True)[0]\n        except ParseException:\n            log.error(\"Failed to parse '{0}'\".format(string))\n            raise", "response": "Parse a string into a CPPType instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert this matrix into a numpy matrix.", "response": "def to_numpy(self):\n        \"\"\"\n        Convert this matrix into a\n        `numpy.matrix <http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html>`_.\n        \"\"\"\n        import numpy as np\n        cols, rows = self.GetNcols(), self.GetNrows()\n        return np.matrix([[self(i, j)\n            for j in range(cols)]\n            for i in range(rows)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a ctypes CFUNCTYPE instance into a value which can be passed into PyROOT", "response": "def callback(cfunc):\n    \"\"\"\n    Turn a ctypes CFUNCTYPE instance into a value which can be passed into PyROOT\n    \"\"\"\n    # Note:\n    # ROOT wants a c_voidp whose addressof() == the call site of the target\n    # function. This hackery is necessary to achieve that.\n    return C.c_voidp.from_address(C.cast(cfunc, C.c_voidp).value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef objectproxy_realaddress(obj):\n    voidp = QROOT.TPython.ObjectProxy_AsVoidPtr(obj)\n    return C.addressof(C.c_char.from_buffer(voidp))", "response": "Obtain a real address as an integer from an objectproxy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all the elements which have an option associated with them.", "response": "def as_list_with_options(self):\n        \"\"\"\n        Similar to list(self) except elements which have an option associated\n        with them are returned as a ``TListItemWithOption``\n        \"\"\"\n        it = ROOT.TIter(self)\n        elem = it.Next()\n        result = []\n        while elem:\n            if it.GetOption():\n                result.append(TListItemWithOption(elem, it.GetOption()))\n            else:\n                result.append(elem)\n            elem = it.Next()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Add(self, value, *optional):\n        if isinstance(value, TListItemWithOption):\n            if optional:\n                raise RuntimeError(\n                    \"option specified along with \"\n                    \"TListItemWithOption. Specify one or the \"\n                    \"other but not both.\")\n            return super(List, self).Add(value.item, value.option)\n        return super(List, self).Add(value, *optional)", "response": "Overload ROOT s basic add method to support supplying\n TListItemWithOption and TListItem with optional option."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_style(style, mpl=False, **kwargs):\n    if mpl:\n        import matplotlib as mpl\n\n        style_dictionary = {}\n        if isinstance(style, string_types):\n            style_dictionary = get_style(style, mpl=True, **kwargs)\n            log.info(\"using matplotlib style '{0}'\".format(style))\n        elif isinstance(style, dict):\n            style_dictionary = style\n            log.info(\"using user-defined matplotlib style\")\n        else:\n            raise TypeError(\"style must be a matplotlib style name or dict\")\n        for k, v in style_dictionary.items():\n            mpl.rcParams[k] = v\n    else:\n        if isinstance(style, string_types):\n            style = get_style(style, **kwargs)\n        log.info(\"using ROOT style '{0}'\".format(style.GetName()))\n        style.cd()", "response": "set the style of the current ROOT tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a ROOT file via ROOT s static ROOT. TFile. Open function and return a File object.", "response": "def root_open(filename, mode=''):\n    \"\"\"\n    Open a ROOT file via ROOT's static ROOT.TFile.Open [1] function and return\n    an asrootpy'd File.\n\n    Parameters\n    ----------\n\n    filename : string\n        The absolute or relative path to the ROOT file.\n\n    mode : string, optional (default='')\n        Mode indicating how the file is to be opened.  This can be either one\n        of the options supported by ROOT.TFile.Open [2], or one of `a`, `a+`,\n        `r`, `r+`, `w` or `w+`, with meanings as for the built-in `open()`\n        function [3].\n\n    Returns\n    -------\n\n    root_file : File\n        an instance of rootpy's File subclass of ROOT's TFile.\n\n    References\n    ----------\n\n    .. [1] http://root.cern.ch/root/html/TFile.html#TFile:Open\n    .. [2] http://root.cern.ch/root/html/TFile.html#TFile:TFile@2\n    .. [3] https://docs.python.org/2/library/functions.html#open\n\n    \"\"\"\n    mode_map = {'a': 'UPDATE',\n                'a+': 'UPDATE',\n                'r': 'READ',\n                'r+': 'UPDATE',\n                'w': 'RECREATE',\n                'w+': 'RECREATE'}\n\n    if mode in mode_map:\n        mode = mode_map[mode]\n\n    filename = expand_path(filename)\n    prev_dir = ROOT.gDirectory\n    root_file = ROOT.R.TFile.Open(filename, mode)\n    if not root_file:\n        raise IOError(\"could not open file: '{0}'\".format(filename))\n    root_file.__class__ = File\n    root_file._path = filename\n    root_file._parent = root_file\n    root_file._prev_dir = prev_dir\n    # give Python ownership of the TFile so we can delete it\n    ROOT.SetOwnership(root_file, True)\n    return root_file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlike ROOT s Close but reverts to the gDirectory before this file was opened.", "response": "def Close(self, *args):\n        \"\"\"\n        Like ROOT's Close but reverts to the gDirectory before this file was\n        opened.\n        \"\"\"\n        super(_DirectoryBase, self).Close(*args)\n        return self.cd_previous()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keys(self, latest=False):\n        if latest:\n            keys = {}\n            for key in self.keys():\n                name = key.GetName()\n                if name in keys:\n                    if key.GetCycle() > keys[name].GetCycle():\n                        keys[name] = key\n                else:\n                    keys[name] = key\n            return keys.values()\n        return [asrootpy(key) for key in self.GetListOfKeys()]", "response": "Return a list of the keys in this directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the requested object cast as its corresponding subclass in rootpy if one exists and rootpy = True otherwise return the unadulterated TObject.", "response": "def Get(self, path, rootpy=True, **kwargs):\n        \"\"\"\n        Return the requested object cast as its corresponding subclass in\n        rootpy if one exists and ``rootpy=True``, otherwise return the\n        unadulterated TObject.\n        \"\"\"\n        thing = super(_DirectoryBase, self).Get(path)\n        if not thing:\n            raise DoesNotExist\n\n        # Ensure that the file we took the object from is alive at least as\n        # long as the object being taken from it.\n\n        # Note, Python does *not* own `thing`, it is ROOT's responsibility to\n        # delete it in the C++ sense. (SetOwnership is False). However, ROOT\n        # will delete the object when the TFile's destructor is run.\n        # Therefore, when `thing` goes out of scope and the file referred to\n        # by `this` has no references left, the file is destructed and calls\n        # `thing`'s delete.\n\n        # (this is thanks to the fact that weak referents (used by keepalive)\n        #  are notified when they are dead).\n\n        keepalive(thing, self)\n\n        if rootpy:\n            return asrootpy(thing, **kwargs)\n        return thing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride TDirectory s GetKey and also handle accessing keys arbitrarily deep in subdirectories.", "response": "def GetKey(self, path, cycle=9999, rootpy=True, **kwargs):\n        \"\"\"\n        Override TDirectory's GetKey and also handle accessing keys nested\n        arbitrarily deep in subdirectories.\n        \"\"\"\n        key = super(_DirectoryBase, self).GetKey(path, cycle)\n        if not key:\n            raise DoesNotExist\n        if rootpy:\n            return asrootpy(key, **kwargs)\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a new directory.", "response": "def mkdir(self, path, title=\"\", recurse=False):\n        \"\"\"\n        Make a new directory. If recurse is True, create parent directories\n        as required. Return the newly created TDirectory.\n        \"\"\"\n        head, tail = os.path.split(os.path.normpath(path))\n        if tail == \"\":\n            raise ValueError(\"invalid directory name: {0}\".format(path))\n        with preserve_current_directory():\n            dest = self\n            if recurse:\n                parent_dirs = head.split(os.path.sep)\n                for parent_dir in parent_dirs:\n                    try:\n                        newdest = dest.GetDirectory(parent_dir)\n                        dest = newdest\n                    except DoesNotExist:\n                        dest = dest.mkdir(parent_dir)\n            elif head != \"\":\n                dest = dest.GetDirectory(head)\n            if tail in dest:\n                raise ValueError(\"{0} already exists\".format(path))\n            newdir = asrootpy(super(_DirectoryBase, dest).mkdir(tail, title))\n        return newdir"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rm(self, path, cycle=';*'):\n        rdir = self\n        with preserve_current_directory():\n            dirname, objname = os.path.split(os.path.normpath(path))\n            if dirname:\n                rdir = rdir.Get(dirname)\n            rdir.Delete(objname + cycle)", "response": "Delete an object at path relative to this directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copytree(self, dest_dir, src=None, newname=None,\n                 exclude=None, overwrite=False):\n        \"\"\"\n        Copy this directory or just one contained object into another\n        directory.\n\n        Parameters\n        ----------\n\n        dest_dir : string or Directory\n            The destination directory.\n\n        src : string, optional (default=None)\n            If ``src`` is None then this entire directory is copied recursively\n            otherwise if ``src`` is a string path to an object relative to this\n            directory, only that object will be copied. The copied object can\n            optionally be given a ``newname``.\n\n        newname : string, optional (default=None)\n            An optional new name for the copied object.\n\n        exclude : callable, optional (default=None)\n            ``exclude`` can optionally be a function which takes\n            ``(path, object_name)`` and if returns True excludes\n            objects from being copied if the entire directory is being copied\n            recursively.\n\n        overwrite : bool, optional (default=False)\n            If True, then overwrite existing objects with the same name.\n\n        \"\"\"\n        def copy_object(obj, dest, name=None):\n            if name is None:\n                name = obj.GetName()\n            if not overwrite and name in dest:\n                raise ValueError(\n                    \"{0} already exists in {1} and `overwrite=False`\".format(\n                        name, dest._path))\n            dest.cd()\n            if isinstance(obj, ROOT.R.TTree):\n                new_obj = obj.CloneTree(-1, \"fast\")\n                new_obj.Write(name, ROOT.R.TObject.kOverwrite)\n            else:\n                obj.Write(name, ROOT.R.TObject.kOverwrite)\n\n        with preserve_current_directory():\n            if isinstance(src, string_types):\n                src = asrootpy(self.Get(src))\n            else:\n                src = self\n            if isinstance(dest_dir, string_types):\n                try:\n                    dest_dir = asrootpy(self.GetDirectory(dest_dir))\n                except DoesNotExist:\n                    dest_dir = self.mkdir(dest_dir)\n            if isinstance(src, ROOT.R.TDirectory):\n                # Copy a directory\n                cp_name = newname if newname is not None else src.GetName()\n                # See if the directory already exists\n                if cp_name not in dest_dir:\n                    # Destination directory doesn't exist, so make a new one\n                    new_dir = dest_dir.mkdir(cp_name)\n                else:\n                    new_dir = dest_dir.get(cp_name)\n                # Copy everything in the src directory to the destination\n                for (path, dirnames, objects) in src.walk(maxdepth=0):\n                    # Copy all the objects\n                    for object_name in objects:\n                        if exclude and exclude(path, object_name):\n                            continue\n                        thing = src.Get(object_name)\n                        copy_object(thing, new_dir)\n                    for dirname in dirnames:\n                        if exclude and exclude(path, dirname):\n                            continue\n                        rdir = src.GetDirectory(dirname)\n                        # Recursively copy objects in subdirectories\n                        rdir.copytree(\n                            new_dir,\n                            exclude=exclude, overwrite=overwrite)\n            else:\n                # Copy an object\n                copy_object(src, dest_dir, name=newname)", "response": "Copy a tree or just one contained object into another directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef walk(self,\n             top=None,\n             path=None,\n             depth=0,\n             maxdepth=-1,\n             class_ref=None,\n             class_pattern=None,\n             return_classname=False,\n             treat_dirs_as_objs=False):\n        \"\"\"\n        Walk the directory structure and content in and below a directory.\n        For each directory in the directory tree rooted at ``top`` (including\n        ``top`` itself, but excluding '.' and '..'), yield a 3-tuple\n        ``dirpath, dirnames, filenames``.\n\n        Parameters\n        ----------\n\n        top : string, optional (default=None)\n            A path to a starting directory relative to this directory,\n            otherwise start at this directory.\n\n        path : string, optional (default=None)\n            A path prepended as a prefix on the ``dirpath``. This argument is\n            used internally as the recursion traverses down through\n            subdirectories.\n\n        depth : int, optional (default=0)\n            The current depth, used internally as the recursion traverses down\n            through subdirectories.\n\n        max_depth : int, optional (default=-1)\n            The maximum depth in the directory hierarchy to traverse. There is\n            no limit applied by default.\n\n        class_ref : class, optional (default=None)\n            If not None then only include objects that are instances of\n            ``class_ref``.\n\n        class_pattern : string, optional (default=None)\n            If not None then only include objects in ``filenames`` with class\n            names that match ``class_pattern``. ``class_pattern`` should be a\n            Unix shell-style wildcarded string.\n\n        return_classname : bool, optional (default=False)\n            If True, then each entry in ``filenames`` is a tuple of\n            the form ``(filename, classname)``.\n\n        treat_dirs_as_objs : bool, optional (default=False)\n            If True, ``filenames`` contains directories as well.\n\n        Returns\n        -------\n\n        dirpath, dirnames, filenames : iterator\n            An iterator over the 3-tuples ``dirpath, dirnames, filenames``.\n            ``dirpath`` is a string, the path to the directory. ``dirnames`` is\n            a list of the names of the subdirectories in ``dirpath``\n            (excluding '.' and '..'). ``filenames`` is a list of the names of\n            the non-directory files/objects in ``dirpath``.\n\n        Notes\n        -----\n\n        The names in the lists are just names, with no path components.\n        To get a full path (which begins with top) to a file or directory\n        in ``dirpath``, use ``os.path.join(dirpath, name)``.\n\n        \"\"\"\n        dirnames, objectnames = [], []\n        tdirectory = self.GetDirectory(top) if top else self\n        for key in tdirectory.keys(latest=True):\n            name = key.GetName()\n            classname = key.GetClassName()\n            is_directory = classname.startswith('TDirectory')\n            if is_directory:\n                dirnames.append(name)\n            if not is_directory or treat_dirs_as_objs:\n                if class_ref is not None:\n                    tclass = ROOT.TClass.GetClass(classname, True, True)\n                    if not tclass or not tclass.InheritsFrom(class_ref.Class()):\n                        continue\n                if class_pattern is not None:\n                    if not fnmatch(classname, class_pattern):\n                        continue\n                name = (name if not return_classname else (name, classname))\n                objectnames.append(name)\n        if path:\n            dirpath = os.path.join(path, tdirectory.GetName())\n        elif not isinstance(tdirectory, ROOT.R.TFile):\n            dirpath = tdirectory.GetName()\n        else:\n            dirpath = ''\n        yield dirpath, dirnames, objectnames\n        if depth == maxdepth:\n            return\n        for dirname in dirnames:\n            rdir = tdirectory.GetDirectory(dirname)\n            for x in rdir.walk(\n                    class_ref=class_ref,\n                    class_pattern=class_pattern,\n                    depth=depth + 1,\n                    maxdepth=maxdepth,\n                    path=dirpath,\n                    return_classname=return_classname,\n                    treat_dirs_as_objs=treat_dirs_as_objs):\n                yield x", "response": "Walks the directory structure and content in and below a directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _populate_cache(self):\n        self.cache = autovivitree()\n\n        for path, dirs, objects in self.walk(return_classname=True,\n                                             treat_dirs_as_objs=True):\n            b = self.cache\n            for d in ['']+path.split('/'):\n                b = b[d]\n                obj = [(path, o) for o in objects]\n                if 'obj' in b:\n                    b['obj'] += obj\n                else:\n                    b['obj'] = obj", "response": "Populate the cache with the contents of the current directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self,\n             regexp, negate_regexp=False,\n             class_pattern=None,\n             find_fnc=re.search,\n             refresh_cache=False):\n        \"\"\"\n        yield the full path of the matching regular expression and the\n        match itself\n        \"\"\"\n        if refresh_cache or not hasattr(self, 'cache'):\n            self._populate_cache()\n\n        b = self.cache\n        split_regexp = regexp.split('/')\n\n        # traverse as deep as possible in the cache\n        # special case if the first character is not the root, i.e. not \"\"\n        if split_regexp[0] == '':\n            for d in split_regexp:\n                if d in b:\n                    b = b[d]\n                else:\n                    break\n        else:\n            b = b['']\n\n        # perform the search\n        for path, (obj, classname) in b['obj']:\n            if class_pattern:\n                if not fnmatch(classname, class_pattern):\n                    continue\n            joined_path = os.path.join(*['/', path, obj])\n            result = find_fnc(regexp, joined_path)\n            if (result is not None) ^ negate_regexp:\n                yield joined_path, result", "response": "finds the full path of the matching regular expression and the corresponding match itself"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the function uses the super", "response": "def uses_super(func):\n    \"\"\"\n    Check if the function/property/classmethod/staticmethod uses the `super` builtin\n    \"\"\"\n    if isinstance(func, property):\n        return any(uses_super(f) for f in (func.fget, func.fset, func.fdel) if f)\n    elif isinstance(func, (staticmethod, classmethod)):\n        if sys.version_info >= (2, 7):\n            func = func.__func__\n        elif isinstance(func, staticmethod):\n            func = func.__get__(True)\n        else: # classmethod\n            func = func.__get__(True).im_func\n    if sys.version_info[0] >= 3:\n        return 'super' in func.__code__.co_names\n    return 'super' in func.func_code.co_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart a new GUI thread if possible.", "response": "def start_new_gui_thread():\n    \"\"\"\n    Attempt to start a new GUI thread, if possible.\n\n    It is only possible to start one if there was one running on module import.\n    \"\"\"\n    PyGUIThread = getattr(ROOT, 'PyGUIThread', None)\n\n    if PyGUIThread is not None:\n        assert not PyGUIThread.isAlive(), \"GUI thread already running!\"\n\n    assert _processRootEvents, (\n        \"GUI thread wasn't started when rootwait was imported, \"\n        \"so it can't be restarted\")\n\n    ROOT.keeppolling = 1\n    ROOT.PyGUIThread = threading.Thread(\n        None, _processRootEvents, None, (ROOT,))\n\n    ROOT.PyGUIThread.finishSchedule = _finishSchedule\n    ROOT.PyGUIThread.setDaemon(1)\n    ROOT.PyGUIThread.start()\n    log.debug(\"successfully started a new GUI thread\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops the GUI thread.", "response": "def stop_gui_thread():\n    \"\"\"\n    Try to stop the GUI thread. If it was running returns True,\n    otherwise False.\n    \"\"\"\n    PyGUIThread = getattr(ROOT, 'PyGUIThread', None)\n\n    if PyGUIThread is None or not PyGUIThread.isAlive():\n        log.debug(\"no existing GUI thread is runnng\")\n        return False\n\n    ROOT.keeppolling = 0\n    try:\n        PyGUIThread.finishSchedule()\n    except AttributeError:\n        log.debug(\"unable to call finishSchedule() on PyGUIThread\")\n        pass\n    PyGUIThread.join()\n    log.debug(\"successfully stopped the existing GUI thread\")\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait for all canvases to be closed or middle click will shut the canvas.", "response": "def wait_for_zero_canvases(middle_mouse_close=False):\n    \"\"\"\n    Wait for all canvases to be closed, or CTRL-c.\n\n    If `middle_mouse_close`, middle click will shut the canvas.\n\n    incpy.ignore\n    \"\"\"\n    if not __ACTIVE:\n        wait_failover(wait_for_zero_canvases)\n        return\n\n    @dispatcher\n    def count_canvases():\n        \"\"\"\n        Count the number of active canvases and finish gApplication.Run()\n        if there are none remaining.\n\n        incpy.ignore\n        \"\"\"\n        if not get_visible_canvases():\n            try:\n                ROOT.gSystem.ExitLoop()\n            except AttributeError:\n                # We might be exiting and ROOT.gROOT will raise an AttributeError\n                pass\n\n    @dispatcher\n    def exit_application_loop():\n        \"\"\"\n        Signal handler for CTRL-c to cause gApplication.Run() to finish.\n\n        incpy.ignore\n        \"\"\"\n        ROOT.gSystem.ExitLoop()\n\n    # Handle CTRL-c\n    sh = ROOT.TSignalHandler(ROOT.kSigInterrupt, True)\n    sh.Add()\n    sh.Connect(\"Notified()\", \"TPyDispatcher\",\n               exit_application_loop, \"Dispatch()\")\n\n    visible_canvases = get_visible_canvases()\n\n    for canvas in visible_canvases:\n        log.debug(\"waiting for canvas {0} to close\".format(canvas.GetName()))\n        canvas.Update()\n\n        if middle_mouse_close:\n            attach_event_handler(canvas)\n\n        if not getattr(canvas, \"_py_close_dispatcher_attached\", False):\n            # Attach a handler only once to each canvas\n            canvas._py_close_dispatcher_attached = True\n            canvas.Connect(\"Closed()\", \"TPyDispatcher\",\n                           count_canvases, \"Dispatch()\")\n            keepalive(canvas, count_canvases)\n\n    if visible_canvases and not ROOT.gROOT.IsBatch():\n        run_application_until_done()\n\n        # Disconnect from canvases\n        for canvas in visible_canvases:\n            if getattr(canvas, \"_py_close_dispatcher_attached\", False):\n                canvas._py_close_dispatcher_attached = False\n                canvas.Disconnect(\"Closed()\", count_canvases, \"Dispatch()\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting until a TGMainFrame is closed or ctrl - c is received.", "response": "def wait_for_frame(frame):\n    \"\"\"\n    wait until a TGMainFrame is closed or ctrl-c\n    \"\"\"\n    if not frame:\n        # It's already closed or maybe we're in batch mode\n        return\n\n    @dispatcher\n    def close():\n        ROOT.gSystem.ExitLoop()\n\n    if not getattr(frame, \"_py_close_dispatcher_attached\", False):\n        frame._py_close_dispatcher_attached = True\n        frame.Connect(\"CloseWindow()\", \"TPyDispatcher\", close, \"Dispatch()\")\n\n    @dispatcher\n    def exit_application_loop():\n        \"\"\"\n        Signal handler for CTRL-c to cause gApplication.Run() to finish.\n\n        incpy.ignore\n        \"\"\"\n        ROOT.gSystem.ExitLoop()\n\n    # Handle CTRL-c\n    sh = ROOT.TSignalHandler(ROOT.kSigInterrupt, True)\n    sh.Add()\n    sh.Connect(\"Notified()\", \"TPyDispatcher\",\n               exit_application_loop, \"Dispatch()\")\n\n    if not ROOT.gROOT.IsBatch():\n        run_application_until_done()\n        # Need to disconnect to prevent close handler from running when python\n        # teardown has already commenced.\n        frame.Disconnect(\"CloseWindow()\", close, \"Dispatch()\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_for_browser_close(b):\n    if b:\n        if not __ACTIVE:\n            wait_failover(wait_for_browser_close)\n            return\n        wait_for_frame(b.GetBrowserImp().GetMainFrame())", "response": "Wait until a TBrowser is closed"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_trace(logger, level=logging.DEBUG, show_enter=True, show_exit=True):\n    def wrap(function):\n        l = logger.getChild(function.__name__).log\n        @wraps(function)\n        def thunk(*args, **kwargs):\n            global trace_depth\n            trace_depth.value += 1\n            try:\n                start = time()\n                if show_enter:\n                    l(level, \"{0}> {1} {2}\".format(\" \"*trace_depth.value,\n                                                   args, kwargs))\n                try:\n                    result = function(*args, **kwargs)\n                except:\n                    _, result, _ = sys.exc_info()\n                    raise\n                finally:\n                    if show_exit:\n                        l(level, \"{0}< return {1} [{2:.2f} sec]\".format(\n                            \" \"*trace_depth.value, result, time() - start))\n            finally:\n                trace_depth.value -= 1\n            return result\n        return thunk\n    return wrap", "response": "log a statement on function entry and exit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the widget to show the ETA or total time when finished.", "response": "def update(self, pbar):\n        'Updates the widget to show the ETA or total time when finished.'\n\n        if pbar.currval == 0:\n            return 'ETA:  --:--:--'\n        elif pbar.finished:\n            return 'Time: %s' % self.format_time(pbar.seconds_elapsed)\n        else:\n            return 'ETA:  %s' % self.format_time(self._eta(pbar))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the widget with the current SI prefixed speed.", "response": "def update(self, pbar):\n        'Updates the widget with the current SI prefixed speed.'\n\n        if pbar.seconds_elapsed < 2e-6 or pbar.currval < 2e-6:  # =~ 0\n            scaled = power = 0\n        else:\n            scaled, power = self._speed(pbar)\n\n        return self.format % (scaled, self.prefixes[power], self.unit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_stack(logger, level=logging.INFO, limit=None, frame=None):\n    if showing_stack.inside:\n        return\n    showing_stack.inside = True\n    try:\n        if frame is None:\n            frame = sys._getframe(1)\n        stack = \"\".join(traceback.format_stack(frame, limit))\n        for line in (l[2:] for l in stack.split(\"\\n\") if l.strip()):\n            logger.log(level, line)\n    finally:\n        showing_stack.inside = False", "response": "Log the current stack on the given logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef showdeletion(self, *objects):\n        from ..memory import showdeletion as S\n        for o in objects:\n            S.monitor_object_cleanup(o)", "response": "Record a stack trace at the point when an ROOT TObject is deleted\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trace(self, level=logging.DEBUG, show_enter=True, show_exit=True):\n        from . import log_trace\n        return log_trace(self, level, show_enter, show_exit)", "response": "Function decorator to trace the log entry and exit with the given values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_stack(self, message_regex=\"^.*$\", min_level=logging.DEBUG,\n        limit=4096, once=True):\n        \"\"\"\n        Enable showing the origin of log messages by dumping a stack trace into\n        the ``stack`` logger at the :const:``logging.INFO`` severity.\n\n        :param message_regex: is a full-line regex which the message must\n            satisfy in order to trigger stack dump\n        :param min_level: the minimum severity the message must have in order to\n            trigger the stack dump\n        :param limit: Maximum stack depth to show\n        :param once: Only show the stack once per unique ``(logger, origin line\n            of code)``\n        \"\"\"\n        value = re.compile(message_regex), limit, once, min_level\n        self.show_stack_regexes.append(value)", "response": "Show the stack trace of the log messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef frame_unique(f):\n        return f.f_code.co_filename, f.f_code.co_name, f.f_lineno", "response": "A tuple representing a value which is unique to a given frame s line of\n        execution\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the maximum stack depth to show requested by any hooks and return - 1 if there are none matching.", "response": "def show_stack_depth(self, record, frame):\n        \"\"\"\n        Compute the maximum stack depth to show requested by any hooks,\n        returning -1 if there are none matching, or if we've already emitted\n        one for the line of code referred to.\n        \"\"\"\n        logger = self\n\n        depths = [-1]\n        msg = record.getMessage()\n\n        # For each logger in the hierarchy\n        while logger:\n            to_match = getattr(logger, \"show_stack_regexes\", ())\n            for regex, depth, once, min_level in to_match:\n                if record.levelno < min_level:\n                    continue\n                if not regex.match(record.msg):\n                    continue\n                # Only for a given regex, line number and logger\n                unique = regex, self.frame_unique(frame), record.name\n                if once:\n                    if unique in logger.shown_stack_frames:\n                        # We've shown this one already.\n                        continue\n                    # Prevent this stack frame from being shown again\n                    logger.shown_stack_frames.add(unique)\n                depths.append(depth)\n            logger = logger.parent\n        return max(depths)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the child of this log entry with the given suffix.", "response": "def getChild(self, suffix):\n        \"\"\"\n        Taken from CPython 2.7, modified to remove duplicate prefix and suffixes\n        \"\"\"\n        if suffix is None:\n            return self\n        if self.root is not self:\n            if suffix.startswith(self.name + \".\"):\n                # Remove duplicate prefix\n                suffix = suffix[len(self.name + \".\"):]\n                suf_parts = suffix.split(\".\")\n                if len(suf_parts) > 1 and suf_parts[-1] == suf_parts[-2]:\n                    # If we have a submodule's name equal to the parent's name,\n                    # omit it.\n                    suffix = \".\".join(suf_parts[:-1])\n            suffix = '.'.join((self.name, suffix))\n        return self.manager.getLogger(suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef method_file_cd(f):\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        with preserve_current_directory():\n            self.GetDirectory().cd()\n            return f(self, *args, **kwargs)\n    return wrapper", "response": "Decorator to cd back to the original directory where this object was created."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef chainable(f):\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # perform action\n        f(self, *args, **kwargs)\n        # return reference to class.\n        return self\n    return wrapper", "response": "Decorator which causes a void function to return self\n    Allows chaining of multiple modifier class methods."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef camel_to_snake(name):\n    s1 = FIRST_CAP_RE.sub(r'\\1_\\2', name)\n    return ALL_CAP_RE.sub(r'\\1_\\2', s1).lower()", "response": "Convert camelcase to snake case."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef snake_case_methods(cls, debug=False):\n    if not CONVERT_SNAKE_CASE:\n        return cls\n    # get the ROOT base class\n    root_base = cls._ROOT\n    members = inspect.getmembers(root_base)\n    # filter out any methods that already exist in lower and uppercase forms\n    # i.e. TDirectory::cd and Cd...\n    names = {}\n    for name, member in members:\n        lower_name = name.lower()\n        if lower_name in names:\n            del names[lower_name]\n        else:\n            names[lower_name] = None\n\n    for name, member in members:\n        if name.lower() not in names:\n            continue\n        # Don't touch special methods or methods without cap letters\n        if name[0] == '_' or name.islower():\n            continue\n        # Is this a method of the ROOT base class?\n        if not inspect.ismethod(member) and not inspect.isfunction(member):\n            continue\n        # convert CamelCase to snake_case\n        new_name = camel_to_snake(name)\n        # Use a __dict__ lookup rather than getattr because we _want_ to\n        # obtain the _descriptor_, and not what the descriptor gives us\n        # when it is `getattr`'d.\n        value = None\n        skip = False\n        for c in cls.mro():\n            # skip methods that are already overridden\n            if new_name in c.__dict__:\n                skip = True\n                break\n            if name in c.__dict__:\n                value = c.__dict__[name]\n                break\n        # <neo>Woah, a use for for-else</neo>\n        else:\n            # Weird. Maybe the item lives somewhere else, such as on the\n            # metaclass?\n            value = getattr(cls, name)\n        if skip:\n            continue\n        setattr(cls, new_name, value)\n    return cls", "response": "A class decorator adding snake_case methods that alias capitalized ROOT methods. cls must subclass the ROOT class and define the _ROOT class variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_ufloat(roorealvar):\n    if isinstance(roorealvar, (U.AffineScalarFunc, U.Variable)):\n        return roorealvar\n    return U.ufloat((roorealvar.getVal(), roorealvar.getError()))", "response": "Cast a RooRealVar to an uncertainties. ufloat"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef correlated_values(param_names, roofitresult):\n    pars = roofitresult.floatParsFinal()\n    #pars.Print()\n    pars = [pars[i] for i in range(pars.getSize())]\n    parnames = [p.GetName() for p in pars]\n\n    values = [(p.getVal(), p.getError()) for p in pars]\n    #values = [as_ufloat(p) for p in pars]\n    matrix = asrootpy(roofitresult.correlationMatrix()).to_numpy()\n\n    uvalues = U.correlated_values_norm(values, matrix.tolist())\n    uvalues = dict((n, v) for n, v in zip(parnames, uvalues))\n\n    assert all(n in uvalues for n in parnames), (\n        \"name {0} isn't in parameter list {1}\".format(n, parnames))\n\n    # Return a tuple in the order it was asked for\n    return tuple(uvalues[n] for n in param_names)", "response": "Returns a list of symbolic values for a set of parameters in a RooFitResult."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the attribute is valid for the given metaclass and value.", "response": "def checkattr(metacls, attr, value):\n        \"\"\"\n        Only allow class attributes that are instances of\n        rootpy.types.Column, ROOT.TObject, or ROOT.ObjectProxy\n        \"\"\"\n        if not isinstance(value, (\n                types.MethodType,\n                types.FunctionType,\n                classmethod,\n                staticmethod,\n                property)):\n            if attr in dir(type('dummy', (object,), {})) + \\\n                    ['__metaclass__', '__qualname__']:\n                return\n            if attr.startswith('_'):\n                raise SyntaxError(\n                    \"TreeModel attribute `{0}` \"\n                    \"must not start with `_`\".format(attr))\n            if not inspect.isclass(value):\n                if not isinstance(value, Column):\n                    raise TypeError(\n                        \"TreeModel attribute `{0}` \"\n                        \"must be an instance of \"\n                        \"`rootpy.tree.treetypes.Column`\".format(attr))\n                return\n            if not issubclass(value, (ROOT.TObject, ROOT.ObjectProxy)):\n                raise TypeError(\n                    \"TreeModel attribute `{0}` must inherit \"\n                    \"from `ROOT.TObject` or `ROOT.ObjectProxy`\".format(\n                        attr))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new TreeModel where class attribute names are prefixed with name", "response": "def prefix(cls, name):\n        \"\"\"\n        Create a new TreeModel where class attribute\n        names are prefixed with ``name``\n        \"\"\"\n        attrs = dict([(name + attr, value) for attr, value in cls.get_attrs()])\n        return TreeModelMeta(\n            '_'.join([name, cls.__name__]),\n            (TreeModel,), attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_attrs(cls):\n        ignore = dir(type('dummy', (object,), {})) + ['__metaclass__']\n        attrs = [\n            item for item in inspect.getmembers(cls) if item[0] not in ignore\n            and not isinstance(\n                item[1], (\n                    types.FunctionType,\n                    types.MethodType,\n                    classmethod,\n                    staticmethod,\n                    property))]\n        # sort by idx and use attribute name to break ties\n        attrs.sort(key=lambda attr: (getattr(attr[1], 'idx', -1), attr[0]))\n        return attrs", "response": "Get all class attributes ordered by definition"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the TreeModel into a compiled C struct.", "response": "def to_struct(cls, name=None):\n        \"\"\"\n        Convert the TreeModel into a compiled C struct\n        \"\"\"\n        if name is None:\n            name = cls.__name__\n        basic_attrs = dict([(attr_name, value)\n                            for attr_name, value in cls.get_attrs()\n                            if isinstance(value, Column)])\n        if not basic_attrs:\n            return None\n        src = 'struct {0} {{'.format(name)\n        for attr_name, value in basic_attrs.items():\n            src += '{0} {1};'.format(value.type.typename, attr_name)\n        src += '};'\n        if ROOT.gROOT.ProcessLine(src) != 0:\n            return None\n        return getattr(ROOT, name, None)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a PDG ID to a printable string.", "response": "def id_to_name(id):\n    \"\"\"\n    Convert a PDG ID to a printable string.\n    \"\"\"\n    name = pdgid_names.get(id)\n    if not name:\n        name = repr(id)\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef id_to_root_name(id):\n    name = root_names.get(id)\n    if not name:\n        name = repr(id)\n    return name", "response": "Convert a PDG ID to a string with root markup."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_closure(vals):\n    args = ','.join('x%i' % i for i in range(len(vals)))\n    f = eval(\"lambda %s:lambda:(%s)\" % (args, args))\n    if sys.version_info[0] >= 3:\n        return f(*vals).__closure__\n    return f(*vals).func_closure", "response": "Build a new closure for the given list of values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _inject_closure_values_fix_closures(c, injected, **kwargs):\n    code = c.code\n    orig_len = len(code)\n    for iback, (opcode, value) in enumerate(reversed(code)):\n        i = orig_len - iback - 1\n\n        if opcode != MAKE_CLOSURE:\n            continue\n\n        codeobj = code[i-1-OPCODE_OFFSET]\n        assert codeobj[0] == byteplay.LOAD_CONST\n\n        build_tuple = code[i-2-OPCODE_OFFSET]\n        assert build_tuple[0] == byteplay.BUILD_TUPLE\n        n_closed = build_tuple[1]\n\n        load_closures = code[i-2-OPCODE_OFFSET-n_closed:i-2-OPCODE_OFFSET]\n        assert all(o == byteplay.LOAD_CLOSURE for o, _ in load_closures)\n\n        newlcs = [(byteplay.LOAD_CLOSURE, inj) for inj in injected]\n\n        code[i-2-OPCODE_OFFSET] = byteplay.BUILD_TUPLE, n_closed + len(injected)\n        code[i-2-OPCODE_OFFSET:i-2-OPCODE_OFFSET] = newlcs\n\n        _inject_closure_values_fix_code(codeobj[1], injected, **kwargs)", "response": "Recursively fix closures and adds the injected closures to the current Python bytecode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _inject_closure_values_fix_code(c, injected, **kwargs):\n    # Add more closure variables\n    c.freevars += injected\n\n    # Replace LOAD_GLOBAL with LOAD_DEREF (fetch from closure cells)\n    # for named variables\n    for i, (opcode, value) in enumerate(c.code):\n        if opcode == byteplay.LOAD_GLOBAL and value in kwargs:\n            c.code[i] = byteplay.LOAD_DEREF, value\n\n    _inject_closure_values_fix_closures(c, injected, **kwargs)\n\n    return c", "response": "Recursively fix any closures that are not referenced by the code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inject_closure_values(func, **kwargs):\n    wrapped_by = None\n\n    if isinstance(func, property):\n        fget, fset, fdel = func.fget, func.fset, func.fdel\n        if fget: fget = fix_func(fget, **kwargs)\n        if fset: fset = fix_func(fset, **kwargs)\n        if fdel: fdel = fix_func(fdel, **kwargs)\n        wrapped_by = type(func)\n        return wrapped_by(fget, fset, fdel)\n\n    elif isinstance(func, (staticmethod, classmethod)):\n        func = func.__func__\n        wrapped_by = type(func)\n\n    newfunc = _inject_closure_values(func, **kwargs)\n\n    if wrapped_by:\n        newfunc = wrapped_by(newfunc)\n    return newfunc", "response": "Returns a new function that will injects the values of the passed in kwargs into the new function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef axes(self, ndim=1,\n             xlimits=None, ylimits=None, zlimits=None,\n             xbins=1, ybins=1, zbins=1):\n        \"\"\"\n        Create and return axes on this pad\n        \"\"\"\n        if xlimits is None:\n            xlimits = (0, 1)\n        if ylimits is None:\n            ylimits = (0, 1)\n        if zlimits is None:\n            zlimits = (0, 1)\n        if ndim == 1:\n            from .hist import Hist\n            hist = Hist(1, xlimits[0], xlimits[1])\n        elif ndim == 2:\n            from .hist import Hist2D\n            hist = Hist2D(1, xlimits[0], xlimits[1],\n                          1, ylimits[0], ylimits[1])\n        elif ndim == 3:\n            from .hist import Hist3D\n            hist = Hist3D(1, xlimits[0], xlimits[1],\n                          1, ylimits[0], ylimits[1],\n                          1, zlimits[0], zlimits[1])\n        else:\n            raise ValueError(\"ndim must be 1, 2, or 3\")\n        with self:\n            hist.Draw('AXIS')\n        xaxis = hist.xaxis\n        yaxis = hist.yaxis\n        if isinstance(xbins, (list, tuple)):\n            xbins = array('d', xbins)\n        if hasattr(xbins, '__iter__'):\n            xaxis.Set(len(xbins) - 1, xbins)\n        else:\n            xaxis.Set(xbins, *xlimits)\n        if ndim > 1:\n            if isinstance(ybins, (list, tuple)):\n                ybins = array('d', ybins)\n            if hasattr(ybins, '__iter__'):\n                yaxis.Set(len(ybins) - 1, ybins)\n            else:\n                yaxis.Set(ybins, *ylimits)\n        else:\n            yaxis.limits = ylimits\n            yaxis.range_user = ylimits\n        if ndim > 1:\n            zaxis = hist.zaxis\n            if ndim == 3:\n                if isinstance(zbins, (list, tuple)):\n                    zbins = array('d', zbins)\n                if hasattr(zbins, '__iter__'):\n                    zaxis.Set(len(zbins) - 1, zbins)\n                else:\n                    zaxis.Set(zbins, *zlimits)\n            else:\n                zaxis.limits = zlimits\n                zaxis.range_user = zlimits\n            return xaxis, yaxis, zaxis\n        return xaxis, yaxis", "response": "Create and return axes on this pad."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a ROOT TTree into a HDF5 table.", "response": "def tree2hdf5(tree, hfile, group=None,\n              entries=-1, show_progress=False, **kwargs):\n    \"\"\"\n    Convert a TTree into a HDF5 table.\n\n    Parameters\n    ----------\n\n    tree : ROOT.TTree\n        A ROOT TTree.\n\n    hfile : string or PyTables HDF5 File\n        A PyTables HDF5 File handle or string path to an existing HDF5 file.\n\n    group : string or PyTables Group instance, optional (default=None)\n        Write the table at this location in the HDF5 file.\n\n    entries : int, optional (default=-1)\n        The number of entries to read at once while converting a ROOT TTree\n        into an HDF5 table. By default read the entire TTree into memory (this\n        may not be desired if your TTrees are large).\n\n    show_progress : bool, optional (default=False)\n        If True, then display and update a progress bar on stdout as the TTree\n        is converted.\n\n    kwargs : dict, optional\n        Additional keyword arguments for the tree2array function.\n\n    \"\"\"\n    show_progress = show_progress and check_tty(sys.stdout)\n    if show_progress:\n        widgets = [Percentage(), ' ', Bar(), ' ', ETA()]\n\n    own_h5file = False\n    if isinstance(hfile, string_types):\n        hfile = tables_open(filename=hfile, mode=\"w\", title=\"Data\")\n        own_h5file = True\n\n    log.info(\"Converting tree '{0}' with {1:d} entries ...\".format(\n        tree.GetName(),\n        tree.GetEntries()))\n\n    if not group:\n        group = hfile.root\n    elif isinstance(group, string_types):\n        group_where = '/' + os.path.dirname(group)\n        group_name = os.path.basename(group)\n        if TABLES_NEW_API:\n            group = hfile.create_group(group_where, group_name,\n                                       createparents=True)\n        else:\n            group = hfile.createGroup(group_where, group_name)\n\n    if tree.GetName() in group:\n        log.warning(\n            \"Tree '{0}' already exists \"\n            \"in the output file\".format(tree.GetName()))\n        return\n\n    total_entries = tree.GetEntries()\n    pbar = None\n    if show_progress and total_entries > 0:\n        pbar = ProgressBar(widgets=widgets, maxval=total_entries)\n\n    if entries <= 0:\n        # read the entire tree\n        if pbar is not None:\n            pbar.start()\n        array = tree2array(tree, **kwargs)\n        array = _drop_object_col(array)\n        if TABLES_NEW_API:\n            table = hfile.create_table(\n                group, tree.GetName(),\n                array, tree.GetTitle())\n        else:\n            table = hfile.createTable(\n                group, tree.GetName(),\n                array, tree.GetTitle())\n        # flush data in the table\n        table.flush()\n        # flush all pending data\n        hfile.flush()\n    else:\n        # read the tree in chunks\n        start = 0\n        while start < total_entries or start == 0:\n            if start > 0:\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\n                        \"ignore\",\n                        RootNumpyUnconvertibleWarning)\n                    warnings.simplefilter(\n                        \"ignore\",\n                        tables.NaturalNameWarning)\n                    array = tree2array(\n                        tree,\n                        start=start,\n                        stop=start + entries,\n                        **kwargs)\n                array = _drop_object_col(array, warn=False)\n                table.append(array)\n            else:\n                array = tree2array(\n                    tree,\n                    start=start,\n                    stop=start + entries,\n                    **kwargs)\n                array = _drop_object_col(array)\n                if pbar is not None:\n                    # start after any output from root_numpy\n                    pbar.start()\n                if TABLES_NEW_API:\n                    table = hfile.create_table(\n                        group, tree.GetName(),\n                        array, tree.GetTitle())\n                else:\n                    table = hfile.createTable(\n                        group, tree.GetName(),\n                        array, tree.GetTitle())\n            start += entries\n            if start <= total_entries and pbar is not None:\n                pbar.update(start)\n            # flush data in the table\n            table.flush()\n            # flush all pending data\n            hfile.flush()\n\n    if pbar is not None:\n        pbar.finish()\n\n    if own_h5file:\n        hfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert all trees in a ROOT file into an HDF5 file.", "response": "def root2hdf5(rfile, hfile, rpath='',\n              entries=-1, userfunc=None,\n              show_progress=False,\n              ignore_exception=False,\n              **kwargs):\n    \"\"\"\n    Convert all trees in a ROOT file into tables in an HDF5 file.\n\n    Parameters\n    ----------\n\n    rfile : string or asrootpy'd ROOT File\n        A ROOT File handle or string path to an existing ROOT file.\n\n    hfile : string or PyTables HDF5 File\n        A PyTables HDF5 File handle or string path to an existing HDF5 file.\n\n    rpath : string, optional (default='')\n        Top level path to begin traversal through the ROOT file. By default\n        convert everything in and below the root directory.\n\n    entries : int, optional (default=-1)\n        The number of entries to read at once while converting a ROOT TTree\n        into an HDF5 table. By default read the entire TTree into memory (this\n        may not be desired if your TTrees are large).\n\n    userfunc : callable, optional (default=None)\n        A function that will be called on every tree and that must return a\n        tree or list of trees that will be converted instead of the original\n        tree.\n\n    show_progress : bool, optional (default=False)\n        If True, then display and update a progress bar on stdout as each tree\n        is converted.\n\n    ignore_exception : bool, optional (default=False)\n        If True, then ignore exceptions raised in converting trees and instead\n        skip such trees.\n\n    kwargs : dict, optional\n        Additional keyword arguments for the tree2array function.\n\n    \"\"\"\n    own_rootfile = False\n    if isinstance(rfile, string_types):\n        rfile = root_open(rfile)\n        own_rootfile = True\n\n    own_h5file = False\n    if isinstance(hfile, string_types):\n        hfile = tables_open(filename=hfile, mode=\"w\", title=\"Data\")\n        own_h5file = True\n\n    for dirpath, dirnames, treenames in rfile.walk(\n            rpath, class_ref=QROOT.TTree):\n\n        # skip directories w/o trees\n        if not treenames:\n            continue\n\n        treenames.sort()\n\n        group_where = '/' + os.path.dirname(dirpath)\n        group_name = os.path.basename(dirpath)\n\n        if not group_name:\n            group = hfile.root\n        elif TABLES_NEW_API:\n            group = hfile.create_group(group_where, group_name,\n                                       createparents=True)\n        else:\n            group = hfile.createGroup(group_where, group_name)\n\n        ntrees = len(treenames)\n        log.info(\n            \"Will convert {0:d} tree{1} in {2}\".format(\n                ntrees, 's' if ntrees != 1 else '',\n                os.path.join(group_where, group_name)))\n\n        for treename in treenames:\n\n            input_tree = rfile.Get(os.path.join(dirpath, treename))\n\n            if userfunc is not None:\n                tmp_file = TemporaryFile()\n                # call user-defined function on tree and get output trees\n                log.info(\"Calling user function on tree '{0}'\".format(\n                    input_tree.GetName()))\n                trees = userfunc(input_tree)\n\n                if not isinstance(trees, list):\n                    trees = [trees]\n\n            else:\n                trees = [input_tree]\n                tmp_file = None\n\n            for tree in trees:\n                try:\n                    tree2hdf5(tree, hfile, group=group,\n                              entries=entries,\n                              show_progress=show_progress,\n                              **kwargs)\n                except Exception as e:\n                    if ignore_exception:\n                        log.error(\"Failed to convert tree '{0}': {1}\".format(\n                            tree.GetName(), str(e)))\n                    else:\n                        raise\n\n            input_tree.Delete()\n\n            if userfunc is not None:\n                for tree in trees:\n                    tree.Delete()\n                tmp_file.Close()\n\n    if own_h5file:\n        hfile.close()\n    if own_rootfile:\n        rfile.Close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Crop(self, x1, x2, copy=False):\n        numPoints = self.GetN()\n        if copy:\n            cropGraph = self.Clone()\n            copyGraph = self\n        else:\n            cropGraph = self\n            copyGraph = self.Clone()\n        cropGraph.Set(0)\n        X = copyGraph.GetX()\n        EXlow = copyGraph.GetEXlow()\n        EXhigh = copyGraph.GetEXhigh()\n        Y = copyGraph.GetY()\n        EYlow = copyGraph.GetEYlow()\n        EYhigh = copyGraph.GetEYhigh()\n        xmin = copyGraph.GetXmin()\n        if x1 < xmin-EXlow[0]:\n            cropGraph.Set(numPoints + 1)\n        xmax = copyGraph.GetXmax()\n        if x2 > xmax+EXhigh[numPoints-1]:\n            cropGraph.Set(numPoints + 1)\n        index = 0\n        for i in range(numPoints):\n            if i == 0 and x1 < xmin:\n                cropGraph.SetPoint(0, x1, copyGraph.Eval(x1))\n                index += 1\n            elif i == numPoints-1 and x2 > xmax+EXhigh[i]:\n                cropGraph.SetPoint(i, x2, copyGraph.Eval(x2))\n            if x1<=X[i]-EXlow[i] and X[i]+EXhigh[i]<=x2:\n                cropGraph.SetPoint(index, X[i], Y[i])\n                cropGraph.SetPointError(\n                    index,\n                    EXlow[i], EXhigh[i],\n                    EYlow[i], EYhigh[i])\n                index += 1\n        return cropGraph", "response": "Returns a new graph with the points which lie outside of x1 and x2."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new version of the current state of the set.", "response": "def Reverse(self, copy=False):\n        \"\"\"\n        Reverse the order of the points\n        \"\"\"\n        numPoints = self.GetN()\n        if copy:\n            revGraph = self.Clone()\n        else:\n            revGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            index = numPoints - 1 - i\n            revGraph.SetPoint(i, X[index], Y[index])\n            revGraph.SetPointError(\n                i,\n                EXlow[index], EXhigh[index],\n                EYlow[index], EYhigh[index])\n        return revGraph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshift the graph left or right by value.", "response": "def Shift(self, value, copy=False):\n        \"\"\"\n        Shift the graph left or right by value\n        \"\"\"\n        numPoints = self.GetN()\n        if copy:\n            shiftGraph = self.Clone()\n        else:\n            shiftGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            shiftGraph.SetPoint(i, X[i] + value, Y[i])\n            shiftGraph.SetPointError(\n                i,\n                EXlow[i], EXhigh[i],\n                EYlow[i], EYhigh[i])\n        return shiftGraph"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Append(self, other):\n        orig_len = len(self)\n        self.Set(orig_len + len(other))\n        ipoint = orig_len\n        if hasattr(self, 'SetPointError'):\n            for point in other:\n                self.SetPoint(ipoint, point.x.value, point.y.value)\n                self.SetPointError(\n                    ipoint,\n                    point.x.error_low, point.x.error_hi,\n                    point.y.error_low, point.y.error_hi)\n                ipoint += 1\n        else:\n            for point in other:\n                self.SetPoint(ipoint, point.x.value, point.y.value)\n                ipoint += 1", "response": "Append points from another graph to this one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nkeeping patients alive at least as long as nurse is around using a .", "response": "def keepalive(nurse, *patients):\n    \"\"\"\n    Keep ``patients`` alive at least as long as ``nurse`` is around using a\n    ``WeakKeyDictionary``.\n    \"\"\"\n    if DISABLED:\n        return\n    if hashable(nurse):\n        hashable_patients = []\n        for p in patients:\n            if hashable(p):\n                log.debug(\"Keeping {0} alive for lifetime of {1}\".format(p, nurse))\n                hashable_patients.append(p)\n            else:\n                log.warning(\"Unable to keep unhashable object {0} \"\n                            \"alive for lifetime of {1}\".format(p, nurse))\n        KEEPALIVE.setdefault(nurse, set()).update(hashable_patients)\n    else:\n        log.warning(\"Unable to keep objects alive for lifetime of \"\n                    \"unhashable object {0}\".format(nurse))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a slice object into a canonical form for histogram bin content and edge slicing.", "response": "def canonify_slice(s, n):\n    \"\"\"\n    Convert a slice object into a canonical form\n    to simplify treatment in histogram bin content\n    and edge slicing.\n    \"\"\"\n    if isinstance(s, (int, long)):\n        return canonify_slice(slice(s, s + 1, None), n)\n    start = s.start % n if s.start is not None else 0\n    stop = s.stop % n if s.stop is not None else n\n    step = s.step if s.step is not None else 1\n    return slice(start, stop, step)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bin_to_edge_slice(s, n):\n    s = canonify_slice(s, n)\n    start = s.start\n    stop = s.stop\n    if start > stop:\n        _stop = start + 1\n        start = stop + 1\n        stop = _stop\n    start = max(start - 1, 0)\n    step = abs(s.step)\n    if stop <= 1 or start >= n - 1 or stop == start + 1:\n        return slice(0, None, min(step, n - 2))\n    s = slice(start, stop, abs(s.step))\n    if len(range(*s.indices(n - 1))) < 2:\n        return slice(start, stop, stop - start - 1)\n    return s", "response": "Convert a bin slice into a bin edge slice."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and fill a one - dimensional histogram.", "response": "def histogram(data, *args, **kwargs):\n    \"\"\"\n    Create and fill a one-dimensional histogram.\n\n    The same arguments as the ``Hist`` class are expected.\n    If the number of bins and the ranges are not specified they are\n    automatically deduced with the ``autobinning`` function using the method\n    specified by the ``binning`` argument. Only one-dimensional histogramming\n    is supported.\n    \"\"\"\n    from .autobinning import autobinning\n    dim = kwargs.pop('dim', 1)\n    if dim != 1:\n        raise NotImplementedError\n    if 'binning' in kwargs:\n        args = autobinning(data, kwargs['binning'])\n        del kwargs['binning']\n    histo = Hist(*args, **kwargs)\n    for d in data:\n        histo.Fill(d)\n    return list(histo.xedgesl()), histo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef overflow(self):\n        indices = self.hist.xyz(self.idx)\n        for i in range(self.hist.GetDimension()):\n            if indices[i] == 0 or indices[i] == self.hist.nbins(i) + 1:\n                return True\n        return False", "response": "Returns true if this BinProxy is for an overflow bin\n        Returns False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of effective entries in this bin.", "response": "def effective_entries(self):\n        \"\"\"\n        Number of effective entries in this bin.\n        The number of unweighted entries this bin would need to\n        contain in order to have the same statistical power as this\n        bin with possibly weighted entries, estimated by:\n\n            (sum of weights) ** 2 / (sum of squares of weights)\n\n        \"\"\"\n        sum_w2 = self.sum_w2\n        if sum_w2 == 0:\n            return abs(self.value)\n        return (self.value ** 2) / sum_w2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the xyz coordinates corresponding to the global bin number.", "response": "def xyz(self, idx):\n        \"\"\"\n        return binx, biny, binz corresponding to the global bin number\n        \"\"\"\n        # Not implemented for Python 3:\n        # GetBinXYZ(i, x, y, z)\n        nx  = self.GetNbinsX() + 2\n        ny  = self.GetNbinsY() + 2\n        ndim = self.GetDimension()\n        if ndim < 2:\n            binx = idx % nx\n            biny = 0\n            binz = 0\n        elif ndim < 3:\n            binx = idx % nx\n            biny = ((idx - binx) // nx) % ny\n            binz = 0\n        elif ndim < 4:\n            binx = idx % nx\n            biny = ((idx - binx) // nx) % ny\n            binz = ((idx - binx) // nx - biny) // ny\n        else:\n            raise NotImplementedError\n        return binx, biny, binz"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nbins(self, axis=0, overflow=False):\n        if axis == 0:\n            nbins = self.GetNbinsX()\n        elif axis == 1:\n            nbins = self.GetNbinsY()\n        elif axis == 2:\n            nbins = self.GetNbinsZ()\n        else:\n            raise ValueError(\"axis must be 0, 1, or 2\")\n        if overflow:\n            nbins += 2\n        return nbins", "response": "Get the number of bins along an axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bins_range(self, axis=0, overflow=False):\n        nbins = self.nbins(axis=axis, overflow=False)\n        if overflow:\n            start = 0\n            end_offset = 2\n        else:\n            start = 1\n            end_offset = 1\n        return range(start, nbins + end_offset)", "response": "Return a range of bin indices for iterating along an axis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the binning is uniform along the specified axis.", "response": "def uniform(self, axis=None, precision=1E-7):\n        \"\"\"\n        Return True if the binning is uniform along the specified axis.\n        If axis is None (the default), then return True if the binning is\n        uniform along all axes. Otherwise return False.\n\n        Parameters\n        ----------\n\n        axis : int (default=None)\n            Axis along which to check if the binning is uniform. If None,\n            then check all axes.\n\n        precision : float (default=1E-7)\n            The threshold below which differences in bin widths are ignored and\n            treated as equal.\n\n        Returns\n        -------\n\n        True if the binning is uniform, otherwise False.\n\n        \"\"\"\n        if axis is None:\n            for axis in range(self.GetDimension()):\n                widths = list(self._width(axis=axis))\n                if not all(abs(x - widths[0]) < precision for x in widths):\n                    return False\n            return True\n        widths = list(self._width(axis=axis))\n        return all(abs(x - widths[0]) < precision for x in widths)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uniform_binned(self, name=None):\n        if self.GetDimension() == 1:\n            new_hist = Hist(\n                self.GetNbinsX(), 0, self.GetNbinsX(),\n                name=name, type=self.TYPE)\n        elif self.GetDimension() == 2:\n            new_hist = Hist2D(\n                self.GetNbinsX(), 0, self.GetNbinsX(),\n                self.GetNbinsY(), 0, self.GetNbinsY(),\n                name=name, type=self.TYPE)\n        else:\n            new_hist = Hist3D(\n                self.GetNbinsX(), 0, self.GetNbinsX(),\n                self.GetNbinsY(), 0, self.GetNbinsY(),\n                self.GetNbinsZ(), 0, self.GetNbinsZ(),\n                name=name, type=self.TYPE)\n        # copy over the bin contents and errors\n        for outbin, inbin in zip(new_hist.bins(), self.bins()):\n            outbin.value = inbin.value\n            outbin.error = inbin.error\n        new_hist.decorate(self)\n        new_hist.entries = self.entries\n        return new_hist", "response": "Return a new histogram with constant width bins along all axes by the bin indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef underflow(self, axis=0):\n        if axis not in range(3):\n            raise ValueError(\"axis must be 0, 1, or 2\")\n        if self.DIM == 1:\n            return self.GetBinContent(0)\n        elif self.DIM == 2:\n            def idx(i):\n                arg = [i]\n                arg.insert(axis, 0)\n                return arg\n            return [\n                self.GetBinContent(*idx(i))\n                for i in self.bins_range(axis=(axis + 1) % 2, overflow=True)]\n        elif self.DIM == 3:\n            axes = [0, 1, 2]\n            axes.remove(axis)\n            axis2, axis3 = axes\n            def idx(i, j):\n                arg = [i, j]\n                arg.insert(axis, 0)\n                return arg\n            return [[\n                self.GetBinContent(*idx(i, j))\n                for i in self.bins_range(axis=axis2, overflow=True)]\n                for j in self.bins_range(axis=axis3, overflow=True)]", "response": "Return the underflow for the given axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the lower bound of the binning along an axis", "response": "def lowerbound(self, axis=0):\n        \"\"\"\n        Get the lower bound of the binning along an axis\n        \"\"\"\n        if not 0 <= axis < self.GetDimension():\n            raise ValueError(\n                \"axis must be a non-negative integer less than \"\n                \"the dimensionality of the histogram\")\n        if axis == 0:\n            return self.xedges(1)\n        if axis == 1:\n            return self.yedges(1)\n        if axis == 2:\n            return self.zedges(1)\n        raise TypeError(\"axis must be an integer\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the lower and upper bounds of the binning along an axis", "response": "def bounds(self, axis=0):\n        \"\"\"\n        Get the lower and upper bounds of the binning along an axis\n        \"\"\"\n        if not 0 <= axis < self.GetDimension():\n            raise ValueError(\n                \"axis must be a non-negative integer less than \"\n                \"the dimensionality of the histogram\")\n        if axis == 0:\n            return self.xedges(1), self.xedges(-2)\n        if axis == 1:\n            return self.yedges(1), self.yedges(-2)\n        if axis == 2:\n            return self.zedges(1), self.zedges(-2)\n        raise TypeError(\"axis must be an integer\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting whether two histograms are considered compatible by the number of dimensions number of bins along each axis and number of edges along each axis.", "response": "def check_compatibility(self, other, check_edges=False, precision=1E-7):\n        \"\"\"\n        Test whether two histograms are considered compatible by the number of\n        dimensions, number of bins along each axis, and optionally the bin\n        edges.\n\n        Parameters\n        ----------\n\n        other : histogram\n            A rootpy histogram\n\n        check_edges : bool, optional (default=False)\n            If True then also check that the bin edges are equal within\n            the specified precision.\n\n        precision : float, optional (default=1E-7)\n            The value below which differences between floats are treated as\n            nil when comparing bin edges.\n\n        Raises\n        ------\n\n        TypeError\n            If the histogram dimensionalities do not match\n\n        ValueError\n            If the histogram sizes, number of bins along an axis, or\n            optionally the bin edges do not match\n\n        \"\"\"\n        if self.GetDimension() != other.GetDimension():\n            raise TypeError(\"histogram dimensionalities do not match\")\n        if len(self) != len(other):\n            raise ValueError(\"histogram sizes do not match\")\n        for axis in range(self.GetDimension()):\n            if self.nbins(axis=axis) != other.nbins(axis=axis):\n                raise ValueError(\n                    \"numbers of bins along axis {0:d} do not match\".format(\n                        axis))\n        if check_edges:\n            for axis in range(self.GetDimension()):\n                if not all([abs(l - r) < precision\n                    for l, r in zip(self._edges(axis), other._edges(axis))]):\n                    raise ValueError(\n                        \"edges do not match along axis {0:d}\".format(axis))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfills this histogram with a NumPy array.", "response": "def fill_array(self, array, weights=None):\n        \"\"\"\n        Fill this histogram with a NumPy array\n        \"\"\"\n        try:\n            try:\n                from root_numpy import fill_hist as fill_func\n            except ImportError:\n                from root_numpy import fill_array as fill_func\n        except ImportError:\n            log.critical(\n                \"root_numpy is needed for Hist*.fill_array. \"\n                \"Is it installed and importable?\")\n            raise\n        fill_func(self, array, weights=weights)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_view(self, view):\n        other = view.hist\n        _other_x_center = other.axis(0).GetBinCenter\n        _other_y_center = other.axis(1).GetBinCenter\n        _other_z_center = other.axis(2).GetBinCenter\n        _other_get = other.GetBinContent\n        _other_get_bin = super(_HistBase, other).GetBin\n        other_sum_w2 = other.GetSumw2()\n        _other_sum_w2_at = other_sum_w2.At\n\n        _find = self.FindBin\n        sum_w2 = self.GetSumw2()\n        _sum_w2_at = sum_w2.At\n        _sum_w2_setat = sum_w2.SetAt\n        _set = self.SetBinContent\n        _get = self.GetBinContent\n\n        for x, y, z in view.points:\n            idx = _find(\n                _other_x_center(x),\n                _other_y_center(y),\n                _other_z_center(z))\n            other_idx = _other_get_bin(x, y, z)\n            _set(idx, _get(idx) + _other_get(other_idx))\n            _sum_w2_setat(\n                _sum_w2_at(idx) + _other_sum_w2_at(other_idx),\n                idx)", "response": "Fill this histogram from a view of another histogram."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nobtain the true number of entries in the bin weighted by w^2.", "response": "def get_sum_w2(self, ix, iy=0, iz=0):\n        \"\"\"\n        Obtain the true number of entries in the bin weighted by w^2\n        \"\"\"\n        if self.GetSumw2N() == 0:\n            raise RuntimeError(\n                \"Attempting to access Sumw2 in histogram \"\n                \"where weights were not stored\")\n        xl = self.nbins(axis=0, overflow=True)\n        yl = self.nbins(axis=1, overflow=True)\n        idx = xl * yl * iz + xl * iy + ix\n        if not 0 <= idx < self.GetSumw2N():\n            raise IndexError(\"bin index out of range\")\n        return self.GetSumw2().At(idx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the true number of entries in the bin weighted by w^2.", "response": "def set_sum_w2(self, w, ix, iy=0, iz=0):\n        \"\"\"\n        Sets the true number of entries in the bin weighted by w^2\n        \"\"\"\n        if self.GetSumw2N() == 0:\n            raise RuntimeError(\n                \"Attempting to access Sumw2 in histogram \"\n                \"where weights were not stored\")\n        xl = self.nbins(axis=0, overflow=True)\n        yl = self.nbins(axis=1, overflow=True)\n        idx = xl * yl * iz + xl * iy + ix\n        if not 0 <= idx < self.GetSumw2N():\n            raise IndexError(\"bin index out of range\")\n        self.GetSumw2().SetAt(w, idx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new histogram with the bins merged along the specified axis.", "response": "def merge_bins(self, bin_ranges, axis=0):\n        \"\"\"\n        Merge bins in bin ranges\n\n        Parameters\n        ----------\n\n        bin_ranges : list of tuples\n            A list of tuples of bin indices for each bin range to be merged\n            into one bin.\n\n        axis : int (default=1)\n            The integer identifying the axis to merge bins along.\n\n        Returns\n        -------\n\n        hist : TH1\n            The rebinned histogram.\n\n        Examples\n        --------\n\n        Merge the overflow bins into the first and last real bins::\n\n            newhist = hist.merge_bins([(0, 1), (-2, -1)])\n\n        \"\"\"\n        ndim = self.GetDimension()\n        if axis > ndim - 1:\n            raise ValueError(\n                \"axis is out of range\")\n        axis_bins = self.nbins(axis=axis, overflow=True)\n\n        # collect the indices along this axis to be merged\n        # support negative indices via slicing\n        windows = []\n        for window in bin_ranges:\n            if len(window) != 2:\n                raise ValueError(\n                    \"bin range tuples must contain \"\n                    \"two elements: {0!r}\".format(window))\n            l, r = window\n            if l == r:\n                raise ValueError(\n                    \"bin indices must not be equal \"\n                    \"in a merging window: {0!r}\".format(window))\n            if (l < 0 and r >= 0) or (l > 0 and r > 0 and l > r):\n                raise ValueError(\n                    \"invalid bin range: {0!r}\".format(window))\n            if r == -1:\n                r = axis_bins\n            else:\n                r += 1\n            bin_idx = range(*slice(l, r).indices(axis_bins))\n            if bin_idx: # skip []\n                windows.append(list(bin_idx))\n\n        if not windows:\n            # no merging will take place so return a clone\n            return self.Clone()\n\n        # check that windows do not overlap\n        if len(windows) > 1:\n            flattened = [idx for window in windows for idx in window]\n            if len(flattened) != len(set(flattened)):\n                raise ValueError(\n                    \"bin index windows overlap: {0!r}\".format(bin_ranges))\n\n        # construct a mapping from old to new bin index along this axis\n        windows.sort()\n        mapping = {}\n        left_idx = {}\n        offset = 0\n        for window in windows:\n            # put underflow in first bin\n            new_idx = window[0] - offset or 1\n            left_idx[window[0] or 1] = None\n            for idx in window:\n                mapping[idx] = new_idx\n            offset += len(window) - 1\n            if window[0] == 0:\n                offset -= 1\n\n        new_axis_bins = axis_bins - offset\n\n        # construct new bin edges\n        new_edges = []\n        for i, edge in enumerate(self._edges(axis)):\n            if (i != axis_bins - 2 and i + 1 in mapping\n                and i + 1 not in left_idx):\n                continue\n            new_edges.append(edge)\n\n        # construct new histogram and fill\n        new_hist = self.empty_clone(binning=new_edges, axis=axis)\n\n        this_axis = self.axis(axis)\n        new_axis = new_hist.axis(axis)\n\n        def translate(idx):\n            if idx in mapping:\n                return mapping[idx]\n            if idx == 0:\n                return 0\n            # use TH1.FindBin to determine where the bins should be merged\n            return new_axis.FindBin(this_axis.GetBinCenter(idx))\n\n        for bin in self.bins(overflow=True):\n            xyz = bin.xyz\n            new_xyz = list(xyz)\n            new_xyz[axis] = translate(int(xyz[axis]))\n\n            x, y, z = new_xyz\n\n            new_v = new_hist.GetBinContent(x, y, z)\n            new_hist.SetBinContent(x, y, z, new_v + bin.value)\n\n            sum_w2 = self.get_sum_w2(*xyz)\n            new_sum_w2 = new_hist.get_sum_w2(x, y, z)\n            new_hist.set_sum_w2(sum_w2 + new_sum_w2, x, y, z)\n\n        # transfer stats info\n        stat_array = array('d', [0.] * 10)\n        self.GetStats(stat_array)\n        new_hist.PutStats(stat_array)\n        entries = self.GetEntries()\n        new_hist.SetEntries(entries)\n        return new_hist"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rebinned(self, bins, axis=0):\n        ndim = self.GetDimension()\n        if axis >= ndim:\n            raise ValueError(\n                \"axis must be less than the dimensionality of the histogram\")\n\n        if isinstance(bins, int):\n            _bins = [1] * ndim\n            try:\n                _bins[axis] = bins\n            except IndexError:\n                raise ValueError(\"axis must be 0, 1, or 2\")\n            bins = tuple(_bins)\n\n        if isinstance(bins, tuple):\n            if len(bins) != ndim:\n                raise ValueError(\n                    \"bins must be a tuple with the same \"\n                    \"number of elements as histogram axes\")\n            newname = '{0}_{1}'.format(self.__class__.__name__, uuid())\n            if ndim == 1:\n                hist = self.Rebin(bins[0], newname)\n            elif ndim == 2:\n                hist = self.Rebin2D(bins[0], bins[1], newname)\n            else:\n                hist = self.Rebin3D(bins[0], bins[1], bins[2], newname)\n            hist = asrootpy(hist)\n        elif hasattr(bins, '__iter__'):\n            hist = self.empty_clone(bins, axis=axis)\n            nbinsx = self.nbins(0)\n            nbinsy = self.nbins(1)\n            nbinsz = self.nbins(2)\n            xaxis = self.xaxis\n            yaxis = self.yaxis\n            zaxis = self.zaxis\n            sum_w2 = self.GetSumw2()\n            _sum_w2_at = sum_w2.At\n            new_sum_w2 = hist.GetSumw2()\n            _new_sum_w2_at = new_sum_w2.At\n            _new_sum_w2_setat = new_sum_w2.SetAt\n            _x_center = xaxis.GetBinCenter\n            _y_center = yaxis.GetBinCenter\n            _z_center = zaxis.GetBinCenter\n            _find = hist.FindBin\n            _set = hist.SetBinContent\n            _get = hist.GetBinContent\n            _this_get = self.GetBinContent\n            _get_bin = super(_HistBase, self).GetBin\n            for z in range(1, nbinsz + 1):\n                for y in range(1, nbinsy + 1):\n                    for x in range(1, nbinsx + 1):\n                        newbin = _find(\n                            _x_center(x), _y_center(y), _z_center(z))\n                        idx = _get_bin(x, y, z)\n                        _set(newbin, _get(newbin) + _this_get(idx))\n                        _new_sum_w2_setat(\n                            _new_sum_w2_at(newbin) + _sum_w2_at(idx),\n                            newbin)\n            hist.SetEntries(self.GetEntries())\n        else:\n            raise TypeError(\n                \"bins must either be an integer, a tuple, or an iterable\")\n        return hist", "response": "Returns a new rebinned histogram with the given bins along the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef smoothed(self, iterations=1):\n        copy = self.Clone(shallow=True)\n        copy.Smooth(iterations)\n        return copy", "response": "Returns a smoothed copy of this histogram with the same attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new empty histogram with the same binning and axis.", "response": "def empty_clone(self, binning=None, axis=0, type=None, **kwargs):\n        \"\"\"\n        Return a new empty histogram. The binning may be modified\n        along one axis by specifying the binning and axis arguments.\n        If binning is False, then the corresponding axis is dropped\n        from the returned histogram.\n        \"\"\"\n        ndim = self.GetDimension()\n        if binning is False and ndim == 1:\n            raise ValueError(\n                \"cannot remove the x-axis of a 1D histogram\")\n        args = []\n        for iaxis in range(ndim):\n            if iaxis == axis:\n                if binning is False:\n                    # skip this axis\n                    continue\n                elif binning is not None:\n                    if hasattr(binning, '__iter__'):\n                        binning = (binning,)\n                    args.extend(binning)\n                    continue\n            args.append(list(self._edges(axis=iaxis)))\n        if type is None:\n            type = self.TYPE\n        if binning is False:\n            ndim -= 1\n        cls = [Hist, Hist2D, Hist3D][ndim - 1]\n        return cls(*args, type=type, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the quantiles of the object along the specified axis.", "response": "def quantiles(self, quantiles,\n                  axis=0, strict=False,\n                  recompute_integral=False):\n        \"\"\"\n        Calculate the quantiles of this histogram.\n\n        Parameters\n        ----------\n\n        quantiles : list or int\n            A list of cumulative probabilities or an integer used to determine\n            equally spaced values between 0 and 1 (inclusive).\n\n        axis : int, optional (default=0)\n            The axis to compute the quantiles along. 2D and 3D histograms are\n            first projected along the desired axis before computing the\n            quantiles.\n\n        strict : bool, optional (default=False)\n            If True, then return the sorted unique quantiles corresponding\n            exactly to bin edges of this histogram.\n\n        recompute_integral : bool, optional (default=False)\n            If this histogram was filled with SetBinContent instead of Fill,\n            then the integral must be computed before calculating the\n            quantiles.\n\n        Returns\n        -------\n\n        output : list or numpy array\n            If NumPy is importable then an array of the quantiles is returned,\n            otherwise a list is returned.\n\n        \"\"\"\n        if axis >= self.GetDimension():\n            raise ValueError(\n                \"axis must be less than the dimensionality of the histogram\")\n        if recompute_integral:\n            self.ComputeIntegral()\n        if isinstance(self, _Hist2D):\n            newname = '{0}_{1}'.format(self.__class__.__name__, uuid())\n            if axis == 0:\n                proj = self.ProjectionX(newname, 1, self.nbins(1))\n            elif axis == 1:\n                proj = self.ProjectionY(newname, 1, self.nbins(0))\n            else:\n                raise ValueError(\"axis must be 0 or 1\")\n            return asrootpy(proj).quantiles(\n                quantiles, strict=strict, recompute_integral=False)\n        elif isinstance(self, _Hist3D):\n            newname = '{0}_{1}'.format(self.__class__.__name__, uuid())\n            if axis == 0:\n                proj = self.ProjectionX(\n                    newname, 1, self.nbins(1), 1, self.nbins(2))\n            elif axis == 1:\n                proj = self.ProjectionY(\n                    newname, 1, self.nbins(0), 1, self.nbins(2))\n            elif axis == 2:\n                proj = self.ProjectionZ(\n                    newname, 1, self.nbins(0), 1, self.nbins(1))\n            else:\n                raise ValueError(\"axis must be 0, 1, or 2\")\n            return asrootpy(proj).quantiles(\n                quantiles, strict=strict, recompute_integral=False)\n        try:\n            import numpy as np\n        except ImportError:\n            # use python implementation\n            use_numpy = False\n        else:\n            use_numpy = True\n        if isinstance(quantiles, int):\n            num_quantiles = quantiles\n            if use_numpy:\n                qs = np.linspace(0, 1, num_quantiles)\n                output = np.empty(num_quantiles, dtype=float)\n            else:\n                def linspace(start, stop, n):\n                    if n == 1:\n                        yield start\n                        return\n                    h = float(stop - start) / (n - 1)\n                    for i in range(n):\n                        yield start + h * i\n                quantiles = list(linspace(0, 1, num_quantiles))\n                qs = array('d', quantiles)\n                output = array('d', [0.] * num_quantiles)\n        else:\n            num_quantiles = len(quantiles)\n            if use_numpy:\n                qs = np.array(quantiles, dtype=float)\n                output = np.empty(num_quantiles, dtype=float)\n            else:\n                qs = array('d', quantiles)\n                output = array('d', [0.] * num_quantiles)\n        if strict:\n            integral = self.GetIntegral()\n            nbins = self.nbins(0)\n            if use_numpy:\n                edges = np.empty(nbins + 1, dtype=float)\n                self.GetLowEdge(edges)\n                edges[-1] = edges[-2] + self.GetBinWidth(nbins)\n                integral = np.ndarray((nbins + 1,), dtype=float, buffer=integral)\n                idx = np.searchsorted(integral, qs, side='left')\n                output = np.unique(np.take(edges, idx))\n            else:\n                quantiles = list(set(qs))\n                quantiles.sort()\n                output = []\n                ibin = 0\n                for quant in quantiles:\n                    # find first bin greater than or equal to quant\n                    while integral[ibin] < quant and ibin < nbins + 1:\n                        ibin += 1\n                    edge = self.GetBinLowEdge(ibin + 1)\n                    output.append(edge)\n                    if ibin >= nbins + 1:\n                        break\n                output = list(set(output))\n                output.sort()\n            return output\n        self.GetQuantiles(num_quantiles, output, qs)\n        if use_numpy:\n            return output\n        return list(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the integral over a range of bins.", "response": "def integral(self, xbin1=None, xbin2=None,\n                 width=False, error=False, overflow=False):\n        \"\"\"\n        Compute the integral and error over a range of bins\n        \"\"\"\n        if xbin1 is None:\n            xbin1 = 0 if overflow else 1\n        if xbin2 is None:\n            xbin2 = -1 if overflow else -2\n        nbinsx = self.nbins(axis=0, overflow=True)\n        xbin1 %= nbinsx\n        xbin2 %= nbinsx\n        options = 'width' if width else ''\n        if error:\n            error = ROOT.Double()\n            integral = super(_Hist, self).IntegralAndError(\n                xbin1, xbin2, error, options)\n            return integral, error\n        return super(_Hist, self).Integral(xbin1, xbin2, options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef poisson_errors(self):\n        graph = Graph(self.nbins(axis=0), type='asymm')\n        graph.SetLineWidth(self.GetLineWidth())\n        graph.SetMarkerSize(self.GetMarkerSize())\n        chisqr = ROOT.TMath.ChisquareQuantile\n        npoints = 0\n        for bin in self.bins(overflow=False):\n            entries = bin.effective_entries\n            if entries <= 0:\n                continue\n            ey_low = entries - 0.5 * chisqr(0.1586555, 2. * entries)\n            ey_high = 0.5 * chisqr(\n                1. - 0.1586555, 2. * (entries + 1)) - entries\n            ex = bin.x.width / 2.\n            graph.SetPoint(npoints, bin.x.center, bin.value)\n            graph.SetPointEXlow(npoints, ex)\n            graph.SetPointEXhigh(npoints, ex)\n            graph.SetPointEYlow(npoints, ey_low)\n            graph.SetPointEYhigh(npoints, ey_high)\n            npoints += 1\n        graph.Set(npoints)\n        return graph", "response": "Return a TGraphAsymmErrors representation of this histogram where the point y errors are Poisson."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting this histogram into a 2D histogram with the y - axis repeated along the x - axis similar to NumPy s ravel().", "response": "def ravel(self, name=None):\n        \"\"\"\n        Convert 2D histogram into 1D histogram with the y-axis repeated along\n        the x-axis, similar to NumPy's ravel().\n        \"\"\"\n        nbinsx = self.nbins(0)\n        nbinsy = self.nbins(1)\n        left_edge = self.xedgesl(1)\n        right_edge = self.xedgesh(nbinsx)\n        out = Hist(nbinsx * nbinsy,\n                   left_edge, nbinsy * (right_edge - left_edge) + left_edge,\n                   type=self.TYPE,\n                   name=name,\n                   title=self.title,\n                   **self.decorators)\n        for i, bin in enumerate(self.bins(overflow=False)):\n            out.SetBinContent(i + 1, bin.value)\n            out.SetBinError(i + 1, bin.error)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef integral(self,\n                 xbin1=1, xbin2=-2,\n                 ybin1=1, ybin2=-2,\n                 zbin1=1, zbin2=-2,\n                 width=False,\n                 error=False,\n                 overflow=False):\n        \"\"\"\n        Compute the integral and error over a range of bins\n        \"\"\"\n        if xbin1 is None:\n            xbin1 = 0 if overflow else 1\n        if xbin2 is None:\n            xbin2 = -1 if overflow else -2\n        if ybin1 is None:\n            ybin1 = 0 if overflow else 1\n        if ybin2 is None:\n            ybin2 = -1 if overflow else -2\n        if zbin1 is None:\n            zbin1 = 0 if overflow else 1\n        if zbin2 is None:\n            zbin2 = -1 if overflow else -2\n        nbinsx = self.nbins(axis=0, overflow=True)\n        xbin1 %= nbinsx\n        xbin2 %= nbinsx\n        nbinsy = self.nbins(axis=1, overflow=True)\n        ybin1 %= nbinsy\n        ybin2 %= nbinsy\n        nbinsz = self.nbins(axis=2, overflow=True)\n        zbin1 %= nbinsz\n        zbin2 %= nbinsz\n        options = 'width' if width else ''\n        if error:\n            error = ROOT.Double()\n            integral = super(_Hist3D, self).IntegralAndError(\n                xbin1, xbin2, ybin1, ybin2, zbin1, zbin2, error, options)\n            return integral, error\n        return super(_Hist3D, self).Integral(\n            xbin1, xbin2, ybin1, ybin2, zbin1, zbin2, options)", "response": "Return the integral and error over a range of bins."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new expression that is indirectly defined from the tokens matched in a previous expression that looks for a repeat of a previous expression.", "response": "def matchPreviousExpr(expr):\r\n    \"\"\"Helper to define an expression that is indirectly defined from\r\n       the tokens matched in a previous expression, that is, it looks\r\n       for a 'repeat' of a previous expression.  For example::\r\n           first = Word(nums)\r\n           second = matchPreviousExpr(first)\r\n           matchExpr = first + \":\" + second\r\n       will match C{\"1:1\"}, but not C{\"1:2\"}.  Because this matches by\r\n       expressions, will *not* match the leading C{\"1:1\"} in C{\"1:10\"};\r\n       the expressions are evaluated first, and then compared, so\r\n       C{\"1\"} is compared with C{\"10\"}.\r\n       Do *not* use with packrat parsing enabled.\r\n    \"\"\"\r\n    rep = Forward()\r\n    e2 = expr.copy()\r\n    rep <<= e2\r\n    def copyTokenToRepeater(s,l,t):\r\n        matchTokens = _flatten(t.asList())\r\n        def mustMatchTheseTokens(s,l,t):\r\n            theseTokens = _flatten(t.asList())\r\n            if  theseTokens != matchTokens:\r\n                raise ParseException(\"\",0,\"\")\r\n        rep.setParseAction( mustMatchTheseTokens, callDuringTry=True )\r\n    expr.addParseAction(copyTokenToRepeater, callDuringTry=True)\r\n    return rep"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new object that matches the given string or list of strings.", "response": "def oneOf( strs, caseless=False, useRegex=True ):\r\n    \"\"\"Helper to quickly define a set of alternative Literals, and makes sure to do\r\n       longest-first testing when there is a conflict, regardless of the input order,\r\n       but returns a C{L{MatchFirst}} for best performance.\r\n\r\n       Parameters:\r\n        - strs - a string of space-delimited literals, or a list of string literals\r\n        - caseless - (default=False) - treat all literals as caseless\r\n        - useRegex - (default=True) - as an optimization, will generate a Regex\r\n          object; otherwise, will generate a C{MatchFirst} object (if C{caseless=True}, or\r\n          if creating a C{Regex} raises an exception)\r\n    \"\"\"\r\n    if caseless:\r\n        isequal = ( lambda a,b: a.upper() == b.upper() )\r\n        masks = ( lambda a,b: b.upper().startswith(a.upper()) )\r\n        parseElementClass = CaselessLiteral\r\n    else:\r\n        isequal = ( lambda a,b: a == b )\r\n        masks = ( lambda a,b: b.startswith(a) )\r\n        parseElementClass = Literal\r\n\r\n    symbols = []\r\n    if isinstance(strs,basestring):\r\n        symbols = strs.split()\r\n    elif isinstance(strs, collections.Sequence):\r\n        symbols = list(strs[:])\r\n    elif isinstance(strs, _generatorType):\r\n        symbols = list(strs)\r\n    else:\r\n        warnings.warn(\"Invalid argument to oneOf, expected string or list\",\r\n                SyntaxWarning, stacklevel=2)\r\n    if not symbols:\r\n        return NoMatch()\r\n\r\n    i = 0\r\n    while i < len(symbols)-1:\r\n        cur = symbols[i]\r\n        for j,other in enumerate(symbols[i+1:]):\r\n            if ( isequal(other, cur) ):\r\n                del symbols[i+j+1]\r\n                break\r\n            elif ( masks(cur, other) ):\r\n                del symbols[i+j+1]\r\n                symbols.insert(i,other)\r\n                cur = other\r\n                break\r\n        else:\r\n            i += 1\r\n\r\n    if not caseless and useRegex:\r\n        #~ print (strs,\"->\", \"|\".join( [ _escapeRegexChars(sym) for sym in symbols] ))\r\n        try:\r\n            if len(symbols)==len(\"\".join(symbols)):\r\n                return Regex( \"[%s]\" % \"\".join(_escapeRegexRangeChars(sym) for sym in symbols) )\r\n            else:\r\n                return Regex( \"|\".join(re.escape(sym) for sym in symbols) )\r\n        except:\r\n            warnings.warn(\"Exception creating Regex for oneOf, building MatchFirst\",\r\n                    SyntaxWarning, stacklevel=2)\r\n\r\n\r\n    # last resort, just use MatchFirst\r\n    return MatchFirst( [ parseElementClass(sym) for sym in symbols ] )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_on_esc_or_middlemouse(event, x, y, obj):\n    #print \"Event handler called:\", args\n\n    if (event == ROOT.kButton2Down\n            # User pressed middle mouse\n        or (event == ROOT.kMouseMotion and\n            x == y == 0 and\n            # User pressed escape. Yes. Don't ask me why kMouseMotion.\n            ROOT.gROOT.IsEscaped())):\n\n        # Defer the close because otherwise root segfaults when it tries to\n        # run gPad->Modified()\n        obj._py_closetimer = ROOT.TTimer()\n        obj._py_closetimer.Connect(\"Timeout()\", \"TCanvas\", obj, \"Close()\")\n        # Single shot after 10ms\n        obj._py_closetimer.Start(10, ROOT.kTRUE)", "response": "Closes the canvases when the middle mouse is pressed or the canvas area is clicked with\n    middle mouse button."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattaching a handler function to the ProcessedEvent slot.", "response": "def attach_event_handler(canvas, handler=close_on_esc_or_middlemouse):\n    \"\"\"\n    Attach a handler function to the ProcessedEvent slot, defaulting to\n    closing when middle mouse is clicked or escape is pressed\n\n    Note that escape only works if the pad has focus, which in ROOT-land means\n    the mouse has to be over the canvas area.\n    \"\"\"\n    if getattr(canvas, \"_py_event_dispatcher_attached\", None):\n        return\n\n    event_dispatcher = C.TPyDispatcherProcessedEvent(handler)\n    canvas.Connect(\"ProcessedEvent(int,int,int,TObject*)\",\n                   \"TPyDispatcherProcessedEvent\", event_dispatcher,\n                   \"Dispatch(int,int,int,TObject*)\")\n\n    # Attach a handler only once to each canvas, and keep the dispatcher alive\n    canvas._py_event_dispatcher_attached = event_dispatcher"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_contour_matrix(arrays,\n                        fields,\n                        filename,\n                        weights=None,\n                        sample_names=None,\n                        sample_lines=None,\n                        sample_colors=None,\n                        color_map=None,\n                        num_bins=20,\n                        num_contours=3,\n                        cell_width=2,\n                        cell_height=2,\n                        cell_margin_x=0.05,\n                        cell_margin_y=0.05,\n                        dpi=100,\n                        padding=0,\n                        animate_field=None,\n                        animate_steps=10,\n                        animate_delay=20,\n                        animate_loop=0):\n    \"\"\"\n    Create a matrix of contour plots showing all possible 2D projections of a\n    multivariate dataset. You may optionally animate the contours as a cut on\n    one of the fields is increased. ImageMagick must be installed to produce\n    animations.\n\n    Parameters\n    ----------\n\n    arrays : list of arrays of shape [n_samples, n_fields]\n        A list of 2D NumPy arrays for each sample. All arrays must have the\n        same number of columns.\n\n    fields : list of strings\n        A list of the field names.\n\n    filename : string\n        The output filename. If animatation is enabled\n        ``animate_field is not None`` then ``filename`` must have the .gif\n        extension.\n\n    weights : list of arrays, optional (default=None)\n        List of 1D NumPy arrays of sample weights corresponding to the arrays\n        in ``arrays``.\n\n    sample_names : list of strings, optional (default=None)\n        A list of the sample names for the legend. If None, then no legend will\n        be shown.\n\n    sample_lines : list of strings, optional (default=None)\n        A list of matplotlib line styles for each sample. If None then line\n        styles will cycle through 'dashed', 'solid', 'dashdot', and 'dotted'.\n        Elements of this list may also be a list of line styles which will be\n        cycled through for the contour lines of the corresponding sample.\n\n    sample_colors : list of matplotlib colors, optional (default=None)\n        The color of the contours for each sample. If None, then colors will be\n        selected according to regular intervals along the ``color_map``.\n\n    color_map : a matplotlib color map, optional (default=None)\n        If ``sample_colors is None`` then select colors according to regular\n        intervals along this matplotlib color map. If ``color_map`` is None,\n        then the spectral color map is used.\n\n    num_bins : int, optional (default=20)\n        The number of bins along both axes of the 2D histograms.\n\n    num_contours : int, optional (default=3)\n        The number of contour line to show for each sample.\n\n    cell_width : float, optional (default=2)\n        The width, in inches, of each subplot in the matrix.\n\n    cell_height : float, optional (default=2)\n        The height, in inches, of each subplot in the matrix.\n\n    cell_margin_x : float, optional (default=0.05)\n        The horizontal margin between adjacent subplots, as a fraction\n        of the subplot size.\n\n    cell_margin_y : float, optional (default=0.05)\n        The vertical margin between adjacent subplots, as a fraction\n        of the subplot size.\n\n    dpi : int, optional (default=100)\n        The number of pixels per inch.\n\n    padding : float, optional (default=0)\n        The padding, as a fraction of the range of the value along each axes to\n        guarantee around each sample's contour plot.\n\n    animate_field : string, optional (default=None)\n        The field to animate a cut along. By default no animation is produced.\n        If ``animate_field is not None`` then ``filename`` must end in the .gif\n        extension and an animated GIF is produced.\n\n    animate_steps : int, optional (default=10)\n        The number of frames in the animation, corresponding to the number of\n        regularly spaced cut values to show along the range of the\n        ``animate_field``.\n\n    animate_delay : int, optional (default=20)\n        The duration that each frame is shown in the animation as a multiple of\n        1 / 100 of a second.\n\n    animate_loop : int, optional (default=0)\n        The number of times to loop the animation. If zero, then loop forever.\n\n    Notes\n    -----\n\n    NumPy and matplotlib are required\n\n    \"\"\"\n    import numpy as np\n    from .. import root2matplotlib as r2m\n    import matplotlib.pyplot as plt\n    from matplotlib.ticker import MaxNLocator\n    from matplotlib import cm\n    from matplotlib.lines import Line2D\n\n    # we must have at least two fields (columns)\n    num_fields = len(fields)\n    if num_fields < 2:\n        raise ValueError(\n            \"record arrays must have at least two fields\")\n    # check that all arrays have the same number of columns\n    for array in arrays:\n        if array.shape[1] != num_fields:\n            raise ValueError(\n                \"number of array columns does not match number of fields\")\n\n    if sample_colors is None:\n        if color_map is None:\n            color_map = cm.spectral\n        steps = np.linspace(0, 1, len(arrays) + 2)[1:-1]\n        sample_colors = [color_map(s) for s in steps]\n\n    # determine range of each field\n    low = np.vstack([a.min(axis=0) for a in arrays]).min(axis=0)\n    high = np.vstack([a.max(axis=0) for a in arrays]).max(axis=0)\n    width = np.abs(high - low)\n    width *= padding\n    low -= width\n    high += width\n\n    def single_frame(arrays, filename, label=None):\n\n        # create the canvas and divide into matrix\n        fig, axes = plt.subplots(\n            nrows=num_fields,\n            ncols=num_fields,\n            figsize=(cell_width * num_fields, cell_height * num_fields))\n        fig.subplots_adjust(hspace=cell_margin_y, wspace=cell_margin_x)\n\n        for ax in axes.flat:\n            # only show the left and bottom axes ticks and labels\n            if ax.is_last_row() and not ax.is_last_col():\n                ax.xaxis.set_visible(True)\n                ax.xaxis.set_ticks_position('bottom')\n                ax.xaxis.set_major_locator(MaxNLocator(4, prune='both'))\n                for tick in ax.xaxis.get_major_ticks():\n                    tick.label.set_rotation('vertical')\n            else:\n                ax.xaxis.set_visible(False)\n\n            if ax.is_first_col() and not ax.is_first_row():\n                ax.yaxis.set_visible(True)\n                ax.yaxis.set_ticks_position('left')\n                ax.yaxis.set_major_locator(MaxNLocator(4, prune='both'))\n            else:\n                ax.yaxis.set_visible(False)\n\n        # turn off axes frames in upper triangular matrix\n        for ix, iy in zip(*np.triu_indices_from(axes, k=0)):\n            axes[ix, iy].axis('off')\n\n        levels = np.linspace(0, 1, num_contours + 2)[1:-1]\n\n        # plot the data\n        for iy, ix in zip(*np.tril_indices_from(axes, k=-1)):\n            ymin = float(low[iy])\n            ymax = float(high[iy])\n            xmin = float(low[ix])\n            xmax = float(high[ix])\n            for isample, a in enumerate(arrays):\n                hist = Hist2D(\n                    num_bins, xmin, xmax,\n                    num_bins, ymin, ymax)\n                if weights is not None:\n                    hist.fill_array(a[:, [ix, iy]], weights[isample])\n                else:\n                    hist.fill_array(a[:, [ix, iy]])\n                # normalize so maximum is 1.0\n                _max = hist.GetMaximum()\n                if _max != 0:\n                    hist /= _max\n                r2m.contour(hist,\n                    axes=axes[iy, ix],\n                    levels=levels,\n                    linestyles=sample_lines[isample] if sample_lines else LINES,\n                    colors=sample_colors[isample])\n\n        # label the diagonal subplots\n        for i, field in enumerate(fields):\n            axes[i, i].annotate(field,\n                (0.1, 0.2),\n                rotation=45,\n                xycoords='axes fraction',\n                ha='left', va='center')\n\n        # make proxy artists for legend\n        lines = []\n        for color in sample_colors:\n            lines.append(Line2D([0, 0], [0, 0], color=color))\n\n        if sample_names is not None:\n            # draw the legend\n            leg = fig.legend(lines, sample_names, loc=(0.65, 0.8))\n            leg.set_frame_on(False)\n\n        if label is not None:\n            axes[0, 0].annotate(label, (0, 1),\n                ha='left', va='top',\n                xycoords='axes fraction')\n\n        fig.savefig(filename, bbox_inches='tight', dpi=dpi)\n        plt.close(fig)\n\n    if animate_field is not None:\n        _, ext = os.path.splitext(filename)\n        if ext != '.gif':\n            raise ValueError(\n                \"animation is only supported for .gif files\")\n        field_idx = fields.index(animate_field)\n        cuts = np.linspace(\n            low[field_idx],\n            high[field_idx],\n            animate_steps + 1)[:-1]\n        gif = GIF()\n        temp_dir = tempfile.mkdtemp()\n        for i, cut in enumerate(cuts):\n            frame_filename = os.path.join(temp_dir, 'frame_{0:d}.png'.format(i))\n            label = '{0} > {1:.2f}'.format(animate_field, cut)\n            log.info(\"creating frame for {0} ...\".format(label))\n            new_arrays = []\n            for array in arrays:\n                new_arrays.append(array[array[:, field_idx] > cut])\n            single_frame(new_arrays,\n                filename=frame_filename,\n                label=label)\n            gif.add_frame(frame_filename)\n        gif.write(filename, delay=animate_delay, loop=animate_loop)\n        shutil.rmtree(temp_dir)\n    else:\n        single_frame(arrays, filename=filename)", "response": "Plots the contour matrix of the multivariate dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a number to a string using the given alphabet.", "response": "def _num_to_string(self, number, pad_to_length=None):\n        \"\"\"\n        Convert a number to a string, using the given alphabet.\n        \"\"\"\n        output = \"\"\n        while number:\n            number, digit = divmod(number, self._alpha_len)\n            output += self._alphabet[digit]\n        if pad_to_length:\n            remainder = max(pad_to_length - len(output), 0)\n            output = output + self._alphabet[0] * remainder\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _string_to_int(self, string):\n        number = 0\n        for char in string[::-1]:\n            number = number * self._alpha_len + self._alphabet.index(char)\n        return number", "response": "Convert a string to a number using the given alphabet."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode(self, uuid, pad_length=22):\n        return self._num_to_string(uuid.int, pad_to_length=pad_length)", "response": "Encodes a UUID into a string according to the alphabet"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate and return a UUID.", "response": "def uuid(self, name=None, pad_length=22):\n        \"\"\"\n        Generate and return a UUID.\n\n        If the name parameter is provided, set the namespace to the provided\n        name and generate a UUID.\n        \"\"\"\n        # If no name is given, generate a random UUID.\n        if name is None:\n            uuid = _uu.uuid4()\n        elif \"http\" not in name.lower():\n            uuid = _uu.uuid5(_uu.NAMESPACE_DNS, name)\n        else:\n            uuid = _uu.uuid5(_uu.NAMESPACE_URL, name)\n        return self.encode(uuid, pad_length)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef random(self, length=22):\n        random_num = int(binascii.b2a_hex(os.urandom(length)), 16)\n        return self._num_to_string(random_num, pad_to_length=length)[:length]", "response": "Generate and return a cryptographically - secure short random string\n        of the specified length."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit(self,\n            data='obsData',\n            model_config='ModelConfig',\n            param_const=None,\n            param_values=None,\n            param_ranges=None,\n            poi_const=False,\n            poi_value=None,\n            poi_range=None,\n            extended=False,\n            num_cpu=1,\n            process_strategy=0,\n            offset=False,\n            print_level=None,\n            return_nll=False,\n            **kwargs):\n        \"\"\"\n        Fit a pdf to data in a workspace\n\n        Parameters\n        ----------\n\n        workspace : RooWorkspace\n            The workspace\n\n        data : str or RooAbsData, optional (default='obsData')\n            The name of the data or a RooAbsData instance.\n\n        model_config : str or ModelConfig, optional (default='ModelConfig')\n            The name of the ModelConfig in the workspace or a\n            ModelConfig instance.\n\n        param_const : dict, optional (default=None)\n            A dict mapping parameter names to booleans setting\n            the const state of the parameter\n\n        param_values : dict, optional (default=None)\n            A dict mapping parameter names to values\n\n        param_ranges : dict, optional (default=None)\n            A dict mapping parameter names to 2-tuples defining the ranges\n\n        poi_const : bool, optional (default=False)\n            If True, then make the parameter of interest (POI) constant\n\n        poi_value : float, optional (default=None)\n            If not None, then set the POI to this value\n\n        poi_range : tuple, optional (default=None)\n            If not None, then set the range of the POI with this 2-tuple\n\n        extended : bool, optional (default=False)\n            If True, add extended likelihood term (False by default)\n\n        num_cpu : int, optional (default=1)\n            Parallelize NLL calculation on multiple CPU cores.\n            If negative then use all CPU cores.\n            By default use only one CPU core.\n\n        process_strategy : int, optional (default=0)\n            **Strategy 0:** Divide events into N equal chunks.\n\n            **Strategy 1:** Process event i%N in process N. Recommended for\n            binned data with a substantial number of zero-bins, which will be\n            distributed across processes more equitably in this strategy.\n\n            **Strategy 2:** Process each component likelihood of a\n            RooSimultaneous fully in a single process and distribute components\n            over processes. This approach can be benificial if normalization\n            calculation time dominates the total computation time of a\n            component (since the normalization calculation must be performed\n            in each process in strategies 0 and 1. However beware that if the\n            RooSimultaneous components do not share many parameters this\n            strategy is inefficient: as most minuit-induced likelihood\n            calculations involve changing a single parameter, only 1 of the N\n            processes will be active most of the time if RooSimultaneous\n            components do not share many parameters.\n\n            **Strategy 3:** Follow strategy 0 for all RooSimultaneous\n            components, except those with less than 30 dataset entries,\n            for which strategy 2 is followed.\n\n        offset : bool, optional (default=False)\n            Offset likelihood by initial value (so that starting value of FCN\n            in minuit is zero). This can improve numeric stability in\n            simultaneously fits with components with large likelihood values.\n\n        print_level : int, optional (default=None)\n            The verbosity level for the minimizer algorithm.\n            If None (the default) then use the global default print level.\n            If negative then all non-fatal messages will be suppressed.\n\n        return_nll : bool, optional (default=False)\n            If True then also return the RooAbsReal NLL function that was\n            minimized.\n\n        kwargs : dict, optional\n            Remaining keyword arguments are passed to the minimize function\n\n        Returns\n        -------\n\n        result : RooFitResult\n            The fit result.\n\n        func : RooAbsReal\n            If return_nll is True, the NLL function is also returned.\n\n        See Also\n        --------\n\n        minimize\n\n        \"\"\"\n        if isinstance(model_config, string_types):\n            model_config = self.obj(\n                model_config, cls=ROOT.RooStats.ModelConfig)\n        if isinstance(data, string_types):\n            data = self.data(data)\n        pdf = model_config.GetPdf()\n\n        pois = model_config.GetParametersOfInterest()\n        if pois.getSize() > 0:\n            poi = pois.first()\n            poi.setConstant(poi_const)\n            if poi_value is not None:\n                poi.setVal(poi_value)\n            if poi_range is not None:\n                poi.setRange(*poi_range)\n\n        if param_const is not None:\n            for param_name, const in param_const.items():\n                var = self.var(param_name)\n                var.setConstant(const)\n        if param_values is not None:\n            for param_name, param_value in param_values.items():\n                var = self.var(param_name)\n                var.setVal(param_value)\n        if param_ranges is not None:\n            for param_name, param_range in param_ranges.items():\n                var = self.var(param_name)\n                var.setRange(*param_range)\n\n        if print_level < 0:\n            msg_service = ROOT.RooMsgService.instance()\n            msg_level = msg_service.globalKillBelow()\n            msg_service.setGlobalKillBelow(ROOT.RooFit.FATAL)\n\n        args = [\n            ROOT.RooFit.Constrain(model_config.GetNuisanceParameters()),\n            ROOT.RooFit.GlobalObservables(model_config.GetGlobalObservables())]\n        if extended:\n            args.append(ROOT.RooFit.Extended(True))\n        if offset:\n            args.append(ROOT.RooFit.Offset(True))\n        if num_cpu != 1:\n            if num_cpu == 0:\n                raise ValueError(\"num_cpu must be non-zero\")\n            if num_cpu < 0:\n                num_cpu = NCPU\n            args.append(ROOT.RooFit.NumCPU(num_cpu, process_strategy))\n\n        func = pdf.createNLL(data, *args)\n\n        if print_level < 0:\n            msg_service.setGlobalKillBelow(msg_level)\n\n        result = minimize(func, print_level=print_level, **kwargs)\n\n        if return_nll:\n            return result, func\n        return result", "response": "Fit a pdf to data in a workspace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_trafaret(trafaret):\n    if isinstance(trafaret, Trafaret):\n        return trafaret\n    elif isinstance(trafaret, type):\n        if issubclass(trafaret, Trafaret):\n            return trafaret()\n        # str, int, float are classes, but its appropriate to use them\n        # as trafaret functions\n        return Call(lambda val: trafaret(val))\n    elif callable(trafaret):\n        return Call(trafaret)\n    else:\n        raise RuntimeError(\"%r should be instance or subclass\"\n                           \" of Trafaret\" % trafaret)", "response": "Helper for complex trafarets takes trafaret instance or class\n    and returns trafaret instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if dict has all given keys", "response": "def DictKeys(keys):\n    \"\"\"\n    Checks if dict has all given keys\n\n    :param keys:\n    :type keys:\n\n    >>> _dd(DictKeys(['a','b']).check({'a':1,'b':2,}))\n    \"{'a': 1, 'b': 2}\"\n    >>> extract_error(DictKeys(['a','b']), {'a':1,'b':2,'c':3,})\n    {'c': 'c is not allowed key'}\n    >>> extract_error(DictKeys(['key','key2']), {'key':'val'})\n    {'key2': 'is required'}\n    \"\"\"\n    req = [(Key(key), Any) for key in keys]\n    return Dict(dict(req))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef guard(trafaret=None, **kwargs):\n    if (\n        trafaret\n        and not isinstance(trafaret, Dict)\n        and not isinstance(trafaret, Forward)\n    ):\n        raise RuntimeError(\"trafaret should be instance of Dict or Forward\")\n    elif trafaret and kwargs:\n        raise RuntimeError(\"choose one way of initialization,\"\n                           \" trafaret or kwargs\")\n    if not trafaret:\n        trafaret = Dict(**kwargs)\n\n    def wrapper(fn):\n        argspec = getargspec(fn)\n\n        @functools.wraps(fn)\n        def decor(*args, **kwargs):\n            fnargs = argspec.args\n            if fnargs and fnargs[0] in ['self', 'cls']:\n                obj = args[0]\n                fnargs = fnargs[1:]\n                checkargs = args[1:]\n            else:\n                obj = None\n                checkargs = args\n\n            try:\n                call_args = dict(\n                    itertools.chain(zip(fnargs, checkargs), kwargs.items())\n                )\n                for name, default in zip(reversed(fnargs),\n                                         reversed(argspec.defaults or ())):\n                    if name not in call_args:\n                        call_args[name] = default\n                converted = trafaret(call_args)\n            except DataError as err:\n                raise GuardError(error=err.error)\n            return fn(obj, **converted) if obj else fn(**converted)\n        decor.__doc__ = \"guarded with %r\\n\\n\" % trafaret + (decor.__doc__ or \"\")\n        return decor\n    return wrapper", "response": "Decorator for protecting function with trafarets\nShipment"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncatches errors and returns it as dict", "response": "def catch(checker, *a, **kw):\n    \"\"\"\n    Helper for tests - catch error and return it as dict\n    \"\"\"\n    try:\n        return checker(*a, **kw)\n    except DataError as error:\n        return error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_error(checker, *a, **kw):\n\n    res = catch_error(checker, *a, **kw)\n    if isinstance(res, DataError):\n        return res.as_dict()\n    return res", "response": "Helper for tests - catch error and return it as dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _clone_args(self):\n        keys = list(self.keys)\n        kw = {}\n        if self.allow_any or self.extras:\n            kw['allow_extra'] = list(self.extras)\n            if self.allow_any:\n                kw['allow_extra'].append('*')\n            kw['allow_extra_trafaret'] = self.extras_trafaret\n        if self.ignore_any or self.ignore:\n            kw['ignore_extra'] = list(self.ignore)\n            if self.ignore_any:\n                kw['ignore_any'].append('*')\n        return keys, kw", "response": "return args to create new Dict clone\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_optional(self, *args):\n        deprecated('This method is deprecated. You can not change keys instances.')\n        for key in self.keys:\n            if key.name in args or '*' in args:\n                key.make_optional()\n        return self", "response": "Make all the keys in - place for given args."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new Dict instance with the union of self and other.", "response": "def merge(self, other):\n        \"\"\"\n        Extends one Dict with other Dict Key`s or Key`s list,\n        or dict instance supposed for Dict\n        \"\"\"\n        ignore = self.ignore\n        extra = self.extras\n        if isinstance(other, Dict):\n            other_keys = other.keys\n            ignore += other.ignore\n            extra += other.extras\n        elif isinstance(other, (list, tuple)):\n            other_keys = list(other)\n        elif isinstance(other, dict):\n            return self.__class__(other, *self.keys)\n        else:\n            raise TypeError('You must merge Dict only with Dict'\n                            ' or list of Keys')\n        return self.__class__(*(self.keys + other_keys), ignore_extra=ignore,\n                              allow_extra=extra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fold(data, prefix='', delimeter='__'):\n    if not isinstance(delimeter, (tuple, list)):\n        delimeter = (delimeter, )\n\n    def deep(data):\n        if len(data) == 1 and len(data[0][0]) < 2:\n            if data[0][0]:\n                return {data[0][0][0]: data[0][1]}\n            return data[0][1]\n\n        collect = {}\n        for key, group in groupby(data, lambda kv: kv[0][0]):\n            nest_data = [(k[1:], v) for k, v in group]\n            collect[key] = deep(nest_data)\n\n        is_num = all(k.isdigit() for k in collect.keys())\n        if is_num:\n            return [i[1] for i in sorted(collect.items())]\n        return collect\n\n    data_ = [\n        (split(key, delimeter), value)\n        for key, value in sorted(data.items())\n    ]\n    result = deep(data_)\n    return result[prefix] if prefix else result", "response": "Folds the data into a single tree structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct a new base trafaret from a string or list of trafarets.", "response": "def construct(arg):\n    '''\n    Shortcut syntax to define trafarets.\n\n    - int, str, float and bool will return t.Int, t.String, t.Float and t.Bool\n    - one element list will return t.List\n    - tuple or list with several args will return t.Tuple\n    - dict will return t.Dict. If key has '?' at the and it will be optional and '?' will be removed\n    - any callable will be t.Call\n    - otherwise it will be returned as is\n\n    construct is recursive and will try construct all lists, tuples and dicts args\n    '''\n    if isinstance(arg, t.Trafaret):\n        return arg\n    elif isinstance(arg, tuple) or (isinstance(arg, list) and len(arg) > 1):\n        return t.Tuple(*(construct(a) for a in arg))\n    elif isinstance(arg, list):\n        # if len(arg) == 1\n        return t.List(construct(arg[0]))\n    elif isinstance(arg, dict):\n        return t.Dict({construct_key(key): construct(value) for key, value in arg.items()})\n    elif isinstance(arg, str):\n        return t.Atom(arg)\n    elif isinstance(arg, type):\n        if arg is int:\n            return t.Int()\n        elif arg is float:\n            return t.Float()\n        elif arg is str:\n            return t.String()\n        elif arg is bool:\n            return t.Bool()\n        else:\n            return t.Type(arg)\n    elif callable(arg):\n        return t.Call(arg)\n    else:\n        return arg"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef confirm_key(name, confirm_name, trafaret):\n    def check_(value):\n        first, second = None, None\n        if name in value:\n            first = value[name]\n        else:\n            yield name, t.DataError('is required'), (name,)\n        if confirm_name in value:\n            second = value[confirm_name]\n        else:\n            yield confirm_name, t.DataError('is required'), (confirm_name,)\n        if not (first and second):\n            return\n        yield name, t.catch_error(trafaret, first), (name,)\n        yield confirm_name, t.catch_error(trafaret, second), (confirm_name,)\n        if first != second:\n            yield confirm_name, t.DataError('must be equal to {}'.format(name)), (confirm_name,)\n    return check_", "response": "Takes name confirm_name and trafaret and returns a function that checks if both data have the same name and confirm_name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_capacity(self, legacy=None):\n        params = None\n        if legacy:\n            params = {'legacy': legacy}\n\n        return self.call_api('/capacity', params=params)['capacity']", "response": "Get capacity of all facilities.\n\n        :param legacy: Indicate set of server types to include in response\n\n        Validation of `legacy` is left to the packet api to avoid going out of date if any new value is introduced.\n        The currently known values are:\n          - only (current default, will be switched \"soon\")\n          - include\n          - exclude (soon to be default)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all currencies that are supported by the passed in project and support level.", "response": "def supported_currencies(self, project='moneywagon', level=\"full\"):\n        \"\"\"\n        Returns a list of all currencies that are supported by the passed in project.\n        and support level. Support level can be: \"block\", \"transaction\", \"address\"\n        or \"full\".\n        \"\"\"\n        ret = []\n        if project == 'multiexplorer-wallet':\n            for currency, data in self.sorted_crypto_data:\n                if not data.get(\"bip44_coin_type\"):\n                    continue\n                if len(data.get('services', {}).get(\"push_tx\", [])) < 1:\n                    continue\n                if len(data.get('services', {}).get(\"historical_transactions\", [])) < 1:\n                    continue\n                if len(data.get('services', {}).get(\"single_transaction\", [])) < 1:\n                    continue\n                if len(data.get('services', {}).get(\"unspent_outputs\", [])) < 1:\n                    continue\n                ret.append(currency)\n\n            altcore_tx = self.supported_currencies('altcore', level=\"transaction\")\n            return [x for x in ret if x in altcore_tx]\n\n        for symbol, data in self.sorted_crypto_data:\n            if symbol == '': # template\n                continue\n            if self.is_all_supported(data, project, level):\n                ret.append(symbol)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all currencies that are not supported by the passed in project and support level.", "response": "def not_supported_currencies(self, project='moneywagon', level=\"full\"):\n        \"\"\"\n        Returns a list of all currencies that are defined in moneywagon, by not\n        supported by the passed in project and support level. Support level can\n        be: \"block\", \"transaction\", \"address\" or \"full\".\n        \"\"\"\n        supported = self.supported_currencies(project, level)\n        ret = []\n        for symbol, data in self.sorted_crypto_data:\n            if symbol == '': # template\n                continue\n            if symbol not in supported:\n                ret.append(symbol)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the crypto_data for all currencies that also meet the minimum support for altcore.", "response": "def altcore_data(self):\n        \"\"\"\n        Returns the crypto_data for all currencies defined in moneywagon that also\n        meet the minimum support for altcore. Data is keyed according to the\n        bitcore specification.\n        \"\"\"\n        ret = []\n        for symbol in self.supported_currencies(project='altcore', level=\"address\"):\n            data = crypto_data[symbol]\n            priv = data.get('private_key_prefix')\n            pub = data.get('address_version_byte')\n            hha = data.get('header_hash_algo')\n            shb = data.get('script_hash_byte')\n\n            supported = collections.OrderedDict()\n            supported['name'] = data['name']\n            supported['alias'] = symbol\n\n            if pub is not None:\n                supported['pubkeyhash'] = int(pub)\n            if priv:\n                supported['privatekey'] = priv\n            supported['scripthash'] = shb if shb else 5\n            if 'transaction_form' in data:\n                supported['transactionForm'] = data['transaction_form']\n            if 'private_key_form' in data:\n                supported['privateKeyForm'] = data['private_key_form']\n            #if 'message_magic' in data and data['message_magic']:\n            #    supported['networkMagic'] = '0x%s' % binascii.hexlify(data['message_magic'])\n            supported['port'] = data.get('port') or None\n            if hha not in (None, 'double-sha256'):\n                supported['headerHashAlgo'] = hha\n            if data.get('script_hash_algo', 'double-sha256') not in (None, 'double-sha256'):\n                supported['scriptHashAlgo'] = data['script_hash_algo']\n            if data.get('transaction_hash_algo', 'double-sha256') not in (None, 'double-sha256'):\n                supported['transactionHashAlgo'] = data['transaction_hash_algo']\n            if data.get('seed_nodes'):\n                supported['dnsSeeds'] = data['seed_nodes']\n\n            ret.append(supported)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef modify_mempool(mempool, remove=0, add=0, verbose=False):\n    for i in range(remove):\n        popped = mempool.pop()\n        if verbose: print(\"removed:\", popped)\n\n    for i in range(add):\n        new_txid = _make_txid()\n        mempool.append(new_txid)\n        if verbose: print(\"added:\", new_txid)\n\n    return mempool", "response": "Modify a list of items in a mempool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_unit_to_satoshi(self, value, unit='satoshi'):\n        if not unit or unit == 'satoshi':\n            return value\n        if unit == 'bitcoin' or unit == 'btc':\n            return value * 1e8\n\n        # assume fiat currency that we can convert\n        convert = get_current_price(self.crypto, unit)\n        return int(value / convert * 1e8)", "response": "Convert a value to satoshis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_raw_inputs(self, inputs, private_key=None):\n        for i in inputs:\n            self.ins.append(dict(input=i, private_key=private_key))\n            self.change_address = i['address']", "response": "Add a list of utxo s to this transaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting utxos from the remote service.", "response": "def _get_utxos(self, address, services, **modes):\n        \"\"\"\n        Using the service fallback engine, get utxos from remote service.\n        \"\"\"\n        return get_unspent_outputs(\n            self.crypto, address, services=services,\n            **modes\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef private_key_to_address(self, pk):\n        pub = privtopub(pk)\n        pub_byte, priv_byte = get_magic_bytes(self.crypto)\n\n        if priv_byte >= 128:\n            priv_byte -= 128 #pybitcointools bug\n\n        return pubtoaddr(pub, pub_byte)", "response": "Convert a private key in hex format into an address."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_inputs(self, private_key=None, address=None, amount='all', max_ins=None, password=None, services=None, **modes):\n        if private_key:\n            if private_key.startswith('6P'):\n                if not password:\n                    raise Exception(\"Password required for BIP38 encoded private keys\")\n                from .bip38 import Bip38EncryptedPrivateKey\n                private_key = Bip38EncryptedPrivateKey(self.crypto, private_key).decrypt(password)\n\n            address_from_priv = self.private_key_to_address(private_key)\n            if address and address != address_from_priv:\n                raise Exception(\"Invalid Private key\")\n            address = address_from_priv\n            self.change_address = address\n\n        if not services:\n            services = get_optimal_services(self.crypto, 'unspent_outputs')\n\n        total_added_satoshi = 0\n        ins = 0\n        for utxo in self._get_utxos(address, services, **modes):\n            if max_ins and ins >= max_ins:\n                break\n            if (amount == 'all' or total_added_satoshi < amount):\n                ins += 1\n                self.ins.append(\n                    dict(input=utxo, private_key=private_key)\n                )\n                total_added_satoshi += utxo['amount']\n\n        return total_added_satoshi, ins", "response": "Add inputs to the transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef total_input_satoshis(self):\n        just_inputs = [x['input'] for x in self.ins]\n        return sum([x['amount'] for x in just_inputs])", "response": "Get the total satoshis coming from all inputs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an output to the list of outputs.", "response": "def add_output(self, address, value, unit='satoshi'):\n        \"\"\"\n        Add an output (a person who will receive funds via this tx).\n        If no unit is specified, satoshi is implied.\n        \"\"\"\n        value_satoshi = self.from_unit_to_satoshi(value, unit)\n\n        if self.verbose:\n            print(\"Adding output of: %s satoshi (%.8f)\" % (\n                value_satoshi, (value_satoshi / 1e8)\n            ))\n\n        self.outs.append({\n            'address': address,\n            'value': value_satoshi\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onchain_exchange(self, withdraw_crypto, withdraw_address, value, unit='satoshi'):\n        self.onchain_rate = get_onchain_exchange_rates(\n            self.crypto, withdraw_crypto, best=True, verbose=self.verbose\n        )\n        exchange_rate = float(self.onchain_rate['rate'])\n        result = self.onchain_rate['service'].get_onchain_exchange_address(\n            self.crypto, withdraw_crypto, withdraw_address\n        )\n\n        address = result['deposit']\n\n        value_satoshi = self.from_unit_to_satoshi(value, unit)\n\n        if self.verbose:\n            print(\"Adding output of: %s satoshi (%.8f) via onchain exchange, converting to %s %s\" % (\n                value_satoshi, (value_satoshi / 1e8),\n                exchange_rate * value_satoshi / 1e8, withdraw_crypto.upper()\n            ))\n\n        self.outs.append({\n            'address': address,\n            'value': value_satoshi\n        })", "response": "This method is like add_output but it sends to another onchain exchange"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the miner fee for the current class.", "response": "def fee(self, value=None, unit='satoshi'):\n        \"\"\"\n        Set the miner fee, if unit is not set, assumes value is satoshi.\n        If using 'optimal', make sure you have already added all outputs.\n        \"\"\"\n        convert = None\n        if not value:\n            # no fee was specified, use $0.02 as default.\n            convert = get_current_price(self.crypto, \"usd\")\n            self.fee_satoshi = int(0.02 / convert * 1e8)\n            verbose = \"Using default fee of:\"\n\n        elif value == 'optimal':\n            self.fee_satoshi = get_optimal_fee(\n                self.crypto, self.estimate_size(), verbose=self.verbose\n            )\n            verbose = \"Using optimal fee of:\"\n        else:\n            self.fee_satoshi = self.from_unit_to_satoshi(value, unit)\n            verbose = \"Using manually set fee of:\"\n\n        if self.verbose:\n            if not convert:\n                convert = get_current_price(self.crypto, \"usd\")\n            fee_dollar = convert * self.fee_satoshi / 1e8\n            print(verbose + \" %s satoshis ($%.2f)\" % (self.fee_satoshi, fee_dollar))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estimate_size(self):\n        # if there are no outs use 1 (because the change will be an out)\n        outs = len(self.outs) or 1\n        return outs * 34 + 148 * len(self.ins) + 10", "response": "Estimate the size of the current node s record store."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a hex transaction from the inputs and outputs.", "response": "def get_hex(self, signed=True):\n        \"\"\"\n        Given all the data the user has given so far, make the hex using pybitcointools\n        \"\"\"\n        total_ins_satoshi = self.total_input_satoshis()\n        if total_ins_satoshi == 0:\n            raise ValueError(\"Can't make transaction, there are zero inputs\")\n\n        # Note: there can be zero outs (sweep or coalesc transactions)\n        total_outs_satoshi = sum([x['value'] for x in self.outs])\n\n        if not self.fee_satoshi:\n            self.fee() # use default of $0.02\n\n        change_satoshi = total_ins_satoshi - (total_outs_satoshi + self.fee_satoshi)\n\n        if change_satoshi < 0:\n            raise ValueError(\n                \"Input amount (%s) must be more than all output amounts (%s) plus fees (%s). You need more %s.\"\n                % (total_ins_satoshi, total_outs_satoshi, self.fee_satoshi, self.crypto.upper())\n            )\n\n        ins = [x['input'] for x in self.ins]\n\n        if change_satoshi > 0:\n            if self.verbose:\n                print(\"Adding change address of %s satoshis to %s\" % (change_satoshi, self.change_address))\n            change = [{'value': change_satoshi, 'address': self.change_address}]\n        else:\n            change = [] # no change ?!\n            if self.verbose: print(\"Inputs == Outputs, no change address needed.\")\n\n        tx = mktx(ins, self.outs + change)\n\n        if signed:\n            for i, input_data in enumerate(self.ins):\n                if not input_data['private_key']:\n                    raise Exception(\"Can't sign transaction, missing private key for input %s\" % i)\n                tx = sign(tx, i, input_data['private_key'])\n\n        return tx"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gen_primes():\n    D = {}\n    q = 2\n    while True:\n        if q not in D:\n            yield q\n            D[q * q] = [q]\n        else:\n            for p in D[q]:\n                D.setdefault(p + q, []).append(p)\n            del D[q]\n\n        q += 1", "response": "Generate an infinite sequence of prime numbers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_current_price(crypto, fiat, services=None, convert_to=None, helper_prices=None, **modes):\n    fiat = fiat.lower()\n    args = {'crypto': crypto, 'fiat': fiat, 'convert_to': convert_to}\n\n    if not services:\n        services = get_optimal_services(crypto, 'current_price')\n\n    if fiat in services:\n        # first, try service with explicit fiat support\n        try_services = services[fiat]\n        result = _try_price_fetch(try_services, args, modes)\n        if not isinstance(result, Exception):\n            return result\n\n    if '*' in services:\n        # then try wildcard service\n        try_services = services['*']\n        result = _try_price_fetch(try_services, args, modes)\n        if not isinstance(result, Exception):\n            return result\n\n    def _do_composite_price_fetch(crypto, convert_crypto, fiat, helpers, modes):\n        before = modes.get('report_services', False)\n        modes['report_services'] = True\n        services1, converted_price = get_current_price(crypto, convert_crypto, **modes)\n        if not helpers or convert_crypto not in helpers[fiat]:\n            services2, fiat_price = get_current_price(convert_crypto, fiat, **modes)\n        else:\n            services2, fiat_price = helpers[fiat][convert_crypto]\n\n        modes['report_services'] = before\n\n        if modes.get('report_services', False):\n            #print(\"composit service:\", crypto, fiat, services1, services2)\n            serv = CompositeService(services1, services2, convert_crypto)\n            return [serv], converted_price * fiat_price\n        else:\n            return converted_price * fiat_price\n\n    all_composite_cryptos = ['btc', 'ltc', 'doge', 'uno']\n    if crypto in all_composite_cryptos: all_composite_cryptos.remove(crypto)\n    for composite_attempt in all_composite_cryptos:\n        if composite_attempt in services and services[composite_attempt]:\n            result = _do_composite_price_fetch(\n                crypto, composite_attempt, fiat, helper_prices, modes\n            )\n            if not isinstance(result, Exception):\n                return result\n\n    raise result", "response": "Returns the current exchange rate for a cryptocurrency."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the optimal fee based on how big the transaction is.", "response": "def get_optimal_fee(crypto, tx_bytes, **modes):\n    \"\"\"\n    Get the optimal fee based on how big the transaction is. Currently this\n    is only provided for BTC. Other currencies will return $0.02 in satoshi.\n    \"\"\"\n    try:\n        services = get_optimal_services(crypto, 'get_optimal_fee')\n    except NoServicesDefined:\n        convert = get_current_price(crypto, 'usd')\n        fee = int(0.02 / convert * 1e8)\n\n        if modes.get('report_services'):\n            return [None], fee\n        else:\n            return fee\n\n    fee = enforce_service_mode(\n        services, OptimalFee, dict(crypto=crypto, tx_bytes=tx_bytes), modes=modes\n    )\n    if modes.get('report_services'):\n        return fee[0], int(fee[1])\n    else:\n        return int(fee)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget exchange rates for all defined on - chain exchange services.", "response": "def get_onchain_exchange_rates(deposit_crypto=None, withdraw_crypto=None, **modes):\n    \"\"\"\n    Gets exchange rates for all defined on-chain exchange services.\n    \"\"\"\n    from moneywagon.onchain_exchange import ALL_SERVICES\n\n    rates = []\n    for Service in ALL_SERVICES:\n        srv = Service(verbose=modes.get('verbose', False))\n        rates.extend(srv.onchain_exchange_rates())\n\n    if deposit_crypto:\n        rates = [x for x in rates if x['deposit_currency']['code'] == deposit_crypto.upper()]\n\n    if withdraw_crypto:\n        rates = [x for x in rates if x['withdraw_currency']['code'] == withdraw_crypto.upper()]\n\n    if modes.get('best', False):\n        return max(rates, key=lambda x: float(x['rate']))\n\n    return rates"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_keypair(crypto, seed, password=None):\n    if crypto in ['eth', 'etc']:\n        raise CurrencyNotSupported(\"Ethereums not yet supported\")\n\n    pub_byte, priv_byte = get_magic_bytes(crypto)\n    priv = sha256(seed)\n    pub = privtopub(priv)\n\n    priv_wif = encode_privkey(priv, 'wif_compressed', vbyte=priv_byte)\n    if password:\n        # pycrypto etc. must be installed or this will raise ImportError, hence inline import.\n        from .bip38 import Bip38EncryptedPrivateKey\n        priv_wif = str(Bip38EncryptedPrivateKey.encrypt(crypto, priv_wif, password))\n\n    compressed_pub = encode_pubkey(pub, 'hex_compressed')\n    ret = {\n        'public': {\n            'hex_uncompressed': pub,\n            'hex': compressed_pub,\n            'address': pubtoaddr(compressed_pub, pub_byte)\n        },\n        'private': {\n            'wif': priv_wif\n        }\n    }\n    if not password:\n        # only these are valid when no bip38 password is supplied\n        ret['private']['hex'] = encode_privkey(priv, 'hex_compressed', vbyte=priv_byte)\n        ret['private']['hex_uncompressed'] = encode_privkey(priv, 'hex', vbyte=priv_byte)\n        ret['private']['wif_uncompressed'] = encode_privkey(priv, 'wif', vbyte=priv_byte)\n\n    return ret", "response": "Generate a private key and publickey for any currency given a seed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sweep(crypto, private_key, to_address, fee=None, password=None, **modes):\n    from moneywagon.tx import Transaction\n    tx = Transaction(crypto, verbose=modes.get('verbose', False))\n    tx.add_inputs(private_key=private_key, password=password, **modes)\n    tx.change_address = to_address\n    tx.fee(fee)\n\n    return tx.push()", "response": "Move all funds by private key to another address."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a crypto address find which currency it likely belongs to.", "response": "def guess_currency_from_address(address):\n    \"\"\"\n    Given a crypto address, find which currency it likely belongs to.\n    Raises an exception if it can't find a match. Raises exception if address\n    is invalid.\n    \"\"\"\n    if is_py2:\n        fixer = lambda x: int(x.encode('hex'), 16)\n    else:\n        fixer = lambda x: x # does nothing\n\n    first_byte = fixer(b58decode_check(address)[0])\n    double_first_byte = fixer(b58decode_check(address)[:2])\n\n    hits = []\n    for currency, data in crypto_data.items():\n        if hasattr(data, 'get'): # skip incomplete data listings\n            version = data.get('address_version_byte', None)\n            if version is not None and version in [double_first_byte, first_byte]:\n                hits.append([currency, data['name']])\n\n    if hits:\n        return hits\n\n    raise ValueError(\"Unknown Currency with first byte: %s\" % first_byte)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the passed in address or any base58 encoded string and change the version byte to new_version.", "response": "def change_version_byte(address, new_version=None, new_crypto=None):\n    \"\"\"\n    Convert the passed in address (or any base58 encoded string), and change the\n    version byte to `new_version`.\n    \"\"\"\n    if not new_version and new_crypto:\n        try:\n            new_version = crypto_data[new_crypto]['address_version_byte']\n        except KeyError:\n            raise CurrencyNotSupported(\"Unknown currency symbol: \" + new_crypto)\n\n        if not new_version:\n            raise CurrencyNotSupported(\"Can't yet make %s addresses.\" % new_crypto)\n\n    payload = b58decode_check(address)[1:]\n    if is_py2:\n        byte = chr(new_version)\n    else:\n        byte = bytes(chr(new_version), 'ascii')\n\n    return b58encode_check(byte + payload)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef service_table(format='simple', authenticated=False):\n    if authenticated:\n        all_services = ExchangeUniverse.get_authenticated_services()\n    else:\n        all_services = ALL_SERVICES\n\n    if format == 'html':\n        linkify = lambda x: \"<a href='{0}' target='_blank'>{0}</a>\".format(x)\n    else:\n        linkify = lambda x: x\n\n    ret = []\n    for service in sorted(all_services, key=lambda x: x.service_id):\n        ret.append([\n            service.service_id,\n            service.__name__, linkify(service.api_homepage.format(\n                domain=service.domain, protocol=service.protocol\n            )),\n            \", \".join(service.supported_cryptos or [])\n        ])\n\n    return tabulate(ret, headers=['ID', 'Name', 'URL', 'Supported Currencies'], tablefmt=format)", "response": "Returns a string that contains all services currently installed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_pair(self, crypto=\"\", fiat=\"\", verbose=False):\n        self.fetch_pairs()\n        if not crypto and not fiat:\n            raise Exception(\"Fiat or Crypto required\")\n\n        def is_matched(crypto, fiat, pair):\n            if crypto and not fiat:\n                return pair.startswith(\"%s-\" % crypto)\n            if crypto and fiat:\n                return pair == \"%s-%s\" % (crypto, fiat)\n            if not crypto:\n                return pair.endswith(\"-%s\" % fiat)\n\n        matched_pairs = {}\n        for Service, pairs in self._all_pairs.items():\n            matched = [p for p in pairs if is_matched(crypto, fiat, p)]\n            if matched:\n                matched_pairs[Service] = matched\n\n        return matched_pairs", "response": "This utility is used to find an exchange that supports a given exchange pair."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_balances(currency, services=None, verbose=False, timeout=None):\n    balances = {}\n    if not services:\n        services = [\n            x(verbose=verbose, timeout=timeout)\n            for x in ExchangeUniverse.get_authenticated_services()\n        ]\n\n    for e in services:\n        try:\n            balances[e] = e.get_exchange_balance(currency)\n        except NotImplementedError:\n            if verbose:\n                print(e.name, \"balance not implemented\")\n        except Exception as exc:\n            if verbose:\n                print(e.name, \"failed:\", exc.__class__.__name__, str(exc))\n\n    return balances", "response": "Get balances for passed in currency for all exchanges."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef total_exchange_balances(services=None, verbose=None, timeout=None, by_service=False):\n    balances = defaultdict(lambda: 0)\n    if not services:\n        services = [\n            x(verbose=verbose, timeout=timeout)\n            for x in ExchangeUniverse.get_authenticated_services()\n        ]\n\n    for e in services:\n        try:\n            more_balances = e.get_total_exchange_balances()\n            if by_service:\n                balances[e.__class__] = more_balances\n            else:\n                for code, bal in more_balances.items():\n                    balances[code] += bal\n        except NotImplementedError:\n            if verbose:\n                print(e.name, \"total balance not implemented\")\n        except Exception as exc:\n            if verbose:\n                print(e.name, \"failed:\", exc.__class__.__name__, str(exc))\n\n    return balances", "response": "Returns all balances for all exchanges in a single order"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _trim(self, book, balances, side):\n        new_book = []\n        for service, balance in balances.items():\n            accumulation = 0\n            for order in book:\n                if order[2].name == service.name:\n                    if side == 'crypto':\n                        size = order[1]\n                    else:\n                        size = order[1] * order[0] # convert to fiat\n\n                    if size + accumulation <= balance:\n                        new_book.append(order)\n                        accumulation += size\n                    else:\n                        remaining = balance - accumulation\n                        new_book.append([order[0], float(\"%.8f\" % remaining), order[2]])\n                        break\n\n        return sorted(new_book, key=lambda x: x[0], reverse=side == 'fiat')", "response": "Returns a list of all the orderbooks that are in the given orderbook."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compress(x, y):\n    polarity = \"02\" if y % 2 == 0 else \"03\"\n\n    wrap = lambda x: x\n    if not is_py2:\n        wrap = lambda x: bytes(x, 'ascii')\n\n    return unhexlify(wrap(\"%s%0.64x\" % (polarity, x)))", "response": "Encode a x y coordinate in compressed format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uncompress(payload):\n    payload = hexlify(payload)\n    even = payload[:2] == b\"02\"\n    x = int(payload[2:], 16)\n    beta = pow(int(x ** 3 + A * x + B), int((P + 1) // 4), int(P))\n    y = (P-beta) if even else beta\n    return x, y", "response": "Given a compressed ec key in bytes uncompress it using math and return x y"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decrypt(self, passphrase, wif=False):\n        passphrase = normalize('NFC', unicode(passphrase))\n        if is_py2:\n            passphrase = passphrase.encode('utf8')\n\n        if self.ec_multiply:\n            raise Exception(\"Not supported yet\")\n\n        key = scrypt.hash(passphrase, self.addresshash, 16384, 8, 8)\n        derivedhalf1 = key[0:32]\n        derivedhalf2 = key[32:64]\n\n        aes = AES.new(derivedhalf2)\n        decryptedhalf2 = aes.decrypt(self.encryptedhalf2)\n        decryptedhalf1 = aes.decrypt(self.encryptedhalf1)\n        priv = decryptedhalf1 + decryptedhalf2\n        priv = unhexlify('%064x' % (long(hexlify(priv), 16) ^ long(hexlify(derivedhalf1), 16)))\n        pub = privtopub(priv)\n\n        if self.compressed:\n            pub = encode_pubkey(pub, 'hex_compressed')\n        addr = pubtoaddr(pub, self.pub_byte)\n\n        if is_py2:\n            ascii_key = addr\n        else:\n            ascii_key = bytes(addr,'ascii')\n\n        if sha256(sha256(ascii_key).digest()).digest()[0:4] != self.addresshash:\n            raise Exception('Bip38 password decrypt failed: Wrong password?')\n        else:\n            formatt = 'wif' if wif else 'hex'\n            if self.compressed:\n                return encode_privkey(priv, formatt + '_compressed', self.priv_byte)\n            else:\n                return encode_privkey(priv, formatt, self.priv_byte)", "response": "Decrypts the private key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt(cls, crypto, privkey, passphrase):\n        pub_byte, priv_byte = get_magic_bytes(crypto)\n        privformat = get_privkey_format(privkey)\n        if privformat in ['wif_compressed','hex_compressed']:\n            compressed = True\n            flagbyte = b'\\xe0'\n            if privformat == 'wif_compressed':\n                privkey = encode_privkey(privkey, 'hex_compressed')\n                privformat = get_privkey_format(privkey)\n        if privformat in ['wif', 'hex']:\n            compressed = False\n            flagbyte = b'\\xc0'\n        if privformat == 'wif':\n            privkey = encode_privkey(privkey,'hex')\n            privformat = get_privkey_format(privkey)\n\n        pubkey = privtopub(privkey)\n        addr = pubtoaddr(pubkey, pub_byte)\n\n        passphrase = normalize('NFC', unicode(passphrase))\n        if is_py2:\n            ascii_key = addr\n            passphrase = passphrase.encode('utf8')\n        else:\n            ascii_key = bytes(addr,'ascii')\n\n        salt = sha256(sha256(ascii_key).digest()).digest()[0:4]\n        key = scrypt.hash(passphrase, salt, 16384, 8, 8)\n        derivedhalf1, derivedhalf2 = key[:32], key[32:]\n\n        aes = AES.new(derivedhalf2)\n        encryptedhalf1 = aes.encrypt(unhexlify('%0.32x' % (long(privkey[0:32], 16) ^ long(hexlify(derivedhalf1[0:16]), 16))))\n        encryptedhalf2 = aes.encrypt(unhexlify('%0.32x' % (long(privkey[32:64], 16) ^ long(hexlify(derivedhalf1[16:32]), 16))))\n\n        # 39 bytes    2 (6P)      1(R/Y)    4          16               16\n        payload = b'\\x01\\x42' + flagbyte + salt + encryptedhalf1 + encryptedhalf2\n        return cls(crypto, b58encode_check(payload))", "response": "This function encrypts the privkey and returns the encrypted privkey."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_from_intermediate(cls, crypto, intermediate_point, seed, compressed=True, include_cfrm=True):\n        flagbyte = b'\\x20' if compressed else b'\\x00'\n        payload = b58decode_check(str(intermediate_point))\n        ownerentropy = payload[8:16]\n\n        passpoint = payload[16:-4]\n        x, y = uncompress(passpoint)\n\n        if not is_py2:\n            seed = bytes(seed, 'ascii')\n\n        seedb = hexlify(sha256(seed).digest())[:24]\n        factorb = int(hexlify(sha256(sha256(seedb).digest()).digest()), 16)\n        generatedaddress = pubtoaddr(fast_multiply((x, y), factorb))\n\n        wrap = lambda x: x\n        if not is_py2:\n            wrap = lambda x: bytes(x, 'ascii')\n\n        addresshash = sha256(sha256(wrap(generatedaddress)).digest()).digest()[:4]\n\n        encrypted_seedb = scrypt.hash(passpoint, addresshash + ownerentropy, 1024, 1, 1, 64)\n        derivedhalf1, derivedhalf2 = encrypted_seedb[:32], encrypted_seedb[32:]\n\n        aes = AES.new(derivedhalf2)\n        block1 = long(seedb[0:16], 16) ^ long(hexlify(derivedhalf1[0:16]), 16)\n        encryptedpart1 = aes.encrypt(unhexlify('%0.32x' % block1))\n\n        block2 = long(hexlify(encryptedpart1[8:16]) + seedb[16:24], 16) ^ long(hexlify(derivedhalf1[16:32]), 16)\n        encryptedpart2 = aes.encrypt(unhexlify('%0.32x' % block2))\n\n        # 39 bytes      2           1           4              8                8                 16\n        payload = b\"\\x01\\x43\" + flagbyte + addresshash + ownerentropy + encryptedpart1[:8] + encryptedpart2\n        encrypted_pk = b58encode_check(payload)\n\n        if not include_cfrm:\n            return generatedaddress, encrypted_pk\n\n        confirmation_code = Bip38ConfirmationCode.create(flagbyte, ownerentropy, factorb, derivedhalf1, derivedhalf2, addresshash)\n        return generatedaddress, cls(crypto, encrypted_pk), confirmation_code", "response": "Generate an instance of the class from an intermediate point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_address(self, passphrase):\n\n        inter = Bip38IntermediatePoint.create(passphrase, ownersalt=self.ownersalt)\n\n        public_key = privtopub(inter.passpoint)\n\n        # from Bip38EncryptedPrivateKey.create_from_intermediate\n        derived = scrypt.hash(inter.passpoint, self.addresshash + inter.ownerentropy, 1024, 1, 1, 64)\n        derivedhalf1, derivedhalf2 = derived[:32], derived[32:]\n\n        unencrypted_prefix = bytes_to_int(self.pointbprefix) ^ (bytes_to_int(derived[63]) & 0x01);\n\n        aes = AES.new(derivedhalf2)\n        block1 = aes.decrypt(self.pointbx1)\n        block2 = aes.decrypt(self.pointbx2)\n\n        raise Exception(\"Not done yet\")\n\n        return\n        block2 = long(hexlify(pointb2), 16) ^ long(hexlify(derivedhalf1[16:]), 16)\n\n\n        return pubtoaddr(*fast_multiply(pointb, passfactor))", "response": "Generate a new address for the given password and address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push_tx(self, crypto, tx_hex):\n        url = \"%s/pushtx\" % self.base_url\n        return self.post_url(url, {'hex': tx_hex}).content", "response": "This method is untested."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the balances of the given list of wallets.", "response": "def fetch_wallet_balances(wallets, fiat, **modes):\n    \"\"\"\n    Wallets must be list of two item lists. First item is crypto, second item\n    is the address. example:\n\n    [\n        ['btc', '1PZ3Ps9RvCmUW1s1rHE25FeR8vtKUrhEai'],\n        ['ltc', 'Lb78JDGxMcih1gs3AirMeRW6jaG5V9hwFZ']\n    ]\n    \"\"\"\n    price_fetch = set([x[0] for x in wallets])\n    balances = {}\n    prices = {}\n\n    fetch_length = len(wallets) + len(price_fetch)\n\n    helpers = {fiat.lower(): {}}\n    if not modes.get('async', False):\n        # synchronous fetching\n        for crypto in price_fetch:\n            try:\n                p = get_current_price(\n                    crypto, fiat, helper_prices=helpers, report_services=True, **modes\n                )\n                prices[crypto] = {'price': p}\n                if crypto in ['btc', 'ltc', 'doge', 'uno']:\n                    helpers[fiat.lower()][crypto] = p\n            except NoService as exc:\n                prices[crypto] = {'error': str(exc)}\n\n        for crypto, address in wallets:\n            if address.replace('.', '').isdigit():\n                balances[address] = {'balance': float(address)}\n                continue\n\n            try:\n                balances[address] = {'balance': get_address_balance(crypto, address.strip(), **modes)}\n            except NoService as exc:\n                balances[address] = {'error': str(exc)}\n\n    else:\n        # asynchronous fetching\n        if modes.get('verbose', False):\n            print(\"Need to make\", fetch_length, \"external calls\")\n\n        with futures.ThreadPoolExecutor(max_workers=int(fetch_length / 2)) as executor:\n            future_to_key = dict(\n                (executor.submit(\n                    get_current_price, crypto, fiat, report_services=True, **modes\n                ), crypto) for crypto in price_fetch\n            )\n\n            future_to_key.update(dict(\n                (executor.submit(\n                    get_address_balance, crypto, address.strip(), **modes\n                ), address) for crypto, address in wallets\n            ))\n\n            done, not_done = futures.wait(future_to_key, return_when=futures.ALL_COMPLETED)\n            if len(not_done) > 0:\n                print (not_done)\n                import debug\n                raise Exception(\"Broke\") #not_done.pop().exception()\n\n            for future in done:\n                key = future_to_key[future]\n                if len(key) > 5: # this will break if a crypto symbol is longer than 5 chars.\n                    which = balances\n                else:\n                    which = prices\n\n                res = future.result()\n                which[key] = res\n\n    ret = []\n\n    for crypto, address in wallets:\n        error = None\n        if 'balance' in balances[address]:\n            crypto_value = balances[address]['balance']\n        else:\n            crypto_value = 0\n            error = balances[address]['error']\n\n        if 'price' in prices[crypto]:\n            sources, fiat_price = prices[crypto]['price']\n        else:\n            sources, fiat_price = [], 0\n            error = prices[crypto]['error']\n\n        ret.append({\n            'crypto': crypto,\n            'address': address,\n            'crypto_value': crypto_value,\n            'fiat_value': (crypto_value or 0) * (fiat_price or 0),\n            'conversion_price': fiat_price,\n            'price_source': sources[0].name if sources else \"None\",\n            'error': error\n        })\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replay_block(self, block_to_replay, limit=5):\n\n        if block_to_replay == 'latest':\n            if self.verbose:\n                print(\"Getting latest %s block header\" % source.upper())\n            block = get_block(self.source, latest=True, verbose=self.verbose)\n            if self.verbose:\n                print(\"Latest %s block is #%s\" % (self.source.upper(), block['block_number']))\n        else:\n            blocknum = block_to_replay if type(block_to_replay) == int else block_to_replay['block_number']\n            if blocknum < self.parent_fork_block or blocknum < self.child_fork_block:\n                raise Exception(\"Can't replay blocks mined before the fork\")\n\n        if type(block_to_replay) is not dict:\n            if self.verbose:\n                print(\"Getting %s block header #%s\" % (self.source.upper(), block_to_replay))\n            block = get_block(self.source, block_number=int(block_to_replay), verbose=self.verbose)\n        else:\n            block = block_to_replay\n\n        if self.verbose:\n            print(\"Using %s for pushing to %s\" % (self.pusher.name, self.destination.upper()))\n            print(\"Using %s for getting %s transactions\" % (self.tx_fetcher.name, self.source.upper()))\n            print(\"Finished getting block header,\", len(block['txids']), \"transactions in block, will replay\", (limit or \"all of them\"))\n\n        results = []\n        enforced_limit = (limit or len(block['txids']))\n\n        for i, txid in enumerate(block['txids'][:enforced_limit]):\n            print(\"outside\", txid)\n            self._replay_tx(txid, i)", "response": "Replay all transactions in source currency to passed in block_to_replay."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all curencies that have a service defined that implements get_block.", "response": "def get_block_currencies():\n    \"\"\"\n    Returns a list of all curencies (by code) that have a service defined that\n    implements `get_block`.\n    \"\"\"\n    return ['btc', 'ltc', 'ppc', 'dash', 'doge', 'ric']\n    currencies = []\n    for currency, data in crypto_data.items():\n        if type(data) is list:\n            continue\n        block_services = data.get('services', {}).get('get_block', [])\n        if len(block_services) > 0 and not all([x.get_block.by_latest for x in block_services]):\n\n            currencies.append(currency)\n\n    return currencies"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _per_era_supply(self, block_height):\n        coins = 0\n        for era in self.supply_data['eras']:\n            end_block = era['end']\n            start_block = era['start']\n            reward = era['reward']\n\n            if not end_block or block_height <= end_block:\n                blocks_this_era = block_height - start_block\n                coins += blocks_this_era * reward\n                break\n\n            blocks_per_era = end_block - start_block\n            coins += reward * blocks_per_era\n\n        return coins", "response": "Calculate the coin supply based on the erases defined in crypto_data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the supply of coins for a given block height.", "response": "def _standard_supply(self, block_height):\n        \"\"\"\n        Calculate the supply of coins for a given time (in either datetime, or\n        block height) for coins that use the \"standard\" method of halfing.\n        \"\"\"\n        start_coins_per_block = self.supply_data['start_coins_per_block']\n        minutes_per_block = self.supply_data['minutes_per_block']\n        blocks_per_era = self.supply_data['blocks_per_era']\n        full_cap = self.supply_data.get('full_cap')\n\n        if not full_cap:\n            full_cap = 100000000000 # nearly infinite\n\n        coins = 0\n        for era, start_block in enumerate(range(0, full_cap, blocks_per_era), 1):\n            end_block = start_block + blocks_per_era\n            reward = start_coins_per_block / float(2 ** (era - 1))\n            if block_height < end_block:\n                blocks_this_era = block_height - start_block\n                coins += blocks_this_era * reward\n                break\n\n            coins += reward * blocks_per_era\n\n        return coins"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enforce_service_mode(services, FetcherClass, kwargs, modes):\n    fast_level = modes.get('fast', 0)\n    average_level = modes.get('average', 0)\n    paranoid_level = modes.get('paranoid', 0)\n    private_level = modes.get('private', 0)\n    verbose = modes.get('verbose', False)\n    timeout = modes.get('timeout', None)\n\n    if len(services) == 0:\n        raise NoService(\"No services defined\")\n\n    if modes.get('random', False):\n        random.shuffle(services)\n\n    if private_level  > 0:\n        results = _do_private_mode(\n            FetcherClass, services, kwargs, random_wait_seconds=private_level,\n            verbose=verbose, timeout=timeout\n        )\n        return results\n\n    elif average_level <= 1 and paranoid_level <= 1 and fast_level == 0:\n        # only need to make 1 external call, no need for threading...\n        fetcher = FetcherClass(services=services, verbose=verbose, timeout=timeout)\n        consensus_results = fetcher.action(**kwargs)\n        used_services = [fetcher._successful_service]\n\n    elif average_level > 1:\n        # instead of checking that all results are the same, we just return the average of all results.\n        # mostly useful for non-blockchain operations like price and optimal fee.\n        results = _get_results(\n            FetcherClass, services, kwargs, num_results=average_level, verbose=verbose, timeout=timeout\n        )\n\n        to_compare, used_services = _prepare_consensus(FetcherClass, results)\n        consensus_results = sum(to_compare) / len(to_compare)\n\n    elif paranoid_level > 1:\n        results = _get_results(\n            FetcherClass, services, kwargs, num_results=paranoid_level, verbose=verbose, timeout=timeout\n        )\n        to_compare, used_services = _prepare_consensus(FetcherClass, results)\n\n        if len(set(to_compare)) > 1:\n            full_results = zip(used_services, to_compare)\n            show_error = \", \".join(\"%s: %s\" % (s.name, v) for s, v in full_results)\n            sd = ServiceDisagreement(\"No service consensus: %s\" % show_error)\n            sd.network_results = {\n                service: result for service, result in full_results\n            }\n            raise sd\n\n        # if all values match, return any one (in this case the first one).\n        # also return the list of all services that confirm this result.\n        consensus_results = results[0][1]\n\n    elif fast_level >= 1:\n        raise Exception(\"Fast mode not yet working\")\n        results = _get_results(\n            FetcherClass, services, kwargs, fast=fast_level, verbose=verbose\n        )\n\n    else:\n        raise Exception(\"No mode specified.\")\n\n    if modes.get('report_services'):\n        return used_services, consensus_results\n    else:\n        return consensus_results", "response": "Enforces the service mode of the given services."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a list of results return a list that is simplified to make consensus determination possible.", "response": "def _prepare_consensus(FetcherClass, results):\n    \"\"\"\n    Given a list of results, return a list that is simplified to make consensus\n    determination possible. Returns two item tuple, first arg is simplified list,\n    the second argument is a list of all services used in making these results.\n    \"\"\"\n    # _get_results returns lists of 2 item list, first element is service, second is the returned value.\n    # when determining consensus amoung services, only take into account values returned.\n    if hasattr(FetcherClass, \"strip_for_consensus\"):\n        to_compare = [\n            FetcherClass.strip_for_consensus(value) for (fetcher, value) in results\n        ]\n    else:\n        to_compare = [value for fetcher, value in results]\n\n    return to_compare, [fetcher._successful_service for fetcher, values in results]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_results(FetcherClass, services, kwargs, num_results=None, fast=0, verbose=False, timeout=None):\n    results = []\n\n    if not num_results or fast:\n        num_results = len(services)\n\n    with futures.ThreadPoolExecutor(max_workers=len(services)) as executor:\n        fetches = {}\n        for service in services[:num_results]:\n            tail = [x for x in services if x is not service]\n            random.shuffle(tail)\n            srv = FetcherClass(services=[service] + tail, verbose=verbose, timeout=timeout)\n            fetches[executor.submit(srv.action, **kwargs)] = srv\n\n        if fast == 1:\n            raise NotImplementedError\n            # ths code is a work in progress. futures.FIRST_COMPLETED works differently than I thought...\n            to_iterate, still_going = futures.wait(fetches, return_when=futures.FIRST_COMPLETED)\n            for x in still_going:\n                try:\n                    x.result(timeout=1.001)\n                except futures._base.TimeoutError:\n                    pass\n\n        elif fast > 1:\n            raise Exception(\"fast level greater than 1 not yet implemented\")\n        else:\n            to_iterate = futures.as_completed(fetches)\n\n        for future in to_iterate:\n            service = fetches[future]\n            results.append([service, future.result()])\n\n    return results", "response": "Returns a list of lists of all the available services."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _do_private_mode(FetcherClass, services, kwargs, random_wait_seconds, timeout, verbose):\n    addresses = kwargs.pop('addresses')\n    results = {}\n\n    with futures.ThreadPoolExecutor(max_workers=len(addresses)) as executor:\n        fetches = {}\n        for address in addresses:\n            k = kwargs\n            k['address'] = address\n            random.shuffle(services)\n            srv = FetcherClass(\n                services=services, verbose=verbose, timeout=timeout or 5.0,\n                random_wait_seconds=random_wait_seconds\n            )\n            # address is returned because balance needs to be returned\n            # attached to the address. Other methods (get_transaction, unspent_outputs, etc)\n            # do not need to be indexed by address. (upstream they are stripped out)\n            fetches[executor.submit(srv.action, **k)] = (srv, address)\n\n        to_iterate = futures.as_completed(fetches)\n\n        for future in to_iterate:\n            service, address = fetches[future]\n            results[address] = future.result()\n\n    return results", "response": "Private mode for the internal fetch of the unspent outputs and historical transactions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a string of currency units to protocol units.", "response": "def currency_to_protocol(amount):\n    \"\"\"\n    Convert a string of 'currency units' to 'protocol units'. For instance\n    converts 19.1 bitcoin to 1910000000 satoshis.\n\n    Input is a float, output is an integer that is 1e8 times larger.\n\n    It is hard to do this conversion because multiplying\n    floats causes rounding nubers which will mess up the transactions creation\n    process.\n\n    examples:\n\n    19.1 -> 1910000000\n    0.001 -> 100000\n\n    \"\"\"\n    if type(amount) in [float, int]:\n        amount = \"%.8f\" % amount\n\n    return int(amount.replace(\".\", ''))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a tx object in the moneywagon format and converts it to the format that pybitcointools s serialize funcion takes then return in raw hex format.", "response": "def to_rawtx(tx):\n    \"\"\"\n    Take a tx object in the moneywagon format and convert it to the format\n    that pybitcointools's `serialize` funcion takes, then return in raw hex\n    format.\n    \"\"\"\n    if tx.get('hex'):\n        return tx['hex']\n\n    new_tx = {}\n\n    locktime = tx.get('locktime', 0)\n    new_tx['locktime'] = locktime\n    new_tx['version'] = tx.get('version', 1)\n    new_tx['ins'] = [\n        {\n            'outpoint': {'hash': str(x['txid']), 'index': x['n']},\n            'script': str(x['scriptSig'].replace(' ', '')),\n            'sequence': x.get('sequence', 0xFFFFFFFF if locktime == 0 else None)\n        } for x in tx['inputs']\n    ]\n\n    new_tx['outs'] = [\n        {\n            'script': str(x['scriptPubKey']),\n            'value': x['amount']\n        } for x in tx['outputs']\n    ]\n\n    return serialize(new_tx)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_error(self, response):\n        if response.status_code == 500:\n            raise ServiceError(\"500 - \" + response.content)\n\n        if response.status_code == 503:\n            if \"DDoS protection by Cloudflare\" in response.content:\n                raise ServiceError(\"Foiled by Cloudfare's DDoS protection\")\n            raise ServiceError(\"503 - Temporarily out of service.\")\n\n        if response.status_code == 429:\n            raise ServiceError(\"429 - Too many requests\")\n\n        if response.status_code == 404:\n            raise ServiceError(\"404 - Not Found\")\n\n        if response.status_code == 400:\n            raise ServiceError(\"400 - Bad Request\")", "response": "Check if the response is an error."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_currency(self, base_fiat, base_amount, target_fiat):\n        url = \"http://api.fixer.io/latest?base=%s\" % base_fiat\n        data = self.get_url(url).json()\n        try:\n            return data['rates'][target_fiat.upper()] * base_amount\n        except KeyError:\n            raise Exception(\"Can not convert %s to %s\" % (base_fiat, target_fiat))", "response": "Convert one fiat amount to another fiat"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfix the symbol in the order that they are used.", "response": "def fix_symbol(self, symbol, reverse=False):\n        \"\"\"\n        In comes a moneywagon format symbol, and returned in the symbol converted\n        to one the service can understand.\n        \"\"\"\n        if not self.symbol_mapping:\n            return symbol\n\n        for old, new in self.symbol_mapping:\n            if reverse:\n                if symbol == new:\n                    return old\n            else:\n                if symbol == old:\n                    return new\n\n        return symbol"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a market identifier from the service.", "response": "def parse_market(self, market, split_char='_'):\n        \"\"\"\n        In comes the market identifier directly from the service. Returned is\n        the crypto and fiat identifier in moneywagon format.\n        \"\"\"\n        crypto, fiat = market.lower().split(split_char)\n        return (\n            self.fix_symbol(crypto, reverse=True),\n            self.fix_symbol(fiat, reverse=True)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_market(self, crypto, fiat, seperator=\"_\"):\n        return (\"%s%s%s\" % (\n            self.fix_symbol(crypto), seperator, self.fix_symbol(fiat))\n        ).lower()", "response": "Convert a crypto and fiat to a market string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _external_request(self, method, url, *args, **kwargs):\n        self.last_url = url\n        if url in self.responses.keys() and method == 'get':\n            return self.responses[url] # return from cache if its there\n\n        headers = kwargs.pop('headers', None)\n        custom = {'User-Agent': useragent}\n        if headers:\n            headers.update(custom)\n            kwargs['headers'] = headers\n        else:\n            kwargs['headers'] = custom\n\n        if self.timeout:\n            # add timeout parameter to requests.get if one was passed in on construction...\n            kwargs['timeout'] = self.timeout\n\n        start = datetime.datetime.now()\n        response = getattr(requests, method)(url, verify=self.ssl_verify, *args, **kwargs)\n        self.total_external_fetch_duration += datetime.datetime.now() - start\n\n        if self.verbose:\n            print(\"Got Response: %s (took %s)\" % (url, (datetime.datetime.now() - start)))\n\n        self.last_raw_response = response\n\n        self.check_error(response)\n\n        if method == 'get':\n            self.responses[url] = response # cache for later\n\n        return response", "response": "Wrapper for requests. get with useragent automatically set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the block data for the given block hash and number.", "response": "def get_block(self, crypto, block_hash='', block_number='', latest=False):\n        \"\"\"\n        Get block based on either block height, block number or get the latest\n        block. Only one of the previous arguments must be passed on.\n\n        Returned is a dictionary object with the following keys:\n\n        * required fields:\n\n        block_number - int\n        size - size of block\n        time - datetime object of when the block was made\n        hash - str (must be all lowercase)\n        tx_count - int, the number of transactions included in thi block.\n\n        * optional fields:\n\n        confirmations - int\n        sent_value - total value moved from all included transactions\n        total_fees - total amount of tx fees from all included transactions\n        mining_difficulty - what the difficulty was when this block was made.\n        merkle_root - str (lower case)\n        previous_hash - str (lower case)\n        next_hash - str (lower case) (or `None` of its the latest block)\n        miner - name of miner that first relayed this block\n        version - block version\n        \"\"\"\n        raise NotImplementedError(\n            self.name + \" does not support getting getting block data. \"\n            \"Or rather it has no defined 'get_block' method.\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_order(self, crypto, fiat, amount, price, type=\"limit\"):\n        raise NotImplementedError(\n            self.name + \" does not support making orders. \"\n            \"Or rather it has no defined 'make_order' method.\"\n        )", "response": "This method buys or sells crypto on an exchange using fiat balance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries each service until one returns a response.", "response": "def _try_services(self, method_name, *args, **kwargs):\n        \"\"\"\n        Try each service until one returns a response. This function only\n        catches the bare minimum of exceptions from the service class. We want\n        exceptions to be raised so the service classes can be debugged and\n        fixed quickly.\n        \"\"\"\n        crypto = ((args and args[0]) or kwargs['crypto']).lower()\n        address = kwargs.get('address', '').lower()\n        fiat = kwargs.get('fiat', '').lower()\n\n        if not self.services:\n            raise CurrencyNotSupported(\"No services defined for %s for %s\" % (method_name, crypto))\n\n        if self.random_wait_seconds > 0:\n            # for privacy... To avoid correlating addresses to same origin\n            # only gets called before the first service call. Does not pause\n            # before each and every call.\n            pause_time = random.random() * self.random_wait_seconds\n            if self.verbose:\n                print(\"Pausing for: %.2f seconds\" % pause_time)\n            time.sleep(pause_time)\n\n        for service in self.services:\n            if service.supported_cryptos and (crypto not in service.supported_cryptos):\n                if self.verbose:\n                    print(\"SKIP:\", \"%s not supported for %s\" % (crypto, service.__class__.__name__))\n                continue\n            try:\n                if self.verbose: print(\"* Trying:\", service, crypto, \"%s%s\" % (address, fiat))\n                ret =  getattr(service, method_name)(*args, **kwargs)\n                self._successful_service = service\n                return ret\n            except (KeyError, IndexError, TypeError, ValueError,\n                    requests.exceptions.Timeout, requests.exceptions.ConnectionError) as exc:\n                # API has probably changed, therefore service class broken\n                if self.verbose: print(\"FAIL:\", service, exc.__class__.__name__, exc)\n                self._failed_services.append({\n                    'service': service,\n                    'error': \"%s %s\" % (exc.__class__.__name__, exc)\n                })\n            except NoService as exc:\n                # service classes can raise this exception if for whatever reason\n                # that service can't return a response, but maybe another one can.\n                if self.verbose: print(\"SKIP:\", exc.__class__.__name__, exc)\n                self._failed_services.append({'service': service, 'error': \"Skipped: %s\" % str(exc)})\n            except NotImplementedError as exc:\n                if self.verbose: print(\"SKIP:\", exc.__class__.__name__, exc)\n                self._failed_services.append({'service': service, 'error': \"Not Implemented\"})\n\n\n        if not self._failed_services:\n            raise NotImplementedError(\n                \"No Services defined for %s and %s\" % (crypto, method_name)\n            )\n\n        if set(x['error'] for x in self._failed_services) == set(['Not Implemented']) and method_name.endswith(\"multi\"):\n            # some currencies may not have any multi functions defined, so retry\n            # with private mode (which tries multiple services).\n            raise RevertToPrivateMode(\"All services do not implement %s service\" % method_name)\n\n        failed_msg = ', '.join(\n            [\"{service.name} -> {error}\".format(**x) for x in self._failed_services]\n        )\n        raise NoService(self.no_service_msg(*args, **kwargs) + \"! Tried: \" + failed_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eight_decimal_places(amount, format=\"str\"):\n    if type(amount) == str:\n        return amount\n    if format == 'str':\n        return \"%.8f\" % amount\n    if format == 'float':\n        return float(\"%.8f\" % amount)", "response": "Returns the amount in decimal places for the eight number of digits."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_historical_price(self, crypto, fiat, at_time):\n        # represents the 'width' of the quandl data returned (one day)\n        # if quandl ever supports data hourly or something, this can be changed\n        interval = datetime.timedelta(hours=48)\n        crypto = crypto.lower()\n        fiat = fiat.lower()\n\n        at_time = arrow.get(at_time).datetime\n\n        data = crypto_data[crypto]\n        name, date_created = data['name'], data['genesis_date']\n\n        if date_created.replace(tzinfo=pytz.utc) > at_time:\n            raise Exception(\"%s (%s) did not exist on %s\" % (name, crypto, at_time))\n\n        if crypto == 'btc':\n            # Bitcoin to fiat\n            if fiat == 'usd':\n                if at_time < datetime.datetime(2013, 2, 1, tzinfo=pytz.utc):\n                    exchange = 'MtGox'\n                else:\n                    exchange = \"Bitstamp\"\n            else:\n                exchange = quandl_exchange_btc_to_fiat[fiat.upper()]\n\n            source = \"BITCOIN/%s%s\" % (exchange.upper(), fiat.upper())\n            price_index = 1\n        else:\n            # some altcoin to bitcoin\n            if fiat != 'btc':\n                raise Exception(\"Altcoins are only available via BTC base fiat\")\n            if crypto == 'ltc':\n                source, price_index = ['BTCE/BTCLTC', 4]\n            else:\n                source, price_index = ['CRYPTOCHART/' + crypto.upper(), 1]\n\n        url = \"https://www.quandl.com/api/v1/datasets/%s.json\" % source\n        trim = \"?trim_start={0:%Y-%m-%d}&trim_end={1:%Y-%m-%d}\".format(\n            at_time - interval, at_time + interval\n        )\n\n        response = self.get_url(url + trim).json()\n        closest_distance = interval\n\n        best_price = None\n        for line in response['data']:\n            date = line[0]\n            price = line[price_index]\n            tick_date = arrow.get(date).datetime\n            distance = at_time - tick_date\n\n            if distance.total_seconds() == 0:\n                return price, source, tick_date\n\n            if distance < closest_distance:\n                closest_distance = distance\n                best_price = price\n                best_date = tick_date\n\n        if not best_price:\n            msg = \"Quandl's data source is incomplete. Could not get best price for %s/%s on %s.\" % (\n                crypto, fiat, at_time\n            )\n            raise NoData(msg)\n\n        return best_price, source, best_date", "response": "Get the historical price for a given crypto and fiat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all installed services.", "response": "def _get_all_services(crypto=None, just_exchange=False):\n    \"\"\"\n    Go through the crypto_data structure and return all list of all (unique)\n    installed services. Optionally filter by crypto-currency.\n    \"\"\"\n    from moneywagon.crypto_data import crypto_data\n\n    if not crypto:\n        # no currency specified, get all services\n        to_iterate = crypto_data.items()\n    else:\n        # limit to one currency\n        to_iterate = [(crypto, crypto_data[crypto])]\n\n    services = []\n    for currency, data in to_iterate:\n        if 'services' not in data:\n            continue\n        if currency == '':\n            continue # template\n\n        # price services are defined as dictionaries, all other services\n        # are defined as a list.\n        price_services = data['services']['current_price']\n        del data['services']['current_price']\n\n        all_services = list(price_services.values())\n        if not just_exchange:\n            all_services += list(data['services'].values())\n\n        # replace\n        data['services']['current_price'] = price_services\n\n        services.append([\n            item for sublist in all_services for item in sublist\n        ])\n\n    return sorted(\n        set([item for sublist in services for item in sublist]),\n        key=lambda x: x.__name__\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_crypto_data(github_path):\n    data = {'github_link': 'https://github.com/%s' % github_path}\n\n    content = get_content_from_github(github_path, \"chainparams.cpp\")\n    if content:\n        data.update(_get_from_chainparams(content))\n    else:\n        content = get_content_from_github(github_path, \"base58.h\")\n        if content:\n            data.update(_get_from_base58h(content))\n\n    content = get_content_from_github(github_path, \"main.cpp\")\n    if content:\n        data.update(_get_from_main(content))\n\n    return data", "response": "Extract crypto data from github file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconcatenates a sequence of arrays.", "response": "def uconcatenate(arrs, axis=0):\n    \"\"\"Concatenate a sequence of arrays.\n\n    This wrapper around numpy.concatenate preserves units. All input arrays\n    must have the same units.  See the documentation of numpy.concatenate for\n    full details.\n\n    Examples\n    --------\n    >>> from unyt import cm\n    >>> A = [1, 2, 3]*cm\n    >>> B = [2, 3, 4]*cm\n    >>> uconcatenate((A, B))\n    unyt_array([1, 2, 3, 2, 3, 4], 'cm')\n\n    \"\"\"\n    v = np.concatenate(arrs, axis=axis)\n    v = _validate_numpy_wrapper_units(v, arrs)\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ucross(arr1, arr2, registry=None, axisa=-1, axisb=-1, axisc=-1, axis=None):\n    v = np.cross(arr1, arr2, axisa=axisa, axisb=axisb, axisc=axisc, axis=axis)\n    units = arr1.units * arr2.units\n    arr = unyt_array(v, units, registry=registry)\n    return arr", "response": "Applies the cross product to two YT arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the sorted unique elements of the two input arrays. A wrapper around numpy.intersect1d that preserves units. All input arrays must have the same units. See the documentation of numpy.intersect1d for full details. Examples -------- >>> from unyt import cm >>> A = [1, 2, 3]*cm >>> B = [2, 3, 4]*cm >>> uintersect1d(A, B) unyt_array([2, 3], 'cm')", "response": "def uintersect1d(arr1, arr2, assume_unique=False):\n    \"\"\"Find the sorted unique elements of the two input arrays.\n\n    A wrapper around numpy.intersect1d that preserves units.  All input arrays\n    must have the same units.  See the documentation of numpy.intersect1d for\n    full details.\n\n    Examples\n    --------\n    >>> from unyt import cm\n    >>> A = [1, 2, 3]*cm\n    >>> B = [2, 3, 4]*cm\n    >>> uintersect1d(A, B)\n    unyt_array([2, 3], 'cm')\n\n    \"\"\"\n    v = np.intersect1d(arr1, arr2, assume_unique=assume_unique)\n    v = _validate_numpy_wrapper_units(v, [arr1, arr2])\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the union of two arrays.", "response": "def uunion1d(arr1, arr2):\n    \"\"\"Find the union of two arrays.\n\n    A wrapper around numpy.intersect1d that preserves units.  All input arrays\n    must have the same units.  See the documentation of numpy.intersect1d for\n    full details.\n\n    Examples\n    --------\n    >>> from unyt import cm\n    >>> A = [1, 2, 3]*cm\n    >>> B = [2, 3, 4]*cm\n    >>> uunion1d(A, B)\n    unyt_array([1, 2, 3, 4], 'cm')\n\n    \"\"\"\n    v = np.union1d(arr1, arr2)\n    v = _validate_numpy_wrapper_units(v, [arr1, arr2])\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unorm(data, ord=None, axis=None, keepdims=False):\n    norm = np.linalg.norm(data, ord=ord, axis=axis, keepdims=keepdims)\n    if norm.shape == ():\n        return unyt_quantity(norm, data.units)\n    return unyt_array(norm, data.units)", "response": "Matrix or vector norm that preserves units"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef udot(op1, op2):\n    dot = np.dot(op1.d, op2.d)\n    units = op1.units * op2.units\n    if dot.shape == ():\n        return unyt_quantity(dot, units)\n    return unyt_array(dot, units)", "response": "Matrix or vector dot product that preserves units"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uvstack(arrs):\n    v = np.vstack(arrs)\n    v = _validate_numpy_wrapper_units(v, arrs)\n    return v", "response": "Stack arrays in sequence vertically while preserving units"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uhstack(arrs):\n    v = np.hstack(arrs)\n    v = _validate_numpy_wrapper_units(v, arrs)\n    return v", "response": "Stack arrays in sequence horizontally while preserving units"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ustack(arrs, axis=0):\n    v = np.stack(arrs, axis=axis)\n    v = _validate_numpy_wrapper_units(v, arrs)\n    return v", "response": "Join a sequence of arrays along a new axis while preserving units."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the array to the given units in - place.", "response": "def convert_to_units(self, units, equivalence=None, **kwargs):\n        \"\"\"\n        Convert the array to the given units in-place.\n\n        Optionally, an equivalence can be specified to convert to an\n        equivalent quantity which is not in the same dimensions.\n\n        Parameters\n        ----------\n        units : Unit object or string\n            The units you want to convert to.\n        equivalence : string, optional\n            The equivalence you wish to use. To see which equivalencies\n            are supported for this object, try the ``list_equivalencies``\n            method. Default: None\n        kwargs: optional\n            Any additional keyword arguments are supplied to the equivalence\n\n        Raises\n        ------\n        If the provided unit does not have the same dimensions as the array\n        this will raise a UnitConversionError\n\n        Examples\n        --------\n\n        >>> from unyt import cm, km\n        >>> length = [3000, 2000, 1000]*cm\n        >>> length.convert_to_units('m')\n        >>> print(length)\n        [30. 20. 10.] m\n        \"\"\"\n        units = _sanitize_units_convert(units, self.units.registry)\n        if equivalence is None:\n            conv_data = _check_em_conversion(\n                self.units, units, registry=self.units.registry\n            )\n            if any(conv_data):\n                new_units, (conv_factor, offset) = _em_conversion(\n                    self.units, conv_data, units\n                )\n            else:\n                new_units = units\n                (conv_factor, offset) = self.units.get_conversion_factor(\n                    new_units, self.dtype\n                )\n\n            self.units = new_units\n            values = self.d\n            # if our dtype is an integer do the following somewhat awkward\n            # dance to change the dtype in-place. We can't use astype\n            # directly because that will create a copy and not update self\n            if self.dtype.kind in (\"u\", \"i\"):\n                # create a copy of the original data in floating point\n                # form, it's possible this may lose precision for very\n                # large integers\n                dsize = values.dtype.itemsize\n                new_dtype = \"f\" + str(dsize)\n                large = LARGE_INPUT.get(dsize, 0)\n                if large and np.any(np.abs(values) > large):\n                    warnings.warn(\n                        \"Overflow encountered while converting to units '%s'\"\n                        % new_units,\n                        RuntimeWarning,\n                        stacklevel=2,\n                    )\n                float_values = values.astype(new_dtype)\n                # change the dtypes in-place, this does not change the\n                # underlying memory buffer\n                values.dtype = new_dtype\n                self.dtype = new_dtype\n                # actually fill in the new float values now that our\n                # dtype is correct\n                np.copyto(values, float_values)\n            values *= conv_factor\n\n            if offset:\n                np.subtract(values, offset, values)\n        else:\n            self.convert_to_equivalent(units, equivalence, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_to_base(self, unit_system=None, equivalence=None, **kwargs):\n        self.convert_to_units(\n            self.units.get_base_equivalent(unit_system),\n            equivalence=equivalence,\n            **kwargs\n        )", "response": "Convert the array in - place to the equivalent base units."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the array and in - place to the equivalent cgs units.", "response": "def convert_to_cgs(self, equivalence=None, **kwargs):\n        \"\"\"\n        Convert the array and in-place to the equivalent cgs units.\n\n        Optionally, an equivalence can be specified to convert to an\n        equivalent quantity which is not in the same dimensions.\n\n        Parameters\n        ----------\n        equivalence : string, optional\n            The equivalence you wish to use. To see which equivalencies\n            are supported for this object, try the ``list_equivalencies``\n            method. Default: None\n        kwargs: optional\n            Any additional keyword arguments are supplied to the equivalence\n\n        Raises\n        ------\n        If the provided unit does not have the same dimensions as the array\n        this will raise a UnitConversionError\n\n        Examples\n        --------\n        >>> from unyt import Newton\n        >>> data = [1., 2., 3.]*Newton\n        >>> data.convert_to_cgs()\n        >>> data\n        unyt_array([100000., 200000., 300000.], 'dyn')\n\n        \"\"\"\n        self.convert_to_units(\n            self.units.get_cgs_equivalent(), equivalence=equivalence, **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_to_mks(self, equivalence=None, **kwargs):\n        self.convert_to_units(self.units.get_mks_equivalent(), equivalence, **kwargs)", "response": "Convert the array and units to the equivalent mks units."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a copy of this array with the data converted to the supplied units.", "response": "def in_units(self, units, equivalence=None, **kwargs):\n        \"\"\"\n        Creates a copy of this array with the data converted to the\n        supplied units, and returns it.\n\n        Optionally, an equivalence can be specified to convert to an\n        equivalent quantity which is not in the same dimensions.\n\n        Parameters\n        ----------\n        units : Unit object or string\n            The units you want to get a new quantity in.\n        equivalence : string, optional\n            The equivalence you wish to use. To see which equivalencies\n            are supported for this object, try the ``list_equivalencies``\n            method. Default: None\n        kwargs: optional\n            Any additional keyword arguments are supplied to the\n            equivalence\n\n        Raises\n        ------\n        If the provided unit does not have the same dimensions as the array\n        this will raise a UnitConversionError\n\n        Examples\n        --------\n        >>> from unyt import c, gram\n        >>> m = 10*gram\n        >>> E = m*c**2\n        >>> print(E.in_units('erg'))\n        8.987551787368176e+21 erg\n        >>> print(E.in_units('J'))\n        898755178736817.6 J\n        \"\"\"\n        units = _sanitize_units_convert(units, self.units.registry)\n        if equivalence is None:\n            conv_data = _check_em_conversion(\n                self.units, units, registry=self.units.registry\n            )\n            if any(conv_data):\n                new_units, (conversion_factor, offset) = _em_conversion(\n                    self.units, conv_data, units\n                )\n                offset = 0\n            else:\n                new_units = units\n                (conversion_factor, offset) = self.units.get_conversion_factor(\n                    new_units, self.dtype\n                )\n            dsize = self.dtype.itemsize\n            if self.dtype.kind in (\"u\", \"i\"):\n                large = LARGE_INPUT.get(dsize, 0)\n                if large and np.any(np.abs(self.d) > large):\n                    warnings.warn(\n                        \"Overflow encountered while converting to units '%s'\"\n                        % new_units,\n                        RuntimeWarning,\n                        stacklevel=2,\n                    )\n            new_dtype = np.dtype(\"f\" + str(dsize))\n            conversion_factor = new_dtype.type(conversion_factor)\n            ret = np.asarray(self.ndview * conversion_factor, dtype=new_dtype)\n            if offset:\n                np.subtract(ret, offset, ret)\n\n            new_array = type(self)(ret, new_units, bypass_validation=True)\n\n            return new_array\n        else:\n            return self.to_equivalent(units, equivalence, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of this array with the data converted to the specified units.", "response": "def to(self, units, equivalence=None, **kwargs):\n        \"\"\"\n        Creates a copy of this array with the data converted to the\n        supplied units, and returns it.\n\n        Optionally, an equivalence can be specified to convert to an\n        equivalent quantity which is not in the same dimensions.\n\n        .. note::\n\n            All additional keyword arguments are passed to the\n            equivalency, which should be used if that particular\n            equivalency requires them.\n\n        Parameters\n        ----------\n        units : Unit object or string\n            The units you want to get a new quantity in.\n        equivalence : string, optional\n            The equivalence you wish to use. To see which\n            equivalencies are supported for this unitful\n            quantity, try the :meth:`list_equivalencies`\n            method. Default: None\n        kwargs: optional\n            Any additional keywoard arguments are supplied to the\n            equivalence\n\n        Raises\n        ------\n        If the provided unit does not have the same dimensions as the array\n        this will raise a UnitConversionError\n\n        Examples\n        --------\n        >>> from unyt import c, gram\n        >>> m = 10*gram\n        >>> E = m*c**2\n        >>> print(E.to('erg'))\n        8.987551787368176e+21 erg\n        >>> print(E.to('J'))\n        898755178736817.6 J\n        \"\"\"\n        return self.in_units(units, equivalence=equivalence, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_value(self, units=None, equivalence=None, **kwargs):\n        if units is None:\n            v = self.value\n        else:\n            v = self.in_units(units, equivalence=equivalence, **kwargs).value\n        if isinstance(self, unyt_quantity):\n            return float(v)\n        else:\n            return v", "response": "Returns the value of the current object in the specified units or in the specified units."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef in_base(self, unit_system=None):\n        us = _sanitize_unit_system(unit_system, self)\n        try:\n            conv_data = _check_em_conversion(\n                self.units, unit_system=us, registry=self.units.registry\n            )\n        except MKSCGSConversionError:\n            raise UnitsNotReducible(self.units, us)\n        if any(conv_data):\n            to_units, (conv, offset) = _em_conversion(\n                self.units, conv_data, unit_system=us\n            )\n        else:\n            to_units = self.units.get_base_equivalent(unit_system)\n            conv, offset = self.units.get_conversion_factor(to_units, self.dtype)\n        new_dtype = np.dtype(\"f\" + str(self.dtype.itemsize))\n        conv = new_dtype.type(conv)\n        ret = self.v * conv\n        if offset:\n            ret = ret - offset\n        return type(self)(ret, to_units)", "response": "Returns a copy of this array with the data in the specified base units."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_to_equivalent(self, unit, equivalence, **kwargs):\n        conv_unit = Unit(unit, registry=self.units.registry)\n        if self.units.same_dimensions_as(conv_unit):\n            self.convert_to_units(conv_unit)\n            return\n        this_equiv = equivalence_registry[equivalence](in_place=True)\n        if self.has_equivalent(equivalence):\n            this_equiv.convert(self, conv_unit.dimensions, **kwargs)\n            self.convert_to_units(conv_unit)\n        else:\n            raise InvalidUnitEquivalence(equivalence, self.units, conv_unit)", "response": "Returns a copy of the unyt_array in the specified units assuming the unyt_array is equivalent to the given units."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_equivalent(self, unit, equivalence, **kwargs):\n        conv_unit = Unit(unit, registry=self.units.registry)\n        if self.units.same_dimensions_as(conv_unit):\n            return self.in_units(conv_unit)\n        this_equiv = equivalence_registry[equivalence]()\n        if self.has_equivalent(equivalence):\n            new_arr = this_equiv.convert(self, conv_unit.dimensions, **kwargs)\n            return new_arr.in_units(conv_unit)\n        else:\n            raise InvalidUnitEquivalence(equivalence, self.units, unit)", "response": "Converts the unyt_array to the specified units assuming the unyt_array is equivalent to the specified units."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef argsort(self, axis=-1, kind=\"quicksort\", order=None):\n        return self.view(np.ndarray).argsort(axis, kind, order)", "response": "Returns the indices that would sort the array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_astropy(cls, arr, unit_registry=None):\n        # Converting from AstroPy Quantity\n        try:\n            u = arr.unit\n            _arr = arr\n        except AttributeError:\n            u = arr\n            _arr = 1.0 * u\n        ap_units = []\n        for base, exponent in zip(u.bases, u.powers):\n            unit_str = base.to_string()\n            # we have to do this because AstroPy is silly and defines\n            # hour as \"h\"\n            if unit_str == \"h\":\n                unit_str = \"hr\"\n            ap_units.append(\"%s**(%s)\" % (unit_str, Rational(exponent)))\n        ap_units = \"*\".join(ap_units)\n        if isinstance(_arr.value, np.ndarray) and _arr.shape != ():\n            return unyt_array(_arr.value, ap_units, registry=unit_registry)\n        else:\n            return unyt_quantity(_arr.value, ap_units, registry=unit_registry)", "response": "Convert an AstroPy Quantity to a unyt_array or unyt_quantity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert this quantity to an AstroPy quantity with the same unit information.", "response": "def to_astropy(self, **kwargs):\n        \"\"\"\n        Creates a new AstroPy quantity with the same unit information.\n\n        Example\n        -------\n        >>> from unyt import g, cm\n        >>> data = [3, 4, 5]*g/cm**3\n        >>> data.to_astropy()\n        <Quantity [3., 4., 5.] g / cm3>\n        \"\"\"\n        return self.value * _astropy.units.Unit(str(self.units), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_pint(cls, arr, unit_registry=None):\n        p_units = []\n        for base, exponent in arr._units.items():\n            bs = convert_pint_units(base)\n            p_units.append(\"%s**(%s)\" % (bs, Rational(exponent)))\n        p_units = \"*\".join(p_units)\n        if isinstance(arr.magnitude, np.ndarray):\n            return unyt_array(arr.magnitude, p_units, registry=unit_registry)\n        else:\n            return unyt_quantity(arr.magnitude, p_units, registry=unit_registry)", "response": "Convert a Pint Quantity to a unyt_array or unyt_quantity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_pint(self, unit_registry=None):\n        if unit_registry is None:\n            unit_registry = _pint.UnitRegistry()\n        powers_dict = self.units.expr.as_powers_dict()\n        units = []\n        for unit, pow in powers_dict.items():\n            # we have to do this because Pint doesn't recognize\n            # \"yr\" as \"year\"\n            if str(unit).endswith(\"yr\") and len(str(unit)) in [2, 3]:\n                unit = str(unit).replace(\"yr\", \"year\")\n            units.append(\"%s**(%s)\" % (unit, Rational(pow)))\n        units = \"*\".join(units)\n        return unit_registry.Quantity(self.value, units)", "response": "Converts a unyt_array or unyt_quantity to a Pint Quantity."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a copy of the array.", "response": "def copy(self, order=\"C\"):\n        \"\"\"\n        Return a copy of the array.\n\n        Parameters\n        ----------\n        order : {'C', 'F', 'A', 'K'}, optional\n            Controls the memory layout of the copy. 'C' means C-order,\n            'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n            'C' otherwise. 'K' means match the layout of `a` as closely\n            as possible. (Note that this function and :func:`numpy.copy`\n            are very similar, but have different default values for their\n            order= arguments.)\n\n        See also\n        --------\n        numpy.copy\n        numpy.copyto\n\n        Examples\n        --------\n        >>> from unyt import km\n        >>> x = [[1,2,3],[4,5,6]] * km\n        >>> y = x.copy()\n        >>> x.fill(0)\n        >>> print(x)\n        [[0 0 0]\n         [0 0 0]] km\n\n        >>> print(y)\n        [[1 2 3]\n         [4 5 6]] km\n\n        \"\"\"\n        return type(self)(np.copy(np.asarray(self)), self.units)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dot(self, b, out=None):\n        res_units = self.units * getattr(b, \"units\", NULL_UNIT)\n        ret = self.view(np.ndarray).dot(np.asarray(b), out=out) * res_units\n        if out is not None:\n            out.units = res_units\n        return ret", "response": "dot product of two arrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_rest_table(data, full=False):\n    data = data if data else [[\"No Data\"]]\n    table = []\n    # max size of each column\n    sizes = list(map(max, zip(*[[len(str(elt)) for elt in member] for member in data])))\n    num_elts = len(sizes)\n\n    if full:\n        start_of_line = \"| \"\n        vertical_separator = \" | \"\n        end_of_line = \" |\"\n        line_marker = \"-\"\n    else:\n        start_of_line = \"\"\n        vertical_separator = \"  \"\n        end_of_line = \"\"\n        line_marker = \"=\"\n\n    meta_template = vertical_separator.join(\n        [\"{{{{{0}:{{{0}}}}}}}\".format(i) for i in range(num_elts)]\n    )\n    template = \"{0}{1}{2}\".format(\n        start_of_line, meta_template.format(*sizes), end_of_line\n    )\n    # determine top/bottom borders\n    if full:\n        to_separator = maketrans(\"| \", \"+-\")\n    else:\n        to_separator = maketrans(\"|\", \"+\")\n    start_of_line = start_of_line.translate(to_separator)\n    vertical_separator = vertical_separator.translate(to_separator)\n    end_of_line = end_of_line.translate(to_separator)\n    separator = \"{0}{1}{2}\".format(\n        start_of_line,\n        vertical_separator.join([x * line_marker for x in sizes]),\n        end_of_line,\n    )\n    # determine header separator\n    th_separator_tr = maketrans(\"-\", \"=\")\n    start_of_line = start_of_line.translate(th_separator_tr)\n    line_marker = line_marker.translate(th_separator_tr)\n    vertical_separator = vertical_separator.translate(th_separator_tr)\n    end_of_line = end_of_line.translate(th_separator_tr)\n    th_separator = \"{0}{1}{2}\".format(\n        start_of_line,\n        vertical_separator.join([x * line_marker for x in sizes]),\n        end_of_line,\n    )\n    # prepare result\n    table.append(separator)\n    # set table header\n    titles = data[0]\n    table.append(template.format(*titles))\n    table.append(th_separator)\n\n    for d in data[1:-1]:\n        table.append(template.format(*d))\n        if full:\n            table.append(separator)\n    table.append(template.format(*data[-1]))\n    table.append(separator)\n\n    return \"\\n\".join(table)", "response": "Generate a Sphinx table that contains all the data in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_units(module, namespace):\n    for key, value in module.__dict__.items():\n        if isinstance(value, (unyt_quantity, Unit)):\n            namespace[key] = value", "response": "Import Unit objects from a module into a namespace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_symbols(namespace, registry):\n    import unyt.unit_symbols as us\n    from unyt.unit_object import Unit\n\n    for name, unit in vars(us).items():\n        if name.startswith(\"_\"):\n            continue\n        namespace[name] = Unit(unit.expr, registry=registry)\n    for name in [k for k in registry.keys() if k not in namespace]:\n        namespace[name] = Unit(name, registry=registry)", "response": "Adds the unit symbols from unyt. unit_symbols to a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_constants(namespace, registry):\n    from unyt.array import unyt_quantity\n\n    for constant_name in physical_constants:\n        value, unit_name, alternate_names = physical_constants[constant_name]\n        for name in alternate_names + [constant_name]:\n            quan = unyt_quantity(value, unit_name, registry=registry)\n            try:\n                namespace[name] = quan.in_base(unit_system=registry.unit_system)\n            except UnitsNotReducible:\n                namespace[name] = quan\n            namespace[name + \"_mks\"] = unyt_quantity(\n                value, unit_name, registry=registry\n            )\n            try:\n                namespace[name + \"_cgs\"] = quan.in_cgs()\n            except UnitsNotReducible:\n                pass\n            if name == \"h\":\n                # backward compatibility for unyt 1.0, which defined hmks\n                namespace[\"hmks\"] = namespace[\"h_mks\"].copy()\n                namespace[\"hcgs\"] = namespace[\"h_cgs\"].copy()", "response": "Adds the quantities from unyt. physical_constants to a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for the unit data tuple corresponding to the given symbol in the given dictionary of unit data tuples. Returns the tuple corresponding to the given symbol.", "response": "def _lookup_unit_symbol(symbol_str, unit_symbol_lut):\n    \"\"\"\n    Searches for the unit data tuple corresponding to the given symbol.\n\n    Parameters\n    ----------\n    symbol_str : str\n        The unit symbol to look up.\n    unit_symbol_lut : dict\n        Dictionary with symbols as keys and unit data tuples as values.\n\n    \"\"\"\n    if symbol_str in unit_symbol_lut:\n        # lookup successful, return the tuple directly\n        return unit_symbol_lut[symbol_str]\n\n    # could still be a known symbol with a prefix\n    prefix, symbol_wo_prefix = _split_prefix(symbol_str, unit_symbol_lut)\n\n    if prefix:\n        # lookup successful, it's a symbol with a prefix\n        unit_data = unit_symbol_lut[symbol_wo_prefix]\n        prefix_value = unit_prefixes[prefix][0]\n\n        # Need to add some special handling for comoving units\n        # this is fine for now, but it wouldn't work for a general\n        # unit that has an arbitrary LaTeX representation\n        if symbol_wo_prefix != \"cm\" and symbol_wo_prefix.endswith(\"cm\"):\n            sub_symbol_wo_prefix = symbol_wo_prefix[:-2]\n            sub_symbol_str = symbol_str[:-2]\n        else:\n            sub_symbol_wo_prefix = symbol_wo_prefix\n            sub_symbol_str = symbol_str\n        latex_repr = unit_data[3].replace(\n            \"{\" + sub_symbol_wo_prefix + \"}\", \"{\" + sub_symbol_str + \"}\"\n        )\n\n        # Leave offset and dimensions the same, but adjust scale factor and\n        # LaTeX representation\n        ret = (\n            unit_data[0] * prefix_value,\n            unit_data[1],\n            unit_data[2],\n            latex_repr,\n            False,\n        )\n\n        unit_symbol_lut[symbol_str] = ret\n\n        return ret\n\n    # no dice\n    raise UnitParseError(\n        \"Could not find unit symbol '%s' in the provided \" \"symbols.\" % symbol_str\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unit_system_id(self):\n        if self._unit_system_id is None:\n            hash_data = bytearray()\n            for k, v in sorted(self.lut.items()):\n                hash_data.extend(k.encode(\"utf8\"))\n                hash_data.extend(repr(v).encode(\"utf8\"))\n            m = md5()\n            m.update(hash_data)\n            self._unit_system_id = str(m.hexdigest())\n        return self._unit_system_id", "response": "This method returns the unique identifier for the unit system in the unit registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new entry to the internal registry.", "response": "def add(\n        self,\n        symbol,\n        base_value,\n        dimensions,\n        tex_repr=None,\n        offset=None,\n        prefixable=False,\n    ):\n        \"\"\"\n        Add a symbol to this registry.\n\n        Parameters\n        ----------\n\n        symbol : str\n           The name of the unit\n        base_value : float\n           The scaling from the units value to the equivalent SI unit\n           with the same dimensions\n        dimensions : expr\n           The dimensions of the unit\n        tex_repr : str, optional\n           The LaTeX representation of the unit. If not provided a LaTeX\n           representation is automatically generated from the name of\n           the unit.\n        offset : float, optional\n           If set, the zero-point offset to apply to the unit to convert\n           to SI. This is mostly used for units like Farhenheit and\n           Celcius that are not defined on an absolute scale.\n        prefixable : bool\n           If True, then SI-prefix versions of the unit will be created\n           along with the unit itself.\n\n        \"\"\"\n        from unyt.unit_object import _validate_dimensions\n\n        self._unit_system_id = None\n\n        # Validate\n        if not isinstance(base_value, float):\n            raise UnitParseError(\n                \"base_value (%s) must be a float, got a %s.\"\n                % (base_value, type(base_value))\n            )\n\n        if offset is not None:\n            if not isinstance(offset, float):\n                raise UnitParseError(\n                    \"offset value (%s) must be a float, got a %s.\"\n                    % (offset, type(offset))\n                )\n        else:\n            offset = 0.0\n\n        _validate_dimensions(dimensions)\n\n        if tex_repr is None:\n            # make educated guess that will look nice in most cases\n            tex_repr = r\"\\rm{\" + symbol.replace(\"_\", r\"\\ \") + \"}\"\n\n        # Add to lut\n        self.lut[symbol] = (base_value, dimensions, offset, tex_repr, prefixable)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, symbol):\n        self._unit_system_id = None\n\n        if symbol not in self.lut:\n            raise SymbolNotFoundError(\n                \"Tried to remove the symbol '%s', but it does not exist \"\n                \"in this registry.\" % symbol\n            )\n\n        del self.lut[symbol]", "response": "Removes the entry for the unit matching symbol from the registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmodifies the base value of a unit symbol.", "response": "def modify(self, symbol, base_value):\n        \"\"\"\n        Change the base value of a unit symbol.  Useful for adjusting code\n        units after parsing parameters.\n\n        Parameters\n        ----------\n\n        symbol : str\n           The name of the symbol to modify\n        base_value : float\n           The new base_value for the symbol.\n\n        \"\"\"\n        self._unit_system_id = None\n\n        if symbol not in self.lut:\n            raise SymbolNotFoundError(\n                \"Tried to modify the symbol '%s', but it does not exist \"\n                \"in this registry.\" % symbol\n            )\n\n        if hasattr(base_value, \"in_base\"):\n            new_dimensions = base_value.units.dimensions\n            base_value = base_value.in_base(\"mks\")\n            base_value = base_value.value\n        else:\n            new_dimensions = self.lut[symbol][1]\n\n        self.lut[symbol] = (float(base_value), new_dimensions) + self.lut[symbol][2:]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a json - serialized version of the unit registry", "response": "def to_json(self):\n        \"\"\"\n        Returns a json-serialized version of the unit registry\n        \"\"\"\n        sanitized_lut = {}\n        for k, v in self.lut.items():\n            san_v = list(v)\n            repr_dims = str(v[1])\n            san_v[1] = repr_dims\n            sanitized_lut[k] = tuple(san_v)\n\n        return json.dumps(sanitized_lut)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a UnitRegistry object from a json - serialized unit registry.", "response": "def from_json(cls, json_text):\n        \"\"\"\n        Returns a UnitRegistry object from a json-serialized unit registry\n\n        Parameters\n        ----------\n\n        json_text : str\n           A string containing a json represention of a UnitRegistry\n        \"\"\"\n        data = json.loads(json_text)\n        lut = {}\n        for k, v in data.items():\n            unsan_v = list(v)\n            unsan_v[1] = sympify(v[1], locals=vars(unyt_dims))\n            lut[k] = tuple(unsan_v)\n\n        return cls(lut=lut, add_default_symbols=False)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_same_dimensions(self, unit_object):\n        equiv = [k for k, v in self.lut.items() if v[1] is unit_object.dimensions]\n        equiv = list(sorted(set(equiv)))\n        return equiv", "response": "Return a list of base unit names that this registry knows about that\n        are of equivalent dimensions to unit_object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert between E & M units and CGS base units.", "response": "def _em_conversion(orig_units, conv_data, to_units=None, unit_system=None):\n    \"\"\"Convert between E&M & MKS base units.\n\n    If orig_units is a CGS (or MKS) E&M unit, conv_data contains the\n    corresponding MKS (or CGS) unit and scale factor converting between them.\n    This must be done by replacing the expression of the original unit\n    with the new one in the unit expression and multiplying by the scale\n    factor.\n    \"\"\"\n    conv_unit, canonical_unit, scale = conv_data\n    if conv_unit is None:\n        conv_unit = canonical_unit\n    new_expr = scale * canonical_unit.expr\n    if unit_system is not None:\n        # we don't know the to_units, so we get it directly from the\n        # conv_data\n        to_units = Unit(conv_unit.expr, registry=orig_units.registry)\n    new_units = Unit(new_expr, registry=orig_units.registry)\n    conv = new_units.get_conversion_factor(to_units)\n    return to_units, conv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck to see if the unit contains E &M units and if so returns the corresponding E&M unit.", "response": "def _check_em_conversion(unit, to_unit=None, unit_system=None, registry=None):\n    \"\"\"Check to see if the units contain E&M units\n\n    This function supports unyt's ability to convert data to and from E&M\n    electromagnetic units. However, this support is limited and only very\n    simple unit expressions can be readily converted. This function tries\n    to see if the unit is an atomic base unit that is present in the\n    em_conversions dict. If it does not contain E&M units, the function\n    returns an empty tuple. If it does contain an atomic E&M unit in\n    the em_conversions dict, it returns a tuple containing the unit to convert\n    to and scale factor. If it contains a more complicated E&M unit and we are\n    trying to convert between CGS & MKS E&M units, it raises an error.\n    \"\"\"\n    em_map = ()\n    if unit == to_unit or unit.dimensions not in em_conversion_dims:\n        return em_map\n    if unit.is_atomic:\n        prefix, unit_wo_prefix = _split_prefix(str(unit), unit.registry.lut)\n    else:\n        prefix, unit_wo_prefix = \"\", str(unit)\n    if (unit_wo_prefix, unit.dimensions) in em_conversions:\n        em_info = em_conversions[unit_wo_prefix, unit.dimensions]\n        em_unit = Unit(prefix + em_info[1], registry=registry)\n        if to_unit is None:\n            cmks_in_unit = current_mks in unit.dimensions.atoms()\n            cmks_in_unit_system = unit_system.units_map[current_mks]\n            cmks_in_unit_system = cmks_in_unit_system is not None\n            if cmks_in_unit and cmks_in_unit_system:\n                em_map = (unit_system[unit.dimensions], unit, 1.0)\n            else:\n                em_map = (None, em_unit, em_info[2])\n        elif to_unit.dimensions == em_unit.dimensions:\n            em_map = (to_unit, em_unit, em_info[2])\n    if em_map:\n        return em_map\n    if unit_system is None:\n        from unyt.unit_systems import unit_system_registry\n\n        unit_system = unit_system_registry[\"mks\"]\n    for unit_atom in unit.expr.atoms():\n        if unit_atom.is_Number:\n            continue\n        bu = str(unit_atom)\n        budims = Unit(bu, registry=registry).dimensions\n        try:\n            if str(unit_system[budims]) == bu:\n                continue\n        except MissingMKSCurrent:\n            raise MKSCGSConversionError(unit)\n    return em_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_conversion_factor(old_units, new_units, dtype):\n    if old_units.dimensions != new_units.dimensions:\n        raise UnitConversionError(\n            old_units, old_units.dimensions, new_units, new_units.dimensions\n        )\n    ratio = old_units.base_value / new_units.base_value\n    if old_units.base_offset == 0 and new_units.base_offset == 0:\n        return (ratio, None)\n    else:\n        # the dimensions are the same, so both are temperatures, where\n        # it's legal to convert units so no need to do error checking\n        return ratio, ratio * old_units.base_offset - new_units.base_offset", "response": "Returns the conversion factor between two units of equivalent dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the total base value and dimensions of a valid unit expression.", "response": "def _get_unit_data_from_expr(unit_expr, unit_symbol_lut):\n    \"\"\"\n    Grabs the total base_value and dimensions from a valid unit expression.\n\n    Parameters\n    ----------\n    unit_expr: Unit object, or sympy Expr object\n        The expression containing unit symbols.\n    unit_symbol_lut: dict\n        Provides the unit data for each valid unit symbol.\n\n    \"\"\"\n    # Now for the sympy possibilities\n    if isinstance(unit_expr, Number):\n        if unit_expr is sympy_one:\n            return (1.0, sympy_one)\n        return (float(unit_expr), sympy_one)\n\n    if isinstance(unit_expr, Symbol):\n        return _lookup_unit_symbol(unit_expr.name, unit_symbol_lut)\n\n    if isinstance(unit_expr, Pow):\n        unit_data = _get_unit_data_from_expr(unit_expr.args[0], unit_symbol_lut)\n        power = unit_expr.args[1]\n        if isinstance(power, Symbol):\n            raise UnitParseError(\"Invalid unit expression '%s'.\" % unit_expr)\n        conv = float(unit_data[0] ** power)\n        unit = unit_data[1] ** power\n        return (conv, unit)\n\n    if isinstance(unit_expr, Mul):\n        base_value = 1.0\n        dimensions = 1\n        for expr in unit_expr.args:\n            unit_data = _get_unit_data_from_expr(expr, unit_symbol_lut)\n            base_value *= unit_data[0]\n            dimensions *= unit_data[1]\n\n        return (float(base_value), dimensions)\n\n    raise UnitParseError(\n        \"Cannot parse for unit data from '%s'. Please supply\"\n        \" an expression of only Unit, Symbol, Pow, and Mul\"\n        \"objects.\" % str(unit_expr)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef define_unit(\n    symbol, value, tex_repr=None, offset=None, prefixable=False, registry=None\n):\n    \"\"\"\n    Define a new unit and add it to the specified unit registry.\n\n    Parameters\n    ----------\n    symbol : string\n        The symbol for the new unit.\n    value : tuple or :class:`unyt.array.unyt_quantity`\n        The definition of the new unit in terms of some other units. For\n        example, one would define a new \"mph\" unit with ``(1.0, \"mile/hr\")``\n        or with ``1.0*unyt.mile/unyt.hr``\n    tex_repr : string, optional\n        The LaTeX representation of the new unit. If one is not supplied, it\n        will be generated automatically based on the symbol string.\n    offset : float, optional\n        The default offset for the unit. If not set, an offset of 0 is assumed.\n    prefixable : boolean, optional\n        Whether or not the new unit can use SI prefixes. Default: False\n    registry : :class:`unyt.unit_registry.UnitRegistry` or None\n        The unit registry to add the unit to. If None, then defaults to the\n        global default unit registry. If registry is set to None then the\n        unit object will be added as an attribute to the top-level :mod:`unyt`\n        namespace to ease working with the newly defined unit. See the example\n        below.\n\n    Examples\n    --------\n    >>> from unyt import day\n    >>> two_weeks = 14.0*day\n    >>> one_day = 1.0*day\n    >>> define_unit(\"two_weeks\", two_weeks)\n    >>> from unyt import two_weeks\n    >>> print((3*two_weeks)/one_day)\n    42.0 dimensionless\n    \"\"\"\n    from unyt.array import unyt_quantity, _iterable\n    import unyt\n\n    if registry is None:\n        registry = default_unit_registry\n    if symbol in registry:\n        raise RuntimeError(\n            \"Unit symbol '%s' already exists in the provided \" \"registry\" % symbol\n        )\n    if not isinstance(value, unyt_quantity):\n        if _iterable(value) and len(value) == 2:\n            value = unyt_quantity(value[0], value[1], registry=registry)\n        else:\n            raise RuntimeError(\n                '\"value\" needs to be a quantity or ' \"(value, unit) tuple!\"\n            )\n    base_value = float(value.in_base(unit_system=\"mks\"))\n    dimensions = value.units.dimensions\n    registry.add(\n        symbol,\n        base_value,\n        dimensions,\n        prefixable=prefixable,\n        tex_repr=tex_repr,\n        offset=offset,\n    )\n    if registry is default_unit_registry:\n        u = Unit(symbol, registry=registry)\n        setattr(unyt, symbol, u)", "response": "Define a new unit in the specified unit registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef latex_repr(self):\n        if self._latex_repr is not None:\n            return self._latex_repr\n        if self.expr.is_Atom:\n            expr = self.expr\n        else:\n            expr = self.expr.copy()\n        self._latex_repr = _get_latex_representation(expr, self.registry)\n        return self._latex_repr", "response": "A LaTeX representation of the unit\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef same_dimensions_as(self, other_unit):\n        # test first for 'is' equality to avoid expensive sympy operation\n        if self.dimensions is other_unit.dimensions:\n            return True\n        return (self.dimensions / other_unit.dimensions) == sympy_one", "response": "Test if the dimensions of other_unit are the same as this unit."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_code_unit(self):\n        for atom in self.expr.atoms():\n            if not (str(atom).startswith(\"code\") or atom.is_Number):\n                return False\n        return True", "response": "Is this a code unit? Returns True if the unit consists of atom units that are being with code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_equivalencies(self):\n        from unyt.equivalencies import equivalence_registry\n\n        for k, v in equivalence_registry.items():\n            if self.has_equivalent(k):\n                print(v())", "response": "Lists the possible equivalencies associated with this unit object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_equivalent(self, equiv):\n        try:\n            this_equiv = equivalence_registry[equiv]()\n        except KeyError:\n            raise KeyError('No such equivalence \"%s\".' % equiv)\n        old_dims = self.dimensions\n        return old_dims in this_equiv._dims", "response": "Check to see if this unit object is an equivalent unit in the specified equivalence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_base_equivalent(self, unit_system=None):\n        from unyt.unit_registry import _sanitize_unit_system\n\n        unit_system = _sanitize_unit_system(unit_system, self)\n        try:\n            conv_data = _check_em_conversion(\n                self.units, registry=self.registry, unit_system=unit_system\n            )\n        except MKSCGSConversionError:\n            raise UnitsNotReducible(self.units, unit_system)\n        if any(conv_data):\n            new_units, _ = _em_conversion(self, conv_data, unit_system=unit_system)\n        else:\n            try:\n                new_units = unit_system[self.dimensions]\n            except MissingMKSCurrent:\n                raise UnitsNotReducible(self.units, unit_system)\n        return Unit(new_units, registry=self.registry)", "response": "Create and return dimensionally - equivalent units in a specified base."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_coeff_unit(self):\n        coeff, mul = self.expr.as_coeff_Mul()\n        coeff = float(coeff)\n        ret = Unit(\n            mul,\n            self.base_value / coeff,\n            self.base_offset,\n            self.dimensions,\n            self.registry,\n        )\n        return coeff, ret", "response": "Factor the coefficient multiplying a unit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new equivalent unit object with a simplified unit expression", "response": "def simplify(self):\n        \"\"\"Return a new equivalent unit object with a simplified unit expression\n\n        >>> import unyt as u\n        >>> unit = (u.m**2/u.cm).simplify()\n        >>> unit\n        100*m\n        \"\"\"\n        expr = self.expr\n        self.expr = _cancel_mul(expr, self.registry)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _auto_positive_symbol(tokens, local_dict, global_dict):\n    result = []\n\n    tokens.append((None, None))  # so zip traverses all tokens\n    for tok, nextTok in zip(tokens, tokens[1:]):\n        tokNum, tokVal = tok\n        nextTokNum, nextTokVal = nextTok\n        if tokNum == token.NAME:\n            name = tokVal\n            if name in global_dict:\n                obj = global_dict[name]\n                if isinstance(obj, (Basic, type)) or callable(obj):\n                    result.append((token.NAME, name))\n                    continue\n\n            # try to resolve known alternative unit name\n            try:\n                used_name = inv_name_alternatives[str(name)]\n            except KeyError:\n                # if we don't know this name it's a user-defined unit name\n                # so we should create a new symbol for it\n                used_name = str(name)\n\n            result.extend(\n                [\n                    (token.NAME, \"Symbol\"),\n                    (token.OP, \"(\"),\n                    (token.NAME, repr(used_name)),\n                    (token.OP, \",\"),\n                    (token.NAME, \"positive\"),\n                    (token.OP, \"=\"),\n                    (token.NAME, \"True\"),\n                    (token.OP, \")\"),\n                ]\n            )\n        else:\n            result.append((tokNum, tokVal))\n\n    return result", "response": "Returns a list of tokens that are used as a symbol for undefined variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the intersection with another range object", "response": "def intersection(self, range):\n        \"\"\"\n\t\tCalculates the intersection with another range object\n\t\t\"\"\"\n        if self.worksheet != range.worksheet:\n            # Different worksheet\n            return None\n        start = (max(self._start[0], range._start[0]),\n                 max(self._start[1], range._start[1]))\n        end = (min(self._end[0], range._end[0]),\n               min(self._end[1], range._end[1]))\n        if end[0] < start[0] or end[1] < start[1]:\n            return None\n        return Range(start, end, self.worksheet, validate=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a directory and any ancestor directories required.", "response": "def _ensure_tree(path):\n    \"\"\"Create a directory (and any ancestor directories required).\n\n    :param path: Directory to create\n    \"\"\"\n    try:\n        os.makedirs(path)\n    except OSError as e:\n        if e.errno == errno.EEXIST:\n            if not os.path.isdir(path):\n                raise\n            else:\n                return False\n        elif e.errno == errno.EISDIR:\n            return False\n        else:\n            raise\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nacquiring & releases a interprocess lock around call into decorated function.", "response": "def interprocess_locked(path):\n    \"\"\"Acquires & releases a interprocess lock around call into\n       decorated function.\"\"\"\n\n    lock = InterProcessLock(path)\n\n    def decorator(f):\n\n        @six.wraps(f)\n        def wrapper(*args, **kwargs):\n            with lock:\n                return f(*args, **kwargs)\n\n        return wrapper\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef acquire(self, blocking=True,\n                delay=DELAY_INCREMENT, max_delay=MAX_DELAY,\n                timeout=None):\n        \"\"\"Attempt to acquire the given lock.\n\n        :param blocking: whether to wait forever to try to acquire the lock\n        :type blocking: bool\n        :param delay: when blocking this is the delay time in seconds that\n                      will be added after each failed acquisition\n        :type delay: int/float\n        :param max_delay: the maximum delay to have (this limits the\n                          accumulated delay(s) added after each failed\n                          acquisition)\n        :type max_delay: int/float\n        :param timeout: an optional timeout (limits how long blocking\n                        will occur for)\n        :type timeout: int/float\n        :returns: whether or not the acquisition succeeded\n        :rtype: bool\n        \"\"\"\n        if delay < 0:\n            raise ValueError(\"Delay must be greater than or equal to zero\")\n        if timeout is not None and timeout < 0:\n            raise ValueError(\"Timeout must be greater than or equal to zero\")\n        if delay >= max_delay:\n            max_delay = delay\n        self._do_open()\n        watch = _utils.StopWatch(duration=timeout)\n        r = _utils.Retry(delay, max_delay,\n                         sleep_func=self.sleep_func, watch=watch)\n        with watch:\n            gotten = r(self._try_acquire, blocking, watch)\n        if not gotten:\n            self.acquired = False\n            return False\n        else:\n            self.acquired = True\n            self.logger.log(_utils.BLATHER,\n                            \"Acquired file lock `%s` after waiting %0.3fs [%s\"\n                            \" attempts were required]\", self.path,\n                            watch.elapsed(), r.attempts)\n            return True", "response": "Attempt to acquire the given lock."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef release(self):\n        if not self.acquired:\n            raise threading.ThreadError(\"Unable to release an unacquired\"\n                                        \" lock\")\n        try:\n            self.unlock()\n        except IOError:\n            self.logger.exception(\"Could not unlock the acquired lock opened\"\n                                  \" on `%s`\", self.path)\n        else:\n            self.acquired = False\n            try:\n                self._do_close()\n            except IOError:\n                self.logger.exception(\"Could not close the file handle\"\n                                      \" opened on `%s`\", self.path)\n            else:\n                self.logger.log(_utils.BLATHER,\n                                \"Unlocked and closed file lock open on\"\n                                \" `%s`\", self.path)", "response": "Release the previously acquired lock."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_locked(*args, **kwargs):\n\n    def decorator(f):\n        attr_name = kwargs.get('lock', '_lock')\n\n        @six.wraps(f)\n        def wrapper(self, *args, **kwargs):\n            rw_lock = getattr(self, attr_name)\n            with rw_lock.read_lock():\n                return f(self, *args, **kwargs)\n\n        return wrapper\n\n    # This is needed to handle when the decorator has args or the decorator\n    # doesn't have args, python is rather weird here...\n    if kwargs or not args:\n        return decorator\n    else:\n        if len(args) == 1:\n            return decorator(args[0])\n        else:\n            return decorator", "response": "Decorator for holding a read lock around call into decorated method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nacquire & releases a write lock around call into decorated method. NOTE(harlowja): if no attribute name is provided then by default the attribute named '_lock' is looked for (this attribute is expected to be a :py:class:`.ReaderWriterLock` object) in the instance object this decorator is attached to.", "response": "def write_locked(*args, **kwargs):\n    \"\"\"Acquires & releases a write lock around call into decorated method.\n\n    NOTE(harlowja): if no attribute name is provided then by default the\n    attribute named '_lock' is looked for (this attribute is expected to be\n    a :py:class:`.ReaderWriterLock` object) in the instance object this\n    decorator is attached to.\n    \"\"\"\n\n    def decorator(f):\n        attr_name = kwargs.get('lock', '_lock')\n\n        @six.wraps(f)\n        def wrapper(self, *args, **kwargs):\n            rw_lock = getattr(self, attr_name)\n            with rw_lock.write_lock():\n                return f(self, *args, **kwargs)\n\n        return wrapper\n\n    # This is needed to handle when the decorator has args or the decorator\n    # doesn't have args, python is rather weird here...\n    if kwargs or not args:\n        return decorator\n    else:\n        if len(args) == 1:\n            return decorator(args[0])\n        else:\n            return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattempt to acquire a lock and auto releases if acquired.", "response": "def try_lock(lock):\n    \"\"\"Attempts to acquire a lock, and auto releases if acquired (on exit).\"\"\"\n    # NOTE(harlowja): the keyword argument for 'blocking' does not work\n    # in py2.x and only is fixed in py3.x (this adjustment is documented\n    # and/or debated in http://bugs.python.org/issue10789); so we'll just\n    # stick to the format that works in both (oddly the keyword argument\n    # works in py2.x but only with reentrant locks).\n    was_locked = lock.acquire(False)\n    try:\n        yield was_locked\n    finally:\n        if was_locked:\n            lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning if the caller is the active writer or a pending writer.", "response": "def is_writer(self, check_pending=True):\n        \"\"\"Returns if the caller is the active writer or a pending writer.\"\"\"\n        me = self._current_thread()\n        if self._writer == me:\n            return True\n        if check_pending:\n            return me in self._pending_writers\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef owner(self):\n        if self._writer is not None:\n            return self.WRITER\n        if self._readers:\n            return self.READER\n        return None", "response": "Returns whether the lock is locked by a writer or reader."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_lock(self):\n        me = self._current_thread()\n        if me in self._pending_writers:\n            raise RuntimeError(\"Writer %s can not acquire a read lock\"\n                               \" while waiting for the write lock\"\n                               % me)\n        with self._cond:\n            while True:\n                # No active writer, or we are the writer;\n                # we are good to become a reader.\n                if self._writer is None or self._writer == me:\n                    try:\n                        self._readers[me] = self._readers[me] + 1\n                    except KeyError:\n                        self._readers[me] = 1\n                    break\n                # An active writer; guess we have to wait.\n                self._cond.wait()\n        try:\n            yield self\n        finally:\n            # I am no longer a reader, remove *one* occurrence of myself.\n            # If the current thread acquired two read locks, then it will\n            # still have to remove that other read lock; this allows for\n            # basic reentrancy to be possible.\n            with self._cond:\n                try:\n                    me_instances = self._readers[me]\n                    if me_instances > 1:\n                        self._readers[me] = me_instances - 1\n                    else:\n                        self._readers.pop(me)\n                except KeyError:\n                    pass\n                self._cond.notify_all()", "response": "Context manager that grants a read lock."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_lock(self):\n        me = self._current_thread()\n        i_am_writer = self.is_writer(check_pending=False)\n        if self.is_reader() and not i_am_writer:\n            raise RuntimeError(\"Reader %s to writer privilege\"\n                               \" escalation not allowed\" % me)\n        if i_am_writer:\n            # Already the writer; this allows for basic reentrancy.\n            yield self\n        else:\n            with self._cond:\n                self._pending_writers.append(me)\n                while True:\n                    # No readers, and no active writer, am I next??\n                    if len(self._readers) == 0 and self._writer is None:\n                        if self._pending_writers[0] == me:\n                            self._writer = self._pending_writers.popleft()\n                            break\n                    self._cond.wait()\n            try:\n                yield self\n            finally:\n                with self._cond:\n                    self._writer = None\n                    self._cond.notify_all()", "response": "Context manager that grants a write lock."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an SMS to Free.", "response": "def send_sms(self, text, **kw):\n        \"\"\"\n        Send an SMS. Since Free only allows us to send SMSes to ourselves you\n        don't have to provide your phone number.\n        \"\"\"\n\n        params = {\n            'user': self._user,\n            'pass': self._passwd,\n            'msg': text\n        }\n\n        kw.setdefault(\"verify\", False)\n\n        if not kw[\"verify\"]:\n            # remove SSL warning\n            requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\n        res = requests.get(FreeClient.BASE_URL, params=params, **kw)\n        return FreeResponse(res.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting a prefix template with the given format info.", "response": "def formatted_prefix(self, **format_info):\n        \"\"\"\n        Gets a dict with format info, and formats a prefix template with that info. For example:\n        if our prefix template is:\n        'some_file_{groups[0]}_{file_number}'\n\n        And we have this method called with:\n\n        formatted_prefix(groups=[US], file_number=0)\n\n        The returned formatted prefix would be:\n        'some_file_US_0'\n        \"\"\"\n        prefix_name = self.prefix_template.format(**format_info)\n        file_number = format_info.pop('file_number', 0)\n        if prefix_name == self.prefix_template:\n            prefix_name += '{:04d}'.format(file_number)\n        for key, value in format_info.iteritems():\n            if value and not self._has_key_info(key):\n                prefix_name = '{}-{}'.format(prefix_name, ''.join(value))\n        return prefix_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_filebase_name(self, group_info, extension='gz', file_name=None):\n        dirname = self.filebase.formatted_dirname(groups=group_info)\n        if not file_name:\n            file_name = self.filebase.prefix_template + '.' + extension\n        return dirname, file_name", "response": "Create a tuple of resolved destination folder name and file name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreceiving the batch and writes it. This method is usually called from a manager.", "response": "def write_batch(self, batch):\n        \"\"\"\n        Receives the batch and writes it. This method is usually called from a manager.\n        \"\"\"\n        for item in batch:\n            for key in item:\n                self.aggregated_info['occurrences'][key] += 1\n            self.increment_written_items()\n            if self.items_limit and self.items_limit == self.get_metadata('items_count'):\n                raise ItemsLimitReached('Finishing job after items_limit reached: {} items written.'\n                                        .format(self.get_metadata('items_count')))\n        self.logger.debug('Wrote items')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_aggregated_info(self):\n        agg_results = {}\n        for key in self.aggregated_info['occurrences']:\n            agg_results[key] = {\n                'occurrences': self.aggregated_info['occurrences'].get(key),\n                'coverage': (float(self.aggregated_info['occurrences']\n                                   .get(key))/float(self.get_metadata('items_count')))*100\n            }\n        return agg_results", "response": "Returns a dictionary that contains the aggregated info for the items that are in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_document_batches(jsonlines, id_field, max_batch_size=CLOUDSEARCH_MAX_BATCH_SIZE):\n    batch = []\n    fixed_initial_size = 2\n\n    def create_entry(line):\n        try:\n            record = json.loads(line)\n        except:\n            raise ValueError('Could not parse JSON from: %s' % line)\n        key = record[id_field]\n        return '{\"type\":\"add\",\"id\":%s,\"fields\":%s}' % (json.dumps(key), line)\n\n    current_size = fixed_initial_size\n    for line in jsonlines:\n        entry = create_entry(line)\n        entry_size = len(entry) + 1\n\n        if max_batch_size > (current_size + entry_size):\n            current_size += entry_size\n            batch.append(entry)\n        else:\n            yield '[' + ','.join(batch) + ']'\n            batch = [entry]\n            current_size = fixed_initial_size + entry_size\n\n    if batch:\n        yield '[' + ','.join(batch) + ']'", "response": "Create batches in expected AWS Cloudsearch format limiting the size per batch according to given max_batch_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a batch to Cloudsearch endpoint", "response": "def _post_document_batch(self, batch):\n        \"\"\"\n        Send a batch to Cloudsearch endpoint\n\n        See: http://docs.aws.amazon.com/cloudsearch/latest/developerguide/submitting-doc-requests.html\n        \"\"\"  # noqa\n        target_batch = '/2013-01-01/documents/batch'\n        url = self.endpoint_url + target_batch\n        return requests.post(url, data=batch, headers={'Content-type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a folders path if it doesn t exist.", "response": "def _create_path_if_not_exist(self, path):\n        \"\"\"\n        Creates a folders path if it doesn't exist\n        \"\"\"\n        if path and not os.path.exists(path):\n            os.makedirs(path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_file_suffix(self, path, prefix):\n        try:\n            number_of_files = len(glob.glob(os.path.join(path, prefix) + '*'))\n        except:\n            number_of_files = 0\n        return '{0:04}'.format(number_of_files)", "response": "Gets a valid filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the last position of the data in the current log entry", "response": "def set_last_position(self, last_position):\n        \"\"\"\n        Called from the manager, it is in charge of updating the last position of data commited\n        by the writer, in order to have resume support\n        \"\"\"\n        last_position = last_position or {}\n        last_position.setdefault('readed_streams', [])\n        last_position.setdefault('stream_offset', {})\n        self.last_position = last_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        if self.read_option('save_pointer'):\n            self._update_last_pointer()\n        super(S3Writer, self).close()", "response": "Called to clean all possible tmp files created during the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a connection object to the AWS S3 bucket.", "response": "def get_boto_connection(aws_access_key_id, aws_secret_access_key, region=None, bucketname=None,\n                        host=None):\n    \"\"\"\n    Conection parameters must be different only if bucket name has a period\n    \"\"\"\n    m = _AWS_ACCESS_KEY_ID_RE.match(aws_access_key_id)\n    if m is None or m.group() != aws_access_key_id:\n        logging.error('The provided aws_access_key_id is not in the correct format. It must \\\n                      be alphanumeric and contain between 16 and 32 characters.')\n\n    if len(aws_access_key_id) > len(aws_secret_access_key):\n        logging.warn(\"The AWS credential keys aren't in the usual size,\"\n                     \" are you using the correct ones?\")\n\n    import boto\n    from boto.s3.connection import OrdinaryCallingFormat\n    extra_args = {}\n    if host is not None:\n        extra_args['host'] = host\n    if bucketname is not None and '.' in bucketname:\n        extra_args['calling_format'] = OrdinaryCallingFormat()\n    if region is None:\n        return boto.connect_s3(aws_access_key_id, aws_secret_access_key, **extra_args)\n    return boto.s3.connect_to_region(region, aws_access_key_id=aws_access_key_id,\n                                     aws_secret_access_key=aws_secret_access_key,\n                                     **extra_args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef maybe_cast_list(value, types):\n    if not isinstance(value, list):\n        return value\n\n    if type(types) not in (list, tuple):\n        types = (types,)\n\n    for list_type in types:\n        if issubclass(list_type, list):\n            try:\n                return list_type(value)\n            except (TypeError, ValueError):\n                pass\n    return value", "response": "Try to coerce list values into more specific list subclasses in types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterate_chunks(file, chunk_size):\n    chunk = file.read(chunk_size)\n    while chunk:\n        yield chunk\n        chunk = file.read(chunk_size)", "response": "Iterate chunks of size chunk_size from a file - like object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npushing a chunk of data back into the internal buffer.", "response": "def unshift(self, chunk):\n        \"\"\"\n        Pushes a chunk of data back into the internal buffer. This is useful\n        in certain situations where a stream is being consumed by code that\n        needs to \"un-consume\" some amount of data that it has optimistically\n        pulled out of the source, so that the data can be passed on to some\n        other party.\n        \"\"\"\n        if chunk:\n            self._pos -= len(chunk)\n            self._unconsumed.append(chunk)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next_chunk(self):\n        if self._unconsumed:\n            data = self._unconsumed.pop()\n        else:\n            data = self._iterator.next()  # Might raise StopIteration\n        self._pos += len(data)\n        return data", "response": "Read a chunk of arbitrary size from the underlying iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, size=None):\n        if size is None or size < 0:\n            return \"\".join(list(self))\n        else:\n            data_chunks = []\n            data_readed = 0\n            try:\n                while data_readed < size:\n                    chunk = self.next_chunk()\n                    data_chunks.append(chunk)\n                    data_readed += len(chunk)\n            except StopIteration:\n                pass\n\n            if data_readed > size:\n                last_chunk = data_chunks.pop()\n                extra_length = data_readed - size\n                last_chunk, extra_data = last_chunk[:-extra_length], last_chunk[-extra_length:]\n                self.unshift(extra_data)\n                data_chunks.append(last_chunk)\n            return \"\".join(data_chunks)", "response": "Reads at most size bytes from the file and returns them as a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading until a new - line character is encountered in the file.", "response": "def readline(self):\n        \"\"\"\n        Read until a new-line character is encountered\n        \"\"\"\n        line = \"\"\n        n_pos = -1\n        try:\n            while n_pos < 0:\n                line += self.next_chunk()\n                n_pos = line.find('\\n')\n        except StopIteration:\n            pass\n\n        if n_pos >= 0:\n            line, extra = line[:n_pos+1], line[n_pos+1:]\n            self.unshift(extra)\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisable al operations and close the underlying file - like object", "response": "def close(self):\n        \"\"\"\n        Disable al operations and close the underlying file-like object, if any\n        \"\"\"\n        if callable(getattr(self._file, 'close', None)):\n            self._iterator.close()\n        self._iterator = None\n        self._unconsumed = None\n        self.closed = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef seek(self, offset, from_what=0):\n        if from_what == 0:  # From the begining\n            if offset >= self.tell():\n                self.seek(offset - self.tell(), from_what=1)\n            else:\n                raise NotImplementedError(\"Can't seek backwards\")\n        elif from_what == 1:  # From the cursor position\n            if offset < 0:\n                raise NotImplementedError(\"Can't seek backwards\")\n            else:\n                self.read(offset)\n        else:\n            raise NotImplementedError(\"Can't seek from there\")\n        return self.tell()", "response": "seek(offset, from_what=0) -> int.  Change stream position.\n\n        Seek to byte offset pos relative to position indicated by whence:\n             0  Start of stream (the default).  pos should be >= tell();\n             1  Current position - negative pos not implemented;\n             2  End of stream - not implemented.\n        Returns the new absolute position."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the directory for the path given recursively creating the parent directories when needed", "response": "def _create_target_dir_if_needed(self, target, depth_limit=20):\n        \"\"\"Creates the directory for the path given, recursively creating\n        parent directories when needed\"\"\"\n\n        if depth_limit <= 0:\n            raise FtpCreateDirsException('Depth limit exceeded')\n        if not target:\n            return\n        target_dir = os.path.dirname(target)\n        parent_dir, dir_name = os.path.split(target_dir)\n\n        parent_dir_ls = []\n        try:\n            parent_dir_ls = self.ftp.nlst(parent_dir)\n        except:\n            # Possibly a microsoft server\n            # They throw exceptions when we try to ls non-existing folders\n            pass\n\n        parent_dir_files = [os.path.basename(d) for d in parent_dir_ls]\n        if dir_name not in parent_dir_files:\n            if parent_dir and target_dir != '/':\n                self._create_target_dir_if_needed(target_dir, depth_limit=depth_limit - 1)\n\n            self.logger.info('Will create dir: %s' % target)\n            self.ftp.mkd(target_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_next_batch(self):\n        number_of_items = self.read_option('number_of_items')\n        for i in range(0, self.batch_size):\n            to_read = self.last_read + 1\n            if to_read >= number_of_items:\n                self.finished = True\n                break\n            else:\n                item = BaseRecord()\n                self.last_read = to_read\n                item['key'] = self.last_read\n                item['country_code'] = random.choice(self.country_codes)\n                item['state'] = random.choice(self.states)\n                item['city'] = random.choice(self.cities)\n                item['value'] = random.randint(0, 10000)\n                self.increase_read()\n                self.last_position['last_read'] = self.last_read\n                yield item\n        self.logger.debug('Done reading batch')", "response": "This method returns a list or generator that yields BaseRecords."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the last position of the items in the cache.", "response": "def set_last_position(self, last_position):\n        \"\"\"\n        Called from the manager, it is in charge of updating the last position of data commited\n        by the writer, in order to have resume support\n        \"\"\"\n        self.last_position = last_position\n        if last_position is not None and last_position.get('last_read') is not None:\n            self.last_read = last_position['last_read']\n        else:\n            self.last_read = -1\n            self.last_position = {\n                'last_read': self.last_read\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a configuration object from a URI. uri_regex is a regex that matches the uri of the file.", "response": "def configuration_from_uri(uri, uri_regex):\n        \"\"\"\n        returns a configuration object.\n        \"\"\"\n        file_path = re.match(uri_regex, uri).groups()[0]\n        with open(file_path) as f:\n            configuration = pickle.load(f)['configuration']\n        configuration = yaml.safe_load(configuration)\n        configuration['exporter_options']['resume'] = True\n        persistence_state_id = file_path.split(os.path.sep)[-1]\n        configuration['exporter_options']['persistence_state_id'] = persistence_state_id\n        return configuration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_for_errors(config, raise_exception=True):\n    errors = {}\n    for section in ['reader', 'writer', 'filter', 'filter_before',\n                    'filter_after', 'transform', 'persistence',\n                    'decompressor', 'deserializer']:\n        config_section = config.get(section)\n        if config_section is None:\n            if section in REQUIRED_CONFIG_SECTIONS:\n                errors[section] = \"Missing section\"\n        else:\n            section_errors = _get_section_errors(config_section)\n            if section_errors:\n                errors[section] = section_errors\n\n    exporter_options = config.get('exporter_options', {})\n    if \"formatter\" in exporter_options:\n        section_errors = _get_section_errors(exporter_options['formatter'])\n        if section_errors:\n            errors['formatter'] = section_errors\n\n    if not _is_stream_reader(config):\n        for section in STREAM_READER_SECTIONS:\n            if config.get(section) and not errors.get(section):\n                errors[section] = 'The %r section can only be used with a stream reader.' % section\n\n    for i, notificator in enumerate(exporter_options.get('notifications', [])):\n        section_errors = _get_section_errors(notificator)\n        if section_errors:\n            errors['notifications_' + str(i)] = section_errors\n\n    if raise_exception and errors:\n        raise ConfigCheckError(errors=errors)\n    else:\n        return errors", "response": "Checks the config for errors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreceive an item and write it to the file.", "response": "def buffer(self, item):\n        \"\"\"\n        Receive an item and write it.\n        \"\"\"\n        key = self.get_key_from_item(item)\n        if not self.grouping_info.is_first_file_item(key):\n            self.items_group_files.add_item_separator_to_file(key)\n        self.grouping_info.ensure_group_info(key)\n        self.items_group_files.add_item_to_file(item, key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npacks the current buffer file for the given key.", "response": "def pack_buffer(self, key):\n        \"\"\"Prepare current buffer file for group of given key to be written\n        (by gathering statistics).\n        \"\"\"\n        self.finish_buffer_write(key)\n        file_path = self.items_group_files.get_current_buffer_file_for_group(key).path\n        file_hash = None\n        if self.hash_algorithm:\n            file_hash = hash_for_file(file_path, self.hash_algorithm)\n\n        file_size = os.path.getsize(file_path)\n        write_info = {\n            'number_of_records': self.grouping_info[key]['buffered_items'],\n            'file_path': file_path,\n            'size': file_size,\n            'file_hash': file_hash,\n        }\n        self.set_metadata_for_file(file_path, **write_info)\n        return write_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a database URI and the persistence state ID from the given persistence URI", "response": "def parse_persistence_uri(cls, persistence_uri):\n        \"\"\"Parse a database URI and the persistence state ID from\n        the given persistence URI\n        \"\"\"\n        regex = cls.persistence_uri_re\n        match = re.match(regex, persistence_uri)\n        if not match:\n            raise ValueError(\"Couldn't parse persistence URI: %s -- regex: %s)\"\n                             % (persistence_uri, regex))\n\n        conn_params = match.groupdict()\n        missing = {'proto', 'job_id', 'database'} - set(conn_params)\n        if missing:\n            raise ValueError('Missing required parameters: %s (given params: %s)'\n                             % (tuple(missing), conn_params))\n\n        persistence_state_id = int(conn_params.pop('job_id'))\n        db_uri = cls.build_db_conn_uri(**conn_params)\n        return db_uri, persistence_state_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a configuration object from a URI.", "response": "def configuration_from_uri(cls, persistence_uri):\n        \"\"\"\n        Return a configuration object.\n        \"\"\"\n        db_uri, persistence_state_id = cls.parse_persistence_uri(persistence_uri)\n        engine = create_engine(db_uri)\n        Base.metadata.create_all(engine)\n        Base.metadata.bind = engine\n        DBSession = sessionmaker(bind=engine)\n        session = DBSession()\n        job = session.query(Job).filter(Job.id == persistence_state_id).first()\n        configuration = job.configuration\n        configuration = yaml.safe_load(configuration)\n        configuration['exporter_options']['resume'] = True\n        configuration['exporter_options']['persistence_state_id'] = persistence_state_id\n        return configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_input_files(cls, input_specification):\n        if isinstance(input_specification, (basestring, dict)):\n            input_specification = [input_specification]\n        elif not isinstance(input_specification, list):\n            raise ConfigurationError(\"Input specification must be string, list or dict.\")\n\n        out = []\n        for input_unit in input_specification:\n            if isinstance(input_unit, basestring):\n                out.append(input_unit)\n            elif isinstance(input_unit, dict):\n                missing = object()\n                directory = input_unit.get('dir', missing)\n                dir_pointer = input_unit.get('dir_pointer', missing)\n                if directory is missing and dir_pointer is missing:\n                    raise ConfigurationError(\n                        'Input directory dict must contain'\n                        ' \"dir\" or \"dir_pointer\" element (but not both)')\n                if directory is not missing and dir_pointer is not missing:\n                    raise ConfigurationError(\n                        'Input directory dict must not contain'\n                        ' both \"dir\" and \"dir_pointer\" elements')\n                if dir_pointer is not missing:\n                    directory = cls._get_pointer(dir_pointer)\n\n                out.extend(cls._get_directory_files(\n                    directory=directory,\n                    pattern=input_unit.get('pattern'),\n                    include_dot_files=input_unit.get('include_dot_files', False)))\n            else:\n                raise ConfigurationError('Input must only contain strings or dicts')\n        return out", "response": "Get list of input files according to input definition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_next_batch(self):\n        messages = self.get_from_kafka()\n        if messages:\n            for message in messages:\n                item = BaseRecord(message)\n                self.increase_read()\n                yield item\n\n        self.logger.debug('Done reading batch')\n        self.last_position = self.consumer.offsets", "response": "This method returns a list or a generator that yields BaseRecords from the manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding messages from the reservoir.", "response": "def consume_messages(self, batchsize):\n        \"\"\" Get messages batch from the reservoir \"\"\"\n        if not self._reservoir:\n            self.finished = True\n            return\n        for msg in self._reservoir[:batchsize]:\n            yield msg\n        self._reservoir = self._reservoir[batchsize:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecompress pre - defined compressed fields for each message.", "response": "def decompress_messages(self, offmsgs):\n        \"\"\" Decompress pre-defined compressed fields for each message.\n            Msgs should be unpacked before this step. \"\"\"\n\n        for offmsg in offmsgs:\n            yield offmsg.message.key, self.decompress_fun(offmsg.message.value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unpack_messages(msgs):\n        import msgpack\n        \"\"\" Deserialize a message to python structures \"\"\"\n\n        for key, msg in msgs:\n            record = msgpack.unpackb(msg)\n            record['_key'] = key\n            yield record", "response": "Unpack a list of messages into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the last position of the data in the consumer.", "response": "def set_last_position(self, last_position):\n        \"\"\"\n        Called from the manager, it is in charge of updating the last position of data commited\n        by the writer, in order to have resume support\n        \"\"\"\n        if last_position is None:\n            self.last_position = {}\n            for partition in self.partitions:\n                self.last_position[partition] = 0\n            self.consumer.offsets = self.last_position.copy()\n            self.consumer.fetch_offsets = self.consumer.offsets.copy()\n        else:\n            self.last_position = last_position\n            self.consumer.offsets = last_position.copy()\n            self.consumer.fetch_offsets = self.consumer.offsets.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the last position of the items in the current record.", "response": "def set_last_position(self, last_position):\n        \"\"\"\n        Called from the manager, it is in charge of updating the last position of data commited\n        by the writer, in order to have resume support\n        \"\"\"\n        if last_position:\n            if isinstance(last_position, six.string_types):\n                last_key = last_position\n            else:\n                last_key = last_position.get('last_key', '')\n            self.last_position = dict(last_key=last_key)\n            self.collection_scanner.set_startafter(last_key)\n        else:\n            self.last_position = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_batch(self, batch):\n        for item in batch:\n            if self.filter(item):\n                yield item\n            else:\n                self.set_metadata('filtered_out',\n                                  self.get_metadata('filtered_out') + 1)\n\n            self.total += 1\n            self._log_progress()", "response": "Returns a generator that yields items from the given batch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_batch(self, batch):\n        for item in batch:\n            self.write_buffer.buffer(item)\n            key = self.write_buffer.get_key_from_item(item)\n            if self.write_buffer.should_write_buffer(key):\n                self._write_current_buffer_for_group_key(key)\n            self.increment_written_items()\n            self._check_items_limit()", "response": "Writes a batch of items to the internal buffer and updates internal counters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises ItemsLimitReached if the items_limit is reached.", "response": "def _check_items_limit(self):\n        \"\"\"\n        Raise ItemsLimitReached if the writer reached the configured items limit.\n        \"\"\"\n        if self.items_limit and self.items_limit == self.get_metadata('items_count'):\n            raise ItemsLimitReached('Finishing job after items_limit reached:'\n                                    ' {} items written.'.format(self.get_metadata('items_count')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflushes all remaining buffers.", "response": "def flush(self):\n        \"\"\"\n        Ensure all remaining buffers are written.\n        \"\"\"\n        for key in self.grouping_info.keys():\n            if self._should_flush(key):\n                self._write_current_buffer_for_group_key(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _write_current_buffer_for_group_key(self, key):\n        write_info = self.write_buffer.pack_buffer(key)\n        self.write(write_info.get('file_path'),\n                   self.write_buffer.grouping_info[key]['membership'])\n        self.write_buffer.clean_tmp_files(write_info)\n        self.write_buffer.add_new_buffer_for_group(key)", "response": "Find the current buffer for a given group key and write it to self. write_buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a valid filename that is a prefix of the file.", "response": "def get_file_suffix(self, path, prefix):\n        \"\"\"\n        Gets a valid filename\n        \"\"\"\n        parent = self._ensure_folder_path(path)\n\n        file_list = self.drive.ListFile({\n            'q': \"'{}' in parents and trashed=false and title contains '{}'\".format(\n                parent['id'], prefix)}).GetList()\n        try:\n            number_of_files = len(file_list)\n        except:\n            number_of_files = 0\n        return '{0:04}'.format(number_of_files)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ensure_folder_path(self, filebase_path):\n        folders = filebase_path.split('/')\n        parent = {\"id\": \"root\"}\n        for folder in folders:\n            file_list = self.drive.ListFile(\n                {'q': \"'{}' in parents and trashed=false and title = '{}'\".format(\n                    parent['id'], folder)}).GetList()\n            if not len(file_list):\n                f = self.drive.CreateFile({'title': folder, 'parents': [parent],\n                                           'mimeType': 'application/vnd.google-apps.folder'})\n                f.Upload()\n            else:\n                parent = {\"id\": file_list[-1][\"id\"]}\n        return parent", "response": "Creates the directory for the path given recursively creating\n        parent directories when needed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the object to the database.", "response": "def save(self, commit=True, **kwargs):\n        '''\n        PeriodicTask is dynamic and save behavior changed\n        See: https://github.com/zakird/celerybeat-mongo/commit/dfbbd20edde91134b57f5406d0ce4eac59d6899b\n        '''\n        if not self.instance:\n            self.instance = self.model_class()  # Force populate_obj in super()\n        return super(PeriodicTaskForm, self).save(commit, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies the existance of a JSON assets manifest", "response": "def has_manifest(app, filename='manifest.json'):\n    '''Verify the existance of a JSON assets manifest'''\n    try:\n        return pkg_resources.resource_exists(app, filename)\n    except ImportError:\n        return os.path.isabs(filename) and os.path.exists(filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_manifest(app, filename='manifest.json'):\n    '''Register an assets json manifest'''\n    if current_app.config.get('TESTING'):\n        return  # Do not spend time here when testing\n    if not has_manifest(app, filename):\n        msg = '{filename} not found for {app}'.format(**locals())\n        raise ValueError(msg)\n    manifest = _manifests.get(app, {})\n    manifest.update(load_manifest(app, filename))\n    _manifests[app] = manifest", "response": "Register an assets json manifest"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_manifest(app, filename='manifest.json'):\n    '''Load an assets json manifest'''\n    if os.path.isabs(filename):\n        path = filename\n    else:\n        path = pkg_resources.resource_filename(app, filename)\n    with io.open(path, mode='r', encoding='utf8') as stream:\n        data = json.load(stream)\n    _registered_manifests[app] = path\n    return data", "response": "Load an assets json manifest"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the path to a static file for a given application entry.", "response": "def from_manifest(app, filename, raw=False, **kwargs):\n    '''\n    Get the path to a static file for a given app entry of a given type.\n\n    :param str app: The application key to which is tied this manifest\n    :param str filename: the original filename (without hash)\n    :param bool raw: if True, doesn't add prefix to the manifest\n    :return: the resolved file path from manifest\n    :rtype: str\n    '''\n    cfg = current_app.config\n\n    if current_app.config.get('TESTING'):\n        return  # Do not spend time here when testing\n\n    path = _manifests[app][filename]\n\n    if not raw and cfg.get('CDN_DOMAIN') and not cfg.get('CDN_DEBUG'):\n        scheme = 'https' if cfg.get('CDN_HTTPS') else request.scheme\n        prefix = '{}://'.format(scheme)\n        if not path.startswith('/'):  # CDN_DOMAIN has no trailing slash\n            path = '/' + path\n        return ''.join((prefix, cfg['CDN_DOMAIN'], path))\n    elif not raw and kwargs.get('external', False):\n        if path.startswith('/'):  # request.host_url has a trailing slash\n            path = path[1:]\n        return ''.join((request.host_url, path))\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cdn_for(endpoint, **kwargs):\n    '''\n    Get a CDN URL for a static assets.\n\n    Do not use a replacement for all flask.url_for calls\n    as it is only meant for CDN assets URLS.\n    (There is some extra round trip which cost is justified\n    by the CDN assets prformance improvements)\n    '''\n    if current_app.config['CDN_DOMAIN']:\n        if not current_app.config.get('CDN_DEBUG'):\n            kwargs.pop('_external', None)  # Avoid the _external parameter in URL\n        return cdn_url_for(endpoint, **kwargs)\n    return url_for(endpoint, **kwargs)", "response": "Returns a CDN URL for the given endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_or_create(self, write_concern=None, auto_save=True,\n                      *q_objs, **query):\n        \"\"\"Retrieve unique object or create, if it doesn't exist.\n\n        Returns a tuple of ``(object, created)``, where ``object`` is\n        the retrieved or created object and ``created`` is a boolean\n        specifying whether a new object was created.\n\n        Taken back from:\n\n        https://github.com/MongoEngine/mongoengine/\n        pull/1029/files#diff-05c70acbd0634d6d05e4a6e3a9b7d66b\n        \"\"\"\n        defaults = query.pop('defaults', {})\n        try:\n            doc = self.get(*q_objs, **query)\n            return doc, False\n        except self._document.DoesNotExist:\n            query.update(defaults)\n            doc = self._document(**query)\n\n            if auto_save:\n                doc.save(write_concern=write_concern)\n            return doc, True", "response": "Retrieve unique object or create if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generic_in(self, **kwargs):\n        '''Bypass buggy GenericReferenceField querying issue'''\n        query = {}\n        for key, value in kwargs.items():\n            if not value:\n                continue\n            # Optimize query for when there is only one value\n            if isinstance(value, (list, tuple)) and len(value) == 1:\n                value = value[0]\n            if isinstance(value, (list, tuple)):\n                if all(isinstance(v, basestring) for v in value):\n                    ids = [ObjectId(v) for v in value]\n                    query['{0}._ref.$id'.format(key)] = {'$in': ids}\n                elif all(isinstance(v, DBRef) for v in value):\n                    query['{0}._ref'.format(key)] = {'$in': value}\n                elif all(isinstance(v, ObjectId) for v in value):\n                    query['{0}._ref.$id'.format(key)] = {'$in': value}\n            elif isinstance(value, ObjectId):\n                query['{0}._ref.$id'.format(key)] = value\n            elif isinstance(value, basestring):\n                query['{0}._ref.$id'.format(key)] = ObjectId(value)\n            else:\n                self.error('expect a list of string, ObjectId or DBRef')\n        return self(__raw__=query)", "response": "Bypass buggy GenericReferenceField querying issue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef issues_notifications(user):\n    '''Notify user about open issues'''\n    notifications = []\n\n    # Only fetch required fields for notification serialization\n    # Greatly improve performances and memory usage\n    qs = issues_for(user).only('id', 'title', 'created', 'subject')\n\n    # Do not dereference subject (so it's a DBRef)\n    # Also improve performances and memory usage\n    for issue in qs.no_dereference():\n        notifications.append((issue.created, {\n            'id': issue.id,\n            'title': issue.title,\n            'subject': {\n                'id': issue.subject['_ref'].id,\n                'type': issue.subject['_cls'].lower(),\n            }\n        }))\n\n    return notifications", "response": "Notify user about open issues"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an identicon configuration parameter.", "response": "def get_config(key):\n    '''\n    Get an identicon configuration parameter.\n\n    Precedance order is:\n        - application config (`udata.cfg`)\n        - theme config\n        - default\n    '''\n    key = 'AVATAR_{0}'.format(key.upper())\n    local_config = current_app.config.get(key)\n    return local_config or getattr(theme.current, key, DEFAULTS[key])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_provider():\n    '''Get the current provider from config'''\n    name = get_config('provider')\n    available = entrypoints.get_all('udata.avatars')\n    if name not in available:\n        raise ValueError('Unknown avatar provider: {0}'.format(name))\n    return available[name]", "response": "Get the current provider from config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating an identicon image.", "response": "def generate_pydenticon(identifier, size):\n    '''\n    Use pydenticon to generate an identicon image.\n    All parameters are extracted from configuration.\n    '''\n    blocks_size = get_internal_config('size')\n    foreground = get_internal_config('foreground')\n    background = get_internal_config('background')\n    generator = pydenticon.Generator(blocks_size, blocks_size,\n                                     digest=hashlib.sha1,\n                                     foreground=foreground,\n                                     background=background)\n\n    # Pydenticon adds padding to the size and as a consequence\n    # we need to compute the size without the padding\n    padding = int(round(get_internal_config('padding') * size / 100.))\n    size = size - 2 * padding\n    padding = (padding, ) * 4\n    return generator.generate(identifier, size, size,\n                              padding=padding,\n                              output_format='png')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef internal(identifier, size):\n    '''\n    Internal provider\n\n    Use pydenticon to generate an identicon.\n    '''\n    identicon = generate_pydenticon(identifier, size)\n    response = send_file(io.BytesIO(identicon), mimetype='image/png')\n    etag = hashlib.sha1(identicon).hexdigest()\n    response.set_etag(etag)\n    return response", "response": "Internal provider for generating an identicon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nredirecting to the external API for the availables.", "response": "def adorable(identifier, size):\n    '''\n    Adorable Avatars provider\n\n    Simply redirect to the external API.\n\n    See: http://avatars.adorable.io/\n    '''\n    url = ADORABLE_AVATARS_URL.format(identifier=identifier, size=size)\n    return redirect(url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef robohash(identifier, size):\n    '''\n    Robohash provider\n\n    Redirect to the Robohash API\n    with parameters extracted from configuration.\n\n    See: https://robohash.org/\n    '''\n    skin = get_config('robohash_skin')\n    background = get_config('robohash_background')\n    url = ROBOHASH_URL.format(\n        identifier=identifier, size=size, skin=skin, bg=background\n    )\n    return redirect(url)", "response": "Redirect to the Robohash API\n    with parameters extracted from configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfeeding the licenses from a JSON file", "response": "def licenses(source=DEFAULT_LICENSE_FILE):\n    '''Feed the licenses from a JSON file'''\n    if source.startswith('http'):\n        json_licenses = requests.get(source).json()\n    else:\n        with open(source) as fp:\n            json_licenses = json.load(fp)\n\n    if len(json_licenses):\n        log.info('Dropping existing licenses')\n        License.drop_collection()\n\n    for json_license in json_licenses:\n        flags = []\n        for field, flag in FLAGS_MAP.items():\n            if json_license.get(field, False):\n                flags.append(flag)\n\n        license = License.objects.create(\n            id=json_license['id'],\n            title=json_license['title'],\n            url=json_license['url'] or None,\n            maintainer=json_license['maintainer'] or None,\n            flags=flags,\n            active=json_license.get('active', False),\n            alternate_urls=json_license.get('alternate_urls', []),\n            alternate_titles=json_license.get('alternate_titles', []),\n        )\n        log.info('Added license \"%s\"', license.title)\n    try:\n        License.objects.get(id=DEFAULT_LICENSE['id'])\n    except License.DoesNotExist:\n        License.objects.create(**DEFAULT_LICENSE)\n        log.info('Added license \"%s\"', DEFAULT_LICENSE['title'])\n    success('Done')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lrun(command, *args, **kwargs):\n    '''Run a local command from project root'''\n    return run('cd {0} && {1}'.format(ROOT, command), *args, **kwargs)", "response": "Run a local command from project root"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize(self):\n        '''List all datasets for a given ...'''\n        fmt = guess_format(self.source.url)\n        # if format can't be guessed from the url\n        # we fallback on the declared Content-Type\n        if not fmt:\n            response = requests.head(self.source.url)\n            mime_type = response.headers.get('Content-Type', '').split(';', 1)[0]\n            if not mime_type:\n                msg = 'Unable to detect format from extension or mime type'\n                raise ValueError(msg)\n            fmt = guess_format(mime_type)\n            if not fmt:\n                msg = 'Unsupported mime type \"{0}\"'.format(mime_type)\n                raise ValueError(msg)\n        graph = self.parse_graph(self.source.url, fmt)\n        self.job.data = {'graph': graph.serialize(format='json-ld', indent=None)}", "response": "List all datasets for a given..."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_tasks():\n    '''Get a list of known tasks with their routing queue'''\n    return {\n        name: get_task_queue(name, cls)\n        for name, cls in celery.tasks.items()\n        # Exclude celery internal tasks\n        if not name.startswith('celery.')\n        # Exclude udata test tasks\n        and not name.startswith('test-')\n    }", "response": "Get a list of known tasks with their routing queue"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying registered tasks with their queue", "response": "def tasks():\n    '''Display registered tasks with their queue'''\n    tasks = get_tasks()\n    longest = max(tasks.keys(), key=len)\n    size = len(longest)\n    for name, queue in sorted(tasks.items()):\n        print('* {0}: {1}'.format(name.ljust(size), queue))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists queued tasks aggregated by name", "response": "def status(queue, munin, munin_config):\n    \"\"\"List queued tasks aggregated by name\"\"\"\n    if munin_config:\n        return status_print_config(queue)\n    queues = get_queues(queue)\n    for queue in queues:\n        status_print_queue(queue, munin=munin)\n    if not munin:\n        print('-' * 40)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls preprocessors before pre_validation", "response": "def pre_validate(self, form):\n        '''Calls preprocessors before pre_validation'''\n        for preprocessor in self._preprocessors:\n            preprocessor(form, self)\n        super(FieldHelper, self).pre_validate(form)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace empty values by None", "response": "def process_formdata(self, valuelist):\n        '''Replace empty values by None'''\n        super(EmptyNone, self).process_formdata(valuelist)\n        self.data = self.data or None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform validation only if data has been submitted", "response": "def validate(self, form, extra_validators=tuple()):\n        '''Perform validation only if data has been submitted'''\n        if not self.has_data:\n            return True\n        if self.is_list_data:\n            if not isinstance(self._formdata[self.name], (list, tuple)):\n                return False\n        return super(NestedModelList, self).validate(form, extra_validators)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_entry(self, formdata=None, data=unset_value, index=None):\n        '''\n        Fill the form with previous data if necessary to handle partial update\n        '''\n        if formdata:\n            prefix = '-'.join((self.name, str(index)))\n            basekey = '-'.join((prefix, '{0}'))\n            idkey = basekey.format('id')\n            if prefix in formdata:\n                formdata[idkey] = formdata.pop(prefix)\n            if hasattr(self.nested_model, 'id') and idkey in formdata:\n                id = self.nested_model.id.to_python(formdata[idkey])\n                data = get_by(self.initial_data, 'id', id)\n\n                initial = flatten_json(self.nested_form,\n                                       data.to_mongo(),\n                                       prefix)\n\n                for key, value in initial.items():\n                    if key not in formdata:\n                        formdata[key] = value\n            else:\n                data = None\n        return super(NestedModelList, self)._add_entry(formdata, data, index)", "response": "Add a new entry to the form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses fields and store individual errors", "response": "def parse(self, data):\n        '''Parse fields and store individual errors'''\n        self.field_errors = {}\n        return dict(\n            (k, self._parse_value(k, v)) for k, v in data.items()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating all metrics for the current date", "response": "def update(site=False, organizations=False, users=False, datasets=False,\n           reuses=False):\n    '''Update all metrics for the current date'''\n    do_all = not any((site, organizations, users, datasets, reuses))\n\n    if do_all or site:\n        log.info('Update site metrics')\n        update_site_metrics()\n\n    if do_all or datasets:\n        log.info('Update datasets metrics')\n        for dataset in Dataset.objects.timeout(False):\n            update_metrics_for(dataset)\n\n    if do_all or reuses:\n        log.info('Update reuses metrics')\n        for reuse in Reuse.objects.timeout(False):\n            update_metrics_for(reuse)\n\n    if do_all or organizations:\n        log.info('Update organizations metrics')\n        for organization in Organization.objects.timeout(False):\n            update_metrics_for(organization)\n\n    if do_all or users:\n        log.info('Update user metrics')\n        for user in User.objects.timeout(False):\n            update_metrics_for(user)\n\n    success('All metrics have been updated')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list():\n    '''List all known metrics'''\n    for cls, metrics in metric_catalog.items():\n        echo(white(cls.__name__))\n\n        for metric in metrics.keys():\n            echo('> {0}'.format(metric))", "response": "List all known metrics"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef labels_for_zone(zone):\n    '''\n    Extract all known zone labels\n    - main code\n    - keys (postal...)\n    - name translation in every supported languages\n    '''\n    labels = set([zone.name, zone.code] + zone.keys_values)\n    for lang in current_app.config['LANGUAGES'].keys():\n        with language(lang):\n            labels.add(_(zone.name))\n    return list(labels)", "response": "Extract all known zone labels for a given zone"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump JSON data to a file", "response": "def json_to_file(data, filename, pretty=False):\n    '''Dump JSON data to a file'''\n    kwargs = dict(indent=4) if pretty else {}\n    dirname = os.path.dirname(filename)\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n    dump = json.dumps(api.__schema__, **kwargs)\n    with open(filename, 'wb') as f:\n        f.write(dump.encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef postman(filename, pretty, urlvars, swagger):\n    '''Dump the API as a Postman collection'''\n    data = api.as_postman(urlvars=urlvars, swagger=swagger)\n    json_to_file(data, filename, pretty)", "response": "Dump the API as a Postman collection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the Swagger / OpenAPI specification with your config", "response": "def validate():\n    '''Validate the Swagger/OpenAPI specification with your config'''\n    with current_app.test_request_context():\n        schema = json.loads(json.dumps(api.__schema__))\n    try:\n        schemas.validate(schema)\n        success('API specifications are valid')\n    except schemas.SchemaValidationError as e:\n        exit_with_error('API specifications are not valid', e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef notify_badge_added_certified(sender, kind=''):\n    '''\n    Send an email when a `CERTIFIED` badge is added to an `Organization`\n\n    Parameters\n    ----------\n    sender\n        The object that emitted the event.\n    kind: str\n        The kind of `Badge` object awarded.\n    '''\n    if kind == CERTIFIED and isinstance(sender, Organization):\n        recipients = [member.user for member in sender.members]\n        subject = _(\n            'Your organization \"%(name)s\" has been certified',\n            name=sender.name\n        )\n        mail.send(\n            subject,\n            recipients,\n            'badge_added_certified',\n            organization=sender,\n            badge=sender.get_badge(kind)\n        )", "response": "Send an email when a CERTIFIED badge is added to an Organization."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discussions_notifications(user):\n    '''Notify user about open discussions'''\n    notifications = []\n\n    # Only fetch required fields for notification serialization\n    # Greatly improve performances and memory usage\n    qs = discussions_for(user).only('id', 'created', 'title', 'subject')\n\n    # Do not dereference subject (so it's a DBRef)\n    # Also improve performances and memory usage\n    for discussion in qs.no_dereference():\n        notifications.append((discussion.created, {\n            'id': discussion.id,\n            'title': discussion.title,\n            'subject': {\n                'id': discussion.subject['_ref'].id,\n                'type': discussion.subject['_cls'].lower(),\n            }\n        }))\n\n    return notifications", "response": "Notify user about open discussions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_signal(signal, request, user, **kwargs):\n    '''Generic method to send signals to Piwik\n\n    given that we always have to compute IP and UID for instance.\n    '''\n    params = {\n        'user_ip': request.remote_addr\n    }\n    params.update(kwargs)\n    if user.is_authenticated:\n        params['uid'] = user.id\n    signal.send(request.url, **params)", "response": "Generic method to send signals to Piwik\n    given that we always have to compute IP and UID for instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef membership_request_notifications(user):\n    '''Notify user about pending membership requests'''\n    orgs = [o for o in user.organizations if o.is_admin(user)]\n    notifications = []\n\n    for org in orgs:\n        for request in org.pending_requests:\n            notifications.append((request.created, {\n                'id': request.id,\n                'organization': org.id,\n                'user': {\n                    'id': request.user.id,\n                    'fullname': request.user.fullname,\n                    'avatar': str(request.user.avatar)\n                }\n            }))\n\n    return notifications", "response": "Notify user about pending membership requests"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(name, url, backend, frequency=None, owner=None, org=None):\n    '''Create a new harvest source'''\n    log.info('Creating a new Harvest source \"%s\"', name)\n    source = actions.create_source(name, url, backend,\n                                   frequency=frequency,\n                                   owner=owner,\n                                   organization=org)\n    log.info('''Created a new Harvest source:\n    name: {0.name},\n    slug: {0.slug},\n    url: {0.url},\n    backend: {0.backend},\n    frequency: {0.frequency},\n    owner: {0.owner},\n    organization: {0.organization}'''.format(source))", "response": "Create a new harvest source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(identifier):\n    '''Validate a source given its identifier'''\n    source = actions.validate_source(identifier)\n    log.info('Source %s (%s) has been validated', source.slug, str(source.id))", "response": "Validate a source given its identifier"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a harvest source", "response": "def delete(identifier):\n    '''Delete a harvest source'''\n    log.info('Deleting source \"%s\"', identifier)\n    actions.delete_source(identifier)\n    log.info('Deleted source \"%s\"', identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all harvest sources", "response": "def sources(scheduled=False):\n    '''List all harvest sources'''\n    sources = actions.list_sources()\n    if scheduled:\n        sources = [s for s in sources if s.periodic_task]\n    if sources:\n        for source in sources:\n            msg = '{source.name} ({source.backend}): {cron}'\n            if source.periodic_task:\n                cron = source.periodic_task.schedule_display\n            else:\n                cron = 'not scheduled'\n            log.info(msg.format(source=source, cron=cron))\n    elif scheduled:\n        log.info('No sources scheduled yet')\n    else:\n        log.info('No sources defined yet')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schedule(identifier, **kwargs):\n    '''Schedule a harvest job to run periodically'''\n    source = actions.schedule(identifier, **kwargs)\n    msg = 'Scheduled {source.name} with the following crontab: {cron}'\n    log.info(msg.format(source=source, cron=source.periodic_task.crontab))", "response": "Schedule a harvest job to run periodically"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unschedule(identifier):\n    '''Unschedule a periodical harvest job'''\n    source = actions.unschedule(identifier)\n    log.info('Unscheduled harvest source \"%s\"', source.name)", "response": "Unschedule a periodical harvest job."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attach(domain, filename):\n    '''\n    Attach existing datasets to their harvest remote id\n\n    Mapping between identifiers should be in FILENAME CSV file.\n    '''\n    log.info('Attaching datasets for domain %s', domain)\n    result = actions.attach(domain, filename)\n    log.info('Attached %s datasets to %s', result.success, domain)", "response": "Attach existing datasets to their harvest remote id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitiating a transfer request", "response": "def request_transfer(subject, recipient, comment):\n    '''Initiate a transfer request'''\n    TransferPermission(subject).test()\n    if recipient == (subject.organization or subject.owner):\n        raise ValueError(\n            'Recipient should be different than the current owner')\n    transfer = Transfer.objects.create(\n        owner=subject.organization or subject.owner,\n        recipient=recipient,\n        subject=subject,\n        comment=comment\n    )\n    return transfer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accept_transfer(transfer, comment=None):\n    '''Accept an incoming a transfer request'''\n    TransferResponsePermission(transfer).test()\n\n    transfer.responded = datetime.now()\n    transfer.responder = current_user._get_current_object()\n    transfer.status = 'accepted'\n    transfer.response_comment = comment\n    transfer.save()\n\n    subject = transfer.subject\n    recipient = transfer.recipient\n    if isinstance(recipient, Organization):\n        subject.organization = recipient\n    elif isinstance(recipient, User):\n        subject.owner = recipient\n\n    subject.save()\n\n    return transfer", "response": "Accept an incoming transfer request"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrefuse an incoming transfer request", "response": "def refuse_transfer(transfer, comment=None):\n    '''Refuse an incoming a transfer request'''\n    TransferResponsePermission(transfer).test()\n\n    transfer.responded = datetime.now()\n    transfer.responder = current_user._get_current_object()\n    transfer.status = 'refused'\n    transfer.response_comment = comment\n    transfer.save()\n\n    return transfer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean(self):\n        '''Fill metrics with defaults on create'''\n        if not self.metrics:\n            self.metrics = dict(\n                (name, spec.default)\n                for name, spec in (metric_catalog.get(self.__class__, {})\n                                                 .items()))\n        return super(WithMetrics, self).clean()", "response": "Fill metrics with defaults on create"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the DCAT catalog for this site", "response": "def build_catalog(site, datasets, format=None):\n    '''Build the DCAT catalog for this site'''\n    site_url = url_for('site.home_redirect', _external=True)\n    catalog_url = url_for('site.rdf_catalog', _external=True)\n    graph = Graph(namespace_manager=namespace_manager)\n    catalog = graph.resource(URIRef(catalog_url))\n\n    catalog.set(RDF.type, DCAT.Catalog)\n    catalog.set(DCT.title, Literal(site.title))\n    catalog.set(DCT.language,\n                Literal(current_app.config['DEFAULT_LANGUAGE']))\n    catalog.set(FOAF.homepage, URIRef(site_url))\n\n    publisher = graph.resource(BNode())\n    publisher.set(RDF.type, FOAF.Organization)\n    publisher.set(FOAF.name, Literal(current_app.config['SITE_AUTHOR']))\n    catalog.set(DCT.publisher, publisher)\n\n    for dataset in datasets:\n        catalog.add(DCAT.dataset, dataset_to_rdf(dataset, graph))\n\n    if isinstance(datasets, Paginable):\n        if not format:\n            raise ValueError('Pagination requires format')\n        catalog.add(RDF.type, HYDRA.Collection)\n        catalog.set(HYDRA.totalItems, Literal(datasets.total))\n        kwargs = {\n            'format': format,\n            'page_size': datasets.page_size,\n            '_external': True,\n        }\n\n        first_url = url_for('site.rdf_catalog_format', page=1, **kwargs)\n        page_url = url_for('site.rdf_catalog_format',\n                           page=datasets.page, **kwargs)\n        last_url = url_for('site.rdf_catalog_format',\n                           page=datasets.pages, **kwargs)\n        pagination = graph.resource(URIRef(page_url))\n        pagination.set(RDF.type, HYDRA.PartialCollectionView)\n\n        pagination.set(HYDRA.first, URIRef(first_url))\n        pagination.set(HYDRA.last, URIRef(last_url))\n        if datasets.has_next:\n            next_url = url_for('site.rdf_catalog_format',\n                               page=datasets.page + 1, **kwargs)\n            pagination.set(HYDRA.next, URIRef(next_url))\n        if datasets.has_prev:\n            prev_url = url_for('site.rdf_catalog_format',\n                               page=datasets.page - 1, **kwargs)\n            pagination.set(HYDRA.previous, URIRef(prev_url))\n\n        catalog.set(HYDRA.view, pagination)\n\n    return catalog"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncast the lazy_gettext'ed subject to string before passing to Celery", "response": "def sendmail_proxy(subject, email, template, **context):\n    \"\"\"Cast the lazy_gettext'ed subject to string before passing to Celery\"\"\"\n    sendmail.delay(subject.value, email, template, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncollecting static files and directories into a directory.", "response": "def collect(path, no_input):\n    '''Collect static files'''\n    if exists(path):\n        msg = '\"%s\" directory already exists and will be erased'\n        log.warning(msg, path)\n        if not no_input:\n            click.confirm('Are you sure?', abort=True)\n\n        log.info('Deleting static directory \"%s\"', path)\n        shutil.rmtree(path)\n\n    prefix = current_app.static_url_path or current_app.static_folder\n    if prefix.startswith('/'):\n        prefix = prefix[1:]\n    destination = join(path, prefix)\n    log.info('Copying application assets into \"%s\"', destination)\n    shutil.copytree(current_app.static_folder, destination)\n\n    for blueprint in current_app.blueprints.values():\n        if blueprint.has_static_folder:\n            prefix = current_app.static_prefixes.get(blueprint.name)\n            prefix = prefix or blueprint.url_prefix or ''\n            prefix += blueprint.static_url_path or ''\n            if prefix.startswith('/'):\n                prefix = prefix[1:]\n\n            log.info('Copying %s assets to %s', blueprint.name, prefix)\n            destination = join(path, prefix)\n            copy_recursive(blueprint.static_folder, destination)\n\n    for prefix, source in current_app.config['STATIC_DIRS']:\n        log.info('Copying %s to %s', source, prefix)\n        destination = join(path, prefix)\n        copy_recursive(source, destination)\n\n    log.info('Done')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_harvester_notifications(user):\n    '''Notify admins about pending harvester validation'''\n    if not user.sysadmin:\n        return []\n\n    notifications = []\n\n    # Only fetch required fields for notification serialization\n    # Greatly improve performances and memory usage\n    qs = HarvestSource.objects(validation__state=VALIDATION_PENDING)\n    qs = qs.only('id', 'created_at', 'name')\n\n    for source in qs:\n        notifications.append((source.created_at, {\n            'id': source.id,\n            'name': source.name,\n        }))\n\n    return notifications", "response": "Notify admins about pending harvester validation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(app, name):\n    '''Get a backend given its name'''\n    backend = get_all(app).get(name)\n    if not backend:\n        msg = 'Harvest backend \"{0}\" is not registered'.format(name)\n        raise EntrypointError(msg)\n    return backend", "response": "Get a backend given its name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self):\n        '''Override search to match on topic tags'''\n        s = super(TopicSearchMixin, self).search()\n        s = s.filter('bool', should=[\n            Q('term', tags=tag) for tag in self.topic.tags\n        ])\n        return s", "response": "Override search to match on topic tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a local udata development server.", "response": "def serve(info, host, port, reload, debugger, eager_loading, with_threads):\n    '''\n    Runs a local udata development server.\n\n    This local server is recommended for development purposes only but it\n    can also be used for simple intranet deployments.\n\n    By default it will not support any sort of concurrency at all\n    to simplify debugging.\n    This can be changed with the --with-threads option which will enable basic\n    multithreading.\n\n    The reloader and debugger are by default enabled if the debug flag of\n    Flask is enabled and disabled otherwise.\n    '''\n    # Werkzeug logger is special and is required\n    # with this configuration for development server\n    logger = logging.getLogger('werkzeug')\n    logger.setLevel(logging.INFO)\n    logger.handlers = []\n\n    debug = current_app.config['DEBUG']\n    if reload is None:\n        reload = bool(debug)\n    if debugger is None:\n        debugger = bool(debug)\n    if eager_loading is None:\n        eager_loading = not reload\n\n    app = DispatchingApp(info.load_app, use_eager_loading=eager_loading)\n\n    settings = os.environ.get('UDATA_SETTINGS',\n                              os.path.join(os.getcwd(), 'udata.cfg'))\n    extra_files = [settings]\n    if reload:\n        extra_files.extend(assets.manifests_paths())\n\n    run_simple(host, port, app, use_reloader=reload,\n               use_debugger=debugger, threaded=with_threads,\n               extra_files=extra_files)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enforce_filetype_file(form, field):\n    '''Only allowed domains in resource.url when filetype is file'''\n    if form._fields.get('filetype').data != RESOURCE_FILETYPE_FILE:\n        return\n    domain = urlparse(field.data).netloc\n    allowed_domains = current_app.config['RESOURCES_FILE_ALLOWED_DOMAINS']\n    allowed_domains += [current_app.config.get('SERVER_NAME')]\n    if current_app.config.get('CDN_DOMAIN'):\n        allowed_domains.append(current_app.config['CDN_DOMAIN'])\n    if '*' in allowed_domains:\n        return\n    if domain and domain not in allowed_domains:\n        message = _('Domain \"{domain}\" not allowed for filetype \"{filetype}\"')\n        raise validators.ValidationError(message.format(\n            domain=domain, filetype=RESOURCE_FILETYPE_FILE\n        ))", "response": "Only allowed domains in resource. url when filetype is file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_legacy_frequencies(form, field):\n    ''' Map legacy frequencies to new ones'''\n    if field.data in LEGACY_FREQUENCIES:\n        field.data = LEGACY_FREQUENCIES[field.data]", "response": "Map legacy frequencies to new ones"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the percentage of availability for resources.", "response": "def resources_availability(self):\n        \"\"\"Return the percentage of availability for resources.\"\"\"\n        # Flatten the list.\n        availabilities = list(\n            chain(\n                *[org.check_availability() for org in self.organizations]\n            )\n        )\n        # Filter out the unknown\n        availabilities = [a for a in availabilities if type(a) is bool]\n        if availabilities:\n            # Trick will work because it's a sum() of booleans.\n            return round(100. * sum(availabilities) / len(availabilities), 2)\n        # if nothing is unavailable, everything is considered OK\n        return 100"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef datasets_org_count(self):\n        from udata.models import Dataset  # Circular imports.\n        return sum(Dataset.objects(organization=org).visible().count()\n                   for org in self.organizations)", "response": "Return the number of datasets of user s organizations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the number of followers of user s organizations.", "response": "def followers_org_count(self):\n        \"\"\"Return the number of followers of user's organizations.\"\"\"\n        from udata.models import Follow  # Circular imports.\n        return sum(Follow.objects(following=org).count()\n                   for org in self.organizations)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_badge(self, kind):\n        ''' Get a badge given its kind if present'''\n        candidates = [b for b in self.badges if b.kind == kind]\n        return candidates[0] if candidates else None", "response": "Get a badge given its kind if present"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_badge(self, kind):\n        '''Perform an atomic prepend for a new badge'''\n        badge = self.get_badge(kind)\n        if badge:\n            return badge\n        if kind not in getattr(self, '__badges__', {}):\n            msg = 'Unknown badge type for {model}: {kind}'\n            raise db.ValidationError(msg.format(model=self.__class__.__name__,\n                                                kind=kind))\n        badge = Badge(kind=kind)\n        if current_user.is_authenticated:\n            badge.created_by = current_user.id\n\n        self.update(__raw__={\n            '$push': {\n                'badges': {\n                    '$each': [badge.to_mongo()],\n                    '$position': 0\n                }\n            }\n        })\n        self.reload()\n        post_save.send(self.__class__, document=self)\n        on_badge_added.send(self, kind=kind)\n        return self.get_badge(kind)", "response": "Perform an atomic prepend for a new badge"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_badge(self, kind):\n        '''Perform an atomic removal for a given badge'''\n        self.update(__raw__={\n            '$pull': {\n                'badges': {'kind': kind}\n            }\n        })\n        self.reload()\n        on_badge_removed.send(self, kind=kind)\n        post_save.send(self.__class__, document=self)", "response": "Perform an atomic removal for a given badge"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef toggle_badge(self, kind):\n        '''Toggle a bdage given its kind'''\n        badge = self.get_badge(kind)\n        if badge:\n            return self.remove_badge(kind)\n        else:\n            return self.add_badge(kind)", "response": "Toggle a bdage given its kind"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef badge_label(self, badge):\n        '''Display the badge label for a given kind'''\n        kind = badge.kind if isinstance(badge, Badge) else badge\n        return self.__badges__[kind]", "response": "Display the badge label for a given kind"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a queryset to query discussions related to a given user s assets.", "response": "def discussions_for(user, only_open=True):\n    '''\n    Build a queryset to query discussions related to a given user's assets.\n\n    It includes discussions coming from the user's organizations\n\n    :param bool only_open: whether to include closed discussions or not.\n    '''\n    # Only fetch required fields for discussion filtering (id and slug)\n    # Greatly improve performances and memory usage\n    datasets = Dataset.objects.owned_by(user.id, *user.organizations).only('id', 'slug')\n    reuses = Reuse.objects.owned_by(user.id, *user.organizations).only('id', 'slug')\n\n    qs = Discussion.objects(subject__in=list(datasets) + list(reuses))\n    if only_open:\n        qs = qs(closed__exists=False)\n    return qs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning relative links into external ones and avoid `nofollow` for us, otherwise add `nofollow`. That callback is not splitted in order to parse the URL only once.", "response": "def nofollow_callback(attrs, new=False):\n    \"\"\"\n    Turn relative links into external ones and avoid `nofollow` for us,\n\n    otherwise add `nofollow`.\n    That callback is not splitted in order to parse the URL only once.\n    \"\"\"\n    parsed_url = urlparse(attrs[(None, 'href')])\n    if parsed_url.netloc in ('', current_app.config['SERVER_NAME']):\n        attrs[(None, 'href')] = '{scheme}://{netloc}{path}'.format(\n            scheme='https' if request.is_secure else 'http',\n            netloc=current_app.config['SERVER_NAME'],\n            path=parsed_url.path)\n        return attrs\n    else:\n        rel = [x for x in attrs.get((None, 'rel'), '').split(' ') if x]\n        if 'nofollow' not in [x.lower() for x in rel]:\n            rel.append('nofollow')\n        attrs[(None, 'rel')] = ' '.join(rel)\n        return attrs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean a BLEACH XML file.", "response": "def bleach_clean(stream):\n    \"\"\"\n    Sanitize malicious attempts but keep the `EXCERPT_TOKEN`.\n    By default, only keeps `bleach.ALLOWED_TAGS`.\n    \"\"\"\n    return bleach.clean(\n        stream,\n        tags=current_app.config['MD_ALLOWED_TAGS'],\n        attributes=current_app.config['MD_ALLOWED_ATTRIBUTES'],\n        styles=current_app.config['MD_ALLOWED_STYLES'],\n        strip_comments=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mdstrip(value, length=None, end='\u2026'):\n    '''\n    Truncate and strip tags from a markdown source\n\n    The markdown source is truncated at the excerpt if present and\n    smaller than the required length. Then, all html tags are stripped.\n    '''\n    if not value:\n        return ''\n    if EXCERPT_TOKEN in value:\n        value = value.split(EXCERPT_TOKEN, 1)[0]\n    rendered = md(value, wrap=False)\n    text = do_striptags(rendered)\n    text = bleach_clean(text)\n    if length and length > 0:\n        text = do_truncate(None, text, length, end=end, leeway=2)\n    return text", "response": "Truncate and strip tags from a markdown source."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntoggle a badge_kind for a given path_or_id", "response": "def toggle(path_or_id, badge_kind):\n    '''Toggle a `badge_kind` for a given `path_or_id`\n\n    The `path_or_id` is either an id, a slug or a file containing a list\n    of ids or slugs.\n    '''\n    if exists(path_or_id):\n        with open(path_or_id) as open_file:\n            for id_or_slug in open_file.readlines():\n                toggle_badge(id_or_slug.strip(), badge_kind)\n    else:\n        toggle_badge(path_or_id, badge_kind)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload(name):\n    '''Handle upload on POST if authorized.'''\n    storage = fs.by_name(name)\n    return jsonify(success=True, **handle_upload(storage))", "response": "Handle upload on POST if authorized."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reindex_model_on_save(sender, document, **kwargs):\n    '''(Re/Un)Index Mongo document on post_save'''\n    if current_app.config.get('AUTO_INDEX'):\n        reindex.delay(document)", "response": "Reindex the document on post_save."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a search adapter", "response": "def register(adapter):\n    '''Register a search adapter'''\n    # register the class in the catalog\n    if adapter.model and adapter.model not in adapter_catalog:\n        adapter_catalog[adapter.model] = adapter\n        # Automatically (re|un)index objects on save/delete\n        post_save.connect(reindex_model_on_save, sender=adapter.model)\n        post_delete.connect(unindex_model_on_delete, sender=adapter.model)\n    return adapter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize(self, index_name=None):\n        '''Create or update indices and mappings'''\n        index_name = index_name or self.index_name\n        index = Index(index_name, using=es.client)\n        for adapter_class in adapter_catalog.values():\n            index.doc_type(adapter_class)\n        index.create()", "response": "Create or update indices and mappings"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps the process method to store the current object instance", "response": "def process(self, formdata=None, obj=None, data=None, **kwargs):\n        '''Wrap the process method to store the current object instance'''\n        self._obj = obj\n        super(CommonFormMixin, self).process(formdata, obj, data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(name):\n    '''Get a linkchecker given its name or fallback on default'''\n    linkcheckers = get_enabled(ENTRYPOINT, current_app)\n    linkcheckers.update(no_check=NoCheckLinkchecker)  # no_check always enabled\n    selected_linkchecker = linkcheckers.get(name)\n    if not selected_linkchecker:\n        default_linkchecker = current_app.config.get(\n                                'LINKCHECKING_DEFAULT_LINKCHECKER')\n        selected_linkchecker = linkcheckers.get(default_linkchecker)\n    if not selected_linkchecker:\n        log.error('No linkchecker found ({} requested and no fallback)'.format(\n                  name))\n    return selected_linkchecker", "response": "Get a linkchecker given its name or fallback on default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all notifications for a given user", "response": "def get_notifications(user):\n    '''List notification for a given user'''\n    notifications = []\n\n    for name, func in _providers.items():\n        notifications.extend([{\n            'type': name,\n            'created_on': dt,\n            'details': details\n        } for dt, details in func(user)])\n\n    return notifications"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_tags(self):\n    '''Count tag occurences by type and update the tag collection'''\n    for key, model in TAGGED.items():\n        collection = '{0}_tags'.format(key)\n        results = (model.objects(tags__exists=True)\n                        .map_reduce(map_tags, reduce_tags, collection))\n        for result in results:\n            tag, created = Tag.objects.get_or_create(name=result.key,\n                                                     auto_save=False)\n            tag.counts[key] = int(result.value) if result.value else 0\n            tag.save()", "response": "Count occurences by type and update the tag collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a document into a new object.", "response": "def from_model(cls, document):\n        \"\"\"By default use the ``to_dict`` method\n\n        and exclude ``_id``, ``_cls`` and ``owner`` fields\n        \"\"\"\n        return cls(meta={'id': document.id}, **cls.serialize(document))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a FacetedSearch for a given list of facets.", "response": "def facet_search(cls, *facets):\n        '''\n        Build a FacetSearch for a given list of facets\n\n        Elasticsearch DSL doesn't allow to list facets\n        once and for all and then later select them.\n        They are always all requested\n\n        As we don't use them every time and facet computation\n        can take some time, we build the FacetedSearch\n        dynamically with only those requested.\n        '''\n        f = dict((k, v) for k, v in cls.facets.items() if k in facets)\n\n        class TempSearch(SearchQuery):\n            adapter = cls\n            analyzer = cls.analyzer\n            boosters = cls.boosters\n            doc_types = cls\n            facets = f\n            fields = cls.fields\n            fuzzy = cls.fuzzy\n            match_type = cls.match_type\n            model = cls.model\n\n        return TempSearch"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npopulates a slug field if needed.", "response": "def populate_slug(instance, field):\n    '''\n    Populate a slug field if needed.\n    '''\n    value = getattr(instance, field.db_field)\n\n    try:\n        previous = instance.__class__.objects.get(id=instance.id)\n    except Exception:\n        previous = None\n\n    # Field value has changed\n    changed = field.db_field in instance._get_changed_fields()\n    # Field initial value has been manually set\n    manual = not previous and value or changed\n\n    if not manual and field.populate_from:\n        # value to slugify is extracted from populate_from parameter\n        value = getattr(instance, field.populate_from)\n        if previous and value == getattr(previous, field.populate_from):\n            return value\n\n    if previous and getattr(previous, field.db_field) == value:\n        # value is unchanged from DB\n        return value\n\n    if previous and not changed and not field.update:\n        # Field is not manually set and slug should not update on change\n        return value\n\n    slug = field.slugify(value)\n\n    # This can happen when serializing an object which does not contain\n    # the properties used to generate the slug. Typically, when such\n    # an object is passed to one of the Celery workers (see issue #20).\n    if slug is None:\n        return\n\n    old_slug = getattr(previous, field.db_field, None)\n\n    if slug == old_slug:\n        return slug\n\n    # Ensure uniqueness\n    if field.unique:\n        base_slug = slug\n        index = 1\n        qs = instance.__class__.objects\n        if previous:\n            qs = qs(id__ne=previous.id)\n\n        def exists(s):\n            return qs(\n                class_check=False, **{field.db_field: s}\n            ).limit(1).count(True) > 0\n\n        while exists(slug):\n            slug = '{0}-{1}'.format(base_slug, index)\n            index += 1\n\n    # Track old slugs for this class\n    if field.follow and old_slug != slug:\n        ns = instance.__class__.__name__\n        # Destroy redirections from this new slug\n        SlugFollow.objects(namespace=ns, old_slug=slug).delete()\n\n        if old_slug:\n            # Create a redirect for previous slug\n            slug_follower, created = SlugFollow.objects.get_or_create(\n                namespace=ns,\n                old_slug=old_slug,\n                auto_save=False,\n            )\n            slug_follower.new_slug = slug\n            slug_follower.save()\n\n            # Maintain previous redirects\n            SlugFollow.objects(namespace=ns, new_slug=old_slug).update(new_slug=slug)\n\n    setattr(instance, field.db_field, slug)\n    return slug"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slugify(self, value):\n        '''\n        Apply slugification according to specified field rules\n        '''\n        if value is None:\n            return\n\n        return slugify.slugify(value, max_length=self.max_length,\n                               separator=self.separator,\n                               to_lower=self.lower_case)", "response": "Apply slugification according to specified field rules\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclean up slug redirections on object deletion", "response": "def cleanup_on_delete(self, sender, document, **kwargs):\n        '''\n        Clean up slug redirections on object deletion\n        '''\n        if not self.follow or sender is not self.owner_document:\n            return\n        slug = getattr(document, self.db_field)\n        namespace = self.owner_document.__name__\n        SlugFollow.objects(namespace=namespace, new_slug=slug).delete()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a job asynchronously", "response": "def delay(name, args, kwargs):\n    '''Run a job asynchronously'''\n    args = args or []\n    kwargs = dict(k.split() for k in kwargs) if kwargs else {}\n    if name not in celery.tasks:\n        log.error('Job %s not found', name)\n    job = celery.tasks[name]\n    log.info('Sending job %s', name)\n    async_result = job.delay(*args, **kwargs)\n    log.info('Job %s sended to workers', async_result.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef boolean(value):\n    '''\n    Convert the content of a string (or a number) to a boolean.\n    Do nothing when input value is already a boolean.\n\n    This filter accepts usual values for ``True`` and ``False``:\n    \"0\", \"f\", \"false\", \"n\", etc.\n    '''\n    if value is None or isinstance(value, bool):\n        return value\n\n    try:\n        return bool(int(value))\n    except ValueError:\n        lower_value = value.strip().lower()\n        if not lower_value:\n            return None\n        if lower_value in ('f', 'false', 'n', 'no', 'off'):\n            return False\n        if lower_value in ('on', 't', 'true', 'y', 'yes'):\n            return True\n        raise Invalid('Unable to parse boolean {0}'.format(value))", "response": "Convert the content of a string or a number to a boolean."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_url(default_scheme='http', **kwargs):\n    def converter(value):\n        if value is None:\n            return value\n        if '://' not in value and default_scheme:\n            value = '://'.join((default_scheme, value.strip()))\n        try:\n            return uris.validate(value)\n        except uris.ValidationError as e:\n            raise Invalid(e.message)\n    return converter", "response": "Returns a converter that converts a clean string to an URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash(value):\n    '''Detect an hash type'''\n    if not value:\n        return\n    elif len(value) == 32:\n        type = 'md5'\n    elif len(value) == 40:\n        type = 'sha1'\n    elif len(value) == 64:\n        type = 'sha256'\n    else:\n        return None\n    return {'type': type, 'value': value}", "response": "Detect an hash type"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef index_model(index_name, adapter):\n    ''' Indel all objects given a model'''\n    model = adapter.model\n    log.info('Indexing {0} objects'.format(model.__name__))\n    qs = model.objects\n    if hasattr(model.objects, 'visible'):\n        qs = qs.visible()\n    if adapter.exclude_fields:\n        qs = qs.exclude(*adapter.exclude_fields)\n\n    docs = iter_qs(qs, adapter)\n    docs = iter_for_index(docs, index_name)\n\n    for ok, info in streaming_bulk(es.client, docs, raise_on_error=False):\n        if not ok:\n            log.error('Unable to index %s \"%s\": %s', model.__name__,\n                      info['index']['_id'], info['index']['error'])", "response": "Indel all objects given a model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenabling refresh and force merge.", "response": "def enable_refresh(index_name):\n    '''\n    Enable refresh and force merge. To be used after indexing.\n\n    See: https://www.elastic.co/guide/en/elasticsearch/reference/master/indices-update-settings.html#bulk\n    '''  # noqa\n    refresh_interval = current_app.config['ELASTICSEARCH_REFRESH_INTERVAL']\n    es.indices.put_settings(index=index_name, body={\n        'index': {'refresh_interval': refresh_interval}\n    })\n    es.indices.forcemerge(index=index_name, request_timeout=30)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an alias for the current index.", "response": "def set_alias(index_name, delete=True):\n    '''\n    Properly end an indexation by creating an alias.\n    Previous alias is deleted if needed.\n    '''\n    log.info('Creating alias \"{0}\" on index \"{1}\"'.format(\n        es.index_name, index_name))\n    if es.indices.exists_alias(name=es.index_name):\n        alias = es.indices.get_alias(name=es.index_name)\n        previous_indices = alias.keys()\n        if index_name not in previous_indices:\n            es.indices.put_alias(index=index_name, name=es.index_name)\n        for index in previous_indices:\n            if index != index_name:\n                es.indices.delete_alias(index=index, name=es.index_name)\n                if delete:\n                    es.indices.delete(index=index)\n    else:\n        es.indices.put_alias(index=index_name, name=es.index_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_error(index_name, keep=False):\n    '''\n    Handle errors while indexing.\n    In case of error, properly log it, remove the index and exit.\n    If `keep` is `True`, index is not deleted.\n    '''\n    # Handle keyboard interrupt\n    signal.signal(signal.SIGINT, signal.default_int_handler)\n    signal.signal(signal.SIGTERM, signal.default_int_handler)\n    has_error = False\n    try:\n        yield\n    except KeyboardInterrupt:\n        print('')  # Proper warning message under the \"^C\" display\n        log.warning('Interrupted by signal')\n        has_error = True\n    except Exception as e:\n        log.error(e)\n        has_error = True\n    if has_error:\n        if not keep:\n            log.info('Removing index %s', index_name)\n            es.indices.delete(index=index_name)\n        sys.exit(-1)", "response": "Handle errors while indexing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index(models=None, name=None, force=False, keep=False):\n    '''\n    Initialize or rebuild the search index\n\n    Models to reindex can optionally be specified as arguments.\n    If not, all models are reindexed.\n    '''\n    index_name = name or default_index_name()\n\n    doc_types_names = [m.__name__.lower() for m in adapter_catalog.keys()]\n    models = [model.lower().rstrip('s') for model in (models or [])]\n    for model in models:\n        if model not in doc_types_names:\n            log.error('Unknown model %s', model)\n            sys.exit(-1)\n\n    log.info('Initiliazing index \"{0}\"'.format(index_name))\n    if es.indices.exists(index_name):\n        if IS_TTY and not force:\n            msg = 'Index {0} will be deleted, are you sure?'\n            click.confirm(msg.format(index_name), abort=True)\n        es.indices.delete(index_name)\n\n    es.initialize(index_name)\n\n    with handle_error(index_name, keep):\n\n        disable_refresh(index_name)\n        for adapter in iter_adapters():\n            if not models or adapter.doc_type().lower() in models:\n                index_model(index_name, adapter)\n            else:\n                log.info('Copying {0} objects to the new index'.format(\n                         adapter.model.__name__))\n                # Need upgrade to Elasticsearch-py 5.0.0 to write:\n                # es.reindex({\n                #     'source': {'index': es.index_name, 'type': adapter.doc_type()},\n                #     'dest': {'index': index_name}\n                # })\n                #\n                # http://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.Elasticsearch.reindex\n                # This method (introduced in Elasticsearch 2.3 but only in Elasticsearch-py 5.0.0)\n                # triggers a server-side documents copy.\n                # Instead we use this helper for meant for backward compatibility\n                # but with poor performance as copy is client-side (scan+bulk)\n                es_reindex(es.client, es.index_name, index_name, scan_kwargs={\n                    'doc_type': adapter.doc_type()\n                })\n\n        enable_refresh(index_name)\n    # At this step, we don't want error handler to delete the index\n    # in case of error\n    set_alias(index_name, delete=not keep)", "response": "Initialize or rebuild the search index for the specified models."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_app(config='udata.settings.Defaults', override=None,\n               init_logging=init_logging):\n    '''Factory for a minimal application'''\n    app = UDataApp(APP_NAME)\n    app.config.from_object(config)\n\n    settings = os.environ.get('UDATA_SETTINGS', join(os.getcwd(), 'udata.cfg'))\n    if exists(settings):\n        app.settings_file = settings  # Keep track of loaded settings for diagnostic\n        app.config.from_pyfile(settings)\n\n    if override:\n        app.config.from_object(override)\n\n    # Loads defaults from plugins\n    for pkg in entrypoints.get_roots(app):\n        if pkg == 'udata':\n            continue  # Defaults are already loaded\n        module = '{}.settings'.format(pkg)\n        if pkgutil.find_loader(module):\n            settings = pkgutil.get_loader(module)\n            for key, default in settings.__dict__.items():\n                app.config.setdefault(key, default)\n\n    app.json_encoder = UDataJsonEncoder\n\n    app.debug = app.config['DEBUG'] and not app.config['TESTING']\n\n    app.wsgi_app = ProxyFix(app.wsgi_app)\n\n    init_logging(app)\n    register_extensions(app)\n\n    return app", "response": "Factory for a minimal application"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a static file to the user.", "response": "def send_static_file(self, filename):\n        '''\n        Override default static handling:\n        - raises 404 if not debug\n        - handle static aliases\n        '''\n        if not self.debug:\n            self.logger.error('Static files are only served in debug')\n            abort(404)\n\n        cache_timeout = self.get_send_file_max_age(filename)\n\n        # Default behavior\n        if isfile(join(self.static_folder, filename)):\n            return send_static(self.static_folder, filename,\n                               cache_timeout=cache_timeout)\n\n        # Handle aliases\n        for prefix, directory in self.config.get('STATIC_DIRS', tuple()):\n            if filename.startswith(prefix):\n                real_filename = filename[len(prefix):]\n                if real_filename.startswith('/'):\n                    real_filename = real_filename[1:]\n                if isfile(join(directory, real_filename)):\n                    return send_static(directory, real_filename,\n                                       cache_timeout=cache_timeout)\n        abort(404)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nroots RDF endpoint with content negociation handling", "response": "def rdf_catalog():\n    '''Root RDF endpoint with content negociation handling'''\n    format = RDF_EXTENSIONS[negociate_content()]\n    url = url_for('site.rdf_catalog_format', format=format)\n    return redirect(url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an existing migration record if exists", "response": "def get_migration(plugin, filename):\n    '''Get an existing migration record if exists'''\n    db = get_db()\n    return db.migrations.find_one({'plugin': plugin, 'filename': filename})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute and record a migration", "response": "def execute_migration(plugin, filename, script, dryrun=False):\n    '''Execute and record a migration'''\n    db = get_db()\n    js = SCRIPT_WRAPPER.format(script)\n    lines = script.splitlines()\n    success = True\n    if not dryrun:\n        try:\n            lines = db.eval(js, plugin, filename, script)\n        except OperationFailure as e:\n            log.error(e.details['errmsg'].replace('\\n', '\\\\n'))\n            success = False\n        except PyMongoError as e:\n            log.error('Unable to apply migration: %s', str(e))\n            success = False\n    echo('\u2502'.encode('utf8'))\n    for line in lines:\n        echo('\u2502\u00a0{0}'.format(line).encode('utf8'))\n    echo('\u2502'.encode('utf8'))\n    echo('\u2514\u2500\u2500[{0}]'.format(green('OK') if success else red('KO')).encode('utf8'))\n    echo('')\n    return success"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of available migrations for udata and enabled plugins", "response": "def available_migrations():\n    '''\n    List available migrations for udata and enabled plugins\n\n    Each row is tuple with following signature:\n\n        (plugin, package, filename)\n    '''\n    migrations = []\n    for filename in resource_listdir('udata', 'migrations'):\n        if filename.endswith('.js'):\n            migrations.append(('udata', 'udata', filename))\n\n    plugins = entrypoints.get_enabled('udata.models', current_app)\n    for plugin, module in plugins.items():\n        if resource_isdir(module.__name__, 'migrations'):\n            for filename in resource_listdir(module.__name__, 'migrations'):\n                if filename.endswith('.js'):\n                    migrations.append((plugin, module.__name__, filename))\n    return sorted(migrations, key=lambda r: r[2])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay the database migrations status", "response": "def status():\n    '''Display the database migrations status'''\n    for plugin, package, filename in available_migrations():\n        migration = get_migration(plugin, filename)\n        if migration:\n            status = green(migration['date'].strftime(DATE_FORMAT))\n        else:\n            status = yellow('Not applied')\n        log_status(plugin, filename, status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a database migration record.", "response": "def unrecord(plugin_or_specs, filename):\n    '''\n    Remove a database migration record.\n\n    \\b\n    A record can be expressed with the following syntaxes:\n     - plugin filename\n     - plugin fliename.js\n     - plugin:filename\n     - plugin:fliename.js\n    '''\n    plugin, filename = normalize_migration(plugin_or_specs, filename)\n    migration = get_migration(plugin, filename)\n    if migration:\n        log.info('Removing migration %s:%s', plugin, filename)\n        db = get_db()\n        db.eval(UNRECORD_WRAPPER, migration['_id'])\n    else:\n        log.error('Migration not found %s:%s', plugin, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(url, schemes=None, tlds=None, private=None, local=None,\n             credentials=None):\n    '''\n    Validate and normalize an URL\n\n    :param str url: The URL to validate and normalize\n    :return str: The normalized URL\n    :raises ValidationError: when URL does not validate\n    '''\n    url = url.strip()\n\n    private = config_for(private, 'URLS_ALLOW_PRIVATE')\n    local = config_for(local, 'URLS_ALLOW_LOCAL')\n    credentials = config_for(credentials, 'URLS_ALLOW_CREDENTIALS')\n    schemes = config_for(schemes, 'URLS_ALLOWED_SCHEMES')\n    tlds = config_for(tlds, 'URLS_ALLOWED_TLDS')\n\n    match = URL_REGEX.match(url)\n    if not match:\n        error(url)\n\n    scheme = (match.group('scheme') or '').lower()\n    if scheme and scheme not in schemes:\n        error(url, 'Invalid scheme {0}'.format(scheme))\n\n    if not credentials and match.group('credentials'):\n        error(url, 'Credentials in URL are not allowed')\n\n    tld = match.group('tld')\n    if tld and tld not in tlds and tld.encode('idna') not in tlds:\n        error(url, 'Invalid TLD {0}'.format(tld))\n\n    ip = match.group('ipv6') or match.group('ipv4')\n    if ip:\n        try:\n            ip = IPAddress(ip)\n        except AddrFormatError:\n            error(url)\n        if ip.is_multicast():\n            error(url, '{0} is a multicast IP'.format(ip))\n        elif not ip.is_loopback() and ip.is_hostmask() or ip.is_netmask():\n            error(url, '{0} is a mask IP'.format(ip))\n\n    if not local:\n        if ip and ip.is_loopback() or match.group('localhost'):\n            error(url, 'is a local URL')\n\n    if not private and ip and ip.is_private():\n        error(url, 'is a private URL')\n\n    return url", "response": "Validate and normalize a URL and return the normalized URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef md(filename):\n    '''\n    Load .md (markdown) file and sanitize it for PyPI.\n    Remove unsupported github tags:\n     - code-block directive\n     - travis ci build badges\n    '''\n    content = io.open(filename).read()\n\n    for match in RE_BADGE.finditer(content):\n        if match.group('badge') not in BADGES_TO_KEEP:\n            content = content.replace(match.group(0), '')\n    return content", "response": "Load a. md file and sanitize it for PyPI."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize an extras key value pair into JSON - LD", "response": "def get_json_ld_extra(key, value):\n    '''Serialize an extras key, value pair into JSON-LD'''\n    value = value.serialize() if hasattr(value, 'serialize') else value\n    return {\n        '@type': 'http://schema.org/PropertyValue',\n        'name': key,\n        'value': value,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching a resource given its UUID", "response": "def get_resource(id):\n    '''Fetch a resource given its UUID'''\n    dataset = Dataset.objects(resources__id=id).first()\n    if dataset:\n        return get_by(dataset.resources, 'id', id)\n    else:\n        return CommunityResource.objects(id=id).first()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef guess(cls, *strings, **kwargs):\n        '''\n        Try to guess a license from a list of strings.\n\n        Accept a `default` keyword argument which will be\n        the default fallback license.\n        '''\n        license = None\n        for string in strings:\n            license = cls.guess_one(string)\n            if license:\n                break\n        return license or kwargs.get('default')", "response": "Try to guess a license from a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to guess license from a string.", "response": "def guess_one(cls, text):\n        '''\n        Try to guess license from a string.\n\n        Try to exact match on identifier then slugified title\n        and fallback on edit distance ranking (after slugification)\n        '''\n        if not text:\n            return\n        qs = cls.objects\n        text = text.strip().lower()  # Stored identifiers are lower case\n        slug = cls.slug.slugify(text)  # Use slug as it normalize string\n        license = qs(\n            db.Q(id=text) | db.Q(slug=slug) | db.Q(url=text)\n            | db.Q(alternate_urls=text)\n        ).first()\n        if license is None:\n            # Try to single match with a low Damerau-Levenshtein distance\n            computed = ((l, rdlevenshtein(l.slug, slug)) for l in cls.objects)\n            candidates = [l for l, d in computed if d <= MAX_DISTANCE]\n            # If there is more that one match, we cannot determinate\n            # which one is closer to safely choose between candidates\n            if len(candidates) == 1:\n                license = candidates[0]\n        if license is None:\n            # Try to single match with a low Damerau-Levenshtein distance\n            computed = (\n                (l, rdlevenshtein(cls.slug.slugify(t), slug))\n                for l in cls.objects\n                for t in l.alternate_titles\n            )\n            candidates = [l for l, d in computed if d <= MAX_DISTANCE]\n            # If there is more that one match, we cannot determinate\n            # which one is closer to safely choose between candidates\n            if len(candidates) == 1:\n                license = candidates[0]\n        return license"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef need_check(self):\n        '''Does the resource needs to be checked against its linkchecker?\n\n        We check unavailable resources often, unless they go over the\n        threshold. Available resources are checked less and less frequently\n        based on their historical availability.\n        '''\n        min_cache_duration, max_cache_duration, ko_threshold = [\n            current_app.config.get(k) for k in (\n                'LINKCHECKING_MIN_CACHE_DURATION',\n                'LINKCHECKING_MAX_CACHE_DURATION',\n                'LINKCHECKING_UNAVAILABLE_THRESHOLD',\n            )\n        ]\n        count_availability = self.extras.get('check:count-availability', 1)\n        is_available = self.check_availability()\n        if is_available == 'unknown':\n            return True\n        elif is_available or count_availability > ko_threshold:\n            delta = min(min_cache_duration * count_availability,\n                        max_cache_duration)\n        else:\n            delta = min_cache_duration\n        if self.extras.get('check:date'):\n            limit_date = datetime.now() - timedelta(minutes=delta)\n            check_date = self.extras['check:date']\n            if not isinstance(check_date, datetime):\n                try:\n                    check_date = parse_dt(check_date)\n                except (ValueError, TypeError):\n                    return True\n            if check_date >= limit_date:\n                return False\n        return True", "response": "Does the resource need to be checked against its linkchecker?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_availability(self):\n        # Only check remote resources.\n        remote_resources = [resource\n                            for resource in self.resources\n                            if resource.filetype == 'remote']\n        if not remote_resources:\n            return []\n        return [resource.check_availability() for resource in remote_resources]", "response": "Check if resources from that dataset are available."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the next expected update date for the current frequency and last_update.", "response": "def next_update(self):\n        \"\"\"Compute the next expected update date,\n\n        given the frequency and last_update.\n        Return None if the frequency is not handled.\n        \"\"\"\n        delta = None\n        if self.frequency == 'daily':\n            delta = timedelta(days=1)\n        elif self.frequency == 'weekly':\n            delta = timedelta(weeks=1)\n        elif self.frequency == 'fortnighly':\n            delta = timedelta(weeks=2)\n        elif self.frequency == 'monthly':\n            delta = timedelta(weeks=4)\n        elif self.frequency == 'bimonthly':\n            delta = timedelta(weeks=4 * 2)\n        elif self.frequency == 'quarterly':\n            delta = timedelta(weeks=52 / 4)\n        elif self.frequency == 'biannual':\n            delta = timedelta(weeks=52 / 2)\n        elif self.frequency == 'annual':\n            delta = timedelta(weeks=52)\n        elif self.frequency == 'biennial':\n            delta = timedelta(weeks=52 * 2)\n        elif self.frequency == 'triennial':\n            delta = timedelta(weeks=52 * 3)\n        elif self.frequency == 'quinquennial':\n            delta = timedelta(weeks=52 * 5)\n        if delta is None:\n            return\n        else:\n            return self.last_update + delta"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict filled with metrics related to the inner quality of the dataset.", "response": "def quality(self):\n        \"\"\"Return a dict filled with metrics related to the inner\n\n        quality of the dataset:\n\n            * number of tags\n            * description length\n            * and so on\n        \"\"\"\n        from udata.models import Discussion  # noqa: Prevent circular imports\n        result = {}\n        if not self.id:\n            # Quality is only relevant on saved Datasets\n            return result\n        if self.next_update:\n            result['frequency'] = self.frequency\n            result['update_in'] = -(self.next_update - datetime.now()).days\n        if self.tags:\n            result['tags_count'] = len(self.tags)\n        if self.description:\n            result['description_length'] = len(self.description)\n        if self.resources:\n            result['has_resources'] = True\n            result['has_only_closed_or_no_formats'] = all(\n                resource.closed_or_no_format for resource in self.resources)\n            result['has_unavailable_resources'] = not all(\n                self.check_availability())\n        discussions = Discussion.objects(subject=self)\n        if discussions:\n            result['discussions'] = len(discussions)\n            result['has_untreated_discussions'] = not all(\n                discussion.person_involved(self.owner)\n                for discussion in discussions)\n        result['score'] = self.compute_quality_score(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the score related to the quality of that dataset.", "response": "def compute_quality_score(self, quality):\n        \"\"\"Compute the score related to the quality of that dataset.\"\"\"\n        score = 0\n        UNIT = 2\n        if 'frequency' in quality:\n            # TODO: should be related to frequency.\n            if quality['update_in'] < 0:\n                score += UNIT\n            else:\n                score -= UNIT\n        if 'tags_count' in quality:\n            if quality['tags_count'] > 3:\n                score += UNIT\n        if 'description_length' in quality:\n            if quality['description_length'] > 100:\n                score += UNIT\n        if 'has_resources' in quality:\n            if quality['has_only_closed_or_no_formats']:\n                score -= UNIT\n            else:\n                score += UNIT\n            if quality['has_unavailable_resources']:\n                score -= UNIT\n            else:\n                score += UNIT\n        if 'discussions' in quality:\n            if quality['has_untreated_discussions']:\n                score -= UNIT\n            else:\n                score += UNIT\n        if score < 0:\n            return 0\n        return score"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_resource(self, resource):\n        '''Perform an atomic prepend for a new resource'''\n        resource.validate()\n        self.update(__raw__={\n            '$push': {\n                'resources': {\n                    '$each': [resource.to_mongo()],\n                    '$position': 0\n                }\n            }\n        })\n        self.reload()\n        post_save.send(self.__class__, document=self,\n                       resource_added=resource.id)", "response": "Perform an atomic prepend for a new resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_resource(self, resource):\n        '''Perform an atomic update for an existing resource'''\n        index = self.resources.index(resource)\n        data = {\n            'resources__{index}'.format(index=index): resource\n        }\n        self.update(**data)\n        self.reload()\n        post_save.send(self.__class__, document=self)", "response": "Perform an atomic update for an existing resource"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_aggregation(self, name):\n        '''\n        Fetch an aggregation result given its name\n\n        As there is no way at this point know the aggregation type\n        (ie. bucket, pipeline or metric)\n        we guess it from the response attributes.\n        Only bucket and metric types are handled\n        '''\n        agg = self.aggregations[name]\n        if 'buckets' in agg:\n            return agg['buckets']\n        else:\n            return agg", "response": "Get an aggregation result given its name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef language(lang_code):\n    '''Force a given language'''\n    ctx = None\n    if not request:\n        ctx = current_app.test_request_context()\n        ctx.push()\n    backup = g.get('lang_code')\n    g.lang_code = lang_code\n    refresh()\n    yield\n    g.lang_code = backup\n    if ctx:\n        ctx.pop()\n    refresh()", "response": "Force a given language"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef redirect_to_lang(*args, **kwargs):\n    '''Redirect non lang-prefixed urls to default language.'''\n    endpoint = request.endpoint.replace('_redirect', '')\n    kwargs = multi_to_dict(request.args)\n    kwargs.update(request.view_args)\n    kwargs['lang_code'] = default_lang\n    return redirect(url_for(endpoint, **kwargs))", "response": "Redirect non lang - prefixed urls to default language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef redirect_to_unlocalized(*args, **kwargs):\n    '''Redirect lang-prefixed urls to no prefixed URL.'''\n    endpoint = request.endpoint.replace('_redirect', '')\n    kwargs = multi_to_dict(request.args)\n    kwargs.update(request.view_args)\n    kwargs.pop('lang_code', None)\n    return redirect(url_for(endpoint, **kwargs))", "response": "Redirect lang - prefixed urls to no prefixed URL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the correct gettext translations that should be used for this request.", "response": "def get_translations(self):\n        \"\"\"Returns the correct gettext translations that should be used for\n        this request.  This will never fail and return a dummy translation\n        object if used outside of the request or if a translation cannot be\n        found.\n        \"\"\"\n        ctx = stack.top\n        if ctx is None:\n            return NullTranslations()\n\n        locale = get_locale()\n\n        cache = self.get_translations_cache(ctx)\n\n        translations = cache.get(str(locale))\n        if translations is None:\n            translations_dir = self.get_translations_path(ctx)\n            translations = Translations.load(translations_dir, locale,\n                                             domain=self.domain)\n\n            # Load plugins translations\n            if isinstance(translations, Translations):\n                # Load core extensions translations\n                from wtforms.i18n import messages_path\n                wtforms_translations = Translations.load(messages_path(),\n                                                         locale,\n                                                         domain='wtforms')\n                translations.merge(wtforms_translations)\n\n                import flask_security\n                flask_security_translations = Translations.load(\n                    join(flask_security.__path__[0], 'translations'),\n                    locale,\n                    domain='flask_security'\n                )\n                translations.merge(flask_security_translations)\n\n                for pkg in entrypoints.get_roots(current_app):\n                    package = pkgutil.get_loader(pkg)\n                    path = join(package.filename, 'translations')\n                    domains = [f.replace(path, '').replace('.pot', '')[1:]\n                               for f in iglob(join(path, '*.pot'))]\n                    for domain in domains:\n                        translations.merge(Translations.load(path, locale,\n                                                             domain=domain))\n\n                # Allows the theme to provide or override translations\n                from . import theme\n\n                theme_translations_dir = join(theme.current.path, 'translations')\n                if exists(theme_translations_dir):\n                    domain = theme.current.identifier\n                    theme_translations = Translations.load(theme_translations_dir,\n                                                           locale,\n                                                           domain=domain)\n                    translations.merge(theme_translations)\n\n                cache[str(locale)] = translations\n\n        return translations"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n        # Static assets are not localized\n        if endpoint == 'static':\n            return super(I18nBlueprintSetupState, self).add_url_rule(\n                rule, endpoint=endpoint, view_func=view_func, **options)\n        if self.url_prefix:\n            rule = self.url_prefix + rule\n        options.setdefault('subdomain', self.subdomain)\n        if endpoint is None:\n            endpoint = _endpoint_from_view_func(view_func)\n        defaults = self.url_defaults\n        if 'defaults' in options:\n            defaults = dict(defaults, **options.pop('defaults'))\n        # Handle an optional cors=True parameter\n        options.setdefault('cors', False)\n        if options.pop('cors', False):\n            methods = options.get('methods', ['GET'])\n            if 'HEAD' not in methods:\n                methods.append('HEAD')\n            if 'OPTIONS' not in methods:\n                methods.append('OPTIONS')\n            decorator = cors.crossdomain('*', headers='*', credentials=True)\n            view_func = decorator(view_func)\n            options['methods'] = methods\n\n        if options.pop('localize', True):\n            self.app.add_url_rule('/<lang:lang_code>' + rule,\n                                  '%s.%s' % (self.blueprint.name, endpoint),\n                                  view_func, defaults=defaults, **options)\n\n            self.app.add_url_rule(\n                rule, '%s.%s_redirect' % (self.blueprint.name, endpoint),\n                redirect_to_lang, defaults=defaults, **options)\n        else:\n            self.app.add_url_rule(rule,\n                                  '%s.%s' % (self.blueprint.name, endpoint),\n                                  view_func, defaults=defaults, **options)\n\n            self.app.add_url_rule(\n                '/<lang:lang_code>' + rule,\n                '%s.%s_redirect' % (self.blueprint.name, endpoint),\n                redirect_to_unlocalized, defaults=defaults, **options)", "response": "A helper method to register a url rule and optionally a view function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmaps a Resource domain model to a DCAT / RDF graph", "response": "def organization_to_rdf(org, graph=None):\n    '''\n    Map a Resource domain model to a DCAT/RDF graph\n    '''\n    graph = graph or Graph(namespace_manager=namespace_manager)\n    if org.id:\n        org_url = url_for('organizations.show_redirect',\n                          org=org.id,\n                          _external=True)\n        id = URIRef(org_url)\n    else:\n        id = BNode()\n    o = graph.resource(id)\n    o.set(RDF.type, FOAF.Organization)\n    o.set(FOAF.name, Literal(org.name))\n    o.set(RDFS.label, Literal(org.name))\n    if org.url:\n        o.set(FOAF.homepage, URIRef(org.url))\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the given person has been involved in the discussion False otherwise.", "response": "def person_involved(self, person):\n        \"\"\"Return True if the given person has been involved in the\n\n        discussion, False otherwise.\n        \"\"\"\n        return any(message.posted_by == person for message in self.discussion)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _compute_count_availability(resource, status, previous_status):\n    '''Compute the `check:count-availability` extra value'''\n    count_availability = resource.extras.get('check:count-availability', 1)\n    return count_availability + 1 if status == previous_status else 1", "response": "Compute the count - availability extra value for a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck of the resource s URL is part of LINKCHECKING_IGNORE_DOMAINS", "response": "def is_ignored(resource):\n    '''Check of the resource's URL is part of LINKCHECKING_IGNORE_DOMAINS'''\n    ignored_domains = current_app.config['LINKCHECKING_IGNORE_DOMAINS']\n    url = resource.url\n    if url:\n        parsed_url = urlparse(url)\n        return parsed_url.netloc in ignored_domains\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_resource(resource):\n    '''\n    Check a resource availability against a linkchecker backend\n\n    The linkchecker used can be configured on a resource basis by setting\n    the `resource.extras['check:checker']` attribute with a key that points\n    to a valid `udata.linkcheckers` entrypoint. If not set, it will\n    fallback on the default linkchecker defined by the configuration variable\n    `LINKCHECKING_DEFAULT_LINKCHECKER`.\n\n    Returns\n    -------\n    dict or (dict, int)\n        Check results dict and status code (if error).\n    '''\n    linkchecker_type = resource.extras.get('check:checker')\n    LinkChecker = get_linkchecker(linkchecker_type)\n    if not LinkChecker:\n        return {'error': 'No linkchecker configured.'}, 503\n    if is_ignored(resource):\n        return dummy_check_response()\n    result = LinkChecker().check(resource)\n    if not result:\n        return {'error': 'No response from linkchecker'}, 503\n    elif result.get('check:error'):\n        return {'error': result['check:error']}, 500\n    elif not result.get('check:status'):\n        return {'error': 'No status in response from linkchecker'}, 503\n    # store the check result in the resource's extras\n    # XXX maybe this logic should be in the `Resource` model?\n    previous_status = resource.extras.get('check:available')\n    check_keys = _get_check_keys(result, resource, previous_status)\n    resource.extras.update(check_keys)\n    resource.save(signal_kwargs={'ignores': ['post_save']})  # Prevent signal triggering on dataset\n    return result", "response": "Checks a resource availability against a linkchecker."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef owned_pre_save(sender, document, **kwargs):\n    '''\n    Owned mongoengine.pre_save signal handler\n    Need to fetch original owner before the new one erase it.\n    '''\n    if not isinstance(document, Owned):\n        return\n    changed_fields = getattr(document, '_changed_fields', [])\n    if 'organization' in changed_fields:\n        if document.owner:\n            # Change from owner to organization\n            document._previous_owner = document.owner\n            document.owner = None\n        else:\n            # Change from org to another\n            # Need to fetch previous value in base\n            original = sender.objects.only('organization').get(pk=document.pk)\n            document._previous_owner = original.organization\n    elif 'owner' in changed_fields:\n        if document.organization:\n            # Change from organization to owner\n            document._previous_owner = document.organization\n            document.organization = None\n        else:\n            # Change from owner to another\n            # Need to fetch previous value in base\n            original = sender.objects.only('owner').get(pk=document.pk)\n            document._previous_owner = original.owner", "response": "This signal handler is called before the new object is saved."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef owned_post_save(sender, document, **kwargs):\n    '''\n    Owned mongoengine.post_save signal handler\n    Dispatch the `Owned.on_owner_change` signal\n    once the document has been saved including the previous owner.\n\n    The signal handler should have the following signature:\n    ``def handler(document, previous)``\n    '''\n    if isinstance(document, Owned) and hasattr(document, '_previous_owner'):\n        Owned.on_owner_change.send(document, previous=document._previous_owner)", "response": "This is a signal handler for the Owned object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_enabled_plugins():\n    '''\n    Returns enabled preview plugins.\n\n    Plugins are sorted, defaults come last\n    '''\n    plugins = entrypoints.get_enabled('udata.preview', current_app).values()\n    valid = [p for p in plugins if issubclass(p, PreviewPlugin)]\n    for plugin in plugins:\n        if plugin not in valid:\n            clsname = plugin.__name__\n            msg = '{0} is not a valid preview plugin'.format(clsname)\n            warnings.warn(msg, PreviewWarning)\n    return [p() for p in sorted(valid, key=lambda p: 1 if p.fallback else 0)]", "response": "Returns enabled preview plugins."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the most pertinent preview url associated to the resource if any.", "response": "def get_preview_url(resource):\n    '''\n    Returns the most pertinent preview URL associated to the resource, if any.\n\n    :param ResourceMixin resource: the (community) resource to preview\n    :return: a preview url to be displayed into an iframe or a new window\n    :rtype: HttpResponse\n    '''\n    candidates = (p.preview_url(resource)\n                  for p in get_enabled_plugins()\n                  if p.can_preview(resource))\n    return next(iter(candidates), None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds an object in a list given a field value", "response": "def get_by(lst, field, value):\n    '''Find an object in a list given a field value'''\n    for row in lst:\n        if ((isinstance(row, dict) and row.get(field) == value) or\n                (getattr(row, field, None) == value)):\n            return row"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multi_to_dict(multi):\n    '''Transform a Werkzeug multidictionnary into a flat dictionnary'''\n    return dict(\n        (key, value[0] if len(value) == 1 else value)\n        for key, value in multi.to_dict(False).items()\n    )", "response": "Transform a Werkzeug multidictionnary into a flat dictionnary"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a date range start boundary", "response": "def daterange_start(value):\n    '''Parse a date range start boundary'''\n    if not value:\n        return None\n    elif isinstance(value, datetime):\n        return value.date()\n    elif isinstance(value, date):\n        return value\n\n    result = parse_dt(value).date()\n    dashes = value.count('-')\n\n    if dashes >= 2:\n        return result\n    elif dashes == 1:\n        # Year/Month only\n        return result.replace(day=1)\n    else:\n        # Year only\n        return result.replace(day=1, month=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef daterange_end(value):\n    '''Parse a date range end boundary'''\n    if not value:\n        return None\n    elif isinstance(value, datetime):\n        return value.date()\n    elif isinstance(value, date):\n        return value\n\n    result = parse_dt(value).date()\n    dashes = value.count('-')\n\n    if dashes >= 2:\n        # Full date\n        return result\n    elif dashes == 1:\n        # Year/Month\n        return result + relativedelta(months=+1, days=-1, day=1)\n    else:\n        # Year only\n        return result.replace(month=12, day=31)", "response": "Parse a date range end boundary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat a date or datetime into an ISO - 8601 string Support dates before 1900.", "response": "def to_iso(dt):\n    '''\n    Format a date or datetime into an ISO-8601 string\n\n    Support dates before 1900.\n    '''\n    if isinstance(dt, datetime):\n        return to_iso_datetime(dt)\n    elif isinstance(dt, date):\n        return to_iso_date(dt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats a date or datetime into an ISO - 8601 datetime string.", "response": "def to_iso_datetime(dt):\n    '''\n    Format a date or datetime into an ISO-8601 datetime string.\n\n    Time is set to 00:00:00 for dates.\n\n    Support dates before 1900.\n    '''\n    if dt:\n        date_str = to_iso_date(dt)\n        time_str = '{dt.hour:02d}:{dt.minute:02d}:{dt.second:02d}'.format(\n            dt=dt) if isinstance(dt, datetime) else '00:00:00'\n        return 'T'.join((date_str, time_str))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform a value into a boolean", "response": "def to_bool(value):\n    '''\n    Transform a value into a boolean with the following rules:\n\n    - a boolean is returned untouched\n    - a string value should match any casinf of 'true' to be True\n    - an integer should be superior to zero to be True\n    - all other values are False\n    '''\n    if isinstance(value, bool):\n        return value\n    elif isinstance(value, basestring):\n        return value.lower() == 'true' or value.lower() == 't'\n    elif isinstance(value, int):\n        return value > 0\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recursive_get(obj, key):\n    '''\n    Get an attribute or a key recursively.\n\n    :param obj: The object to fetch attribute or key on\n    :type obj: object|dict\n    :param key: Either a string in dotted-notation ar an array of string\n    :type key: string|list|tuple\n    '''\n    if not obj or not key:\n        return\n    parts = key.split('.') if isinstance(key, basestring) else key\n    key = parts.pop(0)\n    if isinstance(obj, dict):\n        value = obj.get(key, None)\n    else:\n        value = getattr(obj, key, None)\n    return recursive_get(value, parts) if parts else value", "response": "Get an attribute or a key recursively.\n\n    :param obj: The object to fetch attribute or key on\n    :type obj: object|dict\n    :param key: Either a string in dotted-notation ar an array of string\n    :type key: string|list|tuple"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a unique string", "response": "def unique_string(length=UUID_LENGTH):\n    '''Generate a unique string'''\n    # We need a string at least as long as length\n    string = str(uuid4()) * int(math.ceil(length / float(UUID_LENGTH)))\n    return string[:length] if length else string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef redirect_territory(level, code):\n    territory = GeoZone.objects.valid_at(datetime.now()).filter(\n        code=code, level='fr:{level}'.format(level=level)).first()\n    return redirect(url_for('territories.territory', territory=territory))", "response": "Redirect to the latest valid territory given the INSEE code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the job with the given name with the given parameters.", "response": "def run(name, params, delay):\n    '''\n    Run the job <name>\n\n    Jobs args and kwargs are given as parameters without dashes.\n\n    Ex:\n        udata job run my-job arg1 arg2 key1=value key2=value\n        udata job run my-job -- arg1 arg2 key1=value key2=value\n    '''\n    args = [p for p in params if '=' not in p]\n    kwargs = dict(p.split('=') for p in params if '=' in p)\n\n    if name not in celery.tasks:\n        exit_with_error('Job %s not found', name)\n    job = celery.tasks[name]\n    label = job_label(name, args, kwargs)\n    if delay:\n        log.info('Sending job %s', label)\n        job.delay(*args, **kwargs)\n        log.info('Job sended to workers')\n    else:\n        log.info('Running job %s', label)\n        job.run(*args, **kwargs)\n        log.info('Job %s done', name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscheduling a job with the given crontab.", "response": "def schedule(cron, name, params):\n    '''\n    Schedule the job <name> to run periodically given the <cron> expression.\n\n    Jobs args and kwargs are given as parameters without dashes.\n\n    Ex:\n        udata job schedule \"* * 0 * *\" my-job arg1 arg2 key1=value key2=value\n    '''\n    if name not in celery.tasks:\n        exit_with_error('Job %s not found', name)\n\n    args = [p for p in params if '=' not in p]\n    kwargs = dict(p.split('=') for p in params if '=' in p)\n    label = 'Job {0}'.format(job_label(name, args, kwargs))\n\n    try:\n        task = PeriodicTask.objects.get(task=name, args=args, kwargs=kwargs)\n        task.modify(crontab=PeriodicTask.Crontab.parse(cron))\n    except PeriodicTask.DoesNotExist:\n        task = PeriodicTask.objects.create(\n            task=name,\n            name=label,\n            description='Periodic {0} job'.format(name),\n            enabled=True,\n            args=args,\n            kwargs=kwargs,\n            crontab=PeriodicTask.Crontab.parse(cron),\n        )\n\n    msg = 'Scheduled {label} with the following crontab: {cron}'\n    log.info(msg.format(label=label, cron=task.schedule_display))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unschedule(name, params):\n    '''\n    Unschedule the job <name> with the given parameters.\n\n    Jobs args and kwargs are given as parameters without dashes.\n\n    Ex:\n        udata job unschedule my-job arg1 arg2 key1=value key2=value\n    '''\n    if name not in celery.tasks:\n        exit_with_error('Job %s not found', name)\n\n    args = [p for p in params if '=' not in p]\n    kwargs = dict(p.split('=') for p in params if '=' in p)\n    label = 'Job {0}'.format(job_label(name, args, kwargs))\n\n    try:\n        task = PeriodicTask.objects.get(task=name, args=args, kwargs=kwargs)\n    except PeriodicTask.DoesNotExist:\n        exit_with_error('No scheduled job match {0}'.format(label))\n\n    task.delete()\n    msg = 'Unscheduled {label} with the following crontab: {cron}'\n    log.info(msg.format(label=label, cron=task.schedule_display))", "response": "Unschedule the job with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef purge(datasets, reuses, organizations):\n    '''\n    Permanently remove data flagged as deleted.\n\n    If no model flag is given, all models are purged.\n    '''\n    purge_all = not any((datasets, reuses, organizations))\n\n    if purge_all or datasets:\n        log.info('Purging datasets')\n        purge_datasets()\n\n    if purge_all or reuses:\n        log.info('Purging reuses')\n        purge_reuses()\n\n    if purge_all or organizations:\n        log.info('Purging organizations')\n        purge_organizations()\n\n    success('Done')", "response": "Permanently remove data flagged as deleted."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_sort(self, params):\n        '''Extract and build sort query from parameters'''\n        sorts = params.pop('sort', [])\n        sorts = [sorts] if isinstance(sorts, basestring) else sorts\n        sorts = [(s[1:], 'desc')\n                 if s.startswith('-') else (s, 'asc')\n                 for s in sorts]\n        self.sorts = [\n            {self.adapter.sorts[s]: d}\n            for s, d in sorts if s in self.adapter.sorts\n        ]", "response": "Extract and build sort query from parameters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract and build pagination from parameters.", "response": "def extract_pagination(self, params):\n        '''Extract and build pagination from parameters'''\n        try:\n            params_page = int(params.pop('page', 1) or 1)\n            self.page = max(params_page, 1)\n        except:\n            # Failsafe, if page cannot be parsed, we falback on first page\n            self.page = 1\n        try:\n            params_page_size = params.pop('page_size', DEFAULT_PAGE_SIZE)\n            self.page_size = int(params_page_size or DEFAULT_PAGE_SIZE)\n        except:\n            # Failsafe, if page_size cannot be parsed, we falback on default\n            self.page_size = DEFAULT_PAGE_SIZE\n        self.page_start = (self.page - 1) * self.page_size\n        self.page_end = self.page_start + self.page_size"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd aggregations representing the facets selected", "response": "def aggregate(self, search):\n        \"\"\"\n        Add aggregations representing the facets selected\n        \"\"\"\n        for f, facet in self.facets.items():\n            agg = facet.get_aggregation()\n            if isinstance(agg, Bucket):\n                search.aggs.bucket(f, agg)\n            elif isinstance(agg, Pipeline):\n                search.aggs.pipeline(f, agg)\n            else:\n                search.aggs.metric(f, agg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, search):\n        '''\n        Perform filtering instead of default post-filtering.\n        '''\n        if not self._filters:\n            return search\n        filters = Q('match_all')\n        for f in self._filters.values():\n            filters &= f\n        return search.filter(filters)", "response": "Perform filtering instead of default post - filtering."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs the Search object.", "response": "def search(self):\n        \"\"\"\n        Construct the Search object.\n        \"\"\"\n        s = Search(doc_type=self.doc_types, using=es.client,\n                   index=es.index_name)\n        # don't return any fields, just the metadata\n        s = s.fields([])\n        # Sort from parameters\n        s = s.sort(*self.sorts)\n        # Paginate from parameters\n        s = s[self.page_start:self.page_end]\n        # Same construction as parent class\n        # Allows to give the same signature as simple search\n        # ie. Response(data) instead of Response(search, data)\n        return s.response_class(partial(SearchResult, self))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncustomizes the search query if necessary.", "response": "def query(self, search, query):\n        '''\n        Customize the search query if necessary.\n\n        It handles the following features:\n         - negation support\n         - optional fuzziness\n         - optional analyzer\n         - optional match_type\n        '''\n        if not query:\n            return search\n\n        included, excluded = [], []\n        for term in query.split(' '):\n            if not term.strip():\n                continue\n            if term.startswith('-'):\n                excluded.append(term[1:])\n            else:\n                included.append(term)\n        if included:\n            search = search.query(self.multi_match(included))\n        for term in excluded:\n            search = search.query(~self.multi_match([term]))\n        return search"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_url(self, url=None, replace=False, **kwargs):\n        '''Serialize the query into an URL'''\n        params = copy.deepcopy(self.filter_values)\n        if self._query:\n            params['q'] = self._query\n        if self.page_size != DEFAULT_PAGE_SIZE:\n            params['page_size'] = self.page_size\n        if kwargs:\n            for key, value in kwargs.items():\n                if not replace and key in params:\n                    if not isinstance(params[key], (list, tuple)):\n                        params[key] = [params[key], value]\n                    else:\n                        params[key].append(value)\n                else:\n                    params[key] = value\n        else:\n            params['page'] = self.page\n        href = Href(url or request.base_url)\n        return href(params)", "response": "Serialize the query into an URL"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures type to string serialization", "response": "def safestr(value):\n    '''Ensure type to string serialization'''\n    if not value or isinstance(value, (int, float, bool, long)):\n        return value\n    elif isinstance(value, (date, datetime)):\n        return value.isoformat()\n    else:\n        return unicode(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yield_rows(adapter):\n    '''Yield a dataset catalog line by line'''\n    csvfile = StringIO()\n    writer = get_writer(csvfile)\n    # Generate header\n    writer.writerow(adapter.header())\n    yield csvfile.getvalue()\n    del csvfile\n\n    for row in adapter.rows():\n        csvfile = StringIO()\n        writer = get_writer(csvfile)\n        writer.writerow(row)\n        yield csvfile.getvalue()\n        del csvfile", "response": "Yield a dataset catalog line by line"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stream(queryset_or_adapter, basename=None):\n    if isinstance(queryset_or_adapter, Adapter):\n        adapter = queryset_or_adapter\n    elif isinstance(queryset_or_adapter, (list, tuple)):\n        if not queryset_or_adapter:\n            raise ValueError(\n                'Type detection is not possible with an empty list')\n        cls = _adapters.get(queryset_or_adapter[0].__class__)\n        adapter = cls(queryset_or_adapter)\n    elif isinstance(queryset_or_adapter, db.BaseQuerySet):\n        cls = _adapters.get(queryset_or_adapter._document)\n        adapter = cls(queryset_or_adapter)\n    else:\n        raise ValueError('Unsupported object type')\n\n    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n    headers = {\n        b'Content-Disposition': 'attachment; filename={0}-{1}.csv'.format(\n            basename or 'export', timestamp),\n    }\n    streamer = stream_with_context(yield_rows(adapter))\n    return Response(streamer, mimetype=\"text/csv\", headers=headers)", "response": "Stream a csv file from an object list a queryset or an instanciated adapter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef header(self):\n        '''Generate the CSV header row'''\n        return (super(NestedAdapter, self).header() +\n                [name for name, getter in self.get_nested_fields()])", "response": "Generate the CSV header row"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rows(self):\n        '''Iterate over queryset objects'''\n        return (self.nested_row(o, n)\n                for o in self.queryset\n                for n in getattr(o, self.attribute, []))", "response": "Iterate over queryset objects and return a list of nested rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nested_row(self, obj, nested):\n        '''Convert an object into a flat csv row'''\n        row = self.to_row(obj)\n        for name, getter in self.get_nested_fields():\n            content = ''\n            if getter is not None:\n                try:\n                    content = safestr(getter(nested))\n                except Exception, e:  # Catch all errors intentionally.\n                    log.error('Error exporting CSV for {name}: {error}'.format(\n                        name=self.__class__.__name__, error=e))\n            row.append(content)\n        return row", "response": "Convert an object into a flat csv row"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnotify user about pending transfer requests", "response": "def transfer_request_notifications(user):\n    '''Notify user about pending transfer requests'''\n    orgs = [o for o in user.organizations if o.is_member(user)]\n    notifications = []\n\n    qs = Transfer.objects(recipient__in=[user] + orgs, status='pending')\n    # Only fetch required fields for notification serialization\n    # Greatly improve performances and memory usage\n    qs = qs.only('id', 'created', 'subject')\n\n    # Do not dereference subject (so it's a DBRef)\n    # Also improve performances and memory usage\n    for transfer in qs.no_dereference():\n        notifications.append((transfer.created, {\n            'id': transfer.id,\n            'subject': {\n                'class': transfer.subject['_cls'].lower(),\n                'id': transfer.subject['_ref'].id\n            }\n        }))\n\n    return notifications"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(subject, recipients, template_base, **kwargs):\n    '''\n    Send a given email to multiple recipients.\n\n    User prefered language is taken in account.\n    To translate the subject in the right language, you should ugettext_lazy\n    '''\n    sender = kwargs.pop('sender', None)\n    if not isinstance(recipients, (list, tuple)):\n        recipients = [recipients]\n\n    debug = current_app.config.get('DEBUG', False)\n    send_mail = current_app.config.get('SEND_MAIL', not debug)\n    connection = send_mail and mail.connect or dummyconnection\n\n    with connection() as conn:\n        for recipient in recipients:\n            lang = i18n._default_lang(recipient)\n            with i18n.language(lang):\n                log.debug(\n                    'Sending mail \"%s\" to recipient \"%s\"', subject, recipient)\n                msg = Message(subject, sender=sender,\n                              recipients=[recipient.email])\n                msg.body = theme.render(\n                    'mail/{0}.txt'.format(template_base), subject=subject,\n                    sender=sender, recipient=recipient, **kwargs)\n                msg.html = theme.render(\n                    'mail/{0}.html'.format(template_base), subject=subject,\n                    sender=sender, recipient=recipient, **kwargs)\n                conn.send(msg)", "response": "Send a given email to multiple recipients."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef public_dsn(dsn):\n    '''Transform a standard Sentry DSN into a public one'''\n    m = RE_DSN.match(dsn)\n    if not m:\n        log.error('Unable to parse Sentry DSN')\n    public = '{scheme}://{client_id}@{domain}/{site_id}'.format(\n        **m.groupdict())\n    return public", "response": "Transform a standard Sentry DSN into a public one"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncleans all build artifacts", "response": "def clean(ctx, node=False, translations=False, all=False):\n    '''Cleanup all build artifacts'''\n    header('Clean all build artifacts')\n    patterns = [\n        'build', 'dist', 'cover', 'docs/_build',\n        '**/*.pyc', '*.egg-info', '.tox', 'udata/static/*'\n    ]\n    if node or all:\n        patterns.append('node_modules')\n    if translations or all:\n        patterns.append('udata/translations/*/LC_MESSAGES/udata.mo')\n    for pattern in patterns:\n        info(pattern)\n    lrun('rm -rf {0}'.format(' '.join(patterns)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a development update", "response": "def update(ctx, migrate=False):\n    '''Perform a development update'''\n    msg = 'Update all dependencies'\n    if migrate:\n        msg += ' and migrate data'\n    header(msg)\n    info('Updating Python dependencies')\n    lrun('pip install -r requirements/develop.pip')\n    lrun('pip install -e .')\n    info('Updating JavaScript dependencies')\n    lrun('npm install')\n    if migrate:\n        info('Migrating database')\n        lrun('udata db migrate')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun tests suite with coverage", "response": "def cover(ctx, html=False):\n    '''Run tests suite with coverage'''\n    header('Run tests suite with coverage')\n    cmd = 'pytest --cov udata --cov-report term'\n    if html:\n        cmd = ' '.join((cmd, '--cov-report html:reports/python/cover'))\n    with ctx.cd(ROOT):\n        ctx.run(cmd, pty=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef qa(ctx):\n    '''Run a quality report'''\n    header('Performing static analysis')\n    info('Python static analysis')\n    flake8_results = lrun('flake8 udata --jobs 1', pty=True, warn=True)\n    info('JavaScript static analysis')\n    eslint_results = lrun('npm -s run lint', pty=True, warn=True)\n    if flake8_results.failed or eslint_results.failed:\n        exit(flake8_results.return_code or eslint_results.return_code)\n    print(green('OK'))", "response": "Run a quality report"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract translatable strings from the current language", "response": "def i18n(ctx, update=False):\n    '''Extract translatable strings'''\n    header('Extract translatable strings')\n\n    info('Extract Python strings')\n    lrun('python setup.py extract_messages')\n\n    # Fix crowdin requiring Language with `2-digit` iso code in potfile\n    # to produce 2-digit iso code pofile\n    # Opening the catalog also allows to set extra metadata\n    potfile = join(ROOT, 'udata', 'translations', '{}.pot'.format(I18N_DOMAIN))\n    with open(potfile, 'rb') as infile:\n        catalog = read_po(infile, 'en')\n    catalog.copyright_holder = 'Open Data Team'\n    catalog.msgid_bugs_address = 'i18n@opendata.team'\n    catalog.language_team = 'Open Data Team <i18n@opendata.team>'\n    catalog.last_translator = 'Open Data Team <i18n@opendata.team>'\n    catalog.revision_date = datetime.now(LOCALTZ)\n    with open(potfile, 'wb') as outfile:\n        write_po(outfile, catalog, width=80)\n\n    if update:\n        lrun('python setup.py update_catalog')\n\n    info('Extract JavaScript strings')\n    keys = set()\n    catalog = {}\n    catalog_filename = join(ROOT, 'js', 'locales',\n                            '{}.en.json'.format(I18N_DOMAIN))\n    if exists(catalog_filename):\n        with codecs.open(catalog_filename, encoding='utf8') as f:\n            catalog = json.load(f)\n\n    globs = '*.js', '*.vue', '*.hbs'\n    regexps = [\n        re.compile(r'(?:|\\.|\\s|\\{)_\\(\\s*(?:\"|\\')(.*?)(?:\"|\\')\\s*(?:\\)|,)'),  # JS _('trad')\n        re.compile(r'v-i18n=\"(.*?)\"'),  # Vue.js directive v-i18n=\"trad\"\n        re.compile(r'\"\\{\\{\\{?\\s*\\'(.*?)\\'\\s*\\|\\s*i18n\\}\\}\\}?\"'),  # Vue.js filter {{ 'trad'|i18n }}\n        re.compile(r'{{_\\s*\"(.*?)\"\\s*}}'),  # Handlebars {{_ \"trad\" }}\n        re.compile(r'{{_\\s*\\'(.*?)\\'\\s*}}'),  # Handlebars {{_ 'trad' }}\n        re.compile(r'\\:[a-z0-9_\\-]+=\"\\s*_\\(\\'(.*?)\\'\\)\\s*\"'),  # Vue.js binding :prop=\"_('trad')\"\n    ]\n\n    for directory, _, _ in os.walk(join(ROOT, 'js')):\n        glob_patterns = (iglob(join(directory, g)) for g in globs)\n        for filename in itertools.chain(*glob_patterns):\n            print('Extracting messages from {0}'.format(green(filename)))\n            content = codecs.open(filename, encoding='utf8').read()\n            for regexp in regexps:\n                for match in regexp.finditer(content):\n                    key = match.group(1)\n                    key = key.replace('\\\\n', '\\n')\n                    keys.add(key)\n                    if key not in catalog:\n                        catalog[key] = key\n\n    # Remove old/not found translations\n    for key in catalog.keys():\n        if key not in keys:\n            del catalog[key]\n\n    with codecs.open(catalog_filename, 'w', encoding='utf8') as f:\n        json.dump(catalog, f, sort_keys=True, indent=4, ensure_ascii=False,\n                  encoding='utf8', separators=(',', ': '))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing Flask JSON to serialize", "response": "def output_json(data, code, headers=None):\n    '''Use Flask JSON to serialize'''\n    resp = make_response(json.dumps(data), code)\n    resp.headers.extend(headers or {})\n    return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_name_from_path(path):\n    base_path, query_string = path.split('?')\n    infos = base_path.strip('/').split('/')[2:]  # Removes api/version.\n    if len(infos) > 1:  # This is an object.\n        name = '{category} / {name}'.format(\n            category=infos[0].title(),\n            name=infos[1].replace('-', ' ').title()\n        )\n    else:  # This is a collection.\n        name = '{category}'.format(category=infos[0].title())\n    return safe_unicode(name)", "response": "Return a readable name from a URL path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_unauthorized_file_type(error):\n    '''Error occuring when the user try to upload a non-allowed file type'''\n    url = url_for('api.allowed_extensions', _external=True)\n    msg = (\n        'This file type is not allowed.'\n        'The allowed file type list is available at {url}'\n    ).format(url=url)\n    return {'message': msg}, 400", "response": "Error occuring when the user try to upload a non - allowed file type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nenforces authentication on a given method / verb and optionally check a given permission .", "response": "def secure(self, func):\n        '''Enforce authentication on a given method/verb\n        and optionally check a given permission\n        '''\n        if isinstance(func, basestring):\n            return self._apply_permission(Permission(RoleNeed(func)))\n        elif isinstance(func, Permission):\n            return self._apply_permission(func)\n        else:\n            return self._apply_secure(func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _apply_secure(self, func, permission=None):\n        '''Enforce authentication on a given method/verb'''\n        self._handle_api_doc(func, {'security': 'apikey'})\n\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if not current_user.is_authenticated:\n                self.abort(401)\n\n            if permission is not None:\n                with permission.require():\n                    return func(*args, **kwargs)\n            else:\n                return func(*args, **kwargs)\n\n        return wrapper", "response": "Enforce authentication on a given method / verb"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authentify(self, func):\n        '''Authentify the user if credentials are given'''\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if current_user.is_authenticated:\n                return func(*args, **kwargs)\n\n            apikey = request.headers.get(HEADER_API_KEY)\n            if apikey:\n                try:\n                    user = User.objects.get(apikey=apikey)\n                except User.DoesNotExist:\n                    self.abort(401, 'Invalid API Key')\n\n                if not login_user(user, False):\n                    self.abort(401, 'Inactive user')\n            else:\n                oauth2.check_credentials()\n            return func(*args, **kwargs)\n        return wrapper", "response": "Authentify the user if credentials are given"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self, form_cls, obj=None):\n        '''Validate a form from the request and handle errors'''\n        if 'application/json' not in request.headers.get('Content-Type'):\n            errors = {'Content-Type': 'expecting application/json'}\n            self.abort(400, errors=errors)\n        form = form_cls.from_json(request.json, obj=obj, instance=obj,\n                                  csrf_enabled=False)\n        if not form.validate():\n            self.abort(400, errors=form.errors)\n        return form", "response": "Validate a form from the request and handle errors"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides to change the WWW - Authenticate challenge", "response": "def unauthorized(self, response):\n        '''Override to change the WWW-Authenticate challenge'''\n        realm = current_app.config.get('HTTP_OAUTH_REALM', 'uData')\n        challenge = 'Bearer realm=\"{0}\"'.format(realm)\n\n        response.headers['WWW-Authenticate'] = challenge\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks <number > of URLs that have not been ( recently checked )", "response": "def check_resources(self, number):\n    '''Check <number> of URLs that have not been (recently) checked'''\n    if not current_app.config.get('LINKCHECKING_ENABLED'):\n        log.error('Link checking is disabled.')\n        return\n\n    base_pipeline = [\n        {'$match': {'resources': {'$gt': []}}},\n        {'$project': {'resources._id': True,\n                      'resources.extras.check:date': True}},\n        {'$unwind': '$resources'},\n    ]\n    # unchecked resources\n    pipeline = base_pipeline + [\n        {'$match': {'resources.extras.check:date': {'$eq': None}}},\n        {'$limit': number}\n    ]\n    resources = list(Dataset.objects.aggregate(*pipeline))\n    # not recently checked resources\n    slots_left = number - len(resources)\n    if slots_left:\n        pipeline = base_pipeline + [\n            {'$match': {'resources.extras.check:date': {'$ne': None}}},\n            {'$sort': {'resources.extras.check:date': 1}},\n            {'$limit': slots_left}\n        ]\n        resources += list(Dataset.objects.aggregate(*pipeline))\n\n    nb_resources = len(resources)\n    log.info('Checking %s resources...', nb_resources)\n    for idx, dataset_resource in enumerate(resources):\n        dataset_obj = Dataset.objects.get(id=dataset_resource['_id'])\n        resource_id = dataset_resource['resources']['_id']\n        rid = uuid.UUID(resource_id)\n        resource_obj = get_by(dataset_obj.resources, 'id', rid)\n        log.info('Checking resource %s (%s/%s)',\n                 resource_id, idx + 1, nb_resources)\n        if resource_obj.need_check():\n            check_resource(resource_obj)\n        else:\n            log.info(\"--> Skipping this resource, cache is fresh enough.\")\n    log.info('Done.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render():\n    '''Force (re)rendering stored images'''\n    from udata.core.organization.models import Organization\n    from udata.core.post.models import Post\n    from udata.core.reuse.models import Reuse\n    from udata.core.user.models import User\n\n    header('Rendering images')\n\n    count = Counter()\n    total = Counter()\n\n    organizations = Organization.objects(logo__exists=True)\n    total['orgs'] = organizations.count()\n    log.info('Processing {0} organizations logos'.format(total['orgs']))\n    for org in organizations:\n        count['orgs'] += render_or_skip(org, 'logo')\n\n    users = User.objects(avatar__exists=True)\n    total['users'] = users.count()\n    log.info('Processing {0} user avatars'.format(total['users']))\n    for user in users:\n        count['users'] += render_or_skip(user, 'avatar')\n\n    posts = Post.objects(image__exists=True)\n    total['posts'] = posts.count()\n    log.info('Processing {0} post images'.format(total['posts']))\n    for post in posts:\n        count['posts'] += render_or_skip(post, 'image')\n\n    reuses = Reuse.objects(image__exists=True)\n    total['reuses'] = reuses.count()\n    log.info('Processing {0} reuse images'.format(total['reuses']))\n    for reuse in reuses:\n        count['reuses'] += render_or_skip(reuse, 'image')\n\n    log.info('''Summary:\n    Organization logos: {count[orgs]}/{total[orgs]}\n    User avatars: {count[users]}/{total[users]}\n    Post images: {count[posts]}/{total[posts]}\n    Reuse images: {count[reuses]}/{total[reuses]}\n    '''.format(count=count, total=total))\n    success('Images rendered')", "response": "Render stored images in a single order."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all followers for a given object", "response": "def get(self, id):\n        '''List all followers for a given object'''\n        args = parser.parse_args()\n        model = self.model.objects.only('id').get_or_404(id=id)\n        qs = Follow.objects(following=model, until=None)\n        return qs.paginate(args['page'], args['page_size'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, id):\n        '''Follow an object given its ID'''\n        model = self.model.objects.only('id').get_or_404(id=id)\n        follow, created = Follow.objects.get_or_create(\n            follower=current_user.id, following=model, until=None)\n        count = Follow.objects.followers(model).count()\n        if not current_app.config['TESTING']:\n            tracking.send_signal(on_new_follow, request, current_user)\n        return {'followers': count}, 201 if created else 200", "response": "Follow an object given its ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, id):\n        '''Unfollow an object given its ID'''\n        model = self.model.objects.only('id').get_or_404(id=id)\n        follow = Follow.objects.get_or_404(follower=current_user.id,\n                                           following=model,\n                                           until=None)\n        follow.until = datetime.now()\n        follow.save()\n        count = Follow.objects.followers(model).count()\n        return {'followers': count}, 200", "response": "Unfollow an object given its ID"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisplaying an error message with optional details", "response": "def error(msg, details=None):\n    '''Display an error message with optional details'''\n    msg = '{0} {1}'.format(red(KO), white(safe_unicode(msg)))\n    msg = safe_unicode(msg)\n    if details:\n        msg = b'\\n'.join((msg, safe_unicode(details)))\n    echo(format_multiline(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexits with error message.", "response": "def exit_with_error(msg, details=None, code=-1):\n    '''Exit with error'''\n    error(msg, details)\n    sys.exit(code)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nindent traceback info for better readability", "response": "def formatException(self, ei):\n        '''Indent traceback info for better readability'''\n        out = super(CliFormatter, self).formatException(ei)\n        return b'\u2502' + format_multiline(out)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload udata commands from entry points and commands submodules", "response": "def load_udata_commands(self, ctx):\n        '''\n        Load udata commands from:\n        - `udata.commands.*` module\n        - known internal modules with commands\n        - plugins exporting a `udata.commands` entrypoint\n        '''\n        if self._udata_commands_loaded:\n            return\n\n        # Load all commands submodules\n        pattern = os.path.join(os.path.dirname(__file__), '[!_]*.py')\n        for filename in iglob(pattern):\n            module = os.path.splitext(os.path.basename(filename))[0]\n            try:\n                __import__('udata.commands.{0}'.format(module))\n            except Exception as e:\n                error('Unable to import {0}'.format(module), e)\n\n        # Load all core modules commands\n        for module in MODULES_WITH_COMMANDS:\n            try:\n                __import__('udata.{0}.commands'.format(module))\n            except Exception as e:\n                error('Unable to import {0}'.format(module), e)\n\n        # Load commands from entry points for enabled plugins\n        app = ctx.ensure_object(ScriptInfo).load_app()\n        entrypoints.get_enabled('udata.commands', app)\n\n        # Ensure loading happens once\n        self._udata_commands_loaded = False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(self, *args, **kwargs):\n        '''\n        Instanciate ScriptInfo before parent does\n        to ensure the `settings` parameters is available to `create_app\n        '''\n        obj = kwargs.get('obj')\n        if obj is None:\n            obj = ScriptInfo(create_app=self.create_app)\n        # This is the import line: allows create_app to access the settings\n        obj.settings = kwargs.pop('settings', 'udata.settings.Defaults')\n        kwargs['obj'] = obj\n        return super(UdataGroup, self).main(*args, **kwargs)", "response": "Instanciate ScriptInfo before parent does\n        to ensure the settings parameters are available to create_app\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_enabled(name, app):\n    '''\n    Get (and load) entrypoints registered on name\n    and enabled for the given app.\n    '''\n    plugins = app.config['PLUGINS']\n    return dict(_ep_to_kv(e) for e in iter_all(name) if e.name in plugins)", "response": "Get entrypoints registered on name\n    and enabled for the given app."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming an entrypoint into a key - value tuple where the key is the entrypoint name and the value is the class with the name attribute matching from the entrypoint name.", "response": "def _ep_to_kv(entrypoint):\n    '''\n    Transform an entrypoint into a key-value tuple where:\n    - key is the entrypoint name\n    - value is the entrypoint class with the name attribute\n      matching from entrypoint name\n    '''\n    cls = entrypoint.load()\n    cls.name = entrypoint.name\n    return (entrypoint.name, cls)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef known_dists():\n    '''Return a list of all Distributions exporting udata.* entrypoints'''\n    return (\n        dist for dist in pkg_resources.working_set\n        if any(k in ENTRYPOINTS for k in dist.get_entry_map().keys())\n    )", "response": "Return a list of all Distributions exporting udata. entrypoints"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plugins_dists(app, name=None):\n    '''Return a list of Distributions with enabled udata plugins'''\n    if name:\n        plugins = set(e.name for e in iter_all(name) if e.name in app.config['PLUGINS'])\n    else:\n        plugins = set(app.config['PLUGINS'])\n    return [\n        d for d in known_dists()\n        if any(set(v.keys()) & plugins for v in d.get_entry_map().values())\n    ]", "response": "Return a list of Distributions with enabled udata plugins"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of root packages and modules exposing endpoints.", "response": "def get_roots(app=None):\n    '''\n    Returns the list of root packages/modules exposing endpoints.\n\n    If app is provided, only returns those of enabled plugins\n    '''\n    roots = set()\n    plugins = app.config['PLUGINS'] if app else None\n    for name in ENTRYPOINTS.keys():\n        for ep in iter_all(name):\n            if plugins is None or ep.name in plugins:\n                roots.add(ep.module_name.split('.', 1)[0])\n    return list(roots)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lazy_raise_or_redirect():\n    '''\n    Raise exception lazily to ensure request.endpoint is set\n    Also perform redirect if needed\n    '''\n    if not request.view_args:\n        return\n    for name, value in request.view_args.items():\n        if isinstance(value, NotFound):\n            request.routing_exception = value\n            break\n        elif isinstance(value, LazyRedirect):\n            new_args = request.view_args\n            new_args[name] = value.arg\n            new_url = url_for(request.endpoint, **new_args)\n            return redirect(new_url)", "response": "Raise exception lazily to ensure request. endpoint is set\n    Also perform redirect if needed\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a string to a GeoZone object.", "response": "def to_python(self, value):\n        \"\"\"\n        `value` has slashs in it, that's why we inherit from `PathConverter`.\n\n        E.g.: `commune/13200@latest/`, `departement/13@1860-07-01/` or\n        `region/76@2016-01-01/Auvergne-Rhone-Alpes/`.\n\n        Note that the slug is not significative but cannot be omitted.\n        \"\"\"\n        if '/' not in value:\n            return\n\n        level, code = value.split('/')[:2]  # Ignore optional slug\n\n        geoid = GeoZone.SEPARATOR.join([level, code])\n        zone = GeoZone.objects.resolve(geoid)\n\n        if not zone and GeoZone.SEPARATOR not in level:\n            # Try implicit default prefix\n            level = GeoZone.SEPARATOR.join([self.DEFAULT_PREFIX, level])\n            geoid = GeoZone.SEPARATOR.join([level, code])\n            zone = GeoZone.objects.resolve(geoid)\n\n        return zone or NotFound()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreconstructs the URL from level name code datagouv id and slug.", "response": "def to_url(self, obj):\n        \"\"\"\n        Reconstruct the URL from level name, code or datagouv id and slug.\n        \"\"\"\n        level_name = getattr(obj, 'level_name', None)\n        if not level_name:\n            raise ValueError('Unable to serialize \"%s\" to url' % obj)\n\n        code = getattr(obj, 'code', None)\n        slug = getattr(obj, 'slug', None)\n        validity = getattr(obj, 'validity', None)\n        if code and slug:\n            return '{level_name}/{code}@{start_date}/{slug}'.format(\n                level_name=level_name,\n                code=code,\n                start_date=getattr(validity, 'start', None) or 'latest',\n                slug=slug\n            )\n        else:\n            raise ValueError('Unable to serialize \"%s\" to url' % obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config():\n    '''Display some details about the local configuration'''\n    if hasattr(current_app, 'settings_file'):\n        log.info('Loaded configuration from %s', current_app.settings_file)\n\n    log.info(white('Current configuration'))\n    for key in sorted(current_app.config):\n        if key.startswith('__') or not key.isupper():\n            continue\n        echo('{0}: {1}'.format(white(key), current_app.config[key]))", "response": "Display some details about the local configuration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plugins():\n    '''Display some details about the local plugins'''\n    plugins = current_app.config['PLUGINS']\n    for name, description in entrypoints.ENTRYPOINTS.items():\n        echo('{0} ({1})'.format(white(description), name))\n        if name == 'udata.themes':\n            actives = [current_app.config['THEME']]\n        elif name == 'udata.avatars':\n            actives = [avatar_config('provider')]\n        else:\n            actives = plugins\n        for ep in sorted(entrypoints.iter_all(name), key=by_name):\n            echo('> {0}: {1}'.format(ep.name, is_active(ep, actives)))", "response": "Display some details about the local plugins"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverwriting this method to implement custom contextual permissions", "response": "def can(self, *args, **kwargs):\n        '''Overwrite this method to implement custom contextual permissions'''\n        if isinstance(self.require, auth.Permission):\n            return self.require.can()\n        elif callable(self.require):\n            return self.require()\n        elif isinstance(self.require, bool):\n            return self.require\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef theme_static_with_version(ctx, filename, external=False):\n    '''Override the default theme static to add cache burst'''\n    if current_app.theme_manager.static_folder:\n        url = assets.cdn_for('_themes.static',\n                             filename=current.identifier + '/' + filename,\n                             _external=external)\n    else:\n        url = assets.cdn_for('_themes.static',\n                             themeid=current.identifier,\n                             filename=filename,\n                             _external=external)\n    if url.endswith('/'):  # this is a directory, no need for cache burst\n        return url\n    if current_app.config['DEBUG']:\n        burst = time()\n    else:\n        burst = current.entrypoint.dist.version\n    return '{url}?_={burst}'.format(url=url, burst=burst)", "response": "Override the default theme static to add cache burst"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a template with uData frontend specifics", "response": "def render(template, **context):\n    '''\n    Render a template with uData frontend specifics\n\n        * Theme\n    '''\n    theme = current_app.config['THEME']\n    return render_theme_template(get_theme(theme), template, **context)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef context(name):\n    '''A decorator for theme context processors'''\n    def wrapper(func):\n        g.theme.context_processors[name] = func\n        return func\n    return wrapper", "response": "A decorator for theme context processors"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the current theme variant", "response": "def variant(self):\n        '''Get the current theme variant'''\n        variant = current_app.config['THEME_VARIANT']\n        if variant not in self.variants:\n            log.warning('Unkown theme variant: %s', variant)\n            return 'default'\n        else:\n            return variant"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_redirect(id):\n    '''\n    Redirect to the latest version of a resource given its identifier.\n    '''\n    resource = get_resource(id)\n    return redirect(resource.url.strip()) if resource else abort(404)", "response": "Redirect to the latest version of a resource given its identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nroot RDF endpoint with content negociation handling", "response": "def rdf(dataset):\n    '''Root RDF endpoint with content negociation handling'''\n    format = RDF_EXTENSIONS[negociate_content()]\n    url = url_for('datasets.rdf_format', dataset=dataset.id, format=format)\n    return redirect(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef group_resources_by_type(resources):\n    groups = defaultdict(list)\n    for resource in resources:\n        groups[getattr(resource, 'type')].append(resource)\n    ordered = OrderedDict()\n    for rtype, rtype_label in RESOURCE_TYPES.items():\n        if groups[rtype]:\n            ordered[(rtype, rtype_label)] = groups[rtype]\n    return ordered", "response": "Group a list of resources by type with order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_source(name, url, backend,\n                  description=None,\n                  frequency=DEFAULT_HARVEST_FREQUENCY,\n                  owner=None,\n                  organization=None,\n                  config=None,\n                  ):\n    '''Create a new harvest source'''\n    if owner and not isinstance(owner, User):\n        owner = User.get(owner)\n\n    if organization and not isinstance(organization, Organization):\n        organization = Organization.get(organization)\n\n    source = HarvestSource.objects.create(\n        name=name,\n        url=url,\n        backend=backend,\n        description=description,\n        frequency=frequency or DEFAULT_HARVEST_FREQUENCY,\n        owner=owner,\n        organization=organization,\n        config=config,\n    )\n    signals.harvest_source_created.send(source)\n    return source", "response": "Create a new harvest source"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_source(ident, data):\n    '''Update an harvest source'''\n    source = get_source(ident)\n    source.modify(**data)\n    signals.harvest_source_updated.send(source)\n    return source", "response": "Update an harvest source with the given data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_source(ident, comment=None):\n    '''Validate a source for automatic harvesting'''\n    source = get_source(ident)\n    source.validation.on = datetime.now()\n    source.validation.comment = comment\n    source.validation.state = VALIDATION_ACCEPTED\n    if current_user.is_authenticated:\n        source.validation.by = current_user._get_current_object()\n    source.save()\n    schedule(ident, cron=current_app.config['HARVEST_DEFAULT_SCHEDULE'])\n    launch(ident)\n    return source", "response": "Validate a source for automatic harvesting"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreject a source for automatic harvesting", "response": "def reject_source(ident, comment):\n    '''Reject a source for automatic harvesting'''\n    source = get_source(ident)\n    source.validation.on = datetime.now()\n    source.validation.comment = comment\n    source.validation.state = VALIDATION_REFUSED\n    if current_user.is_authenticated:\n        source.validation.by = current_user._get_current_object()\n    source.save()\n    return source"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an harvest source", "response": "def delete_source(ident):\n    '''Delete an harvest source'''\n    source = get_source(ident)\n    source.deleted = datetime.now()\n    source.save()\n    signals.harvest_source_deleted.send(source)\n    return source"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlaunches or resume an harvesting for a given source if none is running", "response": "def run(ident):\n    '''Launch or resume an harvesting for a given source if none is running'''\n    source = get_source(ident)\n    cls = backends.get(current_app, source.backend)\n    backend = cls(source)\n    backend.harvest()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npreviewing an harvesting for a given source", "response": "def preview(ident):\n    '''Preview an harvesting for a given source'''\n    source = get_source(ident)\n    cls = backends.get(current_app, source.backend)\n    max_items = current_app.config['HARVEST_PREVIEW_MAX_ITEMS']\n    backend = cls(source, dryrun=True, max_items=max_items)\n    return backend.harvest()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preview_from_config(name, url, backend,\n                        description=None,\n                        frequency=DEFAULT_HARVEST_FREQUENCY,\n                        owner=None,\n                        organization=None,\n                        config=None,\n                        ):\n    '''Preview an harvesting from a source created with the given parameters'''\n    if owner and not isinstance(owner, User):\n        owner = User.get(owner)\n\n    if organization and not isinstance(organization, Organization):\n        organization = Organization.get(organization)\n\n    source = HarvestSource(\n        name=name,\n        url=url,\n        backend=backend,\n        description=description,\n        frequency=frequency or DEFAULT_HARVEST_FREQUENCY,\n        owner=owner,\n        organization=organization,\n        config=config,\n    )\n    cls = backends.get(current_app, source.backend)\n    max_items = current_app.config['HARVEST_PREVIEW_MAX_ITEMS']\n    backend = cls(source, dryrun=True, max_items=max_items)\n    return backend.harvest()", "response": "Preview an harvesting from a source created with the given parameters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef schedule(ident, cron=None, minute='*', hour='*',\n             day_of_week='*', day_of_month='*', month_of_year='*'):\n    '''Schedule an harvesting on a source given a crontab'''\n    source = get_source(ident)\n\n    if cron:\n        minute, hour, day_of_month, month_of_year, day_of_week = cron.split()\n\n    crontab = PeriodicTask.Crontab(\n        minute=str(minute),\n        hour=str(hour),\n        day_of_week=str(day_of_week),\n        day_of_month=str(day_of_month),\n        month_of_year=str(month_of_year)\n    )\n\n    if source.periodic_task:\n        source.periodic_task.modify(crontab=crontab)\n    else:\n        source.modify(periodic_task=PeriodicTask.objects.create(\n            task='harvest',\n            name='Harvest {0}'.format(source.name),\n            description='Periodic Harvesting',\n            enabled=True,\n            args=[str(source.id)],\n            crontab=crontab,\n        ))\n    signals.harvest_source_scheduled.send(source)\n    return source", "response": "Schedule an harvesting on a source given a crontab"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attach(domain, filename):\n    '''Attach existing dataset to their harvest remote id before harvesting.\n\n    The expected csv file format is the following:\n\n    - a column with header \"local\" and the local IDs or slugs\n    - a column with header \"remote\" and the remote IDs\n\n    The delimiter should be \";\". columns order\n    and extras columns does not matter\n    '''\n    count = 0\n    errors = 0\n    with open(filename) as csvfile:\n        reader = csv.DictReader(csvfile,\n                                delimiter=b';',\n                                quotechar=b'\"')\n        for row in reader:\n            try:\n                dataset = Dataset.objects.get(id=ObjectId(row['local']))\n            except:  # noqa  (Never stop on failure)\n                log.warning('Unable to attach dataset : %s', row['local'])\n                errors += 1\n                continue\n\n            # Detach previously attached dataset\n            Dataset.objects(**{\n                'extras__harvest:domain': domain,\n                'extras__harvest:remote_id': row['remote']\n            }).update(**{\n                'unset__extras__harvest:domain': True,\n                'unset__extras__harvest:remote_id': True\n            })\n\n            dataset.extras['harvest:domain'] = domain\n            dataset.extras['harvest:remote_id'] = row['remote']\n            dataset.last_modified = datetime.now()\n            dataset.save()\n            count += 1\n\n    return AttachResult(count, errors)", "response": "Attach existing dataset to their harvest remote id before harvesting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmap a User object to a DCAT / RDF graph", "response": "def user_to_rdf(user, graph=None):\n    '''\n    Map a Resource domain model to a DCAT/RDF graph\n    '''\n    graph = graph or Graph(namespace_manager=namespace_manager)\n    if user.id:\n        user_url = url_for('users.show_redirect',\n                           user=user.id,\n                           _external=True)\n        id = URIRef(user_url)\n    else:\n        id = BNode()\n    o = graph.resource(id)\n    o.set(RDF.type, FOAF.Person)\n    o.set(FOAF.name, Literal(user.fullname))\n    o.set(RDFS.label, Literal(user.fullname))\n    if user.website:\n        o.set(FOAF.homepage, URIRef(user.website))\n    return o"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, key, dbtype):\n        '''Register a DB type to add constraint on a given extra key'''\n        if not issubclass(dbtype, (BaseField, EmbeddedDocument)):\n            msg = 'ExtrasField can only register MongoEngine fields'\n            raise TypeError(msg)\n        self.registered[key] = dbtype", "response": "Register a DB type to add constraint on a given extra key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create():\n    '''Create a new user'''\n    data = {\n        'first_name': click.prompt('First name'),\n        'last_name': click.prompt('Last name'),\n        'email': click.prompt('Email'),\n        'password': click.prompt('Password', hide_input=True),\n        'password_confirm': click.prompt('Confirm Password', hide_input=True),\n    }\n    # Until https://github.com/mattupstate/flask-security/issues/672 is fixed\n    with current_app.test_request_context():\n        form = RegisterForm(MultiDict(data), meta={'csrf': False})\n    if form.validate():\n        data['password'] = encrypt_password(data['password'])\n        del data['password_confirm']\n        data['confirmed_at'] = datetime.utcnow()\n        user = datastore.create_user(**data)\n        success('User(id={u.id} email={u.email}) created'.format(u=user))\n        return user\n    errors = '\\n'.join('\\n'.join(e) for e in form.errors.values())\n    exit_with_error('Error creating user', errors)", "response": "Create a new user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nactivate an existing user", "response": "def activate():\n    '''Activate an existing user (validate their email confirmation)'''\n    email = click.prompt('Email')\n    user = User.objects(email=email).first()\n    if not user:\n        exit_with_error('Invalid user')\n    if user.confirmed_at is not None:\n        exit_with_error('User email address already confirmed')\n        return\n    user.confirmed_at = datetime.utcnow()\n    user.save()\n    success('User activated successfully')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes an existing user", "response": "def delete():\n    '''Delete an existing user'''\n    email = click.prompt('Email')\n    user = User.objects(email=email).first()\n    if not user:\n        exit_with_error('Invalid user')\n    user.delete()\n    success('User deleted successfully')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_admin(email):\n    '''Set an user as administrator'''\n    user = datastore.get_user(email)\n    log.info('Adding admin role to user %s (%s)', user.fullname, user.email)\n    role = datastore.find_or_create_role('admin')\n    datastore.add_role_to_user(user, role)\n    success('User %s (%s) is now administrator' % (user.fullname, user.email))", "response": "Set an user as administrator"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncombine a chunked file into a whole file again.", "response": "def combine_chunks(storage, args, prefix=None):\n    '''\n    Combine a chunked file into a whole file again.\n    Goes through each part, in order,\n    and appends that part's bytes to another destination file.\n    Chunks are stored in the chunks storage.\n    '''\n    uuid = args['uuid']\n    # Normalize filename including extension\n    target = utils.normalize(args['filename'])\n    if prefix:\n        target = os.path.join(prefix, target)\n    with storage.open(target, 'wb') as out:\n        for i in xrange(args['totalparts']):\n            partname = chunk_filename(uuid, i)\n            out.write(chunks.read(partname))\n            chunks.delete(partname)\n    chunks.delete(chunk_filename(uuid, META))\n    return target"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_uploaded_image(field):\n    '''Parse an uploaded image and save into a db.ImageField()'''\n    args = image_parser.parse_args()\n\n    image = args['file']\n    if image.mimetype not in IMAGES_MIMETYPES:\n        api.abort(400, 'Unsupported image format')\n    bbox = args.get('bbox', None)\n    if bbox:\n        bbox = [int(float(c)) for c in bbox.split(',')]\n    field.save(image, bbox=bbox)", "response": "Parse an uploaded image and save into a db. ImageField object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves a model given a name or dict with class entry.", "response": "def resolve_model(self, model):\n        '''\n        Resolve a model given a name or dict with `class` entry.\n\n        :raises ValueError: model specification is wrong or does not exists\n        '''\n        if not model:\n            raise ValueError('Unsupported model specifications')\n        if isinstance(model, basestring):\n            classname = model\n        elif isinstance(model, dict) and 'class' in model:\n            classname = model['class']\n        else:\n            raise ValueError('Unsupported model specifications')\n\n        try:\n            return get_document(classname)\n        except self.NotRegistered:\n            message = 'Model \"{0}\" does not exist'.format(classname)\n            raise ValueError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_fixtures(datasets, reuses):\n    '''Build sample fixture data (users, datasets and reuses).'''\n    user = UserFactory()\n    log.info('Generated user \"{user.email}\".'.format(user=user))\n\n    organization = OrganizationFactory(members=[Member(user=user)])\n    log.info('Generated organization \"{org.name}\".'.format(org=organization))\n\n    for _ in range(datasets):\n        dataset = VisibleDatasetFactory(organization=organization)\n        DiscussionFactory(subject=dataset, user=user)\n        ReuseFactory.create_batch(reuses, datasets=[dataset], owner=user)\n\n    msg = 'Generated {datasets} dataset(s) with {reuses} reuse(s) each.'\n    log.info(msg.format(**locals()))", "response": "Build sample fixture data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the plain text representation of markdown encoded text with an ellipsis.", "response": "def tooltip_ellipsis(source, length=0):\n    ''' return the plain text representation of markdown encoded text.  That\n    is the texted without any html tags.  If ``length`` is 0 then it\n    will not be truncated.'''\n    try:\n        length = int(length)\n    except ValueError:  # invalid literal for int()\n        return source  # Fail silently.\n    ellipsis = '<a href v-tooltip title=\"{0}\">...</a>'.format(source)\n    return Markup((source[:length] + ellipsis)\n                  if len(source) > length and length > 0 else source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef daterange_with_details(value):\n    '''Display a date range in the shorter possible maner.'''\n    delta = value.end - value.start\n    start, end = None, None\n    if is_first_year_day(value.start) and is_last_year_day(value.end):\n        start = value.start.year\n        if delta.days > 365:\n            end = value.end.year\n    elif is_first_month_day(value.start) and is_last_month_day(value.end):\n        start = short_month(value.start)\n        if delta.days > 31:\n            end = short_month(value.end)\n    else:\n        start = short_day(value.start)\n        if value.start != value.end:\n            end = short_day(value.end)\n    return _('%(start)s to %(end)s', start=start, end=end) if end else start", "response": "Display a date range in the shorter possible maner."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay a date range in the shorter possible maner.", "response": "def daterange(value, details=False):\n    '''Display a date range in the shorter possible maner.'''\n    if not isinstance(value, db.DateRange):\n        raise ValueError('daterange only accept db.DateRange as parameter')\n\n    if details:\n        return daterange_with_details(value)\n\n    date_format = 'YYYY'\n\n    delta = value.end - value.start\n    start, end = None, None\n    start = format_date(value.start, date_format)\n    if delta.days > 365:\n        end = format_date(value.end, date_format)\n\n    return '{start!s}\u2013{end!s}'.format(start=start, end=end) if end else start"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender the alternate links for the current page.", "response": "def i18n_alternate_links():\n    \"\"\"Render the <link rel=\"alternate\" hreflang />\n\n    if page is in a I18nBlueprint\n    \"\"\"\n    if (not request.endpoint or\n            not current_app.url_map.is_endpoint_expecting(request.endpoint,\n                                                          'lang_code')):\n        return Markup('')\n\n    try:\n        LINK_PATTERN = (\n            '<link rel=\"alternate\" href=\"{url}\" hreflang=\"{lang}\" />')\n        links = []\n        current_lang = get_current_locale().language\n\n        params = {}\n        if request.args:\n            params.update(request.args)\n        if request.view_args:\n            params.update(request.view_args)\n\n        for lang in current_app.config['LANGUAGES']:\n            if lang != current_lang:\n                url = url_for(request.endpoint, lang_code=lang, **params)\n                links.append(LINK_PATTERN.format(url=url, lang=lang))\n        return Markup(''.join(links))\n    except Exception:\n        # Never fails\n        return Markup('')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filesize(value):\n    '''Display a human readable filesize'''\n    suffix = 'o'\n    for unit in '', 'K', 'M', 'G', 'T', 'P', 'E', 'Z':\n        if abs(value) < 1024.0:\n            return \"%3.1f%s%s\" % (value, unit, suffix)\n        value /= 1024.0\n    return \"%.1f%s%s\" % (value, 'Y', suffix)", "response": "Display a human readable filesize"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a content negociation on the format given the Accept header", "response": "def negociate_content(default='json-ld'):\n    '''Perform a content negociation on the format given the Accept header'''\n    mimetype = request.accept_mimetypes.best_match(ACCEPTED_MIME_TYPES.keys())\n    return ACCEPTED_MIME_TYPES.get(mimetype, default)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to extract an URL from a resource property.", "response": "def url_from_rdf(rdf, prop):\n    '''\n    Try to extract An URL from a resource property.\n    It can be expressed in many forms as a URIRef or a Literal\n    '''\n    value = rdf.value(prop)\n    if isinstance(value, (URIRef, Literal)):\n        return value.toPython()\n    elif isinstance(value, RdfResource):\n        return value.identifier.toPython()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef graph_response(graph, format):\n    '''\n    Return a proper flask response for a RDF resource given an expected format.\n    '''\n    fmt = guess_format(format)\n    if not fmt:\n        abort(404)\n    headers = {\n        'Content-Type': RDF_MIME_TYPES[fmt]\n    }\n    kwargs = {}\n    if fmt == 'json-ld':\n        kwargs['context'] = context\n    if isinstance(graph, RdfResource):\n        graph = graph.graph\n    return graph.serialize(format=fmt, **kwargs), 200, headers", "response": "Return a proper flask response for a RDF resource given an expected format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlimiting current QuerySet to zone valid at a given date", "response": "def valid_at(self, valid_date):\n        '''Limit current QuerySet to zone valid at a given date'''\n        is_valid = db.Q(validity__end__gt=valid_date,\n                        validity__start__lte=valid_date)\n        no_validity = db.Q(validity=None)\n        return self(is_valid | no_validity)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving a GeoZone given a GeoID.", "response": "def resolve(self, geoid, id_only=False):\n        '''\n        Resolve a GeoZone given a GeoID.\n\n        The start date is resolved from the given GeoID,\n        ie. it find there is a zone valid a the geoid validity,\n        resolve the `latest` alias\n        or use `latest` when no validity is given.\n\n        If `id_only` is True,\n        the result will be the resolved GeoID\n        instead of the resolved zone.\n        '''\n        level, code, validity = geoids.parse(geoid)\n        qs = self(level=level, code=code)\n        if id_only:\n            qs = qs.only('id')\n        if validity == 'latest':\n            result = qs.latest()\n        else:\n            result = qs.valid_at(validity).first()\n        return result.id if id_only and result else result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef keys_values(self):\n        keys_values = []\n        for value in self.keys.values():\n            if isinstance(value, list):\n                keys_values += value\n            elif isinstance(value, basestring) and not value.startswith('-'):\n                # Avoid -99. Should be fixed in geozones\n                keys_values.append(value)\n            elif isinstance(value, int) and value >= 0:\n                # Avoid -99. Should be fixed in geozones\n                keys_values.append(str(value))\n        return keys_values", "response": "Return a list of all the key values in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef child_level(self):\n        HANDLED_LEVELS = current_app.config.get('HANDLED_LEVELS')\n        try:\n            return HANDLED_LEVELS[HANDLED_LEVELS.index(self.level) - 1]\n        except (IndexError, ValueError):\n            return None", "response": "Return the child level given handled levels."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef harvest(self):\n        '''Start the harvesting process'''\n        if self.perform_initialization() is not None:\n            self.process_items()\n            self.finalize()\n        return self.job", "response": "Start the harvesting process"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming the harvesting for a given job", "response": "def perform_initialization(self):\n        '''Initialize the harvesting for a given job'''\n        log.debug('Initializing backend')\n        factory = HarvestJob if self.dryrun else HarvestJob.objects.create\n        self.job = factory(status='initializing',\n                           started=datetime.now(),\n                           source=self.source)\n\n        before_harvest_job.send(self)\n\n        try:\n            self.initialize()\n            self.job.status = 'initialized'\n            if not self.dryrun:\n                self.job.save()\n        except HarvestValidationError as e:\n            log.info('Initialization failed for \"%s\" (%s)',\n                     safe_unicode(self.source.name), self.source.backend)\n            error = HarvestError(message=safe_unicode(e))\n            self.job.errors.append(error)\n            self.job.status = 'failed'\n            self.end()\n            return\n        except Exception as e:\n            self.job.status = 'failed'\n            error = HarvestError(message=safe_unicode(e))\n            self.job.errors.append(error)\n            self.end()\n            msg = 'Initialization failed for \"{0.name}\" ({0.backend})'\n            log.exception(msg.format(self.source))\n            return\n\n        if self.max_items:\n            self.job.items = self.job.items[:self.max_items]\n\n        if self.job.items:\n            log.debug('Queued %s items', len(self.job.items))\n\n        return len(self.job.items)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dataset(self, remote_id):\n        '''Get or create a dataset given its remote ID (and its source)\n        We first try to match `source_id` to be source domain independent\n        '''\n        dataset = Dataset.objects(__raw__={\n            'extras.harvest:remote_id': remote_id,\n            '$or': [\n                {'extras.harvest:domain': self.source.domain},\n                {'extras.harvest:source_id': str(self.source.id)},\n            ],\n        }).first()\n        return dataset or Dataset()", "response": "Get or create a dataset given its remote ID and source ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a data validation against a given Voluptous schema.", "response": "def validate(self, data, schema):\n        '''Perform a data validation against a given schema.\n\n        :param data: an object to validate\n        :param schema: a Voluptous schema to validate against\n        '''\n        try:\n            return schema(data)\n        except MultipleInvalid as ie:\n            errors = []\n            for error in ie.errors:\n                if error.path:\n                    field = '.'.join(str(p) for p in error.path)\n                    path = error.path\n                    value = data\n                    while path:\n                        attr = path.pop(0)\n                        try:\n                            if isinstance(value, (list, tuple)):\n                                attr = int(attr)\n                            value = value[attr]\n                        except Exception:\n                            value = None\n\n                    txt = safe_unicode(error).replace('for dictionary value', '')\n                    txt = txt.strip()\n                    if isinstance(error, RequiredFieldInvalid):\n                        msg = '[{0}] {1}'\n                    else:\n                        msg = '[{0}] {1}: {2}'\n                    try:\n                        msg = msg.format(field, txt, str(value))\n                    except Exception:\n                        msg = '[{0}] {1}'.format(field, txt)\n\n                else:\n                    msg = str(error)\n                errors.append(msg)\n            msg = '\\n- '.join(['Validation error:'] + errors)\n            raise HarvestValidationError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(obj):\n    '''\n    Handle a badge add API.\n\n    - Expecting badge_fieds as payload\n    - Return the badge as payload\n    - Return 200 if the badge is already\n    - Return 201 if the badge is added\n    '''\n    Form = badge_form(obj.__class__)\n    form = api.validate(Form)\n    kind = form.kind.data\n    badge = obj.get_badge(kind)\n    if badge:\n        return badge\n    else:\n        return obj.add_badge(kind), 201", "response": "Handle a badge add API."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a specific badge", "response": "def remove(obj, kind):\n    '''\n    Handle badge removal API\n\n    - Returns 404 if the badge for this kind is absent\n    - Returns 204 on success\n    '''\n    if not obj.get_badge(kind):\n        api.abort(404, 'Badge does not exists')\n    obj.remove_badge(kind)\n    return '', 204"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_for_territories(query):\n    if not query or not current_app.config.get('ACTIVATE_TERRITORIES'):\n        return []\n\n    dbqs = db.Q()\n    query = query.lower()\n    is_digit = query.isdigit()\n    query_length = len(query)\n    for level in current_app.config.get('HANDLED_LEVELS'):\n        if level == 'country':\n            continue  # Level not fully handled yet.\n        q = db.Q(level=level)\n        if (query_length == 2 and level == 'fr:departement' and\n                (is_digit or query in ('2a', '2b'))):\n            # Counties + Corsica.\n            q &= db.Q(code=query)\n        elif query_length == 3 and level == 'fr:departement' and is_digit:\n            # French DROM-COM.\n            q &= db.Q(code=query)\n        elif query_length == 5 and level == 'fr:commune' and (\n                is_digit or query.startswith('2a') or query.startswith('2b')):\n            # INSEE code then postal codes with Corsica exceptions.\n            q &= db.Q(code=query) | db.Q(keys__postal__contains=query)\n        elif query_length >= 4:\n            # Check names starting with query or exact match.\n            q &= db.Q(name__istartswith=query) | db.Q(name__iexact=query)\n        else:\n            continue\n\n        # Meta Q object, ready to be passed to a queryset.\n        dbqs |= q\n\n    if dbqs.empty:\n        return []\n\n    # Sort matching results by population and area.\n    return GeoZone.objects(dbqs).order_by('-population', '-area')", "response": "Check if a given query is valid and return a geozone queryset of territories given the query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a geoid from text and return a tuple ( level code validity )", "response": "def parse(text):\n    '''Parse a geoid from text and return a tuple (level, code, validity)'''\n    if '@' in text:\n        spatial, validity = text.split('@')\n    else:\n        spatial = text\n        validity = 'latest'\n    if ':' not in spatial:\n        raise GeoIDError('Bad GeoID format: {0}'.format(text))\n    # country-subset is a special case:\n    if spatial.startswith('country-subset:'):\n        level, code = spatial.split(':', 1)\n    else:\n        level, code = spatial.rsplit(':', 1)\n    return level, code, validity"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(level, code, validity=None):\n    '''Serialize a GeoID from its parts'''\n    spatial = ':'.join((level, code))\n    if not validity:\n        return spatial\n    elif isinstance(validity, basestring):\n        return '@'.join((spatial, validity))\n    elif isinstance(validity, datetime):\n        return '@'.join((spatial, validity.date().isoformat()))\n    elif isinstance(validity, date):\n        return '@'.join((spatial, validity.isoformat()))\n    else:\n        msg = 'Unknown GeoID validity type: {0}'\n        raise GeoIDError(msg.format(type(validity).__name__))", "response": "Serialize a GeoID from its parts"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a GeoID from a given zone", "response": "def from_zone(zone):\n    '''Build a GeoID from a given zone'''\n    validity = zone.validity.start if zone.validity else None\n    return build(zone.level, zone.code, validity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resource_to_rdf(resource, dataset=None, graph=None):\n    '''\n    Map a Resource domain model to a DCAT/RDF graph\n    '''\n    graph = graph or Graph(namespace_manager=namespace_manager)\n    if dataset and dataset.id:\n        id = URIRef(url_for('datasets.show_redirect', dataset=dataset.id,\n                            _external=True,\n                            _anchor='resource-{0}'.format(resource.id)))\n    else:\n        id = BNode(resource.id)\n    permalink = url_for('datasets.resource', id=resource.id, _external=True)\n    r = graph.resource(id)\n    r.set(RDF.type, DCAT.Distribution)\n    r.set(DCT.identifier, Literal(resource.id))\n    r.add(DCT.title, Literal(resource.title))\n    r.add(DCT.description, Literal(resource.description))\n    r.add(DCAT.downloadURL, URIRef(resource.url))\n    r.add(DCAT.accessURL, URIRef(permalink))\n    r.add(DCT.issued, Literal(resource.published))\n    r.add(DCT.modified, Literal(resource.modified))\n    if dataset and dataset.license:\n        r.add(DCT.rights, Literal(dataset.license.title))\n        if dataset.license.url:\n            r.add(DCT.license, URIRef(dataset.license.url))\n    if resource.filesize is not None:\n        r.add(DCAT.bytesSize, Literal(resource.filesize))\n    if resource.mime:\n        r.add(DCAT.mediaType, Literal(resource.mime))\n    if resource.format:\n        r.add(DCT.term('format'), Literal(resource.format))\n    if resource.checksum:\n        checksum = graph.resource(BNode())\n        checksum.set(RDF.type, SPDX.Checksum)\n        algorithm = 'checksumAlgorithm_{0}'.format(resource.checksum.type)\n        checksum.add(SPDX.algorithm, getattr(SPDX, algorithm))\n        checksum.add(SPDX.checksumValue, Literal(resource.checksum.value))\n        r.add(SPDX.checksum, checksum)\n    return r", "response": "Map a Resource domain model to a DCAT / RDF graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dataset_to_rdf(dataset, graph=None):\n    '''\n    Map a dataset domain model to a DCAT/RDF graph\n    '''\n    # Use the unlocalized permalink to the dataset as URI when available\n    # unless there is already an upstream URI\n    if 'uri' in dataset.extras:\n        id = URIRef(dataset.extras['uri'])\n    elif dataset.id:\n        id = URIRef(url_for('datasets.show_redirect',\n                            dataset=dataset.id,\n                            _external=True))\n    else:\n        id = BNode()\n    # Expose upstream identifier if present\n    if 'dct:identifier' in dataset.extras:\n        identifier = dataset.extras['dct:identifier']\n    else:\n        identifier = dataset.id\n    graph = graph or Graph(namespace_manager=namespace_manager)\n\n    d = graph.resource(id)\n    d.set(RDF.type, DCAT.Dataset)\n    d.set(DCT.identifier, Literal(identifier))\n    d.set(DCT.title, Literal(dataset.title))\n    d.set(DCT.description, Literal(dataset.description))\n    d.set(DCT.issued, Literal(dataset.created_at))\n    d.set(DCT.modified, Literal(dataset.last_modified))\n\n    if dataset.acronym:\n        d.set(SKOS.altLabel, Literal(dataset.acronym))\n\n    for tag in dataset.tags:\n        d.add(DCAT.keyword, Literal(tag))\n\n    for resource in dataset.resources:\n        d.add(DCAT.distribution, resource_to_rdf(resource, dataset, graph))\n\n    if dataset.owner:\n        d.add(DCT.publisher, user_to_rdf(dataset.owner, graph))\n    elif dataset.organization:\n        d.add(DCT.publisher, organization_to_rdf(dataset.organization, graph))\n\n    if dataset.temporal_coverage:\n        d.set(DCT.temporal, temporal_to_rdf(dataset.temporal_coverage, graph))\n\n    frequency = frequency_to_rdf(dataset.frequency)\n    if frequency:\n        d.set(DCT.accrualPeriodicity, frequency)\n\n    return d", "response": "Map a dataset to a DCAT / RDF graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef temporal_from_literal(text):\n    '''\n    Parse a temporal coverage from a literal ie. either:\n    - an ISO date range\n    - a single ISO date period (month,year)\n    '''\n    if text.count('/') == 1:\n        # This is an ISO date range as preconized by Gov.uk\n        # http://guidance.data.gov.uk/dcat_fields.html\n        start, end = text.split('/')\n        return db.DateRange(\n            start=parse_dt(start).date(),\n            end=parse_dt(end).date()\n        )\n    else:\n        separators = text.count('-')\n        if separators == 0:\n            # this is a year\n            return db.DateRange(\n                start=date(int(text), 1, 1),\n                end=date(int(text), 12, 31)\n            )\n        elif separators == 1:\n            # this is a month\n            dt = parse_dt(text).date()\n            return db.DateRange(\n                start=dt.replace(day=1),\n                end=dt.replace(day=calendar.monthrange(dt.year, dt.month)[1])\n            )", "response": "Parse a temporal coverage from a literal ie. a date range or a single ISO date period."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef temporal_from_resource(resource):\n    '''\n    Parse a temporal coverage from a RDF class/resource ie. either:\n    - a `dct:PeriodOfTime` with schema.org `startDate` and `endDate` properties\n    - an inline gov.uk Time Interval value\n    - an URI reference to a gov.uk Time Interval ontology\n      http://reference.data.gov.uk/\n    '''\n    if isinstance(resource.identifier, URIRef):\n        # Fetch remote ontology if necessary\n        g = Graph().parse(str(resource.identifier))\n        resource = g.resource(resource.identifier)\n    if resource.value(SCHEMA.startDate):\n        return db.DateRange(\n            start=resource.value(SCHEMA.startDate).toPython(),\n            end=resource.value(SCHEMA.endDate).toPython()\n        )\n    elif resource.value(SCV.min):\n        return db.DateRange(\n            start=resource.value(SCV.min).toPython(),\n            end=resource.value(SCV.max).toPython()\n        )", "response": "Parse a temporal coverage from a RDF class or resource"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef title_from_rdf(rdf, url):\n    '''\n    Try to extract a distribution title from a property.\n    As it's not a mandatory property,\n    it fallback on building a title from the URL\n    then the format and in last ressort a generic resource name.\n    '''\n    title = rdf_value(rdf, DCT.title)\n    if title:\n        return title\n    if url:\n        last_part = url.split('/')[-1]\n        if '.' in last_part and '?' not in last_part:\n            return last_part\n    fmt = rdf_value(rdf, DCT.term('format'))\n    lang = current_app.config['DEFAULT_LANGUAGE']\n    with i18n.language(lang):\n        if fmt:\n            return i18n._('{format} resource').format(format=fmt.lower())\n        else:\n            return i18n._('Nameless resource')", "response": "Try to extract a distribution title from a property."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resource_from_rdf(graph_or_distrib, dataset=None):\n    '''\n    Map a Resource domain model to a DCAT/RDF graph\n    '''\n    if isinstance(graph_or_distrib, RdfResource):\n        distrib = graph_or_distrib\n    else:\n        node = graph_or_distrib.value(predicate=RDF.type,\n                                      object=DCAT.Distribution)\n        distrib = graph_or_distrib.resource(node)\n\n    download_url = url_from_rdf(distrib, DCAT.downloadURL)\n    access_url = url_from_rdf(distrib, DCAT.accessURL)\n    url = safe_unicode(download_url or access_url)\n\n    if dataset:\n        resource = get_by(dataset.resources, 'url', url)\n    if not dataset or not resource:\n        resource = Resource()\n        if dataset:\n            dataset.resources.append(resource)\n    resource.title = title_from_rdf(distrib, url)\n    resource.url = url\n    resource.description = sanitize_html(distrib.value(DCT.description))\n    resource.filesize = rdf_value(distrib, DCAT.bytesSize)\n    resource.mime = rdf_value(distrib, DCAT.mediaType)\n    fmt = rdf_value(distrib, DCT.term('format'))\n    if fmt:\n        resource.format = fmt.lower()\n    checksum = distrib.value(SPDX.checksum)\n    if checksum:\n        algorithm = checksum.value(SPDX.algorithm).identifier\n        algorithm = CHECKSUM_ALGORITHMS.get(algorithm)\n        if algorithm:\n            resource.checksum = Checksum()\n            resource.checksum.value = rdf_value(checksum, SPDX.checksumValue)\n            resource.checksum.type = algorithm\n\n    resource.published = rdf_value(distrib, DCT.issued, resource.published)\n    resource.modified = rdf_value(distrib, DCT.modified, resource.modified)\n\n    identifier = rdf_value(distrib, DCT.identifier)\n    if identifier:\n        resource.extras['dct:identifier'] = identifier\n\n    if isinstance(distrib.identifier, URIRef):\n        resource.extras['uri'] = distrib.identifier.toPython()\n\n    return resource", "response": "Maps a RDF graph to a DCAT resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dataset_from_rdf(graph, dataset=None, node=None):\n    '''\n    Create or update a dataset from a RDF/DCAT graph\n    '''\n    dataset = dataset or Dataset()\n\n    if node is None:  # Assume first match is the only match\n        node = graph.value(predicate=RDF.type, object=DCAT.Dataset)\n\n    d = graph.resource(node)\n\n    dataset.title = rdf_value(d, DCT.title)\n    dataset.description = sanitize_html(d.value(DCT.description))\n    dataset.frequency = frequency_from_rdf(d.value(DCT.accrualPeriodicity))\n\n    acronym = rdf_value(d, SKOS.altLabel)\n    if acronym:\n        dataset.acronym = acronym\n\n    tags = [tag.toPython() for tag in d.objects(DCAT.keyword)]\n    tags += [theme.toPython() for theme in d.objects(DCAT.theme)]\n    dataset.tags = list(set(tags))\n\n    identifier = rdf_value(d, DCT.identifier)\n    if identifier:\n        dataset.extras['dct:identifier'] = identifier\n\n    if isinstance(d.identifier, URIRef):\n        dataset.extras['uri'] = d.identifier.toPython()\n\n    dataset.temporal_coverage = temporal_from_rdf(d.value(DCT.temporal))\n\n    licenses = set()\n    for distrib in d.objects(DCAT.distribution | DCAT.distributions):\n        resource_from_rdf(distrib, dataset)\n        for predicate in DCT.license, DCT.rights:\n            value = distrib.value(predicate)\n            if isinstance(value, (URIRef, Literal)):\n                licenses.add(value.toPython())\n            elif isinstance(value, RdfResource):\n                licenses.add(value.identifier.toPython())\n\n    default_license = dataset.license or License.default()\n    dataset.license = License.guess(*licenses, default=default_license)\n\n    return dataset", "response": "Create or update a dataset from a RDF graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_url_does_not_exists(form, field):\n    '''Ensure a reuse URL is not yet registered'''\n    if field.data != field.object_data and Reuse.url_exists(field.data):\n        raise validators.ValidationError(_('This URL is already registered'))", "response": "Ensure a reuse URL is not yet registered"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattaching a zone to a given organization.", "response": "def attach_zone(geoid, organization_id_or_slug):\n    '''Attach a zone <geoid> restricted to level for a given <organization>.'''\n    organization = Organization.objects.get_by_id_or_slug(\n        organization_id_or_slug)\n    if not organization:\n        log.error('No organization found for %s', organization_id_or_slug)\n    geozone = GeoZone.objects.get(id=geoid)\n    if not geozone:\n        log.error('No geozone found for %s', geoid)\n    log.info('Attaching {organization} with {geozone.name}'.format(\n             organization=organization, geozone=geozone))\n    organization.zone = geozone.id\n    organization.save()\n    log.info('Done')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detach_zone(organization_id_or_slug):\n    '''Detach the zone of a given <organization>.'''\n    organization = Organization.objects.get_by_id_or_slug(\n        organization_id_or_slug)\n    if not organization:\n        exit_with_error(\n            'No organization found for {0}'.format(organization_id_or_slug)\n        )\n    log.info('Detaching {organization} from {organization.zone}'.format(\n             organization=organization))\n    organization.zone = None\n    organization.save()\n    log.info('Done')", "response": "Detach the zone of a given organization."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(ctx):\n    '''Initialize your udata instance (search index, user, sample data...)'''\n\n    log.info('Apply DB migrations if needed')\n    ctx.invoke(migrate, record=True)\n\n    ctx.invoke(index)\n\n    if IS_TTY:\n        text = _('Do you want to create a superadmin user?')\n        if click.confirm(text, default=True):\n            user = ctx.invoke(user_commands.create)\n            ctx.invoke(user_commands.set_admin, email=user.email)\n\n        text = _('Do you want to import some data-related license?')\n        if click.confirm(text, default=True):\n            ctx.invoke(licenses)\n\n        text = _('Do you want to create some sample data?')\n        if click.confirm(text, default=True):\n            ctx.invoke(generate_fixtures)\n\n    success(_('Your udata instance is ready!'))", "response": "Initialize your udata instance (search index, user, sample data...)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obj_to_string(obj):\n    '''Render an object into a unicode string if possible'''\n    if not obj:\n        return None\n    elif isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    elif isinstance(obj, basestring):\n        return obj\n    elif is_lazy_string(obj):\n        return obj.value\n    elif hasattr(obj, '__html__'):\n        return obj.__html__()\n    else:\n        return str(obj)", "response": "Render an object into a unicode string if possible"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_filter(self, filter_values):\n        field = self._params['field']\n        # Build a `AND` query on values wihtout the OR operator.\n        # and a `OR` query for each value containing the OR operator.\n        filters = [\n            Q('bool', should=[\n                Q('term',  **{field: v}) for v in value.split(OR_SEPARATOR)\n            ])\n            if OR_SEPARATOR in value else\n            Q('term',  **{field: value})\n            for value in filter_values\n        ]\n        return Q('bool', must=filters) if len(filters) > 1 else filters[0]", "response": "Improve the original one to deal with OR cases."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_values(self, data, filter_values):\n        values = super(ModelTermsFacet, self).get_values(data, filter_values)\n        ids = [key for (key, doc_count, selected) in values]\n        # Perform a model resolution: models are feched from DB\n        # We use model field to cast IDs\n        ids = [self.model_field.to_mongo(id) for id in ids]\n        objects = self.model.objects.in_bulk(ids)\n\n        return [\n            (objects.get(self.model_field.to_mongo(key)), doc_count, selected)\n            for (key, doc_count, selected) in values\n        ]", "response": "Turn the raw bucket data into a list of tuples containing the object number of documents and a flag indicating whether this value has been\n        selected or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Q object that filters the items by the given filter value.", "response": "def get_value_filter(self, filter_value):\n        '''\n        Fix here until upstream PR is merged\n        https://github.com/elastic/elasticsearch-dsl-py/pull/473\n        '''\n        self.validate_parameter(filter_value)\n        f, t = self._ranges[filter_value]\n        limits = {}\n        # lt and gte to ensure non-overlapping ranges\n        if f is not None:\n            limits['gte'] = f\n        if t is not None:\n            limits['lt'] = t\n\n        return Q('range', **{\n            self._params['field']: limits\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, commit=True, **kwargs):\n        '''Register the current user as admin on creation'''\n        org = super(OrganizationForm, self).save(commit=False, **kwargs)\n\n        if not org.id:\n            user = current_user._get_current_object()\n            member = Member(user=user, role='admin')\n            org.members.append(member)\n\n        if commit:\n            org.save()\n\n        return org", "response": "Register the current user as admin on creation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a geozones archive from a local path or a remote URL.", "response": "def load(filename, drop=False):\n    '''\n    Load a geozones archive from <filename>\n\n    <filename> can be either a local path or a remote URL.\n    '''\n    if filename.startswith('http'):\n        log.info('Downloading GeoZones bundle: %s', filename)\n        filename, _ = urlretrieve(filename, tmp.path('geozones.tar.xz'))\n\n    log.info('Extracting GeoZones bundle')\n    with contextlib.closing(lzma.LZMAFile(filename)) as xz:\n        with tarfile.open(fileobj=xz) as f:\n            f.extractall(tmp.root)\n\n    log.info('Loading GeoZones levels')\n\n    if drop:\n        log.info('Dropping existing levels')\n        GeoLevel.drop_collection()\n\n    log.info('Loading levels.msgpack')\n    levels_filepath = tmp.path('levels.msgpack')\n    with open(levels_filepath) as fp:\n        unpacker = msgpack.Unpacker(fp, encoding=str('utf-8'))\n        for i, level in enumerate(unpacker, start=1):\n            GeoLevel.objects(id=level['id']).modify(\n                upsert=True,\n                set__name=level['label'],\n                set__parents=[level_ref(p) for p in level['parents']],\n                set__admin_level=level.get('admin_level')\n            )\n    os.remove(levels_filepath)\n    log.info('Loaded {total} levels'.format(total=i))\n\n    if drop:\n        log.info('Dropping existing spatial zones')\n        GeoZone.drop_collection()\n\n    log.info('Loading zones.msgpack')\n    zones_filepath = tmp.path('zones.msgpack')\n    with open(zones_filepath) as fp:\n        unpacker = msgpack.Unpacker(fp, encoding=str('utf-8'))\n        unpacker.next()  # Skip headers.\n        for i, geozone in enumerate(unpacker):\n            params = {\n                'slug': slugify.slugify(geozone['name'], separator='-'),\n                'level': geozone['level'],\n                'code': geozone['code'],\n                'name': geozone['name'],\n                'keys': geozone.get('keys'),\n                'parents': geozone.get('parents', []),\n                'ancestors': geozone.get('ancestors', []),\n                'successors': geozone.get('successors', []),\n                'validity': geozone.get('validity'),\n                'population': geozone.get('population'),\n                'dbpedia': geozone.get('dbpedia'),\n                'flag': geozone.get('flag'),\n                'blazon': geozone.get('blazon'),\n                'wikipedia': geozone.get('wikipedia'),\n                'area': geozone.get('area'),\n            }\n            if geozone.get('geom') and (\n                geozone['geom']['type'] != 'GeometryCollection' or\n                    geozone['geom']['geometries']):\n                params['geom'] = geozone['geom']\n            try:\n                GeoZone.objects(id=geozone['_id']).modify(upsert=True, **{\n                    'set__{0}'.format(k): v for k, v in params.items()\n                })\n            except errors.ValidationError as e:\n                log.warning('Validation error (%s) for %s with %s',\n                            e, geozone['_id'], params)\n                continue\n    os.remove(zones_filepath)\n    log.info('Loaded {total} zones'.format(total=i))\n\n    shutil.rmtree(tmp.path('translations'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload logos from a geologos archive from a local path or a remote URL.", "response": "def load_logos(filename):\n    '''\n    Load logos from a geologos archive from <filename>\n\n    <filename> can be either a local path or a remote URL.\n    '''\n    if filename.startswith('http'):\n        log.info('Downloading GeoLogos bundle: %s', filename)\n        filename, _ = urlretrieve(filename, tmp.path('geologos.tar.xz'))\n\n    log.info('Extracting GeoLogos bundle')\n    with contextlib.closing(lzma.LZMAFile(filename)) as xz:\n        with tarfile.open(fileobj=xz) as f:\n            f.extractall(tmp.root)\n\n    log.info('Moving to the final location and cleaning up')\n    if os.path.exists(logos.root):\n        shutil.rmtree(logos.root)\n    shutil.move(tmp.path('logos'), logos.root)\n    log.info('Done')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmigrate zones from old to new ids in datasets.", "response": "def migrate():\n    '''\n    Migrate zones from old to new ids in datasets.\n\n    Should only be run once with the new version of geozones w/ geohisto.\n    '''\n    counter = Counter()\n    drom_zone = GeoZone.objects(id='country-subset:fr:drom').first()\n    dromcom_zone = GeoZone.objects(id='country-subset:fr:dromcom').first()\n    # Iter over datasets with zones\n    for dataset in Dataset.objects(spatial__zones__gt=[]):\n        counter['datasets'] += 1\n        new_zones = []\n        for zone in dataset.spatial.zones:\n            if zone.id.startswith('fr/'):\n                counter['zones'] += 1\n                country, kind, zone_id = zone.id.split('/')\n                zone_id = zone_id.upper()  # Corsica 2a/b case.\n                if kind == 'town':\n                    counter['towns'] += 1\n                    new_zones.append(\n                        GeoZone\n                        .objects(code=zone_id, level='fr:commune')\n                        .valid_at(date.today())\n                        .first())\n                elif kind == 'county':\n                    counter['counties'] += 1\n                    new_zones.append(\n                        GeoZone\n                        .objects(code=zone_id, level='fr:departement')\n                        .valid_at(date.today())\n                        .first())\n                elif kind == 'region':\n                    counter['regions'] += 1\n                    # Only link to pre-2016 regions which kept the same id.\n                    new_zones.append(\n                        GeoZone\n                        .objects(code=zone_id, level='fr:region')\n                        .first())\n                elif kind == 'epci':\n                    counter['epcis'] += 1\n                    new_zones.append(\n                        GeoZone\n                        .objects(code=zone_id, level='fr:epci')\n                        .valid_at(dataset.created_at.date())\n                        .first())\n                else:\n                    new_zones.append(zone)\n            elif zone.id.startswith('country-subset/fr'):\n                counter['zones'] += 1\n                subset, country, kind = zone.id.split('/')\n                if kind == 'dom':\n                    counter['drom'] += 1\n                    new_zones.append(drom_zone)\n                elif kind == 'domtom':\n                    counter['dromcom'] += 1\n                    new_zones.append(dromcom_zone)\n            elif zone.id.startswith('country/'):\n                counter['zones'] += 1\n                counter['countries'] += 1\n                new_zones.append(zone.id.replace('/', ':'))\n            elif zone.id.startswith('country-group/'):\n                counter['zones'] += 1\n                counter['countrygroups'] += 1\n                new_zones.append(zone.id.replace('/', ':'))\n            else:\n                new_zones.append(zone)\n        dataset.update(\n            spatial=SpatialCoverage(\n                granularity=dataset.spatial.granularity,\n                zones=[getattr(z, 'id', z) for z in new_zones if z]\n            )\n        )\n    log.info(Formatter().vformat('''Summary\n    Processed {zones} zones in {datasets} datasets:\n    - {countrygroups} country groups (World/UE)\n    - {countries} countries\n    - France:\n        - {regions} regions\n        - {counties} counties\n        - {epcis} EPCIs\n        - {towns} towns\n        - {drom} DROM\n        - {dromcom} DROM-COM\n    ''', (), counter))\n    log.info('Done')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a cache key by concatenating the prefix with a hash of the path.", "response": "def get_cache_key(path):\n    \"\"\"\n    Create a cache key by concatenating the prefix with a hash of the path.\n    \"\"\"\n    # Python 2/3 support for path hashing\n    try:\n        path_hash = hashlib.md5(path).hexdigest()\n    except TypeError:\n        path_hash = hashlib.md5(path.encode('utf-8')).hexdigest()\n    return settings.cache_key_prefix + path_hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_remote_etag(storage, prefixed_path):\n    normalized_path = safe_join(storage.location, prefixed_path).replace(\n        '\\\\', '/')\n    try:\n        return storage.bucket.get_key(normalized_path).etag\n    except AttributeError:\n        pass\n    try:\n        return storage.bucket.Object(normalized_path).e_tag\n    except:\n        pass\n    return None", "response": "Get etag of path from S3 using boto or boto3."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget etag of path from cache or S3", "response": "def get_etag(storage, path, prefixed_path):\n    \"\"\"\n    Get etag of path from cache or S3 - in that order.\n    \"\"\"\n    cache_key = get_cache_key(path)\n    etag = cache.get(cache_key, False)\n    if etag is False:\n        etag = get_remote_etag(storage, prefixed_path)\n        cache.set(cache_key, etag)\n    return etag"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates md5 hash from file contents.", "response": "def get_file_hash(storage, path):\n    \"\"\"\n    Create md5 hash from file contents.\n    \"\"\"\n    contents = storage.open(path).read()\n    file_hash = hashlib.md5(contents).hexdigest()\n\n    # Check if content should be gzipped and hash gzipped content\n    content_type = mimetypes.guess_type(path)[0] or 'application/octet-stream'\n    if settings.is_gzipped and content_type in settings.gzip_content_types:\n        cache_key = get_cache_key('gzip_hash_%s' % file_hash)\n        file_hash = cache.get(cache_key, False)\n        if file_hash is False:\n            buffer = BytesIO()\n            zf = gzip.GzipFile(\n                mode='wb', compresslevel=6, fileobj=buffer, mtime=0.0)\n            zf.write(force_bytes(contents))\n            zf.close()\n            file_hash = hashlib.md5(buffer.getvalue()).hexdigest()\n            cache.set(cache_key, file_hash)\n\n    return '\"%s\"' % file_hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_matching_etag(remote_storage, source_storage, path, prefixed_path):\n    storage_etag = get_etag(remote_storage, path, prefixed_path)\n    local_etag = get_file_hash(source_storage, path)\n    return storage_etag == local_etag", "response": "Compare etag of path in source storage with remote."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the file should be copied otherwise False.", "response": "def should_copy_file(remote_storage, path, prefixed_path, source_storage):\n    \"\"\"\n    Returns True if the file should be copied, otherwise False.\n    \"\"\"\n    if has_matching_etag(\n            remote_storage, source_storage, path, prefixed_path):\n        logger.info(\"%s: Skipping based on matching file hashes\" % path)\n        return False\n\n    # Invalidate cached versions of lookup before copy\n    destroy_etag(path)\n    logger.info(\"%s: Hashes did not match\" % path)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_options(self, **options):\n        ignore_etag = options.pop('ignore_etag', False)\n        disable = options.pop('disable_collectfast', False)\n        if ignore_etag:\n            warnings.warn(\n                \"--ignore-etag is deprecated since 0.5.0, use \"\n                \"--disable-collectfast instead.\")\n        if ignore_etag or disable:\n            self.collectfast_enabled = False\n        super(Command, self).set_options(**options)", "response": "Set options and handle deprecation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride collect to copy files concurrently.", "response": "def collect(self):\n        \"\"\"\n        Override collect to copy files concurrently. The tasks are populated by\n        Command.copy_file() which is called by super().collect().\n        \"\"\"\n        ret = super(Command, self).collect()\n        if settings.threads:\n            Pool(settings.threads).map(self.do_copy_file, self.tasks)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle(self, **options):\n        super(Command, self).handle(**options)\n        return \"{} static file{} copied.\".format(\n            self.num_copied_files,\n            '' if self.num_copied_files == 1 else 's')", "response": "Override handle to supress summary output\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_copy_file(self, args):\n        path, prefixed_path, source_storage = args\n\n        reset_connection(self.storage)\n\n        if self.collectfast_enabled and not self.dry_run:\n            try:\n                if not should_copy_file(\n                        self.storage, path, prefixed_path, source_storage):\n                    return False\n            except Exception as e:\n                if settings.debug:\n                    raise\n                # Ignore errors and let default collectstatic handle copy\n                self.stdout.write(smart_str(\n                    \"Ignored error in Collectfast:\\n%s\\n--> Continuing using \"\n                    \"default collectstatic.\" % e))\n\n        self.num_copied_files += 1\n        return super(Command, self).copy_file(\n            path, prefixed_path, source_storage)", "response": "Determine if file should be copied or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy a file from the source storage to the current directory.", "response": "def copy_file(self, path, prefixed_path, source_storage):\n        \"\"\"\n        Appends path to task queue if threads are enabled, otherwise copies\n        the file with a blocking call.\n        \"\"\"\n        args = (path, prefixed_path, source_storage)\n        if settings.threads:\n            self.tasks.append(args)\n        else:\n            self.do_copy_file(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_file(self, path, prefixed_path, source_storage):\n        if not self.collectfast_enabled:\n            return super(Command, self).delete_file(\n                path, prefixed_path, source_storage)\n        if not self.dry_run:\n            self.log(\"Deleting '%s'\" % path)\n            self.storage.delete(prefixed_path)\n        else:\n            self.log(\"Pretending to delete '%s'\" % path)\n        return True", "response": "Override delete_file to skip modified time and exists lookups."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_all(rasters, roi=None, dest_resolution=None, merge_strategy=MergeStrategy.UNION,\n              shape=None, ul_corner=None, crs=None, pixel_strategy=PixelStrategy.FIRST,\n              resampling=Resampling.nearest):\n    \"\"\"Merge a list of rasters, cropping by a region of interest.\n       There are cases that the roi is not precise enough for this cases one can use,\n       the upper left corner the shape and crs to precisely define the roi.\n       When roi is provided the ul_corner, shape and crs are ignored\n    \"\"\"\n\n    first_raster = rasters[0]\n\n    if roi:\n        crs = crs or roi.crs\n\n    dest_resolution = dest_resolution or _dest_resolution(first_raster, crs)\n\n    # Create empty raster\n    empty = GeoRaster2.empty_from_roi(\n        roi, resolution=dest_resolution, band_names=first_raster.band_names,\n        dtype=first_raster.dtype, shape=shape, ul_corner=ul_corner, crs=crs)\n\n    # Create a list of single band rasters\n    all_band_names, projected_rasters = _prepare_rasters(rasters, merge_strategy, empty,\n                                                         resampling=resampling)\n    assert len(projected_rasters) == len(rasters)\n\n    prepared_rasters = _apply_pixel_strategy(projected_rasters, pixel_strategy)\n\n    # Extend the rasters list with only those that have the requested bands\n    prepared_rasters = _explode_rasters(prepared_rasters, all_band_names)\n\n    if all_band_names:\n        # Merge common bands\n        prepared_rasters = _merge_common_bands(prepared_rasters)\n\n        # Merge all bands\n        raster = reduce(_stack_bands, prepared_rasters)\n\n        return empty.copy_with(image=raster.image, band_names=raster.band_names)\n\n    else:\n        raise ValueError(\"result contains no bands, use another merge strategy\")", "response": "Merge a list of rasters into a single site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining the common bands.", "response": "def _merge_common_bands(rasters):\n    # type: (List[_Raster]) -> List[_Raster]\n    \"\"\"Combine the common bands.\n\n    \"\"\"\n    # Compute band order\n    all_bands = IndexedSet([rs.band_names[0] for rs in rasters])\n\n    def key(rs):\n        return all_bands.index(rs.band_names[0])\n\n    rasters_final = []  # type: List[_Raster]\n    for band_name, rasters_group in groupby(sorted(rasters, key=key), key=key):\n        rasters_final.append(reduce(_fill_pixels, rasters_group))\n\n    return rasters_final"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _prepare_rasters(rasters, merge_strategy, first, resampling=Resampling.nearest):\n    # type: (List[GeoRaster2], MergeStrategy, GeoRaster2, Resampling) -> Tuple[IndexedSet[str], List[Optional[_Raster]]]\n    \"\"\"Prepares the rasters according to the baseline (first) raster and the merge strategy.\n\n    The baseline (first) raster is used to crop and reproject the other rasters,\n    while the merge strategy is used to compute the bands of the result. These\n    are returned for diagnostics.\n\n    \"\"\"\n    # Create list of prepared rasters\n    all_band_names = IndexedSet(first.band_names)\n    projected_rasters = []\n    for raster in rasters:\n        projected_raster = _prepare_other_raster(first, raster, resampling=resampling)\n\n        # Modify the bands only if an intersecting raster was returned\n        if projected_raster:\n            if merge_strategy is MergeStrategy.INTERSECTION:\n                all_band_names.intersection_update(projected_raster.band_names)\n            elif merge_strategy is MergeStrategy.UNION:\n                all_band_names.update(projected_raster.band_names)\n\n        # Some rasters might be None. In this way, we still retain the original order\n        projected_rasters.append(projected_raster)\n\n    return all_band_names, projected_rasters", "response": "Prepares the rasters according to the baseline and the merge strategy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _explode_raster(raster, band_names=[]):\n    # type: (_Raster, Iterable[str]) -> List[_Raster]\n    \"\"\"Splits a raster into multiband rasters.\n\n    \"\"\"\n    # Using band_names=[] does no harm because we are not mutating it in place\n    # and it makes MyPy happy\n    if not band_names:\n        band_names = raster.band_names\n    else:\n        band_names = list(IndexedSet(raster.band_names).intersection(band_names))\n\n    return [_Raster(image=raster.bands_data([band_name]), band_names=[band_name]) for band_name in band_names]", "response": "Splits a raster into multiband rasters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging two single band rasters with the same band by filling the pixels according to depth.", "response": "def _fill_pixels(one, other):\n    # type: (_Raster, _Raster) -> _Raster\n    \"\"\"Merges two single band rasters with the same band by filling the pixels according to depth.\n\n    \"\"\"\n    assert len(one.band_names) == len(other.band_names) == 1, \"Rasters are not single band\"\n\n    # We raise an error in the intersection is empty.\n    # Other options include returning an \"empty\" raster or just None.\n    # The problem with the former is that GeoRaster2 expects a 2D or 3D\n    # numpy array, so there is no obvious way to signal that this raster\n    # has no bands. Also, returning a (1, 1, 0) numpy array is useless\n    # for future concatenation, so the expected shape should be used\n    # instead. The problem with the latter is that it breaks concatenation\n    # anyway and requires special attention. Suggestions welcome.\n    if one.band_names != other.band_names:\n        raise ValueError(\"rasters have no bands in common, use another merge strategy\")\n\n    new_image = one.image.copy()\n    other_image = other.image\n\n    # The values that I want to mask are the ones that:\n    # * Were already masked in the other array, _or_\n    # * Were already unmasked in the one array, so I don't overwrite them\n    other_values_mask = (np.ma.getmaskarray(other_image)[0] | (~np.ma.getmaskarray(one.image)[0]))\n\n    # Reshape the mask to fit the future array\n    other_values_mask = other_values_mask[None, ...]\n\n    # Overwrite the values that I don't want to mask\n    new_image[~other_values_mask] = other_image[~other_values_mask]\n\n    # In other words, the values that I wanted to write are the ones that:\n    # * Were already masked in the one array, _and_\n    # * Were not masked in the other array\n    # The reason for using the inverted form is to retain the semantics\n    # of \"masked=True\" that apply for masked arrays. The same logic\n    # could be written, using the De Morgan's laws, as\n    # other_values_mask = (one.image.mask[0] & (~other_image.mask[0])\n    # other_values_mask = other_values_mask[None, ...]\n    # new_image[other_values_mask] = other_image[other_values_mask]\n    # but here the word \"mask\" does not mean the same as in masked arrays.\n\n    return _Raster(image=new_image, band_names=one.band_names)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _stack_bands(one, other):\n    # type: (_Raster, _Raster) -> _Raster\n    \"\"\"Merges two rasters with non overlapping bands by stacking the bands.\n\n    \"\"\"\n    assert set(one.band_names).intersection(set(other.band_names)) == set()\n\n    # We raise an error in the bands are the same. See above.\n    if one.band_names == other.band_names:\n        raise ValueError(\"rasters have the same bands, use another merge strategy\")\n\n    # Apply \"or\" to the mask in the same way rasterio does, see\n    # https://mapbox.github.io/rasterio/topics/masks.html#dataset-masks\n    # In other words, mask the values that are already masked in either\n    # of the two rasters, since one mask per band is not supported\n    new_mask = np.ma.getmaskarray(one.image)[0] | np.ma.getmaskarray(other.image)[0]\n\n    # Concatenate the data along the band axis and apply the mask\n    new_image = np.ma.masked_array(\n        np.concatenate([\n            one.image.data,\n            other.image.data\n        ]),\n        mask=[new_mask] * (one.image.shape[0] + other.image.shape[0])\n    )\n    new_bands = one.band_names + other.band_names\n\n    # We don't copy image and mask here, due to performance issues,\n    # this output should not use without eventually being copied\n    # In this context we are copying the object in the end of merge_all merge_first and merge\n    return _Raster(image=new_image, band_names=new_bands)", "response": "Merges two rasters with non overlapping bands by stacking the bands."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new copy of one with the same image and other.", "response": "def merge_two(one, other, merge_strategy=MergeStrategy.UNION, silent=False, pixel_strategy=PixelStrategy.FIRST):\n    # type: (GeoRaster2, GeoRaster2, MergeStrategy, bool, PixelStrategy) -> GeoRaster2\n    \"\"\"Merge two rasters into one.\n\n    Parameters\n    ----------\n    one : GeoRaster2\n        Left raster to merge.\n    other : GeoRaster2\n        Right raster to merge.\n    merge_strategy : MergeStrategy, optional\n        Merge strategy, from :py:data:`telluric.georaster.MergeStrategy` (default to \"union\").\n    silent : bool, optional\n        Whether to raise errors or return some result, default to False (raise errors).\n    pixel_strategy: PixelStrategy, optional\n        Pixel strategy, from :py:data:`telluric.georaster.PixelStrategy` (default to \"top\").\n\n    Returns\n    -------\n    GeoRaster2\n\n    \"\"\"\n    other_res = _prepare_other_raster(one, other)\n    if other_res is None:\n        if silent:\n            return one\n        else:\n            raise ValueError(\"rasters do not intersect\")\n\n    else:\n        other = other.copy_with(image=other_res.image, band_names=other_res.band_names)  # To make MyPy happy\n\n    # Create a list of single band rasters\n    # Cropping won't happen twice, since other was already cropped\n    all_band_names, projected_rasters = _prepare_rasters([other], merge_strategy, first=one)\n\n    if not all_band_names and not silent:\n        raise ValueError(\"rasters have no bands in common, use another merge strategy\")\n\n    prepared_rasters = _apply_pixel_strategy(projected_rasters, pixel_strategy)\n\n    prepared_rasters = _explode_rasters(prepared_rasters, all_band_names)\n\n    # Merge common bands\n    prepared_rasters = _merge_common_bands(_explode_raster(one, all_band_names) + prepared_rasters)\n\n    # Merge all bands\n    raster = reduce(_stack_bands, prepared_rasters)\n\n    return one.copy_with(image=raster.image, band_names=raster.band_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_image(self, image, nodata=None):\n        # convert to masked array:\n        if isinstance(image, np.ma.core.MaskedArray):\n            masked = image\n        elif isinstance(image, np.core.ndarray):\n            masked = self._build_masked_array(image, nodata)\n        else:\n            raise GeoRaster2NotImplementedError('only ndarray or masked array supported, got %s' % type(image))\n\n        # make sure array is 3d:\n        if len(masked.shape) == 3:\n            self._image = masked\n        elif len(masked.shape) == 2:\n            self._image = masked[np.newaxis, :, :]\n        else:\n            raise GeoRaster2Error('expected 2d or 3d image, got shape=%s' % masked.shape)\n\n        # update shape\n        if self._shape is None:\n            self._set_shape(self._image.shape)\n\n        self._image_after_load_validations()\n        if self._image_readonly:\n            self._image.setflags(write=0)", "response": "Set image to nodata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn handler to open rasters ( rasterio. open ).", "response": "def _raster_opener(cls, filename, *args, **kwargs):\n        \"\"\"Return handler to open rasters (rasterio.open).\"\"\"\n        with rasterio.Env(**cls.get_gdal_env(filename)):\n            try:\n                return rasterio.open(filename, *args, **kwargs)\n            except (rasterio.errors.RasterioIOError, rasterio._err.CPLE_BaseError) as e:\n                raise GeoRaster2IOError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_wms(cls, filename, vector, resolution, destination_file=None):\n        doc = wms_vrt(filename,\n                      bounds=vector,\n                      resolution=resolution).tostring()\n        filename = cls._save_to_destination_file(doc, destination_file)\n        return GeoRaster2.open(filename)", "response": "Create georaster from a web service definition file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a GeoRaster2 object from a list of rasters.", "response": "def from_rasters(cls, rasters, relative_to_vrt=True, destination_file=None, nodata=None, mask_band=None):\n        \"\"\"Create georaster out of a list of rasters.\"\"\"\n        if isinstance(rasters, list):\n            doc = raster_list_vrt(rasters, relative_to_vrt, nodata, mask_band).tostring()\n        else:\n            doc = raster_collection_vrt(rasters, relative_to_vrt, nodata, mask_band).tostring()\n        filename = cls._save_to_destination_file(doc, destination_file)\n        return GeoRaster2.open(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a georaster from a file.", "response": "def open(cls, filename, band_names=None, lazy_load=True, mutable=False, **kwargs):\n        \"\"\"\n        Read a georaster from a file.\n\n        :param filename: url\n        :param band_names: list of strings, or string.\n                            if None - will try to read from image, otherwise - these will be ['0', ..]\n        :param lazy_load: if True - do not load anything\n        :return: GeoRaster2\n        \"\"\"\n        if mutable:\n            geo_raster = MutableGeoRaster(filename=filename, band_names=band_names, **kwargs)\n        else:\n            geo_raster = cls(filename=filename, band_names=band_names, **kwargs)\n        if not lazy_load:\n            geo_raster._populate_from_rasterio_object(read_image=True)\n        return geo_raster"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts tags from file.", "response": "def tags(cls, filename, namespace=None):\n        \"\"\"Extract tags from file.\"\"\"\n        return cls._raster_opener(filename).tags(ns=namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the filename of the source file used by this object.", "response": "def source_file(self):\n        \"\"\" When using open, returns the filename used\n        \"\"\"\n        if self._filename is None:\n            self._filename = self._as_in_memory_geotiff()._filename\n        return self._filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef blockshapes(self):\n        if self._blockshapes is None:\n            if self._filename:\n                self._populate_from_rasterio_object(read_image=False)\n            else:\n                # if no file is attached to the raster set the shape of each band to be the data array size\n                self._blockshapes = [(self.height, self.width) for z in range(self.num_bands)]\n        return self._blockshapes", "response": "Raster all bands block shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename, tags=None, **kwargs):\n        if not filename.startswith(\"/vsi\"):\n            folder = os.path.abspath(os.path.join(filename, os.pardir))\n            os.makedirs(folder, exist_ok=True)\n\n        internal_mask = kwargs.get('GDAL_TIFF_INTERNAL_MASK', True)\n        nodata_value = kwargs.get('nodata', None)\n        compression = kwargs.get('compression', Compression.lzw)\n        rasterio_envs = {'GDAL_TIFF_INTERNAL_MASK': internal_mask}\n        if os.environ.get('DEBUG', False):\n            rasterio_envs['CPL_DEBUG'] = True\n        with rasterio.Env(**rasterio_envs):\n            try:\n                size = self.shape\n                extension = os.path.splitext(filename)[1].lower()[1:]\n                driver = gdal_drivers[extension]\n\n                # tiled\n                tiled = kwargs.get('tiled', False)\n                blockxsize = kwargs.get('blockxsize', 256)\n                blockysize = kwargs.get('blockysize', 256)\n\n                params = {\n                    'mode': \"w\", 'transform': self.affine, 'crs': self.crs,\n                    'driver': driver, 'width': size[2], 'height': size[1], 'count': size[0],\n                    'dtype': dtype_map[self.dtype.type],\n                    'nodata': nodata_value,\n                    'masked': True,\n                    'blockxsize': min(blockxsize, size[2]),\n                    'blockysize': min(blockysize, size[1]),\n                    'tiled': tiled,\n                    'compress': compression.name if compression in Compression else compression,\n                }\n                # additional creation options\n                # -co COPY_SRC_OVERVIEWS=YES  -co COMPRESS=DEFLATE -co PHOTOMETRIC=MINISBLACK\n                creation_options = kwargs.get('creation_options', {})\n                if creation_options:\n                    params.update(**creation_options)\n\n                if self._image is None and self._filename is not None:\n                    creation_options[\"blockxsize\"] = params[\"blockxsize\"]\n                    creation_options[\"blockysize\"] = params[\"blockysize\"]\n                    creation_options[\"tiled\"] = params[\"tiled\"]\n                    creation_options[\"compress\"] = params[\"compress\"]\n                    rasterio.shutil.copy(self.source_file, filename, creation_options=creation_options)\n                    self._cleanup()\n                    with GeoRaster2._raster_opener(filename, \"r+\",) as r:\n                        self._add_overviews_and_tags(r, tags, kwargs)\n\n                else:\n                    with GeoRaster2._raster_opener(filename, **params) as r:\n\n                        # write data:\n                        for band in range(self.shape[0]):\n                            img = self.image.data\n                            r.write_band(1 + band, img[band, :, :])\n\n                        # write mask:\n                        if not (\n                            np.ma.getmaskarray(self.image) ==\n                            np.ma.getmaskarray(self.image)[0]\n                        ).all():\n                            warnings.warn(\n                                \"Saving different masks per band is not supported, \"\n                                \"the union of the masked values will be performed.\", GeoRaster2Warning\n                            )\n\n                        if params.get('masked'):\n                            mask = _mask_from_masked_array(self.image)\n                            r.write_mask(mask)\n\n                        self._add_overviews_and_tags(r, tags, kwargs)\n\n                return GeoRaster2.open(filename)\n\n            except (rasterio.errors.RasterioIOError, rasterio._err.CPLE_BaseError, KeyError) as e:\n                raise GeoRaster2IOError(e)", "response": "Save GeoRaster to file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, point):\n        if not (isinstance(point, GeoVector) and point.type == 'Point'):\n            raise TypeError('expect GeoVector(Point), got %s' % (point,))\n\n        target = self.to_raster(point)\n        return self.image[:, int(target.y), int(target.x)]", "response": "Get the pixel values at the requested point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a copy of the raster converted to the specified type.", "response": "def astype(self, dst_type, in_range='dtype', out_range='dtype', clip_negative=False):\n        \"\"\" Returns copy of the raster, converted to desired type\n        Supported types: uint8, uint16, uint32, int8, int16, int32, float16, float32, float64\n\n        :param dst_type: desired type\n        :param in_range: str or 2-tuple, default 'dtype':\n            'image': use image min/max as the intensity range,\n            'dtype': use min/max of the image's dtype as the intensity range,\n            2-tuple: use explicit min/max intensities, it is possible to use\n            'min' or 'max' as tuple values - in this case they will be\n            replaced by min or max intensity of image respectively\n        :param out_range: str or 2-tuple, default 'dtype':\n            'dtype': use min/max of the image's dtype as the intensity range,\n            2-tuple: use explicit min/max intensities\n        :param clip_negative: boolean, if `True` - clip the negative range, default False\n        :return: numpy array of values\n        \"\"\"\n\n        def type_max(dtype):\n            return np.iinfo(dtype).max\n\n        def type_min(dtype):\n            return np.iinfo(dtype).min\n\n        if (\n            in_range is None and out_range is not None or\n            out_range is None and in_range is not None\n        ):\n            raise GeoRaster2Error(\"Both ranges should be specified or none of them.\")\n\n        src_type = self.image.dtype\n        if not np.issubdtype(src_type, np.integer) and in_range == 'dtype':\n            in_range = 'image'\n            warnings.warn(\"Value 'dtype' of in_range parameter is supported only for integer type. \"\n                          \"Instead 'image' will be used.\", GeoRaster2Warning)\n\n        if not np.issubdtype(dst_type, np.integer) and out_range == 'dtype':\n            raise GeoRaster2Error(\"Value 'dtype' of out_range parameter is supported only for integer type.\")\n\n        if (\n            dst_type == src_type and\n            in_range == out_range == 'dtype'\n        ):\n            return self\n\n        # streching or shrinking intensity levels is required\n        if out_range is not None:\n            if out_range == 'dtype':\n                omax = type_max(dst_type)\n                omin = type_min(dst_type)\n                if clip_negative and omin < 0:\n                    omin = 0\n            else:\n                omin, omax = out_range\n\n            if in_range == 'dtype':\n                imin = type_min(src_type)\n                imax = type_max(src_type)\n            elif in_range == 'image':\n                imin = min(self.min())\n                imax = max(self.max())\n            else:\n                imin, imax = in_range\n                if imin == 'min':\n                    imin = min(self.min())\n                if imax == 'max':\n                    imax = max(self.max())\n\n            if imin == imax:\n                conversion_gain = 0\n            else:\n                conversion_gain = (omax - omin) / (imax - imin)\n\n            # temp conversion, to handle saturation\n            dst_array = conversion_gain * (self.image.astype(np.float) - imin) + omin\n            dst_array = np.clip(dst_array, omin, omax)\n        else:\n            dst_array = self.image\n        dst_array = dst_array.astype(dst_type)\n        return self.copy_with(image=dst_array)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncrops raster outside vector", "response": "def crop(self, vector, resolution=None, masked=None,\n             bands=None, resampling=Resampling.cubic):\n        \"\"\"\n        crops raster outside vector (convex hull)\n        :param vector: GeoVector, GeoFeature, FeatureCollection\n        :param resolution: output resolution, None for full resolution\n        :param resampling: reprojection resampling method, default `cubic`\n\n        :return: GeoRaster\n        \"\"\"\n        bounds, window = self._vector_to_raster_bounds(vector.envelope, boundless=self._image is None)\n        if resolution:\n            xsize, ysize = self._resolution_to_output_shape(bounds, resolution)\n        else:\n            xsize, ysize = (None, None)\n\n        return self.pixel_crop(bounds, xsize, ysize, window=window,\n                               masked=masked, bands=bands, resampling=resampling)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncropping the raster outside the image.", "response": "def pixel_crop(self, bounds, xsize=None, ysize=None, window=None,\n                   masked=None, bands=None, resampling=Resampling.cubic):\n        \"\"\"Crop raster outside vector (convex hull).\n\n        :param bounds: bounds of requester portion of the image in image pixels\n        :param xsize: output raster width, None for full resolution\n        :param ysize: output raster height, None for full resolution\n        :param windows: the bounds representation window on image in image pixels, Optional\n        :param bands: list of indices of requested bands, default None which returns all bands\n        :param resampling: reprojection resampling method, default `cubic`\n\n        :return: GeoRaster\n        \"\"\"\n\n        if self._image is not None:\n            raster = self._crop(bounds, xsize=xsize, ysize=ysize, resampling=resampling)\n            if bands is not None:\n                raster = raster.limit_to_bands(bands)\n            return raster\n        else:\n            window = window or rasterio.windows.Window(bounds[0],\n                                                       bounds[1],\n                                                       bounds[2] - bounds[0] + 1,\n                                                       bounds[3] - bounds[1] + 1)\n            return self.get_window(window, xsize=xsize, ysize=ysize, masked=masked,\n                                   bands=bands, resampling=resampling)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _crop(self, bounds, xsize=None, ysize=None, resampling=Resampling.cubic):\n        out_raster = self[\n            int(bounds[0]): int(bounds[2]),\n            int(bounds[1]): int(bounds[3])\n        ]\n\n        if xsize and ysize:\n            if not (xsize == out_raster.width and ysize == out_raster.height):\n                out_raster = out_raster.resize(dest_width=xsize, dest_height=ysize, resampling=resampling)\n        return out_raster", "response": "Crop raster outside vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of this GeoRaster with no modifications.", "response": "def copy(self, mutable=False):\n        \"\"\"Return a copy of this GeoRaster with no modifications.\n\n        Can be use to create a Mutable copy of the GeoRaster\"\"\"\n\n        if self.not_loaded():\n            _cls = self.__class__\n            if mutable:\n                _cls = MutableGeoRaster\n            return _cls.open(self._filename)\n\n        return self.copy_with(mutable=mutable)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a shallow copy of this GeoRaster with some attributes changed.", "response": "def copy_with(self, mutable=False, **kwargs):\n        \"\"\"Get a copy of this GeoRaster with some attributes changed. NOTE: image is shallow-copied!\"\"\"\n        init_args = {'affine': self.affine, 'crs': self.crs, 'band_names': self.band_names, 'nodata': self.nodata_value}\n        init_args.update(kwargs)\n\n        # The image is a special case because we don't want to make a copy of a possibly big array\n        # unless totally necessary\n        if 'image' not in init_args and not self.not_loaded():\n            init_args['image'] = self.image\n        if mutable:\n            _cls = MutableGeoRaster\n        else:\n            _cls = GeoRaster2\n\n        return _cls(**init_args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprovide either ratio, or ratio_x and ratio_y, or dest_width and/or dest_height. :return: GeoRaster2", "response": "def resize(self, ratio=None, ratio_x=None, ratio_y=None, dest_width=None, dest_height=None, dest_resolution=None,\n               resampling=Resampling.cubic):\n        \"\"\"\n        Provide either ratio, or ratio_x and ratio_y, or dest_width and/or dest_height.\n\n        :return: GeoRaster2\n        \"\"\"\n        # validate input:\n        if sum([ratio is not None, ratio_x is not None and ratio_y is not None,\n                dest_height is not None or dest_width is not None, dest_resolution is not None]) != 1:\n            raise GeoRaster2Error(\n                'please provide either ratio, or {ratio_x,ratio_y}, or {dest_height, dest_width}, or dest_resolution')\n\n        if dest_width is not None and dest_height is not None:\n            ratio_x = float(dest_width) / self.width\n            ratio_y = float(dest_height) / self.height\n        elif dest_width is not None:\n            ratio = float(dest_width) / self.width\n        elif dest_height is not None:\n            ratio = float(dest_height) / self.height\n        elif dest_resolution is not None:\n            ratio = self.resolution() / dest_resolution\n        if ratio is not None:\n            ratio_x, ratio_y = ratio, ratio\n\n        return self._resize(ratio_x, ratio_y, resampling)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resize(self, ratio_x, ratio_y, resampling):\n        new_width = int(np.ceil(self.width * ratio_x))\n        new_height = int(np.ceil(self.height * ratio_y))\n\n        dest_affine = self.affine * Affine.scale(1 / ratio_x, 1 / ratio_y)\n        if self.not_loaded():\n            window = rasterio.windows.Window(0, 0, self.width, self.height)\n            resized_raster = self.get_window(window, xsize=new_width, ysize=new_height, resampling=resampling)\n        else:\n            resized_raster = self._reproject(new_width, new_height, dest_affine, resampling=resampling)\n        return resized_raster", "response": "Return raster resized by ratio."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_pillow_image(self, return_mask=False):\n        img = np.rollaxis(np.rollaxis(self.image.data, 2), 2)\n        img = Image.fromarray(img[:, :, 0]) if img.shape[2] == 1 else Image.fromarray(img)\n        if return_mask:\n            mask = np.ma.getmaskarray(self.image)\n            mask = Image.fromarray(np.rollaxis(np.rollaxis(mask, 2), 2).astype(np.uint8)[:, :, 0])\n            return img, mask\n        else:\n            return img", "response": "Return Pillow. Image and optionally also mask."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _reproject(self, new_width, new_height, dest_affine, dtype=None,\n                   dst_crs=None, resampling=Resampling.cubic):\n        \"\"\"Return re-projected raster to new raster.\n\n        :param new_width: new raster width in pixels\n        :param new_height: new raster height in pixels\n        :param dest_affine: new raster affine\n        :param dtype: new raster dtype, default current dtype\n        :param dst_crs: new raster crs, default current crs\n        :param resampling: reprojection resampling method, default `cubic`\n\n        :return GeoRaster2\n        \"\"\"\n        if new_width == 0 or new_height == 0:\n            return None\n        dst_crs = dst_crs or self.crs\n        dtype = dtype or self.image.data.dtype\n        max_dtype_value = self._max_per_dtype(self.dtype)\n        src_transform = self._patch_affine(self.affine)\n        dst_transform = self._patch_affine(dest_affine)\n\n        band_images = []\n\n        # in order to support multiband rasters with different mask I had to split the raster\n        # to single band rasters with alpha band\n\n        for band_name in self.band_names:\n            single_band_raster = self.bands_data([band_name])\n            mask = np.ma.getmaskarray(single_band_raster)\n            # mask is interperted to maximal value in alpha band\n            alpha = (~mask).astype(np.uint8) * max_dtype_value\n            src_image = np.concatenate((single_band_raster.data, alpha))\n            alpha_band_idx = 2\n\n            dest_image = np.zeros([alpha_band_idx, new_height, new_width], dtype=self.dtype)\n            rasterio.warp.reproject(src_image, dest_image, src_transform=src_transform,\n                                    dst_transform=dst_transform, src_crs=self.crs, dst_crs=dst_crs,\n                                    resampling=resampling, dest_alpha=alpha_band_idx,\n                                    init_dest_nodata=False, src_alpha=alpha_band_idx)\n            dest_image = np.ma.masked_array(dest_image[0:1, :, :], dest_image[1:2, :, :] == 0)\n            band_images.append(dest_image)\n        dest_image = np.ma.concatenate(band_images)\n        new_raster = self.copy_with(image=np.ma.masked_array(dest_image.data, np.ma.getmaskarray(dest_image)),\n                                    affine=dst_transform, crs=dst_crs)\n\n        return new_raster", "response": "Reproject the raster to new raster."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reproject(self, dst_crs=None, resolution=None, dimensions=None,\n                  src_bounds=None, dst_bounds=None, target_aligned_pixels=False,\n                  resampling=Resampling.cubic, creation_options=None, **kwargs):\n        \"\"\"Return re-projected raster to new raster.\n\n        Parameters\n        ------------\n        dst_crs: rasterio.crs.CRS, optional\n            Target coordinate reference system.\n        resolution: tuple (x resolution, y resolution) or float, optional\n            Target resolution, in units of target coordinate reference\n            system.\n        dimensions: tuple (width, height), optional\n            Output size in pixels and lines.\n        src_bounds: tuple (xmin, ymin, xmax, ymax), optional\n            Georeferenced extent of output (in source georeferenced units).\n        dst_bounds: tuple (xmin, ymin, xmax, ymax), optional\n            Georeferenced extent of output (in destination georeferenced units).\n        target_aligned_pixels: bool, optional\n            Align the output bounds based on the resolution.\n            Default is `False`.\n        resampling: rasterio.enums.Resampling\n            Reprojection resampling method. Default is `cubic`.\n        creation_options: dict, optional\n            Custom creation options.\n        kwargs: optional\n            Additional arguments passed to transformation function.\n\n        Returns\n        ---------\n        out: GeoRaster2\n        \"\"\"\n        if self._image is None and self._filename is not None:\n            # image is not loaded yet\n            with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tf:\n                warp(self._filename, tf.name, dst_crs=dst_crs, resolution=resolution,\n                     dimensions=dimensions, creation_options=creation_options,\n                     src_bounds=src_bounds, dst_bounds=dst_bounds,\n                     target_aligned_pixels=target_aligned_pixels,\n                     resampling=resampling, **kwargs)\n\n            new_raster = self.__class__(filename=tf.name, temporary=True,\n                                        band_names=self.band_names)\n        else:\n            # image is loaded already\n            # SimpleNamespace is handy to hold the properties that calc_transform expects, see\n            # https://docs.python.org/3/library/types.html#types.SimpleNamespace\n            src = SimpleNamespace(width=self.width, height=self.height, transform=self.transform, crs=self.crs,\n                                  bounds=BoundingBox(*self.footprint().get_bounds(self.crs)),\n                                  gcps=None)\n            dst_crs, dst_transform, dst_width, dst_height = calc_transform(\n                src, dst_crs=dst_crs, resolution=resolution, dimensions=dimensions,\n                target_aligned_pixels=target_aligned_pixels,\n                src_bounds=src_bounds, dst_bounds=dst_bounds)\n            new_raster = self._reproject(dst_width, dst_height, dst_transform,\n                                         dst_crs=dst_crs, resampling=resampling)\n\n        return new_raster", "response": "Reproject the raster to a new raster."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_png(self, transparent=True, thumbnail_size=None, resampling=None, in_range='dtype', out_range='dtype'):\n        return self.to_bytes(transparent=transparent, thumbnail_size=thumbnail_size,\n                             resampling=resampling, in_range=in_range, out_range=out_range)", "response": "Convert the image to png format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_bytes(self, transparent=True, thumbnail_size=None, resampling=None, in_range='dtype', out_range='dtype',\n                 format=\"png\"):\n        \"\"\"\n        Convert to selected format (discarding geo).\n\n        Optionally also resizes.\n        Note: for color images returns interlaced.\n        :param transparent: if True - sets alpha channel for nodata pixels\n        :param thumbnail_size: if not None - resize to thumbnail size, e.g. 512\n        :param in_range: input intensity range\n        :param out_range: output intensity range\n        :param format : str, image format, default \"png\"\n        :param resampling: one of Resampling enums\n\n        :return bytes\n        \"\"\"\n        resampling = resampling if resampling is not None else Resampling.cubic\n\n        if self.num_bands < 3:\n            warnings.warn(\"Deprecation: to_png of less then three bands raster will be not be supported in next \\\nrelease, please use: .colorize('gray').to_png()\", GeoRaster2Warning)\n\n        if self.num_bands > 3:\n            warnings.warn(\"Limiting %d bands raster to first three bands to generate png\" % self.num_bands,\n                          GeoRaster2Warning)\n            three_first_bands = self.band_names[:3]\n            raster = self.limit_to_bands(three_first_bands)\n        elif self.num_bands == 2:\n            warnings.warn(\"Limiting two bands raster to use the first band to generate png\",\n                          GeoRaster2Warning)\n            first_band = self.band_names[:1]\n            raster = self.limit_to_bands(first_band)\n        else:\n            raster = self\n\n        if raster.image.dtype != np.uint8:\n            warnings.warn(\"downscaling dtype to 'uint8' to convert to png\",\n                          GeoRaster2Warning)\n            thumbnail = raster.astype(np.uint8, in_range=in_range, out_range=out_range)\n        else:\n            thumbnail = raster.copy_with()\n\n        if thumbnail_size:\n            if thumbnail.width > thumbnail.height:\n                thumbnail = thumbnail.resize(dest_width=thumbnail_size, resampling=resampling)\n            else:\n                thumbnail = thumbnail.resize(dest_height=thumbnail_size, resampling=resampling)\n\n        img, mask = thumbnail.to_pillow_image(return_mask=True)\n\n        if transparent:\n            mask = np.array(mask)[:, :, np.newaxis]\n            mask = 255 - 255 * mask  # inverse\n\n            if thumbnail.num_bands == 1:\n                img = np.stack([img, img, img], axis=2)  # make grayscale into rgb. bypass, as mode=LA isn't supported\n\n            img = np.stack(tuple(np.split(np.asarray(img), 3, axis=2) + [mask]), axis=2)  # re-arrange into RGBA\n            img = img[:, :, :, 0]\n\n        f = io.BytesIO()\n        imageio.imwrite(f, img, format)\n        image_data = f.getvalue()\n        return image_data", "response": "Convert the image to bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_bytes(cls, image_bytes, affine, crs, band_names=None):\n        b = io.BytesIO(image_bytes)\n        image = imageio.imread(b)\n        roll = np.rollaxis(image, 2)\n        if band_names is None:\n            band_names = [0, 1, 2]\n        elif isinstance(band_names, str):\n            band_names = [band_names]\n\n        return GeoRaster2(image=roll[:3, :, :], affine=affine, crs=crs, band_names=band_names)", "response": "Create a GeoRaster object from a BytesIo object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _repr_html_(self):\n        TileServer.run_tileserver(self, self.footprint())\n        capture = \"raster: %s\" % self._filename\n        mp = TileServer.folium_client(self, self.footprint(), capture=capture)\n        return mp._repr_html_()", "response": "Required for jupyter notebook to show raster as an interactive map."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns image corner in pixels as shapely. Point.", "response": "def image_corner(self, corner):\n        \"\"\"Return image corner in pixels, as shapely.Point.\"\"\"\n        if corner not in self.corner_types():\n            raise GeoRaster2Error('corner %s invalid, expected: %s' % (corner, self.corner_types()))\n\n        x = 0 if corner[1] == 'l' else self.width\n        y = 0 if corner[0] == 'u' else self.height\n        return Point(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef center(self):\n        image_center = Point(self.width / 2, self.height / 2)\n        return self.to_world(image_center)", "response": "Return footprint center in world coordinates as GeoVector."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns image rectangle in pixels as shapely. Polygon.", "response": "def bounds(self):\n        \"\"\"Return image rectangle in pixels, as shapely.Polygon.\"\"\"\n        corners = [self.image_corner(corner) for corner in self.corner_types()]\n        return Polygon([[corner.x, corner.y] for corner in corners])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the footprint of the current object.", "response": "def _calc_footprint(self):\n        \"\"\"Return rectangle in world coordinates, as GeoVector.\"\"\"\n        corners = [self.corner(corner) for corner in self.corner_types()]\n        coords = []\n        for corner in corners:\n            shape = corner.get_shape(corner.crs)\n            coords.append([shape.x, shape.y])\n\n        shp = Polygon(coords)\n        #  TODO use GeoVector.from_bounds\n        self._footprint = GeoVector(shp, self.crs)\n        return self._footprint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the vector in pixel coordinates as shapely. Geometry.", "response": "def to_raster(self, vector):\n        \"\"\"Return the vector in pixel coordinates, as shapely.Geometry.\"\"\"\n        return transform(vector.get_shape(vector.crs), vector.crs, self.crs, dst_affine=~self.affine)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the shape in pixel coordinates as GeoVector.", "response": "def to_world(self, shape, dst_crs=None):\n        \"\"\"Return the shape (provided in pixel coordinates) in world coordinates, as GeoVector.\"\"\"\n        if dst_crs is None:\n            dst_crs = self.crs\n        shp = transform(shape, self.crs, dst_crs, dst_affine=self.affine)\n        return GeoVector(shp, dst_crs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reduce(self, op):\n        per_band = [getattr(np.ma, op)(self.image.data[band, np.ma.getmaskarray(self.image)[band, :, :] == np.False_])\n                    for band in range(self.num_bands)]\n        return per_band", "response": "Reduce the raster to a score using op"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mask(self, vector, mask_shape_nodata=False):\n        from telluric.collections import BaseCollection\n\n        # crop raster to reduce memory footprint\n        cropped = self.crop(vector)\n\n        if isinstance(vector, BaseCollection):\n            shapes = [cropped.to_raster(feature) for feature in vector]\n        else:\n            shapes = [cropped.to_raster(vector)]\n\n        mask = geometry_mask(shapes, (cropped.height, cropped.width), Affine.identity(), invert=mask_shape_nodata)\n        masked = cropped.deepcopy_with()\n        masked.image.mask |= mask\n        return masked", "response": "Mask pixels inside vector as nodata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn raster with a mask calculated based on provided value.", "response": "def mask_by_value(self, nodata):\n        \"\"\"\n        Return raster with a mask calculated based on provided value.\n        Only pixels with value=nodata will be masked.\n\n        :param nodata: value of the pixels that should be masked\n        :return: GeoRaster2\n        \"\"\"\n        return self.copy_with(image=np.ma.masked_array(self.image.data, mask=self.image.data == nodata))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving as Cloud Optimized GeoTiff object to a new file.", "response": "def save_cloud_optimized(self, dest_url, resampling=Resampling.gauss, blocksize=256,\n                             overview_blocksize=256, creation_options=None):\n        \"\"\"Save as Cloud Optimized GeoTiff object to a new file.\n\n        :param dest_url: path to the new raster\n        :param resampling: which Resampling to use on reading, default Resampling.gauss\n        :param blocksize: the size of the blocks default 256\n        :param overview_blocksize: the block size of the overviews, default 256\n        :param creation_options: dict, options that can override the source raster profile,\n                              notice that you can't override tiled=True, and the blocksize\n                              the list of creation_options can be found here https://www.gdal.org/frmt_gtiff.html\n        :return: new GeoRaster of the tiled object\n        \"\"\"\n\n        src = self  # GeoRaster2.open(self._filename)\n\n        with tempfile.NamedTemporaryFile(suffix='.tif') as tf:\n            src.save(tf.name, overviews=False)\n            convert_to_cog(tf.name, dest_url, resampling, blocksize, overview_blocksize, creation_options)\n\n        geotiff = GeoRaster2.open(dest_url)\n        return geotiff"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the outshape of a window.", "response": "def _get_window_out_shape(self, bands, window, xsize, ysize):\n        \"\"\"Get the outshape of a window.\n\n        this method is only used inside get_window to calculate the out_shape\n        \"\"\"\n\n        if xsize and ysize is None:\n            ratio = window.width / xsize\n            ysize = math.ceil(window.height / ratio)\n        elif ysize and xsize is None:\n            ratio = window.height / ysize\n            xsize = math.ceil(window.width / ratio)\n        elif xsize is None and ysize is None:\n            ysize = math.ceil(window.height)\n            xsize = math.ceil(window.width)\n        return (len(bands), ysize, xsize)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn if we should read from rasterio using the masked", "response": "def _read_with_mask(raster, masked):\n        \"\"\" returns if we should read from rasterio using the masked\n        \"\"\"\n        if masked is None:\n            mask_flags = raster.mask_flag_enums\n            per_dataset_mask = all([rasterio.enums.MaskFlags.per_dataset in flags for flags in mask_flags])\n            masked = per_dataset_mask\n        return masked"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a window from raster.", "response": "def get_window(self, window, bands=None,\n                   xsize=None, ysize=None,\n                   resampling=Resampling.cubic, masked=None, affine=None\n                   ):\n        \"\"\"Get window from raster.\n\n        :param window: requested window\n        :param bands: list of indices of requested bads, default None which returns all bands\n        :param xsize: tile x size default None, for full resolution pass None\n        :param ysize: tile y size default None, for full resolution pass None\n        :param resampling: which Resampling to use on reading, default Resampling.cubic\n        :param masked: if True uses the maks, if False doesn't use the mask, if None looks to see if there is a mask,\n                       if mask exists using it, the default None\n        :return: GeoRaster2 of tile\n        \"\"\"\n        bands = bands or list(range(1, self.num_bands + 1))\n\n        # requested_out_shape and out_shape are different for out of bounds window\n        out_shape = self._get_window_out_shape(bands, window, xsize, ysize)\n        try:\n            read_params = {\n                \"window\": window,\n                \"resampling\": resampling,\n                \"boundless\": True,\n                \"out_shape\": out_shape,\n            }\n\n            # to handle get_window / get_tile of in memory rasters\n            filename = self._raster_backed_by_a_file()._filename\n            with self._raster_opener(filename) as raster:  # type: rasterio.io.DatasetReader\n                read_params[\"masked\"] = self._read_with_mask(raster, masked)\n                array = raster.read(bands, **read_params)\n            nodata = 0 if not np.ma.isMaskedArray(array) else None\n            affine = affine or self._calculate_new_affine(window, out_shape[2], out_shape[1])\n            raster = self.copy_with(image=array, affine=affine, nodata=nodata)\n\n            return raster\n\n        except (rasterio.errors.RasterioIOError, rasterio._err.CPLE_HttpResponseError) as e:\n            raise GeoRaster2IOError(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tile(self, x_tile, y_tile, zoom,\n                 bands=None, masked=None, resampling=Resampling.cubic):\n        \"\"\"Convert mercator tile to raster window.\n\n        :param x_tile: x coordinate of tile\n        :param y_tile: y coordinate of tile\n        :param zoom: zoom level\n        :param bands: list of indices of requested bands, default None which returns all bands\n        :param resampling: reprojection resampling method, default `cubic`\n\n        :return: GeoRaster2 of tile in WEB_MERCATOR_CRS\n\n        You can use TELLURIC_GET_TILE_BUFFER env variable to control the number of pixels surrounding\n        the vector you should fetch when using this method on a raster that is not in WEB_MERCATOR_CRS\n        default to 10\n        \"\"\"\n        if self.crs == WEB_MERCATOR_CRS:\n            return self._get_tile_when_web_mercator_crs(x_tile, y_tile, zoom, bands, masked, resampling)\n\n        roi = GeoVector.from_xyz(x_tile, y_tile, zoom)\n        left, bottom, right, top = roi.get_bounds(WEB_MERCATOR_CRS)\n        new_affine = rasterio.warp.calculate_default_transform(WEB_MERCATOR_CRS, self.crs,\n                                                               256, 256, left, bottom, right, top)[0]\n        new_resolution = resolution_from_affine(new_affine)\n        buffer_ratio = int(os.environ.get(\"TELLURIC_GET_TILE_BUFFER\", 10))\n        roi_buffer = roi.buffer(math.sqrt(roi.area * buffer_ratio / 100))\n        raster = self.crop(roi_buffer, resolution=new_resolution, masked=masked,\n                           bands=bands, resampling=resampling)\n        raster = raster.reproject(dst_crs=WEB_MERCATOR_CRS, resolution=MERCATOR_RESOLUTION_MAPPING[zoom],\n                                  dst_bounds=roi_buffer.get_bounds(WEB_MERCATOR_CRS),\n                                  resampling=Resampling.cubic_spline)\n        # raster = raster.get_tile(x_tile, y_tile, zoom, bands, masked, resampling)\n        raster = raster.crop(roi).resize(dest_width=256, dest_height=256)\n        return raster", "response": "Convert mercator tile to raster window."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef colorize(self, colormap, band_name=None, vmin=None, vmax=None):\n        vmin = vmin if vmin is not None else min(self.min())\n        vmax = vmax if vmax is not None else max(self.max())\n\n        cmap = matplotlib.cm.get_cmap(colormap)  # type: matplotlib.colors.Colormap\n\n        band_index = 0\n        if band_name is None:\n            if self.num_bands > 1:\n                warnings.warn(\"Using the first band to colorize the raster\", GeoRaster2Warning)\n        else:\n            band_index = self.band_names.index(band_name)\n\n        normalized = (self.image[band_index, :, :] - vmin) / (vmax - vmin)\n\n        # Colormap instances are used to convert data values (floats)\n        # to RGBA color that the respective Colormap\n        #\n        # https://matplotlib.org/_modules/matplotlib/colors.html#Colormap\n        image_data = cmap(normalized)\n        image_data = image_data[:, :, 0:3]\n\n        # convert floats [0,1] to uint8 [0,255]\n        image_data = image_data * 255\n        image_data = image_data.astype(np.uint8)\n\n        image_data = np.rollaxis(image_data, 2)\n\n        # force nodata where it was in original raster:\n        mask = _join_masks_from_masked_array(self.image)\n        mask = np.stack([mask[0, :, :]] * 3)\n        array = np.ma.array(image_data.data, mask=mask).filled(0)  # type: np.ndarray\n        array = np.ma.array(array, mask=mask)\n\n        return self.copy_with(image=array, band_names=['red', 'green', 'blue'])", "response": "Apply a colormap on a selected band."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndissolve features contained in a FeatureCollection and applies an aggregation function to its properties.", "response": "def dissolve(collection, aggfunc=None):\n    # type: (BaseCollection, Optional[Callable[[list], Any]]) -> GeoFeature\n    \"\"\"Dissolves features contained in a FeatureCollection and applies an aggregation\n    function to its properties.\n\n    \"\"\"\n    new_properties = {}\n    if aggfunc:\n        temp_properties = defaultdict(list)  # type: DefaultDict[Any, Any]\n        for feature in collection:\n            for key, value in feature.attributes.items():\n                temp_properties[key].append(value)\n\n        for key, values in temp_properties.items():\n            try:\n                new_properties[key] = aggfunc(values)\n\n            except Exception:\n                # We just do not use these results\n                pass\n\n    return GeoFeature(collection.cascaded_union, new_properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters results that intersect a given GeoFeature or Vector.", "response": "def filter(self, intersects):\n        \"\"\"Filter results that intersect a given GeoFeature or Vector.\n\n        \"\"\"\n        try:\n            crs = self.crs\n            vector = intersects.geometry if isinstance(intersects, GeoFeature) else intersects\n            prepared_shape = prep(vector.get_shape(crs))\n            hits = []\n\n            for feature in self:\n                target_shape = feature.geometry.get_shape(crs)\n                if prepared_shape.overlaps(target_shape) or prepared_shape.intersects(target_shape):\n                    hits.append(feature)\n\n        except IndexError:\n            hits = []\n\n        return FeatureCollection(hits)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sort(self, by, desc=False):\n        if callable(by):\n            key = by\n        else:\n            def key(feature):\n                return feature[by]\n\n        sorted_features = sorted(list(self), reverse=desc, key=key)\n        return self.__class__(sorted_features)", "response": "Sorts the list of feature objects in descending or ascending order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngroup the collection by a value of a property.", "response": "def groupby(self, by):\n        # type: (Union[str, Callable[[GeoFeature], str]]) -> _CollectionGroupBy\n        \"\"\"Groups collection using a value of a property.\n\n        Parameters\n        ----------\n        by : str or callable\n            If string, name of the property by which to group.\n            If callable, should receive a GeoFeature and return the category.\n\n        Returns\n        -------\n        _CollectionGroupBy\n\n        \"\"\"\n        results = OrderedDict()  # type: OrderedDict[str, list]\n        for feature in self:\n            if callable(by):\n                value = by(feature)\n            else:\n                value = feature[by]\n\n            results.setdefault(value, []).append(feature)\n\n        if hasattr(self, \"_schema\"):\n            # I am doing this to trick mypy, is there a better way?\n            # calling self._schema generates a mypy problem\n            schema = getattr(self, \"_schema\")\n\n        return _CollectionGroupBy(results, schema=schema)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndissolving geometries and rasters within groupby.", "response": "def dissolve(self, by=None, aggfunc=None):\n        # type: (Optional[str], Optional[Callable]) -> FeatureCollection\n        \"\"\"Dissolve geometries and rasters within `groupby`.\n\n        \"\"\"\n        if by:\n            agg = partial(dissolve, aggfunc=aggfunc)  # type: Callable[[BaseCollection], GeoFeature]\n            return self.groupby(by).agg(agg)\n\n        else:\n            return FeatureCollection([dissolve(self, aggfunc)])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rasterize(self, dest_resolution, *, polygonize_width=0, crs=WEB_MERCATOR_CRS, fill_value=None,\n                  bounds=None, dtype=None, **polygonize_kwargs):\n        \"\"\"Binarize a FeatureCollection and produce a raster with the target resolution.\n\n        Parameters\n        ----------\n        dest_resolution: float\n            Resolution in units of the CRS.\n        polygonize_width : int, optional\n            Width for the polygonized features (lines and points) in pixels, default to 0 (they won't appear).\n        crs : ~rasterio.crs.CRS, dict (optional)\n            Coordinate system, default to :py:data:`telluric.constants.WEB_MERCATOR_CRS`.\n        fill_value : float or function, optional\n            Value that represents data, default to None (will default to :py:data:`telluric.rasterization.FILL_VALUE`.\n            If given a function, it must accept a single :py:class:`~telluric.features.GeoFeature` and return a numeric\n            value.\n        nodata_value : float, optional\n            Nodata value, default to None (will default to :py:data:`telluric.rasterization.NODATA_VALUE`.\n        bounds : GeoVector, optional\n            Optional bounds for the target image, default to None (will use the FeatureCollection convex hull).\n        dtype : numpy.dtype, optional\n            dtype of the result, required only if fill_value is a function.\n        polygonize_kwargs : dict\n            Extra parameters to the polygonize function.\n\n        \"\"\"\n        # Avoid circular imports\n        from telluric.georaster import merge_all, MergeStrategy\n        from telluric.rasterization import rasterize, NODATA_DEPRECATION_WARNING\n\n        # Compute the size in real units and polygonize the features\n        if not isinstance(polygonize_width, int):\n            raise TypeError(\"The width in pixels must be an integer\")\n\n        if polygonize_kwargs.pop(\"nodata_value\", None):\n            warnings.warn(NODATA_DEPRECATION_WARNING, DeprecationWarning)\n\n        # If the pixels width is 1, render points as squares to avoid missing data\n        if polygonize_width == 1:\n            polygonize_kwargs.update(cap_style_point=CAP_STYLE.square)\n\n        # Reproject collection to target CRS\n        if (\n            self.crs is not None and\n            self.crs != crs\n        ):\n            reprojected = self.reproject(crs)\n        else:\n            reprojected = self\n\n        width = polygonize_width * dest_resolution\n        polygonized = [feature.polygonize(width, **polygonize_kwargs) for feature in reprojected]\n\n        # Discard the empty features\n        shapes = [feature.geometry.get_shape(crs) for feature in polygonized\n                  if not feature.is_empty]\n\n        if bounds is None:\n            bounds = self.envelope\n\n        if bounds.area == 0.0:\n            raise ValueError(\"Specify non-empty ROI\")\n\n        if not len(self):\n            fill_value = None\n\n        if callable(fill_value):\n            if dtype is None:\n                raise ValueError(\"dtype must be specified for multivalue rasterization\")\n\n            rasters = []\n            for feature in self:\n                rasters.append(feature.geometry.rasterize(\n                    dest_resolution, fill_value=fill_value(feature), bounds=bounds, dtype=dtype, crs=crs)\n                )\n\n            return merge_all(rasters, bounds.reproject(crs), dest_resolution, merge_strategy=MergeStrategy.INTERSECTION)\n\n        else:\n            return rasterize(shapes, crs, bounds.get_shape(crs), dest_resolution, fill_value=fill_value, dtype=dtype)", "response": "Binarize a FeatureCollection and produce a raster."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, filename, driver=None, schema=None):\n        if driver is None:\n            driver = DRIVERS.get(os.path.splitext(filename)[-1])\n\n        if schema is None:\n            schema = self.schema\n\n        if driver == \"GeoJSON\":\n            # Workaround for https://github.com/Toblerity/Fiona/issues/438\n            # https://stackoverflow.com/a/27045091/554319\n            with contextlib.suppress(FileNotFoundError):\n                os.remove(filename)\n\n            crs = WGS84_CRS\n        else:\n            crs = self.crs\n\n        with fiona.open(filename, 'w', driver=driver, schema=schema, crs=crs) as sink:\n            for feature in self:\n                new_feature = self._adapt_feature_before_write(feature)\n                sink.write(new_feature.to_record(crs))", "response": "Saves the collection to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new FeatureCollection with the results of applying the statements in the arguments to each element.", "response": "def apply(self, **kwargs):\n        \"\"\"Return a new FeatureCollection with the results of applying the statements in the arguments to each element.\n\n        \"\"\"\n        def _apply(f):\n            properties = copy.deepcopy(f.properties)\n            for prop, value in kwargs.items():\n                if callable(value):\n                    properties[prop] = value(f)\n                else:\n                    properties[prop] = value\n\n            return f.copy_with(properties=properties)\n        new_fc = self.map(_apply)\n        new_schema = self.schema.copy()\n        property_names_set = kwargs.keys()\n        prop_types_map = FeatureCollection.guess_types_by_feature(new_fc[0], property_names_set)\n        for key, value_type in prop_types_map.items():\n            # already defined attribute that we just override will have the same position as before\n            # new attributes will be appened\n            new_schema[\"properties\"][key] = FIELD_TYPES_MAP_REV.get(value_type, 'str')\n        new_fc._schema = new_schema\n        return new_fc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self):\n        if self._schema is not None:\n            with MemoryFile() as memfile:\n                with memfile.open(driver=\"ESRI Shapefile\", schema=self.schema) as target:\n                    for _item in self._results:\n                        # getting rid of the assets that don't behave well becasue of in memroy rasters\n                        item = GeoFeature(_item.geometry, _item.properties)\n                        target.write(item.to_record(item.crs))", "response": "if schema exists we run shape file validation code of fiona by trying to save to in MemoryFile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a FileCollection from a file in disk.", "response": "def open(cls, filename, crs=None):\n        \"\"\"Creates a FileCollection from a file in disk.\n\n        Parameters\n        ----------\n        filename : str\n            Path of the file to read.\n        crs : CRS\n            overrides the crs of the collection, this funtion will not reprojects\n\n        \"\"\"\n        with fiona.Env():\n            with fiona.open(filename, 'r') as source:\n                original_crs = CRS(source.crs)\n                schema = source.schema\n                length = len(source)\n        crs = crs or original_crs\n        ret_val = cls(filename, crs, schema, length)\n        return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter out Groups based on filtering function.", "response": "def filter(self, func):\n        # type: (Callable[[BaseCollection], bool]) -> _CollectionGroupBy\n        \"\"\"Filter out Groups based on filtering function.\n\n        The function should get a FeatureCollection and return True to leave in the Group and False to take it out.\n        \"\"\"\n        results = OrderedDict()  # type: OrderedDict\n        for name, group in self:\n            if func(group):\n                results[name] = group\n\n        return self.__class__(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prettify(elem):\n    rough_string = ET.tostring(elem, 'utf-8')\n    reparsed = minidom.parseString(rough_string)\n    return reparsed.toprettyxml(indent=\"\\t\")", "response": "Return a pretty - printed XML string for the Element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets context to default.", "response": "def reset_context(**options):\n    \"\"\"Reset context to default.\"\"\"\n    local_context._options = {}\n    local_context._options.update(options)\n    log.debug(\"New TelluricContext context %r created\", local_context._options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context():\n    if not local_context._options:\n        raise TelluricContextError(\"TelluricContext context not exists\")\n    else:\n        log.debug(\"Got a copy of context %r options\", local_context._options)\n        return local_context._options.copy()", "response": "Get a mapping of current options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_context(**options):\n    if not local_context._options:\n        raise TelluricContextError(\"TelluricContext context not exists\")\n    else:\n        local_context._options.update(options)\n        log.debug(\"Updated existing %r with options %r\", local_context._options, options)", "response": "Set options in the existing context."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_defaults(cls, **kwargs):\n        options = TelluricContext.default_options()\n        options.update(**kwargs)\n        return cls(**options)", "response": "Create a new TelluricContext with default config options."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_properties(properties, schema):\n    new_properties = properties.copy()\n    for prop_value, (prop_name, prop_type) in zip(new_properties.values(), schema[\"properties\"].items()):\n        if prop_value is None:\n            continue\n        elif prop_type == \"time\":\n            new_properties[prop_name] = parse_date(prop_value).time()\n        elif prop_type == \"date\":\n            new_properties[prop_name] = parse_date(prop_value).date()\n        elif prop_type == \"datetime\":\n            new_properties[prop_name] = parse_date(prop_value)\n\n    return new_properties", "response": "Transform properties types according to a schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serialize_properties(properties):\n    new_properties = properties.copy()\n    for attr_name, attr_value in new_properties.items():\n        if isinstance(attr_value, datetime):\n            new_properties[attr_name] = attr_value.isoformat()\n        elif not isinstance(attr_value, (dict, list, tuple, str, int, float, bool, type(None))):\n            # Property is not JSON-serializable according to this table\n            # https://docs.python.org/3.4/library/json.html#json.JSONEncoder\n            # so we convert to string\n            new_properties[attr_name] = str(attr_value)\n    return new_properties", "response": "Serialize properties.\n\n    Parameters\n    ----------\n    properties : dict\n        Properties to serialize."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_record(cls, record, crs, schema=None):\n        properties = cls._to_properties(record, schema)\n        vector = GeoVector(shape(record['geometry']), crs)\n        if record.get('raster'):\n            assets = {k: dict(type=RASTER_TYPE, product='visual', **v) for k, v in record.get('raster').items()}\n        else:\n            assets = record.get('assets', {})\n        return cls(vector, properties, assets)", "response": "Create GeoFeature from a record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a new GeoFeature with different geometry or preperties.", "response": "def copy_with(self, geometry=None, properties=None, assets=None):\n        \"\"\"Generate a new GeoFeature with different geometry or preperties.\"\"\"\n        def copy_assets_object(asset):\n            obj = asset.get(\"__object\")\n            if hasattr(\"copy\", obj):\n                new_obj = obj.copy()\n            if obj:\n                asset[\"__object\"] = new_obj\n\n        geometry = geometry or self.geometry.copy()\n        new_properties = copy.deepcopy(self.properties)\n        if properties:\n            new_properties.update(properties)\n        if not assets:\n            assets = copy.deepcopy(self.assets)\n            map(copy_assets_object, assets.values())\n        else:\n            assets = {}\n        return self.__class__(geometry, new_properties, assets)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize a GeoFeature object with a GeoRaster.", "response": "def from_raster(cls, raster, properties, product='visual'):\n        \"\"\"Initialize a GeoFeature object with a GeoRaster\n\n        Parameters\n        ----------\n        raster : GeoRaster\n            the raster in the feature\n        properties : dict\n            Properties.\n        product : str\n            product associated to the raster\n        \"\"\"\n        footprint = raster.footprint()\n        assets = raster.to_assets(product=product)\n        return cls(footprint, properties, assets)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_raster(self):\n        return any(asset.get('type') == RASTER_TYPE for asset in self.assets.values())", "response": "True if any of the assets is type raster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raster(self, name=None, **creteria):\n        if name:\n            asset = self.assets[name]\n            if asset[\"type\"] in raster_types:\n                __object = asset.get('__object')\n                if isinstance(__object, GeoRaster2):\n                    return __object\n                else:\n                    return GeoRaster2.from_assets([asset])\n            else:\n                return None\n\n        if creteria:\n            key = next(iter(creteria))\n            value = creteria[key]\n        else:\n            # default creteria is to return a visual raster\n            key = 'product'\n            value = 'visual'\n\n        rasters = {k: asset for k, asset in self.assets.items() if asset['type'] in raster_types}\n        raster_list = list(rasters.values())\n        # if there is only a single raster in the assetes and it hase a GeoRaster object serve the object\n        if len(raster_list) == 1 and isinstance(raster_list[0].get('__object'), GeoRaster2):\n            return raster_list[0].get('__object')\n        rasters = {k: r for k, r in rasters.items() if r[key] == value}\n        raster = GeoRaster2.from_assets(rasters)\n        return raster", "response": "Generates a GeoRaster2 object based on the asset name or a creteria."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wms_vrt(wms_file, bounds=None, resolution=None):\n\n    from telluric import rasterization, constants\n    wms_tree = ET.parse(wms_file)\n    service = wms_tree.find(\".//Service\")\n    if service is not None:\n        service_name = service.attrib.get(\"name\")\n    else:\n        raise ValueError(\"Service tag is required\")\n    # definition is based on https://www.gdal.org/frmt_wms.html\n    if service_name == \"VirtualEarth\":\n        left = find_and_convert_to_type(float, wms_tree, \".//DataWindow/UpperLeftX\", -20037508.34)\n        up = find_and_convert_to_type(float, wms_tree, \".//DataWindow/UpperLeftY\", 20037508.34)\n        right = find_and_convert_to_type(float, wms_tree, \".//DataWindow/LowerRightX\", 20037508.34)\n        bottom = find_and_convert_to_type(float, wms_tree, \".//DataWindow/LowerRightY\", -20037508.34)\n        upper_bound_zoom = find_and_convert_to_type(int, wms_tree, \".//DataWindow/TileLevel\", 19)\n        projection = find_and_convert_to_type(str, wms_tree, \".//Projection\", \"EPSG: 3857\")\n        projection = CRS(init=projection)\n        blockx = find_and_convert_to_type(str, wms_tree, \".//BlockSizeX\", 256)\n        blocky = find_and_convert_to_type(str, wms_tree, \".//BlockSizeY\", 256)\n    else:\n        left = find_and_convert_to_type(float, wms_tree, \".//DataWindow/UpperLeftX\", -180.0)\n        up = find_and_convert_to_type(float, wms_tree, \".//DataWindow/UpperLeftY\", 90.0)\n        right = find_and_convert_to_type(float, wms_tree, \".//DataWindow/LowerRightX\", 180.0)\n        bottom = find_and_convert_to_type(float, wms_tree, \".//DataWindow/LowerRightY\", -90.0)\n        upper_bound_zoom = find_and_convert_to_type(int, wms_tree, \".//DataWindow/TileLevel\", 0)\n        projection = find_and_convert_to_type(str, wms_tree, \".//Projection\", \"EPSG:4326\")\n        blockx = find_and_convert_to_type(str, wms_tree, \".//BlockSizeX\", 1024)\n        blocky = find_and_convert_to_type(str, wms_tree, \".//BlockSizeY\", 1024)\n        projection = CRS(init=projection)\n\n    bands_count = find_and_convert_to_type(int, wms_tree, \".//BandsCount\", 3)\n    data_type = find_and_convert_to_type(str, wms_tree, \".//DataType\", \"Byte\")\n\n    src_bounds = (left, bottom, right, up)\n    bounds = bounds.get_bounds(crs=projection) or src_bounds\n    src_resolution = constants.MERCATOR_RESOLUTION_MAPPING[upper_bound_zoom]\n    resolution = resolution or constants.MERCATOR_RESOLUTION_MAPPING[upper_bound_zoom]\n    dst_width, dst_height, transform = rasterization.raster_data(bounds=bounds, dest_resolution=resolution)\n    orig_width, orig_height, orig_transform = rasterization.raster_data(\n        bounds=src_bounds, dest_resolution=src_resolution)\n    src_window = from_bounds(*bounds, transform=orig_transform)\n\n    vrt = BaseVRT(dst_width, dst_height, projection, transform)\n\n    vrt.add_metadata(domain=\"IMAGE_STRUCTURE\", items={\"INTERLEAVE\": \"PIXEL\"})\n\n    if bands_count != 3:\n        raise ValueError(\"We support currently on 3 bands WMS\")\n\n    for idx, band in enumerate([\"RED\", \"GREEN\", \"BLUE\"]):\n        bidx = idx + 1\n\n        band_element = vrt.add_band(data_type, bidx, band)\n        dst_window = Window(0, 0, dst_width, dst_height)\n\n        vrt.add_band_simplesource(band_element, bidx, data_type, False, os.path.abspath(wms_file),\n                                  orig_width, orig_height, blockx, blocky,\n                                  src_window, dst_window)\n\n    return vrt", "response": "Make a VRT XML document from a WMS file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef boundless_vrt_doc(\n        src_dataset, nodata=None, background=None, hidenodata=False,\n        width=None, height=None, transform=None, bands=None):\n    \"\"\"Make a VRT XML document.\n    Parameters\n    ----------\n    src_dataset : Dataset\n        The dataset to wrap.\n    background : Dataset, optional\n        A dataset that provides the optional VRT background. NB: this dataset\n        must have the same number of bands as the src_dataset.\n    Returns\n    -------\n    bytes\n        An ascii-encoded string (an ElementTree detail)\n    \"\"\"\n\n    nodata = nodata or src_dataset.nodata\n    width = width or src_dataset.width\n    height = height or src_dataset.height\n    transform = transform or src_dataset.transform\n\n    vrt = BaseVRT(width, height, src_dataset.crs, transform)\n\n    bidxs = src_dataset.indexes if bands is None else bands\n    for bidx in bidxs:\n        ci = src_dataset.colorinterp[bidx - 1]\n        block_shape = src_dataset.block_shapes[bidx - 1]\n        dtype = src_dataset.dtypes[bidx - 1]\n\n        band_element = vrt.add_band(dtype, bidx, ci.name, nodata=nodata, hidenodata=True)\n\n        if background is not None:\n            src_window = Window(0, 0, background.width, background.height)\n            dst_window = Window(0, 0, width, height)\n            vrt.add_band_simplesource(band_element, bidx, dtype, False, background.name,\n                                      width, height, block_shape[1], block_shape[0],\n                                      src_window, dst_window)\n\n        src_window = Window(0, 0, src_dataset.width, src_dataset.height)\n        xoff = (src_dataset.transform.xoff - transform.xoff) / transform.a\n        yoff = (src_dataset.transform.yoff - transform.yoff) / transform.e\n        xsize = src_dataset.width * src_dataset.transform.a / transform.a\n        ysize = src_dataset.height * src_dataset.transform.e / transform.e\n        dst_window = Window(xoff, yoff, xsize, ysize)\n        vrt.add_band_simplesource(band_element, bidx, dtype, False, src_dataset.name,\n                                  width, height, block_shape[1], block_shape[0],\n                                  src_window, dst_window, nodata=src_dataset.nodata)\n\n    if all(MaskFlags.per_dataset in flags for flags in src_dataset.mask_flag_enums):\n        mask_band = vrt.add_mask_band('Byte')\n        src_window = Window(0, 0, src_dataset.width, src_dataset.height)\n        xoff = (src_dataset.transform.xoff - transform.xoff) / transform.a\n        yoff = (src_dataset.transform.yoff - transform.yoff) / transform.e\n        xsize = src_dataset.width\n        ysize = src_dataset.height\n        dst_window = Window(xoff, yoff, xsize, ysize)\n        vrt.add_band_simplesource(mask_band, 'mask,1', 'Byte', False, src_dataset.name,\n                                  width, height, block_shape[1], block_shape[0], src_window, dst_window)\n    return vrt", "response": "Create a VRT XML document that contains a boundless VRT."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raster_list_vrt(rasters, relative_to_vrt=True, nodata=None, mask_band=None):\n\n    from telluric import FeatureCollection\n    fc = FeatureCollection.from_georasters(rasters)\n    return raster_collection_vrt(fc, relative_to_vrt, nodata, mask_band)", "response": "Create a VRT XML document from a list of GeoRaster2 objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef raster_collection_vrt(fc, relative_to_vrt=True, nodata=None, mask_band=None):\n\n    def max_resolution():\n        max_affine = max(fc, key=lambda f: f.raster().resolution()).raster().affine\n        return abs(max_affine.a), abs(max_affine.e)\n\n    from telluric import rasterization\n    from telluric.georaster import band_names_tag\n    assert all(fc.crs == f.crs for f in fc), \"all rasters should have the same CRS\"\n\n    rasters = (f.raster() for f in fc)\n    bounds = fc.convex_hull.get_bounds(fc.crs)\n    resolution = max_resolution()\n    width, height, affine = rasterization.raster_data(bounds, resolution)\n\n    bands = {}  # type: Dict[str, tuple]\n    band_names = []  # type: List[Any]\n    vrt = BaseVRT(width, height, fc.crs, affine)\n\n    last_band_idx = 0\n    if mask_band is not None:\n        mask_band = vrt.add_mask_band(\"Byte\")\n\n    for raster in rasters:\n        for i, band_name in enumerate(raster.band_names):\n            if band_name in bands:\n                band_element, band_idx = bands[band_name]\n            else:\n                last_band_idx += 1\n                band_idx = last_band_idx\n                band_element = vrt.add_band(raster.dtype, band_idx, band_name_to_color_interpretation(band_name),\n                                            nodata=nodata)\n                bands[band_name] = (band_element, last_band_idx)\n                band_names.append(band_name)\n\n            src_window = Window(0, 0, raster.width, raster.height)\n            xoff = (raster.affine.xoff - affine.xoff) / affine.a\n            yoff = (raster.affine.yoff - affine.yoff) / affine.e\n            xsize = raster.width * raster.affine.a / affine.a\n            ysize = raster.height * raster.affine.e / affine.e\n            dst_window = Window(xoff, yoff, xsize, ysize)\n            file_name = raster.source_file if relative_to_vrt else os.path.join(os.getcwd(), raster.source_file)\n\n            vrt.add_band_simplesource(band_element, band_idx, raster.dtype, relative_to_vrt, file_name,\n                                      raster.width, raster.height,\n                                      raster.block_shape(i)[1], raster.block_shape(i)[0],\n                                      src_window, dst_window)\n            if i == mask_band:\n                vrt.add_band_simplesource(mask_band, \"mask,%s\" % (mask_band + 1), \"Byte\", relative_to_vrt, file_name,\n                                          raster.width, raster.height,\n                                          raster.block_shape(i)[1], raster.block_shape(i)[0],\n                                          src_window, dst_window)\n\n    vrt.add_metadata(items={band_names_tag: json.dumps(band_names)})\n    return vrt", "response": "Create a VRT XML document from a feature collection of GeoRasters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(shape, source_crs, destination_crs=None, src_affine=None, dst_affine=None):\n    if destination_crs is None:\n        destination_crs = WGS84_CRS\n\n    if src_affine is not None:\n        shape = ops.transform(lambda r, q: ~src_affine * (r, q), shape)\n\n    shape = generate_transform(source_crs, destination_crs)(shape)\n\n    if dst_affine is not None:\n        shape = ops.transform(lambda r, q: dst_affine * (r, q), shape)\n\n    return shape", "response": "Transforms shape from one CRS to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a GeoVector in a simple Folium map.", "response": "def simple_plot(feature, *, mp=None, **map_kwargs):\n    \"\"\"Plots a GeoVector in a simple Folium map.\n\n    For more complex and customizable plots using Jupyter widgets,\n    use the plot function instead.\n\n    Parameters\n    ----------\n    feature : telluric.vectors.GeoVector, telluric.features.GeoFeature, telluric.collections.BaseCollection\n        Data to plot.\n\n    \"\"\"\n    # This import is here to avoid cyclic references\n    from telluric.collections import BaseCollection\n\n    if mp is None:\n        mp = folium.Map(tiles=\"Stamen Terrain\", **map_kwargs)\n\n    if feature.is_empty:\n        warnings.warn(\"The geometry is empty.\")\n\n    else:\n        if isinstance(feature, BaseCollection):\n            feature = feature[:SIMPLE_PLOT_MAX_ROWS]\n\n        folium.GeoJson(mapping(feature), name='geojson', overlay=True).add_to(mp)\n        shape = feature.envelope.get_shape(WGS84_CRS)\n        mp.fit_bounds([shape.bounds[:1:-1], shape.bounds[1::-1]])\n\n    return mp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate optimum zoom level for a geometry.", "response": "def zoom_level_from_geometry(geometry, splits=4):\n    \"\"\"Generate optimum zoom level for geometry.\n\n    Notes\n    -----\n    The obvious solution would be\n\n    >>> mercantile.bounding_tile(*geometry.get_shape(WGS84_CRS).bounds).z\n\n    However, if the geometry is split between two or four tiles,\n    the resulting zoom level might be too big.\n\n    \"\"\"\n    # This import is here to avoid cyclic references\n    from telluric.vectors import generate_tile_coordinates\n\n    # We split the geometry and compute the zoom level for each chunk\n    levels = []\n    for chunk in generate_tile_coordinates(geometry, (splits, splits)):\n        levels.append(mercantile.bounding_tile(*chunk.get_shape(WGS84_CRS).bounds).z)\n\n    # We now return the median value using the median_low function, which\n    # always picks the result from the list\n    return median_low(levels)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning Leaflet layer from shape.", "response": "def layer_from_element(element, style_function=None):\n    \"\"\"Return Leaflet layer from shape.\n\n    Parameters\n    ----------\n    element : telluric.vectors.GeoVector, telluric.features.GeoFeature, telluric.collections.BaseCollection\n        Data to plot.\n\n    \"\"\"\n    # This import is here to avoid cyclic references\n    from telluric.collections import BaseCollection\n\n    if isinstance(element, BaseCollection):\n        styled_element = element.map(lambda feat: style_element(feat, style_function))\n\n    else:\n        styled_element = style_element(element, style_function)\n\n    return GeoJSON(data=mapping(styled_element), name='GeoJSON')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot a GeoVector in an ipyleaflet map.", "response": "def plot(feature, mp=None, style_function=None, **map_kwargs):\n    \"\"\"Plots a GeoVector in an ipyleaflet map.\n\n    Parameters\n    ----------\n    feature : telluric.vectors.GeoVector, telluric.features.GeoFeature, telluric.collections.BaseCollection\n        Data to plot.\n    mp : ipyleaflet.Map, optional\n        Map in which to plot, default to None (creates a new one).\n    style_function : func\n        Function that returns an style dictionary for\n    map_kwargs : kwargs, optional\n        Extra parameters to send to ipyleaflet.Map.\n\n    \"\"\"\n    map_kwargs.setdefault('basemap', basemaps.Stamen.Terrain)\n    if feature.is_empty:\n        warnings.warn(\"The geometry is empty.\")\n        mp = Map(**map_kwargs) if mp is None else mp\n\n    else:\n        if mp is None:\n            center = feature.envelope.centroid.reproject(WGS84_CRS)\n            zoom = zoom_level_from_geometry(feature.envelope)\n\n            mp = Map(center=(center.y, center.x), zoom=zoom, **map_kwargs)\n\n        mp.add_layer(layer_from_element(feature, style_function))\n\n    return mp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dimension(geometry):\n    coordinates = geometry[\"coordinates\"]\n    type_ = geometry[\"type\"]\n    if type_ in ('Point',):\n        return len(coordinates)\n    elif type_ in ('LineString', 'MultiPoint'):\n        return len(coordinates[0])\n    elif type_ in ('Polygon', 'MultiLineString'):\n        return len(coordinates[0][0])\n    elif type_ in ('MultiPolygon',):\n        return len(coordinates[0][0][0])\n    else:\n        raise ValueError(\"Invalid type '{}'\".format(type_))", "response": "Gets the dimension of a Fiona - like geometry element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_tile_coordinates(roi, num_tiles):\n    # type: (GeoVector, Tuple[int, int]) -> Iterator[GeoVector]\n    \"\"\"Yields N x M rectangular tiles for a region of interest.\n\n    Parameters\n    ----------\n    roi : GeoVector\n        Region of interest\n    num_tiles : tuple\n        Tuple (horizontal_tiles, vertical_tiles)\n\n    Yields\n    ------\n    ~telluric.vectors.GeoVector\n\n    \"\"\"\n    bounds = roi.get_shape(roi.crs).bounds\n\n    x_range = np.linspace(bounds[0], bounds[2], int(num_tiles[0]) + 1)\n    y_range = np.linspace(bounds[1], bounds[3], int(num_tiles[1]) + 1)\n\n    for y_start, y_end in zip(y_range[:-1], y_range[1:]):\n        for x_start, x_end in zip(x_range[:-1], x_range[1:]):\n            new_roi = GeoVector(\n                Polygon.from_bounds(x_start, y_start, x_end, y_end),\n                roi.crs\n            )\n\n            yield new_roi", "response": "Generate N x M rectangular tiles for a region of interest."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate N x M rectangular tiles for a region of interest.", "response": "def generate_tile_coordinates_from_pixels(roi, scale, size):\n    \"\"\"Yields N x M rectangular tiles for a region of interest.\n\n    Parameters\n    ----------\n    roi : GeoVector\n        Region of interest\n    scale : float\n        Scale factor (think of it as pixel resolution)\n    size : tuple\n        Pixel size in (width, height) to be multiplied by the scale factor\n\n    Yields\n    ------\n    ~telluric.vectors.GeoVector\n\n    \"\"\"\n    if not all(isinstance(coord, int) for coord in size):\n        raise ValueError(\"Pixel size must be a tuple of integers\")\n\n    width = size[0] * scale\n    height = size[1] * scale\n\n    minx, miny, maxx, maxy = roi.get_shape(roi.crs).bounds\n\n    num_w = np.ceil((maxx - minx) / width)\n    num_h = np.ceil((maxy - miny) / height)\n\n    new_roi = GeoVector.from_bounds(\n        xmin=minx, ymin=miny,\n        xmax=minx + num_w * width, ymax=miny + num_h * height,\n        crs=roi.crs\n    )\n\n    yield from generate_tile_coordinates(new_roi, (num_w, num_h))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_geojson(cls, filename):\n        with open(filename) as fd:\n            geometry = json.load(fd)\n\n        if 'type' not in geometry:\n            raise TypeError(\"%s is not a valid geojson.\" % (filename,))\n\n        return cls(to_shape(geometry), WGS84_CRS)", "response": "Load vector from geojson."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving vector as geojson.", "response": "def to_geojson(self, filename):\n        \"\"\"Save vector as geojson.\"\"\"\n        with open(filename, 'w') as fd:\n            json.dump(self.to_record(WGS84_CRS), fd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_bounds(cls, xmin, ymin, xmax, ymax, crs=DEFAULT_CRS):\n        return cls(Polygon.from_bounds(xmin, ymin, xmax, ymax), crs)", "response": "Creates a new GeoVector object from a bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_xyz(cls, x, y, z):\n        bb = xy_bounds(x, y, z)\n        return cls.from_bounds(xmin=bb.left, ymin=bb.bottom,\n                               xmax=bb.right, ymax=bb.top,\n                               crs=WEB_MERCATOR_CRS)", "response": "Creates a GeoVector from Mercator slippy map values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cascaded_union(cls, vectors, dst_crs, prevalidate=False):\n        # type: (list, CRS, bool) -> GeoVector\n        \"\"\"Generate a GeoVector from the cascade union of the impute vectors.\"\"\"\n        try:\n            shapes = [geometry.get_shape(dst_crs) for geometry in vectors]\n\n            if prevalidate:\n                if not all([sh.is_valid for sh in shapes]):\n                    warnings.warn(\n                        \"Some invalid shapes found, discarding them.\"\n                    )\n\n        except IndexError:\n            crs = DEFAULT_CRS\n            shapes = []\n\n        return cls(\n            cascaded_union([sh for sh in shapes if sh.is_valid]).simplify(0),\n            crs=dst_crs\n        )", "response": "Generate a GeoVector from the cascade union of the impute vectors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload vector from record.", "response": "def from_record(cls, record, crs):\n        \"\"\"Load vector from record.\"\"\"\n        if 'type' not in record:\n            raise TypeError(\"The data isn't a valid record.\")\n\n        return cls(to_shape(record), crs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bounding_box(self, crs):\n        return self.from_bounds(*self.get_bounds(crs), crs=crs)", "response": "Gets the bounding box as GeoVector in a specified CRS."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the shape of this object is equal to the shape of the other object.", "response": "def equals_exact(self, other, tolerance):\n        \"\"\" invariant to crs. \"\"\"\n        # This method cannot be delegated because it has an extra parameter\n        return self._shape.equals_exact(other.get_shape(self.crs), tolerance=tolerance)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the two objects are almost equal.", "response": "def almost_equals(self, other, decimal=6):\n        \"\"\" invariant to crs. \"\"\"\n        # This method cannot be delegated because it has an extra parameter\n        return self._shape.almost_equals(other.get_shape(self.crs), decimal=decimal)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nturn line or point into a buffered polygon.", "response": "def polygonize(self, width, cap_style_line=CAP_STYLE.flat, cap_style_point=CAP_STYLE.round):\n        \"\"\"Turns line or point into a buffered polygon.\"\"\"\n        shape = self._shape\n        if isinstance(shape, (LineString, MultiLineString)):\n            return self.__class__(\n                shape.buffer(width / 2, cap_style=cap_style_line),\n                self.crs\n            )\n        elif isinstance(shape, (Point, MultiPoint)):\n            return self.__class__(\n                shape.buffer(width / 2, cap_style=cap_style_point),\n                self.crs\n            )\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_to_cog(source_file, destination_file, resampling=rasterio.enums.Resampling.gauss, blocksize=256,\n                   overview_blocksize=256, creation_options=None):\n    \"\"\"Convert source file to a Cloud Optimized GeoTiff new file.\n\n    :param source_file: path to the original raster\n    :param destination_file: path to the new raster\n    :param resampling: which Resampling to use on reading, default Resampling.gauss\n    :param blocksize: the size of the blocks default 256\n    :param overview_blocksize: the block size of the overviews, default 256\n    :param creation_options: <dictioanry>, options that can override the source raster profile,\n                          notice that you can't override tiled=True, and the blocksize\n    \"\"\"\n\n    with rasterio.open(source_file) as src:\n        # creation_options overrides proile\n        source_profile = src.profile\n    creation_options = _creation_options_for_cog(creation_options, source_profile, blocksize)\n\n    with rasterio.Env(GDAL_TIFF_INTERNAL_MASK=True, GDAL_TIFF_OVR_BLOCKSIZE=overview_blocksize):\n        with TemporaryDirectory() as temp_dir:\n            temp_file = os.path.join(temp_dir, 'temp.tif')\n            rasterio_sh.copy(source_file, temp_file, **creation_options)\n            with rasterio.open(temp_file, 'r+') as dest:\n                factors = _calc_overviews_factors(dest)\n                dest.build_overviews(factors, resampling=resampling)\n                dest.update_tags(ns='rio_overview', resampling=resampling.name)\n\n                telluric_tags = _get_telluric_tags(source_file)\n                if telluric_tags:\n                    dest.update_tags(**telluric_tags)\n\n            rasterio_sh.copy(temp_file, destination_file,\n                             COPY_SRC_OVERVIEWS=True, **creation_options)", "response": "Convert a source file to a Cloud Optimized GeoTiff file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the transformation matrix for a reprojection of a source file.", "response": "def calc_transform(src, dst_crs=None, resolution=None, dimensions=None,\n                   src_bounds=None, dst_bounds=None, target_aligned_pixels=False):\n    \"\"\"Output dimensions and transform for a reprojection.\n\n    Parameters\n    ------------\n    src: rasterio.io.DatasetReader\n        Data source.\n    dst_crs: rasterio.crs.CRS, optional\n        Target coordinate reference system.\n    resolution: tuple (x resolution, y resolution) or float, optional\n        Target resolution, in units of target coordinate reference\n        system.\n    dimensions: tuple (width, height), optional\n        Output file size in pixels and lines.\n    src_bounds: tuple (xmin, ymin, xmax, ymax), optional\n        Georeferenced extent of output file from source bounds\n        (in source georeferenced units).\n    dst_bounds: tuple (xmin, ymin, xmax, ymax), optional\n        Georeferenced extent of output file from destination bounds\n        (in destination georeferenced units).\n    target_aligned_pixels: bool, optional\n        Align the output bounds based on the resolution.\n        Default is `False`.\n\n    Returns\n    -------\n    dst_crs: rasterio.crs.CRS\n        Output crs\n    transform: Affine\n        Output affine transformation matrix\n    width, height: int\n        Output dimensions\n    \"\"\"\n    if resolution is not None:\n        if isinstance(resolution, (float, int)):\n            resolution = (float(resolution), float(resolution))\n\n    if target_aligned_pixels:\n        if not resolution:\n            raise ValueError('target_aligned_pixels cannot be used without resolution')\n        if src_bounds or dst_bounds:\n            raise ValueError('target_aligned_pixels cannot be used with src_bounds or dst_bounds')\n\n    elif dimensions:\n        invalid_combos = (dst_bounds, resolution)\n        if any(p for p in invalid_combos if p is not None):\n            raise ValueError('dimensions cannot be used with dst_bounds or resolution')\n\n    if src_bounds and dst_bounds:\n        raise ValueError('src_bounds and dst_bounds may not be specified simultaneously')\n\n    if dst_crs is not None:\n\n        if dimensions:\n            # Calculate resolution appropriate for dimensions\n            # in target.\n            dst_width, dst_height = dimensions\n            bounds = src_bounds or src.bounds\n            xmin, ymin, xmax, ymax = transform_bounds(\n                src.crs, dst_crs, *bounds)\n            dst_transform = Affine(\n                (xmax - xmin) / float(dst_width),\n                0, xmin, 0,\n                (ymin - ymax) / float(dst_height),\n                ymax\n            )\n\n        elif src_bounds or dst_bounds:\n            if not resolution:\n                raise ValueError('resolution is required when using src_bounds or dst_bounds')\n\n            if src_bounds:\n                xmin, ymin, xmax, ymax = transform_bounds(\n                    src.crs, dst_crs, *src_bounds)\n            else:\n                xmin, ymin, xmax, ymax = dst_bounds\n\n            dst_transform = Affine(resolution[0], 0, xmin, 0, -resolution[1], ymax)\n            dst_width = max(int(ceil((xmax - xmin) / resolution[0])), 1)\n            dst_height = max(int(ceil((ymax - ymin) / resolution[1])), 1)\n\n        else:\n            if src.transform.is_identity and src.gcps:\n                src_crs = src.gcps[1]\n                kwargs = {'gcps': src.gcps[0]}\n            else:\n                src_crs = src.crs\n                kwargs = src.bounds._asdict()\n            dst_transform, dst_width, dst_height = calcdt(\n                src_crs, dst_crs, src.width, src.height,\n                resolution=resolution, **kwargs)\n\n    elif dimensions:\n        # Same projection, different dimensions, calculate resolution.\n        dst_crs = src.crs\n        dst_width, dst_height = dimensions\n        l, b, r, t = src_bounds or src.bounds\n        dst_transform = Affine(\n            (r - l) / float(dst_width),\n            0, l, 0,\n            (b - t) / float(dst_height),\n            t\n        )\n\n    elif src_bounds or dst_bounds:\n        # Same projection, different dimensions and possibly\n        # different resolution.\n        if not resolution:\n            resolution = (src.transform.a, -src.transform.e)\n\n        dst_crs = src.crs\n        xmin, ymin, xmax, ymax = (src_bounds or dst_bounds)\n        dst_transform = Affine(resolution[0], 0, xmin, 0, -resolution[1], ymax)\n        dst_width = max(int(ceil((xmax - xmin) / resolution[0])), 1)\n        dst_height = max(int(ceil((ymax - ymin) / resolution[1])), 1)\n\n    elif resolution:\n        # Same projection, different resolution.\n        dst_crs = src.crs\n        l, b, r, t = src.bounds\n        dst_transform = Affine(resolution[0], 0, l, 0, -resolution[1], t)\n        dst_width = max(int(ceil((r - l) / resolution[0])), 1)\n        dst_height = max(int(ceil((t - b) / resolution[1])), 1)\n\n    else:\n        dst_crs = src.crs\n        dst_transform = src.transform\n        dst_width = src.width\n        dst_height = src.height\n\n    if target_aligned_pixels:\n        dst_transform, dst_width, dst_height = aligned_target(\n            dst_transform, dst_width, dst_height, resolution)\n\n    return dst_crs, dst_transform, dst_width, dst_height"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef warp(source_file, destination_file, dst_crs=None, resolution=None, dimensions=None,\n         src_bounds=None, dst_bounds=None, src_nodata=None, dst_nodata=None,\n         target_aligned_pixels=False, check_invert_proj=True,\n         creation_options=None, resampling=Resampling.cubic, **kwargs):\n    \"\"\"Warp a raster dataset.\n\n    Parameters\n    ------------\n    source_file: str, file object or pathlib.Path object\n        Source file.\n    destination_file: str, file object or pathlib.Path object\n        Destination file.\n    dst_crs: rasterio.crs.CRS, optional\n        Target coordinate reference system.\n    resolution: tuple (x resolution, y resolution) or float, optional\n        Target resolution, in units of target coordinate reference\n        system.\n    dimensions: tuple (width, height), optional\n        Output file size in pixels and lines.\n    src_bounds: tuple (xmin, ymin, xmax, ymax), optional\n        Georeferenced extent of output file from source bounds\n        (in source georeferenced units).\n    dst_bounds: tuple (xmin, ymin, xmax, ymax), optional\n        Georeferenced extent of output file from destination bounds\n        (in destination georeferenced units).\n    src_nodata: int, float, or nan, optional\n        Manually overridden source nodata.\n    dst_nodata: int, float, or nan, optional\n        Manually overridden destination nodata.\n    target_aligned_pixels: bool, optional\n        Align the output bounds based on the resolution.\n        Default is `False`.\n    check_invert_proj: bool, optional\n        Constrain output to valid coordinate region in dst_crs.\n        Default is `True`.\n    creation_options: dict, optional\n        Custom creation options.\n    resampling: rasterio.enums.Resampling\n        Reprojection resampling method. Default is `cubic`.\n    kwargs: optional\n        Additional arguments passed to transformation function.\n\n    Returns\n    ---------\n    out: None\n        Output is written to destination.\n    \"\"\"\n\n    with rasterio.Env(CHECK_WITH_INVERT_PROJ=check_invert_proj):\n        with rasterio.open(source_file) as src:\n            out_kwargs = src.profile.copy()\n            dst_crs, dst_transform, dst_width, dst_height = calc_transform(\n                src, dst_crs, resolution, dimensions,\n                src_bounds, dst_bounds, target_aligned_pixels)\n\n            # If src_nodata is not None, update the dst metadata NODATA\n            # value to src_nodata (will be overridden by dst_nodata if it is not None.\n            if src_nodata is not None:\n                # Update the destination NODATA value\n                out_kwargs.update({\n                    'nodata': src_nodata\n                })\n\n            # Validate a manually set destination NODATA value.\n            if dst_nodata is not None:\n                if src_nodata is None and src.meta['nodata'] is None:\n                    raise ValueError('src_nodata must be provided because dst_nodata is not None')\n                else:\n                    out_kwargs.update({'nodata': dst_nodata})\n\n            out_kwargs.update({\n                'crs': dst_crs,\n                'transform': dst_transform,\n                'width': dst_width,\n                'height': dst_height\n            })\n\n            # Adjust block size if necessary.\n            if ('blockxsize' in out_kwargs and\n                    dst_width < out_kwargs['blockxsize']):\n                del out_kwargs['blockxsize']\n            if ('blockysize' in out_kwargs and\n                    dst_height < out_kwargs['blockysize']):\n                del out_kwargs['blockysize']\n\n            if creation_options is not None:\n                out_kwargs.update(**creation_options)\n\n            with rasterio.open(destination_file, 'w', **out_kwargs) as dst:\n                reproject(\n                    source=rasterio.band(src, src.indexes),\n                    destination=rasterio.band(dst, dst.indexes),\n                    src_transform=src.transform,\n                    src_crs=src.crs,\n                    src_nodata=src_nodata,\n                    dst_transform=out_kwargs['transform'],\n                    dst_crs=out_kwargs['crs'],\n                    dst_nodata=dst_nodata,\n                    resampling=resampling,\n                    **kwargs)", "response": "Warp a raster dataset to a new raster file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_overviews(source_file, factors=None, minsize=256, external=False,\n                    blocksize=256, interleave='pixel', compress='lzw',\n                    resampling=Resampling.gauss, **kwargs):\n    \"\"\"Build overviews at one or more decimation factors for all\n    bands of the dataset.\n\n    Parameters\n    ------------\n    source_file : str, file object or pathlib.Path object\n        Source file.\n    factors : list, optional\n        A list of integral overview levels to build.\n    minsize : int, optional\n        Maximum width or height of the smallest overview level. Only taken into account\n        if explicit factors are not specified. Defaults to `256`.\n    external : bool, optional\n        Can be set to `True` to force external overviews in the GeoTIFF (.ovr) format.\n        Default is False.\n    blocksize : int, optional\n        The block size (tile width and height) used for overviews. Should be a\n        power-of-two value between 64 and 4096. Default value is `256`.\n    interleave : str, optional\n        Interleaving. Default value is `pixel`.\n    compress : str, optional\n        Set the compression to use. Default is `lzw`.\n    resampling : rasterio.enums.Resampling\n        Resampling method. Default is `gauss`.\n    kwargs : optional\n        Additional arguments passed to rasterio.Env.\n\n    Returns\n    ---------\n    out: None\n        Original file is altered or external .ovr can be created.\n    \"\"\"\n\n    with rasterio.open(source_file, 'r+') as dst:\n        if factors is None:\n            factors = _calc_overviews_factors(\n                SimpleNamespace(width=dst.width, height=dst.height), minsize)\n\n        with rasterio.Env(\n            GDAL_TIFF_OVR_BLOCKSIZE=blocksize,\n            INTERLEAVE_OVERVIEW=interleave,\n            COMPRESS_OVERVIEW=compress,\n            TIFF_USE_OVR=external,\n            **kwargs\n        ):\n            dst.build_overviews(factors, resampling)", "response": "Builds all of the overviews at one or more decimation factors for all the object tables in the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_vrt(source_file, destination_file, **kwargs):\n    with rasterio.open(source_file) as src:\n        vrt_doc = boundless_vrt_doc(src, **kwargs).tostring()\n\n        with open(destination_file, 'wb') as dst:\n            dst.write(vrt_doc)\n\n    return destination_file", "response": "Builds a VRT XML document from source_file to destination_file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstretch the image histogram.", "response": "def stretch_histogram(img, dark_clip_percentile=None, bright_clip_percentile=None,\n                      dark_clip_value=None, bright_clip_value=None, ignore_zero=True):\n    \"\"\"Stretch img histogram.\n\n    2 possible modes: by percentile (pass dark/bright_clip_percentile), or by value (pass dark/bright_clip_value)\n    :param dark_clip_percentile: percent of pixels that will be saturated to min_value\n    :param bright_clip_percentile: percent of pixels that will be saturated to max_value\n    :param dark_clip_value: all values below this will be saturated to min_value\n    :param bright_clip_value: all values above this will be saturated to max_value\n    :param ignore_zero: if true, pixels with value 0 are ignored in stretch calculation\n    :returns image (same shape as 'img')\n    \"\"\"\n    # verify stretching method is specified:\n    if (dark_clip_percentile is not None and dark_clip_value is not None) or \\\n            (bright_clip_percentile is not None and bright_clip_value is not None):\n        raise KeyError('Provided parameters for both by-percentile and by-value stretch, need only one of those.')\n\n    # the default stretching:\n    if dark_clip_percentile is None and dark_clip_value is None:\n        dark_clip_percentile = 0.001\n    if bright_clip_percentile is None and bright_clip_value is None:\n        bright_clip_percentile = 0.001\n\n    if dark_clip_percentile is not None:\n        dark_clip_value = np.percentile(img[img != 0] if ignore_zero else img, 100 * dark_clip_percentile)\n    if bright_clip_percentile is not None:\n        bright_clip_value = np.percentile(img[img != 0] if ignore_zero else img, 100 * (1 - bright_clip_percentile))\n\n    dst_min = np.iinfo(img.dtype).min\n    dst_max = np.iinfo(img.dtype).max\n\n    if bright_clip_value == dark_clip_value:\n        raise HistogramStretchingError\n    gain = (dst_max - dst_min) / (bright_clip_value - dark_clip_value)\n    offset = -gain * dark_clip_value + dst_min\n\n    stretched = np.empty_like(img, dtype=img.dtype)\n    if len(img.shape) == 2:\n        stretched[:, :] = np.clip(gain * img[:, :].astype(np.float32) + offset, dst_min, dst_max).astype(img.dtype)\n    else:\n        for band in range(img.shape[0]):\n            stretched[band, :, :] = np.clip(gain * img[band, :, :].astype(np.float32) + offset,\n                                            dst_min, dst_max).astype(img.dtype)\n    return stretched"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _distribution_info(self):\n\n        print('Gathering information...')\n        system = platform.system()\n\n        # Cygwin system is CYGWIN-NT-xxx.\n        system = 'cygwin' if 'CYGWIN' in system else system\n\n        processor = platform.processor()\n        machine = '64bit' if sys.maxsize > 2 ** 32 else '32bit'\n\n        print('SYSTEM:   ', system)\n        print('PROCESSOR:', processor)\n        print('MACHINE:  ', machine)\n\n        return self._dists[(system, machine)]", "response": "Creates the name and extension for the best available CSPICE package and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload the CSPICE package from the server.", "response": "def _download(self):\n        \"\"\"Support function that encapsulates the OpenSSL transfer of the CSPICE\n        package to the self._local io.ByteIO stream.\n\n        :raises RuntimeError if there has been any issue with the HTTPS\n                             communication\n\n        .. note::\n\n           Handling of CSPICE downloads from HTTPS\n           ---------------------------------------\n           Some Python distributions may be linked to an old version of OpenSSL\n           which will not let you connect to NAIF server due to recent SSL cert\n           upgrades on the JPL servers.  Moreover, versions older than\n           OpenSSL 1.0.1g are known to contain the 'the Heartbleed Bug'.\n           Therefore this method provides two different implementations for the\n           HTTPS GET call to the NAIF server to download the required CSPICE\n           distribution package.\n        \"\"\"\n        # Use urllib3 (based on PyOpenSSL).\n        if ssl.OPENSSL_VERSION < 'OpenSSL 1.0.1g':\n            # Force urllib3 to use pyOpenSSL\n            import urllib3.contrib.pyopenssl\n            urllib3.contrib.pyopenssl.inject_into_urllib3()\n\n            import certifi\n            import urllib3\n\n            try:\n                # Search proxy in ENV variables\n                proxies = {}\n                for key, value in os.environ.items():\n                    if '_proxy' in key.lower():\n                        proxies[key.lower().replace('_proxy','')] = value\n\n                # Create a ProolManager\n                if 'https' in proxies:\n                    https = urllib3.ProxyManager(proxies['https'],\n                                                cert_reqs='CERT_REQUIRED',\n                                                ca_certs=certifi.where())\n                elif 'http' in proxies:\n                    https = urllib3.ProxyManager(proxies['http'],\n                                                cert_reqs='CERT_REQUIRED',\n                                                ca_certs=certifi.where())\n                else:\n                    https = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',\n                                                ca_certs=certifi.where())\n                # Send the request to get the CSPICE package.\n                response = https.request('GET', self._rcspice,\n                                         timeout=urllib3.Timeout(10))\n            except urllib3.exceptions.HTTPError as err:\n                raise RuntimeError(err.message)\n\n            # Convert the response to io.BytesIO and store it in local memory.\n            self._local = io.BytesIO(response.data)\n\n        # Use the standard urllib (using system OpenSSL).\n        else:\n            try:\n                # Send the request to get the CSPICE package (proxy auto detected).\n                response = urllib.request.urlopen(self._rcspice, timeout=10)\n            except urllib.error.URLError as err:\n                raise RuntimeError(err.reason)\n\n            # Convert the response to io.BytesIO and store it in local memory.\n            self._local = io.BytesIO(response.read())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unpack(self):\n        if self._ext == 'zip':\n            with ZipFile(self._local, 'r') as archive:\n                archive.extractall(self._root)\n        else:\n            cmd = 'gunzip | tar xC ' + self._root\n            proc = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE)\n            proc.stdin.write(self._local.read())\n        self._local.close()", "response": "Unpacks the CSPICE package on the given root directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a segment of a segment is spice - friendly.", "response": "def checkForSpiceError(f):\n    \"\"\"\n    Internal function to check\n    :param f:\n    :raise stypes.SpiceyError:\n    \"\"\"\n    if failed():\n        errorparts = {\n            \"tkvsn\": tkvrsn(\"TOOLKIT\").replace(\"CSPICE_\", \"\"),\n            \"short\": getmsg(\"SHORT\", 26),\n            \"explain\": getmsg(\"EXPLAIN\", 100).strip(),\n            \"long\": getmsg(\"LONG\", 321).strip(),\n            \"traceback\": qcktrc(200)}\n        msg = stypes.errorformat.format(**errorparts)\n        reset()\n        raise stypes.SpiceyError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spiceFoundExceptionThrower(f):\n    @functools.wraps(f)\n    def wrapper(*args, **kwargs):\n        res = f(*args, **kwargs)\n        if config.catch_false_founds:\n            found = res[-1]\n            if isinstance(found, bool) and not found:\n                raise stypes.SpiceyError(\"Spice returns not found for function: {}\".format(f.__name__), found=found)\n            elif hasattr(found, '__iter__') and not all(found):\n                raise stypes.SpiceyError(\"Spice returns not found in a series of calls for function: {}\".format(f.__name__), found=found)\n            else:\n                actualres = res[0:-1]\n                if len(actualres) == 1:\n                    return actualres[0]\n                else:\n                    return actualres\n        else:\n            return res\n\n    return wrapper", "response": "Decorator for wrapping functions that use status codes\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef found_check():\n    current_catch_state = config.catch_false_founds\n    config.catch_false_founds = True\n    yield\n    config.catch_false_founds = current_catch_state", "response": "A context manager that checks if the found flag is set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend an item to a character cell.", "response": "def appndc(item, cell):\n    \"\"\"\n    Append an item to a character cell.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/appndc_c.html\n\n    :param item: The item to append.\n    :type item: str or list\n    :param cell: The cell to append to.\n    :type cell: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cell, stypes.SpiceCell)\n    if isinstance(item, list):\n        for c in item:\n            libspice.appndc_c(stypes.stringToCharP(c), cell)\n    else:\n        item = stypes.stringToCharP(item)\n        libspice.appndc_c(item, cell)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef appndd(item, cell):\n    assert isinstance(cell, stypes.SpiceCell)\n    if hasattr(item, \"__iter__\"):\n        for d in item:\n            libspice.appndd_c(ctypes.c_double(d), cell)\n    else:\n        item = ctypes.c_double(item)\n        libspice.appndd_c(item, cell)", "response": "Append an item to a double precision cell."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef appndi(item, cell):\n    assert isinstance(cell, stypes.SpiceCell)\n    if hasattr(item, \"__iter__\"):\n        for i in item:\n            libspice.appndi_c(ctypes.c_int(i), cell)\n    else:\n        item = ctypes.c_int(item)\n        libspice.appndi_c(item, cell)", "response": "Append an item to an integer cell."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef axisar(axis, angle):\n    axis = stypes.toDoubleVector(axis)\n    angle = ctypes.c_double(angle)\n    r = stypes.emptyDoubleMatrix()\n    libspice.axisar_c(axis, angle, r)\n    return stypes.cMatrixToNumpy(r)", "response": "Construct a rotation matrix that rotates vectors by a specified axis and angle about a specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef badkpv(caller, name, comp, insize, divby, intype):\n    caller = stypes.stringToCharP(caller)\n    name = stypes.stringToCharP(name)\n    comp = stypes.stringToCharP(comp)\n    insize = ctypes.c_int(insize)\n    divby = ctypes.c_int(divby)\n    intype = ctypes.c_char(intype.encode(encoding='UTF-8'))\n    return bool(libspice.badkpv_c(caller, name, comp, insize, divby, intype))", "response": "Determine if a kernel pool variable is present and if so returns true."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bltfrm(frmcls, outCell=None):\n    frmcls = ctypes.c_int(frmcls)\n    if not outCell:\n        outCell = stypes.SPICEINT_CELL(1000)\n    libspice.bltfrm_c(frmcls, outCell)\n    return outCell", "response": "Return a SPICE set containing the frame IDs of all built - in frames of a specified class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating the SPICE integer code of a body into a common name for that body.", "response": "def bodc2n(code, lenout=_default_len_out):\n    \"\"\"\n    Translate the SPICE integer code of a body into a common name\n    for that body.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/bodc2n_c.html\n\n    :param code: Integer ID code to be translated into a name.\n    :type code: int\n    :param lenout: Maximum length of output name.\n    :type lenout: int\n    :return: A common name for the body identified by code.\n    :rtype: str\n    \"\"\"\n    code = ctypes.c_int(code)\n    name = stypes.stringToCharP(\" \" * lenout)\n    lenout = ctypes.c_int(lenout)\n    found = ctypes.c_int()\n    libspice.bodc2n_c(code, lenout, name, ctypes.byref(found))\n    return stypes.toPythonString(name), bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate a body ID code to a string representation of the body ID value.", "response": "def bodc2s(code, lenout=_default_len_out):\n    \"\"\"\n    Translate a body ID code to either the corresponding name or if no\n    name to ID code mapping exists, the string representation of the\n    body ID value.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/bodc2s_c.html\n\n    :param code: Integer ID code to translate to a string.\n    :type code: int\n    :param lenout: Maximum length of output name.\n    :type lenout: int\n    :return: String corresponding to 'code'.\n    :rtype: str\n    \"\"\"\n    code = ctypes.c_int(code)\n    name = stypes.stringToCharP(\" \" * lenout)\n    lenout = ctypes.c_int(lenout)\n    libspice.bodc2s_c(code, lenout, name)\n    return stypes.toPythonString(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef boddef(name, code):\n    name = stypes.stringToCharP(name)\n    code = ctypes.c_int(code)\n    libspice.boddef_c(name, code)", "response": "Define a body name and ID code pair for later translation via Boddef."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bodfnd(body, item):\n    body = ctypes.c_int(body)\n    item = stypes.stringToCharP(item)\n    return bool(libspice.bodfnd_c(body, item))", "response": "Determine whether values exist for some item for any body in the kernel pool."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntranslating the name of a body or object to a SPICE ID code.", "response": "def bodn2c(name):\n    \"\"\"\n    Translate the name of a body or object to the corresponding SPICE\n    integer ID code.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/bodn2c_c.html\n\n    :param name: Body name to be translated into a SPICE ID code.\n    :type name: str\n    :return: SPICE integer ID code for the named body.\n    :rtype: int\n    \"\"\"\n    name = stypes.stringToCharP(name)\n    code = ctypes.c_int(0)\n    found = ctypes.c_int(0)\n    libspice.bodn2c_c(name, ctypes.byref(code), ctypes.byref(found))\n    return code.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bods2c(name):\n    name = stypes.stringToCharP(name)\n    code = ctypes.c_int(0)\n    found = ctypes.c_int(0)\n    libspice.bods2c_c(name, ctypes.byref(code), ctypes.byref(found))\n    return code.value, bool(found.value)", "response": "Translate a string containing a body name or ID code to an integer ID code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the values of some item in a kernel pool.", "response": "def bodvar(body, item, dim):\n    \"\"\"\n    Deprecated: This routine has been superseded by :func:`bodvcd` and\n    :func:`bodvrd`. This routine is supported for purposes of backward\n    compatibility only.\n\n    Return the values of some item for any body in the kernel pool.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/bodvar_c.html\n\n    :param body: ID code of body.\n    :type body: int\n    :param item:\n                Item for which values are desired,\n                (\"RADII\", \"NUT_PREC_ANGLES\", etc.)\n    :type item: str\n    :param dim: Number of values returned.\n    :type dim: int\n    :return: values\n    :rtype: Array of floats\n    \"\"\"\n    body = ctypes.c_int(body)\n    dim = ctypes.c_int(dim)\n    item = stypes.stringToCharP(item)\n    values = stypes.emptyDoubleVector(dim.value)\n    libspice.bodvar_c(body, item, ctypes.byref(dim), values)\n    return stypes.cVectorToPython(values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bodvcd(bodyid, item, maxn):\n    bodyid = ctypes.c_int(bodyid)\n    item = stypes.stringToCharP(item)\n    dim = ctypes.c_int()\n    values = stypes.emptyDoubleVector(maxn)\n    maxn = ctypes.c_int(maxn)\n    libspice.bodvcd_c(bodyid, item, maxn, ctypes.byref(dim), values)\n    return dim.value, stypes.cVectorToPython(values)", "response": "Fetch the double precision values of an item in the kernel pool associated with a body."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bodvrd(bodynm, item, maxn):\n    bodynm = stypes.stringToCharP(bodynm)\n    item = stypes.stringToCharP(item)\n    dim = ctypes.c_int()\n    values = stypes.emptyDoubleVector(maxn)\n    maxn = ctypes.c_int(maxn)\n    libspice.bodvrd_c(bodynm, item, maxn, ctypes.byref(dim), values)\n    return dim.value, stypes.cVectorToPython(values)", "response": "Fetch from the kernel pool the double precision values\n    of an item associated with a body."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef brcktd(number, end1, end2):\n    number = ctypes.c_double(number)\n    end1 = ctypes.c_double(end1)\n    end2 = ctypes.c_double(end2)\n    return libspice.brcktd_c(number, end1, end2)", "response": "This function returns the value within an interval that is enclosed by the number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbracket a number. That is, given a number and an acceptable interval, make sure that the number is contained in the interval. (If the number is already in the interval, leave it alone. If not, set it to the nearest endpoint of the interval.) http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/brckti_c.html :param number: Number to be bracketed. :type number: int :param end1: One of the bracketing endpoints for number. :type end1: int :param end2: The other bracketing endpoint for number. :type end2: int :return: value within an interval :rtype: int", "response": "def brckti(number, end1, end2):\n    \"\"\"\n    Bracket a number. That is, given a number and an acceptable\n    interval, make sure that the number is contained in the\n    interval. (If the number is already in the interval, leave it\n    alone. If not, set it to the nearest endpoint of the interval.)\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/brckti_c.html\n\n    :param number: Number to be bracketed.\n    :type number: int\n    :param end1: One of the bracketing endpoints for number.\n    :type end1: int\n    :param end2: The other bracketing endpoint for number.\n    :type end2: int\n    :return: value within an interval\n    :rtype: int\n    \"\"\"\n    number = ctypes.c_int(number)\n    end1 = ctypes.c_int(end1)\n    end2 = ctypes.c_int(end2)\n    return libspice.brckti_c(number, end1, end2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bschoc(value, ndim, lenvals, array, order):\n    value = stypes.stringToCharP(value)\n    ndim = ctypes.c_int(ndim)\n    lenvals = ctypes.c_int(lenvals)\n    array = stypes.listToCharArrayPtr(array, xLen=lenvals, yLen=ndim)\n    order = stypes.toIntVector(order)\n    return libspice.bschoc_c(value, ndim, lenvals, array, order)", "response": "Do a binary search for a given value within a character string array. Return the index of the first matching entry or - 1 if the key value is not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bschoi(value, ndim, array, order):\n    value = ctypes.c_int(value)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toIntVector(array)\n    order = stypes.toIntVector(order)\n    return libspice.bschoi_c(value, ndim, array, order)", "response": "Do a binary search for a given value within an integer array and return the index of the matching array entry or - 1 if the key value is not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bsrchc(value, ndim, lenvals, array):\n    value = stypes.stringToCharP(value)\n    ndim = ctypes.c_int(ndim)\n    lenvals = ctypes.c_int(lenvals)\n    array = stypes.listToCharArrayPtr(array, xLen=lenvals, yLen=ndim)\n    return libspice.bsrchc_c(value, ndim, lenvals, array)", "response": "Do a binary earch for a given value within a character string array. Return the index of the first matching array entry or - 1 if no matching array entry was found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bsrchd(value, ndim, array):\n    value = ctypes.c_double(value)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toDoubleVector(array)\n    return libspice.bsrchd_c(value, ndim, array)", "response": "Binary search for a key value within a double precision array. Return the index of the matching array entry or - 1 if the key value is not found."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndo a binary search for a key value within an integer array, assumed to be in increasing order. Return the index of the matching array entry, or -1 if the key value is not found. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/bsrchi_c.html :param value: Value to find in array. :type value: int :param ndim: Dimension of array. :type ndim: int :param array: Array to be searched. :type array: Array of ints :return: index :rtype: int", "response": "def bsrchi(value, ndim, array):\n    \"\"\"\n    Do a binary search for a key value within an integer array,\n    assumed to be in increasing order. Return the index of the\n    matching array entry, or -1 if the key value is not found.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/bsrchi_c.html\n\n    :param value: Value to find in array.\n    :type value: int\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param array: Array to be searched.\n    :type array: Array of ints\n    :return: index\n    :rtype: int\n    \"\"\"\n    value = ctypes.c_int(value)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toIntVector(array)\n    return libspice.bsrchi_c(value, ndim, array)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the frame name frame ID and center associated with a given frame class and class ID.", "response": "def ccifrm(frclss, clssid, lenout=_default_len_out):\n    \"\"\"\n    Return the frame name, frame ID, and center associated with\n    a given frame class and class ID.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ccifrm_c.html\n\n    :param frclss: Class of frame.\n    :type frclss: int\n    :param clssid: Class ID of frame.\n    :type clssid: int\n    :param lenout: Maximum length of output string.\n    :type lenout: int\n    :return:\n            the frame name,\n            frame ID,\n            center.\n    :rtype: tuple\n    \"\"\"\n    frclss = ctypes.c_int(frclss)\n    clssid = ctypes.c_int(clssid)\n    lenout = ctypes.c_int(lenout)\n    frcode = ctypes.c_int()\n    frname = stypes.stringToCharP(lenout)\n    center = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.ccifrm_c(frclss, clssid, lenout, ctypes.byref(frcode), frname,\n                      ctypes.byref(center), ctypes.byref(found))\n    return frcode.value, stypes.toPythonString(\n        frname), center.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cgv2el(center, vec1, vec2):\n    center = stypes.toDoubleVector(center)\n    vec1 = stypes.toDoubleVector(vec1)\n    vec2 = stypes.toDoubleVector(vec2)\n    ellipse = stypes.Ellipse()\n    libspice.cgv2el_c(center, vec1, vec2, ctypes.byref(ellipse))\n    return ellipse", "response": "Return an array of 3 - Elements from a center vector and two generating vectors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive the coefficients for the Chebyshev expansion of a polynomial, this returns the value of the polynomial and its first nderiv derivatives evaluated at the input X. https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/chbder_c.html :param cp: degp+1 Chebyshev polynomial coefficients. :type cp: Array of floats :param degp: Degree of polynomial. :type degp: int :param x2s: Transformation parameters of polynomial. :type x2s: Array of floats :param x: Value for which the polynomial is to be evaluated :type x: float :param nderiv: The number of derivatives to compute :type nderiv: int :return: Array of the derivatives of the polynomial :rtype: Array of floats", "response": "def chbder(cp, degp, x2s, x, nderiv):\n    \"\"\"\n    Given the coefficients for the Chebyshev expansion of a\n    polynomial, this returns the value of the polynomial and its\n    first nderiv derivatives evaluated at the input X.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/chbder_c.html\n    \n    :param cp: degp+1 Chebyshev polynomial coefficients.\n    :type cp: Array of floats\n    :param degp: Degree of polynomial.\n    :type degp: int\n    :param x2s: Transformation parameters of polynomial.\n    :type x2s: Array of floats\n    :param x: Value for which the polynomial is to be evaluated\n    :type x: float\n    :param nderiv: The number of derivatives to compute\n    :type nderiv: int\n    :return: Array of the derivatives of the polynomial\n    :rtype: Array of floats\n    \"\"\"\n    cp = stypes.toDoubleVector(cp)\n    degp = ctypes.c_int(degp)\n    x2s = stypes.toDoubleVector(x2s)\n    x = ctypes.c_double(x)\n    partdp = stypes.emptyDoubleVector(3*(nderiv+1))\n    dpdxs = stypes.emptyDoubleVector(nderiv+1)\n    nderiv = ctypes.c_int(nderiv)\n    libspice.chbder_c(cp, degp, x2s, x, nderiv, partdp, dpdxs)\n    return stypes.cVectorToPython(dpdxs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the frame ID code and name associated with a frame center.", "response": "def cidfrm(cent, lenout=_default_len_out):\n    \"\"\"\n    Retrieve frame ID code and name to associate with a frame center.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/cidfrm_c.html\n\n    :param cent: An object to associate a frame with.\n    :type cent: int\n    :param lenout: Available space in output string frname.\n    :type lenout: int\n    :return:\n            frame ID code,\n            name to associate with a frame center.\n    :rtype: tuple\n    \"\"\"\n    cent = ctypes.c_int(cent)\n    lenout = ctypes.c_int(lenout)\n    frcode = ctypes.c_int()\n    frname = stypes.stringToCharP(lenout)\n    found = ctypes.c_int()\n    libspice.cidfrm_c(cent, lenout, ctypes.byref(frcode), frname,\n                      ctypes.byref(found))\n    return frcode.value, stypes.toPythonString(frname), bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ckcov(ck, idcode, needav, level, tol, timsys, cover=None):\n    ck = stypes.stringToCharP(ck)\n    idcode = ctypes.c_int(idcode)\n    needav = ctypes.c_int(needav)\n    level = stypes.stringToCharP(level)\n    tol = ctypes.c_double(tol)\n    timsys = stypes.stringToCharP(timsys)\n    if not cover:\n        cover = stypes.SPICEDOUBLE_CELL(20000)\n    assert isinstance(cover, stypes.SpiceCell)\n    assert cover.dtype == 1\n    libspice.ckcov_c(ck, idcode, needav, level, tol, timsys,\n                     ctypes.byref(cover))\n    return cover", "response": "Find the coverage window for a specified object in a CK file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ckgp(inst, sclkdp, tol, ref):\n    inst = ctypes.c_int(inst)\n    sclkdp = ctypes.c_double(sclkdp)\n    tol = ctypes.c_double(tol)\n    ref = stypes.stringToCharP(ref)\n    cmat = stypes.emptyDoubleMatrix()\n    clkout = ctypes.c_double()\n    found = ctypes.c_int()\n    libspice.ckgp_c(inst, sclkdp, tol, ref, cmat, ctypes.byref(clkout),\n                    ctypes.byref(found))\n    return stypes.cMatrixToNumpy(cmat), clkout.value, bool(found.value)", "response": "Return the C - matrix pointing data for a specified spacecraft clock time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the C - matrix pointing data and angular velocity vector for a specified spacecraft clock time.", "response": "def ckgpav(inst, sclkdp, tol, ref):\n    \"\"\"\n    Get pointing (attitude) and angular velocity\n    for a specified spacecraft clock time.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckgpav_c.html\n\n    :param inst: NAIF ID of instrument, spacecraft, or structure.\n    :type inst: int\n    :param sclkdp: Encoded spacecraft clock time.\n    :type sclkdp: float\n    :param tol: Time tolerance.\n    :type tol: float\n    :param ref: Reference frame.\n    :type ref: str\n    :return:\n            C-matrix pointing data,\n            Angular velocity vector,\n            Output encoded spacecraft clock time.\n    :rtype: tuple\n    \"\"\"\n    inst = ctypes.c_int(inst)\n    sclkdp = ctypes.c_double(sclkdp)\n    tol = ctypes.c_double(tol)\n    ref = stypes.stringToCharP(ref)\n    cmat = stypes.emptyDoubleMatrix()\n    av = stypes.emptyDoubleVector(3)\n    clkout = ctypes.c_double()\n    found = ctypes.c_int()\n    libspice.ckgpav_c(inst, sclkdp, tol, ref, cmat, av, ctypes.byref(clkout),\n                      ctypes.byref(found))\n    return stypes.cMatrixToNumpy(cmat), stypes.cVectorToPython(\n            av), clkout.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a CK pointing file and return its handle.", "response": "def cklpf(filename):\n    \"\"\"\n    Load a CK pointing file for use by the CK readers.  Return that\n    file's handle, to be used by other CK routines to refer to the\n    file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/cklpf_c.html\n\n    :param filename: Name of the CK file to be loaded.\n    :type filename: str\n    :return: Loaded file's handle.\n    :rtype: int\n    \"\"\"\n    filename = stypes.stringToCharP(filename)\n    handle = ctypes.c_int()\n    libspice.cklpf_c(filename, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the set of ID codes of all objects in a CK file.", "response": "def ckobj(ck, outCell=None):\n    \"\"\"\n    Find the set of ID codes of all objects in a specified CK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckobj_c.html\n\n    :param ck: Name of CK file.\n    :type ck: str\n    :param outCell: Optional user provided Spice Int cell.\n    :type outCell: Optional spiceypy.utils.support_types.SpiceCell\n    :return: Set of ID codes of objects in CK file.\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(ck, str)\n    ck = stypes.stringToCharP(ck)\n    if not outCell:\n        outCell = stypes.SPICEINT_CELL(1000)\n    assert isinstance(outCell, stypes.SpiceCell)\n    assert outCell.dtype == 2\n    libspice.ckobj_c(ck, ctypes.byref(outCell))\n    return outCell"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a new CK file and return the handle of the opened CK file.", "response": "def ckopn(filename, ifname, ncomch):\n    \"\"\"\n    Open a new CK file, returning the handle of the opened file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckopn_c.html\n\n    :param filename: The name of the CK file to be opened.\n    :type filename: str\n    :param ifname: The internal filename for the CK.\n    :type ifname: str\n    :param ncomch: The number of characters to reserve for comments.\n    :type ncomch: int\n    :return: The handle of the opened CK file.\n    :rtype: int\n    \"\"\"\n    filename = stypes.stringToCharP(filename)\n    ifname = stypes.stringToCharP(ifname)\n    ncomch = ctypes.c_int(ncomch)\n    handle = ctypes.c_int()\n    libspice.ckopn_c(filename, ifname, ncomch, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ckw01(handle, begtim, endtim, inst, ref, avflag, segid, nrec, sclkdp, quats,\n          avvs):\n    \"\"\"\n    Add a type 1 segment to a C-kernel.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckw01_c.html\n\n    :param handle: Handle of an open CK file.\n    :type handle: int\n    :param begtim: The beginning encoded SCLK of the segment.\n    :type begtim: float\n    :param endtim: The ending encoded SCLK of the segment.\n    :type endtim: float\n    :param inst: The NAIF instrument ID code.\n    :type inst: int\n    :param ref: The reference frame of the segment.\n    :type ref: str\n    :param avflag: True if the segment will contain angular velocity.\n    :type avflag: bool\n    :param segid: Segment identifier.\n    :type segid: str\n    :param nrec: Number of pointing records.\n    :type nrec: int\n    :param sclkdp: Encoded SCLK times.\n    :type sclkdp: Array of floats\n    :param quats: Quaternions representing instrument pointing.\n    :type quats: Nx4-Element Array of floats\n    :param avvs: Angular velocity vectors.\n    :type avvs: Nx3-Element Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    begtim = ctypes.c_double(begtim)\n    endtim = ctypes.c_double(endtim)\n    inst = ctypes.c_int(inst)\n    ref = stypes.stringToCharP(ref)\n    avflag = ctypes.c_int(avflag)\n    segid = stypes.stringToCharP(segid)\n    sclkdp = stypes.toDoubleVector(sclkdp)\n    quats = stypes.toDoubleMatrix(quats)\n    avvs = stypes.toDoubleMatrix(avvs)\n    nrec = ctypes.c_int(nrec)\n    libspice.ckw01_c(handle, begtim, endtim, inst, ref, avflag, segid, nrec,\n                     sclkdp, quats, avvs)", "response": "Add a type 1 segment to a C - kernel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a type 2 segment to a C - kernel.", "response": "def ckw02(handle, begtim, endtim, inst, ref, segid, nrec, start, stop, quats,\n          avvs, rates):\n    \"\"\"\n    Write a type 2 segment to a C-kernel.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckw02_c.html\n\n    :param handle: Handle of an open CK file.\n    :type handle: int\n    :param begtim: The beginning encoded SCLK of the segment.\n    :type begtim: float\n    :param endtim: The ending encoded SCLK of the segment.\n    :type endtim: float\n    :param inst: The NAIF instrument ID code.\n    :type inst: int\n    :param ref: The reference frame of the segment.\n    :type ref: str\n    :param segid: Segment identifier.\n    :type segid: str\n    :param nrec: Number of pointing records.\n    :type nrec: int\n    :param start: Encoded SCLK interval start times.\n    :type start: Array of floats\n    :param stop: Encoded SCLK interval stop times.\n    :type stop: Array of floats\n    :param quats: Quaternions representing instrument pointing.\n    :type quats: Nx4-Element Array of floats\n    :param avvs: Angular velocity vectors.\n    :type avvs: Nx3-Element Array of floats\n    :param rates: Number of seconds per tick for each interval.\n    :type rates: Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    begtim = ctypes.c_double(begtim)\n    endtim = ctypes.c_double(endtim)\n    inst = ctypes.c_int(inst)\n    ref = stypes.stringToCharP(ref)\n    segid = stypes.stringToCharP(segid)\n    start = stypes.toDoubleVector(start)\n    stop = stypes.toDoubleVector(stop)\n    rates = stypes.toDoubleVector(rates)\n    quats = stypes.toDoubleMatrix(quats)\n    avvs = stypes.toDoubleMatrix(avvs)\n    nrec = ctypes.c_int(nrec)\n    libspice.ckw02_c(handle, begtim, endtim, inst, ref, segid, nrec, start,\n                     stop, quats, avvs, rates)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ckw03(handle, begtim, endtim, inst, ref, avflag, segid, nrec, sclkdp, quats,\n          avvs, nints, starts):\n    \"\"\"\n    Add a type 3 segment to a C-kernel.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckw03_c.html\n\n    :param handle: Handle of an open CK file.\n    :type handle: int\n    :param begtim: The beginning encoded SCLK of the segment.\n    :type begtim: float\n    :param endtim: The ending encoded SCLK of the segment.\n    :type endtim: float\n    :param inst: The NAIF instrument ID code.\n    :type inst: int\n    :param ref: The reference frame of the segment.\n    :type ref: str\n    :param avflag: True if the segment will contain angular velocity.\n    :type avflag: bool\n    :param segid: Segment identifier.\n    :type segid: str\n    :param nrec: Number of pointing records.\n    :type nrec: int\n    :param sclkdp: Encoded SCLK times.\n    :type sclkdp: Array of floats\n    :param quats: Quaternions representing instrument pointing.\n    :type quats: Nx4-Element Array of floats\n    :param avvs: Angular velocity vectors.\n    :type avvs: Nx3-Element Array of floats\n    :param nints: Number of intervals.\n    :type nints: int\n    :param starts: Encoded SCLK interval start times.\n    :type starts: Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    begtim = ctypes.c_double(begtim)\n    endtim = ctypes.c_double(endtim)\n    inst = ctypes.c_int(inst)\n    ref = stypes.stringToCharP(ref)\n    avflag = ctypes.c_int(avflag)\n    segid = stypes.stringToCharP(segid)\n    sclkdp = stypes.toDoubleVector(sclkdp)\n    quats = stypes.toDoubleMatrix(quats)\n    avvs = stypes.toDoubleMatrix(avvs)\n    nrec = ctypes.c_int(nrec)\n    starts = stypes.toDoubleVector(starts)\n    nints = ctypes.c_int(nints)\n    libspice.ckw03_c(handle, begtim, endtim, inst, ref, avflag, segid, nrec,\n                     sclkdp, quats, avvs, nints, starts)", "response": "Add a type 3 segment to a C - kernel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ckw05(handle, subtype, degree, begtim, endtim, inst, ref, avflag, segid,\n          sclkdp, packts, rate, nints, starts):\n    \"\"\"\n    Write a type 5 segment to a CK file.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ckw05_c.html\n\n    :param handle: Handle of an open CK file.\n    :type handle: int\n    :param subtype: CK type 5 subtype code. Can be: 0, 1, 2, 3 see naif docs via link above.\n    :type subtype: int\n    :param degree: Degree of interpolating polynomials.\n    :type degree: int\n    :param begtim: The beginning encoded SCLK of the segment.\n    :type begtim: float\n    :param endtim: The ending encoded SCLK of the segment.\n    :type endtim: float\n    :param inst: The NAIF instrument ID code.\n    :type inst: int\n    :param ref: The reference frame of the segment.\n    :type ref: str\n    :param avflag: True if the segment will contain angular velocity.\n    :type avflag: bool\n    :param segid: Segment identifier.\n    :type segid: str\n    :param sclkdp: Encoded SCLK times.\n    :type sclkdp: Array of floats\n    :param packts: Array of packets.\n    :type packts: Some NxM vector of floats\n    :param rate: Nominal SCLK rate in seconds per tick.\n    :type rate: float\n    :param nints: Number of intervals.\n    :type nints: int\n    :param starts: Encoded SCLK interval start times.\n    :type starts: Array of floats\n    \"\"\"\n    handle  = ctypes.c_int(handle)\n    subtype = ctypes.c_int(subtype)\n    degree  = ctypes.c_int(degree)\n    begtim  = ctypes.c_double(begtim)\n    endtim  = ctypes.c_double(endtim)\n    inst    = ctypes.c_int(inst)\n    ref     = stypes.stringToCharP(ref)\n    avflag  = ctypes.c_int(avflag)\n    segid   = stypes.stringToCharP(segid)\n    n       = ctypes.c_int(len(packts))\n    sclkdp  = stypes.toDoubleVector(sclkdp)\n    packts  = stypes.toDoubleMatrix(packts)\n    rate    = ctypes.c_double(rate)\n    nints   = ctypes.c_int(nints)\n    starts  = stypes.toDoubleVector(starts)\n    libspice.ckw05_c(handle, subtype, degree, begtim, endtim, inst, ref, avflag,\n                     segid, n, sclkdp, packts, rate, nints, starts)", "response": "This function writes a type 5 segment to a CK file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncompressing a character string by removing occurrences of more than N consecutive occurrences of a specified character.", "response": "def cmprss(delim, n, instr, lenout=_default_len_out):\n    \"\"\"\n    Compress a character string by removing occurrences of\n    more than N consecutive occurrences of a specified\n    character.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/cmprss_c.html\n\n    :param delim: Delimiter to be compressed.\n    :type delim: str\n    :param n: Maximum consecutive occurrences of delim.\n    :type n: int\n    :param instr: Input string.\n    :type instr: str\n    :param lenout: Optional available space in output string.\n    :type lenout: Optional int\n    :return: Compressed string.\n    :rtype: str\n    \"\"\"\n    delim = ctypes.c_char(delim.encode(encoding='UTF-8'))\n    n = ctypes.c_int(n)\n    instr = stypes.stringToCharP(instr)\n    output = stypes.stringToCharP(lenout)\n    libspice.cmprss_c(delim, n, instr, lenout, output)\n    return stypes.toPythonString(output)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cnmfrm(cname, lenout=_default_len_out):\n    lenout = ctypes.c_int(lenout)\n    frname = stypes.stringToCharP(lenout)\n    cname = stypes.stringToCharP(cname)\n    found = ctypes.c_int()\n    frcode = ctypes.c_int()\n    libspice.cnmfrm_c(cname, lenout, ctypes.byref(frcode), frname,\n                      ctypes.byref(found))\n    return frcode.value, stypes.toPythonString(frname), bool(found.value)", "response": "Retrieve the frame ID code and name associated with an object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef conics(elts, et):\n    elts = stypes.toDoubleVector(elts)\n    et = ctypes.c_double(et)\n    state = stypes.emptyDoubleVector(6)\n    libspice.conics_c(elts, et, state)\n    return stypes.cVectorToPython(state)", "response": "Determine the state of an orbiting body at a specified time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking a measurement X the units associated with X and units to which X should be converted ; return Y the value of the measurement in the output units.", "response": "def convrt(x, inunit, outunit):\n    \"\"\"\n    Take a measurement X, the units associated with\n    X, and units to which X should be converted; return Y\n    the value of the measurement in the output units.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/convrt_c.html\n\n    :param x: Number representing a measurement in some units.\n    :type x: float\n    :param inunit: The units in which x is measured.\n    :type inunit: str\n    :param outunit: Desired units for the measurement.\n    :type outunit: str\n    :return: The measurment in the desired units.\n    :rtype: float\n    \"\"\"\n\t\n    inunit = stypes.stringToCharP(inunit)\n    outunit = stypes.stringToCharP(outunit)\n    y = ctypes.c_double()\n    if hasattr(x, \"__iter__\"):\n        outArray=[]\n        for n in x:\n            libspice.convrt_c(n,inunit,outunit,ctypes.byref(y))\n            outArray.append(y.value)\n        return outArray\n\t\n    x = ctypes.c_double(x)\n    libspice.convrt_c(x, inunit, outunit, ctypes.byref(y))\n    return y.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying the contents of a SpiceCell to another SpiceCell of the same type.", "response": "def copy(cell):\n    \"\"\"\n    Copy the contents of a SpiceCell of any data type to another\n    cell of the same type.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/copy_c.html\n\n    :param cell: Cell to be copied.\n    :type cell: spiceypy.utils.support_types.SpiceCell\n    :return: New cell\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cell, stypes.SpiceCell)\n    # Next line was redundant with [raise NotImpImplementedError] below\n    # assert cell.dtype == 0 or cell.dtype == 1 or cell.dtype == 2\n    if cell.dtype is 0:\n        newcopy = stypes.SPICECHAR_CELL(cell.size, cell.length)\n    elif cell.dtype is 1:\n        newcopy = stypes.SPICEDOUBLE_CELL(cell.size)\n    elif cell.dtype is 2:\n        newcopy = stypes.SPICEINT_CELL(cell.size)\n    else:\n        raise NotImplementedError\n    libspice.copy_c(ctypes.byref(cell), ctypes.byref(newcopy))\n    return newcopy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the index of the first occurrence in a string of a collection of characters starting at a specified location.", "response": "def cpos(string, chars, start):\n    \"\"\"\n    Find the first occurrence in a string of a character belonging\n    to a collection of characters, starting at a specified location,\n    searching forward.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/cpos_c.html\n\n    :param string: Any character string.\n    :type string: str\n    :param chars: A collection of characters.\n    :type chars: str\n    :param start: Position to begin looking for one of chars.\n    :type start: int\n    :return:\n            The index of the first character of str at or\n            following index start that is in the collection chars.\n    :rtype: int\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    chars = stypes.stringToCharP(chars)\n    start = ctypes.c_int(start)\n    return libspice.cpos_c(string, chars, start)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cposr(string, chars, start):\n    string = stypes.stringToCharP(string)\n    chars = stypes.stringToCharP(chars)\n    start = ctypes.c_int(start)\n    return libspice.cposr_c(string, chars, start)", "response": "Return the index of the first occurrence in a string of a collection of characters starting at a specified location."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nindicate whether or not any watched kernel variables that have a specified agent on their notification list have been updated.", "response": "def cvpool(agent):\n    \"\"\"\n    Indicate whether or not any watched kernel variables that have a\n    specified agent on their notification list have been updated.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/cvpool_c.html\n\n    :param agent: Name of the agent to check for notices.\n    :type agent: str\n    :return: True if variables for \"agent\" have been updated.\n    :rtype: bool\n    \"\"\"\n    agent = stypes.stringToCharP(agent)\n    update = ctypes.c_int()\n    libspice.cvpool_c(agent, ctypes.byref(update))\n    return bool(update.value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cyllat(r, lonc, z):\n    r = ctypes.c_double(r)\n    lonc = ctypes.c_double(lonc)\n    z = ctypes.c_double(z)\n    radius = ctypes.c_double()\n    lon = ctypes.c_double()\n    lat = ctypes.c_double()\n    libspice.cyllat_c(r, lonc, z, ctypes.byref(radius), ctypes.byref(lon),\n                      ctypes.byref(lat))\n    return radius.value, lon.value, lat.value", "response": "Convert from cylindrical to latitudinal coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cylrec(r, lon, z):\n    r = ctypes.c_double(r)\n    lon = ctypes.c_double(lon)\n    z = ctypes.c_double(z)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.cylrec_c(r, lon, z, rectan)\n    return stypes.cVectorToPython(rectan)", "response": "Convert from cylindrical to rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts from cylindrical to spherical coordinates.", "response": "def cylsph(r, lonc, z):\n    \"\"\"\n    Convert from cylindrical to spherical coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/cylsph_c.html\n\n    :param r: Rectangular coordinates of the point.\n    :type r: float\n    :param lonc: Angle (radians) of point from XZ plane.\n    :type lonc: float\n    :param z: Height of point above XY plane.\n    :type z: float\n    :return:\n            Distance of point from origin,\n            Polar angle (co-latitude in radians) of point,\n            Azimuthal angle (longitude) of point (radians).\n    :rtype: tuple\n    \"\"\"\n    r = ctypes.c_double(r)\n    lonc = ctypes.c_double(lonc)\n    z = ctypes.c_double(z)\n    radius = ctypes.c_double()\n    colat = ctypes.c_double()\n    lon = ctypes.c_double()\n    libspice.cyllat_c(r, lonc, z, ctypes.byref(radius), ctypes.byref(colat),\n                      ctypes.byref(lon))\n    return radius.value, colat.value, lon.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding comments from a buffer of character strings to the comment area of a binary DAF file.", "response": "def dafac(handle, buffer):\n    \"\"\"\n    Add comments from a buffer of character strings to the comment\n    area of a binary DAF file, appending them to any comments which\n    are already present in the file's comment area.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dafac_c.html\n\n    :param handle: handle of a DAF opened with write access.\n    :type handle: int\n    :param buffer: Buffer of comments to put into the comment area.\n    :type buffer: list[str]\n    \"\"\"\n    handle  = ctypes.c_int(handle)\n    lenvals = ctypes.c_int(len(max(buffer, key=len)) + 1)\n    n       = ctypes.c_int(len(buffer))\n    buffer  = stypes.listToCharArrayPtr(buffer)\n    libspice.dafac_c(handle, n, lenvals, buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dafec(handle, bufsiz, lenout=_default_len_out):\n    handle = ctypes.c_int(handle)\n    buffer = stypes.emptyCharArray(yLen=bufsiz, xLen=lenout)\n    bufsiz = ctypes.c_int(bufsiz)\n    lenout = ctypes.c_int(lenout)\n    n = ctypes.c_int()\n    done = ctypes.c_int()\n    libspice.dafec_c(handle, bufsiz, lenout, ctypes.byref(n),\n                     ctypes.byref(buffer), ctypes.byref(done))\n    return n.value, stypes.cVectorToPython(buffer), bool(done.value)", "response": "Extract comments from the comment area of a binary DAF."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef daffna():\n    found = ctypes.c_int()\n    libspice.daffna_c(ctypes.byref(found))\n    return bool(found.value)", "response": "This function returns True if an array was found in the current DAF."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if an array was found in the current DAF.", "response": "def daffpa():\n    \"\"\"\n    Find the previous (backward) array in the current DAF.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/daffpa_c.html\n\n    :return: True if an array was found.\n    :rtype: bool\n    \"\"\"\n    found = ctypes.c_int()\n    libspice.daffpa_c(ctypes.byref(found))\n    return bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dafgda(handle, begin, end):\n    handle = ctypes.c_int(handle)\n    data = stypes.emptyDoubleVector(abs(end - begin))\n    begin = ctypes.c_int(begin)\n    end = ctypes.c_int(end)\n    libspice.dafgda_c(handle, begin, end, data)\n    return stypes.cVectorToPython(data)", "response": "Read the double precision data bounded by two addresses within a DAF."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning ( get ) the handle of the current DAF currently being searched.", "response": "def dafgh():\n    \"\"\"\n    Return (get) the handle of the DAF currently being searched.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dafgh_c.html\n\n    :return: Handle for current DAF.\n    :rtype: int\n    \"\"\"\n    outvalue = ctypes.c_int()\n    libspice.dafgh_c(ctypes.byref(outvalue))\n    return outvalue.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn ( get ) the name of the current array in the current DAF.", "response": "def dafgn(lenout=_default_len_out):\n    \"\"\"\n    Return (get) the name for the current array in the current DAF.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dafgn_c.html\n\n    :param lenout: Length of array name string.\n    :type lenout: int\n    :return: Name of current array.\n    :rtype: str\n    \"\"\"\n    lenout = ctypes.c_int(lenout)\n    name = stypes.stringToCharP(lenout)\n    libspice.dafgn_c(lenout, name)\n    return stypes.toPythonString(name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the summary for the current array in the current DAF.", "response": "def dafgs(n=125):\n    # The 125 may be a hard set,\n    # I got strange errors that occasionally happened without it\n    \"\"\"\n    Return (get) the summary for the current array in the current DAF.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dafgs_c.html\n\n    :param n: Optional length N for result Array.\n    :return: Summary for current array.\n    :rtype: Array of floats\n    \"\"\"\n    retarray = stypes.emptyDoubleVector(125)\n    # libspice.dafgs_c(ctypes.cast(retarray, ctypes.POINTER(ctypes.c_double)))\n    libspice.dafgs_c(retarray)\n    return stypes.cVectorToPython(retarray)[0:n]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dafgsr(handle, recno, begin, end):\n    handle = ctypes.c_int(handle)\n    recno = ctypes.c_int(recno)\n    begin = ctypes.c_int(begin)\n    end = ctypes.c_int(end)\n    # dafgsr_c will retrieve no more than 128 words\n    data = stypes.emptyDoubleVector(1 + min([128,end.value]) - max([begin.value,1]))\n    found = ctypes.c_int()\n    libspice.dafgsr_c(handle, recno, begin, end, data, ctypes.byref(found))\n    return stypes.cVectorToPython(data), bool(found.value)", "response": "Read a portion of the contents of a summary record in a DAF file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dafopr(fname):\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int()\n    libspice.dafopr_c(fname, ctypes.byref(handle))\n    return handle.value", "response": "Open a DAF for subsequent read requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dafopw(fname):\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int()\n    libspice.dafopw_c(fname, ctypes.byref(handle))\n    return handle.value", "response": "Open a DAF for subsequent write requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dafps(nd, ni, dc, ic):\n    dc = stypes.toDoubleVector(dc)\n    ic = stypes.toIntVector(ic)\n    outsum = stypes.emptyDoubleVector(nd + ni)\n    nd = ctypes.c_int(nd)\n    ni = ctypes.c_int(ni)\n    libspice.dafps_c(nd, ni, dc, ic, outsum)\n    return stypes.cVectorToPython(outsum)", "response": "Pack a double precision and integer components into a single array of floats."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the double precision data bounded by two addresses within a DAF.", "response": "def dafrda(handle, begin, end):\n    \"\"\"\n    Read the double precision data bounded by two addresses within a DAF.\n\n    Deprecated: This routine has been superseded by :func:`dafgda` and\n    :func:`dafgsr`.  This routine is supported for purposes of backward\n    compatibility only.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dafrda_c.html\n\n    :param handle: Handle of a DAF.\n    :type handle: int\n    :param begin: Initial address within file.\n    :type begin: int\n    :param end: Final address within file.\n    :type end: int\n    :return: Data contained between begin and end.\n    :rtype: Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    begin = ctypes.c_int(begin)\n    end = ctypes.c_int(end)\n    data = stypes.emptyDoubleVector(1 + end.value - begin.value)\n    libspice.dafrda_c(handle, begin, end, data)\n    return stypes.cVectorToPython(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dafrfr(handle, lenout=_default_len_out):\n    handle = ctypes.c_int(handle)\n    lenout = ctypes.c_int(lenout)\n    nd = ctypes.c_int()\n    ni = ctypes.c_int()\n    ifname = stypes.stringToCharP(lenout)\n    fward = ctypes.c_int()\n    bward = ctypes.c_int()\n    free = ctypes.c_int()\n    libspice.dafrfr_c(handle, lenout, ctypes.byref(nd), ctypes.byref(ni),\n                      ifname, ctypes.byref(fward), ctypes.byref(bward),\n                      ctypes.byref(free))\n    return nd.value, ni.value, stypes.toPythonString(\n            ifname), fward.value, bward.value, free.value", "response": "Read the contents of a DAF file record."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the summary for the current array in the current DAF.", "response": "def dafrs(insum):\n    \"\"\"\n    Change the summary for the current array in the current DAF.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dafrs_c.html\n\n    :param insum: New summary for current array.\n    :type insum: Array of floats\n    \"\"\"\n    insum = stypes.toDoubleVector(insum)\n    libspice.dafrs_c(ctypes.byref(insum))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dafus(insum, nd, ni):\n    insum = stypes.toDoubleVector(insum)\n    dc = stypes.emptyDoubleVector(nd)\n    ic = stypes.emptyIntVector(ni)\n    nd = ctypes.c_int(nd)\n    ni = ctypes.c_int(ni)\n    libspice.dafus_c(insum, nd, ni, dc, ic)\n    return stypes.cVectorToPython(dc), stypes.cVectorToPython(ic)", "response": "Unpack an array summary into its double precision and integer components."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd comments from a buffer of character strings to the comment area of a binary DAS file.", "response": "def dasac(handle, buffer):\n    \"\"\"\n    Add comments from a buffer of character strings to the comment\n    area of a binary DAS file, appending them to any comments which\n    are already present in the file's comment area.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dasac_c.html\n\n    :param handle: DAS handle of a file opened with write access.\n    :type handle: int\n    :param buffer: Buffer of lines to be put into the comment area.\n    :type buffer: Array of strs\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    n = ctypes.c_int(len(buffer))\n    buflen = ctypes.c_int(max(len(s) for s in buffer) + 1)\n    buffer = stypes.listToCharArrayPtr(buffer)\n    libspice.dasac_c(handle, n, buflen, buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract comments from the comment area of a binary DAS file.", "response": "def dasec(handle, bufsiz=_default_len_out, buflen=_default_len_out):\n    \"\"\"\n    Extract comments from the comment area of a binary DAS file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dasec_c.html\n\n    :param handle: Handle of binary DAS file open with read access.\n    :type handle: int\n    :param bufsiz: Maximum size, in lines, of buffer.\n    :type bufsiz: int\n    :param buflen: Line length associated with buffer.\n    :type buflen: int\n    :return:\n            Number of comments extracted from the DAS file,\n            Buffer in which extracted comments are placed,\n            Indicates whether all comments have been extracted.\n    :rtype: tuple\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    buffer = stypes.emptyCharArray(buflen, bufsiz)\n    bufsiz = ctypes.c_int(bufsiz)\n    buflen = ctypes.c_int(buflen)\n    n = ctypes.c_int(0)\n    done = ctypes.c_int()\n    libspice.dasec_c(handle, bufsiz, buflen, ctypes.byref(n),\n                     ctypes.byref(buffer), ctypes.byref(done))\n    return n.value, stypes.cVectorToPython(buffer), done.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dashfn(handle, lenout=_default_len_out):\n    handle = ctypes.c_int(handle)\n    namlen = ctypes.c_int(lenout)\n    fname  = stypes.stringToCharP(lenout)\n    libspice.dashfn_c(handle, namlen, fname)\n    return stypes.toPythonString(fname)", "response": "Return the name of the DAS file associated with a handle."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dasonw(fname, ftype, ifname, ncomch):\n    fnamelen = ctypes.c_int(len(fname))\n    ftypelen = ctypes.c_int(len(ftype))\n    ifnamelen = ctypes.c_int(len(ifname))\n    ncomch  = ctypes.c_int(ncomch)\n    handle  = ctypes.c_int()\n    fname   = stypes.stringToCharP(fname)\n    ftype   = stypes.stringToCharP(ftype)\n    ifname  = stypes.stringToCharP(ifname)\n    libspice.dasonw_(fname, ftype, ifname, ctypes.byref(ncomch), ctypes.byref(handle), fnamelen, ftypelen, ifnamelen)\n    return handle.value", "response": "Create a new DAS file containing the specified file type and number of comment areas."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening a DAS file for reading.", "response": "def dasopr(fname):\n    \"\"\"\n    Open a DAS file for reading.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dasopr_c.html\n\n    :param fname: Name of a DAS file to be opened.\n    :type fname: str\n    :return: Handle assigned to the opened DAS file.\n    :rtype: int\n    \"\"\"\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int()\n    libspice.dasopr_c(fname, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a DAS file for writing.", "response": "def dasopw(fname):\n    \"\"\"\n    Open a DAS file for writing.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dasopw_c.html\n    :param fname: Name of a DAS file to be opened. \n    :type fname: str\n    :return: Handle assigned to the opened DAS file.\n    \"\"\"\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int(0)\n    libspice.dasopw_c(fname, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dasrfr(handle, lenout=_default_len_out):\n    handle = ctypes.c_int(handle)\n    idwlen = ctypes.c_int(lenout) # intentional\n    ifnlen = ctypes.c_int(lenout) # intentional\n    idword = stypes.stringToCharP(lenout)\n    ifname = stypes.stringToCharP(lenout)\n    nresvr = ctypes.c_int(0)\n    nresvc = ctypes.c_int(0)\n    ncomr  = ctypes.c_int(0)\n    ncomc  = ctypes.c_int(0)\n    libspice.dasrfr_c(handle, idwlen, ifnlen, idword, ifname,\n                      ctypes.byref(nresvr), ctypes.byref(nresvc),\n                      ctypes.byref(ncomr), ctypes.byref(ncomc))\n    return stypes.toPythonString(idword), stypes.toPythonString(ifname), nresvr.value, nresvc.value, ncomr.value, ncomc.value", "response": "Return the contents of the specified DAS file record."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dcyldr(x, y, z):\n    x = ctypes.c_double(x)\n    y = ctypes.c_double(y)\n    z = ctypes.c_double(z)\n    jacobi = stypes.emptyDoubleMatrix()\n    libspice.dcyldr_c(x, y, z, jacobi)\n    return stypes.cMatrixToNumpy(jacobi)", "response": "This routine computes the Jacobian of the transformation from rectangular to cylindrical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the value of Delta ET ( ET - UTC at an input epoch.", "response": "def deltet(epoch, eptype):\n    \"\"\"\n    Return the value of Delta ET (ET-UTC) for an input epoch.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/deltet_c.html\n\n    :param epoch: Input epoch (seconds past J2000).\n    :type epoch: float\n    :param eptype: Type of input epoch (\"UTC\" or \"ET\").\n    :type eptype: str\n    :return: Delta ET (ET-UTC) at input epoch.\n    :rtype: float\n    \"\"\"\n    epoch = ctypes.c_double(epoch)\n    eptype = stypes.stringToCharP(eptype)\n    delta = ctypes.c_double()\n    libspice.deltet_c(epoch, eptype, ctypes.byref(delta))\n    return delta.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diags2(symmat):\n    symmat = stypes.toDoubleMatrix(symmat)\n    diag = stypes.emptyDoubleMatrix(x=2, y=2)\n    rotateout = stypes.emptyDoubleMatrix(x=2, y=2)\n    libspice.diags2_c(symmat, diag, rotateout)\n    return stypes.cMatrixToNumpy(diag), stypes.cMatrixToNumpy(rotateout)", "response": "Diagonalize a symmetric 2x2 matrix and return a diagonal matrix similar to symmat and a rotation used as the similarity transformation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the descriptor of the last segment in a DLA file.", "response": "def dlabbs(handle):\n    \"\"\"\n    Begin a backward segment search in a DLA file.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dlabbs_c.html\n    \n    :param handle: Handle of open DLA file.\n    :type handle: int\n    :return: Descriptor of last segment in DLA file\n    :rtype: spiceypy.utils.support_types.SpiceDLADescr\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    descr  = stypes.SpiceDLADescr()\n    found  = ctypes.c_int()\n    libspice.dlabbs_c(handle, ctypes.byref(descr), ctypes.byref(found))\n    return descr, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dlabfs(handle):\n    handle = ctypes.c_int(handle)\n    descr  = stypes.SpiceDLADescr()\n    found  = ctypes.c_int()\n    libspice.dlabfs_c(handle, ctypes.byref(descr), ctypes.byref(found))\n    return descr, bool(found.value)", "response": "This function returns the descriptor of the next segment in a DLA file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dlafns(handle, descr):\n    assert isinstance(descr, stypes.SpiceDLADescr)\n    handle = ctypes.c_int(handle)\n    nxtdsc = stypes.SpiceDLADescr()\n    found  = ctypes.c_int()\n    libspice.dlafns_c(handle, ctypes.byref(descr), ctypes.byref(nxtdsc), ctypes.byref(found))\n    return nxtdsc, bool(found.value)", "response": "Find the next segment following a specified segment in a DLA file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the segment preceding a specified segment in a DLA file.", "response": "def dlafps(handle, descr):\n    \"\"\"\n    Find the segment preceding a specified segment in a DLA file.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dlafps_c.html\n    \n    :param handle: Handle of open DLA file.\n    :type handle: c_int\n    :param descr: Descriptor of a segment in DLA file. \n    :type descr: spiceypy.utils.support_types.SpiceDLADescr\n    :return: Descriptor of previous segment in DLA file\n    :rtype: spiceypy.utils.support_types.SpiceDLADescr\n    \"\"\"\n    assert isinstance(descr, stypes.SpiceDLADescr)\n    handle = ctypes.c_int(handle)\n    prvdsc = stypes.SpiceDLADescr()\n    found = ctypes.c_int()\n    libspice.dlafps_c(handle, ctypes.byref(descr), ctypes.byref(prvdsc),\n                      ctypes.byref(found))\n    return prvdsc, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a double precision number to an equivalent character string using base 16 scientific notation.", "response": "def dp2hx(number, lenout=_default_len_out):\n    \"\"\"\n    Convert a double precision number to an equivalent character\n    string using base 16 \"scientific notation.\"\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dp2hx_c.html\n\n    :param number: D.p. number to be converted.\n    :type number: float\n    :param lenout: Available space for output string.\n    :type lenout: int\n    :return: Equivalent character string, left justified.\n    :rtype: str\n    \"\"\"\n    number = ctypes.c_double(number)\n    lenout = ctypes.c_int(lenout)\n    string = stypes.stringToCharP(lenout)\n    length = ctypes.c_int()\n    libspice.dp2hx_c(number, lenout, string, ctypes.byref(length))\n    return stypes.toPythonString(string)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dpgrdr(body, x, y, z, re, f):\n    body = stypes.stringToCharP(body)\n    x = ctypes.c_double(x)\n    y = ctypes.c_double(y)\n    z = ctypes.c_double(z)\n    re = ctypes.c_double(re)\n    f = ctypes.c_double(f)\n    jacobi = stypes.emptyDoubleMatrix()\n    libspice.dpgrdr_c(body, x, y, z, re, f, jacobi)\n    return stypes.cMatrixToNumpy(jacobi)", "response": "This routine computes the Jacobian matrix of the transformation from rectangular to planetographic coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef drdcyl(r, lon, z):\n    r = ctypes.c_double(r)\n    lon = ctypes.c_double(lon)\n    z = ctypes.c_double(z)\n    jacobi = stypes.emptyDoubleMatrix()\n    libspice.drdcyl_c(r, lon, z, jacobi)\n    return stypes.cMatrixToNumpy(jacobi)", "response": "This routine computes the Jacobian of the transformation from a cylindrical to rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef drdgeo(lon, lat, alt, re, f):\n    lon = ctypes.c_double(lon)\n    lat = ctypes.c_double(lat)\n    alt = ctypes.c_double(alt)\n    re = ctypes.c_double(re)\n    f = ctypes.c_double(f)\n    jacobi = stypes.emptyDoubleMatrix()\n    libspice.drdgeo_c(lon, lat, alt, re, f, jacobi)\n    return stypes.cMatrixToNumpy(jacobi)", "response": "This routine computes the Jacobian of the transformation from a geodetic point to rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef drdlat(r, lon, lat):\n    r = ctypes.c_double(r)\n    lon = ctypes.c_double(lon)\n    lat = ctypes.c_double(lat)\n    jacobi = stypes.emptyDoubleMatrix()\n    libspice.drdlat_c(r, lon, lat, jacobi)\n    return stypes.cMatrixToNumpy(jacobi)", "response": "Compute the Jacobian of the transformation from latitudinal to\n    rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dskb02(handle, dladsc):\n\n    handle = ctypes.c_int(handle)\n    nv = ctypes.c_int(0)\n    np = ctypes.c_int(0)\n    nvxtot = ctypes.c_int(0)\n    vtxbds = stypes.emptyDoubleMatrix(3, 2)\n    voxsiz = ctypes.c_double(0.0)\n    voxori = stypes.emptyDoubleVector(3)\n    vgrext = stypes.emptyIntVector(3)\n    cgscal = ctypes.c_int(0)\n    vtxnpl = ctypes.c_int(0)\n    voxnpt = ctypes.c_int(0)\n    voxnpl = ctypes.c_int(0)\n    libspice.dskb02_c(handle, dladsc, ctypes.byref(nv), ctypes.byref(np), ctypes.byref(nvxtot), vtxbds, ctypes.byref(voxsiz), voxori, vgrext, ctypes.byref(cgscal), ctypes.byref(vtxnpl), ctypes.byref(voxnpt), ctypes.byref(voxnpl))\n    return nv.value, np.value, nvxtot.value, stypes.cMatrixToNumpy(vtxbds), voxsiz.value, stypes.cVectorToPython(voxori), stypes.cVectorToPython(vgrext), cgscal.value, vtxnpl.value, voxnpt.value, voxnpl.value", "response": "Return the bookkeeping data from a DSK type 2 segment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing a DSK file and segregate it.", "response": "def dskcls(handle, optmiz=False):\n    \"\"\"\n    Close a DSK file. \n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskcls_c.html\n    \n    :param handle: Handle assigned to the opened DSK file.\n    :type handle: int\n    :param optmiz: Flag indicating whether to segregate the DSK.\n    :type optmiz: bool\n    :return: \n    \"\"\"\n    handle = ctypes.c_int(handle)\n    optmiz = ctypes.c_int(optmiz)\n    libspice.dskcls_c(handle, optmiz)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching double precision data from a type 2 DSK segment.", "response": "def dskd02(handle,dladsc,item,start,room):\n    \"\"\"\n    Fetch double precision data from a type 2 DSK segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskd02_c.html\n\n    :param handle: DSK file handle\n    :type handle: int\n    :param dladsc: DLA descriptor\n    :type dladsc: spiceypy.utils.support_types.SpiceDLADescr\n    :param item: Keyword identifying item to fetch\n    :type item: int\n    :param start: Start index\n    :type start: int\n    :param room: Amount of room in output array\n    :type room: int\n    :return: Array containing requested item\n    :rtype: numpy.ndarray\n    \"\"\"\n\n    handle = ctypes.c_int(handle)\n    item   = ctypes.c_int(item)\n    start  = ctypes.c_int(start)\n    room   = ctypes.c_int(room)\n    n      = ctypes.c_int(0)\n    values = stypes.emptyDoubleVector(room)\n    libspice.dskd02_c(handle, dladsc, item, start, room, ctypes.byref(n), values)\n    return stypes.cVectorToPython(values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dskgd(handle, dladsc):\n    handle = ctypes.c_int(handle)\n    dskdsc = stypes.SpiceDSKDescr()\n    libspice.dskgd_c(handle, ctypes.byref(dladsc), ctypes.byref(dskdsc))\n    return dskdsc", "response": "Return the DSK descriptor from a DSK segment identified by a DAS handle and DLA descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dskgtl(keywrd):\n    keywrd = ctypes.c_int(keywrd)\n    dpval  = ctypes.c_double(0)\n    libspice.dskgtl_c(keywrd, ctypes.byref(dpval))\n    return dpval.value", "response": "Get the value of a specified DSK tolerance or margin parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching integer data from a type 2 DSK segment.", "response": "def dski02(handle, dladsc, item, start, room):\n    \"\"\"\n    Fetch integer data from a type 2 DSK segment.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dski02_c.html\n\n    :param handle: DSK file handle.\n    :type handle: int\n    :param dladsc: DLA descriptor.\n    :type dladsc: spiceypy.utils.support_types.SpiceDLADescr\n    :param item: Keyword identifying item to fetch.\n    :type item: int\n    :param start: Start index.\n    :type start: int\n    :param room: Amount of room in output array.\n    :type room: int\n    :return: Array containing requested item.\n    :rtype: array\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    item = ctypes.c_int(item)\n    start = ctypes.c_int(start)\n    room = ctypes.c_int(room)\n    n = ctypes.c_int()\n    values = stypes.emptyIntVector(room)\n    libspice.dski02_c(handle, dladsc, item, start, room, ctypes.byref(n), values)\n    return stypes.cMatrixToNumpy(values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dskmi2(vrtces, plates, finscl, corscl, worksz, voxpsz, voxlsz, makvtl, spxisz):\n    nv     = ctypes.c_int(len(vrtces))\n    vrtces = stypes.toDoubleMatrix(vrtces)\n    np     = ctypes.c_int(len(plates))\n    plates = stypes.toIntMatrix(plates)\n    finscl = ctypes.c_double(finscl)\n    corscl = ctypes.c_int(corscl)\n    worksz = ctypes.c_int(worksz)\n    voxpsz = ctypes.c_int(voxpsz)\n    voxlsz = ctypes.c_int(voxlsz)\n    makvtl = ctypes.c_int(makvtl)\n    spxisz = ctypes.c_int(spxisz)\n    work   = stypes.emptyIntMatrix(2, worksz)\n    spaixd = stypes.emptyDoubleVector(10) # SPICE_DSK02_SPADSZ\n    spaixi = stypes.emptyIntVector(spxisz)\n    libspice.dskmi2_c(nv, vrtces, np, plates, finscl, corscl, worksz, voxpsz, voxlsz, makvtl, spxisz, work, spaixd, spaixi)\n    return stypes.cVectorToPython(spaixd), stypes.cVectorToPython(spaixi)", "response": "This routine creates a spatial index for a DSK type 2 segment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dskn02(handle, dladsc, plid):\n    handle = ctypes.c_int(handle)\n    plid   = ctypes.c_int(plid)\n    normal = stypes.emptyDoubleVector(3)\n    libspice.dskn02_c(handle, dladsc, plid, normal)\n    return stypes.cVectorToPython(normal)", "response": "Compute the unit normal vector for a specified plate from a type\n    2 DSK segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dskobj(dsk):\n    dsk = stypes.stringToCharP(dsk)\n    bodids = stypes.SPICEINT_CELL(10000)\n    libspice.dskobj_c(dsk, ctypes.byref(bodids))\n    return bodids", "response": "Return the set of body ID codes of all objects in a specified DSK file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dskopn(fname, ifname, ncomch):\n    fname = stypes.stringToCharP(fname)\n    ifname = stypes.stringToCharP(ifname)\n    ncomch = ctypes.c_int(ncomch)\n    handle = ctypes.c_int()\n    libspice.dskopn_c(fname, ifname, ncomch, ctypes.byref(handle))\n    return handle.value", "response": "Open a new DSK file for subsequent write operations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dskp02(handle, dladsc, start, room):\n    handle = ctypes.c_int(handle)\n    start  = ctypes.c_int(start)\n    room   = ctypes.c_int(room)\n    n      = ctypes.c_int(0)\n    plates = stypes.emptyIntMatrix(3, room)\n    libspice.dskp02_c(handle, dladsc, start, room, ctypes.byref(n), plates)\n    return stypes.cMatrixToNumpy(plates)", "response": "Fetch triangular plates from a type 2 DSK segment."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the lower and upper bounds of a set of triangular plates to .", "response": "def dskrb2(vrtces, plates, corsys, corpar):\n    \"\"\"\n    Determine range bounds for a set of triangular plates to\n    be stored in a type 2 DSK segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskrb2_c.html\n\n    :param vrtces: Vertices\n    :type vrtces: NxM-Element Array of floats\n    :param plates: Plates\n    :type plates: NxM-Element Array of ints\n    :param corsys: DSK coordinate system code\n    :type corsys: int\n    :param corpar: DSK coordinate system parameters\n    :type corpar: N-Element Array of floats\n    :return: Lower and Upper bound on range of third coordinate\n    :rtype: tuple\n    \"\"\"\n    nv     = ctypes.c_int(len(vrtces))\n    vrtces = stypes.toDoubleMatrix(vrtces)\n    np     = ctypes.c_int(len(plates))\n    plates = stypes.toIntMatrix(plates)\n    corsys = ctypes.c_int(corsys)\n    corpar = stypes.toDoubleVector(corpar)\n    mncor3 = ctypes.c_double(0.0)\n    mxcor3 = ctypes.c_double(0.0)\n    libspice.dskrb2_c(nv, vrtces, np, plates, corsys, corpar, ctypes.byref(mncor3), ctypes.byref(mxcor3))\n\n    return mncor3.value, mxcor3.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dsksrf(dsk, bodyid):\n    dsk    = stypes.stringToCharP(dsk)\n    bodyid = ctypes.c_int(bodyid)\n    srfids = stypes.SPICEINT_CELL(10000)\n    libspice.dsksrf_c(dsk, bodyid, ctypes.byref(srfids))\n    return srfids", "response": "Find the set of surface ID codes associated with a given body in a DSK file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dskstl(keywrd, dpval):\n    keywrd = ctypes.c_int(keywrd)\n    dpval = ctypes.c_double(dpval)\n    libspice.dskstl_c(keywrd, dpval)", "response": "Set the value of a specified DSK tolerance or margin parameter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching vertices from a type 2 DSK segment.", "response": "def dskv02(handle, dladsc, start, room):\n    \"\"\"\n    Fetch vertices from a type 2 DSK segment.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskv02_c.html\n\n    :param handle: DSK file handle.\n    :type handle: int\n    :param dladsc: DLA descriptor.\n    :type dladsc: spiceypy.utils.support_types.SpiceDLADescr\n    :param start: Start index.\n    :type start: int\n    :param room: Amount of room in output array.\n    :type room: int\n    :return: Array containing vertices.\n    :rtype: Room x 3-Element Array of floats\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    start  = ctypes.c_int(start)\n    room   = ctypes.c_int(room)\n    n      = ctypes.c_int()\n    vrtces = stypes.emptyDoubleMatrix(3, room)\n    libspice.dskv02_c(handle, dladsc, start, room, ctypes.byref(n), vrtces)\n    return stypes.cMatrixToNumpy(vrtces)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dskw02(handle, center, surfid, dclass, fname, corsys, corpar, mncor1,\n           mxcor1, mncor2, mxcor2, mncor3, mxcor3, first, last, vrtces,\n           plates, spaixd, spaixi):\n    \"\"\"\n    Write a type 2 segment to a DSK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskw02_c.html\n\n    :param handle: Handle assigned to the opened DSK file\n    :type handle: int\n    :param center: Central body ID code\n    :type center: int\n    :param surfid: Surface ID code\n    :type surfid: int\n    :param dclass: Data class\n    :type dclass: int\n    :param fname: Reference frame\n    :type fname: str\n    :param corsys: Coordinate system code\n    :type corsys: int\n    :param corpar: Coordinate system parameters\n    :type corpar: N-Element Array of floats\n    :param mncor1: Minimum value of first coordinate\n    :type mncor1: float\n    :param mxcor1: Maximum value of first coordinate\n    :type mxcor1: float\n    :param mncor2: Minimum value of second coordinate\n    :type mncor2: float\n    :param mxcor2: Maximum value of second coordinate\n    :type mxcor2: float\n    :param mncor3: Minimum value of third coordinate\n    :type mncor3: float\n    :param mxcor3: Maximum value of third coordinate\n    :type mxcor3: float\n    :param first: Coverage start time\n    :type first: float\n    :param last: Coverage stop time\n    :type last: float\n    :param vrtces: Vertices\n    :type vrtces: NxM-Element Array of floats\n    :param plates: Plates\n    :type plates: NxM-Element Array of ints\n    :param spaixd: Double precision component of spatial index\n    :type spaixd: N-Element Array of floats\n    :param spaixi: Integer component of spatial index\n    :type spaixi: N-Element Array of ints\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    center = ctypes.c_int(center)\n    surfid = ctypes.c_int(surfid)\n    dclass = ctypes.c_int(dclass)\n    fname  = stypes.stringToCharP(fname)\n    corsys = ctypes.c_int(corsys)\n    corpar = stypes.toDoubleVector(corpar)\n    mncor1 = ctypes.c_double(mncor1)\n    mxcor1 = ctypes.c_double(mxcor1)\n    mncor2 = ctypes.c_double(mncor2)\n    mxcor2 = ctypes.c_double(mxcor2)\n    mncor3 = ctypes.c_double(mncor3)\n    mxcor3 = ctypes.c_double(mxcor3)\n    first  = ctypes.c_double(first)\n    last   = ctypes.c_double(last)\n    nv     = ctypes.c_int(len(vrtces))\n    vrtces = stypes.toDoubleMatrix(vrtces)\n    np     = ctypes.c_int(len(plates))\n    plates = stypes.toIntMatrix(plates)\n    spaixd = stypes.toDoubleVector(spaixd)\n    spaixi = stypes.toIntVector(spaixi)\n    libspice.dskw02_c(handle, center, surfid, dclass, fname, corsys, corpar,\n                      mncor1, mxcor1, mncor2, mxcor2, mncor3, mxcor3, first,\n                      last, nv, vrtces, np, plates, spaixd, spaixi)", "response": "Write a type 2 segment to a DSK file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dskx02(handle, dladsc, vertex, raydir):\n    handle = ctypes.c_int(handle)\n    vertex = stypes.toDoubleVector(vertex)\n    raydir = stypes.toDoubleVector(raydir)\n    plid   = ctypes.c_int()\n    xpt    = stypes.emptyDoubleVector(3)\n    found  = ctypes.c_int()\n    libspice.dskx02_c(handle, ctypes.byref(dladsc), vertex, raydir, ctypes.byref(plid), xpt, ctypes.byref(found))\n    return plid.value, stypes.cVectorToPython(xpt), bool(found.value)", "response": "Determine the plate ID and body - fixed coordinates of the intersection of a specified ray with the DSK kernel containing the given segment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a ray - surface intercept using data provided by the kernel segment contributing surface data.", "response": "def dskxsi(pri, target, srflst, et, fixref, vertex, raydir):\n    \"\"\"\n    Compute a ray-surface intercept using data provided by\n    multiple loaded DSK segments. Return information about\n    the source of the data defining the surface on which the\n    intercept was found: DSK handle, DLA and DSK descriptors,\n    and DSK data type-dependent parameters.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskxsi_c.html\n\n    :param pri: Data prioritization flag.\n    :type pri: bool\n    :param target: Target body name.\n    :type target: str\n    :param srflst: Surface ID list.\n    :type srflst: list of int\n    :param et: Epoch, expressed as seconds past J2000 TDB.\n    :type et: float\n    :param fixref: Name of target body-fixed reference frame.\n    :type fixref: str\n    :param vertex: Vertex of ray.\n    :type vertex: 3-Element Array of floats\n    :param raydir: Direction vector of ray.\n    :type raydir: 3-Element Array of floats\n    :return: Intercept point, Handle of segment contributing surface data, DLADSC, DSKDSC, Double precision component of source info, Integer component of source info\n    :rtype: tuple\n    \"\"\"\n    pri = ctypes.c_int(pri)\n    target = stypes.stringToCharP(target)\n    nsurf = ctypes.c_int(len(srflst))\n    srflst = stypes.toIntVector(srflst)\n    et = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    vertex = stypes.toDoubleVector(vertex)\n    raydir = stypes.toDoubleVector(raydir)\n    maxd = ctypes.c_int(1)\n    maxi = ctypes.c_int(1)\n    xpt  = stypes.emptyDoubleVector(3)\n    handle = ctypes.c_int(0)\n    dladsc = stypes.SpiceDLADescr()\n    dskdsc = stypes.SpiceDSKDescr()\n    dc     = stypes.emptyDoubleVector(1)\n    ic     = stypes.emptyIntVector(1)\n    found  = ctypes.c_int()\n    libspice.dskxsi_c(pri, target, nsurf, srflst, et, fixref, vertex, raydir, maxd, maxi, xpt, handle, dladsc, dskdsc, dc, ic, found)\n    return stypes.cVectorToPython(xpt), handle.value, dladsc, dskdsc, stypes.cVectorToPython(dc), stypes.cVectorToPython(ic), bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing ray - surface intercepts for a set of rays.", "response": "def dskxv(pri, target, srflst, et, fixref, vtxarr, dirarr):\n    \"\"\"\n    Compute ray-surface intercepts for a set of rays, using data\n    provided by multiple loaded DSK segments.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dskxv_c.html\n\n    :param pri: Data prioritization flag.\n    :type pri: bool\n    :param target: Target body name.\n    :type target: str\n    :param srflst: Surface ID list.\n    :type srflst: list of int\n    :param et: Epoch, expressed as seconds past J2000 TDB.\n    :type et: float\n    :param fixref: Name of target body-fixed reference frame.\n    :type fixref: str\n    :param vtxarr: Array of vertices of rays.\n    :type vtxarr: Nx3-Element Array of floats\n    :param dirarr: Array of direction vectors of rays.\n    :type dirarr: Nx3-Element Array of floats\n    :return: Intercept point array and Found flag array.\n    :rtype: tuple\n    \"\"\"\n    pri    = ctypes.c_int(pri)\n    target = stypes.stringToCharP(target)\n    nsurf  = ctypes.c_int(len(srflst))\n    srflst = stypes.toIntVector(srflst)\n    et     = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    nray   = ctypes.c_int(len(vtxarr))\n    vtxarr = stypes.toDoubleMatrix(vtxarr)\n    dirarr = stypes.toDoubleMatrix(dirarr)\n    xptarr = stypes.emptyDoubleMatrix(y=nray)\n    fndarr = stypes.emptyIntVector(nray)\n    libspice.dskxv_c(pri, target, nsurf, srflst, et, fixref, nray, vtxarr, dirarr, xptarr, fndarr)\n    return stypes.cMatrixToNumpy(xptarr), stypes.cVectorToPython(fndarr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dskz02(handle, dladsc):\n    handle = ctypes.c_int(handle)\n    nv = ctypes.c_int()\n    np = ctypes.c_int()\n    libspice.dskz02_c(handle, dladsc, ctypes.byref(nv), ctypes.byref(np))\n    return nv.value, np.value", "response": "Return the number of vertices and number of plates in a type 2 DSK segment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the data about a kernel pool variable.", "response": "def dtpool(name):\n    \"\"\"\n    Return the data about a kernel pool variable.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dtpool_c.html\n\n    :param name: Name of the variable whose value is to be returned.\n    :type name: str\n    :return:\n            Number of values returned for name,\n            Type of the variable \"C\", \"N\", or \"X\".\n    :rtype: tuple\n    \"\"\"\n    name = stypes.stringToCharP(name)\n    found = ctypes.c_int()\n    n = ctypes.c_int()\n    typeout = ctypes.c_char()\n    libspice.dtpool_c(name, ctypes.byref(found), ctypes.byref(n),\n                      ctypes.byref(typeout))\n    return n.value, stypes.toPythonString(typeout.value), bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ducrss(s1, s2):\n    assert len(s1) is 6 and len(s2) is 6\n    s1 = stypes.toDoubleVector(s1)\n    s2 = stypes.toDoubleVector(s2)\n    sout = stypes.emptyDoubleVector(6)\n    libspice.ducrss_c(s1, s2, sout)\n    return stypes.cVectorToPython(sout)", "response": "Compute the unit vector parallel to the cross product of s1 and s2 and return the derivative of the cross product of s2."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the cross product of two 3 - dimensional vectors and the derivative of this cross product.", "response": "def dvcrss(s1, s2):\n    \"\"\"\n    Compute the cross product of two 3-dimensional vectors\n    and the derivative of this cross product.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dvcrss_c.html\n\n    :param s1: Left hand state for cross product and derivative.\n    :type s1: 6-Element Array of floats\n    :param s2: Right hand state for cross product and derivative.\n    :type s2: 6-Element Array of floats\n    :return: State associated with cross product of positions.\n    :rtype: 6-Element Array of floats\n    \"\"\"\n    assert len(s1) is 6 and len(s2) is 6\n    s1 = stypes.toDoubleVector(s1)\n    s2 = stypes.toDoubleVector(s2)\n    sout = stypes.emptyDoubleVector(6)\n    libspice.dvcrss_c(s1, s2, sout)\n    return stypes.cVectorToPython(sout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the derivative of the dot product of two double - vector precision position vectors.", "response": "def dvdot(s1, s2):\n    \"\"\"\n    Compute the derivative of the dot product of two double\n    precision position vectors.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dvdot_c.html\n\n    :param s1: First state vector in the dot product.\n    :type s1: 6-Element Array of floats\n    :param s2: Second state vector in the dot product.\n    :type s2: 6-Element Array of floats\n    :return: The derivative of the dot product.\n    :rtype: float\n    \"\"\"\n    assert len(s1) is 6 and len(s2) is 6\n    s1 = stypes.toDoubleVector(s1)\n    s2 = stypes.toDoubleVector(s2)\n    return libspice.dvdot_c(s1, s2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dvhat(s1):\n    assert len(s1) is 6\n    s1 = stypes.toDoubleVector(s1)\n    sout = stypes.emptyDoubleVector(6)\n    libspice.dvhat_c(s1, sout)\n    return stypes.cVectorToPython(sout)", "response": "Find the unit vector corresponding to a state vector and its time derivative."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to calculate the derivative of the norm of a 3-vector. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dvnorm_c.html :param state: A 6-vector composed of three coordinates and their derivatives. :type state: 6-Element Array of floats :return: The derivative of the norm of a 3-vector. :rtype: float", "response": "def dvnorm(state):\n    \"\"\"\n    Function to calculate the derivative of the norm of a 3-vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dvnorm_c.html\n\n    :param state:\n                A 6-vector composed of three coordinates and their derivatives.\n    :type state: 6-Element Array of floats\n    :return: The derivative of the norm of a 3-vector.\n    :rtype: float\n    \"\"\"\n    assert len(state) is 6\n    state = stypes.toDoubleVector(state)\n    return libspice.dvnorm_c(state)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the time derivative of the angular separation between two input states S1 and S2.", "response": "def dvsep(s1, s2):\n    \"\"\"\n    Calculate the time derivative of the separation angle between\n    two input states, S1 and S2.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/dvsep_c.html\n\n    :param s1: State vector of the first body.\n    :type s1: 6-Element Array of floats\n    :param s2: State vector of the second body.\n    :type s2: 6-Element Array of floats\n    :return: The time derivative of the angular separation between S1 and S2.\n    :rtype: float\n    \"\"\"\n    assert len(s1) is 6 and len(s2) is 6\n    s1 = stypes.toDoubleVector(s1)\n    s2 = stypes.toDoubleVector(s2)\n    return libspice.dvsep_c(s1, s2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the limb of a triaxial ellipsoid viewed from a specified point.", "response": "def edlimb(a, b, c, viewpt):\n    \"\"\"\n    Find the limb of a triaxial ellipsoid, viewed from a specified point.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/edlimb_c.html\n\n    :param a: Length of ellipsoid semi-axis lying on the x-axis.\n    :type a: float\n    :param b: Length of ellipsoid semi-axis lying on the y-axis.\n    :type b: float\n    :param c: Length of ellipsoid semi-axis lying on the z-axis.\n    :type c: float\n    :param viewpt: Location of viewing point.\n    :type viewpt: 3-Element Array of floats\n    :return: Limb of ellipsoid as seen from viewing point.\n    :rtype: spiceypy.utils.support_types.Ellipse\n    \"\"\"\n    limb = stypes.Ellipse()\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    viewpt = stypes.toDoubleVector(viewpt)\n    libspice.edlimb_c(a, b, c, viewpt, ctypes.byref(limb))\n    return limb"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing a set of points on the umbral or penumbral terminator of a specified target body.", "response": "def edterm(trmtyp, source, target, et, fixref, abcorr, obsrvr, npts):\n    \"\"\"\n    Compute a set of points on the umbral or penumbral terminator of\n    a specified target body, where the target shape is modeled as an\n    ellipsoid.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/edterm_c.html\n\n    :param trmtyp: Terminator type.\n    :type trmtyp: str\n    :param source: Light source.\n    :type source: str\n    :param target: Target body.\n    :type target: str\n    :param et: Observation epoch.\n    :type et: str\n    :param fixref: Body-fixed frame associated with target.\n    :type fixref: str\n    :param abcorr: Aberration correction.\n    :type abcorr: str\n    :param obsrvr: Observer.\n    :type obsrvr: str\n    :param npts: Number of points in terminator set.\n    :type npts: int\n    :return:\n            Epoch associated with target center,\n            Position of observer in body-fixed frame,\n            Terminator point set.\n    :rtype: tuple\n    \"\"\"\n    trmtyp = stypes.stringToCharP(trmtyp)\n    source = stypes.stringToCharP(source)\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    trgepc = ctypes.c_double()\n    obspos = stypes.emptyDoubleVector(3)\n    trmpts = stypes.emptyDoubleMatrix(x=3, y=npts)\n    npts = ctypes.c_int(npts)\n    libspice.edterm_c(trmtyp, source, target, et, fixref, abcorr, obsrvr, npts,\n                      ctypes.byref(trgepc), obspos, trmpts)\n    return trgepc.value, stypes.cVectorToPython(obspos), stypes.cMatrixToNumpy(\n            trmpts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd data to a character column in a specified EK record.", "response": "def ekacec(handle, segno, recno, column, nvals, cvals, isnull):\n    \"\"\"\n    Add data to a character column in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekacec_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record to which data is to be added.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :param nvals: Number of values to add to column.\n    :type nvals: int\n    :param cvals: Character values to add to column.\n    :type cvals: list of str.\n    :param isnull: Flag indicating whether column entry is null.\n    :type isnull: bool\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int(nvals)\n    vallen = ctypes.c_int(len(max(cvals, key=len)) + 1)\n    cvals = stypes.listToCharArrayPtr(cvals)\n    isnull = ctypes.c_int(isnull)\n    libspice.ekacec_c(handle, segno, recno, column, nvals, vallen, cvals, isnull)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd data to an integer column in a specified EK record.", "response": "def ekacei(handle, segno, recno, column, nvals, ivals, isnull):\n    \"\"\"\n    Add data to an integer column in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekacei_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record to which data is to be added.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :param nvals: Number of values to add to column.\n    :type nvals: int\n    :param ivals: Integer values to add to column.\n    :type ivals: Array of ints\n    :param isnull: Flag indicating whether column entry is null.\n    :type isnull: bool\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int(nvals)\n    ivals = stypes.toIntVector(ivals)\n    isnull = ctypes.c_int(isnull)\n    libspice.ekacei_c(handle, segno, recno, column, nvals, ivals, isnull)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an entire character column to an EK segment.", "response": "def ekaclc(handle, segno, column, vallen, cvals, entszs, nlflgs, rcptrs,\n           wkindx):\n    \"\"\"\n    Add an entire character column to an EK segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekaclc_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Number of segment to add column to.\n    :type segno: int\n    :param column: Column name.\n    :type column: str\n    :param vallen: Length of character values.\n    :type vallen: int\n    :param cvals: Character values to add to column.\n    :type cvals: list of str.\n    :param entszs: Array of sizes of column entries.\n    :type entszs: Array of ints\n    :param nlflgs: Array of null flags for column entries.\n    :type nlflgs: Array of bools\n    :param rcptrs: Record pointers for segment.\n    :type rcptrs: Array of ints\n    :param wkindx: Work space for column index.\n    :type wkindx: Array of ints\n    :return: Work space for column index.\n    :rtype: Array of ints\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    column = stypes.stringToCharP(column)\n    vallen = ctypes.c_int(vallen)\n    cvals = stypes.listToCharArrayPtr(cvals)\n    entszs = stypes.toIntVector(entszs)\n    nlflgs = stypes.toIntVector(nlflgs)\n    rcptrs = stypes.toIntVector(rcptrs)\n    wkindx = stypes.toIntVector(wkindx)\n    libspice.ekaclc_c(handle, segno, column, vallen, cvals, entszs, nlflgs,\n                      rcptrs, wkindx)\n    return stypes.cVectorToPython(wkindx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd an entire double precision column to an EK segment.", "response": "def ekacld(handle, segno, column, dvals, entszs, nlflgs, rcptrs, wkindx):\n    \"\"\"\n    Add an entire double precision column to an EK segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekacld_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Number of segment to add column to.\n    :type segno: int\n    :param column: Column name.\n    :type column: str\n    :param dvals: Double precision values to add to column.\n    :type dvals: Array of floats\n    :param entszs: Array of sizes of column entries.\n    :type entszs: Array of ints\n    :param nlflgs: Array of null flags for column entries.\n    :type nlflgs: Array of bools\n    :param rcptrs: Record pointers for segment.\n    :type rcptrs: Array of ints\n    :param wkindx: Work space for column index.\n    :type wkindx: Array of ints\n    :return: Work space for column index.\n    :rtype: Array of ints\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    column = stypes.stringToCharP(column)\n    dvals = stypes.toDoubleVector(dvals)\n    entszs = stypes.toIntVector(entszs)\n    nlflgs = stypes.toIntVector(nlflgs)\n    rcptrs = stypes.toIntVector(rcptrs)\n    wkindx = stypes.toIntVector(wkindx)\n    libspice.ekacld_c(handle, segno, column, dvals, entszs, nlflgs, rcptrs,\n                      wkindx)\n    return stypes.cVectorToPython(wkindx)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an entire integer column to an EK segment.", "response": "def ekacli(handle, segno, column, ivals, entszs, nlflgs, rcptrs, wkindx):\n    \"\"\"\n    Add an entire integer column to an EK segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekacli_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Number of segment to add column to.\n    :type segno: int\n    :param column: Column name.\n    :type column: str\n    :param ivals: Integer values to add to column.\n    :type ivals: Array of ints\n    :type entszs: Array of ints\n    :param nlflgs: Array of null flags for column entries.\n    :type nlflgs: Array of bools\n    :param rcptrs: Record pointers for segment.\n    :type rcptrs: Array of ints\n    :param wkindx: Work space for column index.\n    :type wkindx: Array of ints\n    :return: Work space for column index.\n    :rtype: Array of ints\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    column = stypes.stringToCharP(column)\n    ivals = stypes.toIntVector(ivals)\n    entszs = stypes.toIntVector(entszs)\n    nlflgs = stypes.toIntVector(nlflgs)\n    rcptrs = stypes.toIntVector(rcptrs)\n    wkindx = stypes.toIntVector(wkindx)\n    libspice.ekacli_c(handle, segno, column, ivals, entszs, nlflgs, rcptrs,\n                      wkindx)\n    return stypes.cVectorToPython(wkindx)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nappending a new empty record at the end of an E - kernel segment.", "response": "def ekappr(handle, segno):\n    \"\"\"\n    Append a new, empty record at the end of a specified E-kernel segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekappr_c.html\n\n    :param handle: File handle.\n    :type handle: int\n    :param segno: Segment number.\n    :type segno: int\n    :return: Number of appended record.\n    :rtype: int\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int()\n    libspice.ekappr_c(handle, segno, ctypes.byref(recno))\n    return recno.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a new segment in an E - kernel.", "response": "def ekbseg(handle, tabnam, cnames, decls):\n    \"\"\"\n    Start a new segment in an E-kernel.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekbseg_c.html\n\n    :param handle: File handle.\n    :type handle: int\n    :param tabnam: Table name.\n    :type tabnam: str\n    :param cnames: Names of columns.\n    :type cnames: list of str.\n    :param decls: Declarations of columns.\n    :type decls: list of str.\n    :return: Segment number.\n    :rtype: int\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    tabnam = stypes.stringToCharP(tabnam)\n    ncols  = ctypes.c_int(len(cnames))\n    cnmlen = ctypes.c_int(len(max(cnames, key=len)) + 1) # needs to be len(name)+1 ie 'c1' to 3 for ekbseg do not fail\n    cnames = stypes.listToCharArrayPtr(cnames)\n    declen = ctypes.c_int(len(max(decls, key=len)) + 1)\n    decls = stypes.listToCharArrayPtr(decls)\n    segno = ctypes.c_int()\n    libspice.ekbseg_c(handle, tabnam, ncols, cnmlen, cnames, declen, decls, ctypes.byref(segno))\n    return segno.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the number of distinct columns in a specified table.", "response": "def ekccnt(table):\n    \"\"\"\n    Return the number of distinct columns in a specified,\n    currently loaded table.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekccnt_c.html\n\n    :param table: Name of table.\n    :type table: str\n    :return: Count of distinct, currently loaded columns.\n    :rtype: int\n    \"\"\"\n    table = stypes.stringToCharP(table)\n    ccount = ctypes.c_int()\n    libspice.ekccnt_c(table, ctypes.byref(ccount))\n    return ccount.value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ekcii(table, cindex, lenout=_default_len_out):\n    table = stypes.stringToCharP(table)\n    cindex = ctypes.c_int(cindex)\n    lenout = ctypes.c_int(lenout)\n    column = stypes.stringToCharP(lenout)\n    attdsc = stypes.SpiceEKAttDsc()\n    libspice.ekcii_c(table, cindex, lenout, column, ctypes.byref(attdsc))\n    return stypes.toPythonString(column), attdsc", "response": "Return the attribute information about a column belonging to a loaded EK table specifying the column by table and index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ekdelr(handle, segno, recno):\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    libspice.ekdelr_c(handle, segno, recno)", "response": "Delete a specified record from an E - kernel segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompletes a fast write operation on a new E - kernel segment.", "response": "def ekffld(handle, segno, rcptrs):\n    \"\"\"\n    Complete a fast write operation on a new E-kernel segment.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekffld_c.html\n\n    :param handle: File handle.\n    :type handle: int\n    :param segno: Segment number.\n    :type segno: int\n    :param rcptrs: Record pointers.\n    :type rcptrs: Array of ints\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    rcptrs = stypes.toIntVector(rcptrs)\n    libspice.ekffld_c(handle, segno,\n                      ctypes.cast(rcptrs, ctypes.POINTER(ctypes.c_int)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ekfind(query, lenout=_default_len_out):\n    query = stypes.stringToCharP(query)\n    lenout = ctypes.c_int(lenout)\n    nmrows = ctypes.c_int()\n    error = ctypes.c_int()\n    errmsg = stypes.stringToCharP(lenout)\n    libspice.ekfind_c(query, lenout, ctypes.byref(nmrows), ctypes.byref(error),\n                      errmsg)\n    return nmrows.value, error.value, stypes.toPythonString(errmsg)", "response": "Find E - kernel data that satisfy a set of constraints."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ekgc(selidx, row, element, lenout=_default_len_out):\n    selidx = ctypes.c_int(selidx)\n    row = ctypes.c_int(row)\n    element = ctypes.c_int(element)\n    lenout = ctypes.c_int(lenout)\n    null = ctypes.c_int()\n    found = ctypes.c_int()\n    cdata = stypes.stringToCharP(lenout)\n    libspice.ekgc_c(selidx, row, element, lenout, cdata, ctypes.byref(null), ctypes.byref(found))\n    return stypes.toPythonString(cdata), null.value, bool(found.value)", "response": "Return an element of an entry in a specified column of character type in a specified row."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an element of an entry in a column of double precision type in a specific row.", "response": "def ekgd(selidx, row, element):\n    \"\"\"\n    Return an element of an entry in a column of double precision type in a\n    specified row.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekgd_c.html\n\n    :param selidx: Index of parent column in SELECT clause.\n    :type selidx: int\n    :param row: Row to fetch from.\n    :type row: int\n    :param element: Index of element, within column entry, to fetch.\n    :type element: int\n    :return:\n            Double precision element of column entry,\n            Flag indicating whether column entry was null.\n    :rtype: tuple\n    \"\"\"\n    selidx = ctypes.c_int(selidx)\n    row = ctypes.c_int(row)\n    element = ctypes.c_int(element)\n    ddata = ctypes.c_double()\n    null = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.ekgd_c(selidx, row, element, ctypes.byref(ddata),\n                    ctypes.byref(null), ctypes.byref(found))\n    return ddata.value, null.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an element of an entry in a specified column of integer type in a specified row.", "response": "def ekgi(selidx, row, element):\n    \"\"\"\n    Return an element of an entry in a column of integer type in a specified\n    row.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekgi_c.html\n\n    :param selidx: Index of parent column in SELECT clause.\n    :type selidx: int\n    :param row: Row to fetch from.\n    :type row: int\n    :param element: Index of element, within column entry, to fetch.\n    :type element: int\n    :return:\n            Integer element of column entry,\n            Flag indicating whether column entry was null.\n    :rtype: tuple\n    \"\"\"\n    selidx = ctypes.c_int(selidx)\n    row = ctypes.c_int(row)\n    element = ctypes.c_int(element)\n    idata = ctypes.c_int()\n    null = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.ekgi_c(selidx, row, element, ctypes.byref(idata),\n                    ctypes.byref(null), ctypes.byref(found))\n    return idata.value, null.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a segment from an E - kernel file and return its number and array of record pointers.", "response": "def ekifld(handle, tabnam, ncols, nrows, cnmlen, cnames, declen, decls):\n    \"\"\"\n    Initialize a new E-kernel segment to allow fast writing.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekifld_c.html\n\n    :param handle: File handle.\n    :type handle: int\n    :param tabnam: Table name.\n    :type tabnam: str\n    :param ncols: Number of columns in the segment.\n    :type ncols: int\n    :param nrows: Number of rows in the segment.\n    :type nrows: int\n    :param cnmlen: Length of names in in column name array.\n    :type cnmlen: int\n    :param cnames: Names of columns.\n    :type cnames: list of str.\n    :param declen: Length of declaration strings in declaration array.\n    :type declen: int\n    :param decls: Declarations of columns.\n    :type decls: list of str.\n    :return: Segment number, Array of record pointers.\n    :rtype: tuple\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    tabnam = stypes.stringToCharP(tabnam)\n    ncols = ctypes.c_int(ncols)\n    nrows = ctypes.c_int(nrows)\n    cnmlen = ctypes.c_int(cnmlen)\n    cnames = stypes.listToCharArray(cnames)\n    declen = ctypes.c_int(declen)\n    recptrs = stypes.emptyIntVector(nrows)\n    decls = stypes.listToCharArray(decls)\n    segno = ctypes.c_int()\n    libspice.ekifld_c(handle, tabnam, ncols, nrows, cnmlen, cnames, declen,\n                      decls, ctypes.byref(segno), recptrs)\n    return segno.value, stypes.cVectorToPython(recptrs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new empty record to an E - kernel segment at a specified record number.", "response": "def ekinsr(handle, segno, recno):\n    \"\"\"\n    Add a new, empty record to a specified E-kernel segment at a specified\n    index.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekinsr_c.html\n\n    :param handle: File handle.\n    :type handle: int\n    :param segno: Segment number.\n    :type segno: int\n    :param recno: Record number.\n    :type recno: int\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    libspice.ekinsr_c(handle, segno, recno)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading an EK file and return its handle.", "response": "def eklef(fname):\n    \"\"\"\n    Load an EK file, making it accessible to the EK readers.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/eklef_c.html\n\n    :param fname: Name of EK file to load.\n    :type fname: str\n    :return: File handle of loaded EK file.\n    :rtype: int\n    \"\"\"\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int()\n    libspice.eklef_c(fname, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eknelt(selidx, row):\n    selidx = ctypes.c_int(selidx)\n    row = ctypes.c_int(row)\n    return libspice.eknelt_c(selidx, row)", "response": "Return the number of elements in a specified column entry in a current row."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the number of loaded EK tables.", "response": "def ekntab():\n    \"\"\"\n    Return the number of loaded EK tables.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekntab_c.html\n\n    :return: The number of loaded EK tables.\n    :rtype: int\n    \"\"\"\n    n = ctypes.c_int(0)\n    libspice.ekntab_c(ctypes.byref(n))\n    return n.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a new E - kernel file and prepare it for writing.", "response": "def ekopn(fname, ifname, ncomch):\n    \"\"\"\n    Open a new E-kernel file and prepare the file for writing.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekopn_c.html\n\n    :param fname: Name of EK file.\n    :type fname: str\n    :param ifname: Internal file name.\n    :type ifname: str\n    :param ncomch: The number of characters to reserve for comments.\n    :type ncomch: int\n    :return: Handle attached to new EK file.\n    :rtype: int\n    \"\"\"\n    fname = stypes.stringToCharP(fname)\n    ifname = stypes.stringToCharP(ifname)\n    ncomch = ctypes.c_int(ncomch)\n    handle = ctypes.c_int()\n    libspice.ekopn_c(fname, ifname, ncomch, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ekopr(fname):\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int()\n    libspice.ekopr_c(fname, ctypes.byref(handle))\n    return handle.value", "response": "Open an existing E - kernel file for reading."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a scratch E - kernel file and prepare the file for writing.", "response": "def ekops():\n    \"\"\"\n    Open a scratch (temporary) E-kernel file and prepare the file\n    for writing.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekops_c.html\n\n    :return: Handle attached to new EK file.\n    :rtype: int\n    \"\"\"\n    handle = ctypes.c_int()\n    libspice.ekops_c(ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen an existing E - kernel file for writing.", "response": "def ekopw(fname):\n    \"\"\"\n    Open an existing E-kernel file for writing.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekopw_c.html\n\n    :param fname: Name of EK file.\n    :type fname: str\n    :return: Handle attached to EK file.\n    :rtype: int\n    \"\"\"\n    fname = stypes.stringToCharP(fname)\n    handle = ctypes.c_int()\n    libspice.ekopw_c(fname, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a string of a specified length in a specified table and column.", "response": "def ekpsel(query, msglen, tablen, collen):\n    \"\"\"\n    Parse the SELECT clause of an EK query, returning full particulars\n    concerning each selected item.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekpsel_c.html\n    note: oddly docs at url are incomplete/incorrect.\n\n    :param query: EK query.\n    :type query: str\n    :param msglen: Available space in the output error message string.\n    :type msglen: int\n    :param tablen: UNKNOWN? Length of Table?\n    :type tablen: int\n    :param collen: UNKOWN? Length of Column?\n    :return:\n            Number of items in SELECT clause of query,\n            Begin positions of expressions in SELECT clause,\n            End positions of expressions in SELECT clause,\n            Data types of expressions,\n            Classes of expressions,\n            Names of tables qualifying SELECT columns,\n            Names of columns in SELECT clause of query,\n            Error flag,\n            Parse error message.\n    :rtype: tuple\n    \"\"\"\n    query = stypes.stringToCharP(query)\n    msglen = ctypes.c_int(msglen)\n    tablen = ctypes.c_int(tablen)\n    collen = ctypes.c_int(collen)\n    n = ctypes.c_int()\n    xbegs = stypes.emptyIntVector(_SPICE_EK_MAXQSEL)\n    xends = stypes.emptyIntVector(_SPICE_EK_MAXQSEL)\n    xtypes = stypes.emptyIntVector(_SPICE_EK_MAXQSEL)\n    xclass = stypes.emptyIntVector(_SPICE_EK_MAXQSEL)\n    tabs = stypes.emptyCharArray(yLen=_SPICE_EK_MAXQSEL, xLen=tablen)\n    cols = stypes.emptyCharArray(yLen=_SPICE_EK_MAXQSEL, xLen=collen)\n    error = ctypes.c_int()\n    errmsg = stypes.stringToCharP(msglen)\n    libspice.ekpsel_c(query, msglen, tablen, collen, ctypes.byref(n),\n                      xbegs, xends, xtypes, xclass, ctypes.byref(tabs),\n                      ctypes.byref(cols), ctypes.byref(error), errmsg)\n    return (n.value,\n            stypes.cVectorToPython(xbegs)[:n.value],\n            stypes.cVectorToPython(xends)[:n.value],\n            stypes.cVectorToPython(xtypes)[:n.value],\n            stypes.cVectorToPython(xclass)[:n.value],\n            stypes.cVectorToPython(tabs)[:n.value],\n            stypes.cVectorToPython(cols)[:n.value],\n            error.value,\n            stypes.toPythonString(errmsg))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading data from a character column in a specified EK record.", "response": "def ekrcec(handle, segno, recno, column, lenout, nelts=_SPICE_EK_EKRCEX_ROOM_DEFAULT):\n    \"\"\"\n    Read data from a character column in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekrcec_c.html\n\n    :param handle: Handle attached to EK file.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record from which data is to be read.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :param lenout: Maximum length of output strings.\n    :type lenout: int\n    :param nelts: Number of elements to allow for (default=100)\n    :type nelts: int\n    :return:\n            Number of values in column entry,\n            Character values in column entry,\n            Flag indicating whether column entry is null.\n    :rtype: tuple\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    lenout = ctypes.c_int(lenout)\n    nvals = ctypes.c_int()\n    cvals = stypes.emptyCharArray(yLen=nelts, xLen=lenout)\n    isnull = ctypes.c_int()\n    libspice.ekrcec_c(handle, segno, recno, column, lenout, ctypes.byref(nvals), ctypes.byref(cvals), ctypes.byref(isnull))\n    assert failed() or (nvals.value <= nelts)\n    return nvals.value, stypes.cVectorToPython(cvals)[:nvals.value], bool(isnull.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads data from a double precision column in a specified EK record.", "response": "def ekrced(handle, segno, recno, column, nelts=_SPICE_EK_EKRCEX_ROOM_DEFAULT):\n    \"\"\"\n    Read data from a double precision column in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekrced_c.html\n\n    :param handle: Handle attached to EK file.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record from which data is to be read.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :return:\n            Number of values in column entry,\n            Float values in column entry,\n            Flag indicating whether column entry is null.\n    :rtype: tuple\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int(0)\n    dvals = stypes.emptyDoubleVector(nelts)\n    isnull = ctypes.c_int()\n    libspice.ekrced_c(handle, segno, recno, column, ctypes.byref(nvals), dvals,\n                      ctypes.byref(isnull))\n    assert failed() or (nvals.value <= nelts)\n    return nvals.value, stypes.cVectorToPython(dvals)[:nvals.value], bool(isnull.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading data from an integer column in a specified EK record.", "response": "def ekrcei(handle, segno, recno, column, nelts=_SPICE_EK_EKRCEX_ROOM_DEFAULT):\n    \"\"\"\n    Read data from an integer column in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekrcei_c.html\n\n    :param handle: Handle attached to EK file.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record from which data is to be read.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :return:\n            Number of values in column entry,\n            Integer values in column entry,\n            Flag indicating whether column entry is null.\n    :rtype: tuple\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int()\n    ivals = stypes.emptyIntVector(nelts)\n    isnull = ctypes.c_int()\n    libspice.ekrcei_c(handle, segno, recno, column, ctypes.byref(nvals), ivals,\n                      ctypes.byref(isnull))\n    assert failed() or (nvals.value <= nelts)\n    return nvals.value, stypes.cVectorToPython(ivals)[:nvals.value], bool(isnull.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn summary information for a specified segment in a specified EK.", "response": "def ekssum(handle, segno):\n    \"\"\"\n    Return summary information for a specified segment in a specified EK.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekssum_c.html\n\n    :param handle: Handle of EK.\n    :type handle: int\n    :param segno: Number of segment to be summarized.\n    :type segno: int\n    :return: EK segment summary.\n    :rtype: spicepy.utils.support_types.SpiceEKSegSum\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    segsum = stypes.SpiceEKSegSum()\n    libspice.ekssum_c(handle, segno, ctypes.byref(segsum))\n    return segsum"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ektnam(n, lenout=_default_len_out):\n    n = ctypes.c_int(n)\n    lenout = ctypes.c_int(lenout)\n    table = stypes.stringToCharP(lenout)\n    libspice.ektnam_c(n, lenout, table)\n    return stypes.toPythonString(table)", "response": "Return the name of a specified loaded table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ekucec(handle, segno, recno, column, nvals, cvals, isnull):\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int(nvals)\n    vallen = ctypes.c_int(len(max(cvals, key=len)) + 1)\n    cvals = stypes.listToCharArrayPtr(cvals, xLen=vallen)\n    isnull = ctypes.c_int(isnull)\n    libspice.ekucec_c(handle, segno, recno, column, nvals, vallen, cvals, isnull)", "response": "Update a character column entry in a specified EK record."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a double precision column entry in a specified EK record.", "response": "def ekuced(handle, segno, recno, column, nvals, dvals, isnull):\n    \"\"\"\n    Update a double precision column entry in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekuced_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record to which data is to be updated.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :param nvals: Number of values in new column entry.\n    :type nvals: int\n    :param dvals: Double precision values comprising new column entry.\n    :type dvals: Array of floats\n    :param isnull: Flag indicating whether column entry is null.\n    :type isnull: bool\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int(nvals)\n    dvals = stypes.toDoubleVector(dvals)\n    isnull = ctypes.c_int(isnull)\n    libspice.ekaced_c(handle, segno, recno, column, nvals, dvals, isnull)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate an integer column entry in a specified EK record.", "response": "def ekucei(handle, segno, recno, column, nvals, ivals, isnull):\n    \"\"\"\n    Update an integer column entry in a specified EK record.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ekucei_c.html\n\n    :param handle: EK file handle.\n    :type handle: int\n    :param segno: Index of segment containing record.\n    :type segno: int\n    :param recno: Record to which data is to be updated.\n    :type recno: int\n    :param column: Column name.\n    :type column: str\n    :param nvals: Number of values in new column entry.\n    :type nvals: int\n    :param ivals: Integer values comprising new column entry.\n    :type ivals: Array of ints\n    :param isnull: Flag indicating whether column entry is null.\n    :type isnull: bool\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    segno = ctypes.c_int(segno)\n    recno = ctypes.c_int(recno)\n    column = stypes.stringToCharP(column)\n    nvals = ctypes.c_int(nvals)\n    ivals = stypes.toIntVector(ivals)\n    isnull = ctypes.c_int(isnull)\n    libspice.ekucei_c(handle, segno, recno, column, nvals, ivals, isnull)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an ellipse to a center vector and two generating vectors.", "response": "def el2cgv(ellipse):\n    \"\"\"\n    Convert an ellipse to a center vector and two generating\n    vectors. The selected generating vectors are semi-axes of the\n    ellipse.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/el2cgv_c.html\n\n    :param ellipse: An Ellipse\n    :type ellipse: spiceypy.utils.support_types.Ellipse\n    :return: Center and semi-axes of ellipse.\n    :rtype: tuple\n    \"\"\"\n    assert (isinstance(ellipse, stypes.Ellipse))\n    center = stypes.emptyDoubleVector(3)\n    smajor = stypes.emptyDoubleVector(3)\n    sminor = stypes.emptyDoubleVector(3)\n    libspice.el2cgv_c(ctypes.byref(ellipse), center, smajor, sminor)\n    return stypes.cVectorToPython(center), stypes.cVectorToPython(\n            smajor), stypes.cVectorToPython(sminor)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef elemc(item, inset):\n    assert isinstance(inset, stypes.SpiceCell)\n    item = stypes.stringToCharP(item)\n    return bool(libspice.elemc_c(item, ctypes.byref(inset)))", "response": "Determine whether an item is an element of a character set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef elemd(item, inset):\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.dtype == 1\n    item = ctypes.c_double(item)\n    return bool(libspice.elemd_c(item, ctypes.byref(inset)))", "response": "Determine whether an item is an element of a double precision set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines whether an item is an element of an integer set.", "response": "def elemi(item, inset):\n    \"\"\"\n    Determine whether an item is an element of an integer set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/elemi_c.html\n\n    :param item: Item to be tested.\n    :type item: int\n    :param inset: Set to be tested.\n    :type inset: spiceypy.utils.support_types.SpiceCell\n    :return: True if item is an element of set.\n    :rtype: bool\n    \"\"\"\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.dtype == 2\n    item = ctypes.c_int(item)\n    return bool(libspice.elemi_c(item, ctypes.byref(inset)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the state of an object described by an equinoctial element relative to some fixed plane.", "response": "def eqncpv(et, epoch, eqel, rapol, decpol):\n    \"\"\"\n    Compute the state (position and velocity of an object whose\n    trajectory is described via equinoctial elements relative to some\n    fixed plane (usually the equatorial plane of some planet).\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/eqncpv_c.html\n\n    :param et: Epoch in seconds past J2000 to find state.\n    :type et: float\n    :param epoch: Epoch of elements in seconds past J2000.\n    :type epoch: float\n    :param eqel: Array of equinoctial elements\n    :type eqel: 9-Element Array of floats\n    :param rapol: Right Ascension of the pole of the reference plane.\n    :type rapol: float\n    :param decpol: Declination of the pole of the reference plane.\n    :type decpol: float\n    :return: State of the object described by eqel.\n    :rtype: 6-Element Array of floats\n    \"\"\"\n    et = ctypes.c_double(et)\n    epoch = ctypes.c_double(epoch)\n    eqel = stypes.toDoubleVector(eqel)\n    rapol = ctypes.c_double(rapol)\n    decpol = ctypes.c_double(decpol)\n    state = stypes.emptyDoubleVector(6)\n    libspice.eqncpv_c(et, epoch, eqel, rapol, decpol, state)\n    return stypes.cVectorToPython(state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eqstr(a, b):\n    return bool(libspice.eqstr_c(stypes.stringToCharP(a), stypes.stringToCharP(b)))", "response": "Determine whether two strings are equivalent."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef erract(op, lenout, action=None):\n    if action is None:\n        action = \"\"\n    lenout = ctypes.c_int(lenout)\n    op = stypes.stringToCharP(op)\n    action = ctypes.create_string_buffer(str.encode(action), lenout.value)\n    actionptr = ctypes.c_char_p(ctypes.addressof(action))\n    libspice.erract_c(op, lenout, actionptr)\n    return stypes.toPythonString(actionptr)", "response": "Retrieve or set the default error action."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef errch(marker, string):\n    marker = stypes.stringToCharP(marker)\n    string = stypes.stringToCharP(string)\n    libspice.errch_c(marker, string)", "response": "Substitute a character string for the first occurrence of a marker in the current long error message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving or set the name of the current output device for error messages.", "response": "def errdev(op, lenout, device):\n    \"\"\"\n    Retrieve or set the name of the current output device for error messages.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/errdev_c.html\n\n    :param op: The operation, \"GET\" or \"SET\".\n    :type op: str\n    :param lenout: Length of device for output.\n    :type lenout: int\n    :param device: The device name.\n    :type device: str\n    :return: The device name.\n    :rtype: str\n    \"\"\"\n    lenout = ctypes.c_int(lenout)\n    op = stypes.stringToCharP(op)\n    device = ctypes.create_string_buffer(str.encode(device), lenout.value)\n    deviceptr = ctypes.c_char_p(ctypes.addressof(device))\n    libspice.errdev_c(op, lenout, deviceptr)\n    return stypes.toPythonString(deviceptr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubstitute a double precision number for the first occurrence of a marker found in the current long error message.", "response": "def errdp(marker, number):\n    \"\"\"\n    Substitute a double precision number for the first occurrence of\n    a marker found in the current long error message.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/errdp_c.html\n\n    :param marker: A substring of the error message to be replaced.\n    :type marker: str\n    :param number: The d.p. number to substitute for marker.\n    :type number: float\n    \"\"\"\n    marker = stypes.stringToCharP(marker)\n    number = ctypes.c_double(number)\n    libspice.errdp_c(marker, number)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef errint(marker, number):\n    marker = stypes.stringToCharP(marker)\n    number = ctypes.c_int(number)\n    libspice.errint_c(marker, number)", "response": "Substitute an integer for the first occurrence of a marker found\n    in the current long error message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve or set the list of error message items to be output when an error is detected.", "response": "def errprt(op, lenout, inlist):\n    \"\"\"\n    Retrieve or set the list of error message items to be output when an\n    error is detected.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/errprt_c.html\n\n    :param op: The operation, \"GET\" or \"SET\".\n    :type op: str\n    :param lenout: Length of list for output.\n    :type lenout: int\n    :param inlist: Specification of error messages to be output.\n    :type inlist: list of str.\n    :return: A list of error message items.\n    :rtype: list of str.\n    \"\"\"\n    lenout = ctypes.c_int(lenout)\n    op = stypes.stringToCharP(op)\n    inlist = ctypes.create_string_buffer(str.encode(inlist), lenout.value)\n    inlistptr = ctypes.c_char_p(ctypes.addressof(inlist))\n    libspice.errdev_c(op, lenout, inlistptr)\n    return stypes.toPythonString(inlistptr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef esrchc(value, array):\n    value = stypes.stringToCharP(value)\n    ndim = ctypes.c_int(len(array))\n    lenvals = ctypes.c_int(len(max(array, key=len)) + 1)\n    array = stypes.listToCharArray(array, xLen=lenvals, yLen=ndim)\n    return libspice.esrchc_c(value, ndim, lenvals, array)", "response": "Search for a given value within a character string array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef et2lst(et, body, lon, typein, timlen=_default_len_out, ampmlen=_default_len_out):\n    et = ctypes.c_double(et)\n    body = ctypes.c_int(body)\n    lon = ctypes.c_double(lon)\n    typein = stypes.stringToCharP(typein)\n    timlen = ctypes.c_int(timlen)\n    ampmlen = ctypes.c_int(ampmlen)\n    hr = ctypes.c_int()\n    mn = ctypes.c_int()\n    sc = ctypes.c_int()\n    time = stypes.stringToCharP(timlen)\n    ampm = stypes.stringToCharP(ampmlen)\n    libspice.et2lst_c(et, body, lon, typein, timlen, ampmlen,\n                      ctypes.byref(hr), ctypes.byref(mn), ctypes.byref(sc),\n                      time, ampm)\n    return hr.value, mn.value, sc.value, stypes.toPythonString(\n            time), stypes.toPythonString(ampm)", "response": "Given an ephemeris epoch compute the local solar time for a specified object on the surface of a specified body at a specified longitude."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an input time from ephemeris seconds past J2000 to Calendar Day - of - Year or Julian Date format UTC.", "response": "def et2utc(et, formatStr, prec, lenout=_default_len_out):\n    \"\"\"\n    Convert an input time from ephemeris seconds past J2000\n    to Calendar, Day-of-Year, or Julian Date format, UTC.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/et2utc_c.html\n\n    :param et: Input epoch, given in ephemeris seconds past J2000.\n    :type et: float\n    :param formatStr: Format of output epoch.\n    :type formatStr: str\n    :param prec: Digits of precision in fractional seconds or days.\n    :type prec: int\n    :param lenout: The length of the output string plus 1.\n    :type lenout: int\n    :return: Output time string in UTC\n    :rtype: str\n    \"\"\"\n    et = ctypes.c_double(et)\n    prec = ctypes.c_int(prec)\n    lenout = ctypes.c_int(lenout)\n    formatStr = stypes.stringToCharP(formatStr)\n    utcstr = stypes.stringToCharP(lenout)\n    libspice.et2utc_c(et, formatStr, prec, lenout, utcstr)\n    return stypes.toPythonString(utcstr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef etcal(et, lenout=_default_len_out):\n    lenout = ctypes.c_int(lenout)\n    string = stypes.stringToCharP(lenout)\n    if hasattr(et, \"__iter__\"):\n        strings = []\n        for t in et:\n            libspice.etcal_c(t, lenout, string)\n            checkForSpiceError(None)\n            strings.append(stypes.toPythonString(string))\n        return strings\n    else:\n        et = ctypes.c_double(et)\n        libspice.etcal_c(et, lenout, string)\n        return stypes.toPythonString(string)", "response": "Convert from an ephemeris epoch measured in seconds past\n    the epoch of J2000 to a standard calendar string format using a\n    formal calendar free of leapseconds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a rotation matrix from an Euler angles.", "response": "def eul2m(angle3, angle2, angle1, axis3, axis2, axis1):\n    \"\"\"\n    Construct a rotation matrix from a set of Euler angles.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/eul2m_c.html\n\n    :param angle3: Rotation angle about third rotation axis (radians).\n    :type angle3: float\n    :param angle2: Rotation angle about second rotation axis (radians).\n    :type angle2: float\n    :param angle1: Rotation angle about first rotation axis (radians).\n    :type angle1: float\n    :param axis3: Axis number of third rotation axis.\n    :type axis3: int\n    :param axis2: Axis number of second rotation axis.\n    :type axis2: int\n    :param axis1: Axis number of first rotation axis.]\n    :type axis1: int\n    :return: Product of the 3 rotations.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    angle3 = ctypes.c_double(angle3)\n    angle2 = ctypes.c_double(angle2)\n    angle1 = ctypes.c_double(angle1)\n    axis3 = ctypes.c_int(axis3)\n    axis2 = ctypes.c_int(axis2)\n    axis1 = ctypes.c_int(axis1)\n    r = stypes.emptyDoubleMatrix()\n    libspice.eul2m_c(angle3, angle2, angle1, axis3, axis2, axis1, r)\n    return stypes.cMatrixToNumpy(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines whether a file in question exists in the .", "response": "def exists(fname):\n    \"\"\"\n    Determine whether a file exists.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/exists_c.html\n\n    :param fname: Name of the file in question.\n    :return: True if the file exists, False otherwise.\n    :rtype: bool\n    \"\"\"\n    fname = stypes.stringToCharP(fname)\n    return bool(libspice.exists_c(fname))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a kernel variable is in the kernel pool.", "response": "def expool(name):\n    \"\"\"\n    Confirm the existence of a kernel variable in the kernel pool.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/expool_c.html\n\n    :param name: Name of the variable whose value is to be returned.\n    :type name: str\n    :return: True when the variable is in the pool.\n    :rtype: bool\n    \"\"\"\n    name = stypes.stringToCharP(name)\n    found = ctypes.c_int()\n    libspice.expool_c(name, ctypes.byref(found))\n    return bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fn2lun(fname):\n    fnameP    = stypes.stringToCharP(fname)\n    unit_out  = ctypes.c_int()\n    fname_len = ctypes.c_int(len(fname)+1)\n    libspice.fn2lun_(fnameP,ctypes.byref(unit_out),fname_len)\n    return unit_out.value", "response": "Internal undocumented command for mapping a filename of a file to its corresponding logical unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fovray(inst, raydir, rframe, abcorr, observer, et):\n    inst = stypes.stringToCharP(inst)\n    raydir = stypes.toDoubleVector(raydir)\n    rframe = stypes.stringToCharP(rframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    observer = stypes.stringToCharP(observer)\n    et = ctypes.c_double(et)\n    visible = ctypes.c_int()\n    libspice.fovray_c(inst, raydir, rframe, abcorr, observer, ctypes.byref(et),\n                      ctypes.byref(visible))\n    return bool(visible.value)", "response": "Determine if a specified ray is within the field - of - view of a specified instrument at a given time."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fovtrg(inst, target, tshape, tframe, abcorr, observer, et):\n    inst = stypes.stringToCharP(inst)\n    target = stypes.stringToCharP(target)\n    tshape = stypes.stringToCharP(tshape)\n    tframe = stypes.stringToCharP(tframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    observer = stypes.stringToCharP(observer)\n    et = ctypes.c_double(et)\n    visible = ctypes.c_int()\n    libspice.fovtrg_c(inst, target, tshape, tframe, abcorr, observer,\n                      ctypes.byref(et), ctypes.byref(visible))\n    return bool(visible.value)", "response": "Determine if a specified ephemeris object is within the field - of - view of a specified instrument at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef frame(x):\n    x = stypes.toDoubleVector(x)\n    y = stypes.emptyDoubleVector(3)\n    z = stypes.emptyDoubleVector(3)\n    libspice.frame_c(x, y, z)\n    return stypes.cVectorToPython(x), stypes.cVectorToPython(y), stypes.cVectorToPython(\n            z)", "response": "Return a tuple of 3 - element vectors from a 3 - element array of parallel unit vectors on output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef frinfo(frcode):\n    frcode = ctypes.c_int(frcode)\n    cent = ctypes.c_int()\n    frclss = ctypes.c_int()\n    clssid = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.frinfo_c(frcode, ctypes.byref(cent), ctypes.byref(frclss),\n                      ctypes.byref(clssid), ctypes.byref(found))\n    return cent.value, frclss.value, clssid.value, bool(found.value)", "response": "Return the attributes of a specific frame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the name of a reference frame associated with a SPICE ID code.", "response": "def frmnam(frcode, lenout=_default_len_out):\n    \"\"\"\n    Retrieve the name of a reference frame associated with a SPICE ID code.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/frmnam_c.html\n\n    :param frcode: an integer code for a reference frame\n    :type frcode: int\n    :param lenout: Maximum length of output string.\n    :type lenout: int\n    :return: the name associated with the reference frame.\n    :rtype: str\n    \"\"\"\n    frcode = ctypes.c_int(frcode)\n    lenout = ctypes.c_int(lenout)\n    frname = stypes.stringToCharP(lenout)\n    libspice.frmnam_c(frcode, lenout, frname)\n    return stypes.toPythonString(frname)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads one or more SPICE kernels into a program.", "response": "def furnsh(path):\n    \"\"\"\n    Load one or more SPICE kernels into a program.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/furnsh_c.html\n\n    :param path: one or more paths to kernels\n    :type path: str or list of str\n    \"\"\"\n    if isinstance(path, list):\n        for p in path:\n            libspice.furnsh_c(stypes.stringToCharP(p))\n    else:\n        path = stypes.stringToCharP(path)\n        libspice.furnsh_c(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gcpool(name, start, room, lenout=_default_len_out):\n    name = stypes.stringToCharP(name)\n    start = ctypes.c_int(start)\n    room = ctypes.c_int(room)\n    lenout = ctypes.c_int(lenout)\n    n = ctypes.c_int()\n    cvals = stypes.emptyCharArray(lenout, room)\n    found = ctypes.c_int()\n    libspice.gcpool_c(name, start, room, lenout, ctypes.byref(n),\n                      ctypes.byref(cvals), ctypes.byref(found))\n    return [stypes.toPythonString(x.value) for x in\n            cvals[0:n.value]], bool(found.value)", "response": "Return the character value of a kernel variable from the kernel pool."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gdpool(name, start, room):\n    name = stypes.stringToCharP(name)\n    start = ctypes.c_int(start)\n    values = stypes.emptyDoubleVector(room)\n    room = ctypes.c_int(room)\n    n = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.gdpool_c(name, start, room, ctypes.byref(n),\n                      ctypes.cast(values, ctypes.POINTER(ctypes.c_double)),\n                      ctypes.byref(found))\n    return stypes.cVectorToPython(values)[0:n.value], bool(found.value)", "response": "Return the d. p. value of a kernel variable from the kernel pool."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting geodetic coordinates to rectangular coordinates.", "response": "def georec(lon, lat, alt, re, f):\n    \"\"\"\n    Convert geodetic coordinates to rectangular coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/georec_c.html\n\n    :param lon: Geodetic longitude of point (radians).\n    :type lon: float\n    :param lat: Geodetic latitude  of point (radians).\n    :type lat: float\n    :param alt: Altitude of point above the reference spheroid.\n    :type alt: float\n    :param re: Equatorial radius of the reference spheroid.\n    :type re: float\n    :param f: Flattening coefficient.\n    :type f: float\n    :return: Rectangular coordinates of point.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    lon = ctypes.c_double(lon)\n    lat = ctypes.c_double(lat)\n    alt = ctypes.c_double(alt)\n    re = ctypes.c_double(re)\n    f = ctypes.c_double(f)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.georec_c(lon, lat, alt, re, f, rectan)\n    return stypes.cVectorToPython(rectan)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getelm(frstyr, lineln, lines):\n    frstyr = ctypes.c_int(frstyr)\n    lineln = ctypes.c_int(lineln)\n    lines = stypes.listToCharArrayPtr(lines, xLen=lineln, yLen=2)\n    epoch = ctypes.c_double()\n    elems = stypes.emptyDoubleVector(10)  # guess for length\n    libspice.getelm_c(frstyr, lineln, lines, ctypes.byref(epoch), elems)\n    return epoch.value, stypes.cVectorToPython(elems)", "response": "Given a set of lines of a two - line element set parse the lines and return the elements in units suitable for use\n    in SPICE software."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the architecture and file type of the most SPICE kernel file.", "response": "def getfat(file):\n    \"\"\"\n    Determine the file architecture and file type of most SPICE kernel files.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/getfat_c.html\n\n    :param file: The name of a file to be examined.\n    :type file: str\n    :return: The architecture of the kernel file, The type of the kernel file.\n    :rtype: tuple\n    \"\"\"\n    file = stypes.stringToCharP(file)\n    arclen = ctypes.c_int(4)\n    typlen = ctypes.c_int(4)\n    arch = stypes.stringToCharP(arclen)\n    rettype = stypes.stringToCharP(typlen)\n    libspice.getfat_c(file, arclen, typlen, arch, rettype)\n    return stypes.toPythonString(arch), stypes.toPythonString(rettype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the current short error message or the long error message.", "response": "def getmsg(option, lenout=_default_len_out):\n    \"\"\"\n    Retrieve the current short error message,\n    the explanation of the short error message, or the\n    long error message.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/getmsg_c.html\n\n    :param option: Indicates type of error message.\n    :type option: str\n    :param lenout: Available space in the output string msg.\n    :type lenout: int\n    :return: The error message to be retrieved.\n    :rtype: str\n    \"\"\"\n    option = stypes.stringToCharP(option)\n    lenout = ctypes.c_int(lenout)\n    msg = stypes.stringToCharP(lenout)\n    libspice.getmsg_c(option, lenout, msg)\n    return stypes.toPythonString(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gfdist(target, abcorr, obsrvr, relate, refval, adjust, step, nintvls,\n           cnfine, result=None):\n    \"\"\"\n    Return the time window over which a specified constraint on\n    observer-target distance is met.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfdist_c.html\n\n    :param target: Name of the target body.\n    :type target: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param relate: Relational operator.\n    :type relate: str\n    :param refval: Reference value.\n    :type refval: float\n    :param adjust: Adjustment value for absolute extrema searches.\n    :type adjust: float\n    :param step: Step size used for locating extrema and roots.\n    :type step: float\n    :param nintvls: Workspace window interval count.\n    :type nintvls: int\n    :param cnfine: SPICE window to which the search is confined.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    target = stypes.stringToCharP(target)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step = ctypes.c_double(step)\n    nintvls = ctypes.c_int(nintvls)\n    libspice.gfdist_c(target, abcorr, obsrvr, relate, refval, adjust,\n                      step, nintvls, ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "Return the time window over which a specified constraint on the target body is met."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gfevnt(udstep, udrefn, gquant, qnpars, lenvals, qpnams,\n           qcpars, qdpars, qipars, qlpars, op, refval,\n           tol, adjust, rpt, udrepi, udrepu, udrepf,\n           nintvls, bail, udbail, cnfine, result=None):\n    \"\"\"\n    Determine time intervals when a specified geometric quantity\n    satisfies a specified mathematical condition.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfevnt_c.html\n\n    :param udstep: Name of the routine that computes and returns a\n    :type udstep: spiceypy.utils.callbacks.UDSTEP\n    :param udrefn: Name of the routine that computes a refined time\n    :type udrefn: spiceypy.utils.callbacks.UDREFN\n    :param gquant: Type of geometric quantity\n    :type gquant: str\n    :param qnpars: Number of quantity definition parameters\n    :type qnpars: int\n    :param lenvals: Length of strings in qpnams and qcpars\n    :type lenvals: int\n    :param qpnams: Names of quantity definition parameters\n    :type qpnams: List\n    :param qcpars: Array of character quantity definition parameters\n    :type qcpars: List\n    :param qdpars: Array of double precision quantity definition\n    :type qdpars: N-Element Array of floats\n    :param qipars: Array of integer quantity definition parameters\n    :type qipars: N-Element Array of str\n    :param qlpars: Array of logical quantity definition parameters\n    :type qlpars: N-Element Array of int\n    :param op: Operator that either looks for an extreme value\n    :type op: str\n    :param refval: Reference value\n    :type refval: float\n    :param tol: Convergence tolerance in seconds\n    :type tol: float\n    :param adjust: Absolute extremum adjustment value\n    :type adjust: float\n    :param rpt: Progress reporter on TRUE or off FALSE\n    :type rpt: int\n    :param udrepi: Function that initializes progress reporting\n    :type udrepi: spiceypy.utils.callbacks.UDREPI\n    :param udrepu: Function that updates the progress report\n    :type udrepu: spiceypy.utils.callbacks.UDREPU\n    :param udrepf: Function that finalizes progress reporting\n    :type udrepf: spiceypy.utils.callbacks.UDREPF\n    :param nintvls: Workspace window interval count\n    :type nintvls: int\n    :param bail: Logical indicating program interrupt monitoring\n    :type bail: int\n    :param udbail: Name of a routine that signals a program interrupt\n    :type udbail: spiceypy.utils.callbacks.UDBAIL\n    :param cnfine: SPICE window to which the search is restricted\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    gquant  = stypes.stringToCharP(gquant)\n    qnpars  = ctypes.c_int(qnpars)\n    lenvals = ctypes.c_int(lenvals)\n    qpnams  = stypes.listToCharArrayPtr(qpnams, xLen=lenvals, yLen=qnpars)\n    qcpars  = stypes.listToCharArrayPtr(qcpars, xLen=lenvals, yLen=qnpars)\n    qdpars  = stypes.toDoubleVector(qdpars)\n    qipars  = stypes.toIntVector(qipars)\n    qlpars  = stypes.toIntVector(qlpars)\n    op      = stypes.stringToCharP(op)\n    refval  = ctypes.c_double(refval)\n    tol     = ctypes.c_double(tol)\n    adjust  = ctypes.c_double(adjust)\n    rpt     = ctypes.c_int(rpt)\n    nintvls = ctypes.c_int(nintvls)\n    bail    = ctypes.c_int(bail)\n    libspice.gfevnt_c(udstep, udrefn, gquant, qnpars, lenvals, qpnams, qcpars,\n                      qdpars, qipars, qlpars, op, refval, tol,\n                      adjust, rpt, udrepi, udrepu, udrepf, nintvls, bail,\n                      udbail, ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "This routine computes a refined time series of geometric quantity and returns a time series of time intervals when a specified geometric quantity satisfies a specified mathematical condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gffove(inst, tshape, raydir, target, tframe, abcorr, obsrvr,\n           tol, udstep, udrefn, rpt, udrepi, udrepu, udrepf, bail, udbail, cnfine, result=None):\n    \"\"\"\n    Determine time intervals when a specified target body or ray\n    intersects the space bounded by the field-of-view (FOV) of a\n    specified instrument. Report progress and handle interrupts if so\n    commanded.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gffove_c.html\n\n    :param inst: Name of the instrument\n    :type inst: str\n    :param tshape: Type of shape model used for target body\n    :type tshape: str\n    :param raydir: Ray s direction vector\n    :type raydir: N-Element Array of floats\n    :param target: Name of the target body\n    :type target: str\n    :param tframe: Body fixed body centered frame for target body\n    :type tframe: str\n    :param abcorr: Aberration correction flag\n    :type abcorr: str\n    :param obsrvr: Name of the observing body\n    :type obsrvr: str\n    :param tol: Convergence tolerance in seconds\n    :type tol: float\n    :param udstep: Name of the routine that returns a time step\n    :type udstep: spiceypy.utils.callbacks.UDSTEP\n    :param udrefn: Name of the routine that computes a refined time\n    :type udrefn: spiceypy.utils.callbacks.UDREFN\n    :param rpt:  Progress report flag\n    :type rpt: bool\n    :param udrepi: Function that initializes progress reporting.\n    :type udrepi: spiceypy.utils.callbacks.UDREP\n    :param udrepu: Function that updates the progress report\n    :type udrepu: spiceypy.utils.callbacks.UDREPU\n    :param udrepf: Function that finalizes progress reporting\n    :type udrepf: spiceypy.utils.callbacks.UDREPF\n    :param bail: Logical indicating program interrupt monitoring\n    :type bail: bool\n    :param udbail: Name of a routine that signals a program interrupt\n    :type udbail: spiceypy.utils.callbacks.UDBAIL\n    :param cnfine: SPICE window to which the search is restricted\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    inst = stypes.stringToCharP(inst)\n    tshape = stypes.stringToCharP(tshape)\n    raydir = stypes.toDoubleVector(raydir)\n    target = stypes.stringToCharP(target)\n    tframe = stypes.stringToCharP(tframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    tol = ctypes.c_double(tol)\n    rpt = ctypes.c_int(rpt)\n    bail = ctypes.c_int(bail)\n    libspice.gffove_c(inst, tshape, raydir, target, tframe,\n                      abcorr, obsrvr, tol, udstep, udrefn, rpt,\n                      udrepi, udrepu, udrepf, bail, udbail,\n                      ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "This function calculates the time intervals when a specified target body or rays intersect the space bounded by the field - of - view FOFV of the specified instrument."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the time window over which a specified constraint on the observed phase, solar incidence, or emission angle at a specifed target body surface point is met. :param method: Shape model used to represent the surface of the target body. :type method: str :param angtyp: The type of illumination angle for which a search is to be performed. :type angtyp: str :param target: Name of a target body. :type target: str :param illumn: Name of the illumination source. :type illumn: str :param fixref: Name of the body-fixed, body-centered reference frame associated with the target body. :type fixref: str :param abcorr: The aberration corrections to be applied. :type abcorr: str :param obsrvr: Name of an observing body. :type obsrvr: str :param spoint: Body-fixed coordinates of a target surface point. :type spoint: 3-Element Array of floats :param relate: Relational operator used to define a constraint on a specified illumination angle. :type relate: str :param refval: Reference value used with 'relate' to define an equality or inequality to be satisfied by the specified illumination angle. :type refval: float :param adjust: Parameter used to modify searches for absolute extrema. :type adjust: float :param step: Step size to be used in the search. :type step: float :param nintvls: Number of intervals that can be accommodated by each of the dynamically allocated workspace windows used internally by this routine. :type nintvls: int :param cnfine: Window that confines the time period over which the specified search is conducted. This can be updated by gfilum :type cnfine: spiceypy.utils.support_types.SpiceCell :param result: Optional SPICE Window of intervals in the confinement window that the illumination angle constraint is satisfied. :type result: spiceypy.utils.support_types.SpiceCell", "response": "def gfilum(method, angtyp, target, illumn,\n           fixref, abcorr, obsrvr, spoint,\n           relate, refval, adjust, step, nintvls, cnfine, result=None):\n    \"\"\"\n    Return the time window over which a specified constraint on\n    the observed phase, solar incidence, or emission angle at\n    a specifed target body surface point is met.\n\n    :param method: Shape model used to represent the surface of the target body.\n    :type method: str\n    :param angtyp: The type of illumination angle for which a search is to be performed.\n    :type angtyp: str\n    :param target: Name of a target body.\n    :type target: str\n    :param illumn: Name of the illumination source.\n    :type illumn: str\n    :param fixref: Name of the body-fixed, body-centered reference frame associated with the target body.\n    :type fixref: str\n    :param abcorr: The aberration corrections to be applied.\n    :type abcorr: str\n    :param obsrvr: Name of an observing body.\n    :type obsrvr: str\n    :param spoint: Body-fixed coordinates of a target surface point.\n    :type spoint: 3-Element Array of floats\n    :param relate: Relational operator used to define a constraint on a specified illumination angle.\n    :type relate: str\n    :param refval: Reference value used with 'relate' to define an equality or inequality to be satisfied by the specified illumination angle.\n    :type refval: float\n    :param adjust: Parameter used to modify searches for absolute extrema.\n    :type adjust: float\n    :param step: Step size to be used in the search.\n    :type step: float\n    :param nintvls: Number of intervals that can be accommodated by each of the dynamically allocated workspace windows used internally by this routine.\n    :type nintvls: int\n    :param cnfine: Window that confines the time period over which the specified search is conducted. This can be updated by gfilum\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE Window of intervals in the confinement window that the illumination angle constraint is satisfied.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    method = stypes.stringToCharP(method)\n    angtyp = stypes.stringToCharP(angtyp)\n    target = stypes.stringToCharP(target)\n    illumn = stypes.stringToCharP(illumn)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.toDoubleVector(spoint)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step   = ctypes.c_double(step)\n    nintvls = ctypes.c_int(nintvls)\n    libspice.gfilum_c(method, angtyp, target, illumn,\n                      fixref, abcorr, obsrvr, spoint,\n                      relate, refval, adjust, step,\n                      nintvls, ctypes.byref(cnfine), ctypes.byref(result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gfocce(occtyp, front, fshape, fframe, back,\n           bshape, bframe, abcorr, obsrvr, tol,\n           udstep, udrefn, rpt, udrepi, udrepu,\n           udrepf, bail, udbail, cnfine, result=None):\n    \"\"\"\n    Determine time intervals when an observer sees one target\n    occulted by another. Report progress and handle interrupts\n    if so commanded.\n\n    The surfaces of the target bodies may be represented by triaxial\n    ellipsoids or by topographic data provided by DSK files.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfocce_c.html\n\n    :param occtyp: Type of occultation\n    :type occtyp: str\n    :param front: Name of body occulting the other\n    :type front: str\n    :param fshape: Type of shape model used for front body\n    :type fshape: str\n    :param fframe: Body fixed body centered frame for front body\n    :type fframe: str\n    :param back: Name of body occulted by the other\n    :type back: str\n    :param bshape: Type of shape model used for back body\n    :type bshape: str\n    :param bframe: Body fixed body centered frame for back body\n    :type bframe: str\n    :param abcorr: Aberration correction flag\n    :type abcorr: str\n    :param obsrvr: Name of the observing body\n    :type obsrvr: str\n    :param tol: Convergence tolerance in seconds\n    :type tol: float\n    :param udstep: Name of the routine that returns a time step\n    :type udstep: spiceypy.utils.callbacks.UDSTEP\n    :param udrefn: Name of the routine that computes a refined time\n    :type udrefn: spiceypy.utils.callbacks.UDREFN\n    :param rpt: Progress report flag\n    :type rpt: bool\n    :param udrepi: Function that initializes progress reporting.\n    :type udrepi: spiceypy.utils.callbacks.UDREP\n    :param udrepu: Function that updates the progress report\n    :type udrepu: spiceypy.utils.callbacks.UDREPU\n    :param udrepf: Function that finalizes progress reporting\n    :type udrepf: spiceypy.utils.callbacks.UDREPF\n    :param bail: Logical indicating program interrupt monitoring\n    :type bail: bool\n    :param udbail: Name of a routine that signals a program interrupt\n    :type udbail: spiceypy.utils.callbacks.UDBAIL\n    :param cnfine: SPICE window to which the search is restricted\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    occtyp = stypes.stringToCharP(occtyp)\n    front = stypes.stringToCharP(front)\n    fshape = stypes.stringToCharP(fshape)\n    fframe = stypes.stringToCharP(fframe)\n    back = stypes.stringToCharP(back)\n    bshape = stypes.stringToCharP(bshape)\n    bframe = stypes.stringToCharP(bframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    tol = ctypes.c_double(tol)\n    rpt = ctypes.c_int(rpt)\n    bail = ctypes.c_int(bail)\n    libspice.gfocce_c(occtyp, front, fshape, fframe, back,\n                      bshape, bframe, abcorr, obsrvr, tol,\n                      udstep, udrefn, rpt, udrepi, udrepu, udrepf,\n                      bail, udbail, ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "This function is used to determine time intervals when an observer sees one target and another."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gfoclt(occtyp, front, fshape, fframe, back, bshape, bframe, abcorr, obsrvr,\n           step, cnfine, result=None):\n    \"\"\"\n    Determine time intervals when an observer sees one target\n    occulted by, or in transit across, another.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfoclt_c.html\n\n    :param occtyp: Type of occultation.\n    :type occtyp: str\n    :param front: Name of body occulting the other.\n    :type front: str\n    :param fshape: Type of shape model used for front body.\n    :type fshape: str\n    :param fframe: Body-fixed, body-centered frame for front body.\n    :type fframe: str\n    :param back: Name of body occulted by the other.\n    :type back: str\n    :param bshape: Type of shape model used for back body.\n    :type bshape: str\n    :param bframe: Body-fixed, body-centered frame for back body.\n    :type bframe: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param step: Step size in seconds for finding occultation events.\n    :type step: float\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    occtyp = stypes.stringToCharP(occtyp)\n    front = stypes.stringToCharP(front)\n    fshape = stypes.stringToCharP(fshape)\n    fframe = stypes.stringToCharP(fframe)\n    back = stypes.stringToCharP(back)\n    bshape = stypes.stringToCharP(bshape)\n    bframe = stypes.stringToCharP(bframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    step = ctypes.c_double(step)\n    libspice.gfoclt_c(occtyp, front, fshape, fframe, back, bshape, bframe,\n                      abcorr, obsrvr, step, ctypes.byref(cnfine),\n                      ctypes.byref(result))\n    return result", "response": "This function returns a time interval that is used to find occultations in a target segment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the time intervals for which a specified constraint on the phase angle between an illumination source a target body and an observer body centers is met.", "response": "def gfpa(target, illmin, abcorr, obsrvr, relate, refval, adjust, step, nintvals,\n         cnfine, result=None):\n    \"\"\"\n    Determine time intervals for which a specified constraint\n    on the phase angle between an illumination source, a target,\n    and observer body centers is met.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfpa_c.html\n\n    :param target: Name of the target body.\n    :type target: str\n    :param illmin: Name of the illuminating body.\n    :type illmin: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param relate: Relational operator.\n    :type relate: str\n    :param refval: Reference value.\n    :type refval: float\n    :param adjust: Adjustment value for absolute extrema searches.\n    :type adjust: float\n    :param step: Step size used for locating extrema and roots.\n    :type step: float\n    :param nintvals: Workspace window interval count.\n    :type nintvals: int\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    target = stypes.stringToCharP(target)\n    illmin = stypes.stringToCharP(illmin)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step = ctypes.c_double(step)\n    nintvals = ctypes.c_int(nintvals)\n    libspice.gfpa_c(target, illmin, abcorr, obsrvr, relate, refval,\n                    adjust, step, nintvals, ctypes.byref(cnfine),\n                    ctypes.byref(result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gfposc(target, inframe, abcorr, obsrvr, crdsys, coord, relate, refval,\n           adjust, step, nintvals, cnfine, result=None):\n    \"\"\"\n    Determine time intervals for which a coordinate of an\n    observer-target position vector satisfies a numerical constraint.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfposc_c.html\n\n    :param target: Name of the target body.\n    :type target: str\n    :param inframe: Name of the reference frame for coordinate calculations.\n    :type inframe: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param crdsys: Name of the coordinate system containing COORD\n    :type crdsys: str\n    :param coord: Name of the coordinate of interest\n    :type coord: str\n    :param relate: Relational operator.\n    :type relate: str\n    :param refval: Reference value.\n    :type refval: float\n    :param adjust: Adjustment value for absolute extrema searches.\n    :type adjust: float\n    :param step: Step size used for locating extrema and roots.\n    :type step: float\n    :param nintvals: Workspace window interval count.\n    :type nintvals: int\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    target = stypes.stringToCharP(target)\n    inframe = stypes.stringToCharP(inframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    crdsys = stypes.stringToCharP(crdsys)\n    coord = stypes.stringToCharP(coord)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step = ctypes.c_double(step)\n    nintvals = ctypes.c_int(nintvals)\n    libspice.gfposc_c(target, inframe, abcorr, obsrvr, crdsys, coord,\n                      relate, refval, adjust, step, nintvals,\n                      ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "This function calculates the time intervals for which a coordinate vector satisfies a numerical constraint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gfrefn(t1, t2, s1, s2):\n    t1 = ctypes.c_double(t1)\n    t2 = ctypes.c_double(t2)\n    s1 = ctypes.c_int(s1)\n    s2 = ctypes.c_int(s2)\n    t = ctypes.c_double()\n    libspice.gfrefn_c(t1, t2, s1, s2, ctypes.byref(t))\n    return t.value", "response": "This function returns the next time at which we can do better."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gfrepi(window, begmss, endmss):\n    begmss = stypes.stringToCharP(begmss)\n    endmss = stypes.stringToCharP(endmss)\n    # don't do anything if we were given a pointer to a SpiceCell, like if we were in a callback\n    if not isinstance(window, ctypes.POINTER(stypes.SpiceCell)):\n        assert isinstance(window, stypes.SpiceCell)\n        assert window.is_double()\n        window = ctypes.byref(window)\n    libspice.gfrepi_c(window, begmss, endmss)", "response": "This entry point initializes a search progress report."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gfrepu(ivbeg, ivend, time):\n    ivbeg = ctypes.c_double(ivbeg)\n    ivend = ctypes.c_double(ivend)\n    time = ctypes.c_double(time)\n    libspice.gfrepu_c(ivbeg, ivend, time)", "response": "This function tells the progress reporting system how far a search has progressed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gfrfov(inst, raydir, rframe, abcorr, obsrvr, step, cnfine, result=None):\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    inst = stypes.stringToCharP(inst)\n    raydir = stypes.toDoubleVector(raydir)\n    rframe = stypes.stringToCharP(rframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    step = ctypes.c_double(step)\n    libspice.gfrfov_c(inst, raydir, rframe, abcorr, obsrvr, step,\n                      ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "Determine time intervals when a specified ray intersects the field - of - view of a specified instrument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine time intervals when the angular separation between the position vectors of two target bodies relative to an observer satisfies a numerical relationship. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfsep_c.html :param targ1: Name of first body. :type targ1: str :param shape1: Name of shape model describing the first body. :type shape1: str :param inframe1: The body-fixed reference frame of the first body. :type inframe1: str :param targ2: Name of second body. :type targ2: str :param shape2: Name of the shape model describing the second body. :type shape2: str :param inframe2: The body-fixed reference frame of the second body :type inframe2: str :param abcorr: Aberration correction flag :type abcorr: str :param obsrvr: Name of the observing body. :type obsrvr: str :param relate: Relational operator. :type relate: str :param refval: Reference value. :type refval: float :param adjust: Absolute extremum adjustment value. :type adjust: float :param step: Step size in seconds for finding angular separation events. :type step: float :param nintvals: Workspace window interval count. :type nintvals: int :param cnfine: SPICE window to which the search is restricted. :type cnfine: spiceypy.utils.support_types.SpiceCell :param result: Optional SPICE window containing results. :type result: spiceypy.utils.support_types.SpiceCell", "response": "def gfsep(targ1, shape1, inframe1, targ2, shape2, inframe2, abcorr, obsrvr,\n          relate, refval, adjust, step, nintvals, cnfine, result=None):\n    \"\"\"\n    Determine time intervals when the angular separation between\n    the position vectors of two target bodies relative to an observer\n    satisfies a numerical relationship.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfsep_c.html\n\n    :param targ1: Name of first body.\n    :type targ1: str\n    :param shape1: Name of shape model describing the first body.\n    :type shape1: str\n    :param inframe1: The body-fixed reference frame of the first body.\n    :type inframe1: str\n    :param targ2: Name of second body.\n    :type targ2: str\n    :param shape2: Name of the shape model describing the second body.\n    :type shape2: str\n    :param inframe2: The body-fixed reference frame of the second body\n    :type inframe2: str\n    :param abcorr: Aberration correction flag\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param relate: Relational operator.\n    :type relate: str\n    :param refval: Reference value.\n    :type refval: float\n    :param adjust: Absolute extremum adjustment value.\n    :type adjust: float\n    :param step: Step size in seconds for finding angular separation events.\n    :type step: float\n    :param nintvals: Workspace window interval count.\n    :type nintvals: int\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    targ1 = stypes.stringToCharP(targ1)\n    shape1 = stypes.stringToCharP(shape1)\n    inframe1 = stypes.stringToCharP(inframe1)\n    targ2 = stypes.stringToCharP(targ2)\n    shape2 = stypes.stringToCharP(shape2)\n    inframe2 = stypes.stringToCharP(inframe2)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step = ctypes.c_double(step)\n    nintvals = ctypes.c_int(nintvals)\n    libspice.gfsep_c(targ1, shape1, inframe1, targ2, shape2, inframe2,\n                     abcorr, obsrvr, relate, refval, adjust, step, nintvals,\n                     ctypes.byref(cnfine), ctypes.byref(result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining time intervals for which a coordinate of an surface intercept position vector satisfies a numerical constraint. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfsntc_c.html :param target: Name of the target body. :type target: str :param fixref: Body fixed frame associated with the target. :type fixref: str :param method: Name of method type for surface intercept calculation. :type method: str :param abcorr: Aberration correction flag :type abcorr: str :param obsrvr: Name of the observing body. :type obsrvr: str :param dref: Reference frame of direction vector of dvec. :type dref: str :param dvec: Pointing direction vector from the observer. :type dvec: 3-Element Array of floats :param crdsys: Name of the coordinate system containing COORD. :type crdsys: str :param coord: Name of the coordinate of interest :type coord: str :param relate: Relational operator. :type relate: str :param refval: Reference value. :type refval: float :param adjust: Absolute extremum adjustment value. :type adjust: float :param step: Step size in seconds for finding angular separation events. :type step: float :param nintvals: Workspace window interval count. :type nintvals: int :param cnfine: SPICE window to which the search is restricted. :type cnfine: spiceypy.utils.support_types.SpiceCell :param result: Optional SPICE window containing results. :type result: spiceypy.utils.support_types.SpiceCell", "response": "def gfsntc(target, fixref, method, abcorr, obsrvr, dref, dvec, crdsys, coord,\n           relate, refval, adjust, step, nintvals,\n           cnfine, result=None):\n    \"\"\"\n    Determine time intervals for which a coordinate of an\n    surface intercept position vector satisfies a numerical constraint.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfsntc_c.html\n\n    :param target: Name of the target body.\n    :type target: str\n    :param fixref: Body fixed frame associated with the target.\n    :type fixref: str\n    :param method: Name of method type for surface intercept calculation.\n    :type method: str\n    :param abcorr: Aberration correction flag\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param dref: Reference frame of direction vector of dvec.\n    :type dref: str\n    :param dvec: Pointing direction vector from the observer.\n    :type dvec: 3-Element Array of floats\n    :param crdsys: Name of the coordinate system containing COORD.\n    :type crdsys: str\n    :param coord: Name of the coordinate of interest\n    :type coord: str\n    :param relate: Relational operator.\n    :type relate: str\n    :param refval: Reference value.\n    :type refval: float\n    :param adjust: Absolute extremum adjustment value.\n    :type adjust: float\n    :param step: Step size in seconds for finding angular separation events.\n    :type step: float\n    :param nintvals: Workspace window interval count.\n    :type nintvals: int\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    target = stypes.stringToCharP(target)\n    fixref = stypes.stringToCharP(fixref)\n    method = stypes.stringToCharP(method)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    dref = stypes.stringToCharP(dref)\n    dvec = stypes.toDoubleVector(dvec)\n    crdsys = stypes.stringToCharP(crdsys)\n    coord = stypes.stringToCharP(coord)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step = ctypes.c_double(step)\n    nintvals = ctypes.c_int(nintvals)\n    libspice.gfsntc_c(target, fixref, method, abcorr, obsrvr,\n                      dref, dvec, crdsys, coord, relate, refval,\n                      adjust, step, nintvals, ctypes.byref(cnfine),\n                      ctypes.byref(result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the time step set by the most recent call to gfstep_c.", "response": "def gfstep(time):\n    \"\"\"\n    Return the time step set by the most recent call to :func:`gfsstp`.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfstep_c.html\n\n    :param time: Ignored ET value.\n    :type time: float\n    :return: Time step to take.\n    :rtype: float\n    \"\"\"\n    time = ctypes.c_double(time)\n    step = ctypes.c_double()\n    libspice.gfstep_c(time, ctypes.byref(step))\n    return step.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gfsubc(target, fixref, method, abcorr, obsrvr, crdsys, coord, relate,\n           refval, adjust, step, nintvals, cnfine,\n           result):\n    \"\"\"\n    Determine time intervals for which a coordinate of an\n    subpoint position vector satisfies a numerical constraint.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfsubc_c.html\n\n    :param target: Name of the target body.\n    :type target: str\n    :param fixref: Body fixed frame associated with the target.\n    :type fixref: str\n    :param method: Name of method type for subpoint calculation.\n    :type method: str\n    :param abcorr: Aberration correction flag\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param crdsys: Name of the coordinate system containing COORD.\n    :type crdsys: str\n    :param coord: Name of the coordinate of interest\n    :type coord: str\n    :param relate: Relational operator.\n    :type relate: str\n    :param refval: Reference value.\n    :type refval: float\n    :param adjust: Adjustment value for absolute extrema searches.\n    :type adjust: float\n    :param step: Step size used for locating extrema and roots.\n    :type step: float\n    :param nintvals: Workspace window interval count.\n    :type nintvals: int\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: Optional SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(2000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    target = stypes.stringToCharP(target)\n    fixref = stypes.stringToCharP(fixref)\n    method = stypes.stringToCharP(method)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    crdsys = stypes.stringToCharP(crdsys)\n    coord = stypes.stringToCharP(coord)\n    relate = stypes.stringToCharP(relate)\n    refval = ctypes.c_double(refval)\n    adjust = ctypes.c_double(adjust)\n    step = ctypes.c_double(step)\n    nintvals = ctypes.c_int(nintvals)\n    libspice.gfsubc_c(target, fixref, method, abcorr, obsrvr, crdsys,\n                      coord, relate, refval, adjust, step, nintvals,\n                      ctypes.byref(cnfine), ctypes.byref(result))\n    return result", "response": "This function calculates the time intervals for which a coordinate of an anatomical subpoint vector satisfies a numerical constraint."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a SpiceCell containing the time intervals when a specified ephemeris object is visible within the field - of - view of the target body.", "response": "def gftfov(inst, target, tshape, tframe, abcorr, obsrvr, step, cnfine, result=None):\n    \"\"\"\n    Determine time intervals when a specified ephemeris object\n    intersects the space bounded by the field-of-view (FOV) of a\n    specified instrument.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gftfov_c.html\n\n    :param inst: Name of the instrument.\n    :type inst: str\n    :param target: Name of the target body.\n    :type target: str\n    :param tshape: Type of shape model used for target body.\n    :type tshape: str\n    :param tframe: Body-fixed, body-centered frame for target body.\n    :type tframe: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param obsrvr: Name of the observing body.\n    :type obsrvr: str\n    :param step: Step size in seconds for finding FOV events.\n    :type step: float\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :return: SpiceCell containing set of time  intervals, within the confinement period, when the target body is visible\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(cnfine, stypes.SpiceCell)\n    assert cnfine.is_double()\n    if result is None:\n        result = stypes.SPICEDOUBLE_CELL(20000)\n    else:\n        assert isinstance(result, stypes.SpiceCell)\n        assert result.is_double()\n    inst   = stypes.stringToCharP(inst)\n    target = stypes.stringToCharP(target)\n    tshape = stypes.stringToCharP(tshape)\n    tframe = stypes.stringToCharP(tframe)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    step = ctypes.c_double(step)\n    libspice.gftfov_c(inst, target, tshape, tframe, abcorr, obsrvr, step,\n                      ctypes.byref(cnfine), ctypes.byref(result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gfudb(udfuns, udfunb, step, cnfine, result):\n    step = ctypes.c_double(step)\n    libspice.gfudb_c(udfuns, udfunb, step, ctypes.byref(cnfine), ctypes.byref(result))", "response": "This routine is used to perform a GF search on a user defined boolean quantity."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a GF search on a user defined scalar quantity. https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfuds_c.html :param udfuns: Name of the routine that computes the scalar quantity of interest at some time. :type udfuns: ctypes.CFunctionType :param udqdec: Name of the routine that computes whether the scalar quantity is decreasing. :type udqdec: ctypes.CFunctionType :param relate: Operator that either looks for an extreme value (max, min, local, absolute) or compares the geometric quantity value and a number. :type relate: str :param refval: Value used as reference for scalar quantity condition. :type refval: float :param adjust: Allowed variation for absolute extremal geometric conditions. :type adjust: float :param step: Step size used for locating extrema and roots. :type step: float :param nintvls: Workspace window interval count. :type nintvls: int :param cnfine: SPICE window to which the search is restricted. :type cnfine: spiceypy.utils.support_types.SpiceCell :param result: SPICE window containing results. :type result: spiceypy.utils.support_types.SpiceCell :return: result :rtype: spiceypy.utils.support_types.SpiceCell", "response": "def gfuds(udfuns, udqdec, relate, refval, adjust, step, nintvls, cnfine, result):\n    \"\"\"\n    Perform a GF search on a user defined scalar quantity.\n\n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gfuds_c.html\n\n    :param udfuns: Name of the routine that computes the scalar quantity of interest at some time.\n    :type udfuns: ctypes.CFunctionType\n    :param udqdec: Name of the routine that computes whether the scalar quantity is decreasing.\n    :type udqdec: ctypes.CFunctionType\n    :param relate: Operator that either looks for an extreme value (max, min, local, absolute) or compares the geometric quantity value and a number.\n    :type relate: str\n    :param refval: Value used as reference for scalar quantity condition.\n    :type refval: float\n    :param adjust: Allowed variation for absolute extremal geometric conditions.\n    :type adjust: float\n    :param step: Step size used for locating extrema and roots.\n    :type step: float\n    :param nintvls: Workspace window interval count.\n    :type  nintvls: int\n    :param cnfine: SPICE window to which the search is restricted.\n    :type cnfine: spiceypy.utils.support_types.SpiceCell\n    :param result: SPICE window containing results.\n    :type result: spiceypy.utils.support_types.SpiceCell\n    :return: result\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    relate  = stypes.stringToCharP(relate)\n    refval  = ctypes.c_double(refval)\n    adjust  = ctypes.c_double(adjust)\n    step    = ctypes.c_double(step)\n    nintvls = ctypes.c_int(nintvls)\n    libspice.gfuds_c(udfuns, udqdec, relate, refval, adjust, step, nintvls, ctypes.byref(cnfine), ctypes.byref(result))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the integer value of a kernel variable from the kernel pool.", "response": "def gipool(name, start, room):\n    \"\"\"\n    Return the integer value of a kernel variable from the kernel pool.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/gipool_c.html\n\n    :param name: Name of the variable whose value is to be returned.\n    :type name: str\n    :param start: Which component to start retrieving for name.\n    :type start: int\n    :param room: The largest number of values to return.\n    :type room: int\n    :return: Values associated with name.\n    :rtype: list of int\n    \"\"\"\n    name = stypes.stringToCharP(name)\n    start = ctypes.c_int(start)\n    ivals = stypes.emptyIntVector(room)\n    room = ctypes.c_int(room)\n    n = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.gipool_c(name, start, room, ctypes.byref(n), ivals,\n                      ctypes.byref(found))\n    return stypes.cVectorToPython(ivals)[0:n.value], bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gnpool(name, start, room, lenout=_default_len_out):\n    name = stypes.stringToCharP(name)\n    start = ctypes.c_int(start)\n    kvars = stypes.emptyCharArray(yLen=room, xLen=lenout)\n    room = ctypes.c_int(room)\n    lenout = ctypes.c_int(lenout)\n    n = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.gnpool_c(name, start, room, lenout, ctypes.byref(n), kvars,\n                      ctypes.byref(found))\n    return stypes.cVectorToPython(kvars)[0:n.value], bool(found.value)", "response": "Return the names of kernel variables matching a specified template."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hrmint(xvals, yvals, x):\n    work  = stypes.emptyDoubleVector(int(2*len(yvals)+1))\n    n     = ctypes.c_int(len(xvals))\n    xvals = stypes.toDoubleVector(xvals)\n    yvals = stypes.toDoubleVector(yvals)\n    x     = ctypes.c_double(x)\n    f     = ctypes.c_double(0)\n    df    = ctypes.c_double(0)\n    libspice.hrmint_c(n, xvals, yvals, x, work, f, df)\n    return f.value, df.value", "response": "Evaluate a Hermite interpolating polynomial at a specified xvals and yvals."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hx2dp(string):\n    string = stypes.stringToCharP(string)\n    lenout = ctypes.c_int(80)\n    errmsg = stypes.stringToCharP(lenout)\n    number = ctypes.c_double()\n    error = ctypes.c_int()\n    libspice.hx2dp_c(string, lenout, ctypes.byref(number), ctypes.byref(error),\n                     errmsg)\n    if not error.value:\n        return number.value\n    else:\n        return stypes.toPythonString(errmsg)", "response": "Convert a string representing a double precision number in base 16 scientific notation into its equivalent double precision number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ident():\n    matrix = stypes.emptyDoubleMatrix()\n    libspice.ident_c(matrix)\n    return stypes.cMatrixToNumpy(matrix)", "response": "This routine returns the 3x3 identity matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef illumf(method, target, ilusrc, et, fixref, abcorr, obsrvr, spoint):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    ilusrc = stypes.stringToCharP(ilusrc)\n    et     = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.toDoubleVector(spoint)\n    trgepc = ctypes.c_double(0)\n    srfvec = stypes.emptyDoubleVector(3)\n    phase  = ctypes.c_double(0)\n    incdnc = ctypes.c_double(0)\n    emissn = ctypes.c_double(0)\n    visibl = ctypes.c_int()\n    lit    = ctypes.c_int()\n    libspice.illumf_c(method, target, ilusrc, et, fixref, abcorr, obsrvr, spoint,\n                      ctypes.byref(trgepc), srfvec, ctypes.byref(phase),\n                      ctypes.byref(incdnc), ctypes.byref(emissn),\n                      ctypes.byref(visibl), ctypes.byref(lit))\n    return trgepc.value, stypes.cVectorToPython(srfvec), \\\n           phase.value, incdnc.value, emissn.value, bool(visibl.value), bool(lit.value)", "response": "Compute the illumination angles phase incidence and emission angle at a specified point on a target body."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef illumg(method, target, ilusrc, et, fixref, abcorr, obsrvr, spoint):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    ilusrc = stypes.stringToCharP(ilusrc)\n    et     = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.toDoubleVector(spoint)\n    trgepc = ctypes.c_double(0)\n    srfvec = stypes.emptyDoubleVector(3)\n    phase  = ctypes.c_double(0)\n    incdnc = ctypes.c_double(0)\n    emissn = ctypes.c_double(0)\n    libspice.illumg_c(method, target, ilusrc, et, fixref, abcorr, obsrvr, spoint,\n                      ctypes.byref(trgepc), srfvec, ctypes.byref(phase),\n                      ctypes.byref(incdnc), ctypes.byref(emissn))\n    return trgepc.value, stypes.cVectorToPython(srfvec), \\\n           phase.value, incdnc.value, emissn.value", "response": "Find the illumination angles at a specified target body epoch vector source incidence vector and source surface point."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ilumin(method, target, et, fixref, abcorr, obsrvr, spoint):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    spoint = stypes.toDoubleVector(spoint)\n    trgepc = ctypes.c_double(0)\n    srfvec = stypes.emptyDoubleVector(3)\n    phase = ctypes.c_double(0)\n    solar = ctypes.c_double(0)\n    emissn = ctypes.c_double(0)\n    libspice.ilumin_c(method, target, et, fixref, abcorr, obsrvr, spoint,\n                      ctypes.byref(trgepc),\n                      srfvec, ctypes.byref(phase), ctypes.byref(solar),\n                      ctypes.byref(emissn))\n    return trgepc.value, stypes.cVectorToPython(\n            srfvec), phase.value, solar.value, emissn.value", "response": "This routine returns the illumination angles phase solar incidence and emission angles at a specified surface point."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the intersection of a triaxial ellipsoid and a plane.", "response": "def inedpl(a, b, c, plane):\n    \"\"\"\n    Find the intersection of a triaxial ellipsoid and a plane.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/inedpl_c.html\n\n    :param a: Length of ellipsoid semi-axis lying on the x-axis.\n    :type a: float\n    :param b: Length of ellipsoid semi-axis lying on the y-axis.\n    :type b: float\n    :param c: Length of ellipsoid semi-axis lying on the z-axis.\n    :type c: float\n    :param plane: Plane that intersects ellipsoid.\n    :type plane: spiceypy.utils.support_types.Plane\n    :return: Intersection ellipse.\n    :rtype: spiceypy.utils.support_types.Ellipse\n    \"\"\"\n    assert (isinstance(plane, stypes.Plane))\n    ellipse = stypes.Ellipse()\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    found = ctypes.c_int()\n    libspice.inedpl_c(a, b, c, ctypes.byref(plane), ctypes.byref(ellipse),\n                      ctypes.byref(found))\n    return ellipse, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inelpl(ellips, plane):\n    assert (isinstance(plane, stypes.Plane))\n    assert (isinstance(ellips, stypes.Ellipse))\n    nxpts = ctypes.c_int()\n    xpt1 = stypes.emptyDoubleVector(3)\n    xpt2 = stypes.emptyDoubleVector(3)\n    libspice.inelpl_c(ctypes.byref(ellips), ctypes.byref(plane),\n                      ctypes.byref(nxpts), xpt1, xpt2)\n    return nxpts.value, stypes.cVectorToPython(xpt1), stypes.cVectorToPython(xpt2)", "response": "Find the intersection of an ellipse and a plane."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the intersection of a ray and a plane.", "response": "def inrypl(vertex, direct, plane):\n    \"\"\"\n    Find the intersection of a ray and a plane.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/inrypl_c.html\n\n    :param vertex: Vertex vector of ray.\n    :type vertex: 3-Element Array of floats\n    :param direct: Direction vector of ray.\n    :type direct: 3-Element Array of floats\n    :param plane: A SPICE plane.\n    :type plane: spiceypy.utils.support_types.Plane\n    :return:\n            Number of intersection points of ray and plane,\n            Intersection point,\n            if nxpts == 1.\n    :rtype: tuple\n    \"\"\"\n    assert (isinstance(plane, stypes.Plane))\n    vertex = stypes.toDoubleVector(vertex)\n    direct = stypes.toDoubleVector(direct)\n    nxpts = ctypes.c_int()\n    xpt = stypes.emptyDoubleVector(3)\n    libspice.inrypl_c(vertex, direct, ctypes.byref(plane), ctypes.byref(nxpts),\n                      xpt)\n    return nxpts.value, stypes.cVectorToPython(xpt)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insrtc(item, inset):\n    assert isinstance(inset, stypes.SpiceCell)\n    if isinstance(item, list):\n        for c in item:\n            libspice.insrtc_c(stypes.stringToCharP(c), ctypes.byref(inset))\n    else:\n        item = stypes.stringToCharP(item)\n        libspice.insrtc_c(item, ctypes.byref(inset))", "response": "Insert an item into a character set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninserting an item into a double precision set.", "response": "def insrtd(item, inset):\n    \"\"\"\n    Insert an item into a double precision set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/insrtd_c.html\n\n    :param item: Item to be inserted.\n    :type item: Union[float,Iterable[float]]\n    :param inset: Insertion set.\n    :type inset: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(inset, stypes.SpiceCell)\n    if hasattr(item, \"__iter__\"):\n        for d in item:\n            libspice.insrtd_c(ctypes.c_double(d), ctypes.byref(inset))\n    else:\n        item = ctypes.c_double(item)\n        libspice.insrtd_c(item, ctypes.byref(inset))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insrti(item, inset):\n    assert isinstance(inset, stypes.SpiceCell)\n    if hasattr(item, \"__iter__\"):\n        for i in item:\n            libspice.insrti_c(ctypes.c_int(i), ctypes.byref(inset))\n    else:\n        item = ctypes.c_int(item)\n        libspice.insrti_c(item, ctypes.byref(inset))", "response": "Insert an item into an integer set."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the intersection of two sets of any data type to form a third set.", "response": "def inter(a, b):\n    \"\"\"\n    Intersect two sets of any data type to form a third set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/inter_c.html\n\n    :param a: First input set.\n    :type a: spiceypy.utils.support_types.SpiceCell\n    :param b: Second input set.\n    :type b: spiceypy.utils.support_types.SpiceCell\n    :return: Intersection of a and b.\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(a, stypes.SpiceCell)\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == b.dtype\n    # Next line was redundant with [raise NotImpImplementedError] below\n    # assert a.dtype == 0 or a.dtype == 1 or a.dtype == 2\n    if a.dtype is 0:\n        c = stypes.SPICECHAR_CELL(max(a.size, b.size), max(a.length, b.length))\n    elif a.dtype is 1:\n        c = stypes.SPICEDOUBLE_CELL(max(a.size, b.size))\n    elif a.dtype is 2:\n        c = stypes.SPICEINT_CELL(max(a.size, b.size))\n    else:\n        raise NotImplementedError\n    libspice.inter_c(ctypes.byref(a), ctypes.byref(b), ctypes.byref(c))\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef invert(m):\n    m = stypes.toDoubleMatrix(m)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.invert_c(m, mout)\n    return stypes.cMatrixToNumpy(mout)", "response": "Generate the inverse of a 3x3 matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a matrix, construct the matrix whose rows are the columns of the first divided by the length squared of the the corresponding columns of the input matrix. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/invort_c.html :param m: A 3x3 Matrix. :type m: 3x3-Element Array of floats :return: m after transposition and scaling of rows. :rtype: 3x3-Element Array of floats", "response": "def invort(m):\n    \"\"\"\n    Given a matrix, construct the matrix whose rows are the\n    columns of the first divided by the length squared of the\n    the corresponding columns of the input matrix.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/invort_c.html\n\n    :param m: A 3x3 Matrix.\n    :type m: 3x3-Element Array of floats\n    :return: m after transposition and scaling of rows.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    m = stypes.toDoubleMatrix(m)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.invort_c(m, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines whether an array of n items contains the integers 0 through n - 1.", "response": "def isordv(array, n):\n    \"\"\"\n    Determine whether an array of n items contains the integers\n    0 through n-1.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/isordv_c.html\n\n    :param array: Array of integers.\n    :type array: Array of ints\n    :param n: Number of integers in array.\n    :type n: int\n    :return:\n            The function returns True if the array contains the\n            integers 0 through n-1, otherwise it returns False.\n    :rtype: bool\n    \"\"\"\n    array = stypes.toIntVector(array)\n    n = ctypes.c_int(n)\n    return bool(libspice.isordv_c(array, n))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for a given value within a character string array. Return - 1 if the value is not found.", "response": "def isrchc(value, ndim, lenvals, array):\n    \"\"\"\n    Search for a given value within a character string array. Return\n    the index of the first matching array entry, or -1 if the key\n    value was not found.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/isrchc_c.html\n\n    :param value: Key value to be found in array.\n    :type value: str\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param lenvals: String length.\n    :type lenvals: int\n    :param array: Character string array to search.\n    :type array: list of str\n    :return:\n            The index of the first matching array element or -1\n            if the value is not found.\n    :rtype: int\n    \"\"\"\n    value = stypes.stringToCharP(value)\n    array = stypes.listToCharArrayPtr(array, xLen=lenvals, yLen=ndim)\n    ndim = ctypes.c_int(ndim)\n    lenvals = ctypes.c_int(lenvals)\n    return libspice.isrchc_c(value, ndim, lenvals, array)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch for a given value within a double precision array.", "response": "def isrchd(value, ndim, array):\n    \"\"\"\n    Search for a given value within a double precision array. Return\n    the index of the first matching array entry, or -1 if the key value\n    was not found.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/isrchd_c.html\n\n    :param value: Key value to be found in array.\n    :type value: float\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param array: Double Precision array to search.\n    :type array: Array of floats\n    :return:\n            The index of the first matching array element or -1\n            if the value is not found.\n    :rtype: int\n    \"\"\"\n    value = ctypes.c_double(value)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toDoubleVector(array)\n    return libspice.isrchd_c(value, ndim, array)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for a given value within an integer array.", "response": "def isrchi(value, ndim, array):\n    \"\"\"\n    Search for a given value within an integer array. Return\n    the index of the first matching array entry, or -1 if the key\n    value was not found.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/isrchi_c.html\n\n    :param value: Key value to be found in array.\n    :type value: int\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param array: Integer array to search.\n    :type array: Array of ints\n    :return:\n            The index of the first matching array element or -1\n            if the value is not found.\n    :rtype: int\n    \"\"\"\n    value = ctypes.c_int(value)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toIntVector(array)\n    return libspice.isrchi_c(value, ndim, array)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isrot(m, ntol, dtol):\n    m = stypes.toDoubleMatrix(m)\n    ntol = ctypes.c_double(ntol)\n    dtol = ctypes.c_double(dtol)\n    return bool(libspice.isrot_c(m, ntol, dtol))", "response": "Indicate whether a 3x3 matrix is a rotation matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a boolean value indicating whether a string contains only white space characters.", "response": "def iswhsp(string):\n    \"\"\"\n    Return a boolean value indicating whether a string contains\n    only white space characters.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/iswhsp_c.html\n\n    :param string: String to be tested.\n    :type string: str\n    :return:\n            the boolean value True if the string is empty or contains\n            only white space characters; otherwise it returns the value False.\n    :rtype: bool\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    return bool(libspice.iswhsp_c(string))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kdata(which, kind, fillen=_default_len_out, typlen=_default_len_out, srclen=_default_len_out):\n    which = ctypes.c_int(which)\n    kind = stypes.stringToCharP(kind)\n    fillen = ctypes.c_int(fillen)\n    typlen = ctypes.c_int(typlen)\n    srclen = ctypes.c_int(srclen)\n    file = stypes.stringToCharP(fillen)\n    filtyp = stypes.stringToCharP(typlen)\n    source = stypes.stringToCharP(srclen)\n    handle = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.kdata_c(which, kind, fillen, typlen, srclen, file, filtyp, source,\n                     ctypes.byref(handle), ctypes.byref(found))\n    return stypes.toPythonString(file), stypes.toPythonString(\n            filtyp), stypes.toPythonString(source), handle.value, bool(found.value)", "response": "Return data for the nth kernel that is among a list of specified kernel types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn information about a loaded kernel specified by name.", "response": "def kinfo(file, typlen=_default_len_out, srclen=_default_len_out):\n    \"\"\"\n    Return information about a loaded kernel specified by name.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/kinfo_c.html\n\n    :param file: Name of a kernel to fetch information for\n    :type file: str\n    :param typlen: Available space in output kernel type string.\n    :type typlen: int\n    :param srclen: Available space in output source string.\n    :type srclen: int\n    :return:\n            The type of the kernel,\n            Name of the source file used to load file,\n            The handle attached to file.\n    :rtype: tuple\n    \"\"\"\n    typlen = ctypes.c_int(typlen)\n    srclen = ctypes.c_int(srclen)\n    file = stypes.stringToCharP(file)\n    filtyp = stypes.stringToCharP(\" \" * typlen.value)\n    source = stypes.stringToCharP(\" \" * srclen.value)\n    handle = ctypes.c_int()\n    found = ctypes.c_int()\n    libspice.kinfo_c(file, typlen, srclen, filtyp, source, ctypes.byref(handle),\n                     ctypes.byref(found))\n    return stypes.toPythonString(filtyp), stypes.toPythonString(\n            source), handle.value, bool(found.value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a SPICE set containing the frame IDs of all reference frames of a given class.", "response": "def kplfrm(frmcls, outCell=None):\n    \"\"\"\n    Return a SPICE set containing the frame IDs of all reference\n    frames of a given class having specifications in the kernel pool.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/kplfrm_c.html\n\n    :param frmcls: Frame class.\n    :type frmcls: int\n    :param outCell: Optional output Spice Int Cell\n    :type outCell: spiceypy.utils.support_types.SpiceCell\n    :return: Set of ID codes of frames of the specified class.\n    :rtype: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    if not outCell:\n        outCell = stypes.SPICEINT_CELL(1000)\n    frmcls = ctypes.c_int(frmcls)\n    libspice.kplfrm_c(frmcls, ctypes.byref(outCell))\n    return outCell"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the current number of kernels that have been loaded by the KEEPER interface.", "response": "def ktotal(kind):\n    \"\"\"\n    Return the current number of kernels that have been loaded\n    via the KEEPER interface that are of a specified type.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ktotal_c.html\n\n    :param kind: A list of kinds of kernels to count.\n    :type kind: str\n    :return: The number of kernels of type kind.\n    :rtype: int\n    \"\"\"\n    kind = stypes.stringToCharP(kind)\n    count = ctypes.c_int()\n    libspice.ktotal_c(kind, ctypes.byref(count))\n    return count.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kxtrct(keywd, terms, nterms, instring, termlen=_default_len_out, stringlen=_default_len_out, substrlen=_default_len_out):\n    assert nterms <= len(terms)\n    # Python strings and string arrays => to C char pointers\n    keywd = stypes.stringToCharP(keywd)\n    terms = stypes.listToCharArrayPtr([s[:termlen-1] for s in terms[:nterms]],xLen=termlen,yLen=nterms)\n    instring = stypes.stringToCharP(instring[:stringlen-1],inlen=stringlen)\n    substr = stypes.stringToCharP(substrlen)\n    # Python ints => to C ints\n    termlen = ctypes.c_int(termlen)\n    nterms = ctypes.c_int(nterms)\n    stringlen = ctypes.c_int(stringlen)\n    substrlen = ctypes.c_int(substrlen)\n    found = ctypes.c_int()\n    libspice.kxtrct_c(keywd, termlen, terms, nterms,\n                      stringlen, substrlen, instring, ctypes.byref(found),\n                      substr)\n    return stypes.toPythonString(instring), stypes.toPythonString(\n            substr), bool(found.value)", "response": "Locate a keyword in a string and extract the substring from the beginning of the first subsequent recognized terminator of a list of words."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert from latitudinal coordinates to cylindrical coordinates.", "response": "def latcyl(radius, lon, lat):\n    \"\"\"\n    Convert from latitudinal coordinates to cylindrical coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/latcyl_c.html\n\n    :param radius: Distance of a point from the origin.\n    :type radius:\n    :param lon: Angle of the point from the XZ plane in radians.\n    :param lat: Angle of the point from the XY plane in radians.\n    :return: (r, lonc, z)\n    :rtype: tuple\n    \"\"\"\n    radius = ctypes.c_double(radius)\n    lon = ctypes.c_double(lon)\n    lat = ctypes.c_double(lat)\n    r = ctypes.c_double()\n    lonc = ctypes.c_double()\n    z = ctypes.c_double()\n    libspice.latcyl_c(radius, lon, lat, ctypes.byref(r), ctypes.byref(lonc),\n                      ctypes.byref(z))\n    return r.value, lonc.value, z.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef latrec(radius, longitude, latitude):\n    radius = ctypes.c_double(radius)\n    longitude = ctypes.c_double(longitude)\n    latitude = ctypes.c_double(latitude)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.latrec_c(radius, longitude, latitude, rectan)\n    return stypes.cVectorToPython(rectan)", "response": "Convert from latitudinal coordinates to rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef latsph(radius, lon, lat):\n    radius = ctypes.c_double(radius)\n    lon = ctypes.c_double(lon)\n    lat = ctypes.c_double(lat)\n    rho = ctypes.c_double()\n    colat = ctypes.c_double()\n    lons = ctypes.c_double()\n    libspice.latsph_c(radius, lon, lat, ctypes.byref(rho), ctypes.byref(colat),\n                      ctypes.byref(lons))\n    return rho.value, colat.value, lons.value", "response": "Convert from latitudinal coordinates to spherical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef latsrf(method, target, et, fixref, lonlat):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    et     = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    npts   = ctypes.c_int(len(lonlat))\n    lonlat = stypes.toDoubleMatrix(lonlat)\n    srfpts = stypes.emptyDoubleMatrix(3, npts.value)\n    libspice.latsrf_c(method, target, et, fixref, npts, lonlat, srfpts)\n    return stypes.cMatrixToNumpy(srfpts)", "response": "Return the surface points of a specified target body at a specified epoch."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the characters in a string to lowercase.", "response": "def lcase(instr, lenout=_default_len_out):\n    \"\"\"\n    Convert the characters in a string to lowercase.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lcase_c.html\n\n    :param instr: Input string.\n    :type instr: str\n    :param lenout: Maximum length of output string.\n    :type lenout: int\n    :return: Output string, all lowercase.\n    :rtype: str\n    \"\"\"\n    instr = stypes.stringToCharP(instr)\n    lenout = ctypes.c_int(lenout)\n    outstr = stypes.stringToCharP(lenout)\n    libspice.lcase_c(instr, lenout, outstr)\n    return stypes.toPythonString(outstr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates a Lagrange interpolating polynomial for a specified set of coordinate pairs at a specified abscissa value.", "response": "def lgrind(xvals, yvals, x):\n    \"\"\"\n    Evaluate a Lagrange interpolating polynomial for a specified\n    set of coordinate pairs, at a specified abscissa value.\n    Return the value of both polynomial and derivative.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lgrind_c.html\n\n    :param xvals: Abscissa values.\n    :type xvals: N-Element Array of floats\n    :param yvals: Ordinate values.\n    :type yvals: N-Element Array of floats\n    :param x: Point at which to interpolate the polynomial.\n    :type x: float\n    :return: Polynomial value at x, Polynomial derivative at x.\n    :rtype: tuple\n    \"\"\"\n    n = ctypes.c_int(len(xvals))\n    xvals = stypes.toDoubleVector(xvals)\n    yvals = stypes.toDoubleVector(yvals)\n    work  = stypes.emptyDoubleVector(n.value*2)\n    x  = ctypes.c_double(x)\n    p  = ctypes.c_double(0)\n    dp = ctypes.c_double(0)\n    libspice.lgrind_c(n, xvals, yvals, work, x, p, dp)\n    return p.value, dp.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lmpool(cvals):\n    lenvals = ctypes.c_int(len(max(cvals, key=len)) + 1)\n    n = ctypes.c_int(len(cvals))\n    cvals = stypes.listToCharArrayPtr(cvals, xLen=lenvals, yLen=n)\n    libspice.lmpool_c(cvals, lenvals, n)", "response": "Load the variables contained in an internal buffer into the kernel pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a list of items delimited by a single character.", "response": "def lparse(inlist, delim, nmax):\n    \"\"\"\n    Parse a list of items delimited by a single character.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lparse_c.html\n\n    :param inlist: list of items delimited by delim.\n    :type inlist: list\n    :param delim: Single character used to delimit items.\n    :type delim: str\n    :param nmax: Maximum number of items to return.\n    :type nmax: int\n    :return: Items in the list, left justified.\n    :rtype: list of str\n    \"\"\"\n    delim = stypes.stringToCharP(delim)\n    lenout = ctypes.c_int(len(inlist))\n    inlist = stypes.stringToCharP(inlist)\n    nmax = ctypes.c_int(nmax)\n    items = stypes.emptyCharArray(lenout, nmax)\n    n = ctypes.c_int()\n    libspice.lparse_c(inlist, delim, nmax, lenout, ctypes.byref(n),\n                      ctypes.byref(items))\n    return [stypes.toPythonString(x.value) for x in items[0:n.value]]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lparsm(inlist, delims, nmax, lenout=None):\n    if lenout is None:\n        lenout = ctypes.c_int(len(inlist) + 1)\n    else:\n        lenout = ctypes.c_int(lenout)\n    inlist = stypes.stringToCharP(inlist)\n    delims = stypes.stringToCharP(delims)\n    items = stypes.emptyCharArray(lenout.value, nmax)\n    nmax = ctypes.c_int(nmax)\n    n = ctypes.c_int()\n    libspice.lparsm_c(inlist, delims, nmax, lenout, ctypes.byref(n), items)\n    return [stypes.toPythonString(x.value) for x in items][0:n.value]", "response": "Parse a list of items separated by multiple delimiters and return a list of items in the list left justified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a list of items separated by multiple delimiters and return a set containing the items in the list that are left justified.", "response": "def lparss(inlist, delims, NMAX=20, LENGTH=50):\n    \"\"\"\n    Parse a list of items separated by multiple delimiters, placing the\n    resulting items into a set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lparss_c.html\n\n    :param inlist: list of items delimited by delims.\n    :type inlist:\n    :param delims: Single characters which delimit items.\n    :type delims: str\n    :param NMAX: Optional nmax of spice set.\n    :type NMAX: int\n    :param LENGTH: Optional length of strings in spice set\n    :type LENGTH: int\n    :return: Set containing items in the list, left justified.\n    :rtype:\n    \"\"\"\n    inlist = stypes.stringToCharP(inlist)\n    delims = stypes.stringToCharP(delims)\n    returnSet = stypes.SPICECHAR_CELL(NMAX, LENGTH)\n    libspice.lparss_c(inlist, delims, ctypes.byref(returnSet))\n    return returnSet"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lspcn(body, et, abcorr):\n    body = stypes.stringToCharP(body)\n    et = ctypes.c_double(et)\n    abcorr = stypes.stringToCharP(abcorr)\n    return libspice.lspcn_c(body, et, abcorr)", "response": "Compute L_s the planetocentric longitude of the sun as seen\n    from a specified body."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a character string and an ordered array of character strings find the index of the last element less than or equal to the given string.", "response": "def lstlec(string, n, lenvals, array):\n    \"\"\"\n    Given a character string and an ordered array of character\n    strings, find the index of the largest array element less than\n    or equal to the given string.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lstlec_c.html\n\n    :param string: Upper bound value to search against.\n    :type string: str\n    :param n: Number elements in array.\n    :type n: int\n    :param lenvals: String length.\n    :type lenvals: int\n    :param array: Array of possible lower bounds.\n    :type array: list\n    :return:\n            index of the last element of array that is\n            lexically less than or equal to string.\n    :rtype: int\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    array = stypes.listToCharArrayPtr(array, xLen=lenvals, yLen=n)\n    n = ctypes.c_int(n)\n    lenvals = ctypes.c_int(lenvals)\n    return libspice.lstlec_c(string, n, lenvals, array)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a number x and an array of non - decreasing floats find the index of the last element less than or equal to x.", "response": "def lstled(x, n, array):\n    \"\"\"\n    Given a number x and an array of non-decreasing floats\n    find the index of the largest array element less than or equal to x.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lstled_c.html\n\n    :param x: Value to search against.\n    :type x: float\n    :param n: Number elements in array.\n    :type n: int\n    :param array: Array of possible lower bounds\n    :type array: list\n    :return: index of the last element of array that is less than or equal to x.\n    :rtype: int\n    \"\"\"\n    array = stypes.toDoubleVector(array)\n    x = ctypes.c_double(x)\n    n = ctypes.c_int(n)\n    return libspice.lstled_c(x, n, array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a number x and an array of non - decreasing ints find the index of the last element less than or equal to x.", "response": "def lstlei(x, n, array):\n    \"\"\"\n    Given a number x and an array of non-decreasing ints,\n    find the index of the largest array element less than or equal to x.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lstlei_c.html\n\n    :param x: Value to search against.\n    :type x: int\n    :param n: Number elements in array.\n    :type n: int\n    :param array: Array of possible lower bounds\n    :type array: list\n    :return: index of the last element of array that is less than or equal to x.\n    :rtype: int\n    \"\"\"\n    array = stypes.toIntVector(array)\n    x = ctypes.c_int(x)\n    n = ctypes.c_int(n)\n    return libspice.lstlei_c(x, n, array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a character string and an ordered array of character strings find the index of the largest array element less than the given string.", "response": "def lstltc(string, n, lenvals, array):\n    \"\"\"\n    Given a character string and an ordered array of character\n    strings, find the index of the largest array element less than\n    the given string.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lstltc_c.html\n\n    :param string: Upper bound value to search against.\n    :type string: int\n    :param n: Number elements in array.\n    :type n: int\n    :param lenvals: String length.\n    :type lenvals: int\n    :param array: Array of possible lower bounds\n    :type array: list\n    :return:\n            index of the last element of array that\n            is lexically less than string.\n    :rtype: int\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    array = stypes.listToCharArrayPtr(array, xLen=lenvals, yLen=n)\n    n = ctypes.c_int(n)\n    lenvals = ctypes.c_int(lenvals)\n    return libspice.lstltc_c(string, n, lenvals, array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a number x and an array of non - decreasing floats find the index of the last element of the array that is less than x.", "response": "def lstltd(x, n, array):\n    \"\"\"\n    Given a number x and an array of non-decreasing floats\n    find the index of the largest array element less than x.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lstltd_c.html\n\n    :param x: Value to search against\n    :type x: float\n    :param n: Number elements in array\n    :type n: int\n    :param array: Array of possible lower bounds\n    :type array: list\n    :return: index of the last element of array that is less than x.\n    :rtype: int\n    \"\"\"\n    array = stypes.toDoubleVector(array)\n    x = ctypes.c_double(x)\n    n = ctypes.c_int(n)\n    return libspice.lstltd_c(x, n, array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a number x and an array of non - decreasing int n find the index of the last element of the array that is less than x.", "response": "def lstlti(x, n, array):\n    \"\"\"\n    Given a number x and an array of non-decreasing int,\n    find the index of the largest array element less than x.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lstlti_c.html\n\n    :param x: Value to search against\n    :type x: int\n    :param n: Number elements in array\n    :type n: int\n    :param array: Array of possible lower bounds\n    :type array: list\n    :return: index of the last element of array that is less than x.\n    :rtype: int\n    \"\"\"\n    array = stypes.toIntVector(array)\n    x = ctypes.c_int(x)\n    n = ctypes.c_int(n)\n    return libspice.lstlti_c(x, n, array)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ltime(etobs, obs, direct, targ):\n    etobs = ctypes.c_double(etobs)\n    obs = ctypes.c_int(obs)\n    direct = stypes.stringToCharP(direct)\n    targ = ctypes.c_int(targ)\n    ettarg = ctypes.c_double()\n    elapsd = ctypes.c_double()\n    libspice.ltime_c(etobs, obs, direct, targ, ctypes.byref(ettarg),\n                     ctypes.byref(elapsd))\n    return ettarg.value, elapsd.value", "response": "This routine computes the transmit time between receive and transmit objects at a specified target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscan a string from a specified starting position for the last decimal number.", "response": "def lx4dec(string, first):\n    \"\"\"\n    Scan a string from a specified starting position for the\n    end of a decimal number.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lx4dec_c.html\n\n    :param string: Any character string.\n    :type string: str\n    :param first: First character to scan from in string.\n    :type first: int\n    :return: last and nchar\n    :rtype: tuple\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    first = ctypes.c_int(first)\n    last = ctypes.c_int()\n    nchar = ctypes.c_int()\n    libspice.lx4dec_c(string, first, ctypes.byref(last), ctypes.byref(nchar))\n    return last.value, nchar.value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lx4num(string, first):\n    string = stypes.stringToCharP(string)\n    first = ctypes.c_int(first)\n    last = ctypes.c_int()\n    nchar = ctypes.c_int()\n    libspice.lx4num_c(string, first, ctypes.byref(last), ctypes.byref(nchar))\n    return last.value, nchar.value", "response": "Scan a string from a specified starting position for the last and nchar of a number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscanning a string from a specified starting position for the last and nchar of a signed integer.", "response": "def lx4sgn(string, first):\n    \"\"\"\n    Scan a string from a specified starting position for the\n    end of a signed integer.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/lx4sgn_c.html\n\n    :param string: Any character string.\n    :type string: str\n    :param first: First character to scan from in string.\n    :type first: int\n    :return: last and nchar\n    :rtype: tuple\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    first = ctypes.c_int(first)\n    last = ctypes.c_int()\n    nchar = ctypes.c_int()\n    libspice.lx4sgn_c(string, first, ctypes.byref(last), ctypes.byref(nchar))\n    return last.value, nchar.value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lx4uns(string, first):\n    string = stypes.stringToCharP(string)\n    first = ctypes.c_int(first)\n    last = ctypes.c_int()\n    nchar = ctypes.c_int()\n    libspice.lx4uns_c(string, first, ctypes.byref(last), ctypes.byref(nchar))\n    return last.value, nchar.value", "response": "Scan a string from a specified starting position for the last unsigned integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef lxqstr(string, qchar, first):\n    string = stypes.stringToCharP(string)\n    qchar = ctypes.c_char(qchar.encode(encoding='UTF-8'))\n    first = ctypes.c_int(first)\n    last = ctypes.c_int()\n    nchar = ctypes.c_int()\n    libspice.lxqstr_c(string, qchar, first, ctypes.byref(last),\n                      ctypes.byref(nchar))\n    return last.value, nchar.value", "response": "Lex ( scan ) a quoted string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfactoring a rotation matrix as a product of three rotations about specified coordinate axes.", "response": "def m2eul(r, axis3, axis2, axis1):\n    \"\"\"\n    Factor a rotation matrix as a product of three rotations\n    about specified coordinate axes.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/m2eul_c.html\n\n    :param r: A rotation matrix to be factored\n    :type r: 3x3-Element Array of floats\n    :param axis3: third rotation axes.\n    :type axis3: int\n    :param axis2: second rotation axes.\n    :type axis2: int\n    :param axis1: first rotation axes.\n    :type axis1: int\n    :return: Third, second, and first Euler angles, in radians.\n    :rtype: tuple\n    \"\"\"\n    r = stypes.toDoubleMatrix(r)\n    axis3 = ctypes.c_int(axis3)\n    axis2 = ctypes.c_int(axis2)\n    axis1 = ctypes.c_int(axis1)\n    angle3 = ctypes.c_double()\n    angle2 = ctypes.c_double()\n    angle1 = ctypes.c_double()\n    libspice.m2eul_c(r, axis3, axis2, axis1, ctypes.byref(angle3),\n                     ctypes.byref(angle2), ctypes.byref(angle1))\n    return angle3.value, angle2.value, angle1.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a unit quaternion corresponding to a specified rotation matrix.", "response": "def m2q(r):\n    \"\"\"\n    Find a unit quaternion corresponding to a specified rotation matrix.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/m2q_c.html\n\n    :param r: A rotation matrix to be factored\n    :type r: 3x3-Element Array of floats\n    :return: A unit quaternion representing the rotation matrix\n    :rtype: 4-Element Array of floats\n    \"\"\"\n    r = stypes.toDoubleMatrix(r)\n    q = stypes.emptyDoubleVector(4)\n    libspice.m2q_c(r, q)\n    return stypes.cVectorToPython(q)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef matchi(string, templ, wstr, wchr):\n    string = stypes.stringToCharP(string)\n    templ = stypes.stringToCharP(templ)\n    wstr = ctypes.c_char(wstr.encode(encoding='UTF-8'))\n    wchr = ctypes.c_char(wchr.encode(encoding='UTF-8'))\n    return bool(libspice.matchi_c(string, templ, wstr, wchr))", "response": "Return True if a string is matched by a template containing wild cards."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if a string is matched by a template containing wild cards.", "response": "def matchw(string, templ, wstr, wchr):\n    # ctypes.c_char(wstr.encode(encoding='UTF-8')\n    \"\"\"\n    Determine whether a string is matched by a template containing wild cards.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/matchw_c.html\n\n    :param string: String to be tested.\n    :type string: str\n    :param templ: Template (with wild cards) to test against string.\n    :type templ: str\n    :param wstr: Wild string token.\n    :type wstr: str of length 1\n    :param wchr: Wild character token.\n    :type wchr: str of length 1\n    :return: The function returns True if string matches templ, else False\n    :rtype: bool\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    templ = stypes.stringToCharP(templ)\n    wstr = ctypes.c_char(wstr.encode(encoding='UTF-8'))\n    wchr = ctypes.c_char(wchr.encode(encoding='UTF-8'))\n    return bool(libspice.matchw_c(string, templ, wstr, wchr))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset one double precision 3x3 matrix equal to another. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mequ_c.html :param m1: input matrix. :type m1: 3x3-Element Array of floats :return: Output matrix equal to m1. :rtype: 3x3-Element Array of floats", "response": "def mequ(m1):\n    \"\"\"\n    Set one double precision 3x3 matrix equal to another.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mequ_c.html\n\n    :param m1: input matrix.\n    :type m1: 3x3-Element Array of floats\n    :return: Output matrix equal to m1.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.mequ_c(m1, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset one double precision matrix of arbitrary size equal to another. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mequg_c.html :param m1: Input matrix. :type m1: NxM-Element Array of floats :param nr: Row dimension of m1. :type nr: int :param nc: Column dimension of m1. :type nc: int :return: Output matrix equal to m1 :rtype: NxM-Element Array of floats", "response": "def mequg(m1, nr, nc):\n    \"\"\"\n    Set one double precision matrix of arbitrary size equal to another.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mequg_c.html\n\n    :param m1: Input matrix.\n    :type m1: NxM-Element Array of floats\n    :param nr: Row dimension of m1.\n    :type nr: int\n    :param nc: Column dimension of m1.\n    :type nc: int\n    :return: Output matrix equal to m1\n    :rtype: NxM-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    mout = stypes.emptyDoubleMatrix(x=nc, y=nr)\n    nc = ctypes.c_int(nc)\n    nr = ctypes.c_int(nr)\n    libspice.mequg_c(m1, nc, nr, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmultiplying the transpose of a 3x3 matrix and a 3x3 matrix.", "response": "def mtxm(m1, m2):\n    \"\"\"\n    Multiply the transpose of a 3x3 matrix and a 3x3 matrix.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mtxm_c.html\n\n    :param m1: 3x3 double precision matrix.\n    :type m1: 3x3-Element Array of floats\n    :param m2: 3x3 double precision matrix.\n    :type m2: 3x3-Element Array of floats\n    :return: The produce m1 transpose times m2.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    m2 = stypes.toDoubleMatrix(m2)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.mtxm_c(m1, m2, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mtxmg(m1, m2, ncol1, nr1r2, ncol2):\n    m1 = stypes.toDoubleMatrix(m1)\n    m2 = stypes.toDoubleMatrix(m2)\n    mout = stypes.emptyDoubleMatrix(x=ncol2, y=ncol1)\n    ncol1 = ctypes.c_int(ncol1)\n    nr1r2 = ctypes.c_int(nr1r2)\n    ncol2 = ctypes.c_int(ncol2)\n    libspice.mtxmg_c(m1, m2, ncol1, nr1r2, ncol2, mout)\n    return stypes.cMatrixToNumpy(mout)", "response": "Multiply a matrix with another matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmultiply a 3x3 matrix and a 3 - dimensional double precision vector.", "response": "def mtxv(m1, vin):\n    \"\"\"\n    Multiplies the transpose of a 3x3 matrix\n    on the left with a vector on the right.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mtxv_c.html\n\n    :param m1: 3x3 double precision matrix.\n    :type m1: 3x3-Element Array of floats\n    :param vin: 3-dimensional double precision vector.\n    :type vin: 3-Element Array of floats\n    :return: 3-dimensional double precision vector.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    vin = stypes.toDoubleVector(vin)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.mtxv_c(m1, vin, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mtxvg(m1, v2, ncol1, nr1r2):\n    m1 = stypes.toDoubleMatrix(m1)\n    v2 = stypes.toDoubleVector(v2)\n    ncol1 = ctypes.c_int(ncol1)\n    nr1r2 = ctypes.c_int(nr1r2)\n    vout = stypes.emptyDoubleVector(ncol1.value)\n    libspice.mtxvg_c(m1, v2, ncol1, nr1r2, vout)\n    return stypes.cVectorToPython(vout)", "response": "Multiply a matrix and a vector of arbitrary size and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmultiplying two 3x3 double precision matrices.", "response": "def mxm(m1, m2):\n    \"\"\"\n    Multiply two 3x3 matrices.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mxm_c.html\n\n    :param m1: 3x3 double precision matrix.\n    :type m1: 3x3-Element Array of floats\n    :param m2: 3x3 double precision matrix.\n    :type m2: 3x3-Element Array of floats\n    :return: 3x3 double precision matrix.\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    m2 = stypes.toDoubleMatrix(m2)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.mxm_c(m1, m2, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmultiply two double precision matrices of arbitrary size.", "response": "def mxmg(m1, m2, nrow1, ncol1, ncol2):\n    \"\"\"\n    Multiply two double precision matrices of arbitrary size.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mxmg_c.html\n\n    :param m1: nrow1 X ncol1 double precision matrix.\n    :type m1: NxM-Element Array of floats\n    :param m2: ncol1 X ncol2 double precision matrix.\n    :type m2: NxM-Element Array of floats\n    :param nrow1: Row dimension of m1\n    :type nrow1: int\n    :param ncol1: Column dimension of m1 and row dimension of m2.\n    :type ncol1: int\n    :param ncol2: Column dimension of m2\n    :type ncol2: int\n    :return: nrow1 X ncol2 double precision matrix.\n    :rtype: NxM-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    m2 = stypes.toDoubleMatrix(m2)\n    mout = stypes.emptyDoubleMatrix(x=ncol2, y=nrow1)\n    nrow1 = ctypes.c_int(nrow1)\n    ncol1 = ctypes.c_int(ncol1)\n    ncol2 = ctypes.c_int(ncol2)\n    libspice.mxmg_c(m1, m2, nrow1, ncol1, ncol2, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mxmt(m1, m2):\n    m1 = stypes.toDoubleMatrix(m1)\n    m2 = stypes.toDoubleMatrix(m2)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.mxmt_c(m1, m2, mout)\n    return stypes.cMatrixToNumpy(mout)", "response": "Multiply a 3x3 matrix and the transpose of another 3x3 matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmultiplies a matrix and the transpose of a matrix both of arbitrary size.", "response": "def mxmtg(m1, m2, nrow1, nc1c2, nrow2):\n    \"\"\"\n    Multiply a matrix and the transpose of a matrix, both of arbitrary size.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/mxmtg_c.html\n\n    :param m1: Left-hand matrix to be multiplied.\n    :type m1: NxM-Element Array of floats\n    :param m2: Right-hand matrix whose transpose is to be multiplied\n    :type m2: NxM-Element Array of floats\n    :param nrow1: Row dimension of m1 and row dimension of mout.\n    :type nrow1: int\n    :param nc1c2: Column dimension of m1 and column dimension of m2.\n    :type nc1c2: int\n    :param nrow2: Row dimension of m2 and column dimension of mout.\n    :type nrow2: int\n    :return: Product matrix.\n    :rtype: NxM-Element Array of floats\n    \"\"\"\n    m1 = stypes.toDoubleMatrix(m1)\n    m2 = stypes.toDoubleMatrix(m2)\n    mout = stypes.emptyDoubleMatrix(x=nrow2, y=nrow1)\n    nrow1 = ctypes.c_int(nrow1)\n    nc1c2 = ctypes.c_int(nc1c2)\n    nrow2 = ctypes.c_int(nrow2)\n    libspice.mxmtg_c(m1, m2, nrow1, nc1c2, nrow2, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mxv(m1, vin):\n    m1 = stypes.toDoubleMatrix(m1)\n    vin = stypes.toDoubleVector(vin)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.mxv_c(m1, vin, vout)\n    return stypes.cVectorToPython(vout)", "response": "Multiply a 3x3 double precision matrix with a 3 - dimensional double precision vector."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mxvg(m1, v2, nrow1, nc1r2):\n    m1 = stypes.toDoubleMatrix(m1)\n    v2 = stypes.toDoubleVector(v2)\n    nrow1 = ctypes.c_int(nrow1)\n    nc1r2 = ctypes.c_int(nc1r2)\n    vout = stypes.emptyDoubleVector(nrow1.value)\n    libspice.mxvg_c(m1, v2, nrow1, nc1r2, vout)\n    return stypes.cVectorToPython(vout)", "response": "Multiply a matrix and a vector of arbitrary size."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlooks up the SPICE ID code associated with a string.", "response": "def namfrm(frname):\n    \"\"\"\n    Look up the frame ID code associated with a string.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/namfrm_c.html\n\n    :param frname: The name of some reference frame.\n    :type frname: str\n    :return: The SPICE ID code of the frame.\n    :rtype: int\n    \"\"\"\n    frname = stypes.stringToCharP(frname)\n    frcode = ctypes.c_int()\n    libspice.namfrm_c(frname, ctypes.byref(frcode))\n    return frcode.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ncpos(string, chars, start):\n    string = stypes.stringToCharP(string)\n    chars = stypes.stringToCharP(chars)\n    start = ctypes.c_int(start)\n    return libspice.ncpos_c(string, chars, start)", "response": "Find the first occurrence in a string of a character NOT belonging to a collection of characters starting at a specified location."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the first occurrence in a string of a character NOT belonging to a collection of characters starting at a specified location.", "response": "def ncposr(string, chars, start):\n    \"\"\"\n    Find the first occurrence in a string of a character NOT belonging to a\n    collection of characters, starting at a specified location,\n    searching in reverse.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/ncposr_c.html\n\n    :param string: Any character string.\n    :type string: str\n    :param chars: A collection of characters.\n    :type chars: str\n    :param start: Position to begin looking for one of chars.\n    :type start: int\n    :return: index\n    :rtype: int\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    chars = stypes.stringToCharP(chars)\n    start = ctypes.c_int(start)\n    return libspice.ncposr_c(string, chars, start)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nearpt(positn, a, b, c):\n    positn = stypes.toDoubleVector(positn)\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    npoint = stypes.emptyDoubleVector(3)\n    alt = ctypes.c_double()\n    libspice.nearpt_c(positn, a, b, c, npoint, ctypes.byref(alt))\n    return stypes.cVectorToPython(npoint), alt.value", "response": "Locates the point on the surface of an ellipsoid that is near to positn."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind nearest point on a triaxial ellipsoid to a specified line and the distance from the ellipsoid to the line.", "response": "def npedln(a, b, c, linept, linedr):\n    \"\"\"\n    Find nearest point on a triaxial ellipsoid to a specified\n    line and the distance from the ellipsoid to the line.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/npedln_c.html\n\n    :param a: Length of ellipsoid's semi-axis in the x direction\n    :type a: float\n    :param b: Length of ellipsoid's semi-axis in the y direction\n    :type b: float\n    :param c: Length of ellipsoid's semi-axis in the z direction\n    :type c: float\n    :param linept: Length of ellipsoid's semi-axis in the z direction\n    :type linept: 3-Element Array of floats\n    :param linedr: Direction vector of line\n    :type linedr: 3-Element Array of floats\n    :return: Nearest point on ellipsoid to line, Distance of ellipsoid from line\n    :rtype: tuple\n    \"\"\"\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    linept = stypes.toDoubleVector(linept)\n    linedr = stypes.toDoubleVector(linedr)\n    pnear = stypes.emptyDoubleVector(3)\n    dist = ctypes.c_double()\n    libspice.npedln_c(a, b, c, linept, linedr, pnear, ctypes.byref(dist))\n    return stypes.cVectorToPython(pnear), dist.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the nearest point on an ellipse to a specified point.", "response": "def npelpt(point, ellips):\n    \"\"\"\n    Find the nearest point on an ellipse to a specified point, both\n    in three-dimensional space, and find the distance between the\n    ellipse and the point.\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/npelpt_c.html\n\n    :param point: Point whose distance to an ellipse is to be found.\n    :type point: 3-Element Array of floats\n    :param ellips: An ellipse.\n    :type ellips: spiceypy.utils.support_types.Ellipse\n    :return: Nearest point on ellipsoid to line, Distance of ellipsoid from line\n    :rtype: tuple\n    \"\"\"\n    assert (isinstance(ellips, stypes.Ellipse))\n    point = stypes.toDoubleVector(point)\n    pnear = stypes.emptyDoubleVector(3)\n    dist = ctypes.c_double()\n    libspice.npelpt_c(point, ctypes.byref(ellips), pnear, ctypes.byref(dist))\n    return stypes.cVectorToPython(pnear), dist.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the nearest point on a line to a specified point and return the distance between the two points.", "response": "def nplnpt(linpt, lindir, point):\n    \"\"\"\n    Find the nearest point on a line to a specified point,\n    and find the distance between the two points.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/nplnpt_c.html\n\n    :param linpt: Point on a line\n    :type linpt: 3-Element Array of floats\n    :param lindir: line's direction vector\n    :type lindir: 3-Element Array of floats\n    :param point: A second point.\n    :type point: 3-Element Array of floats\n    :return:\n            Nearest point on the line to point,\n            Distance between point and pnear\n    :rtype: tuple\n    \"\"\"\n    linpt = stypes.toDoubleVector(linpt)\n    lindir = stypes.toDoubleVector(lindir)\n    point = stypes.toDoubleVector(point)\n    pnear = stypes.emptyDoubleVector(3)\n    dist = ctypes.c_double()\n    libspice.nplnpt_c(linpt, lindir, point, pnear, ctypes.byref(dist))\n    return stypes.cVectorToPython(pnear), dist.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nvc2pl(normal, constant):\n    plane = stypes.Plane()\n    normal = stypes.toDoubleVector(normal)\n    constant = ctypes.c_double(constant)\n    libspice.nvc2pl_c(normal, constant, ctypes.byref(plane))\n    return plane", "response": "Make a plane from a normal vector and a constant."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a plane from a normal vector and a point.", "response": "def nvp2pl(normal, point):\n    \"\"\"\n    Make a plane from a normal vector and a point.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/nvp2pl_c.html\n\n    :param normal: A normal vector defining a plane.\n    :type normal: 3-Element Array of floats\n    :param point: A point defining a plane.\n    :type point: 3-Element Array of floats\n    :return: plane\n    :rtype: spiceypy.utils.support_types.Plane\n    \"\"\"\n    normal = stypes.toDoubleVector(normal)\n    point = stypes.toDoubleVector(point)\n    plane = stypes.Plane()\n    libspice.nvp2pl_c(normal, point, ctypes.byref(plane))\n    return plane"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef occult(target1, shape1, frame1, target2, shape2, frame2, abcorr, observer,\n           et):\n    \"\"\"\n    Determines the occultation condition (not occulted, partially,\n    etc.) of one target relative to another target as seen by\n    an observer at a given time.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/occult_c.html\n\n    :param target1: Name or ID of first target.\n    :type target1: str\n    :param shape1: Type of shape model used for first target.\n    :type shape1: str\n    :param frame1: Body-fixed, body-centered frame for first body.\n    :type frame1: str\n    :param target2: Name or ID of second target.\n    :type target2: str\n    :param shape2: Type of shape model used for second target.\n    :type shape2: str\n    :param frame2: Body-fixed, body-centered frame for second body.\n    :type frame2: str\n    :param abcorr: Aberration correction flag.\n    :type abcorr: str\n    :param observer: Name or ID of the observer.\n    :type observer: str\n    :param et: Time of the observation (seconds past J2000).\n    :type et: float\n    :return: Occultation identification code.\n    :rtype: int\n    \"\"\"\n    target1 = stypes.stringToCharP(target1)\n    shape1 = stypes.stringToCharP(shape1)\n    frame1 = stypes.stringToCharP(frame1)\n    target2 = stypes.stringToCharP(target2)\n    shape2 = stypes.stringToCharP(shape2)\n    frame2 = stypes.stringToCharP(frame2)\n    abcorr = stypes.stringToCharP(abcorr)\n    observer = stypes.stringToCharP(observer)\n    et = ctypes.c_double(et)\n    occult_code = ctypes.c_int()\n    libspice.occult_c(target1, shape1, frame1, target2, shape2, frame2, abcorr,\n                      observer, et, ctypes.byref(occult_code))\n    return occult_code.value", "response": "Return the occultation condition code for a given target."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ordd(item, inset):\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.is_double()\n    item = ctypes.c_double(item)\n    return libspice.ordd_c(item, ctypes.byref(inset))", "response": "This function returns the ordinal position of any given item within a double precision set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ordi(item, inset):\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.is_int()\n    assert isinstance(item, int)\n    item = ctypes.c_int(item)\n    return libspice.ordi_c(item, ctypes.byref(inset))", "response": "This function returns the ordinal position of any given item within a set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef orderc(array, ndim=None):\n    if ndim is None:\n        ndim = ctypes.c_int(len(array))\n    else:\n        ndim = ctypes.c_int(ndim)\n    lenvals = ctypes.c_int(len(max(array, key=len)) + 1)\n    iorder = stypes.emptyIntVector(ndim)\n    array = stypes.listToCharArray(array, lenvals, ndim)\n    libspice.orderc_c(lenvals, array, ndim, iorder)\n    return stypes.cVectorToPython(iorder)", "response": "Determine the order of elements in an array of character strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines the order of elements in a double precision array.", "response": "def orderd(array, ndim=None):\n    \"\"\"\n    Determine the order of elements in a double precision array.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/orderd_c.html\n\n    :param array: Input array.\n    :type array: Array of floats\n    :param ndim: Optional Length of input array\n    :type ndim: int\n    :return: Order vector for array.\n    :rtype: array of ints\n    \"\"\"\n    if ndim is None:\n        ndim = ctypes.c_int(len(array))\n    else:\n        ndim = ctypes.c_int(ndim)\n    array = stypes.toDoubleVector(array)\n    iorder = stypes.emptyIntVector(ndim)\n    libspice.orderd_c(array, ndim, iorder)\n    return stypes.cVectorToPython(iorder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef orderi(array, ndim=None):\n    if ndim is None:\n        ndim = ctypes.c_int(len(array))\n    else:\n        ndim = ctypes.c_int(ndim)\n    array = stypes.toIntVector(array)\n    iorder = stypes.emptyIntVector(ndim)\n    libspice.orderi_c(array, ndim, iorder)\n    return stypes.cVectorToPython(iorder)", "response": "Determine the order of elements in an integer array."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the set of osculating conic orbital elements that are at a specified state at a specified epoch and a given Gravitational parameter.", "response": "def oscelt(state, et, mu):\n    \"\"\"\n    Determine the set of osculating conic orbital elements that\n    corresponds to the state (position, velocity) of a body at\n    some epoch.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/oscelt_c.html\n\n    :param state: State of body at epoch of elements.\n    :type state: Float Array of 6 elements.\n    :param et: Epoch of elements.\n    :type et: float\n    :param mu: Gravitational parameter (GM) of primary body.\n    :type mu: float\n    :return: Equivalent conic elements\n    :rtype: Float Array of 8 elements.\n    \"\"\"\n    state = stypes.toDoubleVector(state)\n    et = ctypes.c_double(et)\n    mu = ctypes.c_double(mu)\n    elts = stypes.emptyDoubleVector(8)\n    libspice.oscelt_c(state, et, mu, elts)\n    return stypes.cVectorToPython(elts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the set of osculating conic orbital elements that are at a specified state at a specified epoch and a given Gravitational parameter.", "response": "def oscltx(state, et, mu):\n    \"\"\"\n    Determine the set of osculating conic orbital elements that \n    corresponds to the state (position, velocity) of a body at some \n    epoch. In additional to the classical elements, return the true \n    anomaly, semi-major axis, and period, if applicable. \n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/oscltx_c.html\n    \n    :param state: State of body at epoch of elements. \n    :type state: 6-Element Array of floats\n    :param et: Epoch of elements. \n    :type et: float\n    :param mu: Gravitational parameter (GM) of primary body. \n    :type mu: float\n    :return: Extended set of classical conic elements. \n    \"\"\"\n    state = stypes.toDoubleVector(state)\n    et = ctypes.c_double(et)\n    mu = ctypes.c_double(mu)\n    elts = stypes.emptyDoubleVector(20)\n    libspice.oscltx_c(state, et, mu, elts)\n    return stypes.cVectorToPython(elts)[0:11]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pckcov(pck, idcode, cover):\n    pck = stypes.stringToCharP(pck)\n    idcode = ctypes.c_int(idcode)\n    assert isinstance(cover, stypes.SpiceCell)\n    assert cover.dtype == 1\n    libspice.pckcov_c(pck, idcode, ctypes.byref(cover))", "response": "Find the coverage window for a specified binary PCK file and class ID code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind the set of reference frame class ID codes of all frames in a specified binary PCK file.", "response": "def pckfrm(pck, ids):\n    \"\"\"\n    Find the set of reference frame class ID codes of all frames\n    in a specified binary PCK file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pckfrm_c.html\n\n    :param pck: Name of PCK file.\n    :type pck: str\n    :param ids: Set of frame class ID codes of frames in PCK file.\n    :type ids: SpiceCell\n    \"\"\"\n    pck = stypes.stringToCharP(pck)\n    assert isinstance(ids, stypes.SpiceCell)\n    assert ids.dtype == 2\n    libspice.pckfrm_c(pck, ctypes.byref(ids))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a binary PCK file for use by the readers.", "response": "def pcklof(filename):\n    \"\"\"\n    Load a binary PCK file for use by the readers.  Return the\n    handle of the loaded file which is used by other PCK routines to\n    refer to the file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pcklof_c.html\n\n    :param filename: Name of the file to be loaded.\n    :type filename: str\n    :return: Loaded file's handle.\n    :rtype: int\n    \"\"\"\n    filename = stypes.stringToCharP(filename)\n    handle = ctypes.c_int()\n    libspice.pcklof_c(filename, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new PCK file and return the handle of the opened file.", "response": "def pckopn(name, ifname, ncomch):\n    \"\"\"\n    Create a new PCK file, returning the handle of the opened file. \n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pckopn_c.html\n    \n    :param name: The name of the PCK file to be opened. \n    :type name: str\n    :param ifname: The internal filename for the PCK.\n    :type ifname: str\n    :param ncomch: The number of characters to reserve for comments. \n    :type ncomch: int\n    :return: The handle of the opened PCK file.\n    :rtype: int\n    \"\"\"\n    name = stypes.stringToCharP(name)\n    ifname = stypes.stringToCharP(ifname)\n    ncomch = ctypes.c_int(ncomch)\n    handle = ctypes.c_int()\n    libspice.pckopn_c(name, ifname, ncomch, ctypes.byref(handle))\n    return handle.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a type 2 segment to a binary PCK file.", "response": "def pckw02(handle, classid, frname, first, last, segid, intlen, n, polydg, cdata, btime):\n    \"\"\"\n    Write a type 2 segment to a PCK binary file given the file handle,\n    frame class ID, base frame, time range covered by the segment, and\n    the Chebyshev polynomial coefficients.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pckw02_c.html\n    \n    :param handle: Handle of binary PCK file open for writing.\n    :type handle: int\n    :param classid: Frame class ID of body-fixed frame.\n    :type classid: int\n    :param frname: Name of base reference frame.\n    :type frname: str\n    :param first: Start time of interval covered by segment. \n    :type first: float\n    :param last: End time of interval covered by segment.\n    :type last: float\n    :param segid: Segment identifier.\n    :type segid: str\n    :param intlen: Length of time covered by logical record.\n    :type intlen: float\n    :param n: Number of logical records in segment.\n    :type n: int\n    :param polydg: Chebyshev polynomial degree. \n    :type polydg: int\n    :param cdata: Array of Chebyshev coefficients.\n    :type cdata: N-Element Array of floats\n    :param btime: Begin time of first logical record.\n    :type btime: float\n    \"\"\"\n    handle = ctypes.c_int(handle)\n    classid = ctypes.c_int(classid)\n    frame = stypes.stringToCharP(frname)\n    first = ctypes.c_double(first)\n    last = ctypes.c_double(last)\n    segid = stypes.stringToCharP(segid)\n    intlen = ctypes.c_double(intlen)\n    n = ctypes.c_int(n)\n    polydg = ctypes.c_int(polydg)\n    cdata = stypes.toDoubleVector(cdata)\n    btime = ctypes.c_double(btime)\n    libspice.pckw02_c(handle, classid, frame, first, last, segid, intlen, n, polydg, cdata, btime)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pcpool(name, cvals):\n    name = stypes.stringToCharP(name)\n    lenvals = ctypes.c_int(len(max(cvals, key=len)) + 1)\n    n = ctypes.c_int(len(cvals))\n    cvals = stypes.listToCharArray(cvals, lenvals, n)\n    libspice.pcpool_c(name, n, lenvals, cvals)", "response": "This entry point provides a method for programmatically inserting character data into the kernel pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pdpool(name, dvals):\n    name = stypes.stringToCharP(name)\n    n = ctypes.c_int(len(dvals))\n    dvals = stypes.toDoubleVector(dvals)\n    libspice.pdpool_c(name, n, dvals)", "response": "This entry point provides a method for programmatically inserting double precision data into the kernel pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pgrrec(body, lon, lat, alt, re, f):\n    body = stypes.stringToCharP(body)\n    lon = ctypes.c_double(lon)\n    lat = ctypes.c_double(lat)\n    alt = ctypes.c_double(alt)\n    re = ctypes.c_double(re)\n    f = ctypes.c_double(f)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.pgrrec_c(body, lon, lat, alt, re, f, rectan)\n    return stypes.cVectorToPython(rectan)", "response": "Convert planetographic coordinates to rectangular coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef phaseq(et, target, illmn, obsrvr, abcorr):\n    et = ctypes.c_double(et)\n    target = stypes.stringToCharP(target)\n    illmn = stypes.stringToCharP(illmn)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    abcorr = stypes.stringToCharP(abcorr)\n    return libspice.phaseq_c(et, target, illmn, obsrvr, abcorr)", "response": "Compute the apparent phase angle for a target observer illuminating body and aberration correction flag."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprojects an ellipse onto a plane orthogonally.", "response": "def pjelpl(elin, plane):\n    \"\"\"\n    Project an ellipse onto a plane, orthogonally.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pjelpl_c.html\n\n    :param elin: A SPICE ellipse to be projected.\n    :type elin: spiceypy.utils.support_types.Ellipse\n    :param plane: A plane onto which elin is to be projected.\n    :type plane: supporttypes.Plane\n    :return: A SPICE ellipse resulting from the projection.\n    :rtype: spiceypy.utils.support_types.Ellipse\n    \"\"\"\n    assert (isinstance(elin, stypes.Ellipse))\n    assert (isinstance(plane, stypes.Plane))\n    elout = stypes.Ellipse()\n    libspice.pjelpl_c(ctypes.byref(elin), ctypes.byref(plane),\n                      ctypes.byref(elout))\n    return elout"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pl2nvc(plane):\n    assert (isinstance(plane, stypes.Plane))\n    normal = stypes.emptyDoubleVector(3)\n    constant = ctypes.c_double()\n    libspice.pl2nvc_c(ctypes.byref(plane), normal, ctypes.byref(constant))\n    return stypes.cVectorToPython(normal), constant.value", "response": "Return a unit normal vector and constant that define a specified plane."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a unit normal vector and point that define a specified plane.", "response": "def pl2nvp(plane):\n    \"\"\"\n    Return a unit normal vector and point that define a specified plane.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pl2nvp_c.html\n\n\n    :param plane: A SPICE plane.\n    :type plane: supporttypes.Plane\n    :return: A unit normal vector and point that define plane.\n    :rtype: tuple\n    \"\"\"\n    assert (isinstance(plane, stypes.Plane))\n    normal = stypes.emptyDoubleVector(3)\n    point = stypes.emptyDoubleVector(3)\n    libspice.pl2nvp_c(ctypes.byref(plane), normal, point)\n    return stypes.cVectorToPython(normal), stypes.cVectorToPython(point)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pl2psv(plane):\n    assert (isinstance(plane, stypes.Plane))\n    point = stypes.emptyDoubleVector(3)\n    span1 = stypes.emptyDoubleVector(3)\n    span2 = stypes.emptyDoubleVector(3)\n    libspice.pl2psv_c(ctypes.byref(plane), point, span1, span2)\n    return stypes.cVectorToPython(point), stypes.cVectorToPython(\n            span1), stypes.cVectorToPython(span2)", "response": "Return a point and two orthogonal spanning vectors that generate\n    a specified plane."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the total area of a collection of triangular plates.", "response": "def pltar(vrtces, plates):\n    \"\"\"\n    Compute the total area of a collection of triangular plates.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pltar_c.html\n    \n    :param vrtces: Array of vertices.\n    :type vrtces: Nx3-Element Array of floats\n    :param plates: Array of plates. \n    :type plates: Nx3-Element Array of ints\n    :return: total area of the set of plates\n    :rtype: float\n    \"\"\"\n    nv = ctypes.c_int(len(vrtces))\n    vrtces = stypes.toDoubleMatrix(vrtces)\n    np = ctypes.c_int(len(plates))\n    plates = stypes.toIntMatrix(plates)\n    return libspice.pltar_c(nv, vrtces, np, plates)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pltexp(iverts, delta):\n    iverts = stypes.toDoubleMatrix(iverts)\n    delta = ctypes.c_double(delta)\n    overts = stypes.emptyDoubleMatrix()\n    libspice.pltexp_c(iverts, delta, overts)\n    return stypes.cMatrixToNumpy(overts)", "response": "Expand a triangular plate by a specified amount."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pltnp(point, v1, v2, v3):\n    point = stypes.toDoubleVector(point)\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    v3 = stypes.toDoubleVector(v3)\n    pnear = stypes.emptyDoubleVector(3)\n    dist = ctypes.c_double()\n    libspice.pltnp_c(point, v1, v2, v3, pnear, ctypes.byref(dist))\n    return stypes.cVectorToPython(pnear), dist.value", "response": "Find the nearest point on a triangular plate to a given point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pltnrm(v1, v2, v3):\n    v1 = stypes.toDoubleVector(v1)\n    v2 = stypes.toDoubleVector(v2)\n    v3 = stypes.toDoubleVector(v3)\n    normal = stypes.emptyDoubleVector(3)\n    libspice.pltnrm_c(v1, v2, v3, normal)\n    return stypes.cVectorToPython(normal)", "response": "Compute an outward normal vector of a triangular plate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pltvol(vrtces, plates):\n    nv = ctypes.c_int(len(vrtces))\n    vrtces = stypes.toDoubleMatrix(vrtces)\n    np = ctypes.c_int(len(plates))\n    plates = stypes.toIntMatrix(plates)\n    return libspice.pltvol_c(nv, vrtces, np, plates)", "response": "Compute the volume of a three - dimensional region bounded by a \n    collection of triangular plates."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the value of a polynomial and its first n derivatives at the value t.", "response": "def polyds(coeffs, deg, nderiv, t):\n    \"\"\"\n    Compute the value of a polynomial and it's first\n    n derivatives at the value t.\n    \n    https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/polyds_c.html\n    \n    :param coeffs: Coefficients of the polynomial to be evaluated.\n    :type coeffs: N-Element Array of floats\n    :param deg: Degree of the polynomial to be evaluated.\n    :type deg: int\n    :param nderiv: Number of derivatives to compute.\n    :type nderiv: int\n    :param t: Point to evaluate the polynomial and derivatives\n    :type t: float\n    :return: Value of polynomial and derivatives.\n    :rtype: nderiv-Element Array of floats\n    \"\"\"\n    coeffs = stypes.toDoubleVector(coeffs)\n    deg = ctypes.c_int(deg)\n    p = stypes.emptyDoubleVector(nderiv + 1)\n    nderiv = ctypes.c_int(nderiv)\n    t = ctypes.c_double(t)\n    libspice.polyds_c(ctypes.byref(coeffs), deg, nderiv, t, p)\n    return stypes.cVectorToPython(p)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the first occurrence of a substring starting at a specified location.", "response": "def pos(string, substr, start):\n    \"\"\"\n    Find the first occurrence in a string of a substring, starting at\n    a specified location, searching forward.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pos_c.html\n\n    :param string: Any character string.\n    :type string: str\n    :param substr: Substring to locate in the character string.\n    :type substr: str\n    :param start: Position to begin looking for substr in string.\n    :type start: int\n    :return:\n            The index of the first occurrence of substr\n            in string at or following index start.\n    :rtype: int\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    substr = stypes.stringToCharP(substr)\n    start = ctypes.c_int(start)\n    return libspice.pos_c(string, substr, start)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef posr(string, substr, start):\n    string = stypes.stringToCharP(string)\n    substr = stypes.stringToCharP(substr)\n    start = ctypes.c_int(start)\n    return libspice.posr_c(string, substr, start)", "response": "Find the first occurrence in a string of a substring starting at a specified location searching backward."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a central mass and the state of massless body at time t_0, this routine determines the state as predicted by a two-body force model at time t_0 + dt. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/prop2b_c.html :param gm: Gravity of the central mass. :type gm: float :param pvinit: Initial state from which to propagate a state. :type pvinit: 6-Element Array of floats :param dt: Time offset from initial state to propagate to. :type dt: float :return: The propagated state. :rtype: 6-Element Array of floats", "response": "def prop2b(gm, pvinit, dt):\n    \"\"\"\n    Given a central mass and the state of massless body at time t_0,\n    this routine determines the state as predicted by a two-body\n    force model at time t_0 + dt.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/prop2b_c.html\n\n    :param gm: Gravity of the central mass.\n    :type gm: float\n    :param pvinit: Initial state from which to propagate a state.\n    :type pvinit: 6-Element Array of floats\n    :param dt: Time offset from initial state to propagate to.\n    :type dt: float\n    :return: The propagated state.\n    :rtype: 6-Element Array of floats\n    \"\"\"\n    gm = ctypes.c_double(gm)\n    pvinit = stypes.toDoubleVector(pvinit)\n    dt = ctypes.c_double(dt)\n    pvprop = stypes.emptyDoubleVector(6)\n    libspice.prop2b_c(gm, pvinit, dt, pvprop)\n    return stypes.cVectorToPython(pvprop)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a string as a double precision number.", "response": "def prsdp(string):\n    \"\"\"\n    Parse a string as a double precision number, encapsulating error handling.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/prsdp_c.html\n\n    :param string: String representing a d.p. number.\n    :type string: str\n    :return: D.p. value obtained by parsing string.\n    :rtype: float\n    \"\"\"\n    string = stypes.stringToCharP(string)\n    dpval = ctypes.c_double()\n    libspice.prsdp_c(string, ctypes.byref(dpval))\n    return dpval.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prsint(string):\n    string = stypes.stringToCharP(string)\n    intval = ctypes.c_int()\n    libspice.prsint_c(string, ctypes.byref(intval))\n    return intval.value", "response": "Parse a string as an integer encapsulating error handling."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef psv2pl(point, span1, span2):\n    point = stypes.toDoubleVector(point)\n    span1 = stypes.toDoubleVector(span1)\n    span2 = stypes.toDoubleVector(span2)\n    plane = stypes.Plane()\n    libspice.psv2pl_c(point, span1, span2, ctypes.byref(plane))\n    return plane", "response": "Make a CSPICE plane from a point and two spanning vectors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the rotation matrix that transforms position vectors from one frame to another at a specified epoch.", "response": "def pxform(fromstr, tostr, et):\n    \"\"\"\n    Return the matrix that transforms position vectors from one\n    specified frame to another at a specified epoch.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pxform_c.html\n\n    :param fromstr: Name of the frame to transform from.\n    :type fromstr: str\n    :param tostr: Name of the frame to transform to.\n    :type tostr: str\n    :param et: Epoch of the rotation matrix.\n    :type et: float\n    :return: A rotation matrix.\n    :rtype: 3x3 Element Array of floats\n    \"\"\"\n    et = ctypes.c_double(et)\n    tostr = stypes.stringToCharP(tostr)\n    fromstr = stypes.stringToCharP(fromstr)\n    rotatematrix = stypes.emptyDoubleMatrix()\n    libspice.pxform_c(fromstr, tostr, et, rotatematrix)\n    return stypes.cMatrixToNumpy(rotatematrix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the 3x3 matrix that transforms position vectors from one frame to another specified frame at a specified epoch to another specified frame at a specified epoch.", "response": "def pxfrm2(frame_from, frame_to, etfrom, etto):\n    \"\"\"\n    Return the 3x3 matrix that transforms position vectors from one\n    specified frame at a specified epoch to another specified\n    frame at another specified epoch.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/pxfrm2_c.html\n\n    :param frame_from: Name of the frame to transform from.\n    :type frame_from: str\n    :param frame_to: Name of the frame to transform to.\n    :type frame_to: str\n    :param etfrom: Evaluation time of frame_from.\n    :type etfrom: float\n    :param etto: Evaluation time of frame_to.\n    :type etto: float\n    :return: A position transformation matrix from frame_from to frame_to\n    :rtype: 3x3 Element Array of floats\n    \"\"\"\n    frame_from = stypes.stringToCharP(frame_from)\n    frame_to = stypes.stringToCharP(frame_to)\n    etfrom = ctypes.c_double(etfrom)\n    etto = ctypes.c_double(etto)\n    outmatrix = stypes.emptyDoubleMatrix()\n    libspice.pxfrm2_c(frame_from, frame_to, etfrom, etto, outmatrix)\n    return stypes.cMatrixToNumpy(outmatrix)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef q2m(q):\n    q = stypes.toDoubleVector(q)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.q2m_c(q, mout)\n    return stypes.cMatrixToNumpy(mout)", "response": "Find the rotation matrix corresponding to a specified unit quaternion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef qcktrc(tracelen=_default_len_out):\n    tracestr = stypes.stringToCharP(tracelen)\n    tracelen = ctypes.c_int(tracelen)\n    libspice.qcktrc_c(tracelen, tracestr)\n    return stypes.toPythonString(tracestr)", "response": "Return a string containing a traceback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nderiving angular velocity from a unit quaternion and its derivative with respect to time.", "response": "def qdq2av(q, dq):\n    \"\"\"\n    Derive angular velocity from a unit quaternion and its derivative\n    with respect to time.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/qdq2av_c.html\n\n    :param q: Unit SPICE quaternion.\n    :type q: 4-Element Array of floats\n    :param dq: Derivative of q with respect to time\n    :type dq: 4-Element Array of floats\n    :return: Angular velocity defined by q and dq.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    q = stypes.toDoubleVector(q)\n    dq = stypes.toDoubleVector(dq)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.qdq2av_c(q, dq, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef qxq(q1, q2):\n    q1 = stypes.toDoubleVector(q1)\n    q2 = stypes.toDoubleVector(q2)\n    vout = stypes.emptyDoubleVector(4)\n    libspice.qxq_c(q1, q2, vout)\n    return stypes.cVectorToPython(vout)", "response": "Multiply two quaternions.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/qxq_c.html\n\n    :param q1: First SPICE quaternion.\n    :type q1: 4-Element Array of floats\n    :param q2: Second SPICE quaternion.\n    :type q2: 4-Element Array of floats\n    :return: Product of q1 and q2.\n    :rtype: 4-Element Array of floats"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts from range right ascension and declination to rectangular coordinates.", "response": "def radrec(inrange, re, dec):\n    \"\"\"\n    Convert from range, right ascension, and declination to rectangular\n    coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/radrec_c.html\n\n    :param inrange: Distance of a point from the origin.\n    :type inrange: float\n    :param re: Right ascension of point in radians.\n    :type re: float\n    :param dec: Declination of point in radians.\n    :type dec: float\n    :return: Rectangular coordinates of the point.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    inrange = ctypes.c_double(inrange)\n    re = ctypes.c_double(re)\n    dec = ctypes.c_double(dec)\n    rectan = stypes.emptyDoubleVector(3)\n    libspice.radrec_c(inrange, re, dec, rectan)\n    return stypes.cVectorToPython(rectan)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raxisa(matrix):\n    matrix = stypes.toDoubleMatrix(matrix)\n    axis = stypes.emptyDoubleVector(3)\n    angle = ctypes.c_double()\n    libspice.raxisa_c(matrix, axis, ctypes.byref(angle))\n    return stypes.cVectorToPython(axis), angle.value", "response": "Compute the axis of the rotation given by an input matrix and the angle of the rotation about that axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the next line of text from a text file.", "response": "def rdtext(file, lenout=_default_len_out):  # pragma: no cover\n    \"\"\"\n    Read the next line of text from a text file.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/rdtext_c.html\n\n    :param file: Name of text file.\n    :type file: str\n    :param lenout: Available room in output line.\n    :type lenout: int\n    :return: Next line from the text file, End-of-file indicator\n    :rtype: tuple\n    \"\"\"\n    file = stypes.stringToCharP(file)\n    line = stypes.stringToCharP(lenout)\n    lenout = ctypes.c_int(lenout)\n    eof = ctypes.c_int()\n    libspice.rdtext_c(file, lenout, line, ctypes.byref(eof))\n    return stypes.toPythonString(line), bool(eof.value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reccyl(rectan):\n    rectan = stypes.toDoubleVector(rectan)\n    radius = ctypes.c_double(0)\n    lon = ctypes.c_double(0)\n    z = ctypes.c_double(0)\n    libspice.reccyl_c(rectan, ctypes.byref(radius), ctypes.byref(lon),\n                      ctypes.byref(z))\n    return radius.value, lon.value, z.value", "response": "Convert from rectangular to cylindrical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting from rectangular coordinates to geodetic coordinates.", "response": "def recgeo(rectan, re, f):\n    \"\"\"\n    Convert from rectangular coordinates to geodetic coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/recgeo_c.html\n\n    :param rectan: Rectangular coordinates of a point.\n    :type rectan: 3-Element Array of floats\n    :param re: Equatorial radius of the reference spheroid.\n    :type re: float\n    :param f: Flattening coefficient.\n    :type f: float\n    :return:\n            Geodetic longitude (radians),\n            Geodetic latitude (radians),\n            Altitude above reference spheroid\n    :rtype: tuple\n    \"\"\"\n    rectan = stypes.toDoubleVector(rectan)\n    re = ctypes.c_double(re)\n    f = ctypes.c_double(f)\n    longitude = ctypes.c_double(0)\n    latitude = ctypes.c_double(0)\n    alt = ctypes.c_double(0)\n    libspice.recgeo_c(rectan, re, f, ctypes.byref(longitude),\n                      ctypes.byref(latitude), ctypes.byref(alt))\n    return longitude.value, latitude.value, alt.value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert from rectangular coordinates to latitudinal coordinates.", "response": "def reclat(rectan):\n    \"\"\"\n    Convert from rectangular coordinates to latitudinal coordinates.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reclat_c.html\n\n    :param rectan: Rectangular coordinates of a point.\n    :type rectan: 3-Element Array of floats\n    :return: Distance from the origin, Longitude in radians, Latitude in radians\n    :rtype: tuple\n    \"\"\"\n    rectan = stypes.toDoubleVector(rectan)\n    radius = ctypes.c_double(0)\n    longitude = ctypes.c_double(0)\n    latitude = ctypes.c_double(0)\n    libspice.reclat_c(rectan, ctypes.byref(radius), ctypes.byref(longitude),\n                      ctypes.byref(latitude))\n    return radius.value, longitude.value, latitude.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recpgr(body, rectan, re, f):\n    body = stypes.stringToCharP(body)\n    rectan = stypes.toDoubleVector(rectan)\n    re = ctypes.c_double(re)\n    f = ctypes.c_double(f)\n    lon = ctypes.c_double()\n    lat = ctypes.c_double()\n    alt = ctypes.c_double()\n    libspice.recpgr_c(body, rectan, re, f, ctypes.byref(lon), ctypes.byref(lat),\n                      ctypes.byref(alt))\n    return lon.value, lat.value, alt.value", "response": "Convert rectangular coordinates to planetographic coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts rectangular coordinates to range right ascension and declination.", "response": "def recrad(rectan):\n    \"\"\"\n    Convert rectangular coordinates to range, right ascension, and declination.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/recrad_c.html\n\n    :param rectan: Rectangular coordinates of a point.\n    :type rectan: 3-Element Array of floats\n    :return:\n            Distance of the point from the origin,\n            Right ascension in radians,\n            Declination in radians\n    :rtype: tuple\n    \"\"\"\n    rectan = stypes.toDoubleVector(rectan)\n    outrange = ctypes.c_double()\n    ra = ctypes.c_double()\n    dec = ctypes.c_double()\n    libspice.recrad_c(rectan, ctypes.byref(outrange), ctypes.byref(ra),\n                      ctypes.byref(dec))\n    return outrange.value, ra.value, dec.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recsph(rectan):\n    rectan = stypes.toDoubleVector(rectan)\n    r = ctypes.c_double()\n    colat = ctypes.c_double()\n    lon = ctypes.c_double()\n    libspice.recsph_c(rectan, ctypes.byref(r), ctypes.byref(colat),\n                      ctypes.byref(lon))\n    return r.value, colat.value, lon.value", "response": "Convert from rectangular coordinates to spherical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving an item from a character set.", "response": "def removc(item, inset):\n    \"\"\"\n    Remove an item from a character set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/removc_c.html\n\n    :param item: Item to be removed.\n    :type item: str\n    :param inset: Set to be updated.\n    :type inset: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.dtype == 0\n    item = stypes.stringToCharP(item)\n    libspice.removc_c(item, ctypes.byref(inset))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving an item from a double precision set.", "response": "def removd(item, inset):\n    \"\"\"\n    Remove an item from a double precision set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/removd_c.html\n\n    :param item: Item to be removed.\n    :type item: float\n    :param inset: Set to be updated.\n    :type inset: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.dtype == 1\n    item = ctypes.c_double(item)\n    libspice.removd_c(item, ctypes.byref(inset))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an item from an integer set.", "response": "def removi(item, inset):\n    \"\"\"\n    Remove an item from an integer set.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/removi_c.html\n\n    :param item: Item to be removed.\n    :type item: int\n    :param inset: Set to be updated.\n    :type inset: spiceypy.utils.support_types.SpiceCell\n    \"\"\"\n    assert isinstance(inset, stypes.SpiceCell)\n    assert inset.dtype == 2\n    item = ctypes.c_int(item)\n    libspice.removi_c(item, ctypes.byref(inset))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nre-order the elements of an array of character strings according to a given order vector. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reordc_c.html :param iorder: Order vector to be used to re-order array. :type iorder: Array of ints :param ndim: Dimension of array. :type ndim: int :param lenvals: String length. :type lenvals: int :param array: Array to be re-ordered. :type array: Array of strs :return: Re-ordered Array. :rtype: Array of strs", "response": "def reordc(iorder, ndim, lenvals, array):\n    \"\"\"\n    Re-order the elements of an array of character strings\n    according to a given order vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reordc_c.html\n\n    :param iorder: Order vector to be used to re-order array.\n    :type iorder: Array of ints\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param lenvals: String length.\n    :type lenvals: int\n    :param array: Array to be re-ordered.\n    :type array: Array of strs\n    :return: Re-ordered Array.\n    :rtype: Array of strs\n    \"\"\"\n    iorder = stypes.toIntVector(iorder)\n    ndim = ctypes.c_int(ndim)\n    lenvals = ctypes.c_int(lenvals + 1)\n    array = stypes.listToCharArray(array, xLen=lenvals, yLen=ndim)\n    libspice.reordc_c(iorder, ndim, lenvals, array)\n    return [stypes.toPythonString(x.value) for x in array]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nre-order the elements of a double precision array according to a given order vector. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reordd_c.html :param iorder: Order vector to be used to re-order array. :type iorder: Array of ints :param ndim: Dimension of array. :type ndim: int :param array: Array to be re-ordered. :type array: Array of floats :return: Re-ordered Array. :rtype: Array of floats", "response": "def reordd(iorder, ndim, array):\n    \"\"\"\n    Re-order the elements of a double precision array according to\n    a given order vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reordd_c.html\n\n    :param iorder: Order vector to be used to re-order array.\n    :type iorder: Array of ints\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param array: Array to be re-ordered.\n    :type array: Array of floats\n    :return: Re-ordered Array.\n    :rtype: Array of floats\n    \"\"\"\n    iorder = stypes.toIntVector(iorder)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toDoubleVector(array)\n    libspice.reordd_c(iorder, ndim, array)\n    return stypes.cVectorToPython(array)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nre-order the elements of an integer array according to a given order vector. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reordi_c.html :param iorder: Order vector to be used to re-order array. :type iorder: Array of ints :param ndim: Dimension of array. :type ndim: int :param array: Array to be re-ordered. :type array: Array of ints :return: Re-ordered Array. :rtype: Array of ints", "response": "def reordi(iorder, ndim, array):\n    \"\"\"\n    Re-order the elements of an integer array according to\n    a given order vector.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/reordi_c.html\n\n    :param iorder: Order vector to be used to re-order array.\n    :type iorder: Array of ints\n    :param ndim: Dimension of array.\n    :type ndim: int\n    :param array: Array to be re-ordered.\n    :type array: Array of ints\n    :return: Re-ordered Array.\n    :rtype: Array of ints\n    \"\"\"\n    iorder = stypes.toIntVector(iorder)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toIntVector(array)\n    libspice.reordi_c(iorder, ndim, array)\n    return stypes.cVectorToPython(array)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reordl(iorder, ndim, array):\n    iorder = stypes.toIntVector(iorder)\n    ndim = ctypes.c_int(ndim)\n    array = stypes.toIntVector(array)\n    libspice.reordl_c(iorder, ndim, array)\n    return stypes.cIntVectorToBoolPython(array)", "response": "Re - order the elements of a logical array according to a given order vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace a marker with a character string.", "response": "def repmc(instr, marker, value, lenout=None):\n    \"\"\"\n    Replace a marker with a character string.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/repmc_c.html\n\n    :param instr: Input string.\n    :type instr: str\n    :param marker: Marker to be replaced.\n    :type marker: str\n    :param value: Replacement value.\n    :type value: str\n    :param lenout: Optional available space in output string\n    :type lenout: int\n    :return: Output string.\n    :rtype: str\n    \"\"\"\n    if lenout is None:\n        lenout = ctypes.c_int(len(instr) + len(value) + len(marker) + 15)\n    instr = stypes.stringToCharP(instr)\n    marker = stypes.stringToCharP(marker)\n    value = stypes.stringToCharP(value)\n    out = stypes.stringToCharP(lenout)\n    libspice.repmc_c(instr, marker, value, lenout, out)\n    return stypes.toPythonString(out)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef repmct(instr, marker, value, repcase, lenout=None):\n    if lenout is None:\n        lenout = ctypes.c_int(len(instr) + len(marker) + 15)\n    instr = stypes.stringToCharP(instr)\n    marker = stypes.stringToCharP(marker)\n    value = ctypes.c_int(value)\n    repcase = ctypes.c_char(repcase.encode(encoding='UTF-8'))\n    out = stypes.stringToCharP(lenout)\n    libspice.repmct_c(instr, marker, value, repcase, lenout, out)\n    return stypes.toPythonString(out)", "response": "Replace a marker with a text representation of a cardinal number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing a marker with a double precision number.", "response": "def repmd(instr, marker, value, sigdig):\n    \"\"\"\n    Replace a marker with a double precision number.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/repmd_c.html\n\n    :param instr: Input string.\n    :type instr: str\n    :param marker: Marker to be replaced.\n    :type marker: str\n    :param value: Replacement value.\n    :type value: float\n    :param sigdig: Significant digits in replacement text.\n    :type sigdig: int\n    :return: Output string.\n    :rtype: str\n    \"\"\"\n    lenout = ctypes.c_int(len(instr) + len(marker) + 15)\n    instr = stypes.stringToCharP(instr)\n    marker = stypes.stringToCharP(marker)\n    value = ctypes.c_double(value)\n    sigdig = ctypes.c_int(sigdig)\n    out = stypes.stringToCharP(lenout)\n    libspice.repmd_c(instr, marker, value, sigdig, lenout, out)\n    return stypes.toPythonString(out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef repmf(instr, marker, value, sigdig, informat, lenout=None):\n    if lenout is None:\n        lenout = ctypes.c_int(len(instr) + len(marker) + 15)\n    instr = stypes.stringToCharP(instr)\n    marker = stypes.stringToCharP(marker)\n    value = ctypes.c_double(value)\n    sigdig = ctypes.c_int(sigdig)\n    informat = ctypes.c_char(informat.encode(encoding='UTF-8'))\n    out = stypes.stringToCharP(lenout)\n    libspice.repmf_c(instr, marker, value, sigdig, informat, lenout, out)\n    return stypes.toPythonString(out)", "response": "Replace a marker in a string with a formatted double precision value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef repmi(instr, marker, value, lenout=None):\n    if lenout is None:\n        lenout = ctypes.c_int(len(instr) + len(marker) + 15)\n    instr = stypes.stringToCharP(instr)\n    marker = stypes.stringToCharP(marker)\n    value = ctypes.c_int(value)\n    out = stypes.stringToCharP(lenout)\n    libspice.repmi_c(instr, marker, value, lenout, out)\n    return stypes.toPythonString(out)", "response": "Replace a marker with an integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the 3x3 rotation matrix generated by a rotation of a specified angle about a specified axis.", "response": "def rotate(angle, iaxis):\n    \"\"\"\n    Calculate the 3x3 rotation matrix generated by a rotation\n    of a specified angle about a specified axis. This rotation\n    is thought of as rotating the coordinate system.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/rotate_c.html\n\n    :param angle: Angle of rotation (radians).\n    :type angle: float\n    :param iaxis: Axis of rotation X=1, Y=2, Z=3.\n    :type iaxis: int\n    :return: Resulting rotation matrix\n    :rtype: 3x3-Element Array of floats\n    \"\"\"\n    angle = ctypes.c_double(angle)\n    iaxis = ctypes.c_int(iaxis)\n    mout = stypes.emptyDoubleMatrix()\n    libspice.rotate_c(angle, iaxis, mout)\n    return stypes.cMatrixToNumpy(mout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming a vector to a new coordinate system rotated by angle radians about axis iaxis. This transformation rotates v1 by angle radians about the specified axis. http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/rotvec_c.html :param v1: Vector whose coordinate system is to be rotated. :type v1: 3-Element Array of floats :param angle: Angle of rotation (radians). :type angle: float :param iaxis: Axis of rotation X=1, Y=2, Z=3. :type iaxis: int :return: the vector expressed in the new coordinate system. :rtype: 3-Element Array of floats", "response": "def rotvec(v1, angle, iaxis):\n    \"\"\"\n    Transform a vector to a new coordinate system rotated by angle\n    radians about axis iaxis.  This transformation rotates v1 by\n    angle radians about the specified axis.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/rotvec_c.html\n\n    :param v1: Vector whose coordinate system is to be rotated.\n    :type v1: 3-Element Array of floats\n    :param angle: Angle of rotation (radians).\n    :type angle: float\n    :param iaxis: Axis of rotation X=1, Y=2, Z=3.\n    :type iaxis: int\n    :return: the vector expressed in the new coordinate system.\n    :rtype: 3-Element Array of floats\n    \"\"\"\n    v1 = stypes.toDoubleVector(v1)\n    angle = ctypes.c_double(angle)\n    iaxis = ctypes.c_int(iaxis)\n    vout = stypes.emptyDoubleVector(3)\n    libspice.rotvec_c(v1, angle, iaxis, vout)\n    return stypes.cVectorToPython(vout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rquad(a, b, c):\n    a = ctypes.c_double(a)\n    b = ctypes.c_double(b)\n    c = ctypes.c_double(c)\n    root1 = stypes.emptyDoubleVector(2)\n    root2 = stypes.emptyDoubleVector(2)\n    libspice.rquad_c(a, b, c, root1, root2)\n    return stypes.cVectorToPython(root1), stypes.cVectorToPython(root2)", "response": "Find the roots of a quadratic equation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind semi - axis vectors of an ellipse generated by two arbitrary vectors.", "response": "def saelgv(vec1, vec2):\n    \"\"\"\n    Find semi-axis vectors of an ellipse generated by two arbitrary\n    three-dimensional vectors.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/saelgv_c.html\n\n    :param vec1: First vector used to generate an ellipse.\n    :type vec1: 3-Element Array of floats\n    :param vec2: Second vector used to generate an ellipse.\n    :type vec2: 3-Element Array of floats\n    :return: Semi-major axis of ellipse, Semi-minor axis of ellipse.\n    :rtype: tuple\n    \"\"\"\n    vec1 = stypes.toDoubleVector(vec1)\n    vec2 = stypes.toDoubleVector(vec2)\n    smajor = stypes.emptyDoubleVector(3)\n    sminor = stypes.emptyDoubleVector(3)\n    libspice.saelgv_c(vec1, vec2, smajor, sminor)\n    return stypes.cVectorToPython(smajor), stypes.cVectorToPython(sminor)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scard(incard, cell):\n    assert isinstance(cell, stypes.SpiceCell)\n    incard = ctypes.c_int(incard)\n    libspice.scard_c(incard, ctypes.byref(cell))\n    return cell", "response": "This routine is used to set the cardinality of a SPICE cell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert double precision encoding of spacecraft clock time into a character representation.", "response": "def scdecd(sc, sclkdp, lenout=_default_len_out, MXPART=None):\n    # todo: figure out how to use mxpart\n    \"\"\"\n    Convert double precision encoding of spacecraft clock time into\n    a character representation.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/scdecd_c.html\n\n    :param sc: NAIF spacecraft identification code.\n    :type sc: int\n    :param sclkdp: Encoded representation of a spacecraft clock count.\n    :type sclkdp: float\n    :param lenout: Maximum allowed length of output SCLK string.\n    :type lenout: int\n    :param MXPART: Maximum number of spacecraft clock partitions.\n    :type MXPART: int\n    :return: Character representation of a clock count.\n    :rtype: str\n    \"\"\"\n    sc = ctypes.c_int(sc)\n    sclkdp = ctypes.c_double(sclkdp)\n    sclkch = stypes.stringToCharP(\" \" * lenout)\n    lenout = ctypes.c_int(lenout)\n    libspice.scdecd_c(sc, sclkdp, lenout, sclkch)\n    return stypes.toPythonString(sclkch)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sce2c(sc, et):\n    sc = ctypes.c_int(sc)\n    et = ctypes.c_double(et)\n    sclkdp = ctypes.c_double()\n    libspice.sce2c_c(sc, et, ctypes.byref(sclkdp))\n    return sclkdp.value", "response": "Convert a NAIF spacecraft clock time to continuous encoded alphabetical tick values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sce2s(sc, et, lenout=_default_len_out):\n    sc = ctypes.c_int(sc)\n    et = ctypes.c_double(et)\n    sclkch = stypes.stringToCharP(\" \" * lenout)\n    lenout = ctypes.c_int(lenout)\n    libspice.sce2s_c(sc, et, lenout, sclkch)\n    return stypes.toPythonString(sclkch)", "response": "Convert an Ephemeris spacecraft clock ID code and time to an SCLK character string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a NAIF spacecraft clock time from seconds past J2000 to integral spacecraft clock ticks.", "response": "def sce2t(sc, et):\n    \"\"\"\n    Convert ephemeris seconds past J2000 (ET) to integral\n    encoded spacecraft clock (\"ticks\"). For conversion to\n    fractional ticks, (required for C-kernel production), see\n    the routine :func:`sce2c`.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/sce2t_c.html\n\n    :param sc: NAIF spacecraft ID code.\n    :type sc: int\n    :param et: Ephemeris time, seconds past J2000.\n    :type et: float\n    :return: SCLK, encoded as ticks since spacecraft clock start.\n    :rtype: float\n    \"\"\"\n    sc = ctypes.c_int(sc)\n    et = ctypes.c_double(et)\n    sclkdp = ctypes.c_double()\n    libspice.sce2t_c(sc, et, ctypes.byref(sclkdp))\n    return sclkdp.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nencode a character representation of spacecraft clock time into a double precision number.", "response": "def scencd(sc, sclkch, MXPART=None):\n    \"\"\"\n    Encode character representation of spacecraft clock time into a\n    double precision number.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/scencd_c.html\n\n    :param sc: NAIF spacecraft identification code.\n    :type sc: int\n    :param sclkch: Character representation of a spacecraft clock.\n    :type sclkch: str\n    :param MXPART: Maximum number of spacecraft clock partitions.\n    :type MXPART: int\n    :return: Encoded representation of the clock count.\n    :rtype: float\n    \"\"\"\n    sc = ctypes.c_int(sc)\n    sclkch = stypes.stringToCharP(sclkch)\n    sclkdp = ctypes.c_double()\n    libspice.scencd_c(sc, sclkch, ctypes.byref(sclkdp))\n    return sclkdp.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scfmt(sc, ticks, lenout=_default_len_out):\n    sc = ctypes.c_int(sc)\n    ticks = ctypes.c_double(ticks)\n    clkstr = stypes.stringToCharP(lenout)\n    lenout = ctypes.c_int(lenout)\n    libspice.scfmt_c(sc, ticks, lenout, clkstr)\n    return stypes.toPythonString(clkstr)", "response": "Convert encoded spacecraft clock ticks to character clock format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scpart(sc):\n    sc = ctypes.c_int(sc)\n    nparts = ctypes.c_int()\n    pstart = stypes.emptyDoubleVector(9999)\n    pstop = stypes.emptyDoubleVector(9999)\n    libspice.scpart_c(sc, nparts, pstart, pstop)\n    return stypes.cVectorToPython(pstart)[0:nparts.value], stypes.cVectorToPython(\n            pstop)[0:nparts.value]", "response": "Return the number of spacecraft clock partitions and the start and stop times of the spacecraft clock kernel file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scs2e(sc, sclkch):\n    sc = ctypes.c_int(sc)\n    sclkch = stypes.stringToCharP(sclkch)\n    et = ctypes.c_double()\n    libspice.scs2e_c(sc, sclkch, ctypes.byref(et))\n    return et.value", "response": "Convert a spacecraft clock string to ephemeris seconds past J2000."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sct2e(sc, sclkdp):\n    sc = ctypes.c_int(sc)\n    sclkdp = ctypes.c_double(sclkdp)\n    et = ctypes.c_double()\n    libspice.sct2e_c(sc, sclkdp, ctypes.byref(et))\n    return et.value", "response": "Convert encoded spacecraft clock ticks to ephemeris time seconds past J2000."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a spacecraft clock format string to number of ticks.", "response": "def sctiks(sc, clkstr):\n    \"\"\"\n    Convert a spacecraft clock format string to number of \"ticks\".\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/sctiks_c.html\n\n    :param sc: NAIF spacecraft identification code.\n    :type sc: int\n    :param clkstr: Character representation of a spacecraft clock.\n    :type clkstr: str\n    :return: Number of ticks represented by the clock string.\n    :rtype: float\n    \"\"\"\n    sc = ctypes.c_int(sc)\n    clkstr = stypes.stringToCharP(clkstr)\n    ticks = ctypes.c_double()\n    libspice.sctiks_c(sc, clkstr, ctypes.byref(ticks))\n    return ticks.value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sdiff(a, b):\n    assert isinstance(a, stypes.SpiceCell)\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == b.dtype\n    # The next line was redundant with the [raise NotImplementedError] line below\n    # assert a.dtype == 0 or a.dtype == 1 or a.dtype == 2\n    if a.dtype is 0:\n        c = stypes.SPICECHAR_CELL(a.size, a.length)\n    elif a.dtype is 1:\n        c = stypes.SPICEDOUBLE_CELL(a.size)\n    elif a.dtype is 2:\n        c = stypes.SPICEINT_CELL(a.size)\n    else:\n        raise NotImplementedError\n    libspice.sdiff_c(ctypes.byref(a), ctypes.byref(b), ctypes.byref(c))\n    return c", "response": "Return the symmetric difference of two sets of any data type to form a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_c(a, op, b):\n    assert isinstance(a, stypes.SpiceCell)\n    assert isinstance(b, stypes.SpiceCell)\n    assert a.dtype == b.dtype\n    assert isinstance(op, str)\n    op = stypes.stringToCharP(op)\n    return bool(libspice.set_c(ctypes.byref(a), op, ctypes.byref(b)))", "response": "Compare two sets of any data type and return a boolean indicating if the set is successful."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsorting an array of character strings according to the ASCII Shell Sort algorithm.", "response": "def shellc(ndim, lenvals, array):\n    # This works! looks like this is a mutable 2d char array\n    \"\"\"\n    Sort an array of character strings according to the ASCII\n    collating sequence using the Shell Sort algorithm.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/shellc_c.html\n\n    :param ndim: Dimension of the array.\n    :type ndim: int\n    :param lenvals: String length.\n    :type lenvals: int\n    :param array: The array to be sorted.\n    :type array: list of str.\n    :return: The sorted array.\n    :rtype: list of str.\n    \"\"\"\n    array = stypes.listToCharArray(array, xLen=lenvals, yLen=ndim)\n    ndim = ctypes.c_int(ndim)\n    lenvals = ctypes.c_int(lenvals)\n    libspice.shellc_c(ndim, lenvals, ctypes.byref(array))\n    return stypes.cVectorToPython(array)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shelld(ndim, array):\n    # Works!, use this as example for \"I/O\" parameters\n    \"\"\"\n    Sort a double precision array using the Shell Sort algorithm.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/shelld_c.html\n\n    :param ndim: Dimension of the array.\n    :type ndim: int\n    :param array: The array to be sorted.\n    :type array: Array of floats\n    :return: The sorted array.\n    :rtype: Array of floats\n    \"\"\"\n    array = stypes.toDoubleVector(array)\n    ndim = ctypes.c_int(ndim)\n    libspice.shelld_c(ndim, ctypes.cast(array, ctypes.POINTER(ctypes.c_double)))\n    return stypes.cVectorToPython(array)", "response": "Sort a double precision array using the Shell Sort algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsort an integer array using the Shell Sort algorithm.", "response": "def shelli(ndim, array):\n    # Works!, use this as example for \"I/O\" parameters\n    \"\"\"\n    Sort an integer array using the Shell Sort algorithm.\n\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/shelli_c.html\n\n    :param ndim: Dimension of the array.\n    :type ndim: int\n    :param array: The array to be sorted.\n    :type array: Array of ints\n    :return: The sorted array.\n    :rtype: Array of ints\n    \"\"\"\n    array = stypes.toIntVector(array)\n    ndim = ctypes.c_int(ndim)\n    libspice.shelli_c(ndim, ctypes.cast(array, ctypes.POINTER(ctypes.c_int)))\n    return stypes.cVectorToPython(array)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sincpt(method, target, et, fixref, abcorr, obsrvr, dref, dvec):\n    method = stypes.stringToCharP(method)\n    target = stypes.stringToCharP(target)\n    et = ctypes.c_double(et)\n    fixref = stypes.stringToCharP(fixref)\n    abcorr = stypes.stringToCharP(abcorr)\n    obsrvr = stypes.stringToCharP(obsrvr)\n    dref = stypes.stringToCharP(dref)\n    dvec = stypes.toDoubleVector(dvec)\n    spoint = stypes.emptyDoubleVector(3)\n    trgepc = ctypes.c_double(0)\n    srfvec = stypes.emptyDoubleVector(3)\n    found = ctypes.c_int(0)\n    libspice.sincpt_c(method, target, et, fixref, abcorr, obsrvr, dref, dvec,\n                      spoint, ctypes.byref(trgepc), srfvec, ctypes.byref(found))\n    return stypes.cVectorToPython(spoint), trgepc.value, stypes.cVectorToPython(\n            srfvec), bool(found.value)", "response": "Compute the surface intercept of a ray on a target body at a specified epoch optionally corrected for light time and stellar\n    aberration."}
